---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0016557254
Z variance train             0.6929989
KL Divergence                0.1493272
KL Loss                      0.014932721
QF Loss                      52.754097
VF Loss                      29.104033
Policy Loss                  -5.356247
Q Predictions Mean           -8.268626e-05
Q Predictions Std            0.0018177214
Q Predictions Max            0.0041797124
Q Predictions Min            -0.005514064
V Predictions Mean           -0.0037715207
V Predictions Std            0.002017618
V Predictions Max            0.0011805382
V Predictions Min            -0.013789941
Log Pis Mean                 -5.375225
Log Pis Std                  0.6116294
Log Pis Max                  -3.6759536
Log Pis Min                  -7.1185293
Policy mu Mean               0.00077328447
Policy mu Std                0.0022656973
Policy mu Max                0.0069492925
Policy mu Min                -0.004265392
Policy log std Mean          0.00072304124
Policy log std Std           0.0014439642
Policy log std Max           0.004306564
Policy log std Min           -0.0039009256
Z mean eval                  0.16604769
Z variance eval              0.007234956
total_rewards                [-17.60499484  13.35571356  51.63248204  46.87651718  -8.98870907
 -43.68421328  22.16198584  21.03603866  -8.48487064  15.42885058]
total_rewards_mean           9.172880002358713
total_rewards_std            27.82630607395378
total_rewards_max            51.63248204493958
total_rewards_min            -43.68421328249631
Number of train steps total  4000
Number of env steps total    7000
Number of rollouts total     0
Train Time (s)               116.19819777132943
(Previous) Eval Time (s)     0
Sample Time (s)              22.07810948928818
Epoch Time (s)               138.2763072606176
Total Train Time (s)         153.95894283102825
Epoch                        0
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:34:08.602226 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #0 | Epoch Duration: 153.9650948047638
2020-01-11 23:34:08.602559 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #0 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.16819963
Z variance train             0.0071961344
KL Divergence                10.0271
KL Loss                      1.00271
QF Loss                      194.02449
VF Loss                      34.559074
Policy Loss                  -61.737816
Q Predictions Mean           59.880802
Q Predictions Std            23.16639
Q Predictions Max            117.18459
Q Predictions Min            -10.564855
V Predictions Mean           62.727314
V Predictions Std            22.023817
V Predictions Max            116.99882
V Predictions Min            -4.9054704
Log Pis Mean                 -2.5331342
Log Pis Std                  1.624151
Log Pis Max                  0.948789
Log Pis Min                  -6.8194485
Policy mu Mean               0.014512969
Policy mu Std                0.42519265
Policy mu Max                1.3198265
Policy mu Min                -1.3852552
Policy log std Mean          -0.7333908
Policy log std Std           0.120087765
Policy log std Max           -0.35059223
Policy log std Min           -1.1615745
Z mean eval                  0.30351847
Z variance eval              0.0063232398
total_rewards                [ 5.91496447e+00 -3.81466766e+01 -5.88509057e+01 -1.45280352e+02
 -1.72239663e+02  1.33738772e+01 -2.50841237e+01 -2.03290609e+01
 -1.61243492e+01 -4.46776807e-02]
total_rewards_mean           -45.68109669444744
total_rewards_std            60.2828186125797
total_rewards_max            13.373877180011378
total_rewards_min            -172.23966267420434
Number of train steps total  8000
Number of env steps total    12000
Number of rollouts total     0
Train Time (s)               113.55103554110974
(Previous) Eval Time (s)     15.688445764128119
Sample Time (s)              17.90402339072898
Epoch Time (s)               147.14350469596684
Total Train Time (s)         298.21981471730396
Epoch                        1
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:36:32.862844 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #1 | Epoch Duration: 144.2600336074829
2020-01-11 23:36:32.863075 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #1 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.30134124
Z variance train             0.0064027393
KL Divergence                10.52693
KL Loss                      1.052693
QF Loss                      174.38744
VF Loss                      57.9358
Policy Loss                  -109.93296
Q Predictions Mean           106.076904
Q Predictions Std            32.411625
Q Predictions Max            187.38617
Q Predictions Min            -26.830505
V Predictions Mean           112.79932
V Predictions Std            28.276733
V Predictions Max            200.21901
V Predictions Min            13.692856
Log Pis Mean                 -2.2679672
Log Pis Std                  2.0522463
Log Pis Max                  6.72944
Log Pis Min                  -8.647721
Policy mu Mean               0.068976045
Policy mu Std                0.47987288
Policy mu Max                1.4986684
Policy mu Min                -1.4773487
Policy log std Mean          -0.7120058
Policy log std Std           0.16020724
Policy log std Max           -0.3199265
Policy log std Min           -1.2472335
Z mean eval                  0.40541297
Z variance eval              0.012820487
total_rewards                [ -14.08723471    5.80708935   14.43120048   -4.35391692  -20.12298265
  -68.81722093  -53.87070232 -131.67830207  -45.28636533 -159.05745674]
total_rewards_mean           -47.70358918493601
total_rewards_std            55.168075877461156
total_rewards_max            14.431200481995164
total_rewards_min            -159.05745674228933
Number of train steps total  12000
Number of env steps total    17000
Number of rollouts total     0
Train Time (s)               109.96999209793285
(Previous) Eval Time (s)     12.80471076304093
Sample Time (s)              17.42193667171523
Epoch Time (s)               140.196639532689
Total Train Time (s)         437.56045416370034
Epoch                        2
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:38:52.203214 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #2 | Epoch Duration: 139.33997917175293
2020-01-11 23:38:52.203373 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #2 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.3919789
Z variance train             0.011497242
KL Divergence                9.232474
KL Loss                      0.92324746
QF Loss                      218.5252
VF Loss                      76.78125
Policy Loss                  -128.64519
Q Predictions Mean           125.28686
Q Predictions Std            36.087143
Q Predictions Max            197.80775
Q Predictions Min            -27.626669
V Predictions Mean           130.56723
V Predictions Std            31.400347
V Predictions Max            215.92607
V Predictions Min            -15.581874
Log Pis Mean                 -2.1429114
Log Pis Std                  2.2292957
Log Pis Max                  8.02164
Log Pis Min                  -7.279838
Policy mu Mean               0.0103763705
Policy mu Std                0.49892092
Policy mu Max                2.3961952
Policy mu Min                -1.6512399
Policy log std Mean          -0.69014573
Policy log std Std           0.21911661
Policy log std Max           -0.24212581
Policy log std Min           -1.7927227
Z mean eval                  0.2919739
Z variance eval              0.005487942
total_rewards                [   6.92688829   38.38437056 -103.10756857   39.09349298   46.74773329
   15.65209713   84.68472552   21.33555679   35.1379713     1.48660042]
total_rewards_mean           18.634186771538968
total_rewards_std            46.370700714584295
total_rewards_max            84.68472551834482
total_rewards_min            -103.10756856559505
Number of train steps total  16000
Number of env steps total    22000
Number of rollouts total     0
Train Time (s)               109.10336342500523
(Previous) Eval Time (s)     11.947790580801666
Sample Time (s)              18.017202640417963
Epoch Time (s)               139.06835664622486
Total Train Time (s)         577.4074506773613
Epoch                        3
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:41:12.051148 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #3 | Epoch Duration: 139.84764075279236
2020-01-11 23:41:12.051304 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #3 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.27669212
Z variance train             0.005235535
KL Divergence                10.927242
KL Loss                      1.0927242
QF Loss                      166.59705
VF Loss                      60.71804
Policy Loss                  -136.35883
Q Predictions Mean           133.01233
Q Predictions Std            37.25695
Q Predictions Max            222.15971
Q Predictions Min            -15.773437
V Predictions Mean           139.32758
V Predictions Std            30.91908
V Predictions Max            223.83867
V Predictions Min            17.067284
Log Pis Mean                 -2.4046073
Log Pis Std                  2.1816897
Log Pis Max                  5.9278336
Log Pis Min                  -8.231848
Policy mu Mean               0.037428696
Policy mu Std                0.4546213
Policy mu Max                2.0060046
Policy mu Min                -1.7271248
Policy log std Mean          -0.74412525
Policy log std Std           0.22047335
Policy log std Max           -0.26420823
Policy log std Min           -1.7383271
Z mean eval                  0.34639084
Z variance eval              0.013438998
total_rewards                [-119.81271899    8.3455892    24.1674926   134.65844506   12.20136997
   16.21986922  -56.86621259   45.65447197   42.2248904    65.57842847]
total_rewards_mean           17.237162532409894
total_rewards_std            64.79508428505301
total_rewards_max            134.65844506124301
total_rewards_min            -119.81271898678288
Number of train steps total  20000
Number of env steps total    27000
Number of rollouts total     0
Train Time (s)               109.83360880007967
(Previous) Eval Time (s)     12.726760085206479
Sample Time (s)              18.29402000643313
Epoch Time (s)               140.85438889171928
Total Train Time (s)         715.3392711151391
Epoch                        4
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:43:29.986560 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #4 | Epoch Duration: 137.93509125709534
2020-01-11 23:43:29.986841 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #4 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.354583
Z variance train             0.014409805
KL Divergence                8.971459
KL Loss                      0.8971459
QF Loss                      185.04852
VF Loss                      40.34292
Policy Loss                  -155.23979
Q Predictions Mean           152.55826
Q Predictions Std            35.734524
Q Predictions Max            263.99298
Q Predictions Min            -8.048279
V Predictions Mean           157.39001
V Predictions Std            30.541035
V Predictions Max            258.59186
V Predictions Min            13.913042
Log Pis Mean                 -2.3943744
Log Pis Std                  2.3115118
Log Pis Max                  8.727685
Log Pis Min                  -10.018734
Policy mu Mean               0.0032437656
Policy mu Std                0.44827643
Policy mu Max                1.7828585
Policy mu Min                -1.9303122
Policy log std Mean          -0.73720455
Policy log std Std           0.20847563
Policy log std Max           -0.33139914
Policy log std Min           -1.9015751
Z mean eval                  0.43102294
Z variance eval              0.008563849
total_rewards                [-92.53534339  16.01029049  15.82039873 -19.165478     8.11433788
 -90.83734425  76.35310205  -6.61060779  12.76621182 -32.837701  ]
total_rewards_mean           -11.29221334563874
total_rewards_std            48.573276198530834
total_rewards_max            76.3531020507347
total_rewards_min            -92.53534338527345
Number of train steps total  24000
Number of env steps total    32000
Number of rollouts total     0
Train Time (s)               112.42206495907158
(Previous) Eval Time (s)     9.807144348975271
Sample Time (s)              18.17978531587869
Epoch Time (s)               140.40899462392554
Total Train Time (s)         863.9145199153572
Epoch                        5
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:45:58.562540 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #5 | Epoch Duration: 148.57541155815125
2020-01-11 23:45:58.562875 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #5 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.42661238
Z variance train             0.0076286136
KL Divergence                10.327846
KL Loss                      1.0327846
QF Loss                      180.77545
VF Loss                      49.57016
Policy Loss                  -179.45529
Q Predictions Mean           173.12912
Q Predictions Std            29.12573
Q Predictions Max            257.11835
Q Predictions Min            -7.4034295
V Predictions Mean           179.04858
V Predictions Std            23.943752
V Predictions Max            262.5966
V Predictions Min            50.561703
Log Pis Mean                 -2.5800304
Log Pis Std                  1.9398966
Log Pis Max                  4.07501
Log Pis Min                  -10.075164
Policy mu Mean               0.044620834
Policy mu Std                0.4418192
Policy mu Max                1.9984663
Policy mu Min                -1.7350558
Policy log std Mean          -0.73165226
Policy log std Std           0.19486831
Policy log std Max           -0.2725948
Policy log std Min           -1.763667
Z mean eval                  0.4726986
Z variance eval              0.007777387
total_rewards                [106.67293437  36.52779114   2.19467058  45.26346048 -28.33657913
  68.66756834  18.53859602  12.18363385 -50.42363439  30.1281833 ]
total_rewards_mean           24.14166245799076
total_rewards_std            42.89447597793111
total_rewards_max            106.6729343736156
total_rewards_min            -50.423634387896286
Number of train steps total  28000
Number of env steps total    37000
Number of rollouts total     0
Train Time (s)               114.57470580283552
(Previous) Eval Time (s)     17.973269758280367
Sample Time (s)              18.059797742869705
Epoch Time (s)               150.6077733039856
Total Train Time (s)         1010.4701430802234
Epoch                        6
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:48:25.118725 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #6 | Epoch Duration: 146.55565333366394
2020-01-11 23:48:25.118947 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #6 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.48092914
Z variance train             0.008655979
KL Divergence                10.426775
KL Loss                      1.0426775
QF Loss                      155.19167
VF Loss                      55.9276
Policy Loss                  -190.1684
Q Predictions Mean           184.4142
Q Predictions Std            36.59394
Q Predictions Max            263.81848
Q Predictions Min            -23.278572
V Predictions Mean           186.84552
V Predictions Std            30.19821
V Predictions Max            263.58188
V Predictions Min            6.6122546
Log Pis Mean                 -2.5720186
Log Pis Std                  2.4037209
Log Pis Max                  9.45011
Log Pis Min                  -9.055099
Policy mu Mean               0.00012740726
Policy mu Std                0.4128502
Policy mu Max                1.3733547
Policy mu Min                -1.6455287
Policy log std Mean          -0.739376
Policy log std Std           0.22382906
Policy log std Max           -0.2972328
Policy log std Min           -1.9747791
Z mean eval                  0.5491973
Z variance eval              0.018735189
total_rewards                [  45.79944131 -165.04443763    9.82383978   71.44751179  -39.98545995
   32.39385557  117.39424492  -18.38063874   -0.63111642   35.23613449]
total_rewards_mean           8.805337512168697
total_rewards_std            71.95318567509527
total_rewards_max            117.39424492135933
total_rewards_min            -165.0444376271735
Number of train steps total  32000
Number of env steps total    42000
Number of rollouts total     0
Train Time (s)               118.49702110514045
(Previous) Eval Time (s)     13.92089219018817
Sample Time (s)              17.963643585331738
Epoch Time (s)               150.38155688066036
Total Train Time (s)         1170.0652904873714
Epoch                        7
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:51:04.720086 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #7 | Epoch Duration: 159.6008493900299
2020-01-11 23:51:04.720543 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #7 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.54895985
Z variance train             0.018939678
KL Divergence                9.672497
KL Loss                      0.9672497
QF Loss                      200.96165
VF Loss                      47.390778
Policy Loss                  -205.62346
Q Predictions Mean           202.78343
Q Predictions Std            41.601944
Q Predictions Max            294.3759
Q Predictions Min            -8.757319
V Predictions Mean           206.58774
V Predictions Std            34.870422
V Predictions Max            292.06064
V Predictions Min            14.474457
Log Pis Mean                 -2.2796497
Log Pis Std                  2.3357239
Log Pis Max                  7.660469
Log Pis Min                  -8.834877
Policy mu Mean               0.02108236
Policy mu Std                0.4393405
Policy mu Max                2.289349
Policy mu Min                -1.6758432
Policy log std Mean          -0.75688386
Policy log std Std           0.20676744
Policy log std Max           -0.33692014
Policy log std Min           -1.7947705
Z mean eval                  0.52587205
Z variance eval              0.0122599285
total_rewards                [ 71.51742835  92.49383458   4.77931086 100.45816375 -15.33702685
   2.17937227  24.08987122  43.11383698 195.49341196 149.89042565]
total_rewards_mean           66.86786287903087
total_rewards_std            65.14241193171146
total_rewards_max            195.49341196412306
total_rewards_min            -15.337026846495808
Number of train steps total  36000
Number of env steps total    47000
Number of rollouts total     0
Train Time (s)               108.72885172488168
(Previous) Eval Time (s)     23.139865199569613
Sample Time (s)              17.411316791083664
Epoch Time (s)               149.28003371553496
Total Train Time (s)         1312.7032128931023
Epoch                        8
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:53:27.354811 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #8 | Epoch Duration: 142.6340229511261
2020-01-11 23:53:27.355034 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #8 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.62708116
Z variance train             0.016962882
KL Divergence                9.316777
KL Loss                      0.93167776
QF Loss                      161.59988
VF Loss                      69.740944
Policy Loss                  -229.99153
Q Predictions Mean           226.9124
Q Predictions Std            48.66098
Q Predictions Max            328.9597
Q Predictions Min            -12.211094
V Predictions Mean           231.58678
V Predictions Std            42.46088
V Predictions Max            321.338
V Predictions Min            -8.345267
Log Pis Mean                 -2.646676
Log Pis Std                  2.463576
Log Pis Max                  9.222266
Log Pis Min                  -9.945261
Policy mu Mean               -0.011502814
Policy mu Std                0.42435133
Policy mu Max                1.9747018
Policy mu Min                -2.5736635
Policy log std Mean          -0.7454102
Policy log std Std           0.21901275
Policy log std Max           -0.24118164
Policy log std Min           -2.1627755
Z mean eval                  0.6814079
Z variance eval              0.010947429
total_rewards                [254.41450339 162.11821494  48.36328457 120.85337924 -46.12130918
 127.97990239 380.2991232   -7.53408935  72.20080708  69.5862057 ]
total_rewards_mean           118.21600219929114
total_rewards_std            118.93224235481037
total_rewards_max            380.2991232021468
total_rewards_min            -46.121309184871784
Number of train steps total  40000
Number of env steps total    52000
Number of rollouts total     0
Train Time (s)               111.16891730204225
(Previous) Eval Time (s)     16.493600929155946
Sample Time (s)              17.927317420952022
Epoch Time (s)               145.5898356521502
Total Train Time (s)         1464.0381597457454
Epoch                        9
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:55:58.692997 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #9 | Epoch Duration: 151.3377561569214
2020-01-11 23:55:58.693320 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #9 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.53795785
Z variance train             0.007889065
KL Divergence                11.091391
KL Loss                      1.1091391
QF Loss                      169.50154
VF Loss                      90.736046
Policy Loss                  -228.36314
Q Predictions Mean           222.14026
Q Predictions Std            46.730377
Q Predictions Max            318.14978
Q Predictions Min            -39.83706
V Predictions Mean           222.54517
V Predictions Std            39.190903
V Predictions Max            305.90952
V Predictions Min            -5.36947
Log Pis Mean                 -2.5325108
Log Pis Std                  2.5093534
Log Pis Max                  11.493405
Log Pis Min                  -9.357055
Policy mu Mean               0.029210571
Policy mu Std                0.42632303
Policy mu Max                2.341741
Policy mu Min                -2.0189464
Policy log std Mean          -0.77923435
Policy log std Std           0.19928274
Policy log std Max           -0.26033407
Policy log std Min           -2.0575655
Z mean eval                  0.6123659
Z variance eval              0.009269578
total_rewards                [214.80410719  50.83164738 166.06359789 188.30012641  57.26697489
  71.56552294  -1.90578485 273.58111976  49.74278554 109.8660034 ]
total_rewards_mean           118.01161005652693
total_rewards_std            83.83769493568462
total_rewards_max            273.5811197627358
total_rewards_min            -1.9057848486367277
Number of train steps total  44000
Number of env steps total    57000
Number of rollouts total     0
Train Time (s)               109.85632406687364
(Previous) Eval Time (s)     22.24118914268911
Sample Time (s)              18.545401849783957
Epoch Time (s)               150.6429150593467
Total Train Time (s)         1607.226104579866
Epoch                        10
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:58:21.881565 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #10 | Epoch Duration: 143.18800854682922
2020-01-11 23:58:21.881795 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #10 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7265876
Z variance train             0.011669965
KL Divergence                11.47793
KL Loss                      1.147793
QF Loss                      272.03232
VF Loss                      81.80172
Policy Loss                  -254.881
Q Predictions Mean           249.50743
Q Predictions Std            55.107998
Q Predictions Max            333.7848
Q Predictions Min            -42.98548
V Predictions Mean           253.41483
V Predictions Std            44.870926
V Predictions Max            326.83646
V Predictions Min            -10.591139
Log Pis Mean                 -2.0378747
Log Pis Std                  2.5517793
Log Pis Max                  9.259559
Log Pis Min                  -8.620846
Policy mu Mean               0.012480132
Policy mu Std                0.45395795
Policy mu Max                2.1972375
Policy mu Min                -2.6408384
Policy log std Mean          -0.7894882
Policy log std Std           0.21513735
Policy log std Max           -0.34805435
Policy log std Min           -1.8604531
Z mean eval                  0.7538227
Z variance eval              0.013833724
total_rewards                [ 57.09716909   5.91434868 148.3515192  250.79486917 186.39597447
  74.39286223 220.24190119 414.38662797  96.0217753   86.9278285 ]
total_rewards_mean           154.05248757941519
total_rewards_std            113.20634921211936
total_rewards_max            414.38662796655836
total_rewards_min            5.9143486824656835
Number of train steps total  48000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               114.74381820578128
(Previous) Eval Time (s)     14.78596408199519
Sample Time (s)              17.946970058139414
Epoch Time (s)               147.47675234591588
Total Train Time (s)         1762.6217588009313
Epoch                        11
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:00:57.278450 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #11 | Epoch Duration: 155.396484375
2020-01-12 00:00:57.278663 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #11 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.75762165
Z variance train             0.013817206
KL Divergence                11.091553
KL Loss                      1.1091553
QF Loss                      153.73975
VF Loss                      84.17034
Policy Loss                  -261.27466
Q Predictions Mean           255.63225
Q Predictions Std            50.83563
Q Predictions Max            352.40396
Q Predictions Min            -25.365326
V Predictions Mean           255.39688
V Predictions Std            45.99889
V Predictions Max            337.15692
V Predictions Min            -43.90088
Log Pis Mean                 -2.1357987
Log Pis Std                  2.5350592
Log Pis Max                  9.612739
Log Pis Min                  -8.292886
Policy mu Mean               0.050483786
Policy mu Std                0.44077095
Policy mu Max                1.8828764
Policy mu Min                -2.0537484
Policy log std Mean          -0.7806127
Policy log std Std           0.19332306
Policy log std Max           -0.26168716
Policy log std Min           -1.8386457
Z mean eval                  0.6180913
Z variance eval              0.017777456
total_rewards                [ 27.64656167  16.58171603 236.52279457 308.13640763  68.31791657
 256.77247854  55.50545516  25.63322864 224.2974874  144.60768453]
total_rewards_mean           136.4021730734569
total_rewards_std            105.5618028679598
total_rewards_max            308.1364076282269
total_rewards_min            16.581716028063788
Number of train steps total  52000
Number of env steps total    67000
Number of rollouts total     0
Train Time (s)               113.78961632214487
(Previous) Eval Time (s)     22.705412095878273
Sample Time (s)              17.42523290636018
Epoch Time (s)               153.92026132438332
Total Train Time (s)         1908.3904392365366
Epoch                        12
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:03:23.047075 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #12 | Epoch Duration: 145.76825833320618
2020-01-12 00:03:23.047271 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #12 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7466837
Z variance train             0.023730373
KL Divergence                10.666201
KL Loss                      1.0666201
QF Loss                      223.69681
VF Loss                      68.33354
Policy Loss                  -270.5996
Q Predictions Mean           267.8305
Q Predictions Std            56.735874
Q Predictions Max            349.96277
Q Predictions Min            -34.761387
V Predictions Mean           269.64102
V Predictions Std            50.6908
V Predictions Max            345.57715
V Predictions Min            -36.54904
Log Pis Mean                 -2.0602694
Log Pis Std                  2.3970678
Log Pis Max                  12.8614235
Log Pis Min                  -9.983359
Policy mu Mean               -0.02816587
Policy mu Std                0.4372748
Policy mu Max                2.2905178
Policy mu Min                -3.4924884
Policy log std Mean          -0.8151484
Policy log std Std           0.2032098
Policy log std Max           -0.33146283
Policy log std Min           -1.8674424
Z mean eval                  0.6204003
Z variance eval              0.02095216
total_rewards                [ 79.87875776  28.67215252 182.12728478 246.40147061 224.87747681
 287.81176191 295.87934613 184.58352613 195.25728387 232.39207144]
total_rewards_mean           195.78811319773916
total_rewards_std            80.56644797244401
total_rewards_max            295.87934612853843
total_rewards_min            28.672152522351148
Number of train steps total  56000
Number of env steps total    72000
Number of rollouts total     0
Train Time (s)               111.02107962500304
(Previous) Eval Time (s)     14.553137619048357
Sample Time (s)              18.132792524062097
Epoch Time (s)               143.7070097681135
Total Train Time (s)         2059.1421405728906
Epoch                        13
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:05:53.802544 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #13 | Epoch Duration: 150.75513434410095
2020-01-12 00:05:53.802737 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #13 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.62732375
Z variance train             0.018901419
KL Divergence                11.581184
KL Loss                      1.1581185
QF Loss                      162.03738
VF Loss                      55.75673
Policy Loss                  -283.74
Q Predictions Mean           280.88382
Q Predictions Std            38.5132
Q Predictions Max            354.45642
Q Predictions Min            -21.032068
V Predictions Mean           288.62564
V Predictions Std            35.15435
V Predictions Max            350.39706
V Predictions Min            49.792957
Log Pis Mean                 -2.4064689
Log Pis Std                  1.9501308
Log Pis Max                  6.054588
Log Pis Min                  -9.845343
Policy mu Mean               0.052915238
Policy mu Std                0.39143455
Policy mu Max                1.5800916
Policy mu Min                -1.3432587
Policy log std Mean          -0.80069494
Policy log std Std           0.17417924
Policy log std Max           -0.3575375
Policy log std Min           -1.7395934
Z mean eval                  0.64031965
Z variance eval              0.019566564
total_rewards                [363.84811788  51.18694986 315.38740276 128.45595635  34.44647389
 149.53722712 230.29329861 176.96740658  33.08083429 494.02076222]
total_rewards_mean           197.72244295676992
total_rewards_std            145.97442314185838
total_rewards_max            494.0207622249577
total_rewards_min            33.08083428886948
Number of train steps total  60000
Number of env steps total    77000
Number of rollouts total     0
Train Time (s)               110.8036199901253
(Previous) Eval Time (s)     21.600948280654848
Sample Time (s)              17.93537131883204
Epoch Time (s)               150.3399395896122
Total Train Time (s)         2207.3446759446524
Epoch                        14
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:08:22.003326 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #14 | Epoch Duration: 148.2004430294037
2020-01-12 00:08:22.003522 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #14 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7295421
Z variance train             0.023297166
KL Divergence                11.092532
KL Loss                      1.1092533
QF Loss                      253.24496
VF Loss                      57.166634
Policy Loss                  -293.0909
Q Predictions Mean           289.93427
Q Predictions Std            48.59239
Q Predictions Max            364.88535
Q Predictions Min            -24.648682
V Predictions Mean           292.61322
V Predictions Std            41.92979
V Predictions Max            367.22507
V Predictions Min            17.796116
Log Pis Mean                 -2.3472228
Log Pis Std                  2.2482948
Log Pis Max                  8.346342
Log Pis Min                  -8.63187
Policy mu Mean               0.045360908
Policy mu Std                0.39607286
Policy mu Max                2.1339242
Policy mu Min                -2.0646017
Policy log std Mean          -0.8158784
Policy log std Std           0.21115597
Policy log std Max           -0.30850783
Policy log std Min           -1.8141317
Z mean eval                  0.642325
Z variance eval              0.016661486
total_rewards                [109.37376819 128.22201841 281.83567356 150.69142999  31.20888487
 333.94971346  67.31080667 117.93454234 128.1523275   57.44313267]
total_rewards_mean           140.61222976527392
total_rewards_std            91.3691461363644
total_rewards_max            333.9497134554594
total_rewards_min            31.20888487450321
Number of train steps total  64000
Number of env steps total    82000
Number of rollouts total     0
Train Time (s)               114.480137843173
(Previous) Eval Time (s)     19.46115732099861
Sample Time (s)              17.869511912576854
Epoch Time (s)               151.81080707674846
Total Train Time (s)         2350.6051533268765
Epoch                        15
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:10:45.267190 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #15 | Epoch Duration: 143.26349425315857
2020-01-12 00:10:45.267499 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #15 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6451837
Z variance train             0.016636936
KL Divergence                11.514625
KL Loss                      1.1514624
QF Loss                      276.85895
VF Loss                      33.685246
Policy Loss                  -299.37347
Q Predictions Mean           298.37097
Q Predictions Std            44.147736
Q Predictions Max            390.67734
Q Predictions Min            5.6229324
V Predictions Mean           300.7324
V Predictions Std            38.80815
V Predictions Max            391.05222
V Predictions Min            105.143486
Log Pis Mean                 -2.2980146
Log Pis Std                  1.9316088
Log Pis Max                  7.5276165
Log Pis Min                  -8.228662
Policy mu Mean               0.010506055
Policy mu Std                0.39925417
Policy mu Max                1.7180105
Policy mu Min                -1.8896122
Policy log std Mean          -0.8111822
Policy log std Std           0.18438388
Policy log std Max           -0.38116324
Policy log std Min           -1.8264754
Z mean eval                  0.6226741
Z variance eval              0.011578875
total_rewards                [429.86942316 137.54038043 195.57380695 201.79428218  34.91988149
 209.38657002 188.17495678 162.70953866 221.89367367 531.38289066]
total_rewards_mean           231.32454040119993
total_rewards_std            136.42419677228742
total_rewards_max            531.382890658713
total_rewards_min            34.91988148946263
Number of train steps total  68000
Number of env steps total    87000
Number of rollouts total     0
Train Time (s)               114.29883921984583
(Previous) Eval Time (s)     10.91355224326253
Sample Time (s)              18.002399965189397
Epoch Time (s)               143.21479142829776
Total Train Time (s)         2500.8333179098554
Epoch                        16
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:13:15.496477 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #16 | Epoch Duration: 150.22869443893433
2020-01-12 00:13:15.496792 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #16 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6187891
Z variance train             0.01166831
KL Divergence                13.089013
KL Loss                      1.3089013
QF Loss                      231.90656
VF Loss                      86.69714
Policy Loss                  -306.16537
Q Predictions Mean           304.51825
Q Predictions Std            50.39274
Q Predictions Max            417.7489
Q Predictions Min            21.16994
V Predictions Mean           305.2612
V Predictions Std            46.03028
V Predictions Max            416.13596
V Predictions Min            72.30245
Log Pis Mean                 -2.2172565
Log Pis Std                  2.064011
Log Pis Max                  8.463845
Log Pis Min                  -7.750527
Policy mu Mean               0.0251538
Policy mu Std                0.3839591
Policy mu Max                1.3637964
Policy mu Min                -1.5532469
Policy log std Mean          -0.83090323
Policy log std Std           0.18970834
Policy log std Max           -0.39877456
Policy log std Min           -1.9105175
Z mean eval                  0.6087526
Z variance eval              0.018110357
total_rewards                [202.14793579 270.18107859 690.35924454 134.08301511  57.12550479
 139.68884946 269.76045216 720.8134326  165.25811363 230.99557783]
total_rewards_mean           288.0413204497298
total_rewards_std            217.84075077691344
total_rewards_max            720.8134325976081
total_rewards_min            57.125504793917834
Number of train steps total  72000
Number of env steps total    92000
Number of rollouts total     0
Train Time (s)               110.06509669590741
(Previous) Eval Time (s)     17.927148669958115
Sample Time (s)              17.930706964805722
Epoch Time (s)               145.92295233067125
Total Train Time (s)         2649.2570078554563
Epoch                        17
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:15:43.922509 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #17 | Epoch Duration: 148.4255030155182
2020-01-12 00:15:43.922824 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #17 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.60782427
Z variance train             0.018049512
KL Divergence                12.4512615
KL Loss                      1.2451261
QF Loss                      183.09306
VF Loss                      44.43425
Policy Loss                  -312.23187
Q Predictions Mean           306.36304
Q Predictions Std            67.00193
Q Predictions Max            413.06747
Q Predictions Min            -14.10293
V Predictions Mean           312.97192
V Predictions Std            60.208477
V Predictions Max            413.3715
V Predictions Min            7.5589123
Log Pis Mean                 -1.7914908
Log Pis Std                  2.4873052
Log Pis Max                  10.590526
Log Pis Min                  -8.826147
Policy mu Mean               0.041119553
Policy mu Std                0.41777393
Policy mu Max                1.6298528
Policy mu Min                -3.017479
Policy log std Mean          -0.8754326
Policy log std Std           0.21429524
Policy log std Max           -0.3812679
Policy log std Min           -1.8623202
Z mean eval                  0.6011203
Z variance eval              0.011670643
total_rewards                [383.02338478 291.52253575 545.78960932 479.72639303 170.27448682
 434.50056605 120.18394624 550.35746409 889.90037276 226.95969964]
total_rewards_mean           409.2238458483423
total_rewards_std            215.32057322057673
total_rewards_max            889.9003727626772
total_rewards_min            120.18394623720235
Number of train steps total  76000
Number of env steps total    97000
Number of rollouts total     0
Train Time (s)               114.6102976934053
(Previous) Eval Time (s)     20.429377839900553
Sample Time (s)              17.339039749465883
Epoch Time (s)               152.37871528277174
Total Train Time (s)         2802.2556891920976
Epoch                        18
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:18:16.921640 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #18 | Epoch Duration: 152.99853444099426
2020-01-12 00:18:16.921917 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #18 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7847653
Z variance train             0.014262667
KL Divergence                13.286903
KL Loss                      1.3286904
QF Loss                      180.67552
VF Loss                      85.55326
Policy Loss                  -339.40714
Q Predictions Mean           336.8009
Q Predictions Std            71.10401
Q Predictions Max            450.96527
Q Predictions Min            -45.40299
V Predictions Mean           345.1254
V Predictions Std            65.4975
V Predictions Max            459.51184
V Predictions Min            18.87367
Log Pis Mean                 -1.9715803
Log Pis Std                  2.4660716
Log Pis Max                  13.309824
Log Pis Min                  -7.3668942
Policy mu Mean               0.008982204
Policy mu Std                0.40595388
Policy mu Max                1.8214128
Policy mu Min                -2.495315
Policy log std Mean          -0.86972904
Policy log std Std           0.18927713
Policy log std Max           -0.35400033
Policy log std Min           -1.8795683
Z mean eval                  0.63485783
Z variance eval              0.012880373
total_rewards                [380.46420375 595.13334442 114.1517207  302.71282621 126.40342959
 472.07526999 928.16840886 209.44856901 585.51923817 595.1340274 ]
total_rewards_mean           430.92110380970615
total_rewards_std            242.46399238436572
total_rewards_max            928.1684088599438
total_rewards_min            114.15172070117322
Number of train steps total  80000
Number of env steps total    102000
Number of rollouts total     0
Train Time (s)               117.14037275221199
(Previous) Eval Time (s)     21.048895636107773
Sample Time (s)              18.25170359155163
Epoch Time (s)               156.4409719798714
Total Train Time (s)         2959.0622985460795
Epoch                        19
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:20:53.730912 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #19 | Epoch Duration: 156.80878734588623
2020-01-12 00:20:53.731230 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #19 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7387627
Z variance train             0.016574964
KL Divergence                13.551935
KL Loss                      1.3551935
QF Loss                      243.39526
VF Loss                      78.18599
Policy Loss                  -360.7097
Q Predictions Mean           357.84845
Q Predictions Std            69.117546
Q Predictions Max            478.03278
Q Predictions Min            -34.305798
V Predictions Mean           363.15396
V Predictions Std            62.377
V Predictions Max            469.14148
V Predictions Min            33.981663
Log Pis Mean                 -1.7924025
Log Pis Std                  2.201364
Log Pis Max                  8.590601
Log Pis Min                  -7.5117264
Policy mu Mean               0.059005752
Policy mu Std                0.40936095
Policy mu Max                2.0014942
Policy mu Min                -1.8529161
Policy log std Mean          -0.85648805
Policy log std Std           0.18848684
Policy log std Max           -0.38345492
Policy log std Min           -1.8310081
Z mean eval                  0.6218583
Z variance eval              0.00910872
total_rewards                [232.10453764 449.65460668 172.62915522 637.59747799 217.3942447
 365.21916141 843.91454827 259.1142329  146.62894222 305.28282212]
total_rewards_mean           362.95397291433403
total_rewards_std            212.06418331831054
total_rewards_max            843.914548269719
total_rewards_min            146.62894221841725
Number of train steps total  84000
Number of env steps total    107000
Number of rollouts total     0
Train Time (s)               118.00917969457805
(Previous) Eval Time (s)     21.416426805779338
Sample Time (s)              18.53288654051721
Epoch Time (s)               157.9584930408746
Total Train Time (s)         3121.372093927581
Epoch                        20
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:23:36.041193 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #20 | Epoch Duration: 162.30973887443542
2020-01-12 00:23:36.041397 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #20 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7012373
Z variance train             0.011286443
KL Divergence                14.365691
KL Loss                      1.4365691
QF Loss                      168.44067
VF Loss                      38.59926
Policy Loss                  -360.35526
Q Predictions Mean           358.93414
Q Predictions Std            66.48354
Q Predictions Max            467.04272
Q Predictions Min            -0.057588458
V Predictions Mean           363.24615
V Predictions Std            63.18081
V Predictions Max            464.34283
V Predictions Min            49.958748
Log Pis Mean                 -2.2867367
Log Pis Std                  1.9851952
Log Pis Max                  9.665283
Log Pis Min                  -7.776854
Policy mu Mean               -0.008759032
Policy mu Std                0.39720917
Policy mu Max                1.3403383
Policy mu Min                -2.0957668
Policy log std Mean          -0.8399787
Policy log std Std           0.177023
Policy log std Max           -0.2793457
Policy log std Min           -1.6768059
Z mean eval                  0.6059256
Z variance eval              0.0082138
total_rewards                [124.3521548  158.65660312 474.62475196 440.39646751 178.51811351
 236.1439867  173.57244132 610.12165264 139.03480137 536.67397775]
total_rewards_mean           307.2094950669045
total_rewards_std            177.0408140474864
total_rewards_max            610.1216526389762
total_rewards_min            124.3521547961866
Number of train steps total  88000
Number of env steps total    112000
Number of rollouts total     0
Train Time (s)               111.46479338267818
(Previous) Eval Time (s)     25.767395588103682
Sample Time (s)              17.963848788756877
Epoch Time (s)               155.19603775953874
Total Train Time (s)         3270.8706108038314
Epoch                        21
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:26:05.539395 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #21 | Epoch Duration: 149.49784922599792
2020-01-12 00:26:05.539544 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #21 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6131198
Z variance train             0.0084932465
KL Divergence                14.243038
KL Loss                      1.4243039
QF Loss                      239.66805
VF Loss                      66.53248
Policy Loss                  -348.68283
Q Predictions Mean           346.4669
Q Predictions Std            69.73432
Q Predictions Max            473.44205
Q Predictions Min            30.310116
V Predictions Mean           351.35287
V Predictions Std            67.13282
V Predictions Max            467.52228
V Predictions Min            43.035873
Log Pis Mean                 -1.9383359
Log Pis Std                  2.2407868
Log Pis Max                  11.504784
Log Pis Min                  -7.8291826
Policy mu Mean               0.023056079
Policy mu Std                0.42321435
Policy mu Max                2.4513035
Policy mu Min                -1.8971394
Policy log std Mean          -0.84876746
Policy log std Std           0.18964449
Policy log std Max           -0.24805287
Policy log std Min           -1.9401025
Z mean eval                  0.60573125
Z variance eval              0.011187362
total_rewards                [100.25593024 572.85237563 236.65320443 520.02701019  55.53546944
 493.26858632 168.56100606 440.60610838 367.44502955 545.76121156]
total_rewards_mean           350.0965931801364
total_rewards_std            184.60321574890017
total_rewards_max            572.852375627006
total_rewards_min            55.535469441864706
Number of train steps total  92000
Number of env steps total    117000
Number of rollouts total     0
Train Time (s)               116.54082433506846
(Previous) Eval Time (s)     20.0689415843226
Sample Time (s)              17.52062190650031
Epoch Time (s)               154.13038782589138
Total Train Time (s)         3429.997372662183
Epoch                        22
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:28:44.667694 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #22 | Epoch Duration: 159.1280288696289
2020-01-12 00:28:44.667886 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #22 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.60520655
Z variance train             0.011212083
KL Divergence                13.834555
KL Loss                      1.3834555
QF Loss                      249.02426
VF Loss                      103.07175
Policy Loss                  -368.88486
Q Predictions Mean           365.49673
Q Predictions Std            74.91028
Q Predictions Max            485.32547
Q Predictions Min            29.89916
V Predictions Mean           372.2917
V Predictions Std            71.445915
V Predictions Max            490.80716
V Predictions Min            59.958076
Log Pis Mean                 -2.188159
Log Pis Std                  2.2748039
Log Pis Max                  8.509909
Log Pis Min                  -9.796627
Policy mu Mean               -0.04051527
Policy mu Std                0.40095636
Policy mu Max                2.2219908
Policy mu Min                -1.7221115
Policy log std Mean          -0.8501357
Policy log std Std           0.21310331
Policy log std Max           -0.20275879
Policy log std Min           -1.8785274
Z mean eval                  0.5761637
Z variance eval              0.0153865125
total_rewards                [ 508.48319492  493.09281645  699.23877033 1000.5632644   830.46692675
  153.3471298   577.57320205  907.62796211  907.74750027  230.52843618]
total_rewards_mean           630.8669203255556
total_rewards_std            275.59853802977847
total_rewards_max            1000.5632644044259
total_rewards_min            153.3471297988713
Number of train steps total  96000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               117.23476685304195
(Previous) Eval Time (s)     25.066295978147537
Sample Time (s)              18.206113233231008
Epoch Time (s)               160.5071760644205
Total Train Time (s)         3587.9461484025232
Epoch                        23
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:31:22.619487 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #23 | Epoch Duration: 157.95143699645996
2020-01-12 00:31:22.619807 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #23 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.5753621
Z variance train             0.015367518
KL Divergence                14.160462
KL Loss                      1.4160463
QF Loss                      242.9502
VF Loss                      61.475815
Policy Loss                  -376.66806
Q Predictions Mean           374.39658
Q Predictions Std            76.52725
Q Predictions Max            495.28397
Q Predictions Min            -0.35180265
V Predictions Mean           375.74695
V Predictions Std            74.33435
V Predictions Max            489.49738
V Predictions Min            62.83642
Log Pis Mean                 -1.9306419
Log Pis Std                  2.4337113
Log Pis Max                  8.103468
Log Pis Min                  -12.523694
Policy mu Mean               0.015875824
Policy mu Std                0.40581784
Policy mu Max                1.8422279
Policy mu Min                -1.778307
Policy log std Mean          -0.8964369
Policy log std Std           0.20669314
Policy log std Max           -0.35379824
Policy log std Min           -1.8210232
Z mean eval                  0.57558703
Z variance eval              0.011072473
total_rewards                [ 475.26677477 1139.80038003  262.9059461    43.0560416   321.62484111
  653.0975612   549.97854915  223.54701909 1204.61412011  110.86109108]
total_rewards_mean           498.47523242622174
total_rewards_std            381.71130404347156
total_rewards_max            1204.6141201146193
total_rewards_min            43.05604160249344
Number of train steps total  100000
Number of env steps total    127000
Number of rollouts total     0
Train Time (s)               114.65725416131318
(Previous) Eval Time (s)     22.51023396709934
Sample Time (s)              18.15959303639829
Epoch Time (s)               155.3270811648108
Total Train Time (s)         3743.172023234889
Epoch                        24
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:33:57.845615 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #24 | Epoch Duration: 155.22558093070984
2020-01-12 00:33:57.845810 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #24 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.63722837
Z variance train             0.012030993
KL Divergence                14.581353
KL Loss                      1.4581354
QF Loss                      213.33002
VF Loss                      62.122475
Policy Loss                  -386.34604
Q Predictions Mean           385.41162
Q Predictions Std            80.61188
Q Predictions Max            505.4776
Q Predictions Min            -19.684801
V Predictions Mean           390.549
V Predictions Std            80.46863
V Predictions Max            511.24774
V Predictions Min            -14.956203
Log Pis Mean                 -1.8051542
Log Pis Std                  2.1534228
Log Pis Max                  13.582567
Log Pis Min                  -7.9390416
Policy mu Mean               0.044610362
Policy mu Std                0.40586865
Policy mu Max                1.8418705
Policy mu Min                -3.1399345
Policy log std Mean          -0.8804461
Policy log std Std           0.19335301
Policy log std Max           -0.3250066
Policy log std Min           -1.7926304
Z mean eval                  0.62196577
Z variance eval              0.015392412
total_rewards                [1106.74733209 1005.61857854  383.65749474  436.16525263  333.77352341
  171.64971485  842.86162665  225.42013229  442.20370587  191.95452147]
total_rewards_mean           514.0051882546256
total_rewards_std            326.50685306735824
total_rewards_max            1106.747332086387
total_rewards_min            171.64971485443897
Number of train steps total  104000
Number of env steps total    132000
Number of rollouts total     0
Train Time (s)               118.32019507093355
(Previous) Eval Time (s)     22.40846086665988
Sample Time (s)              18.316290196031332
Epoch Time (s)               159.04494613362476
Total Train Time (s)         3898.5847680675797
Epoch                        25
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:36:33.259240 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #25 | Epoch Duration: 155.4132800102234
2020-01-12 00:36:33.259442 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #25 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.5798446
Z variance train             0.013549261
KL Divergence                14.396252
KL Loss                      1.4396251
QF Loss                      231.86871
VF Loss                      87.21836
Policy Loss                  -400.2857
Q Predictions Mean           398.04352
Q Predictions Std            85.22953
Q Predictions Max            519.0764
Q Predictions Min            -6.7595882
V Predictions Mean           393.21146
V Predictions Std            82.29995
V Predictions Max            512.65
V Predictions Min            56.64322
Log Pis Mean                 -1.8776933
Log Pis Std                  2.3017821
Log Pis Max                  8.58952
Log Pis Min                  -9.942091
Policy mu Mean               0.03252514
Policy mu Std                0.41153938
Policy mu Max                2.019154
Policy mu Min                -1.9402208
Policy log std Mean          -0.8661954
Policy log std Std           0.21558742
Policy log std Max           -0.2559319
Policy log std Min           -1.9016523
Z mean eval                  0.62437403
Z variance eval              0.018110748
total_rewards                [ 223.40558001  708.47391411 1387.36078769  358.92786901  643.79455882
  600.93289838  165.68741072  617.00015072 1424.14643572  180.56927042]
total_rewards_mean           631.0298875602005
total_rewards_std            432.20237606606065
total_rewards_max            1424.1464357224568
total_rewards_min            165.6874107173672
Number of train steps total  108000
Number of env steps total    137000
Number of rollouts total     0
Train Time (s)               113.06169265974313
(Previous) Eval Time (s)     18.77650459110737
Sample Time (s)              17.58103284612298
Epoch Time (s)               149.41923009697348
Total Train Time (s)         4054.8831813479774
Epoch                        26
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:39:09.560444 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #26 | Epoch Duration: 156.3008258342743
2020-01-12 00:39:09.560696 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #26 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.62456113
Z variance train             0.018144932
KL Divergence                14.226164
KL Loss                      1.4226164
QF Loss                      303.01727
VF Loss                      75.02228
Policy Loss                  -423.03894
Q Predictions Mean           416.94965
Q Predictions Std            95.3379
Q Predictions Max            561.41516
Q Predictions Min            -28.416845
V Predictions Mean           426.044
V Predictions Std            90.68492
V Predictions Max            573.65765
V Predictions Min            9.389897
Log Pis Mean                 -1.7727709
Log Pis Std                  2.3017616
Log Pis Max                  15.1446
Log Pis Min                  -7.8441124
Policy mu Mean               0.01070247
Policy mu Std                0.4359341
Policy mu Max                2.6175122
Policy mu Min                -2.0974576
Policy log std Mean          -0.89309776
Policy log std Std           0.20616058
Policy log std Max           -0.20695695
Policy log std Min           -1.8968058
Z mean eval                  0.61574095
Z variance eval              0.020304594
total_rewards                [ 391.91168306   49.193516    649.3914841  1369.14234772   91.44752474
  163.87491719  225.73475043  290.49533575  370.68898835  218.03418838]
total_rewards_mean           381.9914735718728
total_rewards_std            367.2343349615747
total_rewards_max            1369.1423477152798
total_rewards_min            49.193515996696405
Number of train steps total  112000
Number of env steps total    142000
Number of rollouts total     0
Train Time (s)               113.69080673204735
(Previous) Eval Time (s)     25.65780997602269
Sample Time (s)              17.65158498706296
Epoch Time (s)               157.000201695133
Total Train Time (s)         4206.530324654188
Epoch                        27
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:41:41.208556 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #27 | Epoch Duration: 151.6476571559906
2020-01-12 00:41:41.208797 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #27 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6143546
Z variance train             0.020535877
KL Divergence                13.675712
KL Loss                      1.3675712
QF Loss                      263.30307
VF Loss                      83.33495
Policy Loss                  -427.8904
Q Predictions Mean           427.5116
Q Predictions Std            103.95296
Q Predictions Max            579.56415
Q Predictions Min            -26.223806
V Predictions Mean           433.47736
V Predictions Std            97.92503
V Predictions Max            578.8639
V Predictions Min            68.90732
Log Pis Mean                 -1.7428832
Log Pis Std                  2.4228098
Log Pis Max                  16.156012
Log Pis Min                  -8.921928
Policy mu Mean               0.04631009
Policy mu Std                0.4366579
Policy mu Max                3.209222
Policy mu Min                -2.1466942
Policy log std Mean          -0.8729959
Policy log std Std           0.2159337
Policy log std Max           -0.3429322
Policy log std Min           -2.0840807
Z mean eval                  0.59907067
Z variance eval              0.01879669
total_rewards                [1446.44088172  104.50112758  355.37387331 1317.94600979  402.96709348
  218.83241258 1486.91480443  631.42474498  442.10847542  187.96147645]
total_rewards_mean           659.4470899746694
total_rewards_std            516.560907142024
total_rewards_max            1486.9148044311562
total_rewards_min            104.50112757867431
Number of train steps total  116000
Number of env steps total    147000
Number of rollouts total     0
Train Time (s)               111.70410045515746
(Previous) Eval Time (s)     20.304956878069788
Sample Time (s)              17.36194252828136
Epoch Time (s)               149.3709998615086
Total Train Time (s)         4356.037777107209
Epoch                        28
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:44:10.718715 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #28 | Epoch Duration: 149.5097050666809
2020-01-12 00:44:10.719034 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #28 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.598161
Z variance train             0.018821644
KL Divergence                14.336632
KL Loss                      1.4336632
QF Loss                      320.66922
VF Loss                      103.93261
Policy Loss                  -442.74606
Q Predictions Mean           439.51245
Q Predictions Std            94.016205
Q Predictions Max            565.5191
Q Predictions Min            20.000591
V Predictions Mean           436.25967
V Predictions Std            92.209045
V Predictions Max            555.7614
V Predictions Min            35.6066
Log Pis Mean                 -2.0158641
Log Pis Std                  2.0522177
Log Pis Max                  9.216391
Log Pis Min                  -8.085607
Policy mu Mean               0.019767523
Policy mu Std                0.41409746
Policy mu Max                1.5484569
Policy mu Min                -2.0810869
Policy log std Mean          -0.88681877
Policy log std Std           0.20961906
Policy log std Max           -0.28461897
Policy log std Min           -1.9303873
Z mean eval                  0.5789013
Z variance eval              0.02196535
total_rewards                [ 612.35160584  418.31339767  258.91018938   34.38573006 1057.36721144
  638.68275863  212.33946542 1539.97989488  465.89262394  779.17456441]
total_rewards_mean           601.7397441670271
total_rewards_std            420.0007625490869
total_rewards_max            1539.979894878256
total_rewards_min            34.38573006208961
Number of train steps total  120000
Number of env steps total    152000
Number of rollouts total     0
Train Time (s)               114.1456129415892
(Previous) Eval Time (s)     20.44336848286912
Sample Time (s)              18.890700886026025
Epoch Time (s)               153.47968231048435
Total Train Time (s)         4509.57442172477
Epoch                        29
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:46:44.258257 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #29 | Epoch Duration: 153.53900837898254
2020-01-12 00:46:44.258452 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #29 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.60375404
Z variance train             0.022711156
KL Divergence                13.70779
KL Loss                      1.370779
QF Loss                      237.54807
VF Loss                      50.79004
Policy Loss                  -441.17093
Q Predictions Mean           437.1409
Q Predictions Std            105.13633
Q Predictions Max            608.04895
Q Predictions Min            -6.4126186
V Predictions Mean           442.6528
V Predictions Std            103.72335
V Predictions Max            616.48456
V Predictions Min            13.996898
Log Pis Mean                 -1.6650114
Log Pis Std                  2.2101068
Log Pis Max                  12.676877
Log Pis Min                  -8.292219
Policy mu Mean               0.013276441
Policy mu Std                0.43191803
Policy mu Max                1.9001967
Policy mu Min                -1.8651787
Policy log std Mean          -0.88446665
Policy log std Std           0.19945973
Policy log std Max           -0.36282477
Policy log std Min           -2.0854707
Z mean eval                  0.6098334
Z variance eval              0.02265353
total_rewards                [1224.1545984  1372.07048325 1346.98631432 1613.62975641 1237.58237262
  132.74824083  834.93965396  160.6612925   566.59861669  962.60519571]
total_rewards_mean           945.1976524688567
total_rewards_std            488.3779527745069
total_rewards_max            1613.6297564105976
total_rewards_min            132.74824083293802
Number of train steps total  124000
Number of env steps total    157000
Number of rollouts total     0
Train Time (s)               113.1195130199194
(Previous) Eval Time (s)     20.502370811998844
Sample Time (s)              17.8924424611032
Epoch Time (s)               151.51432629302144
Total Train Time (s)         4666.603535038419
Epoch                        30
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:49:21.285109 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #30 | Epoch Duration: 157.02653694152832
2020-01-12 00:49:21.285287 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #30 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6118931
Z variance train             0.022656303
KL Divergence                14.428731
KL Loss                      1.4428731
QF Loss                      193.68651
VF Loss                      49.758904
Policy Loss                  -456.43857
Q Predictions Mean           452.398
Q Predictions Std            108.71669
Q Predictions Max            613.84406
Q Predictions Min            -25.500952
V Predictions Mean           454.58627
V Predictions Std            104.5084
V Predictions Max            600.7074
V Predictions Min            36.190845
Log Pis Mean                 -1.6128352
Log Pis Std                  2.0836537
Log Pis Max                  6.8160934
Log Pis Min                  -6.2788334
Policy mu Mean               0.0624946
Policy mu Std                0.45038962
Policy mu Max                1.951907
Policy mu Min                -1.3561532
Policy log std Mean          -0.8884287
Policy log std Std           0.21104261
Policy log std Max           -0.3390627
Policy log std Min           -1.9317441
Z mean eval                  0.6128098
Z variance eval              0.02100854
total_rewards                [887.59070909 452.48869652 393.33421685 839.16222876 114.39726884
 200.22004353 339.21718426 296.22995689 405.70963124 446.74356633]
total_rewards_mean           437.5093502315491
total_rewards_std            236.11425827468108
total_rewards_max            887.5907090863699
total_rewards_min            114.39726884044528
Number of train steps total  128000
Number of env steps total    162000
Number of rollouts total     0
Train Time (s)               112.47179697686806
(Previous) Eval Time (s)     26.014293866232038
Sample Time (s)              18.13047252036631
Epoch Time (s)               156.6165633634664
Total Train Time (s)         4823.612837344408
Epoch                        31
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:51:58.298413 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #31 | Epoch Duration: 157.01294660568237
2020-01-12 00:51:58.298707 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #31 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.61185205
Z variance train             0.021007916
KL Divergence                13.849053
KL Loss                      1.3849053
QF Loss                      341.21786
VF Loss                      89.29442
Policy Loss                  -448.75327
Q Predictions Mean           446.2691
Q Predictions Std            133.2801
Q Predictions Max            625.21924
Q Predictions Min            -33.098244
V Predictions Mean           449.2566
V Predictions Std            125.22499
V Predictions Max            618.8966
V Predictions Min            -4.683177
Log Pis Mean                 -1.7767651
Log Pis Std                  2.4740067
Log Pis Max                  12.423796
Log Pis Min                  -8.385267
Policy mu Mean               0.04016748
Policy mu Std                0.45343986
Policy mu Max                1.8795092
Policy mu Min                -2.1254265
Policy log std Mean          -0.85249114
Policy log std Std           0.23427549
Policy log std Max           -0.25688463
Policy log std Min           -2.2256505
Z mean eval                  0.61015964
Z variance eval              0.031166583
total_rewards                [ 477.8440747  1247.26668908  168.51475505  222.27202572 1186.27288736
 1579.82309026 1570.99261757 1188.44844652 1575.26258128  410.01982414]
total_rewards_mean           962.6716991670592
total_rewards_std            550.2293663716663
total_rewards_max            1579.823090256361
total_rewards_min            168.51475504804606
Number of train steps total  132000
Number of env steps total    167000
Number of rollouts total     0
Train Time (s)               106.34277768619359
(Previous) Eval Time (s)     26.410352429375052
Sample Time (s)              17.364308991935104
Epoch Time (s)               150.11743910750374
Total Train Time (s)         4974.515205051284
Epoch                        32
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:54:29.200557 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #32 | Epoch Duration: 150.90163350105286
2020-01-12 00:54:29.200772 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #32 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6101409
Z variance train             0.03125804
KL Divergence                13.793662
KL Loss                      1.3793663
QF Loss                      612.59143
VF Loss                      188.13156
Policy Loss                  -460.14587
Q Predictions Mean           454.7317
Q Predictions Std            127.11375
Q Predictions Max            609.6895
Q Predictions Min            -28.406202
V Predictions Mean           462.65427
V Predictions Std            122.09577
V Predictions Max            608.17444
V Predictions Min            -8.509408
Log Pis Mean                 -1.5242721
Log Pis Std                  2.641628
Log Pis Max                  14.801746
Log Pis Min                  -9.09207
Policy mu Mean               0.03745988
Policy mu Std                0.46199152
Policy mu Max                1.8942798
Policy mu Min                -3.0552795
Policy log std Mean          -0.88165045
Policy log std Std           0.23176995
Policy log std Max           -0.32514733
Policy log std Min           -2.200006
Z mean eval                  0.6262115
Z variance eval              0.02329563
total_rewards                [1150.7276114   896.88123168  428.00261155  455.2651184   115.0926759
  424.7860974   919.70818331  276.19585347  186.14999235 1457.13264883]
total_rewards_mean           630.9942024293749
total_rewards_std            425.58312094717587
total_rewards_max            1457.1326488255218
total_rewards_min            115.09267590095347
Number of train steps total  136000
Number of env steps total    172000
Number of rollouts total     0
Train Time (s)               112.29506239714101
(Previous) Eval Time (s)     27.194281287956983
Sample Time (s)              18.10809012921527
Epoch Time (s)               157.59743381431326
Total Train Time (s)         5130.0825935290195
Epoch                        33
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:57:04.768162 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #33 | Epoch Duration: 155.5672423839569
2020-01-12 00:57:04.768315 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #33 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.62736684
Z variance train             0.023357451
KL Divergence                14.507053
KL Loss                      1.4507054
QF Loss                      360.5976
VF Loss                      102.77868
Policy Loss                  -475.07355
Q Predictions Mean           468.57312
Q Predictions Std            127.76105
Q Predictions Max            650.04974
Q Predictions Min            -17.910889
V Predictions Mean           476.71924
V Predictions Std            123.5914
V Predictions Max            654.2525
V Predictions Min            203.88046
Log Pis Mean                 -1.8818281
Log Pis Std                  2.1484451
Log Pis Max                  6.098424
Log Pis Min                  -8.194109
Policy mu Mean               0.0737924
Policy mu Std                0.43884978
Policy mu Max                1.8486314
Policy mu Min                -2.050053
Policy log std Mean          -0.85200465
Policy log std Std           0.22020206
Policy log std Max           -0.25940147
Policy log std Min           -2.0226285
Z mean eval                  0.61443526
Z variance eval              0.018592907
total_rewards                [ 557.15777505  716.83424436 1171.7074089   892.72148822  364.87205356
  607.15679426 1078.13697449 1553.15873668  757.76318147  866.19023747]
total_rewards_mean           856.5698894442467
total_rewards_std            325.261314142726
total_rewards_max            1553.158736675201
total_rewards_min            364.8720535572499
Number of train steps total  140000
Number of env steps total    177000
Number of rollouts total     0
Train Time (s)               111.08855402935296
(Previous) Eval Time (s)     25.16379825025797
Sample Time (s)              17.83139309519902
Epoch Time (s)               154.08374537480995
Total Train Time (s)         5281.937452284619
Epoch                        34
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:59:36.625127 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #34 | Epoch Duration: 151.85668206214905
2020-01-12 00:59:36.625339 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #34 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6178861
Z variance train             0.018685814
KL Divergence                14.901717
KL Loss                      1.4901718
QF Loss                      261.2147
VF Loss                      93.14957
Policy Loss                  -487.5973
Q Predictions Mean           480.52542
Q Predictions Std            127.670425
Q Predictions Max            634.3198
Q Predictions Min            -7.4126377
V Predictions Mean           482.33838
V Predictions Std            124.47592
V Predictions Max            632.3223
V Predictions Min            34.898094
Log Pis Mean                 -1.4575895
Log Pis Std                  2.6499913
Log Pis Max                  12.479576
Log Pis Min                  -10.167397
Policy mu Mean               0.007454328
Policy mu Std                0.48667952
Policy mu Max                1.9187223
Policy mu Min                -2.1949732
Policy log std Mean          -0.8612404
Policy log std Std           0.20938568
Policy log std Max           -0.22367454
Policy log std Min           -2.0868337
Z mean eval                  0.63053465
Z variance eval              0.01947737
total_rewards                [1533.00081466  419.60274639  230.73523411   11.08518886  690.22336819
  390.0849413   262.38244265 1451.8745655   508.67871291 1681.35472544]
total_rewards_mean           717.9022740009536
total_rewards_std            575.9122717346918
total_rewards_max            1681.3547254387965
total_rewards_min            11.08518886257763
Number of train steps total  144000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               115.63492433307692
(Previous) Eval Time (s)     22.936449525877833
Sample Time (s)              18.065799489617348
Epoch Time (s)               156.6371733485721
Total Train Time (s)         5433.70780876698
Epoch                        35
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:02:08.395697 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #35 | Epoch Duration: 151.77021288871765
2020-01-12 01:02:08.395872 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #35 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6305998
Z variance train             0.019446524
KL Divergence                14.5916605
KL Loss                      1.459166
QF Loss                      433.13397
VF Loss                      75.11991
Policy Loss                  -497.3022
Q Predictions Mean           495.85583
Q Predictions Std            135.3816
Q Predictions Max            681.8164
Q Predictions Min            28.521227
V Predictions Mean           493.08258
V Predictions Std            133.75998
V Predictions Max            682.8233
V Predictions Min            65.39864
Log Pis Mean                 -1.683928
Log Pis Std                  2.4663916
Log Pis Max                  16.721613
Log Pis Min                  -9.42997
Policy mu Mean               0.010702331
Policy mu Std                0.46436882
Policy mu Max                2.4768133
Policy mu Min                -1.9557207
Policy log std Mean          -0.87953985
Policy log std Std           0.2166617
Policy log std Max           -0.16939074
Policy log std Min           -2.112076
Z mean eval                  0.631673
Z variance eval              0.014936471
total_rewards                [ 559.78414889  103.82937589  651.19528671   67.86349185 1465.15893043
  233.4782926   467.56189868  425.45278324  618.38978059  769.41974782]
total_rewards_mean           536.2133736692833
total_rewards_std            381.1550130919605
total_rewards_max            1465.15893042803
total_rewards_min            67.86349185013783
Number of train steps total  148000
Number of env steps total    187000
Number of rollouts total     0
Train Time (s)               111.99622300732881
(Previous) Eval Time (s)     18.06919045606628
Sample Time (s)              17.47641126997769
Epoch Time (s)               147.54182473337278
Total Train Time (s)         5584.298250393476
Epoch                        36
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:04:38.989917 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #36 | Epoch Duration: 150.59387230873108
2020-01-12 01:04:38.990233 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #36 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.63215655
Z variance train             0.014912447
KL Divergence                15.332254
KL Loss                      1.5332254
QF Loss                      313.8961
VF Loss                      98.44864
Policy Loss                  -520.5003
Q Predictions Mean           514.3882
Q Predictions Std            135.88304
Q Predictions Max            709.9727
Q Predictions Min            1.7539792
V Predictions Mean           519.79254
V Predictions Std            130.68343
V Predictions Max            697.086
V Predictions Min            78.40105
Log Pis Mean                 -1.3301702
Log Pis Std                  2.624221
Log Pis Max                  14.493208
Log Pis Min                  -8.769742
Policy mu Mean               0.07154539
Policy mu Std                0.48233926
Policy mu Max                2.685484
Policy mu Min                -2.2730243
Policy log std Mean          -0.91448665
Policy log std Std           0.25560394
Policy log std Max           -0.24777973
Policy log std Min           -2.3263578
Z mean eval                  0.63882065
Z variance eval              0.011016212
total_rewards                [1444.70867395  434.36194064 1524.1118293   827.93450009  183.61515519
  234.47943152  367.78373134  104.65006963 1114.57732359 1044.53092948]
total_rewards_mean           728.0753584732968
total_rewards_std            505.12846767833275
total_rewards_max            1524.1118293009986
total_rewards_min            104.65006962894367
Number of train steps total  152000
Number of env steps total    192000
Number of rollouts total     0
Train Time (s)               115.37819919316098
(Previous) Eval Time (s)     21.120940191671252
Sample Time (s)              18.114480001851916
Epoch Time (s)               154.61361938668415
Total Train Time (s)         5738.8435699585825
Epoch                        37
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:07:13.534508 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #37 | Epoch Duration: 154.54407787322998
2020-01-12 01:07:13.534654 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #37 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.63983643
Z variance train             0.011004075
KL Divergence                15.925764
KL Loss                      1.5925764
QF Loss                      544.65906
VF Loss                      98.736404
Policy Loss                  -541.81934
Q Predictions Mean           539.70264
Q Predictions Std            132.54341
Q Predictions Max            700.34406
Q Predictions Min            -11.629272
V Predictions Mean           544.79376
V Predictions Std            130.94682
V Predictions Max            695.33203
V Predictions Min            37.546772
Log Pis Mean                 -1.5388577
Log Pis Std                  2.4619875
Log Pis Max                  10.152186
Log Pis Min                  -7.050629
Policy mu Mean               0.023044117
Policy mu Std                0.48994705
Policy mu Max                1.763294
Policy mu Min                -2.0468724
Policy log std Mean          -0.86684465
Policy log std Std           0.19479662
Policy log std Max           -0.3622774
Policy log std Min           -1.7471793
Z mean eval                  0.68368685
Z variance eval              0.0051091416
total_rewards                [1422.37743799 1071.13675072 1161.60073439  721.25111627  -25.66530751
   74.39639251  828.24376233   40.96621629  583.91316429  927.34637542]
total_rewards_mean           680.5566642707365
total_rewards_std            479.919013612472
total_rewards_max            1422.3774379934
total_rewards_min            -25.665307512553028
Number of train steps total  156000
Number of env steps total    197000
Number of rollouts total     0
Train Time (s)               110.95432528760284
(Previous) Eval Time (s)     21.051101927179843
Sample Time (s)              18.36233620485291
Epoch Time (s)               150.3677634196356
Total Train Time (s)         5885.779869883321
Epoch                        38
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:09:40.474843 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #38 | Epoch Duration: 146.9400336742401
2020-01-12 01:09:40.475158 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #38 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.68607783
Z variance train             0.005033982
KL Divergence                18.157326
KL Loss                      1.8157326
QF Loss                      309.70865
VF Loss                      68.416954
Policy Loss                  -529.573
Q Predictions Mean           525.3758
Q Predictions Std            148.1933
Q Predictions Max            690.9658
Q Predictions Min            -18.057745
V Predictions Mean           534.1189
V Predictions Std            148.90498
V Predictions Max            698.1987
V Predictions Min            64.6097
Log Pis Mean                 -1.6134524
Log Pis Std                  2.2859468
Log Pis Max                  7.677858
Log Pis Min                  -7.6676683
Policy mu Mean               0.054803155
Policy mu Std                0.46188113
Policy mu Max                1.8350949
Policy mu Min                -2.0314224
Policy log std Mean          -0.84516656
Policy log std Std           0.22418311
Policy log std Max           -0.106339455
Policy log std Min           -1.6962686
Z mean eval                  0.6661431
Z variance eval              0.010695811
total_rewards                [1410.77157986  135.68676979    2.68788899   65.83131243  902.92938882
 1168.33845872  728.63510957  133.96378263   48.8997148   127.46403891]
total_rewards_mean           472.52080445275215
total_rewards_std            502.79808538733437
total_rewards_max            1410.7715798640127
total_rewards_min            2.687888990322624
Number of train steps total  160000
Number of env steps total    202000
Number of rollouts total     0
Train Time (s)               116.0036142366007
(Previous) Eval Time (s)     17.623035178985447
Sample Time (s)              18.610321142245084
Epoch Time (s)               152.23697055783123
Total Train Time (s)         6033.484117570333
Epoch                        39
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:12:08.178829 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #39 | Epoch Duration: 147.70345520973206
2020-01-12 01:12:08.179008 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #39 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.658328
Z variance train             0.0107268365
KL Divergence                18.095655
KL Loss                      1.8095655
QF Loss                      836.91266
VF Loss                      120.19954
Policy Loss                  -534.41376
Q Predictions Mean           533.1332
Q Predictions Std            155.77724
Q Predictions Max            732.3089
Q Predictions Min            41.608418
V Predictions Mean           537.2241
V Predictions Std            153.55406
V Predictions Max            726.5277
V Predictions Min            32.206993
Log Pis Mean                 -1.5266664
Log Pis Std                  2.5730054
Log Pis Max                  10.832556
Log Pis Min                  -6.722081
Policy mu Mean               0.008547427
Policy mu Std                0.4845113
Policy mu Max                2.7756972
Policy mu Min                -2.5849385
Policy log std Mean          -0.88819075
Policy log std Std           0.24350205
Policy log std Max           -0.3066159
Policy log std Min           -2.2369204
Z mean eval                  0.6523627
Z variance eval              0.007401794
total_rewards                [1642.38911967 1747.7462811   522.0858874   441.62709504  188.13136118
 1863.74485628 1659.28328     932.1635728   433.43630397 1706.60076977]
total_rewards_mean           1113.7208527209673
total_rewards_std            636.1892262250575
total_rewards_max            1863.7448562827374
total_rewards_min            188.13136118448185
Number of train steps total  164000
Number of env steps total    207000
Number of rollouts total     0
Train Time (s)               115.7375969896093
(Previous) Eval Time (s)     13.08924269489944
Sample Time (s)              18.178346001077443
Epoch Time (s)               147.00518568558618
Total Train Time (s)         6194.515953319147
Epoch                        40
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:14:49.213486 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #40 | Epoch Duration: 161.0343210697174
2020-01-12 01:14:49.213712 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #40 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6757712
Z variance train             0.007379681
KL Divergence                17.719181
KL Loss                      1.7719182
QF Loss                      370.5447
VF Loss                      76.37292
Policy Loss                  -522.79156
Q Predictions Mean           521.8239
Q Predictions Std            172.79764
Q Predictions Max            731.48364
Q Predictions Min            -16.594807
V Predictions Mean           525.08514
V Predictions Std            170.71703
V Predictions Max            728.4327
V Predictions Min            13.817872
Log Pis Mean                 -1.5649012
Log Pis Std                  2.4950266
Log Pis Max                  8.986522
Log Pis Min                  -8.127979
Policy mu Mean               0.028531652
Policy mu Std                0.470058
Policy mu Max                1.869534
Policy mu Min                -1.6068286
Policy log std Mean          -0.87507427
Policy log std Std           0.21571912
Policy log std Max           -0.26563486
Policy log std Min           -1.8340056
Z mean eval                  0.65296835
Z variance eval              0.014660356
total_rewards                [1688.95286882   58.60963289 1176.23925748  814.71674366  560.33164948
 1464.14994409 1726.93354135  918.54409217 1632.24947748 1117.60682012]
total_rewards_mean           1115.833402753817
total_rewards_std            514.7300167243628
total_rewards_max            1726.9335413469823
total_rewards_min            58.60963289252509
Number of train steps total  168000
Number of env steps total    212000
Number of rollouts total     0
Train Time (s)               116.68191734002903
(Previous) Eval Time (s)     27.118061523884535
Sample Time (s)              18.71932885609567
Epoch Time (s)               162.51930772000924
Total Train Time (s)         6352.469317014795
Epoch                        41
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:17:27.169485 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #41 | Epoch Duration: 157.9555642604828
2020-01-12 01:17:27.169789 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #41 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6511156
Z variance train             0.014690083
KL Divergence                16.361282
KL Loss                      1.6361283
QF Loss                      364.4062
VF Loss                      228.63472
Policy Loss                  -542.8651
Q Predictions Mean           536.53595
Q Predictions Std            168.96667
Q Predictions Max            721.0189
Q Predictions Min            -15.139687
V Predictions Mean           545.5273
V Predictions Std            158.34155
V Predictions Max            724.5904
V Predictions Min            60.13662
Log Pis Mean                 -1.1840837
Log Pis Std                  2.6714308
Log Pis Max                  14.197348
Log Pis Min                  -8.64319
Policy mu Mean               0.05520284
Policy mu Std                0.4901075
Policy mu Max                1.9300798
Policy mu Min                -2.4970727
Policy log std Mean          -0.90770364
Policy log std Std           0.25195557
Policy log std Max           -0.22787917
Policy log std Min           -2.0612373
Z mean eval                  0.6612328
Z variance eval              0.013137639
total_rewards                [ 471.36522071 1909.23291008 1773.78137064 1721.56509169 1143.85539943
 1008.42956196 1659.95180419  158.74766876  494.69093426 1144.87128149]
total_rewards_mean           1148.6491243214327
total_rewards_std            586.9343767723934
total_rewards_max            1909.2329100792226
total_rewards_min            158.74766875886667
Number of train steps total  172000
Number of env steps total    217000
Number of rollouts total     0
Train Time (s)               113.48792415205389
(Previous) Eval Time (s)     22.554040028247982
Sample Time (s)              19.23732181545347
Epoch Time (s)               155.27928599575534
Total Train Time (s)         6508.176604938228
Epoch                        42
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:20:02.875777 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #42 | Epoch Duration: 155.70577764511108
2020-01-12 01:20:02.875974 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #42 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6602563
Z variance train             0.013143303
KL Divergence                16.008535
KL Loss                      1.6008536
QF Loss                      352.79724
VF Loss                      101.47463
Policy Loss                  -562.7779
Q Predictions Mean           557.76245
Q Predictions Std            166.38377
Q Predictions Max            743.521
Q Predictions Min            -46.02864
V Predictions Mean           564.5978
V Predictions Std            159.55267
V Predictions Max            740.8403
V Predictions Min            20.612482
Log Pis Mean                 -1.0700285
Log Pis Std                  2.6318717
Log Pis Max                  10.203117
Log Pis Min                  -9.043642
Policy mu Mean               0.04495725
Policy mu Std                0.49343082
Policy mu Max                2.2374415
Policy mu Min                -2.9118023
Policy log std Mean          -0.92257905
Policy log std Std           0.23892201
Policy log std Max           -0.31122047
Policy log std Min           -2.159125
Z mean eval                  0.6629736
Z variance eval              0.018434921
total_rewards                [ 592.19241565 1905.81387872 1654.33209885  227.78268783 1760.92889007
 1277.67119395  737.89293755  635.66056947  186.8227203   461.00257661]
total_rewards_mean           944.0099968999114
total_rewards_std            615.5696539162788
total_rewards_max            1905.8138787213384
total_rewards_min            186.82272029826254
Number of train steps total  176000
Number of env steps total    222000
Number of rollouts total     0
Train Time (s)               117.11088894912973
(Previous) Eval Time (s)     22.980196028016508
Sample Time (s)              18.548185878433287
Epoch Time (s)               158.63927085557953
Total Train Time (s)         6664.40538859833
Epoch                        43
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:22:39.105747 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #43 | Epoch Duration: 156.22965455055237
2020-01-12 01:22:39.105898 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #43 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6685274
Z variance train             0.01836448
KL Divergence                15.473936
KL Loss                      1.5473937
QF Loss                      282.0652
VF Loss                      109.3993
Policy Loss                  -563.6229
Q Predictions Mean           557.73364
Q Predictions Std            168.85205
Q Predictions Max            753.07294
Q Predictions Min            19.336267
V Predictions Mean           556.5011
V Predictions Std            166.82858
V Predictions Max            734.7836
V Predictions Min            68.377975
Log Pis Mean                 -1.4740758
Log Pis Std                  2.4198277
Log Pis Max                  10.9216
Log Pis Min                  -8.274492
Policy mu Mean               0.055340555
Policy mu Std                0.49337047
Policy mu Max                2.3569674
Policy mu Min                -1.7390183
Policy log std Mean          -0.8667942
Policy log std Std           0.2403483
Policy log std Max           -0.18859738
Policy log std Min           -2.1059294
Z mean eval                  0.6683676
Z variance eval              0.016953878
total_rewards                [ 715.76120882 1091.71946183 1832.00915191 1783.95977813 1566.9474156
 1399.85238163  962.21008096 1793.75889425  201.10480469  379.93126564]
total_rewards_mean           1172.725444346364
total_rewards_std            568.6129482513492
total_rewards_max            1832.0091519104417
total_rewards_min            201.10480469065013
Number of train steps total  180000
Number of env steps total    227000
Number of rollouts total     0
Train Time (s)               116.67672148812562
(Previous) Eval Time (s)     20.570237713865936
Sample Time (s)              18.283586248289794
Epoch Time (s)               155.53054545028135
Total Train Time (s)         6820.937957544811
Epoch                        44
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:25:15.639398 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #44 | Epoch Duration: 156.53338289260864
2020-01-12 01:25:15.639558 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #44 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6695317
Z variance train             0.01698802
KL Divergence                16.372084
KL Loss                      1.6372083
QF Loss                      393.77563
VF Loss                      56.86923
Policy Loss                  -566.5119
Q Predictions Mean           563.5181
Q Predictions Std            161.8772
Q Predictions Max            759.07666
Q Predictions Min            172.15804
V Predictions Mean           566.6637
V Predictions Std            162.08417
V Predictions Max            755.796
V Predictions Min            177.09354
Log Pis Mean                 -1.4106729
Log Pis Std                  2.3817592
Log Pis Max                  9.18003
Log Pis Min                  -6.5606375
Policy mu Mean               0.024216926
Policy mu Std                0.4794462
Policy mu Max                2.231518
Policy mu Min                -1.5528704
Policy log std Mean          -0.88551277
Policy log std Std           0.22474973
Policy log std Max           -0.33875448
Policy log std Min           -1.925621
Z mean eval                  0.66964495
Z variance eval              0.01870433
total_rewards                [1768.49621575 1025.72512132  291.43833638 1674.26602892 1783.40729103
 1723.17783693 1599.27478849 1655.94178125 1776.25171518 1893.79686174]
total_rewards_mean           1519.1775976977965
total_rewards_std            466.9080594947801
total_rewards_max            1893.7968617361182
total_rewards_min            291.4383363810456
Number of train steps total  184000
Number of env steps total    232000
Number of rollouts total     0
Train Time (s)               118.76777127198875
(Previous) Eval Time (s)     21.572767034638673
Sample Time (s)              18.412826226558536
Epoch Time (s)               158.75336453318596
Total Train Time (s)         6981.711308243219
Epoch                        45
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:27:56.417175 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #45 | Epoch Duration: 160.77746748924255
2020-01-12 01:27:56.417452 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #45 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6696638
Z variance train             0.018689783
KL Divergence                15.634254
KL Loss                      1.5634254
QF Loss                      404.76428
VF Loss                      123.27749
Policy Loss                  -579.2902
Q Predictions Mean           578.3257
Q Predictions Std            167.33139
Q Predictions Max            763.92645
Q Predictions Min            126.31762
V Predictions Mean           573.14014
V Predictions Std            163.25517
V Predictions Max            754.1115
V Predictions Min            184.51414
Log Pis Mean                 -1.7518207
Log Pis Std                  2.503741
Log Pis Max                  7.486618
Log Pis Min                  -8.1967
Policy mu Mean               0.010470814
Policy mu Std                0.45916778
Policy mu Max                1.7957269
Policy mu Min                -1.9713054
Policy log std Mean          -0.87669456
Policy log std Std           0.2380706
Policy log std Max           -0.22969681
Policy log std Min           -2.088634
Z mean eval                  0.6870852
Z variance eval              0.013834551
total_rewards                [ 538.78023033 1743.7277112  1108.93808396  421.06576949 1786.6676041
 1880.32105041  672.56995656  763.3228153  1936.11576273 1733.63302032]
total_rewards_mean           1258.514200438473
total_rewards_std            584.4791475692873
total_rewards_max            1936.1157627291666
total_rewards_min            421.0657694881309
Number of train steps total  188000
Number of env steps total    237000
Number of rollouts total     0
Train Time (s)               113.32921539619565
(Previous) Eval Time (s)     23.596566780935973
Sample Time (s)              18.756232865620404
Epoch Time (s)               155.68201504275203
Total Train Time (s)         7134.668831326999
Epoch                        46
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:30:29.373443 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #46 | Epoch Duration: 152.95580077171326
2020-01-12 01:30:29.373633 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #46 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.68543905
Z variance train             0.013857496
KL Divergence                16.021503
KL Loss                      1.6021503
QF Loss                      371.87103
VF Loss                      66.00681
Policy Loss                  -574.9847
Q Predictions Mean           571.2999
Q Predictions Std            184.1579
Q Predictions Max            759.60034
Q Predictions Min            -2.7947335
V Predictions Mean           577.0012
V Predictions Std            179.05455
V Predictions Max            754.93506
V Predictions Min            172.5342
Log Pis Mean                 -1.4496946
Log Pis Std                  2.686487
Log Pis Max                  13.138844
Log Pis Min                  -8.369794
Policy mu Mean               0.06383027
Policy mu Std                0.48421475
Policy mu Max                1.662125
Policy mu Min                -2.623494
Policy log std Mean          -0.87061816
Policy log std Std           0.23570451
Policy log std Max           -0.36453164
Policy log std Min           -1.9437705
Z mean eval                  0.67081606
Z variance eval              0.009856308
total_rewards                [1854.04728845 1986.95998246  684.74416722  467.45655888 1552.11927137
  506.93945423  273.98534575 1878.59492163 1811.55699145 1726.99441192]
total_rewards_mean           1274.339839336225
total_rewards_std            660.9060743900786
total_rewards_max            1986.9599824640052
total_rewards_min            273.9853457519906
Number of train steps total  192000
Number of env steps total    242000
Number of rollouts total     0
Train Time (s)               114.42769303824753
(Previous) Eval Time (s)     20.87006405601278
Sample Time (s)              18.53333688341081
Epoch Time (s)               153.83109397767112
Total Train Time (s)         7286.6398088536225
Epoch                        47
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:33:01.347168 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #47 | Epoch Duration: 151.9733817577362
2020-01-12 01:33:01.347409 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #47 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6693529
Z variance train             0.00985934
KL Divergence                17.004929
KL Loss                      1.7004929
QF Loss                      414.68076
VF Loss                      109.63016
Policy Loss                  -577.17957
Q Predictions Mean           572.89734
Q Predictions Std            180.70103
Q Predictions Max            820.9945
Q Predictions Min            -1.2403078
V Predictions Mean           583.8133
V Predictions Std            178.33568
V Predictions Max            817.967
V Predictions Min            46.7026
Log Pis Mean                 -1.2128956
Log Pis Std                  2.8624792
Log Pis Max                  11.918192
Log Pis Min                  -8.32806
Policy mu Mean               0.007354592
Policy mu Std                0.51355153
Policy mu Max                3.2105794
Policy mu Min                -2.1536033
Policy log std Mean          -0.89604664
Policy log std Std           0.23361997
Policy log std Max           -0.34149683
Policy log std Min           -2.2215412
Z mean eval                  0.67670834
Z variance eval              0.013210143
total_rewards                [1873.4411867  1781.77243993 1813.98753258 1704.59626411 1650.44940252
  375.23180716 1744.93501166  268.97526467  810.24385053 1933.41364149]
total_rewards_mean           1395.70464013381
total_rewards_std            614.5967058561109
total_rewards_max            1933.4136414901263
total_rewards_min            268.9752646673242
Number of train steps total  196000
Number of env steps total    247000
Number of rollouts total     0
Train Time (s)               119.81306025618687
(Previous) Eval Time (s)     19.01202727900818
Sample Time (s)              18.688464743550867
Epoch Time (s)               157.51355227874592
Total Train Time (s)         7449.407167621888
Epoch                        48
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:35:44.115128 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #48 | Epoch Duration: 162.76754665374756
2020-01-12 01:35:44.115300 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #48 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.67576087
Z variance train             0.013208571
KL Divergence                16.490578
KL Loss                      1.6490577
QF Loss                      419.88864
VF Loss                      90.69125
Policy Loss                  -594.3274
Q Predictions Mean           591.03546
Q Predictions Std            179.2731
Q Predictions Max            782.16675
Q Predictions Min            9.658467
V Predictions Mean           589.97864
V Predictions Std            175.15668
V Predictions Max            772.6858
V Predictions Min            35.7498
Log Pis Mean                 -0.8735013
Log Pis Std                  2.7738106
Log Pis Max                  11.287621
Log Pis Min                  -7.053212
Policy mu Mean               0.04241264
Policy mu Std                0.50314784
Policy mu Max                2.824962
Policy mu Min                -2.8829618
Policy log std Mean          -0.947706
Policy log std Std           0.26532024
Policy log std Max           -0.00034964085
Policy log std Min           -2.2478666
Z mean eval                  0.68312913
Z variance eval              0.013936445
total_rewards                [1348.2654394  1714.40356667 1879.94807015  178.6000982  1069.04339444
 1960.02656894 1874.38729264 1828.36200991  115.26429139  305.95282401]
total_rewards_mean           1227.4253555758507
total_rewards_std            721.4608978012211
total_rewards_max            1960.02656893835
total_rewards_min            115.26429139442922
Number of train steps total  200000
Number of env steps total    252000
Number of rollouts total     0
Train Time (s)               120.69519637804478
(Previous) Eval Time (s)     24.26570800691843
Sample Time (s)              19.603699955157936
Epoch Time (s)               164.56460434012115
Total Train Time (s)         7607.594904259779
Epoch                        49
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:38:22.307257 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #49 | Epoch Duration: 158.19179034233093
2020-01-12 01:38:22.307543 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #49 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.68361574
Z variance train             0.013894135
KL Divergence                16.63738
KL Loss                      1.6637381
QF Loss                      504.77985
VF Loss                      130.4798
Policy Loss                  -594.18896
Q Predictions Mean           588.5788
Q Predictions Std            180.64522
Q Predictions Max            789.8116
Q Predictions Min            -12.054709
V Predictions Mean           590.393
V Predictions Std            174.81544
V Predictions Max            784.3606
V Predictions Min            52.048
Log Pis Mean                 -1.274678
Log Pis Std                  2.4186332
Log Pis Max                  10.668084
Log Pis Min                  -7.6491413
Policy mu Mean               0.06571016
Policy mu Std                0.4895702
Policy mu Max                1.8271952
Policy mu Min                -2.2775147
Policy log std Mean          -0.8922634
Policy log std Std           0.25987235
Policy log std Max           -0.16983443
Policy log std Min           -2.2568295
Z mean eval                  0.6927115
Z variance eval              0.010013158
total_rewards                [ 184.78631558  793.96880641  612.09011873 1847.35667425  239.76273527
 1032.8064001   395.52976243  544.08093934 1799.36977762  946.22472255]
total_rewards_mean           839.5976252282887
total_rewards_std            557.8877694896671
total_rewards_max            1847.3566742533565
total_rewards_min            184.7863155796257
Number of train steps total  204000
Number of env steps total    257000
Number of rollouts total     0
Train Time (s)               119.12241541501135
(Previous) Eval Time (s)     17.892530691809952
Sample Time (s)              18.834339587483555
Epoch Time (s)               155.84928569430485
Total Train Time (s)         7762.023843462579
Epoch                        50
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:40:56.734827 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #50 | Epoch Duration: 154.42709136009216
2020-01-12 01:40:56.734982 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #50 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.69264144
Z variance train             0.010015467
KL Divergence                17.299559
KL Loss                      1.7299559
QF Loss                      353.97467
VF Loss                      43.499092
Policy Loss                  -615.933
Q Predictions Mean           614.0266
Q Predictions Std            177.94806
Q Predictions Max            819.68555
Q Predictions Min            179.10388
V Predictions Mean           616.07764
V Predictions Std            176.97581
V Predictions Max            816.4644
V Predictions Min            178.09352
Log Pis Mean                 -1.6054108
Log Pis Std                  2.5030785
Log Pis Max                  8.291201
Log Pis Min                  -9.024648
Policy mu Mean               0.028848313
Policy mu Std                0.4885509
Policy mu Max                1.9349666
Policy mu Min                -1.5705837
Policy log std Mean          -0.8961949
Policy log std Std           0.23851816
Policy log std Max           -0.29204637
Policy log std Min           -1.9320431
Z mean eval                  0.696129
Z variance eval              0.010861224
total_rewards                [ 251.44660401 1723.60518126  432.6621368  1892.25078819 1532.41733065
 1150.67312606 1959.1199352   922.64288877 1267.34027691 2171.69965748]
total_rewards_mean           1330.3857925309853
total_rewards_std            615.3689409286133
total_rewards_max            2171.699657480934
total_rewards_min            251.44660400804355
Number of train steps total  208000
Number of env steps total    262000
Number of rollouts total     0
Train Time (s)               105.33125581871718
(Previous) Eval Time (s)     16.470032079145312
Sample Time (s)              17.577947799582034
Epoch Time (s)               139.37923569744453
Total Train Time (s)         7906.998150380328
Epoch                        51
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:43:21.711040 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #51 | Epoch Duration: 144.9759178161621
2020-01-12 01:43:21.711266 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #51 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6968578
Z variance train             0.010886392
KL Divergence                16.803164
KL Loss                      1.6803163
QF Loss                      355.4713
VF Loss                      282.8923
Policy Loss                  -600.0982
Q Predictions Mean           595.7405
Q Predictions Std            208.0505
Q Predictions Max            823.975
Q Predictions Min            -16.956654
V Predictions Mean           607.4785
V Predictions Std            202.76279
V Predictions Max            826.21906
V Predictions Min            3.5096743
Log Pis Mean                 -1.0683042
Log Pis Std                  2.8844573
Log Pis Max                  11.332179
Log Pis Min                  -9.468178
Policy mu Mean               0.037870653
Policy mu Std                0.5053395
Policy mu Max                2.96585
Policy mu Min                -2.4690862
Policy log std Mean          -0.89276195
Policy log std Std           0.26709387
Policy log std Max           -0.2306889
Policy log std Min           -2.3445287
Z mean eval                  0.7140192
Z variance eval              0.010700329
total_rewards                [1238.38904753  287.11320695  641.83842861  252.52709066  136.45834077
 1169.3722444   238.95670338 1586.74516272 1516.84113383  286.52160773]
total_rewards_mean           735.4762966592416
total_rewards_std            550.120768229116
total_rewards_max            1586.7451627173577
total_rewards_min            136.45834077211467
Number of train steps total  212000
Number of env steps total    267000
Number of rollouts total     0
Train Time (s)               109.77845240104944
(Previous) Eval Time (s)     22.066407860722393
Sample Time (s)              18.786403115373105
Epoch Time (s)               150.63126337714493
Total Train Time (s)         8050.281724304892
Epoch                        52
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:45:44.997196 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #52 | Epoch Duration: 143.28571105003357
2020-01-12 01:45:44.997491 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #52 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7139002
Z variance train             0.010707952
KL Divergence                17.283636
KL Loss                      1.7283636
QF Loss                      618.0485
VF Loss                      57.095425
Policy Loss                  -620.9257
Q Predictions Mean           621.24335
Q Predictions Std            190.4088
Q Predictions Max            857.2402
Q Predictions Min            170.25749
V Predictions Mean           620.70496
V Predictions Std            191.64369
V Predictions Max            854.8263
V Predictions Min            172.91444
Log Pis Mean                 -1.4462698
Log Pis Std                  2.7124934
Log Pis Max                  7.217228
Log Pis Min                  -8.9681835
Policy mu Mean               0.028624391
Policy mu Std                0.4784664
Policy mu Max                2.0104156
Policy mu Min                -2.0529594
Policy log std Mean          -0.87614983
Policy log std Std           0.26627958
Policy log std Max           -0.17803735
Policy log std Min           -2.2414258
Z mean eval                  0.70211875
Z variance eval              0.01190179
total_rewards                [1040.6813843  1872.5667124   741.60663933  840.7780822    37.75005045
   37.45417315 1106.64130255  195.80123162  214.5219944   682.30508636]
total_rewards_mean           677.0106656768364
total_rewards_std            551.3944600557803
total_rewards_max            1872.5667124010574
total_rewards_min            37.454173146448845
Number of train steps total  216000
Number of env steps total    272000
Number of rollouts total     0
Train Time (s)               114.41143715474755
(Previous) Eval Time (s)     14.720566598698497
Sample Time (s)              18.726036292500794
Epoch Time (s)               147.85804004594684
Total Train Time (s)         8200.663975084666
Epoch                        53
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:48:15.382324 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #53 | Epoch Duration: 150.38462495803833
2020-01-12 01:48:15.382626 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #53 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.70300734
Z variance train             0.0119087305
KL Divergence                16.928247
KL Loss                      1.6928247
QF Loss                      294.72076
VF Loss                      60.750935
Policy Loss                  -636.25397
Q Predictions Mean           633.7836
Q Predictions Std            193.79265
Q Predictions Max            830.90393
Q Predictions Min            18.913074
V Predictions Mean           635.02747
V Predictions Std            191.9015
V Predictions Max            830.8446
V Predictions Min            9.277851
Log Pis Mean                 -1.2746708
Log Pis Std                  2.6352339
Log Pis Max                  8.915282
Log Pis Min                  -8.033592
Policy mu Mean               0.064767644
Policy mu Std                0.495116
Policy mu Max                2.4636874
Policy mu Min                -1.5454336
Policy log std Mean          -0.90569305
Policy log std Std           0.27482167
Policy log std Max           -0.2648179
Policy log std Min           -2.1887655
Z mean eval                  0.7282804
Z variance eval              0.012045992
total_rewards                [1889.61533278 1875.45653164  100.18609969  164.18261042 1870.79544267
  732.5850045   928.43590138 1831.90262878 1839.19763423 1942.06000496]
total_rewards_mean           1317.4417191043094
total_rewards_std            719.5214730473156
total_rewards_max            1942.060004962383
total_rewards_min            100.18609968831846
Number of train steps total  220000
Number of env steps total    277000
Number of rollouts total     0
Train Time (s)               110.80254230182618
(Previous) Eval Time (s)     17.246848883572966
Sample Time (s)              17.867796713951975
Epoch Time (s)               145.91718789935112
Total Train Time (s)         8353.994018296245
Epoch                        54
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:50:48.712440 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #54 | Epoch Duration: 153.3295488357544
2020-01-12 01:50:48.712711 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #54 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7274535
Z variance train             0.012027553
KL Divergence                17.200003
KL Loss                      1.7200003
QF Loss                      357.34756
VF Loss                      279.2556
Policy Loss                  -639.023
Q Predictions Mean           637.5806
Q Predictions Std            187.96147
Q Predictions Max            845.6605
Q Predictions Min            -21.3264
V Predictions Mean           649.73004
V Predictions Std            185.96999
V Predictions Max            858.94104
V Predictions Min            63.38101
Log Pis Mean                 -1.5333465
Log Pis Std                  2.6952984
Log Pis Max                  9.648937
Log Pis Min                  -8.554757
Policy mu Mean               -0.0043978896
Policy mu Std                0.50196886
Policy mu Max                1.8063239
Policy mu Min                -1.7219818
Policy log std Mean          -0.8793651
Policy log std Std           0.28329247
Policy log std Max           -0.1355111
Policy log std Min           -2.3711994
Z mean eval                  0.7068077
Z variance eval              0.008216139
total_rewards                [1191.48295391 2093.45543078 1832.49298775  460.80713741 2118.61569772
 1641.93027997   74.72091787  164.61829355  442.99992823 1921.31334956]
total_rewards_mean           1194.2436976760328
total_rewards_std            788.3669694034678
total_rewards_max            2118.615697724338
total_rewards_min            74.72091787308672
Number of train steps total  224000
Number of env steps total    282000
Number of rollouts total     0
Train Time (s)               118.36818682122976
(Previous) Eval Time (s)     24.658871117047966
Sample Time (s)              18.24253269005567
Epoch Time (s)               161.2695906283334
Total Train Time (s)         8509.040446041618
Epoch                        55
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:53:23.760942 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #55 | Epoch Duration: 155.04806232452393
2020-01-12 01:53:23.761162 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #55 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7073457
Z variance train             0.008205811
KL Divergence                18.450678
KL Loss                      1.8450679
QF Loss                      3352.7996
VF Loss                      180.49858
Policy Loss                  -653.0147
Q Predictions Mean           643.8914
Q Predictions Std            191.38013
Q Predictions Max            893.0335
Q Predictions Min            -32.19748
V Predictions Mean           654.40344
V Predictions Std            184.16165
V Predictions Max            895.9007
V Predictions Min            146.7828
Log Pis Mean                 -0.90717494
Log Pis Std                  3.0494587
Log Pis Max                  20.166382
Log Pis Min                  -6.7620997
Policy mu Mean               0.03346458
Policy mu Std                0.5258092
Policy mu Max                3.0785756
Policy mu Min                -2.0697205
Policy log std Mean          -0.89460665
Policy log std Std           0.28774908
Policy log std Max           -0.23238367
Policy log std Min           -2.3903875
Z mean eval                  0.7160726
Z variance eval              0.007719218
total_rewards                [ 704.64476038 1321.19103186 1149.61922743  183.55082995  239.21568213
  280.27324649  208.72096557 1623.81249433 1268.84044521 1256.29184401]
total_rewards_mean           823.6160527353499
total_rewards_std            530.8752395069478
total_rewards_max            1623.8124943270905
total_rewards_min            183.55082995168874
Number of train steps total  228000
Number of env steps total    287000
Number of rollouts total     0
Train Time (s)               114.54892445495352
(Previous) Eval Time (s)     18.437047748826444
Sample Time (s)              17.84590672655031
Epoch Time (s)               150.83187893033028
Total Train Time (s)         8657.39635198377
Epoch                        56
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:55:52.117033 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #56 | Epoch Duration: 148.35571336746216
2020-01-12 01:55:52.117184 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #56 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7175654
Z variance train             0.0077406066
KL Divergence                18.856728
KL Loss                      1.8856728
QF Loss                      378.04333
VF Loss                      225.09209
Policy Loss                  -656.01886
Q Predictions Mean           654.04297
Q Predictions Std            195.38994
Q Predictions Max            842.4743
Q Predictions Min            3.372013
V Predictions Mean           654.6543
V Predictions Std            187.2546
V Predictions Max            838.9806
V Predictions Min            109.724106
Log Pis Mean                 -1.0041158
Log Pis Std                  2.768996
Log Pis Max                  11.302685
Log Pis Min                  -9.3187475
Policy mu Mean               0.047694717
Policy mu Std                0.5119743
Policy mu Max                2.2590306
Policy mu Min                -2.0284016
Policy log std Mean          -0.9137984
Policy log std Std           0.2641003
Policy log std Max           -0.1124621
Policy log std Min           -2.2368522
Z mean eval                  0.7333256
Z variance eval              0.0070576197
total_rewards                [1992.54172262 1222.11804738 1044.71335811 1095.40209652   71.10992522
  258.99732547  400.40483723  639.28151215 1868.97355449 1921.05374291]
total_rewards_mean           1051.4596122111143
total_rewards_std            672.6146283539425
total_rewards_max            1992.541722619535
total_rewards_min            71.10992521699873
Number of train steps total  232000
Number of env steps total    292000
Number of rollouts total     0
Train Time (s)               110.33465892495587
(Previous) Eval Time (s)     15.960581995081156
Sample Time (s)              18.075038397684693
Epoch Time (s)               144.37027931772172
Total Train Time (s)         8803.045412125066
Epoch                        57
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:58:17.769209 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #57 | Epoch Duration: 145.65188002586365
2020-01-12 01:58:17.769460 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #57 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.73431236
Z variance train             0.0070670387
KL Divergence                19.22896
KL Loss                      1.922896
QF Loss                      997.78516
VF Loss                      514.4591
Policy Loss                  -665.5304
Q Predictions Mean           662.92944
Q Predictions Std            194.66534
Q Predictions Max            882.4578
Q Predictions Min            38.343376
V Predictions Mean           666.3401
V Predictions Std            190.85982
V Predictions Max            875.10284
V Predictions Min            24.91956
Log Pis Mean                 -1.0757282
Log Pis Std                  2.7130694
Log Pis Max                  11.160891
Log Pis Min                  -7.1462154
Policy mu Mean               0.0799451
Policy mu Std                0.5326357
Policy mu Max                2.565513
Policy mu Min                -1.9201604
Policy log std Mean          -0.867049
Policy log std Std           0.2640909
Policy log std Max           -0.22004056
Policy log std Min           -2.5509882
Z mean eval                  0.72311944
Z variance eval              0.016743626
total_rewards                [ 743.75921498 1202.05977453  240.27754811  107.57438174 2085.95219207
  271.02902159 1467.98162407  366.05234025 1953.02156502  331.02665276]
total_rewards_mean           876.8734315126985
total_rewards_std            708.2266862431584
total_rewards_max            2085.9521920733264
total_rewards_min            107.57438173624031
Number of train steps total  236000
Number of env steps total    297000
Number of rollouts total     0
Train Time (s)               109.9552779532969
(Previous) Eval Time (s)     17.241879471112043
Sample Time (s)              17.886660429649055
Epoch Time (s)               145.083817854058
Total Train Time (s)         8945.232150403783
Epoch                        58
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:00:39.958597 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #58 | Epoch Duration: 142.18892669677734
2020-01-12 02:00:39.958878 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #58 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.72391295
Z variance train             0.016807443
KL Divergence                16.955685
KL Loss                      1.6955684
QF Loss                      999.6467
VF Loss                      93.62278
Policy Loss                  -672.6011
Q Predictions Mean           669.7091
Q Predictions Std            186.34596
Q Predictions Max            899.8998
Q Predictions Min            166.57382
V Predictions Mean           673.0733
V Predictions Std            184.2417
V Predictions Max            889.1378
V Predictions Min            171.14996
Log Pis Mean                 -1.2718759
Log Pis Std                  2.484531
Log Pis Max                  8.397424
Log Pis Min                  -7.731375
Policy mu Mean               0.070937425
Policy mu Std                0.48301798
Policy mu Max                1.687995
Policy mu Min                -2.0315154
Policy log std Mean          -0.8820767
Policy log std Std           0.26041573
Policy log std Max           -0.2190113
Policy log std Min           -2.0384274
Z mean eval                  0.7525851
Z variance eval              0.015188992
total_rewards                [ 743.20450555 1990.16639931  904.46403305 1356.53612933 1969.24139212
 2036.93959332 1875.22246426   42.42293439  463.01955036  756.59411522]
total_rewards_mean           1213.7811116904675
total_rewards_std            690.7119618615263
total_rewards_max            2036.9395933172455
total_rewards_min            42.422934394502036
Number of train steps total  240000
Number of env steps total    302000
Number of rollouts total     0
Train Time (s)               109.31368578691036
(Previous) Eval Time (s)     14.346654310822487
Sample Time (s)              18.304193457588553
Epoch Time (s)               141.9645335553214
Total Train Time (s)         9091.02576123178
Epoch                        59
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:03:05.753505 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #59 | Epoch Duration: 145.7943925857544
2020-01-12 02:03:05.753750 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #59 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7525864
Z variance train             0.015170475
KL Divergence                16.77978
KL Loss                      1.6779779
QF Loss                      288.25934
VF Loss                      117.74281
Policy Loss                  -679.25665
Q Predictions Mean           676.2894
Q Predictions Std            203.0691
Q Predictions Max            888.0566
Q Predictions Min            -25.021748
V Predictions Mean           681.0034
V Predictions Std            202.98936
V Predictions Max            890.5989
V Predictions Min            8.67254
Log Pis Mean                 -1.2203734
Log Pis Std                  2.6986485
Log Pis Max                  9.098777
Log Pis Min                  -10.437348
Policy mu Mean               0.031874467
Policy mu Std                0.47421148
Policy mu Max                1.7438964
Policy mu Min                -2.3352084
Policy log std Mean          -0.9084592
Policy log std Std           0.2666247
Policy log std Max           -0.23962784
Policy log std Min           -1.9626291
Z mean eval                  0.73908556
Z variance eval              0.014885595
total_rewards                [ 493.27161263 2016.5851861  2061.0456007  1932.68039417 1900.33436448
 1573.33492792 2098.20459499 1927.82976483  744.66106665 1104.49455025]
total_rewards_mean           1585.244206272957
total_rewards_std            560.6402739894678
total_rewards_max            2098.2045949945195
total_rewards_min            493.2716126260184
Number of train steps total  244000
Number of env steps total    307000
Number of rollouts total     0
Train Time (s)               113.19155175983906
(Previous) Eval Time (s)     18.17620592005551
Sample Time (s)              17.824993113987148
Epoch Time (s)               149.19275079388171
Total Train Time (s)         9243.837813044433
Epoch                        60
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:05:38.575637 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #60 | Epoch Duration: 152.82168436050415
2020-01-12 02:05:38.575939 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #60 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7368844
Z variance train             0.014831923
KL Divergence                16.588947
KL Loss                      1.6588948
QF Loss                      5121.341
VF Loss                      127.99743
Policy Loss                  -668.0884
Q Predictions Mean           668.4381
Q Predictions Std            199.05719
Q Predictions Max            890.26605
Q Predictions Min            49.57368
V Predictions Mean           676.1105
V Predictions Std            198.59343
V Predictions Max            892.05896
V Predictions Min            64.52638
Log Pis Mean                 -1.0603938
Log Pis Std                  2.691793
Log Pis Max                  10.377669
Log Pis Min                  -7.2194366
Policy mu Mean               0.023956235
Policy mu Std                0.51715404
Policy mu Max                2.5144715
Policy mu Min                -2.0168018
Policy log std Mean          -0.8947841
Policy log std Std           0.2654196
Policy log std Max           -0.21335405
Policy log std Min           -2.1443863
Z mean eval                  0.7368365
Z variance eval              0.016287362
total_rewards                [2048.03826477 2291.97732211  413.38144891  444.58232012 2174.62749818
  476.18337356  684.69205214 1980.57343172  352.33280968  805.54390703]
total_rewards_mean           1167.1932428231078
total_rewards_std            794.5455846283924
total_rewards_max            2291.977322109854
total_rewards_min            352.33280968364465
Number of train steps total  248000
Number of env steps total    312000
Number of rollouts total     0
Train Time (s)               112.01708638109267
(Previous) Eval Time (s)     21.804849080741405
Sample Time (s)              17.939705871976912
Epoch Time (s)               151.76164133381099
Total Train Time (s)         9396.559657787438
Epoch                        61
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:08:11.291158 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #61 | Epoch Duration: 152.7149965763092
2020-01-12 02:08:11.291409 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #61 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7366456
Z variance train             0.016270436
KL Divergence                16.961708
KL Loss                      1.6961708
QF Loss                      326.45563
VF Loss                      127.55343
Policy Loss                  -668.2549
Q Predictions Mean           664.9578
Q Predictions Std            211.50111
Q Predictions Max            874.3329
Q Predictions Min            -34.94977
V Predictions Mean           668.3748
V Predictions Std            207.04047
V Predictions Max            870.7826
V Predictions Min            47.34442
Log Pis Mean                 -1.534838
Log Pis Std                  2.5310953
Log Pis Max                  11.401173
Log Pis Min                  -6.441674
Policy mu Mean               0.08886184
Policy mu Std                0.4686102
Policy mu Max                1.8131775
Policy mu Min                -1.4704785
Policy log std Mean          -0.8742785
Policy log std Std           0.2690704
Policy log std Max           -0.19705194
Policy log std Min           -2.2721581
Z mean eval                  0.7592435
Z variance eval              0.01973529
total_rewards                [ 216.34284548 2203.75220713  105.20163077   74.93033861 2184.4581263
  695.6415947  2304.04971929 1395.09661218 2143.80267998  309.87921201]
total_rewards_mean           1163.315496643527
total_rewards_std            926.8014763410135
total_rewards_max            2304.049719289085
total_rewards_min            74.930338612209
Number of train steps total  252000
Number of env steps total    317000
Number of rollouts total     0
Train Time (s)               115.7699292008765
(Previous) Eval Time (s)     22.757899885065854
Sample Time (s)              17.877006085123867
Epoch Time (s)               156.40483517106622
Total Train Time (s)         9549.347532853018
Epoch                        62
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:10:44.082251 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #62 | Epoch Duration: 152.7906436920166
2020-01-12 02:10:44.082526 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #62 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7587906
Z variance train             0.019692436
KL Divergence                17.213581
KL Loss                      1.7213582
QF Loss                      396.47226
VF Loss                      101.77467
Policy Loss                  -671.19977
Q Predictions Mean           669.20874
Q Predictions Std            219.25703
Q Predictions Max            871.83295
Q Predictions Min            -19.129978
V Predictions Mean           675.1625
V Predictions Std            217.59874
V Predictions Max            899.7874
V Predictions Min            0.2901411
Log Pis Mean                 -1.1710368
Log Pis Std                  2.9492657
Log Pis Max                  12.281188
Log Pis Min                  -9.068795
Policy mu Mean               0.008777961
Policy mu Std                0.5362591
Policy mu Max                2.3848622
Policy mu Min                -2.5574715
Policy log std Mean          -0.8857739
Policy log std Std           0.2657359
Policy log std Max           -0.2626148
Policy log std Min           -2.2946956
Z mean eval                  0.77005273
Z variance eval              0.012805539
total_rewards                [ 228.154225   2105.30283431 2242.34339483 2257.52994522   87.09176041
 2013.41759803  393.89844573  775.90467218 1629.36918663 1547.8587426 ]
total_rewards_mean           1328.0870804936947
total_rewards_std            827.0475725578257
total_rewards_max            2257.5299452239965
total_rewards_min            87.09176040857906
Number of train steps total  256000
Number of env steps total    322000
Number of rollouts total     0
Train Time (s)               108.40080452663824
(Previous) Eval Time (s)     19.143395007122308
Sample Time (s)              18.008287102915347
Epoch Time (s)               145.5524866366759
Total Train Time (s)         9694.06619829312
Epoch                        63
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:13:08.800418 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #63 | Epoch Duration: 144.71770405769348
2020-01-12 02:13:08.800581 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #63 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.76914644
Z variance train             0.012833124
KL Divergence                18.379623
KL Loss                      1.8379624
QF Loss                      451.11115
VF Loss                      84.59856
Policy Loss                  -705.0806
Q Predictions Mean           704.0301
Q Predictions Std            200.25093
Q Predictions Max            925.8146
Q Predictions Min            1.8089614
V Predictions Mean           703.5937
V Predictions Std            193.34024
V Predictions Max            918.487
V Predictions Min            44.10324
Log Pis Mean                 -1.0879481
Log Pis Std                  3.2039738
Log Pis Max                  21.752262
Log Pis Min                  -7.7562103
Policy mu Mean               0.05960228
Policy mu Std                0.5461246
Policy mu Max                3.1033156
Policy mu Min                -2.6354141
Policy log std Mean          -0.8890671
Policy log std Std           0.25983393
Policy log std Max           -0.23880816
Policy log std Min           -2.2293677
Z mean eval                  0.7510423
Z variance eval              0.019609634
total_rewards                [ -16.22917172   -9.7920187  2044.93699102  322.99619365  439.32584763
 2130.63051947  606.25204579 2260.91128939   84.04959875  929.18504945]
total_rewards_mean           879.2266344721627
total_rewards_std            873.9772630852963
total_rewards_max            2260.9112893851493
total_rewards_min            -16.229171719792284
Number of train steps total  260000
Number of env steps total    327000
Number of rollouts total     0
Train Time (s)               118.87348848814145
(Previous) Eval Time (s)     18.30834026215598
Sample Time (s)              17.76132266689092
Epoch Time (s)               154.94315141718835
Total Train Time (s)         9845.586079402361
Epoch                        64
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:15:40.322107 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #64 | Epoch Duration: 151.5214068889618
2020-01-12 02:15:40.322299 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #64 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.74865276
Z variance train             0.019553829
KL Divergence                18.238985
KL Loss                      1.8238986
QF Loss                      775.74414
VF Loss                      240.06377
Policy Loss                  -689.316
Q Predictions Mean           689.4273
Q Predictions Std            214.32254
Q Predictions Max            921.1744
Q Predictions Min            -28.923851
V Predictions Mean           700.3164
V Predictions Std            214.50224
V Predictions Max            939.2039
V Predictions Min            -16.39396
Log Pis Mean                 -1.507786
Log Pis Std                  2.6766672
Log Pis Max                  7.5570984
Log Pis Min                  -8.761951
Policy mu Mean               0.041902646
Policy mu Std                0.49090695
Policy mu Max                1.698548
Policy mu Min                -1.7964606
Policy log std Mean          -0.85907346
Policy log std Std           0.2438772
Policy log std Max           -0.19199139
Policy log std Min           -1.8839762
Z mean eval                  0.7640841
Z variance eval              0.01614725
total_rewards                [2264.60802449  244.45163037   73.40261742 1168.09763204 2183.8404532
  355.97817023 2262.03380597  707.50194258 2269.16945619 2302.06199653]
total_rewards_mean           1383.114572901922
total_rewards_std            915.9608008136393
total_rewards_max            2302.0619965343744
total_rewards_min            73.4026174233485
Number of train steps total  264000
Number of env steps total    332000
Number of rollouts total     0
Train Time (s)               115.98083633556962
(Previous) Eval Time (s)     14.886315654963255
Sample Time (s)              17.77212262712419
Epoch Time (s)               148.63927461765707
Total Train Time (s)         9998.72593060648
Epoch                        65
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:18:13.463873 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #65 | Epoch Duration: 153.14141726493835
2020-01-12 02:18:13.464095 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.76469254
Z variance train             0.016171442
KL Divergence                18.432741
KL Loss                      1.8432741
QF Loss                      916.95544
VF Loss                      125.65982
Policy Loss                  -670.9752
Q Predictions Mean           662.753
Q Predictions Std            245.64752
Q Predictions Max            930.8704
Q Predictions Min            -38.70726
V Predictions Mean           669.28015
V Predictions Std            235.18137
V Predictions Max            929.4404
V Predictions Min            35.816322
Log Pis Mean                 -1.0213506
Log Pis Std                  2.9558828
Log Pis Max                  11.83429
Log Pis Min                  -9.565273
Policy mu Mean               0.0050027883
Policy mu Std                0.51810765
Policy mu Max                2.5150099
Policy mu Min                -1.9971193
Policy log std Mean          -0.9169744
Policy log std Std           0.32242385
Policy log std Max           -0.23351759
Policy log std Min           -2.824789
Z mean eval                  0.7894054
Z variance eval              0.013022336
total_rewards                [2146.43289637 2214.95487903 2179.45174508 1046.44967347  654.92190634
 2205.32156629 1383.69835001 1304.51887643 2243.0730702   255.32886802]
total_rewards_mean           1563.4151831235772
total_rewards_std            701.4928325230204
total_rewards_max            2243.073070199851
total_rewards_min            255.32886801646015
Number of train steps total  268000
Number of env steps total    337000
Number of rollouts total     0
Train Time (s)               116.86651444900781
(Previous) Eval Time (s)     19.38813482085243
Sample Time (s)              18.04388791602105
Epoch Time (s)               154.2985371858813
Total Train Time (s)         10156.067234494723
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:20:50.807147 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #66 | Epoch Duration: 157.34288024902344
2020-01-12 02:20:50.807350 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #66 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7894796
Z variance train             0.013009945
KL Divergence                18.019695
KL Loss                      1.8019695
QF Loss                      324.39417
VF Loss                      79.92299
Policy Loss                  -707.0373
Q Predictions Mean           705.8882
Q Predictions Std            225.42732
Q Predictions Max            930.0782
Q Predictions Min            -22.557505
V Predictions Mean           702.8907
V Predictions Std            224.14735
V Predictions Max            912.44354
V Predictions Min            -8.445933
Log Pis Mean                 -0.9860581
Log Pis Std                  2.9505668
Log Pis Max                  13.032885
Log Pis Min                  -10.700972
Policy mu Mean               0.0711253
Policy mu Std                0.53368264
Policy mu Max                2.5068133
Policy mu Min                -3.0000927
Policy log std Mean          -0.89093465
Policy log std Std           0.28535566
Policy log std Max           -0.27081412
Policy log std Min           -2.6449838
Z mean eval                  0.7558074
Z variance eval              0.014047304
total_rewards                [1983.44099065  137.20105221  534.93995163 1160.24415293 2039.65983495
  105.60490914  573.66039862  276.05066352  453.81388316 1361.07132584]
total_rewards_mean           862.5687162667407
total_rewards_std            691.379685199943
total_rewards_max            2039.6598349519347
total_rewards_min            105.60490914329483
Number of train steps total  272000
Number of env steps total    342000
Number of rollouts total     0
Train Time (s)               111.99735065503046
(Previous) Eval Time (s)     22.43216184200719
Sample Time (s)              17.87250770861283
Epoch Time (s)               152.30202020565048
Total Train Time (s)         10303.396834149957
Epoch                        67
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:23:18.139180 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #67 | Epoch Duration: 147.33165192604065
2020-01-12 02:23:18.139448 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #67 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.75441897
Z variance train             0.014063342
KL Divergence                17.823475
KL Loss                      1.7823476
QF Loss                      389.07803
VF Loss                      67.124985
Policy Loss                  -715.074
Q Predictions Mean           713.5643
Q Predictions Std            213.68463
Q Predictions Max            918.0189
Q Predictions Min            -33.66009
V Predictions Mean           715.8992
V Predictions Std            213.81332
V Predictions Max            907.97363
V Predictions Min            -82.491806
Log Pis Mean                 -1.3002683
Log Pis Std                  2.6414437
Log Pis Max                  12.227666
Log Pis Min                  -9.675413
Policy mu Mean               0.03192975
Policy mu Std                0.52780867
Policy mu Max                2.7246199
Policy mu Min                -1.6909329
Policy log std Mean          -0.87735647
Policy log std Std           0.25715938
Policy log std Max           -0.20563674
Policy log std Min           -2.0681062
Z mean eval                  0.7709054
Z variance eval              0.018285183
total_rewards                [2135.15356046  934.68312033   28.33417341  204.91590992  876.22000083
   48.33607356 1718.35258111  400.44224226  605.67347439 2022.79640061]
total_rewards_mean           897.49075368985
total_rewards_std            759.0878191806406
total_rewards_max            2135.1535604587225
total_rewards_min            28.33417341444382
Number of train steps total  276000
Number of env steps total    347000
Number of rollouts total     0
Train Time (s)               110.22240831097588
(Previous) Eval Time (s)     17.46150363283232
Sample Time (s)              18.006728692445904
Epoch Time (s)               145.6906406362541
Total Train Time (s)         10448.52622820763
Epoch                        68
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:25:43.268341 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #68 | Epoch Duration: 145.12870049476624
2020-01-12 02:25:43.268491 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #68 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7704367
Z variance train             0.018233884
KL Divergence                18.700062
KL Loss                      1.8700062
QF Loss                      307.48553
VF Loss                      82.76101
Policy Loss                  -721.97174
Q Predictions Mean           720.79333
Q Predictions Std            212.71031
Q Predictions Max            932.79913
Q Predictions Min            -40.498627
V Predictions Mean           724.42706
V Predictions Std            209.1723
V Predictions Max            930.8103
V Predictions Min            72.28975
Log Pis Mean                 -1.0370553
Log Pis Std                  2.8814056
Log Pis Max                  10.579469
Log Pis Min                  -7.748653
Policy mu Mean               -0.025321763
Policy mu Std                0.53424066
Policy mu Max                2.2775009
Policy mu Min                -2.053989
Policy log std Mean          -0.87308
Policy log std Std           0.27463752
Policy log std Max           -0.1635027
Policy log std Min           -2.4542396
Z mean eval                  0.76421237
Z variance eval              0.012108657
total_rewards                [ 900.91358037 2070.09790782 2243.98789419 1793.69075787   28.91400607
   29.85618117 2166.59547477 2038.41093343  593.08934841 2248.76773168]
total_rewards_mean           1411.4323815759176
total_rewards_std            876.814628989318
total_rewards_max            2248.767731675173
total_rewards_min            28.914006070833445
Number of train steps total  280000
Number of env steps total    352000
Number of rollouts total     0
Train Time (s)               113.08535581082106
(Previous) Eval Time (s)     16.899292464833707
Sample Time (s)              19.057201612275094
Epoch Time (s)               149.04184988792986
Total Train Time (s)         10598.432288368233
Epoch                        69
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:28:13.176059 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #69 | Epoch Duration: 149.9074330329895
2020-01-12 02:28:13.176232 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #69 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.76442826
Z variance train             0.012110572
KL Divergence                18.88171
KL Loss                      1.8881711
QF Loss                      469.57663
VF Loss                      102.33728
Policy Loss                  -710.13776
Q Predictions Mean           705.8609
Q Predictions Std            238.77979
Q Predictions Max            950.3509
Q Predictions Min            -44.507595
V Predictions Mean           710.29816
V Predictions Std            233.76569
V Predictions Max            927.7973
V Predictions Min            -51.592407
Log Pis Mean                 -0.9728759
Log Pis Std                  2.9740908
Log Pis Max                  12.454157
Log Pis Min                  -6.933288
Policy mu Mean               0.008574
Policy mu Std                0.5238878
Policy mu Max                2.3945158
Policy mu Min                -2.6644943
Policy log std Mean          -0.88837326
Policy log std Std           0.28679383
Policy log std Max           -0.16678596
Policy log std Min           -2.1579576
Z mean eval                  0.770527
Z variance eval              0.008662067
total_rewards                [ 395.83651854 2379.15626567 2098.27724313 1020.38085889 1126.25971881
  597.37670435  411.05180446 2326.34733323 1108.9231412   556.34443677]
total_rewards_mean           1201.9954025061948
total_rewards_std            745.5528916822658
total_rewards_max            2379.156265669408
total_rewards_min            395.8365185394553
Number of train steps total  284000
Number of env steps total    357000
Number of rollouts total     0
Train Time (s)               119.54121497971937
(Previous) Eval Time (s)     17.764584159944206
Sample Time (s)              17.43104265956208
Epoch Time (s)               154.73684179922566
Total Train Time (s)         10757.245424821507
Epoch                        70
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:30:51.991251 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #70 | Epoch Duration: 158.81487131118774
2020-01-12 02:30:51.991428 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #70 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.77042246
Z variance train             0.008662434
KL Divergence                19.17382
KL Loss                      1.9173821
QF Loss                      349.4736
VF Loss                      83.23299
Policy Loss                  -732.24054
Q Predictions Mean           730.5494
Q Predictions Std            219.68248
Q Predictions Max            943.73456
Q Predictions Min            61.561043
V Predictions Mean           732.08374
V Predictions Std            219.6136
V Predictions Max            936.9432
V Predictions Min            -6.5703187
Log Pis Mean                 -1.2728055
Log Pis Std                  2.6886916
Log Pis Max                  8.18071
Log Pis Min                  -10.434122
Policy mu Mean               0.015729135
Policy mu Std                0.5028394
Policy mu Max                2.5518258
Policy mu Min                -1.7655705
Policy log std Mean          -0.8804947
Policy log std Std           0.26404327
Policy log std Max           -0.2719807
Policy log std Min           -1.9344704
Z mean eval                  0.787987
Z variance eval              0.01607127
total_rewards                [2298.69377865 2388.93694294 1501.55021823 2404.8735852  2249.30468278
  451.65791055  494.25828222   58.85316133 2241.99530681 2337.29803658]
total_rewards_mean           1642.7421905298822
total_rewards_std            896.8662227094379
total_rewards_max            2404.873585201797
total_rewards_min            58.853161333404316
Number of train steps total  288000
Number of env steps total    362000
Number of rollouts total     0
Train Time (s)               119.17594538303092
(Previous) Eval Time (s)     21.84233279991895
Sample Time (s)              17.61218161834404
Epoch Time (s)               158.6304598012939
Total Train Time (s)         10913.17322522914
Epoch                        71
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:33:27.919492 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #71 | Epoch Duration: 155.92792749404907
2020-01-12 02:33:27.919663 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #71 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7881592
Z variance train             0.01607268
KL Divergence                18.137547
KL Loss                      1.8137547
QF Loss                      571.09143
VF Loss                      77.94342
Policy Loss                  -735.3822
Q Predictions Mean           733.39905
Q Predictions Std            207.62749
Q Predictions Max            985.1201
Q Predictions Min            165.9579
V Predictions Mean           736.75934
V Predictions Std            204.65991
V Predictions Max            982.98083
V Predictions Min            167.67412
Log Pis Mean                 -1.1319277
Log Pis Std                  2.3256576
Log Pis Max                  4.578492
Log Pis Min                  -7.4594784
Policy mu Mean               0.065275446
Policy mu Std                0.5190175
Policy mu Max                2.0300052
Policy mu Min                -1.8077563
Policy log std Mean          -0.8751462
Policy log std Std           0.24817923
Policy log std Max           -0.21904653
Policy log std Min           -1.7314167
Z mean eval                  0.7664493
Z variance eval              0.013487458
total_rewards                [2422.34163985 2329.94350854 1349.70527612 2003.11764866 2138.50943118
 2188.74783943 2396.48543827 2318.62856938 2117.07444227 2097.02719283]
total_rewards_mean           2136.158098653544
total_rewards_std            293.4951494499136
total_rewards_max            2422.3416398496456
total_rewards_min            1349.7052761228802
Number of train steps total  292000
Number of env steps total    367000
Number of rollouts total     0
Train Time (s)               115.14642465487123
(Previous) Eval Time (s)     19.139479242265224
Sample Time (s)              18.572340071201324
Epoch Time (s)               152.85824396833777
Total Train Time (s)         11072.728489716537
Epoch                        72
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:36:07.479364 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #72 | Epoch Duration: 159.5595519542694
2020-01-12 02:36:07.479637 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #72 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7661367
Z variance train             0.013551908
KL Divergence                18.359179
KL Loss                      1.8359178
QF Loss                      682.5728
VF Loss                      181.92984
Policy Loss                  -733.6644
Q Predictions Mean           732.75616
Q Predictions Std            224.24316
Q Predictions Max            965.6379
Q Predictions Min            2.1935253
V Predictions Mean           731.1661
V Predictions Std            217.24644
V Predictions Max            951.8848
V Predictions Min            81.36874
Log Pis Mean                 -0.91124886
Log Pis Std                  2.9915898
Log Pis Max                  14.233988
Log Pis Min                  -6.8941126
Policy mu Mean               0.041299563
Policy mu Std                0.5271683
Policy mu Max                2.097802
Policy mu Min                -2.0293837
Policy log std Mean          -0.9088608
Policy log std Std           0.31492084
Policy log std Max           -0.11002612
Policy log std Min           -2.6489563
Z mean eval                  0.7826713
Z variance eval              0.013985802
total_rewards                [2302.58242834 2376.45507335   47.61046936  303.93960249  259.20438591
  953.76939597  143.56613332 1464.43561785 1160.58873392 1780.56078939]
total_rewards_mean           1079.2712629895918
total_rewards_std            839.9532620549116
total_rewards_max            2376.4550733454926
total_rewards_min            47.610469356830734
Number of train steps total  296000
Number of env steps total    372000
Number of rollouts total     0
Train Time (s)               112.35341379418969
(Previous) Eval Time (s)     25.840464903973043
Sample Time (s)              18.727572098374367
Epoch Time (s)               156.9214507965371
Total Train Time (s)         11220.366503773723
Epoch                        73
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:38:35.118124 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #73 | Epoch Duration: 147.63825345039368
2020-01-12 02:38:35.118420 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #73 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7835721
Z variance train             0.013963197
KL Divergence                18.077938
KL Loss                      1.8077939
QF Loss                      700.9789
VF Loss                      369.60876
Policy Loss                  -741.14215
Q Predictions Mean           737.9226
Q Predictions Std            227.99469
Q Predictions Max            982.90466
Q Predictions Min            -35.452168
V Predictions Mean           737.8236
V Predictions Std            223.72047
V Predictions Max            968.6748
V Predictions Min            76.90008
Log Pis Mean                 -1.0723372
Log Pis Std                  2.804223
Log Pis Max                  14.800247
Log Pis Min                  -8.011
Policy mu Mean               0.057475463
Policy mu Std                0.50608456
Policy mu Max                2.2417989
Policy mu Min                -2.2613516
Policy log std Mean          -0.8885398
Policy log std Std           0.28252915
Policy log std Max           -0.23424602
Policy log std Min           -2.2869072
Z mean eval                  0.7736729
Z variance eval              0.017094046
total_rewards                [ 513.88073201 2504.42128383 2499.1906607  2104.3184988  1034.4058553
 2460.48953334 1839.60102406 2320.63163197 1043.05283841 1831.23042478]
total_rewards_mean           1815.1222483218414
total_rewards_std            678.1189660835619
total_rewards_max            2504.421283834641
total_rewards_min            513.8807320137299
Number of train steps total  300000
Number of env steps total    377000
Number of rollouts total     0
Train Time (s)               108.58300862973556
(Previous) Eval Time (s)     16.556947681121528
Sample Time (s)              18.13123325770721
Epoch Time (s)               143.2711895685643
Total Train Time (s)         11369.41236443771
Epoch                        74
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:41:04.164469 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #74 | Epoch Duration: 149.04582452774048
2020-01-12 02:41:04.164653 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #74 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.77511704
Z variance train             0.01710677
KL Divergence                17.866364
KL Loss                      1.7866364
QF Loss                      417.09216
VF Loss                      213.03558
Policy Loss                  -723.80817
Q Predictions Mean           719.91504
Q Predictions Std            238.12875
Q Predictions Max            991.00354
Q Predictions Min            27.645414
V Predictions Mean           714.9249
V Predictions Std            233.11258
V Predictions Max            982.42163
V Predictions Min            14.449406
Log Pis Mean                 -0.88796806
Log Pis Std                  3.120714
Log Pis Max                  10.204855
Log Pis Min                  -8.436447
Policy mu Mean               0.018293055
Policy mu Std                0.5288728
Policy mu Max                1.6942341
Policy mu Min                -2.1053774
Policy log std Mean          -0.9012846
Policy log std Std           0.29718795
Policy log std Max           -0.17270666
Policy log std Min           -2.17964
Z mean eval                  0.78549325
Z variance eval              0.013769453
total_rewards                [  84.07664448 2159.4463743   203.86375943 1609.7651987    36.95961528
 2490.28908866  666.70290222 2096.61198759   85.67699586  643.95182088]
total_rewards_mean           1007.7344387410214
total_rewards_std            928.0673360578747
total_rewards_max            2490.2890886627642
total_rewards_min            36.95961528336247
Number of train steps total  304000
Number of env steps total    382000
Number of rollouts total     0
Train Time (s)               114.24445708002895
(Previous) Eval Time (s)     22.3312947480008
Sample Time (s)              17.586541873402894
Epoch Time (s)               154.16229370143265
Total Train Time (s)         11515.644769793376
Epoch                        75
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:43:30.398387 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #75 | Epoch Duration: 146.2336082458496
2020-01-12 02:43:30.398594 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #75 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.78682995
Z variance train             0.013753335
KL Divergence                19.100458
KL Loss                      1.9100459
QF Loss                      427.07562
VF Loss                      106.11872
Policy Loss                  -747.68896
Q Predictions Mean           743.60925
Q Predictions Std            239.1914
Q Predictions Max            976.8754
Q Predictions Min            -18.705992
V Predictions Mean           743.41534
V Predictions Std            234.20657
V Predictions Max            964.4075
V Predictions Min            -1.5651066
Log Pis Mean                 -0.99639255
Log Pis Std                  2.7940328
Log Pis Max                  11.585846
Log Pis Min                  -8.146671
Policy mu Mean               0.031982712
Policy mu Std                0.52665615
Policy mu Max                1.7656235
Policy mu Min                -2.0062988
Policy log std Mean          -0.8827163
Policy log std Std           0.27703354
Policy log std Max           -0.10051161
Policy log std Min           -2.1513076
Z mean eval                  0.7897608
Z variance eval              0.007878529
total_rewards                [2333.31835715 2323.39533933 2155.45072578 2410.03685063 2481.90597646
 2317.30694924 2433.57470442  362.96602163 2380.85135136  618.70657456]
total_rewards_mean           1981.751285054396
total_rewards_std            752.2269792823669
total_rewards_max            2481.9059764570015
total_rewards_min            362.9660216262736
Number of train steps total  308000
Number of env steps total    387000
Number of rollouts total     0
Train Time (s)               113.2230395260267
(Previous) Eval Time (s)     14.402332882862538
Sample Time (s)              17.5169976670295
Epoch Time (s)               145.14237007591873
Total Train Time (s)         11668.113518717233
Epoch                        76
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:46:02.868164 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #76 | Epoch Duration: 152.46945023536682
2020-01-12 02:46:02.868326 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #76 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7896542
Z variance train             0.007862223
KL Divergence                20.347797
KL Loss                      2.0347798
QF Loss                      663.62866
VF Loss                      120.49403
Policy Loss                  -744.8543
Q Predictions Mean           743.1301
Q Predictions Std            227.78767
Q Predictions Max            989.53973
Q Predictions Min            -3.7733731
V Predictions Mean           745.75085
V Predictions Std            223.14987
V Predictions Max            984.88696
V Predictions Min            31.04896
Log Pis Mean                 -1.0318503
Log Pis Std                  2.9710093
Log Pis Max                  9.680309
Log Pis Min                  -10.544603
Policy mu Mean               0.004756824
Policy mu Std                0.5186394
Policy mu Max                2.020929
Policy mu Min                -1.6253498
Policy log std Mean          -0.91227365
Policy log std Std           0.28381076
Policy log std Max           -0.12917876
Policy log std Min           -2.1553676
Z mean eval                  0.77102196
Z variance eval              0.009542908
total_rewards                [  19.74169682  193.52645601  333.73745046 1705.63087342   64.1457887
 2305.95075601 1487.92404866  391.22827127  261.67693735  467.98261441]
total_rewards_mean           723.1544893107015
total_rewards_std            761.896258355582
total_rewards_max            2305.950756011473
total_rewards_min            19.74169681652014
Number of train steps total  312000
Number of env steps total    392000
Number of rollouts total     0
Train Time (s)               115.46317823138088
(Previous) Eval Time (s)     21.729121486190706
Sample Time (s)              17.627010935917497
Epoch Time (s)               154.81931065348908
Total Train Time (s)         11818.903946524952
Epoch                        77
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:48:33.661726 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #77 | Epoch Duration: 150.79326272010803
2020-01-12 02:48:33.661964 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.76726735
Z variance train             0.009592436
KL Divergence                19.799683
KL Loss                      1.9799683
QF Loss                      492.2142
VF Loss                      212.96432
Policy Loss                  -747.83325
Q Predictions Mean           749.20184
Q Predictions Std            241.45128
Q Predictions Max            981.11554
Q Predictions Min            -10.204594
V Predictions Mean           756.4952
V Predictions Std            242.16025
V Predictions Max            985.00085
V Predictions Min            24.811718
Log Pis Mean                 -1.1045792
Log Pis Std                  2.7497118
Log Pis Max                  7.926205
Log Pis Min                  -8.029202
Policy mu Mean               0.04657952
Policy mu Std                0.5318578
Policy mu Max                2.0943701
Policy mu Min                -2.0402079
Policy log std Mean          -0.9061519
Policy log std Std           0.28239316
Policy log std Max           -0.20622367
Policy log std Min           -2.1616752
Z mean eval                  0.77652955
Z variance eval              0.008293166
total_rewards                [1026.83319882  118.14957158 2313.22883465  748.95694166  252.31189538
  681.01560673 2048.11145189  483.49356592   96.84934814 2422.20591934]
total_rewards_mean           1019.1156334106261
total_rewards_std            861.7873605193172
total_rewards_max            2422.2059193441746
total_rewards_min            96.84934813952916
Number of train steps total  316000
Number of env steps total    397000
Number of rollouts total     0
Train Time (s)               117.58194042602554
(Previous) Eval Time (s)     17.70275774784386
Sample Time (s)              17.29829990118742
Epoch Time (s)               152.58299807505682
Total Train Time (s)         11967.978988189716
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:51:02.739789 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #78 | Epoch Duration: 149.0776243209839
2020-01-12 02:51:02.740099 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #78 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7770989
Z variance train             0.008303775
KL Divergence                19.734621
KL Loss                      1.9734621
QF Loss                      508.5904
VF Loss                      141.46016
Policy Loss                  -759.8381
Q Predictions Mean           756.58374
Q Predictions Std            227.24562
Q Predictions Max            1024.2794
Q Predictions Min            26.586002
V Predictions Mean           766.1388
V Predictions Std            228.75035
V Predictions Max            1015.20215
V Predictions Min            69.471245
Log Pis Mean                 -1.013098
Log Pis Std                  2.9059124
Log Pis Max                  10.451645
Log Pis Min                  -8.339422
Policy mu Mean               0.02920766
Policy mu Std                0.51424086
Policy mu Max                1.6361296
Policy mu Min                -1.9298961
Policy log std Mean          -0.9101064
Policy log std Std           0.28005272
Policy log std Max           -0.19521731
Policy log std Min           -2.135757
Z mean eval                  0.78092474
Z variance eval              0.015911542
total_rewards                [-1.76640386e+00  7.32096011e+02  3.18879462e+02  2.35416564e+03
  4.10202195e+02  1.41143361e+01  1.97041505e+03  1.97227818e+03
  1.16108606e+03  2.37322133e+03]
total_rewards_mean           1130.4691858987167
total_rewards_std            912.2129091009363
total_rewards_max            2373.221328027181
total_rewards_min            -1.7664038607439794
Number of train steps total  320000
Number of env steps total    402000
Number of rollouts total     0
Train Time (s)               114.81297365995124
(Previous) Eval Time (s)     14.197117594070733
Sample Time (s)              17.522604117169976
Epoch Time (s)               146.53269537119195
Total Train Time (s)         12121.697065746877
Epoch                        79
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:53:36.457817 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #79 | Epoch Duration: 153.71751856803894
2020-01-12 02:53:36.457986 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #79 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.78215516
Z variance train             0.015904352
KL Divergence                18.722046
KL Loss                      1.8722047
QF Loss                      458.38812
VF Loss                      93.2045
Policy Loss                  -785.46954
Q Predictions Mean           783.3871
Q Predictions Std            218.89496
Q Predictions Max            1014.06775
Q Predictions Min            -31.721756
V Predictions Mean           789.09814
V Predictions Std            215.75421
V Predictions Max            1019.3315
V Predictions Min            -23.054583
Log Pis Mean                 -0.81004417
Log Pis Std                  2.777921
Log Pis Max                  17.845701
Log Pis Min                  -8.285554
Policy mu Mean               0.038767695
Policy mu Std                0.5205748
Policy mu Max                3.16269
Policy mu Min                -3.340409
Policy log std Mean          -0.9579654
Policy log std Std           0.28743798
Policy log std Max           -0.14415085
Policy log std Min           -2.450497
Z mean eval                  0.79913366
Z variance eval              0.021520864
total_rewards                [2055.36024397  289.80129392  356.33025342 1795.68896066 1132.84077402
   38.11197066  390.70727599 1084.31420869  444.18643069 1239.74752055]
total_rewards_mean           882.7088932578248
total_rewards_std            649.2808662852105
total_rewards_max            2055.36024397332
total_rewards_min            38.11197066052999
Number of train steps total  324000
Number of env steps total    407000
Number of rollouts total     0
Train Time (s)               111.5832165949978
(Previous) Eval Time (s)     21.381670034024864
Sample Time (s)              18.550122608430684
Epoch Time (s)               151.51500923745334
Total Train Time (s)         12272.829700048082
Epoch                        80
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:56:07.594218 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #80 | Epoch Duration: 151.13605761528015
2020-01-12 02:56:07.594468 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #80 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7989809
Z variance train             0.021539848
KL Divergence                18.471958
KL Loss                      1.8471959
QF Loss                      654.53613
VF Loss                      292.19034
Policy Loss                  -768.7029
Q Predictions Mean           766.3329
Q Predictions Std            242.56946
Q Predictions Max            993.6879
Q Predictions Min            -31.723175
V Predictions Mean           769.79175
V Predictions Std            240.1711
V Predictions Max            998.3098
V Predictions Min            1.1503863
Log Pis Mean                 -0.9048258
Log Pis Std                  2.6140742
Log Pis Max                  7.8166904
Log Pis Min                  -7.044507
Policy mu Mean               0.02668187
Policy mu Std                0.5203554
Policy mu Max                2.3507588
Policy mu Min                -2.0868433
Policy log std Mean          -0.9252342
Policy log std Std           0.2840772
Policy log std Max           -0.25461012
Policy log std Min           -2.1529615
Z mean eval                  0.7873503
Z variance eval              0.015396453
total_rewards                [2365.00431495 1024.06154877 1200.06086306 1791.45997037 2229.28217316
  736.18377524 2560.03409141 2294.40439772  560.42253603  809.83724312]
total_rewards_mean           1557.0750913835752
total_rewards_std            731.1795532586915
total_rewards_max            2560.034091411396
total_rewards_min            560.422536031526
Number of train steps total  328000
Number of env steps total    412000
Number of rollouts total     0
Train Time (s)               117.7472140993923
(Previous) Eval Time (s)     21.002411962021142
Sample Time (s)              17.95402682526037
Epoch Time (s)               156.7036528866738
Total Train Time (s)         12429.766420065425
Epoch                        81
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:58:44.530417 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #81 | Epoch Duration: 156.9357714653015
2020-01-12 02:58:44.530567 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #81 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.78675836
Z variance train             0.015388062
KL Divergence                17.94822
KL Loss                      1.794822
QF Loss                      1506.7563
VF Loss                      243.2959
Policy Loss                  -777.6061
Q Predictions Mean           771.871
Q Predictions Std            233.84952
Q Predictions Max            1010.6007
Q Predictions Min            -2.5304594
V Predictions Mean           779.3807
V Predictions Std            227.55757
V Predictions Max            1006.6058
V Predictions Min            15.006432
Log Pis Mean                 -0.8991116
Log Pis Std                  2.7266095
Log Pis Max                  8.412142
Log Pis Min                  -8.918821
Policy mu Mean               0.049701586
Policy mu Std                0.5373572
Policy mu Max                2.0871248
Policy mu Min                -1.7593887
Policy log std Mean          -0.9066014
Policy log std Std           0.28292635
Policy log std Max           -0.22498822
Policy log std Min           -2.305975
Z mean eval                  0.7741251
Z variance eval              0.013612302
total_rewards                [ 794.63008949  540.41082525  701.69268976 1432.46563543 1237.52126225
 1576.00867847 2791.99370098  769.99077404 1005.36735202 2022.7746915 ]
total_rewards_mean           1287.285569919695
total_rewards_std            663.5154628296017
total_rewards_max            2791.9937009810114
total_rewards_min            540.4108252517235
Number of train steps total  332000
Number of env steps total    417000
Number of rollouts total     0
Train Time (s)               115.99665063293651
(Previous) Eval Time (s)     21.234225302934647
Sample Time (s)              18.026781069580466
Epoch Time (s)               155.25765700545162
Total Train Time (s)         12577.327008687891
Epoch                        82
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:01:12.092373 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #82 | Epoch Duration: 147.56169247627258
2020-01-12 03:01:12.092523 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #82 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7735721
Z variance train             0.013608327
KL Divergence                17.758976
KL Loss                      1.7758976
QF Loss                      368.8131
VF Loss                      52.304913
Policy Loss                  -774.0582
Q Predictions Mean           772.3224
Q Predictions Std            248.66013
Q Predictions Max            1010.8927
Q Predictions Min            -20.908165
V Predictions Mean           775.89606
V Predictions Std            247.94244
V Predictions Max            1001.8052
V Predictions Min            12.185053
Log Pis Mean                 -1.0687811
Log Pis Std                  3.067583
Log Pis Max                  13.5099125
Log Pis Min                  -9.794588
Policy mu Mean               0.024303172
Policy mu Std                0.5379978
Policy mu Max                2.6452427
Policy mu Min                -3.6389294
Policy log std Mean          -0.89430994
Policy log std Std           0.26931766
Policy log std Max           -0.0004913211
Policy log std Min           -2.1100235
Z mean eval                  0.8086258
Z variance eval              0.011148208
total_rewards                [1486.04829852 2581.24241246 1108.70398342   26.52949451  208.63273371
   23.94922791  145.58614297  444.39638903 2536.65466011   85.0352535 ]
total_rewards_mean           864.6778596133396
total_rewards_std            965.869286341602
total_rewards_max            2581.2424124616955
total_rewards_min            23.949227914117138
Number of train steps total  336000
Number of env steps total    422000
Number of rollouts total     0
Train Time (s)               118.76264716498554
(Previous) Eval Time (s)     13.53795187920332
Sample Time (s)              18.108421318698674
Epoch Time (s)               150.40902036288753
Total Train Time (s)         12730.329267604742
Epoch                        83
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:03:45.096318 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #83 | Epoch Duration: 153.00367832183838
2020-01-12 03:03:45.096542 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.80976903
Z variance train             0.011175035
KL Divergence                18.191822
KL Loss                      1.8191823
QF Loss                      422.75214
VF Loss                      154.7209
Policy Loss                  -794.7702
Q Predictions Mean           790.7593
Q Predictions Std            227.06631
Q Predictions Max            1036.6649
Q Predictions Min            -58.130604
V Predictions Mean           789.6941
V Predictions Std            220.17471
V Predictions Max            1019.33014
V Predictions Min            161.82281
Log Pis Mean                 -0.8998388
Log Pis Std                  3.0773957
Log Pis Max                  16.974052
Log Pis Min                  -8.892059
Policy mu Mean               0.053940922
Policy mu Std                0.54172504
Policy mu Max                2.6764162
Policy mu Min                -3.011132
Policy log std Mean          -0.92282486
Policy log std Std           0.2912013
Policy log std Max           -0.12027025
Policy log std Min           -2.6230278
Z mean eval                  0.7977866
Z variance eval              0.010686801
total_rewards                [2302.81923497 2604.29472206  145.94707448   81.38606093 1273.55907032
 1298.45082078 1567.11616761  355.65311282  287.13790217  850.92934871]
total_rewards_mean           1076.7293514851212
total_rewards_std            849.5050967845478
total_rewards_max            2604.294722062787
total_rewards_min            81.38606093361952
Number of train steps total  340000
Number of env steps total    427000
Number of rollouts total     0
Train Time (s)               110.06165663897991
(Previous) Eval Time (s)     16.13229183992371
Sample Time (s)              17.773878917563707
Epoch Time (s)               143.96782739646733
Total Train Time (s)         12876.81014303444
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:06:11.577932 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #84 | Epoch Duration: 146.48127365112305
2020-01-12 03:06:11.578114 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #84 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7977116
Z variance train             0.010692821
KL Divergence                18.674503
KL Loss                      1.8674504
QF Loss                      574.63306
VF Loss                      293.8094
Policy Loss                  -803.2007
Q Predictions Mean           799.8316
Q Predictions Std            227.76767
Q Predictions Max            1022.9494
Q Predictions Min            10.948198
V Predictions Mean           815.13086
V Predictions Std            221.54524
V Predictions Max            1031.102
V Predictions Min            26.165377
Log Pis Mean                 -0.7392465
Log Pis Std                  2.6597598
Log Pis Max                  10.590428
Log Pis Min                  -7.1450744
Policy mu Mean               0.0056716306
Policy mu Std                0.5399963
Policy mu Max                3.3217309
Policy mu Min                -2.4715068
Policy log std Mean          -0.92386
Policy log std Std           0.27783203
Policy log std Max           -0.33146214
Policy log std Min           -2.3192744
Z mean eval                  0.7879314
Z variance eval              0.010509499
total_rewards                [ 157.89260872 1064.89909486  945.24672367  374.06586645 2193.11608465
 2508.38467615 2547.92039935 1197.96430296 2501.97007321  174.48220826]
total_rewards_mean           1366.5942038284302
total_rewards_std            939.9801372864091
total_rewards_max            2547.9203993545434
total_rewards_min            157.8926087182019
Number of train steps total  344000
Number of env steps total    432000
Number of rollouts total     0
Train Time (s)               110.46045294078067
(Previous) Eval Time (s)     18.64540247898549
Sample Time (s)              18.041541615966707
Epoch Time (s)               147.14739703573287
Total Train Time (s)         13029.700128083583
Epoch                        85
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:08:44.470670 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #85 | Epoch Duration: 152.89242219924927
2020-01-12 03:08:44.470893 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #85 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.788237
Z variance train             0.010514726
KL Divergence                18.57229
KL Loss                      1.8572291
QF Loss                      526.6397
VF Loss                      125.3201
Policy Loss                  -802.1087
Q Predictions Mean           798.57477
Q Predictions Std            231.13457
Q Predictions Max            1054.4719
Q Predictions Min            -0.6831243
V Predictions Mean           805.9426
V Predictions Std            227.46104
V Predictions Max            1050.0336
V Predictions Min            12.285791
Log Pis Mean                 -0.9129788
Log Pis Std                  2.993282
Log Pis Max                  15.970585
Log Pis Min                  -8.1529045
Policy mu Mean               0.0118666105
Policy mu Std                0.56455815
Policy mu Max                3.4474132
Policy mu Min                -3.1003644
Policy log std Mean          -0.90730387
Policy log std Std           0.3160904
Policy log std Max           1.0676215
Policy log std Min           -2.7820225
Z mean eval                  0.791237
Z variance eval              0.014812986
total_rewards                [2321.05747849  445.56797267 2333.639805   1032.08750595 2586.54563828
 2528.38343627  517.57209195 2372.76182946 2013.21324879 2577.7408443 ]
total_rewards_mean           1872.8569851156662
total_rewards_std            818.5096996403289
total_rewards_max            2586.5456382751627
total_rewards_min            445.56797266646095
Number of train steps total  348000
Number of env steps total    437000
Number of rollouts total     0
Train Time (s)               112.1799123683013
(Previous) Eval Time (s)     24.390135009773076
Sample Time (s)              17.470345275010914
Epoch Time (s)               154.0403926530853
Total Train Time (s)         13182.301715109032
Epoch                        86
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:11:17.073919 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #86 | Epoch Duration: 152.6028597354889
2020-01-12 03:11:17.074120 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #86 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7907173
Z variance train             0.014832608
KL Divergence                18.514847
KL Loss                      1.8514847
QF Loss                      381.59906
VF Loss                      100.98511
Policy Loss                  -781.9343
Q Predictions Mean           780.464
Q Predictions Std            256.0048
Q Predictions Max            1037.7385
Q Predictions Min            24.181026
V Predictions Mean           780.18243
V Predictions Std            253.97404
V Predictions Max            1036.7668
V Predictions Min            99.895096
Log Pis Mean                 -0.65240526
Log Pis Std                  2.8090856
Log Pis Max                  9.821897
Log Pis Min                  -6.732116
Policy mu Mean               0.0464252
Policy mu Std                0.54292953
Policy mu Max                2.0256443
Policy mu Min                -1.7469971
Policy log std Mean          -0.92684686
Policy log std Std           0.2938924
Policy log std Max           -0.1609698
Policy log std Min           -2.2530289
Z mean eval                  0.79552925
Z variance eval              0.013231042
total_rewards                [ 698.51334588 1186.06194233  591.40565774  145.43072953 2594.49133172
 2629.29963033  683.52988855  235.30448429 2559.09035293 2650.05623634]
total_rewards_mean           1397.318359963211
total_rewards_std            1023.6949349832479
total_rewards_max            2650.0562363374343
total_rewards_min            145.43072953213144
Number of train steps total  352000
Number of env steps total    442000
Number of rollouts total     0
Train Time (s)               110.90539080975577
(Previous) Eval Time (s)     22.95231177099049
Sample Time (s)              17.58018639823422
Epoch Time (s)               151.43788897898048
Total Train Time (s)         13325.53548275726
Epoch                        87
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:13:40.309352 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #87 | Epoch Duration: 143.23507404327393
2020-01-12 03:13:40.309548 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7956387
Z variance train             0.013218108
KL Divergence                18.81876
KL Loss                      1.881876
QF Loss                      612.8347
VF Loss                      362.7414
Policy Loss                  -829.4431
Q Predictions Mean           825.22656
Q Predictions Std            218.47874
Q Predictions Max            1036.2844
Q Predictions Min            6.8278694
V Predictions Mean           828.92914
V Predictions Std            213.83545
V Predictions Max            1033.8186
V Predictions Min            153.30289
Log Pis Mean                 -0.68512416
Log Pis Std                  2.900121
Log Pis Max                  8.977381
Log Pis Min                  -7.9362717
Policy mu Mean               0.000736329
Policy mu Std                0.57535136
Policy mu Max                2.219193
Policy mu Min                -1.9218564
Policy log std Mean          -0.9434702
Policy log std Std           0.30282092
Policy log std Max           -0.18545914
Policy log std Min           -2.3725774
Z mean eval                  0.81153
Z variance eval              0.016910061
total_rewards                [ 547.81465542 1649.9737353   927.29051849  138.39545687 2521.34611034
 2367.11462387   44.21630911 1692.28180548 2503.46582017  396.76948438]
total_rewards_mean           1278.8668519425676
total_rewards_std            937.9492928937284
total_rewards_max            2521.346110344267
total_rewards_min            44.21630910575833
Number of train steps total  356000
Number of env steps total    447000
Number of rollouts total     0
Train Time (s)               117.03821742814034
(Previous) Eval Time (s)     14.749220338184386
Sample Time (s)              17.867537124548107
Epoch Time (s)               149.65497489087284
Total Train Time (s)         13478.229611892253
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:16:13.005542 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #88 | Epoch Duration: 152.69584012031555
2020-01-12 03:16:13.005747 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #88 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.80996716
Z variance train             0.016898246
KL Divergence                18.262478
KL Loss                      1.8262478
QF Loss                      492.0285
VF Loss                      292.19208
Policy Loss                  -803.0463
Q Predictions Mean           799.06055
Q Predictions Std            242.02605
Q Predictions Max            1028.13
Q Predictions Min            161.8969
V Predictions Mean           801.3586
V Predictions Std            239.09845
V Predictions Max            1020.5067
V Predictions Min            129.12358
Log Pis Mean                 -1.0045722
Log Pis Std                  2.9671423
Log Pis Max                  13.000673
Log Pis Min                  -8.961504
Policy mu Mean               0.029167645
Policy mu Std                0.5245797
Policy mu Max                1.9457431
Policy mu Min                -1.7739905
Policy log std Mean          -0.9163534
Policy log std Std           0.28742695
Policy log std Max           -0.2607689
Policy log std Min           -2.7057981
Z mean eval                  0.824815
Z variance eval              0.0114180315
total_rewards                [2719.74955722 2540.54503927  976.52215361 2651.4547998  1209.06927453
 2578.25533183 2460.0594017  1764.04018861  194.56867895 2111.76048065]
total_rewards_mean           1920.6024906167054
total_rewards_std            819.6611473587051
total_rewards_max            2719.749557218503
total_rewards_min            194.568678949635
Number of train steps total  360000
Number of env steps total    452000
Number of rollouts total     0
Train Time (s)               114.2128991400823
(Previous) Eval Time (s)     17.78978360025212
Sample Time (s)              17.80853425618261
Epoch Time (s)               149.81121699651703
Total Train Time (s)         13634.836691223085
Epoch                        89
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:18:49.613915 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #89 | Epoch Duration: 156.60801792144775
2020-01-12 03:18:49.614103 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #89 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8195384
Z variance train             0.011415224
KL Divergence                19.028748
KL Loss                      1.9028748
QF Loss                      2256.101
VF Loss                      877.76587
Policy Loss                  -824.5996
Q Predictions Mean           827.2854
Q Predictions Std            239.10469
Q Predictions Max            1045.0264
Q Predictions Min            14.106737
V Predictions Mean           835.3733
V Predictions Std            236.83446
V Predictions Max            1058.6654
V Predictions Min            45.371635
Log Pis Mean                 -0.4119366
Log Pis Std                  3.0731716
Log Pis Max                  11.941391
Log Pis Min                  -8.255994
Policy mu Mean               0.027215831
Policy mu Std                0.55564123
Policy mu Max                2.0811942
Policy mu Min                -2.009008
Policy log std Mean          -0.96405756
Policy log std Std           0.3119749
Policy log std Max           -0.28081447
Policy log std Min           -2.8631217
Z mean eval                  0.80152065
Z variance eval              0.014298213
total_rewards                [ 966.74316594  140.48414533 2572.54001496 1493.69791936 1510.34996757
 1445.45350856 2254.53962956  664.0761349  2605.19673999  336.57517414]
total_rewards_mean           1398.9656400331523
total_rewards_std            838.2807974065062
total_rewards_max            2605.196739987581
total_rewards_min            140.4841453336582
Number of train steps total  364000
Number of env steps total    457000
Number of rollouts total     0
Train Time (s)               113.92046088026837
(Previous) Eval Time (s)     24.586293485946953
Sample Time (s)              18.360268205869943
Epoch Time (s)               156.86702257208526
Total Train Time (s)         13785.027987427544
Epoch                        90
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:21:19.806649 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #90 | Epoch Duration: 150.19240164756775
2020-01-12 03:21:19.806815 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #90 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.80103284
Z variance train             0.0142798815
KL Divergence                18.37482
KL Loss                      1.8374821
QF Loss                      608.63904
VF Loss                      82.90415
Policy Loss                  -836.743
Q Predictions Mean           834.27014
Q Predictions Std            235.43896
Q Predictions Max            1058.014
Q Predictions Min            -35.356945
V Predictions Mean           833.2471
V Predictions Std            231.12593
V Predictions Max            1068.3123
V Predictions Min            7.1202593
Log Pis Mean                 -0.44850802
Log Pis Std                  2.7470143
Log Pis Max                  8.543642
Log Pis Min                  -8.769854
Policy mu Mean               0.04263351
Policy mu Std                0.56459934
Policy mu Max                2.4157896
Policy mu Min                -2.4286127
Policy log std Mean          -0.9253479
Policy log std Std           0.26707914
Policy log std Max           -0.24953657
Policy log std Min           -2.5299842
Z mean eval                  0.79024
Z variance eval              0.009972041
total_rewards                [2551.86418694 2575.16843115 2634.80923907  439.85672324   66.76963856
 2632.63474682  231.51205263 2632.18565806 2542.60184697  928.15988012]
total_rewards_mean           1723.5562403563115
total_rewards_std            1087.026392642685
total_rewards_max            2634.8092390650863
total_rewards_min            66.76963855609134
Number of train steps total  368000
Number of env steps total    462000
Number of rollouts total     0
Train Time (s)               119.01930686365813
(Previous) Eval Time (s)     17.911394854076207
Sample Time (s)              17.658991552889347
Epoch Time (s)               154.58969327062368
Total Train Time (s)         13942.128311416134
Epoch                        91
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:23:56.909176 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #91 | Epoch Duration: 157.10221648216248
2020-01-12 03:23:56.909390 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #91 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.79064924
Z variance train             0.009978044
KL Divergence                19.23541
KL Loss                      1.9235411
QF Loss                      586.05005
VF Loss                      305.74338
Policy Loss                  -851.75226
Q Predictions Mean           851.7244
Q Predictions Std            214.07358
Q Predictions Max            1086.8011
Q Predictions Min            161.09093
V Predictions Mean           853.578
V Predictions Std            210.94653
V Predictions Max            1077.6306
V Predictions Min            194.15404
Log Pis Mean                 -0.6490134
Log Pis Std                  2.8102171
Log Pis Max                  11.087912
Log Pis Min                  -11.287602
Policy mu Mean               0.0028992076
Policy mu Std                0.52678317
Policy mu Max                2.1332226
Policy mu Min                -2.020954
Policy log std Mean          -0.9628483
Policy log std Std           0.29261506
Policy log std Max           -0.29685223
Policy log std Min           -2.6371367
Z mean eval                  0.80582124
Z variance eval              0.0128952265
total_rewards                [1612.72502183  547.52460098 1095.80059231  601.53415708  541.79613857
  678.79612304 2558.50632184 2602.16983241  933.80057438  201.48866224]
total_rewards_mean           1137.414202467519
total_rewards_std            806.8647747287614
total_rewards_max            2602.169832411141
total_rewards_min            201.48866223548458
Number of train steps total  372000
Number of env steps total    467000
Number of rollouts total     0
Train Time (s)               118.61550773028284
(Previous) Eval Time (s)     20.423581927083433
Sample Time (s)              17.940312867052853
Epoch Time (s)               156.97940252441913
Total Train Time (s)         14094.626380348578
Epoch                        92
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:26:29.409832 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #92 | Epoch Duration: 152.5002725124359
2020-01-12 03:26:29.410060 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #92 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.80677116
Z variance train             0.012866971
KL Divergence                18.92936
KL Loss                      1.892936
QF Loss                      477.69455
VF Loss                      150.2275
Policy Loss                  -831.1004
Q Predictions Mean           828.0897
Q Predictions Std            249.65218
Q Predictions Max            1047.559
Q Predictions Min            20.69136
V Predictions Mean           839.6052
V Predictions Std            248.57452
V Predictions Max            1061.5449
V Predictions Min            8.220254
Log Pis Mean                 -0.7690434
Log Pis Std                  2.8698971
Log Pis Max                  15.471188
Log Pis Min                  -7.535132
Policy mu Mean               0.030265847
Policy mu Std                0.59239656
Policy mu Max                2.9373038
Policy mu Min                -2.4655628
Policy log std Mean          -0.89461094
Policy log std Std           0.2692258
Policy log std Max           -0.16502023
Policy log std Min           -2.033678
Z mean eval                  0.8092489
Z variance eval              0.00804936
total_rewards                [2649.88704276  -71.1512018   398.33807827 2513.46283493 1501.23602722
  401.84203215 2791.75820522  363.27799651 1503.67691811  661.91416225]
total_rewards_mean           1271.4242095621182
total_rewards_std            1018.7336900849836
total_rewards_max            2791.7582052249577
total_rewards_min            -71.15120180170102
Number of train steps total  376000
Number of env steps total    472000
Number of rollouts total     0
Train Time (s)               114.05557496007532
(Previous) Eval Time (s)     15.944137380924076
Sample Time (s)              17.515914582647383
Epoch Time (s)               147.51562692364678
Total Train Time (s)         14246.463322955184
Epoch                        93
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:29:01.249641 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #93 | Epoch Duration: 151.8393816947937
2020-01-12 03:29:01.249920 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8080341
Z variance train             0.00805442
KL Divergence                20.059977
KL Loss                      2.0059977
QF Loss                      712.7942
VF Loss                      140.1875
Policy Loss                  -853.8086
Q Predictions Mean           851.39526
Q Predictions Std            226.42511
Q Predictions Max            1057.9357
Q Predictions Min            165.00838
V Predictions Mean           855.8128
V Predictions Std            223.25537
V Predictions Max            1065.0653
V Predictions Min            172.96854
Log Pis Mean                 -0.6167908
Log Pis Std                  2.7321012
Log Pis Max                  11.577704
Log Pis Min                  -7.829889
Policy mu Mean               0.047721177
Policy mu Std                0.56421596
Policy mu Max                2.625365
Policy mu Min                -1.6798396
Policy log std Mean          -0.90252024
Policy log std Std           0.27894023
Policy log std Max           -0.20689058
Policy log std Min           -2.6062522
Z mean eval                  0.8227585
Z variance eval              0.0085462015
total_rewards                [  49.34730731  672.11763827 1102.31362045 2160.10578095 1062.38951995
 2556.15521766 1250.02540918 1658.67992909  479.21272477  147.28885282]
total_rewards_mean           1113.76360004573
total_rewards_std            784.7520928719699
total_rewards_max            2556.1552176631353
total_rewards_min            49.34730731067373
Number of train steps total  380000
Number of env steps total    477000
Number of rollouts total     0
Train Time (s)               112.26230557402596
(Previous) Eval Time (s)     20.267590424977243
Sample Time (s)              18.264121315442026
Epoch Time (s)               150.79401731444523
Total Train Time (s)         14392.209927720949
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:31:26.999438 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #94 | Epoch Duration: 145.7492892742157
2020-01-12 03:31:26.999754 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #94 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8229454
Z variance train             0.008522821
KL Divergence                19.70945
KL Loss                      1.970945
QF Loss                      792.73987
VF Loss                      260.12988
Policy Loss                  -852.4254
Q Predictions Mean           850.42346
Q Predictions Std            241.35046
Q Predictions Max            1113.4833
Q Predictions Min            30.241585
V Predictions Mean           854.7827
V Predictions Std            238.9219
V Predictions Max            1104.1589
V Predictions Min            4.0199842
Log Pis Mean                 -0.41286713
Log Pis Std                  3.0419943
Log Pis Max                  13.049365
Log Pis Min                  -7.9687886
Policy mu Mean               0.034688596
Policy mu Std                0.5623815
Policy mu Max                2.0297878
Policy mu Min                -2.3953984
Policy log std Mean          -0.9466791
Policy log std Std           0.2762101
Policy log std Max           -0.2371524
Policy log std Min           -2.5190494
Z mean eval                  0.82793295
Z variance eval              0.012146588
total_rewards                [1757.15886299  770.39000316  268.33409789  612.9649916   870.57051139
 2599.70231503  758.29439983 1946.54165282  504.82268415 2105.64062676]
total_rewards_mean           1219.4420145622853
total_rewards_std            763.3739164746291
total_rewards_max            2599.702315033223
total_rewards_min            268.33409789419846
Number of train steps total  384000
Number of env steps total    482000
Number of rollouts total     0
Train Time (s)               114.1577109801583
(Previous) Eval Time (s)     15.22253038501367
Sample Time (s)              19.1680969404988
Epoch Time (s)               148.54833830567077
Total Train Time (s)         14546.304732003715
Epoch                        95
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:34:01.097490 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #95 | Epoch Duration: 154.0974521636963
2020-01-12 03:34:01.097792 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #95 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8267422
Z variance train             0.0121289585
KL Divergence                19.097244
KL Loss                      1.9097245
QF Loss                      879.9569
VF Loss                      133.25555
Policy Loss                  -841.56854
Q Predictions Mean           836.2798
Q Predictions Std            258.27606
Q Predictions Max            1095.1791
Q Predictions Min            150.5603
V Predictions Mean           843.0692
V Predictions Std            253.50873
V Predictions Max            1087.6832
V Predictions Min            160.24821
Log Pis Mean                 -1.040196
Log Pis Std                  2.8157253
Log Pis Max                  10.654346
Log Pis Min                  -8.141762
Policy mu Mean               0.02212016
Policy mu Std                0.5292329
Policy mu Max                2.3710568
Policy mu Min                -1.8141686
Policy log std Mean          -0.9142798
Policy log std Std           0.27297333
Policy log std Max           -0.24099398
Policy log std Min           -2.3547654
Z mean eval                  0.8079092
Z variance eval              0.013155954
total_rewards                [ 713.16928056   36.95223554   20.62778431  727.34845176 1465.60843499
  597.16668429   81.92002948  404.07397345  977.66516686    4.55661491]
total_rewards_mean           502.9088656154845
total_rewards_std            462.6787910737815
total_rewards_max            1465.6084349932407
total_rewards_min            4.5566149074042315
Number of train steps total  388000
Number of env steps total    487000
Number of rollouts total     0
Train Time (s)               112.82869672495872
(Previous) Eval Time (s)     20.771324429195374
Sample Time (s)              18.110324068926275
Epoch Time (s)               151.71034522308037
Total Train Time (s)         14686.545853400137
Epoch                        96
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:36:21.337648 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #96 | Epoch Duration: 140.23965620994568
2020-01-12 03:36:21.337798 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8071553
Z variance train             0.013147009
KL Divergence                19.39908
KL Loss                      1.939908
QF Loss                      809.6752
VF Loss                      142.67973
Policy Loss                  -847.66705
Q Predictions Mean           845.1466
Q Predictions Std            241.16997
Q Predictions Max            1099.1707
Q Predictions Min            -5.707351
V Predictions Mean           842.0354
V Predictions Std            241.01053
V Predictions Max            1090.9353
V Predictions Min            -66.2163
Log Pis Mean                 -1.0636764
Log Pis Std                  2.810767
Log Pis Max                  8.559565
Log Pis Min                  -7.6476297
Policy mu Mean               0.04410313
Policy mu Std                0.55314445
Policy mu Max                2.420795
Policy mu Min                -2.2390223
Policy log std Mean          -0.87454015
Policy log std Std           0.26962712
Policy log std Max           -0.07192439
Policy log std Min           -1.9738814
Z mean eval                  0.84950984
Z variance eval              0.010775189
total_rewards                [2574.34364271 2316.76370669 2777.48974249 2650.99517422 2531.44532921
 1299.57913191 2597.67887525 2756.59202378 1279.40038758 2607.17492168]
total_rewards_mean           2339.1462935534055
total_rewards_std            538.4136925948441
total_rewards_max            2777.489742485912
total_rewards_min            1279.4003875811486
Number of train steps total  392000
Number of env steps total    492000
Number of rollouts total     0
Train Time (s)               111.81257125781849
(Previous) Eval Time (s)     9.30037130927667
Sample Time (s)              17.619420641567558
Epoch Time (s)               138.73236320866272
Total Train Time (s)         14839.460872884374
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:38:54.254431 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #97 | Epoch Duration: 152.91650986671448
2020-01-12 03:38:54.254626 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #97 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8483459
Z variance train             0.010789276
KL Divergence                20.09008
KL Loss                      2.0090082
QF Loss                      790.3066
VF Loss                      222.25868
Policy Loss                  -832.56995
Q Predictions Mean           828.87726
Q Predictions Std            267.13885
Q Predictions Max            1153.6282
Q Predictions Min            104.3263
V Predictions Mean           832.5401
V Predictions Std            265.54587
V Predictions Max            1147.8993
V Predictions Min            26.939741
Log Pis Mean                 -0.75765157
Log Pis Std                  2.948029
Log Pis Max                  8.988093
Log Pis Min                  -8.508986
Policy mu Mean               0.023467984
Policy mu Std                0.54863137
Policy mu Max                2.1762798
Policy mu Min                -1.9602863
Policy log std Mean          -0.90113044
Policy log std Std           0.30304632
Policy log std Max           -0.10143322
Policy log std Min           -2.4030712
Z mean eval                  0.8159688
Z variance eval              0.011832583
total_rewards                [ 356.41455789  136.75485458 2564.00479069 1804.45559189 2699.71051815
 1403.4278077  2742.81817128 1030.75743929 2515.24107747 1384.98539511]
total_rewards_mean           1663.8570204056814
total_rewards_std            915.4175587486617
total_rewards_max            2742.818171275124
total_rewards_min            136.75485458097543
Number of train steps total  396000
Number of env steps total    497000
Number of rollouts total     0
Train Time (s)               117.35004818812013
(Previous) Eval Time (s)     23.48419469129294
Sample Time (s)              18.452073723543435
Epoch Time (s)               159.2863166029565
Total Train Time (s)         14994.741481126752
Epoch                        98
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:41:29.540217 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #98 | Epoch Duration: 155.28544330596924
2020-01-12 03:41:29.540486 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #98 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8163425
Z variance train             0.0118478
KL Divergence                19.880743
KL Loss                      1.9880743
QF Loss                      519.94507
VF Loss                      151.32027
Policy Loss                  -824.3339
Q Predictions Mean           821.558
Q Predictions Std            271.0163
Q Predictions Max            1091.3201
Q Predictions Min            -17.136242
V Predictions Mean           831.2928
V Predictions Std            269.57727
V Predictions Max            1098.1598
V Predictions Min            -30.385363
Log Pis Mean                 -0.59715223
Log Pis Std                  2.9614532
Log Pis Max                  11.403715
Log Pis Min                  -8.016813
Policy mu Mean               0.008880264
Policy mu Std                0.5657371
Policy mu Max                2.3614366
Policy mu Min                -2.247865
Policy log std Mean          -0.9127246
Policy log std Std           0.2821846
Policy log std Max           -0.056357026
Policy log std Min           -2.0963547
Z mean eval                  0.83142316
Z variance eval              0.012384557
total_rewards                [ 426.14513899 2829.88726295 2832.34541391  236.26846421 2655.77720867
  630.73982      34.77898468 2735.1272012  2759.63015988 2736.02902358]
total_rewards_mean           1787.6728678054642
total_rewards_std            1197.691581033858
total_rewards_max            2832.3454139082555
total_rewards_min            34.778984678388724
Number of train steps total  400000
Number of env steps total    502000
Number of rollouts total     0
Train Time (s)               115.24325724784285
(Previous) Eval Time (s)     19.48300248803571
Sample Time (s)              18.810144084971398
Epoch Time (s)               153.53640382084996
Total Train Time (s)         15151.612457145005
Epoch                        99
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:44:06.412459 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #99 | Epoch Duration: 156.871755361557
2020-01-12 03:44:06.412728 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #99 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.83203477
Z variance train             0.012448104
KL Divergence                19.994568
KL Loss                      1.9994568
QF Loss                      948.40717
VF Loss                      153.13792
Policy Loss                  -838.6329
Q Predictions Mean           834.41644
Q Predictions Std            281.536
Q Predictions Max            1087.0494
Q Predictions Min            41.20027
V Predictions Mean           838.2661
V Predictions Std            279.23196
V Predictions Max            1093.5189
V Predictions Min            70.58015
Log Pis Mean                 -0.80477417
Log Pis Std                  2.9412017
Log Pis Max                  9.99214
Log Pis Min                  -8.716248
Policy mu Mean               0.006467145
Policy mu Std                0.54166824
Policy mu Max                2.0422838
Policy mu Min                -1.8436166
Policy log std Mean          -0.93535006
Policy log std Std           0.32436782
Policy log std Max           -0.07805532
Policy log std Min           -2.442204
Z mean eval                  0.83448696
Z variance eval              0.017154265
total_rewards                [1063.06435626 2631.47551814   35.36508462 1314.14039158 1754.95793429
  354.96391945 1683.13425801  376.66442436 2839.51056758 1109.70896509]
total_rewards_mean           1316.2985419381666
total_rewards_std            890.5916222329727
total_rewards_max            2839.5105675751506
total_rewards_min            35.36508461563946
Number of train steps total  404000
Number of env steps total    507000
Number of rollouts total     0
Train Time (s)               113.72339528379962
(Previous) Eval Time (s)     22.8180347266607
Sample Time (s)              17.58835028251633
Epoch Time (s)               154.12978029297665
Total Train Time (s)         15301.75855360739
Epoch                        100
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:46:36.561558 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #100 | Epoch Duration: 150.14859247207642
2020-01-12 03:46:36.561860 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #100 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.834672
Z variance train             0.017115485
KL Divergence                18.506058
KL Loss                      1.8506058
QF Loss                      1001.1332
VF Loss                      99.21303
Policy Loss                  -847.5648
Q Predictions Mean           844.91656
Q Predictions Std            270.91382
Q Predictions Max            1116.6202
Q Predictions Min            155.23854
V Predictions Mean           844.5737
V Predictions Std            270.50732
V Predictions Max            1106.9792
V Predictions Min            133.62894
Log Pis Mean                 -0.7940979
Log Pis Std                  2.558468
Log Pis Max                  8.27332
Log Pis Min                  -7.7605352
Policy mu Mean               0.00133422
Policy mu Std                0.5298631
Policy mu Max                1.7606375
Policy mu Min                -1.8886465
Policy log std Mean          -0.90111685
Policy log std Std           0.2919677
Policy log std Max           -0.26118213
Policy log std Min           -2.4116478
Z mean eval                  0.8305265
Z variance eval              0.011675799
total_rewards                [2406.20653291 2452.73987261  423.69831745  210.14800076 1697.1607827
 1932.72861876 2574.84774207 2612.6983685  2567.80704654 2777.78087308]
total_rewards_mean           1965.581615536577
total_rewards_std            881.8084960785015
total_rewards_max            2777.7808730813285
total_rewards_min            210.14800075695985
Number of train steps total  408000
Number of env steps total    512000
Number of rollouts total     0
Train Time (s)               119.77243940066546
(Previous) Eval Time (s)     18.836513072252274
Sample Time (s)              18.149964961223304
Epoch Time (s)               156.75891743414104
Total Train Time (s)         15461.174749532249
Epoch                        101
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:49:15.980073 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #101 | Epoch Duration: 159.417982339859
2020-01-12 03:49:15.980341 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #101 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8301425
Z variance train             0.011688544
KL Divergence                18.761324
KL Loss                      1.8761324
QF Loss                      1093.1724
VF Loss                      107.5255
Policy Loss                  -896.20215
Q Predictions Mean           891.7476
Q Predictions Std            238.94507
Q Predictions Max            1129.6312
Q Predictions Min            -5.4454784
V Predictions Mean           899.54736
V Predictions Std            225.3467
V Predictions Max            1114.9564
V Predictions Min            128.0361
Log Pis Mean                 -0.7606716
Log Pis Std                  3.0527592
Log Pis Max                  12.26779
Log Pis Min                  -8.165413
Policy mu Mean               0.0005006273
Policy mu Std                0.55743194
Policy mu Max                2.0306413
Policy mu Min                -2.2121913
Policy log std Mean          -0.96097326
Policy log std Std           0.31200626
Policy log std Max           -0.12109357
Policy log std Min           -2.9040976
Z mean eval                  0.82841617
Z variance eval              0.008900781
total_rewards                [2894.48997587 1471.34576586 2824.46116652 1567.10510269 2641.94449976
 1837.11427946 1480.84796056 2755.99302944   73.97413239 2370.13944033]
total_rewards_mean           1991.7415352878684
total_rewards_std            840.9689321461855
total_rewards_max            2894.489975870604
total_rewards_min            73.9741323922753
Number of train steps total  412000
Number of env steps total    517000
Number of rollouts total     0
Train Time (s)               109.0462117837742
(Previous) Eval Time (s)     21.495282877702266
Sample Time (s)              18.174365740269423
Epoch Time (s)               148.71586040174589
Total Train Time (s)         15609.562545715831
Epoch                        102
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:51:44.367964 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #102 | Epoch Duration: 148.38744711875916
2020-01-12 03:51:44.368111 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #102 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8276351
Z variance train             0.00892067
KL Divergence                19.56074
KL Loss                      1.956074
QF Loss                      493.351
VF Loss                      103.463264
Policy Loss                  -880.1959
Q Predictions Mean           876.49396
Q Predictions Std            255.55524
Q Predictions Max            1142.8901
Q Predictions Min            -27.002226
V Predictions Mean           877.9242
V Predictions Std            248.782
V Predictions Max            1148.3505
V Predictions Min            20.523203
Log Pis Mean                 -0.4336126
Log Pis Std                  3.0770066
Log Pis Max                  12.709287
Log Pis Min                  -7.7048078
Policy mu Mean               -0.0014276761
Policy mu Std                0.5515086
Policy mu Max                2.3899293
Policy mu Min                -3.313156
Policy log std Mean          -0.97208893
Policy log std Std           0.3045543
Policy log std Max           0.21936524
Policy log std Min           -2.3484898
Z mean eval                  0.8418498
Z variance eval              0.007510719
total_rewards                [ 843.99004124  444.9781384  2710.0936238  2459.27334715 1671.64858061
  181.55035638 2541.24936357  324.86086139 2719.41675834 1977.22170958]
total_rewards_mean           1587.4282780470883
total_rewards_std            989.9069557377632
total_rewards_max            2719.4167583429107
total_rewards_min            181.55035637938857
Number of train steps total  416000
Number of env steps total    522000
Number of rollouts total     0
Train Time (s)               115.67368329828605
(Previous) Eval Time (s)     21.166602965909988
Sample Time (s)              19.048863649368286
Epoch Time (s)               155.88914991356432
Total Train Time (s)         15762.40098414896
Epoch                        103
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:54:17.208638 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #103 | Epoch Duration: 152.84041237831116
2020-01-12 03:54:17.208832 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #103 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.84109735
Z variance train             0.0074884137
KL Divergence                20.217295
KL Loss                      2.0217295
QF Loss                      387.11975
VF Loss                      112.373344
Policy Loss                  -878.2074
Q Predictions Mean           874.547
Q Predictions Std            259.77966
Q Predictions Max            1106.4836
Q Predictions Min            -21.302181
V Predictions Mean           882.1339
V Predictions Std            258.92557
V Predictions Max            1121.0682
V Predictions Min            26.688848
Log Pis Mean                 -0.47272995
Log Pis Std                  2.774712
Log Pis Max                  11.876434
Log Pis Min                  -6.116886
Policy mu Mean               0.033020835
Policy mu Std                0.5576707
Policy mu Max                2.2345006
Policy mu Min                -2.4372416
Policy log std Mean          -0.9165366
Policy log std Std           0.28848293
Policy log std Max           -0.22511876
Policy log std Min           -2.433786
Z mean eval                  0.8476261
Z variance eval              0.011152847
total_rewards                [2738.75847406 2592.00494285  850.18902588 1055.82029523  716.62685351
  424.36409981 2452.10124627  928.25558916  862.38350513  135.44227082]
total_rewards_mean           1275.5946302740615
total_rewards_std            900.8660658812381
total_rewards_max            2738.7584740638376
total_rewards_min            135.44227082026214
Number of train steps total  420000
Number of env steps total    527000
Number of rollouts total     0
Train Time (s)               116.27897887118161
(Previous) Eval Time (s)     18.1175535377115
Sample Time (s)              17.66386914998293
Epoch Time (s)               152.06040155887604
Total Train Time (s)         15915.026388060767
Epoch                        104
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:56:49.835457 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #104 | Epoch Duration: 152.62650156021118
2020-01-12 03:56:49.835644 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.84573185
Z variance train             0.011148093
KL Divergence                19.593102
KL Loss                      1.9593102
QF Loss                      3497.8174
VF Loss                      97.33426
Policy Loss                  -870.76733
Q Predictions Mean           864.9214
Q Predictions Std            268.6953
Q Predictions Max            1129.4542
Q Predictions Min            1.3390331
V Predictions Mean           874.0518
V Predictions Std            265.51697
V Predictions Max            1127.147
V Predictions Min            42.67342
Log Pis Mean                 -0.46308592
Log Pis Std                  2.9771192
Log Pis Max                  12.8099575
Log Pis Min                  -10.916495
Policy mu Mean               0.011523518
Policy mu Std                0.57642853
Policy mu Max                3.7300918
Policy mu Min                -2.325932
Policy log std Mean          -0.94406456
Policy log std Std           0.29307425
Policy log std Max           -0.19883603
Policy log std Min           -2.3970063
Z mean eval                  0.8234312
Z variance eval              0.0086295055
total_rewards                [  78.6891053  1579.2621903  1140.367352    349.29359995  463.68600374
 2505.14599933 2147.40271459 2385.21316202 2827.16638706  911.54822905]
total_rewards_mean           1438.77747433165
total_rewards_std            940.05478244065
total_rewards_max            2827.1663870559605
total_rewards_min            78.6891052953531
Number of train steps total  424000
Number of env steps total    532000
Number of rollouts total     0
Train Time (s)               115.54890102241188
(Previous) Eval Time (s)     18.68334574997425
Sample Time (s)              17.553575380239636
Epoch Time (s)               151.78582215262577
Total Train Time (s)         16067.236241918523
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:59:22.046493 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #105 | Epoch Duration: 152.21069025993347
2020-01-12 03:59:22.046677 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #105 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.82342225
Z variance train             0.008635037
KL Divergence                20.61522
KL Loss                      2.061522
QF Loss                      391.4817
VF Loss                      66.0436
Policy Loss                  -867.6082
Q Predictions Mean           865.7982
Q Predictions Std            273.0976
Q Predictions Max            1151.0111
Q Predictions Min            13.855176
V Predictions Mean           867.46185
V Predictions Std            275.0248
V Predictions Max            1148.8939
V Predictions Min            21.44503
Log Pis Mean                 -0.94699126
Log Pis Std                  2.4264257
Log Pis Max                  7.03392
Log Pis Min                  -6.8409038
Policy mu Mean               0.058264945
Policy mu Std                0.5260299
Policy mu Max                2.0361438
Policy mu Min                -2.580465
Policy log std Mean          -0.90893537
Policy log std Std           0.2635279
Policy log std Max           -0.04129386
Policy log std Min           -2.2717392
Z mean eval                  0.8188394
Z variance eval              0.005518137
total_rewards                [2561.82642586 2809.87743922   49.3907955   763.26725887  608.75444009
 2776.95490782  760.02333359  685.79319385  140.42566343  457.01353974]
total_rewards_mean           1161.3326997973154
total_rewards_std            1044.7504422511554
total_rewards_max            2809.8774392238465
total_rewards_min            49.390795496818605
Number of train steps total  428000
Number of env steps total    537000
Number of rollouts total     0
Train Time (s)               115.26690315408632
(Previous) Eval Time (s)     19.107906227000058
Sample Time (s)              17.804121816065162
Epoch Time (s)               152.17893119715154
Total Train Time (s)         16214.317615364213
Epoch                        106
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:01:49.130011 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #106 | Epoch Duration: 147.08317708969116
2020-01-12 04:01:49.130231 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.81938964
Z variance train             0.0055331625
KL Divergence                20.684885
KL Loss                      2.0684886
QF Loss                      691.2087
VF Loss                      165.02177
Policy Loss                  -849.8234
Q Predictions Mean           844.02136
Q Predictions Std            291.8002
Q Predictions Max            1092.2872
Q Predictions Min            -57.68652
V Predictions Mean           850.52295
V Predictions Std            284.11957
V Predictions Max            1102.5964
V Predictions Min            -15.877102
Log Pis Mean                 -0.5117037
Log Pis Std                  3.169419
Log Pis Max                  15.26111
Log Pis Min                  -7.6249876
Policy mu Mean               0.02461595
Policy mu Std                0.59617794
Policy mu Max                3.4165356
Policy mu Min                -2.1094084
Policy log std Mean          -0.90853715
Policy log std Std           0.2963885
Policy log std Max           -0.1412949
Policy log std Min           -2.3965392
Z mean eval                  0.8353388
Z variance eval              0.008413181
total_rewards                [1477.19614282  451.21737889 2622.27853009  364.3838026   806.31217232
   82.36898654  476.4222085  1284.29850159 1969.27548842 2746.60084457]
total_rewards_mean           1228.0354056323515
total_rewards_std            909.3570870261352
total_rewards_max            2746.600844570813
total_rewards_min            82.3689865380468
Number of train steps total  432000
Number of env steps total    542000
Number of rollouts total     0
Train Time (s)               118.62838852079585
(Previous) Eval Time (s)     14.011865708976984
Sample Time (s)              18.467227751854807
Epoch Time (s)               151.10748198162764
Total Train Time (s)         16370.059199722484
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:04:24.874539 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #107 | Epoch Duration: 155.7440390586853
2020-01-12 04:04:24.874770 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #107 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.83456814
Z variance train             0.008415937
KL Divergence                20.52176
KL Loss                      2.0521762
QF Loss                      1233.5005
VF Loss                      229.13266
Policy Loss                  -883.73016
Q Predictions Mean           879.93774
Q Predictions Std            263.51553
Q Predictions Max            1134.1522
Q Predictions Min            31.119083
V Predictions Mean           883.9042
V Predictions Std            257.79214
V Predictions Max            1138.7203
V Predictions Min            66.06391
Log Pis Mean                 -0.7621428
Log Pis Std                  2.78986
Log Pis Max                  9.4712925
Log Pis Min                  -9.519709
Policy mu Mean               -0.013136563
Policy mu Std                0.56902385
Policy mu Max                2.5655622
Policy mu Min                -2.1183362
Policy log std Mean          -0.92653346
Policy log std Std           0.2770258
Policy log std Max           -0.23539788
Policy log std Min           -2.2266107
Z mean eval                  0.8381092
Z variance eval              0.0067341803
total_rewards                [1427.62931837 2208.96867395 2474.01206626 2778.20184792 2517.14202204
 2649.66246886 2867.73512359   41.31830965 2542.70536044 1579.62737423]
total_rewards_mean           2108.700256531249
total_rewards_std            826.652397154548
total_rewards_max            2867.735123586859
total_rewards_min            41.31830965255321
Number of train steps total  436000
Number of env steps total    547000
Number of rollouts total     0
Train Time (s)               118.29933698382229
(Previous) Eval Time (s)     18.64819802902639
Sample Time (s)              18.336247648112476
Epoch Time (s)               155.28378266096115
Total Train Time (s)         16528.572127592284
Epoch                        108
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:07:03.391831 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #108 | Epoch Duration: 158.51685190200806
2020-01-12 04:07:03.392116 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #108 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8367556
Z variance train             0.006730929
KL Divergence                21.343033
KL Loss                      2.1343033
QF Loss                      531.69025
VF Loss                      257.05545
Policy Loss                  -903.03394
Q Predictions Mean           902.7744
Q Predictions Std            247.98763
Q Predictions Max            1116.1682
Q Predictions Min            -15.909722
V Predictions Mean           910.2429
V Predictions Std            245.72546
V Predictions Max            1123.2418
V Predictions Min            6.141483
Log Pis Mean                 -0.5137764
Log Pis Std                  2.8457348
Log Pis Max                  14.164438
Log Pis Min                  -6.6841335
Policy mu Mean               0.027098674
Policy mu Std                0.55754966
Policy mu Max                3.7096403
Policy mu Min                -2.4353964
Policy log std Mean          -0.9626339
Policy log std Std           0.30217975
Policy log std Max           -0.13762546
Policy log std Min           -2.516524
Z mean eval                  0.863443
Z variance eval              0.00875139
total_rewards                [2714.99111262 2727.82019359  235.542132   2824.65202367 2775.61272804
  525.04891609 2169.5344704    77.185834    471.66522527 1067.74985397]
total_rewards_mean           1558.980248964101
total_rewards_std            1122.3734860219529
total_rewards_max            2824.6520236739834
total_rewards_min            77.18583399754183
Number of train steps total  440000
Number of env steps total    552000
Number of rollouts total     0
Train Time (s)               119.6690299748443
(Previous) Eval Time (s)     21.880939190275967
Sample Time (s)              18.2472352264449
Epoch Time (s)               159.79720439156517
Total Train Time (s)         16684.863109004218
Epoch                        109
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:09:39.682186 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #109 | Epoch Duration: 156.28987407684326
2020-01-12 04:09:39.682364 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #109 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8624495
Z variance train             0.008765553
KL Divergence                20.654575
KL Loss                      2.0654576
QF Loss                      941.2298
VF Loss                      430.7312
Policy Loss                  -894.32715
Q Predictions Mean           890.79535
Q Predictions Std            252.2666
Q Predictions Max            1143.1249
Q Predictions Min            -20.015335
V Predictions Mean           892.3495
V Predictions Std            248.13344
V Predictions Max            1141.5286
V Predictions Min            56.005066
Log Pis Mean                 -0.113120414
Log Pis Std                  3.0540078
Log Pis Max                  10.162683
Log Pis Min                  -10.947867
Policy mu Mean               -0.014998769
Policy mu Std                0.57303125
Policy mu Max                2.180914
Policy mu Min                -2.0683875
Policy log std Mean          -0.9697615
Policy log std Std           0.3036741
Policy log std Max           -0.16342121
Policy log std Min           -2.245563
Z mean eval                  0.8510679
Z variance eval              0.010050063
total_rewards                [2742.54951796  325.5376365   259.22712807 2950.47689087 2873.65855913
 1241.65029116  909.34736221 1673.6864842  2871.77069574  237.27492421]
total_rewards_mean           1608.5179490048727
total_rewards_std            1107.1530891037503
total_rewards_max            2950.4768908716096
total_rewards_min            237.27492421419356
Number of train steps total  444000
Number of env steps total    557000
Number of rollouts total     0
Train Time (s)               118.65889635588974
(Previous) Eval Time (s)     18.37331209005788
Sample Time (s)              18.871528130490333
Epoch Time (s)               155.90373657643795
Total Train Time (s)         16839.35474406928
Epoch                        110
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:12:14.179162 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #110 | Epoch Duration: 154.4966175556183
2020-01-12 04:12:14.179483 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8512068
Z variance train             0.010048452
KL Divergence                20.108677
KL Loss                      2.0108678
QF Loss                      376.62146
VF Loss                      110.81413
Policy Loss                  -909.27325
Q Predictions Mean           905.7886
Q Predictions Std            244.93015
Q Predictions Max            1134.3271
Q Predictions Min            136.39526
V Predictions Mean           906.9223
V Predictions Std            240.78177
V Predictions Max            1128.962
V Predictions Min            146.64116
Log Pis Mean                 -0.56010133
Log Pis Std                  2.7765903
Log Pis Max                  15.170422
Log Pis Min                  -7.515123
Policy mu Mean               -0.0013819092
Policy mu Std                0.56835
Policy mu Max                2.120207
Policy mu Min                -2.263631
Policy log std Mean          -0.9299816
Policy log std Std           0.27862984
Policy log std Max           -0.19623137
Policy log std Min           -2.0331047
Z mean eval                  0.8431144
Z variance eval              0.015297991
total_rewards                [2882.71707507  376.41451905 2751.32499266 2699.01748595 2981.76775717
  573.91530946 1028.21909123  278.46816266 1579.22965776 1044.87203248]
total_rewards_mean           1619.5946083495044
total_rewards_std            1049.5801022014907
total_rewards_max            2981.76775717081
total_rewards_min            278.4681626560088
Number of train steps total  448000
Number of env steps total    562000
Number of rollouts total     0
Train Time (s)               113.20142504107207
(Previous) Eval Time (s)     16.96584008168429
Sample Time (s)              18.13353847945109
Epoch Time (s)               148.30080360220745
Total Train Time (s)         16991.43276053574
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:14:46.259350 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #111 | Epoch Duration: 152.07955527305603
2020-01-12 04:14:46.259717 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #111 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8429801
Z variance train             0.015258774
KL Divergence                18.581099
KL Loss                      1.8581098
QF Loss                      622.10675
VF Loss                      309.51892
Policy Loss                  -870.47327
Q Predictions Mean           868.6383
Q Predictions Std            277.99765
Q Predictions Max            1168.5771
Q Predictions Min            30.997671
V Predictions Mean           871.3781
V Predictions Std            278.03256
V Predictions Max            1162.3502
V Predictions Min            -85.183716
Log Pis Mean                 -0.5984713
Log Pis Std                  3.137847
Log Pis Max                  22.392895
Log Pis Min                  -6.226341
Policy mu Mean               0.015989397
Policy mu Std                0.56869316
Policy mu Max                3.680772
Policy mu Min                -3.2606976
Policy log std Mean          -0.91148925
Policy log std Std           0.32492507
Policy log std Max           0.23192543
Policy log std Min           -2.882038
Z mean eval                  0.86151564
Z variance eval              0.012222072
total_rewards                [ 181.19019612 1244.71399375 1499.11517848 2718.16511082   94.52050356
 2805.3354327   298.99268    2802.91716599  612.11519927 2717.61084656]
total_rewards_mean           1497.4676307243617
total_rewards_std            1112.5867902747461
total_rewards_max            2805.3354326986996
total_rewards_min            94.52050355627722
Number of train steps total  452000
Number of env steps total    567000
Number of rollouts total     0
Train Time (s)               110.5908610089682
(Previous) Eval Time (s)     20.744294948875904
Sample Time (s)              17.782900543883443
Epoch Time (s)               149.11805650172755
Total Train Time (s)         17138.491366371978
Epoch                        112
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:17:13.318770 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #112 | Epoch Duration: 147.05875611305237
2020-01-12 04:17:13.318979 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #112 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8624503
Z variance train             0.012204401
KL Divergence                19.439383
KL Loss                      1.9439383
QF Loss                      572.7334
VF Loss                      83.47759
Policy Loss                  -930.7497
Q Predictions Mean           928.7346
Q Predictions Std            241.4892
Q Predictions Max            1179.499
Q Predictions Min            142.58138
V Predictions Mean           934.87006
V Predictions Std            241.59329
V Predictions Max            1171.4293
V Predictions Min            147.02802
Log Pis Mean                 -0.95828706
Log Pis Std                  2.6953616
Log Pis Max                  5.240572
Log Pis Min                  -8.583781
Policy mu Mean               0.072562456
Policy mu Std                0.5483103
Policy mu Max                2.0560992
Policy mu Min                -1.7087003
Policy log std Mean          -0.91935533
Policy log std Std           0.2601683
Policy log std Max           -0.2598439
Policy log std Min           -2.0913553
Z mean eval                  0.82939786
Z variance eval              0.012623687
total_rewards                [2209.16835951  927.50421197 1631.94275879 2977.41126981  309.18543643
  287.45718976 1116.54650667 2835.49606322 2927.34619789  207.30182928]
total_rewards_mean           1542.9359823320294
total_rewards_std            1074.2281225391464
total_rewards_max            2977.411269810864
total_rewards_min            207.30182927680153
Number of train steps total  456000
Number of env steps total    572000
Number of rollouts total     0
Train Time (s)               115.24652579892427
(Previous) Eval Time (s)     18.684709332883358
Sample Time (s)              17.563800108619034
Epoch Time (s)               151.49503524042666
Total Train Time (s)         17287.854961448815
Epoch                        113
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:19:42.685051 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #113 | Epoch Duration: 149.3659107685089
2020-01-12 04:19:42.685284 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #113 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.82851
Z variance train             0.012610318
KL Divergence                19.705383
KL Loss                      1.9705384
QF Loss                      1478.9216
VF Loss                      487.21255
Policy Loss                  -913.8191
Q Predictions Mean           908.05615
Q Predictions Std            244.6905
Q Predictions Max            1129.0316
Q Predictions Min            -28.054384
V Predictions Mean           911.98914
V Predictions Std            235.56415
V Predictions Max            1129.1465
V Predictions Min            3.3183727
Log Pis Mean                 -0.08745073
Log Pis Std                  3.1901581
Log Pis Max                  14.079147
Log Pis Min                  -8.515564
Policy mu Mean               -0.0039696135
Policy mu Std                0.6047773
Policy mu Max                2.8294857
Policy mu Min                -2.632288
Policy log std Mean          -0.95172083
Policy log std Std           0.3062711
Policy log std Max           -0.20645821
Policy log std Min           -2.670764
Z mean eval                  0.85518694
Z variance eval              0.011724097
total_rewards                [ 646.9464984  1042.41836552  871.3784338   407.97560979 2900.41052725
 1792.21661957  322.67715753 2898.40531021 2906.307124    561.71068087]
total_rewards_mean           1435.0446326929628
total_rewards_std            1035.8004070155312
total_rewards_max            2906.3071239962233
total_rewards_min            322.67715753302303
Number of train steps total  460000
Number of env steps total    577000
Number of rollouts total     0
Train Time (s)               113.47647227020934
(Previous) Eval Time (s)     16.55530970171094
Sample Time (s)              18.141047375276685
Epoch Time (s)               148.17282934719697
Total Train Time (s)         17435.067298148293
Epoch                        114
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:22:09.898807 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #114 | Epoch Duration: 147.2133276462555
2020-01-12 04:22:09.899016 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #114 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8551549
Z variance train             0.01173431
KL Divergence                20.545399
KL Loss                      2.05454
QF Loss                      713.4799
VF Loss                      124.18698
Policy Loss                  -894.303
Q Predictions Mean           893.73315
Q Predictions Std            286.0584
Q Predictions Max            1147.9662
Q Predictions Min            -31.960484
V Predictions Mean           888.52545
V Predictions Std            282.89166
V Predictions Max            1129.9089
V Predictions Min            -13.807789
Log Pis Mean                 -0.6160504
Log Pis Std                  2.843236
Log Pis Max                  11.476404
Log Pis Min                  -8.426008
Policy mu Mean               0.00850486
Policy mu Std                0.55455375
Policy mu Max                2.5564485
Policy mu Min                -2.2287533
Policy log std Mean          -0.9158591
Policy log std Std           0.29993996
Policy log std Max           -0.18676686
Policy log std Min           -2.9803405
Z mean eval                  0.8313831
Z variance eval              0.015919467
total_rewards                [ 759.20764458  425.78863973 1176.81884179 2977.1064086  2893.53359472
  590.42156985  662.60436997  353.84903927  272.33669574 2889.07535216]
total_rewards_mean           1300.074215640315
total_rewards_std            1086.7446507812053
total_rewards_max            2977.1064086030765
total_rewards_min            272.33669574339024
Number of train steps total  464000
Number of env steps total    582000
Number of rollouts total     0
Train Time (s)               118.17559561179951
(Previous) Eval Time (s)     15.59551440179348
Sample Time (s)              17.541284527163953
Epoch Time (s)               151.31239454075694
Total Train Time (s)         17587.277529865503
Epoch                        115
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:24:42.112049 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #115 | Epoch Duration: 152.21284413337708
2020-01-12 04:24:42.112333 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.83185387
Z variance train             0.015939308
KL Divergence                19.194569
KL Loss                      1.9194568
QF Loss                      458.48267
VF Loss                      101.19168
Policy Loss                  -905.1001
Q Predictions Mean           900.85065
Q Predictions Std            264.8798
Q Predictions Max            1193.4941
Q Predictions Min            13.31812
V Predictions Mean           902.8612
V Predictions Std            258.96222
V Predictions Max            1181.7831
V Predictions Min            22.155144
Log Pis Mean                 -0.56661415
Log Pis Std                  3.0086904
Log Pis Max                  16.159718
Log Pis Min                  -8.232986
Policy mu Mean               0.007169826
Policy mu Std                0.5581923
Policy mu Max                2.701519
Policy mu Min                -2.1881309
Policy log std Mean          -0.9527006
Policy log std Std           0.29777965
Policy log std Max           -0.2254237
Policy log std Min           -2.7233958
Z mean eval                  0.85563326
Z variance eval              0.014140035
total_rewards                [2981.41114725  677.78169602 2973.54544327   93.91111505 1600.33714382
 2830.54320871  689.96960681  101.23120953  794.34018428 1251.09171994]
total_rewards_mean           1399.4162474682637
total_rewards_std            1089.5366164914235
total_rewards_max            2981.411147245296
total_rewards_min            93.91111505183343
Number of train steps total  468000
Number of env steps total    587000
Number of rollouts total     0
Train Time (s)               122.70333630219102
(Previous) Eval Time (s)     16.495623323135078
Sample Time (s)              17.863556138705462
Epoch Time (s)               157.06251576403156
Total Train Time (s)         17741.685542764142
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:27:16.521385 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #116 | Epoch Duration: 154.40887999534607
2020-01-12 04:27:16.521583 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #116 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.85543555
Z variance train             0.014148302
KL Divergence                19.524967
KL Loss                      1.9524968
QF Loss                      404.3845
VF Loss                      68.71912
Policy Loss                  -908.1884
Q Predictions Mean           906.4376
Q Predictions Std            272.4613
Q Predictions Max            1138.1838
Q Predictions Min            138.52943
V Predictions Mean           907.8156
V Predictions Std            270.39273
V Predictions Max            1133.8962
V Predictions Min            140.15665
Log Pis Mean                 -0.5995095
Log Pis Std                  2.947325
Log Pis Max                  8.67635
Log Pis Min                  -10.327879
Policy mu Mean               0.033395074
Policy mu Std                0.5716686
Policy mu Max                2.54067
Policy mu Min                -2.0990207
Policy log std Mean          -0.92900735
Policy log std Std           0.28195855
Policy log std Max           -0.07052857
Policy log std Min           -2.0059762
Z mean eval                  0.8225616
Z variance eval              0.011936136
total_rewards                [  99.77999329 1606.84081318 2637.09781613 2952.70944454  245.90805513
 2920.50598027 2827.35602293 2954.80650645 1110.96412963 1224.81627952]
total_rewards_mean           1858.0785041075155
total_rewards_std            1085.7798978917647
total_rewards_max            2954.8065064524562
total_rewards_min            99.77999328901528
Number of train steps total  472000
Number of env steps total    592000
Number of rollouts total     0
Train Time (s)               110.66066530533135
(Previous) Eval Time (s)     13.841674427036196
Sample Time (s)              17.90030520968139
Epoch Time (s)               142.40264494204894
Total Train Time (s)         17894.204197940417
Epoch                        117
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:29:49.041555 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #117 | Epoch Duration: 152.51981139183044
2020-01-12 04:29:49.041754 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #117 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8212224
Z variance train             0.01190452
KL Divergence                20.178715
KL Loss                      2.0178716
QF Loss                      716.51465
VF Loss                      95.87
Policy Loss                  -889.60364
Q Predictions Mean           888.526
Q Predictions Std            296.36783
Q Predictions Max            1167.3339
Q Predictions Min            -55.359665
V Predictions Mean           888.0163
V Predictions Std            296.42075
V Predictions Max            1152.5055
V Predictions Min            -51.652596
Log Pis Mean                 -0.46640196
Log Pis Std                  3.0362988
Log Pis Max                  11.366955
Log Pis Min                  -7.486063
Policy mu Mean               0.008408801
Policy mu Std                0.5745499
Policy mu Max                2.0162604
Policy mu Min                -2.1675003
Policy log std Mean          -0.93201256
Policy log std Std           0.31195194
Policy log std Max           -0.22212374
Policy log std Min           -2.8972845
Z mean eval                  0.8468777
Z variance eval              0.008270813
total_rewards                [2737.97784717 1993.38398764  414.85959196  543.42703478  660.89901456
 1959.45545721 2926.21755762  346.8633322  2288.42354704  217.02372016]
total_rewards_mean           1408.8531090340941
total_rewards_std            1016.4718981019449
total_rewards_max            2926.2175576214886
total_rewards_min            217.023720164809
Number of train steps total  476000
Number of env steps total    597000
Number of rollouts total     0
Train Time (s)               115.49225483415648
(Previous) Eval Time (s)     23.95852610003203
Sample Time (s)              17.27656257757917
Epoch Time (s)               156.72734351176769
Total Train Time (s)         18048.927361601964
Epoch                        118
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:32:23.771197 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #118 | Epoch Duration: 154.729172706604
2020-01-12 04:32:23.771610 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #118 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8469094
Z variance train             0.008250476
KL Divergence                20.057297
KL Loss                      2.0057297
QF Loss                      722.90857
VF Loss                      208.18631
Policy Loss                  -907.3037
Q Predictions Mean           903.35345
Q Predictions Std            275.7354
Q Predictions Max            1176.8226
Q Predictions Min            79.53109
V Predictions Mean           909.0138
V Predictions Std            272.2375
V Predictions Max            1191.1057
V Predictions Min            109.35851
Log Pis Mean                 -0.18213175
Log Pis Std                  3.2062685
Log Pis Max                  13.853823
Log Pis Min                  -6.8189936
Policy mu Mean               0.04752133
Policy mu Std                0.57361996
Policy mu Max                1.9907477
Policy mu Min                -1.9611104
Policy log std Mean          -0.95667845
Policy log std Std           0.31897384
Policy log std Max           -0.30599618
Policy log std Min           -2.6732357
Z mean eval                  0.8491818
Z variance eval              0.0086980825
total_rewards                [ 427.49197142 1276.06517819 2991.55313566  -52.88977053  830.85276329
 1619.78923376 1531.25052353 1349.63257406 1123.12553403 2592.21742047]
total_rewards_mean           1368.9088563885239
total_rewards_std            865.1841706816342
total_rewards_max            2991.55313566249
total_rewards_min            -52.88977052574881
Number of train steps total  480000
Number of env steps total    602000
Number of rollouts total     0
Train Time (s)               120.084453266114
(Previous) Eval Time (s)     21.960002116393298
Sample Time (s)              18.44022954115644
Epoch Time (s)               160.48468492366374
Total Train Time (s)         18205.021826094016
Epoch                        119
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:34:59.863949 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #119 | Epoch Duration: 156.0920832157135
2020-01-12 04:34:59.864129 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #119 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8486314
Z variance train             0.008703637
KL Divergence                20.469715
KL Loss                      2.0469716
QF Loss                      2195.718
VF Loss                      393.67477
Policy Loss                  -917.62195
Q Predictions Mean           915.9963
Q Predictions Std            278.56244
Q Predictions Max            1170.9854
Q Predictions Min            -19.575768
V Predictions Mean           911.59973
V Predictions Std            272.56845
V Predictions Max            1154.6969
V Predictions Min            -24.776112
Log Pis Mean                 0.18638816
Log Pis Std                  3.461371
Log Pis Max                  14.815599
Log Pis Min                  -9.280917
Policy mu Mean               0.048665002
Policy mu Std                0.6045631
Policy mu Max                2.0693543
Policy mu Min                -1.9610391
Policy log std Mean          -0.98035705
Policy log std Std           0.3597217
Policy log std Max           -0.20639998
Policy log std Min           -3.103313
Z mean eval                  0.8675744
Z variance eval              0.00966168
total_rewards                [ -12.98675704  892.38435911  360.16195417  240.98435439   49.22600336
 1348.13278682 1711.53917206  991.0100473   101.89079105   33.62674524]
total_rewards_mean           571.5969456467544
total_rewards_std            588.212789963968
total_rewards_max            1711.5391720631842
total_rewards_min            -12.986757038191186
Number of train steps total  484000
Number of env steps total    607000
Number of rollouts total     0
Train Time (s)               115.44739080732688
(Previous) Eval Time (s)     17.567133360076696
Sample Time (s)              18.609164320398122
Epoch Time (s)               151.6236884878017
Total Train Time (s)         18350.42428772617
Epoch                        120
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:37:25.269131 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #120 | Epoch Duration: 145.40487337112427
2020-01-12 04:37:25.269340 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #120 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8685373
Z variance train             0.009659277
KL Divergence                20.357296
KL Loss                      2.0357296
QF Loss                      907.94775
VF Loss                      189.74803
Policy Loss                  -906.8428
Q Predictions Mean           903.44653
Q Predictions Std            293.01285
Q Predictions Max            1171.9371
Q Predictions Min            29.480772
V Predictions Mean           913.59094
V Predictions Std            291.47504
V Predictions Max            1168.3445
V Predictions Min            29.341314
Log Pis Mean                 -0.58883053
Log Pis Std                  2.752496
Log Pis Max                  11.610193
Log Pis Min                  -8.048075
Policy mu Mean               0.018804772
Policy mu Std                0.5754746
Policy mu Max                3.6163557
Policy mu Min                -2.0598383
Policy log std Mean          -0.9290545
Policy log std Std           0.2992283
Policy log std Max           -0.17979795
Policy log std Min           -2.6273394
Z mean eval                  0.84425366
Z variance eval              0.009824114
total_rewards                [1013.1245071   846.61542216   63.92786196 1684.66705621 1201.69440779
  221.49120065 2934.26161499  258.43991177 2096.50321296 3104.40461124]
total_rewards_mean           1342.512980686525
total_rewards_std            1037.5173104974633
total_rewards_max            3104.4046112444407
total_rewards_min            63.92786196298694
Number of train steps total  488000
Number of env steps total    612000
Number of rollouts total     0
Train Time (s)               113.36863176571205
(Previous) Eval Time (s)     11.3479611761868
Sample Time (s)              17.679648767691106
Epoch Time (s)               142.39624170958996
Total Train Time (s)         18497.163142261095
Epoch                        121
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:39:52.009238 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #121 | Epoch Duration: 146.73974585533142
2020-01-12 04:39:52.009410 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8447356
Z variance train             0.009803374
KL Divergence                20.55567
KL Loss                      2.055567
QF Loss                      519.65906
VF Loss                      417.75238
Policy Loss                  -930.8822
Q Predictions Mean           925.275
Q Predictions Std            278.80493
Q Predictions Max            1180.2484
Q Predictions Min            -37.00958
V Predictions Mean           933.121
V Predictions Std            266.57516
V Predictions Max            1175.5736
V Predictions Min            -20.16518
Log Pis Mean                 -0.43709716
Log Pis Std                  3.1363785
Log Pis Max                  13.610741
Log Pis Min                  -7.2731752
Policy mu Mean               -0.018160846
Policy mu Std                0.55317324
Policy mu Max                1.9918554
Policy mu Min                -2.7076077
Policy log std Mean          -0.9673948
Policy log std Std           0.3214907
Policy log std Max           -0.2072407
Policy log std Min           -2.6062512
Z mean eval                  0.8389932
Z variance eval              0.008248121
total_rewards                [2903.87336355 2975.04816466 1217.67842716 1767.17347201  266.55015499
 2278.35176268 3028.05785987  933.2514001   765.21266664 2410.00243576]
total_rewards_mean           1854.519970742595
total_rewards_std            958.7639016273337
total_rewards_max            3028.057859869779
total_rewards_min            266.55015498532885
Number of train steps total  492000
Number of env steps total    617000
Number of rollouts total     0
Train Time (s)               112.12253964971751
(Previous) Eval Time (s)     15.69118230137974
Sample Time (s)              17.797535014804453
Epoch Time (s)               145.6112569659017
Total Train Time (s)         18650.676206475124
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:42:25.526916 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #122 | Epoch Duration: 153.51733136177063
2020-01-12 04:42:25.527219 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #122 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.83822024
Z variance train             0.008255715
KL Divergence                20.734482
KL Loss                      2.0734482
QF Loss                      564.71094
VF Loss                      131.48561
Policy Loss                  -938.207
Q Predictions Mean           934.60223
Q Predictions Std            270.3635
Q Predictions Max            1203.1205
Q Predictions Min            98.62527
V Predictions Mean           935.4142
V Predictions Std            269.40945
V Predictions Max            1203.869
V Predictions Min            88.2188
Log Pis Mean                 -0.5617147
Log Pis Std                  2.9066963
Log Pis Max                  13.695946
Log Pis Min                  -9.129967
Policy mu Mean               0.051219814
Policy mu Std                0.56211805
Policy mu Max                2.1120389
Policy mu Min                -1.7012312
Policy log std Mean          -0.9515656
Policy log std Std           0.27192554
Policy log std Max           -0.050392985
Policy log std Min           -2.3583982
Z mean eval                  0.8523222
Z variance eval              0.01230982
total_rewards                [2981.93257829 2433.66737804 2867.50399686 2936.52391675 2886.65384792
 2865.77891453 3072.72841925 2938.64018378 3095.81683341 3068.46525914]
total_rewards_mean           2914.7711327971333
total_rewards_std            179.9414720498916
total_rewards_max            3095.8168334050874
total_rewards_min            2433.6673780371602
Number of train steps total  496000
Number of env steps total    622000
Number of rollouts total     0
Train Time (s)               113.75888583436608
(Previous) Eval Time (s)     23.59694756520912
Sample Time (s)              18.34425415797159
Epoch Time (s)               155.7000875575468
Total Train Time (s)         18809.139866761863
Epoch                        123
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:45:03.994203 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #123 | Epoch Duration: 158.46665859222412
2020-01-12 04:45:03.994613 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #123 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.85163766
Z variance train             0.012298146
KL Divergence                20.661552
KL Loss                      2.0661552
QF Loss                      1375.156
VF Loss                      143.12427
Policy Loss                  -936.70715
Q Predictions Mean           934.48566
Q Predictions Std            281.1761
Q Predictions Max            1173.9663
Q Predictions Min            70.46634
V Predictions Mean           941.1846
V Predictions Std            276.56937
V Predictions Max            1176.8828
V Predictions Min            108.18212
Log Pis Mean                 -0.5226118
Log Pis Std                  3.0092664
Log Pis Max                  13.457006
Log Pis Min                  -8.659679
Policy mu Mean               0.036343575
Policy mu Std                0.5717898
Policy mu Max                2.32541
Policy mu Min                -1.9324875
Policy log std Mean          -0.9544844
Policy log std Std           0.2932583
Policy log std Max           -0.05727327
Policy log std Min           -2.5348654
Z mean eval                  0.853096
Z variance eval              0.010397808
total_rewards                [3098.0254824  2978.66847585  262.81315702 2654.66728836 1536.39928062
 1711.79180272 2740.7106993  1860.71915868  375.50280803  449.02102943]
total_rewards_mean           1766.831918241181
total_rewards_std            1047.7000413607896
total_rewards_max            3098.0254823973255
total_rewards_min            262.81315701720075
Number of train steps total  500000
Number of env steps total    627000
Number of rollouts total     0
Train Time (s)               111.21996021689847
(Previous) Eval Time (s)     26.36319702817127
Sample Time (s)              18.256699902471155
Epoch Time (s)               155.8398571475409
Total Train Time (s)         18955.150021267124
Epoch                        124
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:47:30.003895 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #124 | Epoch Duration: 146.00904941558838
2020-01-12 04:47:30.004071 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8530814
Z variance train             0.010402777
KL Divergence                19.91082
KL Loss                      1.9910821
QF Loss                      562.4264
VF Loss                      146.34009
Policy Loss                  -959.7972
Q Predictions Mean           956.1482
Q Predictions Std            274.4084
Q Predictions Max            1227.8373
Q Predictions Min            -2.216117
V Predictions Mean           954.96655
V Predictions Std            267.36954
V Predictions Max            1227.5173
V Predictions Min            -1.4159391
Log Pis Mean                 -0.20504221
Log Pis Std                  3.1981747
Log Pis Max                  13.925934
Log Pis Min                  -7.6942496
Policy mu Mean               -0.00048726774
Policy mu Std                0.5937774
Policy mu Max                2.1136854
Policy mu Min                -2.072672
Policy log std Mean          -0.97036266
Policy log std Std           0.33678007
Policy log std Max           -0.25650358
Policy log std Min           -3.2067652
Z mean eval                  0.8603307
Z variance eval              0.0168189
total_rewards                [2975.44006203  659.31074061 2945.11458346 3035.09623231 3060.58873797
 1571.35231011 1149.12349507 3008.11307239 2087.86997056 2260.62084713]
total_rewards_mean           2275.2630051640963
total_rewards_std            841.4519614925184
total_rewards_max            3060.588737970026
total_rewards_min            659.3107406052953
Number of train steps total  504000
Number of env steps total    632000
Number of rollouts total     0
Train Time (s)               121.1440346208401
(Previous) Eval Time (s)     16.532078258227557
Sample Time (s)              18.475083503872156
Epoch Time (s)               156.15119638293982
Total Train Time (s)         19115.18569027027
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:50:10.045525 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #125 | Epoch Duration: 160.0411880016327
2020-01-12 04:50:10.045953 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #125 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8575181
Z variance train             0.016790269
KL Divergence                18.375755
KL Loss                      1.8375756
QF Loss                      2963.1807
VF Loss                      1138.5143
Policy Loss                  -940.64154
Q Predictions Mean           937.022
Q Predictions Std            281.4594
Q Predictions Max            1227.3125
Q Predictions Min            61.361687
V Predictions Mean           941.82275
V Predictions Std            274.4615
V Predictions Max            1224.0641
V Predictions Min            125.10191
Log Pis Mean                 -0.4310804
Log Pis Std                  3.368156
Log Pis Max                  23.623913
Log Pis Min                  -9.940931
Policy mu Mean               -0.050717056
Policy mu Std                0.5846936
Policy mu Max                2.295682
Policy mu Min                -4.503072
Policy log std Mean          -0.96966445
Policy log std Std           0.30618668
Policy log std Max           -0.0605703
Policy log std Min           -3.1586504
Z mean eval                  0.86768377
Z variance eval              0.010929256
total_rewards                [ 134.25730179 2242.80254521 3027.3076556  2993.23603645 3126.49195291
 1995.35895545 3056.88925552 2048.22160462 2393.62177635  619.52900866]
total_rewards_mean           2163.7716092580076
total_rewards_std            988.0587268407643
total_rewards_max            3126.4919529073622
total_rewards_min            134.25730179363526
Number of train steps total  508000
Number of env steps total    637000
Number of rollouts total     0
Train Time (s)               115.8891234099865
(Previous) Eval Time (s)     20.421674150042236
Sample Time (s)              18.10605674330145
Epoch Time (s)               154.41685430333018
Total Train Time (s)         19272.02989211958
Epoch                        126
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:52:46.890723 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #126 | Epoch Duration: 156.8445041179657
2020-01-12 04:52:46.890947 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #126 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8672439
Z variance train             0.010919905
KL Divergence                20.232336
KL Loss                      2.0232337
QF Loss                      736.9311
VF Loss                      215.48569
Policy Loss                  -975.67426
Q Predictions Mean           973.7552
Q Predictions Std            253.43391
Q Predictions Max            1220.1918
Q Predictions Min            -12.201897
V Predictions Mean           979.9893
V Predictions Std            249.47769
V Predictions Max            1230.0928
V Predictions Min            126.74938
Log Pis Mean                 -0.60123634
Log Pis Std                  2.7430174
Log Pis Max                  10.44525
Log Pis Min                  -7.6224117
Policy mu Mean               0.044121034
Policy mu Std                0.5864747
Policy mu Max                2.0515501
Policy mu Min                -2.3120859
Policy log std Mean          -0.9418949
Policy log std Std           0.258346
Policy log std Max           -0.24775952
Policy log std Min           -2.143612
Z mean eval                  0.851339
Z variance eval              0.011858692
total_rewards                [ 449.02771603  389.10048884  939.02235656 2938.28776772 1561.71169168
 3033.98789681  575.12349167  975.53148903 1978.92355961 2911.73174494]
total_rewards_mean           1575.24482028981
total_rewards_std            1018.5840920455404
total_rewards_max            3033.987896811889
total_rewards_min            389.1004888433582
Number of train steps total  512000
Number of env steps total    642000
Number of rollouts total     0
Train Time (s)               113.86466460488737
(Previous) Eval Time (s)     22.849047337193042
Sample Time (s)              18.31128594186157
Epoch Time (s)               155.02499788394198
Total Train Time (s)         19421.140419650823
Epoch                        127
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:55:16.004435 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #127 | Epoch Duration: 149.11329436302185
2020-01-12 04:55:16.004733 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #127 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.85203964
Z variance train             0.011864792
KL Divergence                19.911045
KL Loss                      1.9911045
QF Loss                      847.2914
VF Loss                      234.41754
Policy Loss                  -959.98254
Q Predictions Mean           956.8407
Q Predictions Std            273.49658
Q Predictions Max            1202.1742
Q Predictions Min            10.285741
V Predictions Mean           968.0998
V Predictions Std            274.24902
V Predictions Max            1210.0774
V Predictions Min            3.845437
Log Pis Mean                 -0.26853234
Log Pis Std                  3.122778
Log Pis Max                  12.920173
Log Pis Min                  -6.8903604
Policy mu Mean               0.02183666
Policy mu Std                0.6052346
Policy mu Max                2.6013286
Policy mu Min                -2.1059666
Policy log std Mean          -0.9548638
Policy log std Std           0.29782578
Policy log std Max           -0.25282198
Policy log std Min           -2.511152
Z mean eval                  0.85552007
Z variance eval              0.009480553
total_rewards                [2772.12876514 2870.48218689 1034.63475465  712.94870027 2486.33819083
 3016.73341271  245.67253162 3089.01095047 1020.1940173   984.20685132]
total_rewards_mean           1823.235036118951
total_rewards_std            1056.202230526399
total_rewards_max            3089.0109504651823
total_rewards_min            245.6725316187096
Number of train steps total  516000
Number of env steps total    647000
Number of rollouts total     0
Train Time (s)               119.024740266148
(Previous) Eval Time (s)     16.93699061172083
Sample Time (s)              17.552813824266195
Epoch Time (s)               153.51454470213503
Total Train Time (s)         19578.412742052693
Epoch                        128
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:57:53.279023 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #128 | Epoch Duration: 157.27408123016357
2020-01-12 04:57:53.279249 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #128 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.85582626
Z variance train             0.009467573
KL Divergence                20.023418
KL Loss                      2.002342
QF Loss                      944.2687
VF Loss                      397.45792
Policy Loss                  -934.4183
Q Predictions Mean           931.0275
Q Predictions Std            303.31787
Q Predictions Max            1218.1193
Q Predictions Min            -15.016739
V Predictions Mean           935.11255
V Predictions Std            297.0553
V Predictions Max            1222.3567
V Predictions Min            -20.264503
Log Pis Mean                 -0.14720847
Log Pis Std                  2.9976397
Log Pis Max                  11.829485
Log Pis Min                  -6.306387
Policy mu Mean               0.04496737
Policy mu Std                0.5711835
Policy mu Max                2.1993854
Policy mu Min                -2.0364008
Policy log std Mean          -0.98164445
Policy log std Std           0.33024332
Policy log std Max           -0.21957904
Policy log std Min           -2.4771664
Z mean eval                  0.86862755
Z variance eval              0.009518698
total_rewards                [ 128.20466228 3041.47646726 2395.43913823 2194.33304785 3123.61938862
  257.12942235  237.8622082   569.5384     1841.69643039 2784.63011334]
total_rewards_mean           1657.3929278529158
total_rewards_std            1170.5043873063441
total_rewards_max            3123.619388623594
total_rewards_min            128.20466227550747
Number of train steps total  520000
Number of env steps total    652000
Number of rollouts total     0
Train Time (s)               108.50329960510135
(Previous) Eval Time (s)     20.696224560961127
Sample Time (s)              18.46124357590452
Epoch Time (s)               147.660767741967
Total Train Time (s)         19723.0913321916
Epoch                        129
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:00:17.957821 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #129 | Epoch Duration: 144.6784200668335
2020-01-12 05:00:17.957965 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.86860913
Z variance train             0.009520146
KL Divergence                19.988178
KL Loss                      1.9988178
QF Loss                      565.92615
VF Loss                      485.36057
Policy Loss                  -969.6744
Q Predictions Mean           967.723
Q Predictions Std            256.04742
Q Predictions Max            1231.0906
Q Predictions Min            -53.14163
V Predictions Mean           965.5867
V Predictions Std            252.19666
V Predictions Max            1227.368
V Predictions Min            65.02131
Log Pis Mean                 -0.30208457
Log Pis Std                  3.0728664
Log Pis Max                  19.26103
Log Pis Min                  -8.011981
Policy mu Mean               0.047871426
Policy mu Std                0.58511984
Policy mu Max                2.987906
Policy mu Min                -2.2883904
Policy log std Mean          -0.97279286
Policy log std Std           0.31779394
Policy log std Max           -0.14114708
Policy log std Min           -2.721648
Z mean eval                  0.8465517
Z variance eval              0.010521533
total_rewards                [ 213.46185629  675.01070208  386.3816903  3110.72926769 2985.33525192
 2922.06615605 1561.19639595  841.20379578 3138.21753715   28.72815108]
total_rewards_mean           1586.2330804278258
total_rewards_std            1249.4266189573084
total_rewards_max            3138.2175371460535
total_rewards_min            28.728151078997715
Number of train steps total  524000
Number of env steps total    657000
Number of rollouts total     0
Train Time (s)               122.38447821792215
(Previous) Eval Time (s)     17.71356142265722
Sample Time (s)              18.486745194066316
Epoch Time (s)               158.5847848346457
Total Train Time (s)         19880.217927691527
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:02:55.086549 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #130 | Epoch Duration: 157.12844824790955
2020-01-12 05:02:55.086715 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #130 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.84532565
Z variance train             0.01048968
KL Divergence                20.416885
KL Loss                      2.0416887
QF Loss                      730.6566
VF Loss                      336.19485
Policy Loss                  -964.56604
Q Predictions Mean           963.80743
Q Predictions Std            275.30377
Q Predictions Max            1201.6508
Q Predictions Min            -8.014573
V Predictions Mean           975.5182
V Predictions Std            274.92624
V Predictions Max            1218.3097
V Predictions Min            70.24643
Log Pis Mean                 -0.5180818
Log Pis Std                  2.7745857
Log Pis Max                  13.422695
Log Pis Min                  -7.092667
Policy mu Mean               0.018335925
Policy mu Std                0.5866301
Policy mu Max                2.5644517
Policy mu Min                -2.1481895
Policy log std Mean          -0.94035244
Policy log std Std           0.2623929
Policy log std Max           -0.024727404
Policy log std Min           -2.2361073
Z mean eval                  0.8737809
Z variance eval              0.011191885
total_rewards                [ 919.03400959  236.13910674  877.80244184  613.65935972  679.35797019
  166.85712913  328.69950386 1437.70467761 1454.9741677  1178.9790865 ]
total_rewards_mean           789.3207452894881
total_rewards_std            445.9345140153953
total_rewards_max            1454.9741676994145
total_rewards_min            166.85712912738845
Number of train steps total  528000
Number of env steps total    662000
Number of rollouts total     0
Train Time (s)               116.31506451172754
(Previous) Eval Time (s)     16.256916978396475
Sample Time (s)              17.775411277543753
Epoch Time (s)               150.34739276766777
Total Train Time (s)         20027.999124033842
Epoch                        131
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:05:22.869520 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #131 | Epoch Duration: 147.7826521396637
2020-01-12 05:05:22.869690 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.87278384
Z variance train             0.01114906
KL Divergence                20.785877
KL Loss                      2.0785878
QF Loss                      825.4899
VF Loss                      647.32635
Policy Loss                  -971.05066
Q Predictions Mean           971.3939
Q Predictions Std            262.73474
Q Predictions Max            1225.608
Q Predictions Min            109.396835
V Predictions Mean           969.9362
V Predictions Std            268.30496
V Predictions Max            1219.8307
V Predictions Min            -6.461958
Log Pis Mean                 -0.37813222
Log Pis Std                  3.1464968
Log Pis Max                  13.841957
Log Pis Min                  -8.815508
Policy mu Mean               0.04059702
Policy mu Std                0.56523293
Policy mu Max                2.3789306
Policy mu Min                -2.757098
Policy log std Mean          -0.98229957
Policy log std Std           0.32652828
Policy log std Max           0.05866939
Policy log std Min           -2.6198802
Z mean eval                  0.8673574
Z variance eval              0.01016558
total_rewards                [2853.30476096 1027.15683041 2899.85837889  518.4764777   871.22967032
 1261.46864424 3027.47843761 2975.80131446  188.62844463 2959.98135899]
total_rewards_mean           1858.3384318208537
total_rewards_std            1118.4190710439432
total_rewards_max            3027.478437607211
total_rewards_min            188.62844463102658
Number of train steps total  532000
Number of env steps total    667000
Number of rollouts total     0
Train Time (s)               114.16543951397762
(Previous) Eval Time (s)     13.691867230925709
Sample Time (s)              17.25377056421712
Epoch Time (s)               145.11107730912045
Total Train Time (s)         20180.461393634323
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:07:55.334569 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #132 | Epoch Duration: 152.46473693847656
2020-01-12 05:07:55.334753 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #132 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8689494
Z variance train             0.010155942
KL Divergence                21.225443
KL Loss                      2.1225443
QF Loss                      683.5494
VF Loss                      124.74021
Policy Loss                  -977.36084
Q Predictions Mean           975.1114
Q Predictions Std            262.63843
Q Predictions Max            1207.0394
Q Predictions Min            11.094805
V Predictions Mean           977.7561
V Predictions Std            261.11093
V Predictions Max            1213.1544
V Predictions Min            2.988159
Log Pis Mean                 -0.18633687
Log Pis Std                  2.8166764
Log Pis Max                  12.174774
Log Pis Min                  -8.739681
Policy mu Mean               0.0035175425
Policy mu Std                0.59794605
Policy mu Max                2.2481718
Policy mu Min                -2.6362414
Policy log std Mean          -0.948701
Policy log std Std           0.26966128
Policy log std Max           0.033361375
Policy log std Min           -2.1543384
Z mean eval                  0.87806064
Z variance eval              0.0069231736
total_rewards                [ 5.50311111e+00 -2.13303983e+00  6.57478235e+02  2.27237471e+03
  1.99862039e+03  5.29393701e+02  6.37351365e+02  1.73724596e+02
  2.23623642e+03  2.99571306e+03]
total_rewards_mean           1150.4262552916912
total_rewards_std            1051.0652611199996
total_rewards_max            2995.7130594005735
total_rewards_min            -2.1330398250308016
Number of train steps total  536000
Number of env steps total    672000
Number of rollouts total     0
Train Time (s)               118.40499468985945
(Previous) Eval Time (s)     21.045270735863596
Sample Time (s)              18.92524504289031
Epoch Time (s)               158.37551046861336
Total Train Time (s)         20330.648480217904
Epoch                        133
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:10:25.521972 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #133 | Epoch Duration: 150.18709063529968
2020-01-12 05:10:25.522124 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.87862796
Z variance train             0.006929517
KL Divergence                22.012726
KL Loss                      2.2012727
QF Loss                      558.0217
VF Loss                      132.09435
Policy Loss                  -966.94763
Q Predictions Mean           967.7551
Q Predictions Std            282.14008
Q Predictions Max            1193.3492
Q Predictions Min            6.033457
V Predictions Mean           963.43475
V Predictions Std            281.53955
V Predictions Max            1177.8618
V Predictions Min            -9.796949
Log Pis Mean                 -0.25989336
Log Pis Std                  2.7659023
Log Pis Max                  7.241035
Log Pis Min                  -7.2690334
Policy mu Mean               0.03670267
Policy mu Std                0.55047697
Policy mu Max                2.227759
Policy mu Min                -2.0885527
Policy log std Mean          -1.0013611
Policy log std Std           0.30172282
Policy log std Max           -0.20181078
Policy log std Min           -2.455821
Z mean eval                  0.8652936
Z variance eval              0.0048997514
total_rewards                [3140.16256696 2408.50579522 1350.29205528  478.15196267  840.65047363
 2831.30034229 3296.09804647  146.58649517 3282.66811706  767.7073215 ]
total_rewards_mean           1854.2123176259
total_rewards_std            1196.0934384904303
total_rewards_max            3296.098046469267
total_rewards_min            146.58649516927255
Number of train steps total  540000
Number of env steps total    677000
Number of rollouts total     0
Train Time (s)               113.4294832306914
(Previous) Eval Time (s)     12.856535454746336
Sample Time (s)              17.87630572821945
Epoch Time (s)               144.1623244136572
Total Train Time (s)         20479.824031598866
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:12:54.701756 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #134 | Epoch Duration: 149.17948865890503
2020-01-12 05:12:54.702021 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #134 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.86688185
Z variance train             0.0049095233
KL Divergence                22.514545
KL Loss                      2.2514546
QF Loss                      941.50085
VF Loss                      198.44531
Policy Loss                  -980.0221
Q Predictions Mean           978.56537
Q Predictions Std            291.96597
Q Predictions Max            1216.4852
Q Predictions Min            -12.284151
V Predictions Mean           976.6249
V Predictions Std            289.70358
V Predictions Max            1235.3381
V Predictions Min            0.012572169
Log Pis Mean                 -0.29981524
Log Pis Std                  2.9551337
Log Pis Max                  12.545635
Log Pis Min                  -7.9591775
Policy mu Mean               -0.02365906
Policy mu Std                0.5932894
Policy mu Max                3.014253
Policy mu Min                -2.0704808
Policy log std Mean          -0.9548718
Policy log std Std           0.3012025
Policy log std Max           -0.00592798
Policy log std Min           -2.6817307
Z mean eval                  0.8845638
Z variance eval              0.010413048
total_rewards                [2772.70961654 1811.26264856 2802.68058468 2385.17103956 2888.21876942
  200.74081684 3059.30214688  102.9120736  2810.93075468 1075.51203504]
total_rewards_mean           1990.9440485799219
total_rewards_std            1080.9325234783043
total_rewards_max            3059.302146878159
total_rewards_min            102.91207359882284
Number of train steps total  544000
Number of env steps total    682000
Number of rollouts total     0
Train Time (s)               112.18482662225142
(Previous) Eval Time (s)     17.873383729718626
Sample Time (s)              17.92792744608596
Epoch Time (s)               147.986137798056
Total Train Time (s)         20632.639168548398
Epoch                        135
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:15:27.519628 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #135 | Epoch Duration: 152.81741905212402
2020-01-12 05:15:27.519817 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #135 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.88321245
Z variance train             0.01038083
KL Divergence                21.162514
KL Loss                      2.1162515
QF Loss                      594.60547
VF Loss                      225.5622
Policy Loss                  -975.58405
Q Predictions Mean           974.69305
Q Predictions Std            275.4848
Q Predictions Max            1240.7263
Q Predictions Min            -51.33809
V Predictions Mean           984.7577
V Predictions Std            273.5829
V Predictions Max            1244.0203
V Predictions Min            -0.08679664
Log Pis Mean                 -0.29316425
Log Pis Std                  3.1966658
Log Pis Max                  10.724297
Log Pis Min                  -8.358847
Policy mu Mean               0.009683022
Policy mu Std                0.60395837
Policy mu Max                2.6995554
Policy mu Min                -2.5335846
Policy log std Mean          -0.95057994
Policy log std Std           0.28874063
Policy log std Max           0.15830892
Policy log std Min           -2.48607
Z mean eval                  0.9130069
Z variance eval              0.009324869
total_rewards                [ -11.14090952 1132.15399309 3050.86352162 1574.33789829 3134.24915323
  988.32612308 2719.38321649 2362.37610226  855.41122295 2392.95841932]
total_rewards_mean           1819.8918740807017
total_rewards_std            1009.0733897835842
total_rewards_max            3134.249153227413
total_rewards_min            -11.14090951697384
Number of train steps total  548000
Number of env steps total    687000
Number of rollouts total     0
Train Time (s)               114.8013619701378
(Previous) Eval Time (s)     22.704325824044645
Sample Time (s)              18.67427927767858
Epoch Time (s)               156.17996707186103
Total Train Time (s)         20786.095025206916
Epoch                        136
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:18:00.977066 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #136 | Epoch Duration: 153.45711636543274
2020-01-12 05:18:00.977221 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #136 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91373575
Z variance train             0.009329274
KL Divergence                21.313393
KL Loss                      2.1313393
QF Loss                      2980.3752
VF Loss                      516.37915
Policy Loss                  -980.3469
Q Predictions Mean           977.85297
Q Predictions Std            290.55438
Q Predictions Max            1223.8416
Q Predictions Min            119.43512
V Predictions Mean           982.88086
V Predictions Std            286.25528
V Predictions Max            1232.2417
V Predictions Min            124.110054
Log Pis Mean                 -0.4842909
Log Pis Std                  2.7961955
Log Pis Max                  10.214812
Log Pis Min                  -6.570239
Policy mu Mean               0.014378775
Policy mu Std                0.5615653
Policy mu Max                2.2018833
Policy mu Min                -1.9749161
Policy log std Mean          -0.96237147
Policy log std Std           0.31009534
Policy log std Max           -0.14137399
Policy log std Min           -2.5854723
Z mean eval                  0.8935791
Z variance eval              0.0090596555
total_rewards                [2772.61656293 1490.51990621  341.92413493 1998.88058969 3235.18819121
 3178.48981907 3074.92190625 3071.58758684 3213.46590152 3182.24353905]
total_rewards_mean           2555.9838137700426
total_rewards_std            927.5250722699484
total_rewards_max            3235.188191210721
total_rewards_min            341.924134929112
Number of train steps total  552000
Number of env steps total    692000
Number of rollouts total     0
Train Time (s)               117.22687256801873
(Previous) Eval Time (s)     19.981144880875945
Sample Time (s)              17.29346914868802
Epoch Time (s)               154.5014865975827
Total Train Time (s)         20943.25467911735
Epoch                        137
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:20:38.139210 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #137 | Epoch Duration: 157.16186261177063
2020-01-12 05:20:38.139404 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8940805
Z variance train             0.00906475
KL Divergence                21.406498
KL Loss                      2.1406498
QF Loss                      778.5383
VF Loss                      183.20444
Policy Loss                  -996.47485
Q Predictions Mean           994.9762
Q Predictions Std            267.6283
Q Predictions Max            1219.6478
Q Predictions Min            54.76254
V Predictions Mean           993.6797
V Predictions Std            264.75964
V Predictions Max            1219.3909
V Predictions Min            90.2623
Log Pis Mean                 -0.16614982
Log Pis Std                  2.8008041
Log Pis Max                  12.212122
Log Pis Min                  -7.6741323
Policy mu Mean               -0.028905487
Policy mu Std                0.58158684
Policy mu Max                2.1835282
Policy mu Min                -2.2782714
Policy log std Mean          -1.0020977
Policy log std Std           0.28965974
Policy log std Max           0.040389538
Policy log std Min           -2.4443836
Z mean eval                  0.8990153
Z variance eval              0.006471675
total_rewards                [2904.05293115 2998.85264797 2978.5786676  2907.70086805 1528.14116435
 2902.99781176 2780.50874709 1387.43791006  642.40347462 2163.42916704]
total_rewards_mean           2319.4103389687807
total_rewards_std            804.2751511946989
total_rewards_max            2998.8526479650104
total_rewards_min            642.4034746225484
Number of train steps total  556000
Number of env steps total    697000
Number of rollouts total     0
Train Time (s)               119.54766079084948
(Previous) Eval Time (s)     22.64122626092285
Sample Time (s)              17.77499338798225
Epoch Time (s)               159.96388043975458
Total Train Time (s)         21101.99629973853
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:23:16.882262 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #138 | Epoch Duration: 158.7427146434784
2020-01-12 05:23:16.882426 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #138 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89949256
Z variance train             0.0064769676
KL Divergence                21.258442
KL Loss                      2.1258442
QF Loss                      2879.1055
VF Loss                      222.10278
Policy Loss                  -967.88165
Q Predictions Mean           962.2959
Q Predictions Std            305.99084
Q Predictions Max            1214.5654
Q Predictions Min            -46.188488
V Predictions Mean           968.6693
V Predictions Std            298.17557
V Predictions Max            1199.4661
V Predictions Min            51.23644
Log Pis Mean                 -0.23640929
Log Pis Std                  2.9777544
Log Pis Max                  9.079848
Log Pis Min                  -8.974477
Policy mu Mean               -0.02474458
Policy mu Std                0.5899006
Policy mu Max                2.443166
Policy mu Min                -2.0445735
Policy log std Mean          -0.9367926
Policy log std Std           0.2932503
Policy log std Max           -0.2272225
Policy log std Min           -2.632453
Z mean eval                  0.88307464
Z variance eval              0.012025575
total_rewards                [2323.90636455 2497.85044048  178.95519361 2661.0441792  2264.83745991
  130.57878801 3261.12714867   30.36127466 1131.1426412  3122.81243864]
total_rewards_mean           1760.2615928916653
total_rewards_std            1207.543902851977
total_rewards_max            3261.127148665224
total_rewards_min            30.361274658449634
Number of train steps total  560000
Number of env steps total    702000
Number of rollouts total     0
Train Time (s)               113.17948161205277
(Previous) Eval Time (s)     21.419759844895452
Sample Time (s)              18.107873228844255
Epoch Time (s)               152.70711468579248
Total Train Time (s)         21248.96206405433
Epoch                        139
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:25:43.849965 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #139 | Epoch Duration: 146.96739101409912
2020-01-12 05:25:43.850146 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #139 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8862028
Z variance train             0.012063297
KL Divergence                19.890007
KL Loss                      1.9890007
QF Loss                      592.58167
VF Loss                      183.94305
Policy Loss                  -981.73883
Q Predictions Mean           979.67456
Q Predictions Std            286.4085
Q Predictions Max            1257.1667
Q Predictions Min            34.480244
V Predictions Mean           985.4776
V Predictions Std            282.59464
V Predictions Max            1254.9332
V Predictions Min            53.627666
Log Pis Mean                 -0.30137277
Log Pis Std                  3.092705
Log Pis Max                  12.975906
Log Pis Min                  -9.073634
Policy mu Mean               0.003629115
Policy mu Std                0.5921588
Policy mu Max                2.2938414
Policy mu Min                -2.1713934
Policy log std Mean          -0.9416733
Policy log std Std           0.32080525
Policy log std Max           -0.17940527
Policy log std Min           -2.8062754
Z mean eval                  0.8877799
Z variance eval              0.0065693995
total_rewards                [3103.38706674 1022.71657817 1388.00159634  337.54861473 2692.29951737
 2526.83813745 1236.27974665  554.70547498   56.95851322 2875.83604776]
total_rewards_mean           1579.457129340792
total_rewards_std            1073.0214553154483
total_rewards_max            3103.3870667436195
total_rewards_min            56.95851321554896
Number of train steps total  564000
Number of env steps total    707000
Number of rollouts total     0
Train Time (s)               111.55530425719917
(Previous) Eval Time (s)     15.679723077919334
Sample Time (s)              17.60613778606057
Epoch Time (s)               144.84116512117907
Total Train Time (s)         21396.937743339688
Epoch                        140
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:28:11.830172 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #140 | Epoch Duration: 147.97986888885498
2020-01-12 05:28:11.830480 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #140 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.88859427
Z variance train             0.0065571973
KL Divergence                21.042133
KL Loss                      2.1042135
QF Loss                      475.61725
VF Loss                      91.31032
Policy Loss                  -963.55524
Q Predictions Mean           963.35754
Q Predictions Std            299.65366
Q Predictions Max            1249.3303
Q Predictions Min            17.905176
V Predictions Mean           965.6747
V Predictions Std            299.15738
V Predictions Max            1236.7831
V Predictions Min            -26.572027
Log Pis Mean                 -0.26935577
Log Pis Std                  2.937073
Log Pis Max                  13.650572
Log Pis Min                  -8.165704
Policy mu Mean               0.004326448
Policy mu Std                0.5907945
Policy mu Max                3.319412
Policy mu Min                -3.6238751
Policy log std Mean          -0.9356472
Policy log std Std           0.2910256
Policy log std Max           0.5713466
Policy log std Min           -2.5871449
Z mean eval                  0.8924845
Z variance eval              0.010306138
total_rewards                [3069.68574389 3057.16671693 2878.60117215 3073.15155204 3176.65039986
 3017.31090644  736.87488524 3042.77193748 1753.91329041 2979.01904892]
total_rewards_mean           2678.5145653354784
total_rewards_std            755.17720817304
total_rewards_max            3176.650399864465
total_rewards_min            736.8748852430065
Number of train steps total  568000
Number of env steps total    712000
Number of rollouts total     0
Train Time (s)               116.45674273278564
(Previous) Eval Time (s)     18.81809647800401
Sample Time (s)              19.369584021158516
Epoch Time (s)               154.64442323194817
Total Train Time (s)         21559.013540561777
Epoch                        141
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:30:53.908275 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #141 | Epoch Duration: 162.0776071548462
2020-01-12 05:30:53.908436 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #141 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8934945
Z variance train             0.010308538
KL Divergence                20.509474
KL Loss                      2.0509474
QF Loss                      637.75586
VF Loss                      309.60883
Policy Loss                  -998.89874
Q Predictions Mean           997.6268
Q Predictions Std            281.14374
Q Predictions Max            1239.3607
Q Predictions Min            24.664492
V Predictions Mean           994.2794
V Predictions Std            279.13275
V Predictions Max            1237.1486
V Predictions Min            -23.817247
Log Pis Mean                 -0.22601122
Log Pis Std                  3.2550943
Log Pis Max                  17.795446
Log Pis Min                  -7.2534924
Policy mu Mean               -0.04243269
Policy mu Std                0.61172724
Policy mu Max                2.0706294
Policy mu Min                -2.3978002
Policy log std Mean          -0.9535649
Policy log std Std           0.30131462
Policy log std Max           -0.24388474
Policy log std Min           -2.6515584
Z mean eval                  0.8808977
Z variance eval              0.011386653
total_rewards                [ 153.70482035 1768.40345416 1235.12241584    5.5326191  2718.52814124
 2982.68316732 3197.98798423 1561.02969968 3077.49743898 3076.29042492]
total_rewards_mean           1977.6780165831217
total_rewards_std            1159.7249171694864
total_rewards_max            3197.987984234294
total_rewards_min            5.532619098570938
Number of train steps total  572000
Number of env steps total    717000
Number of rollouts total     0
Train Time (s)               111.93752500088885
(Previous) Eval Time (s)     26.250954097602516
Sample Time (s)              18.03720515500754
Epoch Time (s)               156.2256842534989
Total Train Time (s)         21705.917703698855
Epoch                        142
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:33:20.814885 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #142 | Epoch Duration: 146.9063057899475
2020-01-12 05:33:20.815131 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #142 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8778799
Z variance train             0.011369201
KL Divergence                19.610432
KL Loss                      1.9610432
QF Loss                      504.49713
VF Loss                      227.37654
Policy Loss                  -991.07776
Q Predictions Mean           992.60693
Q Predictions Std            297.63147
Q Predictions Max            1249.314
Q Predictions Min            -29.206913
V Predictions Mean           990.51855
V Predictions Std            294.11862
V Predictions Max            1244.5533
V Predictions Min            17.50216
Log Pis Mean                 -0.3233627
Log Pis Std                  2.8452475
Log Pis Max                  14.9431715
Log Pis Min                  -6.985154
Policy mu Mean               0.021507682
Policy mu Std                0.5867873
Policy mu Max                2.3409662
Policy mu Min                -2.1562507
Policy log std Mean          -0.9495646
Policy log std Std           0.28870755
Policy log std Max           0.17074871
Policy log std Min           -2.3313146
Z mean eval                  0.88217765
Z variance eval              0.012750618
total_rewards                [1083.99722427 2195.02782701 3035.11580677 1831.05035558 1809.97557107
 2457.5520822  3001.07728105 3224.93653893 2936.88754798 1050.38125521]
total_rewards_mean           2262.600149005819
total_rewards_std            762.5706359558683
total_rewards_max            3224.9365389313866
total_rewards_min            1050.3812552102795
Number of train steps total  576000
Number of env steps total    722000
Number of rollouts total     0
Train Time (s)               121.38367997016758
(Previous) Eval Time (s)     16.931273938156664
Sample Time (s)              17.79706767993048
Epoch Time (s)               156.11202158825472
Total Train Time (s)         21871.663200055715
Epoch                        143
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:36:06.561806 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #143 | Epoch Duration: 165.74649906158447
2020-01-12 05:36:06.561981 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #143 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8804992
Z variance train             0.01278999
KL Divergence                20.547165
KL Loss                      2.0547166
QF Loss                      838.1017
VF Loss                      177.03862
Policy Loss                  -1014.3529
Q Predictions Mean           1009.06226
Q Predictions Std            272.36688
Q Predictions Max            1271.3282
Q Predictions Min            112.39512
V Predictions Mean           1015.34033
V Predictions Std            263.40414
V Predictions Max            1258.1155
V Predictions Min            108.85924
Log Pis Mean                 -0.50707024
Log Pis Std                  2.7375257
Log Pis Max                  12.724934
Log Pis Min                  -9.052534
Policy mu Mean               -0.014090835
Policy mu Std                0.56933475
Policy mu Max                3.0926938
Policy mu Min                -2.2815037
Policy log std Mean          -0.9539497
Policy log std Std           0.28494835
Policy log std Max           0.21893871
Policy log std Min           -2.7834375
Z mean eval                  0.9284282
Z variance eval              0.0076949536
total_rewards                [ 873.53318557 2916.51870818   13.395286     79.46497342 1398.32117925
 2967.1401942   396.85996211 2415.97263595 2331.91511348 2822.77006258]
total_rewards_mean           1621.589130075067
total_rewards_std            1146.2820870820085
total_rewards_max            2967.140194199473
total_rewards_min            13.395286002372309
Number of train steps total  580000
Number of env steps total    727000
Number of rollouts total     0
Train Time (s)               118.3858262929134
(Previous) Eval Time (s)     26.56545572821051
Sample Time (s)              17.43855398800224
Epoch Time (s)               162.38983600912616
Total Train Time (s)         22025.58274512645
Epoch                        144
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:38:40.482706 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #144 | Epoch Duration: 153.9205915927887
2020-01-12 05:38:40.482897 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #144 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92872524
Z variance train             0.007685627
KL Divergence                21.82589
KL Loss                      2.182589
QF Loss                      2451.824
VF Loss                      786.7393
Policy Loss                  -990.66736
Q Predictions Mean           988.58496
Q Predictions Std            310.22235
Q Predictions Max            1227.0037
Q Predictions Min            -60.35195
V Predictions Mean           1004.017
V Predictions Std            303.1547
V Predictions Max            1246.1288
V Predictions Min            -35.517128
Log Pis Mean                 -0.36192638
Log Pis Std                  2.8708522
Log Pis Max                  10.974096
Log Pis Min                  -9.32302
Policy mu Mean               0.028392822
Policy mu Std                0.5895885
Policy mu Max                3.4355688
Policy mu Min                -2.8095992
Policy log std Mean          -0.9553113
Policy log std Std           0.31003135
Policy log std Max           -0.085950255
Policy log std Min           -2.6493306
Z mean eval                  0.8741027
Z variance eval              0.0064833323
total_rewards                [3011.51664611  141.90069728  523.23096879  755.23306473 2843.5260883
  458.32190851 1034.92807013 3116.73094511  447.95796483 2928.18173262]
total_rewards_mean           1526.1528086396108
total_rewards_std            1204.0678582183368
total_rewards_max            3116.730945105954
total_rewards_min            141.90069727714746
Number of train steps total  584000
Number of env steps total    732000
Number of rollouts total     0
Train Time (s)               116.65618380205706
(Previous) Eval Time (s)     18.09591862000525
Sample Time (s)              17.830275227315724
Epoch Time (s)               152.58237764937803
Total Train Time (s)         22177.08868226828
Epoch                        145
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:41:11.992897 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #145 | Epoch Duration: 151.5098478794098
2020-01-12 05:41:11.993182 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #145 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8729026
Z variance train             0.0064840345
KL Divergence                21.859915
KL Loss                      2.1859915
QF Loss                      475.46402
VF Loss                      80.88988
Policy Loss                  -1023.1435
Q Predictions Mean           1023.3849
Q Predictions Std            254.17041
Q Predictions Max            1239.3395
Q Predictions Min            -29.180141
V Predictions Mean           1027.6646
V Predictions Std            253.76755
V Predictions Max            1237.4362
V Predictions Min            -4.2131343
Log Pis Mean                 -0.5210173
Log Pis Std                  2.5501425
Log Pis Max                  7.403887
Log Pis Min                  -7.297196
Policy mu Mean               -0.02522622
Policy mu Std                0.5756984
Policy mu Max                2.362732
Policy mu Min                -2.292818
Policy log std Mean          -0.94052505
Policy log std Std           0.262723
Policy log std Max           -0.16185105
Policy log std Min           -2.049194
Z mean eval                  0.87253934
Z variance eval              0.0059714117
total_rewards                [2511.99828642 3083.24852354 2944.81163623  216.81016533  715.11350782
 3223.76333623 2964.04382306 1453.70116668 2951.34750956  608.17091807]
total_rewards_mean           2067.300887294018
total_rewards_std            1126.1133919555564
total_rewards_max            3223.7633362309252
total_rewards_min            216.81016532767342
Number of train steps total  588000
Number of env steps total    737000
Number of rollouts total     0
Train Time (s)               119.43737741513178
(Previous) Eval Time (s)     17.02308122580871
Sample Time (s)              18.034937592688948
Epoch Time (s)               154.49539623362944
Total Train Time (s)         22332.7888070615
Epoch                        146
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:43:47.695011 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #146 | Epoch Duration: 155.70161867141724
2020-01-12 05:43:47.695241 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #146 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.87275475
Z variance train             0.0059799952
KL Divergence                22.186392
KL Loss                      2.2186391
QF Loss                      652.1876
VF Loss                      140.82053
Policy Loss                  -997.687
Q Predictions Mean           996.472
Q Predictions Std            294.08835
Q Predictions Max            1255.1855
Q Predictions Min            74.229744
V Predictions Mean           994.44434
V Predictions Std            291.51477
V Predictions Max            1231.5768
V Predictions Min            -24.07212
Log Pis Mean                 -0.3299107
Log Pis Std                  2.9978192
Log Pis Max                  10.397108
Log Pis Min                  -7.6780844
Policy mu Mean               -0.017748253
Policy mu Std                0.58407116
Policy mu Max                2.2101164
Policy mu Min                -2.3954365
Policy log std Mean          -0.96135
Policy log std Std           0.29911816
Policy log std Max           -0.26002568
Policy log std Min           -2.4362502
Z mean eval                  0.8917941
Z variance eval              0.008179637
total_rewards                [3041.36027605 3070.62967522 3157.19518701  770.42887738  726.03485504
 2380.23308735  707.22785215 1597.6613832  2885.55645201 2580.7817216 ]
total_rewards_mean           2091.710936701181
total_rewards_std            985.8871249414997
total_rewards_max            3157.1951870085586
total_rewards_min            707.2278521502606
Number of train steps total  592000
Number of env steps total    742000
Number of rollouts total     0
Train Time (s)               109.64881120435894
(Previous) Eval Time (s)     18.22902325214818
Sample Time (s)              17.535813296679407
Epoch Time (s)               145.41364775318652
Total Train Time (s)         22478.973065111786
Epoch                        147
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:46:13.881060 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #147 | Epoch Duration: 146.185644865036
2020-01-12 05:46:13.881253 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #147 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8915459
Z variance train             0.008186401
KL Divergence                21.581024
KL Loss                      2.1581025
QF Loss                      601.7492
VF Loss                      94.711464
Policy Loss                  -1031.8998
Q Predictions Mean           1028.6536
Q Predictions Std            247.85687
Q Predictions Max            1261.8828
Q Predictions Min            101.37817
V Predictions Mean           1033.6525
V Predictions Std            245.79993
V Predictions Max            1271.1962
V Predictions Min            106.24983
Log Pis Mean                 -0.42691576
Log Pis Std                  2.6738155
Log Pis Max                  9.674561
Log Pis Min                  -7.973239
Policy mu Mean               -0.015023956
Policy mu Std                0.5904578
Policy mu Max                2.275646
Policy mu Min                -2.0768182
Policy log std Mean          -0.9541523
Policy log std Std           0.26739812
Policy log std Max           0.06374121
Policy log std Min           -2.1319718
Z mean eval                  0.8813826
Z variance eval              0.011659399
total_rewards                [1.96603207e+03 3.17177023e+03 3.03225681e+03 3.19457589e+03
 3.17293365e+03 2.13664147e+03 2.21611981e+03 3.11179986e+03
 1.20470337e+00 2.68478360e+03]
total_rewards_mean           2468.8118101471846
total_rewards_std            938.6310247321719
total_rewards_max            3194.575886996355
total_rewards_min            1.2047033726836425
Number of train steps total  596000
Number of env steps total    747000
Number of rollouts total     0
Train Time (s)               120.86577717773616
(Previous) Eval Time (s)     19.000757961999625
Sample Time (s)              18.143864919431508
Epoch Time (s)               158.0104000591673
Total Train Time (s)         22643.419797799084
Epoch                        148
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:48:58.329781 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #148 | Epoch Duration: 164.44838285446167
2020-01-12 05:48:58.329965 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #148 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8822344
Z variance train             0.011644383
KL Divergence                21.649048
KL Loss                      2.1649048
QF Loss                      326.2574
VF Loss                      78.60138
Policy Loss                  -972.80865
Q Predictions Mean           970.02936
Q Predictions Std            315.12332
Q Predictions Max            1289.9976
Q Predictions Min            -5.693615
V Predictions Mean           972.68353
V Predictions Std            312.9304
V Predictions Max            1280.8926
V Predictions Min            -0.49940348
Log Pis Mean                 -0.51396716
Log Pis Std                  3.184749
Log Pis Max                  13.533847
Log Pis Min                  -11.267331
Policy mu Mean               0.027941134
Policy mu Std                0.5883592
Policy mu Max                3.1587973
Policy mu Min                -1.747611
Policy log std Mean          -0.91984427
Policy log std Std           0.28863654
Policy log std Max           -0.13744783
Policy log std Min           -2.482636
Z mean eval                  0.8876607
Z variance eval              0.006895736
total_rewards                [ 172.71633036 3076.72398464 1171.64538047 2271.38358075 2993.13121655
    6.22472741  475.18597222 3147.37635977 3012.96338246  970.25805901]
total_rewards_mean           1729.7608993652764
total_rewards_std            1233.5830704618515
total_rewards_max            3147.3763597705856
total_rewards_min            6.22472740887523
Number of train steps total  600000
Number of env steps total    752000
Number of rollouts total     0
Train Time (s)               121.22970696818084
(Previous) Eval Time (s)     25.438423021696508
Sample Time (s)              18.232874135952443
Epoch Time (s)               164.9010041258298
Total Train Time (s)         22798.96433277661
Epoch                        149
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:51:33.876619 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #149 | Epoch Duration: 155.5465109348297
2020-01-12 05:51:33.876825 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #149 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8871776
Z variance train             0.0068988786
KL Divergence                21.415304
KL Loss                      2.1415305
QF Loss                      2392.0166
VF Loss                      165.03595
Policy Loss                  -1027.6624
Q Predictions Mean           1024.5752
Q Predictions Std            256.21494
Q Predictions Max            1306.7118
Q Predictions Min            8.64491
V Predictions Mean           1030.2126
V Predictions Std            254.67491
V Predictions Max            1319.9863
V Predictions Min            40.50296
Log Pis Mean                 -0.2777424
Log Pis Std                  2.7514002
Log Pis Max                  9.470441
Log Pis Min                  -6.8011975
Policy mu Mean               -0.0035418065
Policy mu Std                0.61099315
Policy mu Max                2.5716133
Policy mu Min                -2.3083405
Policy log std Mean          -0.9374988
Policy log std Std           0.28176352
Policy log std Max           -0.21893245
Policy log std Min           -3.0044942
Z mean eval                  0.89009076
Z variance eval              0.007783366
total_rewards                [2.41448583e+03 1.27280158e+03 2.34539702e+00 8.15744989e+02
 1.04686899e+03 7.17601771e+02 1.22991867e+03 2.54778674e+02
 6.18810125e+02 3.65580976e+02]
total_rewards_mean           873.8937008907415
total_rewards_std            646.7908166670187
total_rewards_max            2414.4858333515544
total_rewards_min            2.345397016656756
Number of train steps total  604000
Number of env steps total    757000
Number of rollouts total     0
Train Time (s)               115.3332582921721
(Previous) Eval Time (s)     16.083605533000082
Sample Time (s)              19.182851482648402
Epoch Time (s)               150.5997153078206
Total Train Time (s)         22949.726743148174
Epoch                        150
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:54:04.643424 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #150 | Epoch Duration: 150.76642680168152
2020-01-12 05:54:04.643709 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #150 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89104176
Z variance train             0.007788946
KL Divergence                20.615993
KL Loss                      2.0615995
QF Loss                      685.43445
VF Loss                      152.90149
Policy Loss                  -1006.12683
Q Predictions Mean           1004.6949
Q Predictions Std            289.91263
Q Predictions Max            1340.0295
Q Predictions Min            -0.54731405
V Predictions Mean           1007.16376
V Predictions Std            287.99185
V Predictions Max            1331.0159
V Predictions Min            -6.8219805
Log Pis Mean                 -0.45345625
Log Pis Std                  2.9431732
Log Pis Max                  10.129327
Log Pis Min                  -9.341555
Policy mu Mean               0.01892741
Policy mu Std                0.59024626
Policy mu Max                2.2123668
Policy mu Min                -2.2620368
Policy log std Mean          -0.9422905
Policy log std Std           0.2776276
Policy log std Max           -0.22965789
Policy log std Min           -2.2060862
Z mean eval                  0.88535136
Z variance eval              0.0070900545
total_rewards                [ 854.40635365 3073.95531401 2397.875003   2995.77740972 1010.41369609
  175.65178543  638.95948592 2993.12673647  609.95254112 3223.51678063]
total_rewards_mean           1797.3635106037134
total_rewards_std            1173.904222045315
total_rewards_max            3223.516780626641
total_rewards_min            175.65178543436468
Number of train steps total  608000
Number of env steps total    762000
Number of rollouts total     0
Train Time (s)               114.18641287786886
(Previous) Eval Time (s)     16.249982824083418
Sample Time (s)              17.829748957417905
Epoch Time (s)               148.26614465937018
Total Train Time (s)         23100.404151234776
Epoch                        151
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:56:35.323132 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #151 | Epoch Duration: 150.67920064926147
2020-01-12 05:56:35.323360 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #151 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.885666
Z variance train             0.0070864474
KL Divergence                21.030056
KL Loss                      2.1030056
QF Loss                      673.8597
VF Loss                      206.97766
Policy Loss                  -1016.0158
Q Predictions Mean           1016.3905
Q Predictions Std            295.92776
Q Predictions Max            1274.4523
Q Predictions Min            11.916027
V Predictions Mean           1014.19806
V Predictions Std            295.99268
V Predictions Max            1251.9548
V Predictions Min            -31.607533
Log Pis Mean                 -0.3105952
Log Pis Std                  3.2507088
Log Pis Max                  11.876318
Log Pis Min                  -8.766976
Policy mu Mean               0.059755385
Policy mu Std                0.5910967
Policy mu Max                2.884876
Policy mu Min                -3.2332337
Policy log std Mean          -0.9640677
Policy log std Std           0.31604588
Policy log std Max           -0.075508475
Policy log std Min           -2.9898677
Z mean eval                  0.9122629
Z variance eval              0.0073219435
total_rewards                [3114.54269944   22.41406168 1695.03565609 3276.55492276  684.98219293
 1289.54597548 2977.90082463 3007.04050504 1436.12754476 1198.22489998]
total_rewards_mean           1870.236928279613
total_rewards_std            1089.6098181752975
total_rewards_max            3276.5549227607994
total_rewards_min            22.414061675857248
Number of train steps total  612000
Number of env steps total    767000
Number of rollouts total     0
Train Time (s)               119.20228190207854
(Previous) Eval Time (s)     18.662740875035524
Sample Time (s)              17.882885647937655
Epoch Time (s)               155.74790842505172
Total Train Time (s)         23258.86752941273
Epoch                        152
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:59:13.790984 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #152 | Epoch Duration: 158.46744203567505
2020-01-12 05:59:13.791211 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #152 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9134145
Z variance train             0.0073413984
KL Divergence                20.784748
KL Loss                      2.0784748
QF Loss                      825.4078
VF Loss                      194.53485
Policy Loss                  -1023.2371
Q Predictions Mean           1020.74255
Q Predictions Std            287.62564
Q Predictions Max            1280.6112
Q Predictions Min            25.942669
V Predictions Mean           1020.4269
V Predictions Std            281.10858
V Predictions Max            1253.6084
V Predictions Min            6.521543
Log Pis Mean                 -0.35712555
Log Pis Std                  2.9617429
Log Pis Max                  20.568726
Log Pis Min                  -6.832346
Policy mu Mean               0.029411558
Policy mu Std                0.5996407
Policy mu Max                2.579121
Policy mu Min                -2.5407085
Policy log std Mean          -0.92843187
Policy log std Std           0.29360816
Policy log std Max           -0.26148194
Policy log std Min           -3.0964308
Z mean eval                  0.88692874
Z variance eval              0.0056952485
total_rewards                [2289.25394814  664.18653967 3214.22539492  753.30090705 1356.86212277
 2003.51245762 2011.30593307 2430.09599719 2492.34358035 3198.76053043]
total_rewards_mean           2041.3847411223246
total_rewards_std            846.0330067570889
total_rewards_max            3214.2253949233627
total_rewards_min            664.1865396690165
Number of train steps total  616000
Number of env steps total    772000
Number of rollouts total     0
Train Time (s)               115.49669853784144
(Previous) Eval Time (s)     21.381975575350225
Sample Time (s)              18.279167398810387
Epoch Time (s)               155.15784151200205
Total Train Time (s)         23412.335530778393
Epoch                        153
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:01:47.259170 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #153 | Epoch Duration: 153.46779203414917
2020-01-12 06:01:47.259377 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #153 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8861006
Z variance train             0.0056988425
KL Divergence                21.284403
KL Loss                      2.1284404
QF Loss                      772.0112
VF Loss                      244.68979
Policy Loss                  -1010.2569
Q Predictions Mean           1011.7867
Q Predictions Std            302.6026
Q Predictions Max            1272.4088
Q Predictions Min            -27.254154
V Predictions Mean           1013.6224
V Predictions Std            298.86847
V Predictions Max            1260.9698
V Predictions Min            8.658419
Log Pis Mean                 0.03101486
Log Pis Std                  2.978118
Log Pis Max                  10.407483
Log Pis Min                  -8.334837
Policy mu Mean               0.0022421232
Policy mu Std                0.6231502
Policy mu Max                2.2244806
Policy mu Min                -2.3457818
Policy log std Mean          -0.9515536
Policy log std Std           0.3013382
Policy log std Max           -0.11734754
Policy log std Min           -2.3707747
Z mean eval                  0.89253914
Z variance eval              0.0069697783
total_rewards                [1214.19623493 1338.02485769 3171.72423514 2868.14807985 3183.6084764
  483.15057311  224.63251516 1883.83052083 2370.70882934 -148.90710547]
total_rewards_mean           1658.9117216984403
total_rewards_std            1167.9605442611687
total_rewards_max            3183.608476398168
total_rewards_min            -148.90710547081704
Number of train steps total  620000
Number of env steps total    777000
Number of rollouts total     0
Train Time (s)               116.78231271728873
(Previous) Eval Time (s)     19.69160434184596
Sample Time (s)              19.125171875581145
Epoch Time (s)               155.59908893471584
Total Train Time (s)         23567.992397229187
Epoch                        154
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:04:22.918774 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #154 | Epoch Duration: 155.6592400074005
2020-01-12 06:04:22.918993 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #154 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8927218
Z variance train             0.0069878576
KL Divergence                20.889671
KL Loss                      2.088967
QF Loss                      607.5693
VF Loss                      135.72993
Policy Loss                  -997.17676
Q Predictions Mean           996.71875
Q Predictions Std            318.21964
Q Predictions Max            1319.0839
Q Predictions Min            28.349632
V Predictions Mean           998.2797
V Predictions Std            314.7798
V Predictions Max            1295.5958
V Predictions Min            8.862732
Log Pis Mean                 -0.47450632
Log Pis Std                  3.11845
Log Pis Max                  12.67025
Log Pis Min                  -8.026687
Policy mu Mean               0.0027996842
Policy mu Std                0.57723457
Policy mu Max                2.0097966
Policy mu Min                -2.4808233
Policy log std Mean          -0.94370544
Policy log std Std           0.34507436
Policy log std Max           0.10269117
Policy log std Min           -3.0611887
Z mean eval                  0.89568233
Z variance eval              0.00570048
total_rewards                [3133.40194248 3103.15130645 3155.74503627 3034.61675847 3133.55451782
 1989.31346116 3223.70056155 2069.17029006 2083.96639863 2958.93115218]
total_rewards_mean           2788.555142506597
total_rewards_std            490.24647038241164
total_rewards_max            3223.7005615480775
total_rewards_min            1989.313461163893
Number of train steps total  624000
Number of env steps total    782000
Number of rollouts total     0
Train Time (s)               114.08102856809273
(Previous) Eval Time (s)     19.751433483790606
Sample Time (s)              18.049712721258402
Epoch Time (s)               151.88217477314174
Total Train Time (s)         23723.571838981938
Epoch                        155
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:06:58.499135 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #155 | Epoch Duration: 155.5799789428711
2020-01-12 06:06:58.499281 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #155 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89561796
Z variance train             0.005698957
KL Divergence                21.480974
KL Loss                      2.1480975
QF Loss                      573.86487
VF Loss                      250.8561
Policy Loss                  -1048.9058
Q Predictions Mean           1048.4153
Q Predictions Std            278.52133
Q Predictions Max            1266.0477
Q Predictions Min            -54.110764
V Predictions Mean           1045.2561
V Predictions Std            276.30533
V Predictions Max            1257.0316
V Predictions Min            -9.701233
Log Pis Mean                 -0.27344507
Log Pis Std                  2.699509
Log Pis Max                  8.405411
Log Pis Min                  -7.8467174
Policy mu Mean               0.0038059237
Policy mu Std                0.58675486
Policy mu Max                2.3237698
Policy mu Min                -2.190437
Policy log std Mean          -0.96937764
Policy log std Std           0.27785575
Policy log std Max           -0.19553745
Policy log std Min           -2.674388
Z mean eval                  0.91899526
Z variance eval              0.0072663897
total_rewards                [3170.43560476 3003.82865507 3351.98918837 3196.9822068  3207.18669388
 2298.98049767 3142.2933613  2072.5859541  3021.41311493 3113.02349956]
total_rewards_mean           2957.871877643104
total_rewards_std            400.24308369870005
total_rewards_max            3351.989188368101
total_rewards_min            2072.585954097721
Number of train steps total  628000
Number of env steps total    787000
Number of rollouts total     0
Train Time (s)               110.90316131385043
(Previous) Eval Time (s)     23.448920411989093
Sample Time (s)              18.732106264214963
Epoch Time (s)               153.0841879900545
Total Train Time (s)         23878.6453825864
Epoch                        156
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:09:33.574270 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #156 | Epoch Duration: 155.07488012313843
2020-01-12 06:09:33.574425 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #156 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9172187
Z variance train             0.007250534
KL Divergence                20.893585
KL Loss                      2.0893586
QF Loss                      432.4197
VF Loss                      153.90755
Policy Loss                  -1040.7667
Q Predictions Mean           1037.1746
Q Predictions Std            285.5772
Q Predictions Max            1278.046
Q Predictions Min            1.7372426
V Predictions Mean           1039.9448
V Predictions Std            282.9535
V Predictions Max            1270.8164
V Predictions Min            -11.863909
Log Pis Mean                 -0.16685796
Log Pis Std                  2.7561715
Log Pis Max                  11.75523
Log Pis Min                  -7.2538776
Policy mu Mean               0.007966307
Policy mu Std                0.60093075
Policy mu Max                1.8990316
Policy mu Min                -2.0305076
Policy log std Mean          -0.96998256
Policy log std Std           0.26526177
Policy log std Max           -0.2188496
Policy log std Min           -2.1836195
Z mean eval                  0.9040435
Z variance eval              0.0066998056
total_rewards                [ 575.63947881 1694.67347348  355.05680051 3237.60855291 3224.70158617
  367.38932503  708.16576384 1025.17372998 1195.35222349 2535.37294697]
total_rewards_mean           1491.9133881189798
total_rewards_std            1072.2190060039838
total_rewards_max            3237.6085529080337
total_rewards_min            355.0568005129669
Number of train steps total  632000
Number of env steps total    792000
Number of rollouts total     0
Train Time (s)               118.27020207373425
(Previous) Eval Time (s)     25.43930005840957
Sample Time (s)              18.899283225648105
Epoch Time (s)               162.60878535779193
Total Train Time (s)         24031.506885808893
Epoch                        157
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:12:06.440584 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #157 | Epoch Duration: 152.86601161956787
2020-01-12 06:12:06.440854 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #157 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90466774
Z variance train             0.0067190467
KL Divergence                21.372097
KL Loss                      2.1372097
QF Loss                      1174.8015
VF Loss                      446.63727
Policy Loss                  -1058.3306
Q Predictions Mean           1055.4744
Q Predictions Std            254.29634
Q Predictions Max            1293.7739
Q Predictions Min            87.24506
V Predictions Mean           1054.9888
V Predictions Std            248.23186
V Predictions Max            1284.136
V Predictions Min            85.76616
Log Pis Mean                 -0.42029816
Log Pis Std                  2.7529366
Log Pis Max                  12.35898
Log Pis Min                  -9.15291
Policy mu Mean               0.015387103
Policy mu Std                0.5763393
Policy mu Max                2.6350634
Policy mu Min                -2.2452703
Policy log std Mean          -0.9743469
Policy log std Std           0.27335027
Policy log std Max           -0.1790052
Policy log std Min           -3.0309634
Z mean eval                  0.90413034
Z variance eval              0.010085577
total_rewards                [ -11.51490849 3005.48552781 1444.14467933 3294.68886401  333.59262853
 1170.31345033 3115.46028068 3107.48243603 2502.29758034  148.97715446]
total_rewards_mean           1811.0927693020822
total_rewards_std            1276.7215461444991
total_rewards_max            3294.6888640053444
total_rewards_min            -11.514908485477969
Number of train steps total  636000
Number of env steps total    797000
Number of rollouts total     0
Train Time (s)               116.21780844824389
(Previous) Eval Time (s)     15.696181122213602
Sample Time (s)              18.804031745996326
Epoch Time (s)               150.71802131645381
Total Train Time (s)         24183.787530052476
Epoch                        158
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:14:38.724132 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #158 | Epoch Duration: 152.28306698799133
2020-01-12 06:14:38.724374 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #158 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9063543
Z variance train             0.01005605
KL Divergence                21.26019
KL Loss                      2.126019
QF Loss                      863.28784
VF Loss                      185.88336
Policy Loss                  -987.3862
Q Predictions Mean           981.5294
Q Predictions Std            345.25134
Q Predictions Max            1310.723
Q Predictions Min            -53.800987
V Predictions Mean           989.6166
V Predictions Std            337.42172
V Predictions Max            1295.3936
V Predictions Min            -2.1247065
Log Pis Mean                 0.0033846796
Log Pis Std                  3.5118513
Log Pis Max                  16.647694
Log Pis Min                  -8.564758
Policy mu Mean               0.027524495
Policy mu Std                0.6117472
Policy mu Max                2.983831
Policy mu Min                -3.4949472
Policy log std Mean          -0.96574265
Policy log std Std           0.31648985
Policy log std Max           -0.14606214
Policy log std Min           -2.6346247
Z mean eval                  0.8803307
Z variance eval              0.0086382
total_rewards                [1308.44143235 3320.23651754 1755.80148296 3415.31153345 3296.2503571
 3008.19132326 1506.49628269 1236.03827867 3052.83838951 2365.95432456]
total_rewards_mean           2426.555992207377
total_rewards_std            850.3414977285005
total_rewards_max            3415.311533448982
total_rewards_min            1236.0382786747762
Number of train steps total  640000
Number of env steps total    802000
Number of rollouts total     0
Train Time (s)               121.42004847805947
(Previous) Eval Time (s)     17.260924477130175
Sample Time (s)              18.122135371435434
Epoch Time (s)               156.80310832662508
Total Train Time (s)         24346.618618256412
Epoch                        159
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:17:21.555369 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #159 | Epoch Duration: 162.8308448791504
2020-01-12 06:17:21.555517 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #159 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.87988645
Z variance train             0.008637224
KL Divergence                21.255547
KL Loss                      2.1255548
QF Loss                      909.88776
VF Loss                      179.69339
Policy Loss                  -1041.7549
Q Predictions Mean           1045.144
Q Predictions Std            295.27667
Q Predictions Max            1311.9698
Q Predictions Min            14.646924
V Predictions Mean           1039.8091
V Predictions Std            293.60983
V Predictions Max            1314.1022
V Predictions Min            -2.4754472
Log Pis Mean                 -0.11408399
Log Pis Std                  2.997391
Log Pis Max                  16.360699
Log Pis Min                  -7.0536346
Policy mu Mean               0.01066271
Policy mu Std                0.59121114
Policy mu Max                3.5476148
Policy mu Min                -2.7492359
Policy log std Mean          -0.99170864
Policy log std Std           0.29121235
Policy log std Max           -0.26800776
Policy log std Min           -2.6656234
Z mean eval                  0.8884902
Z variance eval              0.008649391
total_rewards                [3135.73342912 3394.3164739  3222.1440003  3360.49865703  246.9794864
 2992.36116152 2304.53404287 3071.81312956 3241.86613321 2199.99590611]
total_rewards_mean           2717.0242420031286
total_rewards_std            912.0844033150828
total_rewards_max            3394.31647390249
total_rewards_min            246.97948640158882
Number of train steps total  644000
Number of env steps total    807000
Number of rollouts total     0
Train Time (s)               112.79485013522208
(Previous) Eval Time (s)     23.288385754916817
Sample Time (s)              17.842614146880805
Epoch Time (s)               153.9258500370197
Total Train Time (s)         24501.413536491804
Epoch                        160
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:19:56.352754 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #160 | Epoch Duration: 154.79711890220642
2020-01-12 06:19:56.352936 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #160 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8884636
Z variance train             0.00865957
KL Divergence                21.238674
KL Loss                      2.1238675
QF Loss                      887.9961
VF Loss                      1792.1969
Policy Loss                  -1047.2844
Q Predictions Mean           1041.7026
Q Predictions Std            278.32327
Q Predictions Max            1294.5956
Q Predictions Min            -37.676083
V Predictions Mean           1041.1255
V Predictions Std            274.00342
V Predictions Max            1284.5488
V Predictions Min            -29.501274
Log Pis Mean                 0.048809625
Log Pis Std                  3.0714848
Log Pis Max                  13.472014
Log Pis Min                  -9.710131
Policy mu Mean               0.023619765
Policy mu Std                0.5806507
Policy mu Max                2.3308659
Policy mu Min                -2.3657203
Policy log std Mean          -1.0211298
Policy log std Std           0.28321484
Policy log std Max           -0.13591015
Policy log std Min           -2.45682
Z mean eval                  0.9096953
Z variance eval              0.00791603
total_rewards                [   9.6430627    26.68356874  985.04189482 3397.17267933  926.96982823
 3270.6962962   848.73301737 2000.31402493 3249.75290609 2319.78573589]
total_rewards_mean           1703.4793014307193
total_rewards_std            1253.5592731830855
total_rewards_max            3397.172679329598
total_rewards_min            9.643062699231422
Number of train steps total  648000
Number of env steps total    812000
Number of rollouts total     0
Train Time (s)               120.2143380860798
(Previous) Eval Time (s)     24.159343996085227
Sample Time (s)              18.400252155493945
Epoch Time (s)               162.77393423765898
Total Train Time (s)         24657.96315715043
Epoch                        161
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:22:32.905810 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #161 | Epoch Duration: 156.55272316932678
2020-01-12 06:22:32.906046 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #161 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91952515
Z variance train             0.0078474
KL Divergence                21.854277
KL Loss                      2.1854277
QF Loss                      680.5332
VF Loss                      290.80432
Policy Loss                  -1057.417
Q Predictions Mean           1057.9608
Q Predictions Std            272.71094
Q Predictions Max            1307.2494
Q Predictions Min            39.663292
V Predictions Mean           1051.3357
V Predictions Std            273.72778
V Predictions Max            1292.6123
V Predictions Min            -0.19036472
Log Pis Mean                 0.15229437
Log Pis Std                  2.9358366
Log Pis Max                  10.879767
Log Pis Min                  -8.827775
Policy mu Mean               0.018200075
Policy mu Std                0.6176456
Policy mu Max                2.0925622
Policy mu Min                -2.222163
Policy log std Mean          -0.9833344
Policy log std Std           0.32715848
Policy log std Max           0.8771796
Policy log std Min           -2.6505728
Z mean eval                  0.89288837
Z variance eval              0.006623932
total_rewards                [2980.03166449  623.08674014 2786.23129994 3211.54367269 1619.60031101
 3186.34234174  177.1767471  3126.48107227 2917.18422867 3195.28986716]
total_rewards_mean           2382.2967945210107
total_rewards_std            1090.6210429830605
total_rewards_max            3211.543672687859
total_rewards_min            177.17674709623762
Number of train steps total  652000
Number of env steps total    817000
Number of rollouts total     0
Train Time (s)               121.35377777880058
(Previous) Eval Time (s)     17.937806406989694
Sample Time (s)              17.232826282270253
Epoch Time (s)               156.52441046806052
Total Train Time (s)         24820.1528704511
Epoch                        162
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:25:15.098053 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #162 | Epoch Duration: 162.19182801246643
2020-01-12 06:25:15.098261 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #162 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8913986
Z variance train             0.006635166
KL Divergence                22.15385
KL Loss                      2.2153852
QF Loss                      1123.8174
VF Loss                      283.5236
Policy Loss                  -1066.8268
Q Predictions Mean           1061.8717
Q Predictions Std            286.73004
Q Predictions Max            1308.0573
Q Predictions Min            9.333641
V Predictions Mean           1067.865
V Predictions Std            278.0865
V Predictions Max            1309.5887
V Predictions Min            27.895082
Log Pis Mean                 -0.079431556
Log Pis Std                  2.704994
Log Pis Max                  15.185512
Log Pis Min                  -8.667358
Policy mu Mean               -0.034344073
Policy mu Std                0.59681106
Policy mu Max                2.345686
Policy mu Min                -1.9800012
Policy log std Mean          -0.9727495
Policy log std Std           0.280359
Policy log std Max           -0.12774706
Policy log std Min           -2.688167
Z mean eval                  0.9076246
Z variance eval              0.007781452
total_rewards                [3153.3206959    18.02566479 3214.08186478 3468.92023523 3310.40953769
  797.2797188   661.54824037 2469.10783243  308.03406362 3318.65954158]
total_rewards_mean           2071.938739519003
total_rewards_std            1364.3744618499354
total_rewards_max            3468.920235225127
total_rewards_min            18.0256647868686
Number of train steps total  656000
Number of env steps total    822000
Number of rollouts total     0
Train Time (s)               116.37728440202773
(Previous) Eval Time (s)     23.604944413993508
Sample Time (s)              18.177168920636177
Epoch Time (s)               158.1593977366574
Total Train Time (s)         24974.798055936582
Epoch                        163
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:27:49.748416 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #163 | Epoch Duration: 154.6499683856964
2020-01-12 06:27:49.748668 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #163 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90589523
Z variance train             0.007797026
KL Divergence                21.315075
KL Loss                      2.1315076
QF Loss                      772.729
VF Loss                      125.35733
Policy Loss                  -1085.6643
Q Predictions Mean           1085.6562
Q Predictions Std            245.54898
Q Predictions Max            1353.7733
Q Predictions Min            89.89178
V Predictions Mean           1088.6047
V Predictions Std            245.40561
V Predictions Max            1349.2197
V Predictions Min            86.17185
Log Pis Mean                 0.1924819
Log Pis Std                  2.7726805
Log Pis Max                  9.079054
Log Pis Min                  -6.895689
Policy mu Mean               0.047884338
Policy mu Std                0.6415737
Policy mu Max                2.405995
Policy mu Min                -2.3942142
Policy log std Mean          -0.97299397
Policy log std Std           0.2787265
Policy log std Max           -0.1500411
Policy log std Min           -2.5650609
Z mean eval                  0.88765097
Z variance eval              0.0059783645
total_rewards                [2888.06690097 2948.34222766 3193.58116519 2034.84435505  950.75858475
 2905.97635528 2844.77396781 2953.82714292 2949.67436886 3168.6264528 ]
total_rewards_mean           2683.8471521283236
total_rewards_std            651.9275899758616
total_rewards_max            3193.5811651901686
total_rewards_min            950.7585847457814
Number of train steps total  660000
Number of env steps total    827000
Number of rollouts total     0
Train Time (s)               113.64121032506227
(Previous) Eval Time (s)     20.0951383872889
Sample Time (s)              18.65918482420966
Epoch Time (s)               152.39553353656083
Total Train Time (s)         25131.705869737547
Epoch                        164
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:30:26.655668 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #164 | Epoch Duration: 156.906809091568
2020-01-12 06:30:26.655902 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #164 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8884345
Z variance train             0.005972223
KL Divergence                21.560265
KL Loss                      2.1560266
QF Loss                      561.9854
VF Loss                      731.39435
Policy Loss                  -1055.0538
Q Predictions Mean           1054.335
Q Predictions Std            290.25378
Q Predictions Max            1298.8251
Q Predictions Min            13.728003
V Predictions Mean           1055.0195
V Predictions Std            280.6368
V Predictions Max            1298.6396
V Predictions Min            12.73703
Log Pis Mean                 0.36990115
Log Pis Std                  2.9043658
Log Pis Max                  11.590361
Log Pis Min                  -9.528124
Policy mu Mean               -0.015041455
Policy mu Std                0.6413809
Policy mu Max                3.251343
Policy mu Min                -2.0234132
Policy log std Mean          -1.0070143
Policy log std Std           0.2936844
Policy log std Max           -0.041042566
Policy log std Min           -2.6474075
Z mean eval                  0.90299827
Z variance eval              0.0069708624
total_rewards                [3240.66153466 2639.25850923 3133.86576361 3415.42526927  542.48288544
 1033.09042789  500.02479025  253.28925985 3186.59167835 1036.89110482]
total_rewards_mean           1898.1581223368205
total_rewards_std            1258.1346478855862
total_rewards_max            3415.4252692685263
total_rewards_min            253.28925985110618
Number of train steps total  664000
Number of env steps total    832000
Number of rollouts total     0
Train Time (s)               119.68849541991949
(Previous) Eval Time (s)     24.60609359666705
Sample Time (s)              17.397987423930317
Epoch Time (s)               161.69257644051686
Total Train Time (s)         25288.168824046385
Epoch                        165
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:33:03.120950 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #165 | Epoch Duration: 156.46490693092346
2020-01-12 06:33:03.121131 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #165 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90349543
Z variance train             0.006968764
KL Divergence                21.51802
KL Loss                      2.151802
QF Loss                      543.1112
VF Loss                      392.6095
Policy Loss                  -1057.3496
Q Predictions Mean           1056.6317
Q Predictions Std            290.18262
Q Predictions Max            1286.3207
Q Predictions Min            -29.993141
V Predictions Mean           1062.282
V Predictions Std            290.22705
V Predictions Max            1292.1732
V Predictions Min            -18.037514
Log Pis Mean                 0.08246035
Log Pis Std                  2.8975682
Log Pis Max                  10.290535
Log Pis Min                  -7.823386
Policy mu Mean               0.017186645
Policy mu Std                0.61847657
Policy mu Max                2.5666294
Policy mu Min                -2.4463432
Policy log std Mean          -0.9793482
Policy log std Std           0.33090413
Policy log std Max           0.9877169
Policy log std Min           -2.6717012
Z mean eval                  0.87786233
Z variance eval              0.009863496
total_rewards                [  86.37956688 3277.70574013 3155.49247322 3220.77024239  326.04189172
 1070.68433785 1337.09400221 2869.16613612 1487.31641252 3369.40838405]
total_rewards_mean           2020.005918709332
total_rewards_std            1229.4184339923036
total_rewards_max            3369.4083840546937
total_rewards_min            86.37956688217605
Number of train steps total  668000
Number of env steps total    837000
Number of rollouts total     0
Train Time (s)               119.26335399225354
(Previous) Eval Time (s)     19.37815123796463
Sample Time (s)              18.603729791473597
Epoch Time (s)               157.24523502169177
Total Train Time (s)         25449.755975083914
Epoch                        166
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:35:44.709540 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #166 | Epoch Duration: 161.58826804161072
2020-01-12 06:35:44.709731 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #166 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.87813014
Z variance train             0.009872268
KL Divergence                21.70237
KL Loss                      2.170237
QF Loss                      1265.4617
VF Loss                      209.11313
Policy Loss                  -1074.1855
Q Predictions Mean           1073.2847
Q Predictions Std            288.92868
Q Predictions Max            1295.9564
Q Predictions Min            26.314602
V Predictions Mean           1074.576
V Predictions Std            285.77084
V Predictions Max            1284.8718
V Predictions Min            68.4596
Log Pis Mean                 -0.22762075
Log Pis Std                  3.046281
Log Pis Max                  15.075385
Log Pis Min                  -9.830906
Policy mu Mean               -0.03171388
Policy mu Std                0.58415985
Policy mu Max                2.5753112
Policy mu Min                -1.9879198
Policy log std Mean          -0.9985343
Policy log std Std           0.30918056
Policy log std Max           -0.25754744
Policy log std Min           -2.9072282
Z mean eval                  0.9070324
Z variance eval              0.008361804
total_rewards                [ 418.36737012   -5.05166466 3311.00914513 3428.1270858  3269.91726493
 1046.68002919 1271.37562719  264.18364065  746.897128   3142.64743746]
total_rewards_mean           1689.4153063825493
total_rewards_std            1351.1783041937044
total_rewards_max            3428.1270858012463
total_rewards_min            -5.051664655032884
Number of train steps total  672000
Number of env steps total    842000
Number of rollouts total     0
Train Time (s)               117.51161350402981
(Previous) Eval Time (s)     23.720892353914678
Sample Time (s)              18.42776549095288
Epoch Time (s)               159.66027134889737
Total Train Time (s)         25604.424381097313
Epoch                        167
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:38:19.378860 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #167 | Epoch Duration: 154.6690182685852
2020-01-12 06:38:19.379023 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #167 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9088683
Z variance train             0.008370015
KL Divergence                22.222095
KL Loss                      2.2222097
QF Loss                      853.2732
VF Loss                      279.03983
Policy Loss                  -1035.0916
Q Predictions Mean           1034.6992
Q Predictions Std            332.1867
Q Predictions Max            1361.9231
Q Predictions Min            -13.751662
V Predictions Mean           1035.3418
V Predictions Std            330.01624
V Predictions Max            1358.4104
V Predictions Min            -32.07561
Log Pis Mean                 0.20550942
Log Pis Std                  3.2348826
Log Pis Max                  11.649391
Log Pis Min                  -7.328984
Policy mu Mean               0.030993082
Policy mu Std                0.62260467
Policy mu Max                2.305828
Policy mu Min                -2.932344
Policy log std Mean          -0.96041524
Policy log std Std           0.33354434
Policy log std Max           -0.07384491
Policy log std Min           -2.698651
Z mean eval                  0.87439156
Z variance eval              0.0064628595
total_rewards                [2983.34573741 3280.4107274  2822.87829647 3191.48020753 3322.605104
 3080.53389965 3353.12028873 3159.75210412 3205.46643629 3402.2698554 ]
total_rewards_mean           3180.186265699746
total_rewards_std            169.43592682264548
total_rewards_max            3402.2698554023855
total_rewards_min            2822.8782964679576
Number of train steps total  676000
Number of env steps total    847000
Number of rollouts total     0
Train Time (s)               118.85958355898038
(Previous) Eval Time (s)     18.729283056221902
Sample Time (s)              17.83237920422107
Epoch Time (s)               155.42124581942335
Total Train Time (s)         25768.53791941749
Epoch                        168
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:41:03.495929 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #168 | Epoch Duration: 164.11679029464722
2020-01-12 06:41:03.496081 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #168 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8728738
Z variance train             0.0064675226
KL Divergence                23.047152
KL Loss                      2.3047152
QF Loss                      1061.0265
VF Loss                      340.4773
Policy Loss                  -1047.0974
Q Predictions Mean           1039.9917
Q Predictions Std            303.1549
Q Predictions Max            1291.5343
Q Predictions Min            53.85649
V Predictions Mean           1041.843
V Predictions Std            298.5688
V Predictions Max            1286.8314
V Predictions Min            47.327236
Log Pis Mean                 0.24548236
Log Pis Std                  3.1545548
Log Pis Max                  13.910772
Log Pis Min                  -7.576998
Policy mu Mean               0.0032430359
Policy mu Std                0.61894065
Policy mu Max                2.0850992
Policy mu Min                -2.3557882
Policy log std Mean          -1.0002086
Policy log std Std           0.31739777
Policy log std Max           -0.008976221
Policy log std Min           -2.7322116
Z mean eval                  0.91952753
Z variance eval              0.011505129
total_rewards                [ -18.45587436 3369.098444   1589.99111512 3362.06745494 1985.73387333
 1730.09263094 2386.93695199 3143.2915268  1899.01955206 3504.68764473]
total_rewards_mean           2295.246331955279
total_rewards_std            1044.2412043041534
total_rewards_max            3504.6876447276686
total_rewards_min            -18.455874363458044
Number of train steps total  680000
Number of env steps total    852000
Number of rollouts total     0
Train Time (s)               121.95311026880518
(Previous) Eval Time (s)     27.4245453318581
Sample Time (s)              17.74834729824215
Epoch Time (s)               167.12600289890543
Total Train Time (s)         25931.367158573586
Epoch                        169
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:43:46.325713 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #169 | Epoch Duration: 162.8295021057129
2020-01-12 06:43:46.325905 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #169 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9193703
Z variance train             0.011487451
KL Divergence                22.554646
KL Loss                      2.2554646
QF Loss                      1380.5182
VF Loss                      180.79709
Policy Loss                  -1061.8546
Q Predictions Mean           1051.7552
Q Predictions Std            315.95398
Q Predictions Max            1339.5867
Q Predictions Min            -162.11478
V Predictions Mean           1057.8047
V Predictions Std            298.1259
V Predictions Max            1323.2675
V Predictions Min            34.448975
Log Pis Mean                 0.088236555
Log Pis Std                  3.138809
Log Pis Max                  15.687457
Log Pis Min                  -7.5492053
Policy mu Mean               -0.012230763
Policy mu Std                0.63181907
Policy mu Max                2.8117342
Policy mu Min                -2.3972647
Policy log std Mean          -0.9692979
Policy log std Std           0.31963348
Policy log std Max           -0.13515133
Policy log std Min           -2.6451073
Z mean eval                  0.9061402
Z variance eval              0.007518375
total_rewards                [3295.60659652 3186.88643151   65.01798017  898.9370001  3206.21990691
 3334.50460882  963.27256743 3219.65247119 3333.63161055 1155.15045198]
total_rewards_mean           2265.8879625201566
total_rewards_std            1250.095831570685
total_rewards_max            3334.5046088216777
total_rewards_min            65.017980173399
Number of train steps total  684000
Number of env steps total    857000
Number of rollouts total     0
Train Time (s)               114.04270656220615
(Previous) Eval Time (s)     23.1277266680263
Sample Time (s)              18.094898310489953
Epoch Time (s)               155.2653315407224
Total Train Time (s)         26082.531574048568
Epoch                        170
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:46:17.491405 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #170 | Epoch Duration: 151.16538977622986
2020-01-12 06:46:17.491590 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #170 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9062789
Z variance train             0.0075073056
KL Divergence                22.765738
KL Loss                      2.276574
QF Loss                      607.67334
VF Loss                      239.95213
Policy Loss                  -1089.3672
Q Predictions Mean           1088.2368
Q Predictions Std            274.6192
Q Predictions Max            1312.508
Q Predictions Min            59.64594
V Predictions Mean           1082.1158
V Predictions Std            272.24652
V Predictions Max            1306.9724
V Predictions Min            64.391525
Log Pis Mean                 0.2259547
Log Pis Std                  3.1334634
Log Pis Max                  15.481401
Log Pis Min                  -9.133328
Policy mu Mean               0.012515052
Policy mu Std                0.61630625
Policy mu Max                2.367692
Policy mu Min                -2.3052745
Policy log std Mean          -0.9993665
Policy log std Std           0.28600878
Policy log std Max           -0.19639808
Policy log std Min           -2.5563684
Z mean eval                  0.90236634
Z variance eval              0.008009644
total_rewards                [3079.82487877 3096.35508813 3238.42506494 3465.95169826 3348.65134809
 3254.48955641 3158.85432927 3334.0506024  3306.0208633  3400.75482611]
total_rewards_mean           3268.337825567231
total_rewards_std            121.22801814830594
total_rewards_max            3465.9516982632585
total_rewards_min            3079.824878767053
Number of train steps total  688000
Number of env steps total    862000
Number of rollouts total     0
Train Time (s)               116.62334985099733
(Previous) Eval Time (s)     19.027471457142383
Sample Time (s)              17.780366314575076
Epoch Time (s)               153.4311876227148
Total Train Time (s)         26246.32300583087
Epoch                        171
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:49:01.285909 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #171 | Epoch Duration: 163.79419493675232
2020-01-12 06:49:01.286093 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #171 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9023403
Z variance train             0.008011709
KL Divergence                22.520947
KL Loss                      2.2520947
QF Loss                      725.8735
VF Loss                      219.67754
Policy Loss                  -1051.8345
Q Predictions Mean           1051.4258
Q Predictions Std            311.96906
Q Predictions Max            1319.4603
Q Predictions Min            34.01194
V Predictions Mean           1047.0066
V Predictions Std            309.31992
V Predictions Max            1301.081
V Predictions Min            -14.627394
Log Pis Mean                 0.097019926
Log Pis Std                  2.7601225
Log Pis Max                  7.466498
Log Pis Min                  -9.238021
Policy mu Mean               -0.010600457
Policy mu Std                0.6097226
Policy mu Max                2.4857466
Policy mu Min                -1.9175407
Policy log std Mean          -0.98054653
Policy log std Std           0.32001844
Policy log std Max           -0.1357534
Policy log std Min           -2.5962932
Z mean eval                  0.89265394
Z variance eval              0.008426608
total_rewards                [ 603.94805384 3288.54488805 2303.42907549  490.9997479  1784.04650509
 1239.09747918  278.5806255  2151.83875726 3296.9980779   225.56990459]
total_rewards_mean           1566.3053114809086
total_rewards_std            1119.8349658727402
total_rewards_max            3296.998077899876
total_rewards_min            225.56990459061188
Number of train steps total  692000
Number of env steps total    867000
Number of rollouts total     0
Train Time (s)               114.83132188627496
(Previous) Eval Time (s)     29.390154112130404
Sample Time (s)              18.064626581035554
Epoch Time (s)               162.28610257944092
Total Train Time (s)         26402.45586862741
Epoch                        172
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:51:37.424122 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #172 | Epoch Duration: 156.13785123825073
2020-01-12 06:51:37.424451 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #172 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.88884246
Z variance train             0.008433933
KL Divergence                21.88092
KL Loss                      2.188092
QF Loss                      652.9186
VF Loss                      129.42693
Policy Loss                  -1042.0968
Q Predictions Mean           1044.1404
Q Predictions Std            332.68976
Q Predictions Max            1332.5245
Q Predictions Min            -18.83184
V Predictions Mean           1044.2529
V Predictions Std            332.52753
V Predictions Max            1338.031
V Predictions Min            -9.137616
Log Pis Mean                 -0.28293085
Log Pis Std                  3.022465
Log Pis Max                  12.28484
Log Pis Min                  -7.1999474
Policy mu Mean               0.0061527938
Policy mu Std                0.5677491
Policy mu Max                2.3311477
Policy mu Min                -1.9247503
Policy log std Mean          -0.97557795
Policy log std Std           0.33097926
Policy log std Max           -0.006113887
Policy log std Min           -2.621955
Z mean eval                  0.89009905
Z variance eval              0.008862851
total_rewards                [3045.36902681 1377.62776909 3222.63979265 3112.86561522 3259.722879
 1304.02328496  258.71648773 1303.51530652 3101.4654974  3132.01359406]
total_rewards_mean           2311.795925343901
total_rewards_std            1064.1625854506358
total_rewards_max            3259.7228789993183
total_rewards_min            258.7164877283788
Number of train steps total  696000
Number of env steps total    872000
Number of rollouts total     0
Train Time (s)               115.70701627572998
(Previous) Eval Time (s)     23.241562496870756
Sample Time (s)              18.111377229448408
Epoch Time (s)               157.05995600204915
Total Train Time (s)         26559.528963310644
Epoch                        173
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:54:14.499474 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #173 | Epoch Duration: 157.07478189468384
2020-01-12 06:54:14.499741 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #173 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8900999
Z variance train             0.00885864
KL Divergence                22.40518
KL Loss                      2.240518
QF Loss                      554.84283
VF Loss                      238.38495
Policy Loss                  -1064.7448
Q Predictions Mean           1061.7031
Q Predictions Std            329.93414
Q Predictions Max            1323.3907
Q Predictions Min            -6.0263524
V Predictions Mean           1062.8655
V Predictions Std            321.49527
V Predictions Max            1320.6333
V Predictions Min            47.002617
Log Pis Mean                 0.11947183
Log Pis Std                  2.9823968
Log Pis Max                  13.881528
Log Pis Min                  -8.895698
Policy mu Mean               -0.025928669
Policy mu Std                0.657015
Policy mu Max                2.5200298
Policy mu Min                -2.5430458
Policy log std Mean          -0.93090045
Policy log std Std           0.29254532
Policy log std Max           -0.039925694
Policy log std Min           -2.5875134
Z mean eval                  0.9730611
Z variance eval              0.0055020577
total_rewards                [2869.31595925 2346.56335714  724.61597627 3296.87930963 3501.97484778
 3099.34609403 2920.79273331 1178.23965683  236.80021251 3298.8305442 ]
total_rewards_mean           2347.335869096495
total_rewards_std            1129.6622751938023
total_rewards_max            3501.974847780745
total_rewards_min            236.80021250642932
Number of train steps total  700000
Number of env steps total    877000
Number of rollouts total     0
Train Time (s)               118.61975817801431
(Previous) Eval Time (s)     23.256090010982007
Sample Time (s)              18.997891866602004
Epoch Time (s)               160.87374005559832
Total Train Time (s)         26718.68873112602
Epoch                        174
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:56:53.660728 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #174 | Epoch Duration: 159.1607813835144
2020-01-12 06:56:53.660907 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #174 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97039926
Z variance train             0.005479145
KL Divergence                22.632029
KL Loss                      2.263203
QF Loss                      691.11664
VF Loss                      114.576294
Policy Loss                  -1105.4595
Q Predictions Mean           1100.8796
Q Predictions Std            280.98404
Q Predictions Max            1375.4856
Q Predictions Min            75.26577
V Predictions Mean           1103.5436
V Predictions Std            275.31738
V Predictions Max            1363.1857
V Predictions Min            71.55239
Log Pis Mean                 -0.31567726
Log Pis Std                  2.9345357
Log Pis Max                  10.851349
Log Pis Min                  -9.73453
Policy mu Mean               0.00478932
Policy mu Std                0.630762
Policy mu Max                2.080803
Policy mu Min                -2.8526359
Policy log std Mean          -0.9459569
Policy log std Std           0.2847159
Policy log std Max           -0.1878615
Policy log std Min           -2.5714283
Z mean eval                  0.9004346
Z variance eval              0.010941906
total_rewards                [2803.81680042 2079.86215534 1286.74571526 3419.98355561 2085.08626375
 3279.19969013  295.0290554  3277.2651409  3401.50875374 2642.42506176]
total_rewards_mean           2457.092219230666
total_rewards_std            982.1971209987862
total_rewards_max            3419.9835556053904
total_rewards_min            295.02905539577444
Number of train steps total  704000
Number of env steps total    882000
Number of rollouts total     0
Train Time (s)               117.92808546638116
(Previous) Eval Time (s)     21.542816577944905
Sample Time (s)              18.124178951140493
Epoch Time (s)               157.59508099546656
Total Train Time (s)         26875.12472716812
Epoch                        175
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:59:30.100339 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #175 | Epoch Duration: 156.43928027153015
2020-01-12 06:59:30.100559 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #175 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90093213
Z variance train             0.011002789
KL Divergence                21.296404
KL Loss                      2.1296403
QF Loss                      640.8656
VF Loss                      95.53984
Policy Loss                  -1088.2098
Q Predictions Mean           1087.5477
Q Predictions Std            286.27957
Q Predictions Max            1319.376
Q Predictions Min            8.539263
V Predictions Mean           1089.1248
V Predictions Std            286.43082
V Predictions Max            1314.3427
V Predictions Min            -1.5497046
Log Pis Mean                 0.004869491
Log Pis Std                  2.8844175
Log Pis Max                  8.258102
Log Pis Min                  -7.790699
Policy mu Mean               -0.018573225
Policy mu Std                0.63544446
Policy mu Max                2.6420708
Policy mu Min                -2.0826223
Policy log std Mean          -0.94873106
Policy log std Std           0.26838297
Policy log std Max           -0.20513362
Policy log std Min           -2.7546816
Z mean eval                  0.89633465
Z variance eval              0.010967459
total_rewards                [1779.10975052 3255.59207038 2861.86737399 1612.49902765 3013.67120668
 1411.73620044 3096.99682128  338.03333554 3173.93865414  138.98499602]
total_rewards_mean           2068.2429436657667
total_rewards_std            1124.8258963662831
total_rewards_max            3255.592070382502
total_rewards_min            138.98499601747903
Number of train steps total  708000
Number of env steps total    887000
Number of rollouts total     0
Train Time (s)               109.56113001005724
(Previous) Eval Time (s)     20.386677498929203
Sample Time (s)              18.441385813523084
Epoch Time (s)               148.38919332250953
Total Train Time (s)         27023.008708993904
Epoch                        176
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:01:57.985429 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #176 | Epoch Duration: 147.8847177028656
2020-01-12 07:01:57.985584 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #176 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8959444
Z variance train             0.010981626
KL Divergence                21.043839
KL Loss                      2.104384
QF Loss                      906.41943
VF Loss                      298.1464
Policy Loss                  -1040.6061
Q Predictions Mean           1039.2734
Q Predictions Std            341.40604
Q Predictions Max            1315.3049
Q Predictions Min            -25.074938
V Predictions Mean           1029.7733
V Predictions Std            340.19516
V Predictions Max            1315.9662
V Predictions Min            21.445658
Log Pis Mean                 0.029852413
Log Pis Std                  3.2300212
Log Pis Max                  18.456312
Log Pis Min                  -8.891022
Policy mu Mean               0.047604937
Policy mu Std                0.6246986
Policy mu Max                2.258708
Policy mu Min                -2.531249
Policy log std Mean          -0.96379447
Policy log std Std           0.3004092
Policy log std Max           -0.18967581
Policy log std Min           -2.2209082
Z mean eval                  0.91888607
Z variance eval              0.007767917
total_rewards                [1834.03647092 3309.15247718  413.43231897 3416.56878034 3410.21194835
 3145.03087215 3326.58034253 3276.54678247 3259.19821812 3220.33178255]
total_rewards_mean           2861.108999359163
total_rewards_std            928.1256096124798
total_rewards_max            3416.5687803423843
total_rewards_min            413.43231896507797
Number of train steps total  712000
Number of env steps total    892000
Number of rollouts total     0
Train Time (s)               116.02928036404774
(Previous) Eval Time (s)     19.881860442925245
Sample Time (s)              17.66809302009642
Epoch Time (s)               153.5792338270694
Total Train Time (s)         27181.69382513594
Epoch                        177
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:04:36.674104 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #177 | Epoch Duration: 158.68837594985962
2020-01-12 07:04:36.674333 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #177 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91968095
Z variance train             0.0077513955
KL Divergence                22.376795
KL Loss                      2.2376795
QF Loss                      1291.7393
VF Loss                      287.54132
Policy Loss                  -1084.302
Q Predictions Mean           1078.6399
Q Predictions Std            297.27844
Q Predictions Max            1335.3645
Q Predictions Min            48.541435
V Predictions Mean           1085.6191
V Predictions Std            291.51987
V Predictions Max            1329.6094
V Predictions Min            62.699406
Log Pis Mean                 0.57101023
Log Pis Std                  3.0121028
Log Pis Max                  16.318207
Log Pis Min                  -6.5941725
Policy mu Mean               0.0075439503
Policy mu Std                0.63134813
Policy mu Max                2.1773496
Policy mu Min                -2.088734
Policy log std Mean          -1.0069587
Policy log std Std           0.34007835
Policy log std Max           -0.16615444
Policy log std Min           -2.8400996
Z mean eval                  0.8966605
Z variance eval              0.005960401
total_rewards                [2945.38896683 3281.35537834 3355.18096723 1850.33700376 2583.76538568
 3286.56075764 3221.7224533  3324.30885322 1307.27817645  863.37130107]
total_rewards_mean           2601.926924353698
total_rewards_std            882.3601743202619
total_rewards_max            3355.1809672348522
total_rewards_min            863.371301071842
Number of train steps total  716000
Number of env steps total    897000
Number of rollouts total     0
Train Time (s)               109.16837406810373
(Previous) Eval Time (s)     24.990683656185865
Sample Time (s)              17.7965183458291
Epoch Time (s)               151.9555760701187
Total Train Time (s)         27330.929855545517
Epoch                        178
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:07:05.911125 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #178 | Epoch Duration: 149.2366282939911
2020-01-12 07:07:05.911307 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #178 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8967358
Z variance train             0.0059526893
KL Divergence                22.716602
KL Loss                      2.2716603
QF Loss                      621.3046
VF Loss                      190.9141
Policy Loss                  -1080.8344
Q Predictions Mean           1080.1111
Q Predictions Std            294.67178
Q Predictions Max            1317.979
Q Predictions Min            -12.753533
V Predictions Mean           1080.7009
V Predictions Std            293.31274
V Predictions Max            1314.6658
V Predictions Min            4.018502
Log Pis Mean                 0.49128002
Log Pis Std                  2.9986355
Log Pis Max                  11.208744
Log Pis Min                  -6.988112
Policy mu Mean               0.046998955
Policy mu Std                0.657471
Policy mu Max                3.3808787
Policy mu Min                -1.9952964
Policy log std Mean          -1.0101043
Policy log std Std           0.29930478
Policy log std Max           0.051372528
Policy log std Min           -2.7140908
Z mean eval                  0.9359455
Z variance eval              0.004966557
total_rewards                [1046.27113532 3418.98797276 3193.5357697   113.44483238  985.75553614
 1341.01945329  778.69031071 3289.46110176  574.87300148 3411.34212238]
total_rewards_mean           1815.3381235908241
total_rewards_std            1273.0228432385038
total_rewards_max            3418.9879727562225
total_rewards_min            113.4448323785997
Number of train steps total  720000
Number of env steps total    902000
Number of rollouts total     0
Train Time (s)               114.23524493398145
(Previous) Eval Time (s)     22.271451078820974
Sample Time (s)              18.458800272084773
Epoch Time (s)               154.9654962848872
Total Train Time (s)         27482.693271744065
Epoch                        179
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:09:37.677009 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #179 | Epoch Duration: 151.76556873321533
2020-01-12 07:09:37.677241 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #179 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9355769
Z variance train             0.0049644546
KL Divergence                22.80457
KL Loss                      2.280457
QF Loss                      1407.2195
VF Loss                      373.60645
Policy Loss                  -1109.8743
Q Predictions Mean           1110.4015
Q Predictions Std            278.62173
Q Predictions Max            1358.9497
Q Predictions Min            -31.882532
V Predictions Mean           1110.5554
V Predictions Std            274.57416
V Predictions Max            1348.0276
V Predictions Min            -33.204235
Log Pis Mean                 0.0014713854
Log Pis Std                  3.111768
Log Pis Max                  17.344482
Log Pis Min                  -9.26473
Policy mu Mean               -0.02799175
Policy mu Std                0.6095683
Policy mu Max                2.535792
Policy mu Min                -2.3652802
Policy log std Mean          -0.9797225
Policy log std Std           0.29710072
Policy log std Max           -0.22872394
Policy log std Min           -2.8153615
Z mean eval                  0.9541237
Z variance eval              0.004728846
total_rewards                [3127.67202457  294.42632426 3398.04693359 3180.49503221 3353.53200861
 3465.23153517 3166.91358533 3158.8133724  3284.8295697  3027.88793194]
total_rewards_mean           2945.7848317772277
total_rewards_std            892.9988101469954
total_rewards_max            3465.231535172651
total_rewards_min            294.42632425708
Number of train steps total  724000
Number of env steps total    907000
Number of rollouts total     0
Train Time (s)               117.5231990092434
(Previous) Eval Time (s)     19.071162753738463
Sample Time (s)              17.724777535069734
Epoch Time (s)               154.3191392980516
Total Train Time (s)         27644.706246234942
Epoch                        180
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:12:19.691433 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #180 | Epoch Duration: 162.01406145095825
2020-01-12 07:12:19.691596 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #180 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95385236
Z variance train             0.0047197617
KL Divergence                22.90287
KL Loss                      2.290287
QF Loss                      693.48004
VF Loss                      226.45734
Policy Loss                  -1091.0354
Q Predictions Mean           1091.2988
Q Predictions Std            299.72284
Q Predictions Max            1344.0128
Q Predictions Min            27.683594
V Predictions Mean           1092.8066
V Predictions Std            296.62625
V Predictions Max            1338.5332
V Predictions Min            66.3952
Log Pis Mean                 0.359173
Log Pis Std                  3.1744814
Log Pis Max                  14.452976
Log Pis Min                  -7.419787
Policy mu Mean               0.04499011
Policy mu Std                0.62966
Policy mu Max                2.079826
Policy mu Min                -2.543986
Policy log std Mean          -0.98628753
Policy log std Std           0.3173537
Policy log std Max           -0.1175434
Policy log std Min           -2.469627
Z mean eval                  0.9431572
Z variance eval              0.005587764
total_rewards                [ 396.71296954 1358.74571828 3183.54378734 3516.54937905 2383.8201423
 3351.12322192 3256.34566328 2448.05776188 3375.60996058  256.01723127]
total_rewards_mean           2352.652583542814
total_rewards_std            1188.469037546299
total_rewards_max            3516.5493790463106
total_rewards_min            256.01723126632953
Number of train steps total  728000
Number of env steps total    912000
Number of rollouts total     0
Train Time (s)               119.77115766704082
(Previous) Eval Time (s)     26.76579038007185
Sample Time (s)              17.88761651236564
Epoch Time (s)               164.4245645594783
Total Train Time (s)         27801.958186864387
Epoch                        181
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:14:56.945077 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #181 | Epoch Duration: 157.2533621788025
2020-01-12 07:14:56.945224 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #181 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94238967
Z variance train             0.0055778744
KL Divergence                22.36635
KL Loss                      2.236635
QF Loss                      470.61945
VF Loss                      121.8043
Policy Loss                  -1079.727
Q Predictions Mean           1080.457
Q Predictions Std            324.84833
Q Predictions Max            1316.2969
Q Predictions Min            20.52806
V Predictions Mean           1081.4723
V Predictions Std            324.66602
V Predictions Max            1320.2656
V Predictions Min            47.98821
Log Pis Mean                 -0.16886465
Log Pis Std                  2.9402943
Log Pis Max                  9.631035
Log Pis Min                  -7.892989
Policy mu Mean               0.020243011
Policy mu Std                0.5958796
Policy mu Max                2.4978366
Policy mu Min                -2.155919
Policy log std Mean          -0.96627057
Policy log std Std           0.2936571
Policy log std Max           -0.19524783
Policy log std Min           -2.6987805
Z mean eval                  0.9414233
Z variance eval              0.005821711
total_rewards                [ 733.86713894 3502.41286976 3422.78710939 1478.23423654 2041.31796581
 1363.00289429 3621.54006705 3479.14782366 3282.63777152 2239.64246905]
total_rewards_mean           2516.4590346001432
total_rewards_std            1020.6336906840558
total_rewards_max            3621.540067051259
total_rewards_min            733.8671389435206
Number of train steps total  732000
Number of env steps total    917000
Number of rollouts total     0
Train Time (s)               119.97100193845108
(Previous) Eval Time (s)     19.59426993317902
Sample Time (s)              17.62036097748205
Epoch Time (s)               157.18563284911215
Total Train Time (s)         27964.134371222463
Epoch                        182
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:17:39.125024 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #182 | Epoch Duration: 162.17967176437378
2020-01-12 07:17:39.125236 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #182 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94171554
Z variance train             0.005811712
KL Divergence                22.61556
KL Loss                      2.2615561
QF Loss                      965.5129
VF Loss                      339.10428
Policy Loss                  -1123.5754
Q Predictions Mean           1122.0217
Q Predictions Std            268.2434
Q Predictions Max            1358.8351
Q Predictions Min            58.33618
V Predictions Mean           1119.2656
V Predictions Std            270.87823
V Predictions Max            1357.0172
V Predictions Min            23.11412
Log Pis Mean                 0.00204641
Log Pis Std                  3.0281723
Log Pis Max                  17.276443
Log Pis Min                  -6.8884554
Policy mu Mean               0.024333801
Policy mu Std                0.63541967
Policy mu Max                3.1254015
Policy mu Min                -2.8086054
Policy log std Mean          -0.9752567
Policy log std Std           0.28707835
Policy log std Max           -0.10505557
Policy log std Min           -2.5411553
Z mean eval                  0.9115884
Z variance eval              0.0059150746
total_rewards                [3338.43074076 -110.69309436  -32.33691955  699.7990518   855.13505892
 3351.55532054 3187.3485816  2317.3794553  2363.88688117 3317.29272229]
total_rewards_mean           1928.7797798472598
total_rewards_std            1361.3314261496928
total_rewards_max            3351.5553205401047
total_rewards_min            -110.6930943648266
Number of train steps total  736000
Number of env steps total    922000
Number of rollouts total     0
Train Time (s)               121.75909913610667
(Previous) Eval Time (s)     24.58793991804123
Sample Time (s)              17.754507201258093
Epoch Time (s)               164.101546255406
Total Train Time (s)         28127.733854298014
Epoch                        183
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:20:22.727557 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #183 | Epoch Duration: 163.60215163230896
2020-01-12 07:20:22.727785 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #183 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9129054
Z variance train             0.0059263175
KL Divergence                22.420277
KL Loss                      2.2420278
QF Loss                      995.42426
VF Loss                      1097.3362
Policy Loss                  -1095.6036
Q Predictions Mean           1092.2144
Q Predictions Std            291.72116
Q Predictions Max            1319.5613
Q Predictions Min            46.32053
V Predictions Mean           1090.417
V Predictions Std            284.99384
V Predictions Max            1308.624
V Predictions Min            50.51673
Log Pis Mean                 0.2087166
Log Pis Std                  2.8457963
Log Pis Max                  10.831987
Log Pis Min                  -9.325295
Policy mu Mean               0.03987851
Policy mu Std                0.6311761
Policy mu Max                2.740284
Policy mu Min                -1.8716455
Policy log std Mean          -0.97563565
Policy log std Std           0.28873777
Policy log std Max           0.032391787
Policy log std Min           -2.8409836
Z mean eval                  0.93999547
Z variance eval              0.0049696774
total_rewards                [  48.47199831  -21.20323213 3286.90756491 1374.8109342  3120.85106655
 1027.6334001  3350.41918609 1112.13593289 1671.49215218 3253.54392421]
total_rewards_mean           1822.5062927311465
total_rewards_std            1269.594604910809
total_rewards_max            3350.419186090062
total_rewards_min            -21.203232132086995
Number of train steps total  740000
Number of env steps total    927000
Number of rollouts total     0
Train Time (s)               116.71165034081787
(Previous) Eval Time (s)     24.088210529182106
Sample Time (s)              17.973264588043094
Epoch Time (s)               158.77312545804307
Total Train Time (s)         28281.11596102547
Epoch                        184
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:22:56.110331 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #184 | Epoch Duration: 153.38237357139587
2020-01-12 07:22:56.110500 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #184 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93947875
Z variance train             0.0049609235
KL Divergence                22.907291
KL Loss                      2.2907293
QF Loss                      803.1101
VF Loss                      160.96461
Policy Loss                  -1050.2891
Q Predictions Mean           1048.394
Q Predictions Std            349.52176
Q Predictions Max            1351.8124
Q Predictions Min            18.241568
V Predictions Mean           1054.0015
V Predictions Std            343.29874
V Predictions Max            1351.516
V Predictions Min            -11.634004
Log Pis Mean                 -0.083677344
Log Pis Std                  3.0382402
Log Pis Max                  9.906242
Log Pis Min                  -7.4134674
Policy mu Mean               -0.020500358
Policy mu Std                0.6050906
Policy mu Max                2.7095208
Policy mu Min                -2.817512
Policy log std Mean          -0.96622276
Policy log std Std           0.32087973
Policy log std Max           -0.066093326
Policy log std Min           -2.7934537
Z mean eval                  0.9341794
Z variance eval              0.006674315
total_rewards                [1029.15644951 2659.92472691   19.52395585 1055.98259353  380.51279608
 1523.39404238   84.70632284 1449.9403254  1479.48628767 1587.23891001]
total_rewards_mean           1126.9866410179145
total_rewards_std            763.6807330477438
total_rewards_max            2659.924726908851
total_rewards_min            19.523955853944088
Number of train steps total  744000
Number of env steps total    932000
Number of rollouts total     0
Train Time (s)               118.46219341130927
(Previous) Eval Time (s)     18.69712810125202
Sample Time (s)              18.07909211749211
Epoch Time (s)               155.2384136300534
Total Train Time (s)         28430.183266456705
Epoch                        185
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:25:25.179400 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #185 | Epoch Duration: 149.06875920295715
2020-01-12 07:25:25.179602 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #185 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93102515
Z variance train             0.0066810837
KL Divergence                22.110214
KL Loss                      2.2110214
QF Loss                      635.7345
VF Loss                      267.6494
Policy Loss                  -1093.3657
Q Predictions Mean           1095.801
Q Predictions Std            308.3972
Q Predictions Max            1356.0507
Q Predictions Min            35.731644
V Predictions Mean           1099.7781
V Predictions Std            304.99854
V Predictions Max            1361.6047
V Predictions Min            51.952908
Log Pis Mean                 0.11644721
Log Pis Std                  3.0869367
Log Pis Max                  10.702826
Log Pis Min                  -9.896805
Policy mu Mean               0.009220837
Policy mu Std                0.6469723
Policy mu Max                2.5571704
Policy mu Min                -2.598125
Policy log std Mean          -0.9717653
Policy log std Std           0.311036
Policy log std Max           -0.044239998
Policy log std Min           -2.7434416
Z mean eval                  0.9179224
Z variance eval              0.00892128
total_rewards                [3379.86068043   74.90414869 3009.31288341 1682.51212108 3378.17423466
  630.04561932 1980.15145964 1547.36791487 3167.75295991 1574.34224883]
total_rewards_mean           2042.4424270835611
total_rewards_std            1106.2435301333953
total_rewards_max            3379.8606804275605
total_rewards_min            74.90414868911229
Number of train steps total  748000
Number of env steps total    937000
Number of rollouts total     0
Train Time (s)               113.79513260675594
(Previous) Eval Time (s)     12.527149846311659
Sample Time (s)              17.288882687687874
Epoch Time (s)               143.61116514075547
Total Train Time (s)         28580.62457845779
Epoch                        186
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:27:55.624010 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #186 | Epoch Duration: 150.44424867630005
2020-01-12 07:27:55.624248 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #186 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91770923
Z variance train             0.008913631
KL Divergence                21.945007
KL Loss                      2.1945007
QF Loss                      641.60846
VF Loss                      549.23975
Policy Loss                  -1123.3724
Q Predictions Mean           1121.235
Q Predictions Std            269.89407
Q Predictions Max            1353.2334
Q Predictions Min            69.748665
V Predictions Mean           1119.3593
V Predictions Std            267.7276
V Predictions Max            1339.5162
V Predictions Min            72.83601
Log Pis Mean                 0.5284307
Log Pis Std                  3.333957
Log Pis Max                  11.692076
Log Pis Min                  -8.962332
Policy mu Mean               0.036205433
Policy mu Std                0.6363505
Policy mu Max                2.821253
Policy mu Min                -1.9656516
Policy log std Mean          -1.0107076
Policy log std Std           0.310627
Policy log std Max           -0.21243691
Policy log std Min           -2.5312238
Z mean eval                  0.9243671
Z variance eval              0.008712059
total_rewards                [1988.86146599  923.63169362 3228.82773561 3095.97559714 1359.07812751
 3258.18675039 3229.4093771  3245.92041422 1126.2511746  3409.14864425]
total_rewards_mean           2486.5290980432655
total_rewards_std            964.8566748932006
total_rewards_max            3409.148644248578
total_rewards_min            923.6316936211665
Number of train steps total  752000
Number of env steps total    942000
Number of rollouts total     0
Train Time (s)               114.14385383808985
(Previous) Eval Time (s)     19.359956707339734
Sample Time (s)              19.031977494247258
Epoch Time (s)               152.53578803967685
Total Train Time (s)         28736.768738613
Epoch                        187
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:30:31.771526 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #187 | Epoch Duration: 156.14712119102478
2020-01-12 07:30:31.771753 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #187 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9237927
Z variance train             0.008714155
KL Divergence                21.482819
KL Loss                      2.1482818
QF Loss                      793.3046
VF Loss                      202.83527
Policy Loss                  -1083.2947
Q Predictions Mean           1080.8391
Q Predictions Std            308.5482
Q Predictions Max            1358.5691
Q Predictions Min            -23.577152
V Predictions Mean           1085.4783
V Predictions Std            304.41507
V Predictions Max            1350.8795
V Predictions Min            -2.8804407
Log Pis Mean                 0.29028592
Log Pis Std                  3.0721974
Log Pis Max                  17.190449
Log Pis Min                  -6.297348
Policy mu Mean               0.028179754
Policy mu Std                0.6175308
Policy mu Max                3.1653614
Policy mu Min                -2.6101334
Policy log std Mean          -1.0107157
Policy log std Std           0.3204556
Policy log std Max           -0.11155236
Policy log std Min           -2.7226837
Z mean eval                  0.92884016
Z variance eval              0.0057025277
total_rewards                [2438.20851967  991.20422786 2782.84308985 3205.67141522  585.83874354
 1478.42475689   66.55694978 3270.80684568  268.86749512 1868.12851318]
total_rewards_mean           1695.6550556780821
total_rewards_std            1139.700782202565
total_rewards_max            3270.8068456785777
total_rewards_min            66.55694978208732
Number of train steps total  756000
Number of env steps total    947000
Number of rollouts total     0
Train Time (s)               111.93886242620647
(Previous) Eval Time (s)     22.970965520013124
Sample Time (s)              17.814832306001335
Epoch Time (s)               152.72466025222093
Total Train Time (s)         28882.95218052389
Epoch                        188
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:32:57.957726 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #188 | Epoch Duration: 146.18580627441406
2020-01-12 07:32:57.957917 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #188 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9266447
Z variance train             0.0057144193
KL Divergence                22.302479
KL Loss                      2.230248
QF Loss                      914.44226
VF Loss                      210.99385
Policy Loss                  -1081.2045
Q Predictions Mean           1080.8829
Q Predictions Std            334.5853
Q Predictions Max            1336.1115
Q Predictions Min            -47.097168
V Predictions Mean           1090.1106
V Predictions Std            332.42096
V Predictions Max            1345.2041
V Predictions Min            -10.072492
Log Pis Mean                 0.26664233
Log Pis Std                  3.2317526
Log Pis Max                  17.316708
Log Pis Min                  -9.0344715
Policy mu Mean               0.033916116
Policy mu Std                0.6252488
Policy mu Max                2.56942
Policy mu Min                -2.43541
Policy log std Mean          -0.9807936
Policy log std Std           0.34094083
Policy log std Max           0.3668226
Policy log std Min           -2.8170993
Z mean eval                  0.9187913
Z variance eval              0.007617954
total_rewards                [3307.0906352  3498.65631488  212.8506884   462.03908439 1309.55331829
 3320.23504127 3400.4161896   661.35023851  237.38605861 2061.46708104]
total_rewards_mean           1847.1044650186348
total_rewards_std            1355.1156649316008
total_rewards_max            3498.6563148787463
total_rewards_min            212.85068839535
Number of train steps total  760000
Number of env steps total    952000
Number of rollouts total     0
Train Time (s)               117.36041407287121
(Previous) Eval Time (s)     16.431802624836564
Sample Time (s)              17.457715873606503
Epoch Time (s)               151.24993257131428
Total Train Time (s)         29036.857993535697
Epoch                        189
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:35:31.869637 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #189 | Epoch Duration: 153.91155004501343
2020-01-12 07:35:31.869928 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #189 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9185522
Z variance train             0.007631456
KL Divergence                20.826582
KL Loss                      2.0826583
QF Loss                      1809.6477
VF Loss                      919.4564
Policy Loss                  -1093.7008
Q Predictions Mean           1092.0087
Q Predictions Std            309.34177
Q Predictions Max            1351.4183
Q Predictions Min            6.581154
V Predictions Mean           1093.1486
V Predictions Std            313.37512
V Predictions Max            1360.9823
V Predictions Min            -30.597694
Log Pis Mean                 0.107334346
Log Pis Std                  3.175773
Log Pis Max                  11.524757
Log Pis Min                  -8.354345
Policy mu Mean               0.03309732
Policy mu Std                0.5995414
Policy mu Max                2.4833412
Policy mu Min                -3.1672473
Policy log std Mean          -0.99216306
Policy log std Std           0.32638034
Policy log std Max           0.09669232
Policy log std Min           -2.6167316
Z mean eval                  0.91888666
Z variance eval              0.01117214
total_rewards                [3338.91175558 2680.60742847 1993.70911935 2407.82205303 3315.29990365
  771.77646289 3316.34704808 1207.86286042 3324.99059489 2859.81279524]
total_rewards_mean           2521.714002158852
total_rewards_std            882.8414565758853
total_rewards_max            3338.911755580977
total_rewards_min            771.7764628858787
Number of train steps total  764000
Number of env steps total    957000
Number of rollouts total     0
Train Time (s)               118.18230309197679
(Previous) Eval Time (s)     19.093063895124942
Sample Time (s)              18.163551235105842
Epoch Time (s)               155.43891822220758
Total Train Time (s)         29194.448582073674
Epoch                        190
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:38:09.465249 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #190 | Epoch Duration: 157.59512424468994
2020-01-12 07:38:09.465443 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #190 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9221668
Z variance train             0.011186084
KL Divergence                20.477701
KL Loss                      2.0477703
QF Loss                      1093.0366
VF Loss                      222.71939
Policy Loss                  -1096.5167
Q Predictions Mean           1101.562
Q Predictions Std            317.07382
Q Predictions Max            1356.3121
Q Predictions Min            37.262074
V Predictions Mean           1103.4792
V Predictions Std            318.1546
V Predictions Max            1350.361
V Predictions Min            -6.2890887
Log Pis Mean                 0.37386522
Log Pis Std                  2.8794827
Log Pis Max                  14.025965
Log Pis Min                  -9.023917
Policy mu Mean               0.00037586177
Policy mu Std                0.6197259
Policy mu Max                2.5458472
Policy mu Min                -1.9877445
Policy log std Mean          -0.99481404
Policy log std Std           0.30184817
Policy log std Max           0.31229186
Policy log std Min           -2.4783459
Z mean eval                  0.93680465
Z variance eval              0.01477876
total_rewards                [ 421.01549981  313.39966385 3371.68165016  202.27166862 1501.52803573
 3231.73475477  898.75604996  989.56919065 2799.57022611 3287.123785  ]
total_rewards_mean           1701.665052465371
total_rewards_std            1259.2246299613857
total_rewards_max            3371.681650160339
total_rewards_min            202.27166862180692
Number of train steps total  768000
Number of env steps total    962000
Number of rollouts total     0
Train Time (s)               110.70500464830548
(Previous) Eval Time (s)     21.248958209063858
Sample Time (s)              18.686858010012656
Epoch Time (s)               150.640820867382
Total Train Time (s)         29344.40827992838
Epoch                        191
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:40:39.429713 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #191 | Epoch Duration: 149.96409487724304
2020-01-12 07:40:39.429993 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #191 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9367654
Z variance train             0.014826456
KL Divergence                20.270449
KL Loss                      2.027045
QF Loss                      832.8512
VF Loss                      162.89124
Policy Loss                  -1119.0446
Q Predictions Mean           1117.6418
Q Predictions Std            312.93262
Q Predictions Max            1403.795
Q Predictions Min            -12.490628
V Predictions Mean           1126.3768
V Predictions Std            313.1965
V Predictions Max            1408.5321
V Predictions Min            -7.899958
Log Pis Mean                 -0.17258418
Log Pis Std                  2.869568
Log Pis Max                  7.5475254
Log Pis Min                  -10.185174
Policy mu Mean               -0.00059725065
Policy mu Std                0.63303703
Policy mu Max                2.4120374
Policy mu Min                -2.1734195
Policy log std Mean          -0.94443536
Policy log std Std           0.28856146
Policy log std Max           -0.20535088
Policy log std Min           -2.6541963
Z mean eval                  0.91309106
Z variance eval              0.008831195
total_rewards                [2380.4405752  3593.87081492 3454.05329609 3453.16952572 3525.16970321
 2103.01444157 1734.47547389 3459.77959326 1997.05913983 3520.7648299 ]
total_rewards_mean           2922.179739358623
total_rewards_std            725.1155630352904
total_rewards_max            3593.870814919921
total_rewards_min            1734.4754738937543
Number of train steps total  772000
Number of env steps total    967000
Number of rollouts total     0
Train Time (s)               119.25380186876282
(Previous) Eval Time (s)     20.571871590800583
Sample Time (s)              18.482352687045932
Epoch Time (s)               158.30802614660934
Total Train Time (s)         29504.170243793167
Epoch                        192
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:43:19.196179 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #192 | Epoch Duration: 159.7659730911255
2020-01-12 07:43:19.196443 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #192 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9145414
Z variance train             0.008825448
KL Divergence                21.716572
KL Loss                      2.1716573
QF Loss                      892.25775
VF Loss                      124.83811
Policy Loss                  -1124.9604
Q Predictions Mean           1123.2769
Q Predictions Std            288.74747
Q Predictions Max            1358.2942
Q Predictions Min            40.599728
V Predictions Mean           1122.72
V Predictions Std            286.51807
V Predictions Max            1359.0928
V Predictions Min            28.358387
Log Pis Mean                 0.25247115
Log Pis Std                  2.6682107
Log Pis Max                  7.851052
Log Pis Min                  -9.8706665
Policy mu Mean               0.020648643
Policy mu Std                0.6209895
Policy mu Max                2.4452736
Policy mu Min                -1.878839
Policy log std Mean          -0.9867976
Policy log std Std           0.30752614
Policy log std Max           0.26130748
Policy log std Min           -2.9587314
Z mean eval                  0.97309506
Z variance eval              0.0057393373
total_rewards                [ 677.03819966 1031.61851188  803.40993861 3348.2090251  3176.28915232
 1818.99142977  656.55481682  846.83559559 3419.29741901 1141.43023207]
total_rewards_mean           1691.9674320834117
total_rewards_std            1108.6589168568635
total_rewards_max            3419.297419013145
total_rewards_min            656.5548168210171
Number of train steps total  776000
Number of env steps total    972000
Number of rollouts total     0
Train Time (s)               117.74985690321773
(Previous) Eval Time (s)     22.02945019165054
Sample Time (s)              18.186706125736237
Epoch Time (s)               157.9660132206045
Total Train Time (s)         29656.413285832852
Epoch                        193
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:45:51.443014 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #193 | Epoch Duration: 152.2463481426239
2020-01-12 07:45:51.443301 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #193 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9705782
Z variance train             0.005751206
KL Divergence                21.516365
KL Loss                      2.1516366
QF Loss                      1036.6316
VF Loss                      221.43651
Policy Loss                  -1101.4551
Q Predictions Mean           1100.2881
Q Predictions Std            332.625
Q Predictions Max            1367.8812
Q Predictions Min            -113.00239
V Predictions Mean           1102.0677
V Predictions Std            327.47095
V Predictions Max            1361.093
V Predictions Min            -37.63896
Log Pis Mean                 -0.1803492
Log Pis Std                  3.112184
Log Pis Max                  15.29295
Log Pis Min                  -11.844107
Policy mu Mean               0.033712536
Policy mu Std                0.60358363
Policy mu Max                2.5173583
Policy mu Min                -2.1731393
Policy log std Mean          -0.9805196
Policy log std Std           0.29773146
Policy log std Max           -0.29449207
Policy log std Min           -2.774448
Z mean eval                  0.94821346
Z variance eval              0.004852108
total_rewards                [ 799.02347606 3426.85072638 3449.05368063 3460.94794365 3057.06960393
  669.84414525 3428.60600216 3556.62801016 3442.99751575  503.75380753]
total_rewards_mean           2579.4774911497443
total_rewards_std            1265.9440176478222
total_rewards_max            3556.6280101584193
total_rewards_min            503.7538075301908
Number of train steps total  780000
Number of env steps total    977000
Number of rollouts total     0
Train Time (s)               117.03867546003312
(Previous) Eval Time (s)     16.309442576020956
Sample Time (s)              18.67158563854173
Epoch Time (s)               152.0197036745958
Total Train Time (s)         29815.76863996638
Epoch                        194
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:48:30.799746 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #194 | Epoch Duration: 159.35624408721924
2020-01-12 07:48:30.799950 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #194 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94598997
Z variance train             0.0048524635
KL Divergence                21.560753
KL Loss                      2.1560752
QF Loss                      1741.3083
VF Loss                      958.709
Policy Loss                  -1107.0371
Q Predictions Mean           1109.2599
Q Predictions Std            314.74255
Q Predictions Max            1389.3727
Q Predictions Min            63.846622
V Predictions Mean           1108.5101
V Predictions Std            308.2356
V Predictions Max            1385.946
V Predictions Min            60.370583
Log Pis Mean                 0.1740824
Log Pis Std                  3.1586304
Log Pis Max                  12.155064
Log Pis Min                  -7.378984
Policy mu Mean               0.0125899315
Policy mu Std                0.61432314
Policy mu Max                2.4287674
Policy mu Min                -2.0031493
Policy log std Mean          -1.0052209
Policy log std Std           0.30776668
Policy log std Max           -0.15108144
Policy log std Min           -2.3189921
Z mean eval                  0.90159166
Z variance eval              0.0044811796
total_rewards                [1142.65854534  114.36156431 3587.49503818  355.88113736  329.28540151
 2444.62578825 3299.97836378  -83.47068498 3452.02017376 3586.97980698]
total_rewards_mean           1822.9815134510566
total_rewards_std            1511.5296642916608
total_rewards_max            3587.4950381820454
total_rewards_min            -83.47068497521023
Number of train steps total  784000
Number of env steps total    982000
Number of rollouts total     0
Train Time (s)               117.62007324397564
(Previous) Eval Time (s)     23.645687356125563
Sample Time (s)              17.935582081321627
Epoch Time (s)               159.20134268142283
Total Train Time (s)         29970.94199121045
Epoch                        195
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:51:05.976506 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #195 | Epoch Duration: 155.17640471458435
2020-01-12 07:51:05.976749 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #195 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9018135
Z variance train             0.0044815307
KL Divergence                22.0421
KL Loss                      2.20421
QF Loss                      637.56525
VF Loss                      281.686
Policy Loss                  -1121.6797
Q Predictions Mean           1119.4639
Q Predictions Std            305.69058
Q Predictions Max            1350.5721
Q Predictions Min            -14.704415
V Predictions Mean           1122.0137
V Predictions Std            299.62354
V Predictions Max            1348.7687
V Predictions Min            -10.839465
Log Pis Mean                 0.09393242
Log Pis Std                  2.967795
Log Pis Max                  8.699257
Log Pis Min                  -7.0020766
Policy mu Mean               0.021343783
Policy mu Std                0.6091561
Policy mu Max                2.6209917
Policy mu Min                -2.1143014
Policy log std Mean          -1.004843
Policy log std Std           0.30872566
Policy log std Max           -0.026916742
Policy log std Min           -2.398332
Z mean eval                  0.9398448
Z variance eval              0.0042568548
total_rewards                [3008.82640667 1031.87305768 3061.91410982 3233.97114889 3218.16159221
 3210.79179807 3225.91438798 1262.90735235 3382.24360538 3003.2283914 ]
total_rewards_mean           2763.9831850441456
total_rewards_std            817.4236654680498
total_rewards_max            3382.243605379694
total_rewards_min            1031.8730576751664
Number of train steps total  788000
Number of env steps total    987000
Number of rollouts total     0
Train Time (s)               117.7130132317543
(Previous) Eval Time (s)     19.62042441405356
Sample Time (s)              17.70545864989981
Epoch Time (s)               155.03889629570767
Total Train Time (s)         30129.83238991117
Epoch                        196
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:53:44.871130 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #196 | Epoch Duration: 158.89419531822205
2020-01-12 07:53:44.871384 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #196 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93857926
Z variance train             0.0042650653
KL Divergence                22.74714
KL Loss                      2.2747142
QF Loss                      1230.2802
VF Loss                      206.80162
Policy Loss                  -1118.6055
Q Predictions Mean           1119.7559
Q Predictions Std            313.60858
Q Predictions Max            1382.3911
Q Predictions Min            36.57914
V Predictions Mean           1118.8292
V Predictions Std            313.0415
V Predictions Max            1370.9906
V Predictions Min            0.37680888
Log Pis Mean                 0.10353379
Log Pis Std                  2.9335232
Log Pis Max                  10.4744005
Log Pis Min                  -7.471645
Policy mu Mean               0.0058182855
Policy mu Std                0.624112
Policy mu Max                2.821553
Policy mu Min                -2.6369398
Policy log std Mean          -0.98059475
Policy log std Std           0.3030901
Policy log std Max           -0.1502502
Policy log std Min           -2.4555173
Z mean eval                  0.9502722
Z variance eval              0.0052855415
total_rewards                [3066.86471225 2167.45618153 3163.14968999 3221.43667629 3308.53291589
 1152.80404385 3057.93162652 3241.70848594  594.92745266 1284.50406478]
total_rewards_mean           2425.9315849697296
total_rewards_std            988.6410601853054
total_rewards_max            3308.5329158894638
total_rewards_min            594.9274526618949
Number of train steps total  792000
Number of env steps total    992000
Number of rollouts total     0
Train Time (s)               115.76327255321667
(Previous) Eval Time (s)     23.475424551870674
Sample Time (s)              18.78430206468329
Epoch Time (s)               158.02299916977063
Total Train Time (s)         30288.245102772955
Epoch                        197
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:56:23.284362 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #197 | Epoch Duration: 158.41281127929688
2020-01-12 07:56:23.284553 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #197 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.950432
Z variance train             0.0052846815
KL Divergence                22.835045
KL Loss                      2.2835045
QF Loss                      2168.6323
VF Loss                      161.72018
Policy Loss                  -1088.1277
Q Predictions Mean           1085.7622
Q Predictions Std            351.62866
Q Predictions Max            1367.1965
Q Predictions Min            -67.69625
V Predictions Mean           1088.543
V Predictions Std            346.2186
V Predictions Max            1361.9594
V Predictions Min            18.182962
Log Pis Mean                 0.021137
Log Pis Std                  3.0419595
Log Pis Max                  11.769355
Log Pis Min                  -8.812528
Policy mu Mean               0.056660537
Policy mu Std                0.6174171
Policy mu Max                3.687024
Policy mu Min                -2.2958932
Policy log std Mean          -0.9490305
Policy log std Std           0.2879118
Policy log std Max           0.93046165
Policy log std Min           -2.1680102
Z mean eval                  0.9204628
Z variance eval              0.009860405
total_rewards                [ 240.3963398  3226.8388083  3340.6463093  3448.87056572 2250.25417182
 3220.93126422 3538.5408727  3334.89766726 1711.85475589 2240.17954859]
total_rewards_mean           2655.3410303605715
total_rewards_std            1002.3099462436971
total_rewards_max            3538.5408727044105
total_rewards_min            240.3963398036152
Number of train steps total  796000
Number of env steps total    997000
Number of rollouts total     0
Train Time (s)               119.94951012684032
(Previous) Eval Time (s)     23.8649119050242
Sample Time (s)              19.204370520543307
Epoch Time (s)               163.01879255240783
Total Train Time (s)         30448.747899064794
Epoch                        198
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:59:03.795305 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #198 | Epoch Duration: 160.51059651374817
2020-01-12 07:59:03.795562 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #198 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91923296
Z variance train             0.009816734
KL Divergence                20.44147
KL Loss                      2.044147
QF Loss                      596.2977
VF Loss                      447.07175
Policy Loss                  -1165.2205
Q Predictions Mean           1162.2021
Q Predictions Std            233.60051
Q Predictions Max            1384.636
Q Predictions Min            44.587063
V Predictions Mean           1159.2156
V Predictions Std            233.61015
V Predictions Max            1381.9121
V Predictions Min            49.70677
Log Pis Mean                 0.23640166
Log Pis Std                  2.9594057
Log Pis Max                  12.245477
Log Pis Min                  -8.799312
Policy mu Mean               0.02173926
Policy mu Std                0.66011703
Policy mu Max                2.5863492
Policy mu Min                -2.1901913
Policy log std Mean          -0.98319453
Policy log std Std           0.2801881
Policy log std Max           -0.25865883
Policy log std Min           -2.3460884
Z mean eval                  0.9140688
Z variance eval              0.005982644
total_rewards                [2716.70279537  265.26241662 3239.85372311 3517.68067975 3151.0652902
 3244.36924575 3404.68169181 1146.1608655  3448.14692863 1184.93487701]
total_rewards_mean           2531.885851374394
total_rewards_std            1134.5299651472048
total_rewards_max            3517.6806797512972
total_rewards_min            265.262416615583
Number of train steps total  800000
Number of env steps total    1002000
Number of rollouts total     0
Train Time (s)               118.5019246400334
(Previous) Eval Time (s)     21.356325363274664
Sample Time (s)              19.43658437160775
Epoch Time (s)               159.2948343749158
Total Train Time (s)         30607.559831454884
Epoch                        199
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:01:42.612437 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #199 | Epoch Duration: 158.8166708946228
2020-01-12 08:01:42.612728 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #199 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9148785
Z variance train             0.0059940736
KL Divergence                21.680525
KL Loss                      2.1680524
QF Loss                      3345.4326
VF Loss                      157.99803
Policy Loss                  -1095.3499
Q Predictions Mean           1094.6978
Q Predictions Std            343.24832
Q Predictions Max            1378.6731
Q Predictions Min            1.8404224
V Predictions Mean           1095.9663
V Predictions Std            340.72263
V Predictions Max            1377.0511
V Predictions Min            1.8886272
Log Pis Mean                 0.032330763
Log Pis Std                  2.7869513
Log Pis Max                  8.9656
Log Pis Min                  -7.4235296
Policy mu Mean               0.016036106
Policy mu Std                0.62010545
Policy mu Max                2.2341962
Policy mu Min                -1.9470756
Policy log std Mean          -0.9710585
Policy log std Std           0.29359308
Policy log std Max           -0.19571996
Policy log std Min           -2.4816155
Z mean eval                  0.97130984
Z variance eval              0.005632372
total_rewards                [3117.66186352 3254.89721268 3314.3282631  3493.6783582  1575.69762616
 3302.6069888  2002.73356809 3188.27702799 3047.24793487 3145.22694177]
total_rewards_mean           2944.2355785172495
total_rewards_std            596.9724301605888
total_rewards_max            3493.6783581967766
total_rewards_min            1575.6976261581185
Number of train steps total  804000
Number of env steps total    1007000
Number of rollouts total     0
Train Time (s)               118.89640721399337
(Previous) Eval Time (s)     20.877804751042277
Sample Time (s)              18.17141287913546
Epoch Time (s)               157.9456248441711
Total Train Time (s)         30769.138156084344
Epoch                        200
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:04:24.192254 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #200 | Epoch Duration: 161.5793333053589
2020-01-12 08:04:24.192447 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #200 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9707077
Z variance train             0.0056281914
KL Divergence                22.506506
KL Loss                      2.2506506
QF Loss                      599.4604
VF Loss                      1024.2141
Policy Loss                  -1126.7007
Q Predictions Mean           1123.5973
Q Predictions Std            318.23306
Q Predictions Max            1404.86
Q Predictions Min            18.00065
V Predictions Mean           1124.2715
V Predictions Std            318.2219
V Predictions Max            1403.9249
V Predictions Min            21.118341
Log Pis Mean                 0.19760025
Log Pis Std                  2.872046
Log Pis Max                  9.856094
Log Pis Min                  -9.02861
Policy mu Mean               0.0071608615
Policy mu Std                0.612317
Policy mu Max                2.8503933
Policy mu Min                -2.8023262
Policy log std Mean          -0.97364736
Policy log std Std           0.2909055
Policy log std Max           -0.066957235
Policy log std Min           -2.4611673
Z mean eval                  0.9403392
Z variance eval              0.0072644996
total_rewards                [1356.75845434  178.8687535  3403.99940039 3247.38929524 3248.70323372
 3489.76633849  736.2269749  3563.60065957 3162.39834102  637.95755403]
total_rewards_mean           2302.5669005194163
total_rewards_std            1317.913809735804
total_rewards_max            3563.600659565015
total_rewards_min            178.86875349526304
Number of train steps total  808000
Number of env steps total    1012000
Number of rollouts total     0
Train Time (s)               116.34388819010928
(Previous) Eval Time (s)     24.511178076267242
Sample Time (s)              18.15083462232724
Epoch Time (s)               159.00590088870376
Total Train Time (s)         30923.96306013828
Epoch                        201
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:06:59.018438 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #201 | Epoch Duration: 154.82586884498596
2020-01-12 08:06:59.018638 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #201 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94348586
Z variance train             0.0072508156
KL Divergence                21.891333
KL Loss                      2.1891334
QF Loss                      970.6989
VF Loss                      118.49249
Policy Loss                  -1116.1246
Q Predictions Mean           1116.4818
Q Predictions Std            317.54352
Q Predictions Max            1391.1246
Q Predictions Min            6.1328297
V Predictions Mean           1114.312
V Predictions Std            313.06253
V Predictions Max            1396.421
V Predictions Min            39.143
Log Pis Mean                 -0.10791925
Log Pis Std                  3.006925
Log Pis Max                  10.122912
Log Pis Min                  -6.3612356
Policy mu Mean               -0.013630367
Policy mu Std                0.6066251
Policy mu Max                2.4105027
Policy mu Min                -2.4314353
Policy log std Mean          -0.9798151
Policy log std Std           0.2978337
Policy log std Max           -0.24900538
Policy log std Min           -2.6491518
Z mean eval                  0.9473551
Z variance eval              0.007884954
total_rewards                [3.23788347e+00 2.63398929e+03 2.27809761e+03 1.59654334e+03
 3.34894545e+03 3.41215071e+03 1.42669051e+03 3.42307360e+03
 1.24424232e+03 6.74811270e+02]
total_rewards_mean           2004.1781992664244
total_rewards_std            1145.5951679116947
total_rewards_max            3423.0735951555926
total_rewards_min            3.2378834661948215
Number of train steps total  812000
Number of env steps total    1017000
Number of rollouts total     0
Train Time (s)               118.56947684288025
(Previous) Eval Time (s)     20.330802015028894
Sample Time (s)              18.387656597886235
Epoch Time (s)               157.28793545579538
Total Train Time (s)         31081.22442249814
Epoch                        202
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:09:36.282129 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #202 | Epoch Duration: 157.26335978507996
2020-01-12 08:09:36.282290 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #202 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94736654
Z variance train             0.007896113
KL Divergence                21.427412
KL Loss                      2.1427412
QF Loss                      4596.8027
VF Loss                      141.98503
Policy Loss                  -1130.7095
Q Predictions Mean           1131.4875
Q Predictions Std            299.6817
Q Predictions Max            1366.6693
Q Predictions Min            67.692894
V Predictions Mean           1130.3657
V Predictions Std            298.85834
V Predictions Max            1358.2795
V Predictions Min            23.121304
Log Pis Mean                 -0.09404439
Log Pis Std                  2.927396
Log Pis Max                  11.939497
Log Pis Min                  -7.321244
Policy mu Mean               -0.013653341
Policy mu Std                0.58512545
Policy mu Max                2.217169
Policy mu Min                -1.7618523
Policy log std Mean          -1.0003494
Policy log std Std           0.29632503
Policy log std Max           -0.27178717
Policy log std Min           -2.577754
Z mean eval                  0.9548931
Z variance eval              0.007183774
total_rewards                [3475.31927601 3522.24591905 3583.73599295 2063.42067988 3244.85084744
  334.25728547  461.54054539 3461.91177353 3478.70763312 1030.53580015]
total_rewards_mean           2465.652575298097
total_rewards_std            1295.860768867929
total_rewards_max            3583.735992950894
total_rewards_min            334.2572854652225
Number of train steps total  816000
Number of env steps total    1022000
Number of rollouts total     0
Train Time (s)               116.02322321385145
(Previous) Eval Time (s)     20.30588372424245
Sample Time (s)              17.955106548499316
Epoch Time (s)               154.28421348659322
Total Train Time (s)         31238.584012366366
Epoch                        203
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:12:13.647220 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #203 | Epoch Duration: 157.36477041244507
2020-01-12 08:12:13.647523 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #203 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9554043
Z variance train             0.0071916683
KL Divergence                22.314274
KL Loss                      2.2314274
QF Loss                      954.8479
VF Loss                      180.73659
Policy Loss                  -1171.0847
Q Predictions Mean           1170.2908
Q Predictions Std            222.30803
Q Predictions Max            1364.8717
Q Predictions Min            0.7184197
V Predictions Mean           1168.0194
V Predictions Std            219.33517
V Predictions Max            1356.2814
V Predictions Min            34.948727
Log Pis Mean                 0.23442365
Log Pis Std                  3.0165312
Log Pis Max                  17.632421
Log Pis Min                  -7.981133
Policy mu Mean               -0.011585721
Policy mu Std                0.64141905
Policy mu Max                2.7371163
Policy mu Min                -3.154694
Policy log std Mean          -0.9937906
Policy log std Std           0.29131228
Policy log std Max           0.27748597
Policy log std Min           -2.5970545
Z mean eval                  0.9509387
Z variance eval              0.007166557
total_rewards                [3320.63234099 3420.55640559 3369.07201029   36.44364936 2353.88874124
 3149.79645048 3245.53429322 2304.2045276  1174.28768121  849.95922947]
total_rewards_mean           2322.4375329454288
total_rewards_std            1163.9528410848195
total_rewards_max            3420.556405587343
total_rewards_min            36.443649357233255
Number of train steps total  820000
Number of env steps total    1027000
Number of rollouts total     0
Train Time (s)               114.79743294836953
(Previous) Eval Time (s)     23.386063186917454
Sample Time (s)              17.510561244096607
Epoch Time (s)               155.6940573793836
Total Train Time (s)         31392.13235135423
Epoch                        204
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:14:47.200596 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #204 | Epoch Duration: 153.5528120994568
2020-01-12 08:14:47.200937 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #204 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9513752
Z variance train             0.0071628042
KL Divergence                22.145329
KL Loss                      2.2145329
QF Loss                      777.05225
VF Loss                      191.77208
Policy Loss                  -1136.1768
Q Predictions Mean           1139.2996
Q Predictions Std            297.38528
Q Predictions Max            1382.5166
Q Predictions Min            -38.129913
V Predictions Mean           1132.9867
V Predictions Std            298.15128
V Predictions Max            1363.457
V Predictions Min            -31.210165
Log Pis Mean                 0.06471323
Log Pis Std                  3.4979494
Log Pis Max                  28.939375
Log Pis Min                  -6.4910107
Policy mu Mean               -0.0072392905
Policy mu Std                0.6377246
Policy mu Max                3.460002
Policy mu Min                -4.5267987
Policy log std Mean          -0.9838133
Policy log std Std           0.30718985
Policy log std Max           -0.21787137
Policy log std Min           -2.761279
Z mean eval                  0.92913043
Z variance eval              0.0038238976
total_rewards                [3217.7672153  3477.05593049 3369.87436225 3333.32883332 1334.01816683
 2883.34701304 3494.9533502   837.57973924 3407.35786846 3158.63083129]
total_rewards_mean           2851.391331042807
total_rewards_std            905.7219482507323
total_rewards_max            3494.9533501966052
total_rewards_min            837.5797392356267
Number of train steps total  824000
Number of env steps total    1032000
Number of rollouts total     0
Train Time (s)               117.89624225487933
(Previous) Eval Time (s)     21.244524616282433
Sample Time (s)              18.999868685379624
Epoch Time (s)               158.14063555654138
Total Train Time (s)         31552.21744956076
Epoch                        205
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:17:27.289688 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #205 | Epoch Duration: 160.08850264549255
2020-01-12 08:17:27.289962 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #205 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9299511
Z variance train             0.003827406
KL Divergence                22.88559
KL Loss                      2.288559
QF Loss                      674.5083
VF Loss                      219.46973
Policy Loss                  -1156.9578
Q Predictions Mean           1154.8063
Q Predictions Std            282.6441
Q Predictions Max            1404.5142
Q Predictions Min            37.167053
V Predictions Mean           1151.5217
V Predictions Std            277.2702
V Predictions Max            1398.8035
V Predictions Min            50.709736
Log Pis Mean                 0.57290363
Log Pis Std                  3.0527794
Log Pis Max                  13.567791
Log Pis Min                  -7.2536874
Policy mu Mean               0.0047075925
Policy mu Std                0.62890434
Policy mu Max                2.36581
Policy mu Min                -1.9714019
Policy log std Mean          -1.0175635
Policy log std Std           0.3128346
Policy log std Max           0.10551453
Policy log std Min           -2.7204514
Z mean eval                  0.9551705
Z variance eval              0.008147947
total_rewards                [1966.65913375 3454.081251   2463.22255158 3365.52126417 3292.92312394
 3236.15251124 3406.65503833 1843.30849651 3360.0121719  2908.90945427]
total_rewards_mean           2929.744499670588
total_rewards_std            585.5887951285624
total_rewards_max            3454.0812509998473
total_rewards_min            1843.3084965108578
Number of train steps total  828000
Number of env steps total    1037000
Number of rollouts total     0
Train Time (s)               116.42461528116837
(Previous) Eval Time (s)     23.19201832311228
Sample Time (s)              17.83852757094428
Epoch Time (s)               157.45516117522493
Total Train Time (s)         31710.967241590843
Epoch                        206
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:20:06.049493 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #206 | Epoch Duration: 158.75931978225708
2020-01-12 08:20:06.049703 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #206 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9560486
Z variance train             0.008188951
KL Divergence                21.312014
KL Loss                      2.1312015
QF Loss                      1299.5021
VF Loss                      225.80333
Policy Loss                  -1130.7408
Q Predictions Mean           1129.3701
Q Predictions Std            318.35876
Q Predictions Max            1380.8569
Q Predictions Min            -3.299693
V Predictions Mean           1133.5723
V Predictions Std            319.306
V Predictions Max            1377.4807
V Predictions Min            5.853365
Log Pis Mean                 0.19918635
Log Pis Std                  3.3667233
Log Pis Max                  17.088373
Log Pis Min                  -10.105983
Policy mu Mean               -0.04259727
Policy mu Std                0.5988323
Policy mu Max                2.8050375
Policy mu Min                -2.0306156
Policy log std Mean          -1.0258095
Policy log std Std           0.35620806
Policy log std Max           0.55193853
Policy log std Min           -3.0038507
Z mean eval                  0.9252659
Z variance eval              0.009260731
total_rewards                [3489.62549807 1580.83642879  246.01036267 3632.06977239 3081.0174591
 3533.17183376 3291.19339478  607.50002206 3586.43478606 3647.62517749]
total_rewards_mean           2669.5484735169957
total_rewards_std            1265.2571784329987
total_rewards_max            3647.6251774923103
total_rewards_min            246.01036267223571
Number of train steps total  832000
Number of env steps total    1042000
Number of rollouts total     0
Train Time (s)               112.30906097916886
(Previous) Eval Time (s)     24.49588169204071
Sample Time (s)              18.3609063741751
Epoch Time (s)               155.16584904538468
Total Train Time (s)         31864.130483269226
Epoch                        207
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:22:39.207672 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #207 | Epoch Duration: 153.15781426429749
2020-01-12 08:22:39.207912 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #207 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92553365
Z variance train             0.00925124
KL Divergence                20.815777
KL Loss                      2.0815778
QF Loss                      577.76074
VF Loss                      179.2396
Policy Loss                  -1120.3871
Q Predictions Mean           1115.5803
Q Predictions Std            331.78912
Q Predictions Max            1371.5569
Q Predictions Min            39.11227
V Predictions Mean           1119.819
V Predictions Std            326.8596
V Predictions Max            1376.1774
V Predictions Min            -0.016796827
Log Pis Mean                 0.010394361
Log Pis Std                  3.360132
Log Pis Max                  31.667698
Log Pis Min                  -7.6976113
Policy mu Mean               0.035709422
Policy mu Std                0.6137374
Policy mu Max                4.6366663
Policy mu Min                -3.8576314
Policy log std Mean          -0.9846936
Policy log std Std           0.31453767
Policy log std Max           -0.1488021
Policy log std Min           -2.8173916
Z mean eval                  0.9361278
Z variance eval              0.007640398
total_rewards                [3241.45618354 3345.58545491 3363.78271232 3405.98078675 3438.18386383
 3319.17302193 3354.10776866 3250.79296351 3438.79406795  603.89911805]
total_rewards_mean           3076.1755941434512
total_rewards_std            826.611580740529
total_rewards_max            3438.7940679520048
total_rewards_min            603.8991180488713
Number of train steps total  836000
Number of env steps total    1047000
Number of rollouts total     0
Train Time (s)               119.17500541498885
(Previous) Eval Time (s)     22.487536694854498
Sample Time (s)              18.811870759818703
Epoch Time (s)               160.47441286966205
Total Train Time (s)         32026.878153855912
Epoch                        208
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:25:21.958988 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #208 | Epoch Duration: 162.7508828639984
2020-01-12 08:25:21.959271 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #208 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93755186
Z variance train             0.0076405415
KL Divergence                21.846355
KL Loss                      2.1846356
QF Loss                      866.94946
VF Loss                      518.2849
Policy Loss                  -1166.5576
Q Predictions Mean           1162.4614
Q Predictions Std            293.13086
Q Predictions Max            1404.5609
Q Predictions Min            -24.731005
V Predictions Mean           1156.1609
V Predictions Std            282.82883
V Predictions Max            1378.1185
V Predictions Min            38.440502
Log Pis Mean                 0.43759388
Log Pis Std                  3.0655417
Log Pis Max                  12.777523
Log Pis Min                  -7.081592
Policy mu Mean               0.023151912
Policy mu Std                0.6261659
Policy mu Max                2.732949
Policy mu Min                -2.166901
Policy log std Mean          -1.0250258
Policy log std Std           0.31455714
Policy log std Max           -0.117501974
Policy log std Min           -2.722188
Z mean eval                  0.9578539
Z variance eval              0.006337125
total_rewards                [3548.53476831 3377.12461069 3508.16092894 3414.62813632 3549.59295381
 1747.10895368 3478.57067007 1764.5255708  3651.17620178  480.89142059]
total_rewards_mean           2852.0314214997898
total_rewards_std            1051.2594448495395
total_rewards_max            3651.1762017806386
total_rewards_min            480.89142058660235
Number of train steps total  840000
Number of env steps total    1052000
Number of rollouts total     0
Train Time (s)               116.44890376087278
(Previous) Eval Time (s)     24.763663601130247
Sample Time (s)              18.718278594780713
Epoch Time (s)               159.93084595678374
Total Train Time (s)         32185.343540186528
Epoch                        209
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:28:00.428463 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #209 | Epoch Duration: 158.4689826965332
2020-01-12 08:28:00.428749 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #209 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9588267
Z variance train             0.006348028
KL Divergence                23.202494
KL Loss                      2.3202493
QF Loss                      925.9032
VF Loss                      157.72336
Policy Loss                  -1136.6067
Q Predictions Mean           1137.4124
Q Predictions Std            333.92606
Q Predictions Max            1397.1449
Q Predictions Min            34.811752
V Predictions Mean           1133.8794
V Predictions Std            328.9802
V Predictions Max            1391.4154
V Predictions Min            20.34148
Log Pis Mean                 0.43666688
Log Pis Std                  3.1701963
Log Pis Max                  17.51234
Log Pis Min                  -7.5709844
Policy mu Mean               0.016578345
Policy mu Std                0.6036938
Policy mu Max                3.8113499
Policy mu Min                -2.2982402
Policy log std Mean          -1.0268378
Policy log std Std           0.32553145
Policy log std Max           -0.1931575
Policy log std Min           -2.6005764
Z mean eval                  0.92760146
Z variance eval              0.0042259106
total_rewards                [1654.91660693 3439.80136932 3391.5617036  3179.05808587 3380.07206915
 3553.95638869 3448.08278298   27.4237651  3491.37805621 3461.44268322]
total_rewards_mean           2902.7693511070333
total_rewards_std            1097.0966597697548
total_rewards_max            3553.9563886918177
total_rewards_min            27.42376510356418
Number of train steps total  844000
Number of env steps total    1057000
Number of rollouts total     0
Train Time (s)               114.41152377426624
(Previous) Eval Time (s)     23.301468916703016
Sample Time (s)              18.36342179076746
Epoch Time (s)               156.07641448173672
Total Train Time (s)         32340.973388227634
Epoch                        210
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:30:36.066716 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #210 | Epoch Duration: 155.63775753974915
2020-01-12 08:30:36.066954 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #210 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9263857
Z variance train             0.004221714
KL Divergence                24.314432
KL Loss                      2.4314432
QF Loss                      1270.9253
VF Loss                      461.04718
Policy Loss                  -1149.764
Q Predictions Mean           1144.5621
Q Predictions Std            322.17285
Q Predictions Max            1434.6907
Q Predictions Min            -54.43897
V Predictions Mean           1155.308
V Predictions Std            310.7408
V Predictions Max            1442.52
V Predictions Min            30.33688
Log Pis Mean                 0.5369665
Log Pis Std                  3.2305608
Log Pis Max                  13.63563
Log Pis Min                  -7.456746
Policy mu Mean               0.028769104
Policy mu Std                0.6484922
Policy mu Max                2.7145886
Policy mu Min                -2.4682097
Policy log std Mean          -1.0080938
Policy log std Std           0.32841894
Policy log std Max           -0.15884352
Policy log std Min           -2.805389
Z mean eval                  0.95770967
Z variance eval              0.004944977
total_rewards                [1033.98461756 3387.26474399 3440.31241067 3150.75024879  413.39445784
 3511.08624698 3327.18717131 1201.81157376 3555.01636479 3373.0087622 ]
total_rewards_mean           2639.3816597884625
total_rewards_std            1169.2212962147134
total_rewards_max            3555.0163647882223
total_rewards_min            413.39445783816996
Number of train steps total  848000
Number of env steps total    1062000
Number of rollouts total     0
Train Time (s)               115.24759881664068
(Previous) Eval Time (s)     22.86250060610473
Sample Time (s)              17.66771201323718
Epoch Time (s)               155.77781143598258
Total Train Time (s)         32498.745033807587
Epoch                        211
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:33:13.833323 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #211 | Epoch Duration: 157.76624751091003
2020-01-12 08:33:13.833485 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #211 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95636904
Z variance train             0.0049593705
KL Divergence                23.812145
KL Loss                      2.3812146
QF Loss                      1285.4078
VF Loss                      1055.959
Policy Loss                  -1163.546
Q Predictions Mean           1163.0382
Q Predictions Std            326.21112
Q Predictions Max            1389.431
Q Predictions Min            -129.66798
V Predictions Mean           1162.7896
V Predictions Std            306.72473
V Predictions Max            1392.3438
V Predictions Min            9.569931
Log Pis Mean                 0.41525027
Log Pis Std                  3.0828328
Log Pis Max                  12.928743
Log Pis Min                  -7.3076553
Policy mu Mean               -0.0074975477
Policy mu Std                0.6578754
Policy mu Max                2.605286
Policy mu Min                -2.3790371
Policy log std Mean          -0.99565774
Policy log std Std           0.30553818
Policy log std Max           0.4423815
Policy log std Min           -2.5718694
Z mean eval                  0.9491971
Z variance eval              0.0076050744
total_rewards                [1577.53120628 3404.1282659  3305.62718326 3227.46590614 3339.23798473
 1328.64307816 3434.88568212 1473.27843587 2811.55995193 2738.40705637]
total_rewards_mean           2664.076475076106
total_rewards_std            820.7253421961423
total_rewards_max            3434.8856821179843
total_rewards_min            1328.6430781626677
Number of train steps total  852000
Number of env steps total    1067000
Number of rollouts total     0
Train Time (s)               122.54857493983582
(Previous) Eval Time (s)     24.850645584985614
Sample Time (s)              18.75494296522811
Epoch Time (s)               166.15416349004954
Total Train Time (s)         32663.751149703283
Epoch                        212
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:35:58.845234 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #212 | Epoch Duration: 165.01158165931702
2020-01-12 08:35:58.845516 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #212 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9510435
Z variance train             0.007625474
KL Divergence                22.647306
KL Loss                      2.2647307
QF Loss                      610.785
VF Loss                      202.68811
Policy Loss                  -1180.188
Q Predictions Mean           1179.0647
Q Predictions Std            278.02322
Q Predictions Max            1376.9805
Q Predictions Min            16.308645
V Predictions Mean           1187.7394
V Predictions Std            277.33533
V Predictions Max            1388.7949
V Predictions Min            34.4503
Log Pis Mean                 0.26879662
Log Pis Std                  2.9179263
Log Pis Max                  9.291715
Log Pis Min                  -5.9281173
Policy mu Mean               0.014186018
Policy mu Std                0.61241806
Policy mu Max                2.7396126
Policy mu Min                -2.6224742
Policy log std Mean          -1.0361015
Policy log std Std           0.2737947
Policy log std Max           -0.16378921
Policy log std Min           -2.2620506
Z mean eval                  0.9787968
Z variance eval              0.0131291
total_rewards                [3524.17556229  496.16399132 1915.32312236   39.93102568 3552.48757825
  358.57364194 1156.43219785 1492.78657833  290.08336978 3690.59954775]
total_rewards_mean           1651.65566155329
total_rewards_std            1381.1425935355287
total_rewards_max            3690.599547752273
total_rewards_min            39.931025676615455
Number of train steps total  856000
Number of env steps total    1072000
Number of rollouts total     0
Train Time (s)               115.46390394633636
(Previous) Eval Time (s)     23.707723029889166
Sample Time (s)              18.524343267083168
Epoch Time (s)               157.6959702433087
Total Train Time (s)         32812.145158176776
Epoch                        213
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:38:27.241855 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #213 | Epoch Duration: 148.3961362838745
2020-01-12 08:38:27.242043 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #213 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97922933
Z variance train             0.013133869
KL Divergence                21.837713
KL Loss                      2.1837714
QF Loss                      1039.8987
VF Loss                      85.19141
Policy Loss                  -1163.2473
Q Predictions Mean           1162.3859
Q Predictions Std            279.98972
Q Predictions Max            1385.4727
Q Predictions Min            31.494738
V Predictions Mean           1163.5742
V Predictions Std            278.62692
V Predictions Max            1384.1016
V Predictions Min            33.13411
Log Pis Mean                 0.5168089
Log Pis Std                  2.9825037
Log Pis Max                  10.312331
Log Pis Min                  -7.466111
Policy mu Mean               0.0252779
Policy mu Std                0.6415532
Policy mu Max                3.0152566
Policy mu Min                -2.237315
Policy log std Mean          -0.99902856
Policy log std Std           0.3004806
Policy log std Max           -0.18718004
Policy log std Min           -2.6233938
Z mean eval                  0.96553737
Z variance eval              0.020858657
total_rewards                [3123.06742071 2947.77925184 3616.15125258 3204.35648997 3264.86025438
 3402.14960814 3372.81031843 3521.37657394 3358.67183117 1973.95922572]
total_rewards_mean           3178.5182226878937
total_rewards_std            440.9864464275601
total_rewards_max            3616.1512525821645
total_rewards_min            1973.9592257212869
Number of train steps total  860000
Number of env steps total    1077000
Number of rollouts total     0
Train Time (s)               118.89526111027226
(Previous) Eval Time (s)     14.40751596307382
Sample Time (s)              17.613169053569436
Epoch Time (s)               150.91594612691551
Total Train Time (s)         32975.38116412843
Epoch                        214
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:41:10.482203 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #214 | Epoch Duration: 163.23999547958374
2020-01-12 08:41:10.482451 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #214 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96585846
Z variance train             0.020935994
KL Divergence                21.915665
KL Loss                      2.1915665
QF Loss                      500.03882
VF Loss                      167.46118
Policy Loss                  -1150.7197
Q Predictions Mean           1149.5974
Q Predictions Std            351.79446
Q Predictions Max            1413.955
Q Predictions Min            18.635649
V Predictions Mean           1154.5319
V Predictions Std            346.15958
V Predictions Max            1414.5004
V Predictions Min            45.17296
Log Pis Mean                 -0.0012685284
Log Pis Std                  2.8892686
Log Pis Max                  12.293469
Log Pis Min                  -6.7432747
Policy mu Mean               -0.015932266
Policy mu Std                0.6092865
Policy mu Max                2.1026042
Policy mu Min                -2.1473007
Policy log std Mean          -0.97220665
Policy log std Std           0.30569327
Policy log std Max           0.096313
Policy log std Min           -2.7627234
Z mean eval                  0.91960317
Z variance eval              0.011574858
total_rewards                [3394.95026162 3476.59509565 1166.35913181    6.6014244  3493.52489596
 3552.70850392 3632.50876574 2614.39059943 3392.30873051 1949.49044328]
total_rewards_mean           2667.943785231988
total_rewards_std            1181.4601598513066
total_rewards_max            3632.5087657399363
total_rewards_min            6.601424398663623
Number of train steps total  864000
Number of env steps total    1082000
Number of rollouts total     0
Train Time (s)               116.14081338932738
(Previous) Eval Time (s)     26.731239906977862
Sample Time (s)              18.19171969918534
Epoch Time (s)               161.06377299549058
Total Train Time (s)         33132.44136802899
Epoch                        215
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:43:47.543825 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #215 | Epoch Duration: 157.06119179725647
2020-01-12 08:43:47.544013 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #215 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91986245
Z variance train             0.011582491
KL Divergence                23.308022
KL Loss                      2.3308022
QF Loss                      414.66583
VF Loss                      108.0149
Policy Loss                  -1211.4446
Q Predictions Mean           1209.2773
Q Predictions Std            255.726
Q Predictions Max            1449.8367
Q Predictions Min            35.172337
V Predictions Mean           1209.9808
V Predictions Std            256.14877
V Predictions Max            1447.6287
V Predictions Min            -3.1758804
Log Pis Mean                 0.47828966
Log Pis Std                  3.1088037
Log Pis Max                  13.004301
Log Pis Min                  -9.335826
Policy mu Mean               -0.0031451015
Policy mu Std                0.64678043
Policy mu Max                2.3287334
Policy mu Min                -2.417373
Policy log std Mean          -0.99727875
Policy log std Std           0.2822594
Policy log std Max           -0.20928407
Policy log std Min           -2.4069552
Z mean eval                  0.94024974
Z variance eval              0.0054290537
total_rewards                [  47.16953115 3252.05800324  946.90587691  683.48822882  -90.52491456
 3321.18458156 3458.41041654 2337.5032359   442.41675721 3413.60185232]
total_rewards_mean           1781.2213569094197
total_rewards_std            1432.6825838928378
total_rewards_max            3458.4104165360204
total_rewards_min            -90.52491455559098
Number of train steps total  868000
Number of env steps total    1087000
Number of rollouts total     0
Train Time (s)               114.51952210301533
(Previous) Eval Time (s)     22.728356163948774
Sample Time (s)              17.908293020911515
Epoch Time (s)               155.15617128787562
Total Train Time (s)         33282.51062502712
Epoch                        216
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:46:17.614628 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #216 | Epoch Duration: 150.07046675682068
2020-01-12 08:46:17.614784 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #216 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9403184
Z variance train             0.0054177586
KL Divergence                24.86586
KL Loss                      2.486586
QF Loss                      927.7572
VF Loss                      420.14078
Policy Loss                  -1181.758
Q Predictions Mean           1179.9775
Q Predictions Std            291.34888
Q Predictions Max            1445.8977
Q Predictions Min            27.552557
V Predictions Mean           1181.7161
V Predictions Std            293.14655
V Predictions Max            1443.4167
V Predictions Min            8.430728
Log Pis Mean                 0.36553067
Log Pis Std                  3.1183822
Log Pis Max                  12.445541
Log Pis Min                  -10.045483
Policy mu Mean               0.029771809
Policy mu Std                0.6142204
Policy mu Max                3.1919198
Policy mu Min                -2.2141564
Policy log std Mean          -1.0393384
Policy log std Std           0.32546404
Policy log std Max           -0.2501344
Policy log std Min           -2.9323783
Z mean eval                  0.98378146
Z variance eval              0.0060979226
total_rewards                [1564.56292825 3480.20199572 1702.17757166 3398.64514982 3432.77696513
 3556.17338332  348.39558045 3070.87140005  167.93351789  938.9785099 ]
total_rewards_mean           2166.0717002185015
total_rewards_std            1303.112968686232
total_rewards_max            3556.173383318816
total_rewards_min            167.93351789287902
Number of train steps total  872000
Number of env steps total    1092000
Number of rollouts total     0
Train Time (s)               111.82076730625704
(Previous) Eval Time (s)     17.64233217993751
Sample Time (s)              17.873494159430265
Epoch Time (s)               147.33659364562482
Total Train Time (s)         33428.9033225188
Epoch                        217
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:48:44.013081 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #217 | Epoch Duration: 146.39813685417175
2020-01-12 08:48:44.013413 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #217 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9854188
Z variance train             0.0061020353
KL Divergence                24.72015
KL Loss                      2.4720151
QF Loss                      618.2152
VF Loss                      112.696045
Policy Loss                  -1209.5024
Q Predictions Mean           1210.2183
Q Predictions Std            278.9881
Q Predictions Max            1433.1533
Q Predictions Min            0.97265494
V Predictions Mean           1208.1036
V Predictions Std            273.5292
V Predictions Max            1428.1896
V Predictions Min            2.2878602
Log Pis Mean                 0.48073477
Log Pis Std                  2.696725
Log Pis Max                  10.114477
Log Pis Min                  -6.834698
Policy mu Mean               0.047571804
Policy mu Std                0.64551204
Policy mu Max                2.6739652
Policy mu Min                -2.365168
Policy log std Mean          -1.0073582
Policy log std Std           0.3107785
Policy log std Max           -0.16121227
Policy log std Min           -2.90973
Z mean eval                  0.9658211
Z variance eval              0.0079593565
total_rewards                [3471.93791433 1630.11776143 2090.55186475   84.26651414 2067.79570112
 2957.55724737 3143.20010615 1255.47628175 2180.70027928 2094.34182209]
total_rewards_mean           2097.594549240547
total_rewards_std            933.3107050629384
total_rewards_max            3471.937914332427
total_rewards_min            84.26651413503537
Number of train steps total  876000
Number of env steps total    1097000
Number of rollouts total     0
Train Time (s)               118.75641128141433
(Previous) Eval Time (s)     16.703529010992497
Sample Time (s)              17.9588503241539
Epoch Time (s)               153.41879061656073
Total Train Time (s)         33583.29722003592
Epoch                        218
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:51:18.408277 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #218 | Epoch Duration: 154.39464402198792
2020-01-12 08:51:18.408462 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #218 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96434724
Z variance train             0.007955775
KL Divergence                23.782429
KL Loss                      2.378243
QF Loss                      1070.7922
VF Loss                      1290.7426
Policy Loss                  -1200.8281
Q Predictions Mean           1197.146
Q Predictions Std            294.0182
Q Predictions Max            1448.6238
Q Predictions Min            -7.168995
V Predictions Mean           1201.0222
V Predictions Std            294.85995
V Predictions Max            1441.9485
V Predictions Min            -14.173814
Log Pis Mean                 -0.0039567947
Log Pis Std                  3.2186463
Log Pis Max                  18.787882
Log Pis Min                  -7.242202
Policy mu Mean               -0.03595955
Policy mu Std                0.6067523
Policy mu Max                2.5862064
Policy mu Min                -2.725219
Policy log std Mean          -1.0066755
Policy log std Std           0.33028436
Policy log std Max           -0.08312738
Policy log std Min           -2.7177036
Z mean eval                  0.9587203
Z variance eval              0.006836146
total_rewards                [3293.34329072 3743.29670147 2580.52831242  641.44239062  680.7670435
 2981.38614973 3469.5854808  3402.96151743 2703.13437172  -23.89843095]
total_rewards_mean           2347.2546827473225
total_rewards_std            1308.0785024706365
total_rewards_max            3743.296701469316
total_rewards_min            -23.898430946908015
Number of train steps total  880000
Number of env steps total    1102000
Number of rollouts total     0
Train Time (s)               116.46935603674501
(Previous) Eval Time (s)     17.679037631954998
Sample Time (s)              18.461458068806678
Epoch Time (s)               152.6098517375067
Total Train Time (s)         33744.596374900546
Epoch                        219
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:53:59.712169 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #219 | Epoch Duration: 161.30351853370667
2020-01-12 08:53:59.712452 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #219 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9625088
Z variance train             0.006852206
KL Divergence                24.369587
KL Loss                      2.4369588
QF Loss                      2174.363
VF Loss                      558.2954
Policy Loss                  -1185.5004
Q Predictions Mean           1187.8411
Q Predictions Std            319.77432
Q Predictions Max            1447.2222
Q Predictions Min            17.384073
V Predictions Mean           1188.8875
V Predictions Std            310.12213
V Predictions Max            1441.3896
V Predictions Min            -15.3708725
Log Pis Mean                 0.2047627
Log Pis Std                  3.071955
Log Pis Max                  11.536689
Log Pis Min                  -6.7805953
Policy mu Mean               -0.025199879
Policy mu Std                0.61376
Policy mu Max                2.9806728
Policy mu Min                -3.0402462
Policy log std Mean          -0.99926066
Policy log std Std           0.32775208
Policy log std Max           0.07244635
Policy log std Min           -2.7659883
Z mean eval                  0.9464548
Z variance eval              0.009091023
total_rewards                [3412.89125109 3652.59336883 2893.712542   3381.16639486   83.32176829
  508.33791867 3592.75707595 3260.82070932 1180.08223111  568.64728131]
total_rewards_mean           2253.43305414464
total_rewards_std            1397.7724079632687
total_rewards_max            3652.593368827604
total_rewards_min            83.32176829493882
Number of train steps total  884000
Number of env steps total    1107000
Number of rollouts total     0
Train Time (s)               115.39045024709776
(Previous) Eval Time (s)     26.37232077307999
Sample Time (s)              18.094240503851324
Epoch Time (s)               159.85701152402908
Total Train Time (s)         33897.84546863707
Epoch                        220
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:56:32.962358 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #220 | Epoch Duration: 153.2497239112854
2020-01-12 08:56:32.962505 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #220 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94533336
Z variance train             0.00908407
KL Divergence                23.37325
KL Loss                      2.3373249
QF Loss                      2080.0066
VF Loss                      110.858315
Policy Loss                  -1199.2269
Q Predictions Mean           1197.9832
Q Predictions Std            307.00323
Q Predictions Max            1439.2969
Q Predictions Min            49.924614
V Predictions Mean           1196.363
V Predictions Std            305.26526
V Predictions Max            1421.8962
V Predictions Min            63.786102
Log Pis Mean                 0.16560805
Log Pis Std                  2.7947667
Log Pis Max                  9.499767
Log Pis Min                  -7.291891
Policy mu Mean               0.008344987
Policy mu Std                0.59104776
Policy mu Max                2.5360184
Policy mu Min                -2.1563954
Policy log std Mean          -1.0190927
Policy log std Std           0.30179557
Policy log std Max           -0.1970036
Policy log std Min           -2.6536765
Z mean eval                  0.9569585
Z variance eval              0.011779896
total_rewards                [3380.88124896 3190.49660639  248.55099123 3173.310745   1782.64604399
 3450.11784495 1899.75167348 1534.33688159 3341.30523524  526.95330803]
total_rewards_mean           2252.8350578863356
total_rewards_std            1160.8201379757802
total_rewards_max            3450.1178449452627
total_rewards_min            248.5509912303439
Number of train steps total  888000
Number of env steps total    1112000
Number of rollouts total     0
Train Time (s)               114.94323431700468
(Previous) Eval Time (s)     19.76469425158575
Sample Time (s)              17.91118752770126
Epoch Time (s)               152.6191160962917
Total Train Time (s)         34050.09494458465
Epoch                        221
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:59:05.213989 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #221 | Epoch Duration: 152.25137281417847
2020-01-12 08:59:05.214160 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #221 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95720136
Z variance train             0.011795196
KL Divergence                22.292122
KL Loss                      2.2292123
QF Loss                      932.42334
VF Loss                      189.90775
Policy Loss                  -1226.699
Q Predictions Mean           1225.7502
Q Predictions Std            267.55502
Q Predictions Max            1427.9524
Q Predictions Min            27.082613
V Predictions Mean           1228.1871
V Predictions Std            263.90106
V Predictions Max            1428.416
V Predictions Min            32.467655
Log Pis Mean                 0.317739
Log Pis Std                  2.8516307
Log Pis Max                  11.03386
Log Pis Min                  -7.7228
Policy mu Mean               0.015504249
Policy mu Std                0.6159257
Policy mu Max                2.3605442
Policy mu Min                -2.1295562
Policy log std Mean          -1.0299945
Policy log std Std           0.30916187
Policy log std Max           -0.1880424
Policy log std Min           -2.6799438
Z mean eval                  0.9480044
Z variance eval              0.011484599
total_rewards                [2322.11679295  -49.84232169 3599.64795887 1767.02551681 2495.67111176
 3315.64300579 2008.99688771 2367.1172306  2213.22814478 2047.29110079]
total_rewards_mean           2208.689542836415
total_rewards_std            929.6459157124152
total_rewards_max            3599.647958872136
total_rewards_min            -49.842321693720415
Number of train steps total  892000
Number of env steps total    1117000
Number of rollouts total     0
Train Time (s)               118.95202016597614
(Previous) Eval Time (s)     19.39663077192381
Sample Time (s)              17.221828606445342
Epoch Time (s)               155.5704795443453
Total Train Time (s)         34207.12163101137
Epoch                        222
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:01:42.245779 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #222 | Epoch Duration: 157.03145456314087
2020-01-12 09:01:42.246066 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #222 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94718486
Z variance train             0.011483316
KL Divergence                21.985836
KL Loss                      2.1985836
QF Loss                      510.4237
VF Loss                      102.18524
Policy Loss                  -1199.8585
Q Predictions Mean           1198.0172
Q Predictions Std            331.99094
Q Predictions Max            1443.1342
Q Predictions Min            -16.69398
V Predictions Mean           1198.4531
V Predictions Std            329.69745
V Predictions Max            1443.9249
V Predictions Min            1.4551142
Log Pis Mean                 -0.08137413
Log Pis Std                  2.8516083
Log Pis Max                  12.035615
Log Pis Min                  -9.194513
Policy mu Mean               0.009986623
Policy mu Std                0.61785066
Policy mu Max                2.6382296
Policy mu Min                -1.9673576
Policy log std Mean          -0.9629169
Policy log std Std           0.31327948
Policy log std Max           -0.1342752
Policy log std Min           -2.5032537
Z mean eval                  0.95061076
Z variance eval              0.0103123505
total_rewards                [3396.69463572 1323.35040154 1591.91308185 2571.07196822 1415.22667876
   35.76907954 3406.29121851 3594.62134529 2125.55364011  519.92057507]
total_rewards_mean           1998.041262457928
total_rewards_std            1175.9364071490172
total_rewards_max            3594.621345290573
total_rewards_min            35.769079535362266
Number of train steps total  896000
Number of env steps total    1122000
Number of rollouts total     0
Train Time (s)               120.740723608993
(Previous) Eval Time (s)     20.857300388161093
Sample Time (s)              17.63244759151712
Epoch Time (s)               159.2304715886712
Total Train Time (s)         34362.94799271738
Epoch                        223
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:04:18.075975 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #223 | Epoch Duration: 155.829674243927
2020-01-12 09:04:18.076218 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #223 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94830626
Z variance train             0.010329184
KL Divergence                21.961624
KL Loss                      2.1961625
QF Loss                      504.45493
VF Loss                      159.53079
Policy Loss                  -1208.3833
Q Predictions Mean           1207.2065
Q Predictions Std            289.59402
Q Predictions Max            1411.0026
Q Predictions Min            -7.95815
V Predictions Mean           1208.8535
V Predictions Std            282.54947
V Predictions Max            1406.4626
V Predictions Min            -16.781551
Log Pis Mean                 -0.16420954
Log Pis Std                  2.9268384
Log Pis Max                  8.829053
Log Pis Min                  -8.843364
Policy mu Mean               0.022582477
Policy mu Std                0.6088776
Policy mu Max                2.4108498
Policy mu Min                -1.9812354
Policy log std Mean          -0.97109056
Policy log std Std           0.28965712
Policy log std Max           0.09538543
Policy log std Min           -2.2484703
Z mean eval                  0.93945915
Z variance eval              0.009187303
total_rewards                [3258.74412833 3454.9182303   233.88075091 3419.10973143 3514.7319498
 1976.242979    281.41397686 3426.48262764 3470.47595634 3524.43646038]
total_rewards_mean           2656.043679099307
total_rewards_std            1276.7111780673358
total_rewards_max            3524.436460376299
total_rewards_min            233.88075091434303
Number of train steps total  900000
Number of env steps total    1127000
Number of rollouts total     0
Train Time (s)               120.85187036078423
(Previous) Eval Time (s)     17.456184839829803
Sample Time (s)              17.544903525151312
Epoch Time (s)               155.85295872576535
Total Train Time (s)         34524.91068176925
Epoch                        224
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:07:00.044827 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #224 | Epoch Duration: 161.9683175086975
2020-01-12 09:07:00.045239 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #224 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9391473
Z variance train             0.009193996
KL Divergence                22.394098
KL Loss                      2.23941
QF Loss                      1265.8965
VF Loss                      804.07837
Policy Loss                  -1222.5499
Q Predictions Mean           1220.3384
Q Predictions Std            282.13016
Q Predictions Max            1419.1775
Q Predictions Min            13.982872
V Predictions Mean           1223.7437
V Predictions Std            275.08484
V Predictions Max            1418.0405
V Predictions Min            7.543724
Log Pis Mean                 0.3311919
Log Pis Std                  3.0927327
Log Pis Max                  12.411015
Log Pis Min                  -6.4812417
Policy mu Mean               0.0026604694
Policy mu Std                0.5912463
Policy mu Max                2.7676613
Policy mu Min                -2.8695228
Policy log std Mean          -1.0594205
Policy log std Std           0.33017525
Policy log std Max           -0.17275679
Policy log std Min           -2.851623
Z mean eval                  0.9601962
Z variance eval              0.0061119124
total_rewards                [1699.76580942 1837.8466705  3646.81912201 3306.18572996 1334.85904616
 3549.7279285  3456.54161885 1514.19985203 1428.62480702 3614.26460112]
total_rewards_mean           2538.883518557227
total_rewards_std            988.155777857552
total_rewards_max            3646.8191220083563
total_rewards_min            1334.859046164334
Number of train steps total  904000
Number of env steps total    1132000
Number of rollouts total     0
Train Time (s)               115.01353898597881
(Previous) Eval Time (s)     23.571220724843442
Sample Time (s)              18.0914638126269
Epoch Time (s)               156.67622352344915
Total Train Time (s)         34678.2874356797
Epoch                        225
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:09:33.422870 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #225 | Epoch Duration: 153.37738180160522
2020-01-12 09:09:33.423114 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #225 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96020967
Z variance train             0.0061073154
KL Divergence                23.015673
KL Loss                      2.3015673
QF Loss                      435.48676
VF Loss                      147.89719
Policy Loss                  -1235.9518
Q Predictions Mean           1236.2366
Q Predictions Std            258.66498
Q Predictions Max            1422.2687
Q Predictions Min            8.176114
V Predictions Mean           1236.5144
V Predictions Std            256.55917
V Predictions Max            1424.0287
V Predictions Min            21.22509
Log Pis Mean                 0.15309703
Log Pis Std                  2.7394547
Log Pis Max                  10.893586
Log Pis Min                  -6.141625
Policy mu Mean               0.020241413
Policy mu Std                0.6198685
Policy mu Max                2.4955537
Policy mu Min                -2.2056708
Policy log std Mean          -0.9992331
Policy log std Std           0.28371662
Policy log std Max           -0.030278325
Policy log std Min           -2.9417305
Z mean eval                  0.968475
Z variance eval              0.014031221
total_rewards                [3513.00644383 2913.05762554 1034.0263987    73.4260224  2036.10661942
  293.92308395 2077.86906585 2752.68692834  269.19913372  652.35125794]
total_rewards_mean           1561.5652579685573
total_rewards_std            1189.194554799251
total_rewards_max            3513.006443825678
total_rewards_min            73.42602239888598
Number of train steps total  908000
Number of env steps total    1137000
Number of rollouts total     0
Train Time (s)               117.44663247466087
(Previous) Eval Time (s)     20.272091635968536
Sample Time (s)              18.552425186615437
Epoch Time (s)               156.27114929724485
Total Train Time (s)         34834.28331361199
Epoch                        226
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:12:09.421253 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #226 | Epoch Duration: 155.9978802204132
2020-01-12 09:12:09.421527 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #226 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.965888
Z variance train             0.014011571
KL Divergence                22.508263
KL Loss                      2.2508264
QF Loss                      474.87488
VF Loss                      167.76726
Policy Loss                  -1245.1279
Q Predictions Mean           1245.2751
Q Predictions Std            263.84244
Q Predictions Max            1450.4275
Q Predictions Min            -86.5626
V Predictions Mean           1238.7759
V Predictions Std            261.42685
V Predictions Max            1445.3314
V Predictions Min            25.664885
Log Pis Mean                 -0.12628411
Log Pis Std                  2.9372878
Log Pis Max                  15.26952
Log Pis Min                  -10.237051
Policy mu Mean               0.037345257
Policy mu Std                0.57388854
Policy mu Max                2.367171
Policy mu Min                -2.2750154
Policy log std Mean          -1.0210412
Policy log std Std           0.30276898
Policy log std Max           0.00489223
Policy log std Min           -3.2830684
Z mean eval                  0.9587963
Z variance eval              0.011683153
total_rewards                [1133.7874667  3681.05194442 2678.37212037  579.39180618 3255.72824122
 3342.13409425 3505.36658781  202.29286172 3643.68994679 3401.05505111]
total_rewards_mean           2542.287012056511
total_rewards_std            1290.5251989469402
total_rewards_max            3681.0519444161323
total_rewards_min            202.29286171530674
Number of train steps total  912000
Number of env steps total    1142000
Number of rollouts total     0
Train Time (s)               116.57980742724612
(Previous) Eval Time (s)     19.998510515782982
Sample Time (s)              17.616964729037136
Epoch Time (s)               154.19528267206624
Total Train Time (s)         34988.61991683673
Epoch                        227
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:14:43.760680 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #227 | Epoch Duration: 154.3389925956726
2020-01-12 09:14:43.760907 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #227 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9588682
Z variance train             0.011676933
KL Divergence                21.92949
KL Loss                      2.192949
QF Loss                      5598.638
VF Loss                      89.241875
Policy Loss                  -1211.7528
Q Predictions Mean           1210.9055
Q Predictions Std            300.84073
Q Predictions Max            1456.3076
Q Predictions Min            27.129847
V Predictions Mean           1210.8538
V Predictions Std            299.00244
V Predictions Max            1446.9343
V Predictions Min            16.499743
Log Pis Mean                 0.30869412
Log Pis Std                  2.8329296
Log Pis Max                  14.317625
Log Pis Min                  -7.368167
Policy mu Mean               0.023761902
Policy mu Std                0.6437402
Policy mu Max                2.7649016
Policy mu Min                -2.1699774
Policy log std Mean          -0.9626942
Policy log std Std           0.2860243
Policy log std Max           -0.07457721
Policy log std Min           -2.171361
Z mean eval                  0.9486265
Z variance eval              0.008459222
total_rewards                [ 670.74653948  402.10427385 3293.66198489 1884.05095879 1259.2085381
 2134.403461   3311.39767245 1694.6982548  3477.55139109 3572.8555957 ]
total_rewards_mean           2170.067867015595
total_rewards_std            1129.371611156039
total_rewards_max            3572.85559570363
total_rewards_min            402.1042738524714
Number of train steps total  916000
Number of env steps total    1147000
Number of rollouts total     0
Train Time (s)               115.1068600770086
(Previous) Eval Time (s)     20.141903867945075
Sample Time (s)              19.212952608708292
Epoch Time (s)               154.46171655366197
Total Train Time (s)         35140.35142286867
Epoch                        228
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:17:15.497050 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #228 | Epoch Duration: 151.73595094680786
2020-01-12 09:17:15.497333 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #228 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94840825
Z variance train             0.008458301
KL Divergence                22.684292
KL Loss                      2.2684293
QF Loss                      614.8596
VF Loss                      170.67145
Policy Loss                  -1235.186
Q Predictions Mean           1236.2031
Q Predictions Std            283.91742
Q Predictions Max            1440.9961
Q Predictions Min            2.7632658
V Predictions Mean           1240.4851
V Predictions Std            282.10095
V Predictions Max            1432.6902
V Predictions Min            18.513355
Log Pis Mean                 -0.030932177
Log Pis Std                  2.9369497
Log Pis Max                  10.658098
Log Pis Min                  -8.064463
Policy mu Mean               0.015410541
Policy mu Std                0.58904266
Policy mu Max                2.515582
Policy mu Min                -1.8417047
Policy log std Mean          -0.99432606
Policy log std Std           0.28182957
Policy log std Max           -0.052279055
Policy log std Min           -2.4144137
Z mean eval                  0.95599234
Z variance eval              0.012907961
total_rewards                [ 407.81896277 2779.59994284  861.78172072 3681.3092622  1067.8324903
 3389.49845346  546.37806944 3668.54721587  139.48973483  468.24663399]
total_rewards_mean           1701.0502486431317
total_rewards_std            1409.8199971001266
total_rewards_max            3681.3092621956584
total_rewards_min            139.48973483032069
Number of train steps total  920000
Number of env steps total    1152000
Number of rollouts total     0
Train Time (s)               124.0335711077787
(Previous) Eval Time (s)     17.415791244711727
Sample Time (s)              18.15645815851167
Epoch Time (s)               159.6058205110021
Total Train Time (s)         35297.08533703396
Epoch                        229
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:19:52.232001 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #229 | Epoch Duration: 156.7344741821289
2020-01-12 09:19:52.232246 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #229 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95543814
Z variance train             0.012872325
KL Divergence                22.617569
KL Loss                      2.261757
QF Loss                      564.379
VF Loss                      159.59297
Policy Loss                  -1217.62
Q Predictions Mean           1213.6322
Q Predictions Std            338.0097
Q Predictions Max            1474.8912
Q Predictions Min            19.58003
V Predictions Mean           1212.9526
V Predictions Std            329.92453
V Predictions Max            1467.6671
V Predictions Min            24.122128
Log Pis Mean                 -0.008467313
Log Pis Std                  3.0708427
Log Pis Max                  15.35964
Log Pis Min                  -7.3298883
Policy mu Mean               0.028095307
Policy mu Std                0.6225412
Policy mu Max                2.4357898
Policy mu Min                -2.0168073
Policy log std Mean          -0.960821
Policy log std Std           0.2994574
Policy log std Max           -0.21934605
Policy log std Min           -3.0226765
Z mean eval                  0.9607002
Z variance eval              0.01520838
total_rewards                [ 379.66185268  916.85843453 2499.49064577 3395.17640465 2622.9095484
 3061.30402879  365.86260645 3238.83944855 3564.27283148   67.05749489]
total_rewards_mean           2011.1433296198568
total_rewards_std            1337.766223841823
total_rewards_max            3564.272831480219
total_rewards_min            67.05749489420836
Number of train steps total  924000
Number of env steps total    1157000
Number of rollouts total     0
Train Time (s)               119.28073275182396
(Previous) Eval Time (s)     14.544110688846558
Sample Time (s)              17.70596426120028
Epoch Time (s)               151.5308077018708
Total Train Time (s)         35450.984445234295
Epoch                        230
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:22:26.134282 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #230 | Epoch Duration: 153.90188550949097
2020-01-12 09:22:26.134520 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #230 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9606001
Z variance train             0.015252034
KL Divergence                22.74403
KL Loss                      2.274403
QF Loss                      440.69592
VF Loss                      133.59082
Policy Loss                  -1224.3239
Q Predictions Mean           1221.4116
Q Predictions Std            300.26532
Q Predictions Max            1469.4513
Q Predictions Min            -11.573506
V Predictions Mean           1218.3892
V Predictions Std            297.47485
V Predictions Max            1466.7755
V Predictions Min            2.248836
Log Pis Mean                 0.27150112
Log Pis Std                  2.7605205
Log Pis Max                  9.484033
Log Pis Min                  -7.3001976
Policy mu Mean               0.041195493
Policy mu Std                0.61103463
Policy mu Max                3.2217953
Policy mu Min                -2.3869188
Policy log std Mean          -1.0035454
Policy log std Std           0.28794074
Policy log std Max           0.07414305
Policy log std Min           -2.1399808
Z mean eval                  1.0166007
Z variance eval              0.008131835
total_rewards                [3174.92413806 2272.40391982  974.77993436 3846.94434359 1515.26122727
 1071.13539453 2385.36213133 1288.09440547 1647.42959752 1815.83374905]
total_rewards_mean           1999.2168841010287
total_rewards_std            884.7723923070562
total_rewards_max            3846.9443435860994
total_rewards_min            974.7799343625385
Number of train steps total  928000
Number of env steps total    1162000
Number of rollouts total     0
Train Time (s)               121.76946428557858
(Previous) Eval Time (s)     16.914852993097156
Sample Time (s)              18.85158413928002
Epoch Time (s)               157.53590141795576
Total Train Time (s)         35607.05546565866
Epoch                        231
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:25:02.208238 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #231 | Epoch Duration: 156.07354593276978
2020-01-12 09:25:02.208436 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #231 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0163033
Z variance train             0.008142652
KL Divergence                23.616283
KL Loss                      2.3616283
QF Loss                      1422.895
VF Loss                      600.0027
Policy Loss                  -1225.976
Q Predictions Mean           1229.3594
Q Predictions Std            298.45724
Q Predictions Max            1485.9137
Q Predictions Min            -42.777836
V Predictions Mean           1226.212
V Predictions Std            295.95987
V Predictions Max            1479.8494
V Predictions Min            -28.71185
Log Pis Mean                 0.19753104
Log Pis Std                  3.1436524
Log Pis Max                  10.966827
Log Pis Min                  -10.2746315
Policy mu Mean               0.0077895015
Policy mu Std                0.63948315
Policy mu Max                2.7093513
Policy mu Min                -2.3644614
Policy log std Mean          -1.0344696
Policy log std Std           0.33662355
Policy log std Max           -0.12912548
Policy log std Min           -2.9685006
Z mean eval                  0.9406458
Z variance eval              0.011848541
total_rewards                [3190.92437967 3313.01295609 3489.13195228 3343.87364425 3509.64357764
 3203.8638053  3449.64910343 3312.1792495  3381.9064508  3079.89674095]
total_rewards_mean           3327.408185991223
total_rewards_std            131.5828372545018
total_rewards_max            3509.6435776382277
total_rewards_min            3079.896740946
Number of train steps total  932000
Number of env steps total    1167000
Number of rollouts total     0
Train Time (s)               116.98205504287034
(Previous) Eval Time (s)     15.452130210120231
Sample Time (s)              18.137147264555097
Epoch Time (s)               150.57133251754567
Total Train Time (s)         35768.90891306754
Epoch                        232
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:27:44.063641 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #232 | Epoch Duration: 161.85506510734558
2020-01-12 09:27:44.063823 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #232 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.940693
Z variance train             0.0118808765
KL Divergence                21.479368
KL Loss                      2.1479368
QF Loss                      673.33154
VF Loss                      130.20074
Policy Loss                  -1241.2961
Q Predictions Mean           1242.8613
Q Predictions Std            257.13556
Q Predictions Max            1432.6653
Q Predictions Min            78.26098
V Predictions Mean           1245.0242
V Predictions Std            259.7748
V Predictions Max            1435.8219
V Predictions Min            58.751114
Log Pis Mean                 0.27703243
Log Pis Std                  3.2993476
Log Pis Max                  21.415985
Log Pis Min                  -8.181111
Policy mu Mean               -0.009855044
Policy mu Std                0.6072792
Policy mu Max                4.3625784
Policy mu Min                -4.831596
Policy log std Mean          -1.0340389
Policy log std Std           0.31758636
Policy log std Max           -0.0016020536
Policy log std Min           -2.6243849
Z mean eval                  0.95019263
Z variance eval              0.007304164
total_rewards                [ -32.43302411 3472.28474763 3406.45898692 3340.559603      7.63446019
 3391.03155904 1251.11870456 1321.43611272  670.81903971 3478.79435119]
total_rewards_mean           2030.7704540857394
total_rewards_std            1447.1862783631634
total_rewards_max            3478.794351190939
total_rewards_min            -32.43302411438115
Number of train steps total  936000
Number of env steps total    1172000
Number of rollouts total     0
Train Time (s)               114.72221246687695
(Previous) Eval Time (s)     26.735573388636112
Sample Time (s)              18.95705956593156
Epoch Time (s)               160.41484542144462
Total Train Time (s)         35923.263505849056
Epoch                        233
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:30:18.419746 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #233 | Epoch Duration: 154.35577654838562
2020-01-12 09:30:18.419910 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #233 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.949073
Z variance train             0.00731232
KL Divergence                22.152153
KL Loss                      2.2152154
QF Loss                      787.022
VF Loss                      207.33194
Policy Loss                  -1245.3718
Q Predictions Mean           1245.9666
Q Predictions Std            296.25363
Q Predictions Max            1460.6268
Q Predictions Min            -19.428612
V Predictions Mean           1244.0798
V Predictions Std            296.70425
V Predictions Max            1454.4756
V Predictions Min            -15.759314
Log Pis Mean                 0.5102752
Log Pis Std                  2.8948293
Log Pis Max                  11.157572
Log Pis Min                  -7.3136597
Policy mu Mean               0.015037176
Policy mu Std                0.6456638
Policy mu Max                2.5277743
Policy mu Min                -2.0578349
Policy log std Mean          -1.0008335
Policy log std Std           0.3138573
Policy log std Max           -0.03622377
Policy log std Min           -2.5696669
Z mean eval                  0.9941152
Z variance eval              0.007508021
total_rewards                [3310.41896533  -37.38021739 1743.48808975 1087.08773978 1576.42271979
 3610.78906504 3778.74864367  406.29093443 2736.57082334 3609.85025501]
total_rewards_mean           2182.228701874867
total_rewards_std            1343.4031055761307
total_rewards_max            3778.7486436657327
total_rewards_min            -37.38021738653009
Number of train steps total  940000
Number of env steps total    1177000
Number of rollouts total     0
Train Time (s)               115.717852354981
(Previous) Eval Time (s)     20.67613456165418
Sample Time (s)              19.28221038542688
Epoch Time (s)               155.67619730206206
Total Train Time (s)         36078.93728120206
Epoch                        234
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:32:54.096316 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #234 | Epoch Duration: 155.67626905441284
2020-01-12 09:32:54.096505 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #234 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99358827
Z variance train             0.0075028753
KL Divergence                22.546495
KL Loss                      2.2546496
QF Loss                      6747.5244
VF Loss                      422.5514
Policy Loss                  -1220.0597
Q Predictions Mean           1220.9055
Q Predictions Std            315.05664
Q Predictions Max            1443.9186
Q Predictions Min            -6.362926
V Predictions Mean           1216.8556
V Predictions Std            311.28738
V Predictions Max            1440.0647
V Predictions Min            15.55743
Log Pis Mean                 0.26681837
Log Pis Std                  2.7268836
Log Pis Max                  10.801922
Log Pis Min                  -7.008031
Policy mu Mean               -0.0057027712
Policy mu Std                0.60188425
Policy mu Max                2.215045
Policy mu Min                -2.0457196
Policy log std Mean          -1.0206497
Policy log std Std           0.3153041
Policy log std Max           0.1648413
Policy log std Min           -2.8136907
Z mean eval                  0.95771265
Z variance eval              0.0063461578
total_rewards                [3076.59141623  372.66708997  257.01432843 3469.59320417  515.44822691
  488.30278585 3551.63339044 1262.76001818 3398.55516896 3651.09880193]
total_rewards_mean           2004.3664431077134
total_rewards_std            1453.5153688255336
total_rewards_max            3651.0988019331808
total_rewards_min            257.0143284337203
Number of train steps total  944000
Number of env steps total    1182000
Number of rollouts total     0
Train Time (s)               113.18380849668756
(Previous) Eval Time (s)     20.67587053682655
Sample Time (s)              17.790798285976052
Epoch Time (s)               151.65047731949016
Total Train Time (s)         36225.149464453105
Epoch                        235
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:35:20.309946 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #235 | Epoch Duration: 146.21332097053528
2020-01-12 09:35:20.310098 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #235 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9567021
Z variance train             0.0063437643
KL Divergence                22.114643
KL Loss                      2.2114644
QF Loss                      479.2448
VF Loss                      99.82994
Policy Loss                  -1236.6625
Q Predictions Mean           1238.0532
Q Predictions Std            318.34778
Q Predictions Max            1463.2354
Q Predictions Min            2.706078
V Predictions Mean           1234.3547
V Predictions Std            316.05563
V Predictions Max            1456.214
V Predictions Min            10.721182
Log Pis Mean                 -0.32252258
Log Pis Std                  2.679791
Log Pis Max                  7.96618
Log Pis Min                  -8.101751
Policy mu Mean               -0.00801393
Policy mu Std                0.57833725
Policy mu Max                2.3419867
Policy mu Min                -2.018803
Policy log std Mean          -0.99422276
Policy log std Std           0.28995404
Policy log std Max           -0.07818723
Policy log std Min           -2.4220243
Z mean eval                  0.9679101
Z variance eval              0.009089594
total_rewards                [1334.87568823 3586.25140156 2738.40242677 3602.25589522  334.74565859
  812.87323376   45.65600997   11.30872687 3606.80927227 3724.36700145]
total_rewards_mean           1979.7545314687225
total_rewards_std            1535.5429056761727
total_rewards_max            3724.367001453421
total_rewards_min            11.308726868691421
Number of train steps total  948000
Number of env steps total    1187000
Number of rollouts total     0
Train Time (s)               120.22143491078168
(Previous) Eval Time (s)     15.238381050992757
Sample Time (s)              17.971470680087805
Epoch Time (s)               153.43128664186224
Total Train Time (s)         36382.40667147515
Epoch                        236
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:37:57.569324 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #236 | Epoch Duration: 157.25911259651184
2020-01-12 09:37:57.569474 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #236 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96718633
Z variance train             0.009104892
KL Divergence                20.488955
KL Loss                      2.0488956
QF Loss                      475.91208
VF Loss                      532.1113
Policy Loss                  -1284.8254
Q Predictions Mean           1282.6763
Q Predictions Std            260.52536
Q Predictions Max            1462.7234
Q Predictions Min            -7.5222893
V Predictions Mean           1290.0864
V Predictions Std            255.70866
V Predictions Max            1468.966
V Predictions Min            1.9863231
Log Pis Mean                 0.38213435
Log Pis Std                  2.96816
Log Pis Max                  16.21836
Log Pis Min                  -6.6968517
Policy mu Mean               -0.013486513
Policy mu Std                0.6235156
Policy mu Max                2.4531386
Policy mu Min                -2.346136
Policy log std Mean          -1.026244
Policy log std Std           0.27735564
Policy log std Max           -0.23980105
Policy log std Min           -2.544796
Z mean eval                  0.9354867
Z variance eval              0.005027742
total_rewards                [3212.80470166 1934.78593609 1303.60968205  630.52115982 2145.53659713
 2535.66335248 3558.65340065 1079.84965534  637.47689855 2711.13832336]
total_rewards_mean           1975.0039707114156
total_rewards_std            988.7220032793622
total_rewards_max            3558.6534006487595
total_rewards_min            630.5211598233528
Number of train steps total  952000
Number of env steps total    1192000
Number of rollouts total     0
Train Time (s)               118.34115603659302
(Previous) Eval Time (s)     19.06589100509882
Sample Time (s)              18.314107098151
Epoch Time (s)               155.72115413984284
Total Train Time (s)         36538.55544199282
Epoch                        237
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:40:33.738277 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #237 | Epoch Duration: 156.16867780685425
2020-01-12 09:40:33.738466 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #237 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9356295
Z variance train             0.0050248792
KL Divergence                22.224958
KL Loss                      2.2224958
QF Loss                      4063.361
VF Loss                      175.19257
Policy Loss                  -1236.1342
Q Predictions Mean           1233.2114
Q Predictions Std            301.23297
Q Predictions Max            1455.5674
Q Predictions Min            -30.490496
V Predictions Mean           1236.1744
V Predictions Std            299.45477
V Predictions Max            1455.1727
V Predictions Min            -9.412813
Log Pis Mean                 0.16584365
Log Pis Std                  3.1315017
Log Pis Max                  13.702901
Log Pis Min                  -7.8350677
Policy mu Mean               -0.0067243474
Policy mu Std                0.6097294
Policy mu Max                2.8943694
Policy mu Min                -2.2864602
Policy log std Mean          -1.0172534
Policy log std Std           0.30635002
Policy log std Max           -0.017835498
Policy log std Min           -2.8013444
Z mean eval                  0.98100966
Z variance eval              0.010080594
total_rewards                [2703.15544836 3844.3426552   325.41603979 3447.70481699  881.61518313
  160.68390642 1822.00833515 1514.09804238 3897.18307914   10.51502291]
total_rewards_mean           1860.6722529460014
total_rewards_std            1451.240504742606
total_rewards_max            3897.1830791405014
total_rewards_min            10.515022909164175
Number of train steps total  956000
Number of env steps total    1197000
Number of rollouts total     0
Train Time (s)               115.47374833701178
(Previous) Eval Time (s)     19.513102439697832
Sample Time (s)              18.319904300849885
Epoch Time (s)               153.3067550775595
Total Train Time (s)         36688.318513716105
Epoch                        238
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:43:03.489392 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #238 | Epoch Duration: 149.75076723098755
2020-01-12 09:43:03.489676 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #238 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98337585
Z variance train             0.010103839
KL Divergence                21.172625
KL Loss                      2.1172626
QF Loss                      703.1026
VF Loss                      178.61418
Policy Loss                  -1257.7379
Q Predictions Mean           1257.91
Q Predictions Std            261.60736
Q Predictions Max            1467.3208
Q Predictions Min            -15.800036
V Predictions Mean           1256.9532
V Predictions Std            257.30978
V Predictions Max            1459.8712
V Predictions Min            -2.0504353
Log Pis Mean                 0.31817883
Log Pis Std                  2.9862235
Log Pis Max                  9.285051
Log Pis Min                  -7.1347437
Policy mu Mean               0.019030306
Policy mu Std                0.6202512
Policy mu Max                2.5809665
Policy mu Min                -2.6625423
Policy log std Mean          -1.0528167
Policy log std Std           0.30013868
Policy log std Max           -0.22314644
Policy log std Min           -2.6350298
Z mean eval                  0.99924344
Z variance eval              0.0071810544
total_rewards                [3520.29698091 3430.8950669  3506.16229853 2055.56396338 3518.72374884
 3553.4519177  3453.28910204  668.59542559 3504.93563865 3669.64570167]
total_rewards_mean           3088.1559844216636
total_rewards_std            919.0490437523903
total_rewards_max            3669.6457016697104
total_rewards_min            668.5954255924091
Number of train steps total  960000
Number of env steps total    1202000
Number of rollouts total     0
Train Time (s)               117.52314059529454
(Previous) Eval Time (s)     15.956751646939665
Sample Time (s)              18.22684187674895
Epoch Time (s)               151.70673411898315
Total Train Time (s)         36847.39121510275
Epoch                        239
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:45:42.563900 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #239 | Epoch Duration: 159.07403111457825
2020-01-12 09:45:42.564100 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #239 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99824286
Z variance train             0.0071672476
KL Divergence                22.27657
KL Loss                      2.227657
QF Loss                      633.7422
VF Loss                      569.27264
Policy Loss                  -1252.3179
Q Predictions Mean           1254.7544
Q Predictions Std            284.0755
Q Predictions Max            1454.7845
Q Predictions Min            -29.304636
V Predictions Mean           1258.4714
V Predictions Std            276.54782
V Predictions Max            1453.7406
V Predictions Min            -6.256368
Log Pis Mean                 0.4270583
Log Pis Std                  3.1613703
Log Pis Max                  16.836567
Log Pis Min                  -6.5887833
Policy mu Mean               0.05744967
Policy mu Std                0.63074094
Policy mu Max                2.7295651
Policy mu Min                -2.364009
Policy log std Mean          -1.0164678
Policy log std Std           0.29714903
Policy log std Max           -0.18964815
Policy log std Min           -2.5543504
Z mean eval                  0.96161187
Z variance eval              0.006987388
total_rewards                [ 478.05166741 3633.76059379 3335.96180791 3645.49532126  -29.33187371
 1688.6517407  3484.96025454 1108.48992686    9.97390183 3538.81292926]
total_rewards_mean           2089.4826269846662
total_rewards_std            1514.6303069390133
total_rewards_max            3645.495321258276
total_rewards_min            -29.331873710953076
Number of train steps total  964000
Number of env steps total    1207000
Number of rollouts total     0
Train Time (s)               118.28051219228655
(Previous) Eval Time (s)     23.323696543928236
Sample Time (s)              17.546469167806208
Epoch Time (s)               159.150677904021
Total Train Time (s)         37003.623065687716
Epoch                        240
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:48:18.798764 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #240 | Epoch Duration: 156.23451709747314
2020-01-12 09:48:18.798982 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #240 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9615094
Z variance train             0.006988219
KL Divergence                22.804718
KL Loss                      2.2804718
QF Loss                      1174.9258
VF Loss                      226.8966
Policy Loss                  -1217.4952
Q Predictions Mean           1216.2859
Q Predictions Std            338.027
Q Predictions Max            1478.0934
Q Predictions Min            -38.569077
V Predictions Mean           1228.2577
V Predictions Std            336.26843
V Predictions Max            1477.3838
V Predictions Min            -23.248043
Log Pis Mean                 0.25820142
Log Pis Std                  3.046298
Log Pis Max                  9.566104
Log Pis Min                  -8.382069
Policy mu Mean               0.026429806
Policy mu Std                0.62036467
Policy mu Max                2.5962834
Policy mu Min                -2.2918851
Policy log std Mean          -1.0308417
Policy log std Std           0.33464494
Policy log std Max           0.4928807
Policy log std Min           -2.7325258
Z mean eval                  0.9727291
Z variance eval              0.008459719
total_rewards                [3824.47340499 1094.36533097  905.12230139  387.0670301  3572.67486789
 3565.91436421 2673.30975543 3462.92561872 3559.94340542 3546.43506035]
total_rewards_mean           2659.2231139466735
total_rewards_std            1262.8227275735105
total_rewards_max            3824.473404989949
total_rewards_min            387.0670300989517
Number of train steps total  968000
Number of env steps total    1212000
Number of rollouts total     0
Train Time (s)               116.07327903294936
(Previous) Eval Time (s)     20.407240443862975
Sample Time (s)              17.909462431445718
Epoch Time (s)               154.38998190825805
Total Train Time (s)         37157.74093583878
Epoch                        241
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:50:52.920389 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #241 | Epoch Duration: 154.12124490737915
2020-01-12 09:50:52.920584 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #241 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9731798
Z variance train             0.008471283
KL Divergence                22.293446
KL Loss                      2.2293446
QF Loss                      1570.4064
VF Loss                      900.4722
Policy Loss                  -1247.1432
Q Predictions Mean           1243.4783
Q Predictions Std            302.93063
Q Predictions Max            1481.02
Q Predictions Min            -30.82744
V Predictions Mean           1257.2422
V Predictions Std            299.66797
V Predictions Max            1487.3511
V Predictions Min            -15.645858
Log Pis Mean                 0.0802772
Log Pis Std                  2.8946195
Log Pis Max                  11.193363
Log Pis Min                  -6.7891183
Policy mu Mean               0.008017538
Policy mu Std                0.58497065
Policy mu Max                2.5283787
Policy mu Min                -2.2462666
Policy log std Mean          -1.0180601
Policy log std Std           0.29127404
Policy log std Max           -0.17554986
Policy log std Min           -2.6294956
Z mean eval                  0.9765967
Z variance eval              0.005917593
total_rewards                [2103.4740088   790.2758877  1182.13348996 1166.05718256 3334.57249827
 3697.37212672 2082.82362    3322.60634315 3375.77612163   11.43380727]
total_rewards_mean           2106.652508605074
total_rewards_std            1224.3454003613833
total_rewards_max            3697.3721267151764
total_rewards_min            11.43380726800358
Number of train steps total  972000
Number of env steps total    1217000
Number of rollouts total     0
Train Time (s)               118.06320700142533
(Previous) Eval Time (s)     20.13819362130016
Sample Time (s)              17.97498695831746
Epoch Time (s)               156.17638758104295
Total Train Time (s)         37310.95563356159
Epoch                        242
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:53:26.137310 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #242 | Epoch Duration: 153.2165937423706
2020-01-12 09:53:26.137517 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #242 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9761125
Z variance train             0.005912884
KL Divergence                22.906199
KL Loss                      2.2906199
QF Loss                      774.046
VF Loss                      114.41958
Policy Loss                  -1271.3068
Q Predictions Mean           1269.865
Q Predictions Std            304.7816
Q Predictions Max            1469.2478
Q Predictions Min            -34.66099
V Predictions Mean           1267.4382
V Predictions Std            301.0809
V Predictions Max            1461.0175
V Predictions Min            -26.842117
Log Pis Mean                 0.24196975
Log Pis Std                  2.84554
Log Pis Max                  8.006838
Log Pis Min                  -7.9197526
Policy mu Mean               -0.005964038
Policy mu Std                0.58656454
Policy mu Max                2.3548112
Policy mu Min                -2.2612193
Policy log std Mean          -1.0032662
Policy log std Std           0.28526127
Policy log std Max           -0.14434707
Policy log std Min           -2.507091
Z mean eval                  0.9706761
Z variance eval              0.0040151845
total_rewards                [1898.76964559 1644.31867087 3457.88485972 3408.41429925 3553.71607041
 3697.64048604 3548.81123843    4.82281726 3647.27213306 3326.3397373 ]
total_rewards_mean           2818.798995793674
total_rewards_std            1170.031863206046
total_rewards_max            3697.6404860420607
total_rewards_min            4.822817259410636
Number of train steps total  976000
Number of env steps total    1222000
Number of rollouts total     0
Train Time (s)               117.4741996456869
(Previous) Eval Time (s)     17.17808380909264
Sample Time (s)              18.13577906275168
Epoch Time (s)               152.78806251753122
Total Train Time (s)         37470.139652711805
Epoch                        243
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:56:05.328744 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #243 | Epoch Duration: 159.1910719871521
2020-01-12 09:56:05.328983 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #243 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9687211
Z variance train             0.0040270602
KL Divergence                23.4995
KL Loss                      2.34995
QF Loss                      7894.5195
VF Loss                      438.11554
Policy Loss                  -1228.6519
Q Predictions Mean           1232.3617
Q Predictions Std            352.33597
Q Predictions Max            1489.2228
Q Predictions Min            -17.83775
V Predictions Mean           1220.817
V Predictions Std            343.45972
V Predictions Max            1474.595
V Predictions Min            -9.706627
Log Pis Mean                 0.008727379
Log Pis Std                  3.229444
Log Pis Max                  20.627157
Log Pis Min                  -6.548931
Policy mu Mean               -0.016704043
Policy mu Std                0.61331755
Policy mu Max                3.6231625
Policy mu Min                -2.3972442
Policy log std Mean          -0.988366
Policy log std Std           0.31509945
Policy log std Max           -0.20405513
Policy log std Min           -2.7600007
Z mean eval                  0.97024536
Z variance eval              0.010433867
total_rewards                [3570.80311344 1566.12051024 2038.92162065  590.42024661 3445.40076003
 1106.79951497 3557.32205446  355.31328445 1892.09423974 3827.19231973]
total_rewards_mean           2195.038766430933
total_rewards_std            1250.2485699237627
total_rewards_max            3827.192319728111
total_rewards_min            355.31328444967846
Number of train steps total  980000
Number of env steps total    1227000
Number of rollouts total     0
Train Time (s)               116.79389208322391
(Previous) Eval Time (s)     23.580759588163346
Sample Time (s)              18.141596700064838
Epoch Time (s)               158.5162483714521
Total Train Time (s)         37623.94295072602
Epoch                        244
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:58:39.134870 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #244 | Epoch Duration: 153.80264711380005
2020-01-12 09:58:39.135214 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #244 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9684669
Z variance train             0.010429255
KL Divergence                22.67953
KL Loss                      2.267953
QF Loss                      794.70435
VF Loss                      1440.4404
Policy Loss                  -1275.3672
Q Predictions Mean           1283.6143
Q Predictions Std            270.85922
Q Predictions Max            1467.5056
Q Predictions Min            -97.020905
V Predictions Mean           1281.1743
V Predictions Std            267.5161
V Predictions Max            1476.533
V Predictions Min            -28.941637
Log Pis Mean                 0.540589
Log Pis Std                  2.81953
Log Pis Max                  13.762161
Log Pis Min                  -6.621544
Policy mu Mean               -0.009008473
Policy mu Std                0.6433388
Policy mu Max                3.8186977
Policy mu Min                -2.5143404
Policy log std Mean          -1.0047454
Policy log std Std           0.31139675
Policy log std Max           0.6424364
Policy log std Min           -3.2256284
Z mean eval                  0.9875058
Z variance eval              0.013703754
total_rewards                [1746.67483812   92.58547233 2248.73730997  434.58391574  618.89201572
 2343.43838733  857.36184476   77.24583812 3784.585753   2881.66427973]
total_rewards_mean           1508.5769654801375
total_rewards_std            1216.138500278685
total_rewards_max            3784.5857529972145
total_rewards_min            77.24583812039792
Number of train steps total  984000
Number of env steps total    1232000
Number of rollouts total     0
Train Time (s)               116.67906179092824
(Previous) Eval Time (s)     18.8668143148534
Sample Time (s)              17.370951178018004
Epoch Time (s)               152.91682728379965
Total Train Time (s)         37773.969051672146
Epoch                        245
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:01:09.159540 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #245 | Epoch Duration: 150.02412033081055
2020-01-12 10:01:09.159746 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #245 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98707163
Z variance train             0.013702887
KL Divergence                22.331026
KL Loss                      2.2331026
QF Loss                      11466.68
VF Loss                      628.3255
Policy Loss                  -1269.7938
Q Predictions Mean           1267.7012
Q Predictions Std            295.69907
Q Predictions Max            1480.4531
Q Predictions Min            -98.72942
V Predictions Mean           1269.7382
V Predictions Std            287.13593
V Predictions Max            1484.302
V Predictions Min            -38.453568
Log Pis Mean                 0.36973527
Log Pis Std                  3.0249848
Log Pis Max                  9.311731
Log Pis Min                  -7.541295
Policy mu Mean               -0.020763775
Policy mu Std                0.6230315
Policy mu Max                2.2644758
Policy mu Min                -2.1529355
Policy log std Mean          -1.0282553
Policy log std Std           0.3421897
Policy log std Max           0.80104685
Policy log std Min           -2.5921357
Z mean eval                  0.9799172
Z variance eval              0.00744467
total_rewards                [1574.41585743 3652.2920116  3685.97726005 2788.04654819 2483.49538257
  464.36213733 3471.42223553 1500.13817107  721.45672294 3595.00775935]
total_rewards_mean           2393.6614086071563
total_rewards_std            1183.6660731989753
total_rewards_max            3685.97726004682
total_rewards_min            464.36213733402144
Number of train steps total  988000
Number of env steps total    1237000
Number of rollouts total     0
Train Time (s)               117.83237391337752
(Previous) Eval Time (s)     15.973834806121886
Sample Time (s)              18.18637660285458
Epoch Time (s)               151.992585322354
Total Train Time (s)         37928.415317602456
Epoch                        246
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:03:43.612136 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #246 | Epoch Duration: 154.4521505832672
2020-01-12 10:03:43.612417 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #246 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9805042
Z variance train             0.007441265
KL Divergence                24.445805
KL Loss                      2.4445806
QF Loss                      579.61865
VF Loss                      686.74713
Policy Loss                  -1269.172
Q Predictions Mean           1271.9187
Q Predictions Std            321.01495
Q Predictions Max            1480.8805
Q Predictions Min            -23.445755
V Predictions Mean           1268.6733
V Predictions Std            312.21185
V Predictions Max            1482.5488
V Predictions Min            -27.220617
Log Pis Mean                 0.59014285
Log Pis Std                  2.7273538
Log Pis Max                  12.962915
Log Pis Min                  -6.2033043
Policy mu Mean               -0.008699742
Policy mu Std                0.65794474
Policy mu Max                4.213619
Policy mu Min                -2.5426126
Policy log std Mean          -1.0040494
Policy log std Std           0.29587603
Policy log std Max           0.48872805
Policy log std Min           -2.8758144
Z mean eval                  0.9617671
Z variance eval              0.003262835
total_rewards                [3754.28219044 3701.55702438 3658.73269151   11.62222851 1528.68236284
 3429.2489478  3879.49427391 1975.01570167 3605.18132637 3615.35518803]
total_rewards_mean           2915.9171935450986
total_rewards_std            1235.8314952025498
total_rewards_max            3879.4942739055755
total_rewards_min            11.622228509993198
Number of train steps total  992000
Number of env steps total    1242000
Number of rollouts total     0
Train Time (s)               117.79689159197733
(Previous) Eval Time (s)     18.433078672271222
Sample Time (s)              18.18006713874638
Epoch Time (s)               154.41003740299493
Total Train Time (s)         38085.432318367064
Epoch                        247
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:06:20.632804 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #247 | Epoch Duration: 157.02016234397888
2020-01-12 10:06:20.633064 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #247 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9629633
Z variance train             0.0032759018
KL Divergence                24.411324
KL Loss                      2.4411323
QF Loss                      642.1747
VF Loss                      164.71628
Policy Loss                  -1290.8165
Q Predictions Mean           1296.5818
Q Predictions Std            257.72458
Q Predictions Max            1517.2
Q Predictions Min            -35.751846
V Predictions Mean           1292.9207
V Predictions Std            253.20734
V Predictions Max            1492.0381
V Predictions Min            -25.67595
Log Pis Mean                 0.3655962
Log Pis Std                  3.1231575
Log Pis Max                  13.803125
Log Pis Min                  -7.58508
Policy mu Mean               0.040553555
Policy mu Std                0.6126739
Policy mu Max                3.1588736
Policy mu Min                -2.1783736
Policy log std Mean          -1.0571856
Policy log std Std           0.29664508
Policy log std Max           -0.11025262
Policy log std Min           -2.3162446
Z mean eval                  0.9687708
Z variance eval              0.012474885
total_rewards                [3752.49041714 3450.76760019 3372.09561174 3702.82964807 3642.09326509
  913.4006646  2293.59609954 1075.82381334 3740.60049037 3813.89535168]
total_rewards_mean           2975.759296177228
total_rewards_std            1075.8502471894208
total_rewards_max            3813.8953516783263
total_rewards_min            913.4006646048155
Number of train steps total  996000
Number of env steps total    1247000
Number of rollouts total     0
Train Time (s)               113.11653356812894
(Previous) Eval Time (s)     21.042923123110086
Sample Time (s)              17.824933116324246
Epoch Time (s)               151.98438980756328
Total Train Time (s)         38242.01106020156
Epoch                        248
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:08:57.216607 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #248 | Epoch Duration: 156.5833239555359
2020-01-12 10:08:57.216899 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #248 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96882135
Z variance train             0.012481367
KL Divergence                21.826694
KL Loss                      2.1826694
QF Loss                      735.183
VF Loss                      204.49522
Policy Loss                  -1265.5636
Q Predictions Mean           1266.2609
Q Predictions Std            324.06113
Q Predictions Max            1511.4476
Q Predictions Min            -44.01334
V Predictions Mean           1268.9573
V Predictions Std            324.88992
V Predictions Max            1503.5071
V Predictions Min            -40.348537
Log Pis Mean                 0.58896077
Log Pis Std                  3.0915651
Log Pis Max                  13.265933
Log Pis Min                  -8.661488
Policy mu Mean               -0.028325152
Policy mu Std                0.6277987
Policy mu Max                2.2142088
Policy mu Min                -2.1307433
Policy log std Mean          -1.024452
Policy log std Std           0.30462068
Policy log std Max           -0.16486287
Policy log std Min           -2.7536445
Z mean eval                  0.97982967
Z variance eval              0.014060224
total_rewards                [1034.59543189 3820.84268038 1134.2019084    13.41128913   94.79581718
 3587.00847075 3712.97336112   12.48065621  585.03295053  597.53977274]
total_rewards_mean           1459.2882338329143
total_rewards_std            1517.295591837946
total_rewards_max            3820.8426803826424
total_rewards_min            12.48065621191082
Number of train steps total  1000000
Number of env steps total    1252000
Number of rollouts total     0
Train Time (s)               118.73300685407594
(Previous) Eval Time (s)     25.641536517068744
Sample Time (s)              18.248999669682235
Epoch Time (s)               162.62354304082692
Total Train Time (s)         38389.7651758804
Epoch                        249
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:11:24.972795 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #249 | Epoch Duration: 147.7556848526001
2020-01-12 10:11:24.972990 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #249 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9831163
Z variance train             0.014027084
KL Divergence                21.745312
KL Loss                      2.1745312
QF Loss                      677.75037
VF Loss                      509.26218
Policy Loss                  -1283.8649
Q Predictions Mean           1284.1189
Q Predictions Std            297.66055
Q Predictions Max            1484.6295
Q Predictions Min            -38.405453
V Predictions Mean           1283.9688
V Predictions Std            295.39233
V Predictions Max            1487.1199
V Predictions Min            -31.611273
Log Pis Mean                 0.25818098
Log Pis Std                  3.070215
Log Pis Max                  14.612398
Log Pis Min                  -9.143599
Policy mu Mean               -0.01767417
Policy mu Std                0.5934029
Policy mu Max                2.3493059
Policy mu Min                -2.3308754
Policy log std Mean          -1.0368035
Policy log std Std           0.30523854
Policy log std Max           0.064573646
Policy log std Min           -2.7239068
Z mean eval                  0.9633249
Z variance eval              0.008769885
total_rewards                [ 223.53093111  136.42834401 1671.93887444 1701.89020633 3708.34440901
 1362.58824434 3566.84518362 3599.47390396 3593.22929518 1393.09205723]
total_rewards_mean           2095.736144922466
total_rewards_std            1340.833805115055
total_rewards_max            3708.3444090100916
total_rewards_min            136.42834401304043
Number of train steps total  1004000
Number of env steps total    1257000
Number of rollouts total     0
Train Time (s)               116.92964508524165
(Previous) Eval Time (s)     10.773357870057225
Sample Time (s)              17.89046095032245
Epoch Time (s)               145.59346390562132
Total Train Time (s)         38541.54359019548
Epoch                        250
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:13:56.754489 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #250 | Epoch Duration: 151.78135347366333
2020-01-12 10:13:56.754644 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #250 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96538866
Z variance train             0.008769629
KL Divergence                22.43244
KL Loss                      2.243244
QF Loss                      821.15094
VF Loss                      411.02383
Policy Loss                  -1297.5566
Q Predictions Mean           1299.3513
Q Predictions Std            245.07643
Q Predictions Max            1496.3182
Q Predictions Min            -65.940445
V Predictions Mean           1305.7601
V Predictions Std            241.45836
V Predictions Max            1488.234
V Predictions Min            -31.88281
Log Pis Mean                 0.35010642
Log Pis Std                  2.9593425
Log Pis Max                  12.15114
Log Pis Min                  -7.925489
Policy mu Mean               0.044164993
Policy mu Std                0.6122018
Policy mu Max                2.6352577
Policy mu Min                -2.421898
Policy log std Mean          -1.0537038
Policy log std Std           0.3175098
Policy log std Max           -0.20276552
Policy log std Min           -3.0747554
Z mean eval                  1.0211923
Z variance eval              0.009103521
total_rewards                [3663.23324656 3625.18704289 -112.78146185 3731.65362902 3589.70272162
 3890.50856364 3688.62368721 3646.95398837 3091.84932991 3688.40311915]
total_rewards_mean           3250.333386650558
total_rewards_std            1137.7449888544875
total_rewards_max            3890.5085636361355
total_rewards_min            -112.78146185270319
Number of train steps total  1008000
Number of env steps total    1262000
Number of rollouts total     0
Train Time (s)               120.12579547334462
(Previous) Eval Time (s)     16.960934496950358
Sample Time (s)              17.94631071249023
Epoch Time (s)               155.0330406827852
Total Train Time (s)         38706.90044306591
Epoch                        251
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:16:42.112117 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #251 | Epoch Duration: 165.35735321044922
2020-01-12 10:16:42.112359 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #251 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.020683
Z variance train             0.009106748
KL Divergence                22.433062
KL Loss                      2.2433062
QF Loss                      492.49384
VF Loss                      225.06766
Policy Loss                  -1266.6836
Q Predictions Mean           1268.2195
Q Predictions Std            328.98257
Q Predictions Max            1509.9528
Q Predictions Min            -39.19217
V Predictions Mean           1261.0856
V Predictions Std            327.3114
V Predictions Max            1499.5496
V Predictions Min            -26.20852
Log Pis Mean                 -0.18055707
Log Pis Std                  2.7064857
Log Pis Max                  10.998489
Log Pis Min                  -6.167228
Policy mu Mean               -0.013495419
Policy mu Std                0.5985174
Policy mu Max                2.5187302
Policy mu Min                -2.5059223
Policy log std Mean          -0.9866965
Policy log std Std           0.3001274
Policy log std Max           -0.028009057
Policy log std Min           -2.7628942
Z mean eval                  1.0450227
Z variance eval              0.010492179
total_rewards                [ 894.66987865 3783.60795783 3398.05228117  567.56382706 1851.02394359
  240.70078976 2209.61393219 3659.077587   3946.62847009  926.53885438]
total_rewards_mean           2147.7477521704413
total_rewards_std            1380.095172827965
total_rewards_max            3946.6284700908072
total_rewards_min            240.70078975605094
Number of train steps total  1012000
Number of env steps total    1267000
Number of rollouts total     0
Train Time (s)               119.54767083702609
(Previous) Eval Time (s)     27.28493902273476
Sample Time (s)              18.44024243718013
Epoch Time (s)               165.27285229694098
Total Train Time (s)         38860.61261053523
Epoch                        252
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:19:15.829079 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #252 | Epoch Duration: 153.7165403366089
2020-01-12 10:19:15.829391 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #252 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0440984
Z variance train             0.010460003
KL Divergence                21.696907
KL Loss                      2.1696908
QF Loss                      608.7462
VF Loss                      117.853546
Policy Loss                  -1308.6068
Q Predictions Mean           1308.5742
Q Predictions Std            271.50195
Q Predictions Max            1508.444
Q Predictions Min            -23.241154
V Predictions Mean           1306.1509
V Predictions Std            265.668
V Predictions Max            1498.9867
V Predictions Min            -27.570024
Log Pis Mean                 0.44282675
Log Pis Std                  3.1472716
Log Pis Max                  16.507383
Log Pis Min                  -7.8654604
Policy mu Mean               0.0379851
Policy mu Std                0.65029913
Policy mu Max                2.891337
Policy mu Min                -2.2440922
Policy log std Mean          -1.0102959
Policy log std Std           0.3141608
Policy log std Max           0.088131905
Policy log std Min           -3.1816182
Z mean eval                  0.99028844
Z variance eval              0.012017301
total_rewards                [1227.80225413 3403.9026341  2493.30716119 3538.62529215  340.3104232
   69.05090589 3729.04569703  195.68626158 2083.7287486  1485.94189178]
total_rewards_mean           1856.7401269642712
total_rewards_std            1340.6067665007386
total_rewards_max            3729.0456970255204
total_rewards_min            69.05090589001375
Number of train steps total  1016000
Number of env steps total    1272000
Number of rollouts total     0
Train Time (s)               116.28484877990559
(Previous) Eval Time (s)     15.728269023820758
Sample Time (s)              17.783513375092298
Epoch Time (s)               149.79663117881864
Total Train Time (s)         39009.34089543251
Epoch                        253
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:21:44.563153 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #253 | Epoch Duration: 148.7335147857666
2020-01-12 10:21:44.563464 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #253 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9902231
Z variance train             0.012032283
KL Divergence                21.3148
KL Loss                      2.13148
QF Loss                      411.1593
VF Loss                      112.815674
Policy Loss                  -1260.1792
Q Predictions Mean           1262.3701
Q Predictions Std            352.00635
Q Predictions Max            1510.6058
Q Predictions Min            -39.190815
V Predictions Mean           1259.1357
V Predictions Std            352.07666
V Predictions Max            1500.8689
V Predictions Min            -30.833654
Log Pis Mean                 -0.004514843
Log Pis Std                  2.842129
Log Pis Max                  11.617707
Log Pis Min                  -9.429686
Policy mu Mean               0.020915892
Policy mu Std                0.5829963
Policy mu Max                2.3177109
Policy mu Min                -1.9691155
Policy log std Mean          -1.0221555
Policy log std Std           0.3033648
Policy log std Max           -0.13455796
Policy log std Min           -2.698787
Z mean eval                  0.9713672
Z variance eval              0.010875374
total_rewards                [1894.2303388  3682.6304218  2619.90433763 1171.56620987 3511.25510214
 2992.52203289 3552.58511616 3526.47200234  803.66401591 3465.50288734]
total_rewards_mean           2722.0332464864305
total_rewards_std            1014.3098138980572
total_rewards_max            3682.63042179688
total_rewards_min            803.6640159052045
Number of train steps total  1020000
Number of env steps total    1277000
Number of rollouts total     0
Train Time (s)               118.03497283905745
(Previous) Eval Time (s)     14.664841962978244
Sample Time (s)              18.24703427636996
Epoch Time (s)               150.94684907840565
Total Train Time (s)         39165.75295471866
Epoch                        254
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:24:20.975569 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #254 | Epoch Duration: 156.4118995666504
2020-01-12 10:24:20.975715 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #254 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97091705
Z variance train             0.010864457
KL Divergence                21.578213
KL Loss                      2.1578214
QF Loss                      2088.7085
VF Loss                      103.56984
Policy Loss                  -1291.1217
Q Predictions Mean           1292.2722
Q Predictions Std            281.66382
Q Predictions Max            1517.1847
Q Predictions Min            -33.607418
V Predictions Mean           1293.8921
V Predictions Std            276.13968
V Predictions Max            1516.1586
V Predictions Min            -33.883095
Log Pis Mean                 0.008701295
Log Pis Std                  2.9232867
Log Pis Max                  8.323246
Log Pis Min                  -7.149596
Policy mu Mean               0.03481649
Policy mu Std                0.59916854
Policy mu Max                2.9131413
Policy mu Min                -1.9182087
Policy log std Mean          -1.0016541
Policy log std Std           0.2844629
Policy log std Max           -0.12934095
Policy log std Min           -2.356133
Z mean eval                  0.9989176
Z variance eval              0.015404927
total_rewards                [ 149.21350563 3764.17570434 3712.17914019  851.10257723  269.12064638
 2877.48743753 2637.8535042  3496.86664093 2486.20849334 1064.99432025]
total_rewards_mean           2130.9201970033037
total_rewards_std            1346.9178509979863
total_rewards_max            3764.1757043446364
total_rewards_min            149.21350563090388
Number of train steps total  1024000
Number of env steps total    1282000
Number of rollouts total     0
Train Time (s)               118.49369625095278
(Previous) Eval Time (s)     20.12962974794209
Sample Time (s)              18.27212628815323
Epoch Time (s)               156.8954522870481
Total Train Time (s)         39318.91185774002
Epoch                        255
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:26:54.139422 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #255 | Epoch Duration: 153.16356205940247
2020-01-12 10:26:54.139634 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #255 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9981654
Z variance train             0.015417432
KL Divergence                20.881824
KL Loss                      2.0881824
QF Loss                      805.965
VF Loss                      821.6744
Policy Loss                  -1265.6301
Q Predictions Mean           1267.1189
Q Predictions Std            336.07825
Q Predictions Max            1498.3934
Q Predictions Min            -44.039627
V Predictions Mean           1262.6509
V Predictions Std            338.92923
V Predictions Max            1504.2788
V Predictions Min            -50.07618
Log Pis Mean                 0.08597678
Log Pis Std                  2.4725387
Log Pis Max                  6.676025
Log Pis Min                  -6.6560326
Policy mu Mean               0.059300084
Policy mu Std                0.60924
Policy mu Max                2.3860955
Policy mu Min                -1.7835016
Policy log std Mean          -0.97724015
Policy log std Std           0.30054685
Policy log std Max           0.4721105
Policy log std Min           -2.5341458
Z mean eval                  0.9887994
Z variance eval              0.00843959
total_rewards                [3579.38167167 1466.40891771 3254.04717268   14.85696211 1987.24670336
 3661.70467338 3799.85822941  777.33488965  521.67533728 3542.32223221]
total_rewards_mean           2260.4836789447127
total_rewards_std            1402.6440030396425
total_rewards_max            3799.858229407936
total_rewards_min            14.856962108968238
Number of train steps total  1028000
Number of env steps total    1287000
Number of rollouts total     0
Train Time (s)               115.10613527707756
(Previous) Eval Time (s)     16.397432981058955
Sample Time (s)              17.452604512684047
Epoch Time (s)               148.95617277082056
Total Train Time (s)         39472.88214354543
Epoch                        256
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:29:28.113953 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #256 | Epoch Duration: 153.97412729263306
2020-01-12 10:29:28.114251 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #256 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98787344
Z variance train             0.008438488
KL Divergence                22.165897
KL Loss                      2.2165897
QF Loss                      440.65082
VF Loss                      182.51338
Policy Loss                  -1265.9492
Q Predictions Mean           1265.5403
Q Predictions Std            337.89682
Q Predictions Max            1514.4524
Q Predictions Min            -69.42488
V Predictions Mean           1265.1937
V Predictions Std            335.96808
V Predictions Max            1510.4283
V Predictions Min            -55.95672
Log Pis Mean                 0.15951386
Log Pis Std                  2.9800618
Log Pis Max                  13.785721
Log Pis Min                  -6.427532
Policy mu Mean               -0.0032221524
Policy mu Std                0.60739243
Policy mu Max                2.9100509
Policy mu Min                -2.227535
Policy log std Mean          -1.021173
Policy log std Std           0.32585543
Policy log std Max           -0.07063192
Policy log std Min           -2.7099857
Z mean eval                  0.97321033
Z variance eval              0.010111146
total_rewards                [ 312.88257908 3574.57758002  282.18397777 3565.85485327 1270.95801334
   92.68275947 2827.92044039 3539.61710342  844.54961739 1956.04176909]
total_rewards_mean           1826.7268693243525
total_rewards_std            1378.0584002463527
total_rewards_max            3574.577580024441
total_rewards_min            92.68275947317613
Number of train steps total  1032000
Number of env steps total    1292000
Number of rollouts total     0
Train Time (s)               122.68078225990757
(Previous) Eval Time (s)     21.415056314785033
Sample Time (s)              17.797269692644477
Epoch Time (s)               161.89310826733708
Total Train Time (s)         39631.081206472125
Epoch                        257
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:32:06.316008 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #257 | Epoch Duration: 158.20154809951782
2020-01-12 10:32:06.316228 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #257 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97273254
Z variance train             0.0101204235
KL Divergence                22.179354
KL Loss                      2.2179353
QF Loss                      1642.335
VF Loss                      241.24176
Policy Loss                  -1296.3418
Q Predictions Mean           1294.3689
Q Predictions Std            296.55035
Q Predictions Max            1510.323
Q Predictions Min            -20.473524
V Predictions Mean           1293.113
V Predictions Std            291.01764
V Predictions Max            1500.7087
V Predictions Min            -24.10694
Log Pis Mean                 0.33768106
Log Pis Std                  3.1792045
Log Pis Max                  14.270832
Log Pis Min                  -9.482838
Policy mu Mean               0.02318098
Policy mu Std                0.58945996
Policy mu Max                2.510766
Policy mu Min                -1.870997
Policy log std Mean          -1.0589645
Policy log std Std           0.33857906
Policy log std Max           -0.0031241179
Policy log std Min           -3.2191677
Z mean eval                  0.9988651
Z variance eval              0.013174164
total_rewards                [2308.29569297 2835.47496077 2989.43110366 3553.86069628 1789.84490808
 3414.02945924 3076.23098671 1940.59988957 2046.6653804  1517.16508371]
total_rewards_mean           2547.159816138523
total_rewards_std            680.6934824856911
total_rewards_max            3553.8606962824724
total_rewards_min            1517.16508371064
Number of train steps total  1036000
Number of env steps total    1297000
Number of rollouts total     0
Train Time (s)               117.47517075901851
(Previous) Eval Time (s)     17.723210423253477
Sample Time (s)              18.08848739322275
Epoch Time (s)               153.28686857549474
Total Train Time (s)         39786.347362335306
Epoch                        258
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:34:41.585899 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #258 | Epoch Duration: 155.26952385902405
2020-01-12 10:34:41.586159 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #258 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9983125
Z variance train             0.013195649
KL Divergence                22.321293
KL Loss                      2.2321293
QF Loss                      437.0739
VF Loss                      75.29593
Policy Loss                  -1326.5178
Q Predictions Mean           1327.1974
Q Predictions Std            241.76585
Q Predictions Max            1520.4203
Q Predictions Min            -44.91536
V Predictions Mean           1326.2595
V Predictions Std            239.76541
V Predictions Max            1522.9957
V Predictions Min            -42.55439
Log Pis Mean                 0.41330075
Log Pis Std                  2.6681921
Log Pis Max                  9.978744
Log Pis Min                  -6.54929
Policy mu Mean               0.010013446
Policy mu Std                0.5872954
Policy mu Max                2.7312534
Policy mu Min                -2.234033
Policy log std Mean          -1.0367811
Policy log std Std           0.26948038
Policy log std Max           -0.19234431
Policy log std Min           -2.2116508
Z mean eval                  0.9898831
Z variance eval              0.016980413
total_rewards                [1505.78900064 3866.25904155 3639.4610968  3618.02838878 1835.77103366
  800.62691201 3958.93867418 3599.93265803 3775.91884413 3724.67068141]
total_rewards_mean           3032.539633118237
total_rewards_std            1111.8769641688625
total_rewards_max            3958.9386741761086
total_rewards_min            800.6269120149927
Number of train steps total  1040000
Number of env steps total    1302000
Number of rollouts total     0
Train Time (s)               114.88999563502148
(Previous) Eval Time (s)     19.705433371011168
Sample Time (s)              18.745363005902618
Epoch Time (s)               153.34079201193526
Total Train Time (s)         39942.448455459904
Epoch                        259
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:37:17.692970 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #259 | Epoch Duration: 156.10658383369446
2020-01-12 10:37:17.693292 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #259 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9896005
Z variance train             0.016982637
KL Divergence                21.771149
KL Loss                      2.177115
QF Loss                      985.2595
VF Loss                      182.39981
Policy Loss                  -1328.9506
Q Predictions Mean           1329.0912
Q Predictions Std            254.98033
Q Predictions Max            1531.5955
Q Predictions Min            -102.43266
V Predictions Mean           1330.6624
V Predictions Std            249.21324
V Predictions Max            1530.892
V Predictions Min            -59.753426
Log Pis Mean                 0.28330374
Log Pis Std                  2.9842436
Log Pis Max                  13.539634
Log Pis Min                  -7.271703
Policy mu Mean               0.028454097
Policy mu Std                0.5921761
Policy mu Max                3.1776705
Policy mu Min                -2.1900268
Policy log std Mean          -1.0731
Policy log std Std           0.30458468
Policy log std Max           -0.23430043
Policy log std Min           -2.9816859
Z mean eval                  1.0069615
Z variance eval              0.016856741
total_rewards                [1536.84982314 3706.79909285 1122.33110904 1125.17369826 3290.32556214
 3526.54609858 3710.89661323 1018.85034945 3765.06257872 3758.22037413]
total_rewards_mean           2656.1055299552204
total_rewards_std            1202.0998295411252
total_rewards_max            3765.0625787183894
total_rewards_min            1018.850349449299
Number of train steps total  1044000
Number of env steps total    1307000
Number of rollouts total     0
Train Time (s)               114.98808247596025
(Previous) Eval Time (s)     22.470879677217454
Sample Time (s)              18.004692597314715
Epoch Time (s)               155.46365475049242
Total Train Time (s)         40095.30922076013
Epoch                        260
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:39:50.556715 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #260 | Epoch Duration: 152.86318922042847
2020-01-12 10:39:50.556957 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #260 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0022601
Z variance train             0.016862605
KL Divergence                21.039555
KL Loss                      2.1039555
QF Loss                      1051.6846
VF Loss                      395.37744
Policy Loss                  -1292.2887
Q Predictions Mean           1292.5305
Q Predictions Std            315.48264
Q Predictions Max            1528.8722
Q Predictions Min            -58.033188
V Predictions Mean           1292.0812
V Predictions Std            311.65897
V Predictions Max            1540.2284
V Predictions Min            -67.17192
Log Pis Mean                 0.4657463
Log Pis Std                  3.2100427
Log Pis Max                  18.35838
Log Pis Min                  -6.885869
Policy mu Mean               0.050970256
Policy mu Std                0.6407026
Policy mu Max                2.2540815
Policy mu Min                -2.770262
Policy log std Mean          -1.0231092
Policy log std Std           0.32791102
Policy log std Max           -0.14690542
Policy log std Min           -2.8383472
Z mean eval                  0.9726803
Z variance eval              0.0084472
total_rewards                [3848.41407575  750.43302016 3593.648429   2281.18763077 1802.36835325
 3289.19285885 1550.2810851  3399.84688576  649.18572276 3588.36646077]
total_rewards_mean           2475.2924522185567
total_rewards_std            1163.9719501153106
total_rewards_max            3848.4140757543246
total_rewards_min            649.1857227630725
Number of train steps total  1048000
Number of env steps total    1312000
Number of rollouts total     0
Train Time (s)               115.81410162802786
(Previous) Eval Time (s)     19.870093994773924
Sample Time (s)              18.287441395688802
Epoch Time (s)               153.97163701849058
Total Train Time (s)         40248.213105376344
Epoch                        261
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:42:23.463681 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #261 | Epoch Duration: 152.9065396785736
2020-01-12 10:42:23.463909 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #261 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9738787
Z variance train             0.0084476005
KL Divergence                22.033264
KL Loss                      2.2033265
QF Loss                      1982.2313
VF Loss                      225.33286
Policy Loss                  -1309.5558
Q Predictions Mean           1313.262
Q Predictions Std            298.2624
Q Predictions Max            1521.7184
Q Predictions Min            -32.30938
V Predictions Mean           1308.9033
V Predictions Std            294.88644
V Predictions Max            1514.3656
V Predictions Min            -43.166767
Log Pis Mean                 0.49467593
Log Pis Std                  2.856164
Log Pis Max                  10.700058
Log Pis Min                  -8.101163
Policy mu Mean               0.030986773
Policy mu Std                0.6103195
Policy mu Max                2.4237323
Policy mu Min                -2.0727417
Policy log std Mean          -1.046036
Policy log std Std           0.3330877
Policy log std Max           -0.11401546
Policy log std Min           -3.009715
Z mean eval                  0.9732229
Z variance eval              0.016177172
total_rewards                [  57.39441559 3646.63189139 3539.55951941    6.44656557 3430.46394942
  654.41623676 2628.53327388 3578.34531625 3724.08838635 2954.43937677]
total_rewards_mean           2422.0318931374604
total_rewards_std            1472.2428040188017
total_rewards_max            3724.088386347427
total_rewards_min            6.446565567873108
Number of train steps total  1052000
Number of env steps total    1317000
Number of rollouts total     0
Train Time (s)               120.30736462306231
(Previous) Eval Time (s)     18.804679207038134
Sample Time (s)              18.37282308144495
Epoch Time (s)               157.4848669115454
Total Train Time (s)         40405.48390756175
Epoch                        262
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:45:00.736483 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #262 | Epoch Duration: 157.27242493629456
2020-01-12 10:45:00.736638 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #262 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9742826
Z variance train             0.016203377
KL Divergence                21.008804
KL Loss                      2.1008804
QF Loss                      524.9132
VF Loss                      120.74375
Policy Loss                  -1306.5308
Q Predictions Mean           1310.6062
Q Predictions Std            297.87814
Q Predictions Max            1541.0186
Q Predictions Min            -45.785378
V Predictions Mean           1304.531
V Predictions Std            298.875
V Predictions Max            1533.9073
V Predictions Min            -49.54596
Log Pis Mean                 -0.0720068
Log Pis Std                  3.1093085
Log Pis Max                  15.2184925
Log Pis Min                  -8.08409
Policy mu Mean               0.032674126
Policy mu Std                0.6175259
Policy mu Max                2.8154318
Policy mu Min                -2.3861582
Policy log std Mean          -0.9983375
Policy log std Std           0.30013835
Policy log std Max           -0.11879879
Policy log std Min           -2.9959512
Z mean eval                  0.98251355
Z variance eval              0.009577491
total_rewards                [3627.19403301 3564.70655703  852.68022797 2101.92887075 3616.93399229
  783.90893314 3566.04062887  138.37090148 3572.56611883 1703.2021363 ]
total_rewards_mean           2352.7532399670627
total_rewards_std            1332.328902397423
total_rewards_max            3627.1940330136995
total_rewards_min            138.37090147533533
Number of train steps total  1056000
Number of env steps total    1322000
Number of rollouts total     0
Train Time (s)               113.53078451100737
(Previous) Eval Time (s)     18.591905862092972
Sample Time (s)              18.215334243606776
Epoch Time (s)               150.33802461670712
Total Train Time (s)         40555.146632755175
Epoch                        263
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:47:30.405003 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #263 | Epoch Duration: 149.6682243347168
2020-01-12 10:47:30.405256 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #263 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9822634
Z variance train             0.009573358
KL Divergence                22.095694
KL Loss                      2.2095695
QF Loss                      651.5866
VF Loss                      267.6481
Policy Loss                  -1313.0531
Q Predictions Mean           1312.1471
Q Predictions Std            305.21164
Q Predictions Max            1546.85
Q Predictions Min            -94.9789
V Predictions Mean           1312.5999
V Predictions Std            296.24213
V Predictions Max            1541.9032
V Predictions Min            -58.005726
Log Pis Mean                 0.4997952
Log Pis Std                  3.3123026
Log Pis Max                  19.726692
Log Pis Min                  -7.451598
Policy mu Mean               0.014507576
Policy mu Std                0.61483115
Policy mu Max                2.4737566
Policy mu Min                -3.0138345
Policy log std Mean          -1.0536517
Policy log std Std           0.31631532
Policy log std Max           -0.1998452
Policy log std Min           -3.0693955
Z mean eval                  1.0100874
Z variance eval              0.011815886
total_rewards                [ 222.53228298 1731.19365842  953.06735383 3836.70672216 2887.37867295
 3484.87526152 3865.26457183 3820.55978198 1405.49785434  616.46059376]
total_rewards_mean           2282.3536753767658
total_rewards_std            1376.8635112876466
total_rewards_max            3865.264571826381
total_rewards_min            222.53228297980843
Number of train steps total  1060000
Number of env steps total    1327000
Number of rollouts total     0
Train Time (s)               120.76569068292156
(Previous) Eval Time (s)     17.92176759010181
Sample Time (s)              18.803301779087633
Epoch Time (s)               157.490760052111
Total Train Time (s)         40711.09917962598
Epoch                        264
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:50:06.360849 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #264 | Epoch Duration: 155.95541763305664
2020-01-12 10:50:06.361044 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #264 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0108883
Z variance train             0.011805016
KL Divergence                22.28244
KL Loss                      2.228244
QF Loss                      1312.0
VF Loss                      296.1858
Policy Loss                  -1287.6937
Q Predictions Mean           1284.9988
Q Predictions Std            322.80682
Q Predictions Max            1509.287
Q Predictions Min            -124.99234
V Predictions Mean           1289.775
V Predictions Std            316.29
V Predictions Max            1508.8549
V Predictions Min            -40.8753
Log Pis Mean                 0.61482
Log Pis Std                  3.3694022
Log Pis Max                  23.699991
Log Pis Min                  -6.915406
Policy mu Mean               -0.0027858065
Policy mu Std                0.64202166
Policy mu Max                5.353785
Policy mu Min                -2.8896005
Policy log std Mean          -1.0413822
Policy log std Std           0.34345204
Policy log std Max           -0.08933729
Policy log std Min           -2.7684093
Z mean eval                  0.98911965
Z variance eval              0.020672832
total_rewards                [ 640.20452126 3677.95277674   18.57679761 3326.64020102 3506.5628766
 3822.02755241 3447.20103056 3165.02173223 3527.90070038 3884.0631602 ]
total_rewards_mean           2901.6151349012066
total_rewards_std            1309.459429850569
total_rewards_max            3884.0631601991868
total_rewards_min            18.576797609678135
Number of train steps total  1064000
Number of env steps total    1332000
Number of rollouts total     0
Train Time (s)               120.43128324998543
(Previous) Eval Time (s)     16.386083520017564
Sample Time (s)              17.519499698188156
Epoch Time (s)               154.33686646819115
Total Train Time (s)         40870.196634385735
Epoch                        265
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:52:45.459512 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #265 | Epoch Duration: 159.09831404685974
2020-01-12 10:52:45.459662 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #265 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9908184
Z variance train             0.020740658
KL Divergence                21.576385
KL Loss                      2.1576385
QF Loss                      806.58276
VF Loss                      147.6176
Policy Loss                  -1318.0023
Q Predictions Mean           1317.7754
Q Predictions Std            291.5645
Q Predictions Max            1515.73
Q Predictions Min            -75.01511
V Predictions Mean           1310.106
V Predictions Std            290.31323
V Predictions Max            1496.8031
V Predictions Min            -74.71011
Log Pis Mean                 0.1310803
Log Pis Std                  2.9781253
Log Pis Max                  13.792971
Log Pis Min                  -7.960817
Policy mu Mean               -0.041431136
Policy mu Std                0.62148345
Policy mu Max                2.6473463
Policy mu Min                -2.2525284
Policy log std Mean          -1.0339897
Policy log std Std           0.26702917
Policy log std Max           -0.047589004
Policy log std Min           -2.2997534
Z mean eval                  0.99113643
Z variance eval              0.014478235
total_rewards                [1251.04241416 3393.61092902 3632.81058892    7.6072002  1918.04493165
 2618.42644601 1800.37059949 1637.81005049 1682.90662393 3581.11629164]
total_rewards_mean           2152.3746075519875
total_rewards_std            1098.5120145393946
total_rewards_max            3632.810588921243
total_rewards_min            7.6072002009791175
Number of train steps total  1068000
Number of env steps total    1337000
Number of rollouts total     0
Train Time (s)               122.78686919575557
(Previous) Eval Time (s)     21.147234966047108
Sample Time (s)              18.68083687266335
Epoch Time (s)               162.61494103446603
Total Train Time (s)         41028.755782933906
Epoch                        266
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:55:24.020750 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #266 | Epoch Duration: 158.56095814704895
2020-01-12 10:55:24.020901 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #266 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9912985
Z variance train             0.01448935
KL Divergence                21.893826
KL Loss                      2.1893826
QF Loss                      561.3109
VF Loss                      126.52588
Policy Loss                  -1292.9365
Q Predictions Mean           1295.9944
Q Predictions Std            330.11832
Q Predictions Max            1512.3395
Q Predictions Min            -77.248825
V Predictions Mean           1292.0293
V Predictions Std            330.43277
V Predictions Max            1519.1577
V Predictions Min            -77.54615
Log Pis Mean                 0.25498295
Log Pis Std                  3.1778898
Log Pis Max                  19.69496
Log Pis Min                  -7.52717
Policy mu Mean               0.017561331
Policy mu Std                0.6113117
Policy mu Max                4.076258
Policy mu Min                -2.0337362
Policy log std Mean          -1.0341213
Policy log std Std           0.28011551
Policy log std Max           -0.20599788
Policy log std Min           -2.2890143
Z mean eval                  1.0062299
Z variance eval              0.013497201
total_rewards                [1936.56460987 3644.71224941 2302.24187186  343.21337421 3634.81045605
 3521.68385303 3755.47069814 3597.21414264 2761.51243723  922.6719268 ]
total_rewards_mean           2642.0095619241024
total_rewards_std            1174.0982098265085
total_rewards_max            3755.4706981434465
total_rewards_min            343.2133742147148
Number of train steps total  1072000
Number of env steps total    1342000
Number of rollouts total     0
Train Time (s)               120.15099420910701
(Previous) Eval Time (s)     17.092944901436567
Sample Time (s)              17.587236350402236
Epoch Time (s)               154.83117546094581
Total Train Time (s)         41186.01535379654
Epoch                        267
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:58:01.287639 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #267 | Epoch Duration: 157.26657581329346
2020-01-12 10:58:01.287976 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #267 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0066004
Z variance train             0.013512343
KL Divergence                21.12409
KL Loss                      2.112409
QF Loss                      902.7317
VF Loss                      235.79993
Policy Loss                  -1290.434
Q Predictions Mean           1293.1245
Q Predictions Std            331.90662
Q Predictions Max            1528.3585
Q Predictions Min            -54.25442
V Predictions Mean           1290.632
V Predictions Std            329.2133
V Predictions Max            1534.4764
V Predictions Min            -58.753944
Log Pis Mean                 0.24557267
Log Pis Std                  3.1910906
Log Pis Max                  12.609036
Log Pis Min                  -8.9731245
Policy mu Mean               0.023346772
Policy mu Std                0.59144056
Policy mu Max                2.1844137
Policy mu Min                -2.2631845
Policy log std Mean          -1.0462158
Policy log std Std           0.35210016
Policy log std Max           0.28189623
Policy log std Min           -2.9397836
Z mean eval                  0.9635658
Z variance eval              0.013354501
total_rewards                [2000.17604137 3452.29208669 3944.28879274 3626.33958072 3662.32411617
 1454.52904686 1266.34994017 1893.10722484 3774.02413195  112.1130946 ]
total_rewards_mean           2518.5544056120752
total_rewards_std            1271.5035215677099
total_rewards_max            3944.2887927381207
total_rewards_min            112.11309460015335
Number of train steps total  1076000
Number of env steps total    1347000
Number of rollouts total     0
Train Time (s)               115.5088189621456
(Previous) Eval Time (s)     19.52802301570773
Sample Time (s)              18.86889908881858
Epoch Time (s)               153.9057410666719
Total Train Time (s)         41344.71535092732
Epoch                        268
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:00:39.990720 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #268 | Epoch Duration: 158.70244979858398
2020-01-12 11:00:39.991054 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #268 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96268606
Z variance train             0.013395771
KL Divergence                19.949215
KL Loss                      1.9949216
QF Loss                      5648.2754
VF Loss                      320.89246
Policy Loss                  -1306.82
Q Predictions Mean           1304.4949
Q Predictions Std            292.18576
Q Predictions Max            1542.8672
Q Predictions Min            -28.347857
V Predictions Mean           1297.8215
V Predictions Std            286.93326
V Predictions Max            1531.5597
V Predictions Min            -48.10483
Log Pis Mean                 0.41447246
Log Pis Std                  3.0267773
Log Pis Max                  12.8864
Log Pis Min                  -8.739971
Policy mu Mean               0.017289832
Policy mu Std                0.6099497
Policy mu Max                2.5931501
Policy mu Min                -2.5929062
Policy log std Mean          -1.0262249
Policy log std Std           0.31300107
Policy log std Max           -0.20300329
Policy log std Min           -3.101534
Z mean eval                  1.0084057
Z variance eval              0.012411342
total_rewards                [2603.04051002 3764.45785735 3770.5127305  3906.23794927  957.49648362
 1136.63778767 3784.65854547   33.04985957 3710.84928966  411.06807192]
total_rewards_mean           2407.800908504275
total_rewards_std            1513.9428278370276
total_rewards_max            3906.2379492675773
total_rewards_min            33.04985957457083
Number of train steps total  1080000
Number of env steps total    1352000
Number of rollouts total     0
Train Time (s)               115.51647258223966
(Previous) Eval Time (s)     24.324400166980922
Sample Time (s)              18.17568760830909
Epoch Time (s)               158.01656035752967
Total Train Time (s)         41497.85843801685
Epoch                        269
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:03:13.138626 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #269 | Epoch Duration: 153.14736032485962
2020-01-12 11:03:13.138902 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #269 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0083961
Z variance train             0.012400032
KL Divergence                20.708124
KL Loss                      2.0708125
QF Loss                      673.42896
VF Loss                      138.57478
Policy Loss                  -1303.2308
Q Predictions Mean           1306.336
Q Predictions Std            301.49734
Q Predictions Max            1508.4303
Q Predictions Min            -76.74584
V Predictions Mean           1301.6814
V Predictions Std            299.6415
V Predictions Max            1504.806
V Predictions Min            -67.84956
Log Pis Mean                 0.5844766
Log Pis Std                  2.951805
Log Pis Max                  12.596897
Log Pis Min                  -6.9046416
Policy mu Mean               0.01669672
Policy mu Std                0.5979881
Policy mu Max                2.6888964
Policy mu Min                -2.4959393
Policy log std Mean          -1.0565729
Policy log std Std           0.3180013
Policy log std Max           -0.16439438
Policy log std Min           -2.9463224
Z mean eval                  0.9962858
Z variance eval              0.0090622185
total_rewards                [3673.52366981 3796.57344038 3641.12274997 3668.05298054 3193.50149507
 3782.80340389 1601.8425324  1115.218141   3887.95307366 3689.3241231 ]
total_rewards_mean           3204.991560982284
total_rewards_std            945.8530810850897
total_rewards_max            3887.9530736625265
total_rewards_min            1115.2181410006062
Number of train steps total  1084000
Number of env steps total    1357000
Number of rollouts total     0
Train Time (s)               123.17177493683994
(Previous) Eval Time (s)     19.4549026992172
Sample Time (s)              18.21155494451523
Epoch Time (s)               160.83823258057237
Total Train Time (s)         41664.71302059665
Epoch                        270
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:05:59.995462 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #270 | Epoch Duration: 166.8563573360443
2020-01-12 11:05:59.995656 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #270 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9972478
Z variance train             0.009050056
KL Divergence                21.001337
KL Loss                      2.1001337
QF Loss                      419.1693
VF Loss                      101.27635
Policy Loss                  -1335.3926
Q Predictions Mean           1339.7587
Q Predictions Std            255.23517
Q Predictions Max            1534.644
Q Predictions Min            -43.510216
V Predictions Mean           1339.0302
V Predictions Std            255.34981
V Predictions Max            1533.579
V Predictions Min            -48.26915
Log Pis Mean                 0.28685328
Log Pis Std                  2.7403505
Log Pis Max                  7.486379
Log Pis Min                  -7.2775803
Policy mu Mean               0.0012990292
Policy mu Std                0.6004887
Policy mu Max                2.6140509
Policy mu Min                -2.3849473
Policy log std Mean          -1.0438018
Policy log std Std           0.27816984
Policy log std Max           -0.18586165
Policy log std Min           -2.2518024
Z mean eval                  1.0355574
Z variance eval              0.014360363
total_rewards                [3730.22757145 3887.5044918  3871.39219318 3925.44518645 3723.52433789
 3929.34047163 3906.06362416 3840.21734373  273.71278074 3643.42308852]
total_rewards_mean           3473.0851089543335
total_rewards_std            1070.4806117607934
total_rewards_max            3929.3404716261775
total_rewards_min            273.712780742704
Number of train steps total  1088000
Number of env steps total    1362000
Number of rollouts total     0
Train Time (s)               120.82448150124401
(Previous) Eval Time (s)     25.47273218864575
Sample Time (s)              18.52851209277287
Epoch Time (s)               164.82572578266263
Total Train Time (s)         41828.23714034259
Epoch                        271
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:08:43.522208 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #271 | Epoch Duration: 163.52633213996887
2020-01-12 11:08:43.522454 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #271 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0345256
Z variance train             0.014361258
KL Divergence                20.382303
KL Loss                      2.0382304
QF Loss                      748.7192
VF Loss                      405.1796
Policy Loss                  -1305.7423
Q Predictions Mean           1310.1647
Q Predictions Std            335.11923
Q Predictions Max            1570.0809
Q Predictions Min            -87.21038
V Predictions Mean           1296.4204
V Predictions Std            331.22748
V Predictions Max            1541.983
V Predictions Min            -87.71652
Log Pis Mean                 0.2427746
Log Pis Std                  3.2063885
Log Pis Max                  12.940441
Log Pis Min                  -7.3518333
Policy mu Mean               0.051810488
Policy mu Std                0.6157057
Policy mu Max                2.652015
Policy mu Min                -2.5051167
Policy log std Mean          -1.0310895
Policy log std Std           0.31768474
Policy log std Max           0.005666375
Policy log std Min           -2.5627966
Z mean eval                  0.9525054
Z variance eval              0.013259331
total_rewards                [1902.68812574  208.15190675 3017.26838752 3805.68921728 2662.0562402
 2600.10510894 2924.73385106 3682.6197283  3020.09995299 3734.62352555]
total_rewards_mean           2755.8036044329283
total_rewards_std            1016.7328050613789
total_rewards_max            3805.6892172849994
total_rewards_min            208.15190675149
Number of train steps total  1092000
Number of env steps total    1367000
Number of rollouts total     0
Train Time (s)               117.64780021784827
(Previous) Eval Time (s)     24.172995666973293
Sample Time (s)              18.59390696696937
Epoch Time (s)               160.41470285179093
Total Train Time (s)         41986.64517020341
Epoch                        272
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:11:21.931398 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #272 | Epoch Duration: 158.40879845619202
2020-01-12 11:11:21.931611 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #272 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9546334
Z variance train             0.0132325385
KL Divergence                20.355404
KL Loss                      2.0355403
QF Loss                      668.8169
VF Loss                      305.53854
Policy Loss                  -1306.7528
Q Predictions Mean           1309.2413
Q Predictions Std            359.6581
Q Predictions Max            1542.8846
Q Predictions Min            -56.54446
V Predictions Mean           1308.5791
V Predictions Std            353.0154
V Predictions Max            1548.8959
V Predictions Min            -51.343903
Log Pis Mean                 0.19904144
Log Pis Std                  3.0821104
Log Pis Max                  11.103926
Log Pis Min                  -8.8746605
Policy mu Mean               0.009643463
Policy mu Std                0.5967815
Policy mu Max                2.2471356
Policy mu Min                -2.4172635
Policy log std Mean          -1.0566015
Policy log std Std           0.321184
Policy log std Max           -0.1317432
Policy log std Min           -2.826315
Z mean eval                  0.98185843
Z variance eval              0.016212314
total_rewards                [2747.98879685 3899.97809915  389.91066448   13.51161815 3860.98374218
 3932.57485855 3785.15810798  171.41617228  681.37317657 2665.20951979]
total_rewards_mean           2214.810475598163
total_rewards_std            1617.2936386289193
total_rewards_max            3932.574858548006
total_rewards_min            13.511618154803777
Number of train steps total  1096000
Number of env steps total    1372000
Number of rollouts total     0
Train Time (s)               123.64839759562165
(Previous) Eval Time (s)     22.166762474924326
Sample Time (s)              18.31095462385565
Epoch Time (s)               164.12611469440162
Total Train Time (s)         42144.32769608358
Epoch                        273
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:13:59.618469 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #273 | Epoch Duration: 157.68670630455017
2020-01-12 11:13:59.618671 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #273 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.982203
Z variance train             0.016223384
KL Divergence                20.398323
KL Loss                      2.0398324
QF Loss                      709.16693
VF Loss                      105.86061
Policy Loss                  -1304.6667
Q Predictions Mean           1306.008
Q Predictions Std            360.71735
Q Predictions Max            1531.9532
Q Predictions Min            -100.175255
V Predictions Mean           1308.2659
V Predictions Std            359.93405
V Predictions Max            1536.7634
V Predictions Min            -83.06345
Log Pis Mean                 0.23795918
Log Pis Std                  2.7056491
Log Pis Max                  8.520847
Log Pis Min                  -7.725892
Policy mu Mean               -0.025010582
Policy mu Std                0.5868497
Policy mu Max                2.565012
Policy mu Min                -1.9656907
Policy log std Mean          -1.0265204
Policy log std Std           0.28862402
Policy log std Max           0.045814514
Policy log std Min           -2.4386544
Z mean eval                  0.98648417
Z variance eval              0.01703588
total_rewards                [3306.56489077  745.92860788 3614.84860482 2755.46200122 3550.96450753
 3560.91852569 1569.28979914 3199.23848574 3692.13575647 3116.05201135]
total_rewards_mean           2911.1403190611923
total_rewards_std            934.4001387286808
total_rewards_max            3692.1357564728064
total_rewards_min            745.9286078777368
Number of train steps total  1100000
Number of env steps total    1377000
Number of rollouts total     0
Train Time (s)               115.57533156266436
(Previous) Eval Time (s)     15.727014325093478
Sample Time (s)              17.675403274595737
Epoch Time (s)               148.97774916235358
Total Train Time (s)         42300.37002911745
Epoch                        274
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:16:35.662976 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #274 | Epoch Duration: 156.04415202140808
2020-01-12 11:16:35.663158 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #274 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98673713
Z variance train             0.017042192
KL Divergence                20.17529
KL Loss                      2.017529
QF Loss                      514.57513
VF Loss                      73.33649
Policy Loss                  -1355.5358
Q Predictions Mean           1354.256
Q Predictions Std            274.45007
Q Predictions Max            1576.9064
Q Predictions Min            -52.617054
V Predictions Mean           1355.3696
V Predictions Std            276.38724
V Predictions Max            1570.11
V Predictions Min            -49.42277
Log Pis Mean                 0.43350655
Log Pis Std                  2.8477173
Log Pis Max                  11.442346
Log Pis Min                  -5.544199
Policy mu Mean               -0.022991829
Policy mu Std                0.6109009
Policy mu Max                2.6623716
Policy mu Min                -2.1046643
Policy log std Mean          -1.0334184
Policy log std Std           0.30654842
Policy log std Max           0.3287542
Policy log std Min           -2.5855875
Z mean eval                  1.0349839
Z variance eval              0.013802012
total_rewards                [1673.84034543 1294.28675505 3766.91974027 2605.04040968 1929.08111345
 3843.80736647 1482.6634489   997.0031406  3898.0786885  3724.72370567]
total_rewards_mean           2521.544471402728
total_rewards_std            1123.7470214683146
total_rewards_max            3898.078688501777
total_rewards_min            997.0031406021267
Number of train steps total  1104000
Number of env steps total    1382000
Number of rollouts total     0
Train Time (s)               125.36576308682561
(Previous) Eval Time (s)     22.793115109670907
Sample Time (s)              17.997142121195793
Epoch Time (s)               166.1560203176923
Total Train Time (s)         42462.346767449286
Epoch                        275
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:19:17.642377 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #275 | Epoch Duration: 161.9790861606598
2020-01-12 11:19:17.642562 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #275 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0325592
Z variance train             0.013744356
KL Divergence                20.562897
KL Loss                      2.0562897
QF Loss                      846.2899
VF Loss                      600.20496
Policy Loss                  -1318.2185
Q Predictions Mean           1322.4028
Q Predictions Std            321.82315
Q Predictions Max            1539.0625
Q Predictions Min            -29.733215
V Predictions Mean           1310.4172
V Predictions Std            321.4814
V Predictions Max            1514.8472
V Predictions Min            -36.99726
Log Pis Mean                 0.12079291
Log Pis Std                  2.8001845
Log Pis Max                  17.943867
Log Pis Min                  -6.229949
Policy mu Mean               0.007211524
Policy mu Std                0.5955258
Policy mu Max                2.4312563
Policy mu Min                -2.4885585
Policy log std Mean          -1.0310564
Policy log std Std           0.29881108
Policy log std Max           -0.1631316
Policy log std Min           -3.2918277
Z mean eval                  0.98520887
Z variance eval              0.014579475
total_rewards                [  25.50264169 3671.086975   1017.9629502  3912.44836892 3659.75702803
 1622.23895408  708.02931698 3770.55670626  541.62903356 2838.16663361]
total_rewards_mean           2176.737860833677
total_rewards_std            1467.3646305429133
total_rewards_max            3912.448368924401
total_rewards_min            25.502641692395304
Number of train steps total  1108000
Number of env steps total    1387000
Number of rollouts total     0
Train Time (s)               119.37409648858011
(Previous) Eval Time (s)     18.61588042601943
Sample Time (s)              17.61905995104462
Epoch Time (s)               155.60903686564416
Total Train Time (s)         42615.730932463426
Epoch                        276
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:21:51.032256 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #276 | Epoch Duration: 153.38953495025635
2020-01-12 11:21:51.032572 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #276 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9853183
Z variance train             0.014546832
KL Divergence                20.411518
KL Loss                      2.0411518
QF Loss                      720.8838
VF Loss                      258.67245
Policy Loss                  -1352.2344
Q Predictions Mean           1351.8342
Q Predictions Std            300.27475
Q Predictions Max            1584.5814
Q Predictions Min            -41.647877
V Predictions Mean           1361.2007
V Predictions Std            293.12247
V Predictions Max            1571.1522
V Predictions Min            -48.26259
Log Pis Mean                 1.0141745
Log Pis Std                  3.457791
Log Pis Max                  22.021784
Log Pis Min                  -7.5449014
Policy mu Mean               0.009056536
Policy mu Std                0.66686124
Policy mu Max                3.2978673
Policy mu Min                -2.7480602
Policy log std Mean          -1.0614555
Policy log std Std           0.31819642
Policy log std Max           -0.119552135
Policy log std Min           -3.2113032
Z mean eval                  1.0147852
Z variance eval              0.011471888
total_rewards                [3591.37097958  732.2502027  3539.21798551 3426.53193884 3662.58476494
 2849.27579454 3852.7711224  3627.20713597 3822.80055001 3609.0513585 ]
total_rewards_mean           3271.306183298332
total_rewards_std            886.52760229279
total_rewards_max            3852.771122397049
total_rewards_min            732.2502026989348
Number of train steps total  1112000
Number of env steps total    1392000
Number of rollouts total     0
Train Time (s)               112.38167154602706
(Previous) Eval Time (s)     16.396049873903394
Sample Time (s)              18.349427863024175
Epoch Time (s)               147.12714928295463
Total Train Time (s)         42772.84831287945
Epoch                        277
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:24:28.150310 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #277 | Epoch Duration: 157.1175193786621
2020-01-12 11:24:28.150460 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #277 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.01544
Z variance train             0.011470358
KL Divergence                20.733276
KL Loss                      2.0733278
QF Loss                      1010.2278
VF Loss                      733.07446
Policy Loss                  -1339.8297
Q Predictions Mean           1341.086
Q Predictions Std            307.4653
Q Predictions Max            1546.8239
Q Predictions Min            -68.54935
V Predictions Mean           1343.5122
V Predictions Std            301.30215
V Predictions Max            1551.4934
V Predictions Min            -70.40172
Log Pis Mean                 0.4510057
Log Pis Std                  3.2541738
Log Pis Max                  13.384621
Log Pis Min                  -8.000345
Policy mu Mean               -0.027825626
Policy mu Std                0.61907136
Policy mu Max                2.320367
Policy mu Min                -3.0027888
Policy log std Mean          -1.0634261
Policy log std Std           0.33409277
Policy log std Max           0.06760359
Policy log std Min           -2.9235826
Z mean eval                  1.0027299
Z variance eval              0.009556996
total_rewards                [3493.26799907 3649.67088094 3631.32276687 3656.25475543 3741.60925923
 3637.52299568 3588.2614649  3849.62196079 3706.71584406 3798.78307167]
total_rewards_mean           3675.3030998653026
total_rewards_std            98.03678705134774
total_rewards_max            3849.621960791768
total_rewards_min            3493.267999072349
Number of train steps total  1116000
Number of env steps total    1397000
Number of rollouts total     0
Train Time (s)               115.01948480820283
(Previous) Eval Time (s)     26.386092291213572
Sample Time (s)              17.430129232350737
Epoch Time (s)               158.83570633176714
Total Train Time (s)         42932.610898096114
Epoch                        278
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:27:07.936977 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #278 | Epoch Duration: 159.78635931015015
2020-01-12 11:27:07.937268 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #278 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0022418
Z variance train             0.009569513
KL Divergence                21.436497
KL Loss                      2.1436498
QF Loss                      1041.1882
VF Loss                      162.62657
Policy Loss                  -1330.8475
Q Predictions Mean           1333.1384
Q Predictions Std            294.99295
Q Predictions Max            1550.5112
Q Predictions Min            -83.97474
V Predictions Mean           1334.8728
V Predictions Std            295.2294
V Predictions Max            1534.3413
V Predictions Min            -108.05398
Log Pis Mean                 0.5513715
Log Pis Std                  2.9403465
Log Pis Max                  11.088158
Log Pis Min                  -10.816209
Policy mu Mean               -0.0077225855
Policy mu Std                0.62464726
Policy mu Max                2.865004
Policy mu Min                -2.4980652
Policy log std Mean          -1.057795
Policy log std Std           0.29160511
Policy log std Max           0.075482845
Policy log std Min           -2.3835473
Z mean eval                  0.99013555
Z variance eval              0.009479218
total_rewards                [3607.4524712  1515.04219782 2557.39366863 3873.60230111 3870.9536405
 3686.99547692 2838.98991156 3171.14010216 1549.24874667  878.04257662]
total_rewards_mean           2754.8861093191776
total_rewards_std            1040.456152274517
total_rewards_max            3873.60230110789
total_rewards_min            878.0425766187002
Number of train steps total  1120000
Number of env steps total    1402000
Number of rollouts total     0
Train Time (s)               117.80952158989385
(Previous) Eval Time (s)     27.336425845045596
Sample Time (s)              19.227957354392856
Epoch Time (s)               164.3739047893323
Total Train Time (s)         43091.67057745624
Epoch                        279
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:29:46.982237 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #279 | Epoch Duration: 159.04475665092468
2020-01-12 11:29:46.982475 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #279 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9911354
Z variance train             0.009477474
KL Divergence                22.165764
KL Loss                      2.2165763
QF Loss                      1888.6094
VF Loss                      153.48628
Policy Loss                  -1331.3331
Q Predictions Mean           1330.3954
Q Predictions Std            302.45328
Q Predictions Max            1547.0723
Q Predictions Min            -91.207855
V Predictions Mean           1336.7659
V Predictions Std            290.0911
V Predictions Max            1555.3212
V Predictions Min            -90.124374
Log Pis Mean                 0.54647315
Log Pis Std                  2.6930833
Log Pis Max                  9.218167
Log Pis Min                  -8.053148
Policy mu Mean               -0.021304995
Policy mu Std                0.6037115
Policy mu Max                2.6217895
Policy mu Min                -1.9239691
Policy log std Mean          -1.0687368
Policy log std Std           0.28572357
Policy log std Max           -0.082707405
Policy log std Min           -2.6547842
Z mean eval                  1.0080272
Z variance eval              0.00834015
total_rewards                [ 919.67688698 1224.06196057  134.71416264 3735.62960612 3526.74939693
 2339.88960471 1162.49975794 1889.72155507 3903.06019326 3935.79702113]
total_rewards_mean           2277.1800145348125
total_rewards_std            1342.445399677031
total_rewards_max            3935.797021128251
total_rewards_min            134.71416263887676
Number of train steps total  1124000
Number of env steps total    1407000
Number of rollouts total     0
Train Time (s)               120.0158371035941
(Previous) Eval Time (s)     22.006932832300663
Sample Time (s)              18.78989056032151
Epoch Time (s)               160.81266049621627
Total Train Time (s)         43251.73369286768
Epoch                        280
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:32:27.047455 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #280 | Epoch Duration: 160.06480979919434
2020-01-12 11:32:27.047663 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #280 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0079472
Z variance train             0.008331955
KL Divergence                22.5434
KL Loss                      2.25434
QF Loss                      519.4938
VF Loss                      401.98596
Policy Loss                  -1344.8447
Q Predictions Mean           1345.3601
Q Predictions Std            285.75485
Q Predictions Max            1559.794
Q Predictions Min            -72.41216
V Predictions Mean           1346.6528
V Predictions Std            281.3156
V Predictions Max            1554.7107
V Predictions Min            -92.3152
Log Pis Mean                 0.51239115
Log Pis Std                  2.9759998
Log Pis Max                  15.444894
Log Pis Min                  -6.905608
Policy mu Mean               -0.002224191
Policy mu Std                0.60969514
Policy mu Max                2.152336
Policy mu Min                -1.9796867
Policy log std Mean          -1.0599682
Policy log std Std           0.32922974
Policy log std Max           0.050043106
Policy log std Min           -3.0188563
Z mean eval                  0.98706234
Z variance eval              0.011546378
total_rewards                [2409.27222473 3964.80832318  717.16960786  260.54004873  203.37662245
 3621.14295479  407.18008999 3880.84151322 3842.4919343  1307.8247217 ]
total_rewards_mean           2061.464804095775
total_rewards_std            1564.1628516388116
total_rewards_max            3964.8083231792366
total_rewards_min            203.37662245024572
Number of train steps total  1128000
Number of env steps total    1412000
Number of rollouts total     0
Train Time (s)               117.8670306103304
(Previous) Eval Time (s)     21.2587735443376
Sample Time (s)              18.054187700152397
Epoch Time (s)               157.1799918548204
Total Train Time (s)         43404.61419751961
Epoch                        281
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:34:59.929550 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #281 | Epoch Duration: 152.88175797462463
2020-01-12 11:34:59.929714 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #281 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98637027
Z variance train             0.011550015
KL Divergence                21.964848
KL Loss                      2.1964848
QF Loss                      706.1642
VF Loss                      516.3966
Policy Loss                  -1315.5814
Q Predictions Mean           1313.5896
Q Predictions Std            375.3817
Q Predictions Max            1588.2999
Q Predictions Min            -80.56482
V Predictions Mean           1311.3634
V Predictions Std            371.83334
V Predictions Max            1581.5808
V Predictions Min            -72.700836
Log Pis Mean                 0.47008222
Log Pis Std                  2.9834516
Log Pis Max                  15.028418
Log Pis Min                  -7.304738
Policy mu Mean               -0.012566367
Policy mu Std                0.59676397
Policy mu Max                2.5225987
Policy mu Min                -2.04108
Policy log std Mean          -1.0313292
Policy log std Std           0.35067934
Policy log std Max           -0.088247836
Policy log std Min           -3.5327504
Z mean eval                  1.0608867
Z variance eval              0.012497725
total_rewards                [3979.21211315 1186.47054158 3947.40647603 2568.87109481 3834.8506551
 3613.33789736 3740.94977051  122.89509678 3615.43439635 1075.67405011]
total_rewards_mean           2768.5102091774997
total_rewards_std            1370.2922836789603
total_rewards_max            3979.212113148002
total_rewards_min            122.89509678251935
Number of train steps total  1132000
Number of env steps total    1417000
Number of rollouts total     0
Train Time (s)               118.03734146105126
(Previous) Eval Time (s)     16.96023508021608
Sample Time (s)              18.607409298885614
Epoch Time (s)               153.60498584015295
Total Train Time (s)         43560.73098146776
Epoch                        282
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:37:36.049040 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #282 | Epoch Duration: 156.1192123889923
2020-01-12 11:37:36.049205 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #282 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0593303
Z variance train             0.012475374
KL Divergence                22.306087
KL Loss                      2.2306087
QF Loss                      651.8489
VF Loss                      130.18365
Policy Loss                  -1325.3536
Q Predictions Mean           1328.6648
Q Predictions Std            348.14185
Q Predictions Max            1541.2124
Q Predictions Min            -66.47152
V Predictions Mean           1325.9536
V Predictions Std            347.62637
V Predictions Max            1546.052
V Predictions Min            -67.63498
Log Pis Mean                 0.58134514
Log Pis Std                  3.1445103
Log Pis Max                  10.39193
Log Pis Min                  -9.394569
Policy mu Mean               0.06807569
Policy mu Std                0.61160564
Policy mu Max                2.3619695
Policy mu Min                -2.523128
Policy log std Mean          -1.0901957
Policy log std Std           0.31058353
Policy log std Max           -0.12592447
Policy log std Min           -2.4037426
Z mean eval                  1.0070908
Z variance eval              0.007960912
total_rewards                [3909.63396334 3804.66707932 3741.09470078 3907.26708924 1708.17893208
  303.18295602  657.92562989  334.91595245 3790.19860598 3782.71340096]
total_rewards_mean           2593.977831005343
total_rewards_std            1548.0762657640175
total_rewards_max            3909.633963343945
total_rewards_min            303.1829560176257
Number of train steps total  1136000
Number of env steps total    1422000
Number of rollouts total     0
Train Time (s)               118.32166827330366
(Previous) Eval Time (s)     19.47413905709982
Sample Time (s)              17.54571465961635
Epoch Time (s)               155.34152199001983
Total Train Time (s)         43714.61155762989
Epoch                        283
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:40:09.934307 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #283 | Epoch Duration: 153.88495683670044
2020-01-12 11:40:09.934537 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #283 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0058858
Z variance train             0.007954027
KL Divergence                22.87342
KL Loss                      2.287342
QF Loss                      1473.4076
VF Loss                      451.79688
Policy Loss                  -1371.0776
Q Predictions Mean           1372.9917
Q Predictions Std            259.5141
Q Predictions Max            1549.1619
Q Predictions Min            -92.09028
V Predictions Mean           1371.3779
V Predictions Std            259.8549
V Predictions Max            1544.7603
V Predictions Min            -88.100296
Log Pis Mean                 0.37044907
Log Pis Std                  3.2224746
Log Pis Max                  15.252626
Log Pis Min                  -6.978321
Policy mu Mean               -0.0032188743
Policy mu Std                0.6000812
Policy mu Max                2.5341272
Policy mu Min                -2.314036
Policy log std Mean          -1.0817151
Policy log std Std           0.3390022
Policy log std Max           0.05089283
Policy log std Min           -2.9571908
Z mean eval                  1.0169499
Z variance eval              0.012259111
total_rewards                [3669.16009216 3815.00499459 3698.11447857 3722.3404969  1847.05091941
  208.08268193 3895.13243954 3852.39529151 3832.04710205 3585.99023661]
total_rewards_mean           3212.531873327459
total_rewards_std            1155.7279379305305
total_rewards_max            3895.132439544936
total_rewards_min            208.08268192897262
Number of train steps total  1140000
Number of env steps total    1427000
Number of rollouts total     0
Train Time (s)               120.27204575808719
(Previous) Eval Time (s)     18.017264844849706
Sample Time (s)              18.39739897986874
Epoch Time (s)               156.68670958280563
Total Train Time (s)         43878.31914168829
Epoch                        284
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:42:53.643600 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #284 | Epoch Duration: 163.70889616012573
2020-01-12 11:42:53.643761 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #284 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0231323
Z variance train             0.012231334
KL Divergence                24.355806
KL Loss                      2.4355807
QF Loss                      612.0563
VF Loss                      150.09802
Policy Loss                  -1376.4448
Q Predictions Mean           1375.9209
Q Predictions Std            303.84747
Q Predictions Max            1585.6827
Q Predictions Min            -99.581375
V Predictions Mean           1378.2278
V Predictions Std            302.7336
V Predictions Max            1577.097
V Predictions Min            -97.1364
Log Pis Mean                 0.4543235
Log Pis Std                  3.1027198
Log Pis Max                  10.442384
Log Pis Min                  -10.270175
Policy mu Mean               0.010844729
Policy mu Std                0.606324
Policy mu Max                2.3325033
Policy mu Min                -2.635477
Policy log std Mean          -1.0962266
Policy log std Std           0.32503435
Policy log std Max           -0.19951093
Policy log std Min           -2.6432633
Z mean eval                  1.0152255
Z variance eval              0.011684339
total_rewards                [3876.33231932  728.64120523  866.85317104  957.04036316 3894.1368701
 3851.11984331 3642.85547142 3994.72948559 3772.08598584 1981.54035079]
total_rewards_mean           2756.5335065801687
total_rewards_std            1364.4882450683485
total_rewards_max            3994.729485588565
total_rewards_min            728.6412052320709
Number of train steps total  1144000
Number of env steps total    1432000
Number of rollouts total     0
Train Time (s)               118.915376087185
(Previous) Eval Time (s)     25.039117842912674
Sample Time (s)              18.530277931131423
Epoch Time (s)               162.4847718612291
Total Train Time (s)         44037.38032315858
Epoch                        285
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:45:32.711574 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #285 | Epoch Duration: 159.06613636016846
2020-01-12 11:45:32.711912 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #285 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0144861
Z variance train             0.011672815
KL Divergence                23.621658
KL Loss                      2.362166
QF Loss                      863.92944
VF Loss                      106.25566
Policy Loss                  -1348.7614
Q Predictions Mean           1348.5643
Q Predictions Std            326.59198
Q Predictions Max            1578.1742
Q Predictions Min            -39.869408
V Predictions Mean           1350.7966
V Predictions Std            328.82498
V Predictions Max            1590.6567
V Predictions Min            -64.08111
Log Pis Mean                 0.4110819
Log Pis Std                  3.164206
Log Pis Max                  13.913879
Log Pis Min                  -8.870451
Policy mu Mean               0.010300811
Policy mu Std                0.64409286
Policy mu Max                2.5852642
Policy mu Min                -2.779973
Policy log std Mean          -1.0195916
Policy log std Std           0.29308066
Policy log std Max           -0.11930549
Policy log std Min           -2.495874
Z mean eval                  1.0155108
Z variance eval              0.0107176425
total_rewards                [3676.92566211 3604.99270274 3816.2211424   869.6235094  3862.63727872
 1761.06361024 3791.13718891 3650.4556377   507.75724488 3665.65064036]
total_rewards_mean           2920.6464617477
total_rewards_std            1262.8720201711292
total_rewards_max            3862.6372787201385
total_rewards_min            507.7572448816183
Number of train steps total  1148000
Number of env steps total    1437000
Number of rollouts total     0
Train Time (s)               119.67307910323143
(Previous) Eval Time (s)     21.62012464692816
Sample Time (s)              18.136245429050177
Epoch Time (s)               159.42944917920977
Total Train Time (s)         44201.40304078581
Epoch                        286
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:48:16.738697 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #286 | Epoch Duration: 164.02654790878296
2020-01-12 11:48:16.738968 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #286 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0164676
Z variance train             0.010699214
KL Divergence                24.092964
KL Loss                      2.4092965
QF Loss                      694.6504
VF Loss                      96.239845
Policy Loss                  -1351.0348
Q Predictions Mean           1350.418
Q Predictions Std            321.75256
Q Predictions Max            1573.3915
Q Predictions Min            -92.53244
V Predictions Mean           1346.8347
V Predictions Std            318.85757
V Predictions Max            1576.3997
V Predictions Min            -82.860695
Log Pis Mean                 0.46410683
Log Pis Std                  3.0453942
Log Pis Max                  9.519964
Log Pis Min                  -9.443783
Policy mu Mean               0.030527903
Policy mu Std                0.6106738
Policy mu Max                2.3904822
Policy mu Min                -1.7828716
Policy log std Mean          -1.0378301
Policy log std Std           0.28090075
Policy log std Max           -0.15471137
Policy log std Min           -2.1436458
Z mean eval                  1.0219494
Z variance eval              0.018793058
total_rewards                [3839.73332194 3719.64094951 3634.61127481 3598.42204218 3700.22780462
 1619.21078907 3562.4239509  3630.95018464 3515.0835304  3470.61637142]
total_rewards_mean           3429.092021949721
total_rewards_std            611.6194403072407
total_rewards_max            3839.733321938432
total_rewards_min            1619.2107890746142
Number of train steps total  1152000
Number of env steps total    1442000
Number of rollouts total     0
Train Time (s)               119.49992439616472
(Previous) Eval Time (s)     26.21694662189111
Sample Time (s)              18.887705815955997
Epoch Time (s)               164.60457683401182
Total Train Time (s)         44364.60918749822
Epoch                        287
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:50:59.946336 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #287 | Epoch Duration: 163.20718717575073
2020-01-12 11:50:59.946552 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #287 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0244734
Z variance train             0.018771918
KL Divergence                22.934837
KL Loss                      2.2934837
QF Loss                      6897.148
VF Loss                      168.32317
Policy Loss                  -1373.1709
Q Predictions Mean           1375.868
Q Predictions Std            221.67174
Q Predictions Max            1559.949
Q Predictions Min            -65.328186
V Predictions Mean           1371.9324
V Predictions Std            218.30124
V Predictions Max            1561.1038
V Predictions Min            -62.398487
Log Pis Mean                 0.7931249
Log Pis Std                  3.0870771
Log Pis Max                  13.17374
Log Pis Min                  -6.5845585
Policy mu Mean               -0.042774893
Policy mu Std                0.6355768
Policy mu Max                2.6549885
Policy mu Min                -2.5031793
Policy log std Mean          -1.1030835
Policy log std Std           0.30122775
Policy log std Max           -0.24194586
Policy log std Min           -2.8914785
Z mean eval                  1.001705
Z variance eval              0.013847423
total_rewards                [3821.75741693 4075.19933308 3955.51086069 4067.88219142 4034.0892777
 4098.7830176  3579.92122876  179.17131968 4017.40541925  214.1324799 ]
total_rewards_mean           3204.3852545001714
total_rewards_std            1511.065795097967
total_rewards_max            4098.78301759816
total_rewards_min            179.1713196826484
Number of train steps total  1156000
Number of env steps total    1447000
Number of rollouts total     0
Train Time (s)               121.26061320398003
(Previous) Eval Time (s)     24.819253189954907
Sample Time (s)              17.39375292090699
Epoch Time (s)               163.47361931484193
Total Train Time (s)         44524.856681820005
Epoch                        288
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:53:40.199430 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #288 | Epoch Duration: 160.25271916389465
2020-01-12 11:53:40.199730 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #288 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0031883
Z variance train             0.013829122
KL Divergence                23.93844
KL Loss                      2.3938441
QF Loss                      709.4448
VF Loss                      97.24623
Policy Loss                  -1373.0847
Q Predictions Mean           1373.6155
Q Predictions Std            297.82812
Q Predictions Max            1577.1262
Q Predictions Min            -107.296776
V Predictions Mean           1372.9703
V Predictions Std            297.54993
V Predictions Max            1571.5974
V Predictions Min            -63.04506
Log Pis Mean                 0.53350997
Log Pis Std                  2.9544232
Log Pis Max                  14.778011
Log Pis Min                  -6.2258396
Policy mu Mean               -0.007867937
Policy mu Std                0.592367
Policy mu Max                2.55278
Policy mu Min                -2.324054
Policy log std Mean          -1.095485
Policy log std Std           0.3087574
Policy log std Max           -0.086202025
Policy log std Min           -2.9799242
Z mean eval                  1.0143951
Z variance eval              0.011330149
total_rewards                [3491.18455784 1458.20323825 1581.79786911    9.63482781 3990.63855706
 2890.54932022 2184.17111415 2318.05730217 1701.42903829 3775.50390185]
total_rewards_mean           2340.1169726751064
total_rewards_std            1167.4409721498832
total_rewards_max            3990.6385570583243
total_rewards_min            9.634827806389378
Number of train steps total  1160000
Number of env steps total    1452000
Number of rollouts total     0
Train Time (s)               116.60363791277632
(Previous) Eval Time (s)     21.59804940689355
Sample Time (s)              18.66001594439149
Epoch Time (s)               156.86170326406136
Total Train Time (s)         44677.970532298554
Epoch                        289
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:56:13.318963 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #289 | Epoch Duration: 153.11897587776184
2020-01-12 11:56:13.319266 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #289 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0143449
Z variance train             0.011315703
KL Divergence                24.158188
KL Loss                      2.415819
QF Loss                      853.917
VF Loss                      197.03032
Policy Loss                  -1367.936
Q Predictions Mean           1368.1619
Q Predictions Std            272.27527
Q Predictions Max            1531.6868
Q Predictions Min            -92.72599
V Predictions Mean           1372.6398
V Predictions Std            269.56717
V Predictions Max            1544.3477
V Predictions Min            -89.0107
Log Pis Mean                 0.7162486
Log Pis Std                  3.1881707
Log Pis Max                  13.551084
Log Pis Min                  -7.4089975
Policy mu Mean               -0.008213902
Policy mu Std                0.63413906
Policy mu Max                2.4704046
Policy mu Min                -2.2467926
Policy log std Mean          -1.062353
Policy log std Std           0.32296562
Policy log std Max           -0.24043727
Policy log std Min           -3.1016986
Z mean eval                  1.0288879
Z variance eval              0.009460675
total_rewards                [3753.72920577  822.58882887  316.17788387 3837.8366522  3918.64025859
  567.42390493 1903.62939045 3756.24223818 3819.32694632 3757.5370344 ]
total_rewards_mean           2645.3132343584793
total_rewards_std            1474.3299405524667
total_rewards_max            3918.6402585861324
total_rewards_min            316.1778838704672
Number of train steps total  1164000
Number of env steps total    1457000
Number of rollouts total     0
Train Time (s)               113.52223104331642
(Previous) Eval Time (s)     17.854971269145608
Sample Time (s)              18.381019399035722
Epoch Time (s)               149.75822171149775
Total Train Time (s)         44828.81383073889
Epoch                        290
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:58:44.163847 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #290 | Epoch Duration: 150.8443603515625
2020-01-12 11:58:44.164012 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #290 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.028547
Z variance train             0.009458317
KL Divergence                24.362324
KL Loss                      2.4362323
QF Loss                      1005.94653
VF Loss                      178.53488
Policy Loss                  -1364.6337
Q Predictions Mean           1367.2448
Q Predictions Std            312.08264
Q Predictions Max            1590.1084
Q Predictions Min            -91.9529
V Predictions Mean           1362.0854
V Predictions Std            305.7179
V Predictions Max            1575.7556
V Predictions Min            -94.71611
Log Pis Mean                 0.57157564
Log Pis Std                  2.9974675
Log Pis Max                  9.528356
Log Pis Min                  -13.075746
Policy mu Mean               0.019560847
Policy mu Std                0.6280926
Policy mu Max                2.6032007
Policy mu Min                -1.9319855
Policy log std Mean          -1.0467643
Policy log std Std           0.31421348
Policy log std Max           -0.11873686
Policy log std Min           -2.5216372
Z mean eval                  1.0069852
Z variance eval              0.011382418
total_rewards                [ 712.11504695 3992.53437946 3933.62326547 3793.86440902 2988.74705485
 3636.22692769 3819.48124037 3648.41444271 3665.43774776 3694.03844033]
total_rewards_mean           3388.448295461578
total_rewards_std            929.187454176506
total_rewards_max            3992.5343794617347
total_rewards_min            712.1150469514905
Number of train steps total  1168000
Number of env steps total    1462000
Number of rollouts total     0
Train Time (s)               120.25825026724488
(Previous) Eval Time (s)     18.940844180993736
Sample Time (s)              18.008725890889764
Epoch Time (s)               157.20782033912838
Total Train Time (s)         44991.59138948936
Epoch                        291
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:01:26.948717 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #291 | Epoch Duration: 162.78453493118286
2020-01-12 12:01:26.949036 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #291 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.005855
Z variance train             0.0113758575
KL Divergence                24.814785
KL Loss                      2.4814785
QF Loss                      725.42053
VF Loss                      361.38562
Policy Loss                  -1342.8481
Q Predictions Mean           1344.0232
Q Predictions Std            343.8718
Q Predictions Max            1580.1349
Q Predictions Min            -88.705765
V Predictions Mean           1337.1648
V Predictions Std            342.93347
V Predictions Max            1566.0044
V Predictions Min            -119.61876
Log Pis Mean                 0.38062882
Log Pis Std                  3.0445852
Log Pis Max                  12.090839
Log Pis Min                  -6.937246
Policy mu Mean               0.025641736
Policy mu Std                0.608136
Policy mu Max                2.5027184
Policy mu Min                -1.8671544
Policy log std Mean          -1.0795119
Policy log std Std           0.34128657
Policy log std Max           0.16138506
Policy log std Min           -2.9635282
Z mean eval                  1.0248947
Z variance eval              0.008644485
total_rewards                [1238.87273487  152.22167477 3785.75160485 1503.22243958 3607.42560958
 3921.35537861 3820.14541925  718.57249275 3751.59928362 3849.02708079]
total_rewards_mean           2634.8193718671887
total_rewards_std            1453.1603636003576
total_rewards_max            3921.35537860726
total_rewards_min            152.22167477055098
Number of train steps total  1172000
Number of env steps total    1467000
Number of rollouts total     0
Train Time (s)               118.98417600570247
(Previous) Eval Time (s)     24.517188479192555
Sample Time (s)              18.540545854717493
Epoch Time (s)               162.0419103396125
Total Train Time (s)         45150.35797067359
Epoch                        292
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:04:05.719669 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #292 | Epoch Duration: 158.77037167549133
2020-01-12 12:04:05.719977 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #292 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0257841
Z variance train             0.008647623
KL Divergence                25.499565
KL Loss                      2.5499566
QF Loss                      726.6643
VF Loss                      279.09222
Policy Loss                  -1378.0333
Q Predictions Mean           1381.982
Q Predictions Std            270.46042
Q Predictions Max            1577.3782
Q Predictions Min            -113.19899
V Predictions Mean           1382.6355
V Predictions Std            272.07483
V Predictions Max            1564.0447
V Predictions Min            -79.8043
Log Pis Mean                 0.4930656
Log Pis Std                  2.9379122
Log Pis Max                  12.7243805
Log Pis Min                  -7.197204
Policy mu Mean               -0.0318657
Policy mu Std                0.63237965
Policy mu Max                2.4383657
Policy mu Min                -3.4183815
Policy log std Mean          -1.0544534
Policy log std Std           0.29590008
Policy log std Max           -0.13450062
Policy log std Min           -2.8403869
Z mean eval                  1.0159502
Z variance eval              0.012772505
total_rewards                [2642.20196558 2253.4010904  3950.6912857   -55.42394312 3035.43170013
 1833.44702725 3938.57549142 2268.74536446 3848.72869635 3943.18842054]
total_rewards_mean           2765.8987098692337
total_rewards_std            1215.093739310767
total_rewards_max            3950.691285698441
total_rewards_min            -55.42394312471036
Number of train steps total  1176000
Number of env steps total    1472000
Number of rollouts total     0
Train Time (s)               114.39214617712423
(Previous) Eval Time (s)     21.245354475919157
Sample Time (s)              18.05443475069478
Epoch Time (s)               153.69193540373817
Total Train Time (s)         45304.76741363667
Epoch                        293
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:06:40.130705 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #293 | Epoch Duration: 154.41052770614624
2020-01-12 12:06:40.130864 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #293 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0158317
Z variance train             0.01279026
KL Divergence                24.688995
KL Loss                      2.4688995
QF Loss                      836.3313
VF Loss                      138.58368
Policy Loss                  -1376.2554
Q Predictions Mean           1378.6416
Q Predictions Std            286.81543
Q Predictions Max            1583.2327
Q Predictions Min            -80.24558
V Predictions Mean           1382.4285
V Predictions Std            283.1386
V Predictions Max            1581.9603
V Predictions Min            -80.27135
Log Pis Mean                 1.1041248
Log Pis Std                  3.0934925
Log Pis Max                  16.898582
Log Pis Min                  -7.265726
Policy mu Mean               -0.003440963
Policy mu Std                0.64337903
Policy mu Max                2.6091852
Policy mu Min                -2.172259
Policy log std Mean          -1.1053625
Policy log std Std           0.3188873
Policy log std Max           -0.14873374
Policy log std Min           -3.2892323
Z mean eval                  0.99419194
Z variance eval              0.008057925
total_rewards                [3697.80081138 3987.08270981 3137.04458638  609.7534793   867.9869679
 3739.12285707  922.69721194 3916.67061655 1617.35279836 3767.07341412]
total_rewards_mean           2626.258545281775
total_rewards_std            1361.7584262010173
total_rewards_max            3987.0827098139575
total_rewards_min            609.7534792979457
Number of train steps total  1180000
Number of env steps total    1477000
Number of rollouts total     0
Train Time (s)               118.08899110089988
(Previous) Eval Time (s)     21.963652682024986
Sample Time (s)              17.798500888049603
Epoch Time (s)               157.85114467097446
Total Train Time (s)         45463.52728398284
Epoch                        294
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:09:18.900277 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #294 | Epoch Duration: 158.76926136016846
2020-01-12 12:09:18.900503 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #294 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99445915
Z variance train             0.008043544
KL Divergence                24.994064
KL Loss                      2.4994066
QF Loss                      789.0438
VF Loss                      129.36957
Policy Loss                  -1356.2678
Q Predictions Mean           1357.9918
Q Predictions Std            345.78998
Q Predictions Max            1564.7715
Q Predictions Min            -98.09019
V Predictions Mean           1358.4187
V Predictions Std            345.36603
V Predictions Max            1558.7421
V Predictions Min            -105.42353
Log Pis Mean                 0.5949516
Log Pis Std                  3.2518132
Log Pis Max                  12.48078
Log Pis Min                  -8.714131
Policy mu Mean               -0.014244835
Policy mu Std                0.6099093
Policy mu Max                2.274444
Policy mu Min                -2.1825204
Policy log std Mean          -1.0628765
Policy log std Std           0.33079672
Policy log std Max           -0.05113685
Policy log std Min           -2.8018813
Z mean eval                  1.0174315
Z variance eval              0.011836738
total_rewards                [1716.7421701  1685.04156123 3683.09487473 1594.49180949 3761.55230728
 3690.86971386 3347.97023025  325.94340971 3967.53209153 3874.2414588 ]
total_rewards_mean           2764.747962699026
total_rewards_std            1236.6828335713874
total_rewards_max            3967.5320915257926
total_rewards_min            325.943409709705
Number of train steps total  1184000
Number of env steps total    1482000
Number of rollouts total     0
Train Time (s)               116.66995793068781
(Previous) Eval Time (s)     22.88144007511437
Sample Time (s)              17.80161064118147
Epoch Time (s)               157.35300864698365
Total Train Time (s)         45618.12379716383
Epoch                        295
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:11:53.493399 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #295 | Epoch Duration: 154.59273076057434
2020-01-12 12:11:53.493601 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #295 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0171
Z variance train             0.011877897
KL Divergence                24.751856
KL Loss                      2.4751856
QF Loss                      620.2495
VF Loss                      126.77243
Policy Loss                  -1389.3417
Q Predictions Mean           1389.2474
Q Predictions Std            265.61304
Q Predictions Max            1571.4792
Q Predictions Min            -70.42466
V Predictions Mean           1391.6184
V Predictions Std            262.98138
V Predictions Max            1567.1998
V Predictions Min            -73.09308
Log Pis Mean                 0.6075459
Log Pis Std                  3.1451266
Log Pis Max                  17.214922
Log Pis Min                  -7.755511
Policy mu Mean               0.014954441
Policy mu Std                0.604441
Policy mu Max                2.7441041
Policy mu Min                -2.724506
Policy log std Mean          -1.0781096
Policy log std Std           0.2823362
Policy log std Max           -0.27665782
Policy log std Min           -2.512268
Z mean eval                  1.0615507
Z variance eval              0.008372752
total_rewards                [3771.91363205 4068.00006092  636.99330738 3931.6756306   858.28177353
 3835.70996414 2005.04558981 3669.71434232 3891.87799318 3091.34111935]
total_rewards_mean           2976.0553413280186
total_rewards_std            1253.402196739402
total_rewards_max            4068.0000609219865
total_rewards_min            636.9933073788632
Number of train steps total  1188000
Number of env steps total    1487000
Number of rollouts total     0
Train Time (s)               118.25552821299061
(Previous) Eval Time (s)     20.120831976179034
Sample Time (s)              18.370887686032802
Epoch Time (s)               156.74724787520245
Total Train Time (s)         45775.413826739416
Epoch                        296
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:14:30.787730 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #296 | Epoch Duration: 157.29395961761475
2020-01-12 12:14:30.787982 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #296 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0638385
Z variance train             0.008355726
KL Divergence                24.879993
KL Loss                      2.4879994
QF Loss                      1507.0101
VF Loss                      218.9687
Policy Loss                  -1394.1704
Q Predictions Mean           1389.0621
Q Predictions Std            303.138
Q Predictions Max            1580.1008
Q Predictions Min            -111.68096
V Predictions Mean           1385.9347
V Predictions Std            286.47906
V Predictions Max            1558.4762
V Predictions Min            -116.73957
Log Pis Mean                 0.86720973
Log Pis Std                  3.0123146
Log Pis Max                  13.357458
Log Pis Min                  -6.121234
Policy mu Mean               -0.03493259
Policy mu Std                0.6516129
Policy mu Max                2.6299884
Policy mu Min                -2.1813116
Policy log std Mean          -1.0785661
Policy log std Std           0.3144879
Policy log std Max           -0.07430518
Policy log std Min           -3.1224241
Z mean eval                  1.0587912
Z variance eval              0.006709973
total_rewards                [3903.54563734 1445.74146438 2113.98970917 3805.79078025 3896.3854777
  752.12778695 -104.62442973 2813.18300197 4070.72083905 4190.05275637]
total_rewards_mean           2688.6913023451407
total_rewards_std            1476.143448594973
total_rewards_max            4190.052756374586
total_rewards_min            -104.62442972906578
Number of train steps total  1192000
Number of env steps total    1492000
Number of rollouts total     0
Train Time (s)               115.46999421017244
(Previous) Eval Time (s)     20.667210581712425
Sample Time (s)              18.02357285981998
Epoch Time (s)               154.16077765170485
Total Train Time (s)         45929.20162823051
Epoch                        297
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:17:04.580777 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #297 | Epoch Duration: 153.79259729385376
2020-01-12 12:17:04.581052 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #297 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0581199
Z variance train             0.006708364
KL Divergence                25.811586
KL Loss                      2.5811586
QF Loss                      546.797
VF Loss                      1894.7358
Policy Loss                  -1407.0155
Q Predictions Mean           1410.3383
Q Predictions Std            267.69495
Q Predictions Max            1603.3687
Q Predictions Min            -125.37831
V Predictions Mean           1411.6152
V Predictions Std            252.69803
V Predictions Max            1600.0251
V Predictions Min            -130.5373
Log Pis Mean                 0.8428098
Log Pis Std                  3.0033424
Log Pis Max                  12.252568
Log Pis Min                  -7.787762
Policy mu Mean               0.013244553
Policy mu Std                0.6484686
Policy mu Max                2.6361773
Policy mu Min                -2.1781237
Policy log std Mean          -1.0634295
Policy log std Std           0.30839908
Policy log std Max           -0.15052807
Policy log std Min           -3.2176673
Z mean eval                  1.0530593
Z variance eval              0.0070201545
total_rewards                [2117.91876729 1691.14350746 2489.65285112 3661.3805097  1449.82067505
  102.82423421 3791.6528983  1478.24594125 4053.1681078  3816.95833286]
total_rewards_mean           2465.276582503483
total_rewards_std            1258.7881768969744
total_rewards_max            4053.168107797357
total_rewards_min            102.82423421440065
Number of train steps total  1196000
Number of env steps total    1497000
Number of rollouts total     0
Train Time (s)               113.51503737969324
(Previous) Eval Time (s)     20.298725806176662
Sample Time (s)              18.673744790721685
Epoch Time (s)               152.4875079765916
Total Train Time (s)         46080.28449422121
Epoch                        298
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:19:35.665140 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #298 | Epoch Duration: 151.0839078426361
2020-01-12 12:19:35.665301 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #298 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0521836
Z variance train             0.0070219813
KL Divergence                24.812702
KL Loss                      2.4812703
QF Loss                      808.9214
VF Loss                      158.91072
Policy Loss                  -1411.6447
Q Predictions Mean           1413.7261
Q Predictions Std            270.45007
Q Predictions Max            1609.2678
Q Predictions Min            -145.61528
V Predictions Mean           1405.5735
V Predictions Std            266.03464
V Predictions Max            1605.1202
V Predictions Min            -126.4714
Log Pis Mean                 0.13332997
Log Pis Std                  2.8665843
Log Pis Max                  9.271402
Log Pis Min                  -11.957174
Policy mu Mean               0.047598623
Policy mu Std                0.5970298
Policy mu Max                2.429232
Policy mu Min                -1.7984037
Policy log std Mean          -1.0609475
Policy log std Std           0.2742005
Policy log std Max           -0.23663557
Policy log std Min           -2.4764938
Z mean eval                  1.0192906
Z variance eval              0.011106996
total_rewards                [3701.72503217 3969.99686728   72.5546095  3839.7305999   887.57682156
  495.88124239 3954.54314063 3932.50477341 3771.28045016 3735.45976853]
total_rewards_mean           2836.125330553877
total_rewards_std            1552.0722169388573
total_rewards_max            3969.9968672821824
total_rewards_min            72.5546094968977
Number of train steps total  1200000
Number of env steps total    1502000
Number of rollouts total     0
Train Time (s)               121.80140422936529
(Previous) Eval Time (s)     18.894831831101328
Sample Time (s)              18.449667601380497
Epoch Time (s)               159.14590366184711
Total Train Time (s)         46242.004576014355
Epoch                        299
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:22:17.393822 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #299 | Epoch Duration: 161.72835993766785
2020-01-12 12:22:17.394113 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #299 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0199096
Z variance train             0.011165399
KL Divergence                24.812553
KL Loss                      2.4812553
QF Loss                      437.984
VF Loss                      361.0432
Policy Loss                  -1402.282
Q Predictions Mean           1405.8816
Q Predictions Std            281.88464
Q Predictions Max            1596.156
Q Predictions Min            -127.0474
V Predictions Mean           1400.6592
V Predictions Std            276.67
V Predictions Max            1585.0621
V Predictions Min            -119.09552
Log Pis Mean                 0.6917604
Log Pis Std                  2.91569
Log Pis Max                  8.281713
Log Pis Min                  -9.569704
Policy mu Mean               0.010338219
Policy mu Std                0.6282354
Policy mu Max                2.8276973
Policy mu Min                -2.5308056
Policy log std Mean          -1.0577407
Policy log std Std           0.2945988
Policy log std Max           -0.19450742
Policy log std Min           -2.689746
Z mean eval                  1.0158513
Z variance eval              0.012685818
total_rewards                [2321.21242617 3701.50118247 3870.26651653    8.24061929 1702.17836111
 4014.62928105 4076.88623076 3922.70563823 4053.61893906 2342.63894453]
total_rewards_mean           3001.3878139196295
total_rewards_std            1301.074359139649
total_rewards_max            4076.8862307589966
total_rewards_min            8.24061929078046
Number of train steps total  1204000
Number of env steps total    1507000
Number of rollouts total     0
Train Time (s)               122.24883006699383
(Previous) Eval Time (s)     21.476928242016584
Sample Time (s)              17.987037440761924
Epoch Time (s)               161.71279574977234
Total Train Time (s)         46403.07950068312
Epoch                        300
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:24:58.468595 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #300 | Epoch Duration: 161.07426285743713
2020-01-12 12:24:58.468796 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #300 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0156455
Z variance train             0.01269531
KL Divergence                25.09256
KL Loss                      2.5092561
QF Loss                      798.72876
VF Loss                      396.70486
Policy Loss                  -1383.5966
Q Predictions Mean           1384.2402
Q Predictions Std            317.83337
Q Predictions Max            1599.2003
Q Predictions Min            -120.73654
V Predictions Mean           1392.4617
V Predictions Std            318.30377
V Predictions Max            1601.4407
V Predictions Min            -100.95208
Log Pis Mean                 0.6052807
Log Pis Std                  3.166617
Log Pis Max                  16.641369
Log Pis Min                  -6.06054
Policy mu Mean               -0.023263667
Policy mu Std                0.6451146
Policy mu Max                2.5300403
Policy mu Min                -2.4918725
Policy log std Mean          -1.0477788
Policy log std Std           0.31052712
Policy log std Max           0.20497441
Policy log std Min           -3.0927138
Z mean eval                  1.0894818
Z variance eval              0.015265539
total_rewards                [3635.63605455 4025.58307014   12.28360438 3322.53009803 2502.9210902
 1787.40286358 3843.32088645 2161.86272602 3756.79505272 3777.40902826]
total_rewards_mean           2882.5744474318003
total_rewards_std            1210.6480976241407
total_rewards_max            4025.5830701402874
total_rewards_min            12.283604384169607
Number of train steps total  1208000
Number of env steps total    1512000
Number of rollouts total     0
Train Time (s)               120.23758828034624
(Previous) Eval Time (s)     20.83809426659718
Sample Time (s)              18.35251196892932
Epoch Time (s)               159.42819451587275
Total Train Time (s)         46566.22124802321
Epoch                        301
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:27:41.612890 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #301 | Epoch Duration: 163.14397287368774
2020-01-12 12:27:41.613086 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #301 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0895921
Z variance train             0.015275289
KL Divergence                24.521847
KL Loss                      2.4521847
QF Loss                      617.4104
VF Loss                      169.5512
Policy Loss                  -1404.6613
Q Predictions Mean           1407.142
Q Predictions Std            244.7704
Q Predictions Max            1584.218
Q Predictions Min            -73.15023
V Predictions Mean           1400.8209
V Predictions Std            246.80319
V Predictions Max            1584.3301
V Predictions Min            -89.26574
Log Pis Mean                 0.8255541
Log Pis Std                  2.9640994
Log Pis Max                  10.894283
Log Pis Min                  -6.938789
Policy mu Mean               0.055092275
Policy mu Std                0.65216416
Policy mu Max                2.5572429
Policy mu Min                -2.4191406
Policy log std Mean          -1.0601863
Policy log std Std           0.30778515
Policy log std Max           -0.14110732
Policy log std Min           -2.5316074
Z mean eval                  1.0245489
Z variance eval              0.014068318
total_rewards                [3284.09200082 3683.87266613 2610.25866484    5.19698255  411.95851749
 3968.7046434  3802.12742541 3763.19756964 3621.94628975 3658.02821541]
total_rewards_mean           2880.9382975433673
total_rewards_std            1385.9805654473764
total_rewards_max            3968.704643401453
total_rewards_min            5.196982552333362
Number of train steps total  1212000
Number of env steps total    1517000
Number of rollouts total     0
Train Time (s)               118.47121580410749
(Previous) Eval Time (s)     24.55352596519515
Sample Time (s)              17.85646478878334
Epoch Time (s)               160.88120655808598
Total Train Time (s)         46726.083534076344
Epoch                        302
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:30:21.477817 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #302 | Epoch Duration: 159.86457014083862
2020-01-12 12:30:21.478014 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #302 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.02393
Z variance train             0.014060771
KL Divergence                24.901327
KL Loss                      2.4901328
QF Loss                      560.1827
VF Loss                      139.07632
Policy Loss                  -1418.6866
Q Predictions Mean           1421.0494
Q Predictions Std            237.26503
Q Predictions Max            1620.7367
Q Predictions Min            -80.57494
V Predictions Mean           1416.0807
V Predictions Std            235.70557
V Predictions Max            1601.8519
V Predictions Min            -97.812935
Log Pis Mean                 0.59002995
Log Pis Std                  3.0854075
Log Pis Max                  13.345233
Log Pis Min                  -6.3966455
Policy mu Mean               -0.013296214
Policy mu Std                0.6139079
Policy mu Max                2.2886255
Policy mu Min                -2.5750718
Policy log std Mean          -1.0515276
Policy log std Std           0.28724137
Policy log std Max           -0.12312317
Policy log std Min           -2.8702614
Z mean eval                  1.0241189
Z variance eval              0.0085902
total_rewards                [ 135.60842641 1199.59435958 3958.78877887 3701.45418994  745.68910191
 3001.09133209 3812.83423878 3942.87613703  359.9824718  4024.95311682]
total_rewards_mean           2488.287215323974
total_rewards_std            1577.6840268759954
total_rewards_max            4024.9531168232334
total_rewards_min            135.6084264141045
Number of train steps total  1216000
Number of env steps total    1522000
Number of rollouts total     0
Train Time (s)               115.68373404396698
(Previous) Eval Time (s)     23.53659086767584
Sample Time (s)              19.35621317801997
Epoch Time (s)               158.5765380896628
Total Train Time (s)         46880.78564872593
Epoch                        303
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:32:56.182689 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #303 | Epoch Duration: 154.70453572273254
2020-01-12 12:32:56.182897 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #303 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0239935
Z variance train             0.008567246
KL Divergence                26.120153
KL Loss                      2.6120155
QF Loss                      1594.0579
VF Loss                      352.5136
Policy Loss                  -1420.165
Q Predictions Mean           1415.0171
Q Predictions Std            257.11066
Q Predictions Max            1634.7257
Q Predictions Min            -148.08447
V Predictions Mean           1415.0022
V Predictions Std            241.28558
V Predictions Max            1636.3442
V Predictions Min            -125.86207
Log Pis Mean                 1.1454607
Log Pis Std                  3.1983697
Log Pis Max                  12.008293
Log Pis Min                  -5.9304204
Policy mu Mean               -0.0031961277
Policy mu Std                0.66161567
Policy mu Max                2.4294274
Policy mu Min                -2.159426
Policy log std Mean          -1.0844545
Policy log std Std           0.3382418
Policy log std Max           -0.10469818
Policy log std Min           -2.7022693
Z mean eval                  1.0228957
Z variance eval              0.010574283
total_rewards                [3626.18407639 2737.1703371  3832.59347131 3914.12960564   35.37014099
 3927.39034677 3959.1181682  3861.07250359 2890.59984345 3771.88774249]
total_rewards_mean           3255.5516235941004
total_rewards_std            1151.3114298422674
total_rewards_max            3959.1181682008055
total_rewards_min            35.37014099272527
Number of train steps total  1220000
Number of env steps total    1527000
Number of rollouts total     0
Train Time (s)               118.11927865585312
(Previous) Eval Time (s)     19.66422497527674
Sample Time (s)              18.347169185988605
Epoch Time (s)               156.13067281711847
Total Train Time (s)         47040.82758041425
Epoch                        304
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:35:36.226332 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #304 | Epoch Duration: 160.0432994365692
2020-01-12 12:35:36.226492 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #304 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0235624
Z variance train             0.010639826
KL Divergence                25.85125
KL Loss                      2.585125
QF Loss                      3296.6895
VF Loss                      1179.7761
Policy Loss                  -1398.4353
Q Predictions Mean           1400.428
Q Predictions Std            333.35272
Q Predictions Max            1612.4744
Q Predictions Min            -138.03384
V Predictions Mean           1396.5283
V Predictions Std            335.1776
V Predictions Max            1616.7527
V Predictions Min            -150.40016
Log Pis Mean                 0.5550852
Log Pis Std                  3.1956484
Log Pis Max                  15.776358
Log Pis Min                  -6.8209524
Policy mu Mean               0.023020718
Policy mu Std                0.6090716
Policy mu Max                2.708441
Policy mu Min                -2.3906183
Policy log std Mean          -1.0692542
Policy log std Std           0.33012938
Policy log std Max           -0.15682757
Policy log std Min           -3.181647
Z mean eval                  1.0244577
Z variance eval              0.007803972
total_rewards                [3769.15310991 3199.68572827 3865.36839646 3936.81726418 3757.42870941
 3860.69649364 3867.11682557 3818.83280462  916.15051716 3773.43957931]
total_rewards_mean           3476.4689428530996
total_rewards_std            875.5139241996966
total_rewards_max            3936.817264175891
total_rewards_min            916.1505171587423
Number of train steps total  1224000
Number of env steps total    1532000
Number of rollouts total     0
Train Time (s)               124.09624454099685
(Previous) Eval Time (s)     23.57653377717361
Sample Time (s)              17.906879865098745
Epoch Time (s)               165.5796581832692
Total Train Time (s)         47208.24625152163
Epoch                        305
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:38:23.647403 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #305 | Epoch Duration: 167.4208002090454
2020-01-12 12:38:23.647554 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #305 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0241259
Z variance train             0.0078089572
KL Divergence                25.241184
KL Loss                      2.5241184
QF Loss                      626.36426
VF Loss                      164.63992
Policy Loss                  -1418.0826
Q Predictions Mean           1420.6162
Q Predictions Std            271.76068
Q Predictions Max            1607.8745
Q Predictions Min            -91.514496
V Predictions Mean           1410.8722
V Predictions Std            271.7425
V Predictions Max            1594.1036
V Predictions Min            -87.6615
Log Pis Mean                 0.91328835
Log Pis Std                  3.1487446
Log Pis Max                  16.263885
Log Pis Min                  -8.690535
Policy mu Mean               -0.0086395545
Policy mu Std                0.6543961
Policy mu Max                2.517591
Policy mu Min                -1.955509
Policy log std Mean          -1.0596344
Policy log std Std           0.29184312
Policy log std Max           -0.1974045
Policy log std Min           -3.163281
Z mean eval                  1.0499308
Z variance eval              0.0148961125
total_rewards                [4095.14160936 3977.08020327 3764.99895978  892.27851361  479.79217371
 1540.52114117 1187.05464957 1986.86890397 2358.44654459  527.64683467]
total_rewards_mean           2080.982953369864
total_rewards_std            1343.6764238311696
total_rewards_max            4095.1416093571224
total_rewards_min            479.79217370785994
Number of train steps total  1228000
Number of env steps total    1537000
Number of rollouts total     0
Train Time (s)               118.6218490502797
(Previous) Eval Time (s)     25.41734827402979
Sample Time (s)              18.255165516398847
Epoch Time (s)               162.29436284070835
Total Train Time (s)         47362.81869802484
Epoch                        306
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:40:58.223233 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #306 | Epoch Duration: 154.57555317878723
2020-01-12 12:40:58.223419 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #306 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0495816
Z variance train             0.014910077
KL Divergence                23.797695
KL Loss                      2.3797696
QF Loss                      2668.1455
VF Loss                      411.4812
Policy Loss                  -1413.8607
Q Predictions Mean           1409.7217
Q Predictions Std            282.74518
Q Predictions Max            1602.7733
Q Predictions Min            -147.93187
V Predictions Mean           1413.1318
V Predictions Std            273.12064
V Predictions Max            1604.0605
V Predictions Min            -120.060936
Log Pis Mean                 0.78353596
Log Pis Std                  3.2609239
Log Pis Max                  15.077503
Log Pis Min                  -10.966818
Policy mu Mean               -0.0060009314
Policy mu Std                0.6414771
Policy mu Max                2.6815658
Policy mu Min                -3.606334
Policy log std Mean          -1.075272
Policy log std Std           0.31196824
Policy log std Max           0.11144352
Policy log std Min           -3.274993
Z mean eval                  1.0063782
Z variance eval              0.014905596
total_rewards                [3710.9010931  3239.0169816  1018.7149732  1414.31507076 4077.96553787
 3664.33768154  829.34657773 3907.72571934 3793.67653054 1795.66348139]
total_rewards_mean           2745.1663647062564
total_rewards_std            1247.8942310721832
total_rewards_max            4077.9655378699417
total_rewards_min            829.3465777269239
Number of train steps total  1232000
Number of env steps total    1542000
Number of rollouts total     0
Train Time (s)               119.45024062599987
(Previous) Eval Time (s)     17.698215244337916
Sample Time (s)              18.59048271505162
Epoch Time (s)               155.7389385853894
Total Train Time (s)         47522.932126110885
Epoch                        307
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:43:38.343332 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #307 | Epoch Duration: 160.1197657585144
2020-01-12 12:43:38.343532 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #307 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0056026
Z variance train             0.014912849
KL Divergence                24.317097
KL Loss                      2.4317098
QF Loss                      1241.7487
VF Loss                      437.9939
Policy Loss                  -1380.0361
Q Predictions Mean           1381.2377
Q Predictions Std            324.4815
Q Predictions Max            1626.6127
Q Predictions Min            -136.03569
V Predictions Mean           1388.2914
V Predictions Std            323.95593
V Predictions Max            1615.132
V Predictions Min            -135.31895
Log Pis Mean                 0.56385565
Log Pis Std                  3.165541
Log Pis Max                  15.69027
Log Pis Min                  -8.75041
Policy mu Mean               -0.0043702307
Policy mu Std                0.61553925
Policy mu Max                2.7106228
Policy mu Min                -1.9289384
Policy log std Mean          -1.0632324
Policy log std Std           0.32473433
Policy log std Max           -0.12338698
Policy log std Min           -3.157209
Z mean eval                  1.0450337
Z variance eval              0.011835156
total_rewards                [3778.21559038 1997.88544779 1761.61959597 4102.65465273 3993.55080733
 1017.54261139  267.84081882 3738.18585258  437.20185742 4024.68436001]
total_rewards_mean           2511.938159440515
total_rewards_std            1500.7347464810691
total_rewards_max            4102.654652726249
total_rewards_min            267.8408188155134
Number of train steps total  1236000
Number of env steps total    1547000
Number of rollouts total     0
Train Time (s)               119.61573075409979
(Previous) Eval Time (s)     22.078712245915085
Sample Time (s)              17.546692638657987
Epoch Time (s)               159.24113563867286
Total Train Time (s)         47677.222350754775
Epoch                        308
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:46:12.634337 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #308 | Epoch Duration: 154.2906515598297
2020-01-12 12:46:12.634555 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #308 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0446049
Z variance train             0.011830935
KL Divergence                24.337917
KL Loss                      2.4337919
QF Loss                      2082.566
VF Loss                      185.06258
Policy Loss                  -1426.5374
Q Predictions Mean           1429.6418
Q Predictions Std            273.08673
Q Predictions Max            1610.082
Q Predictions Min            -113.40309
V Predictions Mean           1432.109
V Predictions Std            271.74637
V Predictions Max            1612.4255
V Predictions Min            -98.61141
Log Pis Mean                 0.94712883
Log Pis Std                  3.0503173
Log Pis Max                  10.527147
Log Pis Min                  -5.8562813
Policy mu Mean               0.0014038589
Policy mu Std                0.63198006
Policy mu Max                2.5438795
Policy mu Min                -2.4249434
Policy log std Mean          -1.0822668
Policy log std Std           0.32175615
Policy log std Max           -0.1626358
Policy log std Min           -2.586752
Z mean eval                  1.0431216
Z variance eval              0.02253552
total_rewards                [3835.98119394 1497.42920325  677.37469854 4027.39685654 2769.48078313
 1111.14661857 1063.10900784 2992.06232298 3884.40822398 1212.50780046]
total_rewards_mean           2307.08967092284
total_rewards_std            1263.142553491659
total_rewards_max            4027.3968565363475
total_rewards_min            677.3746985431941
Number of train steps total  1240000
Number of env steps total    1552000
Number of rollouts total     0
Train Time (s)               117.43720032274723
(Previous) Eval Time (s)     17.12794862361625
Sample Time (s)              18.52951414557174
Epoch Time (s)               153.09466309193522
Total Train Time (s)         47830.012070851866
Epoch                        309
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:48:45.428188 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #309 | Epoch Duration: 152.79345035552979
2020-01-12 12:48:45.428436 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #309 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0434723
Z variance train             0.022519097
KL Divergence                23.04018
KL Loss                      2.304018
QF Loss                      457.26657
VF Loss                      189.00061
Policy Loss                  -1422.3461
Q Predictions Mean           1420.7527
Q Predictions Std            312.8287
Q Predictions Max            1644.2615
Q Predictions Min            -135.31778
V Predictions Mean           1426.1857
V Predictions Std            305.32632
V Predictions Max            1651.4015
V Predictions Min            -135.73177
Log Pis Mean                 0.46870404
Log Pis Std                  3.1129375
Log Pis Max                  12.246845
Log Pis Min                  -6.1287165
Policy mu Mean               0.05048473
Policy mu Std                0.6127553
Policy mu Max                2.4030237
Policy mu Min                -2.2671502
Policy log std Mean          -1.0505327
Policy log std Std           0.29011706
Policy log std Max           -0.029931426
Policy log std Min           -2.2726696
Z mean eval                  1.0362314
Z variance eval              0.011921567
total_rewards                [2083.04957776 3740.04368809  450.2192875  1396.01882486 1678.44430157
 3726.87643909  349.46554678 3771.89246951  187.69591238 1626.86818299]
total_rewards_mean           1901.0574230526713
total_rewards_std            1344.4852962006323
total_rewards_max            3771.8924695110654
total_rewards_min            187.69591237591925
Number of train steps total  1244000
Number of env steps total    1557000
Number of rollouts total     0
Train Time (s)               115.46740301605314
(Previous) Eval Time (s)     16.826416230760515
Sample Time (s)              18.5020047375001
Epoch Time (s)               150.79582398431376
Total Train Time (s)         47980.03013714962
Epoch                        310
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:51:15.449665 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #310 | Epoch Duration: 150.02100157737732
2020-01-12 12:51:15.449885 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #310 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0369523
Z variance train             0.011888143
KL Divergence                24.276333
KL Loss                      2.4276333
QF Loss                      2418.4414
VF Loss                      213.07022
Policy Loss                  -1448.8442
Q Predictions Mean           1450.5356
Q Predictions Std            269.16605
Q Predictions Max            1662.4167
Q Predictions Min            -119.29153
V Predictions Mean           1440.7456
V Predictions Std            265.63162
V Predictions Max            1634.5801
V Predictions Min            -149.0568
Log Pis Mean                 0.945487
Log Pis Std                  2.9072556
Log Pis Max                  11.239447
Log Pis Min                  -7.955045
Policy mu Mean               0.08709133
Policy mu Std                0.62512165
Policy mu Max                2.512495
Policy mu Min                -2.3220022
Policy log std Mean          -1.1110432
Policy log std Std           0.30635902
Policy log std Max           0.057454944
Policy log std Min           -2.6928701
Z mean eval                  1.0394696
Z variance eval              0.0120721925
total_rewards                [3842.15857535 3874.21541852 4076.93310056  318.40266582 3734.25086973
  691.32044761  628.4241872  3933.20543418 4071.48440599 4143.94424298]
total_rewards_mean           2931.433934794739
total_rewards_std            1568.3837819137839
total_rewards_max            4143.944242981214
total_rewards_min            318.40266581615293
Number of train steps total  1248000
Number of env steps total    1562000
Number of rollouts total     0
Train Time (s)               116.66636596666649
(Previous) Eval Time (s)     16.0513166137971
Sample Time (s)              17.81400077464059
Epoch Time (s)               150.53168335510418
Total Train Time (s)         48134.132036126684
Epoch                        311
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:53:49.553919 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #311 | Epoch Duration: 154.10387802124023
2020-01-12 12:53:49.554083 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #311 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0388567
Z variance train             0.012039008
KL Divergence                24.059978
KL Loss                      2.405998
QF Loss                      982.6448
VF Loss                      366.6593
Policy Loss                  -1385.3333
Q Predictions Mean           1388.2098
Q Predictions Std            359.97812
Q Predictions Max            1624.0486
Q Predictions Min            -138.04913
V Predictions Mean           1381.3009
V Predictions Std            356.3814
V Predictions Max            1613.1929
V Predictions Min            -135.42183
Log Pis Mean                 0.21253508
Log Pis Std                  3.1304731
Log Pis Max                  15.1513
Log Pis Min                  -6.8323917
Policy mu Mean               0.013053544
Policy mu Std                0.61495084
Policy mu Max                2.4814467
Policy mu Min                -2.3508239
Policy log std Mean          -1.0666177
Policy log std Std           0.33437887
Policy log std Max           0.22498035
Policy log std Min           -3.9168499
Z mean eval                  1.0357382
Z variance eval              0.012268488
total_rewards                [3904.8758031   135.84725202 2046.36060287  244.04329237 3885.82128891
 1185.87876438 2205.51609607 3426.5212703   963.71482629 1782.48464109]
total_rewards_mean           1978.1063837386046
total_rewards_std            1326.7204779543108
total_rewards_max            3904.8758031022344
total_rewards_min            135.847252023949
Number of train steps total  1252000
Number of env steps total    1567000
Number of rollouts total     0
Train Time (s)               114.65583250625059
(Previous) Eval Time (s)     19.62323026219383
Sample Time (s)              17.626406746916473
Epoch Time (s)               151.9054695153609
Total Train Time (s)         48280.202443232294
Epoch                        312
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:56:15.630573 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #312 | Epoch Duration: 146.07633686065674
2020-01-12 12:56:15.630869 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #312 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0340244
Z variance train             0.012295762
KL Divergence                24.02763
KL Loss                      2.4027631
QF Loss                      1383.7648
VF Loss                      474.04724
Policy Loss                  -1450.0314
Q Predictions Mean           1451.7122
Q Predictions Std            217.69359
Q Predictions Max            1676.4589
Q Predictions Min            29.146242
V Predictions Mean           1454.4811
V Predictions Std            211.99648
V Predictions Max            1667.4045
V Predictions Min            20.88974
Log Pis Mean                 0.8279084
Log Pis Std                  3.4433246
Log Pis Max                  21.17899
Log Pis Min                  -9.983513
Policy mu Mean               0.01486852
Policy mu Std                0.65035367
Policy mu Max                4.016273
Policy mu Min                -2.340797
Policy log std Mean          -1.0775229
Policy log std Std           0.32091177
Policy log std Max           -0.08374822
Policy log std Min           -2.8542297
Z mean eval                  1.0496601
Z variance eval              0.014288383
total_rewards                [1801.73190269 4128.68547038 2950.02036818 1284.72051125 2668.51950464
 1022.69657736 1559.32558976  789.24008706  343.58400953 3886.50645301]
total_rewards_mean           2043.503047385989
total_rewards_std            1238.1698069020488
total_rewards_max            4128.685470383603
total_rewards_min            343.58400953488183
Number of train steps total  1256000
Number of env steps total    1572000
Number of rollouts total     0
Train Time (s)               119.71836337493733
(Previous) Eval Time (s)     13.79379697702825
Sample Time (s)              17.966944811400026
Epoch Time (s)               151.4791051633656
Total Train Time (s)         48435.287046637386
Epoch                        313
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:58:50.716648 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #313 | Epoch Duration: 155.08558869361877
2020-01-12 12:58:50.716795 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #313 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0502589
Z variance train             0.014383974
KL Divergence                24.182755
KL Loss                      2.4182756
QF Loss                      697.6166
VF Loss                      148.85612
Policy Loss                  -1369.483
Q Predictions Mean           1370.1599
Q Predictions Std            400.50702
Q Predictions Max            1622.2517
Q Predictions Min            -178.01192
V Predictions Mean           1369.1533
V Predictions Std            402.3684
V Predictions Max            1626.0654
V Predictions Min            -161.71007
Log Pis Mean                 0.5262383
Log Pis Std                  3.4325547
Log Pis Max                  18.265375
Log Pis Min                  -10.627
Policy mu Mean               -0.005529389
Policy mu Std                0.6295039
Policy mu Max                2.7174346
Policy mu Min                -3.410902
Policy log std Mean          -1.057458
Policy log std Std           0.32235366
Policy log std Max           -0.023118138
Policy log std Min           -3.422327
Z mean eval                  1.0511966
Z variance eval              0.009641214
total_rewards                [3871.9613284  1162.25571991  874.41415552 1636.11162057 3053.31668617
 1545.09950196 1644.22389505 3880.93302848 1172.87173284 2200.38275738]
total_rewards_mean           2104.1570426267185
total_rewards_std            1058.4005226399975
total_rewards_max            3880.9330284759053
total_rewards_min            874.4141555240558
Number of train steps total  1260000
Number of env steps total    1577000
Number of rollouts total     0
Train Time (s)               114.13272888120264
(Previous) Eval Time (s)     17.39998328918591
Sample Time (s)              17.71802980499342
Epoch Time (s)               149.25074197538197
Total Train Time (s)         48584.99409746798
Epoch                        314
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:01:20.425990 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #314 | Epoch Duration: 149.709082365036
2020-01-12 13:01:20.426144 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #314 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0543654
Z variance train             0.009633752
KL Divergence                24.224491
KL Loss                      2.422449
QF Loss                      1130.8201
VF Loss                      695.37665
Policy Loss                  -1414.7524
Q Predictions Mean           1419.7495
Q Predictions Std            269.57968
Q Predictions Max            1599.3728
Q Predictions Min            -170.37611
V Predictions Mean           1419.4529
V Predictions Std            264.43118
V Predictions Max            1601.7969
V Predictions Min            -176.27975
Log Pis Mean                 0.8824753
Log Pis Std                  3.1634853
Log Pis Max                  14.076767
Log Pis Min                  -8.003302
Policy mu Mean               0.021566477
Policy mu Std                0.6472843
Policy mu Max                2.3468213
Policy mu Min                -2.336984
Policy log std Mean          -1.0611224
Policy log std Std           0.33077314
Policy log std Max           -0.14715463
Policy log std Min           -3.075566
Z mean eval                  1.0391331
Z variance eval              0.008818654
total_rewards                [3864.42191334  676.58537829 3985.60661121 3916.63275417 2419.70512325
  571.57894406 3908.07186546 3674.91332384 3300.7104757  1806.97921069]
total_rewards_mean           2812.5205600018076
total_rewards_std            1289.7065640247895
total_rewards_max            3985.606611210217
total_rewards_min            571.5789440592864
Number of train steps total  1264000
Number of env steps total    1582000
Number of rollouts total     0
Train Time (s)               112.19873117096722
(Previous) Eval Time (s)     17.858024497982115
Sample Time (s)              18.32774459104985
Epoch Time (s)               148.3845002599992
Total Train Time (s)         48734.53159690602
Epoch                        315
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:03:49.969397 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #315 | Epoch Duration: 149.54310059547424
2020-01-12 13:03:49.969683 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #315 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0390438
Z variance train             0.008797249
KL Divergence                25.250313
KL Loss                      2.5250313
QF Loss                      577.85425
VF Loss                      148.87085
Policy Loss                  -1456.6554
Q Predictions Mean           1459.9006
Q Predictions Std            245.07375
Q Predictions Max            1657.5316
Q Predictions Min            -86.636795
V Predictions Mean           1457.2218
V Predictions Std            247.56894
V Predictions Max            1654.8553
V Predictions Min            -105.116135
Log Pis Mean                 0.6617876
Log Pis Std                  2.601368
Log Pis Max                  9.407275
Log Pis Min                  -6.776726
Policy mu Mean               0.053549815
Policy mu Std                0.62388444
Policy mu Max                2.294355
Policy mu Min                -2.7434313
Policy log std Mean          -1.0761106
Policy log std Std           0.26675937
Policy log std Max           0.43641508
Policy log std Min           -2.5074015
Z mean eval                  1.0393007
Z variance eval              0.004968187
total_rewards                [3089.02818722 3965.95698656 3957.78680003 4102.43061712 3362.65195252
  198.38620024 4027.930027   3055.15183181 3913.20364573 3605.28915804]
total_rewards_mean           3327.7815406282934
total_rewards_std            1106.338754819483
total_rewards_max            4102.430617123284
total_rewards_min            198.3862002433887
Number of train steps total  1268000
Number of env steps total    1587000
Number of rollouts total     0
Train Time (s)               117.10493506118655
(Previous) Eval Time (s)     19.016309661325067
Sample Time (s)              17.58159727510065
Epoch Time (s)               153.70284199761227
Total Train Time (s)         48892.753501113504
Epoch                        316
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:06:28.194283 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #316 | Epoch Duration: 158.2243995666504
2020-01-12 13:06:28.194491 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #316 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0382185
Z variance train             0.0049730083
KL Divergence                26.544323
KL Loss                      2.6544323
QF Loss                      1455.3217
VF Loss                      1323.5706
Policy Loss                  -1438.0615
Q Predictions Mean           1438.4098
Q Predictions Std            268.46478
Q Predictions Max            1622.4229
Q Predictions Min            -138.96092
V Predictions Mean           1433.5046
V Predictions Std            260.57266
V Predictions Max            1617.0496
V Predictions Min            -161.67232
Log Pis Mean                 1.1840467
Log Pis Std                  3.2915256
Log Pis Max                  14.837801
Log Pis Min                  -6.873308
Policy mu Mean               0.038229506
Policy mu Std                0.67076045
Policy mu Max                2.7836213
Policy mu Min                -2.3305893
Policy log std Mean          -1.1032228
Policy log std Std           0.3608081
Policy log std Max           -0.07789338
Policy log std Min           -3.0196373
Z mean eval                  1.0231054
Z variance eval              0.010734682
total_rewards                [3907.3911425  1166.84410432 3055.0403352  3977.57332322 4165.38390109
 4006.22992057 3926.73266279    7.58252684 3993.94349148 3917.19819196]
total_rewards_mean           3212.391959998946
total_rewards_std            1367.6470691282673
total_rewards_max            4165.383901093305
total_rewards_min            7.582526838938073
Number of train steps total  1272000
Number of env steps total    1592000
Number of rollouts total     0
Train Time (s)               121.86920720199123
(Previous) Eval Time (s)     23.537561840377748
Sample Time (s)              18.800752262119204
Epoch Time (s)               164.20752130448818
Total Train Time (s)         49055.55636808276
Epoch                        317
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:09:11.001034 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #317 | Epoch Duration: 162.8063817024231
2020-01-12 13:09:11.001248 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #317 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0226966
Z variance train             0.0107609425
KL Divergence                25.36208
KL Loss                      2.536208
QF Loss                      956.4609
VF Loss                      724.2427
Policy Loss                  -1429.9557
Q Predictions Mean           1432.5826
Q Predictions Std            287.4748
Q Predictions Max            1657.7328
Q Predictions Min            -134.07243
V Predictions Mean           1430.5554
V Predictions Std            284.76996
V Predictions Max            1647.6451
V Predictions Min            -145.37657
Log Pis Mean                 0.85904
Log Pis Std                  3.3124492
Log Pis Max                  16.01302
Log Pis Min                  -7.203407
Policy mu Mean               0.03093632
Policy mu Std                0.624108
Policy mu Max                2.5073085
Policy mu Min                -2.08882
Policy log std Mean          -1.1275904
Policy log std Std           0.3407894
Policy log std Max           0.012177825
Policy log std Min           -3.471996
Z mean eval                  1.0574322
Z variance eval              0.010132258
total_rewards                [4077.93183895 1803.58105987 3302.0497674  4065.54396394 3437.22762998
 2486.39845785 4095.21611614 3864.74383578 3903.94764506 3881.88079943]
total_rewards_mean           3491.8521114397568
total_rewards_std            734.70117816925
total_rewards_max            4095.2161161397767
total_rewards_min            1803.5810598657818
Number of train steps total  1276000
Number of env steps total    1597000
Number of rollouts total     0
Train Time (s)               113.46456194296479
(Previous) Eval Time (s)     22.136103514116257
Sample Time (s)              18.55711127119139
Epoch Time (s)               154.15777672827244
Total Train Time (s)         49211.65181486448
Epoch                        318
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:11:47.100203 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #318 | Epoch Duration: 156.09879231452942
2020-01-12 13:11:47.100422 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #318 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0575396
Z variance train             0.010139083
KL Divergence                24.766954
KL Loss                      2.4766955
QF Loss                      687.57526
VF Loss                      117.31389
Policy Loss                  -1461.1873
Q Predictions Mean           1462.6215
Q Predictions Std            195.7276
Q Predictions Max            1632.1166
Q Predictions Min            -83.609604
V Predictions Mean           1463.7288
V Predictions Std            192.89595
V Predictions Max            1648.2383
V Predictions Min            -81.18329
Log Pis Mean                 1.0617963
Log Pis Std                  3.333873
Log Pis Max                  17.6268
Log Pis Min                  -10.023876
Policy mu Mean               0.01750256
Policy mu Std                0.6523904
Policy mu Max                2.354757
Policy mu Min                -2.8505461
Policy log std Mean          -1.0818802
Policy log std Std           0.31863934
Policy log std Max           -0.20710444
Policy log std Min           -3.1386886
Z mean eval                  1.0550506
Z variance eval              0.0056509906
total_rewards                [3359.01167843 3885.12789868 3874.66528429  844.58731978 1709.80135899
 1792.85116083  116.65998314  651.48724158 3608.44392468  -40.1749575 ]
total_rewards_mean           1980.2460892901788
total_rewards_std            1499.6017485977166
total_rewards_max            3885.127898679595
total_rewards_min            -40.174957503082275
Number of train steps total  1280000
Number of env steps total    1602000
Number of rollouts total     0
Train Time (s)               119.5909807938151
(Previous) Eval Time (s)     24.076749888714403
Sample Time (s)              18.839050164911896
Epoch Time (s)               162.5067808474414
Total Train Time (s)         49369.17625490576
Epoch                        319
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:14:24.630418 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #319 | Epoch Duration: 157.52980065345764
2020-01-12 13:14:24.630749 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #319 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0539454
Z variance train             0.0056534475
KL Divergence                25.03975
KL Loss                      2.503975
QF Loss                      708.7272
VF Loss                      493.36044
Policy Loss                  -1428.5464
Q Predictions Mean           1432.7283
Q Predictions Std            321.04172
Q Predictions Max            1646.8981
Q Predictions Min            -164.96391
V Predictions Mean           1428.4893
V Predictions Std            321.02783
V Predictions Max            1636.6761
V Predictions Min            -163.76933
Log Pis Mean                 0.9932179
Log Pis Std                  3.1722298
Log Pis Max                  13.943586
Log Pis Min                  -6.204858
Policy mu Mean               0.030338895
Policy mu Std                0.63955843
Policy mu Max                2.8245466
Policy mu Min                -2.6333468
Policy log std Mean          -1.1018846
Policy log std Std           0.35314104
Policy log std Max           -0.239694
Policy log std Min           -2.9737039
Z mean eval                  1.0213848
Z variance eval              0.00793945
total_rewards                [3744.05944938 3956.30076065 3519.52939222 4025.92915559 3911.88727412
  883.33909053 4004.5818229  1083.11234763 3775.14787376 1540.78519516]
total_rewards_mean           3044.4672361943403
total_rewards_std            1244.8453907899445
total_rewards_max            4025.929155590777
total_rewards_min            883.339090529254
Number of train steps total  1284000
Number of env steps total    1607000
Number of rollouts total     0
Train Time (s)               111.08121818117797
(Previous) Eval Time (s)     19.099419108126312
Sample Time (s)              18.048026542179286
Epoch Time (s)               148.22866383148357
Total Train Time (s)         49519.23753667949
Epoch                        320
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:16:54.692892 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #320 | Epoch Duration: 150.06191849708557
2020-01-12 13:16:54.693047 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #320 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.021477
Z variance train             0.0079393005
KL Divergence                24.555168
KL Loss                      2.4555168
QF Loss                      943.77124
VF Loss                      505.46735
Policy Loss                  -1410.5068
Q Predictions Mean           1406.9655
Q Predictions Std            378.04782
Q Predictions Max            1647.4133
Q Predictions Min            -193.5022
V Predictions Mean           1401.9648
V Predictions Std            365.92218
V Predictions Max            1629.8815
V Predictions Min            -182.71834
Log Pis Mean                 0.7395772
Log Pis Std                  3.076343
Log Pis Max                  17.475668
Log Pis Min                  -6.796311
Policy mu Mean               0.011766711
Policy mu Std                0.63595754
Policy mu Max                2.827955
Policy mu Min                -2.1660252
Policy log std Mean          -1.0708766
Policy log std Std           0.31570375
Policy log std Max           -0.112308264
Policy log std Min           -2.8303163
Z mean eval                  1.0409615
Z variance eval              0.0055453414
total_rewards                [3612.26266912 3831.7888842  4047.22792627   12.08958421 4222.55272664
 4022.23877826 2269.96405619 1727.90640173 3002.11062064  246.58128962]
total_rewards_mean           2699.4722936880853
total_rewards_std            1498.6649133211156
total_rewards_max            4222.552726638193
total_rewards_min            12.089584210802617
Number of train steps total  1288000
Number of env steps total    1612000
Number of rollouts total     0
Train Time (s)               116.7688884739764
(Previous) Eval Time (s)     20.932393598835915
Sample Time (s)              17.70808746293187
Epoch Time (s)               155.4093695357442
Total Train Time (s)         49671.912066515535
Epoch                        321
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:19:27.374245 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #321 | Epoch Duration: 152.6810417175293
2020-01-12 13:19:27.374553 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #321 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0399387
Z variance train             0.0055479235
KL Divergence                25.420254
KL Loss                      2.5420253
QF Loss                      6914.4165
VF Loss                      161.623
Policy Loss                  -1420.8285
Q Predictions Mean           1422.0537
Q Predictions Std            331.06506
Q Predictions Max            1662.4292
Q Predictions Min            -159.58621
V Predictions Mean           1419.0173
V Predictions Std            327.87134
V Predictions Max            1664.253
V Predictions Min            -152.40637
Log Pis Mean                 0.667293
Log Pis Std                  3.1717815
Log Pis Max                  17.480373
Log Pis Min                  -7.553931
Policy mu Mean               0.032602362
Policy mu Std                0.6166953
Policy mu Max                2.6754103
Policy mu Min                -2.0230064
Policy log std Mean          -1.0709593
Policy log std Std           0.31183642
Policy log std Max           0.21949196
Policy log std Min           -3.08505
Z mean eval                  1.0608609
Z variance eval              0.0030608173
total_rewards                [3770.580804   3972.54437928 4210.06737561 3936.92035233   34.81625509
 3426.77908659 4070.17764972 4052.47684986 4099.95995874  756.61292391]
total_rewards_mean           3233.093563512675
total_rewards_std            1442.516353012889
total_rewards_max            4210.06737561456
total_rewards_min            34.81625508639058
Number of train steps total  1292000
Number of env steps total    1617000
Number of rollouts total     0
Train Time (s)               116.02273317612708
(Previous) Eval Time (s)     18.203771201893687
Sample Time (s)              18.978984823450446
Epoch Time (s)               153.2054892014712
Total Train Time (s)         49828.62779262522
Epoch                        322
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:22:04.092392 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #322 | Epoch Duration: 156.7176332473755
2020-01-12 13:22:04.092593 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #322 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0609753
Z variance train             0.0030514188
KL Divergence                26.808826
KL Loss                      2.6808827
QF Loss                      1607.5951
VF Loss                      219.07411
Policy Loss                  -1463.6694
Q Predictions Mean           1457.7239
Q Predictions Std            277.0693
Q Predictions Max            1647.8269
Q Predictions Min            -358.0804
V Predictions Mean           1455.6146
V Predictions Std            249.73792
V Predictions Max            1627.4026
V Predictions Min            -187.43262
Log Pis Mean                 0.82822454
Log Pis Std                  3.3542414
Log Pis Max                  14.183541
Log Pis Min                  -8.642443
Policy mu Mean               0.008979868
Policy mu Std                0.6100743
Policy mu Max                2.473319
Policy mu Min                -2.4793003
Policy log std Mean          -1.1245697
Policy log std Std           0.30615765
Policy log std Max           -0.26635998
Policy log std Min           -2.482407
Z mean eval                  1.0234207
Z variance eval              0.0092355525
total_rewards                [3745.41456886 4243.67616923 4107.99423641 3919.69874418 4072.02988284
 1505.88555668 2953.12951005  770.52418025 4016.42919273 3413.52119599]
total_rewards_mean           3274.830323720567
total_rewards_std            1139.257066226093
total_rewards_max            4243.676169229588
total_rewards_min            770.5241802484578
Number of train steps total  1296000
Number of env steps total    1622000
Number of rollouts total     0
Train Time (s)               119.42615073313937
(Previous) Eval Time (s)     21.715572119224817
Sample Time (s)              18.57917365524918
Epoch Time (s)               159.72089650761336
Total Train Time (s)         49988.16387401242
Epoch                        323
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:24:43.631132 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #323 | Epoch Duration: 159.5384087562561
2020-01-12 13:24:43.631345 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #323 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0224456
Z variance train             0.009197015
KL Divergence                24.944036
KL Loss                      2.4944036
QF Loss                      1700.5853
VF Loss                      321.31598
Policy Loss                  -1440.7495
Q Predictions Mean           1440.8145
Q Predictions Std            270.01813
Q Predictions Max            1636.5784
Q Predictions Min            -187.97307
V Predictions Mean           1450.1145
V Predictions Std            271.54315
V Predictions Max            1643.3043
V Predictions Min            -191.16171
Log Pis Mean                 0.57024294
Log Pis Std                  3.0152395
Log Pis Max                  15.486345
Log Pis Min                  -8.341618
Policy mu Mean               0.012361223
Policy mu Std                0.60771364
Policy mu Max                2.750514
Policy mu Min                -2.665188
Policy log std Mean          -1.1102995
Policy log std Std           0.29834038
Policy log std Max           0.09458923
Policy log std Min           -3.163401
Z mean eval                  1.0447128
Z variance eval              0.012847905
total_rewards                [4042.49175759 4134.39541006 4196.88204228 3855.90025848 4174.96063722
 1091.88401463 4198.19858485 3933.29902036 3986.30612988 2474.90773022]
total_rewards_mean           3608.9225585564373
total_rewards_std            969.9255002231386
total_rewards_max            4198.198584848898
total_rewards_min            1091.88401462525
Number of train steps total  1300000
Number of env steps total    1627000
Number of rollouts total     0
Train Time (s)               115.37293515820056
(Previous) Eval Time (s)     21.532766131218523
Sample Time (s)              18.882120979949832
Epoch Time (s)               155.78782226936892
Total Train Time (s)         50145.92796597676
Epoch                        324
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:27:21.398278 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #324 | Epoch Duration: 157.76677799224854
2020-01-12 13:27:21.398478 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #324 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.045624
Z variance train             0.012830159
KL Divergence                24.54005
KL Loss                      2.454005
QF Loss                      973.84094
VF Loss                      245.15094
Policy Loss                  -1400.128
Q Predictions Mean           1400.8928
Q Predictions Std            382.77393
Q Predictions Max            1637.9836
Q Predictions Min            -213.40355
V Predictions Mean           1403.3035
V Predictions Std            384.029
V Predictions Max            1647.7644
V Predictions Min            -185.9298
Log Pis Mean                 0.39461464
Log Pis Std                  2.9710712
Log Pis Max                  9.065386
Log Pis Min                  -7.3762856
Policy mu Mean               0.007688646
Policy mu Std                0.6393073
Policy mu Max                2.6431623
Policy mu Min                -2.2523248
Policy log std Mean          -1.060794
Policy log std Std           0.32828936
Policy log std Max           0.16499603
Policy log std Min           -2.766706
Z mean eval                  1.0222366
Z variance eval              0.005652131
total_rewards                [1047.63549234 4117.47334614 4066.52642674 4073.47394044 4069.14893176
 3990.03289002 4263.13952066 4063.88476836 3968.73375467 4013.43365353]
total_rewards_mean           3767.348272464088
total_rewards_std            909.8447518914168
total_rewards_max            4263.139520657766
total_rewards_min            1047.6354923351562
Number of train steps total  1304000
Number of env steps total    1632000
Number of rollouts total     0
Train Time (s)               124.5463045812212
(Previous) Eval Time (s)     23.511379862669855
Sample Time (s)              18.58526929235086
Epoch Time (s)               166.6429537362419
Total Train Time (s)         50313.428695358336
Epoch                        325
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:30:08.901226 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #325 | Epoch Duration: 167.5026149749756
2020-01-12 13:30:08.901421 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #325 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0224841
Z variance train             0.005657441
KL Divergence                26.419209
KL Loss                      2.6419208
QF Loss                      537.5846
VF Loss                      81.484634
Policy Loss                  -1427.8652
Q Predictions Mean           1428.4514
Q Predictions Std            350.7277
Q Predictions Max            1624.5219
Q Predictions Min            -158.80687
V Predictions Mean           1426.8661
V Predictions Std            348.74817
V Predictions Max            1624.6316
V Predictions Min            -175.41287
Log Pis Mean                 0.6836152
Log Pis Std                  2.8351295
Log Pis Max                  12.186813
Log Pis Min                  -6.7019043
Policy mu Mean               0.0029611764
Policy mu Std                0.6316844
Policy mu Max                2.5695841
Policy mu Min                -2.1877358
Policy log std Mean          -1.0600181
Policy log std Std           0.3142015
Policy log std Max           -0.0008161068
Policy log std Min           -2.9181247
Z mean eval                  1.0301576
Z variance eval              0.011678735
total_rewards                [3941.24069759  843.16893147 4058.49982775   11.47100245 1437.01362688
 4225.71266231 4332.44915288   84.63142468 3280.92652653 2551.38252431]
total_rewards_mean           2476.6496376864534
total_rewards_std            1653.8106211734469
total_rewards_max            4332.4491528806675
total_rewards_min            11.47100245326887
Number of train steps total  1308000
Number of env steps total    1637000
Number of rollouts total     0
Train Time (s)               118.58227588701993
(Previous) Eval Time (s)     24.370749298948795
Sample Time (s)              17.536965153180063
Epoch Time (s)               160.4899903391488
Total Train Time (s)         50466.36086173076
Epoch                        326
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:32:41.837110 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #326 | Epoch Duration: 152.93556022644043
2020-01-12 13:32:41.837309 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #326 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0297335
Z variance train             0.0116469655
KL Divergence                25.582626
KL Loss                      2.5582626
QF Loss                      742.296
VF Loss                      309.90067
Policy Loss                  -1443.2155
Q Predictions Mean           1441.9238
Q Predictions Std            307.78537
Q Predictions Max            1657.5891
Q Predictions Min            -162.11105
V Predictions Mean           1435.7153
V Predictions Std            300.72998
V Predictions Max            1649.6223
V Predictions Min            -165.0116
Log Pis Mean                 1.0684321
Log Pis Std                  3.29364
Log Pis Max                  16.343254
Log Pis Min                  -7.6199393
Policy mu Mean               -0.0070417225
Policy mu Std                0.6274409
Policy mu Max                2.4343057
Policy mu Min                -2.5473328
Policy log std Mean          -1.1311263
Policy log std Std           0.32354975
Policy log std Max           -0.13696313
Policy log std Min           -3.023507
Z mean eval                  1.0449095
Z variance eval              0.005281438
total_rewards                [4118.12522792 4179.49839669 4136.94103634 1259.35192304 3292.77784922
  367.22883438 4117.78783031 1167.16715987 4113.14957613 3922.86288575]
total_rewards_mean           3067.48907196637
total_rewards_std            1436.4912116121088
total_rewards_max            4179.49839668839
total_rewards_min            367.228834384502
Number of train steps total  1312000
Number of env steps total    1642000
Number of rollouts total     0
Train Time (s)               116.38623334886506
(Previous) Eval Time (s)     16.816024632193148
Sample Time (s)              17.629055914934725
Epoch Time (s)               150.83131389599293
Total Train Time (s)         50620.59119700687
Epoch                        327
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:35:16.072761 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #327 | Epoch Duration: 154.2352819442749
2020-01-12 13:35:16.072990 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #327 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0445182
Z variance train             0.005285929
KL Divergence                27.539581
KL Loss                      2.7539582
QF Loss                      628.16223
VF Loss                      124.83785
Policy Loss                  -1463.3082
Q Predictions Mean           1465.1233
Q Predictions Std            291.97318
Q Predictions Max            1656.1506
Q Predictions Min            -227.71204
V Predictions Mean           1461.6997
V Predictions Std            286.8725
V Predictions Max            1652.0602
V Predictions Min            -176.50499
Log Pis Mean                 0.85476637
Log Pis Std                  2.8020492
Log Pis Max                  8.275536
Log Pis Min                  -6.539917
Policy mu Mean               0.03732492
Policy mu Std                0.6098685
Policy mu Max                2.6041963
Policy mu Min                -2.1891973
Policy log std Mean          -1.08884
Policy log std Std           0.30052492
Policy log std Max           -0.20813632
Policy log std Min           -2.327209
Z mean eval                  1.0271914
Z variance eval              0.00654685
total_rewards                [3894.08408581 4218.99353656 2165.50718261 4070.86034188 4294.22297428
 4320.53454145  703.63197937 3654.66938301 4128.72242681 3671.88644825]
total_rewards_mean           3512.3112900026476
total_rewards_std            1111.305157722612
total_rewards_max            4320.5345414515095
total_rewards_min            703.6319793670505
Number of train steps total  1316000
Number of env steps total    1647000
Number of rollouts total     0
Train Time (s)               121.8899403437972
(Previous) Eval Time (s)     20.21971093211323
Sample Time (s)              17.542367583606392
Epoch Time (s)               159.65201885951683
Total Train Time (s)         50784.56143189501
Epoch                        328
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:38:00.044530 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #328 | Epoch Duration: 163.9713842868805
2020-01-12 13:38:00.044697 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #328 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.02784
Z variance train             0.0065446766
KL Divergence                26.014969
KL Loss                      2.601497
QF Loss                      1314.388
VF Loss                      246.80325
Policy Loss                  -1442.4479
Q Predictions Mean           1444.5428
Q Predictions Std            314.86783
Q Predictions Max            1659.6241
Q Predictions Min            -178.90263
V Predictions Mean           1436.3667
V Predictions Std            308.24936
V Predictions Max            1658.917
V Predictions Min            -163.39581
Log Pis Mean                 0.9209281
Log Pis Std                  3.36617
Log Pis Max                  17.117922
Log Pis Min                  -6.577423
Policy mu Mean               0.0050970763
Policy mu Std                0.6457742
Policy mu Max                2.5117338
Policy mu Min                -2.7857747
Policy log std Mean          -1.073559
Policy log std Std           0.30216068
Policy log std Max           -0.26040566
Policy log std Min           -2.503203
Z mean eval                  1.0160166
Z variance eval              0.008841038
total_rewards                [4136.11035024 4309.69813809 4202.67422588 2121.13237832 4172.26878273
 4249.45816042 4021.76871602 4174.1804748  4122.40078909 4077.8114287 ]
total_rewards_mean           3958.75034443075
total_rewards_std            617.446289054904
total_rewards_max            4309.698138090835
total_rewards_min            2121.132378321272
Number of train steps total  1320000
Number of env steps total    1652000
Number of rollouts total     0
Train Time (s)               122.04967085924
(Previous) Eval Time (s)     24.538775429595262
Sample Time (s)              18.674195759929717
Epoch Time (s)               165.26264204876497
Total Train Time (s)         50951.7013623598
Epoch                        329
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:40:47.191085 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #329 | Epoch Duration: 167.14622259140015
2020-01-12 13:40:47.191363 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #329 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0166109
Z variance train             0.008813992
KL Divergence                25.984985
KL Loss                      2.5984986
QF Loss                      958.30817
VF Loss                      2487.2537
Policy Loss                  -1459.7758
Q Predictions Mean           1460.6802
Q Predictions Std            267.1299
Q Predictions Max            1645.465
Q Predictions Min            -195.46501
V Predictions Mean           1456.3933
V Predictions Std            266.62244
V Predictions Max            1634.7151
V Predictions Min            -175.73842
Log Pis Mean                 1.2350457
Log Pis Std                  3.1521096
Log Pis Max                  15.068703
Log Pis Min                  -6.8176146
Policy mu Mean               0.0025078151
Policy mu Std                0.6109079
Policy mu Max                2.1927779
Policy mu Min                -2.5963848
Policy log std Mean          -1.1715689
Policy log std Std           0.29389
Policy log std Max           -0.22326493
Policy log std Min           -2.8350444
Z mean eval                  1.0369871
Z variance eval              0.007454966
total_rewards                [2323.47041936 2259.03484056 1596.75000348 2401.80500941 4052.23725008
 3909.3617836   899.48859111 2069.32115157 3615.42804348 3895.67418304]
total_rewards_mean           2702.2571275677114
total_rewards_std            1041.1819514495687
total_rewards_max            4052.237250076942
total_rewards_min            899.4885911080828
Number of train steps total  1324000
Number of env steps total    1657000
Number of rollouts total     0
Train Time (s)               121.20688536670059
(Previous) Eval Time (s)     26.421986980829388
Sample Time (s)              18.437759262975305
Epoch Time (s)               166.06663161050528
Total Train Time (s)         51109.92432917794
Epoch                        330
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:43:25.416985 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #330 | Epoch Duration: 158.22540760040283
2020-01-12 13:43:25.417221 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #330 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0379653
Z variance train             0.0074654347
KL Divergence                26.192797
KL Loss                      2.6192796
QF Loss                      13137.426
VF Loss                      209.50589
Policy Loss                  -1420.7388
Q Predictions Mean           1423.6431
Q Predictions Std            348.4948
Q Predictions Max            1673.7007
Q Predictions Min            -198.45909
V Predictions Mean           1415.7596
V Predictions Std            348.1151
V Predictions Max            1660.6165
V Predictions Min            -194.88863
Log Pis Mean                 0.5167277
Log Pis Std                  3.0946522
Log Pis Max                  12.017632
Log Pis Min                  -6.893216
Policy mu Mean               0.02119036
Policy mu Std                0.6155859
Policy mu Max                2.1697412
Policy mu Min                -2.574014
Policy log std Mean          -1.072483
Policy log std Std           0.319471
Policy log std Max           -0.094797134
Policy log std Min           -2.4259014
Z mean eval                  1.0674376
Z variance eval              0.010041491
total_rewards                [2293.34605244 4333.47797771  586.07283323 3788.87838991 3720.03460146
 1162.535688   2088.31106372 2269.77353296  195.00721211 1952.35596565]
total_rewards_mean           2238.979331718071
total_rewards_std            1309.9636300829382
total_rewards_max            4333.477977712655
total_rewards_min            195.0072121067393
Number of train steps total  1328000
Number of env steps total    1662000
Number of rollouts total     0
Train Time (s)               112.98107811296359
(Previous) Eval Time (s)     18.580489112064242
Sample Time (s)              17.68180000409484
Epoch Time (s)               149.24336722912267
Total Train Time (s)         51259.77680780599
Epoch                        331
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:45:55.275467 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #331 | Epoch Duration: 149.85805296897888
2020-01-12 13:45:55.275745 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #331 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0684068
Z variance train             0.010020149
KL Divergence                25.993843
KL Loss                      2.5993843
QF Loss                      1298.5106
VF Loss                      908.29816
Policy Loss                  -1454.4341
Q Predictions Mean           1455.0233
Q Predictions Std            315.6083
Q Predictions Max            1686.7651
Q Predictions Min            -226.54002
V Predictions Mean           1451.9857
V Predictions Std            309.90152
V Predictions Max            1684.4867
V Predictions Min            -196.70953
Log Pis Mean                 0.9855302
Log Pis Std                  3.5331109
Log Pis Max                  13.707351
Log Pis Min                  -7.95792
Policy mu Mean               -0.016334813
Policy mu Std                0.6491966
Policy mu Max                3.3123536
Policy mu Min                -2.9046533
Policy log std Mean          -1.1299235
Policy log std Std           0.355639
Policy log std Max           0.16629755
Policy log std Min           -3.132556
Z mean eval                  1.0572124
Z variance eval              0.005906948
total_rewards                [2862.40585902  350.41108551 4133.23547567 4278.30158439  211.10689146
 4232.13194401 4132.01827966 2243.98553049 4073.65884452  434.59976564]
total_rewards_mean           2695.185526036653
total_rewards_std            1670.6744551473157
total_rewards_max            4278.30158439197
total_rewards_min            211.10689145738235
Number of train steps total  1332000
Number of env steps total    1667000
Number of rollouts total     0
Train Time (s)               121.82297118892893
(Previous) Eval Time (s)     19.194891985040158
Sample Time (s)              18.28153333067894
Epoch Time (s)               159.29939650464803
Total Train Time (s)         51417.181981374044
Epoch                        332
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:48:32.681892 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #332 | Epoch Duration: 157.40592694282532
2020-01-12 13:48:32.682044 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #332 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0568297
Z variance train             0.0059069777
KL Divergence                26.31814
KL Loss                      2.631814
QF Loss                      980.4783
VF Loss                      112.23469
Policy Loss                  -1475.486
Q Predictions Mean           1476.5709
Q Predictions Std            240.36053
Q Predictions Max            1653.8488
Q Predictions Min            -190.84274
V Predictions Mean           1474.26
V Predictions Std            240.38812
V Predictions Max            1656.8115
V Predictions Min            -195.06917
Log Pis Mean                 0.54981387
Log Pis Std                  2.8095803
Log Pis Max                  11.000893
Log Pis Min                  -9.73063
Policy mu Mean               0.001375217
Policy mu Std                0.59351325
Policy mu Max                2.4955382
Policy mu Min                -2.5769422
Policy log std Mean          -1.0970837
Policy log std Std           0.28478763
Policy log std Max           -0.1249553
Policy log std Min           -2.2490463
Z mean eval                  1.0568775
Z variance eval              0.011987977
total_rewards                [4177.01338864  118.7541266  4257.79441547 4176.08963442  355.74133087
 1177.52261725 4144.86685474 2693.72650871 1687.06310703 2194.95478465]
total_rewards_mean           2498.3526768390734
total_rewards_std            1556.458284746953
total_rewards_max            4257.794415470773
total_rewards_min            118.75412659537577
Number of train steps total  1336000
Number of env steps total    1672000
Number of rollouts total     0
Train Time (s)               115.35685965511948
(Previous) Eval Time (s)     17.301137685775757
Sample Time (s)              17.826315999031067
Epoch Time (s)               150.4843133399263
Total Train Time (s)         51567.04963179678
Epoch                        333
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:51:02.552392 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #333 | Epoch Duration: 149.8702356815338
2020-01-12 13:51:02.552541 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #333 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.056222
Z variance train             0.011987591
KL Divergence                25.150637
KL Loss                      2.5150638
QF Loss                      407.83694
VF Loss                      200.90889
Policy Loss                  -1478.971
Q Predictions Mean           1479.7042
Q Predictions Std            273.00873
Q Predictions Max            1678.1058
Q Predictions Min            -152.1459
V Predictions Mean           1488.1315
V Predictions Std            272.73505
V Predictions Max            1677.6755
V Predictions Min            -152.75691
Log Pis Mean                 1.1863557
Log Pis Std                  3.032705
Log Pis Max                  15.933605
Log Pis Min                  -6.6195574
Policy mu Mean               0.035986245
Policy mu Std                0.6787727
Policy mu Max                2.807626
Policy mu Min                -2.284989
Policy log std Mean          -1.0829574
Policy log std Std           0.32534352
Policy log std Max           -0.10389984
Policy log std Min           -3.1397085
Z mean eval                  1.1176503
Z variance eval              0.0064072893
total_rewards                [3967.905137    570.56150847 3985.51281651 3764.22486808 3976.31705773
 4007.68233124  592.75368504    6.60967831  146.2181943  3827.14142736]
total_rewards_mean           2484.4926704030613
total_rewards_std            1768.8663454972234
total_rewards_max            4007.6823312444817
total_rewards_min            6.609678310855487
Number of train steps total  1340000
Number of env steps total    1677000
Number of rollouts total     0
Train Time (s)               119.70862195268273
(Previous) Eval Time (s)     16.686752089764923
Sample Time (s)              18.012687580194324
Epoch Time (s)               154.40806162264198
Total Train Time (s)         51722.233868224546
Epoch                        334
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:53:37.739270 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #334 | Epoch Duration: 155.1866111755371
2020-01-12 13:53:37.739432 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #334 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1178253
Z variance train             0.006410538
KL Divergence                25.68404
KL Loss                      2.568404
QF Loss                      754.2141
VF Loss                      107.946915
Policy Loss                  -1464.1516
Q Predictions Mean           1466.2219
Q Predictions Std            301.4088
Q Predictions Max            1682.2953
Q Predictions Min            -194.3762
V Predictions Mean           1462.0168
V Predictions Std            297.30563
V Predictions Max            1670.1066
V Predictions Min            -170.31134
Log Pis Mean                 0.8289436
Log Pis Std                  2.9193807
Log Pis Max                  8.763123
Log Pis Min                  -8.511581
Policy mu Mean               0.03861302
Policy mu Std                0.63785124
Policy mu Max                2.3925567
Policy mu Min                -2.3159354
Policy log std Mean          -1.0862166
Policy log std Std           0.2922433
Policy log std Max           -0.25517762
Policy log std Min           -2.192935
Z mean eval                  1.0350792
Z variance eval              0.00824245
total_rewards                [3704.55567093 3896.78631079  972.6467798  3641.06857148 3998.09821982
 2506.01595947 3465.4800543  2694.86987965 3214.6539647  3183.67570809]
total_rewards_mean           3127.7851119025463
total_rewards_std            853.7138557802698
total_rewards_max            3998.0982198172132
total_rewards_min            972.6467797992419
Number of train steps total  1344000
Number of env steps total    1682000
Number of rollouts total     0
Train Time (s)               115.94446635479107
(Previous) Eval Time (s)     17.46500745927915
Sample Time (s)              18.856594090349972
Epoch Time (s)               152.2660679044202
Total Train Time (s)         51877.804156679194
Epoch                        335
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:56:13.312130 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #335 | Epoch Duration: 155.57258105278015
2020-01-12 13:56:13.312360 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #335 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0355546
Z variance train             0.008232868
KL Divergence                25.07214
KL Loss                      2.507214
QF Loss                      801.72424
VF Loss                      258.10065
Policy Loss                  -1494.3428
Q Predictions Mean           1496.3633
Q Predictions Std            241.89624
Q Predictions Max            1654.1494
Q Predictions Min            -190.2876
V Predictions Mean           1502.0193
V Predictions Std            235.77576
V Predictions Max            1654.1703
V Predictions Min            -190.28152
Log Pis Mean                 0.8796171
Log Pis Std                  2.9691734
Log Pis Max                  10.696697
Log Pis Min                  -6.240204
Policy mu Mean               0.017898995
Policy mu Std                0.64073485
Policy mu Max                2.8101966
Policy mu Min                -2.707098
Policy log std Mean          -1.0862436
Policy log std Std           0.30072907
Policy log std Max           0.65620565
Policy log std Min           -2.3463945
Z mean eval                  1.0631802
Z variance eval              0.007460051
total_rewards                [4196.32954799 4067.48704577 4138.16167118  776.37356826 3241.4407789
 3644.33846271 2545.77685638 1642.35596208 3843.34581637 4151.19593211]
total_rewards_mean           3224.6805641749443
total_rewards_std            1134.2535810397703
total_rewards_max            4196.329547990895
total_rewards_min            776.3735682618412
Number of train steps total  1348000
Number of env steps total    1687000
Number of rollouts total     0
Train Time (s)               118.36848362302408
(Previous) Eval Time (s)     20.7711659129709
Sample Time (s)              17.93355866568163
Epoch Time (s)               157.0732082016766
Total Train Time (s)         52036.002413520124
Epoch                        336
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:58:51.512991 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #336 | Epoch Duration: 158.20049667358398
2020-01-12 13:58:51.513150 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #336 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0623025
Z variance train             0.007470046
KL Divergence                24.507244
KL Loss                      2.4507244
QF Loss                      1155.3335
VF Loss                      191.9756
Policy Loss                  -1533.3115
Q Predictions Mean           1532.0352
Q Predictions Std            181.65009
Q Predictions Max            1690.7961
Q Predictions Min            -201.87253
V Predictions Mean           1526.0444
V Predictions Std            168.90952
V Predictions Max            1690.5106
V Predictions Min            -202.29259
Log Pis Mean                 0.83218384
Log Pis Std                  2.9231372
Log Pis Max                  12.137917
Log Pis Min                  -8.074778
Policy mu Mean               0.0430056
Policy mu Std                0.6187203
Policy mu Max                2.440355
Policy mu Min                -3.633185
Policy log std Mean          -1.1160148
Policy log std Std           0.27622005
Policy log std Max           0.52988815
Policy log std Min           -2.287272
Z mean eval                  1.0525306
Z variance eval              0.013109768
total_rewards                [4213.43309497 3827.8441848  1842.445251     43.46001056 1430.17502564
 4331.34366487 4366.97197121 4138.68802615 3963.60355502 1317.33616254]
total_rewards_mean           2947.530094676866
total_rewards_std            1528.830116885313
total_rewards_max            4366.971971212254
total_rewards_min            43.460010564293164
Number of train steps total  1352000
Number of env steps total    1692000
Number of rollouts total     0
Train Time (s)               119.25793099822477
(Previous) Eval Time (s)     21.898134709335864
Sample Time (s)              18.431654798798263
Epoch Time (s)               159.5877205063589
Total Train Time (s)         52192.634315794334
Epoch                        337
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:01:28.148090 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #337 | Epoch Duration: 156.63480496406555
2020-01-12 14:01:28.148310 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #337 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0519171
Z variance train             0.013082561
KL Divergence                23.998352
KL Loss                      2.3998353
QF Loss                      1660.0448
VF Loss                      255.54028
Policy Loss                  -1515.589
Q Predictions Mean           1515.0461
Q Predictions Std            221.7404
Q Predictions Max            1707.8777
Q Predictions Min            -161.37526
V Predictions Mean           1514.3324
V Predictions Std            224.29514
V Predictions Max            1704.1963
V Predictions Min            -162.60768
Log Pis Mean                 0.9973175
Log Pis Std                  3.3697784
Log Pis Max                  17.85407
Log Pis Min                  -8.262063
Policy mu Mean               -0.015100033
Policy mu Std                0.63159686
Policy mu Max                3.6179805
Policy mu Min                -2.4014835
Policy log std Mean          -1.1358694
Policy log std Std           0.31858116
Policy log std Max           -0.19436681
Policy log std Min           -3.3418882
Z mean eval                  1.0339286
Z variance eval              0.015499502
total_rewards                [  99.19269539 2572.62479618   14.86257044 4243.69215405 1238.57770852
 3029.71743513 4005.93738013 4181.1010955  2883.44930015 4086.09902258]
total_rewards_mean           2635.5254158071166
total_rewards_std            1563.0203960090384
total_rewards_max            4243.6921540533085
total_rewards_min            14.862570437402042
Number of train steps total  1356000
Number of env steps total    1697000
Number of rollouts total     0
Train Time (s)               118.51443095272407
(Previous) Eval Time (s)     18.944892628118396
Sample Time (s)              18.165808414574713
Epoch Time (s)               155.62513199541718
Total Train Time (s)         52350.89604555676
Epoch                        338
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:04:06.414099 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #338 | Epoch Duration: 158.26564717292786
2020-01-12 14:04:06.414336 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #338 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0327758
Z variance train             0.015480092
KL Divergence                22.210754
KL Loss                      2.2210755
QF Loss                      1354.24
VF Loss                      777.17883
Policy Loss                  -1466.1083
Q Predictions Mean           1472.2522
Q Predictions Std            335.98953
Q Predictions Max            1708.8108
Q Predictions Min            -248.48857
V Predictions Mean           1465.3322
V Predictions Std            334.18152
V Predictions Max            1704.1562
V Predictions Min            -203.4317
Log Pis Mean                 0.95730025
Log Pis Std                  3.2423956
Log Pis Max                  15.355839
Log Pis Min                  -8.779065
Policy mu Mean               0.044558436
Policy mu Std                0.6093397
Policy mu Max                2.5766068
Policy mu Min                -2.3901327
Policy log std Mean          -1.1291741
Policy log std Std           0.35310057
Policy log std Max           -0.16105539
Policy log std Min           -3.2802095
Z mean eval                  1.0474526
Z variance eval              0.012745341
total_rewards                [2255.23909786 1186.89883238 4235.65861394 3973.38497524 2307.23216136
 4218.26165688  413.76900501 4080.75759467 4136.3866669   186.19358265]
total_rewards_mean           2699.3782186885137
total_rewards_std            1563.4000864602037
total_rewards_max            4235.65861393834
total_rewards_min            186.19358264901967
Number of train steps total  1360000
Number of env steps total    1702000
Number of rollouts total     0
Train Time (s)               120.0694967689924
(Previous) Eval Time (s)     21.585087204817683
Sample Time (s)              19.120828825980425
Epoch Time (s)               160.7754127997905
Total Train Time (s)         52510.41995801544
Epoch                        339
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:06:45.940965 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #339 | Epoch Duration: 159.526460647583
2020-01-12 14:06:45.941159 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #339 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0482793
Z variance train             0.012730768
KL Divergence                22.59476
KL Loss                      2.2594762
QF Loss                      665.12036
VF Loss                      151.6111
Policy Loss                  -1470.911
Q Predictions Mean           1468.8445
Q Predictions Std            319.90277
Q Predictions Max            1696.5885
Q Predictions Min            -257.0467
V Predictions Mean           1468.5066
V Predictions Std            306.00992
V Predictions Max            1697.5026
V Predictions Min            -228.959
Log Pis Mean                 0.94314265
Log Pis Std                  3.360916
Log Pis Max                  15.800606
Log Pis Min                  -6.642144
Policy mu Mean               0.012828128
Policy mu Std                0.6178942
Policy mu Max                2.5451837
Policy mu Min                -2.2474568
Policy log std Mean          -1.1130774
Policy log std Std           0.353582
Policy log std Max           0.68825126
Policy log std Min           -3.4301028
Z mean eval                  1.0604022
Z variance eval              0.012534077
total_rewards                [3959.65518201 4171.21080228 4290.77985546 4238.68065886  454.48787989
 4016.20592579 1594.56041074 3973.58505491 4054.92148635 4160.72921809]
total_rewards_mean           3491.4816474388963
total_rewards_std            1263.8496555937872
total_rewards_max            4290.779855457766
total_rewards_min            454.48787989339365
Number of train steps total  1364000
Number of env steps total    1707000
Number of rollouts total     0
Train Time (s)               122.74241706263274
(Previous) Eval Time (s)     20.335787604097277
Sample Time (s)              18.214180403854698
Epoch Time (s)               161.29238507058471
Total Train Time (s)         52674.4018739732
Epoch                        340
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:09:29.930257 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #340 | Epoch Duration: 163.98895621299744
2020-01-12 14:09:29.930503 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #340 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0604168
Z variance train             0.012520872
KL Divergence                22.753296
KL Loss                      2.2753296
QF Loss                      1267.0331
VF Loss                      372.27448
Policy Loss                  -1446.2936
Q Predictions Mean           1447.7584
Q Predictions Std            325.3026
Q Predictions Max            1671.1624
Q Predictions Min            -180.31363
V Predictions Mean           1444.8159
V Predictions Std            331.01733
V Predictions Max            1669.0221
V Predictions Min            -214.58171
Log Pis Mean                 0.9086271
Log Pis Std                  3.122927
Log Pis Max                  11.357733
Log Pis Min                  -7.9788423
Policy mu Mean               -0.025221474
Policy mu Std                0.6110938
Policy mu Max                3.0350165
Policy mu Min                -2.1622293
Policy log std Mean          -1.1415787
Policy log std Std           0.33527347
Policy log std Max           -0.09319413
Policy log std Min           -2.711282
Z mean eval                  1.0315721
Z variance eval              0.015520367
total_rewards                [  99.85360132 1797.969561   4041.09678207 4245.21260308 4363.97068802
 1414.59200146 1080.34953228 1677.45887862 4361.80705894 4116.14430108]
total_rewards_mean           2719.8455007869743
total_rewards_std            1568.87545313309
total_rewards_max            4363.970688021366
total_rewards_min            99.85360132001077
Number of train steps total  1368000
Number of env steps total    1712000
Number of rollouts total     0
Train Time (s)               113.46529340092093
(Previous) Eval Time (s)     23.032048251945525
Sample Time (s)              18.00174402166158
Epoch Time (s)               154.49908567452803
Total Train Time (s)         52827.10096296994
Epoch                        341
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:12:02.632517 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #341 | Epoch Duration: 152.7018117904663
2020-01-12 14:12:02.632801 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #341 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0321114
Z variance train             0.015502399
KL Divergence                22.910007
KL Loss                      2.2910008
QF Loss                      786.411
VF Loss                      385.52026
Policy Loss                  -1508.2675
Q Predictions Mean           1511.8558
Q Predictions Std            254.94775
Q Predictions Max            1692.7218
Q Predictions Min            -208.10652
V Predictions Mean           1505.6512
V Predictions Std            256.23398
V Predictions Max            1680.1599
V Predictions Min            -212.02791
Log Pis Mean                 1.1101079
Log Pis Std                  2.9434462
Log Pis Max                  13.084536
Log Pis Min                  -6.584796
Policy mu Mean               -0.014930977
Policy mu Std                0.64562064
Policy mu Max                2.6898382
Policy mu Min                -2.408952
Policy log std Mean          -1.1182897
Policy log std Std           0.3139411
Policy log std Max           -0.1649661
Policy log std Min           -2.7452102
Z mean eval                  1.0377126
Z variance eval              0.010062032
total_rewards                [4109.49892719 3916.47000888 1539.459789   1784.88420666 4109.2323003
 2995.76647227 3821.84131804 3864.91122496 4145.48967003 4358.14814704]
total_rewards_mean           3464.570206437112
total_rewards_std            966.0722669668822
total_rewards_max            4358.148147041953
total_rewards_min            1539.4597890029563
Number of train steps total  1372000
Number of env steps total    1717000
Number of rollouts total     0
Train Time (s)               120.58718446502462
(Previous) Eval Time (s)     21.234453641809523
Sample Time (s)              18.066956422757357
Epoch Time (s)               159.8885945295915
Total Train Time (s)         52989.26241860166
Epoch                        342
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:14:44.796464 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #342 | Epoch Duration: 162.16347289085388
2020-01-12 14:14:44.796649 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #342 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0374786
Z variance train             0.010077165
KL Divergence                23.533485
KL Loss                      2.3533485
QF Loss                      500.75476
VF Loss                      274.49316
Policy Loss                  -1484.4617
Q Predictions Mean           1485.2303
Q Predictions Std            318.28455
Q Predictions Max            1679.3375
Q Predictions Min            -212.79506
V Predictions Mean           1484.9569
V Predictions Std            316.2769
V Predictions Max            1673.2874
V Predictions Min            -215.34451
Log Pis Mean                 0.6820419
Log Pis Std                  2.986522
Log Pis Max                  14.33244
Log Pis Min                  -6.431397
Policy mu Mean               0.02451307
Policy mu Std                0.611952
Policy mu Max                2.657205
Policy mu Min                -2.4139407
Policy log std Mean          -1.0918013
Policy log std Std           0.31943393
Policy log std Max           -0.059429884
Policy log std Min           -2.981701
Z mean eval                  1.0500332
Z variance eval              0.011535464
total_rewards                [4009.20720593 4248.52699672 1589.76804457    6.18005673 4049.55122592
 3060.50865302  651.16786411 2801.21128347 1727.26246282 3996.90245561]
total_rewards_mean           2614.0286248914313
total_rewards_std            1459.9560136081654
total_rewards_max            4248.526996724118
total_rewards_min            6.180056731736402
Number of train steps total  1376000
Number of env steps total    1722000
Number of rollouts total     0
Train Time (s)               117.97778301499784
(Previous) Eval Time (s)     23.50904242368415
Sample Time (s)              18.002558194566518
Epoch Time (s)               159.4893836332485
Total Train Time (s)         53144.02387744142
Epoch                        343
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:17:19.560793 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #343 | Epoch Duration: 154.764004945755
2020-01-12 14:17:19.560974 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #343 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0481192
Z variance train             0.011562342
KL Divergence                22.540604
KL Loss                      2.2540605
QF Loss                      901.67786
VF Loss                      449.40277
Policy Loss                  -1479.9718
Q Predictions Mean           1481.2952
Q Predictions Std            336.56665
Q Predictions Max            1704.4989
Q Predictions Min            -231.41907
V Predictions Mean           1480.1111
V Predictions Std            333.85098
V Predictions Max            1694.3884
V Predictions Min            -210.22112
Log Pis Mean                 0.9789755
Log Pis Std                  3.544793
Log Pis Max                  12.908457
Log Pis Min                  -7.208253
Policy mu Mean               0.014608458
Policy mu Std                0.6344188
Policy mu Max                3.1678257
Policy mu Min                -2.3732297
Policy log std Mean          -1.1013377
Policy log std Std           0.3150336
Policy log std Max           -0.19065142
Policy log std Min           -2.8641996
Z mean eval                  1.0617259
Z variance eval              0.0142240655
total_rewards                [4500.99135575 4599.74839111 4254.20637003   14.86998049 4425.64933085
 4208.00829279 4393.14659376 4398.45651085 4334.63545525  250.18909014]
total_rewards_mean           3537.9901371017827
total_rewards_std            1706.8356943056244
total_rewards_max            4599.748391109493
total_rewards_min            14.86998048751655
Number of train steps total  1380000
Number of env steps total    1727000
Number of rollouts total     0
Train Time (s)               119.58324195398018
(Previous) Eval Time (s)     18.78337150393054
Sample Time (s)              18.32956916000694
Epoch Time (s)               156.69618261791766
Total Train Time (s)         53303.777776652016
Epoch                        344
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:19:59.318979 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #344 | Epoch Duration: 159.75785970687866
2020-01-12 14:19:59.319192 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #344 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0633256
Z variance train             0.014249407
KL Divergence                23.202599
KL Loss                      2.3202598
QF Loss                      626.15076
VF Loss                      296.5772
Policy Loss                  -1489.8154
Q Predictions Mean           1490.3018
Q Predictions Std            362.45807
Q Predictions Max            1726.139
Q Predictions Min            -217.97113
V Predictions Mean           1481.9941
V Predictions Std            362.51642
V Predictions Max            1710.59
V Predictions Min            -229.24304
Log Pis Mean                 1.0049257
Log Pis Std                  3.2293293
Log Pis Max                  14.634108
Log Pis Min                  -7.2862463
Policy mu Mean               -0.004625637
Policy mu Std                0.62112784
Policy mu Max                2.5475984
Policy mu Min                -2.859194
Policy log std Mean          -1.1228387
Policy log std Std           0.33314097
Policy log std Max           -0.091225624
Policy log std Min           -2.7077298
Z mean eval                  1.0766586
Z variance eval              0.008805916
total_rewards                [  39.85477068 4258.87953346 4248.81828999 4063.13169834 1252.65358734
 4270.22458447 4226.14024425 1885.09479058 4210.86462351 4174.53004875]
total_rewards_mean           3263.019217136979
total_rewards_std            1503.4653298059495
total_rewards_max            4270.224584472316
total_rewards_min            39.85477068396771
Number of train steps total  1384000
Number of env steps total    1732000
Number of rollouts total     0
Train Time (s)               120.37697226693854
(Previous) Eval Time (s)     21.844680842012167
Sample Time (s)              17.852587962988764
Epoch Time (s)               160.07424107193947
Total Train Time (s)         53463.020809071604
Epoch                        345
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:22:38.565041 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #345 | Epoch Duration: 159.2456865310669
2020-01-12 14:22:38.565245 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #345 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0763862
Z variance train             0.00879805
KL Divergence                23.614428
KL Loss                      2.3614428
QF Loss                      15292.397
VF Loss                      122.00166
Policy Loss                  -1479.362
Q Predictions Mean           1482.3042
Q Predictions Std            300.8367
Q Predictions Max            1692.4832
Q Predictions Min            -277.19922
V Predictions Mean           1481.1691
V Predictions Std            303.16827
V Predictions Max            1681.5092
V Predictions Min            -292.633
Log Pis Mean                 0.98055726
Log Pis Std                  3.0762417
Log Pis Max                  14.344503
Log Pis Min                  -7.0181646
Policy mu Mean               0.058779743
Policy mu Std                0.60147196
Policy mu Max                2.5514863
Policy mu Min                -2.28804
Policy log std Mean          -1.1532123
Policy log std Std           0.30093893
Policy log std Max           -0.014220595
Policy log std Min           -2.4819698
Z mean eval                  1.0632644
Z variance eval              0.016266
total_rewards                [ 483.78187976   16.72210199 2708.17154641   62.03493219 3006.43894867
 3993.41687753 3058.20750592 4279.08901742  271.12750572 3162.30002168]
total_rewards_mean           2104.1290337293603
total_rewards_std            1613.1248283136504
total_rewards_max            4279.089017419241
total_rewards_min            16.722101992567993
Number of train steps total  1388000
Number of env steps total    1737000
Number of rollouts total     0
Train Time (s)               112.40312290936708
(Previous) Eval Time (s)     21.015802084933966
Sample Time (s)              18.07491726242006
Epoch Time (s)               151.4938422567211
Total Train Time (s)         53609.22886122018
Epoch                        346
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:25:04.776158 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #346 | Epoch Duration: 146.210768699646
2020-01-12 14:25:04.776356 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #346 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0637431
Z variance train             0.016327072
KL Divergence                22.57943
KL Loss                      2.257943
QF Loss                      798.2937
VF Loss                      219.02628
Policy Loss                  -1545.7855
Q Predictions Mean           1547.258
Q Predictions Std            206.62546
Q Predictions Max            1736.3341
Q Predictions Min            -234.2109
V Predictions Mean           1542.7505
V Predictions Std            206.58586
V Predictions Max            1740.752
V Predictions Min            -230.37991
Log Pis Mean                 1.3418655
Log Pis Std                  3.1393607
Log Pis Max                  13.9116125
Log Pis Min                  -5.9633675
Policy mu Mean               -0.025629668
Policy mu Std                0.6499754
Policy mu Max                2.5001636
Policy mu Min                -2.5915868
Policy log std Mean          -1.1201514
Policy log std Std           0.3165522
Policy log std Max           -0.15102535
Policy log std Min           -2.5608697
Z mean eval                  1.0510075
Z variance eval              0.013625188
total_rewards                [4.00181151e+03 5.27436179e+02 4.19228423e+03 3.11718998e+03
 4.46262770e+03 4.35941530e+03 2.43577184e+03 5.81718130e+02
 1.91633594e+00 5.59225343e+02]
total_rewards_mean           2423.939654397491
total_rewards_std            1741.6553922616397
total_rewards_max            4462.627700962459
total_rewards_min            1.9163359368588075
Number of train steps total  1392000
Number of env steps total    1742000
Number of rollouts total     0
Train Time (s)               119.59228290524334
(Previous) Eval Time (s)     15.732424120884389
Sample Time (s)              17.708946786355227
Epoch Time (s)               153.03365381248295
Total Train Time (s)         53765.328707887325
Epoch                        347
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:27:40.884624 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #347 | Epoch Duration: 156.1080994606018
2020-01-12 14:27:40.884923 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #347 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0497007
Z variance train             0.013629049
KL Divergence                23.613075
KL Loss                      2.3613076
QF Loss                      8679.98
VF Loss                      187.56491
Policy Loss                  -1484.7148
Q Predictions Mean           1485.6898
Q Predictions Std            333.13284
Q Predictions Max            1675.8357
Q Predictions Min            -196.28416
V Predictions Mean           1487.3171
V Predictions Std            326.67175
V Predictions Max            1676.3622
V Predictions Min            -246.80194
Log Pis Mean                 0.6742377
Log Pis Std                  2.7909458
Log Pis Max                  9.8848505
Log Pis Min                  -6.3074894
Policy mu Mean               0.007271134
Policy mu Std                0.63722146
Policy mu Max                2.457629
Policy mu Min                -2.291869
Policy log std Mean          -1.0770487
Policy log std Std           0.31871676
Policy log std Max           -0.008796334
Policy log std Min           -2.8418999
Z mean eval                  1.0662456
Z variance eval              0.011588983
total_rewards                [4131.48616504  810.19332413 4484.83640728 4549.03095675 4342.27941979
 3096.49324693 4300.0737373  4306.56371992 3400.84448406 4057.11710124]
total_rewards_mean           3747.891856244717
total_rewards_std            1075.770715562127
total_rewards_max            4549.030956746656
total_rewards_min            810.1933241316389
Number of train steps total  1396000
Number of env steps total    1747000
Number of rollouts total     0
Train Time (s)               121.4432799750939
(Previous) Eval Time (s)     18.806586671154946
Sample Time (s)              17.906171906273812
Epoch Time (s)               158.15603855252266
Total Train Time (s)         53928.319843992125
Epoch                        348
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:30:23.879233 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #348 | Epoch Duration: 162.9940643310547
2020-01-12 14:30:23.879482 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #348 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.068173
Z variance train             0.011560078
KL Divergence                23.70444
KL Loss                      2.370444
QF Loss                      787.05597
VF Loss                      291.9856
Policy Loss                  -1508.2983
Q Predictions Mean           1508.1809
Q Predictions Std            318.74146
Q Predictions Max            1726.292
Q Predictions Min            -227.50555
V Predictions Mean           1509.0413
V Predictions Std            306.6215
V Predictions Max            1712.8887
V Predictions Min            -242.85284
Log Pis Mean                 1.2296383
Log Pis Std                  3.2692175
Log Pis Max                  16.470573
Log Pis Min                  -6.3874016
Policy mu Mean               -0.012720296
Policy mu Std                0.6462663
Policy mu Max                2.7879837
Policy mu Min                -2.4595346
Policy log std Mean          -1.1197939
Policy log std Std           0.3223631
Policy log std Max           0.083907604
Policy log std Min           -2.8287308
Z mean eval                  1.0232046
Z variance eval              0.013351159
total_rewards                [1969.61859785 4196.7860677  1631.54049913 4064.58201522 4020.10734756
  645.16979946 3101.50147844 1997.90792505 -258.88195366  593.99737245]
total_rewards_mean           2196.232914918967
total_rewards_std            1518.1923234629055
total_rewards_max            4196.786067698149
total_rewards_min            -258.8819536645245
Number of train steps total  1400000
Number of env steps total    1752000
Number of rollouts total     0
Train Time (s)               118.22463781572878
(Previous) Eval Time (s)     23.64424018887803
Sample Time (s)              18.066773635800928
Epoch Time (s)               159.93565164040774
Total Train Time (s)         54085.88464062754
Epoch                        349
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:33:01.451141 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #349 | Epoch Duration: 157.5714602470398
2020-01-12 14:33:01.451446 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #349 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0225726
Z variance train             0.013309136
KL Divergence                23.943853
KL Loss                      2.3943853
QF Loss                      918.394
VF Loss                      531.6078
Policy Loss                  -1509.1373
Q Predictions Mean           1513.8108
Q Predictions Std            328.66736
Q Predictions Max            1724.9354
Q Predictions Min            -306.43823
V Predictions Mean           1512.6931
V Predictions Std            326.51584
V Predictions Max            1727.1934
V Predictions Min            -278.14243
Log Pis Mean                 1.1025648
Log Pis Std                  3.0058627
Log Pis Max                  15.388275
Log Pis Min                  -11.971262
Policy mu Mean               0.018203713
Policy mu Std                0.6681742
Policy mu Max                2.692581
Policy mu Min                -2.333935
Policy log std Mean          -1.0939478
Policy log std Std           0.31974387
Policy log std Max           0.13002968
Policy log std Min           -3.2966695
Z mean eval                  1.0835383
Z variance eval              0.016489254
total_rewards                [4049.9552539  3971.41481316 4230.13032887  585.85561223 4508.32857057
 4228.93326113  640.23325088  175.1269068  2379.73190515 4085.54712101]
total_rewards_mean           2885.5257023719064
total_rewards_std            1677.8917449801002
total_rewards_max            4508.32857057212
total_rewards_min            175.12690680090634
Number of train steps total  1404000
Number of env steps total    1757000
Number of rollouts total     0
Train Time (s)               116.48208726989105
(Previous) Eval Time (s)     21.279737938195467
Sample Time (s)              18.277780676726252
Epoch Time (s)               156.03960588481277
Total Train Time (s)         54240.39461294236
Epoch                        350
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:35:35.965858 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #350 | Epoch Duration: 154.5141739845276
2020-01-12 14:35:35.966163 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #350 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0833067
Z variance train             0.016496813
KL Divergence                23.056366
KL Loss                      2.3056366
QF Loss                      1044.2587
VF Loss                      186.15863
Policy Loss                  -1495.1122
Q Predictions Mean           1495.1003
Q Predictions Std            305.36548
Q Predictions Max            1727.7264
Q Predictions Min            -276.53674
V Predictions Mean           1492.4321
V Predictions Std            299.57376
V Predictions Max            1726.1128
V Predictions Min            -251.95346
Log Pis Mean                 1.0876861
Log Pis Std                  3.0473313
Log Pis Max                  16.799608
Log Pis Min                  -7.171662
Policy mu Mean               0.030163733
Policy mu Std                0.67470944
Policy mu Max                3.5216877
Policy mu Min                -2.8003716
Policy log std Mean          -1.0887684
Policy log std Std           0.28035375
Policy log std Max           -0.1621095
Policy log std Min           -2.3232296
Z mean eval                  1.0653232
Z variance eval              0.009727676
total_rewards                [3858.07507451 4315.80477152 4199.46474478 2623.08854658 4184.13808305
 4329.92599221 1489.08159175 4316.84225124 3157.49450599 4141.56905132]
total_rewards_mean           3661.5484612936825
total_rewards_std            904.8628512321901
total_rewards_max            4329.925992206682
total_rewards_min            1489.0815917450545
Number of train steps total  1408000
Number of env steps total    1762000
Number of rollouts total     0
Train Time (s)               121.77035109512508
(Previous) Eval Time (s)     19.75390904676169
Sample Time (s)              18.165549621917307
Epoch Time (s)               159.68980976380408
Total Train Time (s)         54403.958087549545
Epoch                        351
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:38:19.532515 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #351 | Epoch Duration: 163.56612825393677
2020-01-12 14:38:19.532715 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #351 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0663066
Z variance train             0.009739602
KL Divergence                23.525007
KL Loss                      2.3525007
QF Loss                      913.00946
VF Loss                      117.5039
Policy Loss                  -1528.9778
Q Predictions Mean           1532.0521
Q Predictions Std            237.10457
Q Predictions Max            1719.57
Q Predictions Min            -175.69348
V Predictions Mean           1528.403
V Predictions Std            238.44612
V Predictions Max            1711.7467
V Predictions Min            -177.97702
Log Pis Mean                 0.9088644
Log Pis Std                  2.8309436
Log Pis Max                  11.371585
Log Pis Min                  -6.417345
Policy mu Mean               0.033662617
Policy mu Std                0.6391864
Policy mu Max                2.226846
Policy mu Min                -2.2048333
Policy log std Mean          -1.1080583
Policy log std Std           0.27705473
Policy log std Max           -0.25589693
Policy log std Min           -2.3591568
Z mean eval                  1.0425501
Z variance eval              0.010616588
total_rewards                [3930.95781526 4252.18963889 2945.36184296 2887.04256395 2446.86154504
 4327.40316306 4149.97261224 4428.1183956  4257.55359226 4054.12390366]
total_rewards_mean           3767.9585072927075
total_rewards_std            683.764731247324
total_rewards_max            4428.118395602586
total_rewards_min            2446.861545039168
Number of train steps total  1412000
Number of env steps total    1767000
Number of rollouts total     0
Train Time (s)               116.2414594842121
(Previous) Eval Time (s)     23.629901375621557
Sample Time (s)              17.524326804559678
Epoch Time (s)               157.39568766439334
Total Train Time (s)         54561.80978182098
Epoch                        352
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:40:57.393609 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #352 | Epoch Duration: 157.86071276664734
2020-01-12 14:40:57.393896 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #352 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0455365
Z variance train             0.01063408
KL Divergence                23.310295
KL Loss                      2.3310297
QF Loss                      648.83496
VF Loss                      210.05977
Policy Loss                  -1524.3853
Q Predictions Mean           1524.3273
Q Predictions Std            320.1158
Q Predictions Max            1728.4578
Q Predictions Min            -274.95758
V Predictions Mean           1521.1006
V Predictions Std            319.50412
V Predictions Max            1725.3616
V Predictions Min            -235.5945
Log Pis Mean                 1.3200867
Log Pis Std                  2.9454303
Log Pis Max                  11.862413
Log Pis Min                  -5.0264525
Policy mu Mean               0.0025911885
Policy mu Std                0.6553987
Policy mu Max                2.6324577
Policy mu Min                -2.0677028
Policy log std Mean          -1.1084898
Policy log std Std           0.30472377
Policy log std Max           -0.04022169
Policy log std Min           -2.7954714
Z mean eval                  1.0661838
Z variance eval              0.009324169
total_rewards                [4083.78990142 4320.17121311 1102.96051163 4158.76002333 1032.68747233
 4402.96340512 4122.14689755 3926.70294659 4218.23182674 1383.75313012]
total_rewards_mean           3275.2167327943307
total_rewards_std            1383.9961463452394
total_rewards_max            4402.963405121783
total_rewards_min            1032.6874723268083
Number of train steps total  1416000
Number of env steps total    1772000
Number of rollouts total     0
Train Time (s)               122.08364244084805
(Previous) Eval Time (s)     24.094610164873302
Sample Time (s)              18.04518860206008
Epoch Time (s)               164.22344120778143
Total Train Time (s)         54722.80552456668
Epoch                        353
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:43:38.387935 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #353 | Epoch Duration: 160.99384546279907
2020-01-12 14:43:38.388100 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #353 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0647037
Z variance train             0.009328045
KL Divergence                22.961615
KL Loss                      2.2961614
QF Loss                      821.6565
VF Loss                      384.60068
Policy Loss                  -1551.6652
Q Predictions Mean           1553.9828
Q Predictions Std            248.15726
Q Predictions Max            1742.4822
Q Predictions Min            -207.58307
V Predictions Mean           1541.9053
V Predictions Std            243.76488
V Predictions Max            1726.3849
V Predictions Min            -199.96309
Log Pis Mean                 1.0921445
Log Pis Std                  3.1501396
Log Pis Max                  10.478802
Log Pis Min                  -5.9517865
Policy mu Mean               -0.010758273
Policy mu Std                0.64017797
Policy mu Max                2.4077582
Policy mu Min                -2.4708657
Policy log std Mean          -1.1284783
Policy log std Std           0.33211535
Policy log std Max           -0.12706745
Policy log std Min           -2.9805908
Z mean eval                  1.1039323
Z variance eval              0.0091182375
total_rewards                [ 602.72146674 4216.75707494 3566.47728218 4195.25163368  454.79216571
 4377.05790985 4062.59249181 2413.35703303 4248.47371939 4332.75982717]
total_rewards_mean           3247.024060449986
total_rewards_std            1467.9685223512251
total_rewards_max            4377.057909845538
total_rewards_min            454.7921657128186
Number of train steps total  1420000
Number of env steps total    1777000
Number of rollouts total     0
Train Time (s)               124.03540794597939
(Previous) Eval Time (s)     20.8647438515909
Sample Time (s)              18.20485270069912
Epoch Time (s)               163.1050044982694
Total Train Time (s)         54885.84993909625
Epoch                        354
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:46:21.437479 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #354 | Epoch Duration: 163.0492386817932
2020-01-12 14:46:21.437721 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #354 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.105384
Z variance train             0.009116506
KL Divergence                23.393707
KL Loss                      2.3393707
QF Loss                      2279.837
VF Loss                      780.6069
Policy Loss                  -1502.0256
Q Predictions Mean           1504.8944
Q Predictions Std            387.02774
Q Predictions Max            1773.4111
Q Predictions Min            -268.43005
V Predictions Mean           1494.3246
V Predictions Std            382.27335
V Predictions Max            1741.3523
V Predictions Min            -249.6335
Log Pis Mean                 1.02015
Log Pis Std                  3.5708082
Log Pis Max                  18.108469
Log Pis Min                  -6.9286556
Policy mu Mean               0.0080489125
Policy mu Std                0.6211067
Policy mu Max                1.9375014
Policy mu Min                -2.3827715
Policy log std Mean          -1.1244304
Policy log std Std           0.38231748
Policy log std Max           -0.16261935
Policy log std Min           -3.2486854
Z mean eval                  1.095711
Z variance eval              0.0135781765
total_rewards                [2923.2710607  1041.08150393 4072.39148428 1616.59282436 3000.03005686
 4197.66601203 1175.79738725 1341.27604975 3031.17300541 1662.08796298]
total_rewards_mean           2406.1367347558576
total_rewards_std            1126.2689156378315
total_rewards_max            4197.6660120299775
total_rewards_min            1041.0815039311315
Number of train steps total  1424000
Number of env steps total    1782000
Number of rollouts total     0
Train Time (s)               120.01379963941872
(Previous) Eval Time (s)     20.80865011923015
Sample Time (s)              19.760763069149107
Epoch Time (s)               160.58321282779798
Total Train Time (s)         55042.97461357573
Epoch                        355
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:48:58.564970 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #355 | Epoch Duration: 157.12707901000977
2020-01-12 14:48:58.565186 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #355 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0939562
Z variance train             0.013574878
KL Divergence                22.713697
KL Loss                      2.2713697
QF Loss                      1210.5657
VF Loss                      348.3996
Policy Loss                  -1553.1349
Q Predictions Mean           1552.9426
Q Predictions Std            229.51704
Q Predictions Max            1726.1968
Q Predictions Min            -301.505
V Predictions Mean           1549.5945
V Predictions Std            227.21983
V Predictions Max            1713.356
V Predictions Min            -269.74976
Log Pis Mean                 0.88293666
Log Pis Std                  3.2385917
Log Pis Max                  11.869139
Log Pis Min                  -7.3295116
Policy mu Mean               0.04642585
Policy mu Std                0.6143987
Policy mu Max                2.9216259
Policy mu Min                -2.744815
Policy log std Mean          -1.1099887
Policy log std Std           0.32395184
Policy log std Max           -0.105793715
Policy log std Min           -2.91692
Z mean eval                  1.0986854
Z variance eval              0.017226893
total_rewards                [4059.95356007 4263.04337155 4210.76719782 4178.31703677 4228.33917478
 4041.40985114 4279.93495193 4281.91692985 4052.22448968 4290.89943913]
total_rewards_mean           4188.680600271369
total_rewards_std            95.94086769341507
total_rewards_max            4290.899439126788
total_rewards_min            4041.4098511409784
Number of train steps total  1428000
Number of env steps total    1787000
Number of rollouts total     0
Train Time (s)               115.63263139408082
(Previous) Eval Time (s)     17.352182801812887
Sample Time (s)              18.178490239195526
Epoch Time (s)               151.16330443508923
Total Train Time (s)         55204.084596083034
Epoch                        356
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:51:39.680597 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #356 | Epoch Duration: 161.11526036262512
2020-01-12 14:51:39.680844 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #356 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0992688
Z variance train             0.017218743
KL Divergence                22.324892
KL Loss                      2.2324893
QF Loss                      701.9514
VF Loss                      94.22113
Policy Loss                  -1543.5482
Q Predictions Mean           1542.7527
Q Predictions Std            306.3494
Q Predictions Max            1746.5887
Q Predictions Min            -242.08554
V Predictions Mean           1546.0532
V Predictions Std            299.90045
V Predictions Max            1729.1144
V Predictions Min            -253.47073
Log Pis Mean                 1.6579474
Log Pis Std                  3.1323643
Log Pis Max                  15.482395
Log Pis Min                  -5.7166324
Policy mu Mean               -0.0042150556
Policy mu Std                0.6678194
Policy mu Max                2.580642
Policy mu Min                -2.7820985
Policy log std Mean          -1.141763
Policy log std Std           0.3179838
Policy log std Max           -0.007258415
Policy log std Min           -3.1000376
Z mean eval                  1.0814264
Z variance eval              0.011380384
total_rewards                [3226.24785912 1017.91052196 4270.35058313 4220.54361605 4143.78521856
 3875.46681857 4128.46468975 4151.84797899 4171.42542941 2909.01025597]
total_rewards_mean           3611.5052971506607
total_rewards_std            969.5043373055922
total_rewards_max            4270.350583125276
total_rewards_min            1017.9105219559624
Number of train steps total  1432000
Number of env steps total    1792000
Number of rollouts total     0
Train Time (s)               123.22578377462924
(Previous) Eval Time (s)     27.303785531781614
Sample Time (s)              17.614705296698958
Epoch Time (s)               168.1442746031098
Total Train Time (s)         55369.16367039969
Epoch                        357
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:54:24.779336 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #357 | Epoch Duration: 165.09828639030457
2020-01-12 14:54:24.779600 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #357 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0800457
Z variance train             0.01139578
KL Divergence                22.521187
KL Loss                      2.2521188
QF Loss                      1317.299
VF Loss                      740.0603
Policy Loss                  -1483.4059
Q Predictions Mean           1486.0691
Q Predictions Std            390.91736
Q Predictions Max            1734.5249
Q Predictions Min            -242.13606
V Predictions Mean           1498.8428
V Predictions Std            394.81567
V Predictions Max            1729.5281
V Predictions Min            -265.11188
Log Pis Mean                 1.0685346
Log Pis Std                  3.175855
Log Pis Max                  15.435353
Log Pis Min                  -7.693498
Policy mu Mean               -0.0072703306
Policy mu Std                0.6344469
Policy mu Max                2.5464003
Policy mu Min                -2.5212293
Policy log std Mean          -1.1445075
Policy log std Std           0.3759165
Policy log std Max           0.2861415
Policy log std Min           -3.9115915
Z mean eval                  1.0413067
Z variance eval              0.013818379
total_rewards                [3206.05400455  196.14177023 4399.3050667   999.34156726 4201.40425419
 4274.20890702 4291.13307071 4343.5060348  3465.94971495 4248.56854189]
total_rewards_mean           3362.5612932293575
total_rewards_std            1444.4828583050069
total_rewards_max            4399.305066703773
total_rewards_min            196.1417702259876
Number of train steps total  1436000
Number of env steps total    1797000
Number of rollouts total     0
Train Time (s)               120.7348791998811
(Previous) Eval Time (s)     24.257492465898395
Sample Time (s)              18.707712470088154
Epoch Time (s)               163.70008413586766
Total Train Time (s)         55532.75140524097
Epoch                        358
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:57:08.356663 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #358 | Epoch Duration: 163.57686161994934
2020-01-12 14:57:08.356899 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #358 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0404481
Z variance train             0.013841564
KL Divergence                22.536076
KL Loss                      2.2536075
QF Loss                      9197.038
VF Loss                      502.37207
Policy Loss                  -1554.298
Q Predictions Mean           1554.259
Q Predictions Std            253.50209
Q Predictions Max            1734.0767
Q Predictions Min            -227.36813
V Predictions Mean           1547.1925
V Predictions Std            237.24852
V Predictions Max            1712.8889
V Predictions Min            -225.59024
Log Pis Mean                 1.1868093
Log Pis Std                  3.1423857
Log Pis Max                  18.4694
Log Pis Min                  -7.9056206
Policy mu Mean               0.023702633
Policy mu Std                0.60430837
Policy mu Max                2.6396494
Policy mu Min                -1.977828
Policy log std Mean          -1.1873217
Policy log std Std           0.30996904
Policy log std Max           -0.17494935
Policy log std Min           -3.5001924
Z mean eval                  1.0467727
Z variance eval              0.014544984
total_rewards                [4192.25128673 1558.98893503 4379.24988578 2350.27087739 1731.01418035
 1782.35985131  701.82394776 4197.77080067 2101.04109075 4281.50153968]
total_rewards_mean           2727.627239544306
total_rewards_std            1316.8218904163678
total_rewards_max            4379.249885777106
total_rewards_min            701.82394776176
Number of train steps total  1440000
Number of env steps total    1802000
Number of rollouts total     0
Train Time (s)               109.86441873479635
(Previous) Eval Time (s)     24.133941299747676
Sample Time (s)              17.734020706731826
Epoch Time (s)               151.73238074127585
Total Train Time (s)         55679.80136932386
Epoch                        359
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:59:35.411213 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #359 | Epoch Duration: 147.05413246154785
2020-01-12 14:59:35.411442 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #359 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0460559
Z variance train             0.014539205
KL Divergence                22.043476
KL Loss                      2.2043476
QF Loss                      661.02454
VF Loss                      279.6532
Policy Loss                  -1535.4375
Q Predictions Mean           1537.4216
Q Predictions Std            319.21558
Q Predictions Max            1767.792
Q Predictions Min            -220.05724
V Predictions Mean           1532.9153
V Predictions Std            321.0003
V Predictions Max            1768.8698
V Predictions Min            -231.54337
Log Pis Mean                 1.3443719
Log Pis Std                  3.8512144
Log Pis Max                  32.61048
Log Pis Min                  -6.555053
Policy mu Mean               -0.0018518586
Policy mu Std                0.6656338
Policy mu Max                3.7430978
Policy mu Min                -4.35498
Policy log std Mean          -1.1400449
Policy log std Std           0.32001773
Policy log std Max           0.14420187
Policy log std Min           -2.444094
Z mean eval                  1.0505383
Z variance eval              0.00986931
total_rewards                [4250.75246125 4520.28823713 4408.30113835 1306.81852381 2854.14522705
 4233.18415476 4172.64361535 4307.85765492 4374.71170918 3900.41012741]
total_rewards_mean           3832.9112849209005
total_rewards_std            954.8085522656839
total_rewards_max            4520.288237130141
total_rewards_min            1306.818523808714
Number of train steps total  1444000
Number of env steps total    1807000
Number of rollouts total     0
Train Time (s)               119.65555779077113
(Previous) Eval Time (s)     19.455390776041895
Sample Time (s)              18.29843054432422
Epoch Time (s)               157.40937911113724
Total Train Time (s)         55841.74462836748
Epoch                        360
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:02:17.356718 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #360 | Epoch Duration: 161.94511604309082
2020-01-12 15:02:17.356911 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #360 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0525124
Z variance train             0.009883159
KL Divergence                22.52329
KL Loss                      2.252329
QF Loss                      1269.0842
VF Loss                      683.72925
Policy Loss                  -1525.2509
Q Predictions Mean           1526.477
Q Predictions Std            318.06308
Q Predictions Max            1729.3813
Q Predictions Min            -260.3692
V Predictions Mean           1514.8263
V Predictions Std            315.32068
V Predictions Max            1710.6836
V Predictions Min            -242.64189
Log Pis Mean                 1.5135708
Log Pis Std                  3.434219
Log Pis Max                  14.255468
Log Pis Min                  -8.521353
Policy mu Mean               0.0024055757
Policy mu Std                0.66306233
Policy mu Max                2.367758
Policy mu Min                -2.3421876
Policy log std Mean          -1.1464311
Policy log std Std           0.33619222
Policy log std Max           -0.2714445
Policy log std Min           -3.445238
Z mean eval                  1.0948966
Z variance eval              0.009991577
total_rewards                [4267.5304304  4438.29885371 4151.70700756 4400.5342542   877.77662251
 4211.20514598 4192.90210817   32.67184415 4111.12126938 4380.35393115]
total_rewards_mean           3506.410146722354
total_rewards_std            1540.7017586248446
total_rewards_max            4438.298853713879
total_rewards_min            32.671844151791674
Number of train steps total  1448000
Number of env steps total    1812000
Number of rollouts total     0
Train Time (s)               114.45853031333536
(Previous) Eval Time (s)     23.990816751029342
Sample Time (s)              18.649309009779245
Epoch Time (s)               157.09865607414395
Total Train Time (s)         55997.51161245676
Epoch                        361
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:04:53.126698 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #361 | Epoch Duration: 155.76965761184692
2020-01-12 15:04:53.126897 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #361 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0953591
Z variance train             0.010032478
KL Divergence                23.449871
KL Loss                      2.3449872
QF Loss                      2122.3228
VF Loss                      315.1789
Policy Loss                  -1521.9941
Q Predictions Mean           1528.0701
Q Predictions Std            342.25082
Q Predictions Max            1733.4347
Q Predictions Min            -273.4318
V Predictions Mean           1516.9971
V Predictions Std            342.09467
V Predictions Max            1716.313
V Predictions Min            -279.2032
Log Pis Mean                 1.1296196
Log Pis Std                  3.2745535
Log Pis Max                  14.206516
Log Pis Min                  -8.50812
Policy mu Mean               0.014087761
Policy mu Std                0.62290066
Policy mu Max                2.5263362
Policy mu Min                -2.0810606
Policy log std Mean          -1.139577
Policy log std Std           0.35595196
Policy log std Max           -0.0064411163
Policy log std Min           -3.1642208
Z mean eval                  1.065983
Z variance eval              0.0073962547
total_rewards                [1963.13606099 4288.15672218  931.08382958 4535.00188984  786.11970136
 4216.04868414 4261.84064947 4411.30554258 4362.31400297 3894.75207854]
total_rewards_mean           3364.9759161656375
total_rewards_std            1437.3430891742541
total_rewards_max            4535.001889838728
total_rewards_min            786.1197013630863
Number of train steps total  1452000
Number of env steps total    1817000
Number of rollouts total     0
Train Time (s)               122.7245791121386
(Previous) Eval Time (s)     22.66148390294984
Sample Time (s)              17.655975750181824
Epoch Time (s)               163.04203876527026
Total Train Time (s)         56160.426480920054
Epoch                        362
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:07:36.044212 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #362 | Epoch Duration: 162.91716837882996
2020-01-12 15:07:36.044427 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #362 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0666035
Z variance train             0.007405317
KL Divergence                23.862011
KL Loss                      2.3862011
QF Loss                      813.00116
VF Loss                      148.1382
Policy Loss                  -1525.2025
Q Predictions Mean           1526.4143
Q Predictions Std            310.44714
Q Predictions Max            1723.9027
Q Predictions Min            -187.12099
V Predictions Mean           1527.0098
V Predictions Std            310.92566
V Predictions Max            1713.354
V Predictions Min            -201.10948
Log Pis Mean                 0.9846946
Log Pis Std                  3.2167764
Log Pis Max                  11.168522
Log Pis Min                  -9.261443
Policy mu Mean               -0.046059348
Policy mu Std                0.6056245
Policy mu Max                2.5395043
Policy mu Min                -2.7688015
Policy log std Mean          -1.1621263
Policy log std Std           0.2975557
Policy log std Max           -0.077806115
Policy log std Min           -2.505917
Z mean eval                  1.0693674
Z variance eval              0.0150817875
total_rewards                [3889.80893068 4405.33621342  109.11858266  122.55024004 4315.48101503
 4153.12318162 1594.45509096 4097.68804974 4093.54935934 4056.67942151]
total_rewards_mean           3083.779008500107
total_rewards_std            1669.926153855904
total_rewards_max            4405.336213420757
total_rewards_min            109.11858266287213
Number of train steps total  1456000
Number of env steps total    1822000
Number of rollouts total     0
Train Time (s)               112.75280724000186
(Previous) Eval Time (s)     22.536289416253567
Sample Time (s)              17.915921687614173
Epoch Time (s)               153.2050183438696
Total Train Time (s)         56311.392493437044
Epoch                        363
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:10:07.015581 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #363 | Epoch Duration: 150.97101068496704
2020-01-12 15:10:07.015841 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #363 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0688059
Z variance train             0.015079652
KL Divergence                22.719994
KL Loss                      2.2719994
QF Loss                      1327.2764
VF Loss                      864.4168
Policy Loss                  -1545.6166
Q Predictions Mean           1551.7896
Q Predictions Std            288.58008
Q Predictions Max            1743.732
Q Predictions Min            -240.64401
V Predictions Mean           1546.7295
V Predictions Std            294.9619
V Predictions Max            1742.5521
V Predictions Min            -308.01773
Log Pis Mean                 1.1902995
Log Pis Std                  3.2785087
Log Pis Max                  13.6339
Log Pis Min                  -9.59318
Policy mu Mean               -0.020003833
Policy mu Std                0.6491928
Policy mu Max                2.4213865
Policy mu Min                -3.001508
Policy log std Mean          -1.1428745
Policy log std Std           0.32159233
Policy log std Max           0.33681536
Policy log std Min           -2.7858481
Z mean eval                  1.0880504
Z variance eval              0.015465019
total_rewards                [ 4.13433324e+03  4.52234163e+03  4.52068717e+03  4.37262055e+03
 -1.68808868e-01  3.18775146e+03  4.51314897e+03  4.31500686e+03
  3.46379255e+03  1.76697735e+03]
total_rewards_mean           3479.649095707734
total_rewards_std            1424.4562023185001
total_rewards_max            4522.341625306375
total_rewards_min            -0.1688088676995676
Number of train steps total  1460000
Number of env steps total    1827000
Number of rollouts total     0
Train Time (s)               122.39169500302523
(Previous) Eval Time (s)     20.30195507220924
Sample Time (s)              18.73091914644465
Epoch Time (s)               161.42456922167912
Total Train Time (s)         56476.68996650679
Epoch                        364
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:12:52.335069 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #364 | Epoch Duration: 165.3190565109253
2020-01-12 15:12:52.335229 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #364 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0872593
Z variance train             0.015445506
KL Divergence                21.30274
KL Loss                      2.130274
QF Loss                      881.3086
VF Loss                      155.86769
Policy Loss                  -1503.8168
Q Predictions Mean           1507.2025
Q Predictions Std            312.40195
Q Predictions Max            1717.9718
Q Predictions Min            -329.5328
V Predictions Mean           1499.897
V Predictions Std            312.29266
V Predictions Max            1713.1136
V Predictions Min            -325.31317
Log Pis Mean                 1.2259626
Log Pis Std                  3.162778
Log Pis Max                  14.977627
Log Pis Min                  -6.8772583
Policy mu Mean               0.06662742
Policy mu Std                0.63235384
Policy mu Max                3.3147936
Policy mu Min                -3.2141364
Policy log std Mean          -1.1378773
Policy log std Std           0.2848962
Policy log std Max           0.39740312
Policy log std Min           -2.2819939
Z mean eval                  1.0983003
Z variance eval              0.013401294
total_rewards                [2737.33835085 2536.9930524  4404.49309005 1854.0845876  4196.39866607
 2728.99192196  379.17627888 4297.69416338 2884.77522832 4021.31560168]
total_rewards_mean           3004.126094118949
total_rewards_std            1211.7270267255083
total_rewards_max            4404.493090052387
total_rewards_min            379.17627887995803
Number of train steps total  1464000
Number of env steps total    1832000
Number of rollouts total     0
Train Time (s)               118.14357550535351
(Previous) Eval Time (s)     24.196071736048907
Sample Time (s)              17.779983438085765
Epoch Time (s)               160.11963067948818
Total Train Time (s)         56634.89072528528
Epoch                        365
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:15:30.542379 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #365 | Epoch Duration: 158.20698475837708
2020-01-12 15:15:30.542689 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #365 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1013815
Z variance train             0.013386764
KL Divergence                22.431786
KL Loss                      2.2431786
QF Loss                      1196.2473
VF Loss                      1407.8179
Policy Loss                  -1533.6718
Q Predictions Mean           1535.5968
Q Predictions Std            272.0808
Q Predictions Max            1735.7482
Q Predictions Min            -131.39474
V Predictions Mean           1523.4324
V Predictions Std            276.49524
V Predictions Max            1729.5608
V Predictions Min            -140.80241
Log Pis Mean                 1.2074119
Log Pis Std                  3.399787
Log Pis Max                  14.615253
Log Pis Min                  -10.975435
Policy mu Mean               0.029754443
Policy mu Std                0.636345
Policy mu Max                2.9159129
Policy mu Min                -2.7280674
Policy log std Mean          -1.1601076
Policy log std Std           0.3339774
Policy log std Max           0.8145623
Policy log std Min           -3.3955135
Z mean eval                  1.0354307
Z variance eval              0.018333804
total_rewards                [3849.03851362 1467.06773555 4389.80570756 4311.5076019  4129.93523464
 2075.34567035 4281.37843224 4156.03414781 4540.18438064 4073.43993917]
total_rewards_mean           3727.373736347233
total_rewards_std            1003.3025678730769
total_rewards_max            4540.184380638621
total_rewards_min            1467.0677355499965
Number of train steps total  1468000
Number of env steps total    1837000
Number of rollouts total     0
Train Time (s)               123.36266446299851
(Previous) Eval Time (s)     22.283072504214942
Sample Time (s)              17.871826614718884
Epoch Time (s)               163.51756358193234
Total Train Time (s)         56800.05376855144
Epoch                        366
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:18:15.710684 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #366 | Epoch Duration: 165.16775679588318
2020-01-12 15:18:15.710959 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #366 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0351498
Z variance train             0.018338531
KL Divergence                21.14619
KL Loss                      2.114619
QF Loss                      4792.793
VF Loss                      161.61838
Policy Loss                  -1582.4291
Q Predictions Mean           1583.4741
Q Predictions Std            232.91907
Q Predictions Max            1725.2317
Q Predictions Min            -246.24945
V Predictions Mean           1589.2812
V Predictions Std            233.81267
V Predictions Max            1736.3474
V Predictions Min            -264.05084
Log Pis Mean                 1.334046
Log Pis Std                  3.15045
Log Pis Max                  11.113243
Log Pis Min                  -7.8632264
Policy mu Mean               0.058828354
Policy mu Std                0.6382656
Policy mu Max                2.7061794
Policy mu Min                -2.5783043
Policy log std Mean          -1.1642451
Policy log std Std           0.29300344
Policy log std Max           -0.31554115
Policy log std Min           -2.4301152
Z mean eval                  1.109164
Z variance eval              0.012614782
total_rewards                [4253.42610943  756.27435675 4411.30359826 2414.69659624 4247.4701524
 2138.57046736 1969.38965042 2058.57044563 4243.01227714 4177.14408032]
total_rewards_mean           3066.9857733952713
total_rewards_std            1267.766002968467
total_rewards_max            4411.3035982630845
total_rewards_min            756.2743567452409
Number of train steps total  1472000
Number of env steps total    1842000
Number of rollouts total     0
Train Time (s)               119.58571581123397
(Previous) Eval Time (s)     23.93293612310663
Sample Time (s)              18.192232268862426
Epoch Time (s)               161.71088420320302
Total Train Time (s)         56957.76918806648
Epoch                        367
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:20:53.431977 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #367 | Epoch Duration: 157.7207863330841
2020-01-12 15:20:53.432298 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #367 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1088088
Z variance train             0.012578944
KL Divergence                22.838268
KL Loss                      2.2838268
QF Loss                      474.5445
VF Loss                      102.69713
Policy Loss                  -1547.6809
Q Predictions Mean           1548.24
Q Predictions Std            339.69296
Q Predictions Max            1755.164
Q Predictions Min            -321.17084
V Predictions Mean           1549.1182
V Predictions Std            338.0981
V Predictions Max            1754.3756
V Predictions Min            -320.13373
Log Pis Mean                 1.2349602
Log Pis Std                  2.9860485
Log Pis Max                  10.543734
Log Pis Min                  -5.416253
Policy mu Mean               -0.009146837
Policy mu Std                0.64418244
Policy mu Max                2.4340916
Policy mu Min                -2.418176
Policy log std Mean          -1.1139798
Policy log std Std           0.30951306
Policy log std Max           -0.06648803
Policy log std Min           -2.7605686
Z mean eval                  1.0528753
Z variance eval              0.010269141
total_rewards                [ 983.80519242 4461.72638839 1130.79660304    7.714775   1241.5819211
 4330.59568679 4456.6730131  4342.2407252  3556.28886716  869.16293081]
total_rewards_mean           2538.058610300794
total_rewards_std            1736.4166735258807
total_rewards_max            4461.726388392597
total_rewards_min            7.714774999272728
Number of train steps total  1476000
Number of env steps total    1847000
Number of rollouts total     0
Train Time (s)               119.52455029077828
(Previous) Eval Time (s)     19.942535627167672
Sample Time (s)              18.296269167214632
Epoch Time (s)               157.76335508516058
Total Train Time (s)         57115.27080764063
Epoch                        368
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:23:30.936485 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #368 | Epoch Duration: 157.5039520263672
2020-01-12 15:23:30.936700 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #368 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0522856
Z variance train             0.010262017
KL Divergence                23.3744
KL Loss                      2.33744
QF Loss                      508.724
VF Loss                      185.72572
Policy Loss                  -1518.3318
Q Predictions Mean           1519.5156
Q Predictions Std            369.49124
Q Predictions Max            1755.779
Q Predictions Min            -296.43393
V Predictions Mean           1513.5044
V Predictions Std            368.719
V Predictions Max            1741.8453
V Predictions Min            -315.96207
Log Pis Mean                 1.2069058
Log Pis Std                  3.5108502
Log Pis Max                  15.995956
Log Pis Min                  -6.839219
Policy mu Mean               0.024990315
Policy mu Std                0.62597054
Policy mu Max                3.291014
Policy mu Min                -2.7069488
Policy log std Mean          -1.1433964
Policy log std Std           0.3329204
Policy log std Max           -0.0977149
Policy log std Min           -2.718431
Z mean eval                  1.0623752
Z variance eval              0.012582747
total_rewards                [4303.8028315  4254.43562889 1013.78343171 4463.68242098 3030.60014208
  396.70198979 4521.96400911  454.16610578 3418.79328896 4340.5177253 ]
total_rewards_mean           3019.8447574101233
total_rewards_std            1640.277783288086
total_rewards_max            4521.9640091135625
total_rewards_min            396.70198978543397
Number of train steps total  1480000
Number of env steps total    1852000
Number of rollouts total     0
Train Time (s)               119.49592223204672
(Previous) Eval Time (s)     19.682857875712216
Sample Time (s)              17.405587742105126
Epoch Time (s)               156.58436784986407
Total Train Time (s)         57275.44348961441
Epoch                        369
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:26:11.114056 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #369 | Epoch Duration: 160.17720818519592
2020-01-12 15:26:11.114244 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #369 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0626689
Z variance train             0.012582995
KL Divergence                24.003284
KL Loss                      2.4003284
QF Loss                      1439.8877
VF Loss                      183.94948
Policy Loss                  -1583.5668
Q Predictions Mean           1587.4343
Q Predictions Std            189.65665
Q Predictions Max            1781.0593
Q Predictions Min            -165.41957
V Predictions Mean           1591.8796
V Predictions Std            190.95049
V Predictions Max            1783.8213
V Predictions Min            -162.02565
Log Pis Mean                 1.4606994
Log Pis Std                  3.2445948
Log Pis Max                  13.151387
Log Pis Min                  -6.597905
Policy mu Mean               0.028485872
Policy mu Std                0.6547778
Policy mu Max                2.6127744
Policy mu Min                -2.3247447
Policy log std Mean          -1.1658036
Policy log std Std           0.3225527
Policy log std Max           -0.1200577
Policy log std Min           -2.9408312
Z mean eval                  1.078869
Z variance eval              0.022033919
total_rewards                [4.15855038e+03 9.76504105e+02 9.15517721e+02 7.23046511e-01
 3.26698100e+03 1.28140152e+03 8.93711562e+02 1.29454683e+03
 4.32166250e+03 4.36216121e+03]
total_rewards_mean           2147.175987684807
total_rewards_std            1596.138191915655
total_rewards_max            4362.161214795944
total_rewards_min            0.7230465113116864
Number of train steps total  1484000
Number of env steps total    1857000
Number of rollouts total     0
Train Time (s)               118.9066441077739
(Previous) Eval Time (s)     23.2754083070904
Sample Time (s)              18.30013239150867
Epoch Time (s)               160.48218480637297
Total Train Time (s)         57426.709905329626
Epoch                        370
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:28:42.386906 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #370 | Epoch Duration: 151.27249574661255
2020-01-12 15:28:42.387173 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #370 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0779189
Z variance train             0.021970036
KL Divergence                22.422962
KL Loss                      2.2422962
QF Loss                      589.35834
VF Loss                      143.33237
Policy Loss                  -1560.1719
Q Predictions Mean           1561.4543
Q Predictions Std            265.61404
Q Predictions Max            1766.7767
Q Predictions Min            -256.43018
V Predictions Mean           1558.9381
V Predictions Std            261.423
V Predictions Max            1757.1027
V Predictions Min            -226.40651
Log Pis Mean                 1.1700857
Log Pis Std                  2.802015
Log Pis Max                  12.039137
Log Pis Min                  -5.8547926
Policy mu Mean               -0.002111204
Policy mu Std                0.6305459
Policy mu Max                2.5160174
Policy mu Min                -2.522542
Policy log std Mean          -1.1238979
Policy log std Std           0.28627244
Policy log std Max           -0.17724013
Policy log std Min           -2.784494
Z mean eval                  1.092856
Z variance eval              0.020093601
total_rewards                [4140.93976043 4030.84205567 4156.39205952 1101.49951486 4464.14338654
 4321.56576695  488.17773655 4282.27635714 4397.75142356 1759.43957263]
total_rewards_mean           3314.3027633836973
total_rewards_std            1471.5467435784583
total_rewards_max            4464.143386538332
total_rewards_min            488.17773654531766
Number of train steps total  1488000
Number of env steps total    1862000
Number of rollouts total     0
Train Time (s)               118.48232317576185
(Previous) Eval Time (s)     14.06539658177644
Sample Time (s)              17.696184921078384
Epoch Time (s)               150.24390467861667
Total Train Time (s)         57584.36678553233
Epoch                        371
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:31:20.047244 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #371 | Epoch Duration: 157.65987396240234
2020-01-12 15:31:20.047447 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #371 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0922483
Z variance train             0.020029556
KL Divergence                23.804823
KL Loss                      2.3804824
QF Loss                      1408.8538
VF Loss                      310.32858
Policy Loss                  -1536.7952
Q Predictions Mean           1540.457
Q Predictions Std            328.00525
Q Predictions Max            1750.599
Q Predictions Min            -266.18958
V Predictions Mean           1542.7422
V Predictions Std            326.6231
V Predictions Max            1743.6515
V Predictions Min            -275.89685
Log Pis Mean                 1.3613632
Log Pis Std                  2.9420187
Log Pis Max                  13.838049
Log Pis Min                  -8.916917
Policy mu Mean               -0.0070049553
Policy mu Std                0.6423503
Policy mu Max                2.882854
Policy mu Min                -2.4476469
Policy log std Mean          -1.1576116
Policy log std Std           0.31639844
Policy log std Max           0.16291428
Policy log std Min           -2.9154706
Z mean eval                  1.0845041
Z variance eval              0.014424761
total_rewards                [4180.29404248 4216.8764419   866.92355454  941.32945756  185.62298899
 1169.91599409 4542.5427431  4494.22983874 4392.07939581 2626.33436854]
total_rewards_mean           2761.6148825741084
total_rewards_std            1704.5041679731994
total_rewards_max            4542.542743103445
total_rewards_min            185.6229889858571
Number of train steps total  1492000
Number of env steps total    1867000
Number of rollouts total     0
Train Time (s)               116.75151264108717
(Previous) Eval Time (s)     21.481062058359385
Sample Time (s)              17.83625360345468
Epoch Time (s)               156.06882830290124
Total Train Time (s)         57735.76233890327
Epoch                        372
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:33:51.450196 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #372 | Epoch Duration: 151.40257120132446
2020-01-12 15:33:51.450487 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #372 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.085254
Z variance train             0.014395808
KL Divergence                23.56593
KL Loss                      2.356593
QF Loss                      687.2636
VF Loss                      158.3798
Policy Loss                  -1552.0057
Q Predictions Mean           1554.772
Q Predictions Std            327.9352
Q Predictions Max            1774.7131
Q Predictions Min            -319.26022
V Predictions Mean           1551.14
V Predictions Std            318.79236
V Predictions Max            1767.111
V Predictions Min            -300.5519
Log Pis Mean                 1.2991633
Log Pis Std                  2.9613545
Log Pis Max                  11.159115
Log Pis Min                  -6.962442
Policy mu Mean               0.017025746
Policy mu Std                0.6258959
Policy mu Max                2.4451668
Policy mu Min                -2.2359633
Policy log std Mean          -1.1620451
Policy log std Std           0.31134456
Policy log std Max           0.26853967
Policy log std Min           -2.886451
Z mean eval                  1.0799266
Z variance eval              0.017866103
total_rewards                [4512.76588628 4495.94730025 2361.80083412 2479.20592118  369.44908264
 3975.11240128 4515.88583775 1049.57116276 4122.99636363 2773.59371804]
total_rewards_mean           3065.632850794056
total_rewards_std            1429.925605480057
total_rewards_max            4515.8858377513325
total_rewards_min            369.44908264319184
Number of train steps total  1496000
Number of env steps total    1872000
Number of rollouts total     0
Train Time (s)               126.28543581487611
(Previous) Eval Time (s)     16.81447007181123
Sample Time (s)              18.15716113196686
Epoch Time (s)               161.2570670186542
Total Train Time (s)         57902.12641270878
Epoch                        373
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:36:37.819311 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #373 | Epoch Duration: 166.3686022758484
2020-01-12 15:36:37.819564 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #373 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0809997
Z variance train             0.017871697
KL Divergence                23.217482
KL Loss                      2.3217483
QF Loss                      936.6003
VF Loss                      191.98087
Policy Loss                  -1562.9597
Q Predictions Mean           1566.3441
Q Predictions Std            310.53918
Q Predictions Max            1775.4918
Q Predictions Min            -242.07642
V Predictions Mean           1567.7377
V Predictions Std            310.28308
V Predictions Max            1768.3623
V Predictions Min            -251.82256
Log Pis Mean                 0.9537399
Log Pis Std                  3.008974
Log Pis Max                  10.292252
Log Pis Min                  -8.32898
Policy mu Mean               -0.00698933
Policy mu Std                0.62289435
Policy mu Max                2.895168
Policy mu Min                -2.645124
Policy log std Mean          -1.1381083
Policy log std Std           0.2916089
Policy log std Max           0.056263328
Policy log std Min           -2.1625197
Z mean eval                  1.082072
Z variance eval              0.015259223
total_rewards                [4067.8955313  4360.53942134  139.81417333 1460.37800022 1218.47879129
  312.20845133  350.20154561  312.5598972  3475.21987504 4373.67073007]
total_rewards_mean           2007.0966416724289
total_rewards_std            1744.6664163630871
total_rewards_max            4373.670730074891
total_rewards_min            139.81417332711973
Number of train steps total  1500000
Number of env steps total    1877000
Number of rollouts total     0
Train Time (s)               116.9424026622437
(Previous) Eval Time (s)     21.925696493592113
Sample Time (s)              17.694124608300626
Epoch Time (s)               156.56222376413643
Total Train Time (s)         58051.70784437191
Epoch                        374
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:39:07.406386 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #374 | Epoch Duration: 149.58661150932312
2020-01-12 15:39:07.406679 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #374 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0831363
Z variance train             0.01527862
KL Divergence                24.226954
KL Loss                      2.4226954
QF Loss                      5037.118
VF Loss                      163.70715
Policy Loss                  -1508.6202
Q Predictions Mean           1515.1616
Q Predictions Std            382.82
Q Predictions Max            1741.7615
Q Predictions Min            -282.56982
V Predictions Mean           1505.4108
V Predictions Std            387.70276
V Predictions Max            1740.5465
V Predictions Min            -271.03705
Log Pis Mean                 1.2261461
Log Pis Std                  3.3755333
Log Pis Max                  15.752217
Log Pis Min                  -7.514172
Policy mu Mean               0.008064087
Policy mu Std                0.6661876
Policy mu Max                2.6240232
Policy mu Min                -2.4853134
Policy log std Mean          -1.1205754
Policy log std Std           0.31506005
Policy log std Max           -0.22843564
Policy log std Min           -3.271914
Z mean eval                  1.075613
Z variance eval              0.014204222
total_rewards                [4120.74788813 1191.67529641 4207.35006203 4422.81785227  863.30974938
 4373.83451628 4328.79892297 4398.05021831 4265.29971465 4524.6163329 ]
total_rewards_mean           3669.6500553349265
total_rewards_std            1327.496242387797
total_rewards_max            4524.6163329047695
total_rewards_min            863.3097493839613
Number of train steps total  1504000
Number of env steps total    1882000
Number of rollouts total     0
Train Time (s)               122.00237589189783
(Previous) Eval Time (s)     14.94973819795996
Sample Time (s)              17.58689244184643
Epoch Time (s)               154.53900653170422
Total Train Time (s)         58215.88173160236
Epoch                        375
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:41:51.586065 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #375 | Epoch Duration: 164.17916560173035
2020-01-12 15:41:51.586320 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #375 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0759656
Z variance train             0.0142069785
KL Divergence                23.938854
KL Loss                      2.3938854
QF Loss                      695.8237
VF Loss                      663.61145
Policy Loss                  -1570.1344
Q Predictions Mean           1569.562
Q Predictions Std            297.92044
Q Predictions Max            1771.736
Q Predictions Min            -306.12244
V Predictions Mean           1570.1893
V Predictions Std            288.26328
V Predictions Max            1764.0027
V Predictions Min            -315.64536
Log Pis Mean                 0.95586824
Log Pis Std                  3.0480776
Log Pis Max                  14.209239
Log Pis Min                  -7.492506
Policy mu Mean               0.04190633
Policy mu Std                0.63028854
Policy mu Max                2.5157995
Policy mu Min                -3.3726249
Policy log std Mean          -1.1652973
Policy log std Std           0.3027739
Policy log std Max           0.05879605
Policy log std Min           -3.2213964
Z mean eval                  1.0756845
Z variance eval              0.010295304
total_rewards                [4272.08507452 4279.55750098 2765.58709925  485.35150438 1147.23657101
 4290.27081034 4390.07765751 4503.08122809 4468.34414138 2074.99718292]
total_rewards_mean           3267.6588770385692
total_rewards_std            1456.6477420514466
total_rewards_max            4503.081228091211
total_rewards_min            485.35150437619154
Number of train steps total  1508000
Number of env steps total    1887000
Number of rollouts total     0
Train Time (s)               125.4133535278961
(Previous) Eval Time (s)     24.58958683302626
Sample Time (s)              17.659694333095104
Epoch Time (s)               167.66263469401747
Total Train Time (s)         58380.98592588352
Epoch                        376
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:44:36.692230 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #376 | Epoch Duration: 165.10573148727417
2020-01-12 15:44:36.692415 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #376 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0750303
Z variance train             0.010265434
KL Divergence                24.66163
KL Loss                      2.4661632
QF Loss                      827.3303
VF Loss                      227.00363
Policy Loss                  -1542.2845
Q Predictions Mean           1541.7351
Q Predictions Std            350.74948
Q Predictions Max            1788.9432
Q Predictions Min            -314.25446
V Predictions Mean           1547.406
V Predictions Std            347.85565
V Predictions Max            1785.5807
V Predictions Min            -316.36453
Log Pis Mean                 1.0830812
Log Pis Std                  3.3512805
Log Pis Max                  12.752201
Log Pis Min                  -6.8134513
Policy mu Mean               0.022308905
Policy mu Std                0.6417967
Policy mu Max                2.3858752
Policy mu Min                -3.407907
Policy log std Mean          -1.1482891
Policy log std Std           0.32834455
Policy log std Max           -0.054742575
Policy log std Min           -2.9814568
Z mean eval                  1.0862238
Z variance eval              0.013701916
total_rewards                [1016.58435713 4660.46988376 4550.53559366 4306.66373112 4580.0205374
 4317.03869205 4547.66966714 4276.78340461 4578.81536939 4714.24140152]
total_rewards_mean           4154.882263777561
total_rewards_std            1056.0725722199927
total_rewards_max            4714.2414015189215
total_rewards_min            1016.5843571276317
Number of train steps total  1512000
Number of env steps total    1892000
Number of rollouts total     0
Train Time (s)               122.53167984308675
(Previous) Eval Time (s)     22.03239517379552
Sample Time (s)              18.792762166820467
Epoch Time (s)               163.35683718370274
Total Train Time (s)         58546.696262459736
Epoch                        377
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:47:22.405178 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #377 | Epoch Duration: 165.71264672279358
2020-01-12 15:47:22.405329 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #377 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0864117
Z variance train             0.013712203
KL Divergence                24.665943
KL Loss                      2.4665945
QF Loss                      682.59814
VF Loss                      295.5083
Policy Loss                  -1560.5732
Q Predictions Mean           1563.1125
Q Predictions Std            345.38928
Q Predictions Max            1789.7783
Q Predictions Min            -300.0521
V Predictions Mean           1571.1141
V Predictions Std            350.39542
V Predictions Max            1800.8309
V Predictions Min            -306.341
Log Pis Mean                 1.2682012
Log Pis Std                  2.9961708
Log Pis Max                  13.748136
Log Pis Min                  -6.933076
Policy mu Mean               -0.021143647
Policy mu Std                0.6388237
Policy mu Max                2.381307
Policy mu Min                -3.314234
Policy log std Mean          -1.1261675
Policy log std Std           0.31715947
Policy log std Max           0.00670135
Policy log std Min           -2.6639037
Z mean eval                  1.0708345
Z variance eval              0.0092965495
total_rewards                [4428.15584351 4158.32044613 3034.07654051 3027.52946669 3035.82244409
 4034.63495469  169.18310351 1684.9989521  4276.83308787 4035.81119977]
total_rewards_mean           3188.536603886213
total_rewards_std            1286.2933690090615
total_rewards_max            4428.155843505969
total_rewards_min            169.18310351430375
Number of train steps total  1516000
Number of env steps total    1897000
Number of rollouts total     0
Train Time (s)               120.44790490716696
(Previous) Eval Time (s)     24.387884787283838
Sample Time (s)              18.170135896652937
Epoch Time (s)               163.00592559110373
Total Train Time (s)         58705.588877602946
Epoch                        378
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:50:01.300490 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #378 | Epoch Duration: 158.89504528045654
2020-01-12 15:50:01.300682 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #378 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0706185
Z variance train             0.009322427
KL Divergence                25.291397
KL Loss                      2.5291398
QF Loss                      4751.3413
VF Loss                      466.18066
Policy Loss                  -1582.3375
Q Predictions Mean           1589.1193
Q Predictions Std            267.7599
Q Predictions Max            1792.4006
Q Predictions Min            -298.6181
V Predictions Mean           1577.8958
V Predictions Std            268.3639
V Predictions Max            1784.9282
V Predictions Min            -315.4778
Log Pis Mean                 1.468907
Log Pis Std                  3.2807956
Log Pis Max                  17.87551
Log Pis Min                  -8.420645
Policy mu Mean               0.048490763
Policy mu Std                0.6477979
Policy mu Max                2.499802
Policy mu Min                -2.764977
Policy log std Mean          -1.149245
Policy log std Std           0.31622928
Policy log std Max           -0.095258236
Policy log std Min           -3.0549145
Z mean eval                  1.0638512
Z variance eval              0.0143233435
total_rewards                [4031.312909   4550.33608497 1137.55480405 4447.42834977 1126.94787326
  943.44832322 4454.31924465 4434.40266365 2430.27953027 4421.05006361]
total_rewards_mean           3197.707984644312
total_rewards_std            1513.0850600294536
total_rewards_max            4550.336084966001
total_rewards_min            943.4483232207252
Number of train steps total  1520000
Number of env steps total    1902000
Number of rollouts total     0
Train Time (s)               121.23392321262509
(Previous) Eval Time (s)     20.276662946678698
Sample Time (s)              18.2047714414075
Epoch Time (s)               159.7153576007113
Total Train Time (s)         58864.806258599274
Epoch                        379
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:52:40.524893 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #379 | Epoch Duration: 159.22404861450195
2020-01-12 15:52:40.525152 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #379 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0638082
Z variance train             0.014275052
KL Divergence                23.785788
KL Loss                      2.378579
QF Loss                      1166.6212
VF Loss                      628.95776
Policy Loss                  -1557.047
Q Predictions Mean           1556.6917
Q Predictions Std            339.48236
Q Predictions Max            1755.8529
Q Predictions Min            -262.632
V Predictions Mean           1556.7373
V Predictions Std            329.02814
V Predictions Max            1762.2057
V Predictions Min            -251.55267
Log Pis Mean                 1.854213
Log Pis Std                  3.6275444
Log Pis Max                  19.902485
Log Pis Min                  -4.706293
Policy mu Mean               -0.023384448
Policy mu Std                0.6611292
Policy mu Max                2.446475
Policy mu Min                -3.3272464
Policy log std Mean          -1.1986282
Policy log std Std           0.35646787
Policy log std Max           -0.049058795
Policy log std Min           -3.654066
Z mean eval                  1.1029367
Z variance eval              0.009285955
total_rewards                [4261.74434221 4182.63162077 1139.4878603  4423.2542987  4484.32631855
  797.56865364 3424.49260006 4237.47178345  645.52087779 4375.2602287 ]
total_rewards_mean           3197.1758584183863
total_rewards_std            1558.5045022758343
total_rewards_max            4484.3263185515025
total_rewards_min            645.5208777940975
Number of train steps total  1524000
Number of env steps total    1907000
Number of rollouts total     0
Train Time (s)               119.27160051697865
(Previous) Eval Time (s)     19.78500782418996
Sample Time (s)              19.268193950876594
Epoch Time (s)               158.3248022920452
Total Train Time (s)         59022.8901001215
Epoch                        380
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:55:18.610458 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #380 | Epoch Duration: 158.0851263999939
2020-01-12 15:55:18.610605 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #380 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1023773
Z variance train             0.009285666
KL Divergence                25.085382
KL Loss                      2.5085382
QF Loss                      1183.7456
VF Loss                      205.83589
Policy Loss                  -1586.9458
Q Predictions Mean           1589.4456
Q Predictions Std            274.35202
Q Predictions Max            1779.8213
Q Predictions Min            -337.72684
V Predictions Mean           1581.6858
V Predictions Std            272.47443
V Predictions Max            1764.2711
V Predictions Min            -337.09473
Log Pis Mean                 1.2718371
Log Pis Std                  3.2576313
Log Pis Max                  11.395155
Log Pis Min                  -6.619187
Policy mu Mean               0.03180897
Policy mu Std                0.6423119
Policy mu Max                2.549693
Policy mu Min                -2.3919027
Policy log std Mean          -1.1836584
Policy log std Std           0.32277694
Policy log std Max           -0.12379205
Policy log std Min           -2.5993514
Z mean eval                  1.0976899
Z variance eval              0.020824876
total_rewards                [3769.04740936 2985.0452521  4528.82144412 2426.78695121 4301.85042969
 4010.27383262 1864.9990707  4353.4881777  4366.89199217 2693.8761391 ]
total_rewards_mean           3530.1080698756427
total_rewards_std            908.0259227277262
total_rewards_max            4528.82144411542
total_rewards_min            1864.9990707029483
Number of train steps total  1528000
Number of env steps total    1912000
Number of rollouts total     0
Train Time (s)               115.32471755333245
(Previous) Eval Time (s)     19.545014134142548
Sample Time (s)              17.66078169643879
Epoch Time (s)               152.53051338391379
Total Train Time (s)         59177.87383862585
Epoch                        381
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:57:53.599697 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #381 | Epoch Duration: 154.98895025253296
2020-01-12 15:57:53.599953 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #381 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.09795
Z variance train             0.020809038
KL Divergence                23.353655
KL Loss                      2.3353655
QF Loss                      799.0955
VF Loss                      212.32361
Policy Loss                  -1560.1234
Q Predictions Mean           1562.9946
Q Predictions Std            324.36548
Q Predictions Max            1776.9478
Q Predictions Min            -281.12924
V Predictions Mean           1568.2242
V Predictions Std            325.62048
V Predictions Max            1782.7275
V Predictions Min            -306.7571
Log Pis Mean                 0.98131
Log Pis Std                  3.2250102
Log Pis Max                  10.427443
Log Pis Min                  -7.335823
Policy mu Mean               0.013677947
Policy mu Std                0.63267565
Policy mu Max                2.363306
Policy mu Min                -2.2768354
Policy log std Mean          -1.1574275
Policy log std Std           0.32931426
Policy log std Max           -0.14151657
Policy log std Min           -2.830668
Z mean eval                  1.1147301
Z variance eval              0.012683426
total_rewards                [4434.06054833 4465.94138409 4358.85782312 1652.24676645 4663.28585178
 3890.78755695 4333.87861224 3974.53712372 2902.73804061 4284.25736462]
total_rewards_mean           3896.0591071928443
total_rewards_std            882.438770989216
total_rewards_max            4663.285851779024
total_rewards_min            1652.2467664476458
Number of train steps total  1532000
Number of env steps total    1917000
Number of rollouts total     0
Train Time (s)               117.74927978077903
(Previous) Eval Time (s)     22.003128749784082
Sample Time (s)              18.32908367179334
Epoch Time (s)               158.08149220235646
Total Train Time (s)         59337.722018338274
Epoch                        382
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:00:33.452164 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #382 | Epoch Duration: 159.85202598571777
2020-01-12 16:00:33.452360 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #382 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1146504
Z variance train             0.012664465
KL Divergence                24.157633
KL Loss                      2.4157634
QF Loss                      890.4353
VF Loss                      314.7496
Policy Loss                  -1537.2253
Q Predictions Mean           1537.8876
Q Predictions Std            389.08353
Q Predictions Max            1789.736
Q Predictions Min            -335.29166
V Predictions Mean           1528.802
V Predictions Std            386.50998
V Predictions Max            1760.029
V Predictions Min            -312.05057
Log Pis Mean                 1.2622887
Log Pis Std                  3.2049925
Log Pis Max                  12.019161
Log Pis Min                  -7.156967
Policy mu Mean               -0.0052013546
Policy mu Std                0.6257396
Policy mu Max                2.616519
Policy mu Min                -2.2702756
Policy log std Mean          -1.1774664
Policy log std Std           0.31262332
Policy log std Max           -0.028115153
Policy log std Min           -2.66638
Z mean eval                  1.0730131
Z variance eval              0.011247612
total_rewards                [4782.88302301 4652.75613376 1945.38335452 4228.87044577 4478.29583725
 4603.03286443 4459.84273882 4455.88790878  427.17383397 4221.10128175]
total_rewards_mean           3825.5227422054086
total_rewards_std            1372.3731914693626
total_rewards_max            4782.883023014588
total_rewards_min            427.17383396851653
Number of train steps total  1536000
Number of env steps total    1922000
Number of rollouts total     0
Train Time (s)               122.0529054896906
(Previous) Eval Time (s)     23.773388656787574
Sample Time (s)              17.994586808606982
Epoch Time (s)               163.82088095508516
Total Train Time (s)         59503.241093703546
Epoch                        383
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:03:18.974063 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #383 | Epoch Duration: 165.52155876159668
2020-01-12 16:03:18.974274 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #383 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0727806
Z variance train             0.011230604
KL Divergence                23.752096
KL Loss                      2.3752096
QF Loss                      1326.6117
VF Loss                      383.33392
Policy Loss                  -1562.3531
Q Predictions Mean           1563.6567
Q Predictions Std            371.31766
Q Predictions Max            1785.5061
Q Predictions Min            -349.10617
V Predictions Mean           1563.3486
V Predictions Std            370.91983
V Predictions Max            1781.8926
V Predictions Min            -337.78122
Log Pis Mean                 1.6087372
Log Pis Std                  3.5833747
Log Pis Max                  17.26125
Log Pis Min                  -8.009321
Policy mu Mean               0.02292553
Policy mu Std                0.6916938
Policy mu Max                2.889556
Policy mu Min                -2.8991387
Policy log std Mean          -1.1397572
Policy log std Std           0.32759106
Policy log std Max           -0.07006502
Policy log std Min           -3.0900493
Z mean eval                  1.0760779
Z variance eval              0.010173516
total_rewards                [  41.49263214 1216.08232784 4416.19835997 4414.29592469 3840.33470375
 4634.84026775 4140.9196928  4242.18558733  650.9682185  3301.37154621]
total_rewards_mean           3089.86892609809
total_rewards_std            1664.1086995402172
total_rewards_max            4634.840267746571
total_rewards_min            41.492632138228814
Number of train steps total  1540000
Number of env steps total    1927000
Number of rollouts total     0
Train Time (s)               123.46130275400355
(Previous) Eval Time (s)     25.47374556073919
Sample Time (s)              17.775278984103352
Epoch Time (s)               166.7103272988461
Total Train Time (s)         59668.39263688307
Epoch                        384
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:06:04.128653 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #384 | Epoch Duration: 165.15424513816833
2020-01-12 16:06:04.128850 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #384 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.075339
Z variance train             0.01017155
KL Divergence                24.537933
KL Loss                      2.4537933
QF Loss                      1282.1838
VF Loss                      247.13483
Policy Loss                  -1563.161
Q Predictions Mean           1563.7045
Q Predictions Std            342.29758
Q Predictions Max            1799.4739
Q Predictions Min            -343.89954
V Predictions Mean           1551.5044
V Predictions Std            341.2429
V Predictions Max            1793.3346
V Predictions Min            -329.4604
Log Pis Mean                 1.2849736
Log Pis Std                  3.44152
Log Pis Max                  11.909639
Log Pis Min                  -7.678528
Policy mu Mean               0.012291592
Policy mu Std                0.6637519
Policy mu Max                2.825634
Policy mu Min                -2.6248472
Policy log std Mean          -1.1518964
Policy log std Std           0.32537362
Policy log std Max           0.056128144
Policy log std Min           -2.4473403
Z mean eval                  1.079005
Z variance eval              0.016389681
total_rewards                [ -22.23237798 4142.80466916  217.96978863  707.87481807  696.20201301
 4370.22613376 4611.60126886 4554.21043219 4103.06384487 2362.84093016]
total_rewards_mean           2574.4561520726347
total_rewards_std            1882.6338041665504
total_rewards_max            4611.601268864362
total_rewards_min            -22.232377984140562
Number of train steps total  1544000
Number of env steps total    1932000
Number of rollouts total     0
Train Time (s)               120.72496990812942
(Previous) Eval Time (s)     23.917328086681664
Sample Time (s)              18.44004572695121
Epoch Time (s)               163.0823437217623
Total Train Time (s)         59823.62280103145
Epoch                        385
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:08:39.361244 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #385 | Epoch Duration: 155.23225784301758
2020-01-12 16:08:39.361414 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #385 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0784081
Z variance train             0.016421158
KL Divergence                24.552269
KL Loss                      2.455227
QF Loss                      656.3298
VF Loss                      166.41098
Policy Loss                  -1601.478
Q Predictions Mean           1602.969
Q Predictions Std            242.21754
Q Predictions Max            1773.9543
Q Predictions Min            -277.50327
V Predictions Mean           1595.9291
V Predictions Std            241.12135
V Predictions Max            1759.2074
V Predictions Min            -274.15356
Log Pis Mean                 1.6692615
Log Pis Std                  3.2264738
Log Pis Max                  14.986069
Log Pis Min                  -6.2248173
Policy mu Mean               0.029001623
Policy mu Std                0.67975223
Policy mu Max                2.4253943
Policy mu Min                -2.5947697
Policy log std Mean          -1.1538415
Policy log std Std           0.31637156
Policy log std Max           0.07579768
Policy log std Min           -2.8777518
Z mean eval                  1.0766633
Z variance eval              0.011037582
total_rewards                [4210.00326232 4276.12994756 3471.84317901 4470.32886535 4148.01617652
 4458.64402731 3347.80781597 4518.18655234 3234.61062278 3455.59915291]
total_rewards_mean           3959.116960206283
total_rewards_std            491.13358866536873
total_rewards_max            4518.186552342653
total_rewards_min            3234.61062277554
Number of train steps total  1548000
Number of env steps total    1937000
Number of rollouts total     0
Train Time (s)               118.20207596430555
(Previous) Eval Time (s)     16.066912449896336
Sample Time (s)              17.70299609610811
Epoch Time (s)               151.97198451031
Total Train Time (s)         59984.86275607394
Epoch                        386
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:11:20.605172 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #386 | Epoch Duration: 161.24359440803528
2020-01-12 16:11:20.605464 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #386 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0758631
Z variance train             0.011042418
KL Divergence                24.541634
KL Loss                      2.4541633
QF Loss                      879.2036
VF Loss                      246.65002
Policy Loss                  -1588.9803
Q Predictions Mean           1592.3115
Q Predictions Std            328.42065
Q Predictions Max            1814.5659
Q Predictions Min            -285.30405
V Predictions Mean           1591.1425
V Predictions Std            327.21924
V Predictions Max            1795.2583
V Predictions Min            -287.66003
Log Pis Mean                 1.7817171
Log Pis Std                  3.7600758
Log Pis Max                  22.618946
Log Pis Min                  -7.2492933
Policy mu Mean               -0.0040066848
Policy mu Std                0.6477986
Policy mu Max                4.2008057
Policy mu Min                -2.7368543
Policy log std Mean          -1.2015921
Policy log std Std           0.34382874
Policy log std Max           0.40563023
Policy log std Min           -3.327768
Z mean eval                  1.0840861
Z variance eval              0.010185075
total_rewards                [4269.75256675 4453.00733108 3781.70968356 4382.45424874 4469.26047578
 4181.65017706 1743.31043602 2825.24745776 3969.90384406 4397.44605258]
total_rewards_mean           3847.374227338993
total_rewards_std            844.0213496732953
total_rewards_max            4469.260475781516
total_rewards_min            1743.3104360242787
Number of train steps total  1552000
Number of env steps total    1942000
Number of rollouts total     0
Train Time (s)               119.76836712099612
(Previous) Eval Time (s)     25.338213816285133
Sample Time (s)              18.500129631720483
Epoch Time (s)               163.60671056900173
Total Train Time (s)         60147.8476458611
Epoch                        387
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:14:03.592208 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #387 | Epoch Duration: 162.9865424633026
2020-01-12 16:14:03.592375 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #387 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.084757
Z variance train             0.0101784505
KL Divergence                24.789452
KL Loss                      2.4789453
QF Loss                      1611.4226
VF Loss                      289.9757
Policy Loss                  -1576.6888
Q Predictions Mean           1574.2859
Q Predictions Std            316.40472
Q Predictions Max            1780.4194
Q Predictions Min            -184.42502
V Predictions Mean           1571.2673
V Predictions Std            308.4517
V Predictions Max            1766.2036
V Predictions Min            -187.87137
Log Pis Mean                 1.2328633
Log Pis Std                  3.0849469
Log Pis Max                  12.310488
Log Pis Min                  -7.674156
Policy mu Mean               0.02436491
Policy mu Std                0.61520463
Policy mu Max                2.6038785
Policy mu Min                -2.453694
Policy log std Mean          -1.1675159
Policy log std Std           0.3301796
Policy log std Max           -0.13301373
Policy log std Min           -2.8898227
Z mean eval                  1.0808339
Z variance eval              0.0052774614
total_rewards                [4615.01192762 4393.70891282 4754.26906887 4495.4465188  4652.29007735
 4635.17128353 4247.83146072 4700.70818636  678.52231612 3742.72784922]
total_rewards_mean           4091.5687601411546
total_rewards_std            1172.3279125712995
total_rewards_max            4754.269068874969
total_rewards_min            678.5223161190883
Number of train steps total  1556000
Number of env steps total    1947000
Number of rollouts total     0
Train Time (s)               120.52113533485681
(Previous) Eval Time (s)     24.71776683907956
Sample Time (s)              18.56172512564808
Epoch Time (s)               163.80062729958445
Total Train Time (s)         60312.15734649263
Epoch                        388
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:16:47.905944 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #388 | Epoch Duration: 164.3134365081787
2020-01-12 16:16:47.906144 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #388 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0799358
Z variance train             0.005276564
KL Divergence                26.000658
KL Loss                      2.600066
QF Loss                      563.32556
VF Loss                      266.14435
Policy Loss                  -1583.001
Q Predictions Mean           1585.3081
Q Predictions Std            325.8008
Q Predictions Max            1786.7898
Q Predictions Min            -343.8578
V Predictions Mean           1582.7327
V Predictions Std            322.53806
V Predictions Max            1777.2515
V Predictions Min            -313.71823
Log Pis Mean                 1.7345512
Log Pis Std                  3.1517723
Log Pis Max                  17.775204
Log Pis Min                  -5.0259757
Policy mu Mean               -0.005269854
Policy mu Std                0.68254966
Policy mu Max                2.5117939
Policy mu Min                -2.9259837
Policy log std Mean          -1.1566479
Policy log std Std           0.33156192
Policy log std Max           0.1164583
Policy log std Min           -3.0164392
Z mean eval                  1.1189319
Z variance eval              0.008523187
total_rewards                [4359.33828616 3678.74703449 4596.80979114  819.46726603 4479.37224775
 4578.65766206  812.54716375 4418.33727987  372.02529756 4583.73789232]
total_rewards_mean           3269.903992112013
total_rewards_std            1725.5825258837442
total_rewards_max            4596.8097911359455
total_rewards_min            372.02529755728733
Number of train steps total  1560000
Number of env steps total    1952000
Number of rollouts total     0
Train Time (s)               119.43343328638002
(Previous) Eval Time (s)     25.23021438997239
Sample Time (s)              18.5975388600491
Epoch Time (s)               163.2611865364015
Total Train Time (s)         60472.79588083178
Epoch                        389
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:19:28.550994 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #389 | Epoch Duration: 160.64470148086548
2020-01-12 16:19:28.551266 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #389 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1191003
Z variance train             0.0085189445
KL Divergence                25.621193
KL Loss                      2.5621192
QF Loss                      798.2228
VF Loss                      381.42554
Policy Loss                  -1608.4098
Q Predictions Mean           1608.8853
Q Predictions Std            309.59705
Q Predictions Max            1819.6954
Q Predictions Min            -291.20752
V Predictions Mean           1606.1028
V Predictions Std            311.36252
V Predictions Max            1810.3856
V Predictions Min            -332.5012
Log Pis Mean                 1.2167398
Log Pis Std                  3.5417805
Log Pis Max                  15.052435
Log Pis Min                  -9.000079
Policy mu Mean               0.015758943
Policy mu Std                0.6232166
Policy mu Max                2.6758914
Policy mu Min                -4.094161
Policy log std Mean          -1.1852815
Policy log std Std           0.33831277
Policy log std Max           0.08212471
Policy log std Min           -3.0058494
Z mean eval                  1.0760849
Z variance eval              0.008803751
total_rewards                [4345.55322219 1790.74056708 4411.91068408 3974.85133961 4401.09855977
 4181.75045286 2978.12885752 4366.58936432 4323.28445536 2925.7313729 ]
total_rewards_mean           3769.963887568305
total_rewards_std            852.7871132790082
total_rewards_max            4411.910684078974
total_rewards_min            1790.7405670763828
Number of train steps total  1564000
Number of env steps total    1957000
Number of rollouts total     0
Train Time (s)               119.3636055868119
(Previous) Eval Time (s)     22.61339766625315
Sample Time (s)              18.49691874254495
Epoch Time (s)               160.47392199561
Total Train Time (s)         60634.8625999419
Epoch                        390
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:22:10.620671 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #390 | Epoch Duration: 162.06921315193176
2020-01-12 16:22:10.620827 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #390 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0745292
Z variance train             0.008805687
KL Divergence                23.872494
KL Loss                      2.3872495
QF Loss                      741.4244
VF Loss                      118.9362
Policy Loss                  -1593.0123
Q Predictions Mean           1594.641
Q Predictions Std            310.9651
Q Predictions Max            1843.7104
Q Predictions Min            -292.03998
V Predictions Mean           1592.1013
V Predictions Std            307.5302
V Predictions Max            1839.6757
V Predictions Min            -281.31876
Log Pis Mean                 1.3073884
Log Pis Std                  2.9697242
Log Pis Max                  14.005898
Log Pis Min                  -11.058134
Policy mu Mean               -0.005880894
Policy mu Std                0.67919385
Policy mu Max                2.584154
Policy mu Min                -2.4204233
Policy log std Mean          -1.1083488
Policy log std Std           0.29920936
Policy log std Max           0.060921907
Policy log std Min           -2.873
Z mean eval                  1.0655366
Z variance eval              0.010874574
total_rewards                [4433.26290374 2245.25058495 3977.05032267 4455.8526888  4626.81729855
 4560.09581797 4690.37112605 4567.8620908  -245.71153988 4215.93398078]
total_rewards_mean           3752.678527441364
total_rewards_std            1498.0618267586715
total_rewards_max            4690.371126046021
total_rewards_min            -245.71153988440926
Number of train steps total  1568000
Number of env steps total    1962000
Number of rollouts total     0
Train Time (s)               123.64772321097553
(Previous) Eval Time (s)     24.20837218221277
Sample Time (s)              18.430124423466623
Epoch Time (s)               166.28621981665492
Total Train Time (s)         60802.390053861775
Epoch                        391
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:24:58.151163 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #391 | Epoch Duration: 167.53021717071533
2020-01-12 16:24:58.151362 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #391 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0661594
Z variance train             0.010874405
KL Divergence                23.915356
KL Loss                      2.3915355
QF Loss                      924.1305
VF Loss                      204.58081
Policy Loss                  -1587.3394
Q Predictions Mean           1591.0747
Q Predictions Std            329.07104
Q Predictions Max            1818.8406
Q Predictions Min            -150.67667
V Predictions Mean           1590.8456
V Predictions Std            329.70178
V Predictions Max            1816.4159
V Predictions Min            -160.49736
Log Pis Mean                 1.3306971
Log Pis Std                  3.447002
Log Pis Max                  18.974821
Log Pis Min                  -6.6537833
Policy mu Mean               0.05709137
Policy mu Std                0.60405296
Policy mu Max                4.052079
Policy mu Min                -3.1347609
Policy log std Mean          -1.2113589
Policy log std Std           0.35529754
Policy log std Max           -0.20125377
Policy log std Min           -3.6524303
Z mean eval                  1.1198499
Z variance eval              0.005932166
total_rewards                [ 489.84611749 1636.5233644  4890.92264358 3326.16336676 4741.01546942
 2602.62766226 2172.77989652 4667.72735942 3615.98140386 4700.61710882]
total_rewards_mean           3284.420439254295
total_rewards_std            1447.7272221676437
total_rewards_max            4890.922643575902
total_rewards_min            489.84611749472106
Number of train steps total  1572000
Number of env steps total    1967000
Number of rollouts total     0
Train Time (s)               118.94449973385781
(Previous) Eval Time (s)     25.45208092033863
Sample Time (s)              18.27397853601724
Epoch Time (s)               162.67055919021368
Total Train Time (s)         60958.594593599904
Epoch                        392
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:27:34.362914 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #392 | Epoch Duration: 156.21138620376587
2020-01-12 16:27:34.363199 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #392 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1203834
Z variance train             0.005934759
KL Divergence                25.24487
KL Loss                      2.524487
QF Loss                      4709.0312
VF Loss                      145.77931
Policy Loss                  -1606.4094
Q Predictions Mean           1609.4471
Q Predictions Std            301.83252
Q Predictions Max            1825.9015
Q Predictions Min            -355.9737
V Predictions Mean           1602.8445
V Predictions Std            299.87314
V Predictions Max            1810.9042
V Predictions Min            -360.05502
Log Pis Mean                 1.3363109
Log Pis Std                  3.1611621
Log Pis Max                  11.898798
Log Pis Min                  -6.7768044
Policy mu Mean               0.01903782
Policy mu Std                0.6118952
Policy mu Max                2.4541197
Policy mu Min                -2.6608975
Policy log std Mean          -1.1912366
Policy log std Std           0.32194123
Policy log std Max           -0.16512007
Policy log std Min           -2.965935
Z mean eval                  1.0851047
Z variance eval              0.0050715515
total_rewards                [-158.55836527 4392.30705397 4241.10159002  398.18226956 4417.37414972
 4717.94765511 4650.16240941  882.58963059 4443.55107188 4590.59031398]
total_rewards_mean           3257.5247778968915
total_rewards_std            1906.3625559214202
total_rewards_max            4717.947655108966
total_rewards_min            -158.5583652683271
Number of train steps total  1576000
Number of env steps total    1972000
Number of rollouts total     0
Train Time (s)               123.9520422318019
(Previous) Eval Time (s)     18.99258770281449
Sample Time (s)              17.78729309560731
Epoch Time (s)               160.7319230302237
Total Train Time (s)         61123.21624245262
Epoch                        393
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:30:18.989257 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #393 | Epoch Duration: 164.62584447860718
2020-01-12 16:30:18.989486 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #393 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0850003
Z variance train             0.005071193
KL Divergence                25.971418
KL Loss                      2.597142
QF Loss                      583.27
VF Loss                      120.54376
Policy Loss                  -1607.2711
Q Predictions Mean           1609.8391
Q Predictions Std            288.48438
Q Predictions Max            1821.2681
Q Predictions Min            -268.9673
V Predictions Mean           1612.2263
V Predictions Std            289.03723
V Predictions Max            1806.5278
V Predictions Min            -299.687
Log Pis Mean                 1.1379707
Log Pis Std                  3.0287235
Log Pis Max                  12.679026
Log Pis Min                  -6.0833287
Policy mu Mean               0.012387581
Policy mu Std                0.6523078
Policy mu Max                2.640584
Policy mu Min                -2.4772012
Policy log std Mean          -1.1394112
Policy log std Std           0.29888102
Policy log std Max           0.14817917
Policy log std Min           -2.3092284
Z mean eval                  1.065222
Z variance eval              0.006662432
total_rewards                [3293.37124703 2500.16312239 4263.99170656 4599.84614063 4321.09804871
 4624.8856044  4668.06293075 4766.42121074  661.44800152 4685.18813726]
total_rewards_mean           3838.447614999076
total_rewards_std            1267.2828371647163
total_rewards_max            4766.4212107393805
total_rewards_min            661.4480015187687
Number of train steps total  1580000
Number of env steps total    1977000
Number of rollouts total     0
Train Time (s)               114.89187144115567
(Previous) Eval Time (s)     22.886201368179172
Sample Time (s)              17.9811151297763
Epoch Time (s)               155.75918793911114
Total Train Time (s)         61278.510478273965
Epoch                        394
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:32:54.285878 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #394 | Epoch Duration: 155.2962257862091
2020-01-12 16:32:54.286038 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #394 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0628698
Z variance train             0.006660237
KL Divergence                25.558662
KL Loss                      2.5558662
QF Loss                      1107.773
VF Loss                      298.43524
Policy Loss                  -1634.2025
Q Predictions Mean           1631.2258
Q Predictions Std            214.15952
Q Predictions Max            1795.9431
Q Predictions Min            -372.8616
V Predictions Mean           1640.9197
V Predictions Std            188.58096
V Predictions Max            1809.1399
V Predictions Min            -391.2285
Log Pis Mean                 1.3528327
Log Pis Std                  3.6876163
Log Pis Max                  23.714218
Log Pis Min                  -7.7001643
Policy mu Mean               -0.007855531
Policy mu Std                0.6284522
Policy mu Max                2.278505
Policy mu Min                -2.3890283
Policy log std Mean          -1.1957333
Policy log std Std           0.35402286
Policy log std Max           -0.2515267
Policy log std Min           -3.6485581
Z mean eval                  1.072692
Z variance eval              0.01376449
total_rewards                [2770.71320051 4497.30521496 1515.48726838 4717.08999555   27.12403177
 1377.19242381 4702.34500016 1318.01663111 4570.61936592 4362.04469718]
total_rewards_mean           2985.7937829341995
total_rewards_std            1701.9167645502403
total_rewards_max            4717.089995545186
total_rewards_min            27.124031774262672
Number of train steps total  1584000
Number of env steps total    1982000
Number of rollouts total     0
Train Time (s)               118.46657179435715
(Previous) Eval Time (s)     22.42293159617111
Sample Time (s)              17.77230024151504
Epoch Time (s)               158.6618036320433
Total Train Time (s)         61432.4515921711
Epoch                        395
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:35:28.229727 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #395 | Epoch Duration: 153.94357013702393
2020-01-12 16:35:28.229927 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #395 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0703475
Z variance train             0.013724898
KL Divergence                23.75011
KL Loss                      2.3750112
QF Loss                      1261.3882
VF Loss                      225.83118
Policy Loss                  -1591.4161
Q Predictions Mean           1594.3397
Q Predictions Std            337.93567
Q Predictions Max            1831.2356
Q Predictions Min            -307.9315
V Predictions Mean           1592.9626
V Predictions Std            337.625
V Predictions Max            1830.6017
V Predictions Min            -311.02908
Log Pis Mean                 1.6564901
Log Pis Std                  3.3746073
Log Pis Max                  15.624682
Log Pis Min                  -5.5746098
Policy mu Mean               0.03147514
Policy mu Std                0.65684456
Policy mu Max                3.1709752
Policy mu Min                -2.276336
Policy log std Mean          -1.1630616
Policy log std Std           0.3514269
Policy log std Max           -0.02423346
Policy log std Min           -3.1152887
Z mean eval                  1.0849737
Z variance eval              0.01186998
total_rewards                [ 245.22554322  174.62580441 1282.01553248 4108.3076927  3488.79266758
 4637.24531469 4581.45930207 2446.22277445 4671.18455219 3280.78989275]
total_rewards_mean           2891.586907654998
total_rewards_std            1680.2582611788887
total_rewards_max            4671.184552192106
total_rewards_min            174.6258044138778
Number of train steps total  1588000
Number of env steps total    1987000
Number of rollouts total     0
Train Time (s)               120.39941824506968
(Previous) Eval Time (s)     17.704380308743566
Sample Time (s)              17.395431586541235
Epoch Time (s)               155.49923014035448
Total Train Time (s)         61587.72402913682
Epoch                        396
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:38:03.509459 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #396 | Epoch Duration: 155.2793412208557
2020-01-12 16:38:03.509794 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #396 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0854614
Z variance train             0.011853292
KL Divergence                24.56415
KL Loss                      2.456415
QF Loss                      559.3583
VF Loss                      638.26965
Policy Loss                  -1634.96
Q Predictions Mean           1637.3319
Q Predictions Std            251.3757
Q Predictions Max            1826.8728
Q Predictions Min            -333.66995
V Predictions Mean           1639.22
V Predictions Std            252.58797
V Predictions Max            1840.2474
V Predictions Min            -322.75134
Log Pis Mean                 1.2881887
Log Pis Std                  3.2807705
Log Pis Max                  12.810877
Log Pis Min                  -7.523247
Policy mu Mean               0.03420625
Policy mu Std                0.63644797
Policy mu Max                2.7654228
Policy mu Min                -2.4416635
Policy log std Mean          -1.1890209
Policy log std Std           0.31933546
Policy log std Max           -0.15051925
Policy log std Min           -2.8201375
Z mean eval                  1.1569567
Z variance eval              0.0075879386
total_rewards                [4237.61430395  295.37875589 4361.72670008 4475.65515578 4612.10775763
 4208.8165337  4483.5569981  2051.14989223  902.50780337 4717.86179374]
total_rewards_mean           3434.637569448308
total_rewards_std            1596.913717188178
total_rewards_max            4717.8617937386625
total_rewards_min            295.3787558941253
Number of train steps total  1592000
Number of env steps total    1992000
Number of rollouts total     0
Train Time (s)               120.802975110244
(Previous) Eval Time (s)     17.484180971980095
Sample Time (s)              19.149305233731866
Epoch Time (s)               157.43646131595597
Total Train Time (s)         61749.00707234023
Epoch                        397
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:40:44.795296 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #397 | Epoch Duration: 161.2852919101715
2020-01-12 16:40:44.795481 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #397 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1559521
Z variance train             0.0075856694
KL Divergence                24.303541
KL Loss                      2.430354
QF Loss                      1186.1794
VF Loss                      1999.531
Policy Loss                  -1594.815
Q Predictions Mean           1598.0708
Q Predictions Std            330.78436
Q Predictions Max            1818.685
Q Predictions Min            -365.2083
V Predictions Mean           1597.0066
V Predictions Std            321.2529
V Predictions Max            1819.9521
V Predictions Min            -361.25113
Log Pis Mean                 1.5358845
Log Pis Std                  3.2366788
Log Pis Max                  16.489677
Log Pis Min                  -5.933106
Policy mu Mean               0.0079091415
Policy mu Std                0.63946104
Policy mu Max                2.7237117
Policy mu Min                -2.5283227
Policy log std Mean          -1.1865331
Policy log std Std           0.32064396
Policy log std Max           -0.08270502
Policy log std Min           -3.0519354
Z mean eval                  1.0854785
Z variance eval              0.014453347
total_rewards                [4058.57149021 1613.86252569 3448.43576676 4305.24876984 4425.01846316
 4604.42698821  108.6028833  4393.69680281 4618.25149784 4715.25447733]
total_rewards_mean           3629.1369665134625
total_rewards_std            1464.8158224512545
total_rewards_max            4715.254477326511
total_rewards_min            108.60288329667723
Number of train steps total  1596000
Number of env steps total    1997000
Number of rollouts total     0
Train Time (s)               122.24458061624318
(Previous) Eval Time (s)     21.332697269972414
Sample Time (s)              17.819289003964514
Epoch Time (s)               161.3965668901801
Total Train Time (s)         61910.59606896108
Epoch                        398
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:43:26.387610 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #398 | Epoch Duration: 161.59200501441956
2020-01-12 16:43:26.387804 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #398 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.085057
Z variance train             0.014453718
KL Divergence                23.178957
KL Loss                      2.3178957
QF Loss                      1379.7086
VF Loss                      2146.527
Policy Loss                  -1572.2063
Q Predictions Mean           1576.7605
Q Predictions Std            395.37695
Q Predictions Max            1836.5387
Q Predictions Min            -350.37442
V Predictions Mean           1565.5845
V Predictions Std            403.6075
V Predictions Max            1828.2747
V Predictions Min            -375.01083
Log Pis Mean                 1.336268
Log Pis Std                  3.0055754
Log Pis Max                  12.93141
Log Pis Min                  -5.4870253
Policy mu Mean               0.018052641
Policy mu Std                0.6195482
Policy mu Max                2.7002861
Policy mu Min                -3.000581
Policy log std Mean          -1.1918213
Policy log std Std           0.35382506
Policy log std Max           0.055590868
Policy log std Min           -3.242246
Z mean eval                  1.0930994
Z variance eval              0.012948798
total_rewards                [4513.8594972  3487.58345582 2352.54158124 4282.19324214 4338.59871338
 4298.40715994 4731.13348831 3694.64994377 4639.05771084 4272.23714966]
total_rewards_mean           4061.0261942299207
total_rewards_std            678.0214731900389
total_rewards_max            4731.133488313914
total_rewards_min            2352.541581240337
Number of train steps total  1600000
Number of env steps total    2002000
Number of rollouts total     0
Train Time (s)               118.14951380295679
(Previous) Eval Time (s)     21.52777472184971
Sample Time (s)              17.90798373008147
Epoch Time (s)               157.58527225488797
Total Train Time (s)         62072.13355703093
Epoch                        399
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:46:07.930047 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #399 | Epoch Duration: 161.5420787334442
2020-01-12 16:46:07.930264 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #399 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.094084
Z variance train             0.012958963
KL Divergence                24.19699
KL Loss                      2.419699
QF Loss                      885.18665
VF Loss                      139.90053
Policy Loss                  -1644.3837
Q Predictions Mean           1645.9124
Q Predictions Std            261.47186
Q Predictions Max            1854.3792
Q Predictions Min            -220.88074
V Predictions Mean           1643.3876
V Predictions Std            259.31573
V Predictions Max            1851.2817
V Predictions Min            -208.86763
Log Pis Mean                 1.4832652
Log Pis Std                  3.1368537
Log Pis Max                  10.920631
Log Pis Min                  -5.66106
Policy mu Mean               0.0072655845
Policy mu Std                0.6267313
Policy mu Max                3.6495538
Policy mu Min                -2.763608
Policy log std Mean          -1.1831106
Policy log std Std           0.29347235
Policy log std Max           0.0917269
Policy log std Min           -2.2842007
Z mean eval                  1.1042817
Z variance eval              0.012095315
total_rewards                [3124.38857929 4323.6068471  2792.46268751 1409.46382892 4257.60514255
 4190.06245057 4645.70032492 4150.8408229   238.70907606 4483.4453884 ]
total_rewards_mean           3361.6285148230686
total_rewards_std            1410.2643050708266
total_rewards_max            4645.70032491581
total_rewards_min            238.70907605761374
Number of train steps total  1604000
Number of env steps total    2007000
Number of rollouts total     0
Train Time (s)               124.0843605780974
(Previous) Eval Time (s)     25.48428181419149
Sample Time (s)              18.145421578083187
Epoch Time (s)               167.71406397037208
Total Train Time (s)         62238.55927615659
Epoch                        400
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:48:54.361226 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #400 | Epoch Duration: 166.4307894706726
2020-01-12 16:48:54.361461 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #400 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1041828
Z variance train             0.01207783
KL Divergence                24.60639
KL Loss                      2.460639
QF Loss                      615.887
VF Loss                      271.87518
Policy Loss                  -1650.3329
Q Predictions Mean           1652.1809
Q Predictions Std            215.57458
Q Predictions Max            1827.6649
Q Predictions Min            -270.3195
V Predictions Mean           1650.5007
V Predictions Std            217.88898
V Predictions Max            1834.547
V Predictions Min            -282.6729
Log Pis Mean                 1.3819014
Log Pis Std                  2.9949906
Log Pis Max                  11.363897
Log Pis Min                  -6.131536
Policy mu Mean               0.04808067
Policy mu Std                0.63949054
Policy mu Max                2.6185403
Policy mu Min                -2.2705941
Policy log std Mean          -1.176562
Policy log std Std           0.28293967
Policy log std Max           -0.3505211
Policy log std Min           -2.3928828
Z mean eval                  1.127801
Z variance eval              0.009704773
total_rewards                [1895.69497827 4464.00310941 4846.17315356 4480.34348505 4252.92872385
 2568.08578441 4564.62234629 1871.72764491 4150.76479239 1839.39022703]
total_rewards_mean           3493.3734245154033
total_rewards_std            1211.4904042056648
total_rewards_max            4846.173153561971
total_rewards_min            1839.3902270264052
Number of train steps total  1608000
Number of env steps total    2012000
Number of rollouts total     0
Train Time (s)               119.3704284238629
(Previous) Eval Time (s)     24.20066452678293
Sample Time (s)              17.997126631438732
Epoch Time (s)               161.56821958208457
Total Train Time (s)         62398.81643586932
Epoch                        401
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:51:34.622210 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #401 | Epoch Duration: 160.26058316230774
2020-01-12 16:51:34.622408 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #401 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1249142
Z variance train             0.009711415
KL Divergence                24.7622
KL Loss                      2.47622
QF Loss                      917.3228
VF Loss                      195.72913
Policy Loss                  -1631.3005
Q Predictions Mean           1629.31
Q Predictions Std            331.64752
Q Predictions Max            1833.4882
Q Predictions Min            -412.0861
V Predictions Mean           1638.081
V Predictions Std            317.12286
V Predictions Max            1833.3745
V Predictions Min            -405.28384
Log Pis Mean                 1.3509787
Log Pis Std                  3.5240448
Log Pis Max                  26.810703
Log Pis Min                  -9.726686
Policy mu Mean               0.061954554
Policy mu Std                0.64617497
Policy mu Max                3.3758435
Policy mu Min                -2.7792141
Policy log std Mean          -1.1880153
Policy log std Std           0.29861823
Policy log std Max           0.013040185
Policy log std Min           -2.6296103
Z mean eval                  1.0749862
Z variance eval              0.0070432327
total_rewards                [3080.53437378 4639.03467142 1784.27735987   38.41528502 4585.79064051
   16.03828967   50.02191014 3728.888741   4353.26246476 4666.99661302]
total_rewards_mean           2694.32603492011
total_rewards_std            1930.5472345929616
total_rewards_max            4666.996613024071
total_rewards_min            16.038289671138884
Number of train steps total  1612000
Number of env steps total    2017000
Number of rollouts total     0
Train Time (s)               123.58337549911812
(Previous) Eval Time (s)     22.892729275859892
Sample Time (s)              17.598576129879802
Epoch Time (s)               164.07468090485781
Total Train Time (s)         62557.94532689173
Epoch                        402
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:54:13.753513 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #402 | Epoch Duration: 159.1309745311737
2020-01-12 16:54:13.753716 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #402 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0761998
Z variance train             0.0070186155
KL Divergence                25.12085
KL Loss                      2.512085
QF Loss                      1502.2632
VF Loss                      400.19116
Policy Loss                  -1592.1425
Q Predictions Mean           1591.5261
Q Predictions Std            399.15137
Q Predictions Max            1863.641
Q Predictions Min            -418.1353
V Predictions Mean           1582.6287
V Predictions Std            393.32077
V Predictions Max            1857.7676
V Predictions Min            -375.8119
Log Pis Mean                 1.3607687
Log Pis Std                  3.2002196
Log Pis Max                  13.428381
Log Pis Min                  -8.312261
Policy mu Mean               0.01717974
Policy mu Std                0.63722646
Policy mu Max                2.2315385
Policy mu Min                -2.2251964
Policy log std Mean          -1.1828141
Policy log std Std           0.3366697
Policy log std Max           -0.25349796
Policy log std Min           -2.8561907
Z mean eval                  1.0911987
Z variance eval              0.008174165
total_rewards                [ 733.27950139 4524.02500265 4488.17628079 4545.62960794 4607.0123996
 4667.6148226  4220.15482058 4469.5306383  4496.59219183 2744.37239568]
total_rewards_mean           3949.6387661355357
total_rewards_std            1198.4588222610143
total_rewards_max            4667.614822598942
total_rewards_min            733.2795013875933
Number of train steps total  1616000
Number of env steps total    2022000
Number of rollouts total     0
Train Time (s)               116.49375406419858
(Previous) Eval Time (s)     17.94874921394512
Sample Time (s)              17.71779060224071
Epoch Time (s)               152.16029388038442
Total Train Time (s)         62715.97085135197
Epoch                        403
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:56:51.781802 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #403 | Epoch Duration: 158.02796912193298
2020-01-12 16:56:51.781965 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #403 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0930332
Z variance train             0.008188168
KL Divergence                24.811977
KL Loss                      2.4811978
QF Loss                      1540.398
VF Loss                      358.45367
Policy Loss                  -1632.015
Q Predictions Mean           1633.6919
Q Predictions Std            346.71185
Q Predictions Max            1869.3188
Q Predictions Min            -400.49625
V Predictions Mean           1622.3691
V Predictions Std            344.17496
V Predictions Max            1855.8191
V Predictions Min            -418.59344
Log Pis Mean                 1.4549444
Log Pis Std                  3.2317452
Log Pis Max                  12.588602
Log Pis Min                  -10.181359
Policy mu Mean               0.040921904
Policy mu Std                0.6640932
Policy mu Max                3.0030742
Policy mu Min                -3.3705
Policy log std Mean          -1.1628027
Policy log std Std           0.30429557
Policy log std Max           -0.13176787
Policy log std Min           -2.2958732
Z mean eval                  1.099612
Z variance eval              0.012915716
total_rewards                [4338.1283205  1887.56645259  362.34256519 1313.24879968 1107.31536224
 2057.71439052 1384.17724867 4304.60650601 2596.49313057 1922.62106377]
total_rewards_mean           2127.4213839742515
total_rewards_std            1237.8662898803527
total_rewards_max            4338.128320497171
total_rewards_min            362.3425651913042
Number of train steps total  1620000
Number of env steps total    2027000
Number of rollouts total     0
Train Time (s)               119.78010267391801
(Previous) Eval Time (s)     23.81609756918624
Sample Time (s)              17.820891408249736
Epoch Time (s)               161.41709165135399
Total Train Time (s)         62866.64316465054
Epoch                        404
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:59:22.462872 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #404 | Epoch Duration: 150.680734872818
2020-01-12 16:59:22.463159 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #404 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0987089
Z variance train             0.012917948
KL Divergence                22.931225
KL Loss                      2.2931225
QF Loss                      596.2566
VF Loss                      151.95657
Policy Loss                  -1615.5741
Q Predictions Mean           1615.962
Q Predictions Std            315.98227
Q Predictions Max            1819.9811
Q Predictions Min            -390.9986
V Predictions Mean           1616.7356
V Predictions Std            317.2536
V Predictions Max            1822.5936
V Predictions Min            -387.1141
Log Pis Mean                 1.390486
Log Pis Std                  3.1158175
Log Pis Max                  13.144946
Log Pis Min                  -6.662245
Policy mu Mean               -0.017339224
Policy mu Std                0.6486714
Policy mu Max                2.2517953
Policy mu Min                -3.0824585
Policy log std Mean          -1.1607919
Policy log std Std           0.29344752
Policy log std Max           -0.10745609
Policy log std Min           -2.7057216
Z mean eval                  1.1621034
Z variance eval              0.015255401
total_rewards                [4265.37966728 2548.70502396 4461.78966908 4526.81719767 4430.93181961
 4323.09394339 2896.75482363 4407.84991295 4377.54780097 4236.04649426]
total_rewards_mean           4047.491635278505
total_rewards_std            672.0683498625277
total_rewards_max            4526.817197666657
total_rewards_min            2548.705023956025
Number of train steps total  1624000
Number of env steps total    2032000
Number of rollouts total     0
Train Time (s)               122.1291044591926
(Previous) Eval Time (s)     13.079443131107837
Sample Time (s)              17.44380332622677
Epoch Time (s)               152.6523509165272
Total Train Time (s)         63031.3544174619
Epoch                        405
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:02:07.178511 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #405 | Epoch Duration: 164.71512722969055
2020-01-12 17:02:07.178785 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #405 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.16112
Z variance train             0.015320679
KL Divergence                23.193718
KL Loss                      2.319372
QF Loss                      569.7837
VF Loss                      130.09549
Policy Loss                  -1644.4222
Q Predictions Mean           1647.8326
Q Predictions Std            221.42476
Q Predictions Max            1844.6525
Q Predictions Min            -235.65016
V Predictions Mean           1641.8057
V Predictions Std            222.66568
V Predictions Max            1844.3838
V Predictions Min            -248.73442
Log Pis Mean                 1.5601629
Log Pis Std                  3.070809
Log Pis Max                  11.774186
Log Pis Min                  -6.7653923
Policy mu Mean               -0.0034425657
Policy mu Std                0.6377648
Policy mu Max                3.2402306
Policy mu Min                -2.3532367
Policy log std Mean          -1.196228
Policy log std Std           0.28486443
Policy log std Max           -0.24687374
Policy log std Min           -2.5164149
Z mean eval                  1.1030267
Z variance eval              0.035591625
total_rewards                [4277.4838368  1393.69176231 3338.88815881 4723.40752274 4745.16790658
 4672.26281832 2111.14391137 4402.49152446 4832.76950737 4564.31007871]
total_rewards_mean           3906.1617027473535
total_rewards_std            1161.5124249766009
total_rewards_max            4832.769507371599
total_rewards_min            1393.6917623143586
Number of train steps total  1628000
Number of env steps total    2037000
Number of rollouts total     0
Train Time (s)               125.9238973991014
(Previous) Eval Time (s)     25.14191683102399
Sample Time (s)              18.28328443178907
Epoch Time (s)               169.34909866191447
Total Train Time (s)         63199.577305570245
Epoch                        406
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:04:55.408741 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #406 | Epoch Duration: 168.229722738266
2020-01-12 17:04:55.409037 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #406 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1028825
Z variance train             0.035627425
KL Divergence                20.595705
KL Loss                      2.0595706
QF Loss                      1078.8434
VF Loss                      222.23175
Policy Loss                  -1630.5576
Q Predictions Mean           1633.5737
Q Predictions Std            308.6861
Q Predictions Max            1834.8734
Q Predictions Min            -414.8468
V Predictions Mean           1630.1167
V Predictions Std            311.64206
V Predictions Max            1833.1714
V Predictions Min            -398.21512
Log Pis Mean                 1.6245041
Log Pis Std                  3.108417
Log Pis Max                  13.998159
Log Pis Min                  -7.7604027
Policy mu Mean               -0.0029083784
Policy mu Std                0.6297706
Policy mu Max                3.0810618
Policy mu Min                -2.6813126
Policy log std Mean          -1.195305
Policy log std Std           0.301075
Policy log std Max           -0.008947134
Policy log std Min           -2.8404255
Z mean eval                  1.104214
Z variance eval              0.01974066
total_rewards                [4319.92712614 4660.19718303 4488.56571341 2787.65026987 3865.95344497
 -275.2998685   457.95099506 4509.4996432  2164.72385348 4232.69950365]
total_rewards_mean           3121.186786430901
total_rewards_std            1704.342144195003
total_rewards_max            4660.197183031689
total_rewards_min            -275.29986849615113
Number of train steps total  1632000
Number of env steps total    2042000
Number of rollouts total     0
Train Time (s)               114.53287274297327
(Previous) Eval Time (s)     24.02222321787849
Sample Time (s)              19.260064341593534
Epoch Time (s)               157.8151603024453
Total Train Time (s)         63354.834444127046
Epoch                        407
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:07:30.669568 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #407 | Epoch Duration: 155.2603087425232
2020-01-12 17:07:30.669784 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #407 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1026031
Z variance train             0.01975992
KL Divergence                21.541845
KL Loss                      2.1541846
QF Loss                      1333.3118
VF Loss                      456.75262
Policy Loss                  -1612.4828
Q Predictions Mean           1616.2892
Q Predictions Std            345.53595
Q Predictions Max            1844.616
Q Predictions Min            -357.86716
V Predictions Mean           1619.3794
V Predictions Std            335.40396
V Predictions Max            1832.4852
V Predictions Min            -335.24496
Log Pis Mean                 1.8686192
Log Pis Std                  3.6925054
Log Pis Max                  20.584267
Log Pis Min                  -6.4801617
Policy mu Mean               0.032770902
Policy mu Std                0.69217193
Policy mu Max                4.0865664
Policy mu Min                -2.8441076
Policy log std Mean          -1.2091258
Policy log std Std           0.31880435
Policy log std Max           0.18896294
Policy log std Min           -2.4828885
Z mean eval                  1.0897045
Z variance eval              0.012411289
total_rewards                [4694.50314046 3402.72031411 4737.20700046 4342.79519716 4815.11833133
 4548.14091251 4915.28472559 4486.81954041 1750.4836522  4714.21647622]
total_rewards_mean           4240.728929044979
total_rewards_std            923.6125211903236
total_rewards_max            4915.284725586599
total_rewards_min            1750.48365219966
Number of train steps total  1636000
Number of env steps total    2047000
Number of rollouts total     0
Train Time (s)               125.01614949619398
(Previous) Eval Time (s)     21.46706021670252
Sample Time (s)              18.184655881486833
Epoch Time (s)               164.66786559438333
Total Train Time (s)         63522.803147341125
Epoch                        408
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:10:18.643620 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #408 | Epoch Duration: 167.97368121147156
2020-01-12 17:10:18.643853 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #408 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0895216
Z variance train             0.012393648
KL Divergence                23.722729
KL Loss                      2.372273
QF Loss                      538.3445
VF Loss                      148.09299
Policy Loss                  -1625.6182
Q Predictions Mean           1627.7507
Q Predictions Std            328.76437
Q Predictions Max            1856.4862
Q Predictions Min            -322.63947
V Predictions Mean           1631.1594
V Predictions Std            322.5764
V Predictions Max            1857.5258
V Predictions Min            -307.4982
Log Pis Mean                 1.7145506
Log Pis Std                  3.442957
Log Pis Max                  15.77018
Log Pis Min                  -7.327717
Policy mu Mean               0.0054058833
Policy mu Std                0.6507384
Policy mu Max                2.5295198
Policy mu Min                -2.4171312
Policy log std Mean          -1.2065569
Policy log std Std           0.33855206
Policy log std Max           -0.22165513
Policy log std Min           -3.2338948
Z mean eval                  1.0887195
Z variance eval              0.0071253576
total_rewards                [4395.54544314 4382.90075423 2238.68071361 4746.46738849 4786.62209947
 4257.57818275 3022.40199883 4682.50246049 1788.08311028 3789.00607993]
total_rewards_mean           3808.978823122903
total_rewards_std            1031.5697041462777
total_rewards_max            4786.622099471256
total_rewards_min            1788.0831102768582
Number of train steps total  1640000
Number of env steps total    2052000
Number of rollouts total     0
Train Time (s)               115.7232968150638
(Previous) Eval Time (s)     24.77255758503452
Sample Time (s)              19.026748795062304
Epoch Time (s)               159.52260319516063
Total Train Time (s)         63680.470618955325
Epoch                        409
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:12:56.313627 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #409 | Epoch Duration: 157.6696219444275
2020-01-12 17:12:56.313782 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #409 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0888067
Z variance train             0.007135739
KL Divergence                24.813423
KL Loss                      2.4813423
QF Loss                      866.0825
VF Loss                      232.23773
Policy Loss                  -1606.9817
Q Predictions Mean           1606.5916
Q Predictions Std            353.93634
Q Predictions Max            1843.9741
Q Predictions Min            -339.46295
V Predictions Mean           1609.1271
V Predictions Std            350.2135
V Predictions Max            1859.7433
V Predictions Min            -322.85544
Log Pis Mean                 1.5631359
Log Pis Std                  3.4937632
Log Pis Max                  19.236269
Log Pis Min                  -6.5463066
Policy mu Mean               0.008204854
Policy mu Std                0.65195286
Policy mu Max                3.1973085
Policy mu Min                -2.910286
Policy log std Mean          -1.1789408
Policy log std Std           0.3327443
Policy log std Max           0.092740655
Policy log std Min           -3.1920958
Z mean eval                  1.0727551
Z variance eval              0.012374511
total_rewards                [4449.53127021 4789.89179999 4816.48319215 4493.16689024 4477.6703933
 1477.79157752 3401.87752094 2796.41884853  482.83668398  455.63926786]
total_rewards_mean           3164.1307444714894
total_rewards_std            1675.6516610046056
total_rewards_max            4816.483192154861
total_rewards_min            455.6392678550249
Number of train steps total  1644000
Number of env steps total    2057000
Number of rollouts total     0
Train Time (s)               117.39577100193128
(Previous) Eval Time (s)     22.919227975886315
Sample Time (s)              17.854917123913765
Epoch Time (s)               158.16991610173136
Total Train Time (s)         63834.358550612815
Epoch                        410
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:15:30.204553 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #410 | Epoch Duration: 153.89064717292786
2020-01-12 17:15:30.204747 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #410 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0734596
Z variance train             0.012393624
KL Divergence                24.239246
KL Loss                      2.4239247
QF Loss                      640.374
VF Loss                      117.0661
Policy Loss                  -1613.6431
Q Predictions Mean           1613.8967
Q Predictions Std            348.82245
Q Predictions Max            1855.3474
Q Predictions Min            -425.93164
V Predictions Mean           1615.7545
V Predictions Std            346.6304
V Predictions Max            1852.06
V Predictions Min            -418.25916
Log Pis Mean                 1.1983545
Log Pis Std                  3.3753054
Log Pis Max                  13.062421
Log Pis Min                  -6.341135
Policy mu Mean               0.016398102
Policy mu Std                0.6258555
Policy mu Max                2.4273674
Policy mu Min                -2.571486
Policy log std Mean          -1.1892915
Policy log std Std           0.317099
Policy log std Max           0.12009859
Policy log std Min           -2.962946
Z mean eval                  1.0871432
Z variance eval              0.014526598
total_rewards                [4520.84609285 4659.76864861 4740.54903257 4650.25708102 4707.51922579
 4916.6015951  4817.73821949 4298.35510185 4627.16991112 4836.05327556]
total_rewards_mean           4677.485818395451
total_rewards_std            166.95292759045978
total_rewards_max            4916.601595097862
total_rewards_min            4298.355101847696
Number of train steps total  1648000
Number of env steps total    2062000
Number of rollouts total     0
Train Time (s)               113.06958041898906
(Previous) Eval Time (s)     18.639640467241406
Sample Time (s)              17.644945380743593
Epoch Time (s)               149.35416626697406
Total Train Time (s)         63993.38387044566
Epoch                        411
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:18:09.237741 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #411 | Epoch Duration: 159.03283882141113
2020-01-12 17:18:09.238019 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #411 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0862619
Z variance train             0.014538528
KL Divergence                24.556456
KL Loss                      2.4556456
QF Loss                      1063.2546
VF Loss                      233.42755
Policy Loss                  -1624.7234
Q Predictions Mean           1625.2555
Q Predictions Std            364.87515
Q Predictions Max            1859.7742
Q Predictions Min            -420.7871
V Predictions Mean           1630.1034
V Predictions Std            362.0953
V Predictions Max            1863.0604
V Predictions Min            -420.37225
Log Pis Mean                 1.2882121
Log Pis Std                  2.9149806
Log Pis Max                  11.040674
Log Pis Min                  -5.5512495
Policy mu Mean               0.0008773075
Policy mu Std                0.58850795
Policy mu Max                2.787394
Policy mu Min                -3.0046256
Policy log std Mean          -1.2190232
Policy log std Std           0.29715565
Policy log std Max           -0.1816268
Policy log std Min           -2.5732455
Z mean eval                  1.0965116
Z variance eval              0.009540111
total_rewards                [2682.86960964 3980.95937017  209.23699112 4509.91809193 3616.8864373
 4607.53943814 4775.88670814 4478.80836191 3530.39736897 4404.84970006]
total_rewards_mean           3679.735207736766
total_rewards_std            1306.5591453113293
total_rewards_max            4775.886708136384
total_rewards_min            209.23699112040475
Number of train steps total  1652000
Number of env steps total    2067000
Number of rollouts total     0
Train Time (s)               114.1182951265946
(Previous) Eval Time (s)     28.317944320850074
Sample Time (s)              18.14987194398418
Epoch Time (s)               160.58611139142886
Total Train Time (s)         64148.1394270584
Epoch                        412
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:20:43.995058 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #412 | Epoch Duration: 154.75684475898743
2020-01-12 17:20:43.995218 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #412 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0966691
Z variance train             0.009524152
KL Divergence                25.159687
KL Loss                      2.5159688
QF Loss                      984.81885
VF Loss                      385.4639
Policy Loss                  -1678.5952
Q Predictions Mean           1680.3761
Q Predictions Std            212.67575
Q Predictions Max            1864.4625
Q Predictions Min            -315.7204
V Predictions Mean           1677.5359
V Predictions Std            202.08488
V Predictions Max            1863.6025
V Predictions Min            -317.6544
Log Pis Mean                 1.6466184
Log Pis Std                  3.2267094
Log Pis Max                  13.555048
Log Pis Min                  -8.986043
Policy mu Mean               -0.018997815
Policy mu Std                0.6439849
Policy mu Max                2.5354836
Policy mu Min                -2.901249
Policy log std Mean          -1.2106229
Policy log std Std           0.3134839
Policy log std Max           -0.25930262
Policy log std Min           -2.7202382
Z mean eval                  1.1143563
Z variance eval              0.006677944
total_rewards                [4709.1511606  4770.38140644 4607.95122278 2471.44775531 4842.04683251
 4575.77362626  545.38279212   48.79120213 2845.11453407 1026.95032538]
total_rewards_mean           3044.299085761001
total_rewards_std            1828.3487391788685
total_rewards_max            4842.046832510399
total_rewards_min            48.791202125745826
Number of train steps total  1656000
Number of env steps total    2072000
Number of rollouts total     0
Train Time (s)               114.09679338289425
(Previous) Eval Time (s)     22.48841410689056
Sample Time (s)              18.13670382509008
Epoch Time (s)               154.7219113148749
Total Train Time (s)         64298.96479862137
Epoch                        413
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:23:14.827812 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #413 | Epoch Duration: 150.83241653442383
2020-01-12 17:23:14.828106 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #413 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.113908
Z variance train             0.0066789733
KL Divergence                25.775667
KL Loss                      2.5775669
QF Loss                      756.9048
VF Loss                      165.73724
Policy Loss                  -1631.4714
Q Predictions Mean           1633.54
Q Predictions Std            363.1023
Q Predictions Max            1880.3231
Q Predictions Min            -422.2683
V Predictions Mean           1632.426
V Predictions Std            361.4361
V Predictions Max            1884.4386
V Predictions Min            -414.52414
Log Pis Mean                 1.5848017
Log Pis Std                  3.4051058
Log Pis Max                  14.635388
Log Pis Min                  -7.0031304
Policy mu Mean               0.02720074
Policy mu Std                0.62908185
Policy mu Max                2.3091767
Policy mu Min                -2.7201445
Policy log std Mean          -1.2115622
Policy log std Std           0.33874413
Policy log std Max           -0.16767871
Policy log std Min           -3.6125145
Z mean eval                  1.123821
Z variance eval              0.007792684
total_rewards                [2835.35832422 1761.51117655 4269.08681368 4468.03757091 4314.2976016
 4806.77982069 4584.31535206  400.80369431   25.53372862  193.10734143]
total_rewards_mean           2765.883142406901
total_rewards_std            1891.0942372097554
total_rewards_max            4806.77982069123
total_rewards_min            25.533728616506863
Number of train steps total  1660000
Number of env steps total    2077000
Number of rollouts total     0
Train Time (s)               116.28638805402443
(Previous) Eval Time (s)     18.59862239798531
Sample Time (s)              18.030706552788615
Epoch Time (s)               152.91571700479835
Total Train Time (s)         64452.76608142862
Epoch                        414
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:25:48.635623 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #414 | Epoch Duration: 153.80727076530457
2020-01-12 17:25:48.635948 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #414 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1240286
Z variance train             0.0077860327
KL Divergence                26.138361
KL Loss                      2.613836
QF Loss                      1365.662
VF Loss                      174.20282
Policy Loss                  -1633.6622
Q Predictions Mean           1634.984
Q Predictions Std            315.9524
Q Predictions Max            1848.8085
Q Predictions Min            -400.38498
V Predictions Mean           1634.6321
V Predictions Std            313.05875
V Predictions Max            1848.507
V Predictions Min            -445.09427
Log Pis Mean                 1.6495284
Log Pis Std                  3.2955878
Log Pis Max                  13.261137
Log Pis Min                  -7.1901884
Policy mu Mean               -0.037848823
Policy mu Std                0.6757437
Policy mu Max                2.6733978
Policy mu Min                -2.6672628
Policy log std Mean          -1.1766459
Policy log std Std           0.3203331
Policy log std Max           -0.27073038
Policy log std Min           -3.228789
Z mean eval                  1.1213025
Z variance eval              0.009348385
total_rewards                [4372.95460754 4788.20635855   26.53385095 1938.3450726  2565.70069527
 1438.58579674 4807.08607228 5045.14071172 4450.25790408 4640.70664607]
total_rewards_mean           3407.351771578948
total_rewards_std            1681.127624300239
total_rewards_max            5045.1407117169
total_rewards_min            26.53385094886134
Number of train steps total  1664000
Number of env steps total    2082000
Number of rollouts total     0
Train Time (s)               119.22237623017281
(Previous) Eval Time (s)     19.48985127499327
Sample Time (s)              17.876397578511387
Epoch Time (s)               156.58862508367747
Total Train Time (s)         64609.5959042781
Epoch                        415
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:28:25.467857 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #415 | Epoch Duration: 156.83168649673462
2020-01-12 17:28:25.468045 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #415 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.121494
Z variance train             0.009359617
KL Divergence                26.647146
KL Loss                      2.6647146
QF Loss                      870.4125
VF Loss                      311.76205
Policy Loss                  -1674.526
Q Predictions Mean           1678.1096
Q Predictions Std            316.74564
Q Predictions Max            1910.7595
Q Predictions Min            -441.16144
V Predictions Mean           1664.0403
V Predictions Std            312.81003
V Predictions Max            1903.0438
V Predictions Min            -384.1071
Log Pis Mean                 1.4539624
Log Pis Std                  2.8885422
Log Pis Max                  13.039553
Log Pis Min                  -6.375914
Policy mu Mean               -0.0046096602
Policy mu Std                0.622298
Policy mu Max                2.3672798
Policy mu Min                -2.4651587
Policy log std Mean          -1.1987135
Policy log std Std           0.29183772
Policy log std Max           -0.27267665
Policy log std Min           -2.6305985
Z mean eval                  1.1062167
Z variance eval              0.007347837
total_rewards                [4170.4201927   367.72165261 4933.60829349 1204.53741469 4607.29958825
 4546.60825514  481.77247647 3726.59182981   98.28615774 4000.46169339]
total_rewards_mean           2813.7307554289705
total_rewards_std            1902.104591491469
total_rewards_max            4933.608293490475
total_rewards_min            98.28615773570198
Number of train steps total  1668000
Number of env steps total    2087000
Number of rollouts total     0
Train Time (s)               119.16396272508428
(Previous) Eval Time (s)     19.7326726783067
Sample Time (s)              18.304612585809082
Epoch Time (s)               157.20124798920006
Total Train Time (s)         64764.31401892891
Epoch                        416
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:31:00.189187 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #416 | Epoch Duration: 154.72100448608398
2020-01-12 17:31:00.189387 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #416 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1063224
Z variance train             0.0073699737
KL Divergence                27.9351
KL Loss                      2.7935102
QF Loss                      1017.71655
VF Loss                      477.92792
Policy Loss                  -1652.0266
Q Predictions Mean           1653.4016
Q Predictions Std            306.8552
Q Predictions Max            1884.3247
Q Predictions Min            -309.1228
V Predictions Mean           1644.0067
V Predictions Std            309.04544
V Predictions Max            1884.9496
V Predictions Min            -324.71683
Log Pis Mean                 1.9277812
Log Pis Std                  3.749809
Log Pis Max                  17.426456
Log Pis Min                  -6.344451
Policy mu Mean               0.011803984
Policy mu Std                0.67379725
Policy mu Max                2.9146347
Policy mu Min                -2.9001768
Policy log std Mean          -1.2246437
Policy log std Std           0.36893472
Policy log std Max           -0.31185603
Policy log std Min           -2.8667653
Z mean eval                  1.091987
Z variance eval              0.008592368
total_rewards                [5025.06380331 4904.01364366 2159.31843016 4167.4576563   180.92042043
 3249.72172409 4806.68793134 4770.6976839  3019.7839441   913.01964331]
total_rewards_mean           3319.668488059559
total_rewards_std            1659.4853244115081
total_rewards_max            5025.0638033053365
total_rewards_min            180.920420428252
Number of train steps total  1672000
Number of env steps total    2092000
Number of rollouts total     0
Train Time (s)               114.23639263026416
(Previous) Eval Time (s)     17.252111651934683
Sample Time (s)              18.693938054144382
Epoch Time (s)               150.18244233634323
Total Train Time (s)         64916.52040106058
Epoch                        417
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:33:32.402462 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #417 | Epoch Duration: 152.2129204273224
2020-01-12 17:33:32.402756 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #417 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0930156
Z variance train             0.008601707
KL Divergence                27.44091
KL Loss                      2.744091
QF Loss                      758.00134
VF Loss                      128.22618
Policy Loss                  -1667.9983
Q Predictions Mean           1671.2606
Q Predictions Std            282.2383
Q Predictions Max            1884.7463
Q Predictions Min            -406.99307
V Predictions Mean           1672.5288
V Predictions Std            280.7491
V Predictions Max            1888.3204
V Predictions Min            -373.19974
Log Pis Mean                 1.8007723
Log Pis Std                  3.1231754
Log Pis Max                  12.227398
Log Pis Min                  -7.7555103
Policy mu Mean               0.03657049
Policy mu Std                0.62165064
Policy mu Max                2.6774626
Policy mu Min                -2.63086
Policy log std Mean          -1.2078284
Policy log std Std           0.3160632
Policy log std Max           -0.25972873
Policy log std Min           -2.797049
Z mean eval                  1.1123905
Z variance eval              0.013494303
total_rewards                [2415.73182691  760.32771026 4628.51137952 3307.86526257  690.10598744
 3298.33114062 1644.11388211 3707.43219546 1675.4690719  2939.39147968]
total_rewards_mean           2506.727993646556
total_rewards_std            1232.5872683479784
total_rewards_max            4628.51137951913
total_rewards_min            690.1059874370056
Number of train steps total  1676000
Number of env steps total    2097000
Number of rollouts total     0
Train Time (s)               121.31067937426269
(Previous) Eval Time (s)     19.28220734326169
Sample Time (s)              17.322432426270097
Epoch Time (s)               157.91531914379448
Total Train Time (s)         65073.28355847858
Epoch                        418
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:36:09.168501 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #418 | Epoch Duration: 156.7655463218689
2020-01-12 17:36:09.168717 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #418 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1116977
Z variance train             0.013374897
KL Divergence                25.877552
KL Loss                      2.5877552
QF Loss                      738.11926
VF Loss                      442.10223
Policy Loss                  -1700.4564
Q Predictions Mean           1702.2012
Q Predictions Std            203.59642
Q Predictions Max            1894.7522
Q Predictions Min            -445.1958
V Predictions Mean           1694.7972
V Predictions Std            202.33604
V Predictions Max            1879.9994
V Predictions Min            -422.2457
Log Pis Mean                 2.0484662
Log Pis Std                  3.2856197
Log Pis Max                  15.176219
Log Pis Min                  -5.4290695
Policy mu Mean               0.009810591
Policy mu Std                0.65408707
Policy mu Max                5.729842
Policy mu Min                -2.909911
Policy log std Mean          -1.2305462
Policy log std Std           0.32816124
Policy log std Max           1.2071354
Policy log std Min           -3.0037243
Z mean eval                  1.0929624
Z variance eval              0.012690321
total_rewards                [4333.33512826 4641.37595961 1629.36709012 2774.33245085 4491.61400897
  441.85425246 3860.72121801 1943.97342437 4377.80659427 1015.89966902]
total_rewards_mean           2951.0279795930674
total_rewards_std            1511.2093081094415
total_rewards_max            4641.375959614805
total_rewards_min            441.8542524618531
Number of train steps total  1680000
Number of env steps total    2102000
Number of rollouts total     0
Train Time (s)               119.77806607168168
(Previous) Eval Time (s)     18.13216237956658
Sample Time (s)              18.99569738516584
Epoch Time (s)               156.9059258364141
Total Train Time (s)         65229.45214276016
Epoch                        419
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:38:45.340904 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #419 | Epoch Duration: 156.17204356193542
2020-01-12 17:38:45.341112 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #419 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0930352
Z variance train             0.012688914
KL Divergence                25.647968
KL Loss                      2.564797
QF Loss                      1132.5798
VF Loss                      978.3683
Policy Loss                  -1644.5421
Q Predictions Mean           1643.5295
Q Predictions Std            401.76926
Q Predictions Max            1911.7412
Q Predictions Min            -349.08316
V Predictions Mean           1635.0748
V Predictions Std            392.0681
V Predictions Max            1902.2742
V Predictions Min            -324.2636
Log Pis Mean                 1.7761751
Log Pis Std                  4.0605793
Log Pis Max                  20.487162
Log Pis Min                  -7.292089
Policy mu Mean               -0.019535556
Policy mu Std                0.674301
Policy mu Max                4.26859
Policy mu Min                -2.5577352
Policy log std Mean          -1.2159144
Policy log std Std           0.38891307
Policy log std Max           -0.2358973
Policy log std Min           -3.3368375
Z mean eval                  1.1327069
Z variance eval              0.01412954
total_rewards                [2637.72367827 4716.11884428 4783.98304463 4774.1605457  4786.2687755
 4605.27697575 4759.70017509  838.08854498 3216.57585963 4404.07324581]
total_rewards_mean           3952.196968965007
total_rewards_std            1260.7998026945684
total_rewards_max            4786.268775503901
total_rewards_min            838.0885449767154
Number of train steps total  1684000
Number of env steps total    2107000
Number of rollouts total     0
Train Time (s)               119.13006026716903
(Previous) Eval Time (s)     17.39794633584097
Sample Time (s)              18.34761362709105
Epoch Time (s)               154.87562023010105
Total Train Time (s)         65390.061109612696
Epoch                        420
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:41:25.957643 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #420 | Epoch Duration: 160.61635780334473
2020-01-12 17:41:25.957927 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #420 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1312096
Z variance train             0.014073858
KL Divergence                25.034187
KL Loss                      2.5034187
QF Loss                      1158.3018
VF Loss                      4410.6763
Policy Loss                  -1647.1396
Q Predictions Mean           1648.354
Q Predictions Std            357.02267
Q Predictions Max            1895.9092
Q Predictions Min            -460.115
V Predictions Mean           1656.2896
V Predictions Std            333.52567
V Predictions Max            1898.7574
V Predictions Min            -438.13452
Log Pis Mean                 1.8758456
Log Pis Std                  3.2131293
Log Pis Max                  15.567306
Log Pis Min                  -5.957678
Policy mu Mean               0.021193037
Policy mu Std                0.6488109
Policy mu Max                2.551282
Policy mu Min                -2.8379278
Policy log std Mean          -1.2163336
Policy log std Std           0.33879218
Policy log std Max           -0.16867578
Policy log std Min           -3.1779215
Z mean eval                  1.1024492
Z variance eval              0.0078984015
total_rewards                [-284.34819266 4734.02053913  214.97775766 4756.54404752 4819.75062188
 4835.64635261 4760.40462223 4566.62386377 4702.79305158 3898.93754221]
total_rewards_mean           3700.535020592207
total_rewards_std            1888.6527080090725
total_rewards_max            4835.6463526058305
total_rewards_min            -284.3481926610567
Number of train steps total  1688000
Number of env steps total    2112000
Number of rollouts total     0
Train Time (s)               120.59074553195387
(Previous) Eval Time (s)     23.13835013192147
Sample Time (s)              18.174273766111583
Epoch Time (s)               161.90336942998692
Total Train Time (s)         65553.38378552906
Epoch                        421
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:44:09.282677 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #421 | Epoch Duration: 163.3245587348938
2020-01-12 17:44:09.282873 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #421 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1020043
Z variance train             0.0079131145
KL Divergence                26.231167
KL Loss                      2.6231167
QF Loss                      851.3971
VF Loss                      219.69438
Policy Loss                  -1672.6625
Q Predictions Mean           1673.3412
Q Predictions Std            306.25528
Q Predictions Max            1920.4121
Q Predictions Min            -411.8844
V Predictions Mean           1675.7968
V Predictions Std            303.91345
V Predictions Max            1919.0089
V Predictions Min            -406.65735
Log Pis Mean                 1.7549442
Log Pis Std                  3.6826556
Log Pis Max                  26.186874
Log Pis Min                  -7.3613124
Policy mu Mean               0.0463873
Policy mu Std                0.6703743
Policy mu Max                3.6973305
Policy mu Min                -2.980416
Policy log std Mean          -1.199442
Policy log std Std           0.33570558
Policy log std Max           0.42039108
Policy log std Min           -3.452892
Z mean eval                  1.1103069
Z variance eval              0.0037905679
total_rewards                [4411.08386052 4814.12028316 4391.06284365  972.53832066 4636.37812388
 1416.91340128 4737.64776214 4318.8446814  1914.21666291 4593.48755846]
total_rewards_mean           3620.629349805233
total_rewards_std            1453.851247455936
total_rewards_max            4814.120283157091
total_rewards_min            972.538320660837
Number of train steps total  1692000
Number of env steps total    2117000
Number of rollouts total     0
Train Time (s)               125.5443334816955
(Previous) Eval Time (s)     24.559265452902764
Sample Time (s)              19.04078824678436
Epoch Time (s)               169.14438718138263
Total Train Time (s)         65720.56265920727
Epoch                        422
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:46:56.464655 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #422 | Epoch Duration: 167.18165111541748
2020-01-12 17:46:56.464854 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #422 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1123555
Z variance train             0.0037712473
KL Divergence                27.573284
KL Loss                      2.7573285
QF Loss                      841.6984
VF Loss                      370.75925
Policy Loss                  -1680.4917
Q Predictions Mean           1682.0298
Q Predictions Std            278.8055
Q Predictions Max            1883.1022
Q Predictions Min            -215.48448
V Predictions Mean           1668.1519
V Predictions Std            277.29385
V Predictions Max            1862.1844
V Predictions Min            -222.47453
Log Pis Mean                 1.6350024
Log Pis Std                  2.9731648
Log Pis Max                  11.604253
Log Pis Min                  -5.5967307
Policy mu Mean               0.024881292
Policy mu Std                0.5943171
Policy mu Max                2.3126063
Policy mu Min                -2.8819377
Policy log std Mean          -1.2553992
Policy log std Std           0.34163055
Policy log std Max           -0.17081285
Policy log std Min           -3.072485
Z mean eval                  1.0903623
Z variance eval              0.008953567
total_rewards                [3699.75204651 1962.54297747  115.69107188 4307.37916435 4311.25832402
 4278.61423412 2519.7757195  4629.82008043  235.47703    2096.0546901 ]
total_rewards_mean           2815.6365338394603
total_rewards_std            1611.0690667059307
total_rewards_max            4629.820080434334
total_rewards_min            115.6910718791863
Number of train steps total  1696000
Number of env steps total    2122000
Number of rollouts total     0
Train Time (s)               113.6299001313746
(Previous) Eval Time (s)     22.596182425972074
Sample Time (s)              18.24021637486294
Epoch Time (s)               154.4662989322096
Total Train Time (s)         65870.12960356288
Epoch                        423
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:49:26.037727 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #423 | Epoch Duration: 149.57272577285767
2020-01-12 17:49:26.037996 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #423 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0896934
Z variance train             0.008958411
KL Divergence                24.95955
KL Loss                      2.4959552
QF Loss                      584.2811
VF Loss                      188.47511
Policy Loss                  -1641.1235
Q Predictions Mean           1645.3049
Q Predictions Std            419.78738
Q Predictions Max            1920.0406
Q Predictions Min            -438.34903
V Predictions Mean           1647.5201
V Predictions Std            417.47873
V Predictions Max            1915.7406
V Predictions Min            -439.00766
Log Pis Mean                 1.607844
Log Pis Std                  3.2435758
Log Pis Max                  20.965681
Log Pis Min                  -5.8075523
Policy mu Mean               0.020617789
Policy mu Std                0.6350337
Policy mu Max                2.7959685
Policy mu Min                -2.7122042
Policy log std Mean          -1.1962001
Policy log std Std           0.33780128
Policy log std Max           0.067209005
Policy log std Min           -3.101083
Z mean eval                  1.1433579
Z variance eval              0.005410336
total_rewards                [ 500.99355652 4279.05094669 4645.24388265 3337.27536047 1066.73506663
 4701.16279117 4388.50033258  809.18874522 3821.6320439  2969.90865719]
total_rewards_mean           3051.969138301057
total_rewards_std            1571.9293461990026
total_rewards_max            4701.162791166367
total_rewards_min            500.99355651574535
Number of train steps total  1700000
Number of env steps total    2127000
Number of rollouts total     0
Train Time (s)               120.38534235581756
(Previous) Eval Time (s)     17.702268823049963
Sample Time (s)              18.518014511093497
Epoch Time (s)               156.60562568996102
Total Train Time (s)         66027.36679442786
Epoch                        424
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:52:03.282150 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #424 | Epoch Duration: 157.2439374923706
2020-01-12 17:52:03.282423 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #424 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1421479
Z variance train             0.0054232413
KL Divergence                26.334957
KL Loss                      2.6334958
QF Loss                      803.4408
VF Loss                      139.27095
Policy Loss                  -1674.8271
Q Predictions Mean           1677.4504
Q Predictions Std            327.88516
Q Predictions Max            1885.8917
Q Predictions Min            -362.33432
V Predictions Mean           1677.3174
V Predictions Std            330.54153
V Predictions Max            1888.5756
V Predictions Min            -420.20853
Log Pis Mean                 1.8754292
Log Pis Std                  3.6141632
Log Pis Max                  15.026808
Log Pis Min                  -6.868941
Policy mu Mean               0.031361975
Policy mu Std                0.6551067
Policy mu Max                2.3906596
Policy mu Min                -2.7566504
Policy log std Mean          -1.2066283
Policy log std Std           0.34048146
Policy log std Max           0.5106609
Policy log std Min           -2.747881
Z mean eval                  1.1168418
Z variance eval              0.0065406067
total_rewards                [4673.49370711 1813.28947134 5016.84701354 4822.13178201 4488.65841063
 4574.52086758  508.45213673 5002.25182429 4501.24211669 4947.70379909]
total_rewards_mean           4034.859112902115
total_rewards_std            1478.0624570292155
total_rewards_max            5016.8470135438765
total_rewards_min            508.4521367306137
Number of train steps total  1704000
Number of env steps total    2132000
Number of rollouts total     0
Train Time (s)               118.68296920601279
(Previous) Eval Time (s)     18.34025127394125
Sample Time (s)              17.886919654440135
Epoch Time (s)               154.91014013439417
Total Train Time (s)         66188.72878875677
Epoch                        425
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:54:44.648773 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #425 | Epoch Duration: 161.36613941192627
2020-01-12 17:54:44.649015 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #425 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1174449
Z variance train             0.006542581
KL Divergence                26.11628
KL Loss                      2.611628
QF Loss                      1429.5594
VF Loss                      319.0595
Policy Loss                  -1660.9188
Q Predictions Mean           1667.2964
Q Predictions Std            375.35394
Q Predictions Max            1906.8403
Q Predictions Min            -396.04898
V Predictions Mean           1666.0575
V Predictions Std            377.20612
V Predictions Max            1903.0598
V Predictions Min            -405.16354
Log Pis Mean                 1.8307027
Log Pis Std                  3.2923214
Log Pis Max                  21.53709
Log Pis Min                  -6.812648
Policy mu Mean               0.00060488656
Policy mu Std                0.62334913
Policy mu Max                2.677454
Policy mu Min                -2.4171383
Policy log std Mean          -1.2398939
Policy log std Std           0.35120276
Policy log std Max           -0.22510785
Policy log std Min           -4.08705
Z mean eval                  1.1217821
Z variance eval              0.005141628
total_rewards                [4615.95776593 4601.68271307 4760.23947664 4509.56513331 2316.24904793
 4388.72638975 4706.36551737 4484.86556584  801.15923439 4690.80669845]
total_rewards_mean           3987.5617542661334
total_rewards_std            1265.2062329154655
total_rewards_max            4760.239476638543
total_rewards_min            801.1592343858988
Number of train steps total  1708000
Number of env steps total    2137000
Number of rollouts total     0
Train Time (s)               120.14346680697054
(Previous) Eval Time (s)     24.79595033498481
Sample Time (s)              18.228236764203757
Epoch Time (s)               163.1676539061591
Total Train Time (s)         66350.81661575893
Epoch                        426
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:57:26.742746 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #426 | Epoch Duration: 162.09353232383728
2020-01-12 17:57:26.743001 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #426 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1218233
Z variance train             0.0051446375
KL Divergence                27.156202
KL Loss                      2.7156203
QF Loss                      2121.1934
VF Loss                      370.29645
Policy Loss                  -1653.4333
Q Predictions Mean           1655.0537
Q Predictions Std            356.26266
Q Predictions Max            1903.7052
Q Predictions Min            -255.60426
V Predictions Mean           1652.5919
V Predictions Std            353.32224
V Predictions Max            1891.3271
V Predictions Min            -230.95728
Log Pis Mean                 1.7529645
Log Pis Std                  3.5414479
Log Pis Max                  27.19783
Log Pis Min                  -10.0340395
Policy mu Mean               -0.014996376
Policy mu Std                0.6694685
Policy mu Max                2.9441
Policy mu Min                -4.710995
Policy log std Mean          -1.2109636
Policy log std Std           0.31743094
Policy log std Max           -0.1511575
Policy log std Min           -2.942464
Z mean eval                  1.1023891
Z variance eval              0.005270897
total_rewards                [3320.03380252 4433.9008518  4785.28277206 4299.16760551 4580.41720401
 1270.08327237 4286.25930205 4606.02812274 4809.91018918 2829.54002355]
total_rewards_mean           3922.0623145791083
total_rewards_std            1075.198886447924
total_rewards_max            4809.910189184258
total_rewards_min            1270.083272372538
Number of train steps total  1712000
Number of env steps total    2142000
Number of rollouts total     0
Train Time (s)               116.57243048585951
(Previous) Eval Time (s)     23.72152268420905
Sample Time (s)              18.649868179578334
Epoch Time (s)               158.9438213496469
Total Train Time (s)         66510.8445632169
Epoch                        427
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:00:06.778767 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #427 | Epoch Duration: 160.03554105758667
2020-01-12 18:00:06.779064 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #427 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1021926
Z variance train             0.0052883904
KL Divergence                26.957619
KL Loss                      2.695762
QF Loss                      1183.2162
VF Loss                      322.76352
Policy Loss                  -1653.9974
Q Predictions Mean           1655.6068
Q Predictions Std            373.3303
Q Predictions Max            1908.4633
Q Predictions Min            -391.18628
V Predictions Mean           1663.7704
V Predictions Std            373.6221
V Predictions Max            1917.2858
V Predictions Min            -425.8381
Log Pis Mean                 2.1055999
Log Pis Std                  3.5961747
Log Pis Max                  20.805616
Log Pis Min                  -7.133235
Policy mu Mean               -0.00857611
Policy mu Std                0.6559095
Policy mu Max                3.2489066
Policy mu Min                -2.6273513
Policy log std Mean          -1.2601799
Policy log std Std           0.3366475
Policy log std Max           -0.18838859
Policy log std Min           -3.5581598
Z mean eval                  1.101992
Z variance eval              0.011053994
total_rewards                [4618.37393058  420.22738455 4778.60111663 3035.55014416 1055.73563864
  980.41690373  209.21477011 1170.45656533  608.30048386 3159.14304895]
total_rewards_mean           2003.6019986556173
total_rewards_std            1650.7907545909231
total_rewards_max            4778.601116633623
total_rewards_min            209.21477011490424
Number of train steps total  1716000
Number of env steps total    2147000
Number of rollouts total     0
Train Time (s)               122.94570442195982
(Previous) Eval Time (s)     24.81289096456021
Sample Time (s)              19.549125981982797
Epoch Time (s)               167.30772136850283
Total Train Time (s)         66665.42190702679
Epoch                        428
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:02:41.361943 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #428 | Epoch Duration: 154.58264994621277
2020-01-12 18:02:41.362218 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #428 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1013784
Z variance train             0.011026919
KL Divergence                25.603785
KL Loss                      2.5603786
QF Loss                      709.6426
VF Loss                      164.84485
Policy Loss                  -1675.6008
Q Predictions Mean           1679.8848
Q Predictions Std            296.618
Q Predictions Max            1895.777
Q Predictions Min            -385.6484
V Predictions Mean           1679.0966
V Predictions Std            301.69073
V Predictions Max            1901.32
V Predictions Min            -366.95792
Log Pis Mean                 1.8653353
Log Pis Std                  3.2223272
Log Pis Max                  12.299817
Log Pis Min                  -8.196132
Policy mu Mean               -0.013553629
Policy mu Std                0.66752756
Policy mu Max                2.4648924
Policy mu Min                -2.8724098
Policy log std Mean          -1.2133713
Policy log std Std           0.32832253
Policy log std Max           -0.18806982
Policy log std Min           -3.4075217
Z mean eval                  1.1051428
Z variance eval              0.0069968463
total_rewards                [4609.2880292  4732.2992708  3106.39266153 4792.75323474 4598.83246117
 5079.1933465  4873.86081828 4872.18228145 4678.68716471 4866.9924759 ]
total_rewards_mean           4621.048174427152
total_rewards_std            523.1981479127289
total_rewards_max            5079.1933464989415
total_rewards_min            3106.392661527276
Number of train steps total  1720000
Number of env steps total    2152000
Number of rollouts total     0
Train Time (s)               120.42862489167601
(Previous) Eval Time (s)     12.087507381103933
Sample Time (s)              17.79602522868663
Epoch Time (s)               150.31215750146657
Total Train Time (s)         66830.48455073778
Epoch                        429
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:05:26.428297 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #429 | Epoch Duration: 165.0658814907074
2020-01-12 18:05:26.428493 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #429 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1042737
Z variance train             0.006997811
KL Divergence                26.296844
KL Loss                      2.6296844
QF Loss                      2526.4858
VF Loss                      765.97253
Policy Loss                  -1691.333
Q Predictions Mean           1696.4327
Q Predictions Std            214.07977
Q Predictions Max            1887.0768
Q Predictions Min            -341.19235
V Predictions Mean           1697.9868
V Predictions Std            216.02724
V Predictions Max            1891.9303
V Predictions Min            -374.70044
Log Pis Mean                 2.108179
Log Pis Std                  3.6619582
Log Pis Max                  21.239273
Log Pis Min                  -7.424422
Policy mu Mean               0.0067211166
Policy mu Std                0.66814584
Policy mu Max                4.00976
Policy mu Min                -3.5916333
Policy log std Mean          -1.2483032
Policy log std Std           0.36593503
Policy log std Max           0.16266084
Policy log std Min           -3.4934218
Z mean eval                  1.1082748
Z variance eval              0.009230087
total_rewards                [4820.97345357 4631.3463836  4822.80368523 4799.84921008 4357.22174834
 4762.57710481 4622.42314945 4838.95882182 4907.28005845 4692.55226641]
total_rewards_mean           4725.598588175837
total_rewards_std            150.86638635999893
total_rewards_max            4907.280058446862
total_rewards_min            4357.221748339812
Number of train steps total  1724000
Number of env steps total    2157000
Number of rollouts total     0
Train Time (s)               122.555802593939
(Previous) Eval Time (s)     26.840927662793547
Sample Time (s)              19.392886876128614
Epoch Time (s)               168.78961713286117
Total Train Time (s)         66998.97179685067
Epoch                        430
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:08:14.922611 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #430 | Epoch Duration: 168.4939320087433
2020-01-12 18:08:14.922883 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #430 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1088097
Z variance train             0.009239387
KL Divergence                25.727615
KL Loss                      2.5727615
QF Loss                      896.5964
VF Loss                      263.22314
Policy Loss                  -1688.0905
Q Predictions Mean           1692.8118
Q Predictions Std            355.8498
Q Predictions Max            1913.2773
Q Predictions Min            -487.66617
V Predictions Mean           1692.7166
V Predictions Std            354.84448
V Predictions Max            1909.5406
V Predictions Min            -488.78275
Log Pis Mean                 2.0216258
Log Pis Std                  3.6456683
Log Pis Max                  13.382306
Log Pis Min                  -7.533396
Policy mu Mean               0.018158073
Policy mu Std                0.7031619
Policy mu Max                2.6988142
Policy mu Min                -3.2468095
Policy log std Mean          -1.211983
Policy log std Std           0.36456427
Policy log std Max           -0.08073926
Policy log std Min           -3.106831
Z mean eval                  1.144182
Z variance eval              0.009226007
total_rewards                [3428.51625436 4580.98028536 4383.99488877 4898.81953434 4705.58272284
 1889.28260487 4686.28296295 2197.02438087 1611.37103862 4644.78253034]
total_rewards_mean           3702.663720332067
total_rewards_std            1246.2481645819046
total_rewards_max            4898.81953434444
total_rewards_min            1611.371038622147
Number of train steps total  1728000
Number of env steps total    2162000
Number of rollouts total     0
Train Time (s)               111.47059846995398
(Previous) Eval Time (s)     26.544901756104082
Sample Time (s)              17.99059956939891
Epoch Time (s)               156.00609979545698
Total Train Time (s)         67150.73477299418
Epoch                        431
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:10:46.688158 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #431 | Epoch Duration: 151.76509189605713
2020-01-12 18:10:46.688342 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #431 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.143891
Z variance train             0.009214012
KL Divergence                25.675856
KL Loss                      2.5675857
QF Loss                      953.54175
VF Loss                      314.49957
Policy Loss                  -1685.8075
Q Predictions Mean           1689.0552
Q Predictions Std            344.7106
Q Predictions Max            1940.1521
Q Predictions Min            -462.71713
V Predictions Mean           1679.2178
V Predictions Std            348.32275
V Predictions Max            1934.7867
V Predictions Min            -493.1888
Log Pis Mean                 1.9847488
Log Pis Std                  3.673177
Log Pis Max                  16.695126
Log Pis Min                  -7.5841513
Policy mu Mean               -0.012683665
Policy mu Std                0.6762062
Policy mu Max                3.1509495
Policy mu Min                -2.8193262
Policy log std Mean          -1.2291341
Policy log std Std           0.34102514
Policy log std Max           -0.11886549
Policy log std Min           -2.9327455
Z mean eval                  1.1303742
Z variance eval              0.00849079
total_rewards                [1102.96625558 1739.82888707 4549.14029369 4639.64127688 3156.29252221
 4662.55705572 2580.73082128 4634.2676997  1814.97785946 3504.18295194]
total_rewards_mean           3238.45856235223
total_rewards_std            1303.8413003588275
total_rewards_max            4662.557055724692
total_rewards_min            1102.9662555801367
Number of train steps total  1732000
Number of env steps total    2167000
Number of rollouts total     0
Train Time (s)               122.49502517282963
(Previous) Eval Time (s)     22.303581022191793
Sample Time (s)              18.074486228637397
Epoch Time (s)               162.87309242365882
Total Train Time (s)         67312.96975401184
Epoch                        432
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:13:28.930478 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #432 | Epoch Duration: 162.24199986457825
2020-01-12 18:13:28.930712 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #432 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1319788
Z variance train             0.008503861
KL Divergence                26.310062
KL Loss                      2.6310062
QF Loss                      969.35266
VF Loss                      278.1069
Policy Loss                  -1691.0414
Q Predictions Mean           1686.9785
Q Predictions Std            374.98422
Q Predictions Max            1921.0116
Q Predictions Min            -359.33044
V Predictions Mean           1681.8422
V Predictions Std            357.6638
V Predictions Max            1909.2047
V Predictions Min            -375.74493
Log Pis Mean                 1.7103962
Log Pis Std                  3.316844
Log Pis Max                  16.166515
Log Pis Min                  -6.668705
Policy mu Mean               0.040242884
Policy mu Std                0.6552678
Policy mu Max                2.8327456
Policy mu Min                -3.5258753
Policy log std Mean          -1.2012179
Policy log std Std           0.32909396
Policy log std Max           0.77664936
Policy log std Min           -2.8391814
Z mean eval                  1.156801
Z variance eval              0.0063563273
total_rewards                [4834.52743718 3622.58999379 4763.08450762 4438.73695401 5055.75997049
 3337.01821506  609.3146635  4732.28636836 1330.91758876 4148.35856223]
total_rewards_mean           3687.2594260990977
total_rewards_std            1461.8061188476636
total_rewards_max            5055.759970485632
total_rewards_min            609.3146634995837
Number of train steps total  1736000
Number of env steps total    2172000
Number of rollouts total     0
Train Time (s)               121.42810884304345
(Previous) Eval Time (s)     21.672162764705718
Sample Time (s)              17.85439017834142
Epoch Time (s)               160.95466178609058
Total Train Time (s)         67473.18459395412
Epoch                        433
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:16:09.147819 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #433 | Epoch Duration: 160.21691989898682
2020-01-12 18:16:09.148003 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #433 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1573884
Z variance train             0.006370703
KL Divergence                27.016455
KL Loss                      2.7016456
QF Loss                      958.12854
VF Loss                      914.7328
Policy Loss                  -1656.5569
Q Predictions Mean           1659.0654
Q Predictions Std            403.09155
Q Predictions Max            1921.1813
Q Predictions Min            -407.38095
V Predictions Mean           1651.9617
V Predictions Std            383.3822
V Predictions Max            1909.4011
V Predictions Min            -398.933
Log Pis Mean                 2.04973
Log Pis Std                  3.7545552
Log Pis Max                  17.273354
Log Pis Min                  -6.0333896
Policy mu Mean               -0.00021691341
Policy mu Std                0.70251375
Policy mu Max                2.843482
Policy mu Min                -3.4530149
Policy log std Mean          -1.2191002
Policy log std Std           0.35824907
Policy log std Max           -0.08474553
Policy log std Min           -3.110253
Z mean eval                  1.151831
Z variance eval              0.008801019
total_rewards                [5078.45364125 4923.55013615 4899.73460594 4603.71134692 4854.34084403
 4706.82653129 3657.18234779 4532.85904785 2094.11452568 4953.69278705]
total_rewards_mean           4430.446581395176
total_rewards_std            866.6053525931479
total_rewards_max            5078.453641248001
total_rewards_min            2094.114525680949
Number of train steps total  1740000
Number of env steps total    2177000
Number of rollouts total     0
Train Time (s)               117.04440678609535
(Previous) Eval Time (s)     20.934120000805706
Sample Time (s)              18.149931306485087
Epoch Time (s)               156.12845809338614
Total Train Time (s)         67633.6443391107
Epoch                        434
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:18:49.611753 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #434 | Epoch Duration: 160.46360898017883
2020-01-12 18:18:49.611944 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #434 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1495428
Z variance train             0.008803148
KL Divergence                26.212109
KL Loss                      2.6212108
QF Loss                      698.667
VF Loss                      138.47456
Policy Loss                  -1699.264
Q Predictions Mean           1699.7766
Q Predictions Std            288.98325
Q Predictions Max            1921.9878
Q Predictions Min            -303.57382
V Predictions Mean           1694.4625
V Predictions Std            288.77252
V Predictions Max            1908.3123
V Predictions Min            -311.7152
Log Pis Mean                 1.8021309
Log Pis Std                  3.1939788
Log Pis Max                  10.623184
Log Pis Min                  -7.1956787
Policy mu Mean               0.015190982
Policy mu Std                0.6550942
Policy mu Max                2.5415032
Policy mu Min                -2.5337594
Policy log std Mean          -1.2317823
Policy log std Std           0.33019805
Policy log std Max           -0.06100285
Policy log std Min           -3.0905352
Z mean eval                  1.1151724
Z variance eval              0.008669973
total_rewards                [4846.98643776 3985.70809012 4651.63983107 4940.8818803  4656.31455888
 2176.05595589 4976.85235853 5227.0505436  5215.42202473 4817.92880677]
total_rewards_mean           4549.484048763989
total_rewards_std            858.5935442563223
total_rewards_max            5227.050543596438
total_rewards_min            2176.0559558865816
Number of train steps total  1744000
Number of env steps total    2182000
Number of rollouts total     0
Train Time (s)               120.96379304910079
(Previous) Eval Time (s)     25.268957811407745
Sample Time (s)              18.60381952067837
Epoch Time (s)               164.8365703811869
Total Train Time (s)         67798.19800807489
Epoch                        435
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:21:34.170282 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #435 | Epoch Duration: 164.55820965766907
2020-01-12 18:21:34.170483 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #435 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1153135
Z variance train             0.008669894
KL Divergence                26.201498
KL Loss                      2.6201499
QF Loss                      846.6105
VF Loss                      491.88638
Policy Loss                  -1696.1097
Q Predictions Mean           1695.7161
Q Predictions Std            349.0105
Q Predictions Max            1916.4583
Q Predictions Min            -415.76495
V Predictions Mean           1689.3381
V Predictions Std            350.59995
V Predictions Max            1907.897
V Predictions Min            -407.868
Log Pis Mean                 1.9919531
Log Pis Std                  3.4164858
Log Pis Max                  15.816622
Log Pis Min                  -7.3357472
Policy mu Mean               0.009968014
Policy mu Std                0.6616583
Policy mu Max                2.4529848
Policy mu Min                -2.6842246
Policy log std Mean          -1.2420437
Policy log std Std           0.35017693
Policy log std Max           -0.20953405
Policy log std Min           -3.0372484
Z mean eval                  1.095496
Z variance eval              0.013871024
total_rewards                [  23.33349766 4063.75047829 5037.42202562 4923.88826136  341.13079254
 4933.92739191  488.4575201  1484.91249497 1100.90993454 3503.15633936]
total_rewards_mean           2590.088873635427
total_rewards_std            1985.874556917671
total_rewards_max            5037.422025621648
total_rewards_min            23.333497655881008
Number of train steps total  1748000
Number of env steps total    2187000
Number of rollouts total     0
Train Time (s)               121.81495596887544
(Previous) Eval Time (s)     24.990293154958636
Sample Time (s)              18.09081746870652
Epoch Time (s)               164.8960665925406
Total Train Time (s)         67953.09275776055
Epoch                        436
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:24:09.071100 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #436 | Epoch Duration: 154.9004590511322
2020-01-12 18:24:09.071354 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #436 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0966644
Z variance train             0.013894824
KL Divergence                26.553936
KL Loss                      2.6553936
QF Loss                      1093.0869
VF Loss                      697.775
Policy Loss                  -1719.363
Q Predictions Mean           1713.1543
Q Predictions Std            303.82217
Q Predictions Max            1922.1605
Q Predictions Min            -221.64516
V Predictions Mean           1717.0364
V Predictions Std            276.23575
V Predictions Max            1918.7599
V Predictions Min            -231.00963
Log Pis Mean                 2.091216
Log Pis Std                  3.4125736
Log Pis Max                  18.833685
Log Pis Min                  -5.7572613
Policy mu Mean               -0.0014855526
Policy mu Std                0.65788305
Policy mu Max                2.5124297
Policy mu Min                -2.9281442
Policy log std Mean          -1.2603295
Policy log std Std           0.347929
Policy log std Max           0.3410101
Policy log std Min           -3.475648
Z mean eval                  1.1006944
Z variance eval              0.017757718
total_rewards                [4449.44566873 4950.2286976  5148.35797892 4626.72206653 4141.90476431
 4962.08900313  677.91565188 4909.03734111 4869.48721238 5029.0948884 ]
total_rewards_mean           4376.428327300817
total_rewards_std            1265.8139493947551
total_rewards_max            5148.357978924221
total_rewards_min            677.9156518842194
Number of train steps total  1752000
Number of env steps total    2192000
Number of rollouts total     0
Train Time (s)               122.75253992341459
(Previous) Eval Time (s)     14.994377780240029
Sample Time (s)              19.476211039815098
Epoch Time (s)               157.22312874346972
Total Train Time (s)         68121.68630400812
Epoch                        437
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:26:57.672052 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #437 | Epoch Duration: 168.60047268867493
2020-01-12 18:26:57.672389 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #437 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1028445
Z variance train             0.017536242
KL Divergence                26.141285
KL Loss                      2.6141286
QF Loss                      691.64154
VF Loss                      295.11963
Policy Loss                  -1748.8628
Q Predictions Mean           1751.9995
Q Predictions Std            196.75299
Q Predictions Max            1939.9429
Q Predictions Min            -303.17114
V Predictions Mean           1741.5024
V Predictions Std            197.41595
V Predictions Max            1916.758
V Predictions Min            -305.14615
Log Pis Mean                 2.1186194
Log Pis Std                  3.634149
Log Pis Max                  13.978308
Log Pis Min                  -7.2244453
Policy mu Mean               0.031917673
Policy mu Std                0.70478034
Policy mu Max                2.8053331
Policy mu Min                -2.9226747
Policy log std Mean          -1.2189648
Policy log std Std           0.32867113
Policy log std Max           -0.20322305
Policy log std Min           -2.7178116
Z mean eval                  1.1186097
Z variance eval              0.0100928545
total_rewards                [4808.79659338 5162.320209   3002.41770632  711.44719006 5154.78428222
 5197.78284781 5050.13304257  524.66324857 2158.37851125 5005.12219934]
total_rewards_mean           3677.5845830528283
total_rewards_std            1820.0595863496162
total_rewards_max            5197.782847808506
total_rewards_min            524.663248574618
Number of train steps total  1756000
Number of env steps total    2197000
Number of rollouts total     0
Train Time (s)               115.34301101509482
(Previous) Eval Time (s)     26.371377401985228
Sample Time (s)              18.109329860657454
Epoch Time (s)               159.8237182777375
Total Train Time (s)         68278.08761268435
Epoch                        438
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:29:34.075843 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #438 | Epoch Duration: 156.40321397781372
2020-01-12 18:29:34.076004 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #438 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.117688
Z variance train             0.010103007
KL Divergence                25.262428
KL Loss                      2.526243
QF Loss                      751.71704
VF Loss                      191.03542
Policy Loss                  -1708.5596
Q Predictions Mean           1709.0475
Q Predictions Std            309.21796
Q Predictions Max            1945.3593
Q Predictions Min            -353.15823
V Predictions Mean           1702.939
V Predictions Std            305.648
V Predictions Max            1921.4905
V Predictions Min            -339.3803
Log Pis Mean                 1.9536006
Log Pis Std                  3.2322285
Log Pis Max                  12.522218
Log Pis Min                  -8.385885
Policy mu Mean               0.015252398
Policy mu Std                0.6713208
Policy mu Max                4.1386857
Policy mu Min                -2.4110482
Policy log std Mean          -1.222429
Policy log std Std           0.32734802
Policy log std Max           -0.042266488
Policy log std Min           -2.7268362
Z mean eval                  1.1973199
Z variance eval              0.021158466
total_rewards                [4677.63800181 5037.12894795 5025.3786098  4943.79425922 5005.6885943
 4637.47414783  408.94532264 5039.83654753  857.02531982 4400.60449959]
total_rewards_mean           4003.3514250499647
total_rewards_std            1700.3045808742665
total_rewards_max            5039.836547526211
total_rewards_min            408.9453226416701
Number of train steps total  1760000
Number of env steps total    2202000
Number of rollouts total     0
Train Time (s)               123.74597697332501
(Previous) Eval Time (s)     22.950587359257042
Sample Time (s)              18.05676765041426
Epoch Time (s)               164.75333198299631
Total Train Time (s)         68441.70613892749
Epoch                        439
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:32:17.701818 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #439 | Epoch Duration: 163.62563729286194
2020-01-12 18:32:17.702083 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #439 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1983135
Z variance train             0.021225423
KL Divergence                22.5598
KL Loss                      2.25598
QF Loss                      1052.1122
VF Loss                      185.121
Policy Loss                  -1753.4154
Q Predictions Mean           1753.7222
Q Predictions Std            369.93497
Q Predictions Max            1984.3757
Q Predictions Min            -537.463
V Predictions Mean           1759.3131
V Predictions Std            364.23495
V Predictions Max            1990.3948
V Predictions Min            -508.16046
Log Pis Mean                 2.1603205
Log Pis Std                  3.6620333
Log Pis Max                  30.134989
Log Pis Min                  -9.142113
Policy mu Mean               0.011460843
Policy mu Std                0.7149319
Policy mu Max                6.109558
Policy mu Min                -3.4264088
Policy log std Mean          -1.2254353
Policy log std Std           0.33231965
Policy log std Max           2.0
Policy log std Min           -2.5755405
Z mean eval                  1.1177071
Z variance eval              0.016927216
total_rewards                [2975.97447131 4976.69796059 4483.88789036 2335.36293406 4870.29597089
 4772.58646788 4976.08295436 4694.90720012 4660.11264138 4913.95802874]
total_rewards_mean           4365.98665196998
total_rewards_std            879.1629998279344
total_rewards_max            4976.697960590688
total_rewards_min            2335.3629340616408
Number of train steps total  1764000
Number of env steps total    2207000
Number of rollouts total     0
Train Time (s)               118.15648892801255
(Previous) Eval Time (s)     21.82260759314522
Sample Time (s)              17.954851939808577
Epoch Time (s)               157.93394846096635
Total Train Time (s)         68603.92292246595
Epoch                        440
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:34:59.920486 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #440 | Epoch Duration: 162.21822714805603
2020-01-12 18:34:59.920681 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #440 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1170957
Z variance train             0.016921276
KL Divergence                23.034002
KL Loss                      2.3034003
QF Loss                      1285.3368
VF Loss                      149.27365
Policy Loss                  -1747.9563
Q Predictions Mean           1750.0247
Q Predictions Std            196.97627
Q Predictions Max            1945.6871
Q Predictions Min            -520.5344
V Predictions Mean           1746.7814
V Predictions Std            202.27109
V Predictions Max            1942.9927
V Predictions Min            -507.65363
Log Pis Mean                 1.9380844
Log Pis Std                  3.0198877
Log Pis Max                  11.457143
Log Pis Min                  -7.6996236
Policy mu Mean               0.0005236326
Policy mu Std                0.6473068
Policy mu Max                3.0667293
Policy mu Min                -2.326937
Policy log std Mean          -1.2787869
Policy log std Std           0.30839005
Policy log std Max           0.24423552
Policy log std Min           -2.3913383
Z mean eval                  1.1490868
Z variance eval              0.01554853
total_rewards                [4849.34725407 4940.08907723 4963.82557347 4945.97695297 4740.16996109
 4887.62836654 5228.69029049 4707.829302   5158.09575421 5131.79024127]
total_rewards_mean           4955.344277333773
total_rewards_std            164.54064715419614
total_rewards_max            5228.690290492792
total_rewards_min            4707.829301997059
Number of train steps total  1768000
Number of env steps total    2212000
Number of rollouts total     0
Train Time (s)               114.86243709595874
(Previous) Eval Time (s)     26.106611216906458
Sample Time (s)              18.443295111879706
Epoch Time (s)               159.4123434247449
Total Train Time (s)         68765.58478412824
Epoch                        441
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:37:41.589914 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #441 | Epoch Duration: 161.66906213760376
2020-01-12 18:37:41.590218 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #441 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1483877
Z variance train             0.01550173
KL Divergence                23.008236
KL Loss                      2.3008237
QF Loss                      1157.5176
VF Loss                      226.06735
Policy Loss                  -1707.3333
Q Predictions Mean           1709.3037
Q Predictions Std            271.22873
Q Predictions Max            1918.9811
Q Predictions Min            -277.9366
V Predictions Mean           1711.6549
V Predictions Std            269.8466
V Predictions Max            1921.622
V Predictions Min            -297.99905
Log Pis Mean                 2.3147836
Log Pis Std                  3.2385745
Log Pis Max                  13.453942
Log Pis Min                  -6.75977
Policy mu Mean               -0.006932508
Policy mu Std                0.6561593
Policy mu Max                2.5623603
Policy mu Min                -2.8207207
Policy log std Mean          -1.2649939
Policy log std Std           0.34262523
Policy log std Max           -0.27619255
Policy log std Min           -2.8338494
Z mean eval                  1.1110327
Z variance eval              0.014649232
total_rewards                [1722.06353884 4988.72592462 5160.26003278 4706.44085022 5041.29243097
   24.43067974 5149.17214391 4345.26665865 4942.28331985 5028.02838067]
total_rewards_mean           4110.796396025512
total_rewards_std            1678.1854580220154
total_rewards_max            5160.2600327766495
total_rewards_min            24.43067973797106
Number of train steps total  1772000
Number of env steps total    2217000
Number of rollouts total     0
Train Time (s)               121.68546263407916
(Previous) Eval Time (s)     28.363029934931546
Sample Time (s)              17.812473743688315
Epoch Time (s)               167.86096631269902
Total Train Time (s)         68928.16462857975
Epoch                        442
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:40:24.172859 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #442 | Epoch Duration: 162.58242511749268
2020-01-12 18:40:24.173060 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #442 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.110922
Z variance train             0.014627007
KL Divergence                23.87519
KL Loss                      2.3875191
QF Loss                      780.75134
VF Loss                      529.7583
Policy Loss                  -1729.8524
Q Predictions Mean           1731.5076
Q Predictions Std            311.90173
Q Predictions Max            1963.5371
Q Predictions Min            -443.34085
V Predictions Mean           1727.0916
V Predictions Std            312.69266
V Predictions Max            1966.4329
V Predictions Min            -438.24097
Log Pis Mean                 2.0034454
Log Pis Std                  3.4369946
Log Pis Max                  16.9678
Log Pis Min                  -7.3577003
Policy mu Mean               -0.01567073
Policy mu Std                0.6559872
Policy mu Max                2.6276789
Policy mu Min                -2.9053822
Policy log std Mean          -1.2317536
Policy log std Std           0.33920646
Policy log std Max           -0.01964891
Policy log std Min           -3.1115546
Z mean eval                  1.0929811
Z variance eval              0.013083192
total_rewards                [4664.03059315 4944.22162415   94.86276071 4637.86997191 5067.29482365
 3646.6897012  5125.93980698 3263.98084848 3026.42870564 4954.73931872]
total_rewards_mean           3942.6058154602606
total_rewards_std            1479.5034443613024
total_rewards_max            5125.9398069774525
total_rewards_min            94.86276071291614
Number of train steps total  1776000
Number of env steps total    2222000
Number of rollouts total     0
Train Time (s)               112.69423357676715
(Previous) Eval Time (s)     23.084241616073996
Sample Time (s)              18.03904983634129
Epoch Time (s)               153.81752502918243
Total Train Time (s)         69082.62365085259
Epoch                        443
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:42:58.638126 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #443 | Epoch Duration: 154.46490383148193
2020-01-12 18:42:58.638373 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #443 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0926793
Z variance train             0.013085179
KL Divergence                23.472378
KL Loss                      2.3472378
QF Loss                      925.151
VF Loss                      128.42737
Policy Loss                  -1717.4832
Q Predictions Mean           1717.8516
Q Predictions Std            372.95395
Q Predictions Max            1987.2205
Q Predictions Min            -527.9107
V Predictions Mean           1717.184
V Predictions Std            370.0669
V Predictions Max            1986.8922
V Predictions Min            -469.5653
Log Pis Mean                 2.0290422
Log Pis Std                  3.319255
Log Pis Max                  13.734643
Log Pis Min                  -7.2554426
Policy mu Mean               -0.019945808
Policy mu Std                0.70306915
Policy mu Max                2.5055084
Policy mu Min                -2.9876344
Policy log std Mean          -1.206157
Policy log std Std           0.32702002
Policy log std Max           -0.01691103
Policy log std Min           -2.6230621
Z mean eval                  1.1126735
Z variance eval              0.017259479
total_rewards                [5081.14467502 5234.27312068 5169.68856674 5372.02612328 5138.38532737
 5109.17507154 5155.09937764 5304.22484206 4944.28030917 4869.81230643]
total_rewards_mean           5137.810971991295
total_rewards_std            143.6938222333085
total_rewards_max            5372.026123279846
total_rewards_min            4869.812306425741
Number of train steps total  1780000
Number of env steps total    2227000
Number of rollouts total     0
Train Time (s)               120.3692522989586
(Previous) Eval Time (s)     23.731331608258188
Sample Time (s)              18.335938366129994
Epoch Time (s)               162.43652227334678
Total Train Time (s)         69248.64082790399
Epoch                        444
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:45:44.663596 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #444 | Epoch Duration: 166.02501344680786
2020-01-12 18:45:44.663915 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #444 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1127506
Z variance train             0.017252073
KL Divergence                22.715712
KL Loss                      2.2715712
QF Loss                      1138.6802
VF Loss                      200.64235
Policy Loss                  -1781.7065
Q Predictions Mean           1781.3029
Q Predictions Std            238.13657
Q Predictions Max            1982.6884
Q Predictions Min            -267.1044
V Predictions Mean           1772.4674
V Predictions Std            236.1724
V Predictions Max            1959.9572
V Predictions Min            -272.73068
Log Pis Mean                 2.011248
Log Pis Std                  3.1426647
Log Pis Max                  12.306992
Log Pis Min                  -6.209285
Policy mu Mean               0.027205013
Policy mu Std                0.6327808
Policy mu Max                2.432066
Policy mu Min                -2.6953545
Policy log std Mean          -1.2760508
Policy log std Std           0.30003217
Policy log std Max           -0.30811608
Policy log std Min           -2.5370352
Z mean eval                  1.1458975
Z variance eval              0.016597703
total_rewards                [4816.91112221 4957.45326922 4850.68196631 4905.75164106 4784.81922043
 4730.37190569 4815.21460433 4362.68322961 5065.46605014 4985.18844342]
total_rewards_mean           4827.454145240278
total_rewards_std            182.37742218034222
total_rewards_max            5065.466050137777
total_rewards_min            4362.683229611919
Number of train steps total  1784000
Number of env steps total    2232000
Number of rollouts total     0
Train Time (s)               121.93600390478969
(Previous) Eval Time (s)     27.319508609827608
Sample Time (s)              18.00979303009808
Epoch Time (s)               167.26530554471537
Total Train Time (s)         69415.26704067038
Epoch                        445
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:48:31.292173 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #445 | Epoch Duration: 166.62806010246277
2020-01-12 18:48:31.292380 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #445 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1452434
Z variance train             0.016583772
KL Divergence                23.382957
KL Loss                      2.3382957
QF Loss                      1296.3955
VF Loss                      436.0004
Policy Loss                  -1736.182
Q Predictions Mean           1741.3715
Q Predictions Std            336.93826
Q Predictions Max            2014.8414
Q Predictions Min            -527.8167
V Predictions Mean           1737.3586
V Predictions Std            339.12143
V Predictions Max            1996.7074
V Predictions Min            -543.8051
Log Pis Mean                 1.5424764
Log Pis Std                  3.2455306
Log Pis Max                  14.470754
Log Pis Min                  -8.323864
Policy mu Mean               0.008770313
Policy mu Std                0.6225698
Policy mu Max                2.4196966
Policy mu Min                -2.6283772
Policy log std Mean          -1.2210402
Policy log std Std           0.33913434
Policy log std Max           0.11511552
Policy log std Min           -3.1801536
Z mean eval                  1.1285436
Z variance eval              0.01913201
total_rewards                [3130.14660265 5050.90744409 4767.16073702 4878.90479076 4805.92853427
 4901.86120408 4771.45993328 1297.58628585   98.67741469 5099.87777024]
total_rewards_mean           3880.25107169352
total_rewards_std            1699.1108359155887
total_rewards_max            5099.877770242902
total_rewards_min            98.67741468869288
Number of train steps total  1788000
Number of env steps total    2237000
Number of rollouts total     0
Train Time (s)               122.04226950090379
(Previous) Eval Time (s)     26.681961385998875
Sample Time (s)              18.432157238945365
Epoch Time (s)               167.15638812584803
Total Train Time (s)         69577.23574801162
Epoch                        446
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:51:13.264728 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #446 | Epoch Duration: 161.97222256660461
2020-01-12 18:51:13.264901 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #446 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1314768
Z variance train             0.019190967
KL Divergence                23.97116
KL Loss                      2.3971162
QF Loss                      7469.191
VF Loss                      148.82379
Policy Loss                  -1783.8074
Q Predictions Mean           1789.616
Q Predictions Std            218.78912
Q Predictions Max            1992.9298
Q Predictions Min            -252.19775
V Predictions Mean           1788.3038
V Predictions Std            219.5944
V Predictions Max            1980.9323
V Predictions Min            -228.55458
Log Pis Mean                 2.003903
Log Pis Std                  3.5040402
Log Pis Max                  17.093027
Log Pis Min                  -6.9472876
Policy mu Mean               -0.05466592
Policy mu Std                0.62729836
Policy mu Max                2.39869
Policy mu Min                -2.732787
Policy log std Mean          -1.2804996
Policy log std Std           0.32945195
Policy log std Max           -0.1591959
Policy log std Min           -3.431035
Z mean eval                  1.1002738
Z variance eval              0.0124392565
total_rewards                [1443.49313308 4980.76172707 5093.46681913 5119.09342738 5105.84375242
 4928.70024393 4822.95165878 4219.11466367 2663.7960134  4918.06567495]
total_rewards_mean           4329.528711379914
total_rewards_std            1195.7712944829793
total_rewards_max            5119.093427377095
total_rewards_min            1443.4931330774996
Number of train steps total  1792000
Number of env steps total    2242000
Number of rollouts total     0
Train Time (s)               119.29502665204927
(Previous) Eval Time (s)     21.49747482407838
Sample Time (s)              18.060303308535367
Epoch Time (s)               158.85280478466302
Total Train Time (s)         69737.7593860603
Epoch                        447
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:53:53.796131 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #447 | Epoch Duration: 160.53103947639465
2020-01-12 18:53:53.796437 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #447 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1018482
Z variance train             0.012472686
KL Divergence                23.394876
KL Loss                      2.3394878
QF Loss                      856.4174
VF Loss                      550.2496
Policy Loss                  -1731.7875
Q Predictions Mean           1729.365
Q Predictions Std            341.00363
Q Predictions Max            1963.2207
Q Predictions Min            -476.28152
V Predictions Mean           1735.2444
V Predictions Std            324.23627
V Predictions Max            1962.6815
V Predictions Min            -466.52524
Log Pis Mean                 1.936685
Log Pis Std                  3.997079
Log Pis Max                  33.66605
Log Pis Min                  -6.8409348
Policy mu Mean               0.042427514
Policy mu Std                0.6782011
Policy mu Max                5.9927936
Policy mu Min                -4.97848
Policy log std Mean          -1.24359
Policy log std Std           0.34973568
Policy log std Max           2.0
Policy log std Min           -3.0382385
Z mean eval                  1.1068854
Z variance eval              0.01965924
total_rewards                [4869.85259176 5116.44945606 4928.23221108 4768.55750524 5094.53520686
 4912.22610026 4833.79177886 4709.66749902 5186.51764822 4879.93124764]
total_rewards_mean           4929.976124500691
total_rewards_std            147.63003464821756
total_rewards_max            5186.517648223888
total_rewards_min            4709.667499015224
Number of train steps total  1796000
Number of env steps total    2247000
Number of rollouts total     0
Train Time (s)               110.98588382685557
(Previous) Eval Time (s)     23.175356761086732
Sample Time (s)              18.338960184250027
Epoch Time (s)               152.50020077219233
Total Train Time (s)         69894.14249671903
Epoch                        448
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:56:30.186702 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #448 | Epoch Duration: 156.3899528980255
2020-01-12 18:56:30.187106 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #448 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1067722
Z variance train             0.019665664
KL Divergence                23.082762
KL Loss                      2.3082762
QF Loss                      899.62286
VF Loss                      358.6918
Policy Loss                  -1753.135
Q Predictions Mean           1753.4836
Q Predictions Std            298.1873
Q Predictions Max            1984.4535
Q Predictions Min            -542.04694
V Predictions Mean           1752.4702
V Predictions Std            283.02283
V Predictions Max            1966.2527
V Predictions Min            -522.5299
Log Pis Mean                 2.082467
Log Pis Std                  3.684798
Log Pis Max                  18.755825
Log Pis Min                  -11.091923
Policy mu Mean               0.013378302
Policy mu Std                0.69394845
Policy mu Max                3.3368237
Policy mu Min                -3.0810242
Policy log std Mean          -1.2303311
Policy log std Std           0.34023312
Policy log std Max           0.2095629
Policy log std Min           -3.5838418
Z mean eval                  1.1641631
Z variance eval              0.008848441
total_rewards                [2654.60549572 5083.48697031  312.13810165 4765.56860568 4995.78986583
 5023.40062991  694.12155555 5118.26236413 1217.46863974 5147.36808412]
total_rewards_mean           3501.2210312641582
total_rewards_std            1948.329285920301
total_rewards_max            5147.368084119725
total_rewards_min            312.13810164944374
Number of train steps total  1800000
Number of env steps total    2252000
Number of rollouts total     0
Train Time (s)               118.63209480699152
(Previous) Eval Time (s)     27.06479491200298
Sample Time (s)              17.976306153461337
Epoch Time (s)               163.67319587245584
Total Train Time (s)         70056.62132001435
Epoch                        449
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:59:12.668584 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #449 | Epoch Duration: 162.48125624656677
2020-01-12 18:59:12.668796 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #449 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1638772
Z variance train             0.008850972
KL Divergence                25.221764
KL Loss                      2.5221765
QF Loss                      1129.1884
VF Loss                      140.07779
Policy Loss                  -1800.9542
Q Predictions Mean           1804.0383
Q Predictions Std            210.81245
Q Predictions Max            1985.1997
Q Predictions Min            -492.77524
V Predictions Mean           1803.46
V Predictions Std            212.28708
V Predictions Max            1988.5355
V Predictions Min            -505.25485
Log Pis Mean                 2.1054225
Log Pis Std                  3.1447642
Log Pis Max                  12.645295
Log Pis Min                  -5.1491914
Policy mu Mean               0.01598731
Policy mu Std                0.63236046
Policy mu Max                3.0959516
Policy mu Min                -2.6257036
Policy log std Mean          -1.2777778
Policy log std Std           0.3056052
Policy log std Max           -0.09792256
Policy log std Min           -2.6444166
Z mean eval                  1.1631446
Z variance eval              0.0145609155
total_rewards                [4990.91707592 4952.16233744 5077.7806279  4842.9108912  5339.64544813
 4781.83074342 5043.08551857 3412.68662374 5182.91674968 4720.36886333]
total_rewards_mean           4834.43048793344
total_rewards_std            505.4695048783852
total_rewards_max            5339.645448131083
total_rewards_min            3412.6866237382665
Number of train steps total  1804000
Number of env steps total    2257000
Number of rollouts total     0
Train Time (s)               123.29315671883523
(Previous) Eval Time (s)     25.872575694695115
Sample Time (s)              17.87405972275883
Epoch Time (s)               167.03979213628918
Total Train Time (s)         70223.38812794769
Epoch                        450
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:01:59.438857 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #450 | Epoch Duration: 166.7698483467102
2020-01-12 19:01:59.439096 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #450 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1654129
Z variance train             0.014542429
KL Divergence                25.114944
KL Loss                      2.5114944
QF Loss                      891.54315
VF Loss                      233.63234
Policy Loss                  -1809.211
Q Predictions Mean           1813.3834
Q Predictions Std            156.31952
Q Predictions Max            2040.6703
Q Predictions Min            361.76562
V Predictions Mean           1817.501
V Predictions Std            152.89952
V Predictions Max            2040.4492
V Predictions Min            414.2482
Log Pis Mean                 2.0343053
Log Pis Std                  3.2499063
Log Pis Max                  15.489123
Log Pis Min                  -6.6066523
Policy mu Mean               -0.012211785
Policy mu Std                0.6632327
Policy mu Max                2.963985
Policy mu Min                -2.6507492
Policy log std Mean          -1.2609496
Policy log std Std           0.30611056
Policy log std Max           -0.20856082
Policy log std Min           -2.5288773
Z mean eval                  1.1326282
Z variance eval              0.0072741457
total_rewards                [5073.46985702 5152.51615849 5047.2175826  5213.01597038 5348.29007575
 5189.82187507 5117.82143854 2786.99535654 4626.11085435 5137.68052157]
total_rewards_mean           4869.293969031745
total_rewards_std            716.4343948076355
total_rewards_max            5348.290075752985
total_rewards_min            2786.9953565435667
Number of train steps total  1808000
Number of env steps total    2262000
Number of rollouts total     0
Train Time (s)               122.56051272712648
(Previous) Eval Time (s)     25.602312120608985
Sample Time (s)              18.45003316178918
Epoch Time (s)               166.61285800952464
Total Train Time (s)         70390.6413587504
Epoch                        451
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:04:46.694885 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #451 | Epoch Duration: 167.25562977790833
2020-01-12 19:04:46.695037 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #451 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1329232
Z variance train             0.007276021
KL Divergence                26.87201
KL Loss                      2.687201
QF Loss                      1084.7458
VF Loss                      101.42588
Policy Loss                  -1789.7386
Q Predictions Mean           1792.3699
Q Predictions Std            281.46652
Q Predictions Max            2009.1227
Q Predictions Min            -428.84818
V Predictions Mean           1788.8456
V Predictions Std            282.25592
V Predictions Max            2009.91
V Predictions Min            -450.92294
Log Pis Mean                 2.1878932
Log Pis Std                  3.2982066
Log Pis Max                  20.024113
Log Pis Min                  -5.659884
Policy mu Mean               -0.023402132
Policy mu Std                0.67736393
Policy mu Max                2.6213758
Policy mu Min                -2.9809854
Policy log std Mean          -1.228517
Policy log std Std           0.3055743
Policy log std Max           -0.31656504
Policy log std Min           -2.6076155
Z mean eval                  1.112381
Z variance eval              0.01004032
total_rewards                [1104.94569247 1643.05647701 5126.77678706  153.95764044 5203.75403934
 4887.67479726 5049.37863163 4977.37826234  975.30064001 5318.05045597]
total_rewards_mean           3444.0273423526596
total_rewards_std            2051.5031403561984
total_rewards_max            5318.050455969937
total_rewards_min            153.95764044197466
Number of train steps total  1812000
Number of env steps total    2267000
Number of rollouts total     0
Train Time (s)               117.93866986222565
(Previous) Eval Time (s)     26.244740513619035
Sample Time (s)              19.100235514342785
Epoch Time (s)               163.28364589018747
Total Train Time (s)         70546.23845392885
Epoch                        452
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:07:22.299403 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #452 | Epoch Duration: 155.6041853427887
2020-01-12 19:07:22.299688 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #452 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1132054
Z variance train             0.010048019
KL Divergence                25.170174
KL Loss                      2.5170174
QF Loss                      932.7113
VF Loss                      523.09235
Policy Loss                  -1796.0562
Q Predictions Mean           1796.0634
Q Predictions Std            261.43265
Q Predictions Max            2033.9868
Q Predictions Min            -488.96738
V Predictions Mean           1793.9111
V Predictions Std            264.23645
V Predictions Max            2028.0259
V Predictions Min            -508.1207
Log Pis Mean                 2.2722507
Log Pis Std                  3.2123973
Log Pis Max                  14.894143
Log Pis Min                  -4.3965263
Policy mu Mean               -0.021411203
Policy mu Std                0.67088354
Policy mu Max                2.9180179
Policy mu Min                -2.7782452
Policy log std Mean          -1.262746
Policy log std Std           0.3354405
Policy log std Max           -0.009846449
Policy log std Min           -3.137011
Z mean eval                  1.1113174
Z variance eval              0.0112802815
total_rewards                [1972.26895466 5134.86891539 5166.4904163  5205.30044931 1032.60919419
  989.47554646 1414.44478189 2171.73177    2861.57113061 1064.19949265]
total_rewards_mean           2701.296065146225
total_rewards_std            1707.5720103077854
total_rewards_max            5205.300449313518
total_rewards_min            989.475546463133
Number of train steps total  1816000
Number of env steps total    2272000
Number of rollouts total     0
Train Time (s)               118.33731877384707
(Previous) Eval Time (s)     18.564915293827653
Sample Time (s)              17.34649263555184
Epoch Time (s)               154.24872670322657
Total Train Time (s)         70696.3119077785
Epoch                        453
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:09:52.376221 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #453 | Epoch Duration: 150.0763292312622
2020-01-12 19:09:52.376374 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #453 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1123015
Z variance train             0.0113891745
KL Divergence                25.152924
KL Loss                      2.5152924
QF Loss                      1294.0537
VF Loss                      257.58093
Policy Loss                  -1756.4962
Q Predictions Mean           1760.347
Q Predictions Std            314.56473
Q Predictions Max            1989.5415
Q Predictions Min            -491.089
V Predictions Mean           1759.0093
V Predictions Std            319.06107
V Predictions Max            1985.2593
V Predictions Min            -525.52313
Log Pis Mean                 1.9049932
Log Pis Std                  3.078967
Log Pis Max                  17.100302
Log Pis Min                  -7.0835104
Policy mu Mean               0.04444915
Policy mu Std                0.6264812
Policy mu Max                2.6263885
Policy mu Min                -2.4463913
Policy log std Mean          -1.2698065
Policy log std Std           0.3240799
Policy log std Max           -0.19187295
Policy log std Min           -3.1181006
Z mean eval                  1.1894438
Z variance eval              0.01723695
total_rewards                [2085.54508973 5172.31685002 5002.40984678 5138.6894025  5270.98694553
 4890.36192688 2105.71068451 5459.35529055 4414.02153566 5275.16833229]
total_rewards_mean           4481.45659044356
total_rewards_std            1222.5616193392757
total_rewards_max            5459.355290550789
total_rewards_min            2085.5450897287637
Number of train steps total  1820000
Number of env steps total    2277000
Number of rollouts total     0
Train Time (s)               117.75115623697639
(Previous) Eval Time (s)     14.39224356226623
Sample Time (s)              19.088607092853636
Epoch Time (s)               151.23200689209625
Total Train Time (s)         70856.1221413631
Epoch                        454
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:12:32.193982 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #454 | Epoch Duration: 159.8174591064453
2020-01-12 19:12:32.194259 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #454 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.191583
Z variance train             0.017221551
KL Divergence                24.081303
KL Loss                      2.4081304
QF Loss                      1050.5962
VF Loss                      388.11823
Policy Loss                  -1753.6631
Q Predictions Mean           1757.3706
Q Predictions Std            335.48627
Q Predictions Max            1983.7008
Q Predictions Min            -514.2809
V Predictions Mean           1766.1671
V Predictions Std            337.39536
V Predictions Max            1984.4089
V Predictions Min            -511.3977
Log Pis Mean                 2.3361778
Log Pis Std                  3.3955517
Log Pis Max                  16.358458
Log Pis Min                  -5.477455
Policy mu Mean               -0.018308062
Policy mu Std                0.6848914
Policy mu Max                2.337849
Policy mu Min                -3.0754564
Policy log std Mean          -1.2551877
Policy log std Std           0.33004704
Policy log std Max           -0.08334398
Policy log std Min           -2.7103715
Z mean eval                  1.1820326
Z variance eval              0.013817042
total_rewards                [4794.82179815 5012.3795552  4933.76695963 5118.90547319 1246.47631846
 4906.92503874 5187.71611127 5193.50132302 5132.49896327 1500.59521072]
total_rewards_mean           4302.758675164688
total_rewards_std            1470.8159285165875
total_rewards_max            5193.5013230218365
total_rewards_min            1246.4763184591195
Number of train steps total  1824000
Number of env steps total    2282000
Number of rollouts total     0
Train Time (s)               117.56704718386754
(Previous) Eval Time (s)     22.9773135362193
Sample Time (s)              18.684041867032647
Epoch Time (s)               159.2284025871195
Total Train Time (s)         71016.27866253257
Epoch                        455
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:15:12.356228 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #455 | Epoch Duration: 160.16174340248108
2020-01-12 19:15:12.356535 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #455 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1800413
Z variance train             0.013776931
KL Divergence                24.078663
KL Loss                      2.4078662
QF Loss                      901.43
VF Loss                      253.63681
Policy Loss                  -1818.5669
Q Predictions Mean           1821.3917
Q Predictions Std            239.94693
Q Predictions Max            2023.1536
Q Predictions Min            -311.19534
V Predictions Mean           1827.1597
V Predictions Std            240.9424
V Predictions Max            2033.1449
V Predictions Min            -289.25888
Log Pis Mean                 2.321647
Log Pis Std                  3.073403
Log Pis Max                  11.966375
Log Pis Min                  -6.5757155
Policy mu Mean               0.013599964
Policy mu Std                0.62661153
Policy mu Max                2.773119
Policy mu Min                -2.909693
Policy log std Mean          -1.2981528
Policy log std Std           0.33338845
Policy log std Max           -0.056482553
Policy log std Min           -2.6562955
Z mean eval                  1.1350195
Z variance eval              0.01485531
total_rewards                [1328.77762064  831.64426493 5273.99219182 5310.67747933 2066.86917983
  908.36326694 1036.34541282 3777.3850479  4920.12602025  159.67108904]
total_rewards_mean           2561.385157350028
total_rewards_std            1937.5626026589696
total_rewards_max            5310.677479330958
total_rewards_min            159.6710890393992
Number of train steps total  1828000
Number of env steps total    2287000
Number of rollouts total     0
Train Time (s)               115.59753912081942
(Previous) Eval Time (s)     23.91030484298244
Sample Time (s)              18.944730075541884
Epoch Time (s)               158.45257403934374
Total Train Time (s)         71164.44043537136
Epoch                        456
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:17:40.524015 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #456 | Epoch Duration: 148.16724801063538
2020-01-12 19:17:40.524258 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #456 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.135624
Z variance train             0.014834715
KL Divergence                24.108719
KL Loss                      2.410872
QF Loss                      817.4619
VF Loss                      224.62611
Policy Loss                  -1804.2053
Q Predictions Mean           1807.7506
Q Predictions Std            341.7039
Q Predictions Max            2054.5042
Q Predictions Min            -433.97513
V Predictions Mean           1808.3572
V Predictions Std            341.9461
V Predictions Max            2056.9717
V Predictions Min            -422.13092
Log Pis Mean                 2.240499
Log Pis Std                  3.4375665
Log Pis Max                  15.263859
Log Pis Min                  -5.811512
Policy mu Mean               0.0014584402
Policy mu Std                0.67427754
Policy mu Max                2.8943021
Policy mu Min                -2.7853496
Policy log std Mean          -1.261316
Policy log std Std           0.3469186
Policy log std Max           -0.01635933
Policy log std Min           -2.6777978
Z mean eval                  1.1493021
Z variance eval              0.016689904
total_rewards                [-235.87057765 5007.5988366  3222.0306074  1985.54410701 5077.26326406
 3075.29193265 2734.0057587  4871.35721825 5118.50707743 1967.65974676]
total_rewards_mean           3282.3387971201096
total_rewards_std            1680.1725751681977
total_rewards_max            5118.507077426043
total_rewards_min            -235.87057765316308
Number of train steps total  1832000
Number of env steps total    2292000
Number of rollouts total     0
Train Time (s)               119.04999904986471
(Previous) Eval Time (s)     13.62468900019303
Sample Time (s)              17.62395107652992
Epoch Time (s)               150.29863912658766
Total Train Time (s)         71322.95127466321
Epoch                        457
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:20:19.042773 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #457 | Epoch Duration: 158.51831078529358
2020-01-12 19:20:19.043065 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #457 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1511005
Z variance train             0.016697306
KL Divergence                23.318417
KL Loss                      2.3318417
QF Loss                      1037.2302
VF Loss                      533.7747
Policy Loss                  -1751.9003
Q Predictions Mean           1752.3909
Q Predictions Std            405.14975
Q Predictions Max            1984.1758
Q Predictions Min            -422.77118
V Predictions Mean           1743.7865
V Predictions Std            401.19156
V Predictions Max            1976.5305
V Predictions Min            -469.4656
Log Pis Mean                 2.3304317
Log Pis Std                  3.2610896
Log Pis Max                  12.575851
Log Pis Min                  -4.9047384
Policy mu Mean               0.03805901
Policy mu Std                0.63308483
Policy mu Max                3.3381162
Policy mu Min                -2.8799324
Policy log std Mean          -1.311536
Policy log std Std           0.3438259
Policy log std Max           0.003355503
Policy log std Min           -3.3765087
Z mean eval                  1.1650898
Z variance eval              0.011763597
total_rewards                [4940.50100671 4499.69756344 5001.57281459 5108.55462109 4997.49792259
 4085.14381232 5270.79546534 5174.93400409 5262.25107024 5188.83363696]
total_rewards_mean           4952.978191736403
total_rewards_std            359.00594617105236
total_rewards_max            5270.7954653408315
total_rewards_min            4085.1438123209437
Number of train steps total  1836000
Number of env steps total    2297000
Number of rollouts total     0
Train Time (s)               117.80669560888782
(Previous) Eval Time (s)     21.844039415940642
Sample Time (s)              17.98133615264669
Epoch Time (s)               157.63207117747515
Total Train Time (s)         71485.92010154994
Epoch                        458
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:23:02.017549 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #458 | Epoch Duration: 162.9742591381073
2020-01-12 19:23:02.017802 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #458 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1661513
Z variance train             0.011767507
KL Divergence                24.796236
KL Loss                      2.4796236
QF Loss                      936.223
VF Loss                      183.68513
Policy Loss                  -1758.7351
Q Predictions Mean           1762.5641
Q Predictions Std            399.6935
Q Predictions Max            2009.7468
Q Predictions Min            -478.86502
V Predictions Mean           1754.5396
V Predictions Std            400.4113
V Predictions Max            1999.7688
V Predictions Min            -495.1169
Log Pis Mean                 2.2800055
Log Pis Std                  3.1790373
Log Pis Max                  15.086162
Log Pis Min                  -5.078543
Policy mu Mean               0.019136827
Policy mu Std                0.6833843
Policy mu Max                2.7166605
Policy mu Min                -3.147831
Policy log std Mean          -1.2659702
Policy log std Std           0.3372072
Policy log std Max           0.056877494
Policy log std Min           -2.601988
Z mean eval                  1.1281734
Z variance eval              0.010484995
total_rewards                [  13.226534   5280.91202534   19.06650856  454.60948248 5098.34967719
 5105.41092144 5238.22816754 4572.41910416 5161.57860327 2870.66220633]
total_rewards_mean           3381.4463230308493
total_rewards_std            2214.508609287164
total_rewards_max            5280.912025342561
total_rewards_min            13.22653400212777
Number of train steps total  1840000
Number of env steps total    2302000
Number of rollouts total     0
Train Time (s)               125.89983341703191
(Previous) Eval Time (s)     27.185885722283274
Sample Time (s)              18.657690775580704
Epoch Time (s)               171.7434099148959
Total Train Time (s)         71648.48330317112
Epoch                        459
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:25:44.588854 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #459 | Epoch Duration: 162.57084393501282
2020-01-12 19:25:44.589147 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #459 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1277406
Z variance train             0.010505107
KL Divergence                24.231567
KL Loss                      2.4231567
QF Loss                      1134.6199
VF Loss                      172.10374
Policy Loss                  -1784.8348
Q Predictions Mean           1785.0032
Q Predictions Std            321.7138
Q Predictions Max            2012.8842
Q Predictions Min            -462.30347
V Predictions Mean           1782.7786
V Predictions Std            320.94846
V Predictions Max            2009.6885
V Predictions Min            -492.4334
Log Pis Mean                 1.7283208
Log Pis Std                  3.1694422
Log Pis Max                  16.166006
Log Pis Min                  -8.840281
Policy mu Mean               0.0016805755
Policy mu Std                0.62648433
Policy mu Max                3.0324123
Policy mu Min                -2.9429522
Policy log std Mean          -1.2450296
Policy log std Std           0.3067641
Policy log std Max           -0.012986183
Policy log std Min           -2.4117923
Z mean eval                  1.1532171
Z variance eval              0.009955419
total_rewards                [4943.96024378 5362.25100381 4822.92111716 5290.58135427 5220.59821719
 5205.50462263 5062.78626598 5345.73492646 5093.4789999   958.03467029]
total_rewards_mean           4730.585142146817
total_rewards_std            1268.2629683881767
total_rewards_max            5362.251003812411
total_rewards_min            958.0346702881142
Number of train steps total  1844000
Number of env steps total    2307000
Number of rollouts total     0
Train Time (s)               117.25674650724977
(Previous) Eval Time (s)     18.013006718363613
Sample Time (s)              18.00899284798652
Epoch Time (s)               153.2787460735999
Total Train Time (s)         71808.40517894365
Epoch                        460
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:28:24.513402 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #460 | Epoch Duration: 159.92405796051025
2020-01-12 19:28:24.513547 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #460 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1526172
Z variance train             0.009931682
KL Divergence                25.47187
KL Loss                      2.547187
QF Loss                      998.11835
VF Loss                      144.81952
Policy Loss                  -1817.76
Q Predictions Mean           1817.8115
Q Predictions Std            220.8401
Q Predictions Max            2018.3336
Q Predictions Min            -440.20154
V Predictions Mean           1819.7083
V Predictions Std            222.61237
V Predictions Max            2030.082
V Predictions Min            -437.85864
Log Pis Mean                 2.3990357
Log Pis Std                  3.3099334
Log Pis Max                  13.76852
Log Pis Min                  -5.9412594
Policy mu Mean               0.009579359
Policy mu Std                0.6465258
Policy mu Max                2.765109
Policy mu Min                -2.5323112
Policy log std Mean          -1.3048406
Policy log std Std           0.305528
Policy log std Max           -0.33161658
Policy log std Min           -2.7169733
Z mean eval                  1.107754
Z variance eval              0.02363023
total_rewards                [5262.33827963 5370.09256336 3962.78203461  952.60585136 4981.18939234
 5340.09846902 3243.10066643 1645.07528016 5198.85533229 5305.33820635]
total_rewards_mean           4126.1476075544615
total_rewards_std            1569.0073663905207
total_rewards_max            5370.092563357311
total_rewards_min            952.6058513556477
Number of train steps total  1848000
Number of env steps total    2312000
Number of rollouts total     0
Train Time (s)               120.37623186875135
(Previous) Eval Time (s)     24.657996620982885
Sample Time (s)              18.32137779565528
Epoch Time (s)               163.3556062853895
Total Train Time (s)         71968.67026328156
Epoch                        461
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:31:04.783410 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #461 | Epoch Duration: 160.26973462104797
2020-01-12 19:31:04.783613 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #461 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1083459
Z variance train             0.023637492
KL Divergence                24.937315
KL Loss                      2.4937315
QF Loss                      1276.0745
VF Loss                      963.6163
Policy Loss                  -1808.9658
Q Predictions Mean           1801.1267
Q Predictions Std            332.16046
Q Predictions Max            2020.1578
Q Predictions Min            -500.93234
V Predictions Mean           1806.7725
V Predictions Std            317.05936
V Predictions Max            2024.529
V Predictions Min            -500.6261
Log Pis Mean                 2.4891748
Log Pis Std                  3.7979028
Log Pis Max                  22.698833
Log Pis Min                  -5.795029
Policy mu Mean               -0.0062498013
Policy mu Std                0.6458477
Policy mu Max                2.8803852
Policy mu Min                -2.8275592
Policy log std Mean          -1.3144448
Policy log std Std           0.37587336
Policy log std Max           0.100009084
Policy log std Min           -3.574131
Z mean eval                  1.1641554
Z variance eval              0.014136019
total_rewards                [4998.70874569 5305.73547257 4446.72813306 1456.142143   5102.64172606
 1900.09541201 5169.89972918 1262.47721567 5318.58514636 3519.69746064]
total_rewards_mean           3848.0711184240513
total_rewards_std            1599.9934686503016
total_rewards_max            5318.5851463578
total_rewards_min            1262.477215674488
Number of train steps total  1852000
Number of env steps total    2317000
Number of rollouts total     0
Train Time (s)               119.61025399016216
(Previous) Eval Time (s)     21.57181975990534
Sample Time (s)              17.98051006766036
Epoch Time (s)               159.16258381772786
Total Train Time (s)         72126.78546813689
Epoch                        462
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:33:42.903461 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #462 | Epoch Duration: 158.11970376968384
2020-01-12 19:33:42.903705 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #462 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1645497
Z variance train             0.01409928
KL Divergence                25.90854
KL Loss                      2.5908542
QF Loss                      1975.1265
VF Loss                      281.4613
Policy Loss                  -1824.0265
Q Predictions Mean           1821.302
Q Predictions Std            261.34995
Q Predictions Max            2034.0214
Q Predictions Min            -386.29733
V Predictions Mean           1816.3741
V Predictions Std            257.42908
V Predictions Max            2020.6259
V Predictions Min            -384.88275
Log Pis Mean                 2.245863
Log Pis Std                  3.6288352
Log Pis Max                  13.247352
Log Pis Min                  -9.385578
Policy mu Mean               -0.021469183
Policy mu Std                0.663144
Policy mu Max                2.644643
Policy mu Min                -2.8783815
Policy log std Mean          -1.3172123
Policy log std Std           0.33854502
Policy log std Max           -0.2588848
Policy log std Min           -2.922184
Z mean eval                  1.1262281
Z variance eval              0.014632367
total_rewards                [5006.87814079 1599.0061477  5031.52484091 5089.51236003 5148.56638436
 5265.41972825 5173.16843875 5188.757721   4746.88528215 5097.04098321]
total_rewards_mean           4734.676002715004
total_rewards_std            1053.7298010383483
total_rewards_max            5265.419728253926
total_rewards_min            1599.006147702703
Number of train steps total  1856000
Number of env steps total    2322000
Number of rollouts total     0
Train Time (s)               115.57179874693975
(Previous) Eval Time (s)     20.528632089029998
Sample Time (s)              17.94161684717983
Epoch Time (s)               154.04204768314958
Total Train Time (s)         72287.289117001
Epoch                        463
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:36:23.410540 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #463 | Epoch Duration: 160.50660395622253
2020-01-12 19:36:23.410706 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #463 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1245935
Z variance train             0.014626202
KL Divergence                25.762209
KL Loss                      2.576221
QF Loss                      1188.1346
VF Loss                      982.34094
Policy Loss                  -1805.3225
Q Predictions Mean           1806.615
Q Predictions Std            335.23392
Q Predictions Max            2072.2908
Q Predictions Min            -505.2668
V Predictions Mean           1807.2971
V Predictions Std            319.76382
V Predictions Max            2052.8345
V Predictions Min            -497.2853
Log Pis Mean                 2.1091611
Log Pis Std                  3.4077017
Log Pis Max                  17.406437
Log Pis Min                  -7.537415
Policy mu Mean               0.02481879
Policy mu Std                0.63130605
Policy mu Max                3.0249047
Policy mu Min                -2.664517
Policy log std Mean          -1.3034635
Policy log std Std           0.34716752
Policy log std Max           -0.15839815
Policy log std Min           -3.334375
Z mean eval                  1.1547668
Z variance eval              0.010093478
total_rewards                [5142.80879097 1874.80465498 4857.93683722 5148.0828111  3513.42783363
 5228.82776821 5301.16631171 5066.09105082 5319.44403002 4165.08310231]
total_rewards_mean           4561.767319096512
total_rewards_std            1051.918759809025
total_rewards_max            5319.444030023991
total_rewards_min            1874.8046549787725
Number of train steps total  1860000
Number of env steps total    2327000
Number of rollouts total     0
Train Time (s)               124.23920647287741
(Previous) Eval Time (s)     26.992916787043214
Sample Time (s)              18.564699768088758
Epoch Time (s)               169.79682302800938
Total Train Time (s)         72454.52599934442
Epoch                        464
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:39:10.651171 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #464 | Epoch Duration: 167.24033975601196
2020-01-12 19:39:10.651353 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #464 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.152046
Z variance train             0.010073473
KL Divergence                26.143658
KL Loss                      2.6143658
QF Loss                      841.14026
VF Loss                      714.8103
Policy Loss                  -1813.6982
Q Predictions Mean           1815.1438
Q Predictions Std            314.1915
Q Predictions Max            2026.1953
Q Predictions Min            -502.62012
V Predictions Mean           1820.5856
V Predictions Std            305.47852
V Predictions Max            2030.0847
V Predictions Min            -546.9885
Log Pis Mean                 2.400706
Log Pis Std                  3.5718794
Log Pis Max                  24.86778
Log Pis Min                  -10.153884
Policy mu Mean               0.026658867
Policy mu Std                0.6720541
Policy mu Max                2.6253386
Policy mu Min                -2.667066
Policy log std Mean          -1.2869684
Policy log std Std           0.35517132
Policy log std Max           -0.041294813
Policy log std Min           -3.297483
Z mean eval                  1.1459583
Z variance eval              0.013583531
total_rewards                [ 518.37572676 5412.23311018 5452.9651777  5356.61012669  750.68552834
 5369.62164053 2580.81323093 5376.66318793 4918.55604282 5367.58496335]
total_rewards_mean           4110.410873523209
total_rewards_std            1923.6147639100077
total_rewards_max            5452.965177704622
total_rewards_min            518.3757267550724
Number of train steps total  1864000
Number of env steps total    2332000
Number of rollouts total     0
Train Time (s)               114.59928511781618
(Previous) Eval Time (s)     24.436104412656277
Sample Time (s)              18.215549857355654
Epoch Time (s)               157.2509393878281
Total Train Time (s)         72608.1578230192
Epoch                        465
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:41:44.286327 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #465 | Epoch Duration: 153.634840965271
2020-01-12 19:41:44.286498 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #465 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1460578
Z variance train             0.013579572
KL Divergence                26.03111
KL Loss                      2.603111
QF Loss                      803.23914
VF Loss                      238.2228
Policy Loss                  -1857.6532
Q Predictions Mean           1860.6863
Q Predictions Std            100.795204
Q Predictions Max            2034.7452
Q Predictions Min            1488.2064
V Predictions Mean           1866.2323
V Predictions Std            97.86917
V Predictions Max            2034.4963
V Predictions Min            1523.2301
Log Pis Mean                 2.156034
Log Pis Std                  3.0730345
Log Pis Max                  13.493574
Log Pis Min                  -6.596631
Policy mu Mean               -0.011365476
Policy mu Std                0.60705966
Policy mu Max                2.903038
Policy mu Min                -3.0236483
Policy log std Mean          -1.3103735
Policy log std Std           0.30927962
Policy log std Max           -0.28357345
Policy log std Min           -3.238749
Z mean eval                  1.1272185
Z variance eval              0.014430654
total_rewards                [4918.13260952 5121.33269786 3906.67270171 5174.24842815 4971.33836337
 4920.43836572 5102.3324679  4890.40422647 5089.50921911 5077.22414506]
total_rewards_mean           4917.163322486405
total_rewards_std            349.5914783259324
total_rewards_max            5174.248428146854
total_rewards_min            3906.672701712659
Number of train steps total  1868000
Number of env steps total    2337000
Number of rollouts total     0
Train Time (s)               122.61604013293982
(Previous) Eval Time (s)     20.819695110898465
Sample Time (s)              18.199855471029878
Epoch Time (s)               161.63559071486816
Total Train Time (s)         72776.15768034011
Epoch                        466
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:44:32.291494 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #466 | Epoch Duration: 168.0048429965973
2020-01-12 19:44:32.291714 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #466 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1271325
Z variance train             0.014449622
KL Divergence                26.157707
KL Loss                      2.6157708
QF Loss                      894.51135
VF Loss                      234.26125
Policy Loss                  -1831.5454
Q Predictions Mean           1834.7227
Q Predictions Std            312.09094
Q Predictions Max            2049.329
Q Predictions Min            -454.2239
V Predictions Mean           1832.6357
V Predictions Std            310.6374
V Predictions Max            2051.8005
V Predictions Min            -452.20676
Log Pis Mean                 2.127697
Log Pis Std                  3.2547138
Log Pis Max                  21.039688
Log Pis Min                  -5.1644077
Policy mu Mean               0.011969093
Policy mu Std                0.636787
Policy mu Max                3.0300727
Policy mu Min                -2.8358624
Policy log std Mean          -1.2949874
Policy log std Std           0.32120624
Policy log std Max           -0.046209812
Policy log std Min           -3.0271356
Z mean eval                  1.1432931
Z variance eval              0.005720741
total_rewards                [5164.52868139 5141.37265607 2759.50373106 2112.70949347 3162.87225864
 5042.56420996 3491.69924939 5472.00704808 1174.30437268 4791.63354882]
total_rewards_mean           3831.319524957081
total_rewards_std            1424.7512364011216
total_rewards_max            5472.007048082577
total_rewards_min            1174.3043726807414
Number of train steps total  1872000
Number of env steps total    2342000
Number of rollouts total     0
Train Time (s)               119.12949391175061
(Previous) Eval Time (s)     27.18863807618618
Sample Time (s)              18.05328986281529
Epoch Time (s)               164.37142185075209
Total Train Time (s)         72935.23958524363
Epoch                        467
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:47:11.386447 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #467 | Epoch Duration: 159.0945646762848
2020-01-12 19:47:11.386667 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #467 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1433494
Z variance train             0.0057199225
KL Divergence                27.081444
KL Loss                      2.7081444
QF Loss                      904.99133
VF Loss                      264.5621
Policy Loss                  -1808.0016
Q Predictions Mean           1811.6545
Q Predictions Std            367.3704
Q Predictions Max            2069.689
Q Predictions Min            -477.41132
V Predictions Mean           1802.0983
V Predictions Std            371.82776
V Predictions Max            2056.3884
V Predictions Min            -490.7754
Log Pis Mean                 2.4759173
Log Pis Std                  4.0619764
Log Pis Max                  33.88235
Log Pis Min                  -5.3193884
Policy mu Mean               -0.0064059887
Policy mu Std                0.69069904
Policy mu Max                4.2316823
Policy mu Min                -4.791479
Policy log std Mean          -1.2949022
Policy log std Std           0.32940722
Policy log std Max           0.42124057
Policy log std Min           -3.628448
Z mean eval                  1.130374
Z variance eval              0.007714927
total_rewards                [5014.2196906  5285.0437052   102.83944679 4000.99742478 2780.28379336
 5211.74109526 2921.12981633  679.44067936 5309.00871898  312.29054834]
total_rewards_mean           3161.6994919001545
total_rewards_std            2032.2196452819708
total_rewards_max            5309.008718979103
total_rewards_min            102.8394467869788
Number of train steps total  1876000
Number of env steps total    2347000
Number of rollouts total     0
Train Time (s)               118.2719297572039
(Previous) Eval Time (s)     21.911521329078823
Sample Time (s)              17.93476348556578
Epoch Time (s)               158.1182145718485
Total Train Time (s)         73088.07298368169
Epoch                        468
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:49:44.228949 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #468 | Epoch Duration: 152.84210991859436
2020-01-12 19:49:44.229247 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #468 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1304461
Z variance train             0.0077184737
KL Divergence                26.78844
KL Loss                      2.6788442
QF Loss                      1026.7183
VF Loss                      153.6612
Policy Loss                  -1866.9264
Q Predictions Mean           1872.3005
Q Predictions Std            270.72525
Q Predictions Max            2104.021
Q Predictions Min            -533.38196
V Predictions Mean           1865.5469
V Predictions Std            270.60925
V Predictions Max            2098.2988
V Predictions Min            -537.4084
Log Pis Mean                 2.66166
Log Pis Std                  3.5323927
Log Pis Max                  14.161367
Log Pis Min                  -6.571899
Policy mu Mean               0.0056020645
Policy mu Std                0.7225426
Policy mu Max                3.2211666
Policy mu Min                -3.4243953
Policy log std Mean          -1.3017042
Policy log std Std           0.3466968
Policy log std Max           0.06745374
Policy log std Min           -2.5283408
Z mean eval                  1.1095234
Z variance eval              0.005276942
total_rewards                [5220.88478323 5319.33361909 4980.38830608 5236.6876754  5196.25925158
 5271.05450227 5266.08660392 5093.25262924 5195.73774893 5420.18025298]
total_rewards_mean           5219.986537271607
total_rewards_std            113.83322809654116
total_rewards_max            5420.180252978629
total_rewards_min            4980.388306076416
Number of train steps total  1880000
Number of env steps total    2352000
Number of rollouts total     0
Train Time (s)               121.52363811712712
(Previous) Eval Time (s)     16.635088374838233
Sample Time (s)              18.320464584510773
Epoch Time (s)               156.47919107647613
Total Train Time (s)         73254.90864169411
Epoch                        469
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:52:31.069907 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #469 | Epoch Duration: 166.84042406082153
2020-01-12 19:52:31.070134 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #469 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1094584
Z variance train             0.0052807704
KL Divergence                25.862324
KL Loss                      2.5862324
QF Loss                      863.2523
VF Loss                      151.17969
Policy Loss                  -1826.1736
Q Predictions Mean           1830.065
Q Predictions Std            329.58624
Q Predictions Max            2073.1104
Q Predictions Min            -503.61365
V Predictions Mean           1819.4224
V Predictions Std            328.6314
V Predictions Max            2058.472
V Predictions Min            -510.99655
Log Pis Mean                 2.3428516
Log Pis Std                  3.3424153
Log Pis Max                  12.636223
Log Pis Min                  -5.4523015
Policy mu Mean               0.0208936
Policy mu Std                0.6845836
Policy mu Max                2.8087423
Policy mu Min                -2.8369923
Policy log std Mean          -1.2542827
Policy log std Std           0.34727305
Policy log std Max           -0.2066977
Policy log std Min           -2.6571789
Z mean eval                  1.1572002
Z variance eval              0.0055280426
total_rewards                [4931.75482399 5222.72140855 2416.0167452  1637.75988436 5077.88486447
 1542.44491775  945.53653679 5191.21875758 5315.58975575 5231.62275321]
total_rewards_mean           3751.255044766088
total_rewards_std            1761.5756706527984
total_rewards_max            5315.5897557522485
total_rewards_min            945.5365367912368
Number of train steps total  1884000
Number of env steps total    2357000
Number of rollouts total     0
Train Time (s)               119.22217995719984
(Previous) Eval Time (s)     26.995979947969317
Sample Time (s)              18.130839556455612
Epoch Time (s)               164.34899946162477
Total Train Time (s)         73411.96108476724
Epoch                        470
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:55:08.128371 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #470 | Epoch Duration: 157.05805349349976
2020-01-12 19:55:08.128613 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #470 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1569251
Z variance train             0.0055279275
KL Divergence                25.74947
KL Loss                      2.574947
QF Loss                      1305.0427
VF Loss                      479.57755
Policy Loss                  -1845.9932
Q Predictions Mean           1845.5657
Q Predictions Std            317.1385
Q Predictions Max            2092.8687
Q Predictions Min            -509.71652
V Predictions Mean           1841.669
V Predictions Std            300.18243
V Predictions Max            2072.4849
V Predictions Min            -479.4907
Log Pis Mean                 2.4293776
Log Pis Std                  3.4428844
Log Pis Max                  14.824177
Log Pis Min                  -6.3441215
Policy mu Mean               0.021021627
Policy mu Std                0.66319984
Policy mu Max                2.8900518
Policy mu Min                -2.854857
Policy log std Mean          -1.2926803
Policy log std Std           0.33292094
Policy log std Max           -0.11143577
Policy log std Min           -2.844156
Z mean eval                  1.2157906
Z variance eval              0.003705558
total_rewards                [4988.41154309 5322.6369087  4315.32463719 5164.39907093 5213.14108729
 1267.849811   5353.34550908 5002.10002852 4977.88782375  318.36675797]
total_rewards_mean           4192.34631775244
total_rewards_std            1734.7738165558512
total_rewards_max            5353.345509076478
total_rewards_min            318.36675797480837
Number of train steps total  1888000
Number of env steps total    2362000
Number of rollouts total     0
Train Time (s)               120.42811271408573
(Previous) Eval Time (s)     19.704747319221497
Sample Time (s)              18.437189135234803
Epoch Time (s)               158.57004916854203
Total Train Time (s)         73572.43152588792
Epoch                        471
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:57:48.606135 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #471 | Epoch Duration: 160.47734928131104
2020-01-12 19:57:48.606335 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #471 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2153692
Z variance train             0.0037038405
KL Divergence                26.597645
KL Loss                      2.6597645
QF Loss                      3380.4907
VF Loss                      714.261
Policy Loss                  -1838.46
Q Predictions Mean           1840.3809
Q Predictions Std            305.00742
Q Predictions Max            2060.3882
Q Predictions Min            -477.27625
V Predictions Mean           1834.8013
V Predictions Std            300.4116
V Predictions Max            2062.732
V Predictions Min            -480.9577
Log Pis Mean                 2.3023765
Log Pis Std                  3.3868082
Log Pis Max                  19.675865
Log Pis Min                  -6.58866
Policy mu Mean               0.014216492
Policy mu Std                0.65806615
Policy mu Max                2.8376849
Policy mu Min                -2.8731282
Policy log std Mean          -1.3099818
Policy log std Std           0.34993854
Policy log std Max           -0.21479475
Policy log std Min           -3.2238874
Z mean eval                  1.144782
Z variance eval              0.00535953
total_rewards                [2351.89695345  483.24430518 1144.34049341 4174.2722962   779.55230214
 4195.46058039 -263.36237729 5061.12516892 5258.79636609 5173.15267271]
total_rewards_mean           2835.847876119507
total_rewards_std            2058.8604548791272
total_rewards_max            5258.796366091137
total_rewards_min            -263.3623772868704
Number of train steps total  1892000
Number of env steps total    2367000
Number of rollouts total     0
Train Time (s)               118.18781015416607
(Previous) Eval Time (s)     21.61172827705741
Sample Time (s)              18.291657478082925
Epoch Time (s)               158.0911959093064
Total Train Time (s)         73726.64569478855
Epoch                        472
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:00:22.823402 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #472 | Epoch Duration: 154.21692037582397
2020-01-12 20:00:22.823658 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #472 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1454049
Z variance train             0.005369275
KL Divergence                25.880932
KL Loss                      2.5880933
QF Loss                      884.03735
VF Loss                      166.86421
Policy Loss                  -1861.6361
Q Predictions Mean           1867.4045
Q Predictions Std            269.331
Q Predictions Max            2087.4187
Q Predictions Min            -317.57706
V Predictions Mean           1863.3572
V Predictions Std            275.63348
V Predictions Max            2085.628
V Predictions Min            -347.79697
Log Pis Mean                 2.3617911
Log Pis Std                  3.4078803
Log Pis Max                  17.197271
Log Pis Min                  -6.881526
Policy mu Mean               -0.008136368
Policy mu Std                0.6417251
Policy mu Max                2.3770564
Policy mu Min                -2.596145
Policy log std Mean          -1.3159862
Policy log std Std           0.35090038
Policy log std Max           -0.21921301
Policy log std Min           -3.4846797
Z mean eval                  1.1145437
Z variance eval              0.007576613
total_rewards                [5341.89779426  111.31562003 5041.23411996 5534.64070676 5255.40295111
 5338.38615653 5239.73122974 5088.98376292 5134.90743441 5534.34157671]
total_rewards_mean           4762.084135243755
total_rewards_std            1558.4118963557548
total_rewards_max            5534.640706763414
total_rewards_min            111.31562003117651
Number of train steps total  1896000
Number of env steps total    2372000
Number of rollouts total     0
Train Time (s)               120.19885325757787
(Previous) Eval Time (s)     17.737158325035125
Sample Time (s)              17.986080698668957
Epoch Time (s)               155.92209228128195
Total Train Time (s)         73892.45837732498
Epoch                        473
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:03:08.643206 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #473 | Epoch Duration: 165.81934309005737
2020-01-12 20:03:08.643462 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #473 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1143488
Z variance train             0.0075873025
KL Divergence                25.063795
KL Loss                      2.5063796
QF Loss                      1142.7708
VF Loss                      287.05295
Policy Loss                  -1857.9021
Q Predictions Mean           1860.3804
Q Predictions Std            224.68942
Q Predictions Max            2057.9023
Q Predictions Min            -435.8363
V Predictions Mean           1846.6475
V Predictions Std            223.60196
V Predictions Max            2044.983
V Predictions Min            -453.51154
Log Pis Mean                 2.4635477
Log Pis Std                  2.9732764
Log Pis Max                  12.788095
Log Pis Min                  -6.6162877
Policy mu Mean               -0.0012537551
Policy mu Std                0.636298
Policy mu Max                2.935354
Policy mu Min                -2.2721438
Policy log std Mean          -1.3228999
Policy log std Std           0.31096095
Policy log std Max           -0.14728379
Policy log std Min           -2.603706
Z mean eval                  1.1063616
Z variance eval              0.0046671215
total_rewards                [5248.77863385 5253.14052673 5145.91963712 5198.74399477 2107.66124565
 5296.90390112 5398.78134589  404.83357749 5268.35274487 1453.37389927]
total_rewards_mean           4077.6489506770317
total_rewards_std            1845.4911100255638
total_rewards_max            5398.781345894934
total_rewards_min            404.83357749059167
Number of train steps total  1900000
Number of env steps total    2377000
Number of rollouts total     0
Train Time (s)               116.29682124964893
(Previous) Eval Time (s)     27.63406554982066
Sample Time (s)              18.228711996227503
Epoch Time (s)               162.1595987956971
Total Train Time (s)         74048.36259129038
Epoch                        474
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:05:44.554792 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #474 | Epoch Duration: 155.9111204147339
2020-01-12 20:05:44.555053 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #474 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1057576
Z variance train             0.00466518
KL Divergence                26.029392
KL Loss                      2.6029394
QF Loss                      1072.5393
VF Loss                      450.88367
Policy Loss                  -1848.8912
Q Predictions Mean           1847.8293
Q Predictions Std            328.29904
Q Predictions Max            2078.7686
Q Predictions Min            -469.23334
V Predictions Mean           1843.0823
V Predictions Std            311.73514
V Predictions Max            2078.7856
V Predictions Min            -459.00027
Log Pis Mean                 2.5386195
Log Pis Std                  3.5986395
Log Pis Max                  15.48147
Log Pis Min                  -7.538719
Policy mu Mean               0.03626599
Policy mu Std                0.66192645
Policy mu Max                2.7767613
Policy mu Min                -2.8141441
Policy log std Mean          -1.3250284
Policy log std Std           0.35736147
Policy log std Max           -0.3639785
Policy log std Min           -3.4649026
Z mean eval                  1.14788
Z variance eval              0.0052586254
total_rewards                [5191.09118291 5200.3842411  5420.16746986 5388.13891791 5166.40961846
 5594.99992021 5308.13026216  633.0752431  5261.798299   5428.17471896]
total_rewards_mean           4859.236987367569
total_rewards_std            1414.3650535046297
total_rewards_max            5594.999920211121
total_rewards_min            633.0752430953262
Number of train steps total  1904000
Number of env steps total    2382000
Number of rollouts total     0
Train Time (s)               121.68824779614806
(Previous) Eval Time (s)     21.385263181757182
Sample Time (s)              19.599758831318468
Epoch Time (s)               162.6732698092237
Total Train Time (s)         74216.67179074232
Epoch                        475
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:08:32.871148 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #475 | Epoch Duration: 168.31587672233582
2020-01-12 20:08:32.871417 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #475 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1482911
Z variance train             0.0052552437
KL Divergence                25.992498
KL Loss                      2.5992498
QF Loss                      1311.4355
VF Loss                      905.8815
Policy Loss                  -1872.6418
Q Predictions Mean           1873.6263
Q Predictions Std            286.59784
Q Predictions Max            2093.8738
Q Predictions Min            -476.8558
V Predictions Mean           1875.0923
V Predictions Std            279.68622
V Predictions Max            2086.9275
V Predictions Min            -486.58472
Log Pis Mean                 2.3901613
Log Pis Std                  3.3425744
Log Pis Max                  13.452059
Log Pis Min                  -4.9665294
Policy mu Mean               0.019688992
Policy mu Std                0.639536
Policy mu Max                2.7577515
Policy mu Min                -2.8582125
Policy log std Mean          -1.3248305
Policy log std Std           0.34207764
Policy log std Max           -0.23905373
Policy log std Min           -3.3439176
Z mean eval                  1.1377527
Z variance eval              0.00823763
total_rewards                [4936.72005768 5353.58494608 5122.43709011 5252.48590713 5271.77613795
 2447.17883246 5088.06342771 5336.98352251 5206.16735177 5410.09924993]
total_rewards_mean           4942.549652334006
total_rewards_std            842.4677341668981
total_rewards_max            5410.099249931992
total_rewards_min            2447.178832462463
Number of train steps total  1908000
Number of env steps total    2387000
Number of rollouts total     0
Train Time (s)               116.98316900990903
(Previous) Eval Time (s)     27.02753229532391
Sample Time (s)              18.850313439499587
Epoch Time (s)               162.86101474473253
Total Train Time (s)         74377.87234445894
Epoch                        476
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:11:14.077173 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #476 | Epoch Duration: 161.20556640625
2020-01-12 20:11:14.077349 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #476 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1386795
Z variance train             0.008257614
KL Divergence                25.421078
KL Loss                      2.5421078
QF Loss                      1021.4443
VF Loss                      326.78784
Policy Loss                  -1861.6495
Q Predictions Mean           1863.228
Q Predictions Std            285.40314
Q Predictions Max            2084.7932
Q Predictions Min            -456.32007
V Predictions Mean           1854.4475
V Predictions Std            282.92456
V Predictions Max            2066.3342
V Predictions Min            -497.3808
Log Pis Mean                 2.4301033
Log Pis Std                  3.3853974
Log Pis Max                  17.102356
Log Pis Min                  -6.271121
Policy mu Mean               0.025686339
Policy mu Std                0.62975645
Policy mu Max                2.881615
Policy mu Min                -2.9633284
Policy log std Mean          -1.3288753
Policy log std Std           0.34280148
Policy log std Max           -0.058672667
Policy log std Min           -3.0474243
Z mean eval                  1.1113458
Z variance eval              0.0053065848
total_rewards                [5061.73131543 1050.43203052 5497.9214596  2630.51571586 2817.65919042
 4935.30153777  874.23704196 5106.91348852 5156.99909871  956.25973453]
total_rewards_mean           3408.797061330863
total_rewards_std            1852.6371302824796
total_rewards_max            5497.9214595974945
total_rewards_min            874.2370419624411
Number of train steps total  1912000
Number of env steps total    2392000
Number of rollouts total     0
Train Time (s)               121.23404773976654
(Previous) Eval Time (s)     25.371752540115267
Sample Time (s)              17.67501810239628
Epoch Time (s)               164.28081838227808
Total Train Time (s)         74537.41704820096
Epoch                        477
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:13:53.628072 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #477 | Epoch Duration: 159.55054140090942
2020-01-12 20:13:53.628361 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #477 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1114256
Z variance train             0.005307017
KL Divergence                26.379322
KL Loss                      2.6379323
QF Loss                      1398.5227
VF Loss                      109.5312
Policy Loss                  -1905.3798
Q Predictions Mean           1909.1626
Q Predictions Std            225.60522
Q Predictions Max            2099.566
Q Predictions Min            -373.08517
V Predictions Mean           1905.719
V Predictions Std            223.13574
V Predictions Max            2103.0103
V Predictions Min            -331.30765
Log Pis Mean                 2.3435962
Log Pis Std                  3.3101554
Log Pis Max                  13.359991
Log Pis Min                  -7.6455793
Policy mu Mean               0.011054162
Policy mu Std                0.67054695
Policy mu Max                2.61563
Policy mu Min                -3.0939016
Policy log std Mean          -1.3114488
Policy log std Std           0.3197584
Policy log std Max           -0.2778796
Policy log std Min           -2.5584517
Z mean eval                  1.1258631
Z variance eval              0.006892073
total_rewards                [5123.75206715 5285.30277165 5210.4376311  5179.69252869 5083.13729585
 5266.29331691 5004.81267331 4816.95464519 5356.40312933 4989.72012774]
total_rewards_mean           5131.650618692705
total_rewards_std            154.4177333632703
total_rewards_max            5356.403129333096
total_rewards_min            4816.954645190627
Number of train steps total  1916000
Number of env steps total    2397000
Number of rollouts total     0
Train Time (s)               114.02827143436298
(Previous) Eval Time (s)     20.641163328662515
Sample Time (s)              18.63951762812212
Epoch Time (s)               153.3089523911476
Total Train Time (s)         74696.46217907127
Epoch                        478
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:16:32.676109 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #478 | Epoch Duration: 159.04754662513733
2020-01-12 20:16:32.676283 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #478 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1251913
Z variance train             0.0069035566
KL Divergence                25.792475
KL Loss                      2.5792475
QF Loss                      683.7678
VF Loss                      127.95817
Policy Loss                  -1886.9326
Q Predictions Mean           1890.7063
Q Predictions Std            229.09483
Q Predictions Max            2109.686
Q Predictions Min            -442.10364
V Predictions Mean           1887.1799
V Predictions Std            229.30678
V Predictions Max            2103.5698
V Predictions Min            -443.104
Log Pis Mean                 2.36337
Log Pis Std                  3.3942354
Log Pis Max                  15.97747
Log Pis Min                  -6.4557905
Policy mu Mean               -0.019269142
Policy mu Std                0.6690534
Policy mu Max                2.7288315
Policy mu Min                -2.6390004
Policy log std Mean          -1.3001618
Policy log std Std           0.33252934
Policy log std Max           -0.01634717
Policy log std Min           -2.652751
Z mean eval                  1.1696551
Z variance eval              0.00469909
total_rewards                [ 221.65245341 5258.66305402 3607.21518767 4521.36678372 1147.04955673
 5327.05748876 4011.53939421 1931.55756568  114.31554426 5133.02286657]
total_rewards_mean           3127.343989501048
total_rewards_std            1980.7130168071612
total_rewards_max            5327.057488757071
total_rewards_min            114.31554425614705
Number of train steps total  1920000
Number of env steps total    2402000
Number of rollouts total     0
Train Time (s)               119.17862857505679
(Previous) Eval Time (s)     26.379486568272114
Sample Time (s)              17.923980155028403
Epoch Time (s)               163.4820952983573
Total Train Time (s)         74849.99081662204
Epoch                        479
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:19:06.207896 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #479 | Epoch Duration: 153.53142642974854
2020-01-12 20:19:06.208054 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #479 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1698042
Z variance train             0.004694448
KL Divergence                26.872454
KL Loss                      2.6872454
QF Loss                      1033.9474
VF Loss                      206.48373
Policy Loss                  -1897.73
Q Predictions Mean           1897.0911
Q Predictions Std            312.18488
Q Predictions Max            2140.759
Q Predictions Min            -383.6319
V Predictions Mean           1894.8159
V Predictions Std            299.54416
V Predictions Max            2136.9285
V Predictions Min            -384.06244
Log Pis Mean                 2.3353286
Log Pis Std                  3.713244
Log Pis Max                  16.85176
Log Pis Min                  -6.373816
Policy mu Mean               0.019412203
Policy mu Std                0.6750872
Policy mu Max                3.0915616
Policy mu Min                -3.096323
Policy log std Mean          -1.299622
Policy log std Std           0.3188885
Policy log std Max           -0.17601073
Policy log std Min           -2.6550188
Z mean eval                  1.2447679
Z variance eval              0.008329462
total_rewards                [5197.69267275 5134.10897315 4886.99608726 4523.38885211 5372.31023678
 5272.44200899 1732.42874441 5283.34878829 4708.25331991 3683.21759283]
total_rewards_mean           4579.418727648602
total_rewards_std            1063.827507335945
total_rewards_max            5372.310236776853
total_rewards_min            1732.4287444078475
Number of train steps total  1924000
Number of env steps total    2407000
Number of rollouts total     0
Train Time (s)               109.63974723825231
(Previous) Eval Time (s)     16.428520790301263
Sample Time (s)              18.122900737449527
Epoch Time (s)               144.1911687660031
Total Train Time (s)         75000.9202016308
Epoch                        480
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:21:37.142342 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #480 | Epoch Duration: 150.93414068222046
2020-01-12 20:21:37.142566 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #480 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2425047
Z variance train             0.00834146
KL Divergence                25.980967
KL Loss                      2.5980966
QF Loss                      872.34094
VF Loss                      169.58417
Policy Loss                  -1873.9656
Q Predictions Mean           1875.8196
Q Predictions Std            359.84818
Q Predictions Max            2112.7878
Q Predictions Min            -572.0579
V Predictions Mean           1877.0964
V Predictions Std            351.07648
V Predictions Max            2105.627
V Predictions Min            -406.24988
Log Pis Mean                 2.3720438
Log Pis Std                  3.538783
Log Pis Max                  12.896666
Log Pis Min                  -6.5951986
Policy mu Mean               0.026287872
Policy mu Std                0.6595158
Policy mu Max                3.061602
Policy mu Min                -2.9485316
Policy log std Mean          -1.2764944
Policy log std Std           0.32988095
Policy log std Max           0.20966613
Policy log std Min           -2.5519838
Z mean eval                  1.1218475
Z variance eval              0.017689984
total_rewards                [4994.83592012 4911.81962601 5149.16398931 5103.08789594 5347.60436925
 5046.95579206 5392.28201284 5316.6586191  5197.04170171 4689.78107991]
total_rewards_mean           5114.923100626467
total_rewards_std            205.148477612831
total_rewards_max            5392.282012840233
total_rewards_min            4689.781079912794
Number of train steps total  1928000
Number of env steps total    2412000
Number of rollouts total     0
Train Time (s)               113.38085499871522
(Previous) Eval Time (s)     23.171190790832043
Sample Time (s)              17.86255395365879
Epoch Time (s)               154.41459974320605
Total Train Time (s)         75158.88313006377
Epoch                        481
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:24:15.108500 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #481 | Epoch Duration: 157.9657814502716
2020-01-12 20:24:15.108660 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #481 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1225067
Z variance train             0.017672446
KL Divergence                25.87036
KL Loss                      2.587036
QF Loss                      14419.392
VF Loss                      1345.5565
Policy Loss                  -1915.4515
Q Predictions Mean           1922.4082
Q Predictions Std            139.54807
Q Predictions Max            2113.432
Q Predictions Min            263.97614
V Predictions Mean           1911.4054
V Predictions Std            137.14265
V Predictions Max            2101.4229
V Predictions Min            331.3789
Log Pis Mean                 2.5867963
Log Pis Std                  3.4613574
Log Pis Max                  14.3846855
Log Pis Min                  -5.460709
Policy mu Mean               0.027239788
Policy mu Std                0.66609925
Policy mu Max                2.8047326
Policy mu Min                -2.3737392
Policy log std Mean          -1.3111225
Policy log std Std           0.3480679
Policy log std Max           -0.19586623
Policy log std Min           -3.1063828
Z mean eval                  1.1564255
Z variance eval              0.0085084895
total_rewards                [3293.07052374 5326.3181056  4961.42323339 5061.14879027 5175.02034464
  787.12094098 5326.5546361  5464.22770846 4948.08835122 5284.13026048]
total_rewards_mean           4562.710289488341
total_rewards_std            1389.1597597843945
total_rewards_max            5464.227708456766
total_rewards_min            787.1209409823255
Number of train steps total  1932000
Number of env steps total    2417000
Number of rollouts total     0
Train Time (s)               122.257156716194
(Previous) Eval Time (s)     26.722079925239086
Sample Time (s)              17.92700763233006
Epoch Time (s)               166.90624427376315
Total Train Time (s)         75323.49663465703
Epoch                        482
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:26:59.729720 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #482 | Epoch Duration: 164.62091588974
2020-01-12 20:26:59.729962 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #482 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1558337
Z variance train             0.008525972
KL Divergence                25.966381
KL Loss                      2.5966382
QF Loss                      3154.6094
VF Loss                      202.98557
Policy Loss                  -1868.0912
Q Predictions Mean           1872.0361
Q Predictions Std            338.20602
Q Predictions Max            2118.8157
Q Predictions Min            -364.59344
V Predictions Mean           1865.4932
V Predictions Std            339.1345
V Predictions Max            2113.1304
V Predictions Min            -383.4734
Log Pis Mean                 2.7808867
Log Pis Std                  3.808581
Log Pis Max                  14.771416
Log Pis Min                  -8.688873
Policy mu Mean               0.011590097
Policy mu Std                0.70802754
Policy mu Max                3.079045
Policy mu Min                -2.8459246
Policy log std Mean          -1.3106678
Policy log std Std           0.3398942
Policy log std Max           0.011617899
Policy log std Min           -2.663156
Z mean eval                  1.1495628
Z variance eval              0.011679639
total_rewards                [5377.42312736 5225.67708091 5073.14946662 5235.13980652 5366.54091377
 5261.15220181 5323.88216544 2738.85961816 5491.81266882 5215.79934463]
total_rewards_mean           5030.943639406361
total_rewards_std            771.5634842701849
total_rewards_max            5491.812668823472
total_rewards_min            2738.8596181648813
Number of train steps total  1936000
Number of env steps total    2422000
Number of rollouts total     0
Train Time (s)               112.310607614927
(Previous) Eval Time (s)     24.43645139085129
Sample Time (s)              18.809300088323653
Epoch Time (s)               155.55635909410194
Total Train Time (s)         75480.3729663142
Epoch                        483
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:29:36.609589 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #483 | Epoch Duration: 156.8794548511505
2020-01-12 20:29:36.609789 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #483 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1503876
Z variance train             0.011799997
KL Divergence                25.389198
KL Loss                      2.53892
QF Loss                      676.3701
VF Loss                      265.9173
Policy Loss                  -1902.1179
Q Predictions Mean           1906.3369
Q Predictions Std            267.32077
Q Predictions Max            2114.5112
Q Predictions Min            -347.21402
V Predictions Mean           1911.6628
V Predictions Std            264.52393
V Predictions Max            2117.5776
V Predictions Min            -314.5703
Log Pis Mean                 2.4704785
Log Pis Std                  3.386133
Log Pis Max                  12.853193
Log Pis Min                  -6.576324
Policy mu Mean               0.013932388
Policy mu Std                0.6639827
Policy mu Max                2.6844838
Policy mu Min                -2.816933
Policy log std Mean          -1.3039634
Policy log std Std           0.33324614
Policy log std Max           -0.11420035
Policy log std Min           -2.5843387
Z mean eval                  1.1544108
Z variance eval              0.0056250636
total_rewards                [5102.6204851  5337.90936026 5220.84808456 5379.13482425 5513.8639791
 5338.9008497  5380.60420318 5350.39463527 1559.27732176 5166.54623764]
total_rewards_mean           4935.009998081936
total_rewards_std            1130.8337596803553
total_rewards_max            5513.8639791035885
total_rewards_min            1559.2773217575063
Number of train steps total  1940000
Number of env steps total    2427000
Number of rollouts total     0
Train Time (s)               117.6285071047023
(Previous) Eval Time (s)     25.759217315353453
Sample Time (s)              18.30118097597733
Epoch Time (s)               161.68890539603308
Total Train Time (s)         75641.2756166691
Epoch                        484
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:32:17.515743 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #484 | Epoch Duration: 160.90580439567566
2020-01-12 20:32:17.515925 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #484 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1573066
Z variance train             0.005644014
KL Divergence                25.817177
KL Loss                      2.5817177
QF Loss                      2535.3958
VF Loss                      497.22968
Policy Loss                  -1870.7584
Q Predictions Mean           1875.4829
Q Predictions Std            347.58356
Q Predictions Max            2131.8203
Q Predictions Min            -496.46506
V Predictions Mean           1870.8716
V Predictions Std            353.1091
V Predictions Max            2117.688
V Predictions Min            -506.9387
Log Pis Mean                 2.611281
Log Pis Std                  3.6938217
Log Pis Max                  20.41534
Log Pis Min                  -5.1382484
Policy mu Mean               0.004561905
Policy mu Std                0.6561741
Policy mu Max                2.5028257
Policy mu Min                -2.7302098
Policy log std Mean          -1.3457346
Policy log std Std           0.36162362
Policy log std Max           -0.2346549
Policy log std Min           -3.458571
Z mean eval                  1.147736
Z variance eval              0.012103735
total_rewards                [4939.36860326 5364.37361078 3406.3328483  5657.89126055 5331.97426329
 5098.8178741  4698.04726928 5595.7559182  5759.1382582  5307.39926033]
total_rewards_mean           5115.909916628616
total_rewards_std            648.9643100796836
total_rewards_max            5759.138258196408
total_rewards_min            3406.332848304951
Number of train steps total  1944000
Number of env steps total    2432000
Number of rollouts total     0
Train Time (s)               123.71278789406642
(Previous) Eval Time (s)     24.975822146050632
Sample Time (s)              19.41436178330332
Epoch Time (s)               168.10297182342038
Total Train Time (s)         75810.30306694936
Epoch                        485
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:35:06.550129 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #485 | Epoch Duration: 169.03404879570007
2020-01-12 20:35:06.550377 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #485 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1476645
Z variance train             0.012012775
KL Divergence                26.45325
KL Loss                      2.6453252
QF Loss                      1195.4856
VF Loss                      383.28436
Policy Loss                  -1920.2362
Q Predictions Mean           1923.2051
Q Predictions Std            246.04575
Q Predictions Max            2115.0603
Q Predictions Min            -452.18762
V Predictions Mean           1920.334
V Predictions Std            246.66254
V Predictions Max            2107.3354
V Predictions Min            -446.94754
Log Pis Mean                 2.3236394
Log Pis Std                  3.5601127
Log Pis Max                  14.991515
Log Pis Min                  -6.198384
Policy mu Mean               0.039802484
Policy mu Std                0.6314346
Policy mu Max                2.97019
Policy mu Min                -2.7289493
Policy log std Mean          -1.3196592
Policy log std Std           0.35445556
Policy log std Max           1.0132927
Policy log std Min           -3.0502684
Z mean eval                  1.1347083
Z variance eval              0.0049859276
total_rewards                [5131.31114228  550.57576266 5359.3826401  5269.90323716 3707.6631634
 5662.60545148 4163.24005511 5429.80017153 5116.30616492 5498.8699492 ]
total_rewards_mean           4588.965773783575
total_rewards_std            1469.1359765083498
total_rewards_max            5662.605451476123
total_rewards_min            550.57576266271
Number of train steps total  1948000
Number of env steps total    2437000
Number of rollouts total     0
Train Time (s)               115.5791283287108
(Previous) Eval Time (s)     25.906581601127982
Sample Time (s)              18.501371273305267
Epoch Time (s)               159.98708120314404
Total Train Time (s)         75967.76502951793
Epoch                        486
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:37:44.018708 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #486 | Epoch Duration: 157.46812653541565
2020-01-12 20:37:44.018967 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #486 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1340013
Z variance train             0.004980939
KL Divergence                27.195024
KL Loss                      2.7195024
QF Loss                      688.5653
VF Loss                      153.90323
Policy Loss                  -1905.3074
Q Predictions Mean           1909.3539
Q Predictions Std            336.47873
Q Predictions Max            2127.5825
Q Predictions Min            -466.2405
V Predictions Mean           1900.1418
V Predictions Std            334.49734
V Predictions Max            2108.4626
V Predictions Min            -452.708
Log Pis Mean                 2.2099364
Log Pis Std                  3.4870532
Log Pis Max                  13.871056
Log Pis Min                  -5.831571
Policy mu Mean               -0.02223378
Policy mu Std                0.6568981
Policy mu Max                3.2264447
Policy mu Min                -2.918381
Policy log std Mean          -1.2933091
Policy log std Std           0.3545784
Policy log std Max           -0.18670666
Policy log std Min           -2.660963
Z mean eval                  1.1293721
Z variance eval              0.00882499
total_rewards                [5422.90834529 5688.24382489 3496.74092308 5285.39370058 5461.33531541
 5353.43946851 3641.52506437 5280.90768105 5607.78041427 5279.97997075]
total_rewards_mean           5051.825470821698
total_rewards_std            753.4459819101436
total_rewards_max            5688.243824888629
total_rewards_min            3496.7409230826006
Number of train steps total  1952000
Number of env steps total    2442000
Number of rollouts total     0
Train Time (s)               121.63823105813935
(Previous) Eval Time (s)     23.38732252502814
Sample Time (s)              17.59166418062523
Epoch Time (s)               162.61721776379272
Total Train Time (s)         76131.82215507748
Epoch                        487
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:40:28.079391 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #487 | Epoch Duration: 164.060240983963
2020-01-12 20:40:28.079615 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #487 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1301553
Z variance train             0.008820181
KL Divergence                27.358429
KL Loss                      2.735843
QF Loss                      1642.0492
VF Loss                      368.97766
Policy Loss                  -1896.8468
Q Predictions Mean           1898.0415
Q Predictions Std            337.6729
Q Predictions Max            2109.914
Q Predictions Min            -468.7302
V Predictions Mean           1884.22
V Predictions Std            334.0205
V Predictions Max            2097.176
V Predictions Min            -449.77448
Log Pis Mean                 2.436971
Log Pis Std                  3.4557538
Log Pis Max                  14.490029
Log Pis Min                  -7.541819
Policy mu Mean               0.027916525
Policy mu Std                0.64870316
Policy mu Max                3.362797
Policy mu Min                -3.0588477
Policy log std Mean          -1.3270805
Policy log std Std           0.33299276
Policy log std Max           0.13940144
Policy log std Min           -2.6409936
Z mean eval                  1.1213089
Z variance eval              0.0073696496
total_rewards                [ 5.48419990e+03  1.05113365e+02  5.47605532e+03 -2.84599926e+00
  1.04607129e+03  3.40915249e+03  5.42639592e+03  5.09688182e+03
  5.21115426e+03  5.53094157e+03]
total_rewards_mean           3678.3119928425026
total_rewards_std            2250.842115530586
total_rewards_max            5530.941571686796
total_rewards_min            -2.845999263957685
Number of train steps total  1956000
Number of env steps total    2447000
Number of rollouts total     0
Train Time (s)               114.21133747091517
(Previous) Eval Time (s)     24.830046134069562
Sample Time (s)              18.081971327308565
Epoch Time (s)               157.1233549322933
Total Train Time (s)         76282.47717934288
Epoch                        488
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:42:58.737615 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #488 | Epoch Duration: 150.657865524292
2020-01-12 20:42:58.737776 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #488 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1195437
Z variance train             0.007357186
KL Divergence                27.05419
KL Loss                      2.705419
QF Loss                      791.9061
VF Loss                      157.80598
Policy Loss                  -1904.4122
Q Predictions Mean           1908.4667
Q Predictions Std            325.81653
Q Predictions Max            2118.0369
Q Predictions Min            -427.21478
V Predictions Mean           1903.6187
V Predictions Std            323.8316
V Predictions Max            2117.2852
V Predictions Min            -378.6556
Log Pis Mean                 2.5004907
Log Pis Std                  3.1379423
Log Pis Max                  11.975191
Log Pis Min                  -4.7325892
Policy mu Mean               -0.0069141416
Policy mu Std                0.6284209
Policy mu Max                3.0612888
Policy mu Min                -2.7040212
Policy log std Mean          -1.3507013
Policy log std Std           0.3218159
Policy log std Max           0.059582114
Policy log std Min           -2.8023686
Z mean eval                  1.1535125
Z variance eval              0.0023578908
total_rewards                [5195.62679148 5281.34301718 5563.52797714 5145.03696495 5279.37855289
 5214.04445463 5508.29084491 5332.78011075 5459.80434013 5340.18231378]
total_rewards_mean           5332.001536785521
total_rewards_std            131.86609121665512
total_rewards_max            5563.527977141712
total_rewards_min            5145.03696494911
Number of train steps total  1960000
Number of env steps total    2452000
Number of rollouts total     0
Train Time (s)               116.42508644517511
(Previous) Eval Time (s)     18.364256021101028
Sample Time (s)              18.11428544856608
Epoch Time (s)               152.90362791484222
Total Train Time (s)         76444.0341976285
Epoch                        489
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:45:40.302073 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #489 | Epoch Duration: 161.56413006782532
2020-01-12 20:45:40.302290 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #489 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.153932
Z variance train             0.0023623002
KL Divergence                29.240505
KL Loss                      2.9240506
QF Loss                      2358.6702
VF Loss                      949.28
Policy Loss                  -1873.6199
Q Predictions Mean           1869.8945
Q Predictions Std            427.52274
Q Predictions Max            2138.4202
Q Predictions Min            -448.10278
V Predictions Mean           1874.5542
V Predictions Std            406.05664
V Predictions Max            2135.58
V Predictions Min            -452.97708
Log Pis Mean                 2.6480896
Log Pis Std                  3.557179
Log Pis Max                  15.721307
Log Pis Min                  -5.718008
Policy mu Mean               0.021793276
Policy mu Std                0.6676614
Policy mu Max                3.112922
Policy mu Min                -3.3222404
Policy log std Mean          -1.313735
Policy log std Std           0.37365928
Policy log std Max           -0.042947173
Policy log std Min           -3.4218025
Z mean eval                  1.1409862
Z variance eval              0.0032545652
total_rewards                [5333.70648186 5539.55189357 5366.01421824 5288.45788274 5207.45666009
 5352.54183627 5182.07025173 1954.91719297 5469.54207887 1549.84245586]
total_rewards_mean           4624.410095218905
total_rewards_std            1442.4296373777674
total_rewards_max            5539.55189357437
total_rewards_min            1549.8424558576296
Number of train steps total  1964000
Number of env steps total    2457000
Number of rollouts total     0
Train Time (s)               111.76327914232388
(Previous) Eval Time (s)     27.02448523370549
Sample Time (s)              18.153435142245144
Epoch Time (s)               156.94119951827452
Total Train Time (s)         76596.93537721317
Epoch                        490
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:48:13.212888 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #490 | Epoch Duration: 152.91040062904358
2020-01-12 20:48:13.213191 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #490 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1423384
Z variance train             0.003251729
KL Divergence                28.705387
KL Loss                      2.8705387
QF Loss                      740.0513
VF Loss                      540.00415
Policy Loss                  -1900.9167
Q Predictions Mean           1904.2
Q Predictions Std            288.56104
Q Predictions Max            2125.3384
Q Predictions Min            -523.3368
V Predictions Mean           1906.4565
V Predictions Std            288.6677
V Predictions Max            2114.894
V Predictions Min            -540.87695
Log Pis Mean                 1.8843522
Log Pis Std                  3.2300303
Log Pis Max                  12.433575
Log Pis Min                  -7.436592
Policy mu Mean               0.0068550357
Policy mu Std                0.61358887
Policy mu Max                3.202125
Policy mu Min                -2.3633418
Policy log std Mean          -1.3224273
Policy log std Std           0.32800823
Policy log std Max           -0.22500432
Policy log std Min           -3.0512555
Z mean eval                  1.1640961
Z variance eval              0.0024909757
total_rewards                [5252.38290509 5165.76968906 5281.60944276 5398.89161511 2519.88547348
 5304.7397342  5357.95972716 5377.45208232 5375.78562916 5144.97636163]
total_rewards_mean           5017.945265996289
total_rewards_std            836.842123055942
total_rewards_max            5398.891615114513
total_rewards_min            2519.885473481663
Number of train steps total  1968000
Number of env steps total    2462000
Number of rollouts total     0
Train Time (s)               120.66807971801609
(Previous) Eval Time (s)     22.993322384078056
Sample Time (s)              17.962920937221497
Epoch Time (s)               161.62432303931564
Total Train Time (s)         76762.55785395065
Epoch                        491
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:50:58.842445 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #491 | Epoch Duration: 165.62901973724365
2020-01-12 20:50:58.842715 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #491 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1624072
Z variance train             0.002489855
KL Divergence                28.837711
KL Loss                      2.8837712
QF Loss                      859.2721
VF Loss                      119.872826
Policy Loss                  -1919.846
Q Predictions Mean           1921.3303
Q Predictions Std            266.72998
Q Predictions Max            2146.9033
Q Predictions Min            -433.66513
V Predictions Mean           1918.8123
V Predictions Std            263.25696
V Predictions Max            2144.0886
V Predictions Min            -409.90305
Log Pis Mean                 2.3002117
Log Pis Std                  2.9572682
Log Pis Max                  10.9332695
Log Pis Min                  -5.311466
Policy mu Mean               0.004117548
Policy mu Std                0.60000277
Policy mu Max                2.5220842
Policy mu Min                -2.3980207
Policy log std Mean          -1.3299053
Policy log std Std           0.3031699
Policy log std Max           -0.08223593
Policy log std Min           -2.5933766
Z mean eval                  1.2011598
Z variance eval              0.0023059694
total_rewards                [5264.9318847  5405.00892799 5191.5071866  5187.32657955 5396.632128
 5519.91316301 5512.87957499 1052.02256705 1346.82289957 5304.47383571]
total_rewards_mean           4518.151874716522
total_rewards_std            1664.3261844394544
total_rewards_max            5519.913163014151
total_rewards_min            1052.0225670521752
Number of train steps total  1972000
Number of env steps total    2467000
Number of rollouts total     0
Train Time (s)               116.32326971087605
(Previous) Eval Time (s)     26.997706877999008
Sample Time (s)              17.81011631898582
Epoch Time (s)               161.13109290786088
Total Train Time (s)         76919.31984754093
Epoch                        492
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:53:35.607262 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #492 | Epoch Duration: 156.76435375213623
2020-01-12 20:53:35.607417 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #492 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1975969
Z variance train             0.0023067968
KL Divergence                29.432945
KL Loss                      2.9432945
QF Loss                      1101.9761
VF Loss                      408.78812
Policy Loss                  -1911.8555
Q Predictions Mean           1899.7666
Q Predictions Std            367.95444
Q Predictions Max            2136.2366
Q Predictions Min            -409.59714
V Predictions Mean           1901.841
V Predictions Std            330.72205
V Predictions Max            2123.1245
V Predictions Min            -322.9896
Log Pis Mean                 2.7151656
Log Pis Std                  4.5819187
Log Pis Max                  39.20125
Log Pis Min                  -5.8994837
Policy mu Mean               -0.0017215272
Policy mu Std                0.6855156
Policy mu Max                4.4973497
Policy mu Min                -5.6717186
Policy log std Mean          -1.3758883
Policy log std Std           0.36616018
Policy log std Max           0.57140636
Policy log std Min           -3.6435957
Z mean eval                  1.1491114
Z variance eval              0.0042452244
total_rewards                [5453.38167735 5401.72873352 2473.39559364 5281.13257403 5404.3215505
 2840.75853691 1682.69242791  974.69078934 5440.2159976  5411.94547266]
total_rewards_mean           4036.4263353464135
total_rewards_std            1730.3726990828711
total_rewards_max            5453.3816773535555
total_rewards_min            974.6907893424105
Number of train steps total  1976000
Number of env steps total    2472000
Number of rollouts total     0
Train Time (s)               123.30664781620726
(Previous) Eval Time (s)     22.630669206846505
Sample Time (s)              17.517008579336107
Epoch Time (s)               163.45432560238987
Total Train Time (s)         77080.82400713908
Epoch                        493
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:56:17.116461 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #493 | Epoch Duration: 161.5089032649994
2020-01-12 20:56:17.116699 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #493 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1470802
Z variance train             0.0042605293
KL Divergence                29.098812
KL Loss                      2.9098814
QF Loss                      981.9652
VF Loss                      186.75533
Policy Loss                  -1902.2354
Q Predictions Mean           1905.435
Q Predictions Std            338.47214
Q Predictions Max            2139.7576
Q Predictions Min            -517.10846
V Predictions Mean           1904.8584
V Predictions Std            339.7292
V Predictions Max            2139.6113
V Predictions Min            -545.9853
Log Pis Mean                 2.213256
Log Pis Std                  3.0481844
Log Pis Max                  12.583252
Log Pis Min                  -6.6102285
Policy mu Mean               -0.032406375
Policy mu Std                0.6357479
Policy mu Max                3.0252254
Policy mu Min                -2.7805781
Policy log std Mean          -1.2944111
Policy log std Std           0.31342962
Policy log std Max           -0.1292876
Policy log std Min           -2.671071
Z mean eval                  1.1220477
Z variance eval              0.01195097
total_rewards                [5405.46772534 5286.51590061 3118.84682929 3892.22748872 5474.21275717
 5585.74129999 5138.54474337 5166.83216606 5275.09105397 5412.32087655]
total_rewards_mean           4975.580084107421
total_rewards_std            765.9706994032072
total_rewards_max            5585.741299993761
total_rewards_min            3118.8468292889524
Number of train steps total  1980000
Number of env steps total    2477000
Number of rollouts total     0
Train Time (s)               117.54902355093509
(Previous) Eval Time (s)     20.684943959116936
Sample Time (s)              18.47847761074081
Epoch Time (s)               156.71244512079284
Total Train Time (s)         77241.96071666293
Epoch                        494
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:58:58.256831 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #494 | Epoch Duration: 161.13997173309326
2020-01-12 20:58:58.257004 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #494 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1202643
Z variance train             0.01186548
KL Divergence                28.591702
KL Loss                      2.8591702
QF Loss                      752.8966
VF Loss                      131.41145
Policy Loss                  -1921.3378
Q Predictions Mean           1922.6746
Q Predictions Std            269.5217
Q Predictions Max            2128.5234
Q Predictions Min            -458.40552
V Predictions Mean           1918.7563
V Predictions Std            268.30917
V Predictions Max            2119.52
V Predictions Min            -454.5078
Log Pis Mean                 2.2096899
Log Pis Std                  3.0178657
Log Pis Max                  12.00076
Log Pis Min                  -6.2951317
Policy mu Mean               -0.022638137
Policy mu Std                0.61752975
Policy mu Max                2.4250424
Policy mu Min                -2.5802748
Policy log std Mean          -1.3386853
Policy log std Std           0.326028
Policy log std Max           0.023576498
Policy log std Min           -2.7829187
Z mean eval                  1.1407236
Z variance eval              0.0045875986
total_rewards                [ 805.68662217 5544.68522515 4470.3826866  5474.24598689 -294.8580064
 5362.55158859 5286.55143054 3445.74043469 5251.67027619 5254.998274  ]
total_rewards_mean           4060.165451841616
total_rewards_std            2008.8459923627138
total_rewards_max            5544.6852251483415
total_rewards_min            -294.85800640160056
Number of train steps total  1984000
Number of env steps total    2482000
Number of rollouts total     0
Train Time (s)               120.31926224008203
(Previous) Eval Time (s)     25.112145450897515
Sample Time (s)              18.578009270131588
Epoch Time (s)               164.00941696111113
Total Train Time (s)         77404.61167421704
Epoch                        495
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:01:40.917140 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #495 | Epoch Duration: 162.65996193885803
2020-01-12 21:01:40.917429 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #495 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1409562
Z variance train             0.0045925044
KL Divergence                30.983036
KL Loss                      3.0983036
QF Loss                      1014.56323
VF Loss                      199.34671
Policy Loss                  -1939.5636
Q Predictions Mean           1940.1936
Q Predictions Std            227.11443
Q Predictions Max            2152.735
Q Predictions Min            -272.5667
V Predictions Mean           1932.717
V Predictions Std            230.16763
V Predictions Max            2143.034
V Predictions Min            -406.585
Log Pis Mean                 2.1078973
Log Pis Std                  3.3281858
Log Pis Max                  12.085761
Log Pis Min                  -6.013384
Policy mu Mean               0.014077203
Policy mu Std                0.6510477
Policy mu Max                2.3658059
Policy mu Min                -2.5217266
Policy log std Mean          -1.2821407
Policy log std Std           0.32217532
Policy log std Max           0.24734128
Policy log std Min           -2.638986
Z mean eval                  1.1681869
Z variance eval              0.0045678066
total_rewards                [1103.14570183 5023.88546606 4992.36457101 3987.0744209  4291.30550867
 4080.51466573 3719.56844015 4971.79923777 1531.21266302 5041.63056953]
total_rewards_mean           3874.250124467838
total_rewards_std            1362.3954183919163
total_rewards_max            5041.630569529849
total_rewards_min            1103.1457018338772
Number of train steps total  1988000
Number of env steps total    2487000
Number of rollouts total     0
Train Time (s)               125.03628092398867
(Previous) Eval Time (s)     23.762314897030592
Sample Time (s)              18.709546675439924
Epoch Time (s)               167.5081424964592
Total Train Time (s)         77568.77100610454
Epoch                        496
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:04:25.078523 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #496 | Epoch Duration: 164.16090083122253
2020-01-12 21:04:25.078682 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #496 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1663779
Z variance train             0.0045715533
KL Divergence                28.737915
KL Loss                      2.8737915
QF Loss                      16379.554
VF Loss                      1106.1042
Policy Loss                  -1910.6837
Q Predictions Mean           1913.9893
Q Predictions Std            344.08737
Q Predictions Max            2167.568
Q Predictions Min            -436.0827
V Predictions Mean           1919.8644
V Predictions Std            336.24304
V Predictions Max            2162.7676
V Predictions Min            -461.93137
Log Pis Mean                 2.6746678
Log Pis Std                  3.5065753
Log Pis Max                  15.157401
Log Pis Min                  -6.515667
Policy mu Mean               0.023002941
Policy mu Std                0.6636806
Policy mu Max                3.0152707
Policy mu Min                -2.976026
Policy log std Mean          -1.3319948
Policy log std Std           0.37133572
Policy log std Max           -0.059667826
Policy log std Min           -3.1760783
Z mean eval                  1.1430801
Z variance eval              0.004920458
total_rewards                [5282.88305471 5473.56927675  567.76326373 1906.25246764 5498.01025328
 5303.19652832 2759.86244679 4697.16263186 4309.09855392 -513.08360214]
total_rewards_mean           3528.471487486285
total_rewards_std            2102.0853935990785
total_rewards_max            5498.010253277116
total_rewards_min            -513.0836021397832
Number of train steps total  1992000
Number of env steps total    2492000
Number of rollouts total     0
Train Time (s)               125.1205778666772
(Previous) Eval Time (s)     20.414730784948915
Sample Time (s)              18.00676457118243
Epoch Time (s)               163.54207322280854
Total Train Time (s)         77732.70006056875
Epoch                        497
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:07:09.016111 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #497 | Epoch Duration: 163.9372684955597
2020-01-12 21:07:09.016431 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #497 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1425744
Z variance train             0.0049178423
KL Divergence                28.278566
KL Loss                      2.8278568
QF Loss                      1001.58936
VF Loss                      563.65
Policy Loss                  -1913.1439
Q Predictions Mean           1917.1544
Q Predictions Std            317.63666
Q Predictions Max            2146.9932
Q Predictions Min            -357.95615
V Predictions Mean           1914.4739
V Predictions Std            318.245
V Predictions Max            2147.8696
V Predictions Min            -327.261
Log Pis Mean                 3.0195801
Log Pis Std                  3.7667348
Log Pis Max                  19.86347
Log Pis Min                  -4.4904203
Policy mu Mean               0.022079183
Policy mu Std                0.6684205
Policy mu Max                2.8557534
Policy mu Min                -2.8951833
Policy log std Mean          -1.3362727
Policy log std Std           0.34331354
Policy log std Max           -0.0331167
Policy log std Min           -3.2194314
Z mean eval                  1.1189559
Z variance eval              0.0049606813
total_rewards                [5294.86421783 5467.23772823 5317.24389442 2493.50337308 5478.74896485
 5384.87038496 5363.27568451  891.2272586  3819.81764607 5187.09132724]
total_rewards_mean           4469.788047978278
total_rewards_std            1506.529783691985
total_rewards_max            5478.748964845052
total_rewards_min            891.2272586007364
Number of train steps total  1996000
Number of env steps total    2497000
Number of rollouts total     0
Train Time (s)               115.8829105021432
(Previous) Eval Time (s)     20.809565836098045
Sample Time (s)              17.89150173123926
Epoch Time (s)               154.5839780694805
Total Train Time (s)         77890.89088399289
Epoch                        498
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:09:47.213310 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #498 | Epoch Duration: 158.1966187953949
2020-01-12 21:09:47.213618 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #498 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1205065
Z variance train             0.0049549704
KL Divergence                28.0722
KL Loss                      2.8072202
QF Loss                      1007.0501
VF Loss                      377.50894
Policy Loss                  -1913.1229
Q Predictions Mean           1913.7838
Q Predictions Std            342.77295
Q Predictions Max            2141.3174
Q Predictions Min            -318.56967
V Predictions Mean           1921.563
V Predictions Std            339.89194
V Predictions Max            2147.5625
V Predictions Min            -351.76672
Log Pis Mean                 2.3928576
Log Pis Std                  3.518053
Log Pis Max                  32.65766
Log Pis Min                  -5.3777666
Policy mu Mean               0.036532626
Policy mu Std                0.63818127
Policy mu Max                4.6567435
Policy mu Min                -2.9101043
Policy log std Mean          -1.3310677
Policy log std Std           0.30860937
Policy log std Max           0.5424119
Policy log std Min           -3.1699815
Z mean eval                  1.1407626
Z variance eval              0.0018479172
total_rewards                [1604.56118218 2081.34466439   12.67777618 5422.00814086 5417.77685667
 5578.67238479 5505.20163706 5532.36404094 5413.09908388   40.93666065]
total_rewards_mean           3660.8642427600885
total_rewards_std            2301.6772419136223
total_rewards_max            5578.672384787818
total_rewards_min            12.677776184281072
Number of train steps total  2000000
Number of env steps total    2502000
Number of rollouts total     0
Train Time (s)               112.18440050398931
(Previous) Eval Time (s)     24.421874615829438
Sample Time (s)              19.04372873250395
Epoch Time (s)               155.6500038523227
Total Train Time (s)         78040.87027232908
Epoch                        499
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:12:17.198478 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #499 | Epoch Duration: 149.98465061187744
2020-01-12 21:12:17.198684 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #499 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1404097
Z variance train             0.0018466765
KL Divergence                30.140612
KL Loss                      3.0140612
QF Loss                      644.9875
VF Loss                      154.48222
Policy Loss                  -1964.1248
Q Predictions Mean           1964.8938
Q Predictions Std            242.14885
Q Predictions Max            2166.881
Q Predictions Min            -537.8316
V Predictions Mean           1958.499
V Predictions Std            237.67796
V Predictions Max            2161.2559
V Predictions Min            -453.42114
Log Pis Mean                 1.919155
Log Pis Std                  3.09413
Log Pis Max                  11.826015
Log Pis Min                  -6.9494457
Policy mu Mean               0.0046763257
Policy mu Std                0.62254214
Policy mu Max                2.6240246
Policy mu Min                -3.171926
Policy log std Mean          -1.303297
Policy log std Std           0.3066112
Policy log std Max           0.04787922
Policy log std Min           -2.6992066
Z mean eval                  1.1820233
Z variance eval              0.0040944815
total_rewards                [5067.6467372  5486.25460901 4975.61991129 5575.34963314 5267.127542
 2136.23536653 5549.27416682 5444.7885782  5514.17030577 5231.63808715]
total_rewards_mean           5024.81049371217
total_rewards_std            982.6778162203492
total_rewards_max            5575.349633140229
total_rewards_min            2136.235366533975
Number of train steps total  2004000
Number of env steps total    2507000
Number of rollouts total     0
Train Time (s)               118.61000521387905
(Previous) Eval Time (s)     18.756206918042153
Sample Time (s)              17.676214152015746
Epoch Time (s)               155.04242628393695
Total Train Time (s)         78202.72404346848
Epoch                        500
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:14:59.065536 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #500 | Epoch Duration: 161.86667156219482
2020-01-12 21:14:59.065841 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #500 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1822903
Z variance train             0.0040906025
KL Divergence                29.254255
KL Loss                      2.9254255
QF Loss                      5664.1543
VF Loss                      577.137
Policy Loss                  -1937.9645
Q Predictions Mean           1936.4036
Q Predictions Std            385.16577
Q Predictions Max            2180.9707
Q Predictions Min            -579.87585
V Predictions Mean           1942.7627
V Predictions Std            359.57767
V Predictions Max            2178.6558
V Predictions Min            -586.11664
Log Pis Mean                 2.6598897
Log Pis Std                  3.6051393
Log Pis Max                  19.699726
Log Pis Min                  -7.3676043
Policy mu Mean               0.061261494
Policy mu Std                0.65613335
Policy mu Max                2.3569427
Policy mu Min                -2.6158814
Policy log std Mean          -1.3152883
Policy log std Std           0.37001693
Policy log std Max           -0.02323234
Policy log std Min           -3.2312407
Z mean eval                  1.1684895
Z variance eval              0.0045885798
total_rewards                [5637.84452288 5328.57066528 3332.31467668 5519.89151988 3842.61950938
 5565.11691369 -130.99481139  695.65402298 5296.51220973  792.53531843]
total_rewards_mean           3588.0064547551638
total_rewards_std            2189.36236007362
total_rewards_max            5637.844522882169
total_rewards_min            -130.99481138715345
Number of train steps total  2008000
Number of env steps total    2512000
Number of rollouts total     0
Train Time (s)               122.80992307700217
(Previous) Eval Time (s)     25.5801307130605
Sample Time (s)              17.770546939224005
Epoch Time (s)               166.16060072928667
Total Train Time (s)         78363.91682524793
Epoch                        501
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:17:40.256530 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #501 | Epoch Duration: 161.1904740333557
2020-01-12 21:17:40.256742 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #501 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1686239
Z variance train             0.004585158
KL Divergence                28.346561
KL Loss                      2.8346562
QF Loss                      1383.4702
VF Loss                      211.36267
Policy Loss                  -1935.1481
Q Predictions Mean           1937.5396
Q Predictions Std            330.78784
Q Predictions Max            2160.4268
Q Predictions Min            -634.26404
V Predictions Mean           1930.9674
V Predictions Std            328.92334
V Predictions Max            2152.4587
V Predictions Min            -577.7164
Log Pis Mean                 2.6818385
Log Pis Std                  3.3384442
Log Pis Max                  13.925856
Log Pis Min                  -12.366532
Policy mu Mean               0.0023204049
Policy mu Std                0.6473052
Policy mu Max                2.601315
Policy mu Min                -2.8297985
Policy log std Mean          -1.3552349
Policy log std Std           0.33004844
Policy log std Max           0.4026928
Policy log std Min           -2.6709466
Z mean eval                  1.1166948
Z variance eval              0.0033920768
total_rewards                [5130.49105012 5389.16078991 5464.1480227  5310.07360522 3008.19131842
 -289.9566988  5355.03266943 5508.30977598 5266.13215163 2839.71105817]
total_rewards_mean           4298.129374278062
total_rewards_std            1806.291080306309
total_rewards_max            5508.309775982714
total_rewards_min            -289.9566988012626
Number of train steps total  2012000
Number of env steps total    2517000
Number of rollouts total     0
Train Time (s)               115.96748333098367
(Previous) Eval Time (s)     20.60970326187089
Sample Time (s)              17.671657586470246
Epoch Time (s)               154.2488441793248
Total Train Time (s)         78522.32069653785
Epoch                        502
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:20:18.663433 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #502 | Epoch Duration: 158.4065399169922
2020-01-12 21:20:18.663634 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #502 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1168344
Z variance train             0.0033914887
KL Divergence                28.996025
KL Loss                      2.8996027
QF Loss                      1162.8827
VF Loss                      906.39514
Policy Loss                  -1949.1671
Q Predictions Mean           1950.8667
Q Predictions Std            266.48575
Q Predictions Max            2154.2878
Q Predictions Min            -388.1658
V Predictions Mean           1952.8938
V Predictions Std            245.49255
V Predictions Max            2147.019
V Predictions Min            -395.49176
Log Pis Mean                 2.6805694
Log Pis Std                  3.409796
Log Pis Max                  13.232767
Log Pis Min                  -6.945008
Policy mu Mean               0.021420501
Policy mu Std                0.67143697
Policy mu Max                2.849001
Policy mu Min                -2.739041
Policy log std Mean          -1.3463091
Policy log std Std           0.33278304
Policy log std Max           -0.27464283
Policy log std Min           -2.7417254
Z mean eval                  1.1555448
Z variance eval              0.0042961068
total_rewards                [5478.20728568 5859.7783738  5540.35952229 5300.90456407 5513.68950334
 5246.78559142 5391.22313557 2261.95185269 5461.40249358 5536.1278032 ]
total_rewards_mean           5159.043012562854
total_rewards_std            978.3943349623472
total_rewards_max            5859.778373795388
total_rewards_min            2261.9518526936313
Number of train steps total  2016000
Number of env steps total    2522000
Number of rollouts total     0
Train Time (s)               119.1956455828622
(Previous) Eval Time (s)     24.767129311338067
Sample Time (s)              18.147508930880576
Epoch Time (s)               162.11028382508084
Total Train Time (s)         78684.38510328159
Epoch                        503
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:23:00.734111 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #503 | Epoch Duration: 162.07031774520874
2020-01-12 21:23:00.734343 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #503 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1557736
Z variance train             0.0042911395
KL Divergence                29.787317
KL Loss                      2.9787319
QF Loss                      938.7742
VF Loss                      114.72858
Policy Loss                  -1977.7471
Q Predictions Mean           1979.3927
Q Predictions Std            193.22534
Q Predictions Max            2153.0503
Q Predictions Min            -324.53247
V Predictions Mean           1979.7827
V Predictions Std            196.984
V Predictions Max            2155.3604
V Predictions Min            -420.3672
Log Pis Mean                 2.4213994
Log Pis Std                  3.074931
Log Pis Max                  11.705738
Log Pis Min                  -4.5787888
Policy mu Mean               0.018478552
Policy mu Std                0.6495779
Policy mu Max                2.9081702
Policy mu Min                -2.9781234
Policy log std Mean          -1.3346252
Policy log std Std           0.32323635
Policy log std Max           -0.11370695
Policy log std Min           -2.7933896
Z mean eval                  1.1892356
Z variance eval              0.002141085
total_rewards                [4312.47618396 1447.33347967 5405.38284099 5456.55869292 1615.91401877
 1031.31523785 5377.98755101 5502.58217274 5453.07643161 5590.32022602]
total_rewards_mean           4119.294683553754
total_rewards_std            1840.1686679978193
total_rewards_max            5590.320226019459
total_rewards_min            1031.315237853662
Number of train steps total  2020000
Number of env steps total    2527000
Number of rollouts total     0
Train Time (s)               121.30925953388214
(Previous) Eval Time (s)     24.726848930120468
Sample Time (s)              18.18450416205451
Epoch Time (s)               164.22061262605712
Total Train Time (s)         78844.63285383396
Epoch                        504
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:25:40.997412 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #504 | Epoch Duration: 160.26287698745728
2020-01-12 21:25:40.997677 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #504 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1894469
Z variance train             0.0021417285
KL Divergence                30.518227
KL Loss                      3.0518227
QF Loss                      1246.6859
VF Loss                      251.57324
Policy Loss                  -1960.5798
Q Predictions Mean           1963.6826
Q Predictions Std            283.3889
Q Predictions Max            2184.7834
Q Predictions Min            -614.567
V Predictions Mean           1964.0728
V Predictions Std            280.8676
V Predictions Max            2191.7883
V Predictions Min            -595.2957
Log Pis Mean                 2.5729284
Log Pis Std                  3.2177544
Log Pis Max                  15.630056
Log Pis Min                  -4.9520154
Policy mu Mean               0.015918227
Policy mu Std                0.64956635
Policy mu Max                3.0862148
Policy mu Min                -2.4492168
Policy log std Mean          -1.3389032
Policy log std Std           0.33521852
Policy log std Max           -0.22553027
Policy log std Min           -2.9489222
Z mean eval                  1.1739337
Z variance eval              0.0013359161
total_rewards                [5461.8218184   576.41404716 5445.92492461 4120.72685359 5452.92229218
 5392.67506596 5480.44622331 5427.36311442 5484.64308899 5455.61559998]
total_rewards_mean           4829.855302860473
total_rewards_std            1472.3836053417701
total_rewards_max            5484.643088993276
total_rewards_min            576.414047155668
Number of train steps total  2024000
Number of env steps total    2532000
Number of rollouts total     0
Train Time (s)               121.53154054284096
(Previous) Eval Time (s)     20.76880011940375
Sample Time (s)              18.45208072150126
Epoch Time (s)               160.75242138374597
Total Train Time (s)         79008.49418460205
Epoch                        505
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:28:24.858100 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #505 | Epoch Duration: 163.86022114753723
2020-01-12 21:28:24.858331 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #505 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1783144
Z variance train             0.0013388043
KL Divergence                31.720917
KL Loss                      3.1720917
QF Loss                      989.19934
VF Loss                      130.9141
Policy Loss                  -1967.6512
Q Predictions Mean           1972.8009
Q Predictions Std            329.42392
Q Predictions Max            2180.2305
Q Predictions Min            -558.05457
V Predictions Mean           1964.989
V Predictions Std            330.10294
V Predictions Max            2175.2058
V Predictions Min            -596.1683
Log Pis Mean                 2.4233866
Log Pis Std                  3.4898999
Log Pis Max                  13.427121
Log Pis Min                  -9.619474
Policy mu Mean               -0.037180036
Policy mu Std                0.6266823
Policy mu Max                3.1136615
Policy mu Min                -3.1652722
Policy log std Mean          -1.3481238
Policy log std Std           0.332361
Policy log std Max           0.94164205
Policy log std Min           -2.758358
Z mean eval                  1.1459193
Z variance eval              0.0025173132
total_rewards                [5244.57943237 5427.56073132 5644.36087935 2302.33417274 3155.83917954
 3810.69642145 5515.59285693 5473.62221657 5392.94069035 5486.15043197]
total_rewards_mean           4745.367701259634
total_rewards_std            1139.435115350218
total_rewards_max            5644.360879348709
total_rewards_min            2302.3341727448283
Number of train steps total  2028000
Number of env steps total    2537000
Number of rollouts total     0
Train Time (s)               115.46577012911439
(Previous) Eval Time (s)     23.876278182026
Sample Time (s)              18.555312547367066
Epoch Time (s)               157.89736085850745
Total Train Time (s)         79165.66996442387
Epoch                        506
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:31:02.036216 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #506 | Epoch Duration: 157.17771363258362
2020-01-12 21:31:02.036423 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #506 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1458399
Z variance train             0.0025165589
KL Divergence                30.850275
KL Loss                      3.0850275
QF Loss                      913.5434
VF Loss                      143.23682
Policy Loss                  -1909.751
Q Predictions Mean           1911.4058
Q Predictions Std            466.40616
Q Predictions Max            2175.2996
Q Predictions Min            -545.4083
V Predictions Mean           1908.4541
V Predictions Std            459.8671
V Predictions Max            2174.7288
V Predictions Min            -542.04376
Log Pis Mean                 2.56423
Log Pis Std                  3.568806
Log Pis Max                  13.910637
Log Pis Min                  -6.150339
Policy mu Mean               0.013357532
Policy mu Std                0.64829135
Policy mu Max                2.7593372
Policy mu Min                -2.7092426
Policy log std Mean          -1.3201462
Policy log std Std           0.3389429
Policy log std Max           0.08071494
Policy log std Min           -2.6740203
Z mean eval                  1.1019098
Z variance eval              0.0028609035
total_rewards                [5475.07175154 3657.2571051  5415.28250062 5410.57203702 5414.90512803
 5806.04068347 5456.78964903 5627.12924954 5618.50004015 5701.14364647]
total_rewards_mean           5358.269179097885
total_rewards_std            581.7261380849293
total_rewards_max            5806.040683471774
total_rewards_min            3657.2571051037785
Number of train steps total  2032000
Number of env steps total    2542000
Number of rollouts total     0
Train Time (s)               124.49864845909178
(Previous) Eval Time (s)     23.15627008397132
Sample Time (s)              18.115333735011518
Epoch Time (s)               165.77025227807462
Total Train Time (s)         79334.58496077731
Epoch                        507
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:33:50.954398 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #507 | Epoch Duration: 168.91784477233887
2020-01-12 21:33:50.954577 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #507 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1017393
Z variance train             0.002866566
KL Divergence                30.164349
KL Loss                      3.016435
QF Loss                      780.9497
VF Loss                      275.1798
Policy Loss                  -1940.676
Q Predictions Mean           1945.2139
Q Predictions Std            407.66748
Q Predictions Max            2201.2197
Q Predictions Min            -541.9818
V Predictions Mean           1945.4482
V Predictions Std            399.1512
V Predictions Max            2196.1511
V Predictions Min            -517.2575
Log Pis Mean                 2.7344801
Log Pis Std                  3.4276166
Log Pis Max                  15.8019905
Log Pis Min                  -5.4702625
Policy mu Mean               -0.021006547
Policy mu Std                0.6219478
Policy mu Max                2.6290936
Policy mu Min                -2.8110974
Policy log std Mean          -1.3745534
Policy log std Std           0.345425
Policy log std Max           0.04995179
Policy log std Min           -3.3244205
Z mean eval                  1.1809927
Z variance eval              0.0025542444
total_rewards                [5365.38136086 5462.16050864 5469.3151774  5507.51692926 5375.5582479
 5440.6909945  5431.93386221 5433.83041651 5641.12235999 5531.76025009]
total_rewards_mean           5465.927010735485
total_rewards_std            76.07978467923049
total_rewards_max            5641.122359994793
total_rewards_min            5365.381360864464
Number of train steps total  2036000
Number of env steps total    2547000
Number of rollouts total     0
Train Time (s)               127.42079555103555
(Previous) Eval Time (s)     26.303516493644565
Sample Time (s)              18.474230295978487
Epoch Time (s)               172.1985423406586
Total Train Time (s)         79507.85946436832
Epoch                        508
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:36:44.247005 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #508 | Epoch Duration: 173.29228973388672
2020-01-12 21:36:44.247194 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #508 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.188473
Z variance train             0.0025525806
KL Divergence                30.395657
KL Loss                      3.0395658
QF Loss                      832.4636
VF Loss                      184.21727
Policy Loss                  -1967.2064
Q Predictions Mean           1971.0715
Q Predictions Std            302.81705
Q Predictions Max            2183.4236
Q Predictions Min            -368.4677
V Predictions Mean           1968.1763
V Predictions Std            295.9735
V Predictions Max            2176.7554
V Predictions Min            -357.4181
Log Pis Mean                 2.652564
Log Pis Std                  3.7940001
Log Pis Max                  26.572289
Log Pis Min                  -4.1868925
Policy mu Mean               -0.019542964
Policy mu Std                0.644987
Policy mu Max                4.635756
Policy mu Min                -3.9386294
Policy log std Mean          -1.3412597
Policy log std Std           0.34091142
Policy log std Max           1.3360587
Policy log std Min           -3.075786
Z mean eval                  1.1691403
Z variance eval              0.0031830438
total_rewards                [5599.22050742 5333.97732228 5548.35673723 5306.24024127 4468.55573042
 5641.79574722 5372.40814381 5633.92317791 5477.78850864 5402.85363695]
total_rewards_mean           5378.511975315143
total_rewards_std            325.2422537215218
total_rewards_max            5641.795747217346
total_rewards_min            4468.555730419094
Number of train steps total  2040000
Number of env steps total    2552000
Number of rollouts total     0
Train Time (s)               121.42198487883434
(Previous) Eval Time (s)     27.396938167046756
Sample Time (s)              18.563645490910858
Epoch Time (s)               167.38256853679195
Total Train Time (s)         79674.41934259236
Epoch                        509
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:39:30.800341 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #509 | Epoch Duration: 166.55299043655396
2020-01-12 21:39:30.800531 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #509 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1692127
Z variance train             0.003199008
KL Divergence                29.568535
KL Loss                      2.9568536
QF Loss                      784.30994
VF Loss                      161.08438
Policy Loss                  -1953.3964
Q Predictions Mean           1954.3604
Q Predictions Std            345.45767
Q Predictions Max            2193.6284
Q Predictions Min            -479.44507
V Predictions Mean           1956.622
V Predictions Std            345.82675
V Predictions Max            2198.4329
V Predictions Min            -502.98474
Log Pis Mean                 2.4180105
Log Pis Std                  3.163441
Log Pis Max                  14.774019
Log Pis Min                  -6.644958
Policy mu Mean               -0.019798018
Policy mu Std                0.62975156
Policy mu Max                3.0492523
Policy mu Min                -2.803369
Policy log std Mean          -1.3468685
Policy log std Std           0.31732276
Policy log std Max           -0.034745574
Policy log std Min           -2.7056377
Z mean eval                  1.1665099
Z variance eval              0.006465693
total_rewards                [5230.42710467 5374.3966735  5246.48638551 5328.43954993 5235.98643383
 5537.65248979 5477.41136754 5478.02982113 5380.65050388 5334.34731407]
total_rewards_mean           5362.382764385878
total_rewards_std            103.22876036506871
total_rewards_max            5537.652489789829
total_rewards_min            5230.427104674764
Number of train steps total  2044000
Number of env steps total    2557000
Number of rollouts total     0
Train Time (s)               114.47997456882149
(Previous) Eval Time (s)     26.567053572274745
Sample Time (s)              18.915169512853026
Epoch Time (s)               159.96219765394926
Total Train Time (s)         79834.33465419663
Epoch                        510
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:42:10.719210 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #510 | Epoch Duration: 159.91856217384338
2020-01-12 21:42:10.719380 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #510 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1684318
Z variance train             0.00645257
KL Divergence                28.344456
KL Loss                      2.8344457
QF Loss                      891.14386
VF Loss                      245.68312
Policy Loss                  -1974.1738
Q Predictions Mean           1977.0668
Q Predictions Std            339.7134
Q Predictions Max            2205.6787
Q Predictions Min            -459.50757
V Predictions Mean           1965.3865
V Predictions Std            341.24634
V Predictions Max            2189.934
V Predictions Min            -468.7497
Log Pis Mean                 2.0101182
Log Pis Std                  2.9899566
Log Pis Max                  12.586769
Log Pis Min                  -7.082434
Policy mu Mean               0.014404722
Policy mu Std                0.6084605
Policy mu Max                2.5373828
Policy mu Min                -2.7456057
Policy log std Mean          -1.3341699
Policy log std Std           0.29862815
Policy log std Max           -0.20918357
Policy log std Min           -2.9303677
Z mean eval                  1.1334951
Z variance eval              0.004662363
total_rewards                [5361.81227146  475.14427979 5255.38691557 1921.48534996  167.03608563
 3697.62671604 4245.92309957 5139.21985592  274.85163547 5337.94330368]
total_rewards_mean           3187.642951308259
total_rewards_std            2130.35876950342
total_rewards_max            5361.812271461031
total_rewards_min            167.036085633522
Number of train steps total  2048000
Number of env steps total    2562000
Number of rollouts total     0
Train Time (s)               119.79210917418823
(Previous) Eval Time (s)     26.523074289783835
Sample Time (s)              17.634206623770297
Epoch Time (s)               163.94939008774236
Total Train Time (s)         79987.57429141365
Epoch                        511
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:44:43.962686 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #511 | Epoch Duration: 153.24317407608032
2020-01-12 21:44:43.962886 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #511 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1309657
Z variance train             0.0046633207
KL Divergence                29.046247
KL Loss                      2.9046247
QF Loss                      830.93
VF Loss                      1027.9744
Policy Loss                  -1986.9855
Q Predictions Mean           1989.4143
Q Predictions Std            261.05713
Q Predictions Max            2215.6536
Q Predictions Min            -470.28806
V Predictions Mean           1989.345
V Predictions Std            252.15152
V Predictions Max            2206.4873
V Predictions Min            -497.70425
Log Pis Mean                 2.664917
Log Pis Std                  3.401857
Log Pis Max                  17.789347
Log Pis Min                  -6.836875
Policy mu Mean               0.020178743
Policy mu Std                0.6463754
Policy mu Max                3.5867982
Policy mu Min                -2.943225
Policy log std Mean          -1.3387988
Policy log std Std           0.35980493
Policy log std Max           -0.15673292
Policy log std Min           -2.8451557
Z mean eval                  1.1442044
Z variance eval              0.0049453
total_rewards                [5223.70972856 5366.20072354 5527.55343704 5399.15780792 5630.00095116
 5507.25787977 5193.42345689 5652.16086846 5067.90472074 5549.63168418]
total_rewards_mean           5411.700125825965
total_rewards_std            187.20654035266722
total_rewards_max            5652.160868459091
total_rewards_min            5067.904720740935
Number of train steps total  2052000
Number of env steps total    2567000
Number of rollouts total     0
Train Time (s)               113.37378470925614
(Previous) Eval Time (s)     15.8165710628964
Sample Time (s)              17.504762743599713
Epoch Time (s)               146.69511851575226
Total Train Time (s)         80146.01443403587
Epoch                        512
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:47:22.408277 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #512 | Epoch Duration: 158.4452419281006
2020-01-12 21:47:22.408482 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #512 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1442115
Z variance train             0.004942716
KL Divergence                29.450483
KL Loss                      2.9450483
QF Loss                      932.1528
VF Loss                      132.39012
Policy Loss                  -1981.247
Q Predictions Mean           1983.867
Q Predictions Std            286.02216
Q Predictions Max            2205.5674
Q Predictions Min            -478.3929
V Predictions Mean           1984.1626
V Predictions Std            286.9773
V Predictions Max            2210.9683
V Predictions Min            -445.31705
Log Pis Mean                 2.4975252
Log Pis Std                  3.5217707
Log Pis Max                  13.29298
Log Pis Min                  -4.9728165
Policy mu Mean               0.03660807
Policy mu Std                0.65821046
Policy mu Max                2.5986729
Policy mu Min                -3.1357343
Policy log std Mean          -1.3328209
Policy log std Std           0.351632
Policy log std Max           0.088532925
Policy log std Min           -2.9692912
Z mean eval                  1.1290576
Z variance eval              0.0058992906
total_rewards                [5296.15545611 5373.88261917 5518.73925922 5714.40563095 5365.92190993
  629.64540576 3455.7277897  1156.72245292 5550.4776155  5751.02956152]
total_rewards_mean           4381.270770076667
total_rewards_std            1855.6732359579312
total_rewards_max            5751.029561521655
total_rewards_min            629.6454057609482
Number of train steps total  2056000
Number of env steps total    2572000
Number of rollouts total     0
Train Time (s)               121.89275058405474
(Previous) Eval Time (s)     27.566411392297596
Sample Time (s)              17.966686349827796
Epoch Time (s)               167.42584832618013
Total Train Time (s)         80307.4273613044
Epoch                        513
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:50:03.825455 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #513 | Epoch Duration: 161.4168131351471
2020-01-12 21:50:03.825642 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #513 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.130231
Z variance train             0.0059109544
KL Divergence                28.844212
KL Loss                      2.884421
QF Loss                      1067.4563
VF Loss                      148.78313
Policy Loss                  -1980.8186
Q Predictions Mean           1981.0956
Q Predictions Std            292.63177
Q Predictions Max            2182.5046
Q Predictions Min            -336.84726
V Predictions Mean           1976.7666
V Predictions Std            285.84045
V Predictions Max            2178.8225
V Predictions Min            -334.3411
Log Pis Mean                 2.908423
Log Pis Std                  4.0467315
Log Pis Max                  31.569166
Log Pis Min                  -4.9523115
Policy mu Mean               0.047220107
Policy mu Std                0.70433605
Policy mu Max                6.2742457
Policy mu Min                -2.6926482
Policy log std Mean          -1.3436178
Policy log std Std           0.35855108
Policy log std Max           1.3917131
Policy log std Min           -3.185717
Z mean eval                  1.1585555
Z variance eval              0.0054413434
total_rewards                [5507.85358594 5387.74134275 5551.60301445 5500.20426721 5636.96779293
 5550.60226388 5417.35743569 1925.64403151 5641.3297189  5446.64699494]
total_rewards_mean           5156.595044819224
total_rewards_std            1079.9559595780845
total_rewards_max            5641.329718900083
total_rewards_min            1925.644031506734
Number of train steps total  2060000
Number of env steps total    2577000
Number of rollouts total     0
Train Time (s)               119.91965416260064
(Previous) Eval Time (s)     21.557058385573328
Sample Time (s)              19.14419658947736
Epoch Time (s)               160.62090913765132
Total Train Time (s)         80472.45848662453
Epoch                        514
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:52:48.860488 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #514 | Epoch Duration: 165.03468132019043
2020-01-12 21:52:48.860692 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #514 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1575719
Z variance train             0.0054349797
KL Divergence                28.680866
KL Loss                      2.8680866
QF Loss                      707.15576
VF Loss                      146.53091
Policy Loss                  -1971.0519
Q Predictions Mean           1972.9338
Q Predictions Std            339.35178
Q Predictions Max            2199.669
Q Predictions Min            -509.7973
V Predictions Mean           1966.782
V Predictions Std            340.9965
V Predictions Max            2182.7495
V Predictions Min            -492.8089
Log Pis Mean                 2.5363376
Log Pis Std                  3.4701014
Log Pis Max                  19.229046
Log Pis Min                  -7.3323956
Policy mu Mean               0.009234383
Policy mu Std                0.61613053
Policy mu Max                2.3305483
Policy mu Min                -2.7293706
Policy log std Mean          -1.3482307
Policy log std Std           0.3436313
Policy log std Max           -0.07650876
Policy log std Min           -3.1745114
Z mean eval                  1.1432172
Z variance eval              0.0029464532
total_rewards                [5561.73494536 5784.60021153 4944.9193761  -462.06954521 5610.67321776
 3361.95712886 -283.73962158 5334.58575097 5427.37186139 5675.94122562]
total_rewards_mean           4095.597455081645
total_rewards_std            2330.545925066133
total_rewards_max            5784.600211528369
total_rewards_min            -462.06954520767704
Number of train steps total  2064000
Number of env steps total    2582000
Number of rollouts total     0
Train Time (s)               121.38642080873251
(Previous) Eval Time (s)     25.970501587260514
Sample Time (s)              18.027751682326198
Epoch Time (s)               165.38467407831922
Total Train Time (s)         80637.73846416129
Epoch                        515
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:55:34.148179 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #515 | Epoch Duration: 165.2873158454895
2020-01-12 21:55:34.148439 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #515 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.144622
Z variance train             0.0029465647
KL Divergence                30.112867
KL Loss                      3.0112867
QF Loss                      744.6
VF Loss                      165.3316
Policy Loss                  -1984.8359
Q Predictions Mean           1987.6823
Q Predictions Std            368.17206
Q Predictions Max            2240.369
Q Predictions Min            -518.5593
V Predictions Mean           1982.5378
V Predictions Std            371.21713
V Predictions Max            2232.2595
V Predictions Min            -501.48254
Log Pis Mean                 2.8573554
Log Pis Std                  3.6427186
Log Pis Max                  17.953686
Log Pis Min                  -6.664403
Policy mu Mean               0.012592122
Policy mu Std                0.62441957
Policy mu Max                3.1814172
Policy mu Min                -2.4638994
Policy log std Mean          -1.3971579
Policy log std Std           0.35574448
Policy log std Max           -0.16794515
Policy log std Min           -3.1544502
Z mean eval                  1.135292
Z variance eval              0.0050042095
total_rewards                [5497.23361897 5477.31749484 5513.78714237 5254.63847207 5493.56759806
 5583.91264592 5436.61256476 5539.25652172 5613.62584736 5738.7222904 ]
total_rewards_mean           5514.867419646805
total_rewards_std            118.84655082280865
total_rewards_max            5738.72229039926
total_rewards_min            5254.638472066372
Number of train steps total  2068000
Number of env steps total    2587000
Number of rollouts total     0
Train Time (s)               110.31328083295375
(Previous) Eval Time (s)     25.872793266549706
Sample Time (s)              18.071260693483055
Epoch Time (s)               154.2573347929865
Total Train Time (s)         80793.46476029372
Epoch                        516
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:58:09.886318 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #516 | Epoch Duration: 155.73766088485718
2020-01-12 21:58:09.886607 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #516 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1336663
Z variance train             0.0050190478
KL Divergence                29.298023
KL Loss                      2.9298024
QF Loss                      864.469
VF Loss                      397.1631
Policy Loss                  -1989.0579
Q Predictions Mean           1991.6116
Q Predictions Std            326.62683
Q Predictions Max            2211.017
Q Predictions Min            -514.19305
V Predictions Mean           2003.8713
V Predictions Std            328.8522
V Predictions Max            2212.5952
V Predictions Min            -518.0514
Log Pis Mean                 2.4170983
Log Pis Std                  3.3133547
Log Pis Max                  12.501703
Log Pis Min                  -4.171164
Policy mu Mean               0.035598278
Policy mu Std                0.623768
Policy mu Max                2.5251255
Policy mu Min                -2.7969093
Policy log std Mean          -1.3250387
Policy log std Std           0.3300696
Policy log std Max           -0.24510515
Policy log std Min           -2.6682606
Z mean eval                  1.1556313
Z variance eval              0.005586424
total_rewards                [5476.48464408 5542.37475888 5726.3767345  5678.25510547 5515.78814386
 5416.79138474 5635.29123837 5606.76191539 4108.68815107 5030.5988381 ]
total_rewards_mean           5373.741091445186
total_rewards_std            460.3170274374643
total_rewards_max            5726.376734504318
total_rewards_min            4108.6881510660905
Number of train steps total  2072000
Number of env steps total    2592000
Number of rollouts total     0
Train Time (s)               122.11145631922409
(Previous) Eval Time (s)     27.3528096890077
Sample Time (s)              18.09303459757939
Epoch Time (s)               167.55730060581118
Total Train Time (s)         80960.0604259083
Epoch                        517
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:00:56.486826 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #517 | Epoch Duration: 166.6000199317932
2020-01-12 22:00:56.487065 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #517 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1536374
Z variance train             0.0055896314
KL Divergence                29.02527
KL Loss                      2.902527
QF Loss                      642.95197
VF Loss                      268.36945
Policy Loss                  -1974.0125
Q Predictions Mean           1976.4796
Q Predictions Std            413.2198
Q Predictions Max            2244.7102
Q Predictions Min            -443.6182
V Predictions Mean           1982.2651
V Predictions Std            410.69366
V Predictions Max            2230.242
V Predictions Min            -415.23947
Log Pis Mean                 2.5416062
Log Pis Std                  3.426714
Log Pis Max                  11.828037
Log Pis Min                  -4.6549516
Policy mu Mean               0.028429199
Policy mu Std                0.64860815
Policy mu Max                2.6564317
Policy mu Min                -2.42944
Policy log std Mean          -1.3299611
Policy log std Std           0.34293273
Policy log std Max           -0.21141636
Policy log std Min           -2.7209983
Z mean eval                  1.1452047
Z variance eval              0.0034872922
total_rewards                [5050.68594826 3257.3616835  5601.0113348  5409.20849107 5534.30133098
 5432.05078845 2388.59154985 5569.15934023 5501.31512779 5436.48216526]
total_rewards_mean           4918.016776018248
total_rewards_std            1075.0900833488463
total_rewards_max            5601.011334798321
total_rewards_min            2388.591549850667
Number of train steps total  2076000
Number of env steps total    2597000
Number of rollouts total     0
Train Time (s)               126.37838132679462
(Previous) Eval Time (s)     26.39517982583493
Sample Time (s)              18.24665680155158
Epoch Time (s)               171.02021795418113
Total Train Time (s)         81129.28885727422
Epoch                        518
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:03:45.717679 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #518 | Epoch Duration: 169.2304892539978
2020-01-12 22:03:45.717873 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #518 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.144789
Z variance train             0.0034892312
KL Divergence                29.7203
KL Loss                      2.9720302
QF Loss                      815.3579
VF Loss                      303.31726
Policy Loss                  -1972.1451
Q Predictions Mean           1976.1936
Q Predictions Std            391.8275
Q Predictions Max            2224.8918
Q Predictions Min            -472.34943
V Predictions Mean           1973.8804
V Predictions Std            396.07947
V Predictions Max            2232.4246
V Predictions Min            -468.44247
Log Pis Mean                 2.4324021
Log Pis Std                  3.7893567
Log Pis Max                  23.261585
Log Pis Min                  -9.056176
Policy mu Mean               0.011785379
Policy mu Std                0.6297242
Policy mu Max                2.9498243
Policy mu Min                -2.9344578
Policy log std Mean          -1.320571
Policy log std Std           0.36847603
Policy log std Max           0.3112687
Policy log std Min           -3.5023346
Z mean eval                  1.1512823
Z variance eval              0.004041444
total_rewards                [5448.34215307 2480.94874797 5261.01737457 4776.62766913 5515.8453
 5387.41087954 5383.74673464 5468.56111328 5524.71816926 5447.69407586]
total_rewards_mean           5069.49122173033
total_rewards_std            887.4186523088579
total_rewards_max            5524.718169255337
total_rewards_min            2480.948747972143
Number of train steps total  2080000
Number of env steps total    2602000
Number of rollouts total     0
Train Time (s)               117.44816190795973
(Previous) Eval Time (s)     24.605159744154662
Sample Time (s)              18.542088007554412
Epoch Time (s)               160.5954096596688
Total Train Time (s)         81290.49466405995
Epoch                        519
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:06:26.931813 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #519 | Epoch Duration: 161.213764667511
2020-01-12 22:06:26.932110 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #519 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1523113
Z variance train             0.0040367283
KL Divergence                29.83073
KL Loss                      2.983073
QF Loss                      758.41656
VF Loss                      153.33261
Policy Loss                  -2039.7853
Q Predictions Mean           2043.5508
Q Predictions Std            179.81676
Q Predictions Max            2225.845
Q Predictions Min            -222.72249
V Predictions Mean           2044.7203
V Predictions Std            176.06802
V Predictions Max            2223.1038
V Predictions Min            -170.97958
Log Pis Mean                 2.4094758
Log Pis Std                  3.1735086
Log Pis Max                  12.580616
Log Pis Min                  -6.0365815
Policy mu Mean               -0.009473888
Policy mu Std                0.6345299
Policy mu Max                2.862558
Policy mu Min                -2.662947
Policy log std Mean          -1.3300494
Policy log std Std           0.31614265
Policy log std Max           -0.28162897
Policy log std Min           -2.8590698
Z mean eval                  1.1618471
Z variance eval              0.007669826
total_rewards                [5708.61077469 5817.15691099 5094.47414689 5444.92673866 5584.71417924
 5549.63108215 5365.61603434 5490.153541   5454.84585965 5737.63496947]
total_rewards_mean           5524.7764237069905
total_rewards_std            197.92866038264862
total_rewards_max            5817.1569109858565
total_rewards_min            5094.4741468866505
Number of train steps total  2084000
Number of env steps total    2607000
Number of rollouts total     0
Train Time (s)               118.84209480695426
(Previous) Eval Time (s)     25.223157986067235
Sample Time (s)              18.867471660953015
Epoch Time (s)               162.93272445397452
Total Train Time (s)         81455.28478065552
Epoch                        520
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:09:11.724765 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #520 | Epoch Duration: 164.79247045516968
2020-01-12 22:09:11.724960 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #520 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.162101
Z variance train             0.007675925
KL Divergence                27.060524
KL Loss                      2.7060525
QF Loss                      1645.3904
VF Loss                      1402.845
Policy Loss                  -1989.2489
Q Predictions Mean           1990.8679
Q Predictions Std            332.40854
Q Predictions Max            2224.2402
Q Predictions Min            -449.50812
V Predictions Mean           1984.0535
V Predictions Std            335.33594
V Predictions Max            2211.0586
V Predictions Min            -471.6628
Log Pis Mean                 2.5826507
Log Pis Std                  3.2349682
Log Pis Max                  16.304588
Log Pis Min                  -6.618886
Policy mu Mean               -0.009518119
Policy mu Std                0.633782
Policy mu Max                2.865217
Policy mu Min                -2.8738942
Policy log std Mean          -1.3458357
Policy log std Std           0.3446763
Policy log std Max           -0.12320101
Policy log std Min           -3.3363967
Z mean eval                  1.1384013
Z variance eval              0.0052254684
total_rewards                [5478.18179484 5510.61676309 4408.5607543  5504.53191013 5388.60972046
 5490.54372105 5560.09179998 5712.31968323 -573.1181954  5526.74489293]
total_rewards_mean           4800.708284458343
total_rewards_std            1823.3602955323117
total_rewards_max            5712.31968322863
total_rewards_min            -573.118195398773
Number of train steps total  2088000
Number of env steps total    2612000
Number of rollouts total     0
Train Time (s)               118.08911877684295
(Previous) Eval Time (s)     27.08258577203378
Sample Time (s)              18.10496576409787
Epoch Time (s)               163.2766703129746
Total Train Time (s)         81618.3123280122
Epoch                        521
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:11:54.757394 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #521 | Epoch Duration: 163.03230571746826
2020-01-12 22:11:54.757601 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #521 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1393394
Z variance train             0.005222062
KL Divergence                28.152813
KL Loss                      2.8152814
QF Loss                      879.3334
VF Loss                      194.87773
Policy Loss                  -2030.3972
Q Predictions Mean           2035.1497
Q Predictions Std            261.3043
Q Predictions Max            2250.4033
Q Predictions Min            -396.69214
V Predictions Mean           2028.8705
V Predictions Std            259.90942
V Predictions Max            2243.1978
V Predictions Min            -377.7871
Log Pis Mean                 2.862609
Log Pis Std                  3.4296696
Log Pis Max                  14.483883
Log Pis Min                  -8.155933
Policy mu Mean               0.05907613
Policy mu Std                0.6601154
Policy mu Max                2.3698509
Policy mu Min                -3.620598
Policy log std Mean          -1.3776714
Policy log std Std           0.34631777
Policy log std Max           -0.2164048
Policy log std Min           -2.9576159
Z mean eval                  1.16394
Z variance eval              0.006306705
total_rewards                [1.74133863e+03 5.63055151e+03 5.03736897e+03 3.73451244e+00
 5.70690379e+03 5.59215097e+03 5.42055803e+03 5.51617974e+03
 4.47148653e+03 4.72431134e+03]
total_rewards_mean           4384.458402881214
total_rewards_std            1839.5819325947587
total_rewards_max            5706.9037894291505
total_rewards_min            3.7345124396338214
Number of train steps total  2092000
Number of env steps total    2617000
Number of rollouts total     0
Train Time (s)               121.95877962000668
(Previous) Eval Time (s)     26.83790031960234
Sample Time (s)              17.975543019827455
Epoch Time (s)               166.77222295943648
Total Train Time (s)         81779.44504014077
Epoch                        522
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:14:35.895761 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #522 | Epoch Duration: 161.1379852294922
2020-01-12 22:14:35.896011 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #522 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1638047
Z variance train             0.0063027805
KL Divergence                29.16236
KL Loss                      2.916236
QF Loss                      2124.0383
VF Loss                      154.9825
Policy Loss                  -1989.4995
Q Predictions Mean           1985.1846
Q Predictions Std            407.14178
Q Predictions Max            2258.9644
Q Predictions Min            -472.56683
V Predictions Mean           1986.8777
V Predictions Std            386.56815
V Predictions Max            2249.103
V Predictions Min            -484.36954
Log Pis Mean                 2.8150692
Log Pis Std                  4.0223465
Log Pis Max                  20.742584
Log Pis Min                  -8.251251
Policy mu Mean               0.025470877
Policy mu Std                0.6979901
Policy mu Max                3.1634004
Policy mu Min                -3.6308064
Policy log std Mean          -1.3263456
Policy log std Std           0.3731426
Policy log std Max           0.5842433
Policy log std Min           -3.22381
Z mean eval                  1.1471345
Z variance eval              0.004806102
total_rewards                [5285.66564673 3868.5491202  5354.42554027 5741.84937823 5491.77258699
 5683.93833899 1699.37667783 5746.69032794 3903.1551898  5560.67574564]
total_rewards_mean           4833.609855262447
total_rewards_std            1242.5612916459797
total_rewards_max            5746.690327938653
total_rewards_min            1699.376677833733
Number of train steps total  2096000
Number of env steps total    2622000
Number of rollouts total     0
Train Time (s)               122.25168424472213
(Previous) Eval Time (s)     21.203368281945586
Sample Time (s)              18.787311282474548
Epoch Time (s)               162.24236380914226
Total Train Time (s)         81943.83358074632
Epoch                        523
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:17:20.288571 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #523 | Epoch Duration: 164.39240288734436
2020-01-12 22:17:20.288788 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #523 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1471232
Z variance train             0.004805888
KL Divergence                29.406818
KL Loss                      2.940682
QF Loss                      680.40485
VF Loss                      124.43182
Policy Loss                  -2043.2144
Q Predictions Mean           2045.7
Q Predictions Std            243.71924
Q Predictions Max            2250.0671
Q Predictions Min            -411.13828
V Predictions Mean           2041.5066
V Predictions Std            242.836
V Predictions Max            2247.7188
V Predictions Min            -402.52753
Log Pis Mean                 2.5694082
Log Pis Std                  3.2577403
Log Pis Max                  12.63216
Log Pis Min                  -6.9926586
Policy mu Mean               -0.012331905
Policy mu Std                0.6201718
Policy mu Max                2.9573843
Policy mu Min                -2.601198
Policy log std Mean          -1.3605704
Policy log std Std           0.33125785
Policy log std Max           -0.079402566
Policy log std Min           -2.8939934
Z mean eval                  1.1120968
Z variance eval              0.005462076
total_rewards                [3992.54419484 5618.75198569 5586.57987286 5388.49829732 3224.67989407
 5309.59783141 5359.92034484 5517.00981425 5578.63224564 5467.46421415]
total_rewards_mean           5104.367869506367
total_rewards_std            773.4141023502322
total_rewards_max            5618.7519856892295
total_rewards_min            3224.6798940740805
Number of train steps total  2100000
Number of env steps total    2627000
Number of rollouts total     0
Train Time (s)               123.77749981312081
(Previous) Eval Time (s)     23.353096280712634
Sample Time (s)              18.162843307945877
Epoch Time (s)               165.29343940177932
Total Train Time (s)         82111.0432912889
Epoch                        524
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:20:07.506231 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #524 | Epoch Duration: 167.2172622680664
2020-01-12 22:20:07.506547 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #524 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1122223
Z variance train             0.0054579224
KL Divergence                28.717108
KL Loss                      2.8717108
QF Loss                      752.39795
VF Loss                      164.63466
Policy Loss                  -2021.1696
Q Predictions Mean           2022.7117
Q Predictions Std            305.10077
Q Predictions Max            2264.7432
Q Predictions Min            -459.4704
V Predictions Mean           2023.6196
V Predictions Std            302.9322
V Predictions Max            2250.308
V Predictions Min            -441.6452
Log Pis Mean                 2.325509
Log Pis Std                  3.031876
Log Pis Max                  11.458769
Log Pis Min                  -6.460502
Policy mu Mean               -0.0075495746
Policy mu Std                0.6168751
Policy mu Max                2.9540315
Policy mu Min                -2.773372
Policy log std Mean          -1.346295
Policy log std Std           0.30940276
Policy log std Max           0.13869536
Policy log std Min           -2.5379636
Z mean eval                  1.1156931
Z variance eval              0.004950514
total_rewards                [5303.45105959 5503.12289581 5423.87360429 5565.31761117 5489.32951195
  440.15954048  311.7346949  5535.78675216 5411.75171378 5358.70051597]
total_rewards_mean           4434.322790008881
total_rewards_std            2030.7942757710541
total_rewards_max            5565.317611167291
total_rewards_min            311.7346948991104
Number of train steps total  2104000
Number of env steps total    2632000
Number of rollouts total     0
Train Time (s)               119.02689475100487
(Previous) Eval Time (s)     25.276588283013552
Sample Time (s)              17.990491377655417
Epoch Time (s)               162.29397441167384
Total Train Time (s)         82270.98888503807
Epoch                        525
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:22:47.457104 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #525 | Epoch Duration: 159.95031070709229
2020-01-12 22:22:47.457407 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #525 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1153533
Z variance train             0.004937905
KL Divergence                29.002995
KL Loss                      2.9002995
QF Loss                      908.9188
VF Loss                      181.22072
Policy Loss                  -2010.9158
Q Predictions Mean           2016.3232
Q Predictions Std            387.68863
Q Predictions Max            2237.663
Q Predictions Min            -509.86243
V Predictions Mean           2016.6836
V Predictions Std            383.3241
V Predictions Max            2231.1484
V Predictions Min            -457.26965
Log Pis Mean                 2.2435682
Log Pis Std                  3.1101928
Log Pis Max                  12.345737
Log Pis Min                  -5.7686787
Policy mu Mean               0.011866631
Policy mu Std                0.6078563
Policy mu Max                2.3500614
Policy mu Min                -2.7326021
Policy log std Mean          -1.3419623
Policy log std Std           0.3100093
Policy log std Max           -0.2136097
Policy log std Min           -2.7916765
Z mean eval                  1.151022
Z variance eval              0.0043303394
total_rewards                [ -15.50095927 5711.22349138 1713.77431453 5589.5691858   141.06851194
 5584.61732863 5848.82146467 5578.23603916 5705.68339647 5583.54937944]
total_rewards_mean           4144.104215273924
total_rewards_std            2352.1639020584134
total_rewards_max            5848.821464668807
total_rewards_min            -15.500959268902209
Number of train steps total  2108000
Number of env steps total    2637000
Number of rollouts total     0
Train Time (s)               119.81726877810434
(Previous) Eval Time (s)     22.93260260578245
Sample Time (s)              18.70307679893449
Epoch Time (s)               161.45294818282127
Total Train Time (s)         82429.44297170546
Epoch                        526
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:25:25.913431 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #526 | Epoch Duration: 158.45582270622253
2020-01-12 22:25:25.913632 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #526 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1513914
Z variance train             0.0043312474
KL Divergence                29.754328
KL Loss                      2.9754329
QF Loss                      705.1528
VF Loss                      146.84644
Policy Loss                  -2036.3346
Q Predictions Mean           2037.6184
Q Predictions Std            332.0756
Q Predictions Max            2254.1147
Q Predictions Min            -501.33066
V Predictions Mean           2038.6206
V Predictions Std            332.19736
V Predictions Max            2262.2112
V Predictions Min            -497.5767
Log Pis Mean                 2.1909418
Log Pis Std                  3.4870148
Log Pis Max                  14.531497
Log Pis Min                  -7.341975
Policy mu Mean               -0.02046278
Policy mu Std                0.5977098
Policy mu Max                2.585786
Policy mu Min                -2.932153
Policy log std Mean          -1.3672165
Policy log std Std           0.3503332
Policy log std Max           -0.112773776
Policy log std Min           -3.2868304
Z mean eval                  1.2022322
Z variance eval              0.004105268
total_rewards                [5223.22943667 5558.0447829  3802.34899095 3901.73424294 5622.32412348
 5430.33689317 5515.2621101  5518.04024251 5620.80935614 5575.70959138]
total_rewards_mean           5176.783977024552
total_rewards_std            671.7483836926109
total_rewards_max            5622.324123477769
total_rewards_min            3802.3489909505233
Number of train steps total  2112000
Number of env steps total    2642000
Number of rollouts total     0
Train Time (s)               118.41977331601083
(Previous) Eval Time (s)     19.935190788004547
Sample Time (s)              17.972153357695788
Epoch Time (s)               156.32711746171117
Total Train Time (s)         82590.6063780454
Epoch                        527
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:28:07.080528 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #527 | Epoch Duration: 161.1667618751526
2020-01-12 22:28:07.080726 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #527 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2034743
Z variance train             0.00410317
KL Divergence                29.797916
KL Loss                      2.9797916
QF Loss                      955.60956
VF Loss                      281.33066
Policy Loss                  -2015.3534
Q Predictions Mean           2018.7793
Q Predictions Std            356.62433
Q Predictions Max            2243.6104
Q Predictions Min            -457.3559
V Predictions Mean           2022.2812
V Predictions Std            354.25897
V Predictions Max            2246.119
V Predictions Min            -475.3089
Log Pis Mean                 2.715875
Log Pis Std                  3.5016809
Log Pis Max                  13.830677
Log Pis Min                  -8.683367
Policy mu Mean               -0.012737404
Policy mu Std                0.6502978
Policy mu Max                3.1237361
Policy mu Min                -2.733305
Policy log std Mean          -1.3565838
Policy log std Std           0.34023628
Policy log std Max           -0.14930093
Policy log std Min           -2.8635826
Z mean eval                  1.1691649
Z variance eval              0.007805237
total_rewards                [5288.25240335 5298.19220051  674.44845186 5515.42751787 5639.11525534
 5515.00761003   10.20239262  883.9326831  5694.53515372 5486.43014704]
total_rewards_mean           4000.554381543568
total_rewards_std            2288.928551776151
total_rewards_max            5694.53515372386
total_rewards_min            10.202392621518001
Number of train steps total  2116000
Number of env steps total    2647000
Number of rollouts total     0
Train Time (s)               120.52403762564063
(Previous) Eval Time (s)     24.77455033408478
Sample Time (s)              18.028659316711128
Epoch Time (s)               163.32724727643654
Total Train Time (s)         82748.69378093211
Epoch                        528
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:30:45.174002 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #528 | Epoch Duration: 158.09313130378723
2020-01-12 22:30:45.174209 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #528 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1691625
Z variance train             0.007794337
KL Divergence                28.69713
KL Loss                      2.869713
QF Loss                      1047.9333
VF Loss                      119.36752
Policy Loss                  -2059.5532
Q Predictions Mean           2053.0337
Q Predictions Std            316.3274
Q Predictions Max            2281.8489
Q Predictions Min            -386.35568
V Predictions Mean           2056.7136
V Predictions Std            285.4564
V Predictions Max            2270.6794
V Predictions Min            -391.79834
Log Pis Mean                 2.7378378
Log Pis Std                  3.501912
Log Pis Max                  12.46311
Log Pis Min                  -5.076048
Policy mu Mean               -0.01675583
Policy mu Std                0.6849154
Policy mu Max                3.0829687
Policy mu Min                -3.0460417
Policy log std Mean          -1.3385817
Policy log std Std           0.33722484
Policy log std Max           0.010656476
Policy log std Min           -2.8541877
Z mean eval                  1.1111411
Z variance eval              0.0057600345
total_rewards                [1401.4209758  5615.26323982 5581.91695007 5512.71231338  230.76238124
 5506.82995726 5523.97094131 5487.28301067 5674.53298194 5448.10321853]
total_rewards_mean           4598.279597002449
total_rewards_std            1910.139101391754
total_rewards_max            5674.5329819352855
total_rewards_min            230.7623812424951
Number of train steps total  2120000
Number of env steps total    2652000
Number of rollouts total     0
Train Time (s)               116.29368860088289
(Previous) Eval Time (s)     19.540104871615767
Sample Time (s)              18.602448869962245
Epoch Time (s)               154.4362423424609
Total Train Time (s)         82907.23741021007
Epoch                        529
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:33:23.724901 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #529 | Epoch Duration: 158.55050134658813
2020-01-12 22:33:23.725205 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #529 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1097448
Z variance train             0.0057424926
KL Divergence                29.073645
KL Loss                      2.9073646
QF Loss                      866.80725
VF Loss                      150.43079
Policy Loss                  -2019.4491
Q Predictions Mean           2018.397
Q Predictions Std            360.8193
Q Predictions Max            2263.012
Q Predictions Min            -489.4725
V Predictions Mean           2018.8757
V Predictions Std            359.6342
V Predictions Max            2263.657
V Predictions Min            -475.3972
Log Pis Mean                 2.4953663
Log Pis Std                  3.3377566
Log Pis Max                  17.823648
Log Pis Min                  -9.579365
Policy mu Mean               0.01206885
Policy mu Std                0.64840305
Policy mu Max                2.7956135
Policy mu Min                -3.0527656
Policy log std Mean          -1.3399444
Policy log std Std           0.3429988
Policy log std Max           -0.30637884
Policy log std Min           -2.9938848
Z mean eval                  1.1535289
Z variance eval              0.004712603
total_rewards                [5591.67819948 5573.10896302 5652.66865541 5674.12633727 5629.61750598
 5638.5673967  5742.87673152 5323.47261347 5608.19241998 4466.65058495]
total_rewards_mean           5490.095940777503
total_rewards_std            356.66032412418923
total_rewards_max            5742.876731519425
total_rewards_min            4466.65058494762
Number of train steps total  2124000
Number of env steps total    2657000
Number of rollouts total     0
Train Time (s)               123.09100876189768
(Previous) Eval Time (s)     23.654026451986283
Sample Time (s)              18.776511169970036
Epoch Time (s)               165.521546383854
Total Train Time (s)         83076.47591322428
Epoch                        530
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:36:12.972084 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #530 | Epoch Duration: 169.24664950370789
2020-01-12 22:36:12.972370 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #530 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1531543
Z variance train             0.004717085
KL Divergence                29.14554
KL Loss                      2.914554
QF Loss                      836.5578
VF Loss                      157.15611
Policy Loss                  -2043.2208
Q Predictions Mean           2046.1709
Q Predictions Std            329.86194
Q Predictions Max            2296.5017
Q Predictions Min            -512.75244
V Predictions Mean           2037.6619
V Predictions Std            329.22446
V Predictions Max            2269.7761
V Predictions Min            -527.9449
Log Pis Mean                 2.3964028
Log Pis Std                  3.0553255
Log Pis Max                  11.694775
Log Pis Min                  -4.4841795
Policy mu Mean               0.025139017
Policy mu Std                0.5701077
Policy mu Max                2.51899
Policy mu Min                -2.7546985
Policy log std Mean          -1.3854672
Policy log std Std           0.33231732
Policy log std Max           -0.21353674
Policy log std Min           -2.8023407
Z mean eval                  1.1777179
Z variance eval              0.005254229
total_rewards                [5672.41375212 5762.00953525  967.1103176  3697.32140969 5613.26196864
 5565.71726969 5904.59868455 2129.43890532 5585.5068407  5715.29032718]
total_rewards_mean           4661.266901074594
total_rewards_std            1686.8779720313964
total_rewards_max            5904.59868454509
total_rewards_min            967.1103176046829
Number of train steps total  2128000
Number of env steps total    2662000
Number of rollouts total     0
Train Time (s)               122.75680575799197
(Previous) Eval Time (s)     27.3787974556908
Sample Time (s)              18.901139877270907
Epoch Time (s)               169.03674309095368
Total Train Time (s)         83240.73051708052
Epoch                        531
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:38:57.238175 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #531 | Epoch Duration: 164.26557803153992
2020-01-12 22:38:57.238490 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #531 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1742355
Z variance train             0.0052378704
KL Divergence                29.128242
KL Loss                      2.9128244
QF Loss                      827.9894
VF Loss                      165.18936
Policy Loss                  -2054.0928
Q Predictions Mean           2056.6619
Q Predictions Std            306.01984
Q Predictions Max            2271.6765
Q Predictions Min            -557.5393
V Predictions Mean           2051.893
V Predictions Std            300.188
V Predictions Max            2261.6006
V Predictions Min            -475.76303
Log Pis Mean                 2.9796543
Log Pis Std                  3.5391126
Log Pis Max                  15.656634
Log Pis Min                  -5.812845
Policy mu Mean               0.02046145
Policy mu Std                0.6461723
Policy mu Max                2.5652926
Policy mu Min                -2.6774435
Policy log std Mean          -1.3879821
Policy log std Std           0.36205667
Policy log std Max           -0.20615697
Policy log std Min           -3.2015657
Z mean eval                  1.142144
Z variance eval              0.005136305
total_rewards                [2683.68103743 5497.32688236 5642.51753052 5554.83404362 5601.11021539
 1315.973359   5521.76086657 4192.08541102 5196.89314795 4500.85205584]
total_rewards_mean           4570.703454968866
total_rewards_std            1401.3080914282768
total_rewards_max            5642.517530523007
total_rewards_min            1315.9733589974633
Number of train steps total  2132000
Number of env steps total    2667000
Number of rollouts total     0
Train Time (s)               113.64318564580753
(Previous) Eval Time (s)     22.607295361347497
Sample Time (s)              17.90334158204496
Epoch Time (s)               154.1538225892
Total Train Time (s)         83394.46247268794
Epoch                        532
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:41:30.974759 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #532 | Epoch Duration: 153.73602604866028
2020-01-12 22:41:30.975030 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #532 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1426655
Z variance train             0.005127483
KL Divergence                28.013128
KL Loss                      2.801313
QF Loss                      846.0111
VF Loss                      127.69867
Policy Loss                  -2074.637
Q Predictions Mean           2079.4568
Q Predictions Std            198.1213
Q Predictions Max            2302.4788
Q Predictions Min            -424.17007
V Predictions Mean           2069.7263
V Predictions Std            197.28273
V Predictions Max            2288.3523
V Predictions Min            -434.7283
Log Pis Mean                 2.4079194
Log Pis Std                  3.3353417
Log Pis Max                  16.109623
Log Pis Min                  -11.243717
Policy mu Mean               0.05435244
Policy mu Std                0.6634533
Policy mu Max                3.9055345
Policy mu Min                -2.849801
Policy log std Mean          -1.3137892
Policy log std Std           0.29632512
Policy log std Max           -0.20409
Policy log std Min           -2.9217749
Z mean eval                  1.136124
Z variance eval              0.006535093
total_rewards                [5451.64964824  278.96844302 5786.73748126 5861.45875558 5609.04345942
 5591.46042477 5663.95130066 5785.63956727 5752.42812233 5577.19979999]
total_rewards_mean           5135.853700254616
total_rewards_std            1623.168477306751
total_rewards_max            5861.458755580027
total_rewards_min            278.96844302168154
Number of train steps total  2136000
Number of env steps total    2672000
Number of rollouts total     0
Train Time (s)               113.52256749896333
(Previous) Eval Time (s)     22.189227672759444
Sample Time (s)              18.000519810710102
Epoch Time (s)               153.71231498243287
Total Train Time (s)         83550.15488631744
Epoch                        533
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:44:06.673474 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #533 | Epoch Duration: 155.69823622703552
2020-01-12 22:44:06.673703 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #533 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.13584
Z variance train             0.006513805
KL Divergence                27.345858
KL Loss                      2.7345858
QF Loss                      1649.0604
VF Loss                      252.9402
Policy Loss                  -2068.2861
Q Predictions Mean           2071.0308
Q Predictions Std            279.70425
Q Predictions Max            2267.0999
Q Predictions Min            -456.86166
V Predictions Mean           2058.84
V Predictions Std            281.95456
V Predictions Max            2251.3755
V Predictions Min            -464.33743
Log Pis Mean                 2.905993
Log Pis Std                  3.6049793
Log Pis Max                  18.98959
Log Pis Min                  -6.471864
Policy mu Mean               -0.0013711005
Policy mu Std                0.64581054
Policy mu Max                2.654334
Policy mu Min                -2.828357
Policy log std Mean          -1.4087301
Policy log std Std           0.34392485
Policy log std Max           1.7418754
Policy log std Min           -2.8810544
Z mean eval                  1.1517094
Z variance eval              0.003472894
total_rewards                [3781.51053082 5578.53053625 5532.85340243 2886.23626361 5642.26058651
 5629.8524813  4268.90069472 5331.41204139 1280.71555245 5489.24081207]
total_rewards_mean           4542.151290154434
total_rewards_std            1414.2516026879043
total_rewards_max            5642.26058651305
total_rewards_min            1280.7155524542527
Number of train steps total  2140000
Number of env steps total    2677000
Number of rollouts total     0
Train Time (s)               121.94346066005528
(Previous) Eval Time (s)     24.174877017270774
Sample Time (s)              18.27704810956493
Epoch Time (s)               164.39538578689098
Total Train Time (s)         83712.36398285674
Epoch                        534
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:46:48.889628 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #534 | Epoch Duration: 162.2157416343689
2020-01-12 22:46:48.889868 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #534 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1515958
Z variance train             0.0034718227
KL Divergence                28.22258
KL Loss                      2.822258
QF Loss                      855.6437
VF Loss                      117.46408
Policy Loss                  -2104.673
Q Predictions Mean           2108.5635
Q Predictions Std            253.23651
Q Predictions Max            2325.0286
Q Predictions Min            -442.50702
V Predictions Mean           2107.8623
V Predictions Std            251.00487
V Predictions Max            2315.6848
V Predictions Min            -415.34998
Log Pis Mean                 2.6781263
Log Pis Std                  3.2535396
Log Pis Max                  12.578705
Log Pis Min                  -6.80796
Policy mu Mean               0.031238003
Policy mu Std                0.64009726
Policy mu Max                2.8304827
Policy mu Min                -3.093818
Policy log std Mean          -1.3719618
Policy log std Std           0.3364714
Policy log std Max           -0.24306214
Policy log std Min           -2.7859244
Z mean eval                  1.2208602
Z variance eval              0.018339554
total_rewards                [4193.08356033 5188.05081118 5381.04392877 5325.33753268 2406.55116467
  593.03647984 5320.9671932  5230.7635308  5405.72159743 5203.28090757]
total_rewards_mean           4424.783670646713
total_rewards_std            1553.650127803452
total_rewards_max            5405.721597434767
total_rewards_min            593.036479840623
Number of train steps total  2144000
Number of env steps total    2682000
Number of rollouts total     0
Train Time (s)               126.57291291002184
(Previous) Eval Time (s)     21.99493814818561
Sample Time (s)              17.861184247769415
Epoch Time (s)               166.42903530597687
Total Train Time (s)         83879.28590013413
Epoch                        535
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:49:35.815014 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #535 | Epoch Duration: 166.92498302459717
2020-01-12 22:49:35.815161 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #535 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.220165
Z variance train             0.018396351
KL Divergence                25.374718
KL Loss                      2.5374718
QF Loss                      9504.377
VF Loss                      487.18127
Policy Loss                  -2041.8604
Q Predictions Mean           2039.761
Q Predictions Std            460.99625
Q Predictions Max            2316.4866
Q Predictions Min            -561.2897
V Predictions Mean           2025.9498
V Predictions Std            449.1378
V Predictions Max            2293.9033
V Predictions Min            -519.51483
Log Pis Mean                 2.4711075
Log Pis Std                  3.5794528
Log Pis Max                  17.08251
Log Pis Min                  -5.708951
Policy mu Mean               0.06155917
Policy mu Std                0.6919595
Policy mu Max                2.7896183
Policy mu Min                -2.85837
Policy log std Mean          -1.3332119
Policy log std Std           0.38044104
Policy log std Max           -0.0061528683
Policy log std Min           -3.6629524
Z mean eval                  1.172129
Z variance eval              0.014107426
total_rewards                [5502.57058903 1041.53628484 5702.93627223 5743.99688516 5821.97749333
 4392.60483721 5691.79321716 5809.65373716  194.70101895 5714.53996908]
total_rewards_mean           4561.631030416197
total_rewards_std            2020.5976341558437
total_rewards_max            5821.97749333446
total_rewards_min            194.70101895437358
Number of train steps total  2148000
Number of env steps total    2687000
Number of rollouts total     0
Train Time (s)               120.15639975760132
(Previous) Eval Time (s)     22.490593133028597
Sample Time (s)              18.0912374118343
Epoch Time (s)               160.73823030246422
Total Train Time (s)         84039.46221381566
Epoch                        536
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:52:15.997083 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #536 | Epoch Duration: 160.181804895401
2020-01-12 22:52:15.997311 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #536 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1713059
Z variance train             0.0141112115
KL Divergence                26.209782
KL Loss                      2.620978
QF Loss                      928.5178
VF Loss                      205.35614
Policy Loss                  -2049.0796
Q Predictions Mean           2050.0872
Q Predictions Std            432.13455
Q Predictions Max            2318.0112
Q Predictions Min            -482.00528
V Predictions Mean           2054.2805
V Predictions Std            426.44455
V Predictions Max            2316.3643
V Predictions Min            -454.49124
Log Pis Mean                 2.8186574
Log Pis Std                  3.671449
Log Pis Max                  17.635857
Log Pis Min                  -4.211115
Policy mu Mean               0.00015572645
Policy mu Std                0.66564256
Policy mu Max                2.896363
Policy mu Min                -2.869558
Policy log std Mean          -1.3874803
Policy log std Std           0.3365161
Policy log std Max           -0.26153684
Policy log std Min           -3.1521502
Z mean eval                  1.178256
Z variance eval              0.015688708
total_rewards                [5328.20715549 5340.54968444 5488.27798182 5669.65627932 5839.67402317
 5630.42762215 5530.77535564 5384.88340025 5765.35621234 5566.1851981 ]
total_rewards_mean           5554.399291271242
total_rewards_std            166.02655662030668
total_rewards_max            5839.674023165859
total_rewards_min            5328.20715548705
Number of train steps total  2152000
Number of env steps total    2692000
Number of rollouts total     0
Train Time (s)               120.87927235057577
(Previous) Eval Time (s)     21.933878798037767
Sample Time (s)              17.63278284901753
Epoch Time (s)               160.44593399763107
Total Train Time (s)         84204.8417514353
Epoch                        537
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:55:01.383622 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #537 | Epoch Duration: 165.3861439228058
2020-01-12 22:55:01.383911 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #537 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1785326
Z variance train             0.015678007
KL Divergence                25.531906
KL Loss                      2.5531907
QF Loss                      2877.9072
VF Loss                      245.78758
Policy Loss                  -2063.0977
Q Predictions Mean           2065.1233
Q Predictions Std            274.35962
Q Predictions Max            2251.277
Q Predictions Min            -436.73547
V Predictions Mean           2057.104
V Predictions Std            270.4914
V Predictions Max            2243.204
V Predictions Min            -393.71054
Log Pis Mean                 2.978128
Log Pis Std                  3.4015672
Log Pis Max                  14.790758
Log Pis Min                  -4.915329
Policy mu Mean               0.038424447
Policy mu Std                0.61944264
Policy mu Max                2.8682435
Policy mu Min                -2.673311
Policy log std Mean          -1.399872
Policy log std Std           0.3155714
Policy log std Max           -0.28113544
Policy log std Min           -2.7352262
Z mean eval                  1.1930434
Z variance eval              0.0105837565
total_rewards                [5490.07533501 3922.40072034 1422.74766912 5463.88778877 2160.70127772
 2972.0466565  5623.00326931 5732.57628741 1072.42182163 5534.41769649]
total_rewards_mean           3939.4278522297946
total_rewards_std            1788.1742941995992
total_rewards_max            5732.576287410748
total_rewards_min            1072.4218216268366
Number of train steps total  2156000
Number of env steps total    2697000
Number of rollouts total     0
Train Time (s)               125.6307245567441
(Previous) Eval Time (s)     26.873779091984034
Sample Time (s)              18.704072820954025
Epoch Time (s)               171.20857646968216
Total Train Time (s)         84368.27637086948
Epoch                        538
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:57:44.824119 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #538 | Epoch Duration: 163.44000482559204
2020-01-12 22:57:44.824345 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #538 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1934154
Z variance train             0.010568905
KL Divergence                25.573706
KL Loss                      2.5573707
QF Loss                      887.5563
VF Loss                      194.28833
Policy Loss                  -2074.7395
Q Predictions Mean           2077.1084
Q Predictions Std            199.12791
Q Predictions Max            2263.248
Q Predictions Min            -439.69458
V Predictions Mean           2082.3506
V Predictions Std            197.6582
V Predictions Max            2277.3323
V Predictions Min            -418.00723
Log Pis Mean                 3.0170753
Log Pis Std                  3.229583
Log Pis Max                  13.363415
Log Pis Min                  -4.017639
Policy mu Mean               -0.005757581
Policy mu Std                0.64996004
Policy mu Max                2.796356
Policy mu Min                -3.9854932
Policy log std Mean          -1.3890028
Policy log std Std           0.33293647
Policy log std Max           0.1689353
Policy log std Min           -2.8599184
Z mean eval                  1.142915
Z variance eval              0.01057257
total_rewards                [5404.90459658 5464.45748415 5667.77125642   66.17566885 5212.10864409
 5323.03637694 5342.24399713  877.34500377 5508.40271308 5591.35492834]
total_rewards_mean           4445.78006693403
total_rewards_std            1999.1884314801716
total_rewards_max            5667.771256424721
total_rewards_min            66.17566884515213
Number of train steps total  2160000
Number of env steps total    2702000
Number of rollouts total     0
Train Time (s)               125.62580361496657
(Previous) Eval Time (s)     19.10489651095122
Sample Time (s)              18.36299781827256
Epoch Time (s)               163.09369794419035
Total Train Time (s)         84534.09403500427
Epoch                        539
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:00:30.645389 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #539 | Epoch Duration: 165.82088375091553
2020-01-12 23:00:30.645585 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #539 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1431715
Z variance train             0.010554871
KL Divergence                25.907097
KL Loss                      2.5907097
QF Loss                      1281.7395
VF Loss                      324.3335
Policy Loss                  -2069.7026
Q Predictions Mean           2066.5757
Q Predictions Std            363.62665
Q Predictions Max            2287.7498
Q Predictions Min            -580.6732
V Predictions Mean           2061.3286
V Predictions Std            348.79227
V Predictions Max            2280.3496
V Predictions Min            -647.4783
Log Pis Mean                 2.9974613
Log Pis Std                  3.3617742
Log Pis Max                  19.22519
Log Pis Min                  -4.4670362
Policy mu Mean               -0.011033382
Policy mu Std                0.65238327
Policy mu Max                2.8095882
Policy mu Min                -3.0493796
Policy log std Mean          -1.4030492
Policy log std Std           0.3728521
Policy log std Max           0.056720734
Policy log std Min           -3.6039376
Z mean eval                  1.1452496
Z variance eval              0.008328827
total_rewards                [ -15.22994135 5547.15954977 5555.30505915 1252.82511148 5787.30817508
   53.09568209 5506.39867576 5548.17305313 5715.9153471  5520.56350158]
total_rewards_mean           4047.151421378876
total_rewards_std            2390.7020957253703
total_rewards_max            5787.308175078268
total_rewards_min            -15.229941351780738
Number of train steps total  2164000
Number of env steps total    2707000
Number of rollouts total     0
Train Time (s)               119.77447163593024
(Previous) Eval Time (s)     21.831764572765678
Sample Time (s)              18.142715003341436
Epoch Time (s)               159.74895121203735
Total Train Time (s)         84692.01145273214
Epoch                        540
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:03:08.568436 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #540 | Epoch Duration: 157.92271733283997
2020-01-12 23:03:08.568657 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #540 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1483314
Z variance train             0.00830734
KL Divergence                26.055952
KL Loss                      2.6055954
QF Loss                      1220.5486
VF Loss                      294.60696
Policy Loss                  -2074.653
Q Predictions Mean           2078.0198
Q Predictions Std            333.25223
Q Predictions Max            2319.2007
Q Predictions Min            -441.78937
V Predictions Mean           2067.022
V Predictions Std            331.7351
V Predictions Max            2301.1868
V Predictions Min            -439.7322
Log Pis Mean                 2.8793478
Log Pis Std                  3.5688317
Log Pis Max                  15.895906
Log Pis Min                  -4.197557
Policy mu Mean               0.012993511
Policy mu Std                0.65409964
Policy mu Max                2.9488025
Policy mu Min                -2.970933
Policy log std Mean          -1.3774488
Policy log std Std           0.36386266
Policy log std Max           -0.061044574
Policy log std Min           -2.941501
Z mean eval                  1.1447673
Z variance eval              0.007662233
total_rewards                [5556.98181706 5591.91251555 5549.01405964 5717.4154101  5663.84310835
 5435.38880736 5783.61502963 5444.798724   5514.76958703 5458.45311388]
total_rewards_mean           5571.619217258109
total_rewards_std            112.48185386405336
total_rewards_max            5783.615029625107
total_rewards_min            5435.388807362242
Number of train steps total  2168000
Number of env steps total    2712000
Number of rollouts total     0
Train Time (s)               122.75877189682797
(Previous) Eval Time (s)     20.005219527054578
Sample Time (s)              17.508225824218243
Epoch Time (s)               160.2722172481008
Total Train Time (s)         84859.14872460952
Epoch                        541
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:05:55.709133 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #541 | Epoch Duration: 167.1403226852417
2020-01-12 23:05:55.709288 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #541 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1442633
Z variance train             0.0076716663
KL Divergence                25.641476
KL Loss                      2.5641477
QF Loss                      873.85944
VF Loss                      111.47487
Policy Loss                  -2109.703
Q Predictions Mean           2111.4277
Q Predictions Std            171.80202
Q Predictions Max            2289.8555
Q Predictions Min            224.584
V Predictions Mean           2107.2266
V Predictions Std            166.07047
V Predictions Max            2288.1423
V Predictions Min            317.63602
Log Pis Mean                 2.497083
Log Pis Std                  3.1844082
Log Pis Max                  15.175829
Log Pis Min                  -6.0315027
Policy mu Mean               0.009436141
Policy mu Std                0.6101528
Policy mu Max                2.7122116
Policy mu Min                -2.5534952
Policy log std Mean          -1.3908622
Policy log std Std           0.33981618
Policy log std Max           -0.12625575
Policy log std Min           -3.4340925
Z mean eval                  1.1765138
Z variance eval              0.012783806
total_rewards                [5581.83806357 4613.22400862 5571.67834411    6.77787912 5624.29593338
 5614.07225116 5483.06007131 5562.21641463 5534.21560987 5561.60459237]
total_rewards_mean           4915.298316815971
total_rewards_std            1661.0996729110968
total_rewards_max            5624.295933382032
total_rewards_min            6.777879117664227
Number of train steps total  2172000
Number of env steps total    2717000
Number of rollouts total     0
Train Time (s)               121.55676260171458
(Previous) Eval Time (s)     26.87304987711832
Sample Time (s)              18.53402614267543
Epoch Time (s)               166.96383862150833
Total Train Time (s)         85022.77884089528
Epoch                        542
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:08:39.344748 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #542 | Epoch Duration: 163.6353199481964
2020-01-12 23:08:39.344949 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #542 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1749742
Z variance train             0.012765293
KL Divergence                24.98003
KL Loss                      2.498003
QF Loss                      1053.39
VF Loss                      432.14136
Policy Loss                  -2104.358
Q Predictions Mean           2107.313
Q Predictions Std            221.13928
Q Predictions Max            2310.8096
Q Predictions Min            -172.27725
V Predictions Mean           2107.887
V Predictions Std            204.72462
V Predictions Max            2310.6418
V Predictions Min            -8.309484
Log Pis Mean                 2.9609308
Log Pis Std                  3.4288163
Log Pis Max                  19.107704
Log Pis Min                  -5.447175
Policy mu Mean               0.044890836
Policy mu Std                0.647457
Policy mu Max                3.26001
Policy mu Min                -2.6952832
Policy log std Mean          -1.4120587
Policy log std Std           0.3722757
Policy log std Max           -0.2485323
Policy log std Min           -3.3666444
Z mean eval                  1.1884228
Z variance eval              0.012539124
total_rewards                [5559.8540599  5676.03222551 5715.22196511 5475.11978943 5825.80049817
 5731.73274817 5690.6141325  3580.71918484 5876.0911173  2421.09243003]
total_rewards_mean           5155.22781509625
total_rewards_std            1113.2729115673799
total_rewards_max            5876.091117299136
total_rewards_min            2421.0924300267648
Number of train steps total  2176000
Number of env steps total    2722000
Number of rollouts total     0
Train Time (s)               114.62250758009031
(Previous) Eval Time (s)     23.54418281512335
Sample Time (s)              18.469414790160954
Epoch Time (s)               156.63610518537462
Total Train Time (s)         85182.11532948446
Epoch                        543
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:11:18.690028 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #543 | Epoch Duration: 159.34489369392395
2020-01-12 23:11:18.690343 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #543 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.18755
Z variance train             0.012543981
KL Divergence                24.55324
KL Loss                      2.455324
QF Loss                      560.29236
VF Loss                      134.18512
Policy Loss                  -2090.475
Q Predictions Mean           2092.6528
Q Predictions Std            298.03564
Q Predictions Max            2311.7888
Q Predictions Min            -412.30914
V Predictions Mean           2086.0552
V Predictions Std            295.13132
V Predictions Max            2305.324
V Predictions Min            -412.44406
Log Pis Mean                 3.0757442
Log Pis Std                  3.287016
Log Pis Max                  12.866871
Log Pis Min                  -4.512998
Policy mu Mean               0.01389497
Policy mu Std                0.6452436
Policy mu Max                2.6233847
Policy mu Min                -2.6416478
Policy log std Mean          -1.4041524
Policy log std Std           0.33706743
Policy log std Max           -0.20772839
Policy log std Min           -2.9040952
Z mean eval                  1.1428427
Z variance eval              0.007115352
total_rewards                [5597.85078363 5910.16635065 5561.21006268 5708.46981055 4074.16036308
 5607.8363033  5593.75369873 5599.76671856 5534.29669504 5700.68133786]
total_rewards_mean           5488.819212408632
total_rewards_std            482.5564422924754
total_rewards_max            5910.166350652422
total_rewards_min            4074.160363077818
Number of train steps total  2180000
Number of env steps total    2727000
Number of rollouts total     0
Train Time (s)               121.90852490020916
(Previous) Eval Time (s)     26.25265509262681
Sample Time (s)              18.148778409697115
Epoch Time (s)               166.30995840253308
Total Train Time (s)         85349.08371738857
Epoch                        544
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:14:05.665109 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #544 | Epoch Duration: 166.97452402114868
2020-01-12 23:14:05.665339 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #544 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1409043
Z variance train             0.007103271
KL Divergence                26.160603
KL Loss                      2.6160603
QF Loss                      1365.4471
VF Loss                      218.57825
Policy Loss                  -2062.014
Q Predictions Mean           2064.353
Q Predictions Std            381.8055
Q Predictions Max            2291.8394
Q Predictions Min            -374.52957
V Predictions Mean           2068.3062
V Predictions Std            384.99115
V Predictions Max            2295.51
V Predictions Min            -370.18484
Log Pis Mean                 2.6630626
Log Pis Std                  3.2435663
Log Pis Max                  14.381261
Log Pis Min                  -4.478096
Policy mu Mean               0.0044789216
Policy mu Std                0.60612845
Policy mu Max                2.948124
Policy mu Min                -3.4730387
Policy log std Mean          -1.3912005
Policy log std Std           0.3478346
Policy log std Max           -0.02089858
Policy log std Min           -2.9339256
Z mean eval                  1.1553376
Z variance eval              0.0056772507
total_rewards                [5509.50566491 5484.44483339 3456.19428965 5674.47685084 5664.86519334
 5682.35259064 5477.61617557 5519.1193235  5576.47922129  602.65733717]
total_rewards_mean           4864.771148028796
total_rewards_std            1556.4020413159062
total_rewards_max            5682.352590640198
total_rewards_min            602.6573371713362
Number of train steps total  2184000
Number of env steps total    2732000
Number of rollouts total     0
Train Time (s)               114.71879682410508
(Previous) Eval Time (s)     26.916954395826906
Sample Time (s)              18.3317627068609
Epoch Time (s)               159.9675139267929
Total Train Time (s)         85506.89133929648
Epoch                        545
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:16:43.481964 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #545 | Epoch Duration: 157.81641840934753
2020-01-12 23:16:43.482287 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #545 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.155236
Z variance train             0.005679833
KL Divergence                26.821762
KL Loss                      2.6821764
QF Loss                      1506.5979
VF Loss                      947.48157
Policy Loss                  -2078.891
Q Predictions Mean           2080.9329
Q Predictions Std            247.93109
Q Predictions Max            2278.6643
Q Predictions Min            -665.25885
V Predictions Mean           2077.2136
V Predictions Std            247.04921
V Predictions Max            2288.9553
V Predictions Min            -669.25775
Log Pis Mean                 3.0786328
Log Pis Std                  3.9588437
Log Pis Max                  24.810274
Log Pis Min                  -7.3375707
Policy mu Mean               0.024982706
Policy mu Std                0.6968712
Policy mu Max                4.9688764
Policy mu Min                -3.485619
Policy log std Mean          -1.3992178
Policy log std Std           0.3622147
Policy log std Max           1.030685
Policy log std Min           -3.259901
Z mean eval                  1.1176498
Z variance eval              0.0070158527
total_rewards                [5682.50842576 5512.79160958 5590.95303647 5616.997755   5573.04477567
 5711.73582105 5451.23271016 5681.0874415  5717.60832887 5810.32979004]
total_rewards_mean           5634.828969409621
total_rewards_std            101.31230967667334
total_rewards_max            5810.329790037991
total_rewards_min            5451.2327101626415
Number of train steps total  2188000
Number of env steps total    2737000
Number of rollouts total     0
Train Time (s)               120.98543335916474
(Previous) Eval Time (s)     24.76553564798087
Sample Time (s)              18.781371077988297
Epoch Time (s)               164.5323400851339
Total Train Time (s)         85673.58522140048
Epoch                        546
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:19:30.182678 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #546 | Epoch Duration: 166.70014715194702
2020-01-12 23:19:30.182937 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #546 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1174324
Z variance train             0.007023538
KL Divergence                26.014927
KL Loss                      2.6014926
QF Loss                      1191.6917
VF Loss                      184.66762
Policy Loss                  -2103.4763
Q Predictions Mean           2107.9922
Q Predictions Std            222.48557
Q Predictions Max            2293.2246
Q Predictions Min            -434.57153
V Predictions Mean           2100.2761
V Predictions Std            222.72202
V Predictions Max            2283.0618
V Predictions Min            -439.88422
Log Pis Mean                 2.748992
Log Pis Std                  3.603761
Log Pis Max                  27.864882
Log Pis Min                  -5.42492
Policy mu Mean               -0.004901934
Policy mu Std                0.6361195
Policy mu Max                3.5904398
Policy mu Min                -3.088075
Policy log std Mean          -1.3790483
Policy log std Std           0.31468657
Policy log std Max           -0.028867483
Policy log std Min           -2.7487955
Z mean eval                  1.1282413
Z variance eval              0.006479324
total_rewards                [5617.34729712 1943.16118872 5738.4341684  5625.09480425 5683.33675452
 5625.1499054  5482.50505028   13.92305298 5704.6294698  5804.75930918]
total_rewards_mean           4723.834100066046
total_rewards_std            1923.393092969484
total_rewards_max            5804.759309181267
total_rewards_min            13.92305297959242
Number of train steps total  2192000
Number of env steps total    2742000
Number of rollouts total     0
Train Time (s)               121.4039698317647
(Previous) Eval Time (s)     26.933044608682394
Sample Time (s)              18.393748983275145
Epoch Time (s)               166.73076342372224
Total Train Time (s)         85836.42715864861
Epoch                        547
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:22:13.028526 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #547 | Epoch Duration: 162.84540939331055
2020-01-12 23:22:13.028691 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #547 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.128352
Z variance train             0.006476222
KL Divergence                26.848917
KL Loss                      2.6848917
QF Loss                      932.8489
VF Loss                      88.608864
Policy Loss                  -2141.3286
Q Predictions Mean           2145.5078
Q Predictions Std            186.607
Q Predictions Max            2325.6309
Q Predictions Min            -333.6309
V Predictions Mean           2144.3433
V Predictions Std            185.30547
V Predictions Max            2323.9023
V Predictions Min            -319.59024
Log Pis Mean                 2.55198
Log Pis Std                  3.522333
Log Pis Max                  13.559588
Log Pis Min                  -6.0299435
Policy mu Mean               -0.008327594
Policy mu Std                0.6155279
Policy mu Max                2.4228706
Policy mu Min                -3.2293894
Policy log std Mean          -1.385815
Policy log std Std           0.29711843
Policy log std Max           -0.16769242
Policy log std Min           -2.8883054
Z mean eval                  1.1724238
Z variance eval              0.0077850027
total_rewards                [5641.49044299 5668.87344781 5582.42487517 5803.01199245 5632.16554722
 2465.76008803 5605.21682638 5759.12085587 5749.07656633 5670.68500587]
total_rewards_mean           5357.782564813691
total_rewards_std            966.3517065028446
total_rewards_max            5803.011992448098
total_rewards_min            2465.7600880332266
Number of train steps total  2196000
Number of env steps total    2747000
Number of rollouts total     0
Train Time (s)               114.79938395507634
(Previous) Eval Time (s)     23.047443851828575
Sample Time (s)              18.632352018728852
Epoch Time (s)               156.47917982563376
Total Train Time (s)         85995.92421237566
Epoch                        548
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:24:52.528886 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #548 | Epoch Duration: 159.50007557868958
2020-01-12 23:24:52.529077 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #548 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1765764
Z variance train             0.007771738
KL Divergence                25.760414
KL Loss                      2.5760415
QF Loss                      1182.6283
VF Loss                      694.37164
Policy Loss                  -2115.5962
Q Predictions Mean           2121.4285
Q Predictions Std            280.44632
Q Predictions Max            2334.14
Q Predictions Min            -343.5932
V Predictions Mean           2107.3225
V Predictions Std            285.24213
V Predictions Max            2318.4023
V Predictions Min            -321.51413
Log Pis Mean                 3.2675395
Log Pis Std                  4.1241636
Log Pis Max                  28.080765
Log Pis Min                  -6.476865
Policy mu Mean               -0.014302565
Policy mu Std                0.6937405
Policy mu Max                3.249481
Policy mu Min                -3.9758713
Policy log std Mean          -1.3923275
Policy log std Std           0.36192787
Policy log std Max           0.17821264
Policy log std Min           -4.3402767
Z mean eval                  1.1501287
Z variance eval              0.009242071
total_rewards                [5270.57034763 1493.88657733 5663.25396251 5667.78199058 3988.45110881
 5380.7884823  5604.97470302 5418.41014915 5571.90614527 5620.6746054 ]
total_rewards_mean           4968.069807199152
total_rewards_std            1251.530621110879
total_rewards_max            5667.7819905750575
total_rewards_min            1493.8865773272928
Number of train steps total  2200000
Number of env steps total    2752000
Number of rollouts total     0
Train Time (s)               119.12606289610267
(Previous) Eval Time (s)     26.068026398308575
Sample Time (s)              18.210223820526153
Epoch Time (s)               163.4043131149374
Total Train Time (s)         86157.3524502581
Epoch                        549
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:27:33.965196 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #549 | Epoch Duration: 161.43598461151123
2020-01-12 23:27:33.965418 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #549 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1497123
Z variance train             0.0092551205
KL Divergence                26.317059
KL Loss                      2.631706
QF Loss                      1643.044
VF Loss                      225.22617
Policy Loss                  -2080.435
Q Predictions Mean           2081.6904
Q Predictions Std            391.2967
Q Predictions Max            2324.7852
Q Predictions Min            -653.6259
V Predictions Mean           2078.6372
V Predictions Std            386.52768
V Predictions Max            2311.4365
V Predictions Min            -613.07574
Log Pis Mean                 2.9262192
Log Pis Std                  3.5489943
Log Pis Max                  17.85407
Log Pis Min                  -5.2026215
Policy mu Mean               -0.010108542
Policy mu Std                0.6376079
Policy mu Max                3.4598644
Policy mu Min                -3.0083275
Policy log std Mean          -1.3985958
Policy log std Std           0.34747347
Policy log std Max           0.14496195
Policy log std Min           -2.9136024
Z mean eval                  1.1783526
Z variance eval              0.007586571
total_rewards                [5700.64261748 5810.66638306  154.93326619 5743.29192829 5860.5006706
 5759.22031175 5507.16786842 5566.5400168  5826.56220378 5744.28841235]
total_rewards_mean           5167.381367872133
total_rewards_std            1674.1357001586307
total_rewards_max            5860.500670599877
total_rewards_min            154.93326618705214
Number of train steps total  2204000
Number of env steps total    2757000
Number of rollouts total     0
Train Time (s)               120.1398613192141
(Previous) Eval Time (s)     24.099389255978167
Sample Time (s)              18.093577838037163
Epoch Time (s)               162.33282841322944
Total Train Time (s)         86320.21317066438
Epoch                        550
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:30:16.830244 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #550 | Epoch Duration: 162.86465668678284
2020-01-12 23:30:16.830452 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #550 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1787612
Z variance train             0.0075865397
KL Divergence                26.367886
KL Loss                      2.6367886
QF Loss                      580.7212
VF Loss                      144.96033
Policy Loss                  -2119.878
Q Predictions Mean           2122.8193
Q Predictions Std            347.07852
Q Predictions Max            2354.5427
Q Predictions Min            -535.1974
V Predictions Mean           2116.9143
V Predictions Std            348.21814
V Predictions Max            2346.642
V Predictions Min            -551.43774
Log Pis Mean                 2.9692922
Log Pis Std                  3.5486302
Log Pis Max                  12.361734
Log Pis Min                  -8.03604
Policy mu Mean               -0.023241261
Policy mu Std                0.6509854
Policy mu Max                2.85486
Policy mu Min                -2.919087
Policy log std Mean          -1.399795
Policy log std Std           0.33818644
Policy log std Max           -0.016612291
Policy log std Min           -2.8026237
Z mean eval                  1.1422228
Z variance eval              0.010354114
total_rewards                [5669.83494632 5584.62296487 5671.88320453 5819.15142791 5337.34398554
 5538.81363412 5774.47341359 5722.53841747 5711.79066971 5801.09634419]
total_rewards_mean           5663.154900824566
total_rewards_std            137.67642644771396
total_rewards_max            5819.151427905499
total_rewards_min            5337.343985536296
Number of train steps total  2208000
Number of env steps total    2762000
Number of rollouts total     0
Train Time (s)               127.70030008396134
(Previous) Eval Time (s)     24.630916273221374
Sample Time (s)              18.54409661050886
Epoch Time (s)               170.87531296769157
Total Train Time (s)         86492.8955308781
Epoch                        551
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:33:09.517192 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #551 | Epoch Duration: 172.6865963935852
2020-01-12 23:33:09.517379 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #551 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1430243
Z variance train             0.010350045
KL Divergence                25.866957
KL Loss                      2.5866957
QF Loss                      952.06525
VF Loss                      212.80327
Policy Loss                  -2138.6807
Q Predictions Mean           2132.0432
Q Predictions Std            286.38196
Q Predictions Max            2321.9578
Q Predictions Min            -329.92706
V Predictions Mean           2133.9502
V Predictions Std            254.74194
V Predictions Max            2321.8503
V Predictions Min            -319.43976
Log Pis Mean                 3.1671667
Log Pis Std                  3.533011
Log Pis Max                  17.46162
Log Pis Min                  -6.9504433
Policy mu Mean               0.029018527
Policy mu Std                0.6700731
Policy mu Max                2.8297923
Policy mu Min                -2.9604614
Policy log std Mean          -1.3969983
Policy log std Std           0.34121132
Policy log std Max           0.34043312
Policy log std Min           -3.2481341
Z mean eval                  1.1497319
Z variance eval              0.011159447
total_rewards                [5711.6799776  5601.52709239 5887.22967118 1668.12346726 5555.38638047
 5474.65529027 5520.76114689 5696.33829815 5446.32195064 5687.85067251]
total_rewards_mean           5224.987394736532
total_rewards_std            1192.177854994079
total_rewards_max            5887.229671181736
total_rewards_min            1668.1234672639648
Number of train steps total  2212000
Number of env steps total    2767000
Number of rollouts total     0
Train Time (s)               121.37569059384987
(Previous) Eval Time (s)     26.441848332993686
Sample Time (s)              17.964958638418466
Epoch Time (s)               165.78249756526202
Total Train Time (s)         86657.8317765221
Epoch                        552
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:35:54.457526 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #552 | Epoch Duration: 164.93998289108276
2020-01-12 23:35:54.457713 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #552 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1508077
Z variance train             0.011146052
KL Divergence                25.454594
KL Loss                      2.5454595
QF Loss                      876.7538
VF Loss                      179.69589
Policy Loss                  -2118.7263
Q Predictions Mean           2120.0078
Q Predictions Std            350.51898
Q Predictions Max            2317.7935
Q Predictions Min            -723.1043
V Predictions Mean           2115.9917
V Predictions Std            345.32635
V Predictions Max            2313.878
V Predictions Min            -704.2879
Log Pis Mean                 2.8743327
Log Pis Std                  3.373392
Log Pis Max                  13.874687
Log Pis Min                  -7.5739174
Policy mu Mean               -0.003531024
Policy mu Std                0.64302915
Policy mu Max                2.8544874
Policy mu Min                -3.2556665
Policy log std Mean          -1.3985858
Policy log std Std           0.31686187
Policy log std Max           -0.13371909
Policy log std Min           -2.8550367
Z mean eval                  1.1858678
Z variance eval              0.007149293
total_rewards                [3482.95262728 5522.68242698 5682.94926336 5564.56620973 5570.10796488
 5390.99934184 5531.92795706 5634.02741846 5553.39949038 5698.53204126]
total_rewards_mean           5363.2144741220645
total_rewards_std            632.2639096403296
total_rewards_max            5698.532041264092
total_rewards_min            3482.952627279921
Number of train steps total  2216000
Number of env steps total    2772000
Number of rollouts total     0
Train Time (s)               122.84058934636414
(Previous) Eval Time (s)     25.599039891269058
Sample Time (s)              18.798299563117325
Epoch Time (s)               167.23792880075052
Total Train Time (s)         86826.87123119319
Epoch                        553
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:38:43.501385 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #553 | Epoch Duration: 169.04354572296143
2020-01-12 23:38:43.501537 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #553 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1853502
Z variance train             0.0071386853
KL Divergence                26.95339
KL Loss                      2.695339
QF Loss                      916.97986
VF Loss                      489.14255
Policy Loss                  -2108.9
Q Predictions Mean           2111.432
Q Predictions Std            362.0329
Q Predictions Max            2344.2532
Q Predictions Min            -736.6668
V Predictions Mean           2104.3765
V Predictions Std            353.67163
V Predictions Max            2321.6729
V Predictions Min            -715.0239
Log Pis Mean                 3.0867271
Log Pis Std                  3.3196552
Log Pis Max                  17.60725
Log Pis Min                  -6.0949807
Policy mu Mean               0.00952184
Policy mu Std                0.64908415
Policy mu Max                2.6750088
Policy mu Min                -3.2131667
Policy log std Mean          -1.4011492
Policy log std Std           0.34709346
Policy log std Max           0.09935677
Policy log std Min           -3.2642546
Z mean eval                  1.1400342
Z variance eval              0.010537882
total_rewards                [5516.78411846 5771.40689032 5595.39981806 5792.62602005 5608.66121019
 4549.66565292 5614.25604903 5678.66991218 5611.39263269 5522.78781532]
total_rewards_mean           5526.165011922053
total_rewards_std            336.8495296699298
total_rewards_max            5792.626020048341
total_rewards_min            4549.665652923877
Number of train steps total  2220000
Number of env steps total    2777000
Number of rollouts total     0
Train Time (s)               118.78185903374106
(Previous) Eval Time (s)     27.404360325075686
Sample Time (s)              18.074220198672265
Epoch Time (s)               164.260439557489
Total Train Time (s)         86991.14857404027
Epoch                        554
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:41:27.782692 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #554 | Epoch Duration: 164.28103685379028
2020-01-12 23:41:27.782888 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #554 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1395824
Z variance train             0.010512299
KL Divergence                26.551987
KL Loss                      2.6551988
QF Loss                      1233.3453
VF Loss                      479.19293
Policy Loss                  -2155.4343
Q Predictions Mean           2158.273
Q Predictions Std            267.5098
Q Predictions Max            2353.0894
Q Predictions Min            -158.4542
V Predictions Mean           2158.063
V Predictions Std            267.4186
V Predictions Max            2348.8337
V Predictions Min            -175.18636
Log Pis Mean                 3.27567
Log Pis Std                  3.9021277
Log Pis Max                  16.419006
Log Pis Min                  -4.728505
Policy mu Mean               0.012620321
Policy mu Std                0.6465012
Policy mu Max                2.7662783
Policy mu Min                -3.1317527
Policy log std Mean          -1.4434602
Policy log std Std           0.36501384
Policy log std Max           -0.110153794
Policy log std Min           -3.0162942
Z mean eval                  1.1578948
Z variance eval              0.008676534
total_rewards                [5429.66996529 5658.43623866 5493.98186105 5886.24730632 5465.7577362
 4583.3860761  5664.80395752 5813.17144683 5682.07504135 4454.49707718]
total_rewards_mean           5413.202670650444
total_rewards_std            468.6951878633746
total_rewards_max            5886.247306316981
total_rewards_min            4454.497077181538
Number of train steps total  2224000
Number of env steps total    2782000
Number of rollouts total     0
Train Time (s)               119.20887502422556
(Previous) Eval Time (s)     27.42465725587681
Sample Time (s)              18.90457832859829
Epoch Time (s)               165.53811060870066
Total Train Time (s)         87154.96516444208
Epoch                        555
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:44:11.603911 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #555 | Epoch Duration: 163.82086753845215
2020-01-12 23:44:11.604084 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #555 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1575433
Z variance train             0.008688549
KL Divergence                26.868523
KL Loss                      2.6868522
QF Loss                      868.6062
VF Loss                      183.69948
Policy Loss                  -2114.775
Q Predictions Mean           2116.8843
Q Predictions Std            383.26706
Q Predictions Max            2351.4773
Q Predictions Min            -695.70667
V Predictions Mean           2111.483
V Predictions Std            378.3105
V Predictions Max            2340.5261
V Predictions Min            -734.86884
Log Pis Mean                 2.547529
Log Pis Std                  3.446473
Log Pis Max                  18.328087
Log Pis Min                  -6.4702344
Policy mu Mean               0.03220546
Policy mu Std                0.6655385
Policy mu Max                2.815196
Policy mu Min                -2.6585479
Policy log std Mean          -1.3736372
Policy log std Std           0.3367533
Policy log std Max           0.124261856
Policy log std Min           -3.240983
Z mean eval                  1.1444728
Z variance eval              0.006984306
total_rewards                [5563.52056909 5451.58287247 5552.90812794 5595.41812159 5668.20382629
 5506.80374291 5454.4417618  5570.56144722 5851.7930558  5437.98492088]
total_rewards_mean           5565.321844597794
total_rewards_std            117.73319336384986
total_rewards_max            5851.793055803715
total_rewards_min            5437.98492087926
Number of train steps total  2228000
Number of env steps total    2787000
Number of rollouts total     0
Train Time (s)               124.96938112797216
(Previous) Eval Time (s)     25.707076714839786
Sample Time (s)              18.29666876839474
Epoch Time (s)               168.97312661120668
Total Train Time (s)         87325.70278616669
Epoch                        556
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:47:02.344416 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #556 | Epoch Duration: 170.74018096923828
2020-01-12 23:47:02.344638 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #556 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1448165
Z variance train             0.0069767213
KL Divergence                27.64559
KL Loss                      2.764559
QF Loss                      854.31726
VF Loss                      137.70508
Policy Loss                  -2121.144
Q Predictions Mean           2124.8687
Q Predictions Std            301.6106
Q Predictions Max            2344.2798
Q Predictions Min            -365.64066
V Predictions Mean           2124.688
V Predictions Std            302.6075
V Predictions Max            2342.874
V Predictions Min            -361.48123
Log Pis Mean                 2.465633
Log Pis Std                  3.3331304
Log Pis Max                  14.236399
Log Pis Min                  -6.415149
Policy mu Mean               -0.0052641826
Policy mu Std                0.625676
Policy mu Max                2.5983636
Policy mu Min                -3.011917
Policy log std Mean          -1.3769978
Policy log std Std           0.33871788
Policy log std Max           -0.2432121
Policy log std Min           -3.3166118
Z mean eval                  1.2171627
Z variance eval              0.008232602
total_rewards                [5401.27669633 1622.3606896  5581.35504397 5609.74965359 5721.4513113
 5569.42310936 5493.16369116 5700.60737644 5549.47636562 5646.25339609]
total_rewards_mean           5189.511733346916
total_rewards_std            1192.4116393761124
total_rewards_max            5721.451311301736
total_rewards_min            1622.3606896022152
Number of train steps total  2232000
Number of env steps total    2792000
Number of rollouts total     0
Train Time (s)               120.18067379808053
(Previous) Eval Time (s)     27.473831524606794
Sample Time (s)              17.867511163000017
Epoch Time (s)               165.52201648568735
Total Train Time (s)         87488.7303583594
Epoch                        557
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:49:45.376257 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #557 | Epoch Duration: 163.03150033950806
2020-01-12 23:49:45.376424 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #557 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2174982
Z variance train             0.008232518
KL Divergence                26.121704
KL Loss                      2.6121705
QF Loss                      1443.3079
VF Loss                      2511.1406
Policy Loss                  -2117.5762
Q Predictions Mean           2118.5776
Q Predictions Std            431.30777
Q Predictions Max            2363.6257
Q Predictions Min            -508.79346
V Predictions Mean           2118.9375
V Predictions Std            427.84195
V Predictions Max            2361.3145
V Predictions Min            -493.73578
Log Pis Mean                 2.80861
Log Pis Std                  3.4624643
Log Pis Max                  14.470014
Log Pis Min                  -5.552455
Policy mu Mean               0.01840567
Policy mu Std                0.65927666
Policy mu Max                3.082376
Policy mu Min                -2.9682212
Policy log std Mean          -1.3537514
Policy log std Std           0.3352828
Policy log std Max           -0.15844858
Policy log std Min           -3.3061218
Z mean eval                  1.1686808
Z variance eval              0.0071373894
total_rewards                [5236.14230806 5447.66823434 5637.13943608 5478.23220462 5484.62297435
 5691.72768739 5591.7651341  5637.09269364 5522.24645483 5435.3551623 ]
total_rewards_mean           5516.199228971813
total_rewards_std            125.6588525538517
total_rewards_max            5691.7276873882365
total_rewards_min            5236.1423080617205
Number of train steps total  2236000
Number of env steps total    2797000
Number of rollouts total     0
Train Time (s)               118.83393576694652
(Previous) Eval Time (s)     24.98303368408233
Sample Time (s)              18.913853307720274
Epoch Time (s)               162.73082275874913
Total Train Time (s)         87653.7950726049
Epoch                        558
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:52:30.450715 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #558 | Epoch Duration: 165.0741467475891
2020-01-12 23:52:30.450936 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #558 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1697487
Z variance train             0.0071485927
KL Divergence                25.161201
KL Loss                      2.5161202
QF Loss                      974.57745
VF Loss                      144.84436
Policy Loss                  -2154.0286
Q Predictions Mean           2156.6384
Q Predictions Std            337.8956
Q Predictions Max            2360.3542
Q Predictions Min            -615.4205
V Predictions Mean           2151.6245
V Predictions Std            340.31735
V Predictions Max            2351.0889
V Predictions Min            -643.35236
Log Pis Mean                 2.3743901
Log Pis Std                  3.206286
Log Pis Max                  11.081751
Log Pis Min                  -8.661062
Policy mu Mean               0.030254059
Policy mu Std                0.59004235
Policy mu Max                2.9479797
Policy mu Min                -3.1103156
Policy log std Mean          -1.3837893
Policy log std Std           0.30041406
Policy log std Max           -0.17639923
Policy log std Min           -2.591844
Z mean eval                  1.1392634
Z variance eval              0.008219463
total_rewards                [5539.83959296 5791.89938886 5550.31682422 5732.02917344 3846.49079588
 5559.55996331 5605.16077941 3009.44383626 5674.07013868 2311.9468161 ]
total_rewards_mean           4862.075730912341
total_rewards_std            1233.6628560427353
total_rewards_max            5791.899388863692
total_rewards_min            2311.9468160957204
Number of train steps total  2240000
Number of env steps total    2802000
Number of rollouts total     0
Train Time (s)               116.50221835775301
(Previous) Eval Time (s)     27.326011976692826
Sample Time (s)              18.2750950101763
Epoch Time (s)               162.10332534462214
Total Train Time (s)         87813.2298745308
Epoch                        559
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:55:09.891361 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #559 | Epoch Duration: 159.44025039672852
2020-01-12 23:55:09.891585 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #559 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1399086
Z variance train             0.008261026
KL Divergence                25.90539
KL Loss                      2.590539
QF Loss                      885.8445
VF Loss                      150.44768
Policy Loss                  -2164.6204
Q Predictions Mean           2167.7842
Q Predictions Std            318.5845
Q Predictions Max            2371.2385
Q Predictions Min            -463.33246
V Predictions Mean           2167.9775
V Predictions Std            322.24734
V Predictions Max            2388.7356
V Predictions Min            -448.97357
Log Pis Mean                 2.8084855
Log Pis Std                  3.8242111
Log Pis Max                  24.737213
Log Pis Min                  -5.449435
Policy mu Mean               0.009789075
Policy mu Std                0.69438636
Policy mu Max                2.7769952
Policy mu Min                -3.6228063
Policy log std Mean          -1.3634686
Policy log std Std           0.35058632
Policy log std Max           0.055379152
Policy log std Min           -2.878223
Z mean eval                  1.1293337
Z variance eval              0.00915349
total_rewards                [5560.76452318 5919.93022968 5920.77914182 5759.55091808 5152.11711903
 5717.31554425 5655.37872509 5575.9290759  5641.85542329 5710.75469265]
total_rewards_mean           5661.437539297032
total_rewards_std            206.52639502183973
total_rewards_max            5920.779141815794
total_rewards_min            5152.1171190332825
Number of train steps total  2244000
Number of env steps total    2807000
Number of rollouts total     0
Train Time (s)               117.59743136400357
(Previous) Eval Time (s)     24.66260808520019
Sample Time (s)              18.294775663409382
Epoch Time (s)               160.55481511261314
Total Train Time (s)         87976.70164546557
Epoch                        560
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:57:53.366444 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #560 | Epoch Duration: 163.47470617294312
2020-01-12 23:57:53.366594 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #560 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1288642
Z variance train             0.009195996
KL Divergence                25.433807
KL Loss                      2.5433807
QF Loss                      1609.0928
VF Loss                      143.9518
Policy Loss                  -2146.774
Q Predictions Mean           2149.6226
Q Predictions Std            331.51627
Q Predictions Max            2384.249
Q Predictions Min            -452.99936
V Predictions Mean           2147.0493
V Predictions Std            329.42636
V Predictions Max            2375.2588
V Predictions Min            -415.06024
Log Pis Mean                 2.9914496
Log Pis Std                  3.3111298
Log Pis Max                  15.317324
Log Pis Min                  -4.0387635
Policy mu Mean               -0.009307893
Policy mu Std                0.63645816
Policy mu Max                2.6902156
Policy mu Min                -2.7572832
Policy log std Mean          -1.4392996
Policy log std Std           0.34940735
Policy log std Max           0.45442307
Policy log std Min           -3.379625
Z mean eval                  1.1329863
Z variance eval              0.011093533
total_rewards                [1297.7762401  5708.41127847 5584.87132134 5540.65409777 5264.85935334
  688.66571367 5596.71646611 5828.25889527 4104.50225136 5387.46063432]
total_rewards_mean           4500.217625174791
total_rewards_std            1816.5005782242815
total_rewards_max            5828.258895269801
total_rewards_min            688.6657136739186
Number of train steps total  2248000
Number of env steps total    2812000
Number of rollouts total     0
Train Time (s)               122.8389024110511
(Previous) Eval Time (s)     27.582210649736226
Sample Time (s)              18.020545532926917
Epoch Time (s)               168.44165859371424
Total Train Time (s)         88139.87725465186
Epoch                        561
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:00:36.549146 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #561 | Epoch Duration: 163.18240356445312
2020-01-13 00:00:36.549384 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #561 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1338298
Z variance train             0.011118074
KL Divergence                25.337276
KL Loss                      2.5337276
QF Loss                      1444.3674
VF Loss                      213.30643
Policy Loss                  -2076.0117
Q Predictions Mean           2081.5112
Q Predictions Std            453.30634
Q Predictions Max            2359.2527
Q Predictions Min            -494.4473
V Predictions Mean           2080.6533
V Predictions Std            448.37924
V Predictions Max            2359.857
V Predictions Min            -461.35333
Log Pis Mean                 2.9222655
Log Pis Std                  3.6918054
Log Pis Max                  17.831268
Log Pis Min                  -6.377974
Policy mu Mean               -0.0065269857
Policy mu Std                0.6858749
Policy mu Max                2.958119
Policy mu Min                -2.9003577
Policy log std Mean          -1.3758881
Policy log std Std           0.3701584
Policy log std Max           -0.23842561
Policy log std Min           -3.7868392
Z mean eval                  1.1680475
Z variance eval              0.005874096
total_rewards                [5609.7686293  5312.94673485 5760.4646163  2259.39720303 5653.13056624
 5768.30943864 5794.58649685 5652.33071251 5607.64950702 5695.7945396 ]
total_rewards_mean           5311.4378444335525
total_rewards_std            1025.4841884838236
total_rewards_max            5794.58649684586
total_rewards_min            2259.3972030309874
Number of train steps total  2252000
Number of env steps total    2817000
Number of rollouts total     0
Train Time (s)               119.74600800685585
(Previous) Eval Time (s)     22.32264462020248
Sample Time (s)              17.99227804504335
Epoch Time (s)               160.06093067210168
Total Train Time (s)         88303.46389623359
Epoch                        562
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:03:20.143769 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #562 | Epoch Duration: 163.59418272972107
2020-01-13 00:03:20.144070 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #562 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1680372
Z variance train             0.0058723814
KL Divergence                26.662304
KL Loss                      2.6662304
QF Loss                      558.8063
VF Loss                      106.397285
Policy Loss                  -2158.5078
Q Predictions Mean           2161.974
Q Predictions Std            299.10153
Q Predictions Max            2380.481
Q Predictions Min            -429.12354
V Predictions Mean           2159.809
V Predictions Std            296.92514
V Predictions Max            2381.4824
V Predictions Min            -402.638
Log Pis Mean                 2.7090616
Log Pis Std                  3.297933
Log Pis Max                  12.348413
Log Pis Min                  -8.572819
Policy mu Mean               0.0014095637
Policy mu Std                0.640155
Policy mu Max                2.7450607
Policy mu Min                -2.5964627
Policy log std Mean          -1.3465886
Policy log std Std           0.31329972
Policy log std Max           -0.15440607
Policy log std Min           -2.8305883
Z mean eval                  1.13363
Z variance eval              0.009737144
total_rewards                [5650.21586655 5536.14644072 5596.14378816 5308.87107504 5653.26097318
 5784.01223256 5824.27104694 5678.93223732 5797.16792184 5655.00403529]
total_rewards_mean           5648.402561760061
total_rewards_std            142.5017258250755
total_rewards_max            5824.2710469371
total_rewards_min            5308.871075041492
Number of train steps total  2256000
Number of env steps total    2822000
Number of rollouts total     0
Train Time (s)               119.57021195301786
(Previous) Eval Time (s)     25.85559168504551
Sample Time (s)              18.026627480983734
Epoch Time (s)               163.4524311190471
Total Train Time (s)         88467.54068724578
Epoch                        563
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:06:04.225661 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #563 | Epoch Duration: 164.08139872550964
2020-01-13 00:06:04.225849 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #563 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1329279
Z variance train             0.009708971
KL Divergence                26.168432
KL Loss                      2.6168432
QF Loss                      1404.947
VF Loss                      310.3875
Policy Loss                  -2175.553
Q Predictions Mean           2180.4177
Q Predictions Std            212.82295
Q Predictions Max            2382.0405
Q Predictions Min            -351.51505
V Predictions Mean           2171.6145
V Predictions Std            214.72816
V Predictions Max            2366.2014
V Predictions Min            -387.34753
Log Pis Mean                 2.9340045
Log Pis Std                  3.6296756
Log Pis Max                  14.545355
Log Pis Min                  -6.2246866
Policy mu Mean               -0.0007069316
Policy mu Std                0.6532546
Policy mu Max                3.6887324
Policy mu Min                -3.3514743
Policy log std Mean          -1.4017088
Policy log std Std           0.34582758
Policy log std Max           0.34030116
Policy log std Min           -3.1327038
Z mean eval                  1.1829679
Z variance eval              0.006361232
total_rewards                [5492.36197699 5623.99976951 1364.34336782 5524.77534375 5522.89408522
 5525.37305495 5771.60069017 5670.21527412 5629.30326712 5398.68470781]
total_rewards_mean           5152.355153745028
total_rewards_std            1266.5712264495496
total_rewards_max            5771.600690167388
total_rewards_min            1364.3433678233125
Number of train steps total  2260000
Number of env steps total    2827000
Number of rollouts total     0
Train Time (s)               125.07912203203887
(Previous) Eval Time (s)     26.484305274672806
Sample Time (s)              18.074682926759124
Epoch Time (s)               169.6381102334708
Total Train Time (s)         88635.14879146358
Epoch                        564
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:08:51.838196 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #564 | Epoch Duration: 167.61220240592957
2020-01-13 00:08:51.838353 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #564 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1841033
Z variance train             0.006349449
KL Divergence                25.93637
KL Loss                      2.5936372
QF Loss                      979.1979
VF Loss                      279.83313
Policy Loss                  -2161.5342
Q Predictions Mean           2164.621
Q Predictions Std            337.00732
Q Predictions Max            2407.0625
Q Predictions Min            -489.00763
V Predictions Mean           2173.4258
V Predictions Std            330.93918
V Predictions Max            2435.093
V Predictions Min            -465.6172
Log Pis Mean                 3.0048206
Log Pis Std                  3.4448378
Log Pis Max                  15.413322
Log Pis Min                  -5.0064564
Policy mu Mean               0.026428286
Policy mu Std                0.6786967
Policy mu Max                2.6315517
Policy mu Min                -2.9235027
Policy log std Mean          -1.3584633
Policy log std Std           0.34305298
Policy log std Max           -0.19851637
Policy log std Min           -2.8888807
Z mean eval                  1.1522013
Z variance eval              0.0033664326
total_rewards                [5593.37035836  101.13269331 5958.41599233 5797.18952819 5656.00239852
 5655.13556699 5833.2234412  5624.64371182 5496.29107819 5660.24594998]
total_rewards_mean           5137.565071889253
total_rewards_std            1683.509207438707
total_rewards_max            5958.415992326468
total_rewards_min            101.13269331304062
Number of train steps total  2264000
Number of env steps total    2832000
Number of rollouts total     0
Train Time (s)               112.91254331776872
(Previous) Eval Time (s)     24.458109081257135
Sample Time (s)              17.91537188971415
Epoch Time (s)               155.28602428874
Total Train Time (s)         88790.71055211267
Epoch                        565
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:11:27.408689 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #565 | Epoch Duration: 155.57017970085144
2020-01-13 00:11:27.408988 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #565 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1521046
Z variance train             0.0033608791
KL Divergence                26.939934
KL Loss                      2.6939933
QF Loss                      1135.9772
VF Loss                      167.72337
Policy Loss                  -2136.707
Q Predictions Mean           2143.9434
Q Predictions Std            381.3384
Q Predictions Max            2402.6794
Q Predictions Min            -402.79
V Predictions Mean           2140.5532
V Predictions Std            382.63705
V Predictions Max            2389.998
V Predictions Min            -439.9368
Log Pis Mean                 2.7250037
Log Pis Std                  3.447218
Log Pis Max                  14.435994
Log Pis Min                  -10.239421
Policy mu Mean               0.021922205
Policy mu Std                0.650038
Policy mu Max                2.9887247
Policy mu Min                -2.7927353
Policy log std Mean          -1.3531343
Policy log std Std           0.34949428
Policy log std Max           -0.17110384
Policy log std Min           -2.9390259
Z mean eval                  1.1493083
Z variance eval              0.0043555317
total_rewards                [1232.34361361 5311.1943395  5597.26751749 5572.63938668 5492.25410072
 5672.46492864 5749.55548894 5638.79040654 5729.22528016 5537.10912429]
total_rewards_mean           5153.284418656915
total_rewards_std            1312.494773418288
total_rewards_max            5749.555488936861
total_rewards_min            1232.3436136065466
Number of train steps total  2268000
Number of env steps total    2837000
Number of rollouts total     0
Train Time (s)               116.44425606075674
(Previous) Eval Time (s)     24.741968880873173
Sample Time (s)              18.30892064748332
Epoch Time (s)               159.49514558911324
Total Train Time (s)         88951.08807415515
Epoch                        566
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:14:07.795662 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #566 | Epoch Duration: 160.38644576072693
2020-01-13 00:14:07.795975 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #566 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1490552
Z variance train             0.0043559973
KL Divergence                26.816416
KL Loss                      2.6816416
QF Loss                      1118.709
VF Loss                      550.7583
Policy Loss                  -2147.8752
Q Predictions Mean           2149.603
Q Predictions Std            324.0196
Q Predictions Max            2362.9111
Q Predictions Min            -390.86188
V Predictions Mean           2150.229
V Predictions Std            315.75107
V Predictions Max            2374.7551
V Predictions Min            -412.4699
Log Pis Mean                 2.77589
Log Pis Std                  3.5405502
Log Pis Max                  16.422016
Log Pis Min                  -3.9294207
Policy mu Mean               0.0013959305
Policy mu Std                0.6606379
Policy mu Max                2.909513
Policy mu Min                -3.0266156
Policy log std Mean          -1.3880632
Policy log std Std           0.36251727
Policy log std Max           -0.057531238
Policy log std Min           -4.770065
Z mean eval                  1.1409982
Z variance eval              0.0046223863
total_rewards                [3391.25176391 2767.3970248  3712.98459554 5723.74474174   62.07751665
 5351.25885351 5755.26008136 5421.45492048 5849.83114438 5671.22706005]
total_rewards_mean           4370.648770242915
total_rewards_std            1794.9717085481254
total_rewards_max            5849.831144378136
total_rewards_min            62.077516647071036
Number of train steps total  2272000
Number of env steps total    2842000
Number of rollouts total     0
Train Time (s)               115.48750218003988
(Previous) Eval Time (s)     25.6329328129068
Sample Time (s)              17.68661512993276
Epoch Time (s)               158.80705012287945
Total Train Time (s)         89106.58592761634
Epoch                        567
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:16:43.296314 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #567 | Epoch Duration: 155.50012588500977
2020-01-13 00:16:43.296512 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #567 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1431499
Z variance train             0.004594645
KL Divergence                26.434265
KL Loss                      2.6434267
QF Loss                      2798.516
VF Loss                      957.9798
Policy Loss                  -2137.8955
Q Predictions Mean           2138.2854
Q Predictions Std            383.39624
Q Predictions Max            2397.7017
Q Predictions Min            -537.28955
V Predictions Mean           2145.3135
V Predictions Std            380.9322
V Predictions Max            2404.808
V Predictions Min            -494.1076
Log Pis Mean                 2.4912481
Log Pis Std                  3.634512
Log Pis Max                  14.604292
Log Pis Min                  -6.3138947
Policy mu Mean               -0.022874575
Policy mu Std                0.6256401
Policy mu Max                2.6592631
Policy mu Min                -2.9690218
Policy log std Mean          -1.3799303
Policy log std Std           0.3496182
Policy log std Max           -0.018570065
Policy log std Min           -3.22159
Z mean eval                  1.1864557
Z variance eval              0.004077196
total_rewards                [5692.56363309 5586.8806004  5809.1405567  5650.26898771 5779.94940007
 2874.6587688  5696.17269657 5451.57635665 2265.88526143 5864.23199927]
total_rewards_mean           5067.132826069877
total_rewards_std            1260.6671906504391
total_rewards_max            5864.231999269912
total_rewards_min            2265.8852614286307
Number of train steps total  2276000
Number of env steps total    2847000
Number of rollouts total     0
Train Time (s)               124.94864187575877
(Previous) Eval Time (s)     22.325731467921287
Sample Time (s)              17.679415229242295
Epoch Time (s)               164.95378857292235
Total Train Time (s)         89273.8998437943
Epoch                        568
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:19:30.618082 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #568 | Epoch Duration: 167.3214008808136
2020-01-13 00:19:30.618360 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #568 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1821072
Z variance train             0.0040559224
KL Divergence                27.051687
KL Loss                      2.7051687
QF Loss                      1142.4233
VF Loss                      186.916
Policy Loss                  -2143.71
Q Predictions Mean           2157.5403
Q Predictions Std            391.95068
Q Predictions Max            2406.3213
Q Predictions Min            -322.08252
V Predictions Mean           2140.1494
V Predictions Std            400.78214
V Predictions Max            2393.8691
V Predictions Min            -420.8911
Log Pis Mean                 2.7422
Log Pis Std                  3.2494538
Log Pis Max                  13.28191
Log Pis Min                  -4.9406605
Policy mu Mean               0.0036322551
Policy mu Std                0.64420766
Policy mu Max                3.2649872
Policy mu Min                -2.8373291
Policy log std Mean          -1.3703921
Policy log std Std           0.32363155
Policy log std Max           -0.05732405
Policy log std Min           -2.8489442
Z mean eval                  1.13408
Z variance eval              0.004209803
total_rewards                [5671.07922489  465.58658342 3877.44544006 5762.53831615 5621.28304372
 5615.80044595 5683.06712817 5653.8358383    53.26008004 5365.62638615]
total_rewards_mean           4376.952248684967
total_rewards_std            2126.8324824162864
total_rewards_max            5762.538316147631
total_rewards_min            53.26008003871056
Number of train steps total  2280000
Number of env steps total    2852000
Number of rollouts total     0
Train Time (s)               124.40039033815265
(Previous) Eval Time (s)     24.693021833896637
Sample Time (s)              18.18798601254821
Epoch Time (s)               167.2813981845975
Total Train Time (s)         89436.9836537335
Epoch                        569
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:22:13.708154 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #569 | Epoch Duration: 163.08959341049194
2020-01-13 00:22:13.708376 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #569 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.133989
Z variance train             0.004210248
KL Divergence                26.635649
KL Loss                      2.663565
QF Loss                      3037.896
VF Loss                      219.14905
Policy Loss                  -2151.831
Q Predictions Mean           2154.555
Q Predictions Std            422.33234
Q Predictions Max            2376.395
Q Predictions Min            -522.03485
V Predictions Mean           2153.4966
V Predictions Std            425.5358
V Predictions Max            2369.8242
V Predictions Min            -523.9235
Log Pis Mean                 3.1596234
Log Pis Std                  3.6385057
Log Pis Max                  19.202047
Log Pis Min                  -7.192204
Policy mu Mean               0.010075342
Policy mu Std                0.69626737
Policy mu Max                3.4431336
Policy mu Min                -2.867125
Policy log std Mean          -1.3989366
Policy log std Std           0.35025752
Policy log std Max           -0.14334345
Policy log std Min           -3.3147998
Z mean eval                  1.154258
Z variance eval              0.008203297
total_rewards                [5442.6267388  5943.94170077 5821.24771842 5833.16595611 5877.95452006
 5857.33171051 5697.31494182 5742.99484968 5820.63614432 5769.09502165]
total_rewards_mean           5780.630930213048
total_rewards_std            130.6802614341521
total_rewards_max            5943.941700765753
total_rewards_min            5442.626738795183
Number of train steps total  2284000
Number of env steps total    2857000
Number of rollouts total     0
Train Time (s)               118.95788715407252
(Previous) Eval Time (s)     20.500914321746677
Sample Time (s)              18.356234058737755
Epoch Time (s)               157.81503553455696
Total Train Time (s)         89600.68020318868
Epoch                        570
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:24:57.411540 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #570 | Epoch Duration: 163.7029950618744
2020-01-13 00:24:57.411781 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #570 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1535033
Z variance train             0.008218351
KL Divergence                25.81955
KL Loss                      2.581955
QF Loss                      1337.987
VF Loss                      2256.98
Policy Loss                  -2160.8987
Q Predictions Mean           2156.6494
Q Predictions Std            364.81146
Q Predictions Max            2396.705
Q Predictions Min            -439.95233
V Predictions Mean           2155.7349
V Predictions Std            353.19885
V Predictions Max            2397.8418
V Predictions Min            -444.2433
Log Pis Mean                 3.6758366
Log Pis Std                  4.049792
Log Pis Max                  25.739456
Log Pis Min                  -4.3814487
Policy mu Mean               0.012421897
Policy mu Std                0.7029596
Policy mu Max                2.9605536
Policy mu Min                -3.4017217
Policy log std Mean          -1.4418235
Policy log std Std           0.4024023
Policy log std Max           -0.24596965
Policy log std Min           -3.5685802
Z mean eval                  1.1333553
Z variance eval              0.007911772
total_rewards                [5786.16596672 5791.39104532 5893.72365943 5779.35878312 5677.91392793
 5762.26540921 5758.04750262 5817.90692891 5517.80293897 5667.63500976]
total_rewards_mean           5745.221117199189
total_rewards_std            97.48521380685929
total_rewards_max            5893.723659431811
total_rewards_min            5517.802938971449
Number of train steps total  2288000
Number of env steps total    2862000
Number of rollouts total     0
Train Time (s)               119.81391046615317
(Previous) Eval Time (s)     26.38854409335181
Sample Time (s)              18.422479340340942
Epoch Time (s)               164.62493389984593
Total Train Time (s)         89766.68294440908
Epoch                        571
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:27:43.423088 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #571 | Epoch Duration: 166.0110912322998
2020-01-13 00:27:43.423398 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #571 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.135058
Z variance train             0.007920964
KL Divergence                25.847702
KL Loss                      2.5847702
QF Loss                      1633.8307
VF Loss                      236.21039
Policy Loss                  -2166.5227
Q Predictions Mean           2169.232
Q Predictions Std            328.4022
Q Predictions Max            2378.9573
Q Predictions Min            -459.20343
V Predictions Mean           2159.6445
V Predictions Std            324.42902
V Predictions Max            2371.1235
V Predictions Min            -400.59348
Log Pis Mean                 3.2373114
Log Pis Std                  3.8591158
Log Pis Max                  18.086418
Log Pis Min                  -8.432061
Policy mu Mean               -0.0031588408
Policy mu Std                0.6749283
Policy mu Max                3.100312
Policy mu Min                -2.9438128
Policy log std Mean          -1.4127994
Policy log std Std           0.34248433
Policy log std Max           0.036304355
Policy log std Min           -2.857074
Z mean eval                  1.1754701
Z variance eval              0.009251578
total_rewards                [5388.49098552 5610.55821834 5919.77273702 5593.93317863 4321.34447682
 5691.46995098 5793.99390144  958.59754693 5867.15320319 5610.75731015]
total_rewards_mean           5075.607150902459
total_rewards_std            1438.4826715922293
total_rewards_max            5919.772737017669
total_rewards_min            958.5975469325467
Number of train steps total  2292000
Number of env steps total    2867000
Number of rollouts total     0
Train Time (s)               116.00407515605912
(Previous) Eval Time (s)     27.774361120071262
Sample Time (s)              18.606424746103585
Epoch Time (s)               162.38486102223396
Total Train Time (s)         89928.17196625378
Epoch                        572
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:30:24.920248 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #572 | Epoch Duration: 161.49661231040955
2020-01-13 00:30:24.920545 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #572 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1756387
Z variance train             0.009236743
KL Divergence                26.007435
KL Loss                      2.6007435
QF Loss                      1323.8848
VF Loss                      190.85982
Policy Loss                  -2209.3064
Q Predictions Mean           2213.696
Q Predictions Std            150.26628
Q Predictions Max            2391.5576
Q Predictions Min            804.4084
V Predictions Mean           2209.8613
V Predictions Std            149.19281
V Predictions Max            2382.5752
V Predictions Min            878.06274
Log Pis Mean                 2.9519658
Log Pis Std                  3.3107615
Log Pis Max                  14.511716
Log Pis Min                  -6.284539
Policy mu Mean               -0.006688755
Policy mu Std                0.62174946
Policy mu Max                3.0341542
Policy mu Min                -2.7791827
Policy log std Mean          -1.4138092
Policy log std Std           0.30504534
Policy log std Max           -0.054132223
Policy log std Min           -2.9222617
Z mean eval                  1.1792701
Z variance eval              0.0068716244
total_rewards                [5443.02048509 5916.00276877 5809.63009461 5790.16726269 5690.91998771
 5585.63017547 5702.35413494 5826.93836167 2260.03456936 5633.6736046 ]
total_rewards_mean           5365.837144491591
total_rewards_std            1043.2276629665923
total_rewards_max            5916.002768766883
total_rewards_min            2260.0345693641234
Number of train steps total  2296000
Number of env steps total    2872000
Number of rollouts total     0
Train Time (s)               117.1614080700092
(Previous) Eval Time (s)     26.885798124130815
Sample Time (s)              18.091250607278198
Epoch Time (s)               162.13845680141822
Total Train Time (s)         90088.99609056255
Epoch                        573
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:33:05.751879 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #573 | Epoch Duration: 160.83111023902893
2020-01-13 00:33:05.752149 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #573 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1790934
Z variance train             0.0068699094
KL Divergence                25.497513
KL Loss                      2.5497513
QF Loss                      697.3264
VF Loss                      114.76444
Policy Loss                  -2182.644
Q Predictions Mean           2187.3188
Q Predictions Std            294.92432
Q Predictions Max            2395.3643
Q Predictions Min            -180.39153
V Predictions Mean           2181.0654
V Predictions Std            291.67398
V Predictions Max            2387.899
V Predictions Min            -182.62659
Log Pis Mean                 2.4644032
Log Pis Std                  3.352994
Log Pis Max                  22.808004
Log Pis Min                  -4.892591
Policy mu Mean               0.018217757
Policy mu Std                0.6411474
Policy mu Max                3.2007382
Policy mu Min                -2.7142162
Policy log std Mean          -1.344703
Policy log std Std           0.31807202
Policy log std Max           -0.24921453
Policy log std Min           -2.8822787
Z mean eval                  1.1125826
Z variance eval              0.016431183
total_rewards                [5405.71118713 5602.27304194 1575.57277936 5659.53966291 5652.13104796
  299.31417488 5688.10603566 5469.23027245 5845.28312015 5626.61894686]
total_rewards_mean           4682.3780269302715
total_rewards_std            1897.4386819067815
total_rewards_max            5845.2831201478275
total_rewards_min            299.31417487866406
Number of train steps total  2300000
Number of env steps total    2877000
Number of rollouts total     0
Train Time (s)               122.53442643722519
(Previous) Eval Time (s)     25.57814081432298
Sample Time (s)              19.13975816918537
Epoch Time (s)               167.25232542073354
Total Train Time (s)         90252.78924576053
Epoch                        574
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:35:49.552973 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #574 | Epoch Duration: 163.800612449646
2020-01-13 00:35:49.553234 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #574 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.11196
Z variance train             0.016448995
KL Divergence                23.822996
KL Loss                      2.3822997
QF Loss                      7152.5947
VF Loss                      4428.5317
Policy Loss                  -2177.2578
Q Predictions Mean           2180.4226
Q Predictions Std            283.85342
Q Predictions Max            2399.459
Q Predictions Min            -71.862495
V Predictions Mean           2191.4932
V Predictions Std            262.68372
V Predictions Max            2412.204
V Predictions Min            -84.20056
Log Pis Mean                 2.5997565
Log Pis Std                  3.5055513
Log Pis Max                  18.12112
Log Pis Min                  -6.159254
Policy mu Mean               -0.004082868
Policy mu Std                0.6106682
Policy mu Max                2.5995648
Policy mu Min                -3.0353706
Policy log std Mean          -1.3950921
Policy log std Std           0.33059436
Policy log std Max           -0.4155507
Policy log std Min           -3.3277059
Z mean eval                  1.1198289
Z variance eval              0.018149855
total_rewards                [5800.73355311 5412.17129533 5737.53207275 5780.25184124 5739.69846377
 5631.09276063 5737.40483313 5849.39642863 5797.37450411 5618.95409157]
total_rewards_mean           5710.4609844289225
total_rewards_std            120.7642860805387
total_rewards_max            5849.396428630002
total_rewards_min            5412.1712953306505
Number of train steps total  2304000
Number of env steps total    2882000
Number of rollouts total     0
Train Time (s)               119.14272513985634
(Previous) Eval Time (s)     22.12611466180533
Sample Time (s)              18.434399760793895
Epoch Time (s)               159.70323956245556
Total Train Time (s)         90417.05821349518
Epoch                        575
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:38:33.826956 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #575 | Epoch Duration: 164.27352857589722
2020-01-13 00:38:33.827163 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #575 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1185653
Z variance train             0.018109012
KL Divergence                24.671368
KL Loss                      2.4671369
QF Loss                      715.331
VF Loss                      515.4581
Policy Loss                  -2184.9373
Q Predictions Mean           2189.127
Q Predictions Std            306.87714
Q Predictions Max            2408.1125
Q Predictions Min            -396.55225
V Predictions Mean           2196.0352
V Predictions Std            309.61398
V Predictions Max            2418.2078
V Predictions Min            -381.96524
Log Pis Mean                 2.7353888
Log Pis Std                  3.5948856
Log Pis Max                  16.809458
Log Pis Min                  -9.8635235
Policy mu Mean               0.022648783
Policy mu Std                0.62540454
Policy mu Max                3.0032704
Policy mu Min                -3.1400867
Policy log std Mean          -1.4023141
Policy log std Std           0.33692014
Policy log std Max           -0.06865227
Policy log std Min           -3.537257
Z mean eval                  1.1881039
Z variance eval              0.013143623
total_rewards                [5636.00461811 5661.72448701 5699.71381163 5019.81756874 5809.90988944
 5727.50392616 5779.98160173 5844.16137522 5773.32458869 5786.93162071]
total_rewards_mean           5673.907348743067
total_rewards_std            226.79289924164215
total_rewards_max            5844.161375218699
total_rewards_min            5019.817568735109
Number of train steps total  2308000
Number of env steps total    2887000
Number of rollouts total     0
Train Time (s)               124.82065191119909
(Previous) Eval Time (s)     26.69608555175364
Sample Time (s)              18.146512119099498
Epoch Time (s)               169.66324958205223
Total Train Time (s)         90586.50548775075
Epoch                        576
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:41:23.281515 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #576 | Epoch Duration: 169.4541735649109
2020-01-13 00:41:23.281772 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #576 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1891427
Z variance train             0.013159962
KL Divergence                25.398355
KL Loss                      2.5398357
QF Loss                      694.2373
VF Loss                      164.75897
Policy Loss                  -2193.093
Q Predictions Mean           2198.433
Q Predictions Std            322.74115
Q Predictions Max            2436.1863
Q Predictions Min            -197.74236
V Predictions Mean           2199.9204
V Predictions Std            320.12576
V Predictions Max            2430.2898
V Predictions Min            -180.07077
Log Pis Mean                 2.9021502
Log Pis Std                  3.1731513
Log Pis Max                  13.53268
Log Pis Min                  -4.9575233
Policy mu Mean               -0.008653805
Policy mu Std                0.63130057
Policy mu Max                2.4896383
Policy mu Min                -2.933952
Policy log std Mean          -1.402328
Policy log std Std           0.3375618
Policy log std Max           0.3340609
Policy log std Min           -2.9498281
Z mean eval                  1.1275412
Z variance eval              0.010771541
total_rewards                [5528.13712668 5831.87552472 5704.60115605 5925.49056093 5732.3866384
 5766.52551655 2547.45294016 5908.01373292 5668.67862389 5703.45125935]
total_rewards_mean           5431.66130796273
total_rewards_std            967.7824540986262
total_rewards_max            5925.490560926326
total_rewards_min            2547.452940156021
Number of train steps total  2312000
Number of env steps total    2892000
Number of rollouts total     0
Train Time (s)               125.40842105494812
(Previous) Eval Time (s)     26.48670522077009
Sample Time (s)              18.475126846693456
Epoch Time (s)               170.37025312241167
Total Train Time (s)         90756.43417414371
Epoch                        577
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:44:13.214156 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #577 | Epoch Duration: 169.93220400810242
2020-01-13 00:44:13.214382 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #577 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1267555
Z variance train             0.010761151
KL Divergence                25.516579
KL Loss                      2.551658
QF Loss                      976.48425
VF Loss                      138.39748
Policy Loss                  -2216.8047
Q Predictions Mean           2218.4014
Q Predictions Std            170.52281
Q Predictions Max            2416.8215
Q Predictions Min            234.25652
V Predictions Mean           2217.036
V Predictions Std            170.81874
V Predictions Max            2409.6057
V Predictions Min            212.87369
Log Pis Mean                 2.9244242
Log Pis Std                  3.4884694
Log Pis Max                  14.273041
Log Pis Min                  -5.8672404
Policy mu Mean               -0.010665595
Policy mu Std                0.62494427
Policy mu Max                2.8879726
Policy mu Min                -2.7529233
Policy log std Mean          -1.4221448
Policy log std Std           0.32743397
Policy log std Max           -0.39883173
Policy log std Min           -2.8497088
Z mean eval                  1.1678177
Z variance eval              0.010432425
total_rewards                [5652.93875697 5971.27269622 2521.32680473    6.95817407 5760.91361732
 5722.18969822 5846.54625759 5662.73675196 1016.1982121  5758.90056736]
total_rewards_mean           4391.998153654546
total_rewards_std            2178.3098843337475
total_rewards_max            5971.272696220169
total_rewards_min            6.958174073664026
Number of train steps total  2316000
Number of env steps total    2897000
Number of rollouts total     0
Train Time (s)               117.61322095384821
(Previous) Eval Time (s)     26.04834393179044
Sample Time (s)              18.35009253723547
Epoch Time (s)               162.01165742287412
Total Train Time (s)         90912.8960471428
Epoch                        578
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:46:49.681361 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #578 | Epoch Duration: 156.46685361862183
2020-01-13 00:46:49.681557 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #578 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1672488
Z variance train             0.010461138
KL Divergence                26.873116
KL Loss                      2.6873116
QF Loss                      1411.4038
VF Loss                      403.61804
Policy Loss                  -2221.0413
Q Predictions Mean           2225.0894
Q Predictions Std            316.6003
Q Predictions Max            2420.452
Q Predictions Min            -396.8103
V Predictions Mean           2225.7195
V Predictions Std            315.79547
V Predictions Max            2427.7717
V Predictions Min            -393.94675
Log Pis Mean                 2.884674
Log Pis Std                  3.736222
Log Pis Max                  13.696738
Log Pis Min                  -8.946009
Policy mu Mean               -0.00040313043
Policy mu Std                0.68200177
Policy mu Max                3.687923
Policy mu Min                -3.125427
Policy log std Mean          -1.3786616
Policy log std Std           0.34384084
Policy log std Max           0.42479026
Policy log std Min           -3.0214944
Z mean eval                  1.1834663
Z variance eval              0.010655569
total_rewards                [5641.42840126 5625.27272168 5836.99650605 5750.82857867 5759.33433524
 5659.22162795 5555.12991041 5793.05154803 5701.73017552 5745.09292454]
total_rewards_mean           5706.808672935318
total_rewards_std            81.71202045962788
total_rewards_max            5836.996506053248
total_rewards_min            5555.129910412504
Number of train steps total  2320000
Number of env steps total    2902000
Number of rollouts total     0
Train Time (s)               120.43713922798634
(Previous) Eval Time (s)     20.50322833796963
Sample Time (s)              18.15094836242497
Epoch Time (s)               159.09131592838094
Total Train Time (s)         91078.59317067917
Epoch                        579
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:49:35.386886 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #579 | Epoch Duration: 165.70515131950378
2020-01-13 00:49:35.387192 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #579 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1835155
Z variance train             0.010636431
KL Divergence                25.50877
KL Loss                      2.550877
QF Loss                      2071.408
VF Loss                      221.98676
Policy Loss                  -2169.3972
Q Predictions Mean           2174.2358
Q Predictions Std            296.30197
Q Predictions Max            2388.7666
Q Predictions Min            -222.77077
V Predictions Mean           2162.18
V Predictions Std            298.67465
V Predictions Max            2370.6924
V Predictions Min            -256.55997
Log Pis Mean                 3.3015463
Log Pis Std                  3.4291105
Log Pis Max                  17.139767
Log Pis Min                  -5.5881424
Policy mu Mean               0.020850195
Policy mu Std                0.66989523
Policy mu Max                3.0394912
Policy mu Min                -3.3989146
Policy log std Mean          -1.4165679
Policy log std Std           0.34100762
Policy log std Max           0.5004817
Policy log std Min           -2.9641
Z mean eval                  1.1685643
Z variance eval              0.011729989
total_rewards                [5447.17015349 5666.07124349 5578.71219182 5529.20949252 5468.68318208
 5705.70192729 3255.4588629  5688.01067595 5771.59735008  486.81368918]
total_rewards_mean           4859.742876880037
total_rewards_std            1620.510311014663
total_rewards_max            5771.597350079134
total_rewards_min            486.81368918217834
Number of train steps total  2324000
Number of env steps total    2907000
Number of rollouts total     0
Train Time (s)               119.31020884914324
(Previous) Eval Time (s)     27.116745138075203
Sample Time (s)              18.454571635928005
Epoch Time (s)               164.88152562314644
Total Train Time (s)         91240.25008528726
Epoch                        580
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:52:17.047545 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #580 | Epoch Duration: 161.66014790534973
2020-01-13 00:52:17.047740 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #580 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1673403
Z variance train             0.011731046
KL Divergence                25.640553
KL Loss                      2.5640552
QF Loss                      1194.9822
VF Loss                      162.00443
Policy Loss                  -2236.208
Q Predictions Mean           2241.7368
Q Predictions Std            187.43181
Q Predictions Max            2446.4363
Q Predictions Min            13.583626
V Predictions Mean           2232.0244
V Predictions Std            190.20308
V Predictions Max            2432.373
V Predictions Min            -72.36517
Log Pis Mean                 2.9078007
Log Pis Std                  3.6524477
Log Pis Max                  14.975732
Log Pis Min                  -5.710288
Policy mu Mean               0.02067314
Policy mu Std                0.66485023
Policy mu Max                2.5085633
Policy mu Min                -3.161043
Policy log std Mean          -1.3733695
Policy log std Std           0.3472007
Policy log std Max           0.061363935
Policy log std Min           -3.1634903
Z mean eval                  1.1381863
Z variance eval              0.011884706
total_rewards                [5653.96962973 5629.46812819 5540.32671192 5761.16617633 5967.50410646
 5755.50024171 2120.87585437 5693.81401233 4472.57640305 5611.34838188]
total_rewards_mean           5220.654964597876
total_rewards_std            1101.719029797672
total_rewards_max            5967.5041064606485
total_rewards_min            2120.875854365293
Number of train steps total  2328000
Number of env steps total    2912000
Number of rollouts total     0
Train Time (s)               117.61213939404115
(Previous) Eval Time (s)     23.895042891148478
Sample Time (s)              18.14291405910626
Epoch Time (s)               159.6500963442959
Total Train Time (s)         91400.9473648509
Epoch                        581
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:54:57.753150 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #581 | Epoch Duration: 160.70523238182068
2020-01-13 00:54:57.753369 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #581 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1373847
Z variance train             0.011883475
KL Divergence                24.837955
KL Loss                      2.4837956
QF Loss                      743.97
VF Loss                      201.1397
Policy Loss                  -2202.339
Q Predictions Mean           2208.6853
Q Predictions Std            306.4097
Q Predictions Max            2411.2327
Q Predictions Min            -155.69347
V Predictions Mean           2204.517
V Predictions Std            304.9955
V Predictions Max            2413.515
V Predictions Min            -169.67917
Log Pis Mean                 3.1854303
Log Pis Std                  3.8872871
Log Pis Max                  18.320135
Log Pis Min                  -6.881614
Policy mu Mean               0.015987705
Policy mu Std                0.69083995
Policy mu Max                3.283741
Policy mu Min                -3.2993884
Policy log std Mean          -1.4177341
Policy log std Std           0.34582767
Policy log std Max           -0.09211767
Policy log std Min           -2.759565
Z mean eval                  1.1710604
Z variance eval              0.016934944
total_rewards                [5526.64376318 5731.20864937 5716.4732142  5703.13281206 5790.03235286
 5738.90493131 5834.70046247 5715.63404478 5628.33763673 5630.40081766]
total_rewards_mean           5701.546868461459
total_rewards_std            83.22933052500919
total_rewards_max            5834.700462472602
total_rewards_min            5526.643763182168
Number of train steps total  2332000
Number of env steps total    2917000
Number of rollouts total     0
Train Time (s)               125.48255570419133
(Previous) Eval Time (s)     24.949895011261106
Sample Time (s)              18.192607060540468
Epoch Time (s)               168.6250577759929
Total Train Time (s)         91571.85407000221
Epoch                        582
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:57:48.660839 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #582 | Epoch Duration: 170.90732336044312
2020-01-13 00:57:48.661034 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #582 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1719403
Z variance train             0.016928285
KL Divergence                24.080795
KL Loss                      2.4080796
QF Loss                      997.6398
VF Loss                      191.83939
Policy Loss                  -2199.1677
Q Predictions Mean           2201.83
Q Predictions Std            361.79453
Q Predictions Max            2400.6892
Q Predictions Min            -497.14005
V Predictions Mean           2190.0723
V Predictions Std            363.05478
V Predictions Max            2397.6755
V Predictions Min            -486.2665
Log Pis Mean                 2.7791533
Log Pis Std                  3.6244454
Log Pis Max                  15.809374
Log Pis Min                  -7.2863564
Policy mu Mean               -0.00094444817
Policy mu Std                0.61276084
Policy mu Max                2.7151363
Policy mu Min                -3.0132241
Policy log std Mean          -1.4465318
Policy log std Std           0.32785183
Policy log std Max           -0.09637213
Policy log std Min           -2.8427982
Z mean eval                  1.1525981
Z variance eval              0.009598346
total_rewards                [2747.92242123 5681.92591937 5787.7207541  5714.28610302 5675.49141178
 5673.51233497 5688.65482486 5494.72901081 5753.12919917 5702.62000121]
total_rewards_mean           5391.999198052818
total_rewards_std            884.349451427854
total_rewards_max            5787.720754102946
total_rewards_min            2747.9224212308745
Number of train steps total  2336000
Number of env steps total    2922000
Number of rollouts total     0
Train Time (s)               122.26582395285368
(Previous) Eval Time (s)     27.231856192927808
Sample Time (s)              18.350432911887765
Epoch Time (s)               167.84811305766925
Total Train Time (s)         91738.33422597172
Epoch                        583
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:00:35.146692 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #583 | Epoch Duration: 166.48552751541138
2020-01-13 01:00:35.146910 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #583 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1520674
Z variance train             0.009593571
KL Divergence                24.977121
KL Loss                      2.4977121
QF Loss                      1015.32587
VF Loss                      141.66934
Policy Loss                  -2198.294
Q Predictions Mean           2200.3833
Q Predictions Std            318.3347
Q Predictions Max            2397.8728
Q Predictions Min            -338.59073
V Predictions Mean           2199.5242
V Predictions Std            317.9547
V Predictions Max            2397.3462
V Predictions Min            -334.77356
Log Pis Mean                 2.922801
Log Pis Std                  3.4510798
Log Pis Max                  14.377808
Log Pis Min                  -5.915435
Policy mu Mean               -0.00817837
Policy mu Std                0.6729322
Policy mu Max                2.8336809
Policy mu Min                -3.096692
Policy log std Mean          -1.3953913
Policy log std Std           0.34668535
Policy log std Max           0.12555575
Policy log std Min           -2.9042459
Z mean eval                  1.1245711
Z variance eval              0.00920151
total_rewards                [5772.64373455 5734.08132782 5965.32669192 5927.49632634 5630.39739594
 5748.6734494  5878.88091024 5461.50905938 5843.03768892 5869.39999571]
total_rewards_mean           5783.144658022531
total_rewards_std            143.07592893828263
total_rewards_max            5965.3266919188445
total_rewards_min            5461.509059379963
Number of train steps total  2340000
Number of env steps total    2927000
Number of rollouts total     0
Train Time (s)               111.9380491040647
(Previous) Eval Time (s)     25.868910155724734
Sample Time (s)              18.90666770329699
Epoch Time (s)               156.71362696308643
Total Train Time (s)         91896.23245755583
Epoch                        584
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:03:13.054374 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #584 | Epoch Duration: 157.90718579292297
2020-01-13 01:03:13.054824 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #584 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1243621
Z variance train             0.009201311
KL Divergence                25.385033
KL Loss                      2.5385034
QF Loss                      932.6852
VF Loss                      216.52899
Policy Loss                  -2198.0708
Q Predictions Mean           2206.269
Q Predictions Std            309.47873
Q Predictions Max            2410.9644
Q Predictions Min            -65.89393
V Predictions Mean           2191.937
V Predictions Std            313.26334
V Predictions Max            2395.0667
V Predictions Min            -105.48181
Log Pis Mean                 2.4223375
Log Pis Std                  3.3618393
Log Pis Max                  14.162485
Log Pis Min                  -6.2409964
Policy mu Mean               0.034022495
Policy mu Std                0.6194051
Policy mu Max                3.079679
Policy mu Min                -2.9774706
Policy log std Mean          -1.3669528
Policy log std Std           0.33474872
Policy log std Max           0.6274036
Policy log std Min           -2.9183834
Z mean eval                  1.1451862
Z variance eval              0.008357065
total_rewards                [5557.67218419 5678.8666237  5846.57973677 5639.80333218 5724.19852253
 5779.08132564 5737.95489547 5732.38255866 4612.69457508 5824.96595756]
total_rewards_mean           5613.419971178931
total_rewards_std            343.2244567697376
total_rewards_max            5846.579736774922
total_rewards_min            4612.694575082842
Number of train steps total  2344000
Number of env steps total    2932000
Number of rollouts total     0
Train Time (s)               123.56301455106586
(Previous) Eval Time (s)     27.062131986021996
Sample Time (s)              19.342929136008024
Epoch Time (s)               169.96807567309588
Total Train Time (s)         92066.01175981155
Epoch                        585
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:06:02.842200 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #585 | Epoch Duration: 169.78709721565247
2020-01-13 01:06:02.842492 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #585 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1454821
Z variance train             0.008339742
KL Divergence                25.680378
KL Loss                      2.5680377
QF Loss                      914.79645
VF Loss                      117.01313
Policy Loss                  -2216.059
Q Predictions Mean           2220.727
Q Predictions Std            266.7882
Q Predictions Max            2438.098
Q Predictions Min            -487.66498
V Predictions Mean           2213.9895
V Predictions Std            266.23828
V Predictions Max            2438.4885
V Predictions Min            -487.5229
Log Pis Mean                 2.8480744
Log Pis Std                  3.48902
Log Pis Max                  16.991611
Log Pis Min                  -5.9949856
Policy mu Mean               0.031554926
Policy mu Std                0.64631724
Policy mu Max                3.0793622
Policy mu Min                -3.1017356
Policy log std Mean          -1.3770769
Policy log std Std           0.3263374
Policy log std Max           0.08760893
Policy log std Min           -2.8483725
Z mean eval                  1.1667792
Z variance eval              0.014105117
total_rewards                [ 148.01758196 5732.54060216 5699.10894514 5791.53974152 5731.28791226
 2941.56579373 5874.2241292  5657.74625104 5690.85408716 5886.94246736]
total_rewards_mean           4915.382751152673
total_rewards_std            1798.7444085094353
total_rewards_max            5886.942467356075
total_rewards_min            148.01758196236193
Number of train steps total  2348000
Number of env steps total    2937000
Number of rollouts total     0
Train Time (s)               126.48526622494683
(Previous) Eval Time (s)     26.88082507904619
Sample Time (s)              17.931785529013723
Epoch Time (s)               171.29787683300674
Total Train Time (s)         92234.07153208973
Epoch                        586
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:08:50.912621 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #586 | Epoch Duration: 168.06977701187134
2020-01-13 01:08:50.913084 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #586 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.165869
Z variance train             0.014092898
KL Divergence                25.463097
KL Loss                      2.5463097
QF Loss                      1221.5243
VF Loss                      249.57971
Policy Loss                  -2222.1907
Q Predictions Mean           2223.7134
Q Predictions Std            322.399
Q Predictions Max            2435.3357
Q Predictions Min            -485.89316
V Predictions Mean           2217.329
V Predictions Std            320.95227
V Predictions Max            2428.5305
V Predictions Min            -507.0831
Log Pis Mean                 3.16467
Log Pis Std                  3.8849392
Log Pis Max                  24.928272
Log Pis Min                  -6.5157495
Policy mu Mean               0.0054575987
Policy mu Std                0.6642982
Policy mu Max                3.6779108
Policy mu Min                -2.7083867
Policy log std Mean          -1.4349775
Policy log std Std           0.36423802
Policy log std Max           0.56546974
Policy log std Min           -4.4350247
Z mean eval                  1.1700232
Z variance eval              0.008189886
total_rewards                [5658.2677487  5754.95770498   70.96151082 5895.07208885 5568.63150187
 5755.56262758 2045.99086741  287.5137614  5884.30960442 5691.42889717]
total_rewards_mean           4261.269631319344
total_rewards_std            2317.986562323993
total_rewards_max            5895.07208885428
total_rewards_min            70.96151081710097
Number of train steps total  2352000
Number of env steps total    2942000
Number of rollouts total     0
Train Time (s)               117.36412587109953
(Previous) Eval Time (s)     23.65237757610157
Sample Time (s)              18.51311869872734
Epoch Time (s)               159.52962214592844
Total Train Time (s)         92390.08971512225
Epoch                        587
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:11:26.932811 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #587 | Epoch Duration: 156.01948523521423
2020-01-13 01:11:26.932960 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #587 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1694874
Z variance train             0.008181984
KL Divergence                26.647518
KL Loss                      2.6647518
QF Loss                      1934.14
VF Loss                      1019.8962
Policy Loss                  -2206.7412
Q Predictions Mean           2210.5703
Q Predictions Std            339.16815
Q Predictions Max            2420.9336
Q Predictions Min            -265.6912
V Predictions Mean           2201.706
V Predictions Std            357.02737
V Predictions Max            2413.176
V Predictions Min            -301.77255
Log Pis Mean                 2.841781
Log Pis Std                  3.7133193
Log Pis Max                  20.947578
Log Pis Min                  -4.798868
Policy mu Mean               0.025582815
Policy mu Std                0.6180731
Policy mu Max                2.8152833
Policy mu Min                -2.6362488
Policy log std Mean          -1.4058535
Policy log std Std           0.36306086
Policy log std Max           -0.15542948
Policy log std Min           -4.0211067
Z mean eval                  1.1526072
Z variance eval              0.010285566
total_rewards                [5606.69402637 4699.22157066 5577.56357655 5687.52690595 5743.35319501
 5706.98610521 4459.33904473 5817.1282825  5802.41990772 5943.11413394]
total_rewards_mean           5504.3346748646
total_rewards_std            476.13462338892725
total_rewards_max            5943.114133937371
total_rewards_min            4459.339044733758
Number of train steps total  2356000
Number of env steps total    2947000
Number of rollouts total     0
Train Time (s)               118.20617586513981
(Previous) Eval Time (s)     20.14197524636984
Sample Time (s)              18.185170353390276
Epoch Time (s)               156.53332146489993
Total Train Time (s)         92552.5724489796
Epoch                        588
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:14:09.419266 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #588 | Epoch Duration: 162.48619413375854
2020-01-13 01:14:09.419414 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #588 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1507878
Z variance train             0.010280768
KL Divergence                25.778276
KL Loss                      2.5778277
QF Loss                      907.2503
VF Loss                      112.61543
Policy Loss                  -2206.0913
Q Predictions Mean           2209.7695
Q Predictions Std            304.87772
Q Predictions Max            2432.669
Q Predictions Min            -396.38242
V Predictions Mean           2205.3335
V Predictions Std            304.72266
V Predictions Max            2413.5193
V Predictions Min            -374.6379
Log Pis Mean                 2.7041545
Log Pis Std                  3.427656
Log Pis Max                  13.51626
Log Pis Min                  -5.5674267
Policy mu Mean               0.007174683
Policy mu Std                0.6149137
Policy mu Max                2.674457
Policy mu Min                -2.762326
Policy log std Mean          -1.4026287
Policy log std Std           0.31510675
Policy log std Max           -0.15582275
Policy log std Min           -2.971259
Z mean eval                  1.2375758
Z variance eval              0.01056774
total_rewards                [5585.09723197 5697.89490304 5679.08114696 5801.98733991 5644.03610883
 5680.22403499 2162.4545759  5519.33239528 5487.92116885 5887.9954781 ]
total_rewards_mean           5314.602438382694
total_rewards_std            1056.8559256456906
total_rewards_max            5887.995478100558
total_rewards_min            2162.454575899814
Number of train steps total  2360000
Number of env steps total    2952000
Number of rollouts total     0
Train Time (s)               114.63023750390857
(Previous) Eval Time (s)     26.094456115737557
Sample Time (s)              18.913988446816802
Epoch Time (s)               159.63868206646293
Total Train Time (s)         92710.92777605867
Epoch                        589
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:16:47.783572 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #589 | Epoch Duration: 158.36400175094604
2020-01-13 01:16:47.783909 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #589 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2381246
Z variance train             0.010528709
KL Divergence                26.28815
KL Loss                      2.6288152
QF Loss                      734.3241
VF Loss                      153.65063
Policy Loss                  -2235.5066
Q Predictions Mean           2238.2598
Q Predictions Std            263.76382
Q Predictions Max            2453.7405
Q Predictions Min            -395.67844
V Predictions Mean           2240.3154
V Predictions Std            262.3629
V Predictions Max            2428.07
V Predictions Min            -363.36374
Log Pis Mean                 2.6540546
Log Pis Std                  3.5019367
Log Pis Max                  19.420631
Log Pis Min                  -5.679892
Policy mu Mean               0.032906972
Policy mu Std                0.61659455
Policy mu Max                3.1464653
Policy mu Min                -3.0175726
Policy log std Mean          -1.3712189
Policy log std Std           0.32183886
Policy log std Max           -0.07894671
Policy log std Min           -3.2926264
Z mean eval                  1.1725047
Z variance eval              0.0092172865
total_rewards                [5511.42427618 5824.40634781 4932.1820483  5634.00547529 5898.42451661
 5855.56387709 5658.55094518 5614.63990672 5668.25246424 1307.93160138]
total_rewards_mean           5190.538145879149
total_rewards_std            1319.5936162961013
total_rewards_max            5898.424516608873
total_rewards_min            1307.931601380003
Number of train steps total  2364000
Number of env steps total    2957000
Number of rollouts total     0
Train Time (s)               119.66876281378791
(Previous) Eval Time (s)     24.81944592995569
Sample Time (s)              18.011325639206916
Epoch Time (s)               162.49953438295051
Total Train Time (s)         92873.24638660066
Epoch                        590
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:19:30.109246 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #590 | Epoch Duration: 162.32510781288147
2020-01-13 01:19:30.109496 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #590 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1721932
Z variance train             0.009221095
KL Divergence                27.218704
KL Loss                      2.7218704
QF Loss                      1261.6218
VF Loss                      154.25565
Policy Loss                  -2226.244
Q Predictions Mean           2230.4663
Q Predictions Std            302.03598
Q Predictions Max            2437.354
Q Predictions Min            -290.93622
V Predictions Mean           2223.7334
V Predictions Std            301.10544
V Predictions Max            2434.3403
V Predictions Min            -318.49405
Log Pis Mean                 3.2304938
Log Pis Std                  3.5714264
Log Pis Max                  16.306246
Log Pis Min                  -6.932481
Policy mu Mean               -0.04031335
Policy mu Std                0.6944895
Policy mu Max                3.622415
Policy mu Min                -3.0073855
Policy log std Mean          -1.3828914
Policy log std Std           0.34639966
Policy log std Max           0.025230646
Policy log std Min           -2.9558387
Z mean eval                  1.2043574
Z variance eval              0.00427859
total_rewards                [5331.12797784 5966.61839158   15.72745001 5787.79302007 4807.3582072
 5945.35368333 5556.11167164 5616.64666039 5112.53688516 5743.17871111]
total_rewards_mean           4988.245265834403
total_rewards_std            1693.8566261389085
total_rewards_max            5966.618391584713
total_rewards_min            15.727450011240926
Number of train steps total  2368000
Number of env steps total    2962000
Number of rollouts total     0
Train Time (s)               121.50525530381128
(Previous) Eval Time (s)     24.644717046059668
Sample Time (s)              18.554819374810904
Epoch Time (s)               164.70479172468185
Total Train Time (s)         93037.1672287872
Epoch                        591
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:22:14.034098 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #591 | Epoch Duration: 163.92442059516907
2020-01-13 01:22:14.034303 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #591 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2044324
Z variance train             0.004278033
KL Divergence                27.907154
KL Loss                      2.7907155
QF Loss                      918.4023
VF Loss                      156.51665
Policy Loss                  -2216.0972
Q Predictions Mean           2221.252
Q Predictions Std            284.5642
Q Predictions Max            2427.5596
Q Predictions Min            -264.29495
V Predictions Mean           2210.812
V Predictions Std            286.51413
V Predictions Max            2407.962
V Predictions Min            -228.89734
Log Pis Mean                 2.7860053
Log Pis Std                  3.4672554
Log Pis Max                  13.396008
Log Pis Min                  -5.7733526
Policy mu Mean               -0.007146608
Policy mu Std                0.6736515
Policy mu Max                3.4549685
Policy mu Min                -2.8922462
Policy log std Mean          -1.3583031
Policy log std Std           0.33946663
Policy log std Max           -0.12221956
Policy log std Min           -3.0224028
Z mean eval                  1.1519964
Z variance eval              0.008050453
total_rewards                [5758.0662901  5907.8711831  5774.37765857 5898.64290923 5737.61782406
 5704.15564162 5765.4381418  5955.50674935 1118.53249563 5787.37821202]
total_rewards_mean           5340.758710547365
total_rewards_std            1409.5924158685964
total_rewards_max            5955.506749349703
total_rewards_min            1118.5324956316883
Number of train steps total  2372000
Number of env steps total    2967000
Number of rollouts total     0
Train Time (s)               111.07768134167418
(Previous) Eval Time (s)     23.8640421689488
Sample Time (s)              18.839569100178778
Epoch Time (s)               153.78129261080176
Total Train Time (s)         93192.11193637084
Epoch                        592
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:24:48.985298 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #592 | Epoch Duration: 154.9508500099182
2020-01-13 01:24:48.985494 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #592 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1521704
Z variance train             0.008045537
KL Divergence                27.120638
KL Loss                      2.7120638
QF Loss                      1379.8074
VF Loss                      4402.6885
Policy Loss                  -2246.5898
Q Predictions Mean           2250.425
Q Predictions Std            281.4352
Q Predictions Max            2451.3564
Q Predictions Min            -505.37427
V Predictions Mean           2246.0864
V Predictions Std            264.25894
V Predictions Max            2440.3843
V Predictions Min            -499.50586
Log Pis Mean                 2.8156857
Log Pis Std                  3.744758
Log Pis Max                  14.498125
Log Pis Min                  -6.4140177
Policy mu Mean               -0.012097833
Policy mu Std                0.63605106
Policy mu Max                2.956243
Policy mu Min                -3.066049
Policy log std Mean          -1.4232736
Policy log std Std           0.35041994
Policy log std Max           -0.28992212
Policy log std Min           -2.9121537
Z mean eval                  1.1507533
Z variance eval              0.010214289
total_rewards                [5579.55208882 5831.98738324 1944.33569934 6063.72951705 5900.75055714
 5790.93640404 5949.88533576  134.40112559 5823.00001212 5944.45280925]
total_rewards_mean           4896.303093235587
total_rewards_std            1974.1262522084298
total_rewards_max            6063.729517054382
total_rewards_min            134.40112559471
Number of train steps total  2376000
Number of env steps total    2972000
Number of rollouts total     0
Train Time (s)               123.32373220007867
(Previous) Eval Time (s)     25.033264238853008
Sample Time (s)              18.45610503712669
Epoch Time (s)               166.81310147605836
Total Train Time (s)         93356.16789385304
Epoch                        593
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:27:33.045484 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #593 | Epoch Duration: 164.05985021591187
2020-01-13 01:27:33.045680 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #593 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1506443
Z variance train             0.010211612
KL Divergence                26.691574
KL Loss                      2.6691575
QF Loss                      720.263
VF Loss                      4091.526
Policy Loss                  -2239.929
Q Predictions Mean           2240.3496
Q Predictions Std            270.27774
Q Predictions Max            2442.7395
Q Predictions Min            -358.42728
V Predictions Mean           2243.746
V Predictions Std            241.48859
V Predictions Max            2430.9065
V Predictions Min            -358.19232
Log Pis Mean                 2.9772341
Log Pis Std                  3.948372
Log Pis Max                  19.332027
Log Pis Min                  -4.865063
Policy mu Mean               -0.018303206
Policy mu Std                0.63486254
Policy mu Max                2.9205165
Policy mu Min                -3.123139
Policy log std Mean          -1.4357964
Policy log std Std           0.38024634
Policy log std Max           -0.22036624
Policy log std Min           -3.6540291
Z mean eval                  1.175745
Z variance eval              0.008388338
total_rewards                [5507.16062059 5901.52559141 5680.9580139  6030.45848471 5755.23106407
 5836.73519153 5606.49884395 5841.15227503 5969.24948076 5878.97226539]
total_rewards_mean           5800.794183134207
total_rewards_std            155.1483460105119
total_rewards_max            6030.4584847091355
total_rewards_min            5507.160620589311
Number of train steps total  2380000
Number of env steps total    2977000
Number of rollouts total     0
Train Time (s)               124.48978414200246
(Previous) Eval Time (s)     22.279691284056753
Sample Time (s)              19.285883653908968
Epoch Time (s)               166.05535907996818
Total Train Time (s)         93527.07042515278
Epoch                        594
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:30:23.951984 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #594 | Epoch Duration: 170.90617084503174
2020-01-13 01:30:23.952140 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #594 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1755093
Z variance train             0.008372205
KL Divergence                27.458279
KL Loss                      2.745828
QF Loss                      1698.3848
VF Loss                      520.272
Policy Loss                  -2255.8396
Q Predictions Mean           2257.455
Q Predictions Std            317.4671
Q Predictions Max            2466.4736
Q Predictions Min            -482.61813
V Predictions Mean           2245.4487
V Predictions Std            323.54398
V Predictions Max            2450.5603
V Predictions Min            -481.5566
Log Pis Mean                 2.8386087
Log Pis Std                  3.5880523
Log Pis Max                  17.018066
Log Pis Min                  -6.6050377
Policy mu Mean               -0.0007203566
Policy mu Std                0.65030515
Policy mu Max                2.9015477
Policy mu Min                -2.9841757
Policy log std Mean          -1.3705653
Policy log std Std           0.34012365
Policy log std Max           -0.09647262
Policy log std Min           -2.857274
Z mean eval                  1.149741
Z variance eval              0.0058888025
total_rewards                [5666.27324792 5880.09367411 5684.01901498 5816.00688386 5847.15275038
 5590.46115211 5610.99449899 5748.54420852 5850.49718208 5783.56354892]
total_rewards_mean           5747.760616187248
total_rewards_std            99.01359942690513
total_rewards_max            5880.093674114265
total_rewards_min            5590.4611521069155
Number of train steps total  2384000
Number of env steps total    2982000
Number of rollouts total     0
Train Time (s)               118.6482383380644
(Previous) Eval Time (s)     27.13020683405921
Sample Time (s)              18.83531135926023
Epoch Time (s)               164.61375653138384
Total Train Time (s)         93691.71475062333
Epoch                        595
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:33:08.601966 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #595 | Epoch Duration: 164.6496787071228
2020-01-13 01:33:08.602169 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #595 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1507292
Z variance train             0.0058870325
KL Divergence                28.351887
KL Loss                      2.8351886
QF Loss                      1175.8127
VF Loss                      270.8358
Policy Loss                  -2193.9543
Q Predictions Mean           2195.5205
Q Predictions Std            411.40366
Q Predictions Max            2438.3325
Q Predictions Min            -434.06995
V Predictions Mean           2187.6208
V Predictions Std            413.9096
V Predictions Max            2422.2646
V Predictions Min            -476.4888
Log Pis Mean                 2.1012943
Log Pis Std                  3.147828
Log Pis Max                  11.7668705
Log Pis Min                  -5.5795527
Policy mu Mean               -0.002116782
Policy mu Std                0.5796712
Policy mu Max                2.753622
Policy mu Min                -2.5105412
Policy log std Mean          -1.3524574
Policy log std Std           0.30071747
Policy log std Max           0.32343292
Policy log std Min           -2.9151998
Z mean eval                  1.1901451
Z variance eval              0.0024859877
total_rewards                [1251.83413099 5751.70516889 5971.71071499 5840.32868779 5745.71916711
 5776.82967899 5223.94823369 5814.60525818  468.64169377 1153.49300427]
total_rewards_mean           4299.881573867405
total_rewards_std            2203.7387341880853
total_rewards_max            5971.710714991008
total_rewards_min            468.64169377014616
Number of train steps total  2388000
Number of env steps total    2987000
Number of rollouts total     0
Train Time (s)               116.74984377995133
(Previous) Eval Time (s)     27.165783793199807
Sample Time (s)              19.41516196122393
Epoch Time (s)               163.33078953437507
Total Train Time (s)         93848.21263119066
Epoch                        596
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:35:45.104699 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #596 | Epoch Duration: 156.50236916542053
2020-01-13 01:35:45.104902 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #596 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.189608
Z variance train             0.0024855924
KL Divergence                29.622124
KL Loss                      2.9622123
QF Loss                      817.85706
VF Loss                      300.62027
Policy Loss                  -2266.6797
Q Predictions Mean           2268.2224
Q Predictions Std            241.63509
Q Predictions Max            2429.565
Q Predictions Min            -554.4794
V Predictions Mean           2259.8335
V Predictions Std            244.29224
V Predictions Max            2429.2322
V Predictions Min            -548.50806
Log Pis Mean                 2.740034
Log Pis Std                  3.463239
Log Pis Max                  14.796017
Log Pis Min                  -5.9368305
Policy mu Mean               0.0065894774
Policy mu Std                0.601921
Policy mu Max                2.8876944
Policy mu Min                -2.535762
Policy log std Mean          -1.4197998
Policy log std Std           0.32497498
Policy log std Max           -0.19238174
Policy log std Min           -3.422904
Z mean eval                  1.1977117
Z variance eval              0.0032248157
total_rewards                [5642.77709009 5672.111208   5734.67785649    9.2695662  5871.50915863
 5578.49305081 5689.31189719 5672.97584747 5335.0935024  5812.22065036]
total_rewards_mean           5101.843982764611
total_rewards_std            1703.013081495486
total_rewards_max            5871.509158632249
total_rewards_min            9.26956619707702
Number of train steps total  2392000
Number of env steps total    2992000
Number of rollouts total     0
Train Time (s)               124.70106222108006
(Previous) Eval Time (s)     20.337011765688658
Sample Time (s)              19.007541252300143
Epoch Time (s)               164.04561523906887
Total Train Time (s)         94016.28364763642
Epoch                        597
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:38:33.181024 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #597 | Epoch Duration: 168.07597756385803
2020-01-13 01:38:33.181216 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #597 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1981137
Z variance train             0.0032276683
KL Divergence                29.721102
KL Loss                      2.9721103
QF Loss                      962.25476
VF Loss                      177.79439
Policy Loss                  -2229.8179
Q Predictions Mean           2233.6748
Q Predictions Std            288.73407
Q Predictions Max            2446.9758
Q Predictions Min            -323.6801
V Predictions Mean           2225.493
V Predictions Std            288.2237
V Predictions Max            2438.1858
V Predictions Min            -321.84167
Log Pis Mean                 2.973446
Log Pis Std                  3.3406405
Log Pis Max                  17.84332
Log Pis Min                  -5.1689887
Policy mu Mean               -0.005280936
Policy mu Std                0.6422787
Policy mu Max                2.520488
Policy mu Min                -4.9276567
Policy log std Mean          -1.4036674
Policy log std Std           0.31956613
Policy log std Max           -0.19885778
Policy log std Min           -3.003113
Z mean eval                  1.1907197
Z variance eval              0.004911231
total_rewards                [5621.21004265 5707.09286362 5808.36396284 5683.18707583 5561.62767378
 5744.15491727 5691.58235097 5671.06466247 5667.39539064 5546.85908873]
total_rewards_mean           5670.253802878999
total_rewards_std            74.80313745746962
total_rewards_max            5808.363962836459
total_rewards_min            5546.859088728714
Number of train steps total  2396000
Number of env steps total    2997000
Number of rollouts total     0
Train Time (s)               122.9244486792013
(Previous) Eval Time (s)     24.36701902607456
Sample Time (s)              17.878134751226753
Epoch Time (s)               165.16960245650262
Total Train Time (s)         94184.30033827014
Epoch                        598
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:41:21.206563 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #598 | Epoch Duration: 168.02517437934875
2020-01-13 01:41:21.206843 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #598 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.191289
Z variance train             0.004911189
KL Divergence                29.776327
KL Loss                      2.9776328
QF Loss                      736.8849
VF Loss                      143.02043
Policy Loss                  -2268.508
Q Predictions Mean           2274.0093
Q Predictions Std            215.30266
Q Predictions Max            2466.2473
Q Predictions Min            -427.25266
V Predictions Mean           2273.7485
V Predictions Std            216.3977
V Predictions Max            2473.8567
V Predictions Min            -430.35678
Log Pis Mean                 3.0353556
Log Pis Std                  3.176809
Log Pis Max                  15.449316
Log Pis Min                  -3.3456836
Policy mu Mean               -0.017508449
Policy mu Std                0.6387374
Policy mu Max                2.7341743
Policy mu Min                -3.032936
Policy log std Mean          -1.4204069
Policy log std Std           0.30700794
Policy log std Max           0.011664629
Policy log std Min           -2.9051416
Z mean eval                  1.2001603
Z variance eval              0.008025683
total_rewards                [5521.2936142  5733.83984402 5838.92111974 5939.71984872 5569.04649721
 5767.04644923 5783.25839832 5924.66915912 5742.01414525 5833.31273029]
total_rewards_mean           5765.312180610454
total_rewards_std            128.75507448069004
total_rewards_max            5939.71984871612
total_rewards_min            5521.293614201799
Number of train steps total  2400000
Number of env steps total    3002000
Number of rollouts total     0
Train Time (s)               122.40018601901829
(Previous) Eval Time (s)     27.222292222082615
Sample Time (s)              18.01068098656833
Epoch Time (s)               167.63315922766924
Total Train Time (s)         94351.66289403616
Epoch                        599
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:44:08.576664 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #599 | Epoch Duration: 167.36962342262268
2020-01-13 01:44:08.576850 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #599 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2051389
Z variance train             0.007966715
KL Divergence                29.699553
KL Loss                      2.9699552
QF Loss                      1593.5139
VF Loss                      330.40912
Policy Loss                  -2209.6282
Q Predictions Mean           2215.2056
Q Predictions Std            379.3079
Q Predictions Max            2440.682
Q Predictions Min            -476.4295
V Predictions Mean           2204.8423
V Predictions Std            362.7023
V Predictions Max            2407.8064
V Predictions Min            -496.91113
Log Pis Mean                 3.0260677
Log Pis Std                  3.9215817
Log Pis Max                  23.893272
Log Pis Min                  -6.0083966
Policy mu Mean               0.0063717207
Policy mu Std                0.6215123
Policy mu Max                3.4247637
Policy mu Min                -3.4661434
Policy log std Mean          -1.4548357
Policy log std Std           0.36814353
Policy log std Max           0.0026023388
Policy log std Min           -3.8720958
Z mean eval                  1.154587
Z variance eval              0.009650394
total_rewards                [ -16.13693871 5772.83514734 5668.6023506  5783.18842927 6047.41367693
 5776.8905676  5872.2934272  5793.05265266  464.80096168 5864.77137431]
total_rewards_mean           4702.771164887819
total_rewards_std            2243.706529658157
total_rewards_max            6047.4136769322395
total_rewards_min            -16.136938708103298
Number of train steps total  2404000
Number of env steps total    3007000
Number of rollouts total     0
Train Time (s)               123.47247488005087
(Previous) Eval Time (s)     26.958511208184063
Sample Time (s)              17.652208269108087
Epoch Time (s)               168.08319435734302
Total Train Time (s)         94514.61999250297
Epoch                        600
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:46:51.540987 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #600 | Epoch Duration: 162.9639961719513
2020-01-13 01:46:51.541190 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #600 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1532724
Z variance train             0.009608583
KL Divergence                28.352253
KL Loss                      2.8352253
QF Loss                      2025.0981
VF Loss                      341.32254
Policy Loss                  -2237.3945
Q Predictions Mean           2234.7935
Q Predictions Std            345.53632
Q Predictions Max            2446.9365
Q Predictions Min            -324.88254
V Predictions Mean           2230.943
V Predictions Std            327.11902
V Predictions Max            2432.9346
V Predictions Min            -325.70255
Log Pis Mean                 2.575939
Log Pis Std                  3.5343454
Log Pis Max                  25.01656
Log Pis Min                  -6.661488
Policy mu Mean               0.020084709
Policy mu Std                0.63227206
Policy mu Max                2.6418774
Policy mu Min                -3.0198705
Policy log std Mean          -1.3834386
Policy log std Std           0.35190624
Policy log std Max           0.0881716
Policy log std Min           -3.423039
Z mean eval                  1.3360275
Z variance eval              0.008475652
total_rewards                [5595.26934493 3513.02206135 5696.87496003 5575.4344104  5591.72550933
 1935.8240283  5784.9932905  5822.5497503  5868.85351158 5830.76445239]
total_rewards_mean           5121.531131912992
total_rewards_std            1253.4632948422857
total_rewards_max            5868.853511584724
total_rewards_min            1935.8240282991096
Number of train steps total  2408000
Number of env steps total    3012000
Number of rollouts total     0
Train Time (s)               121.00892147189006
(Previous) Eval Time (s)     21.839015644043684
Sample Time (s)              17.956424431409687
Epoch Time (s)               160.80436154734343
Total Train Time (s)         94678.29053499969
Epoch                        601
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:49:35.220914 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #601 | Epoch Duration: 163.67954802513123
2020-01-13 01:49:35.221185 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #601 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3380635
Z variance train             0.008462799
KL Divergence                28.499752
KL Loss                      2.8499753
QF Loss                      1147.7749
VF Loss                      843.29456
Policy Loss                  -2291.0273
Q Predictions Mean           2297.2036
Q Predictions Std            258.8247
Q Predictions Max            2468.4673
Q Predictions Min            -388.3996
V Predictions Mean           2313.0366
V Predictions Std            263.6626
V Predictions Max            2496.4417
V Predictions Min            -496.07648
Log Pis Mean                 3.0727901
Log Pis Std                  3.410607
Log Pis Max                  16.401358
Log Pis Min                  -4.312419
Policy mu Mean               0.024269303
Policy mu Std                0.67826086
Policy mu Max                2.8271613
Policy mu Min                -3.2671044
Policy log std Mean          -1.3820556
Policy log std Std           0.3296549
Policy log std Max           -0.047292948
Policy log std Min           -2.940308
Z mean eval                  1.1249975
Z variance eval              0.008628781
total_rewards                [5752.88751638 5819.94598466 5747.89134971 5643.31498221 5791.98499448
 5663.25365546 5856.04211746 5765.40873471 5786.62323717 5724.14851094]
total_rewards_mean           5755.1501083178455
total_rewards_std            62.29066592515766
total_rewards_max            5856.042117462961
total_rewards_min            5643.314982208375
Number of train steps total  2412000
Number of env steps total    3017000
Number of rollouts total     0
Train Time (s)               126.48149179900065
(Previous) Eval Time (s)     24.713855392765254
Sample Time (s)              18.174549111165106
Epoch Time (s)               169.369896302931
Total Train Time (s)         94849.75165737374
Epoch                        602
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:52:26.691253 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #602 | Epoch Duration: 171.46984124183655
2020-01-13 01:52:26.691557 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #602 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.125021
Z variance train             0.00862539
KL Divergence                26.26622
KL Loss                      2.626622
QF Loss                      918.21704
VF Loss                      151.88852
Policy Loss                  -2243.835
Q Predictions Mean           2247.3516
Q Predictions Std            314.30438
Q Predictions Max            2442.6282
Q Predictions Min            -427.7261
V Predictions Mean           2244.9104
V Predictions Std            315.04108
V Predictions Max            2440.7915
V Predictions Min            -441.65894
Log Pis Mean                 2.7633896
Log Pis Std                  3.2778444
Log Pis Max                  13.178808
Log Pis Min                  -4.619655
Policy mu Mean               -0.019399831
Policy mu Std                0.6292366
Policy mu Max                2.43274
Policy mu Min                -3.0376632
Policy log std Mean          -1.3995261
Policy log std Std           0.3364951
Policy log std Max           -0.06660688
Policy log std Min           -3.3904753
Z mean eval                  1.1412653
Z variance eval              0.005933041
total_rewards                [5623.73729102 5918.90444989 5679.59138038 5920.88113232 5693.97072616
 5861.30643119 5748.38435508 5728.58142668 5855.76837151 5816.10400627]
total_rewards_mean           5784.72295705108
total_rewards_std            99.05470069985546
total_rewards_max            5920.881132320413
total_rewards_min            5623.737291020031
Number of train steps total  2416000
Number of env steps total    3022000
Number of rollouts total     0
Train Time (s)               112.21484531695023
(Previous) Eval Time (s)     26.813475637231022
Sample Time (s)              18.47327037807554
Epoch Time (s)               157.5015913322568
Total Train Time (s)         95007.28604623023
Epoch                        603
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:55:04.229657 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #603 | Epoch Duration: 157.53789925575256
2020-01-13 01:55:04.229859 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #603 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.141209
Z variance train             0.0059279185
KL Divergence                27.244858
KL Loss                      2.7244859
QF Loss                      902.52057
VF Loss                      159.30968
Policy Loss                  -2271.313
Q Predictions Mean           2273.3071
Q Predictions Std            200.57312
Q Predictions Max            2442.4233
Q Predictions Min            -262.55136
V Predictions Mean           2264.5405
V Predictions Std            200.83711
V Predictions Max            2429.6025
V Predictions Min            -295.239
Log Pis Mean                 3.1777844
Log Pis Std                  3.6989222
Log Pis Max                  24.0619
Log Pis Min                  -5.240992
Policy mu Mean               -0.0042093545
Policy mu Std                0.6380351
Policy mu Max                3.1147869
Policy mu Min                -3.8478942
Policy log std Mean          -1.4362475
Policy log std Std           0.33296165
Policy log std Max           -0.0007981062
Policy log std Min           -2.7507763
Z mean eval                  1.1643198
Z variance eval              0.005310962
total_rewards                [3.08856527e+00 5.86121520e+03 5.83809564e+03 6.05147572e+03
 5.77211489e+03 5.72537903e+03 5.85225642e+03 5.93520102e+03
 5.87612076e+03 6.04935188e+03]
total_rewards_mean           5296.429913401915
total_rewards_std            1767.2611331836508
total_rewards_max            6051.475720657867
total_rewards_min            3.088565273825151
Number of train steps total  2420000
Number of env steps total    3027000
Number of rollouts total     0
Train Time (s)               118.8959130672738
(Previous) Eval Time (s)     26.849486439023167
Sample Time (s)              18.244923567399383
Epoch Time (s)               163.99032307369635
Total Train Time (s)         95169.04940183181
Epoch                        604
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:57:45.998763 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #604 | Epoch Duration: 161.76875638961792
2020-01-13 01:57:45.998966 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #604 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1642716
Z variance train             0.0053106775
KL Divergence                27.907782
KL Loss                      2.7907782
QF Loss                      797.8725
VF Loss                      153.98042
Policy Loss                  -2253.7778
Q Predictions Mean           2256.142
Q Predictions Std            300.92502
Q Predictions Max            2432.9688
Q Predictions Min            -481.3934
V Predictions Mean           2256.8606
V Predictions Std            281.87082
V Predictions Max            2435.4612
V Predictions Min            -443.72916
Log Pis Mean                 2.8579335
Log Pis Std                  3.5627644
Log Pis Max                  13.76603
Log Pis Min                  -6.065291
Policy mu Mean               -0.033193186
Policy mu Std                0.63524604
Policy mu Max                2.915328
Policy mu Min                -3.1471128
Policy log std Mean          -1.4021912
Policy log std Std           0.34753785
Policy log std Max           -0.24380183
Policy log std Min           -3.0199692
Z mean eval                  1.1990137
Z variance eval              0.0047124038
total_rewards                [5632.54364453 5763.07106216 5703.44592421 5860.03998711 5905.15297396
 5875.37824867 2614.0867605  6011.73211662 5805.26892233 5752.22099865]
total_rewards_mean           5492.2940638723385
total_rewards_std            964.8537048393022
total_rewards_max            6011.732116615065
total_rewards_min            2614.0867604973055
Number of train steps total  2424000
Number of env steps total    3032000
Number of rollouts total     0
Train Time (s)               120.99009670130908
(Previous) Eval Time (s)     24.62762164697051
Sample Time (s)              18.607882094103843
Epoch Time (s)               164.22560044238344
Total Train Time (s)         95335.76030290825
Epoch                        605
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:00:32.713567 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #605 | Epoch Duration: 166.71446132659912
2020-01-13 02:00:32.713727 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #605 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1987308
Z variance train             0.0047121895
KL Divergence                28.751942
KL Loss                      2.8751943
QF Loss                      672.0176
VF Loss                      364.11923
Policy Loss                  -2254.5337
Q Predictions Mean           2258.369
Q Predictions Std            300.7684
Q Predictions Max            2471.1719
Q Predictions Min            -562.95886
V Predictions Mean           2255.693
V Predictions Std            309.50647
V Predictions Max            2466.3591
V Predictions Min            -560.1458
Log Pis Mean                 2.5715528
Log Pis Std                  3.429821
Log Pis Max                  15.2504
Log Pis Min                  -4.6350484
Policy mu Mean               -0.008493494
Policy mu Std                0.6518705
Policy mu Max                2.8954623
Policy mu Min                -3.1491728
Policy log std Mean          -1.3606765
Policy log std Std           0.34110677
Policy log std Max           -0.113075376
Policy log std Min           -2.8948436
Z mean eval                  1.2353991
Z variance eval              0.0082858
total_rewards                [5629.75425689 5732.48711517 3178.4664635  5742.68714294 5770.93725593
 5650.62400709 2572.00256212 5291.61349439 5723.95035811 5705.38826803]
total_rewards_mean           5099.791092416363
total_rewards_std            1127.947532596138
total_rewards_max            5770.93725593298
total_rewards_min            2572.0025621206305
Number of train steps total  2428000
Number of env steps total    3037000
Number of rollouts total     0
Train Time (s)               118.47443283209577
(Previous) Eval Time (s)     27.116132239811122
Sample Time (s)              18.15159603348002
Epoch Time (s)               163.7421611053869
Total Train Time (s)         95496.27760429354
Epoch                        606
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:03:13.237527 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #606 | Epoch Duration: 160.52366733551025
2020-01-13 02:03:13.237760 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #606 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2346491
Z variance train             0.008325453
KL Divergence                27.453009
KL Loss                      2.745301
QF Loss                      2212.276
VF Loss                      433.80505
Policy Loss                  -2243.9668
Q Predictions Mean           2236.208
Q Predictions Std            378.0553
Q Predictions Max            2434.956
Q Predictions Min            -552.6673
V Predictions Mean           2238.656
V Predictions Std            347.0353
V Predictions Max            2428.4456
V Predictions Min            -500.85214
Log Pis Mean                 2.5596433
Log Pis Std                  3.7926593
Log Pis Max                  17.292553
Log Pis Min                  -7.4817476
Policy mu Mean               -0.030039806
Policy mu Std                0.6263995
Policy mu Max                3.1002016
Policy mu Min                -2.9238422
Policy log std Mean          -1.3890307
Policy log std Std           0.36878976
Policy log std Max           0.09585428
Policy log std Min           -3.5899816
Z mean eval                  1.1591678
Z variance eval              0.004891557
total_rewards                [5642.60148931 5795.48117401 5792.17271575 5746.02120289 5711.81725363
 5717.97727458 5745.80580963 5868.85430127 5872.17903963  848.85564616]
total_rewards_mean           5274.176590685778
total_rewards_std            1476.6207768315828
total_rewards_max            5872.179039629403
total_rewards_min            848.8556461576461
Number of train steps total  2432000
Number of env steps total    3042000
Number of rollouts total     0
Train Time (s)               115.13649762701243
(Previous) Eval Time (s)     23.89727962203324
Sample Time (s)              18.49897365225479
Epoch Time (s)               157.53275090130046
Total Train Time (s)         95654.56567905704
Epoch                        607
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:05:51.529118 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #607 | Epoch Duration: 158.29120564460754
2020-01-13 02:05:51.529277 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #607 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1587124
Z variance train             0.0048919925
KL Divergence                27.543766
KL Loss                      2.7543766
QF Loss                      943.1725
VF Loss                      353.40536
Policy Loss                  -2289.2168
Q Predictions Mean           2293.4324
Q Predictions Std            229.06927
Q Predictions Max            2466.6748
Q Predictions Min            -528.4977
V Predictions Mean           2286.6167
V Predictions Std            222.62349
V Predictions Max            2460.5735
V Predictions Min            -543.1189
Log Pis Mean                 2.716887
Log Pis Std                  3.5489285
Log Pis Max                  13.383715
Log Pis Min                  -6.2315273
Policy mu Mean               -0.003497656
Policy mu Std                0.59957886
Policy mu Max                2.49607
Policy mu Min                -3.1801884
Policy log std Mean          -1.4225345
Policy log std Std           0.31624845
Policy log std Max           -0.41487765
Policy log std Min           -2.9214396
Z mean eval                  1.150049
Z variance eval              0.012913732
total_rewards                [5803.52056114 5672.08560849 5685.26327526 5793.61197397 5740.72970535
 5692.29564361 5677.43728726 5808.25526543 5793.68545473 5890.42651077]
total_rewards_mean           5755.731128601734
total_rewards_std            69.57174034448796
total_rewards_max            5890.426510773593
total_rewards_min            5672.085608490572
Number of train steps total  2436000
Number of env steps total    3047000
Number of rollouts total     0
Train Time (s)               123.60621964978054
(Previous) Eval Time (s)     24.655440393369645
Sample Time (s)              18.025874490849674
Epoch Time (s)               166.28753453399986
Total Train Time (s)         95822.88930868544
Epoch                        608
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:08:39.858091 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #608 | Epoch Duration: 168.3286862373352
2020-01-13 02:08:39.858282 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #608 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1503489
Z variance train             0.012894149
KL Divergence                26.876045
KL Loss                      2.6876047
QF Loss                      682.29596
VF Loss                      285.38104
Policy Loss                  -2258.419
Q Predictions Mean           2263.7573
Q Predictions Std            363.51434
Q Predictions Max            2474.9456
Q Predictions Min            -397.03186
V Predictions Mean           2261.064
V Predictions Std            358.92972
V Predictions Max            2477.1125
V Predictions Min            -359.71414
Log Pis Mean                 2.169967
Log Pis Std                  3.1895578
Log Pis Max                  19.30442
Log Pis Min                  -6.1011047
Policy mu Mean               -0.007064038
Policy mu Std                0.60497814
Policy mu Max                3.0703797
Policy mu Min                -2.771382
Policy log std Mean          -1.3543886
Policy log std Std           0.3389362
Policy log std Max           1.5115271
Policy log std Min           -3.9936957
Z mean eval                  1.1792905
Z variance eval              0.013987842
total_rewards                [5672.25563243 1468.00451046 5716.44738026 5607.90218171 5855.24164079
 5534.21501176 5809.90531688 5718.19812453 5772.19796054 5565.39787817]
total_rewards_mean           5271.976563754064
total_rewards_std            1271.7937228412993
total_rewards_max            5855.241640791436
total_rewards_min            1468.00451046118
Number of train steps total  2440000
Number of env steps total    3052000
Number of rollouts total     0
Train Time (s)               119.69852693285793
(Previous) Eval Time (s)     26.69628448691219
Sample Time (s)              18.641656743362546
Epoch Time (s)               165.03646816313267
Total Train Time (s)         95986.0714702257
Epoch                        609
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:11:23.049472 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #609 | Epoch Duration: 163.19102334976196
2020-01-13 02:11:23.049746 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #609 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1801386
Z variance train             0.013950708
KL Divergence                26.840742
KL Loss                      2.6840742
QF Loss                      1619.3123
VF Loss                      215.6266
Policy Loss                  -2261.725
Q Predictions Mean           2270.524
Q Predictions Std            260.4251
Q Predictions Max            2446.4075
Q Predictions Min            -392.1116
V Predictions Mean           2269.2231
V Predictions Std            264.52557
V Predictions Max            2450.2334
V Predictions Min            -446.5169
Log Pis Mean                 2.707917
Log Pis Std                  3.4452457
Log Pis Max                  14.721699
Log Pis Min                  -6.7505608
Policy mu Mean               -0.0053082104
Policy mu Std                0.6264577
Policy mu Max                2.720475
Policy mu Min                -2.8242736
Policy log std Mean          -1.4239988
Policy log std Std           0.3247989
Policy log std Max           -0.30210102
Policy log std Min           -3.0273724
Z mean eval                  1.1409211
Z variance eval              0.017307546
total_rewards                [5637.51970956 5948.20200496 5845.85360162 5807.62941879 5623.73492945
 5799.08648294  324.75545765 5850.5047085  5628.80338105 5925.09957258]
total_rewards_mean           5239.118926709797
total_rewards_std            1641.9966679400022
total_rewards_max            5948.202004962112
total_rewards_min            324.75545764830633
Number of train steps total  2444000
Number of env steps total    3057000
Number of rollouts total     0
Train Time (s)               120.134377730079
(Previous) Eval Time (s)     24.850487818941474
Sample Time (s)              19.48702711611986
Epoch Time (s)               164.47189266514033
Total Train Time (s)         96150.14945463138
Epoch                        610
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:14:07.131484 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #610 | Epoch Duration: 164.081552028656
2020-01-13 02:14:07.131636 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #610 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1413543
Z variance train             0.017311268
KL Divergence                26.905508
KL Loss                      2.6905508
QF Loss                      866.9695
VF Loss                      149.81876
Policy Loss                  -2281.7258
Q Predictions Mean           2285.7227
Q Predictions Std            224.02924
Q Predictions Max            2476.7761
Q Predictions Min            -513.9418
V Predictions Mean           2280.4204
V Predictions Std            224.73366
V Predictions Max            2472.3262
V Predictions Min            -516.88354
Log Pis Mean                 3.047137
Log Pis Std                  3.7284133
Log Pis Max                  12.63324
Log Pis Min                  -7.8092823
Policy mu Mean               -0.020791726
Policy mu Std                0.6799511
Policy mu Max                2.8755224
Policy mu Min                -3.1347828
Policy log std Mean          -1.3873197
Policy log std Std           0.34786865
Policy log std Max           0.19647563
Policy log std Min           -2.7996905
Z mean eval                  1.143463
Z variance eval              0.008930263
total_rewards                [2542.66946425 5620.94146802 4726.71670639 5599.35906804 5942.66012768
 6002.02329938 2333.02149832 5941.72421446 5833.43560901 6110.02089235]
total_rewards_mean           5065.257234789451
total_rewards_std            1365.079139897818
total_rewards_max            6110.02089235087
total_rewards_min            2333.021498321941
Number of train steps total  2448000
Number of env steps total    3062000
Number of rollouts total     0
Train Time (s)               117.74114410020411
(Previous) Eval Time (s)     24.459828043356538
Sample Time (s)              18.19099896028638
Epoch Time (s)               160.39197110384703
Total Train Time (s)         96309.48239823617
Epoch                        611
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:16:46.470180 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #611 | Epoch Duration: 159.33842301368713
2020-01-13 02:16:46.470355 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #611 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1436944
Z variance train             0.008925264
KL Divergence                27.185398
KL Loss                      2.71854
QF Loss                      791.93665
VF Loss                      111.54162
Policy Loss                  -2282.4805
Q Predictions Mean           2288.2034
Q Predictions Std            245.09544
Q Predictions Max            2454.3887
Q Predictions Min            -236.47899
V Predictions Mean           2280.6748
V Predictions Std            242.93533
V Predictions Max            2441.3086
V Predictions Min            -218.3042
Log Pis Mean                 2.5288975
Log Pis Std                  3.335432
Log Pis Max                  13.182381
Log Pis Min                  -4.148897
Policy mu Mean               0.0009432556
Policy mu Std                0.60782367
Policy mu Max                3.2479422
Policy mu Min                -3.1654553
Policy log std Mean          -1.3886086
Policy log std Std           0.3128974
Policy log std Max           0.28966272
Policy log std Min           -2.7724657
Z mean eval                  1.1779928
Z variance eval              0.014170704
total_rewards                [5748.95638067 5948.24403602 5795.0211079  5841.14443095 5801.79603784
 5971.24157354 5805.99393651 5724.80842715 5934.66632517 3381.40882928]
total_rewards_mean           5595.328108503522
total_rewards_std            742.3023938753644
total_rewards_max            5971.241573540246
total_rewards_min            3381.408829283664
Number of train steps total  2452000
Number of env steps total    3067000
Number of rollouts total     0
Train Time (s)               120.54961815476418
(Previous) Eval Time (s)     23.40598903503269
Sample Time (s)              18.481709285639226
Epoch Time (s)               162.4373164754361
Total Train Time (s)         96474.21292653121
Epoch                        612
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:19:31.206581 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #612 | Epoch Duration: 164.736074924469
2020-01-13 02:19:31.206801 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #612 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1778772
Z variance train             0.014150438
KL Divergence                26.24178
KL Loss                      2.624178
QF Loss                      2520.8862
VF Loss                      232.69461
Policy Loss                  -2297.5405
Q Predictions Mean           2302.637
Q Predictions Std            208.55798
Q Predictions Max            2486.6814
Q Predictions Min            -313.41238
V Predictions Mean           2289.3823
V Predictions Std            207.58292
V Predictions Max            2466.1836
V Predictions Min            -331.736
Log Pis Mean                 2.8661957
Log Pis Std                  3.5463066
Log Pis Max                  12.081936
Log Pis Min                  -5.2628016
Policy mu Mean               0.0034847104
Policy mu Std                0.63636225
Policy mu Max                2.5703871
Policy mu Min                -2.9736013
Policy log std Mean          -1.4156272
Policy log std Std           0.3401139
Policy log std Max           0.005583048
Policy log std Min           -3.020596
Z mean eval                  1.2397653
Z variance eval              0.0057587177
total_rewards                [5730.0155962  5779.01823706 5861.24410367 5893.46817837 5864.8157838
 5907.20618151 5535.15202141 5783.22588877 5721.32595863 5837.89307194]
total_rewards_mean           5791.336502136459
total_rewards_std            105.2711704312397
total_rewards_max            5907.206181508297
total_rewards_min            5535.152021413084
Number of train steps total  2456000
Number of env steps total    3072000
Number of rollouts total     0
Train Time (s)               128.0296399500221
(Previous) Eval Time (s)     25.70444331970066
Sample Time (s)              19.03915386646986
Epoch Time (s)               172.77323713619262
Total Train Time (s)         96648.05980910873
Epoch                        613
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:22:25.057460 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #613 | Epoch Duration: 173.85051083564758
2020-01-13 02:22:25.057657 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #613 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2400669
Z variance train             0.0057599186
KL Divergence                28.605974
KL Loss                      2.8605974
QF Loss                      1136.4554
VF Loss                      291.87244
Policy Loss                  -2310.8486
Q Predictions Mean           2318.4238
Q Predictions Std            194.66936
Q Predictions Max            2477.449
Q Predictions Min            -206.42946
V Predictions Mean           2322.2427
V Predictions Std            194.13313
V Predictions Max            2492.5503
V Predictions Min            -198.48296
Log Pis Mean                 2.5435765
Log Pis Std                  3.3543923
Log Pis Max                  16.074303
Log Pis Min                  -4.531739
Policy mu Mean               -0.014971342
Policy mu Std                0.59962064
Policy mu Max                2.4904165
Policy mu Min                -3.189237
Policy log std Mean          -1.3959589
Policy log std Std           0.29954848
Policy log std Max           -0.17336941
Policy log std Min           -2.9420247
Z mean eval                  1.1910512
Z variance eval              0.0046997443
total_rewards                [5632.55961414 5883.80706298 5704.63891142 5987.77059232 5821.18229069
 5737.17743967 5915.65062326 5947.65034353 5710.66843261 5792.08451057]
total_rewards_mean           5813.318982119194
total_rewards_std            111.91573810755361
total_rewards_max            5987.770592315708
total_rewards_min            5632.559614140995
Number of train steps total  2460000
Number of env steps total    3077000
Number of rollouts total     0
Train Time (s)               121.85346935968846
(Previous) Eval Time (s)     26.78140670573339
Sample Time (s)              18.679771010298282
Epoch Time (s)               167.31464707572013
Total Train Time (s)         96815.84923206875
Epoch                        614
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:25:12.851780 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #614 | Epoch Duration: 167.79397821426392
2020-01-13 02:25:12.851986 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #614 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1893412
Z variance train             0.004702472
KL Divergence                28.202652
KL Loss                      2.8202653
QF Loss                      638.0564
VF Loss                      153.10216
Policy Loss                  -2260.8696
Q Predictions Mean           2260.7808
Q Predictions Std            324.55945
Q Predictions Max            2881.113
Q Predictions Min            -379.55624
V Predictions Mean           2256.5342
V Predictions Std            323.1434
V Predictions Max            2937.272
V Predictions Min            -404.1606
Log Pis Mean                 2.912414
Log Pis Std                  3.1841877
Log Pis Max                  19.13018
Log Pis Min                  -3.0044494
Policy mu Mean               -0.026104778
Policy mu Std                0.602881
Policy mu Max                2.7838864
Policy mu Min                -2.543811
Policy log std Mean          -1.4326057
Policy log std Std           0.32112363
Policy log std Max           -0.088377
Policy log std Min           -2.8863873
Z mean eval                  1.184596
Z variance eval              0.004014133
total_rewards                [5770.16876874 2107.39755802 5797.50831725 5702.45686738 5683.67854396
 5604.31851215 5765.29157058 5684.09861513 5855.69017081 5763.84064524]
total_rewards_mean           5373.444956926725
total_rewards_std            1090.7382887920808
total_rewards_max            5855.690170813923
total_rewards_min            2107.3975580154647
Number of train steps total  2464000
Number of env steps total    3082000
Number of rollouts total     0
Train Time (s)               121.92319657281041
(Previous) Eval Time (s)     27.260413892101496
Sample Time (s)              18.490418033208698
Epoch Time (s)               167.6740284981206
Total Train Time (s)         96981.58283014921
Epoch                        615
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:27:58.593418 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #615 | Epoch Duration: 165.7412657737732
2020-01-13 02:27:58.593681 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #615 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1830777
Z variance train             0.00401634
KL Divergence                27.490875
KL Loss                      2.7490876
QF Loss                      694.53564
VF Loss                      116.756355
Policy Loss                  -2294.2654
Q Predictions Mean           2295.3032
Q Predictions Std            310.22232
Q Predictions Max            2474.6584
Q Predictions Min            -603.7182
V Predictions Mean           2298.0986
V Predictions Std            309.5279
V Predictions Max            2498.413
V Predictions Min            -580.03
Log Pis Mean                 2.239203
Log Pis Std                  3.6016338
Log Pis Max                  14.638771
Log Pis Min                  -7.445985
Policy mu Mean               -0.0004156424
Policy mu Std                0.5989605
Policy mu Max                2.4414606
Policy mu Min                -2.9345918
Policy log std Mean          -1.3795797
Policy log std Std           0.33495414
Policy log std Max           -0.23356104
Policy log std Min           -3.067625
Z mean eval                  1.1339375
Z variance eval              0.007561528
total_rewards                [5567.43347456 5880.57158815 5880.60165486 5828.70877673 5717.88231607
 5776.26115352 4451.41390651 5779.41815891 5814.43918683 5777.42108893]
total_rewards_mean           5647.415130506635
total_rewards_std            407.70229017649405
total_rewards_max            5880.601654856066
total_rewards_min            4451.41390650519
Number of train steps total  2468000
Number of env steps total    3087000
Number of rollouts total     0
Train Time (s)               120.97047932818532
(Previous) Eval Time (s)     25.327330416999757
Sample Time (s)              18.28523815702647
Epoch Time (s)               164.58304790221155
Total Train Time (s)         97147.30572618637
Epoch                        616
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:30:44.321550 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #616 | Epoch Duration: 165.72768664360046
2020-01-13 02:30:44.321728 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #616 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1336391
Z variance train             0.0075598224
KL Divergence                26.63515
KL Loss                      2.663515
QF Loss                      1389.321
VF Loss                      170.71234
Policy Loss                  -2308.085
Q Predictions Mean           2310.102
Q Predictions Std            182.31842
Q Predictions Max            2498.4783
Q Predictions Min            368.6957
V Predictions Mean           2303.1533
V Predictions Std            176.6545
V Predictions Max            2480.7327
V Predictions Min            486.16995
Log Pis Mean                 2.8547053
Log Pis Std                  3.4191353
Log Pis Max                  13.889629
Log Pis Min                  -6.270166
Policy mu Mean               0.012492638
Policy mu Std                0.66126466
Policy mu Max                2.6736038
Policy mu Min                -3.0234952
Policy log std Mean          -1.3859929
Policy log std Std           0.34809116
Policy log std Max           -0.14602911
Policy log std Min           -3.115146
Z mean eval                  1.1349978
Z variance eval              0.014107181
total_rewards                [5719.98595886 6002.78031146 5945.89855946 5622.85100432 5804.38507722
 5970.89423906 5777.71790544 5944.42223212 5700.22423925 5931.52951874]
total_rewards_mean           5842.0689045927265
total_rewards_std            126.61986018447945
total_rewards_max            6002.780311461867
total_rewards_min            5622.851004318671
Number of train steps total  2472000
Number of env steps total    3092000
Number of rollouts total     0
Train Time (s)               124.56950795231387
(Previous) Eval Time (s)     26.47165582701564
Sample Time (s)              18.523146450985223
Epoch Time (s)               169.56431023031473
Total Train Time (s)         97317.70248323912
Epoch                        617
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:33:34.727597 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #617 | Epoch Duration: 170.40570425987244
2020-01-13 02:33:34.727898 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #617 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1339799
Z variance train             0.0141130565
KL Divergence                26.142105
KL Loss                      2.6142106
QF Loss                      839.1927
VF Loss                      114.384796
Policy Loss                  -2320.745
Q Predictions Mean           2326.0825
Q Predictions Std            117.52307
Q Predictions Max            2482.743
Q Predictions Min            1837.6517
V Predictions Mean           2317.6934
V Predictions Std            116.02836
V Predictions Max            2475.3687
V Predictions Min            1840.1154
Log Pis Mean                 2.9310484
Log Pis Std                  3.7666206
Log Pis Max                  13.472878
Log Pis Min                  -7.034295
Policy mu Mean               -0.020390749
Policy mu Std                0.6532103
Policy mu Max                3.2462473
Policy mu Min                -3.1835926
Policy log std Mean          -1.4109623
Policy log std Std           0.3151422
Policy log std Max           -0.24130213
Policy log std Min           -2.9247818
Z mean eval                  1.1890085
Z variance eval              0.009134082
total_rewards                [5491.35331846 5739.96189727 5805.74100495 5915.63993869 5706.83653751
 5853.37296027 5722.21871282 5717.75544169 5810.81427922 5802.88027033]
total_rewards_mean           5756.657436120933
total_rewards_std            108.606891198133
total_rewards_max            5915.639938688619
total_rewards_min            5491.353318463806
Number of train steps total  2476000
Number of env steps total    3097000
Number of rollouts total     0
Train Time (s)               117.34203111939132
(Previous) Eval Time (s)     27.312712540850043
Sample Time (s)              18.679489395115525
Epoch Time (s)               163.3342330553569
Total Train Time (s)         97481.38423844054
Epoch                        618
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:36:18.434581 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #618 | Epoch Duration: 163.706449508667
2020-01-13 02:36:18.434858 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #618 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1895832
Z variance train             0.009147508
KL Divergence                26.311577
KL Loss                      2.6311576
QF Loss                      1101.4711
VF Loss                      292.2551
Policy Loss                  -2275.3923
Q Predictions Mean           2274.9014
Q Predictions Std            289.1218
Q Predictions Max            2463.2864
Q Predictions Min            102.8671
V Predictions Mean           2276.6975
V Predictions Std            283.5021
V Predictions Max            2471.9636
V Predictions Min            154.26917
Log Pis Mean                 3.1223407
Log Pis Std                  4.0795355
Log Pis Max                  38.469032
Log Pis Min                  -4.770828
Policy mu Mean               -0.019383054
Policy mu Std                0.6457667
Policy mu Max                7.6388674
Policy mu Min                -4.0609922
Policy log std Mean          -1.4618728
Policy log std Std           0.37050748
Policy log std Max           -0.2840613
Policy log std Min           -3.8224392
Z mean eval                  1.1632736
Z variance eval              0.006465488
total_rewards                [5831.06192776 5857.41840905 5757.85122433    6.8962105  5659.14902992
 5894.02082757 5890.71833588 2912.06385386 5949.52884288 5593.19514895]
total_rewards_mean           4935.190381070747
total_rewards_std            1858.2073085639036
total_rewards_max            5949.528842880458
total_rewards_min            6.896210504550087
Number of train steps total  2480000
Number of env steps total    3102000
Number of rollouts total     0
Train Time (s)               121.54100988106802
(Previous) Eval Time (s)     27.684592645149678
Sample Time (s)              18.493622629437596
Epoch Time (s)               167.7192251556553
Total Train Time (s)         97644.0783069944
Epoch                        619
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:39:01.136193 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #619 | Epoch Duration: 162.70106840133667
2020-01-13 02:39:01.136530 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #619 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1651691
Z variance train             0.0064559677
KL Divergence                26.654722
KL Loss                      2.6654723
QF Loss                      2090.7964
VF Loss                      457.1486
Policy Loss                  -2288.8774
Q Predictions Mean           2286.6792
Q Predictions Std            248.52458
Q Predictions Max            2463.8394
Q Predictions Min            -37.817993
V Predictions Mean           2295.3235
V Predictions Std            210.1453
V Predictions Max            2446.9253
V Predictions Min            73.06371
Log Pis Mean                 3.0143433
Log Pis Std                  3.7260418
Log Pis Max                  23.007095
Log Pis Min                  -6.622867
Policy mu Mean               0.025262855
Policy mu Std                0.65744793
Policy mu Max                2.5969675
Policy mu Min                -3.145741
Policy log std Mean          -1.4019554
Policy log std Std           0.34231344
Policy log std Max           0.32764637
Policy log std Min           -2.9746027
Z mean eval                  1.1984646
Z variance eval              0.005328939
total_rewards                [5642.72842123 5812.11451517 5743.21555664    7.29071073 5744.65943923
 5652.48371388 5995.82536543 5502.37031469 5776.37689906 5877.72360666]
total_rewards_mean           5175.478854272939
total_rewards_std            1727.474269705763
total_rewards_max            5995.825365427321
total_rewards_min            7.290710729858182
Number of train steps total  2484000
Number of env steps total    3107000
Number of rollouts total     0
Train Time (s)               118.63939919369295
(Previous) Eval Time (s)     22.666093346197158
Sample Time (s)              18.37818663707003
Epoch Time (s)               159.68367917696014
Total Train Time (s)         97805.9107529358
Epoch                        620
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:41:42.973279 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #620 | Epoch Duration: 161.83656191825867
2020-01-13 02:41:42.973463 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #620 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1990153
Z variance train             0.005316179
KL Divergence                25.881294
KL Loss                      2.5881295
QF Loss                      1242.5193
VF Loss                      306.8843
Policy Loss                  -2287.9585
Q Predictions Mean           2290.8406
Q Predictions Std            211.06284
Q Predictions Max            2494.7925
Q Predictions Min            -311.22855
V Predictions Mean           2282.8716
V Predictions Std            213.05878
V Predictions Max            2898.7014
V Predictions Min            -307.18225
Log Pis Mean                 2.5841765
Log Pis Std                  3.4350991
Log Pis Max                  14.841021
Log Pis Min                  -4.5112457
Policy mu Mean               0.0046350593
Policy mu Std                0.5943863
Policy mu Max                3.3898177
Policy mu Min                -2.7136798
Policy log std Mean          -1.396219
Policy log std Std           0.32855237
Policy log std Max           0.27286077
Policy log std Min           -3.0614483
Z mean eval                  1.2080283
Z variance eval              0.008702353
total_rewards                [5575.110997   5929.12429214 4242.13697728 5878.98848867 5668.94064885
 5628.15594268 5822.17435328 5943.70327028 5851.75444466  115.41517599]
total_rewards_mean           5065.550459083707
total_rewards_std            1717.3029917026647
total_rewards_max            5943.7032702822235
total_rewards_min            115.41517599469304
Number of train steps total  2488000
Number of env steps total    3112000
Number of rollouts total     0
Train Time (s)               121.05124292895198
(Previous) Eval Time (s)     24.818674594163895
Sample Time (s)              18.22896213689819
Epoch Time (s)               164.09887966001406
Total Train Time (s)         97969.90400017519
Epoch                        621
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:44:26.972508 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #621 | Epoch Duration: 163.99884295463562
2020-01-13 02:44:26.972799 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #621 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2121204
Z variance train             0.008734399
KL Divergence                25.656002
KL Loss                      2.5656002
QF Loss                      805.8247
VF Loss                      257.3183
Policy Loss                  -2281.6567
Q Predictions Mean           2287.6968
Q Predictions Std            195.20586
Q Predictions Max            2475.3645
Q Predictions Min            200.86864
V Predictions Mean           2287.3481
V Predictions Std            198.74689
V Predictions Max            2457.734
V Predictions Min            163.12729
Log Pis Mean                 2.8693566
Log Pis Std                  3.3855796
Log Pis Max                  17.051138
Log Pis Min                  -4.128888
Policy mu Mean               -0.007733942
Policy mu Std                0.62958807
Policy mu Max                2.7034724
Policy mu Min                -3.5213645
Policy log std Mean          -1.4079313
Policy log std Std           0.31472915
Policy log std Max           -0.03629327
Policy log std Min           -3.052507
Z mean eval                  1.187669
Z variance eval              0.00645795
total_rewards                [5643.43099759 5707.69092074 2572.41995446 5516.85191524 5535.6652286
 5597.42493405 5708.37798172 5687.34681357 5688.04238501    9.27327085]
total_rewards_mean           4766.652440182085
total_rewards_std            1831.1049733909351
total_rewards_max            5708.377981721986
total_rewards_min            9.27327084614376
Number of train steps total  2492000
Number of env steps total    3117000
Number of rollouts total     0
Train Time (s)               120.50729539990425
(Previous) Eval Time (s)     24.71830986905843
Sample Time (s)              18.0131789566949
Epoch Time (s)               163.23878422565758
Total Train Time (s)         98132.22777242586
Epoch                        622
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:47:09.302277 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #622 | Epoch Duration: 162.32931351661682
2020-01-13 02:47:09.302473 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #622 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1884115
Z variance train             0.0064475387
KL Divergence                26.559519
KL Loss                      2.655952
QF Loss                      1458.7753
VF Loss                      196.7187
Policy Loss                  -2279.8325
Q Predictions Mean           2281.4082
Q Predictions Std            356.73596
Q Predictions Max            4700.355
Q Predictions Min            -20.919863
V Predictions Mean           2284.9243
V Predictions Std            353.31613
V Predictions Max            4880.1426
V Predictions Min            91.36799
Log Pis Mean                 2.9968767
Log Pis Std                  3.7829833
Log Pis Max                  24.938374
Log Pis Min                  -3.3980877
Policy mu Mean               -0.0029226814
Policy mu Std                0.6601465
Policy mu Max                4.2535086
Policy mu Min                -4.2521496
Policy log std Mean          -1.4031265
Policy log std Std           0.35094255
Policy log std Max           0.06481063
Policy log std Min           -3.8665164
Z mean eval                  1.1292067
Z variance eval              0.017219882
total_rewards                [5635.52729948 5847.329574   5767.86515483 5916.51298332 5817.76238948
 5600.95302798 5773.30587667 5782.62224363 5739.98176514 5647.06574734]
total_rewards_mean           5752.892606186875
total_rewards_std            94.68318339000936
total_rewards_max            5916.512983322228
total_rewards_min            5600.9530279773
Number of train steps total  2496000
Number of env steps total    3122000
Number of rollouts total     0
Train Time (s)               117.650181947276
(Previous) Eval Time (s)     23.80851532984525
Sample Time (s)              19.241493945010006
Epoch Time (s)               160.70019122213125
Total Train Time (s)         98296.2750102086
Epoch                        623
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:49:53.353546 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #623 | Epoch Duration: 164.05092525482178
2020-01-13 02:49:53.353762 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #623 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1295779
Z variance train             0.01722144
KL Divergence                25.053719
KL Loss                      2.5053718
QF Loss                      746.2091
VF Loss                      128.05402
Policy Loss                  -2348.7473
Q Predictions Mean           2352.1738
Q Predictions Std            209.15732
Q Predictions Max            2525.7
Q Predictions Min            -73.10419
V Predictions Mean           2352.7625
V Predictions Std            212.46463
V Predictions Max            2526.2712
V Predictions Min            -155.09929
Log Pis Mean                 2.3940816
Log Pis Std                  3.371083
Log Pis Max                  12.286114
Log Pis Min                  -7.7332907
Policy mu Mean               0.026475824
Policy mu Std                0.6267045
Policy mu Max                3.565074
Policy mu Min                -2.7756615
Policy log std Mean          -1.3532213
Policy log std Std           0.30676663
Policy log std Max           -0.060068488
Policy log std Min           -2.9354522
Z mean eval                  1.1257662
Z variance eval              0.012418795
total_rewards                [5405.61031431 5490.19514692 5682.47483685 2372.71860125 5757.80910401
 5546.08699149 5756.5573748  5506.23901109 5754.6711341  5732.3002779 ]
total_rewards_mean           5300.466279270533
total_rewards_std            983.7339816361495
total_rewards_max            5757.809104006
total_rewards_min            2372.7186012486986
Number of train steps total  2500000
Number of env steps total    3127000
Number of rollouts total     0
Train Time (s)               120.41293746838346
(Previous) Eval Time (s)     27.158958171028644
Sample Time (s)              18.944076468702406
Epoch Time (s)               166.5159721081145
Total Train Time (s)         98460.9246851434
Epoch                        624
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:52:38.013936 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #624 | Epoch Duration: 164.65998768806458
2020-01-13 02:52:38.014210 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #624 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.12596
Z variance train             0.012422664
KL Divergence                25.176865
KL Loss                      2.5176866
QF Loss                      7354.213
VF Loss                      10332.791
Policy Loss                  -2340.7463
Q Predictions Mean           2349.4214
Q Predictions Std            248.43018
Q Predictions Max            4895.603
Q Predictions Min            278.1837
V Predictions Mean           2342.4624
V Predictions Std            242.04335
V Predictions Max            4926.2964
V Predictions Min            192.16516
Log Pis Mean                 2.7526588
Log Pis Std                  3.4118364
Log Pis Max                  15.739299
Log Pis Min                  -6.6930265
Policy mu Mean               0.00021883077
Policy mu Std                0.61387354
Policy mu Max                2.5138655
Policy mu Min                -2.7864945
Policy log std Mean          -1.3942575
Policy log std Std           0.31598797
Policy log std Max           -0.15120995
Policy log std Min           -3.0022464
Z mean eval                  1.170116
Z variance eval              0.0042917347
total_rewards                [5987.53398896 5893.4955478  5672.13009219 5875.03836224 5834.99228898
 2534.393461   5852.70680309 5585.11018959 2720.62029258 5930.24907547]
total_rewards_mean           5188.627010191849
total_rewards_std            1286.1583466501447
total_rewards_max            5987.533988957738
total_rewards_min            2534.393461003014
Number of train steps total  2504000
Number of env steps total    3132000
Number of rollouts total     0
Train Time (s)               121.5054709087126
(Previous) Eval Time (s)     25.30262631876394
Sample Time (s)              18.727361440192908
Epoch Time (s)               165.53545866766945
Total Train Time (s)         98625.60926134838
Epoch                        625
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:55:22.701110 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #625 | Epoch Duration: 164.68671345710754
2020-01-13 02:55:22.701273 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #625 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1721678
Z variance train             0.0042962143
KL Divergence                26.343224
KL Loss                      2.6343224
QF Loss                      10402.235
VF Loss                      334.56763
Policy Loss                  -2292.3818
Q Predictions Mean           2296.5354
Q Predictions Std            260.95267
Q Predictions Max            2477.5315
Q Predictions Min            -30.428661
V Predictions Mean           2292.6304
V Predictions Std            252.15106
V Predictions Max            2474.9028
V Predictions Min            -121.64991
Log Pis Mean                 3.1445167
Log Pis Std                  3.560246
Log Pis Max                  17.218563
Log Pis Min                  -5.2070932
Policy mu Mean               0.014479807
Policy mu Std                0.6658431
Policy mu Max                3.140597
Policy mu Min                -5.5364165
Policy log std Mean          -1.3832843
Policy log std Std           0.34117487
Policy log std Max           1.8179383
Policy log std Min           -2.8666334
Z mean eval                  1.1350142
Z variance eval              0.004298293
total_rewards                [5410.59413473 5669.586278   5689.69693044 5767.13349689 5736.35783781
 5677.16674511 5776.59790975 5676.77288632 5562.97674426 5807.01993659]
total_rewards_mean           5677.390289989709
total_rewards_std            110.75217697564466
total_rewards_max            5807.019936585667
total_rewards_min            5410.59413472565
Number of train steps total  2508000
Number of env steps total    3137000
Number of rollouts total     0
Train Time (s)               122.06392347207293
(Previous) Eval Time (s)     24.453571722842753
Sample Time (s)              17.844314869958907
Epoch Time (s)               164.3618100648746
Total Train Time (s)         98792.20395435998
Epoch                        626
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:58:09.299476 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #626 | Epoch Duration: 166.59808492660522
2020-01-13 02:58:09.299667 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #626 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.134244
Z variance train             0.0042966595
KL Divergence                27.451294
KL Loss                      2.7451293
QF Loss                      570.84045
VF Loss                      791.6314
Policy Loss                  -2311.5745
Q Predictions Mean           2312.98
Q Predictions Std            215.53998
Q Predictions Max            2516.801
Q Predictions Min            660.38513
V Predictions Mean           2308.7407
V Predictions Std            219.02182
V Predictions Max            2515.5784
V Predictions Min            681.2104
Log Pis Mean                 2.5665848
Log Pis Std                  3.5014343
Log Pis Max                  16.874182
Log Pis Min                  -5.764716
Policy mu Mean               -0.004455645
Policy mu Std                0.64844203
Policy mu Max                3.313606
Policy mu Min                -2.762828
Policy log std Mean          -1.3872025
Policy log std Std           0.33593276
Policy log std Max           -0.12187326
Policy log std Min           -2.9605055
Z mean eval                  1.1821862
Z variance eval              0.0039556245
total_rewards                [5745.3311695  5848.13584942 5701.5360867  5743.2125878  5946.43847944
 5761.34561657 5797.78620023 5765.33275546 5764.64833241 5742.57601074]
total_rewards_mean           5781.634308827735
total_rewards_std            65.98868890252206
total_rewards_max            5946.438479444329
total_rewards_min            5701.536086697986
Number of train steps total  2512000
Number of env steps total    3142000
Number of rollouts total     0
Train Time (s)               122.02764376578853
(Previous) Eval Time (s)     26.68958051595837
Sample Time (s)              17.987125683110207
Epoch Time (s)               166.7043499648571
Total Train Time (s)         98959.12574580358
Epoch                        627
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:00:56.228684 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #627 | Epoch Duration: 166.92887949943542
2020-01-13 03:00:56.228912 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #627 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1824389
Z variance train             0.0039524753
KL Divergence                28.063738
KL Loss                      2.8063738
QF Loss                      720.87537
VF Loss                      234.56201
Policy Loss                  -2348.6812
Q Predictions Mean           2350.0044
Q Predictions Std            138.25336
Q Predictions Max            2829.7415
Q Predictions Min            1326.0497
V Predictions Mean           2346.1162
V Predictions Std            128.32133
V Predictions Max            2884.6528
V Predictions Min            1776.1501
Log Pis Mean                 3.0205812
Log Pis Std                  3.5052385
Log Pis Max                  12.303505
Log Pis Min                  -6.82602
Policy mu Mean               0.031808577
Policy mu Std                0.6603183
Policy mu Max                2.9458714
Policy mu Min                -2.7677982
Policy log std Mean          -1.397159
Policy log std Std           0.3265306
Policy log std Max           -0.006716132
Policy log std Min           -2.9060993
Z mean eval                  1.1820433
Z variance eval              0.0038832165
total_rewards                [5557.00890748   50.44637566  897.89457413 -463.58711428 4530.01962491
 5438.22353833 1880.59056983 5829.47582257 5894.30777502 1580.26499819]
total_rewards_mean           3119.4645071834084
total_rewards_std            2438.2021311004346
total_rewards_max            5894.307775022851
total_rewards_min            -463.5871142807426
Number of train steps total  2516000
Number of env steps total    3147000
Number of rollouts total     0
Train Time (s)               121.00885845720768
(Previous) Eval Time (s)     26.913800821173936
Sample Time (s)              18.139395914040506
Epoch Time (s)               166.06205519242212
Total Train Time (s)         99116.10249271011
Epoch                        628
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:03:33.210726 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #628 | Epoch Duration: 156.98160600662231
2020-01-13 03:03:33.211013 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #628 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1816037
Z variance train             0.0038758074
KL Divergence                27.306614
KL Loss                      2.7306614
QF Loss                      875.45215
VF Loss                      231.72504
Policy Loss                  -2357.253
Q Predictions Mean           2362.862
Q Predictions Std            157.1929
Q Predictions Max            3348.2893
Q Predictions Min            1203.6459
V Predictions Mean           2351.872
V Predictions Std            163.15906
V Predictions Max            3492.7822
V Predictions Min            1223.6177
Log Pis Mean                 2.4883044
Log Pis Std                  3.40984
Log Pis Max                  18.720104
Log Pis Min                  -5.9005995
Policy mu Mean               -0.009785267
Policy mu Std                0.62510926
Policy mu Max                3.1040673
Policy mu Min                -3.7448437
Policy log std Mean          -1.3545532
Policy log std Std           0.3171232
Policy log std Max           -0.047405243
Policy log std Min           -3.0321867
Z mean eval                  1.2948687
Z variance eval              0.01088053
total_rewards                [-2067.05173783 -1972.39645578 -1951.27782966 -1970.49230714
 -1952.76617468 -1901.87240918 -1878.15566535 -1900.91507439
 -1992.5226434  -1975.35200906]
total_rewards_mean           -1956.280230647551
total_rewards_std            51.551546747155186
total_rewards_max            -1878.1556653539958
total_rewards_min            -2067.0517378339073
Number of train steps total  2520000
Number of env steps total    3152000
Number of rollouts total     0
Train Time (s)               123.57082748506218
(Previous) Eval Time (s)     17.833019797690213
Sample Time (s)              17.90970005467534
Epoch Time (s)               159.31354733742774
Total Train Time (s)         99285.63242059248
Epoch                        629
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:06:22.747192 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #629 | Epoch Duration: 169.53595542907715
2020-01-13 03:06:22.747420 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #629 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2926702
Z variance train             0.010975599
KL Divergence                26.908058
KL Loss                      2.690806
QF Loss                      14444.098
VF Loss                      4924.2607
Policy Loss                  -3371.869
Q Predictions Mean           3218.6
Q Predictions Std            334.4869
Q Predictions Max            4388.639
Q Predictions Min            2020.737
V Predictions Mean           3398.4844
V Predictions Std            375.35916
V Predictions Max            4778.2095
V Predictions Min            2139.806
Log Pis Mean                 13.927819
Log Pis Std                  5.16913
Log Pis Max                  36.227524
Log Pis Min                  -0.66497993
Policy mu Mean               -0.03187456
Policy mu Std                1.7788051
Policy mu Max                5.1980376
Policy mu Min                -4.8902316
Policy log std Mean          -1.2564237
Policy log std Std           0.5949325
Policy log std Max           0.8485557
Policy log std Min           -3.3877316
Z mean eval                  1.4279453
Z variance eval              0.04660577
total_rewards                [-1462.5244854  -1220.21299045 -2528.47657741 -1268.19601657
 -1442.52282447 -1475.14544059  -860.06476744 -1446.38943095
 -1512.52039054 -1475.99763993]
total_rewards_mean           -1469.2050563745674
total_rewards_std            399.84303166029235
total_rewards_max            -860.0647674419871
total_rewards_min            -2528.476577408767
Number of train steps total  2524000
Number of env steps total    3157000
Number of rollouts total     0
Train Time (s)               119.0880205463618
(Previous) Eval Time (s)     28.05515727913007
Sample Time (s)              18.07102604722604
Epoch Time (s)               165.21420387271792
Total Train Time (s)         99449.29420734895
Epoch                        630
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:09:06.417245 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #630 | Epoch Duration: 163.6696422100067
2020-01-13 03:09:06.417492 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #630 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4278953
Z variance train             0.046490777
KL Divergence                27.18825
KL Loss                      2.718825
QF Loss                      9212.834
VF Loss                      2536.0005
Policy Loss                  -4552.535
Q Predictions Mean           4515.533
Q Predictions Std            446.4739
Q Predictions Max            5183.1987
Q Predictions Min            -40.7299
V Predictions Mean           4579.6787
V Predictions Std            461.64966
V Predictions Max            5350.4014
V Predictions Min            -82.77336
Log Pis Mean                 7.6312494
Log Pis Std                  5.0018473
Log Pis Max                  30.392126
Log Pis Min                  -2.6288047
Policy mu Mean               -0.16165793
Policy mu Std                1.1220409
Policy mu Max                4.2151995
Policy mu Min                -4.9440894
Policy log std Mean          -1.5326177
Policy log std Std           0.47820592
Policy log std Max           0.13652337
Policy log std Min           -3.2106824
Z mean eval                  1.4281436
Z variance eval              0.031939156
total_rewards                [-2214.07773358 -1492.51919675 -1674.58133561 -2198.64202019
 -2069.81043745 -1528.78663224 -1765.53671583 -1843.99042971
 -2293.91210039 -1816.96043211]
total_rewards_mean           -1889.8817033846276
total_rewards_std            274.513563864223
total_rewards_max            -1492.5191967484257
total_rewards_min            -2293.912100393041
Number of train steps total  2528000
Number of env steps total    3162000
Number of rollouts total     0
Train Time (s)               117.80075185699388
(Previous) Eval Time (s)     26.510291415266693
Sample Time (s)              18.01185842556879
Epoch Time (s)               162.32290169782937
Total Train Time (s)         99612.69693954242
Epoch                        631
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:11:49.825808 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #631 | Epoch Duration: 163.40813207626343
2020-01-13 03:11:49.825993 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #631 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4292353
Z variance train             0.03193836
KL Divergence                27.298958
KL Loss                      2.7298958
QF Loss                      93178.9
VF Loss                      1356.2944
Policy Loss                  -4970.854
Q Predictions Mean           4955.678
Q Predictions Std            240.33655
Q Predictions Max            5376.122
Q Predictions Min            3090.2158
V Predictions Mean           4972.5625
V Predictions Std            214.64444
V Predictions Max            5402.2305
V Predictions Min            3979.6282
Log Pis Mean                 5.846672
Log Pis Std                  3.840687
Log Pis Max                  16.103447
Log Pis Min                  -2.6721492
Policy mu Mean               -0.02185137
Policy mu Std                0.96342164
Policy mu Max                3.4217165
Policy mu Min                -3.613663
Policy log std Mean          -1.4551843
Policy log std Std           0.40958983
Policy log std Max           0.0057047606
Policy log std Min           -2.8754182
Z mean eval                  1.2744124
Z variance eval              0.04286409
total_rewards                [-1258.73885393 -1074.3003743  -1158.24209487 -1149.84213297
 -1072.93007905 -1174.7442721  -1003.74698227 -1103.33154765
     2.10670203 -1140.34173811]
total_rewards_mean           -1013.4111373226473
total_rewards_std            344.76374967519075
total_rewards_max            2.1067020295435874
total_rewards_min            -1258.7388539321894
Number of train steps total  2532000
Number of env steps total    3167000
Number of rollouts total     0
Train Time (s)               119.39709299989045
(Previous) Eval Time (s)     27.59521156270057
Sample Time (s)              18.58649272052571
Epoch Time (s)               165.57879728311673
Total Train Time (s)         99775.63618744863
Epoch                        632
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:14:32.773079 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #632 | Epoch Duration: 162.9469256401062
2020-01-13 03:14:32.773321 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #632 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2747816
Z variance train             0.042856395
KL Divergence                26.737656
KL Loss                      2.6737657
QF Loss                      5299.626
VF Loss                      855.5885
Policy Loss                  -4763.6426
Q Predictions Mean           4762.494
Q Predictions Std            251.55116
Q Predictions Max            5029.0835
Q Predictions Min            2445.7278
V Predictions Mean           4747.864
V Predictions Std            263.218
V Predictions Max            5004.118
V Predictions Min            2039.8217
Log Pis Mean                 4.5854015
Log Pis Std                  3.6488883
Log Pis Max                  15.168493
Log Pis Min                  -5.2738404
Policy mu Mean               -0.14410205
Policy mu Std                0.81889933
Policy mu Max                2.6990566
Policy mu Min                -3.9709263
Policy log std Mean          -1.4524524
Policy log std Std           0.3939417
Policy log std Max           0.11453748
Policy log std Min           -2.6863203
Z mean eval                  1.338257
Z variance eval              0.021357525
total_rewards                [ -947.95921556   186.8642454    426.10247446  -713.37338692
  -475.56161554 -1017.44415324  -492.37538934 -1027.6101546
  -693.73033754  -736.46969286]
total_rewards_mean           -549.155722573335
total_rewards_std            468.1566779251448
total_rewards_max            426.1024744634269
total_rewards_min            -1027.610154600388
Number of train steps total  2536000
Number of env steps total    3172000
Number of rollouts total     0
Train Time (s)               122.19198662927374
(Previous) Eval Time (s)     24.96302886120975
Sample Time (s)              18.88784347102046
Epoch Time (s)               166.04285896150395
Total Train Time (s)         99939.57139969058
Epoch                        633
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:17:16.713044 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #633 | Epoch Duration: 163.9395453929901
2020-01-13 03:17:16.713268 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #633 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3385456
Z variance train             0.021350453
KL Divergence                27.63509
KL Loss                      2.763509
QF Loss                      1065.5276
VF Loss                      356.12326
Policy Loss                  -4405.076
Q Predictions Mean           4404.915
Q Predictions Std            191.9267
Q Predictions Max            4597.1855
Q Predictions Min            2930.6147
V Predictions Mean           4403.657
V Predictions Std            185.73503
V Predictions Max            4583.1025
V Predictions Min            3009.0137
Log Pis Mean                 3.5557415
Log Pis Std                  3.5438209
Log Pis Max                  15.547058
Log Pis Min                  -7.3785524
Policy mu Mean               0.03232894
Policy mu Std                0.72273976
Policy mu Max                2.990105
Policy mu Min                -3.3663526
Policy log std Mean          -1.4361666
Policy log std Std           0.3681103
Policy log std Max           -0.15049708
Policy log std Min           -2.713861
Z mean eval                  1.2671831
Z variance eval              0.014457876
total_rewards                [  -30.92134201   -27.1837183   2983.7007621  -1077.02947616
 -1197.64305049  4097.50629172 -1129.80767229  -445.59935667
 -1135.10153764 -1133.9070626 ]
total_rewards_mean           90.40138376551599
total_rewards_std            1795.9834434049883
total_rewards_max            4097.506291724566
total_rewards_min            -1197.6430504868988
Number of train steps total  2540000
Number of env steps total    3177000
Number of rollouts total     0
Train Time (s)               119.51166370278224
(Previous) Eval Time (s)     22.85938688600436
Sample Time (s)              18.26389755308628
Epoch Time (s)               160.63494814187288
Total Train Time (s)         100102.14308763947
Epoch                        634
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:19:59.288402 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #634 | Epoch Duration: 162.57499837875366
2020-01-13 03:19:59.288549 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #634 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2667547
Z variance train             0.014500536
KL Divergence                27.86583
KL Loss                      2.786583
QF Loss                      3472.6313
VF Loss                      690.6992
Policy Loss                  -3875.7366
Q Predictions Mean           3874.2544
Q Predictions Std            297.4387
Q Predictions Max            4066.8723
Q Predictions Min            -2.9987159
V Predictions Mean           3879.4688
V Predictions Std            309.69717
V Predictions Max            4068.3997
V Predictions Min            -310.00772
Log Pis Mean                 3.7117996
Log Pis Std                  3.6474645
Log Pis Max                  22.37821
Log Pis Min                  -8.217907
Policy mu Mean               0.01810208
Policy mu Std                0.6888159
Policy mu Max                3.5405548
Policy mu Min                -6.4626837
Policy log std Mean          -1.483577
Policy log std Std           0.35380352
Policy log std Max           1.3613684
Policy log std Min           -3.3310034
Z mean eval                  1.2751788
Z variance eval              0.017948937
total_rewards                [ 4945.47669485  5073.71464251  5168.71185765  -169.08826662
   968.25130849  -621.86337286  2880.44958666 -1154.42436092
    34.126809    4882.35649708]
total_rewards_mean           2200.771139582655
total_rewards_std            2516.0094736496785
total_rewards_max            5168.711857645121
total_rewards_min            -1154.4243609242633
Number of train steps total  2544000
Number of env steps total    3182000
Number of rollouts total     0
Train Time (s)               126.4245964307338
(Previous) Eval Time (s)     24.799144903197885
Sample Time (s)              17.926200028974563
Epoch Time (s)               169.14994136290625
Total Train Time (s)         100270.83012476843
Epoch                        635
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:22:47.980633 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #635 | Epoch Duration: 168.69194626808167
2020-01-13 03:22:47.980800 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #635 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2741753
Z variance train             0.01797567
KL Divergence                26.801867
KL Loss                      2.6801867
QF Loss                      2546.723
VF Loss                      3296.9873
Policy Loss                  -3607.9597
Q Predictions Mean           3610.5713
Q Predictions Std            250.3904
Q Predictions Max            3814.0989
Q Predictions Min            1449.3806
V Predictions Mean           3596.498
V Predictions Std            275.3919
V Predictions Max            3798.4993
V Predictions Min            941.3074
Log Pis Mean                 3.1278467
Log Pis Std                  3.5336974
Log Pis Max                  16.351507
Log Pis Min                  -6.4528246
Policy mu Mean               0.00092168106
Policy mu Std                0.6531922
Policy mu Max                2.8190038
Policy mu Min                -2.9995997
Policy log std Mean          -1.4388433
Policy log std Std           0.31994528
Policy log std Max           -0.11701405
Policy log std Min           -2.7686682
Z mean eval                  1.3069615
Z variance eval              0.019559568
total_rewards                [4842.08010197 4882.84402142 2151.28345797 5116.48749822 5129.82181871
 5127.41831176 4880.64113251 5248.10314502 5009.9327588  5126.13660657]
total_rewards_mean           4751.474885294498
total_rewards_std            876.0520594698374
total_rewards_max            5248.10314501561
total_rewards_min            2151.283457968478
Number of train steps total  2548000
Number of env steps total    3187000
Number of rollouts total     0
Train Time (s)               122.69093212205917
(Previous) Eval Time (s)     24.340876600239426
Sample Time (s)              18.205192649737
Epoch Time (s)               165.2370013720356
Total Train Time (s)         100437.24792386731
Epoch                        636
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:25:34.408115 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #636 | Epoch Duration: 166.42713522911072
2020-01-13 03:25:34.408450 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #636 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3149202
Z variance train             0.019627005
KL Divergence                26.855892
KL Loss                      2.6855893
QF Loss                      1342.4318
VF Loss                      278.13257
Policy Loss                  -3425.5205
Q Predictions Mean           3427.4673
Q Predictions Std            125.92114
Q Predictions Max            3565.864
Q Predictions Min            2704.9114
V Predictions Mean           3416.918
V Predictions Std            127.314445
V Predictions Max            3560.0015
V Predictions Min            2670.7576
Log Pis Mean                 2.935851
Log Pis Std                  3.2270212
Log Pis Max                  12.013373
Log Pis Min                  -6.115184
Policy mu Mean               0.02735582
Policy mu Std                0.5998214
Policy mu Max                2.7166874
Policy mu Min                -3.0864067
Policy log std Mean          -1.4562883
Policy log std Std           0.2977429
Policy log std Max           -0.3982036
Policy log std Min           -3.095449
Z mean eval                  1.2477823
Z variance eval              0.0072804852
total_rewards                [3622.87730502 4777.58476618  136.84719542 4832.50904982 4870.72296063
 2409.26264929 1976.87570234   46.99582304 5098.52087024 5232.31403835]
total_rewards_mean           3300.4510360334716
total_rewards_std            1928.8187241616622
total_rewards_max            5232.314038348768
total_rewards_min            46.99582303659375
Number of train steps total  2552000
Number of env steps total    3192000
Number of rollouts total     0
Train Time (s)               131.35493815736845
(Previous) Eval Time (s)     25.530677685979754
Sample Time (s)              18.582341355271637
Epoch Time (s)               175.46795719861984
Total Train Time (s)         100609.41150862118
Epoch                        637
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:28:26.589538 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #637 | Epoch Duration: 172.18081974983215
2020-01-13 03:28:26.589833 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #637 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2484643
Z variance train             0.007289539
KL Divergence                29.002506
KL Loss                      2.9002507
QF Loss                      1686.906
VF Loss                      173.73598
Policy Loss                  -3172.9788
Q Predictions Mean           3178.0835
Q Predictions Std            210.11208
Q Predictions Max            3362.8123
Q Predictions Min            1823.5645
V Predictions Mean           3173.588
V Predictions Std            208.55013
V Predictions Max            3352.0747
V Predictions Min            1821.1006
Log Pis Mean                 3.4933887
Log Pis Std                  3.5604055
Log Pis Max                  15.347779
Log Pis Min                  -4.323043
Policy mu Mean               0.052461907
Policy mu Std                0.69982266
Policy mu Max                3.0482976
Policy mu Min                -3.119049
Policy log std Mean          -1.412763
Policy log std Std           0.3092752
Policy log std Max           -0.10762024
Policy log std Min           -2.8215642
Z mean eval                  1.3380579
Z variance eval              0.011167887
total_rewards                [4919.36630653  814.40320549 4945.54383651 4780.12468172 5221.12761927
 4943.66562902 4961.31339439 5081.79715008 4961.75637055  378.74519434]
total_rewards_mean           4100.784338789619
total_rewards_std            1758.091631883249
total_rewards_max            5221.12761926537
total_rewards_min            378.74519434150204
Number of train steps total  2556000
Number of env steps total    3197000
Number of rollouts total     0
Train Time (s)               121.33003442594782
(Previous) Eval Time (s)     22.243247922044247
Sample Time (s)              19.04212060198188
Epoch Time (s)               162.61540294997394
Total Train Time (s)         100772.59848783538
Epoch                        638
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:31:09.773905 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #638 | Epoch Duration: 163.1838653087616
2020-01-13 03:31:09.774116 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #638 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3388517
Z variance train             0.01113259
KL Divergence                28.58296
KL Loss                      2.8582962
QF Loss                      2702.8342
VF Loss                      411.10812
Policy Loss                  -3023.394
Q Predictions Mean           3027.5305
Q Predictions Std            226.10683
Q Predictions Max            4408.607
Q Predictions Min            1711.1879
V Predictions Mean           3018.0818
V Predictions Std            211.04375
V Predictions Max            3819.8455
V Predictions Min            1735.9932
Log Pis Mean                 3.500912
Log Pis Std                  4.0387244
Log Pis Max                  15.810063
Log Pis Min                  -9.187973
Policy mu Mean               0.0096002435
Policy mu Std                0.7062759
Policy mu Max                3.2265327
Policy mu Min                -3.0363333
Policy log std Mean          -1.4107503
Policy log std Std           0.32465363
Policy log std Max           -0.06923914
Policy log std Min           -2.828144
Z mean eval                  1.2332795
Z variance eval              0.00953435
total_rewards                [5188.11471545 5263.43037626 5470.84906942 5333.44736388 5521.63086614
 5353.21151852 5224.71830036 5607.11307534 5763.02156483 5620.23333104]
total_rewards_mean           5434.577018122257
total_rewards_std            182.1894301429339
total_rewards_max            5763.021564826908
total_rewards_min            5188.114715447153
Number of train steps total  2560000
Number of env steps total    3202000
Number of rollouts total     0
Train Time (s)               129.10989631991833
(Previous) Eval Time (s)     22.81133482698351
Sample Time (s)              18.60671078087762
Epoch Time (s)               170.52794192777947
Total Train Time (s)         100946.98810373852
Epoch                        639
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:34:04.167817 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #639 | Epoch Duration: 174.39354419708252
2020-01-13 03:34:04.168017 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #639 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2327607
Z variance train             0.009530686
KL Divergence                28.039616
KL Loss                      2.8039615
QF Loss                      941.0902
VF Loss                      219.26207
Policy Loss                  -2866.119
Q Predictions Mean           2867.6804
Q Predictions Std            229.78275
Q Predictions Max            3058.0142
Q Predictions Min            871.4081
V Predictions Mean           2859.4575
V Predictions Std            223.71591
V Predictions Max            3055.3186
V Predictions Min            931.337
Log Pis Mean                 3.1811414
Log Pis Std                  3.654157
Log Pis Max                  14.834473
Log Pis Min                  -4.4538727
Policy mu Mean               0.0323364
Policy mu Std                0.6909324
Policy mu Max                3.5984576
Policy mu Min                -3.3091612
Policy log std Mean          -1.3919072
Policy log std Std           0.31704402
Policy log std Max           0.015093207
Policy log std Min           -2.821141
Z mean eval                  1.2432011
Z variance eval              0.018059066
total_rewards                [5488.47934757 5542.28527649 5726.8801335  5254.47804643 4818.09608566
 5467.53515797 5781.23700836 1198.06812329 5510.20772549 5731.25505788]
total_rewards_mean           5051.852196263168
total_rewards_std            1311.8938217445152
total_rewards_max            5781.237008356142
total_rewards_min            1198.068123287818
Number of train steps total  2564000
Number of env steps total    3207000
Number of rollouts total     0
Train Time (s)               115.33935046708211
(Previous) Eval Time (s)     26.676619801670313
Sample Time (s)              18.628503430634737
Epoch Time (s)               160.64447369938716
Total Train Time (s)         101105.37270192197
Epoch                        640
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:36:42.556495 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #640 | Epoch Duration: 158.38835406303406
2020-01-13 03:36:42.556695 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #640 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2432951
Z variance train             0.01804198
KL Divergence                28.478605
KL Loss                      2.8478606
QF Loss                      771.2964
VF Loss                      178.11859
Policy Loss                  -2789.9731
Q Predictions Mean           2794.9717
Q Predictions Std            161.41714
Q Predictions Max            2959.38
Q Predictions Min            1976.1077
V Predictions Mean           2792.3613
V Predictions Std            157.95479
V Predictions Max            2946.2441
V Predictions Min            1999.8251
Log Pis Mean                 2.861249
Log Pis Std                  3.7218907
Log Pis Max                  19.486801
Log Pis Min                  -6.324443
Policy mu Mean               0.021757493
Policy mu Std                0.6604356
Policy mu Max                3.1029425
Policy mu Min                -2.9978478
Policy log std Mean          -1.401228
Policy log std Std           0.29624495
Policy log std Max           0.100913525
Policy log std Min           -2.957344
Z mean eval                  1.2513742
Z variance eval              0.01465371
total_rewards                [4912.81746866 5482.06906471 5517.63028204 5449.26351182 4900.30300486
 5459.90831916 5264.70325883 5465.55413395 5639.89007211 5409.53052093]
total_rewards_mean           5350.166963707127
total_rewards_std            238.54545391802463
total_rewards_max            5639.890072112875
total_rewards_min            4900.303004855101
Number of train steps total  2568000
Number of env steps total    3212000
Number of rollouts total     0
Train Time (s)               126.98749184189364
(Previous) Eval Time (s)     24.420141777954996
Sample Time (s)              18.27555557154119
Epoch Time (s)               169.68318919138983
Total Train Time (s)         101277.11414522631
Epoch                        641
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:39:34.301836 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #641 | Epoch Duration: 171.74500823020935
2020-01-13 03:39:34.302028 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #641 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2514647
Z variance train             0.014674492
KL Divergence                28.21162
KL Loss                      2.821162
QF Loss                      1135.8154
VF Loss                      9552.0625
Policy Loss                  -2681.4927
Q Predictions Mean           2678.3286
Q Predictions Std            234.87355
Q Predictions Max            2864.037
Q Predictions Min            23.1891
V Predictions Mean           2678.816
V Predictions Std            230.8838
V Predictions Max            2872.725
V Predictions Min            143.07788
Log Pis Mean                 2.9604053
Log Pis Std                  4.0772276
Log Pis Max                  21.034607
Log Pis Min                  -9.451214
Policy mu Mean               0.01009729
Policy mu Std                0.6628474
Policy mu Max                3.1347475
Policy mu Min                -3.0571587
Policy log std Mean          -1.3891647
Policy log std Std           0.3219376
Policy log std Max           -0.13901818
Policy log std Min           -3.7499685
Z mean eval                  1.2467614
Z variance eval              0.014577215
total_rewards                [5859.22006445 5711.23460234 5545.67980284 5627.18819616 5349.73245739
 5592.99940788 5452.06358115 5494.57573698 5733.48891337 5525.60426049]
total_rewards_mean           5589.1787023066545
total_rewards_std            141.81797560459853
total_rewards_max            5859.22006445334
total_rewards_min            5349.732457390113
Number of train steps total  2572000
Number of env steps total    3217000
Number of rollouts total     0
Train Time (s)               120.01283065695316
(Previous) Eval Time (s)     26.481630417052656
Sample Time (s)              18.30006913980469
Epoch Time (s)               164.7945302138105
Total Train Time (s)         101442.78834573971
Epoch                        642
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:42:19.979944 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #642 | Epoch Duration: 165.6778016090393
2020-01-13 03:42:19.980170 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #642 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2475631
Z variance train             0.014541054
KL Divergence                28.443745
KL Loss                      2.8443744
QF Loss                      710.78015
VF Loss                      432.74347
Policy Loss                  -2620.2358
Q Predictions Mean           2624.2153
Q Predictions Std            188.82568
Q Predictions Max            2817.094
Q Predictions Min            1301.7236
V Predictions Mean           2621.1196
V Predictions Std            184.99944
V Predictions Max            2806.6152
V Predictions Min            1294.256
Log Pis Mean                 3.14624
Log Pis Std                  3.7187657
Log Pis Max                  20.886591
Log Pis Min                  -10.835943
Policy mu Mean               0.02263299
Policy mu Std                0.6505501
Policy mu Max                2.9632847
Policy mu Min                -3.3343008
Policy log std Mean          -1.3994603
Policy log std Std           0.32050398
Policy log std Max           -0.1068362
Policy log std Min           -2.8118925
Z mean eval                  1.2328379
Z variance eval              0.010365108
total_rewards                [5496.45932056 5642.25394385 5499.68909571 5477.79193983 5594.02318117
 5806.45267941 5651.84839372  630.64427673 5546.42159683 5291.12392761]
total_rewards_mean           5063.670835539942
total_rewards_std            1483.2104197991948
total_rewards_max            5806.4526794051
total_rewards_min            630.6442767254332
Number of train steps total  2576000
Number of env steps total    3222000
Number of rollouts total     0
Train Time (s)               120.84158095810562
(Previous) Eval Time (s)     27.364626219961792
Sample Time (s)              18.049953133799136
Epoch Time (s)               166.25616031186655
Total Train Time (s)         101606.51212777663
Epoch                        643
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:45:03.711742 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #643 | Epoch Duration: 163.73142290115356
2020-01-13 03:45:03.712025 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #643 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2336335
Z variance train             0.010378599
KL Divergence                29.651665
KL Loss                      2.9651666
QF Loss                      1014.3363
VF Loss                      1130.9064
Policy Loss                  -2625.814
Q Predictions Mean           2631.5432
Q Predictions Std            558.2915
Q Predictions Max            11250.174
Q Predictions Min            1926.0157
V Predictions Mean           2623.873
V Predictions Std            517.6666
V Predictions Max            10550.036
V Predictions Min            1706.3674
Log Pis Mean                 2.6256008
Log Pis Std                  3.8956463
Log Pis Max                  18.082253
Log Pis Min                  -6.4454575
Policy mu Mean               0.042059273
Policy mu Std                0.6564169
Policy mu Max                4.1127443
Policy mu Min                -3.7935076
Policy log std Mean          -1.3630025
Policy log std Std           0.30677402
Policy log std Max           0.123803616
Policy log std Min           -2.863197
Z mean eval                  1.2323636
Z variance eval              0.007634636
total_rewards                [ -685.31957068  5689.75264725  5375.18470929 -1370.77211255
  2705.47007553  5393.18937906  5565.40275907  3394.68438664
  4378.31701525   182.90656899]
total_rewards_mean           3062.8815857860354
total_rewards_std            2605.933681457358
total_rewards_max            5689.752647250265
total_rewards_min            -1370.77211255453
Number of train steps total  2580000
Number of env steps total    3227000
Number of rollouts total     0
Train Time (s)               122.06473542796448
(Previous) Eval Time (s)     24.839602234773338
Sample Time (s)              17.96963633503765
Epoch Time (s)               164.87397399777547
Total Train Time (s)         101770.09505747957
Epoch                        644
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:47:47.298884 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #644 | Epoch Duration: 163.5866837501526
2020-01-13 03:47:47.299079 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #644 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2297949
Z variance train             0.0076250755
KL Divergence                29.858757
KL Loss                      2.9858758
QF Loss                      1432.8193
VF Loss                      1092.4524
Policy Loss                  -2513.1494
Q Predictions Mean           2514.8428
Q Predictions Std            311.01996
Q Predictions Max            6120.889
Q Predictions Min            1340.2421
V Predictions Mean           2524.5574
V Predictions Std            299.41156
V Predictions Max            5925.7837
V Predictions Min            1348.5778
Log Pis Mean                 3.0660372
Log Pis Std                  3.847131
Log Pis Max                  19.637531
Log Pis Min                  -3.1269488
Policy mu Mean               0.03913506
Policy mu Std                0.73001724
Policy mu Max                3.9143732
Policy mu Min                -3.2361703
Policy log std Mean          -1.3502686
Policy log std Std           0.32424662
Policy log std Max           0.0027201176
Policy log std Min           -2.8564901
Z mean eval                  1.2284274
Z variance eval              0.0121265855
total_rewards                [ 5464.53092322  3096.23795843     8.34004336   397.50114291
  3468.69279654  5393.90214123  1415.72585669  5094.3879042
  -464.22332274 -1088.80309907]
total_rewards_mean           2278.629234478328
total_rewards_std            2411.813132612708
total_rewards_max            5464.530923224293
total_rewards_min            -1088.8030990651328
Number of train steps total  2584000
Number of env steps total    3232000
Number of rollouts total     0
Train Time (s)               126.75608316482976
(Previous) Eval Time (s)     23.551972021814436
Sample Time (s)              18.395775495562702
Epoch Time (s)               168.7038306822069
Total Train Time (s)         101940.97138644569
Epoch                        645
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:50:38.182906 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #645 | Epoch Duration: 170.8836727142334
2020-01-13 03:50:38.183138 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #645 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2266371
Z variance train             0.012085554
KL Divergence                30.75898
KL Loss                      3.075898
QF Loss                      4619.3057
VF Loss                      405.5787
Policy Loss                  -2532.016
Q Predictions Mean           2534.633
Q Predictions Std            219.58478
Q Predictions Max            4710.6016
Q Predictions Min            1320.2142
V Predictions Mean           2540.1714
V Predictions Std            245.21342
V Predictions Max            5303.6025
V Predictions Min            1353.703
Log Pis Mean                 2.7879362
Log Pis Std                  3.7464554
Log Pis Max                  20.889664
Log Pis Min                  -6.4558287
Policy mu Mean               0.010539047
Policy mu Std                0.70169365
Policy mu Max                3.1766524
Policy mu Min                -3.3348057
Policy log std Mean          -1.3122771
Policy log std Std           0.2996893
Policy log std Max           0.018708229
Policy log std Min           -2.9897842
Z mean eval                  1.238341
Z variance eval              0.013027598
total_rewards                [ -691.67407967 -1148.6140187  -2512.29312665   570.97289228
   178.49137413  -423.95638805 -1436.50596913   196.02081402
 -1432.23134414  3734.21978317]
total_rewards_mean           -296.5570062732463
total_rewards_std            1608.2645670179731
total_rewards_max            3734.2197831660997
total_rewards_min            -2512.293126646645
Number of train steps total  2588000
Number of env steps total    3237000
Number of rollouts total     0
Train Time (s)               125.42793983966112
(Previous) Eval Time (s)     25.731468219775707
Sample Time (s)              19.043094228953123
Epoch Time (s)               170.20250228838995
Total Train Time (s)         102108.7155965399
Epoch                        646
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:53:25.929978 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #646 | Epoch Duration: 167.746684551239
2020-01-13 03:53:25.930180 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #646 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2391117
Z variance train             0.013016919
KL Divergence                30.762068
KL Loss                      3.076207
QF Loss                      831.02924
VF Loss                      261.63055
Policy Loss                  -2480.171
Q Predictions Mean           2482.189
Q Predictions Std            208.61557
Q Predictions Max            3788.516
Q Predictions Min            1559.9121
V Predictions Mean           2480.7104
V Predictions Std            212.63023
V Predictions Max            3852.7515
V Predictions Min            1549.9015
Log Pis Mean                 2.239392
Log Pis Std                  4.04094
Log Pis Max                  22.695679
Log Pis Min                  -6.8404865
Policy mu Mean               -0.016449917
Policy mu Std                0.6510409
Policy mu Max                3.2981222
Policy mu Min                -3.2306814
Policy log std Mean          -1.3310745
Policy log std Std           0.30224174
Policy log std Max           0.014452696
Policy log std Min           -2.8310275
Z mean eval                  1.2847874
Z variance eval              0.01117335
total_rewards                [-1531.94002614  -596.43123352  -162.60292507 -1440.40342047
 -1238.45226059 -1029.3112819  -2228.80390703  -945.77368737
  -975.93219822 -1446.17776736]
total_rewards_mean           -1159.5828707666758
total_rewards_std            534.4737668054833
total_rewards_max            -162.60292507276026
total_rewards_min            -2228.803907027138
Number of train steps total  2592000
Number of env steps total    3242000
Number of rollouts total     0
Train Time (s)               122.34471651772037
(Previous) Eval Time (s)     23.275327740702778
Sample Time (s)              18.97125271568075
Epoch Time (s)               164.5912969741039
Total Train Time (s)         102277.46503192652
Epoch                        647
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:56:14.686246 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #647 | Epoch Duration: 168.75590324401855
2020-01-13 03:56:14.686500 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #647 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.282087
Z variance train             0.011184958
KL Divergence                32.565014
KL Loss                      3.2565014
QF Loss                      17945.047
VF Loss                      483.93158
Policy Loss                  -2471.792
Q Predictions Mean           2476.8645
Q Predictions Std            246.78531
Q Predictions Max            4284.3394
Q Predictions Min            1093.0673
V Predictions Mean           2485.7163
V Predictions Std            241.9654
V Predictions Max            4291.895
V Predictions Min            1114.9393
Log Pis Mean                 2.5368207
Log Pis Std                  4.028559
Log Pis Max                  18.818848
Log Pis Min                  -8.455598
Policy mu Mean               -0.035642527
Policy mu Std                0.6885581
Policy mu Max                3.7761834
Policy mu Min                -3.673897
Policy log std Mean          -1.3376309
Policy log std Std           0.31103402
Policy log std Max           -0.3063903
Policy log std Min           -2.8910856
Z mean eval                  1.2486198
Z variance eval              0.00838436
total_rewards                [4256.11893785 1490.77024444 2695.43644051  807.68591106 3694.52630541
   74.19086581 5572.90489848 -571.14203898 5304.92973786 -227.93614872]
total_rewards_mean           2309.7485153695607
total_rewards_std            2194.0381031704455
total_rewards_max            5572.904898480711
total_rewards_min            -571.1420389818741
Number of train steps total  2596000
Number of env steps total    3247000
Number of rollouts total     0
Train Time (s)               114.01979316584766
(Previous) Eval Time (s)     27.439580072183162
Sample Time (s)              18.432528119068593
Epoch Time (s)               159.8919013570994
Total Train Time (s)         102434.19067178061
Epoch                        648
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:58:51.416730 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #648 | Epoch Duration: 156.7300615310669
2020-01-13 03:58:51.416941 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #648 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.248724
Z variance train             0.008379469
KL Divergence                31.123486
KL Loss                      3.1123486
QF Loss                      12738.149
VF Loss                      184.28893
Policy Loss                  -2452.839
Q Predictions Mean           2450.058
Q Predictions Std            256.51297
Q Predictions Max            3828.2327
Q Predictions Min            225.66255
V Predictions Mean           2451.1873
V Predictions Std            238.6896
V Predictions Max            4001.371
V Predictions Min            140.94347
Log Pis Mean                 2.6413193
Log Pis Std                  4.118253
Log Pis Max                  23.502094
Log Pis Min                  -4.1939287
Policy mu Mean               -0.010011826
Policy mu Std                0.7061061
Policy mu Max                4.6187677
Policy mu Min                -3.8246837
Policy log std Mean          -1.3269832
Policy log std Std           0.32150832
Policy log std Max           2.0
Policy log std Min           -2.9245806
Z mean eval                  1.192847
Z variance eval              0.011421567
total_rewards                [-1070.32616596  3051.02080924  5440.99655659  5485.36291992
  5578.81040215  2054.66251957   844.65744529  5756.05981357
  5485.46574033  5635.8278522 ]
total_rewards_mean           3826.2537892905953
total_rewards_std            2340.707578686347
total_rewards_max            5756.05981357464
total_rewards_min            -1070.3261659595194
Number of train steps total  2600000
Number of env steps total    3252000
Number of rollouts total     0
Train Time (s)               119.71654607495293
(Previous) Eval Time (s)     24.27745249820873
Sample Time (s)              18.42062254389748
Epoch Time (s)               162.41462111705914
Total Train Time (s)         102596.90981208486
Epoch                        649
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:01:34.145456 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #649 | Epoch Duration: 162.72836756706238
2020-01-13 04:01:34.145678 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #649 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1933262
Z variance train             0.011421122
KL Divergence                29.798841
KL Loss                      2.9798841
QF Loss                      1330.1031
VF Loss                      253.78207
Policy Loss                  -2439.9326
Q Predictions Mean           2442.2148
Q Predictions Std            274.711
Q Predictions Max            4447.3423
Q Predictions Min            1142.3503
V Predictions Mean           2443.5386
V Predictions Std            273.65137
V Predictions Max            4473.85
V Predictions Min            1168.2256
Log Pis Mean                 2.7530031
Log Pis Std                  3.564947
Log Pis Max                  16.67917
Log Pis Min                  -6.0309343
Policy mu Mean               -0.029754516
Policy mu Std                0.6507942
Policy mu Max                2.743991
Policy mu Min                -3.0142417
Policy log std Mean          -1.3888294
Policy log std Std           0.31519818
Policy log std Max           0.01063478
Policy log std Min           -2.9671404
Z mean eval                  1.2717123
Z variance eval              0.008923403
total_rewards                [5482.14216255 5689.30146702 5506.11009283 5276.83098596 5554.92290837
 -425.03362375 5431.07183732 5563.9410659  5399.17601295 5368.63586768]
total_rewards_mean           4884.709877681851
total_rewards_std            1773.2872828487907
total_rewards_max            5689.301467015417
total_rewards_min            -425.03362374515905
Number of train steps total  2604000
Number of env steps total    3257000
Number of rollouts total     0
Train Time (s)               118.86986331362277
(Previous) Eval Time (s)     24.59082389017567
Sample Time (s)              18.278529348317534
Epoch Time (s)               161.73921655211598
Total Train Time (s)         102761.37062019343
Epoch                        650
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:04:18.615033 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #650 | Epoch Duration: 164.46916675567627
2020-01-13 04:04:18.615306 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #650 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2723058
Z variance train             0.008868067
KL Divergence                30.111477
KL Loss                      3.0111477
QF Loss                      1191.3723
VF Loss                      264.58167
Policy Loss                  -2378.5933
Q Predictions Mean           2383.5325
Q Predictions Std            202.61887
Q Predictions Max            2800.4453
Q Predictions Min            711.7748
V Predictions Mean           2382.0234
V Predictions Std            198.5065
V Predictions Max            2794.1482
V Predictions Min            650.54755
Log Pis Mean                 2.6547956
Log Pis Std                  3.8706317
Log Pis Max                  18.65144
Log Pis Min                  -4.4564953
Policy mu Mean               0.025495652
Policy mu Std                0.6877425
Policy mu Max                4.6024566
Policy mu Min                -2.9098206
Policy log std Mean          -1.3469696
Policy log std Std           0.32838628
Policy log std Max           -0.12919152
Policy log std Min           -3.1976774
Z mean eval                  1.2124417
Z variance eval              0.0070583327
total_rewards                [-1787.34870663   -15.28928199  5660.59121926  1927.10175989
  5584.43480796  3616.33132733  5427.31685621  5708.00336754
  5485.10712955  5464.86379844]
total_rewards_mean           3707.1112277572756
total_rewards_std            2603.384305273038
total_rewards_max            5708.003367544778
total_rewards_min            -1787.348706632393
Number of train steps total  2608000
Number of env steps total    3262000
Number of rollouts total     0
Train Time (s)               119.02697071712464
(Previous) Eval Time (s)     27.32047889335081
Sample Time (s)              18.09746441943571
Epoch Time (s)               164.44491402991116
Total Train Time (s)         102923.88120709546
Epoch                        651
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:07:01.133817 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #651 | Epoch Duration: 162.5182991027832
2020-01-13 04:07:01.134059 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #651 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2123646
Z variance train             0.0070613595
KL Divergence                29.636673
KL Loss                      2.9636674
QF Loss                      887.3428
VF Loss                      352.65143
Policy Loss                  -2378.7266
Q Predictions Mean           2383.0925
Q Predictions Std            158.8342
Q Predictions Max            2893.67
Q Predictions Min            1708.6315
V Predictions Mean           2390.8945
V Predictions Std            154.92015
V Predictions Max            2981.8281
V Predictions Min            1751.7981
Log Pis Mean                 2.8982117
Log Pis Std                  3.7343163
Log Pis Max                  16.780815
Log Pis Min                  -7.543856
Policy mu Mean               -0.01522156
Policy mu Std                0.66619915
Policy mu Max                2.765439
Policy mu Min                -2.6659608
Policy log std Mean          -1.3984791
Policy log std Std           0.32348952
Policy log std Max           -0.14354801
Policy log std Min           -2.8492746
Z mean eval                  1.2147721
Z variance eval              0.0058369017
total_rewards                [-2501.83702907 -1930.89473056 -1702.13823659 -1142.8348406
 -1511.8013525   -292.91188916 -1749.71934191 -1837.57606087
 -1005.59188181  1230.13409779]
total_rewards_mean           -1244.5171265297993
total_rewards_std            1001.83079600054
total_rewards_max            1230.1340977865573
total_rewards_min            -2501.8370290730254
Number of train steps total  2612000
Number of env steps total    3267000
Number of rollouts total     0
Train Time (s)               124.45984657900408
(Previous) Eval Time (s)     25.393538642209023
Sample Time (s)              18.60467717703432
Epoch Time (s)               168.45806239824742
Total Train Time (s)         103092.68831801601
Epoch                        652
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:09:49.946953 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #652 | Epoch Duration: 168.81271529197693
2020-01-13 04:09:49.947144 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #652 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2146885
Z variance train             0.0058439183
KL Divergence                31.156698
KL Loss                      3.11567
QF Loss                      3607.918
VF Loss                      1934.4855
Policy Loss                  -2408.041
Q Predictions Mean           2409.6353
Q Predictions Std            196.24323
Q Predictions Max            4421.721
Q Predictions Min            1706.4214
V Predictions Mean           2411.4526
V Predictions Std            197.35294
V Predictions Max            4539.326
V Predictions Min            1756.1067
Log Pis Mean                 2.848353
Log Pis Std                  4.2051477
Log Pis Max                  19.177303
Log Pis Min                  -6.8617544
Policy mu Mean               -0.033743177
Policy mu Std                0.7814171
Policy mu Max                3.401466
Policy mu Min                -3.6859195
Policy log std Mean          -1.2844157
Policy log std Std           0.35818842
Policy log std Max           0.13426363
Policy log std Min           -3.052168
Z mean eval                  1.2700183
Z variance eval              0.006126764
total_rewards                [-2309.56343947 -1508.27541935 -2182.81951052 -1877.199941
 -2162.03720851 -1673.62180394 -1562.08269417   -75.04031793
 -2145.10223275 -2194.90666108]
total_rewards_mean           -1769.064922870814
total_rewards_std            627.8438267855915
total_rewards_max            -75.04031793108227
total_rewards_min            -2309.5634394660196
Number of train steps total  2616000
Number of env steps total    3272000
Number of rollouts total     0
Train Time (s)               126.37217103410512
(Previous) Eval Time (s)     25.747875947039574
Sample Time (s)              17.828710329253227
Epoch Time (s)               169.94875731039792
Total Train Time (s)         103262.3106390126
Epoch                        653
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:12:39.579274 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #653 | Epoch Duration: 169.6319649219513
2020-01-13 04:12:39.579544 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #653 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2715821
Z variance train             0.006121485
KL Divergence                31.453184
KL Loss                      3.1453185
QF Loss                      805.6693
VF Loss                      188.4671
Policy Loss                  -2477.321
Q Predictions Mean           2474.3384
Q Predictions Std            197.1845
Q Predictions Max            5069.954
Q Predictions Min            1839.7888
V Predictions Mean           2471.0146
V Predictions Std            193.65749
V Predictions Max            5055.8867
V Predictions Min            1862.3363
Log Pis Mean                 2.5445735
Log Pis Std                  4.324547
Log Pis Max                  20.16758
Log Pis Min                  -5.754872
Policy mu Mean               -0.09964929
Policy mu Std                0.7985332
Policy mu Max                3.8523018
Policy mu Min                -3.4627414
Policy log std Mean          -1.2012742
Policy log std Std           0.3425845
Policy log std Max           -0.08307898
Policy log std Min           -2.6914263
Z mean eval                  1.2594922
Z variance eval              0.0053793425
total_rewards                [  -27.93098904 -1708.26875437  1169.49177796  1562.46648119
   293.81729669  -943.52310537 -1089.04656659  -835.4157817
 -1024.027804     686.40505589]
total_rewards_mean           -191.603238934417
total_rewards_std            1036.3951003363645
total_rewards_max            1562.4664811940393
total_rewards_min            -1708.2687543743332
Number of train steps total  2620000
Number of env steps total    3277000
Number of rollouts total     0
Train Time (s)               121.52062163082883
(Previous) Eval Time (s)     25.430776780005544
Sample Time (s)              18.29068444017321
Epoch Time (s)               165.24208285100758
Total Train Time (s)         103419.826873919
Epoch                        654
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:15:17.104189 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #654 | Epoch Duration: 157.5244379043579
2020-01-13 04:15:17.104445 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #654 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2578619
Z variance train             0.005375933
KL Divergence                31.53051
KL Loss                      3.1530511
QF Loss                      2351.0388
VF Loss                      1453.2908
Policy Loss                  -2478.3198
Q Predictions Mean           2479.3643
Q Predictions Std            228.47243
Q Predictions Max            4823.034
Q Predictions Min            1763.1757
V Predictions Mean           2478.032
V Predictions Std            222.51663
V Predictions Max            4723.786
V Predictions Min            1795.562
Log Pis Mean                 3.1914043
Log Pis Std                  3.9170587
Log Pis Max                  19.457039
Log Pis Min                  -6.486005
Policy mu Mean               -0.0010292542
Policy mu Std                0.7679142
Policy mu Max                3.7012587
Policy mu Min                -3.4793863
Policy log std Mean          -1.3232787
Policy log std Std           0.3300469
Policy log std Max           -0.101371765
Policy log std Min           -2.7054186
Z mean eval                  1.2300432
Z variance eval              0.0056511
total_rewards                [-1293.20917846     9.86678596 -1854.34991155  1394.66911828
  -868.43317158 -1687.90137097  1698.74993508  -731.64137614
  4865.20094312   -31.37406709]
total_rewards_mean           150.1577706650068
total_rewards_std            1937.166268588698
total_rewards_max            4865.2009431198685
total_rewards_min            -1854.349911550834
Number of train steps total  2624000
Number of env steps total    3282000
Number of rollouts total     0
Train Time (s)               119.27277916576713
(Previous) Eval Time (s)     17.71282806713134
Sample Time (s)              18.613911589607596
Epoch Time (s)               155.59951882250607
Total Train Time (s)         103578.59275965719
Epoch                        655
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:17:55.875265 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #655 | Epoch Duration: 158.7706379890442
2020-01-13 04:17:55.875461 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #655 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2292931
Z variance train             0.0056617125
KL Divergence                31.423164
KL Loss                      3.1423166
QF Loss                      2809.815
VF Loss                      1552.5896
Policy Loss                  -2509.362
Q Predictions Mean           2503.9219
Q Predictions Std            603.23944
Q Predictions Max            10995.966
Q Predictions Min            0.9719713
V Predictions Mean           2506.3472
V Predictions Std            547.4136
V Predictions Max            10280.842
V Predictions Min            1128.852
Log Pis Mean                 3.2331474
Log Pis Std                  4.3351545
Log Pis Max                  26.899467
Log Pis Min                  -6.850046
Policy mu Mean               -0.015169445
Policy mu Std                0.71624273
Policy mu Max                3.4955873
Policy mu Min                -2.7582831
Policy log std Mean          -1.3914392
Policy log std Std           0.34292388
Policy log std Max           0.015332222
Policy log std Min           -3.7001066
Z mean eval                  1.2285762
Z variance eval              0.0022497945
total_rewards                [4921.41861467  164.91415699 4750.01976028 3255.97077586 5247.40984481
 5142.19287223 1144.45199706 1312.90220223 5228.796688   5184.48080141]
total_rewards_mean           3635.255771353836
total_rewards_std            1910.2576321044287
total_rewards_max            5247.409844809999
total_rewards_min            164.91415699125756
Number of train steps total  2628000
Number of env steps total    3287000
Number of rollouts total     0
Train Time (s)               123.3212755410932
(Previous) Eval Time (s)     20.883617681916803
Sample Time (s)              18.06867092149332
Epoch Time (s)               162.27356414450333
Total Train Time (s)         103744.56307240855
Epoch                        656
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:20:41.858050 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #656 | Epoch Duration: 165.98241877555847
2020-01-13 04:20:41.858406 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #656 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2276161
Z variance train             0.0022461438
KL Divergence                32.2835
KL Loss                      3.2283502
QF Loss                      2293.3223
VF Loss                      401.32935
Policy Loss                  -2405.9917
Q Predictions Mean           2408.7026
Q Predictions Std            247.07846
Q Predictions Max            4773.931
Q Predictions Min            1479.4646
V Predictions Mean           2401.941
V Predictions Std            234.09013
V Predictions Max            4470.9087
V Predictions Min            1485.8497
Log Pis Mean                 3.3873796
Log Pis Std                  3.547372
Log Pis Max                  17.234615
Log Pis Min                  -4.6703444
Policy mu Mean               0.040226623
Policy mu Std                0.72892696
Policy mu Max                3.5975733
Policy mu Min                -2.622335
Policy log std Mean          -1.3647184
Policy log std Std           0.30942968
Policy log std Max           0.5269351
Policy log std Min           -2.7693617
Z mean eval                  1.2228568
Z variance eval              0.004183168
total_rewards                [ 914.43394304 3280.5697286  5522.63989181 5761.12784123 4884.41515625
 4593.9081332  5425.83712709 2733.82233844 5562.01746767 3111.4978888 ]
total_rewards_mean           4179.026951612434
total_rewards_std            1521.1266817845546
total_rewards_max            5761.127841233358
total_rewards_min            914.4339430385285
Number of train steps total  2632000
Number of env steps total    3292000
Number of rollouts total     0
Train Time (s)               121.96449298597872
(Previous) Eval Time (s)     24.59215092100203
Sample Time (s)              18.763866557739675
Epoch Time (s)               165.32051046472043
Total Train Time (s)         103912.2325105588
Epoch                        657
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:23:29.533647 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #657 | Epoch Duration: 167.67496824264526
2020-01-13 04:23:29.533970 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #657 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2230239
Z variance train             0.004178518
KL Divergence                31.250938
KL Loss                      3.125094
QF Loss                      3392.454
VF Loss                      4890.9023
Policy Loss                  -2410.217
Q Predictions Mean           2415.79
Q Predictions Std            241.99579
Q Predictions Max            3867.283
Q Predictions Min            113.82972
V Predictions Mean           2418.236
V Predictions Std            261.05734
V Predictions Max            3926.1199
V Predictions Min            -39.111633
Log Pis Mean                 3.1490712
Log Pis Std                  4.4043593
Log Pis Max                  30.664726
Log Pis Min                  -5.369689
Policy mu Mean               -0.01298033
Policy mu Std                0.71589327
Policy mu Max                3.0904925
Policy mu Min                -5.0411224
Policy log std Mean          -1.3737953
Policy log std Std           0.31241325
Policy log std Max           -0.16424763
Policy log std Min           -3.1964593
Z mean eval                  1.2357513
Z variance eval              0.0074287765
total_rewards                [4333.54431011 5428.20434999 5645.50569013 2091.09081057 5557.85386189
  292.06808886 5008.75812768 1623.21144366 5591.16398026 5468.02722934]
total_rewards_mean           4103.9427892496515
total_rewards_std            1895.3599389042672
total_rewards_max            5645.505690125066
total_rewards_min            292.0680888606495
Number of train steps total  2636000
Number of env steps total    3297000
Number of rollouts total     0
Train Time (s)               128.01276587322354
(Previous) Eval Time (s)     26.946214644238353
Sample Time (s)              18.09694655938074
Epoch Time (s)               173.05592707684264
Total Train Time (s)         104080.80997898057
Epoch                        658
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:26:18.117036 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #658 | Epoch Duration: 168.58283615112305
2020-01-13 04:26:18.117249 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #658 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2362591
Z variance train             0.0074372636
KL Divergence                31.0433
KL Loss                      3.10433
QF Loss                      1492.8733
VF Loss                      234.00513
Policy Loss                  -2391.9302
Q Predictions Mean           2396.2249
Q Predictions Std            201.08133
Q Predictions Max            2832.077
Q Predictions Min            1370.1666
V Predictions Mean           2392.4614
V Predictions Std            194.51657
V Predictions Max            2853.4055
V Predictions Min            1363.6166
Log Pis Mean                 3.1751945
Log Pis Std                  3.735581
Log Pis Max                  16.566338
Log Pis Min                  -9.0238905
Policy mu Mean               0.04213252
Policy mu Std                0.7208326
Policy mu Max                2.8537183
Policy mu Min                -2.7926915
Policy log std Mean          -1.3742808
Policy log std Std           0.32035896
Policy log std Max           -0.19240248
Policy log std Min           -2.8568866
Z mean eval                  1.2373856
Z variance eval              0.0067667207
total_rewards                [2855.40872949 5637.3081999  5609.49683376 5826.31729637 5250.96886243
 5662.09255139 5218.14613738 5608.12329451 5822.12888195  629.6926872 ]
total_rewards_mean           4811.968347438235
total_rewards_std            1624.8198854686216
total_rewards_max            5826.317296374556
total_rewards_min            629.6926871988932
Number of train steps total  2640000
Number of env steps total    3302000
Number of rollouts total     0
Train Time (s)               117.07199518196285
(Previous) Eval Time (s)     22.47283856663853
Sample Time (s)              18.751184683293104
Epoch Time (s)               158.29601843189448
Total Train Time (s)         104241.15339083457
Epoch                        659
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:28:58.470770 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #659 | Epoch Duration: 160.35333633422852
2020-01-13 04:28:58.471048 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #659 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2378943
Z variance train             0.00677166
KL Divergence                30.945034
KL Loss                      3.0945034
QF Loss                      1515.3628
VF Loss                      2128.8965
Policy Loss                  -2388.5056
Q Predictions Mean           2389.7456
Q Predictions Std            285.60394
Q Predictions Max            3552.843
Q Predictions Min            -57.246002
V Predictions Mean           2393.536
V Predictions Std            268.94095
V Predictions Max            3636.6372
V Predictions Min            563.153
Log Pis Mean                 3.2854722
Log Pis Std                  3.7544847
Log Pis Max                  18.761929
Log Pis Min                  -6.99258
Policy mu Mean               0.049308382
Policy mu Std                0.69178325
Policy mu Max                3.743671
Policy mu Min                -3.0004818
Policy log std Mean          -1.411389
Policy log std Std           0.32895428
Policy log std Max           0.0014710426
Policy log std Min           -2.9192166
Z mean eval                  1.2335637
Z variance eval              0.004116711
total_rewards                [5541.77044658 3861.23299785 5516.24866365 5910.77154351 5504.92318768
 5791.44535669 5570.07661903 1360.11617986 5332.74457442 5612.01335666]
total_rewards_mean           5000.1342925934905
total_rewards_std            1327.6549575525748
total_rewards_max            5910.77154351244
total_rewards_min            1360.1161798568996
Number of train steps total  2644000
Number of env steps total    3307000
Number of rollouts total     0
Train Time (s)               123.28353485511616
(Previous) Eval Time (s)     24.529795278795063
Sample Time (s)              18.447418855968863
Epoch Time (s)               166.26074898988008
Total Train Time (s)         104406.76659640577
Epoch                        660
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:31:44.089566 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #660 | Epoch Duration: 165.61830353736877
2020-01-13 04:31:44.089806 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #660 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2328627
Z variance train             0.0041216514
KL Divergence                32.085014
KL Loss                      3.2085016
QF Loss                      2394.422
VF Loss                      567.4332
Policy Loss                  -2351.2126
Q Predictions Mean           2350.5708
Q Predictions Std            242.13783
Q Predictions Max            3503.7075
Q Predictions Min            624.0185
V Predictions Mean           2347.7925
V Predictions Std            237.45976
V Predictions Max            3567.9426
V Predictions Min            599.07654
Log Pis Mean                 3.7416742
Log Pis Std                  4.1612577
Log Pis Max                  26.362724
Log Pis Min                  -4.059499
Policy mu Mean               0.02205677
Policy mu Std                0.7717825
Policy mu Max                3.62857
Policy mu Min                -3.7146935
Policy log std Mean          -1.390047
Policy log std Std           0.35433453
Policy log std Max           0.20566368
Policy log std Min           -2.8318908
Z mean eval                  1.1800306
Z variance eval              0.0042124405
total_rewards                [  -6.36667506   65.06261233 5689.01581664 2333.10301423 5881.97741394
 5627.11345609 5882.53346991 5621.71404671 4001.76888688 5862.04063067]
total_rewards_mean           4095.796267233095
total_rewards_std            2300.1017642981187
total_rewards_max            5882.533469911946
total_rewards_min            -6.366675064553371
Number of train steps total  2648000
Number of env steps total    3312000
Number of rollouts total     0
Train Time (s)               123.05661500291899
(Previous) Eval Time (s)     23.887026781681925
Sample Time (s)              17.906232791021466
Epoch Time (s)               164.84987457562238
Total Train Time (s)         104567.01311225165
Epoch                        661
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:34:24.344879 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #661 | Epoch Duration: 160.2548851966858
2020-01-13 04:34:24.345150 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #661 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1801195
Z variance train             0.0042315256
KL Divergence                31.708984
KL Loss                      3.1708984
QF Loss                      8330.208
VF Loss                      4319.654
Policy Loss                  -2359.017
Q Predictions Mean           2357.0544
Q Predictions Std            263.89172
Q Predictions Max            3865.227
Q Predictions Min            936.5606
V Predictions Mean           2348.7239
V Predictions Std            253.67917
V Predictions Max            3854.452
V Predictions Min            809.1064
Log Pis Mean                 2.9378667
Log Pis Std                  4.0819817
Log Pis Max                  20.91037
Log Pis Min                  -6.0944786
Policy mu Mean               0.05952657
Policy mu Std                0.69900733
Policy mu Max                3.1411386
Policy mu Min                -3.8567333
Policy log std Mean          -1.3881593
Policy log std Std           0.31573746
Policy log std Max           -0.044816494
Policy log std Min           -2.7898588
Z mean eval                  1.243242
Z variance eval              0.0045563825
total_rewards                [5319.27748906 4846.02338315 5759.09561613 5634.2674572   367.6554643
 -424.24341854 5280.884286   5495.56811418 5545.39493415 5633.39522154]
total_rewards_mean           4345.7318547163195
total_rewards_std            2207.4342947337386
total_rewards_max            5759.095616125476
total_rewards_min            -424.24341853743476
Number of train steps total  2652000
Number of env steps total    3317000
Number of rollouts total     0
Train Time (s)               117.3033968321979
(Previous) Eval Time (s)     19.291706508025527
Sample Time (s)              17.80609796475619
Epoch Time (s)               154.40120130497962
Total Train Time (s)         104726.69806277798
Epoch                        662
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:37:04.034370 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #662 | Epoch Duration: 159.68903255462646
2020-01-13 04:37:04.034575 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #662 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2419512
Z variance train             0.004559393
KL Divergence                31.144587
KL Loss                      3.1144588
QF Loss                      1574.4269
VF Loss                      668.9961
Policy Loss                  -2375.2424
Q Predictions Mean           2378.8135
Q Predictions Std            288.26108
Q Predictions Max            4235.1787
Q Predictions Min            111.26308
V Predictions Mean           2383.925
V Predictions Std            283.82758
V Predictions Max            4329.9995
V Predictions Min            101.232834
Log Pis Mean                 3.6882858
Log Pis Std                  4.4455414
Log Pis Max                  22.47915
Log Pis Min                  -5.5244775
Policy mu Mean               -0.0026614517
Policy mu Std                0.786985
Policy mu Max                3.8101852
Policy mu Min                -4.4173684
Policy log std Mean          -1.3993678
Policy log std Std           0.3359787
Policy log std Max           0.08698869
Policy log std Min           -3.210507
Z mean eval                  1.216306
Z variance eval              0.0042129382
total_rewards                [-1008.32904251   345.0066229   4896.63149016 -1201.73969283
  5554.94490864  5649.42055133  5704.94725092  5066.42136047
  -970.77636754  5699.85207413]
total_rewards_mean           2973.637915567023
total_rewards_std            3042.2170402963293
total_rewards_max            5704.947250916716
total_rewards_min            -1201.7396928286712
Number of train steps total  2656000
Number of env steps total    3322000
Number of rollouts total     0
Train Time (s)               118.85477439407259
(Previous) Eval Time (s)     24.579236677847803
Sample Time (s)              17.955872469116002
Epoch Time (s)               161.3898835410364
Total Train Time (s)         104890.0258034505
Epoch                        663
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:39:47.376707 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #663 | Epoch Duration: 163.34195756912231
2020-01-13 04:39:47.377012 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #663 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2167492
Z variance train             0.004204954
KL Divergence                30.846664
KL Loss                      3.0846665
QF Loss                      1477.5967
VF Loss                      209.85323
Policy Loss                  -2364.084
Q Predictions Mean           2368.6826
Q Predictions Std            270.67114
Q Predictions Max            3996.0542
Q Predictions Min            581.65027
V Predictions Mean           2366.255
V Predictions Std            273.03473
V Predictions Max            4121.078
V Predictions Min            573.1719
Log Pis Mean                 2.8487258
Log Pis Std                  3.6584702
Log Pis Max                  18.612164
Log Pis Min                  -7.1571183
Policy mu Mean               0.040913068
Policy mu Std                0.72907704
Policy mu Max                3.0399501
Policy mu Min                -3.274575
Policy log std Mean          -1.331611
Policy log std Std           0.3159595
Policy log std Max           -0.07106328
Policy log std Min           -2.8283591
Z mean eval                  1.2633694
Z variance eval              0.0040374086
total_rewards                [  -12.34341739  2284.50178172  2955.99652857    50.34926998
  -757.46702716   107.06749829  3849.26429707 -1177.43584215
  4829.2128652   5356.36133902]
total_rewards_mean           1748.5507293148505
total_rewards_std            2284.4160955421753
total_rewards_max            5356.361339023552
total_rewards_min            -1177.4358421450952
Number of train steps total  2660000
Number of env steps total    3327000
Number of rollouts total     0
Train Time (s)               122.46649031061679
(Previous) Eval Time (s)     26.530962532386184
Sample Time (s)              17.695728816092014
Epoch Time (s)               166.693181659095
Total Train Time (s)         105049.81893268833
Epoch                        664
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:42:27.171616 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #664 | Epoch Duration: 159.7943980693817
2020-01-13 04:42:27.171834 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #664 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.261895
Z variance train             0.0040544528
KL Divergence                31.129562
KL Loss                      3.1129563
QF Loss                      1710.9122
VF Loss                      674.6441
Policy Loss                  -2354.4822
Q Predictions Mean           2360.401
Q Predictions Std            257.21768
Q Predictions Max            3559.6575
Q Predictions Min            695.1322
V Predictions Mean           2363.1624
V Predictions Std            254.87598
V Predictions Max            3597.1978
V Predictions Min            740.1456
Log Pis Mean                 3.0687938
Log Pis Std                  3.7984853
Log Pis Max                  18.635242
Log Pis Min                  -8.065426
Policy mu Mean               0.018430134
Policy mu Std                0.7047199
Policy mu Max                3.4370055
Policy mu Min                -4.5222673
Policy log std Mean          -1.3816068
Policy log std Std           0.32229832
Policy log std Max           -0.18209219
Policy log std Min           -2.848631
Z mean eval                  1.2514217
Z variance eval              0.018814784
total_rewards                [ 138.25079776 4173.99813904 5644.74650738 5582.37618461 3647.95192909
  999.75656291 2357.5073653  3521.24802289   35.26600475 5727.43269429]
total_rewards_mean           3182.853420803533
total_rewards_std            2103.1102158634735
total_rewards_max            5727.432694290748
total_rewards_min            35.26600475285996
Number of train steps total  2664000
Number of env steps total    3332000
Number of rollouts total     0
Train Time (s)               118.87909751804546
(Previous) Eval Time (s)     19.631908898241818
Sample Time (s)              18.07310116570443
Epoch Time (s)               156.5841075819917
Total Train Time (s)         105208.42239140812
Epoch                        665
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:45:05.784284 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #665 | Epoch Duration: 158.61227583885193
2020-01-13 04:45:05.784543 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #665 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2512358
Z variance train             0.018901149
KL Divergence                28.99347
KL Loss                      2.899347
QF Loss                      30035.87
VF Loss                      9035.421
Policy Loss                  -2367.349
Q Predictions Mean           2369.7773
Q Predictions Std            189.00397
Q Predictions Max            3694.0322
Q Predictions Min            702.02185
V Predictions Mean           2373.0383
V Predictions Std            158.46947
V Predictions Max            3686.9524
V Predictions Min            1810.9695
Log Pis Mean                 2.8389373
Log Pis Std                  3.8679419
Log Pis Max                  25.21151
Log Pis Min                  -6.9588685
Policy mu Mean               0.056481093
Policy mu Std                0.69433385
Policy mu Max                3.726597
Policy mu Min                -3.089326
Policy log std Mean          -1.3390999
Policy log std Std           0.30583233
Policy log std Max           -0.14563978
Policy log std Min           -3.0715103
Z mean eval                  1.2522491
Z variance eval              0.011716757
total_rewards                [-510.32050045 1653.76889251 1880.7566047  -716.00778191 3213.48742419
 2457.6854247  4669.57192329 5492.58292544 -589.62964185 -848.16399685]
total_rewards_mean           1670.3731273768183
total_rewards_std            2203.4282552016566
total_rewards_max            5492.5829254387245
total_rewards_min            -848.1639968542064
Number of train steps total  2668000
Number of env steps total    3337000
Number of rollouts total     0
Train Time (s)               120.83442650223151
(Previous) Eval Time (s)     21.65972157381475
Sample Time (s)              17.779546292033046
Epoch Time (s)               160.2736943680793
Total Train Time (s)         105374.90059930319
Epoch                        666
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:47:52.267786 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #666 | Epoch Duration: 166.4830493927002
2020-01-13 04:47:52.268036 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #666 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2516305
Z variance train             0.011695027
KL Divergence                30.942795
KL Loss                      3.0942795
QF Loss                      2130.323
VF Loss                      714.20795
Policy Loss                  -2362.609
Q Predictions Mean           2363.2847
Q Predictions Std            333.35666
Q Predictions Max            6033.5674
Q Predictions Min            561.9436
V Predictions Mean           2358.798
V Predictions Std            324.62863
V Predictions Max            5976.0444
V Predictions Min            713.2871
Log Pis Mean                 3.3121872
Log Pis Std                  3.8836586
Log Pis Max                  14.506123
Log Pis Min                  -5.4363675
Policy mu Mean               0.007307023
Policy mu Std                0.72074693
Policy mu Max                3.1268175
Policy mu Min                -3.8082561
Policy log std Mean          -1.3923291
Policy log std Std           0.3318834
Policy log std Max           -0.17542434
Policy log std Min           -3.1552582
Z mean eval                  1.2153988
Z variance eval              0.011493896
total_rewards                [-915.71107162 5632.56176746 5672.17333744 5521.46099348 5492.25349846
 5626.54316962 5843.62157266 1022.2743896  -987.08464015 5499.89664531]
total_rewards_mean           3840.7989662258638
total_rewards_std            2755.829955797779
total_rewards_max            5843.621572658905
total_rewards_min            -987.0846401522858
Number of train steps total  2672000
Number of env steps total    3342000
Number of rollouts total     0
Train Time (s)               122.76538102189079
(Previous) Eval Time (s)     27.86879410315305
Sample Time (s)              18.38208274450153
Epoch Time (s)               169.01625786954537
Total Train Time (s)         105542.7782851262
Epoch                        667
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:50:40.153031 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #667 | Epoch Duration: 167.88479614257812
2020-01-13 04:50:40.153306 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #667 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2174098
Z variance train             0.011513529
KL Divergence                29.653227
KL Loss                      2.9653227
QF Loss                      5597.534
VF Loss                      679.7888
Policy Loss                  -2320.9622
Q Predictions Mean           2320.3325
Q Predictions Std            298.3395
Q Predictions Max            4946.8213
Q Predictions Min            342.5753
V Predictions Mean           2317.3333
V Predictions Std            280.36737
V Predictions Max            4846.7236
V Predictions Min            329.8719
Log Pis Mean                 2.7084656
Log Pis Std                  3.5346146
Log Pis Max                  24.89797
Log Pis Min                  -6.3969226
Policy mu Mean               0.009200306
Policy mu Std                0.6582641
Policy mu Max                3.4806561
Policy mu Min                -2.7561738
Policy log std Mean          -1.3820776
Policy log std Std           0.31304994
Policy log std Max           -0.19318819
Policy log std Min           -3.0280566
Z mean eval                  1.2180594
Z variance eval              0.0058466285
total_rewards                [3352.74794581 5710.6780981  5708.59737991 5632.70010465 5560.79617514
 3948.11157033 3918.00541799 5786.82359516 4258.60355903 5631.58730523]
total_rewards_mean           4950.865115133863
total_rewards_std            908.6317438895385
total_rewards_max            5786.823595161907
total_rewards_min            3352.747945806455
Number of train steps total  2676000
Number of env steps total    3347000
Number of rollouts total     0
Train Time (s)               126.46754540130496
(Previous) Eval Time (s)     26.737044561188668
Sample Time (s)              18.438894690480083
Epoch Time (s)               171.6434846529737
Total Train Time (s)         105712.0763770137
Epoch                        668
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:53:29.456106 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #668 | Epoch Duration: 169.302592754364
2020-01-13 04:53:29.456328 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #668 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.218662
Z variance train             0.0058591454
KL Divergence                30.376741
KL Loss                      3.0376742
QF Loss                      3489.57
VF Loss                      1054.8029
Policy Loss                  -2293.9016
Q Predictions Mean           2300.2903
Q Predictions Std            308.6939
Q Predictions Max            2724.7515
Q Predictions Min            282.64853
V Predictions Mean           2290.066
V Predictions Std            307.87244
V Predictions Max            2836.3833
V Predictions Min            333.33548
Log Pis Mean                 3.6324644
Log Pis Std                  4.0071034
Log Pis Max                  28.015766
Log Pis Min                  -4.7416744
Policy mu Mean               0.0063251127
Policy mu Std                0.73204684
Policy mu Max                5.706973
Policy mu Min                -5.572454
Policy log std Mean          -1.4076824
Policy log std Std           0.3261683
Policy log std Max           -0.20117581
Policy log std Min           -2.8310509
Z mean eval                  1.2053096
Z variance eval              0.00938784
total_rewards                [5490.48486276 5699.31713566 5648.5680741  3343.36341554 5809.32315692
 5649.0606336  5831.98690344 5669.5106455  5599.02088702 5700.79428148]
total_rewards_mean           5444.142999603735
total_rewards_std            706.3104256607047
total_rewards_max            5831.986903440081
total_rewards_min            3343.3634155421123
Number of train steps total  2680000
Number of env steps total    3352000
Number of rollouts total     0
Train Time (s)               122.39612393500283
(Previous) Eval Time (s)     24.395848067011684
Sample Time (s)              18.409123169258237
Epoch Time (s)               165.20109517127275
Total Train Time (s)         105879.64103940362
Epoch                        669
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:56:17.025419 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #669 | Epoch Duration: 167.56893658638
2020-01-13 04:56:17.025580 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #669 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2058394
Z variance train             0.009425746
KL Divergence                27.602837
KL Loss                      2.7602837
QF Loss                      1648.1394
VF Loss                      724.552
Policy Loss                  -2260.5251
Q Predictions Mean           2262.7969
Q Predictions Std            321.51917
Q Predictions Max            2507.0254
Q Predictions Min            82.65558
V Predictions Mean           2267.36
V Predictions Std            316.03094
V Predictions Max            2511.3582
V Predictions Min            96.36188
Log Pis Mean                 2.5433936
Log Pis Std                  3.507536
Log Pis Max                  14.279945
Log Pis Min                  -8.33181
Policy mu Mean               0.005629874
Policy mu Std                0.68175316
Policy mu Max                4.398203
Policy mu Min                -3.1636648
Policy log std Mean          -1.3537775
Policy log std Std           0.30012885
Policy log std Max           0.08717704
Policy log std Min           -2.6481702
Z mean eval                  1.1867102
Z variance eval              0.00878495
total_rewards                [5728.06209355 5762.53393535 5590.05667377 5733.96835881 5674.96590322
 5709.09671039 5812.04646773 5950.82049133 5734.79847408 5713.80973896]
total_rewards_mean           5741.015884718924
total_rewards_std            88.70893933823487
total_rewards_max            5950.820491331071
total_rewards_min            5590.056673774329
Number of train steps total  2684000
Number of env steps total    3357000
Number of rollouts total     0
Train Time (s)               120.5284549947828
(Previous) Eval Time (s)     26.763380791060627
Sample Time (s)              18.564197557978332
Epoch Time (s)               165.85603334382176
Total Train Time (s)         106047.1239565094
Epoch                        670
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:59:04.512375 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #670 | Epoch Duration: 167.48664689064026
2020-01-13 04:59:04.512572 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #670 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1866493
Z variance train             0.008779316
KL Divergence                28.843903
KL Loss                      2.8843904
QF Loss                      1029.5538
VF Loss                      1466.1844
Policy Loss                  -2298.7363
Q Predictions Mean           2303.5813
Q Predictions Std            293.46667
Q Predictions Max            4637.5845
Q Predictions Min            102.00237
V Predictions Mean           2299.6396
V Predictions Std            284.18143
V Predictions Max            4652.9976
V Predictions Min            84.98244
Log Pis Mean                 2.9499226
Log Pis Std                  3.741727
Log Pis Max                  17.71101
Log Pis Min                  -5.529221
Policy mu Mean               0.006920594
Policy mu Std                0.6890188
Policy mu Max                2.675967
Policy mu Min                -4.2893214
Policy log std Mean          -1.3834164
Policy log std Std           0.3126901
Policy log std Max           -0.17646217
Policy log std Min           -3.1738749
Z mean eval                  1.2482153
Z variance eval              0.009720714
total_rewards                [5577.61362631 5830.35433528  627.96480888 5522.55170214 5673.15667594
 5636.18889801 5718.24951345 5765.18680934 5678.12069479 5562.8481974 ]
total_rewards_mean           5159.2235261556725
total_rewards_std            1513.0522699335106
total_rewards_max            5830.354335283132
total_rewards_min            627.964808880845
Number of train steps total  2688000
Number of env steps total    3362000
Number of rollouts total     0
Train Time (s)               124.62027238914743
(Previous) Eval Time (s)     28.393670682795346
Sample Time (s)              18.54060193989426
Epoch Time (s)               171.55454501183704
Total Train Time (s)         106214.88758277008
Epoch                        671
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:01:52.284860 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #671 | Epoch Duration: 167.77214002609253
2020-01-13 05:01:52.285135 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #671 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2479918
Z variance train             0.009697465
KL Divergence                27.863764
KL Loss                      2.7863765
QF Loss                      2119.2822
VF Loss                      162.91116
Policy Loss                  -2297.6797
Q Predictions Mean           2302.4175
Q Predictions Std            250.03
Q Predictions Max            2505.5266
Q Predictions Min            340.49078
V Predictions Mean           2296.6099
V Predictions Std            246.82237
V Predictions Max            2648.9373
V Predictions Min            364.11844
Log Pis Mean                 2.6996715
Log Pis Std                  3.4143162
Log Pis Max                  20.225792
Log Pis Min                  -5.732996
Policy mu Mean               -0.026136443
Policy mu Std                0.68897957
Policy mu Max                2.6604562
Policy mu Min                -3.0425448
Policy log std Mean          -1.3476152
Policy log std Std           0.3013031
Policy log std Max           -0.07145822
Policy log std Min           -2.8949864
Z mean eval                  1.1718714
Z variance eval              0.011479176
total_rewards                [5498.65067757 5534.84698065 5764.80825246 5931.47552439  939.58655344
 5849.25243121 5642.20509663 5667.71885554 4772.94860963 5496.72241406]
total_rewards_mean           5109.821539558102
total_rewards_std            1422.3724124369205
total_rewards_max            5931.475524392294
total_rewards_min            939.5865534400153
Number of train steps total  2692000
Number of env steps total    3367000
Number of rollouts total     0
Train Time (s)               124.5583774340339
(Previous) Eval Time (s)     24.61092376988381
Sample Time (s)              18.744253443554044
Epoch Time (s)               167.91355464747176
Total Train Time (s)         106383.04053981323
Epoch                        672
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:04:40.444689 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #672 | Epoch Duration: 168.15935444831848
2020-01-13 05:04:40.444901 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #672 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1716521
Z variance train             0.011504357
KL Divergence                28.440914
KL Loss                      2.8440914
QF Loss                      886.098
VF Loss                      608.59814
Policy Loss                  -2321.3945
Q Predictions Mean           2322.4507
Q Predictions Std            336.7185
Q Predictions Max            6040.09
Q Predictions Min            253.9819
V Predictions Mean           2312.838
V Predictions Std            330.94247
V Predictions Max            6096.8325
V Predictions Min            319.28796
Log Pis Mean                 3.4265409
Log Pis Std                  4.4035244
Log Pis Max                  28.617853
Log Pis Min                  -7.659112
Policy mu Mean               -0.02650683
Policy mu Std                0.7324998
Policy mu Max                2.8147955
Policy mu Min                -4.5622616
Policy log std Mean          -1.4097142
Policy log std Std           0.343682
Policy log std Max           0.01669228
Policy log std Min           -3.157209
Z mean eval                  1.2314008
Z variance eval              0.005584347
total_rewards                [5325.18152222 5657.25089452 5647.86244151 2466.13206863 5621.00940236
 5544.69150003 5644.24853837 5585.03821119 5677.13839554 1593.69022946]
total_rewards_mean           4876.224320381696
total_rewards_std            1439.6478758433009
total_rewards_max            5677.1383955385845
total_rewards_min            1593.6902294596064
Number of train steps total  2696000
Number of env steps total    3372000
Number of rollouts total     0
Train Time (s)               119.70978087326512
(Previous) Eval Time (s)     24.856414816807956
Sample Time (s)              18.755424323957413
Epoch Time (s)               163.3216200140305
Total Train Time (s)         106545.12824506965
Epoch                        673
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:07:22.537053 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #673 | Epoch Duration: 162.09200143814087
2020-01-13 05:07:22.537321 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #673 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2313567
Z variance train             0.0055805715
KL Divergence                29.48268
KL Loss                      2.948268
QF Loss                      3699.9146
VF Loss                      1299.5417
Policy Loss                  -2313.918
Q Predictions Mean           2314.1924
Q Predictions Std            353.84683
Q Predictions Max            5000.995
Q Predictions Min            -15.01738
V Predictions Mean           2316.0405
V Predictions Std            364.5003
V Predictions Max            5489.5464
V Predictions Min            -60.35349
Log Pis Mean                 3.5917597
Log Pis Std                  5.3671694
Log Pis Max                  58.835167
Log Pis Min                  -6.0425763
Policy mu Mean               -0.008119779
Policy mu Std                0.7483027
Policy mu Max                8.482777
Policy mu Min                -5.479463
Policy log std Mean          -1.4442108
Policy log std Std           0.35686636
Policy log std Max           0.7821058
Policy log std Min           -4.050885
Z mean eval                  1.2470016
Z variance eval              0.013517382
total_rewards                [-1354.17391664  5827.41270132  5559.46716281  5568.59203859
  2126.53251281  -243.11681372  5713.74415976  5774.58025803
  5651.22716498  5672.01723775]
total_rewards_mean           4029.6282505702643
total_rewards_std            2645.9860854726753
total_rewards_max            5827.412701319537
total_rewards_min            -1354.1739166416853
Number of train steps total  2700000
Number of env steps total    3377000
Number of rollouts total     0
Train Time (s)               121.19523446494713
(Previous) Eval Time (s)     23.626439841929823
Sample Time (s)              18.041055239271373
Epoch Time (s)               162.86272954614833
Total Train Time (s)         106710.17301004473
Epoch                        674
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:10:07.586068 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #674 | Epoch Duration: 165.04860949516296
2020-01-13 05:10:07.586265 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #674 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2462386
Z variance train             0.013558629
KL Divergence                28.284267
KL Loss                      2.8284268
QF Loss                      1726.0134
VF Loss                      397.73047
Policy Loss                  -2278.8667
Q Predictions Mean           2281.0098
Q Predictions Std            315.3961
Q Predictions Max            2728.8057
Q Predictions Min            -37.83012
V Predictions Mean           2276.9019
V Predictions Std            308.5395
V Predictions Max            2741.7017
V Predictions Min            7.517292
Log Pis Mean                 3.4499516
Log Pis Std                  3.9245825
Log Pis Max                  17.601574
Log Pis Min                  -6.5868573
Policy mu Mean               0.02922112
Policy mu Std                0.747209
Policy mu Max                3.8882957
Policy mu Min                -3.5434523
Policy log std Mean          -1.3776593
Policy log std Std           0.32476616
Policy log std Max           -0.10994196
Policy log std Min           -2.786148
Z mean eval                  1.2749041
Z variance eval              0.0045463042
total_rewards                [5336.65916123 5563.2185803  5685.90763257 5647.50532627 5544.79166352
 5555.76166567 5561.21520313 5747.73215151 5496.75602098 5758.40826736]
total_rewards_mean           5589.795567251815
total_rewards_std            119.74279984697208
total_rewards_max            5758.408267363093
total_rewards_min            5336.659161228939
Number of train steps total  2704000
Number of env steps total    3382000
Number of rollouts total     0
Train Time (s)               117.29302470525727
(Previous) Eval Time (s)     25.8120439928025
Sample Time (s)              18.002715944312513
Epoch Time (s)               161.10778464237228
Total Train Time (s)         106872.82725580223
Epoch                        675
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:12:50.248489 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #675 | Epoch Duration: 162.66207647323608
2020-01-13 05:12:50.248712 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #675 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2740763
Z variance train             0.004546024
KL Divergence                29.779724
KL Loss                      2.9779725
QF Loss                      716.1939
VF Loss                      184.54886
Policy Loss                  -2283.3774
Q Predictions Mean           2284.711
Q Predictions Std            310.787
Q Predictions Max            2581.1807
Q Predictions Min            -210.03893
V Predictions Mean           2284.232
V Predictions Std            312.26028
V Predictions Max            2598.671
V Predictions Min            -177.04468
Log Pis Mean                 2.8583925
Log Pis Std                  3.3693104
Log Pis Max                  18.327938
Log Pis Min                  -4.100443
Policy mu Mean               -0.0015673963
Policy mu Std                0.66061026
Policy mu Max                2.473779
Policy mu Min                -2.924121
Policy log std Mean          -1.3531944
Policy log std Std           0.29518783
Policy log std Max           -0.31985343
Policy log std Min           -2.7796497
Z mean eval                  1.174306
Z variance eval              0.007066791
total_rewards                [5552.56772116 5750.76154625 5827.2290135  5726.08669835 5616.33812077
 5844.71482541 5765.61164394 5635.03206322 5771.76225997 5839.708794  ]
total_rewards_mean           5732.981268657799
total_rewards_std            95.62368364587137
total_rewards_max            5844.714825405235
total_rewards_min            5552.567721164196
Number of train steps total  2708000
Number of env steps total    3387000
Number of rollouts total     0
Train Time (s)               118.95505264913663
(Previous) Eval Time (s)     27.366044082213193
Sample Time (s)              17.938845430035144
Epoch Time (s)               164.25994216138497
Total Train Time (s)         107036.5143222888
Epoch                        676
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:15:33.944041 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #676 | Epoch Duration: 163.6951413154602
2020-01-13 05:15:33.944271 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #676 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1735023
Z variance train             0.007063879
KL Divergence                29.558857
KL Loss                      2.9558856
QF Loss                      922.69806
VF Loss                      239.65631
Policy Loss                  -2313.954
Q Predictions Mean           2318.1987
Q Predictions Std            279.01224
Q Predictions Max            3211.2275
Q Predictions Min            -236.64809
V Predictions Mean           2303.5215
V Predictions Std            276.86752
V Predictions Max            3244.5906
V Predictions Min            -209.26201
Log Pis Mean                 3.1346638
Log Pis Std                  3.815567
Log Pis Max                  22.478287
Log Pis Min                  -4.738148
Policy mu Mean               0.0058977203
Policy mu Std                0.7262271
Policy mu Max                3.0569463
Policy mu Min                -2.9620714
Policy log std Mean          -1.364033
Policy log std Std           0.3064445
Policy log std Max           -0.30215394
Policy log std Min           -2.9068165
Z mean eval                  1.1893321
Z variance eval              0.004456443
total_rewards                [2833.19352667 5834.07664706 5833.28116333 5588.16128016 5434.65905083
 5910.44158907 5739.32994142 5372.30413355 5802.41314663 5460.25667719]
total_rewards_mean           5380.81171559168
total_rewards_std            868.3089474294775
total_rewards_max            5910.441589072323
total_rewards_min            2833.1935266707974
Number of train steps total  2712000
Number of env steps total    3392000
Number of rollouts total     0
Train Time (s)               120.49755725916475
(Previous) Eval Time (s)     26.800909821875393
Sample Time (s)              18.18683074740693
Epoch Time (s)               165.48529782844707
Total Train Time (s)         107201.9322053655
Epoch                        677
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:18:19.370738 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #677 | Epoch Duration: 165.42628288269043
2020-01-13 05:18:19.370984 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #677 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1900871
Z variance train             0.0044451165
KL Divergence                30.312088
KL Loss                      3.0312088
QF Loss                      2764.5122
VF Loss                      1535.4824
Policy Loss                  -2325.4067
Q Predictions Mean           2323.8647
Q Predictions Std            376.59354
Q Predictions Max            6230.6274
Q Predictions Min            -121.78099
V Predictions Mean           2335.5378
V Predictions Std            370.06232
V Predictions Max            6329.9023
V Predictions Min            24.39843
Log Pis Mean                 3.1279657
Log Pis Std                  4.6203823
Log Pis Max                  21.702316
Log Pis Min                  -9.676863
Policy mu Mean               0.0074268384
Policy mu Std                0.76969063
Policy mu Max                4.170044
Policy mu Min                -3.2163422
Policy log std Mean          -1.3429731
Policy log std Std           0.33016402
Policy log std Max           0.04848647
Policy log std Min           -3.4031034
Z mean eval                  1.2007748
Z variance eval              0.0057100593
total_rewards                [5567.4900554  5882.782863   5607.39947567 5966.59027888 5869.88600896
 1581.35483493 5841.24320621 5709.02567045 5956.20943602 5735.10835849]
total_rewards_mean           5371.709018801046
total_rewards_std            1270.1129965762414
total_rewards_max            5966.590278882653
total_rewards_min            1581.354834930824
Number of train steps total  2716000
Number of env steps total    3397000
Number of rollouts total     0
Train Time (s)               114.06646133493632
(Previous) Eval Time (s)     26.741563106887043
Sample Time (s)              19.108605517540127
Epoch Time (s)               159.9166299593635
Total Train Time (s)         107360.79054899653
Epoch                        678
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:20:58.235351 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #678 | Epoch Duration: 158.86418080329895
2020-01-13 05:20:58.235540 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #678 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2008811
Z variance train             0.0057203895
KL Divergence                30.526693
KL Loss                      3.0526693
QF Loss                      2448.3289
VF Loss                      478.17505
Policy Loss                  -2316.9214
Q Predictions Mean           2320.083
Q Predictions Std            321.2991
Q Predictions Max            4218.5415
Q Predictions Min            166.69168
V Predictions Mean           2308.4412
V Predictions Std            325.62286
V Predictions Max            4540.206
V Predictions Min            180.54451
Log Pis Mean                 3.2074976
Log Pis Std                  4.1451325
Log Pis Max                  31.810028
Log Pis Min                  -5.083043
Policy mu Mean               0.008626963
Policy mu Std                0.7207533
Policy mu Max                6.3134665
Policy mu Min                -3.361968
Policy log std Mean          -1.3797016
Policy log std Std           0.31146574
Policy log std Max           -0.2465173
Policy log std Min           -2.8946855
Z mean eval                  1.1668377
Z variance eval              0.012249475
total_rewards                [5361.76885787 5614.62988647 5773.13940917 5428.61075483 1489.30081047
 1807.29376554 5836.72200418 5668.09653944 5800.16104551 5670.61405492]
total_rewards_mean           4845.033712840734
total_rewards_std            1606.3863898237387
total_rewards_max            5836.722004182341
total_rewards_min            1489.300810467821
Number of train steps total  2720000
Number of env steps total    3402000
Number of rollouts total     0
Train Time (s)               118.55309678334743
(Previous) Eval Time (s)     25.6888076569885
Sample Time (s)              18.189066303428262
Epoch Time (s)               162.4309707437642
Total Train Time (s)         107520.28931965167
Epoch                        679
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:23:37.738889 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #679 | Epoch Duration: 159.50322079658508
2020-01-13 05:23:37.739085 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #679 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1667172
Z variance train             0.012257069
KL Divergence                29.073528
KL Loss                      2.907353
QF Loss                      6187.2686
VF Loss                      438.61307
Policy Loss                  -2303.7627
Q Predictions Mean           2300.669
Q Predictions Std            343.5048
Q Predictions Max            4332.414
Q Predictions Min            -245.49225
V Predictions Mean           2309.6929
V Predictions Std            346.29724
V Predictions Max            4396.0303
V Predictions Min            -157.66832
Log Pis Mean                 3.082758
Log Pis Std                  3.9674685
Log Pis Max                  30.285994
Log Pis Min                  -4.122162
Policy mu Mean               0.009926729
Policy mu Std                0.73869884
Policy mu Max                3.0977392
Policy mu Min                -5.273598
Policy log std Mean          -1.3681061
Policy log std Std           0.35001183
Policy log std Max           0.7729095
Policy log std Min           -3.1750956
Z mean eval                  1.1754351
Z variance eval              0.008191155
total_rewards                [5574.31939573 5781.10855746 5633.98966334 5941.83164121 5559.90537412
 5711.1048449  3643.10386137 5837.44999612  114.53856386 3409.24434799]
total_rewards_mean           4720.65962461108
total_rewards_std            1766.593993284346
total_rewards_max            5941.831641210566
total_rewards_min            114.53856386389766
Number of train steps total  2724000
Number of env steps total    3407000
Number of rollouts total     0
Train Time (s)               125.56532765971497
(Previous) Eval Time (s)     22.760764389764518
Sample Time (s)              17.91476670326665
Epoch Time (s)               166.24085875274613
Total Train Time (s)         107685.53180524195
Epoch                        680
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:26:22.986576 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #680 | Epoch Duration: 165.24734377861023
2020-01-13 05:26:22.986801 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #680 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1773846
Z variance train             0.008165258
KL Divergence                29.423065
KL Loss                      2.9423065
QF Loss                      2097.2625
VF Loss                      428.67722
Policy Loss                  -2314.9192
Q Predictions Mean           2316.3281
Q Predictions Std            429.7419
Q Predictions Max            6492.8867
Q Predictions Min            -165.00641
V Predictions Mean           2320.6033
V Predictions Std            437.36813
V Predictions Max            6656.661
V Predictions Min            -234.11952
Log Pis Mean                 3.0703986
Log Pis Std                  4.155715
Log Pis Max                  21.643692
Log Pis Min                  -9.554525
Policy mu Mean               -0.034308534
Policy mu Std                0.72001785
Policy mu Max                3.6096618
Policy mu Min                -3.4979174
Policy log std Mean          -1.3784099
Policy log std Std           0.34338933
Policy log std Max           0.39061618
Policy log std Min           -2.7625442
Z mean eval                  1.2218642
Z variance eval              0.008008669
total_rewards                [5738.4528328  5730.38434641 5719.78453058 5870.29125893 5796.54062288
 5801.17095477 5712.16179515 5335.38543026 5695.41710681 5612.08094374]
total_rewards_mean           5701.166982233489
total_rewards_std            138.62786947342912
total_rewards_max            5870.291258932591
total_rewards_min            5335.3854302599175
Number of train steps total  2728000
Number of env steps total    3412000
Number of rollouts total     0
Train Time (s)               126.60208710609004
(Previous) Eval Time (s)     21.766972055658698
Sample Time (s)              18.58215574035421
Epoch Time (s)               166.95121490210295
Total Train Time (s)         107857.38213568134
Epoch                        681
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:29:14.843080 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #681 | Epoch Duration: 171.85613918304443
2020-01-13 05:29:14.843317 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #681 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2226117
Z variance train             0.008026933
KL Divergence                30.175085
KL Loss                      3.0175085
QF Loss                      529.3865
VF Loss                      267.20685
Policy Loss                  -2316.5557
Q Predictions Mean           2318.1606
Q Predictions Std            301.2272
Q Predictions Max            3131.9438
Q Predictions Min            -51.64646
V Predictions Mean           2314.461
V Predictions Std            298.16452
V Predictions Max            3184.1511
V Predictions Min            31.83274
Log Pis Mean                 2.9434953
Log Pis Std                  4.1641903
Log Pis Max                  23.631468
Log Pis Min                  -5.272491
Policy mu Mean               -0.028794106
Policy mu Std                0.7306718
Policy mu Max                3.060884
Policy mu Min                -3.354606
Policy log std Mean          -1.3455853
Policy log std Std           0.33328333
Policy log std Max           0.51387167
Policy log std Min           -2.8919554
Z mean eval                  1.1799204
Z variance eval              0.0067233564
total_rewards                [5719.23022589 5745.56131193 5416.48791477 5633.75150447 5835.23774175
 5743.22647024 5682.76002868 5751.66430536 5775.11819866 5676.22894082]
total_rewards_mean           5697.926664256686
total_rewards_std            107.93637559165028
total_rewards_max            5835.237741745706
total_rewards_min            5416.48791477038
Number of train steps total  2732000
Number of env steps total    3417000
Number of rollouts total     0
Train Time (s)               124.84787401976064
(Previous) Eval Time (s)     26.671585474163294
Sample Time (s)              18.90210562106222
Epoch Time (s)               170.42156511498615
Total Train Time (s)         108028.41751479404
Epoch                        682
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:32:05.885457 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #682 | Epoch Duration: 171.0419738292694
2020-01-13 05:32:05.885641 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #682 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1796248
Z variance train             0.0066994056
KL Divergence                30.049675
KL Loss                      3.0049675
QF Loss                      1173.1287
VF Loss                      342.8156
Policy Loss                  -2307.047
Q Predictions Mean           2312.1096
Q Predictions Std            309.4634
Q Predictions Max            2501.2344
Q Predictions Min            -269.17563
V Predictions Mean           2318.1768
V Predictions Std            308.96524
V Predictions Max            2505.1233
V Predictions Min            -297.7393
Log Pis Mean                 3.390542
Log Pis Std                  3.9534786
Log Pis Max                  20.579283
Log Pis Min                  -4.224656
Policy mu Mean               0.03459411
Policy mu Std                0.6779259
Policy mu Max                3.3804307
Policy mu Min                -3.169313
Policy log std Mean          -1.4453225
Policy log std Std           0.33848047
Policy log std Max           -0.45122647
Policy log std Min           -3.6151633
Z mean eval                  1.1656113
Z variance eval              0.0049983137
total_rewards                [5599.52590552 1818.38441651 5805.88964692 5696.96647529 5669.51515311
 5603.42018027 5761.14066026 5676.69802026 5719.49875341 5810.80131656]
total_rewards_mean           5316.184052811534
total_rewards_std            1168.0027770216877
total_rewards_max            5810.801316562352
total_rewards_min            1818.3844165081746
Number of train steps total  2736000
Number of env steps total    3422000
Number of rollouts total     0
Train Time (s)               118.52094209799543
(Previous) Eval Time (s)     27.291662560775876
Sample Time (s)              18.170465958770365
Epoch Time (s)               163.98307061754167
Total Train Time (s)         108192.21079031844
Epoch                        683
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:34:49.683732 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #683 | Epoch Duration: 163.79795742034912
2020-01-13 05:34:49.683938 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #683 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1601722
Z variance train             0.0050236806
KL Divergence                30.84592
KL Loss                      3.084592
QF Loss                      1249.7341
VF Loss                      2072.9988
Policy Loss                  -2298.9634
Q Predictions Mean           2298.9934
Q Predictions Std            458.2408
Q Predictions Max            6096.773
Q Predictions Min            -259.30463
V Predictions Mean           2290.355
V Predictions Std            443.7702
V Predictions Max            5807.0347
V Predictions Min            -199.14719
Log Pis Mean                 3.3529673
Log Pis Std                  5.0588484
Log Pis Max                  46.27596
Log Pis Min                  -5.8739076
Policy mu Mean               0.0318954
Policy mu Std                0.7665487
Policy mu Max                7.73277
Policy mu Min                -5.030447
Policy log std Mean          -1.3537791
Policy log std Std           0.3280296
Policy log std Max           0.09993672
Policy log std Min           -3.1050236
Z mean eval                  1.2015135
Z variance eval              0.0130389575
total_rewards                [5368.74619643 5466.77665228 5729.00489548 5488.18807637 4891.54026783
 4814.45622752 5684.31906819 5738.13093387 2642.18844202 5616.07942803]
total_rewards_mean           5143.943018801011
total_rewards_std            889.6394259257467
total_rewards_max            5738.130933870036
total_rewards_min            2642.188442023935
Number of train steps total  2740000
Number of env steps total    3427000
Number of rollouts total     0
Train Time (s)               120.72567693889141
(Previous) Eval Time (s)     27.106245949864388
Sample Time (s)              18.47933328151703
Epoch Time (s)               166.31125617027283
Total Train Time (s)         108357.71582529414
Epoch                        684
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:37:35.195754 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #684 | Epoch Duration: 165.5116810798645
2020-01-13 05:37:35.195979 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #684 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2005546
Z variance train             0.0130562065
KL Divergence                29.509684
KL Loss                      2.9509685
QF Loss                      2457.412
VF Loss                      511.6937
Policy Loss                  -2332.4316
Q Predictions Mean           2338.936
Q Predictions Std            321.91003
Q Predictions Max            3303.5903
Q Predictions Min            -138.17198
V Predictions Mean           2341.0637
V Predictions Std            341.56137
V Predictions Max            3404.283
V Predictions Min            -242.47662
Log Pis Mean                 2.9494114
Log Pis Std                  4.430756
Log Pis Max                  23.523182
Log Pis Min                  -9.515514
Policy mu Mean               -0.006235956
Policy mu Std                0.7293279
Policy mu Max                3.8378608
Policy mu Min                -3.2916718
Policy log std Mean          -1.3534093
Policy log std Std           0.3343956
Policy log std Max           0.017841935
Policy log std Min           -3.6693175
Z mean eval                  1.2109711
Z variance eval              0.006563795
total_rewards                [4104.39577111 2173.37024121 2445.09140858 5501.23634691 5619.97743575
 5646.04197573 -948.72334271 5573.84130902 5844.25549886 5630.35183129]
total_rewards_mean           4158.983847573831
total_rewards_std            2147.6990738360087
total_rewards_max            5844.2554988564425
total_rewards_min            -948.7233427122293
Number of train steps total  2744000
Number of env steps total    3432000
Number of rollouts total     0
Train Time (s)               127.65319865196943
(Previous) Eval Time (s)     26.30635931994766
Sample Time (s)              17.827423709910363
Epoch Time (s)               171.78698168182746
Total Train Time (s)         108528.47349022143
Epoch                        685
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:40:25.957860 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #685 | Epoch Duration: 170.7617290019989
2020-01-13 05:40:25.958016 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #685 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2091849
Z variance train             0.0065819905
KL Divergence                30.37923
KL Loss                      3.037923
QF Loss                      1409.2164
VF Loss                      592.36255
Policy Loss                  -2389.385
Q Predictions Mean           2390.851
Q Predictions Std            416.37372
Q Predictions Max            5231.895
Q Predictions Min            -145.6888
V Predictions Mean           2390.2175
V Predictions Std            422.77682
V Predictions Max            5300.7437
V Predictions Min            -108.42947
Log Pis Mean                 3.1022155
Log Pis Std                  4.3024807
Log Pis Max                  27.497643
Log Pis Min                  -4.7723265
Policy mu Mean               -0.03042443
Policy mu Std                0.7395829
Policy mu Max                4.2693644
Policy mu Min                -4.4073124
Policy log std Mean          -1.3342438
Policy log std Std           0.32697234
Policy log std Max           0.116951585
Policy log std Min           -2.972033
Z mean eval                  1.2574502
Z variance eval              0.006713868
total_rewards                [  -24.43543718   256.23452489  4092.94188949    94.61910485
  5704.92449901  1521.53785821  1687.69982915  1858.35618615
  -526.91521311 -2133.19285451]
total_rewards_mean           1253.1770386970359
total_rewards_std            2170.577416785083
total_rewards_max            5704.924499010738
total_rewards_min            -2133.192854505816
Number of train steps total  2748000
Number of env steps total    3437000
Number of rollouts total     0
Train Time (s)               116.82304486865178
(Previous) Eval Time (s)     25.28078718110919
Sample Time (s)              17.735103223007172
Epoch Time (s)               159.83893527276814
Total Train Time (s)         108680.4363950151
Epoch                        686
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:42:57.925143 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #686 | Epoch Duration: 151.9670102596283
2020-01-13 05:42:57.925333 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #686 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2576101
Z variance train             0.006710184
KL Divergence                30.474545
KL Loss                      3.0474546
QF Loss                      2085.5544
VF Loss                      2616.9368
Policy Loss                  -2364.261
Q Predictions Mean           2368.5034
Q Predictions Std            285.96756
Q Predictions Max            3610.6067
Q Predictions Min            149.34027
V Predictions Mean           2354.893
V Predictions Std            294.57617
V Predictions Max            3608.283
V Predictions Min            16.425777
Log Pis Mean                 3.2347448
Log Pis Std                  4.5308223
Log Pis Max                  27.60619
Log Pis Min                  -5.0674667
Policy mu Mean               0.07958998
Policy mu Std                0.75747705
Policy mu Max                7.355282
Policy mu Min                -3.0042577
Policy log std Mean          -1.3670857
Policy log std Std           0.3704132
Policy log std Max           0.7229036
Policy log std Min           -3.3885207
Z mean eval                  1.2194016
Z variance eval              0.0041064294
total_rewards                [ 705.10387023 3104.16551724  616.1750708   397.02411874 3045.17121363
 1360.94761001 3364.77924346 3035.26936598 -442.04546142 5645.48710048]
total_rewards_mean           2083.207764914691
total_rewards_std            1760.6687186231143
total_rewards_max            5645.487100482798
total_rewards_min            -442.04546141741054
Number of train steps total  2752000
Number of env steps total    3442000
Number of rollouts total     0
Train Time (s)               122.44332618219778
(Previous) Eval Time (s)     17.408582446165383
Sample Time (s)              18.161040351726115
Epoch Time (s)               158.01294898008928
Total Train Time (s)         108839.5519282408
Epoch                        687
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:45:37.045427 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #687 | Epoch Duration: 159.119961977005
2020-01-13 05:45:37.045629 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #687 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2180288
Z variance train             0.004088351
KL Divergence                30.98053
KL Loss                      3.098053
QF Loss                      10229.3545
VF Loss                      3224.4097
Policy Loss                  -2382.961
Q Predictions Mean           2391.628
Q Predictions Std            346.51462
Q Predictions Max            3840.235
Q Predictions Min            -71.07753
V Predictions Mean           2382.9587
V Predictions Std            348.1176
V Predictions Max            3909.3198
V Predictions Min            32.549557
Log Pis Mean                 3.1955504
Log Pis Std                  4.6377835
Log Pis Max                  23.317526
Log Pis Min                  -4.8861833
Policy mu Mean               -0.02082583
Policy mu Std                0.7487504
Policy mu Max                3.2177393
Policy mu Min                -4.5951633
Policy log std Mean          -1.3498514
Policy log std Std           0.36942554
Policy log std Max           0.39066494
Policy log std Min           -3.6625857
Z mean eval                  1.1933678
Z variance eval              0.00787518
total_rewards                [ -404.48540303  1080.78263661  1759.44095902  -932.45295183
 -1104.57655172  3107.52438755  -772.69762738   630.12952528
 -1091.64833493    10.09389902]
total_rewards_mean           228.21105386008134
total_rewards_std            1335.6166249063774
total_rewards_max            3107.524387554048
total_rewards_min            -1104.5765517177865
Number of train steps total  2756000
Number of env steps total    3447000
Number of rollouts total     0
Train Time (s)               120.84354644780979
(Previous) Eval Time (s)     18.515267742797732
Sample Time (s)              17.392888294532895
Epoch Time (s)               156.7517024851404
Total Train Time (s)         109000.51406905614
Epoch                        688
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:48:18.013460 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #688 | Epoch Duration: 160.9676992893219
2020-01-13 05:48:18.013641 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #688 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1935078
Z variance train             0.007870099
KL Divergence                30.12227
KL Loss                      3.012227
QF Loss                      863.4763
VF Loss                      137.88197
Policy Loss                  -2386.9624
Q Predictions Mean           2389.474
Q Predictions Std            363.10373
Q Predictions Max            4602.114
Q Predictions Min            -108.3365
V Predictions Mean           2383.544
V Predictions Std            365.82776
V Predictions Max            4612.3193
V Predictions Min            -127.88607
Log Pis Mean                 2.7048106
Log Pis Std                  4.2688794
Log Pis Max                  18.727253
Log Pis Min                  -8.391134
Policy mu Mean               -0.051101916
Policy mu Std                0.7261105
Policy mu Max                3.3988152
Policy mu Min                -3.5690074
Policy log std Mean          -1.3069286
Policy log std Std           0.3343016
Policy log std Max           0.23362458
Policy log std Min           -2.8475308
Z mean eval                  1.2147132
Z variance eval              0.01177028
total_rewards                [-451.60407178 5835.43581327 2398.92586776 -760.06173159 1631.8972181
  510.1790747  -477.31938339  832.17681917 1257.06854659 5478.11761578]
total_rewards_mean           1625.4815768604649
total_rewards_std            2227.1194438120824
total_rewards_max            5835.435813266619
total_rewards_min            -760.0617315908182
Number of train steps total  2760000
Number of env steps total    3452000
Number of rollouts total     0
Train Time (s)               118.92064836388454
(Previous) Eval Time (s)     22.730959654785693
Sample Time (s)              18.232074156869203
Epoch Time (s)               159.88368217553943
Total Train Time (s)         109159.3389202524
Epoch                        689
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:50:56.848911 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #689 | Epoch Duration: 158.8351058959961
2020-01-13 05:50:56.849181 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #689 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2142771
Z variance train             0.0117640365
KL Divergence                29.110765
KL Loss                      2.9110765
QF Loss                      1111.5985
VF Loss                      235.62743
Policy Loss                  -2378.7576
Q Predictions Mean           2380.3113
Q Predictions Std            209.92708
Q Predictions Max            2985.0552
Q Predictions Min            295.48877
V Predictions Mean           2380.392
V Predictions Std            209.5259
V Predictions Max            2971.744
V Predictions Min            250.7488
Log Pis Mean                 2.532401
Log Pis Std                  3.932339
Log Pis Max                  23.430012
Log Pis Min                  -5.8542547
Policy mu Mean               -0.013703409
Policy mu Std                0.73543763
Policy mu Max                3.0277207
Policy mu Min                -3.9872866
Policy log std Mean          -1.2741754
Policy log std Std           0.29441205
Policy log std Max           0.032600522
Policy log std Min           -2.6369734
Z mean eval                  1.181153
Z variance eval              0.0101329405
total_rewards                [5454.46770532 5800.58525992 5697.24134909 4351.38675421 5805.67116122
 -736.17191139 5749.58433679 5862.49409595 1101.96231287 5467.53732435]
total_rewards_mean           4455.475838834989
total_rewards_std            2214.9738733129516
total_rewards_max            5862.494095950942
total_rewards_min            -736.1719113852489
Number of train steps total  2764000
Number of env steps total    3457000
Number of rollouts total     0
Train Time (s)               123.40863540023565
(Previous) Eval Time (s)     21.68204772984609
Sample Time (s)              17.855778786819428
Epoch Time (s)               162.94646191690117
Total Train Time (s)         109327.83529852424
Epoch                        690
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:53:45.350644 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #690 | Epoch Duration: 168.50127339363098
2020-01-13 05:53:45.350816 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #690 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1799543
Z variance train             0.01014979
KL Divergence                29.625092
KL Loss                      2.9625092
QF Loss                      610.85583
VF Loss                      433.3717
Policy Loss                  -2331.78
Q Predictions Mean           2334.7285
Q Predictions Std            369.77527
Q Predictions Max            2808.969
Q Predictions Min            -179.96124
V Predictions Mean           2330.7808
V Predictions Std            373.25238
V Predictions Max            2859.408
V Predictions Min            -166.31688
Log Pis Mean                 2.46147
Log Pis Std                  3.4301298
Log Pis Max                  21.681602
Log Pis Min                  -5.328431
Policy mu Mean               -0.008667483
Policy mu Std                0.67246467
Policy mu Max                4.012477
Policy mu Min                -2.9559708
Policy log std Mean          -1.3322122
Policy log std Std           0.29542658
Policy log std Max           -0.12929034
Policy log std Min           -2.7890177
Z mean eval                  1.2211663
Z variance eval              0.005422921
total_rewards                [5517.33041083 5773.42126296 3963.08327209 5616.73598357 5750.06603381
 5418.54957974 5935.80465975 5127.14226715 5797.1494372  5501.22165696]
total_rewards_mean           5440.050456405888
total_rewards_std            538.6348887586627
total_rewards_max            5935.804659746006
total_rewards_min            3963.0832720948047
Number of train steps total  2768000
Number of env steps total    3462000
Number of rollouts total     0
Train Time (s)               116.26949104759842
(Previous) Eval Time (s)     27.236574505921453
Sample Time (s)              18.280070218723267
Epoch Time (s)               161.78613577224314
Total Train Time (s)         109488.0871306127
Epoch                        691
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:56:25.612677 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #691 | Epoch Duration: 160.2617003917694
2020-01-13 05:56:25.612946 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #691 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2240266
Z variance train             0.0054126633
KL Divergence                28.643637
KL Loss                      2.8643637
QF Loss                      1280.1587
VF Loss                      277.63043
Policy Loss                  -2330.4766
Q Predictions Mean           2334.565
Q Predictions Std            266.1055
Q Predictions Max            2907.001
Q Predictions Min            -108.09223
V Predictions Mean           2326.3203
V Predictions Std            276.05127
V Predictions Max            2814.0635
V Predictions Min            -380.08618
Log Pis Mean                 2.6177936
Log Pis Std                  3.5871837
Log Pis Max                  14.293451
Log Pis Min                  -6.2219768
Policy mu Mean               0.020629518
Policy mu Std                0.6940367
Policy mu Max                3.7420425
Policy mu Min                -2.837008
Policy log std Mean          -1.3259671
Policy log std Std           0.3100594
Policy log std Max           -0.13733292
Policy log std Min           -2.7714243
Z mean eval                  1.3313465
Z variance eval              0.0046735727
total_rewards                [5595.36667944 5778.39827138 5858.01858853 5828.69104267 5837.38101774
 5643.34899348 4276.28980606 5923.16065452 5942.74350653 5698.71516074]
total_rewards_mean           5638.211372107622
total_rewards_std            466.7127242272224
total_rewards_max            5942.743506533728
total_rewards_min            4276.289806055507
Number of train steps total  2772000
Number of env steps total    3467000
Number of rollouts total     0
Train Time (s)               122.41078194975853
(Previous) Eval Time (s)     25.711831321008503
Sample Time (s)              18.741749067325145
Epoch Time (s)               166.86436233809218
Total Train Time (s)         109655.68377147056
Epoch                        692
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:59:13.213734 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #692 | Epoch Duration: 167.60058450698853
2020-01-13 05:59:13.213931 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #692 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3318307
Z variance train             0.0046781525
KL Divergence                29.32367
KL Loss                      2.932367
QF Loss                      1086.3743
VF Loss                      152.37036
Policy Loss                  -2312.3887
Q Predictions Mean           2313.3054
Q Predictions Std            332.2607
Q Predictions Max            2822.7793
Q Predictions Min            -353.58588
V Predictions Mean           2307.4028
V Predictions Std            328.31616
V Predictions Max            2814.1497
V Predictions Min            -350.6774
Log Pis Mean                 2.9228964
Log Pis Std                  3.7344716
Log Pis Max                  17.597101
Log Pis Min                  -7.2125845
Policy mu Mean               0.048178896
Policy mu Std                0.6924338
Policy mu Max                2.7897286
Policy mu Min                -3.371086
Policy log std Mean          -1.3455878
Policy log std Std           0.30706254
Policy log std Max           -0.20040286
Policy log std Min           -2.8246908
Z mean eval                  1.1646571
Z variance eval              0.008158088
total_rewards                [5504.47321798 5650.88266275 5300.70026264 1233.42354282 2973.84086365
 4714.50075005 5572.94733747 5286.98819947 5613.26828176 5576.64873809]
total_rewards_mean           4742.767385667524
total_rewards_std            1400.00205155343
total_rewards_max            5650.882662745784
total_rewards_min            1233.4235428213053
Number of train steps total  2776000
Number of env steps total    3472000
Number of rollouts total     0
Train Time (s)               115.85738632595167
(Previous) Eval Time (s)     26.447745488025248
Sample Time (s)              18.086459041573107
Epoch Time (s)               160.39159085555002
Total Train Time (s)         109814.29309041379
Epoch                        693
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:01:51.827075 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #693 | Epoch Duration: 158.61301136016846
2020-01-13 06:01:51.827245 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #693 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1645426
Z variance train             0.0081643285
KL Divergence                28.216328
KL Loss                      2.8216329
QF Loss                      4832.5054
VF Loss                      557.05414
Policy Loss                  -2271.4377
Q Predictions Mean           2273.2
Q Predictions Std            442.42075
Q Predictions Max            3254.0928
Q Predictions Min            -348.7829
V Predictions Mean           2266.8076
V Predictions Std            437.0542
V Predictions Max            3295.0513
V Predictions Min            -354.26294
Log Pis Mean                 2.3767157
Log Pis Std                  3.3121932
Log Pis Max                  16.138445
Log Pis Min                  -4.673199
Policy mu Mean               0.023573177
Policy mu Std                0.6277866
Policy mu Max                3.3827753
Policy mu Min                -4.0190735
Policy log std Mean          -1.3659296
Policy log std Std           0.28013083
Policy log std Max           0.25537968
Policy log std Min           -3.0597043
Z mean eval                  1.1793499
Z variance eval              0.0044235378
total_rewards                [5619.17066001 5700.35514061 5677.51814637 5410.87152736 5655.35457508
 3320.95583419 5571.44137525 5802.12928982 5754.45829828 5681.96193965]
total_rewards_mean           5419.421678662627
total_rewards_std            706.7874799584736
total_rewards_max            5802.129289820441
total_rewards_min            3320.955834191289
Number of train steps total  2780000
Number of env steps total    3477000
Number of rollouts total     0
Train Time (s)               118.02268512314186
(Previous) Eval Time (s)     24.668853930197656
Sample Time (s)              18.21843984676525
Epoch Time (s)               160.90997890010476
Total Train Time (s)         109976.6467482578
Epoch                        694
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:04:34.186585 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #694 | Epoch Duration: 162.35921788215637
2020-01-13 06:04:34.186783 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #694 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1776235
Z variance train             0.0044307653
KL Divergence                29.440968
KL Loss                      2.9440968
QF Loss                      1617.3558
VF Loss                      229.90723
Policy Loss                  -2264.595
Q Predictions Mean           2267.8296
Q Predictions Std            398.07822
Q Predictions Max            2521.046
Q Predictions Min            -238.24536
V Predictions Mean           2267.1675
V Predictions Std            393.20105
V Predictions Max            2528.698
V Predictions Min            -241.60678
Log Pis Mean                 2.7000353
Log Pis Std                  3.5873556
Log Pis Max                  15.824966
Log Pis Min                  -5.9095774
Policy mu Mean               -0.018579043
Policy mu Std                0.69207644
Policy mu Max                2.8147068
Policy mu Min                -2.9483967
Policy log std Mean          -1.338658
Policy log std Std           0.30562785
Policy log std Max           -0.22762513
Policy log std Min           -2.8084638
Z mean eval                  1.2125087
Z variance eval              0.0032438624
total_rewards                [5661.11442634 4928.45079938 1733.15566965 5782.58644377 5932.37676615
 5646.74856343 5590.68402321 5768.29245916 5715.92745827 5666.67252661]
total_rewards_mean           5242.600913598392
total_rewards_std            1196.7517871480222
total_rewards_max            5932.376766151954
total_rewards_min            1733.1556696536732
Number of train steps total  2784000
Number of env steps total    3482000
Number of rollouts total     0
Train Time (s)               121.87847052700818
(Previous) Eval Time (s)     26.117787932045758
Sample Time (s)              19.16465619020164
Epoch Time (s)               167.16091464925557
Total Train Time (s)         110142.29330777982
Epoch                        695
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:07:19.838588 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #695 | Epoch Duration: 165.65168356895447
2020-01-13 06:07:19.838768 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #695 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2110744
Z variance train             0.003252775
KL Divergence                29.580526
KL Loss                      2.9580526
QF Loss                      1042.4565
VF Loss                      750.43225
Policy Loss                  -2291.219
Q Predictions Mean           2291.811
Q Predictions Std            398.59506
Q Predictions Max            2533.694
Q Predictions Min            -347.58688
V Predictions Mean           2295.7146
V Predictions Std            387.73163
V Predictions Max            2518.598
V Predictions Min            -322.54922
Log Pis Mean                 2.6045825
Log Pis Std                  3.4949448
Log Pis Max                  13.726461
Log Pis Min                  -5.914513
Policy mu Mean               -0.0043737176
Policy mu Std                0.70548016
Policy mu Max                2.9415991
Policy mu Min                -2.9068108
Policy log std Mean          -1.3214998
Policy log std Std           0.31806177
Policy log std Max           -0.11614323
Policy log std Min           -3.2691975
Z mean eval                  1.1560504
Z variance eval              0.01050056
total_rewards                [ 322.06422417 5530.70564605 5942.4454939  5795.43693908 5657.4936712
 5680.91412733 5988.11344717 5761.79155762 5526.79673013 4807.74496476]
total_rewards_mean           5101.350680140307
total_rewards_std            1623.269810185679
total_rewards_max            5988.113447168782
total_rewards_min            322.0642241668188
Number of train steps total  2788000
Number of env steps total    3487000
Number of rollouts total     0
Train Time (s)               123.88740990497172
(Previous) Eval Time (s)     24.60819820081815
Sample Time (s)              18.1769067812711
Epoch Time (s)               166.67251488706097
Total Train Time (s)         110308.52667582873
Epoch                        696
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:10:06.081699 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #696 | Epoch Duration: 166.2427635192871
2020-01-13 06:10:06.081970 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #696 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1558897
Z variance train             0.010506161
KL Divergence                27.0824
KL Loss                      2.70824
QF Loss                      914.6991
VF Loss                      596.0376
Policy Loss                  -2283.602
Q Predictions Mean           2288.317
Q Predictions Std            404.65457
Q Predictions Max            2536.0178
Q Predictions Min            -327.36517
V Predictions Mean           2300.1577
V Predictions Std            405.43076
V Predictions Max            2536.8416
V Predictions Min            -412.70828
Log Pis Mean                 2.54773
Log Pis Std                  3.4856396
Log Pis Max                  17.606426
Log Pis Min                  -4.972991
Policy mu Mean               0.007846909
Policy mu Std                0.617821
Policy mu Max                2.9605594
Policy mu Min                -2.6808684
Policy log std Mean          -1.3956034
Policy log std Std           0.30210832
Policy log std Max           -0.14146483
Policy log std Min           -2.9294415
Z mean eval                  1.1788919
Z variance eval              0.007490492
total_rewards                [5762.16922908 5648.24504365 5756.96858877 5460.5504612  5774.09739176
 5574.26192048 5496.59200495 5580.9596412  6135.71517955 5727.01111293]
total_rewards_mean           5691.657057357139
total_rewards_std            182.7162469150842
total_rewards_max            6135.7151795513455
total_rewards_min            5460.550461198963
Number of train steps total  2792000
Number of env steps total    3492000
Number of rollouts total     0
Train Time (s)               118.1271026241593
(Previous) Eval Time (s)     24.178189740050584
Sample Time (s)              17.970612599980086
Epoch Time (s)               160.27590496418998
Total Train Time (s)         110472.4712530151
Epoch                        697
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:12:50.031523 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #697 | Epoch Duration: 163.94936442375183
2020-01-13 06:12:50.031681 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #697 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1788837
Z variance train             0.0074945674
KL Divergence                27.540558
KL Loss                      2.7540557
QF Loss                      965.64795
VF Loss                      204.27388
Policy Loss                  -2324.8823
Q Predictions Mean           2326.1082
Q Predictions Std            263.2037
Q Predictions Max            2539.6755
Q Predictions Min            1026.5331
V Predictions Mean           2324.0889
V Predictions Std            251.91055
V Predictions Max            2538.3115
V Predictions Min            1045.9407
Log Pis Mean                 2.8384721
Log Pis Std                  3.4372532
Log Pis Max                  16.115696
Log Pis Min                  -5.6518245
Policy mu Mean               -0.021338202
Policy mu Std                0.6795045
Policy mu Max                3.1132302
Policy mu Min                -2.8469672
Policy log std Mean          -1.3478881
Policy log std Std           0.30842242
Policy log std Max           0.19952297
Policy log std Min           -3.0069516
Z mean eval                  1.1920059
Z variance eval              0.0064095734
total_rewards                [-1.47943699e+01  5.45881423e+03  5.75538757e+03  5.79400844e+03
  5.65476402e+03  5.71282976e+03  5.79766674e+03  4.42671750e+00
  5.35947233e+03  5.58061963e+03]
total_rewards_mean           4510.319506768157
total_rewards_std            2261.7928585130267
total_rewards_max            5797.666738394209
total_rewards_min            -14.7943699376386
Number of train steps total  2796000
Number of env steps total    3497000
Number of rollouts total     0
Train Time (s)               119.69629366323352
(Previous) Eval Time (s)     27.851351118646562
Sample Time (s)              18.146397042553872
Epoch Time (s)               165.69404182443395
Total Train Time (s)         110632.10856527742
Epoch                        698
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:15:29.696677 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #698 | Epoch Duration: 159.66483974456787
2020-01-13 06:15:29.696951 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #698 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1930118
Z variance train             0.0064034956
KL Divergence                28.339132
KL Loss                      2.8339133
QF Loss                      28877.318
VF Loss                      324.40533
Policy Loss                  -2284.8887
Q Predictions Mean           2287.0283
Q Predictions Std            420.12836
Q Predictions Max            2529.0776
Q Predictions Min            -410.58197
V Predictions Mean           2288.3672
V Predictions Std            401.6372
V Predictions Max            2519.299
V Predictions Min            -404.23297
Log Pis Mean                 3.1814563
Log Pis Std                  4.9522424
Log Pis Max                  58.212357
Log Pis Min                  -7.552982
Policy mu Mean               0.030560585
Policy mu Std                0.7324994
Policy mu Max                7.060012
Policy mu Min                -7.229461
Policy log std Mean          -1.3780919
Policy log std Std           0.33719456
Policy log std Max           0.35441756
Policy log std Min           -4.4688935
Z mean eval                  1.1848662
Z variance eval              0.011509279
total_rewards                [5479.38381788 5646.16726015 5700.00213254 5842.67756924 5841.95293778
 5752.4094982  5604.89416024 5671.11521006 5892.09494303 5692.88585654]
total_rewards_mean           5712.358338565655
total_rewards_std            118.3752462329044
total_rewards_max            5892.094943029531
total_rewards_min            5479.383817880837
Number of train steps total  2800000
Number of env steps total    3502000
Number of rollouts total     0
Train Time (s)               116.16954913502559
(Previous) Eval Time (s)     21.82183304708451
Sample Time (s)              18.486084042117
Epoch Time (s)               156.4774662242271
Total Train Time (s)         110793.51304941485
Epoch                        699
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:18:11.109954 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #699 | Epoch Duration: 161.41278791427612
2020-01-13 06:18:11.110235 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #699 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1843162
Z variance train             0.011499241
KL Divergence                27.768562
KL Loss                      2.7768562
QF Loss                      807.642
VF Loss                      283.8119
Policy Loss                  -2288.9465
Q Predictions Mean           2292.107
Q Predictions Std            341.55984
Q Predictions Max            2520.5957
Q Predictions Min            -307.40796
V Predictions Mean           2298.108
V Predictions Std            336.3194
V Predictions Max            2530.1648
V Predictions Min            -280.30582
Log Pis Mean                 2.706527
Log Pis Std                  3.5766578
Log Pis Max                  16.038532
Log Pis Min                  -7.289747
Policy mu Mean               -0.02467328
Policy mu Std                0.6790114
Policy mu Max                3.2436073
Policy mu Min                -3.081535
Policy log std Mean          -1.3434995
Policy log std Std           0.29857656
Policy log std Max           0.16057885
Policy log std Min           -2.6555128
Z mean eval                  1.1406711
Z variance eval              0.009473073
total_rewards                [5643.27798128 5971.37129292 5802.76153759 5598.64905975 2111.44966142
 5839.19096324 5584.40758084 5720.54253834 5433.99640809 5985.83834293]
total_rewards_mean           5369.148536639282
total_rewards_std            1098.4706429340342
total_rewards_max            5985.838342932983
total_rewards_min            2111.4496614186273
Number of train steps total  2804000
Number of env steps total    3507000
Number of rollouts total     0
Train Time (s)               121.34782205102965
(Previous) Eval Time (s)     26.75682340702042
Sample Time (s)              18.49907744070515
Epoch Time (s)               166.60372289875522
Total Train Time (s)         110958.14556813473
Epoch                        700
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:20:55.751490 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #700 | Epoch Duration: 164.6409707069397
2020-01-13 06:20:55.751844 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #700 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1433613
Z variance train             0.009488619
KL Divergence                27.518902
KL Loss                      2.7518902
QF Loss                      1882.4133
VF Loss                      424.10907
Policy Loss                  -2312.2793
Q Predictions Mean           2315.975
Q Predictions Std            258.09857
Q Predictions Max            2515.3257
Q Predictions Min            979.4649
V Predictions Mean           2315.3057
V Predictions Std            252.53192
V Predictions Max            2525.9875
V Predictions Min            1038.4497
Log Pis Mean                 2.6404214
Log Pis Std                  3.5874615
Log Pis Max                  15.169613
Log Pis Min                  -6.5661497
Policy mu Mean               0.035185587
Policy mu Std                0.66519463
Policy mu Max                2.6737106
Policy mu Min                -2.9171102
Policy log std Mean          -1.3730366
Policy log std Std           0.30552804
Policy log std Max           -0.2105074
Policy log std Min           -2.9671707
Z mean eval                  1.218577
Z variance eval              0.009205495
total_rewards                [5374.41308343 5725.47876242 5473.52542571 5850.21353096 5836.9516303
 5981.28030344 5153.04556402 5706.32894553 5564.88723803 5571.63583594]
total_rewards_mean           5623.77603197767
total_rewards_std            235.41798954988033
total_rewards_max            5981.280303436637
total_rewards_min            5153.045564022439
Number of train steps total  2808000
Number of env steps total    3512000
Number of rollouts total     0
Train Time (s)               115.8565684268251
(Previous) Eval Time (s)     24.79375401418656
Sample Time (s)              19.35714100347832
Epoch Time (s)               160.00746344448999
Total Train Time (s)         111120.25553760584
Epoch                        701
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:23:37.872589 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #701 | Epoch Duration: 162.1205449104309
2020-01-13 06:23:37.872813 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #701 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2091148
Z variance train             0.009165237
KL Divergence                27.964043
KL Loss                      2.7964044
QF Loss                      1508.9606
VF Loss                      370.96564
Policy Loss                  -2291.572
Q Predictions Mean           2295.7964
Q Predictions Std            392.78012
Q Predictions Max            2639.7898
Q Predictions Min            -489.56662
V Predictions Mean           2286.9224
V Predictions Std            387.36987
V Predictions Max            2580.586
V Predictions Min            -514.23566
Log Pis Mean                 2.6588619
Log Pis Std                  3.3562455
Log Pis Max                  16.022697
Log Pis Min                  -4.5441313
Policy mu Mean               -0.013607313
Policy mu Std                0.6513014
Policy mu Max                2.8261878
Policy mu Min                -2.8719878
Policy log std Mean          -1.3569059
Policy log std Std           0.2981548
Policy log std Max           -0.20338821
Policy log std Min           -2.7632592
Z mean eval                  1.1889638
Z variance eval              0.012132343
total_rewards                [5636.71394298 5342.54144807 5422.5152759  5734.65436468 5733.58712302
 5641.69415477 5703.38558394 5786.71269248 5562.00633419 5686.31608922]
total_rewards_mean           5625.012700924528
total_rewards_std            136.02838273290175
total_rewards_max            5786.71269248021
total_rewards_min            5342.541448071902
Number of train steps total  2812000
Number of env steps total    3517000
Number of rollouts total     0
Train Time (s)               119.19705131696537
(Previous) Eval Time (s)     26.906505201011896
Sample Time (s)              18.43115649279207
Epoch Time (s)               164.53471301076934
Total Train Time (s)         111284.66078637447
Epoch                        702
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:26:22.281775 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #702 | Epoch Duration: 164.40872406959534
2020-01-13 06:26:22.282071 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #702 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1884792
Z variance train             0.012135254
KL Divergence                26.724289
KL Loss                      2.6724288
QF Loss                      883.60956
VF Loss                      169.96233
Policy Loss                  -2308.7703
Q Predictions Mean           2310.5007
Q Predictions Std            302.5354
Q Predictions Max            2501.6238
Q Predictions Min            -173.39648
V Predictions Mean           2309.793
V Predictions Std            295.4622
V Predictions Max            2501.5295
V Predictions Min            -195.86588
Log Pis Mean                 3.0195603
Log Pis Std                  3.3209577
Log Pis Max                  13.343613
Log Pis Min                  -3.3616602
Policy mu Mean               0.0035321265
Policy mu Std                0.6389109
Policy mu Max                2.6483815
Policy mu Min                -3.2478786
Policy log std Mean          -1.4201262
Policy log std Std           0.3000249
Policy log std Max           -0.30468988
Policy log std Min           -3.3934903
Z mean eval                  1.1417012
Z variance eval              0.012281233
total_rewards                [5469.6918641  5676.54697337 5624.52905323 5678.93315706 5781.13801472
 5797.0615351  5391.71883798 5650.49368019 5716.65656323 5861.9065625 ]
total_rewards_mean           5664.867624147296
total_rewards_std            136.88402570410997
total_rewards_max            5861.906562496481
total_rewards_min            5391.718837980605
Number of train steps total  2816000
Number of env steps total    3522000
Number of rollouts total     0
Train Time (s)               121.78083936870098
(Previous) Eval Time (s)     26.780217358842492
Sample Time (s)              19.051352995913476
Epoch Time (s)               167.61240972345695
Total Train Time (s)         111453.0024067876
Epoch                        703
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:29:10.631008 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #703 | Epoch Duration: 168.34874510765076
2020-01-13 06:29:10.631253 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #703 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1396809
Z variance train             0.012279049
KL Divergence                26.162142
KL Loss                      2.6162143
QF Loss                      744.30865
VF Loss                      89.1616
Policy Loss                  -2299.972
Q Predictions Mean           2304.9678
Q Predictions Std            328.44016
Q Predictions Max            2522.2307
Q Predictions Min            -350.66928
V Predictions Mean           2300.663
V Predictions Std            324.29657
V Predictions Max            2510.985
V Predictions Min            -358.61954
Log Pis Mean                 2.4485087
Log Pis Std                  3.521953
Log Pis Max                  16.530678
Log Pis Min                  -7.1745553
Policy mu Mean               -0.008981403
Policy mu Std                0.6582016
Policy mu Max                2.9152308
Policy mu Min                -3.000812
Policy log std Mean          -1.3300216
Policy log std Std           0.297664
Policy log std Max           -0.19023335
Policy log std Min           -2.822929
Z mean eval                  1.240835
Z variance eval              0.006016708
total_rewards                [5537.64576871 5758.91344776 5802.57873507 5687.90645962 1895.28423505
 2438.10560582 5788.07359669 5793.85734701 1622.02884156 5632.99166265]
total_rewards_mean           4595.738569993228
total_rewards_std            1720.8511678987268
total_rewards_max            5802.578735067219
total_rewards_min            1622.0288415570235
Number of train steps total  2820000
Number of env steps total    3527000
Number of rollouts total     0
Train Time (s)               123.84124359395355
(Previous) Eval Time (s)     27.516197907272726
Sample Time (s)              17.426809350959957
Epoch Time (s)               168.78425085218623
Total Train Time (s)         111616.2760539446
Epoch                        704
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:31:53.915470 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #704 | Epoch Duration: 163.28399968147278
2020-01-13 06:31:53.915788 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #704 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2389783
Z variance train             0.006017279
KL Divergence                27.123863
KL Loss                      2.7123864
QF Loss                      994.3203
VF Loss                      115.12441
Policy Loss                  -2245.4688
Q Predictions Mean           2243.0984
Q Predictions Std            471.07773
Q Predictions Max            2518.4832
Q Predictions Min            -499.4871
V Predictions Mean           2247.1196
V Predictions Std            456.31842
V Predictions Max            2517.8025
V Predictions Min            -455.1535
Log Pis Mean                 3.0731308
Log Pis Std                  3.6331809
Log Pis Max                  14.101244
Log Pis Min                  -5.0261726
Policy mu Mean               -0.029626021
Policy mu Std                0.7090295
Policy mu Max                2.6402583
Policy mu Min                -3.0958173
Policy log std Mean          -1.3380324
Policy log std Std           0.31666303
Policy log std Max           -0.08757937
Policy log std Min           -2.8499725
Z mean eval                  1.1943257
Z variance eval              0.007207903
total_rewards                [5694.1755881  5763.34838866  876.58193277 4156.82994892 5725.25260647
 5713.89777977 4094.04845759 5908.09599619 5601.92314123 4095.39949146]
total_rewards_mean           4762.955333116554
total_rewards_std            1485.8611148901034
total_rewards_max            5908.095996189459
total_rewards_min            876.5819327706989
Number of train steps total  2824000
Number of env steps total    3532000
Number of rollouts total     0
Train Time (s)               122.68448179028928
(Previous) Eval Time (s)     22.015650015324354
Sample Time (s)              17.84900427563116
Epoch Time (s)               162.5491360812448
Total Train Time (s)         111779.2968877675
Epoch                        705
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:34:36.943783 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #705 | Epoch Duration: 163.02773594856262
2020-01-13 06:34:36.944034 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #705 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1939942
Z variance train             0.00719775
KL Divergence                27.338722
KL Loss                      2.7338722
QF Loss                      998.87354
VF Loss                      234.83395
Policy Loss                  -2259.3315
Q Predictions Mean           2265.3096
Q Predictions Std            448.05783
Q Predictions Max            2534.2104
Q Predictions Min            -584.07825
V Predictions Mean           2255.583
V Predictions Std            448.53757
V Predictions Max            2520.4429
V Predictions Min            -622.1857
Log Pis Mean                 2.6536973
Log Pis Std                  3.1550186
Log Pis Max                  16.591675
Log Pis Min                  -6.0103464
Policy mu Mean               0.014971426
Policy mu Std                0.65010667
Policy mu Max                2.68243
Policy mu Min                -3.3575916
Policy log std Mean          -1.3675642
Policy log std Std           0.30714864
Policy log std Max           -0.33855343
Policy log std Min           -3.2220669
Z mean eval                  1.1536362
Z variance eval              0.012824504
total_rewards                [ 155.20405686 5621.00922371 5634.76316517 5892.58997362 5957.50710478
 5739.43158792 5745.26227176 5804.01038896 5793.19548852 5913.79081982]
total_rewards_mean           5225.6764081129895
total_rewards_std            1693.4474643532724
total_rewards_max            5957.507104778761
total_rewards_min            155.20405686195502
Number of train steps total  2828000
Number of env steps total    3537000
Number of rollouts total     0
Train Time (s)               123.8665903871879
(Previous) Eval Time (s)     22.493970814161003
Sample Time (s)              18.130099889822304
Epoch Time (s)               164.4906610911712
Total Train Time (s)         111946.6073145559
Epoch                        706
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:37:24.261325 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #706 | Epoch Duration: 167.31712985038757
2020-01-13 06:37:24.261492 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #706 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1540731
Z variance train             0.012811962
KL Divergence                27.008907
KL Loss                      2.7008908
QF Loss                      1831.7864
VF Loss                      467.8756
Policy Loss                  -2257.471
Q Predictions Mean           2258.0344
Q Predictions Std            451.82605
Q Predictions Max            2529.8804
Q Predictions Min            -561.04736
V Predictions Mean           2253.2163
V Predictions Std            450.19397
V Predictions Max            2503.329
V Predictions Min            -557.1069
Log Pis Mean                 2.8393278
Log Pis Std                  3.6639051
Log Pis Max                  18.962612
Log Pis Min                  -4.26777
Policy mu Mean               -0.02206816
Policy mu Std                0.68615675
Policy mu Max                3.1044722
Policy mu Min                -3.3275714
Policy log std Mean          -1.3637037
Policy log std Std           0.3267853
Policy log std Max           0.14508545
Policy log std Min           -2.8037522
Z mean eval                  1.1824096
Z variance eval              0.0072264867
total_rewards                [-4.91727646e+02  5.79895521e+03  5.89046449e+03  5.68677813e+03
  5.92975615e+03  5.83081344e+03  5.89086133e+03  2.47787812e+00
  5.66183143e+03  5.00179898e+03]
total_rewards_mean           4520.200940912944
total_rewards_std            2398.364122505199
total_rewards_max            5929.756152896213
total_rewards_min            -491.7276460380712
Number of train steps total  2832000
Number of env steps total    3542000
Number of rollouts total     0
Train Time (s)               124.82327710511163
(Previous) Eval Time (s)     25.32012393604964
Sample Time (s)              18.939618688542396
Epoch Time (s)               169.08301972970366
Total Train Time (s)         112114.64957078174
Epoch                        707
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:40:12.313419 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #707 | Epoch Duration: 168.05176615715027
2020-01-13 06:40:12.313672 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #707 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1815922
Z variance train             0.007224689
KL Divergence                26.686604
KL Loss                      2.6686604
QF Loss                      636.29456
VF Loss                      659.0065
Policy Loss                  -2318.9602
Q Predictions Mean           2325.3455
Q Predictions Std            343.1647
Q Predictions Max            2523.3772
Q Predictions Min            -445.64508
V Predictions Mean           2316.6865
V Predictions Std            337.12466
V Predictions Max            2528.5537
V Predictions Min            -424.0644
Log Pis Mean                 2.6584234
Log Pis Std                  3.4931946
Log Pis Max                  17.897892
Log Pis Min                  -6.4695125
Policy mu Mean               -0.010237567
Policy mu Std                0.6387821
Policy mu Max                2.998059
Policy mu Min                -2.853136
Policy log std Mean          -1.3654697
Policy log std Std           0.3294599
Policy log std Max           -0.025303602
Policy log std Min           -3.66566
Z mean eval                  1.1853116
Z variance eval              0.04932099
total_rewards                [ -25.9968619  5649.92868547 5445.48990635 5355.56197493 5433.85196531
 5681.63008175 5609.06866109 5635.21557381 5430.04417335 5759.72443669]
total_rewards_mean           4997.451859685318
total_rewards_std            1679.2052335100514
total_rewards_max            5759.7244366852165
total_rewards_min            -25.99686189510632
Number of train steps total  2836000
Number of env steps total    3547000
Number of rollouts total     0
Train Time (s)               120.17634599516168
(Previous) Eval Time (s)     24.28854107996449
Sample Time (s)              17.9852797081694
Epoch Time (s)               162.45016678329557
Total Train Time (s)         112277.30316831311
Epoch                        708
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:42:54.975976 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #708 | Epoch Duration: 162.66208839416504
2020-01-13 06:42:54.976271 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #708 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.185217
Z variance train             0.049212255
KL Divergence                24.872265
KL Loss                      2.4872265
QF Loss                      8188.736
VF Loss                      2353.5012
Policy Loss                  -2341.7803
Q Predictions Mean           2341.2578
Q Predictions Std            417.41727
Q Predictions Max            2587.0913
Q Predictions Min            -411.997
V Predictions Mean           2350.7415
V Predictions Std            403.96414
V Predictions Max            2588.6467
V Predictions Min            -395.71057
Log Pis Mean                 2.73443
Log Pis Std                  3.3788986
Log Pis Max                  17.55614
Log Pis Min                  -5.5657134
Policy mu Mean               -0.020630706
Policy mu Std                0.6528754
Policy mu Max                2.9090815
Policy mu Min                -3.3252888
Policy log std Mean          -1.3551055
Policy log std Std           0.3142848
Policy log std Max           -0.20061982
Policy log std Min           -3.2617629
Z mean eval                  1.1293523
Z variance eval              0.017597679
total_rewards                [5487.7376795  5782.30772686 5445.83558378 5671.41644098 5833.80836373
 5399.46598838 5641.80011503 6057.87408435 5909.08795604 5726.3713362 ]
total_rewards_mean           5695.570527485653
total_rewards_std            200.28726884141207
total_rewards_max            6057.874084349331
total_rewards_min            5399.465988376319
Number of train steps total  2840000
Number of env steps total    3552000
Number of rollouts total     0
Train Time (s)               118.04668877180666
(Previous) Eval Time (s)     24.50010801712051
Sample Time (s)              18.369777532294393
Epoch Time (s)               160.91657432122156
Total Train Time (s)         112440.29734034557
Epoch                        709
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:45:37.973483 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #709 | Epoch Duration: 162.99701070785522
2020-01-13 06:45:37.973683 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #709 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1316856
Z variance train             0.01760677
KL Divergence                25.05661
KL Loss                      2.505661
QF Loss                      982.9369
VF Loss                      1900.7048
Policy Loss                  -2191.3496
Q Predictions Mean           2198.0708
Q Predictions Std            452.32587
Q Predictions Max            2491.2969
Q Predictions Min            -332.82513
V Predictions Mean           2187.7996
V Predictions Std            456.6789
V Predictions Max            2492.3555
V Predictions Min            -336.29593
Log Pis Mean                 2.7553172
Log Pis Std                  3.679123
Log Pis Max                  19.020668
Log Pis Min                  -5.1372676
Policy mu Mean               -0.019040706
Policy mu Std                0.69896346
Policy mu Max                2.7928042
Policy mu Min                -3.081234
Policy log std Mean          -1.3247006
Policy log std Std           0.33485705
Policy log std Max           -0.022409678
Policy log std Min           -2.900484
Z mean eval                  1.1599591
Z variance eval              0.019697621
total_rewards                [3236.52116639 5494.97222027 2394.78981001  530.78838177 5588.95044917
 5742.8324831  5868.86106507 5917.41453625 5741.06170381 5832.44591213]
total_rewards_mean           4634.863772797516
total_rewards_std            1803.3289614088712
total_rewards_max            5917.41453625357
total_rewards_min            530.7883817667635
Number of train steps total  2844000
Number of env steps total    3557000
Number of rollouts total     0
Train Time (s)               126.06255468633026
(Previous) Eval Time (s)     26.580264372751117
Sample Time (s)              17.90035418374464
Epoch Time (s)               170.54317324282601
Total Train Time (s)         112607.09296959825
Epoch                        710
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:48:24.785359 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #710 | Epoch Duration: 166.8115417957306
2020-01-13 06:48:24.785516 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #710 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1583914
Z variance train             0.019685885
KL Divergence                24.003494
KL Loss                      2.4003494
QF Loss                      1456.5964
VF Loss                      433.7591
Policy Loss                  -2225.1477
Q Predictions Mean           2217.916
Q Predictions Std            469.51315
Q Predictions Max            2543.6965
Q Predictions Min            -524.29156
V Predictions Mean           2230.4316
V Predictions Std            447.54187
V Predictions Max            2522.8562
V Predictions Min            -521.20337
Log Pis Mean                 3.2025208
Log Pis Std                  4.4382105
Log Pis Max                  40.33748
Log Pis Min                  -5.3671207
Policy mu Mean               -0.03342342
Policy mu Std                0.7342583
Policy mu Max                4.08648
Policy mu Min                -3.758602
Policy log std Mean          -1.360023
Policy log std Std           0.3433403
Policy log std Max           -0.16919708
Policy log std Min           -3.7448182
Z mean eval                  1.1873422
Z variance eval              0.02051478
total_rewards                [5415.9971385  3264.35153064 5527.98999166 5359.37495708 5678.03607748
 5978.8439053  5622.29140897 5666.44591891 5777.69860624 5912.57899707]
total_rewards_mean           5420.3608531847
total_rewards_std            742.5160720442155
total_rewards_max            5978.843905298813
total_rewards_min            3264.3515306430213
Number of train steps total  2848000
Number of env steps total    3562000
Number of rollouts total     0
Train Time (s)               122.26594809116796
(Previous) Eval Time (s)     22.84831555886194
Sample Time (s)              18.66911799227819
Epoch Time (s)               163.7833816423081
Total Train Time (s)         112773.73847858142
Epoch                        711
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:51:11.430374 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #711 | Epoch Duration: 166.64469480514526
2020-01-13 06:51:11.430698 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #711 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1871558
Z variance train             0.020501418
KL Divergence                23.666687
KL Loss                      2.3666687
QF Loss                      1007.3787
VF Loss                      342.29977
Policy Loss                  -2270.7812
Q Predictions Mean           2275.6836
Q Predictions Std            381.0569
Q Predictions Max            2506.2676
Q Predictions Min            -245.66545
V Predictions Mean           2267.3374
V Predictions Std            380.86942
V Predictions Max            2504.2634
V Predictions Min            -240.65143
Log Pis Mean                 2.6813707
Log Pis Std                  3.5537136
Log Pis Max                  17.384594
Log Pis Min                  -4.8737583
Policy mu Mean               -0.029947016
Policy mu Std                0.63776153
Policy mu Max                2.8988562
Policy mu Min                -3.3472934
Policy log std Mean          -1.3835769
Policy log std Std           0.33448958
Policy log std Max           -0.17496371
Policy log std Min           -3.3146403
Z mean eval                  1.1941373
Z variance eval              0.013003131
total_rewards                [5556.81751518 5788.91173612 5873.64552435 5175.82010501 6000.38628486
 5832.83464536 5726.62177329 5633.92411107 5687.05950848 5990.2906264 ]
total_rewards_mean           5726.631183011358
total_rewards_std            228.8273281916298
total_rewards_max            6000.386284857555
total_rewards_min            5175.82010501194
Number of train steps total  2852000
Number of env steps total    3567000
Number of rollouts total     0
Train Time (s)               124.60658737225458
(Previous) Eval Time (s)     25.7092277482152
Sample Time (s)              18.44133735401556
Epoch Time (s)               168.75715247448534
Total Train Time (s)         112943.16231178725
Epoch                        712
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:54:00.859148 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #712 | Epoch Duration: 169.42823123931885
2020-01-13 06:54:00.859334 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #712 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.19103
Z variance train             0.012954089
KL Divergence                24.326462
KL Loss                      2.4326463
QF Loss                      705.0389
VF Loss                      179.78656
Policy Loss                  -2329.0527
Q Predictions Mean           2331.4834
Q Predictions Std            378.0553
Q Predictions Max            2561.5195
Q Predictions Min            -317.574
V Predictions Mean           2333.774
V Predictions Std            372.27487
V Predictions Max            2564.3677
V Predictions Min            -286.25946
Log Pis Mean                 2.6452425
Log Pis Std                  3.8277478
Log Pis Max                  22.462782
Log Pis Min                  -5.5266476
Policy mu Mean               0.00449067
Policy mu Std                0.67835426
Policy mu Max                3.1858966
Policy mu Min                -3.217666
Policy log std Mean          -1.3363736
Policy log std Std           0.30241248
Policy log std Max           -0.09674573
Policy log std Min           -2.825484
Z mean eval                  1.2037547
Z variance eval              0.006116499
total_rewards                [ -12.00024929 5904.45294209 5847.00492143 5853.68690592 5732.67242132
 5513.22468371 6036.87470781 5910.55893445 5841.80029458 5775.61527058]
total_rewards_mean           5240.38908326071
total_rewards_std            1755.5954303256085
total_rewards_max            6036.874707814724
total_rewards_min            -12.000249294003382
Number of train steps total  2856000
Number of env steps total    3572000
Number of rollouts total     0
Train Time (s)               124.11096238112077
(Previous) Eval Time (s)     26.380002652760595
Sample Time (s)              19.47481372812763
Epoch Time (s)               169.965778762009
Total Train Time (s)         113110.9032986071
Epoch                        713
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:56:48.607655 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #713 | Epoch Duration: 167.74816703796387
2020-01-13 06:56:48.607907 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #713 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2036998
Z variance train             0.006119892
KL Divergence                26.030561
KL Loss                      2.6030562
QF Loss                      572.50543
VF Loss                      160.5271
Policy Loss                  -2372.5369
Q Predictions Mean           2378.2034
Q Predictions Std            212.14484
Q Predictions Max            2560.016
Q Predictions Min            1011.62335
V Predictions Mean           2372.7292
V Predictions Std            205.5411
V Predictions Max            2547.1213
V Predictions Min            1097.2253
Log Pis Mean                 2.7390113
Log Pis Std                  3.4229808
Log Pis Max                  12.471036
Log Pis Min                  -4.1723857
Policy mu Mean               0.019140663
Policy mu Std                0.6630902
Policy mu Max                2.7570376
Policy mu Min                -2.9335363
Policy log std Mean          -1.3465297
Policy log std Std           0.30437312
Policy log std Max           -0.13846064
Policy log std Min           -2.7637687
Z mean eval                  1.1740562
Z variance eval              0.012654528
total_rewards                [5764.16918336 5741.10434054 5601.14358888 5622.52188842 5783.55095743
 5776.9624506  5968.51378845 5704.93998138 4851.57557374  680.05768101]
total_rewards_mean           5149.453943382274
total_rewards_std            1516.4183468442338
total_rewards_max            5968.513788453961
total_rewards_min            680.0576810124433
Number of train steps total  2860000
Number of env steps total    3577000
Number of rollouts total     0
Train Time (s)               119.65260360902175
(Previous) Eval Time (s)     24.16203217813745
Sample Time (s)              17.797087131999433
Epoch Time (s)               161.61172291915864
Total Train Time (s)         113272.33820315963
Epoch                        714
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:59:30.046993 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #714 | Epoch Duration: 161.4389305114746
2020-01-13 06:59:30.047144 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #714 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1747731
Z variance train             0.0126507925
KL Divergence                24.1371
KL Loss                      2.41371
QF Loss                      1185.9377
VF Loss                      221.0421
Policy Loss                  -2273.646
Q Predictions Mean           2272.109
Q Predictions Std            431.06598
Q Predictions Max            2560.466
Q Predictions Min            -221.8455
V Predictions Mean           2271.2783
V Predictions Std            410.86655
V Predictions Max            2540.312
V Predictions Min            -242.7938
Log Pis Mean                 2.7060294
Log Pis Std                  3.624108
Log Pis Max                  18.697418
Log Pis Min                  -5.762192
Policy mu Mean               -0.026957193
Policy mu Std                0.67136765
Policy mu Max                3.6315434
Policy mu Min                -3.8657532
Policy log std Mean          -1.3495612
Policy log std Std           0.32344672
Policy log std Max           -0.018403769
Policy log std Min           -2.91681
Z mean eval                  1.1691849
Z variance eval              0.016206935
total_rewards                [5765.91932054 5770.84368125 5862.11265709 5699.12300109 5830.40470342
 5891.40607819 5287.90619536 5874.82148311 5700.64008364 1246.01564358]
total_rewards_mean           5292.9192847261975
total_rewards_std            1359.0622121316326
total_rewards_max            5891.406078192305
total_rewards_min            1246.0156435751837
Number of train steps total  2864000
Number of env steps total    3582000
Number of rollouts total     0
Train Time (s)               123.03358998754993
(Previous) Eval Time (s)     23.98892141971737
Sample Time (s)              18.506609700154513
Epoch Time (s)               165.52912110742182
Total Train Time (s)         113440.95044880174
Epoch                        715
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:02:18.667076 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #715 | Epoch Duration: 168.61979460716248
2020-01-13 07:02:18.667307 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #715 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.167948
Z variance train             0.016215522
KL Divergence                24.560595
KL Loss                      2.4560595
QF Loss                      1787.6172
VF Loss                      501.37146
Policy Loss                  -2284.7993
Q Predictions Mean           2286.0117
Q Predictions Std            407.51465
Q Predictions Max            2531.8748
Q Predictions Min            -553.35614
V Predictions Mean           2279.2854
V Predictions Std            394.4234
V Predictions Max            2513.0657
V Predictions Min            -567.4722
Log Pis Mean                 3.040768
Log Pis Std                  4.251279
Log Pis Max                  21.652134
Log Pis Min                  -6.0721908
Policy mu Mean               -0.010627222
Policy mu Std                0.67955935
Policy mu Max                2.9153984
Policy mu Min                -3.0713665
Policy log std Mean          -1.4157169
Policy log std Std           0.34285906
Policy log std Max           -0.25468254
Policy log std Min           -3.6370728
Z mean eval                  1.23585
Z variance eval              0.010992731
total_rewards                [5564.83754125 5699.48892137 5632.8619088  5149.85565112 5696.62363109
 5908.40433881 5724.49457841 5679.4647187  5628.78196921 5562.36824476]
total_rewards_mean           5624.718150352504
total_rewards_std            183.6414628823263
total_rewards_max            5908.404338811676
total_rewards_min            5149.855651124228
Number of train steps total  2868000
Number of env steps total    3587000
Number of rollouts total     0
Train Time (s)               116.8988709799014
(Previous) Eval Time (s)     27.079229075927287
Sample Time (s)              18.845150913111866
Epoch Time (s)               162.82325096894056
Total Train Time (s)         113603.41228045942
Epoch                        716
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:05:01.135188 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #716 | Epoch Duration: 162.46769499778748
2020-01-13 07:05:01.135392 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #716 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2360152
Z variance train             0.010988285
KL Divergence                25.497849
KL Loss                      2.549785
QF Loss                      697.91077
VF Loss                      270.0261
Policy Loss                  -2339.8396
Q Predictions Mean           2342.8755
Q Predictions Std            368.61575
Q Predictions Max            2592.522
Q Predictions Min            -284.11713
V Predictions Mean           2347.7305
V Predictions Std            357.51282
V Predictions Max            2594.818
V Predictions Min            -251.28389
Log Pis Mean                 2.872981
Log Pis Std                  3.781939
Log Pis Max                  22.611446
Log Pis Min                  -8.710154
Policy mu Mean               -0.028822428
Policy mu Std                0.7171515
Policy mu Max                3.1944263
Policy mu Min                -3.5316925
Policy log std Mean          -1.3318275
Policy log std Std           0.309143
Policy log std Max           0.11620057
Policy log std Min           -2.8264494
Z mean eval                  1.2676768
Z variance eval              0.008018881
total_rewards                [5685.76132649 5861.72395899 6031.77526526 5811.4350574  5865.27642846
 5902.77405321 5679.06116714 5666.82801363 5740.47247041 5763.49948172]
total_rewards_mean           5800.860722269655
total_rewards_std            110.79880835123267
total_rewards_max            6031.775265257402
total_rewards_min            5666.828013627085
Number of train steps total  2872000
Number of env steps total    3592000
Number of rollouts total     0
Train Time (s)               117.3972111530602
(Previous) Eval Time (s)     26.723344597034156
Sample Time (s)              18.961232907604426
Epoch Time (s)               163.08178865769878
Total Train Time (s)         113766.56795321964
Epoch                        717
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:07:44.298523 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #717 | Epoch Duration: 163.1629765033722
2020-01-13 07:07:44.298729 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #717 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2675598
Z variance train             0.008011791
KL Divergence                25.761307
KL Loss                      2.5761306
QF Loss                      833.04144
VF Loss                      245.25272
Policy Loss                  -2307.7793
Q Predictions Mean           2309.7834
Q Predictions Std            420.3299
Q Predictions Max            2571.1562
Q Predictions Min            -478.33008
V Predictions Mean           2303.2798
V Predictions Std            420.15204
V Predictions Max            2564.0493
V Predictions Min            -436.7979
Log Pis Mean                 3.764533
Log Pis Std                  3.8779268
Log Pis Max                  15.773123
Log Pis Min                  -5.8787746
Policy mu Mean               0.003775605
Policy mu Std                0.7332838
Policy mu Max                2.7268035
Policy mu Min                -3.3881543
Policy log std Mean          -1.3953148
Policy log std Std           0.3160669
Policy log std Max           -0.17553139
Policy log std Min           -2.8559384
Z mean eval                  1.1559138
Z variance eval              0.012128212
total_rewards                [1799.80990036 5805.85203812 5935.60341588 5889.97566691 5616.25560778
  487.39584822 5805.66774661 6032.67752504 5920.21283646 5959.50468289]
total_rewards_mean           4925.295526825063
total_rewards_std            1916.4693718352103
total_rewards_max            6032.677525037858
total_rewards_min            487.3958482217647
Number of train steps total  2876000
Number of env steps total    3597000
Number of rollouts total     0
Train Time (s)               122.85893017007038
(Previous) Eval Time (s)     26.804131987039
Sample Time (s)              17.609322148375213
Epoch Time (s)               167.2723843054846
Total Train Time (s)         113930.34363119956
Epoch                        718
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:10:28.081231 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #718 | Epoch Duration: 163.78233122825623
2020-01-13 07:10:28.081470 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #718 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1560142
Z variance train             0.012122045
KL Divergence                24.463581
KL Loss                      2.4463582
QF Loss                      1034.8959
VF Loss                      219.52515
Policy Loss                  -2329.8127
Q Predictions Mean           2330.384
Q Predictions Std            407.99048
Q Predictions Max            2565.4216
Q Predictions Min            -493.48605
V Predictions Mean           2325.6243
V Predictions Std            401.19043
V Predictions Max            2564.653
V Predictions Min            -477.2524
Log Pis Mean                 2.4567752
Log Pis Std                  3.9058392
Log Pis Max                  26.886383
Log Pis Min                  -8.658989
Policy mu Mean               0.03366921
Policy mu Std                0.66339594
Policy mu Max                5.194085
Policy mu Min                -3.111682
Policy log std Mean          -1.3700397
Policy log std Std           0.29396728
Policy log std Max           0.3071673
Policy log std Min           -2.8242993
Z mean eval                  1.1620297
Z variance eval              0.01195011
total_rewards                [5799.58473171 5931.24780521 5743.87485609 5729.2861105  5858.54135254
 5660.99203437 5130.40088227 5900.72653088 6026.28807473 5980.22511446]
total_rewards_mean           5776.116749277111
total_rewards_std            241.78896784658767
total_rewards_max            6026.288074729926
total_rewards_min            5130.400882265845
Number of train steps total  2880000
Number of env steps total    3602000
Number of rollouts total     0
Train Time (s)               125.35816644784063
(Previous) Eval Time (s)     23.31374349212274
Sample Time (s)              19.069194795563817
Epoch Time (s)               167.7411047355272
Total Train Time (s)         114101.4997524796
Epoch                        719
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:13:19.245424 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #719 | Epoch Duration: 171.16377973556519
2020-01-13 07:13:19.245650 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #719 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1626766
Z variance train             0.011946294
KL Divergence                24.945522
KL Loss                      2.4945524
QF Loss                      864.02264
VF Loss                      163.57758
Policy Loss                  -2310.9146
Q Predictions Mean           2315.9756
Q Predictions Std            342.0662
Q Predictions Max            2548.2854
Q Predictions Min            -389.35083
V Predictions Mean           2312.6082
V Predictions Std            336.71762
V Predictions Max            2538.9346
V Predictions Min            -444.2973
Log Pis Mean                 2.6532633
Log Pis Std                  3.9465377
Log Pis Max                  23.080536
Log Pis Min                  -4.633158
Policy mu Mean               -0.033985864
Policy mu Std                0.70561075
Policy mu Max                5.469765
Policy mu Min                -2.8856974
Policy log std Mean          -1.3396416
Policy log std Std           0.34277716
Policy log std Max           2.0
Policy log std Min           -2.925448
Z mean eval                  1.187613
Z variance eval              0.0072575198
total_rewards                [5773.17298579 5968.27241661 5892.8977344  2665.35762232 1132.97014337
 5828.45784036 5928.56444213 6089.86094014 5832.88451005 2286.96336175]
total_rewards_mean           4739.940199691477
total_rewards_std            1812.4958990868047
total_rewards_max            6089.860940142481
total_rewards_min            1132.9701433651155
Number of train steps total  2884000
Number of env steps total    3607000
Number of rollouts total     0
Train Time (s)               126.52548979315907
(Previous) Eval Time (s)     26.736041082069278
Sample Time (s)              17.743899669498205
Epoch Time (s)               171.00543054472655
Total Train Time (s)         114268.79835509555
Epoch                        720
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:16:06.548533 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #720 | Epoch Duration: 167.3027310371399
2020-01-13 07:16:06.548728 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #720 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1873113
Z variance train             0.0072568073
KL Divergence                25.69956
KL Loss                      2.569956
QF Loss                      794.63513
VF Loss                      122.417015
Policy Loss                  -2331.9824
Q Predictions Mean           2334.6968
Q Predictions Std            347.5165
Q Predictions Max            2586.6562
Q Predictions Min            -369.3731
V Predictions Mean           2333.941
V Predictions Std            347.14764
V Predictions Max            2588.24
V Predictions Min            -382.2376
Log Pis Mean                 2.86642
Log Pis Std                  3.3896623
Log Pis Max                  12.054325
Log Pis Min                  -5.1800213
Policy mu Mean               0.0014571548
Policy mu Std                0.6910618
Policy mu Max                4.115112
Policy mu Min                -2.705249
Policy log std Mean          -1.3617337
Policy log std Std           0.33257756
Policy log std Max           0.8160844
Policy log std Min           -2.9028468
Z mean eval                  1.160206
Z variance eval              0.005353079
total_rewards                [-788.8204469  5912.89834477 2451.84552502 5703.03678605 5751.47013384
 5812.27672073 5933.39072797 4219.49982463 6072.02296819 6044.51183661]
total_rewards_mean           4711.213242092146
total_rewards_std            2131.7208405156593
total_rewards_max            6072.022968190651
total_rewards_min            -788.820446903833
Number of train steps total  2888000
Number of env steps total    3612000
Number of rollouts total     0
Train Time (s)               117.77057136408985
(Previous) Eval Time (s)     23.03306244686246
Sample Time (s)              18.05914453137666
Epoch Time (s)               158.86277834232897
Total Train Time (s)         114431.03076676326
Epoch                        721
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:18:48.785316 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #721 | Epoch Duration: 162.23645853996277
2020-01-13 07:18:48.785498 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #721 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1600935
Z variance train             0.005349227
KL Divergence                26.431866
KL Loss                      2.6431866
QF Loss                      856.2888
VF Loss                      237.97238
Policy Loss                  -2349.6697
Q Predictions Mean           2352.4658
Q Predictions Std            312.29172
Q Predictions Max            2604.3362
Q Predictions Min            222.57797
V Predictions Mean           2347.8223
V Predictions Std            314.96774
V Predictions Max            2586.5955
V Predictions Min            70.995186
Log Pis Mean                 2.6561909
Log Pis Std                  4.3800087
Log Pis Max                  33.139427
Log Pis Min                  -5.0581713
Policy mu Mean               -0.015826475
Policy mu Std                0.71784073
Policy mu Max                5.681205
Policy mu Min                -6.6676617
Policy log std Mean          -1.3603725
Policy log std Std           0.32144108
Policy log std Max           0.33933592
Policy log std Min           -3.0203195
Z mean eval                  1.1921555
Z variance eval              0.0059107086
total_rewards                [5723.76689681 5904.81151646 5783.75055388 5768.95074925 1947.95198989
 5820.18248033 6004.97529173 5705.45299028 5764.91653529 5867.77479246]
total_rewards_mean           5429.253379637632
total_rewards_std            1163.5701078734332
total_rewards_max            6004.975291729734
total_rewards_min            1947.9519898860663
Number of train steps total  2892000
Number of env steps total    3617000
Number of rollouts total     0
Train Time (s)               117.77027879375964
(Previous) Eval Time (s)     26.40646173618734
Sample Time (s)              18.302659437526017
Epoch Time (s)               162.479399967473
Total Train Time (s)         114592.01426555589
Epoch                        722
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:21:29.777410 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #722 | Epoch Duration: 160.9917631149292
2020-01-13 07:21:29.777670 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #722 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1878871
Z variance train             0.005996304
KL Divergence                25.878212
KL Loss                      2.5878212
QF Loss                      850.5029
VF Loss                      355.96985
Policy Loss                  -2352.6396
Q Predictions Mean           2352.2249
Q Predictions Std            422.88052
Q Predictions Max            2577.3225
Q Predictions Min            -497.362
V Predictions Mean           2353.8672
V Predictions Std            422.57755
V Predictions Max            2586.1191
V Predictions Min            -522.3817
Log Pis Mean                 2.7432606
Log Pis Std                  3.6107001
Log Pis Max                  17.896175
Log Pis Min                  -9.12641
Policy mu Mean               -0.005371997
Policy mu Std                0.65105695
Policy mu Max                2.9350984
Policy mu Min                -3.732834
Policy log std Mean          -1.3749665
Policy log std Std           0.30215073
Policy log std Max           0.72831345
Policy log std Min           -2.9341962
Z mean eval                  1.259895
Z variance eval              0.008486325
total_rewards                [5714.95356106 5956.83147671 5948.83139155 2302.526828   5716.98330055
 5982.02085228 5916.05814782 4108.93216543 5851.0573147  5805.80138405]
total_rewards_mean           5330.399642215304
total_rewards_std            1140.0393503653045
total_rewards_max            5982.020852282759
total_rewards_min            2302.5268280013715
Number of train steps total  2896000
Number of env steps total    3622000
Number of rollouts total     0
Train Time (s)               123.45344507787377
(Previous) Eval Time (s)     24.91850162902847
Sample Time (s)              18.86000212514773
Epoch Time (s)               167.23194883204997
Total Train Time (s)         114758.75731741078
Epoch                        723
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:24:16.528205 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #723 | Epoch Duration: 166.75034737586975
2020-01-13 07:24:16.528420 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #723 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2603505
Z variance train             0.008486027
KL Divergence                25.471245
KL Loss                      2.5471246
QF Loss                      1996.4476
VF Loss                      920.472
Policy Loss                  -2318.208
Q Predictions Mean           2317.025
Q Predictions Std            441.878
Q Predictions Max            2652.5288
Q Predictions Min            -522.9124
V Predictions Mean           2328.1638
V Predictions Std            425.16946
V Predictions Max            2697.885
V Predictions Min            -478.8432
Log Pis Mean                 2.9584942
Log Pis Std                  3.9055474
Log Pis Max                  19.163227
Log Pis Min                  -5.932485
Policy mu Mean               -0.0065319343
Policy mu Std                0.685991
Policy mu Max                3.103272
Policy mu Min                -2.9895697
Policy log std Mean          -1.3581022
Policy log std Std           0.33754858
Policy log std Max           -0.2122637
Policy log std Min           -3.4722137
Z mean eval                  1.2131069
Z variance eval              0.021852653
total_rewards                [5123.7261776  5756.58789433 5667.07128488 5977.0946307  5776.47836908
 5283.95260861 5693.34072998 5668.53423949 5852.88569402 5812.75221775]
total_rewards_mean           5661.2423846452675
total_rewards_std            247.83135922458808
total_rewards_max            5977.094630702759
total_rewards_min            5123.726177601511
Number of train steps total  2900000
Number of env steps total    3627000
Number of rollouts total     0
Train Time (s)               116.20822895690799
(Previous) Eval Time (s)     24.436582337133586
Sample Time (s)              17.83989240648225
Epoch Time (s)               158.48470370052382
Total Train Time (s)         114919.28398582106
Epoch                        724
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:26:57.061377 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #724 | Epoch Duration: 160.53278923034668
2020-01-13 07:26:57.061586 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #724 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.213135
Z variance train             0.02183054
KL Divergence                25.30135
KL Loss                      2.530135
QF Loss                      700.6987
VF Loss                      366.7648
Policy Loss                  -2282.621
Q Predictions Mean           2285.9548
Q Predictions Std            416.49326
Q Predictions Max            2509.7236
Q Predictions Min            -439.87607
V Predictions Mean           2278.207
V Predictions Std            408.67273
V Predictions Max            2504.884
V Predictions Min            -418.86313
Log Pis Mean                 2.5414832
Log Pis Std                  3.8716223
Log Pis Max                  22.259792
Log Pis Min                  -8.828686
Policy mu Mean               0.040046655
Policy mu Std                0.6869938
Policy mu Max                3.394196
Policy mu Min                -3.5911236
Policy log std Mean          -1.3214927
Policy log std Std           0.32873034
Policy log std Max           0.3795327
Policy log std Min           -2.9783158
Z mean eval                  1.2189823
Z variance eval              0.009699123
total_rewards                [ 422.29527483 5706.45091078 5742.93659917 1116.62248474 6014.52506897
 5646.31243531 5849.79868569 5783.87032712 2112.54226405 5796.70401727]
total_rewards_mean           4419.205806792076
total_rewards_std            2132.3590469607875
total_rewards_max            6014.525068967187
total_rewards_min            422.2952748304252
Number of train steps total  2904000
Number of env steps total    3632000
Number of rollouts total     0
Train Time (s)               119.85751280607656
(Previous) Eval Time (s)     26.484362135175616
Sample Time (s)              18.871932762674987
Epoch Time (s)               165.21380770392716
Total Train Time (s)         115079.62760016881
Epoch                        725
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:29:37.415748 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #725 | Epoch Duration: 160.35397458076477
2020-01-13 07:29:37.416118 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #725 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2188883
Z variance train             0.009701531
KL Divergence                24.857843
KL Loss                      2.4857843
QF Loss                      2132.0996
VF Loss                      292.2231
Policy Loss                  -2314.5078
Q Predictions Mean           2318.0688
Q Predictions Std            466.5772
Q Predictions Max            2584.8977
Q Predictions Min            -513.33606
V Predictions Mean           2307.663
V Predictions Std            468.8222
V Predictions Max            2574.204
V Predictions Min            -545.57184
Log Pis Mean                 2.7906384
Log Pis Std                  3.7430823
Log Pis Max                  15.544383
Log Pis Min                  -6.176868
Policy mu Mean               -0.00092610286
Policy mu Std                0.6899601
Policy mu Max                2.9271505
Policy mu Min                -3.0360336
Policy log std Mean          -1.333401
Policy log std Std           0.32108313
Policy log std Max           -0.10228753
Policy log std Min           -2.9287152
Z mean eval                  1.2109019
Z variance eval              0.010450576
total_rewards                [5512.58835158 5267.36871309 5744.27459706 5981.33826831 6033.07768026
 5907.44341629 5965.14318574 6060.15230664 5805.05991452 5720.38111595]
total_rewards_mean           5799.682754943944
total_rewards_std            238.63674941228737
total_rewards_max            6060.152306644973
total_rewards_min            5267.368713089869
Number of train steps total  2908000
Number of env steps total    3637000
Number of rollouts total     0
Train Time (s)               125.0320844836533
(Previous) Eval Time (s)     21.624141971115023
Sample Time (s)              18.44537784671411
Epoch Time (s)               165.10160430148244
Total Train Time (s)         115250.73192698322
Epoch                        726
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:32:28.524060 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #726 | Epoch Duration: 171.1077220439911
2020-01-13 07:32:28.524222 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #726 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.211021
Z variance train             0.010452943
KL Divergence                25.03738
KL Loss                      2.5037382
QF Loss                      955.9624
VF Loss                      128.49876
Policy Loss                  -2338.9387
Q Predictions Mean           2341.9878
Q Predictions Std            361.69095
Q Predictions Max            2584.1614
Q Predictions Min            -48.515892
V Predictions Mean           2337.3833
V Predictions Std            356.78232
V Predictions Max            2576.1238
V Predictions Min            -52.93612
Log Pis Mean                 3.027454
Log Pis Std                  3.5399559
Log Pis Max                  13.611777
Log Pis Min                  -5.0129232
Policy mu Mean               -0.009097741
Policy mu Std                0.703126
Policy mu Max                3.2911222
Policy mu Min                -3.3661084
Policy log std Mean          -1.3741229
Policy log std Std           0.32666233
Policy log std Max           0.2587285
Policy log std Min           -2.9318652
Z mean eval                  1.1617311
Z variance eval              0.0143219065
total_rewards                [5735.09808949 5989.93432037 4044.04091968 4583.98182503 5921.42278398
 5651.5003538  2621.53266062 1024.54021254 5621.23490817 5657.28296781]
total_rewards_mean           4685.056904149781
total_rewards_std            1586.4485583746787
total_rewards_max            5989.934320369851
total_rewards_min            1024.540212537811
Number of train steps total  2912000
Number of env steps total    3642000
Number of rollouts total     0
Train Time (s)               124.02615481102839
(Previous) Eval Time (s)     27.62991577666253
Sample Time (s)              18.853906640782952
Epoch Time (s)               170.50997722847387
Total Train Time (s)         115415.67541422881
Epoch                        727
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:35:13.472383 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #727 | Epoch Duration: 164.94798922538757
2020-01-13 07:35:13.472582 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #727 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1633569
Z variance train             0.014315668
KL Divergence                24.448383
KL Loss                      2.4448383
QF Loss                      724.282
VF Loss                      149.1306
Policy Loss                  -2340.1812
Q Predictions Mean           2345.2783
Q Predictions Std            267.956
Q Predictions Max            2541.6453
Q Predictions Min            -520.0639
V Predictions Mean           2345.3062
V Predictions Std            264.67236
V Predictions Max            2539.4858
V Predictions Min            -523.76904
Log Pis Mean                 2.8278046
Log Pis Std                  3.4031916
Log Pis Max                  13.801436
Log Pis Min                  -7.390066
Policy mu Mean               0.026687158
Policy mu Std                0.6696488
Policy mu Max                2.988877
Policy mu Min                -2.8834436
Policy log std Mean          -1.382349
Policy log std Std           0.30230528
Policy log std Max           -0.18360889
Policy log std Min           -2.748277
Z mean eval                  1.1758296
Z variance eval              0.007059128
total_rewards                [5880.83730111 5884.13329678 5938.30168595 6076.56659757 5801.59444787
 5721.13057499 5894.5583047  6025.46705035 5945.18510945 5865.59296411]
total_rewards_mean           5903.336733286268
total_rewards_std            96.8635436232855
total_rewards_max            6076.566597565547
total_rewards_min            5721.1305749883595
Number of train steps total  2916000
Number of env steps total    3647000
Number of rollouts total     0
Train Time (s)               121.30864534527063
(Previous) Eval Time (s)     22.06760072428733
Sample Time (s)              18.503416780382395
Epoch Time (s)               161.87966284994036
Total Train Time (s)         115583.30301144207
Epoch                        728
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:38:01.104589 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #728 | Epoch Duration: 167.63186717033386
2020-01-13 07:38:01.104786 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #728 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1756959
Z variance train             0.0070511354
KL Divergence                25.627632
KL Loss                      2.5627632
QF Loss                      2529.969
VF Loss                      389.86752
Policy Loss                  -2374.5955
Q Predictions Mean           2370.4924
Q Predictions Std            310.17535
Q Predictions Max            2578.887
Q Predictions Min            -36.196003
V Predictions Mean           2365.4592
V Predictions Std            275.34326
V Predictions Max            2560.4773
V Predictions Min            -49.034706
Log Pis Mean                 3.0330837
Log Pis Std                  3.5220354
Log Pis Max                  15.968774
Log Pis Min                  -7.040324
Policy mu Mean               -0.0039604143
Policy mu Std                0.6742648
Policy mu Max                4.5240545
Policy mu Min                -2.7783737
Policy log std Mean          -1.3798356
Policy log std Std           0.30128375
Policy log std Max           0.8336859
Policy log std Min           -2.8080134
Z mean eval                  1.1729496
Z variance eval              0.010656783
total_rewards                [5744.31909959 5703.86554769 5693.48023398 5432.53224778 5764.31560104
 5961.53717698 5889.24443989 5744.10388973 5677.82296144 5827.67051853]
total_rewards_mean           5743.889171663561
total_rewards_std            134.67977647810721
total_rewards_max            5961.5371769842895
total_rewards_min            5432.532247776204
Number of train steps total  2920000
Number of env steps total    3652000
Number of rollouts total     0
Train Time (s)               120.12855744501576
(Previous) Eval Time (s)     27.81950295669958
Sample Time (s)              17.70894582848996
Epoch Time (s)               165.6570062302053
Total Train Time (s)         115748.11740233749
Epoch                        729
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:40:45.929134 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #729 | Epoch Duration: 164.82420682907104
2020-01-13 07:40:45.929383 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #729 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1728038
Z variance train             0.010657778
KL Divergence                24.981527
KL Loss                      2.4981527
QF Loss                      791.49927
VF Loss                      224.1363
Policy Loss                  -2359.132
Q Predictions Mean           2362.5742
Q Predictions Std            341.9153
Q Predictions Max            2578.8894
Q Predictions Min            -348.37198
V Predictions Mean           2363.893
V Predictions Std            338.96603
V Predictions Max            2583.1306
V Predictions Min            -347.35266
Log Pis Mean                 2.8612928
Log Pis Std                  3.7567923
Log Pis Max                  20.775242
Log Pis Min                  -5.7577124
Policy mu Mean               -0.011110945
Policy mu Std                0.70183456
Policy mu Max                3.8252132
Policy mu Min                -3.8958669
Policy log std Mean          -1.3393552
Policy log std Std           0.31468046
Policy log std Max           0.058583498
Policy log std Min           -2.804481
Z mean eval                  1.1459005
Z variance eval              0.017983448
total_rewards                [5687.98920089 5836.96619746 6054.68363259 5726.71011244 5768.99164043
 3276.17548967 5769.48157811 3941.25603289 5921.84829724 5943.83352248]
total_rewards_mean           5392.793570417601
total_rewards_std            910.3858848133855
total_rewards_max            6054.683632590273
total_rewards_min            3276.1754896665407
Number of train steps total  2924000
Number of env steps total    3657000
Number of rollouts total     0
Train Time (s)               123.96922097215429
(Previous) Eval Time (s)     26.986368943937123
Sample Time (s)              18.551825752016157
Epoch Time (s)               169.50741566810757
Total Train Time (s)         115915.4155463418
Epoch                        730
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:43:33.231276 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #730 | Epoch Duration: 167.30172109603882
2020-01-13 07:43:33.231465 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #730 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1465921
Z variance train             0.017969957
KL Divergence                23.906948
KL Loss                      2.3906949
QF Loss                      1333.165
VF Loss                      282.85284
Policy Loss                  -2327.5686
Q Predictions Mean           2327.3247
Q Predictions Std            360.85236
Q Predictions Max            2563.4082
Q Predictions Min            54.060825
V Predictions Mean           2327.1074
V Predictions Std            359.13373
V Predictions Max            2594.1768
V Predictions Min            -23.51036
Log Pis Mean                 3.1403127
Log Pis Std                  4.5253844
Log Pis Max                  41.764206
Log Pis Min                  -5.571483
Policy mu Mean               -0.018218178
Policy mu Std                0.75041837
Policy mu Max                4.862029
Policy mu Min                -5.7924304
Policy log std Mean          -1.3448238
Policy log std Std           0.30963725
Policy log std Max           -0.13059556
Policy log std Min           -2.9715986
Z mean eval                  1.1597553
Z variance eval              0.025875026
total_rewards                [5812.13398576 5823.81426756 3719.08693475 5803.93817414 5729.28693629
 5368.25190184 5866.09306013 6085.93306075 5996.66925487 5693.08808166]
total_rewards_mean           5589.829565773348
total_rewards_std            649.3731325378747
total_rewards_max            6085.933060745627
total_rewards_min            3719.0869347519256
Number of train steps total  2928000
Number of env steps total    3662000
Number of rollouts total     0
Train Time (s)               125.85328885307536
(Previous) Eval Time (s)     24.780378009658307
Sample Time (s)              18.267767259851098
Epoch Time (s)               168.90143412258476
Total Train Time (s)         116085.83504997194
Epoch                        731
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:46:23.654665 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #731 | Epoch Duration: 170.42308640480042
2020-01-13 07:46:23.654808 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #731 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1608379
Z variance train             0.025870895
KL Divergence                23.626648
KL Loss                      2.362665
QF Loss                      1557.3296
VF Loss                      1521.9181
Policy Loss                  -2337.1611
Q Predictions Mean           2339.7104
Q Predictions Std            449.50726
Q Predictions Max            2592.9412
Q Predictions Min            -390.1688
V Predictions Mean           2337.666
V Predictions Std            442.9065
V Predictions Max            2581.8777
V Predictions Min            -454.42114
Log Pis Mean                 3.0445273
Log Pis Std                  3.9343898
Log Pis Max                  15.149603
Log Pis Min                  -6.6167655
Policy mu Mean               -0.03729041
Policy mu Std                0.7153599
Policy mu Max                3.56992
Policy mu Min                -3.160079
Policy log std Mean          -1.3801438
Policy log std Std           0.34948286
Policy log std Max           0.18916905
Policy log std Min           -3.2762976
Z mean eval                  1.2120459
Z variance eval              0.0137461545
total_rewards                [5587.94776451 5982.03427463  362.41293734 3962.40561544 5716.90120856
 5864.57634164 5934.19819144 5811.83285314 6099.7446169  5730.03996297]
total_rewards_mean           5105.2093766560965
total_rewards_std            1682.8200925006618
total_rewards_max            6099.744616902661
total_rewards_min            362.412937336253
Number of train steps total  2932000
Number of env steps total    3667000
Number of rollouts total     0
Train Time (s)               120.8588832039386
(Previous) Eval Time (s)     26.30172629794106
Sample Time (s)              18.119422357529402
Epoch Time (s)               165.28003185940906
Total Train Time (s)         116248.7682001791
Epoch                        732
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:49:06.599026 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #732 | Epoch Duration: 162.94406867027283
2020-01-13 07:49:06.599320 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #732 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.211636
Z variance train             0.013735997
KL Divergence                24.498678
KL Loss                      2.449868
QF Loss                      783.7549
VF Loss                      247.49966
Policy Loss                  -2345.8696
Q Predictions Mean           2346.186
Q Predictions Std            446.4813
Q Predictions Max            2587.912
Q Predictions Min            -424.08005
V Predictions Mean           2345.7148
V Predictions Std            433.8991
V Predictions Max            2589.5745
V Predictions Min            -398.30783
Log Pis Mean                 2.5680423
Log Pis Std                  3.76488
Log Pis Max                  13.4499
Log Pis Min                  -4.110635
Policy mu Mean               -0.0039542173
Policy mu Std                0.66352266
Policy mu Max                2.4943893
Policy mu Min                -3.0948017
Policy log std Mean          -1.3707819
Policy log std Std           0.32031858
Policy log std Max           0.19566977
Policy log std Min           -3.2505326
Z mean eval                  1.1373913
Z variance eval              0.012137139
total_rewards                [5937.01995113 6043.7348668  5687.89841725 5913.52354919 5931.38593007
 5809.76124297 5806.04179802 5825.8739056  5742.06208324 5694.30841787]
total_rewards_mean           5839.161016214504
total_rewards_std            109.95029831580318
total_rewards_max            6043.734866797879
total_rewards_min            5687.898417250341
Number of train steps total  2936000
Number of env steps total    3672000
Number of rollouts total     0
Train Time (s)               126.03828257601708
(Previous) Eval Time (s)     23.965417386963964
Sample Time (s)              18.183137380052358
Epoch Time (s)               168.1868373430334
Total Train Time (s)         116420.08625054453
Epoch                        733
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:51:57.923115 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #733 | Epoch Duration: 171.32359433174133
2020-01-13 07:51:57.923303 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #733 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1379116
Z variance train             0.012125125
KL Divergence                24.838264
KL Loss                      2.4838264
QF Loss                      1284.4487
VF Loss                      127.56055
Policy Loss                  -2371.5603
Q Predictions Mean           2375.6003
Q Predictions Std            195.48935
Q Predictions Max            2563.7964
Q Predictions Min            1306.3888
V Predictions Mean           2374.9094
V Predictions Std            191.33488
V Predictions Max            2563.46
V Predictions Min            1281.5748
Log Pis Mean                 2.7960382
Log Pis Std                  3.6809042
Log Pis Max                  13.042353
Log Pis Min                  -5.38585
Policy mu Mean               -0.031525545
Policy mu Std                0.65480864
Policy mu Max                2.9430869
Policy mu Min                -3.4766493
Policy log std Mean          -1.3762405
Policy log std Std           0.28981555
Policy log std Max           -0.3847971
Policy log std Min           -2.9123318
Z mean eval                  1.1497205
Z variance eval              0.011652907
total_rewards                [5943.50791508 4808.88093123 5779.61390853 5836.24413568 5889.8425425
 5612.04873539 6030.36849754 5879.87518189 5892.08735683 5913.08188816]
total_rewards_mean           5758.555109283674
total_rewards_std            333.40345153635866
total_rewards_max            6030.368497543559
total_rewards_min            4808.880931234132
Number of train steps total  2940000
Number of env steps total    3677000
Number of rollouts total     0
Train Time (s)               121.10043162107468
(Previous) Eval Time (s)     27.101865253876895
Sample Time (s)              19.498285008128732
Epoch Time (s)               167.7005818830803
Total Train Time (s)         116588.04195750738
Epoch                        734
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:54:45.885692 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #734 | Epoch Duration: 167.96222567558289
2020-01-13 07:54:45.885896 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #734 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1500462
Z variance train             0.01165476
KL Divergence                24.963058
KL Loss                      2.496306
QF Loss                      618.3335
VF Loss                      294.0969
Policy Loss                  -2355.9585
Q Predictions Mean           2354.041
Q Predictions Std            265.99643
Q Predictions Max            2547.8162
Q Predictions Min            524.7858
V Predictions Mean           2347.2314
V Predictions Std            258.56915
V Predictions Max            2559.6042
V Predictions Min            524.2188
Log Pis Mean                 2.6463857
Log Pis Std                  3.7587326
Log Pis Max                  12.720636
Log Pis Min                  -6.8001804
Policy mu Mean               -0.00030719303
Policy mu Std                0.70209587
Policy mu Max                3.2329135
Policy mu Min                -2.658438
Policy log std Mean          -1.3329481
Policy log std Std           0.3031723
Policy log std Max           -0.03950548
Policy log std Min           -2.8018298
Z mean eval                  1.212116
Z variance eval              0.010734556
total_rewards                [5284.24071312 5974.33573078 6019.73468367 6016.55521493 5710.37416057
 6117.40680018 5986.78472764 5809.83113172 6021.23564962  906.5817906 ]
total_rewards_mean           5384.708060281537
total_rewards_std            1510.1376813951435
total_rewards_max            6117.40680017807
total_rewards_min            906.5817905977171
Number of train steps total  2944000
Number of env steps total    3682000
Number of rollouts total     0
Train Time (s)               119.83518014615402
(Previous) Eval Time (s)     27.363148759119213
Sample Time (s)              19.221782088279724
Epoch Time (s)               166.42011099355295
Total Train Time (s)         116751.82237033546
Epoch                        735
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:57:29.676725 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #735 | Epoch Duration: 163.79065251350403
2020-01-13 07:57:29.676992 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #735 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2120345
Z variance train             0.010735172
KL Divergence                25.20615
KL Loss                      2.520615
QF Loss                      1507.0176
VF Loss                      241.43723
Policy Loss                  -2361.2083
Q Predictions Mean           2364.5815
Q Predictions Std            333.1021
Q Predictions Max            2581.4712
Q Predictions Min            -291.875
V Predictions Mean           2364.3564
V Predictions Std            326.81912
V Predictions Max            2575.959
V Predictions Min            -317.645
Log Pis Mean                 3.3872437
Log Pis Std                  3.7582977
Log Pis Max                  18.790985
Log Pis Min                  -4.8550467
Policy mu Mean               0.00040641427
Policy mu Std                0.6992082
Policy mu Max                3.1891894
Policy mu Min                -2.9824634
Policy log std Mean          -1.4169185
Policy log std Std           0.31496662
Policy log std Max           -0.17423248
Policy log std Min           -2.9214056
Z mean eval                  1.1883258
Z variance eval              0.008913579
total_rewards                [5721.31705168 5945.95816776 5875.35674255 5878.4486816  6023.70706141
 5672.75663506 5765.71423412 6196.9988353  5929.64677183 6027.12958794]
total_rewards_mean           5903.703376925264
total_rewards_std            150.06637561890432
total_rewards_max            6196.9988353047265
total_rewards_min            5672.756635056678
Number of train steps total  2948000
Number of env steps total    3687000
Number of rollouts total     0
Train Time (s)               125.42282136762515
(Previous) Eval Time (s)     24.733330559916794
Sample Time (s)              17.983574107754976
Epoch Time (s)               168.13972603529692
Total Train Time (s)         116922.30726525513
Epoch                        736
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:00:20.172382 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #736 | Epoch Duration: 170.49517226219177
2020-01-13 08:00:20.172648 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #736 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1884568
Z variance train             0.008902739
KL Divergence                25.020617
KL Loss                      2.5020616
QF Loss                      634.2611
VF Loss                      183.63611
Policy Loss                  -2344.7812
Q Predictions Mean           2347.238
Q Predictions Std            350.6148
Q Predictions Max            2569.3186
Q Predictions Min            -317.1007
V Predictions Mean           2338.3694
V Predictions Std            345.42877
V Predictions Max            2567.6086
V Predictions Min            -291.99094
Log Pis Mean                 2.9763784
Log Pis Std                  3.7436144
Log Pis Max                  19.660568
Log Pis Min                  -5.6754403
Policy mu Mean               -0.013494035
Policy mu Std                0.669123
Policy mu Max                2.9290307
Policy mu Min                -5.1056623
Policy log std Mean          -1.3864119
Policy log std Std           0.30798247
Policy log std Max           -0.12921286
Policy log std Min           -2.8765059
Z mean eval                  1.1676276
Z variance eval              0.0143738445
total_rewards                [5847.99131333 5875.45849799 5742.63586924 5865.75321784 2895.95354093
 5795.94491208 5895.25104088 5625.30109045 6095.99642366 5880.43550033]
total_rewards_mean           5552.072140672556
total_rewards_std            892.6425683568445
total_rewards_max            6095.996423657391
total_rewards_min            2895.953540928112
Number of train steps total  2952000
Number of env steps total    3692000
Number of rollouts total     0
Train Time (s)               120.07761642010882
(Previous) Eval Time (s)     27.088444294873625
Sample Time (s)              18.64036467159167
Epoch Time (s)               165.80642538657412
Total Train Time (s)         117087.52666160837
Epoch                        737
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:03:05.400093 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #737 | Epoch Duration: 165.22724103927612
2020-01-13 08:03:05.400326 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #737 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1678928
Z variance train             0.01436319
KL Divergence                24.505367
KL Loss                      2.4505367
QF Loss                      1228.6028
VF Loss                      173.26984
Policy Loss                  -2313.7705
Q Predictions Mean           2318.3533
Q Predictions Std            333.32236
Q Predictions Max            2530.4084
Q Predictions Min            -104.372635
V Predictions Mean           2312.355
V Predictions Std            329.86853
V Predictions Max            2523.1548
V Predictions Min            -100.2621
Log Pis Mean                 3.0279007
Log Pis Std                  3.8958902
Log Pis Max                  22.316326
Log Pis Min                  -4.9700165
Policy mu Mean               -0.021935869
Policy mu Std                0.7011701
Policy mu Max                3.351669
Policy mu Min                -3.252787
Policy log std Mean          -1.3680631
Policy log std Std           0.35954955
Policy log std Max           -0.0066330433
Policy log std Min           -4.3089495
Z mean eval                  1.157103
Z variance eval              0.009881412
total_rewards                [5833.63212519 5827.56923808 5904.87760436 5809.48523391 5876.24629807
 5804.8931418  5900.79298426 6080.70906767 5984.70178103 5811.94431948]
total_rewards_mean           5883.48517938562
total_rewards_std            85.04961749606274
total_rewards_max            6080.709067671437
total_rewards_min            5804.8931417978965
Number of train steps total  2956000
Number of env steps total    3697000
Number of rollouts total     0
Train Time (s)               120.2418446089141
(Previous) Eval Time (s)     26.508955876808614
Sample Time (s)              18.078048628289253
Epoch Time (s)               164.82884911401197
Total Train Time (s)         117252.55403755512
Epoch                        738
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:05:50.437683 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #738 | Epoch Duration: 165.03715634346008
2020-01-13 08:05:50.437973 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #738 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1571215
Z variance train             0.009883849
KL Divergence                25.455217
KL Loss                      2.5455217
QF Loss                      950.3811
VF Loss                      135.41783
Policy Loss                  -2324.5
Q Predictions Mean           2321.1504
Q Predictions Std            382.12738
Q Predictions Max            2567.6648
Q Predictions Min            -232.78014
V Predictions Mean           2323.5327
V Predictions Std            371.65118
V Predictions Max            2564.968
V Predictions Min            -221.34277
Log Pis Mean                 2.7833717
Log Pis Std                  4.0180044
Log Pis Max                  19.573181
Log Pis Min                  -5.450718
Policy mu Mean               -0.05213213
Policy mu Std                0.6904966
Policy mu Max                3.0476716
Policy mu Min                -4.2502894
Policy log std Mean          -1.3573396
Policy log std Std           0.31940588
Policy log std Max           -0.15612614
Policy log std Min           -3.29417
Z mean eval                  1.1575537
Z variance eval              0.008727932
total_rewards                [5829.35466984 5823.30340737 5856.4551842  5589.96116322 5713.18670447
  204.27128738 5874.17427202 5856.23442328 5863.12945308 5936.10522969]
total_rewards_mean           5254.617579454681
total_rewards_std            1685.9768345899581
total_rewards_max            5936.105229690123
total_rewards_min            204.27128737862498
Number of train steps total  2960000
Number of env steps total    3702000
Number of rollouts total     0
Train Time (s)               119.96462225588039
(Previous) Eval Time (s)     26.71694727567956
Sample Time (s)              18.816667743958533
Epoch Time (s)               165.49823727551848
Total Train Time (s)         117415.72323370352
Epoch                        739
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:08:33.617438 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #739 | Epoch Duration: 163.17923712730408
2020-01-13 08:08:33.617721 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #739 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1580884
Z variance train             0.008730963
KL Divergence                25.596287
KL Loss                      2.5596287
QF Loss                      1171.9347
VF Loss                      812.5419
Policy Loss                  -2347.8752
Q Predictions Mean           2349.1255
Q Predictions Std            326.01535
Q Predictions Max            2551.195
Q Predictions Min            -363.74124
V Predictions Mean           2357.7893
V Predictions Std            322.26755
V Predictions Max            2560.5986
V Predictions Min            -323.58002
Log Pis Mean                 2.8388069
Log Pis Std                  3.7656803
Log Pis Max                  24.84343
Log Pis Min                  -5.2680964
Policy mu Mean               -0.013697917
Policy mu Std                0.70371
Policy mu Max                2.7640562
Policy mu Min                -3.3102357
Policy log std Mean          -1.3410273
Policy log std Std           0.3121456
Policy log std Max           -0.07704687
Policy log std Min           -2.8346033
Z mean eval                  1.1445892
Z variance eval              0.01053883
total_rewards                [5864.26798111 6086.6490135  5938.08763267 5960.01329836 5976.67022924
 6157.45009446 5959.13888325 5931.48739388 5556.29779104 6083.28248036]
total_rewards_mean           5951.334479787607
total_rewards_std            155.94422776290816
total_rewards_max            6157.450094455198
total_rewards_min            5556.297791044401
Number of train steps total  2964000
Number of env steps total    3707000
Number of rollouts total     0
Train Time (s)               113.89162804279476
(Previous) Eval Time (s)     24.397606710903347
Sample Time (s)              18.939756540115923
Epoch Time (s)               157.22899129381403
Total Train Time (s)         117575.63305949606
Epoch                        740
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:11:13.536361 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #740 | Epoch Duration: 159.91842937469482
2020-01-13 08:11:13.536615 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #740 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1471627
Z variance train             0.010549104
KL Divergence                24.808672
KL Loss                      2.4808671
QF Loss                      1097.5549
VF Loss                      339.41867
Policy Loss                  -2369.972
Q Predictions Mean           2368.4663
Q Predictions Std            330.20538
Q Predictions Max            2567.642
Q Predictions Min            -322.82166
V Predictions Mean           2359.0825
V Predictions Std            323.54617
V Predictions Max            2564.533
V Predictions Min            -343.1881
Log Pis Mean                 3.1552114
Log Pis Std                  3.5841486
Log Pis Max                  15.603056
Log Pis Min                  -4.558241
Policy mu Mean               -0.02656459
Policy mu Std                0.7213062
Policy mu Max                2.7199402
Policy mu Min                -3.0313768
Policy log std Mean          -1.3724461
Policy log std Std           0.32444075
Policy log std Max           -0.09412992
Policy log std Min           -2.9529653
Z mean eval                  1.1324009
Z variance eval              0.016094323
total_rewards                [3042.70090776 5862.25030664 2698.71220608 6101.08105503 5682.61421769
 6078.87132443 5800.0138534  5856.09150529 6168.8776439  5962.4166278 ]
total_rewards_mean           5325.362964802339
total_rewards_std            1237.7217291109293
total_rewards_max            6168.877643901246
total_rewards_min            2698.712206081068
Number of train steps total  2968000
Number of env steps total    3712000
Number of rollouts total     0
Train Time (s)               124.0670583769679
(Previous) Eval Time (s)     27.08672766201198
Sample Time (s)              18.514599931892008
Epoch Time (s)               169.6683859708719
Total Train Time (s)         117742.30236852681
Epoch                        741
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:14:00.213101 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #741 | Epoch Duration: 166.67631697654724
2020-01-13 08:14:00.213283 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #741 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1334865
Z variance train             0.015994642
KL Divergence                24.36544
KL Loss                      2.4365442
QF Loss                      1617.519
VF Loss                      222.14151
Policy Loss                  -2301.5293
Q Predictions Mean           2306.357
Q Predictions Std            382.22986
Q Predictions Max            2560.6917
Q Predictions Min            -247.76797
V Predictions Mean           2299.611
V Predictions Std            374.7573
V Predictions Max            2559.9492
V Predictions Min            -252.12901
Log Pis Mean                 2.8746414
Log Pis Std                  4.060468
Log Pis Max                  15.819304
Log Pis Min                  -8.103943
Policy mu Mean               -0.017979234
Policy mu Std                0.7254808
Policy mu Max                3.8129358
Policy mu Min                -2.9993076
Policy log std Mean          -1.3344774
Policy log std Std           0.33080536
Policy log std Max           0.30751538
Policy log std Min           -2.8693535
Z mean eval                  1.1168708
Z variance eval              0.025585499
total_rewards                [5713.8800146  5979.84589395 6046.46455702 6096.1464937  6038.46043709
 5769.79923328 6077.24849886 5878.34951537 5951.9998669  5761.98283088]
total_rewards_mean           5931.417734164269
total_rewards_std            134.47401988923284
total_rewards_max            6096.146493695749
total_rewards_min            5713.880014601641
Number of train steps total  2972000
Number of env steps total    3717000
Number of rollouts total     0
Train Time (s)               122.80956000462174
(Previous) Eval Time (s)     24.09433450596407
Sample Time (s)              17.476232023909688
Epoch Time (s)               164.3801265344955
Total Train Time (s)         117909.66482536076
Epoch                        742
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:16:47.582161 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #742 | Epoch Duration: 167.3687388896942
2020-01-13 08:16:47.582406 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #742 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1161069
Z variance train             0.025643345
KL Divergence                24.461643
KL Loss                      2.4461644
QF Loss                      967.0553
VF Loss                      206.52736
Policy Loss                  -2328.5757
Q Predictions Mean           2332.4001
Q Predictions Std            331.78082
Q Predictions Max            2569.506
Q Predictions Min            -237.8958
V Predictions Mean           2327.7341
V Predictions Std            330.242
V Predictions Max            2567.4978
V Predictions Min            -245.46341
Log Pis Mean                 3.2575703
Log Pis Std                  3.6095119
Log Pis Max                  13.42436
Log Pis Min                  -4.092547
Policy mu Mean               -0.017885018
Policy mu Std                0.7244414
Policy mu Max                2.5035954
Policy mu Min                -2.8100867
Policy log std Mean          -1.3733586
Policy log std Std           0.3289503
Policy log std Max           0.111641645
Policy log std Min           -2.8569117
Z mean eval                  1.1416672
Z variance eval              0.016171176
total_rewards                [5890.53911866 6037.4146605  6029.15103553 5961.2599381  6030.42136503
 5966.75619124 6117.50470129 1330.2325716   161.43373298 5944.60717147]
total_rewards_mean           4946.932048639263
total_rewards_std            2117.5623068771624
total_rewards_max            6117.504701288486
total_rewards_min            161.43373297940377
Number of train steps total  2976000
Number of env steps total    3722000
Number of rollouts total     0
Train Time (s)               117.15661923680454
(Previous) Eval Time (s)     27.082701245788485
Sample Time (s)              18.1897811726667
Epoch Time (s)               162.42910165525973
Total Train Time (s)         118067.15546699706
Epoch                        743
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:19:25.079499 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #743 | Epoch Duration: 157.496910572052
2020-01-13 08:19:25.079683 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #743 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1410309
Z variance train             0.016162913
KL Divergence                24.408014
KL Loss                      2.4408014
QF Loss                      674.7548
VF Loss                      149.87003
Policy Loss                  -2285.4028
Q Predictions Mean           2284.4543
Q Predictions Std            427.9271
Q Predictions Max            2541.2942
Q Predictions Min            -347.59378
V Predictions Mean           2284.1973
V Predictions Std            405.8343
V Predictions Max            2532.6506
V Predictions Min            -330.95416
Log Pis Mean                 2.9868243
Log Pis Std                  3.8190165
Log Pis Max                  15.75382
Log Pis Min                  -4.508732
Policy mu Mean               -0.018243017
Policy mu Std                0.7359924
Policy mu Max                5.7554817
Policy mu Min                -3.058373
Policy log std Mean          -1.3420936
Policy log std Std           0.31423476
Policy log std Max           0.29709947
Policy log std Min           -2.7508092
Z mean eval                  1.1295979
Z variance eval              0.012118889
total_rewards                [1404.69072469 5774.62296264 6102.11100385 5761.30977631 5777.45179349
 5971.72222191 5958.03020842 5909.55872115 5742.25686292 5888.68996141]
total_rewards_mean           5429.044423678067
total_rewards_std            1345.89186036758
total_rewards_max            6102.111003847742
total_rewards_min            1404.6907246933094
Number of train steps total  2980000
Number of env steps total    3727000
Number of rollouts total     0
Train Time (s)               122.7206988860853
(Previous) Eval Time (s)     22.150195197667927
Sample Time (s)              17.89401358179748
Epoch Time (s)               162.7649076655507
Total Train Time (s)         118234.55686658388
Epoch                        744
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:22:12.485347 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #744 | Epoch Duration: 167.40553379058838
2020-01-13 08:22:12.485500 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #744 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1297219
Z variance train             0.012126866
KL Divergence                24.860016
KL Loss                      2.4860017
QF Loss                      2268.1216
VF Loss                      214.7081
Policy Loss                  -2368.3386
Q Predictions Mean           2369.689
Q Predictions Std            263.9516
Q Predictions Max            2891.4895
Q Predictions Min            109.36642
V Predictions Mean           2366.0405
V Predictions Std            254.20164
V Predictions Max            2999.3872
V Predictions Min            191.28023
Log Pis Mean                 2.5553591
Log Pis Std                  3.5578136
Log Pis Max                  15.504443
Log Pis Min                  -6.739334
Policy mu Mean               0.0026233206
Policy mu Std                0.6799986
Policy mu Max                3.0955884
Policy mu Min                -3.1403506
Policy log std Mean          -1.338067
Policy log std Std           0.30632192
Policy log std Max           -0.18891919
Policy log std Min           -2.9390097
Z mean eval                  1.1244501
Z variance eval              0.010917077
total_rewards                [5872.91939785 6024.05718424 5833.20032469 5871.87820552 3681.50047621
 3455.10285914 5825.82024768 5783.98774587 5994.40159826 5913.12943326]
total_rewards_mean           5425.599747272454
total_rewards_std            932.637564490161
total_rewards_max            6024.05718423827
total_rewards_min            3455.1028591447625
Number of train steps total  2984000
Number of env steps total    3732000
Number of rollouts total     0
Train Time (s)               123.3224412300624
(Previous) Eval Time (s)     26.79050270607695
Sample Time (s)              18.315450981259346
Epoch Time (s)               168.4283949173987
Total Train Time (s)         118401.42988122674
Epoch                        745
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:24:59.373032 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #745 | Epoch Duration: 166.88737750053406
2020-01-13 08:24:59.373335 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #745 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1246886
Z variance train             0.0109018115
KL Divergence                24.720215
KL Loss                      2.4720216
QF Loss                      705.7603
VF Loss                      180.05011
Policy Loss                  -2349.2976
Q Predictions Mean           2352.9878
Q Predictions Std            357.78174
Q Predictions Max            4207.45
Q Predictions Min            -62.603626
V Predictions Mean           2348.433
V Predictions Std            353.6878
V Predictions Max            4243.534
V Predictions Min            -140.34058
Log Pis Mean                 2.7713714
Log Pis Std                  3.676878
Log Pis Max                  15.001457
Log Pis Min                  -6.650168
Policy mu Mean               -0.025531106
Policy mu Std                0.6616469
Policy mu Max                2.7126224
Policy mu Min                -3.0058165
Policy log std Mean          -1.3820009
Policy log std Std           0.33511937
Policy log std Max           -0.05574262
Policy log std Min           -2.9207811
Z mean eval                  1.1613828
Z variance eval              0.014332162
total_rewards                [5870.26534755 5777.48988446 5729.49413936 5800.06011427 5968.7631711
 6018.87421005 6058.46250929 5961.95570285 5914.13168539 5668.57446037]
total_rewards_mean           5876.807122468558
total_rewards_std            122.93893767566162
total_rewards_max            6058.462509294265
total_rewards_min            5668.574460366837
Number of train steps total  2988000
Number of env steps total    3737000
Number of rollouts total     0
Train Time (s)               132.25349468225613
(Previous) Eval Time (s)     25.249127748887986
Sample Time (s)              18.738117584958673
Epoch Time (s)               176.2407400161028
Total Train Time (s)         118579.34055936616
Epoch                        746
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:27:57.289597 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #746 | Epoch Duration: 177.91603088378906
2020-01-13 08:27:57.289863 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #746 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1614792
Z variance train             0.014310321
KL Divergence                24.81791
KL Loss                      2.481791
QF Loss                      862.22784
VF Loss                      226.60016
Policy Loss                  -2358.4224
Q Predictions Mean           2359.2554
Q Predictions Std            255.10063
Q Predictions Max            2551.3354
Q Predictions Min            436.28668
V Predictions Mean           2360.707
V Predictions Std            240.10556
V Predictions Max            2544.973
V Predictions Min            702.18634
Log Pis Mean                 2.8864527
Log Pis Std                  3.8913236
Log Pis Max                  18.358337
Log Pis Min                  -7.9841223
Policy mu Mean               -0.010075044
Policy mu Std                0.67721015
Policy mu Max                3.0525396
Policy mu Min                -3.0841916
Policy log std Mean          -1.3712689
Policy log std Std           0.31464726
Policy log std Max           -0.27808893
Policy log std Min           -2.8777595
Z mean eval                  1.1582472
Z variance eval              0.01359093
total_rewards                [5611.52101972 6017.25441406 5890.40103832 2148.20867011 5854.71630453
 5938.54985604 3972.74794194 6016.90478781 5819.61351524 5844.77424402]
total_rewards_mean           5311.4691791786045
total_rewards_std            1202.0952363452052
total_rewards_max            6017.254414064919
total_rewards_min            2148.2086701120365
Number of train steps total  2992000
Number of env steps total    3742000
Number of rollouts total     0
Train Time (s)               121.72501941397786
(Previous) Eval Time (s)     26.924114366993308
Sample Time (s)              18.271497739013284
Epoch Time (s)               166.92063151998445
Total Train Time (s)         118743.68268000428
Epoch                        747
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:30:41.638353 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #747 | Epoch Duration: 164.348290681839
2020-01-13 08:30:41.638571 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #747 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1580669
Z variance train             0.013592941
KL Divergence                24.84966
KL Loss                      2.484966
QF Loss                      1097.2014
VF Loss                      229.19794
Policy Loss                  -2390.5967
Q Predictions Mean           2391.5845
Q Predictions Std            333.83447
Q Predictions Max            2588.0193
Q Predictions Min            -66.403534
V Predictions Mean           2387.5708
V Predictions Std            326.7603
V Predictions Max            2586.9841
V Predictions Min            -71.09855
Log Pis Mean                 3.0577564
Log Pis Std                  3.8401291
Log Pis Max                  20.904366
Log Pis Min                  -4.8031054
Policy mu Mean               0.017031334
Policy mu Std                0.6861441
Policy mu Max                3.5407996
Policy mu Min                -2.8027656
Policy log std Mean          -1.3864796
Policy log std Std           0.33074966
Policy log std Max           -0.15861416
Policy log std Min           -2.9421916
Z mean eval                  1.104281
Z variance eval              0.009514799
total_rewards                [5865.59987915 5891.9551602  6018.14068418 5709.05654942 5993.58007266
 5889.81445162 5773.48067438 5946.24880804 5913.82296806 5991.23796587]
total_rewards_mean           5899.293721358947
total_rewards_std            93.37142512718023
total_rewards_max            6018.14068417634
total_rewards_min            5709.056549416799
Number of train steps total  2996000
Number of env steps total    3747000
Number of rollouts total     0
Train Time (s)               124.24630629410967
(Previous) Eval Time (s)     24.35144432587549
Sample Time (s)              18.590952613856643
Epoch Time (s)               167.1887032338418
Total Train Time (s)         118914.63924118411
Epoch                        748
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:33:32.599592 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #748 | Epoch Duration: 170.96088027954102
2020-01-13 08:33:32.599755 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #748 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1053629
Z variance train             0.009504396
KL Divergence                24.185806
KL Loss                      2.4185808
QF Loss                      1927.1055
VF Loss                      381.31903
Policy Loss                  -2398.1108
Q Predictions Mean           2398.1545
Q Predictions Std            377.10733
Q Predictions Max            5804.9185
Q Predictions Min            514.94434
V Predictions Mean           2394.1519
V Predictions Std            376.04425
V Predictions Max            5847.488
V Predictions Min            413.99188
Log Pis Mean                 2.922372
Log Pis Std                  3.9318697
Log Pis Max                  19.300303
Log Pis Min                  -5.576364
Policy mu Mean               0.021455415
Policy mu Std                0.71588886
Policy mu Max                3.8193667
Policy mu Min                -3.9689524
Policy log std Mean          -1.3558356
Policy log std Std           0.34459302
Policy log std Max           0.09260929
Policy log std Min           -3.0171044
Z mean eval                  1.1469823
Z variance eval              0.009941932
total_rewards                [5834.49033393 6047.59214352 2327.3466818  5838.71863764 6066.95690756
 1369.50531593 5922.11784989 5757.40019847 5897.73306933 6078.35448185]
total_rewards_mean           5114.021561991058
total_rewards_std            1649.9077882918673
total_rewards_max            6078.3544818461
total_rewards_min            1369.5053159331517
Number of train steps total  3000000
Number of env steps total    3752000
Number of rollouts total     0
Train Time (s)               124.26622516242787
(Previous) Eval Time (s)     28.123264132998884
Sample Time (s)              18.337805805262178
Epoch Time (s)               170.72729510068893
Total Train Time (s)         119080.25058248127
Epoch                        749
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:36:18.218116 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #749 | Epoch Duration: 165.61820483207703
2020-01-13 08:36:18.218312 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Iteration #749 | Started Training: True
2020-01-13 08:36:18.798760 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] Variant:
2020-01-13 08:36:18.799198 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] {
  "env_name": "HalfCheetah-v2",
  "n_train_tasks": 1,
  "n_eval_tasks": 1,
  "latent_size": 5,
  "net_size": 300,
  "path_to_weights": null,
  "env_params": {
    "n_tasks": 2,
    "randomize_tasks": true
  },
  "algo_params": {
    "meta_batch": 1,
    "num_iterations": 750,
    "num_initial_steps": 2000,
    "num_tasks_sample": 5,
    "num_steps_prior": 400,
    "num_steps_posterior": 0,
    "num_extra_rl_steps_posterior": 600,
    "num_train_steps_per_itr": 4000,
    "num_evals": 2,
    "num_steps_per_eval": 600,
    "batch_size": 256,
    "embedding_batch_size": 20,
    "embedding_mini_batch_size": 20,
    "max_path_length": 200,
    "discount": 0.99,
    "soft_target_tau": 0.005,
    "policy_lr": 0.0003,
    "qf_lr": 0.0003,
    "vf_lr": 0.0003,
    "context_lr": 0.0003,
    "reward_scale": 5.0,
    "sparse_rewards": false,
    "kl_lambda": 0.1,
    "use_information_bottleneck": true,
    "use_next_obs_in_context": false,
    "update_post_train": 1,
    "num_exp_traj_eval": 2,
    "recurrent": true,
    "dump_eval_paths": false
  },
  "util_params": {
    "base_log_dir": "./test/train4000_no-clear_H-20_s1",
    "use_gpu": true,
    "gpu_id": 0,
    "debug": false,
    "docker": false
  }
}
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0012457505
Z variance train             0.69295514
KL Divergence                0.14937219
KL Loss                      0.014937219
QF Loss                      30.614424
VF Loss                      16.36408
Policy Loss                  -4.0074687
Q Predictions Mean           -0.003765408
Q Predictions Std            0.0021504015
Q Predictions Max            0.0019707258
Q Predictions Min            -0.008826294
V Predictions Mean           -0.0035245663
V Predictions Std            0.0012763198
V Predictions Max            -0.00020867772
V Predictions Min            -0.0075911563
Log Pis Mean                 -4.0296206
Log Pis Std                  0.5254945
Log Pis Max                  -2.448501
Log Pis Min                  -5.336877
Policy mu Mean               0.0010540453
Policy mu Std                0.0016826743
Policy mu Max                0.007478892
Policy mu Min                -0.0022162735
Policy log std Mean          0.00048335767
Policy log std Std           0.0009788934
Policy log std Max           0.0032959678
Policy log std Min           -0.0020309421
Z mean eval                  0.628561
Z variance eval              0.027482351
total_rewards                [-282.83767511 -290.29498025 -288.35996893 -299.71675192 -285.40588017
 -278.82270476 -273.90804956 -300.54071864 -281.29473746 -258.75060161]
total_rewards_mean           -283.9932068408397
total_rewards_std            11.645072865733463
total_rewards_max            -258.7506016077926
total_rewards_min            -300.5407186433345
Number of train steps total  4000
Number of env steps total    7000
Number of rollouts total     0
Train Time (s)               110.21506367065012
(Previous) Eval Time (s)     0
Sample Time (s)              22.93132338160649
Epoch Time (s)               133.1463870522566
Total Train Time (s)         156.46919088065624
Epoch                        0
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:38:55.358323 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #0 | Epoch Duration: 156.47420167922974
2020-01-13 08:38:55.358612 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #0 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.61568946
Z variance train             0.028527137
KL Divergence                7.506925
KL Loss                      0.75069255
QF Loss                      178.4768
VF Loss                      91.35954
Policy Loss                  -66.59576
Q Predictions Mean           63.76955
Q Predictions Std            20.55064
Q Predictions Max            113.28124
Q Predictions Min            7.455209
V Predictions Mean           72.24949
V Predictions Std            20.661192
V Predictions Max            115.14223
V Predictions Min            14.871356
Log Pis Mean                 -0.9560207
Log Pis Std                  2.5059512
Log Pis Max                  5.9273434
Log Pis Min                  -6.7857504
Policy mu Mean               -0.12984331
Policy mu Std                0.86047906
Policy mu Max                2.0160275
Policy mu Min                -2.642189
Policy log std Mean          -0.31558552
Policy log std Std           0.1337712
Policy log std Max           -0.059776537
Policy log std Min           -0.76984066
Z mean eval                  0.9986416
Z variance eval              0.027677152
total_rewards                [-302.34043717 -406.83261832 -406.99721955 -438.6178349  -337.54477525
 -346.92335863 -403.27890917 -400.42785756 -350.16679193 -381.32558426]
total_rewards_mean           -377.44553867350487
total_rewards_std            39.494477559200064
total_rewards_max            -302.34043716836163
total_rewards_min            -438.61783490208524
Number of train steps total  8000
Number of env steps total    12000
Number of rollouts total     0
Train Time (s)               112.72498171590269
(Previous) Eval Time (s)     23.327456586062908
Sample Time (s)              16.034958101343364
Epoch Time (s)               152.08739640330896
Total Train Time (s)         307.9255045093596
Epoch                        1
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:41:26.813005 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #1 | Epoch Duration: 151.45419478416443
2020-01-13 08:41:26.813158 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #1 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99792844
Z variance train             0.027689924
KL Divergence                9.329681
KL Loss                      0.93296814
QF Loss                      231.60794
VF Loss                      28.55466
Policy Loss                  -129.86415
Q Predictions Mean           123.91619
Q Predictions Std            20.540236
Q Predictions Max            208.16814
Q Predictions Min            47.61658
V Predictions Mean           128.9472
V Predictions Std            20.453411
V Predictions Max            210.2953
V Predictions Min            64.103386
Log Pis Mean                 -1.7842556
Log Pis Std                  2.047518
Log Pis Max                  4.4983897
Log Pis Min                  -9.7208
Policy mu Mean               -0.079125896
Policy mu Std                0.73489505
Policy mu Max                1.9243048
Policy mu Min                -2.261077
Policy log std Mean          -0.27527812
Policy log std Std           0.12119935
Policy log std Max           0.061163895
Policy log std Min           -0.7404426
Z mean eval                  1.352073
Z variance eval              0.018047396
total_rewards                [  -5.29420221 -156.48259271 -134.03712234   -1.63598733 -108.16507388
   94.23408969  -83.30645074  -20.57297564 -163.94716736 -220.2607476 ]
total_rewards_mean           -79.94682301139532
total_rewards_std            90.50134886623094
total_rewards_max            94.23408969189995
total_rewards_min            -220.2607475972802
Number of train steps total  12000
Number of env steps total    17000
Number of rollouts total     0
Train Time (s)               115.22349850274622
(Previous) Eval Time (s)     22.69395993789658
Sample Time (s)              16.82628980698064
Epoch Time (s)               154.74374824762344
Total Train Time (s)         462.764694434125
Epoch                        2
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:44:01.654066 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #2 | Epoch Duration: 154.84076356887817
2020-01-13 08:44:01.654316 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #2 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3512412
Z variance train             0.018025516
KL Divergence                12.646511
KL Loss                      1.2646512
QF Loss                      65.69432
VF Loss                      13.53095
Policy Loss                  -169.8218
Q Predictions Mean           167.72607
Q Predictions Std            42.624184
Q Predictions Max            315.1617
Q Predictions Min            104.69985
V Predictions Mean           170.32433
V Predictions Std            42.162556
V Predictions Max            314.13495
V Predictions Min            110.571175
Log Pis Mean                 -2.3928812
Log Pis Std                  1.9543785
Log Pis Max                  4.890258
Log Pis Min                  -7.4958344
Policy mu Mean               -0.13078327
Policy mu Std                0.6014988
Policy mu Max                1.8279668
Policy mu Min                -1.6683878
Policy log std Mean          -0.29952264
Policy log std Std           0.14448848
Policy log std Max           0.07742707
Policy log std Min           -0.94793475
Z mean eval                  1.5462358
Z variance eval              0.009479667
total_rewards                [1.04357422e+02 8.29185157e+02 2.04116706e+02 8.85620906e+02
 7.19014577e+02 8.45949757e+02 2.66373840e+02 1.16096788e+03
 7.38484213e+02 3.74814194e-01]
total_rewards_mean           575.4445270754835
total_rewards_std            375.47782128232166
total_rewards_max            1160.967879143385
total_rewards_min            0.37481419360368085
Number of train steps total  16000
Number of env steps total    22000
Number of rollouts total     0
Train Time (s)               110.8962363009341
(Previous) Eval Time (s)     22.79065038310364
Sample Time (s)              15.901511052623391
Epoch Time (s)               149.58839773666114
Total Train Time (s)         612.4083675486036
Epoch                        3
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:46:31.299151 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #3 | Epoch Duration: 149.64465761184692
2020-01-13 08:46:31.299370 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #3 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5487229
Z variance train             0.009477184
KL Divergence                15.452665
KL Loss                      1.5452665
QF Loss                      67.18808
VF Loss                      19.785416
Policy Loss                  -221.34027
Q Predictions Mean           220.15317
Q Predictions Std            79.47603
Q Predictions Max            387.4206
Q Predictions Min            108.2124
V Predictions Mean           219.7443
V Predictions Std            78.42544
V Predictions Max            389.1361
V Predictions Min            109.648636
Log Pis Mean                 -1.9174757
Log Pis Std                  2.1933498
Log Pis Max                  5.835287
Log Pis Min                  -7.962221
Policy mu Mean               -0.042990208
Policy mu Std                0.6651067
Policy mu Max                2.0532029
Policy mu Min                -2.0324678
Policy log std Mean          -0.35423145
Policy log std Std           0.18612057
Policy log std Max           0.09108853
Policy log std Min           -1.0839621
Z mean eval                  1.745553
Z variance eval              0.005873815
total_rewards                [1857.15735346 1714.53801862 1845.66297244 1797.54780839 1919.82797648
 1794.05287376 1698.76153223 1839.35469355 1649.08034692 1799.90481242]
total_rewards_mean           1791.5888388284504
total_rewards_std            78.0533404491577
total_rewards_max            1919.827976480664
total_rewards_min            1649.0803469195046
Number of train steps total  20000
Number of env steps total    27000
Number of rollouts total     0
Train Time (s)               113.8979875901714
(Previous) Eval Time (s)     22.84663489414379
Sample Time (s)              16.03130231006071
Epoch Time (s)               152.7759247943759
Total Train Time (s)         764.5886086737737
Epoch                        4
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:49:03.479198 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #4 | Epoch Duration: 152.17967128753662
2020-01-13 08:49:03.479353 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #4 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7473576
Z variance train             0.0059068655
KL Divergence                18.712698
KL Loss                      1.8712698
QF Loss                      81.29608
VF Loss                      21.226429
Policy Loss                  -282.77008
Q Predictions Mean           281.492
Q Predictions Std            114.028465
Q Predictions Max            489.03992
Q Predictions Min            126.96365
V Predictions Mean           283.18365
V Predictions Std            114.066284
V Predictions Max            493.8458
V Predictions Min            133.20044
Log Pis Mean                 -1.4046888
Log Pis Std                  2.4597247
Log Pis Max                  6.5841284
Log Pis Min                  -8.596814
Policy mu Mean               0.012249689
Policy mu Std                0.7089112
Policy mu Max                2.2666492
Policy mu Min                -2.1316712
Policy log std Mean          -0.3894161
Policy log std Std           0.20671816
Policy log std Max           0.039595738
Policy log std Min           -1.2511321
Z mean eval                  1.9102243
Z variance eval              0.0045891325
total_rewards                [2468.12928414 2380.89856258 2331.94889278 2443.38615637 2509.31682747
 2336.45320217 2371.76987537 2382.90445239 2528.11959371 2244.455962  ]
total_rewards_mean           2399.7382808974744
total_rewards_std            83.18968149680059
total_rewards_max            2528.119593708687
total_rewards_min            2244.455961998926
Number of train steps total  24000
Number of env steps total    32000
Number of rollouts total     0
Train Time (s)               115.1550712082535
(Previous) Eval Time (s)     22.250103851314634
Sample Time (s)              16.224637099541724
Epoch Time (s)               153.62981215910986
Total Train Time (s)         919.1265194048174
Epoch                        5
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:51:38.018136 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #5 | Epoch Duration: 154.53866457939148
2020-01-13 08:51:38.018333 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #5 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9107635
Z variance train             0.004586278
KL Divergence                20.624924
KL Loss                      2.0624924
QF Loss                      123.52498
VF Loss                      31.828794
Policy Loss                  -387.9629
Q Predictions Mean           382.90344
Q Predictions Std            157.96204
Q Predictions Max            626.8578
Q Predictions Min            134.73064
V Predictions Mean           384.8045
V Predictions Std            155.61346
V Predictions Max            622.63904
V Predictions Min            144.9738
Log Pis Mean                 -1.0381448
Log Pis Std                  2.6682339
Log Pis Max                  7.850091
Log Pis Min                  -6.667865
Policy mu Mean               0.009502257
Policy mu Std                0.78162557
Policy mu Max                2.3151317
Policy mu Min                -2.4185295
Policy log std Mean          -0.43612465
Policy log std Std           0.21884194
Policy log std Max           0.031076074
Policy log std Min           -1.3481383
Z mean eval                  2.0359802
Z variance eval              0.01664384
total_rewards                [2719.14271542 2917.2033017  2730.75649807 2820.12631663 2792.9247871
 2969.21335084 2956.01755633 2660.11076111 2942.25774435 2830.0372841 ]
total_rewards_mean           2833.7790315645225
total_rewards_std            103.82543710035941
total_rewards_max            2969.21335084046
total_rewards_min            2660.1107611053326
Number of train steps total  28000
Number of env steps total    37000
Number of rollouts total     0
Train Time (s)               114.91340536810458
(Previous) Eval Time (s)     23.158654887694865
Sample Time (s)              16.04918751725927
Epoch Time (s)               154.1212477730587
Total Train Time (s)         1073.4347090842202
Epoch                        6
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:54:12.327141 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #6 | Epoch Duration: 154.30867218971252
2020-01-13 08:54:12.327338 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #6 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0336952
Z variance train             0.016701246
KL Divergence                19.950933
KL Loss                      1.9950933
QF Loss                      136.25708
VF Loss                      65.81027
Policy Loss                  -453.71738
Q Predictions Mean           446.81158
Q Predictions Std            196.09023
Q Predictions Max            761.3243
Q Predictions Min            135.49709
V Predictions Mean           447.89954
V Predictions Std            193.4754
V Predictions Max            747.9191
V Predictions Min            140.80939
Log Pis Mean                 -0.8918572
Log Pis Std                  2.721726
Log Pis Max                  9.734151
Log Pis Min                  -6.7928967
Policy mu Mean               -0.019431265
Policy mu Std                0.77395827
Policy mu Max                2.3524032
Policy mu Min                -2.117918
Policy log std Mean          -0.4843755
Policy log std Std           0.24199
Policy log std Max           0.13079198
Policy log std Min           -1.6417655
Z mean eval                  2.2100582
Z variance eval              0.0075418567
total_rewards                [3151.57828294 3241.32545481 3382.57761737 3431.30420083 3503.40524302
 3353.73553926 3422.46849557 3353.31014662 3515.93891539 3346.91463218]
total_rewards_mean           3370.2558527997403
total_rewards_std            105.40636554133202
total_rewards_max            3515.938915389279
total_rewards_min            3151.578282944603
Number of train steps total  32000
Number of env steps total    42000
Number of rollouts total     0
Train Time (s)               113.95658383984119
(Previous) Eval Time (s)     23.345778845716268
Sample Time (s)              16.107747976202518
Epoch Time (s)               153.41011066175997
Total Train Time (s)         1226.3589313724078
Epoch                        7
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:56:45.254256 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #7 | Epoch Duration: 152.92677688598633
2020-01-13 08:56:45.254437 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #7 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.21005
Z variance train             0.0075446805
KL Divergence                23.19463
KL Loss                      2.319463
QF Loss                      147.64453
VF Loss                      41.245598
Policy Loss                  -569.87616
Q Predictions Mean           565.13226
Q Predictions Std            251.48866
Q Predictions Max            954.66144
Q Predictions Min            158.21219
V Predictions Mean           568.6189
V Predictions Std            248.75885
V Predictions Max            933.09656
V Predictions Min            155.3033
Log Pis Mean                 -0.5360782
Log Pis Std                  3.091602
Log Pis Max                  12.133513
Log Pis Min                  -8.334568
Policy mu Mean               0.043735627
Policy mu Std                0.8684841
Policy mu Max                2.8035772
Policy mu Min                -2.253933
Policy log std Mean          -0.5132446
Policy log std Std           0.24622673
Policy log std Max           0.015334114
Policy log std Min           -1.5874217
Z mean eval                  2.3629317
Z variance eval              0.006886994
total_rewards                [3594.32537675 3795.15757598 3494.79395019 3931.25831927 3421.38713452
 3751.49006873 3754.47476048 3702.41544822 3752.41916563 3895.32665373]
total_rewards_mean           3709.3048453502793
total_rewards_std            154.62735281834702
total_rewards_max            3931.2583192731086
total_rewards_min            3421.3871345239927
Number of train steps total  36000
Number of env steps total    47000
Number of rollouts total     0
Train Time (s)               113.90841681975871
(Previous) Eval Time (s)     22.862104720901698
Sample Time (s)              16.911021458450705
Epoch Time (s)               153.68154299911112
Total Train Time (s)         1379.6716608200222
Epoch                        8
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:59:18.567652 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #8 | Epoch Duration: 153.31305599212646
2020-01-13 08:59:18.568028 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #8 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3656452
Z variance train             0.0068819523
KL Divergence                25.292015
KL Loss                      2.5292015
QF Loss                      185.92572
VF Loss                      139.9944
Policy Loss                  -702.0062
Q Predictions Mean           692.3939
Q Predictions Std            286.06174
Q Predictions Max            1095.758
Q Predictions Min            181.33258
V Predictions Mean           692.11523
V Predictions Std            282.3599
V Predictions Max            1075.938
V Predictions Min            185.51343
Log Pis Mean                 0.22556522
Log Pis Std                  3.1298044
Log Pis Max                  12.58712
Log Pis Min                  -8.339167
Policy mu Mean               -0.012579516
Policy mu Std                0.93578374
Policy mu Max                2.6190236
Policy mu Min                -2.418634
Policy log std Mean          -0.54409164
Policy log std Std           0.25289547
Policy log std Max           0.16135123
Policy log std Min           -1.750263
Z mean eval                  2.4910617
Z variance eval              0.008008067
total_rewards                [3879.74907573 4015.19282022 3827.8469857  4132.09878097 3876.96494965
 3826.19526649 3893.62884471 4000.07590816 4165.95458462 4024.14263897]
total_rewards_mean           3964.184985522963
total_rewards_std            115.64386314925223
total_rewards_max            4165.954584621495
total_rewards_min            3826.195266487261
Number of train steps total  40000
Number of env steps total    52000
Number of rollouts total     0
Train Time (s)               114.14174756687135
(Previous) Eval Time (s)     22.493319396860898
Sample Time (s)              15.80332974717021
Epoch Time (s)               152.43839671090245
Total Train Time (s)         1532.0933290817775
Epoch                        9
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:01:50.988868 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #9 | Epoch Duration: 152.42055916786194
2020-01-13 09:01:50.989025 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #9 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4893162
Z variance train             0.007983432
KL Divergence                27.931353
KL Loss                      2.7931354
QF Loss                      225.785
VF Loss                      69.90759
Policy Loss                  -822.58685
Q Predictions Mean           818.7708
Q Predictions Std            316.1376
Q Predictions Max            1257.152
Q Predictions Min            215.90018
V Predictions Mean           822.5707
V Predictions Std            314.54172
V Predictions Max            1268.7821
V Predictions Min            217.84149
Log Pis Mean                 0.5887064
Log Pis Std                  3.3710744
Log Pis Max                  11.317989
Log Pis Min                  -6.014797
Policy mu Mean               0.012342806
Policy mu Std                0.958221
Policy mu Max                3.055008
Policy mu Min                -2.4398522
Policy log std Mean          -0.5638519
Policy log std Std           0.2669496
Policy log std Max           0.022259116
Policy log std Min           -1.9485407
Z mean eval                  2.5841775
Z variance eval              0.011292124
total_rewards                [3932.32230598 3961.92927781 4089.09974364 4229.64475362 2899.27099211
 4122.76705071 4014.67121934 1315.43011475 4155.65796014 1297.53756468]
total_rewards_mean           3401.8330982806015
total_rewards_std            1106.7975483375694
total_rewards_max            4229.644753623327
total_rewards_min            1297.5375646821826
Number of train steps total  44000
Number of env steps total    57000
Number of rollouts total     0
Train Time (s)               113.46746774762869
(Previous) Eval Time (s)     22.475203794892877
Sample Time (s)              15.668891204986721
Epoch Time (s)               151.6115627475083
Total Train Time (s)         1683.4392182100564
Epoch                        10
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:04:22.336688 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #10 | Epoch Duration: 151.34753489494324
2020-01-13 09:04:22.336897 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #10 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5851238
Z variance train             0.011323895
KL Divergence                28.692623
KL Loss                      2.8692625
QF Loss                      212.95657
VF Loss                      86.12039
Policy Loss                  -936.6323
Q Predictions Mean           932.6178
Q Predictions Std            315.03595
Q Predictions Max            1366.4398
Q Predictions Min            218.67238
V Predictions Mean           934.64075
V Predictions Std            308.8193
V Predictions Max            1355.3606
V Predictions Min            233.92177
Log Pis Mean                 0.7968751
Log Pis Std                  3.2793646
Log Pis Max                  13.367478
Log Pis Min                  -6.2733054
Policy mu Mean               -0.008932165
Policy mu Std                1.0100248
Policy mu Max                2.6883821
Policy mu Min                -2.512717
Policy log std Mean          -0.58778065
Policy log std Std           0.24613313
Policy log std Max           0.11237344
Policy log std Min           -1.8369529
Z mean eval                  2.6603203
Z variance eval              0.004912203
total_rewards                [4170.56592456 4275.4715483   407.42104741 4423.78773341 4216.10583483
 4160.59748308 4453.3837282  4374.76530422 4382.78023001 4609.66843608]
total_rewards_mean           3947.4547270110606
total_rewards_std            1187.446935785901
total_rewards_max            4609.668436079662
total_rewards_min            407.4210474130184
Number of train steps total  48000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               109.17313935002312
(Previous) Eval Time (s)     22.210897183045745
Sample Time (s)              16.031351238954812
Epoch Time (s)               147.41538777202368
Total Train Time (s)         1832.2681331709027
Epoch                        11
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:06:51.165641 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #11 | Epoch Duration: 148.82859563827515
2020-01-13 09:06:51.165800 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #11 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.6593766
Z variance train             0.00491384
KL Divergence                30.781994
KL Loss                      3.0781994
QF Loss                      207.56815
VF Loss                      78.533424
Policy Loss                  -989.04346
Q Predictions Mean           982.5615
Q Predictions Std            392.63773
Q Predictions Max            1453.6288
Q Predictions Min            244.38855
V Predictions Mean           989.34875
V Predictions Std            389.9482
V Predictions Max            1459.927
V Predictions Min            260.82977
Log Pis Mean                 0.9378776
Log Pis Std                  3.4959834
Log Pis Max                  10.368065
Log Pis Min                  -5.6603527
Policy mu Mean               -0.03301247
Policy mu Std                1.0073929
Policy mu Max                2.5755355
Policy mu Min                -2.3752537
Policy log std Mean          -0.6135469
Policy log std Std           0.27561072
Policy log std Max           0.07370755
Policy log std Min           -2.1513438
Z mean eval                  2.7147038
Z variance eval              0.0016501329
total_rewards                [4521.46664688 4651.37278325 4518.45542763 4540.34341057 4384.72352148
 4702.97861461 4396.67108983 4409.09957424 4438.70551793 4499.38929783]
total_rewards_mean           4506.320588426521
total_rewards_std            101.05906871686011
total_rewards_max            4702.978614612975
total_rewards_min            4384.723521482551
Number of train steps total  52000
Number of env steps total    67000
Number of rollouts total     0
Train Time (s)               113.08734135283157
(Previous) Eval Time (s)     23.623825686983764
Sample Time (s)              16.65791191533208
Epoch Time (s)               153.36907895514742
Total Train Time (s)         1985.2628776109777
Epoch                        12
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:09:24.164278 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #12 | Epoch Duration: 152.99831533432007
2020-01-13 09:09:24.164578 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #12 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.7115176
Z variance train             0.0016508574
KL Divergence                32.58106
KL Loss                      3.258106
QF Loss                      309.4172
VF Loss                      76.3751
Policy Loss                  -1110.5791
Q Predictions Mean           1101.6858
Q Predictions Std            379.7665
Q Predictions Max            1568.3882
Q Predictions Min            251.17603
V Predictions Mean           1112.6033
V Predictions Std            374.62457
V Predictions Max            1571.7175
V Predictions Min            279.4167
Log Pis Mean                 1.6185632
Log Pis Std                  3.6092925
Log Pis Max                  13.179838
Log Pis Min                  -6.642151
Policy mu Mean               -0.03498357
Policy mu Std                1.0610904
Policy mu Max                2.815791
Policy mu Min                -2.8044095
Policy log std Mean          -0.62411326
Policy log std Std           0.2666135
Policy log std Max           0.06598106
Policy log std Min           -2.0132556
Z mean eval                  2.7420263
Z variance eval              0.0067500444
total_rewards                [4829.84128498 4777.30155403 4980.34769529 4911.72796549 4835.58456671
 4790.40215215 4777.06324264 4980.86053923 4727.87854095 4711.68551993]
total_rewards_mean           4832.269306140514
total_rewards_std            91.43141244854081
total_rewards_max            4980.860539225302
total_rewards_min            4711.685519934305
Number of train steps total  56000
Number of env steps total    72000
Number of rollouts total     0
Train Time (s)               114.04235506011173
(Previous) Eval Time (s)     23.252722263801843
Sample Time (s)              16.488664836622775
Epoch Time (s)               153.78374216053635
Total Train Time (s)         2139.5485926074907
Epoch                        13
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:11:58.451311 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #13 | Epoch Duration: 154.2865002155304
2020-01-13 09:11:58.451549 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #13 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.739912
Z variance train             0.0067570573
KL Divergence                32.20735
KL Loss                      3.2207353
QF Loss                      277.75253
VF Loss                      109.95351
Policy Loss                  -1180.1444
Q Predictions Mean           1172.6333
Q Predictions Std            377.4912
Q Predictions Max            1665.2825
Q Predictions Min            263.47418
V Predictions Mean           1182.4663
V Predictions Std            372.4897
V Predictions Max            1669.3057
V Predictions Min            271.10486
Log Pis Mean                 1.6712074
Log Pis Std                  3.5153196
Log Pis Max                  14.243598
Log Pis Min                  -5.511313
Policy mu Mean               -0.0191608
Policy mu Std                1.0503997
Policy mu Max                3.2566047
Policy mu Min                -2.7448692
Policy log std Mean          -0.6630574
Policy log std Std           0.29191297
Policy log std Max           -0.03182903
Policy log std Min           -2.2031786
Z mean eval                  2.797116
Z variance eval              0.0011441263
total_rewards                [4776.07997391 4837.40993692 4790.48368321 4844.30457941 4848.42901444
 4511.63574997 4822.23089606 4850.91222145 4669.70106346 4927.85946321]
total_rewards_mean           4787.904658202808
total_rewards_std            111.56773122386693
total_rewards_max            4927.8594632143795
total_rewards_min            4511.635749968187
Number of train steps total  60000
Number of env steps total    77000
Number of rollouts total     0
Train Time (s)               119.70245715789497
(Previous) Eval Time (s)     23.755166636779904
Sample Time (s)              16.742932680994272
Epoch Time (s)               160.20055647566915
Total Train Time (s)         2299.092315150425
Epoch                        14
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:14:37.994060 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #14 | Epoch Duration: 159.54234147071838
2020-01-13 09:14:37.994242 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #14 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.7966328
Z variance train             0.0011451382
KL Divergence                34.50976
KL Loss                      3.4509761
QF Loss                      319.3932
VF Loss                      108.25875
Policy Loss                  -1284.1654
Q Predictions Mean           1271.8296
Q Predictions Std            406.9619
Q Predictions Max            1763.7352
Q Predictions Min            290.53558
V Predictions Mean           1279.5514
V Predictions Std            398.63605
V Predictions Max            1735.9332
V Predictions Min            303.87286
Log Pis Mean                 1.7169232
Log Pis Std                  3.4634504
Log Pis Max                  10.51613
Log Pis Min                  -6.27448
Policy mu Mean               -0.06740414
Policy mu Std                1.0657493
Policy mu Max                2.9395423
Policy mu Min                -2.4258118
Policy log std Mean          -0.6791744
Policy log std Std           0.29076988
Policy log std Max           -0.06727578
Policy log std Min           -2.2145875
Z mean eval                  2.8211129
Z variance eval              0.0016053161
total_rewards                [5060.64882949 5011.20939317 5190.72917734 5133.87591318 4877.89124733
 5007.98774966 5033.37836722 5219.46539725 4873.95402895 4993.96901193]
total_rewards_mean           5040.310911550746
total_rewards_std            110.46814091657116
total_rewards_max            5219.465397248747
total_rewards_min            4873.954028950604
Number of train steps total  64000
Number of env steps total    82000
Number of rollouts total     0
Train Time (s)               111.22370905894786
(Previous) Eval Time (s)     23.096660749986768
Sample Time (s)              16.351071551907808
Epoch Time (s)               150.67144136084244
Total Train Time (s)         2448.9508382081985
Epoch                        15
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:17:07.854372 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #15 | Epoch Duration: 149.85998702049255
2020-01-13 09:17:07.854576 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #15 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.820313
Z variance train             0.0016056638
KL Divergence                35.075005
KL Loss                      3.5075004
QF Loss                      202.2244
VF Loss                      89.710396
Policy Loss                  -1417.5726
Q Predictions Mean           1418.1172
Q Predictions Std            376.16144
Q Predictions Max            1856.5171
Q Predictions Min            315.29562
V Predictions Mean           1423.6191
V Predictions Std            373.91492
V Predictions Max            1855.6464
V Predictions Min            330.5299
Log Pis Mean                 1.5748811
Log Pis Std                  3.2437508
Log Pis Max                  11.160758
Log Pis Min                  -8.5836735
Policy mu Mean               -0.034556095
Policy mu Std                1.057108
Policy mu Max                2.6295822
Policy mu Min                -2.3100877
Policy log std Mean          -0.6868275
Policy log std Std           0.31457034
Policy log std Max           -0.08496094
Policy log std Min           -2.211728
Z mean eval                  2.8481221
Z variance eval              0.0038331256
total_rewards                [5401.26262185 5325.14903902 5387.00577134 5540.10216867 5045.37190922
 5219.63601419 5212.67487934 5210.33905005 5420.8827668  5352.72651775]
total_rewards_mean           5311.515073821945
total_rewards_std            133.83983173880011
total_rewards_max            5540.102168665793
total_rewards_min            5045.371909219382
Number of train steps total  68000
Number of env steps total    87000
Number of rollouts total     0
Train Time (s)               111.5884022898972
(Previous) Eval Time (s)     22.28490922693163
Sample Time (s)              15.710140312090516
Epoch Time (s)               149.58345182891935
Total Train Time (s)         2599.162675632164
Epoch                        16
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:19:38.069105 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #16 | Epoch Duration: 150.21434235572815
2020-01-13 09:19:38.069395 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #16 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.8469844
Z variance train             0.0038243718
KL Divergence                34.674942
KL Loss                      3.4674942
QF Loss                      297.38394
VF Loss                      215.91458
Policy Loss                  -1458.243
Q Predictions Mean           1455.8086
Q Predictions Std            422.7178
Q Predictions Max            1941.162
Q Predictions Min            324.92392
V Predictions Mean           1464.0363
V Predictions Std            418.83316
V Predictions Max            1949.8694
V Predictions Min            334.8216
Log Pis Mean                 2.446762
Log Pis Std                  3.5659308
Log Pis Max                  12.161009
Log Pis Min                  -4.720646
Policy mu Mean               -0.08471286
Policy mu Std                1.126159
Policy mu Max                2.8908978
Policy mu Min                -2.5600197
Policy log std Mean          -0.6931605
Policy log std Std           0.32368702
Policy log std Max           0.12891808
Policy log std Min           -2.2563326
Z mean eval                  2.8818758
Z variance eval              0.0026495527
total_rewards                [5630.44047328 5710.0333353  5685.39805132 5496.34156822 5457.88471918
 5442.27455103 5263.15888352 5602.00128052 5645.97212858 5684.31994298]
total_rewards_mean           5561.782493394348
total_rewards_std            135.7311236920438
total_rewards_max            5710.033335303184
total_rewards_min            5263.15888352204
Number of train steps total  72000
Number of env steps total    92000
Number of rollouts total     0
Train Time (s)               117.27543929312378
(Previous) Eval Time (s)     22.915520214941353
Sample Time (s)              16.701160674914718
Epoch Time (s)               156.89212018297985
Total Train Time (s)         2755.564176379703
Epoch                        17
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:22:14.470609 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #17 | Epoch Duration: 156.4010009765625
2020-01-13 09:22:14.470810 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #17 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.8797407
Z variance train             0.002636795
KL Divergence                35.40076
KL Loss                      3.540076
QF Loss                      394.84595
VF Loss                      107.99864
Policy Loss                  -1490.662
Q Predictions Mean           1478.1667
Q Predictions Std            446.57587
Q Predictions Max            2000.9332
Q Predictions Min            308.02197
V Predictions Mean           1485.8516
V Predictions Std            439.8023
V Predictions Max            1994.7102
V Predictions Min            320.47308
Log Pis Mean                 2.088828
Log Pis Std                  3.7071812
Log Pis Max                  11.848766
Log Pis Min                  -7.4351015
Policy mu Mean               -0.059160005
Policy mu Std                1.1438326
Policy mu Max                2.8186445
Policy mu Min                -2.516161
Policy log std Mean          -0.69020766
Policy log std Std           0.3306695
Policy log std Max           0.014205158
Policy log std Min           -2.4285939
Z mean eval                  2.917715
Z variance eval              0.0019421529
total_rewards                [5459.22935101 5527.65340491 5618.40329076 5585.80793217 5210.99889393
 5505.54501437 5706.34940788 5469.8108328  5613.82716072 5524.74828755]
total_rewards_mean           5522.237357610262
total_rewards_std            126.2843011103276
total_rewards_max            5706.34940787949
total_rewards_min            5210.9988939322575
Number of train steps total  76000
Number of env steps total    97000
Number of rollouts total     0
Train Time (s)               113.07670788094401
(Previous) Eval Time (s)     22.424121217802167
Sample Time (s)              17.058353883679956
Epoch Time (s)               152.55918298242614
Total Train Time (s)         2908.2026102356613
Epoch                        18
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:24:47.110275 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #18 | Epoch Duration: 152.63929891586304
2020-01-13 09:24:47.110463 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #18 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.9160686
Z variance train             0.0019457698
KL Divergence                36.469597
KL Loss                      3.6469598
QF Loss                      241.86157
VF Loss                      79.32068
Policy Loss                  -1581.4052
Q Predictions Mean           1574.209
Q Predictions Std            457.3825
Q Predictions Max            2105.5989
Q Predictions Min            320.18304
V Predictions Mean           1581.9188
V Predictions Std            452.49344
V Predictions Max            2083.8823
V Predictions Min            338.36664
Log Pis Mean                 2.3831782
Log Pis Std                  4.0377784
Log Pis Max                  13.903695
Log Pis Min                  -7.360607
Policy mu Mean               -0.06594125
Policy mu Std                1.138969
Policy mu Max                2.9808815
Policy mu Min                -2.8465543
Policy log std Mean          -0.68876266
Policy log std Std           0.3248765
Policy log std Max           -0.046847403
Policy log std Min           -2.2528903
Z mean eval                  2.940349
Z variance eval              0.002769644
total_rewards                [6009.40233253 5560.73422756 5694.04482406 5747.59278142 5808.18147802
 5950.90890954 5932.70341041 5642.20144737 5768.15070316 5816.42290386]
total_rewards_mean           5793.034301793239
total_rewards_std            134.6181103970868
total_rewards_max            6009.402332525766
total_rewards_min            5560.734227556114
Number of train steps total  80000
Number of env steps total    102000
Number of rollouts total     0
Train Time (s)               111.17429330013692
(Previous) Eval Time (s)     22.503920347895473
Sample Time (s)              16.30650497134775
Epoch Time (s)               149.98471861938015
Total Train Time (s)         3058.297030130867
Epoch                        19
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:27:17.205439 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #19 | Epoch Duration: 150.09483885765076
2020-01-13 09:27:17.205644 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #19 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.9439838
Z variance train             0.0027667587
KL Divergence                37.455894
KL Loss                      3.7455895
QF Loss                      228.49098
VF Loss                      122.239204
Policy Loss                  -1646.0504
Q Predictions Mean           1641.7869
Q Predictions Std            497.14798
Q Predictions Max            2163.5706
Q Predictions Min            327.13052
V Predictions Mean           1638.9038
V Predictions Std            492.19955
V Predictions Max            2150.087
V Predictions Min            327.13977
Log Pis Mean                 2.4957294
Log Pis Std                  3.6633942
Log Pis Max                  12.3768
Log Pis Min                  -6.0116005
Policy mu Mean               -0.05762024
Policy mu Std                1.1360431
Policy mu Max                3.0090466
Policy mu Min                -2.7219417
Policy log std Mean          -0.7179368
Policy log std Std           0.33895478
Policy log std Max           -0.013176978
Policy log std Min           -2.45106
Z mean eval                  2.9692807
Z variance eval              0.0011275718
total_rewards                [5675.32174667 6157.45527639 6178.41828411 6049.64152087 6076.63221364
 6162.36705137 5983.67659652 6023.80841974 5789.05728174 6173.78497887]
total_rewards_mean           6027.016336992761
total_rewards_std            162.78008829778148
total_rewards_max            6178.41828410955
total_rewards_min            5675.321746668095
Number of train steps total  84000
Number of env steps total    107000
Number of rollouts total     0
Train Time (s)               115.74529556790367
(Previous) Eval Time (s)     22.6137089333497
Sample Time (s)              16.163176532369107
Epoch Time (s)               154.52218103362247
Total Train Time (s)         3213.0762766255066
Epoch                        20
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:29:51.985822 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #20 | Epoch Duration: 154.78002047538757
2020-01-13 09:29:51.986010 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #20 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.969176
Z variance train             0.0011287334
KL Divergence                38.2348
KL Loss                      3.82348
QF Loss                      317.11475
VF Loss                      81.19697
Policy Loss                  -1663.3143
Q Predictions Mean           1658.5007
Q Predictions Std            555.8115
Q Predictions Max            2225.8193
Q Predictions Min            325.46414
V Predictions Mean           1662.9115
V Predictions Std            548.30597
V Predictions Max            2233.9324
V Predictions Min            331.10464
Log Pis Mean                 2.9011493
Log Pis Std                  4.001638
Log Pis Max                  14.142928
Log Pis Min                  -8.72017
Policy mu Mean               -0.11319218
Policy mu Std                1.2046347
Policy mu Max                3.4105055
Policy mu Min                -2.7274957
Policy log std Mean          -0.6980953
Policy log std Std           0.3338756
Policy log std Max           0.026949883
Policy log std Min           -2.4231343
Z mean eval                  2.988315
Z variance eval              0.0027386225
total_rewards                [6224.83859335 6392.45408686 6160.53361561 6153.47824149 6076.30423194
 6337.5455483  6222.04856544 6290.13457468 6281.33686014 6278.56071449]
total_rewards_mean           6241.723503231663
total_rewards_std            89.21107886832847
total_rewards_max            6392.454086862964
total_rewards_min            6076.304231938882
Number of train steps total  88000
Number of env steps total    112000
Number of rollouts total     0
Train Time (s)               109.99875999707729
(Previous) Eval Time (s)     22.871245592366904
Sample Time (s)              16.401175576727837
Epoch Time (s)               149.27118116617203
Total Train Time (s)         3361.9804305890575
Epoch                        21
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:32:20.892771 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #21 | Epoch Duration: 148.90659141540527
2020-01-13 09:32:20.893037 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #21 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.9894419
Z variance train             0.0027386246
KL Divergence                38.362457
KL Loss                      3.8362458
QF Loss                      249.25484
VF Loss                      134.95813
Policy Loss                  -1739.1324
Q Predictions Mean           1733.6099
Q Predictions Std            543.0242
Q Predictions Max            2309.32
Q Predictions Min            342.33463
V Predictions Mean           1733.4324
V Predictions Std            539.1463
V Predictions Max            2295.229
V Predictions Min            352.94913
Log Pis Mean                 2.6848764
Log Pis Std                  3.7291672
Log Pis Max                  18.14968
Log Pis Min                  -7.2351723
Policy mu Mean               -0.07033208
Policy mu Std                1.1679295
Policy mu Max                3.828464
Policy mu Min                -2.8160489
Policy log std Mean          -0.7214196
Policy log std Std           0.36038738
Policy log std Max           0.028285503
Policy log std Min           -2.5503786
Z mean eval                  2.9539514
Z variance eval              0.08424366
total_rewards                [6124.72144014 6166.44681509 6062.84211921 6172.68398601 6063.47621807
 6281.85939884 6061.81344307 6114.69412121 5964.1229179  6124.18249322]
total_rewards_mean           6113.684295274628
total_rewards_std            80.58891470403452
total_rewards_max            6281.859398839102
total_rewards_min            5964.122917896567
Number of train steps total  92000
Number of env steps total    117000
Number of rollouts total     0
Train Time (s)               113.21690152678639
(Previous) Eval Time (s)     22.50635629799217
Sample Time (s)              15.91554286563769
Epoch Time (s)               151.63880069041625
Total Train Time (s)         3513.9074077480473
Epoch                        22
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:34:52.819526 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #22 | Epoch Duration: 151.92630124092102
2020-01-13 09:34:52.819731 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #22 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.9519114
Z variance train             0.08451943
KL Divergence                29.024452
KL Loss                      2.9024453
QF Loss                      322.30908
VF Loss                      141.77266
Policy Loss                  -1793.8896
Q Predictions Mean           1785.5422
Q Predictions Std            505.97632
Q Predictions Max            2311.997
Q Predictions Min            306.95187
V Predictions Mean           1799.751
V Predictions Std            497.20844
V Predictions Max            2317.7751
V Predictions Min            341.41827
Log Pis Mean                 2.6078124
Log Pis Std                  3.570827
Log Pis Max                  15.657003
Log Pis Min                  -4.9596915
Policy mu Mean               -0.14817348
Policy mu Std                1.1791874
Policy mu Max                3.3229613
Policy mu Min                -2.9160545
Policy log std Mean          -0.73899645
Policy log std Std           0.33831137
Policy log std Max           0.079631746
Policy log std Min           -2.2482176
Z mean eval                  3.042209
Z variance eval              0.018703828
total_rewards                [6281.52950396 6572.50585662 6428.85028375 6302.83932931 6479.0937376
 6468.15511002 6408.05078962 6140.46966415 6535.19803049 6615.82094551]
total_rewards_mean           6423.251325103558
total_rewards_std            138.50586968379363
total_rewards_max            6615.820945507521
total_rewards_min            6140.469664151648
Number of train steps total  96000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               103.43383543984964
(Previous) Eval Time (s)     22.793551311362535
Sample Time (s)              16.009874084498733
Epoch Time (s)               142.2372608357109
Total Train Time (s)         3656.1186977513134
Epoch                        23
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:37:15.034601 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #23 | Epoch Duration: 142.21468925476074
2020-01-13 09:37:15.034913 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #23 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0413842
Z variance train             0.018700836
KL Divergence                31.228462
KL Loss                      3.1228464
QF Loss                      328.75262
VF Loss                      282.2074
Policy Loss                  -1845.7037
Q Predictions Mean           1844.1597
Q Predictions Std            490.53848
Q Predictions Max            2357.6265
Q Predictions Min            365.60223
V Predictions Mean           1860.0413
V Predictions Std            486.9452
V Predictions Max            2370.1465
V Predictions Min            381.71353
Log Pis Mean                 3.1822777
Log Pis Std                  3.7566957
Log Pis Max                  15.333656
Log Pis Min                  -5.48773
Policy mu Mean               -0.08381573
Policy mu Std                1.2051256
Policy mu Max                3.4683678
Policy mu Min                -2.933063
Policy log std Mean          -0.7371152
Policy log std Std           0.3377837
Policy log std Max           0.010536134
Policy log std Min           -2.4133408
Z mean eval                  3.0449913
Z variance eval              0.03159382
total_rewards                [6320.79159688 6538.31605925 6621.91666066 6775.00551477 6483.90365186
 6328.21141332 6666.03607571 6638.2549586  6572.27559454 6622.95905594]
total_rewards_mean           6556.767058152896
total_rewards_std            137.34846285592243
total_rewards_max            6775.0055147714465
total_rewards_min            6320.791596883648
Number of train steps total  100000
Number of env steps total    127000
Number of rollouts total     0
Train Time (s)               112.13515253504738
(Previous) Eval Time (s)     22.770693704951555
Sample Time (s)              15.975464770570397
Epoch Time (s)               150.88131101056933
Total Train Time (s)         3807.0504746669903
Epoch                        24
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:39:45.966054 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #24 | Epoch Duration: 150.9309046268463
2020-01-13 09:39:45.966252 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #24 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0450187
Z variance train             0.03152943
KL Divergence                30.33129
KL Loss                      3.033129
QF Loss                      319.3366
VF Loss                      102.69345
Policy Loss                  -1874.3087
Q Predictions Mean           1869.2935
Q Predictions Std            545.30414
Q Predictions Max            2457.0107
Q Predictions Min            369.97144
V Predictions Mean           1875.9172
V Predictions Std            539.393
V Predictions Max            2447.0974
V Predictions Min            383.06656
Log Pis Mean                 3.1827922
Log Pis Std                  3.877088
Log Pis Max                  13.450172
Log Pis Min                  -6.404342
Policy mu Mean               -0.056112263
Policy mu Std                1.2200036
Policy mu Max                3.0835428
Policy mu Min                -2.6336553
Policy log std Mean          -0.7338991
Policy log std Std           0.34896323
Policy log std Max           -0.0017611384
Policy log std Min           -2.4599714
Z mean eval                  3.0978477
Z variance eval              0.010375765
total_rewards                [6514.26922526 6349.57898549 6627.85928174 6775.66759215 6394.09623733
 6602.30954009 6640.13199427 6547.86329115 6654.58739391 6670.24245154]
total_rewards_mean           6577.660599293669
total_rewards_std            123.02418336258613
total_rewards_max            6775.667592146787
total_rewards_min            6349.578985487615
Number of train steps total  104000
Number of env steps total    132000
Number of rollouts total     0
Train Time (s)               109.3278941148892
(Previous) Eval Time (s)     22.820015120320022
Sample Time (s)              16.268717131577432
Epoch Time (s)               148.41662636678666
Total Train Time (s)         3955.6629077317193
Epoch                        25
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:42:14.580355 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #25 | Epoch Duration: 148.6139416694641
2020-01-13 09:42:14.580590 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #25 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0959792
Z variance train             0.010386674
KL Divergence                33.490753
KL Loss                      3.3490753
QF Loss                      313.91376
VF Loss                      117.27118
Policy Loss                  -1967.6648
Q Predictions Mean           1962.053
Q Predictions Std            563.7295
Q Predictions Max            2591.8037
Q Predictions Min            420.00778
V Predictions Mean           1973.2997
V Predictions Std            555.6588
V Predictions Max            2581.79
V Predictions Min            430.21002
Log Pis Mean                 3.5288424
Log Pis Std                  3.5745943
Log Pis Max                  16.510845
Log Pis Min                  -6.253705
Policy mu Mean               -0.13335204
Policy mu Std                1.2451128
Policy mu Max                3.7972045
Policy mu Min                -3.0134785
Policy log std Mean          -0.75542575
Policy log std Std           0.3640507
Policy log std Max           -0.08970368
Policy log std Min           -2.5409417
Z mean eval                  3.1197486
Z variance eval              0.011012407
total_rewards                [6998.95761357 7299.84778709 6974.21290656 7002.05391211 6932.54608741
 7070.2276372  6941.70396779 6789.67594866 7017.44957387 6946.66350944]
total_rewards_mean           6997.3338943697045
total_rewards_std            122.78996200296774
total_rewards_max            7299.847787088058
total_rewards_min            6789.675948664673
Number of train steps total  108000
Number of env steps total    137000
Number of rollouts total     0
Train Time (s)               113.75808065896854
(Previous) Eval Time (s)     23.017017828766257
Sample Time (s)              16.430755404755473
Epoch Time (s)               153.20585389249027
Total Train Time (s)         4109.598257263191
Epoch                        26
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:44:48.516667 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #26 | Epoch Duration: 153.9359142780304
2020-01-13 09:44:48.516837 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #26 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.119968
Z variance train             0.011040112
KL Divergence                34.41523
KL Loss                      3.441523
QF Loss                      298.24823
VF Loss                      120.00716
Policy Loss                  -2094.4985
Q Predictions Mean           2100.7217
Q Predictions Std            508.65637
Q Predictions Max            2677.3867
Q Predictions Min            458.90558
V Predictions Mean           2100.9626
V Predictions Std            506.80188
V Predictions Max            2664.8232
V Predictions Min            452.45297
Log Pis Mean                 3.4195952
Log Pis Std                  3.8282175
Log Pis Max                  15.032516
Log Pis Min                  -7.5870123
Policy mu Mean               -0.09554892
Policy mu Std                1.2330188
Policy mu Max                2.735413
Policy mu Min                -3.0015302
Policy log std Mean          -0.76767236
Policy log std Std           0.38923863
Policy log std Max           0.0569669
Policy log std Min           -2.7215874
Z mean eval                  3.138002
Z variance eval              0.005245619
total_rewards                [7086.4870544  7081.39066741 7161.07525033 7154.2482926  6918.12998156
 7292.37079612 6853.98898416 6969.19030923 7104.99140106 6947.59380023]
total_rewards_mean           7056.946653710748
total_rewards_std            126.34652740656905
total_rewards_max            7292.370796122662
total_rewards_min            6853.98898416198
Number of train steps total  112000
Number of env steps total    142000
Number of rollouts total     0
Train Time (s)               118.68731584306806
(Previous) Eval Time (s)     23.746758680790663
Sample Time (s)              16.230451211333275
Epoch Time (s)               158.664525735192
Total Train Time (s)         4268.079735934269
Epoch                        27
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:47:26.998060 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #27 | Epoch Duration: 158.48108792304993
2020-01-13 09:47:26.998210 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #27 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1368222
Z variance train             0.005248281
KL Divergence                36.296867
KL Loss                      3.6296868
QF Loss                      337.81586
VF Loss                      132.49391
Policy Loss                  -2142.2598
Q Predictions Mean           2134.613
Q Predictions Std            516.9549
Q Predictions Max            2718.0159
Q Predictions Min            449.88455
V Predictions Mean           2137.6316
V Predictions Std            511.67856
V Predictions Max            2708.4187
V Predictions Min            442.40405
Log Pis Mean                 3.7565455
Log Pis Std                  3.7168505
Log Pis Max                  14.932155
Log Pis Min                  -6.8590436
Policy mu Mean               -0.11665151
Policy mu Std                1.2618433
Policy mu Max                2.9458475
Policy mu Min                -2.9971943
Policy log std Mean          -0.767945
Policy log std Std           0.37567616
Policy log std Max           -0.002103746
Policy log std Min           -2.584892
Z mean eval                  3.1650262
Z variance eval              0.0031769506
total_rewards                [7064.47194903 7350.06590917 7182.63375402 6892.11867367 7263.09074259
 7142.57086257 7172.11452588 7059.13766016 7101.76418664 6978.18639507]
total_rewards_mean           7120.61546588001
total_rewards_std            126.376810039707
total_rewards_max            7350.0659091671105
total_rewards_min            6892.11867366846
Number of train steps total  116000
Number of env steps total    147000
Number of rollouts total     0
Train Time (s)               113.61160814296454
(Previous) Eval Time (s)     23.563013947103173
Sample Time (s)              15.597603441681713
Epoch Time (s)               152.77222553174943
Total Train Time (s)         4420.032246865332
Epoch                        28
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:49:58.952745 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #28 | Epoch Duration: 151.95440912246704
2020-01-13 09:49:58.952938 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #28 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1648839
Z variance train             0.0031827814
KL Divergence                37.990612
KL Loss                      3.7990613
QF Loss                      264.81915
VF Loss                      94.37902
Policy Loss                  -2181.8354
Q Predictions Mean           2179.369
Q Predictions Std            540.3334
Q Predictions Max            2786.5535
Q Predictions Min            461.0005
V Predictions Mean           2186.4014
V Predictions Std            536.5416
V Predictions Max            2777.6338
V Predictions Min            465.4641
Log Pis Mean                 3.4995375
Log Pis Std                  3.5485554
Log Pis Max                  12.639671
Log Pis Min                  -3.554503
Policy mu Mean               -0.092625745
Policy mu Std                1.239193
Policy mu Max                3.5280297
Policy mu Min                -2.7334669
Policy log std Mean          -0.7682218
Policy log std Std           0.36670858
Policy log std Max           0.07655299
Policy log std Min           -2.6776989
Z mean eval                  3.171751
Z variance eval              0.0034182905
total_rewards                [6939.00743367 7018.85740678 7048.15924338 7190.41991761 7271.46392484
 6928.4843015  7162.66885805 6928.07413586 7342.57355923 7098.52551281]
total_rewards_mean           7092.823429371788
total_rewards_std            139.28331822932014
total_rewards_max            7342.573559229656
total_rewards_min            6928.07413585968
Number of train steps total  120000
Number of env steps total    152000
Number of rollouts total     0
Train Time (s)               105.83528647013009
(Previous) Eval Time (s)     22.744908796157688
Sample Time (s)              16.23722716839984
Epoch Time (s)               144.81742243468761
Total Train Time (s)         4564.409557573963
Epoch                        29
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:52:23.331545 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #29 | Epoch Duration: 144.37844896316528
2020-01-13 09:52:23.331776 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #29 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1731377
Z variance train             0.0034124055
KL Divergence                37.942543
KL Loss                      3.7942543
QF Loss                      240.16031
VF Loss                      59.312298
Policy Loss                  -2353.39
Q Predictions Mean           2354.2754
Q Predictions Std            468.65674
Q Predictions Max            2873.732
Q Predictions Min            478.0843
V Predictions Mean           2352.862
V Predictions Std            461.843
V Predictions Max            2861.9373
V Predictions Min            480.8297
Log Pis Mean                 3.6735225
Log Pis Std                  3.7696393
Log Pis Max                  13.114738
Log Pis Min                  -5.808177
Policy mu Mean               -0.15164824
Policy mu Std                1.2340255
Policy mu Max                3.2241673
Policy mu Min                -2.8932629
Policy log std Mean          -0.782768
Policy log std Std           0.375822
Policy log std Max           0.046737254
Policy log std Min           -2.4567404
Z mean eval                  3.1851358
Z variance eval              0.0032878376
total_rewards                [6796.59993614 6982.75199807 7137.94517552 7261.28233074 7172.30741878
 7029.62292924 7150.37807389 7459.10554291 7265.87693138 7113.45171165]
total_rewards_mean           7136.932204831208
total_rewards_std            169.99493604470894
total_rewards_max            7459.10554290928
total_rewards_min            6796.599936143459
Number of train steps total  124000
Number of env steps total    157000
Number of rollouts total     0
Train Time (s)               114.98555279709399
(Previous) Eval Time (s)     22.305622912943363
Sample Time (s)              15.738180537708104
Epoch Time (s)               153.02935624774545
Total Train Time (s)         4718.218229218852
Epoch                        30
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:54:57.140258 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #30 | Epoch Duration: 153.80829644203186
2020-01-13 09:54:57.140418 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #30 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1837573
Z variance train             0.0033002086
KL Divergence                38.50068
KL Loss                      3.8500679
QF Loss                      319.10583
VF Loss                      97.690346
Policy Loss                  -2323.2732
Q Predictions Mean           2317.8447
Q Predictions Std            544.64435
Q Predictions Max            2877.9702
Q Predictions Min            469.93683
V Predictions Mean           2320.6501
V Predictions Std            538.3944
V Predictions Max            2873.734
V Predictions Min            486.0086
Log Pis Mean                 3.5044463
Log Pis Std                  3.702463
Log Pis Max                  16.747555
Log Pis Min                  -7.005639
Policy mu Mean               -0.16627897
Policy mu Std                1.2368861
Policy mu Max                3.1910024
Policy mu Min                -2.910042
Policy log std Mean          -0.7732821
Policy log std Std           0.38434404
Policy log std Max           0.0045577884
Policy log std Min           -2.858089
Z mean eval                  3.1917021
Z variance eval              0.0054233223
total_rewards                [7340.29896853 7463.88560241 7446.71894359 7407.25705757 7546.50857505
 7407.51868991 7389.19054118 7383.77415311 7528.92135898 7386.55310704]
total_rewards_mean           7430.0626997379495
total_rewards_std            62.88576967328193
total_rewards_max            7546.508575052863
total_rewards_min            7340.298968531366
Number of train steps total  128000
Number of env steps total    162000
Number of rollouts total     0
Train Time (s)               118.8573523205705
(Previous) Eval Time (s)     23.084302621893585
Sample Time (s)              16.50225146720186
Epoch Time (s)               158.44390640966594
Total Train Time (s)         4876.235287742224
Epoch                        31
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:57:35.161802 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #31 | Epoch Duration: 158.0212185382843
2020-01-13 09:57:35.162094 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #31 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1935148
Z variance train             0.0053993515
KL Divergence                38.13127
KL Loss                      3.8131273
QF Loss                      276.1515
VF Loss                      105.253525
Policy Loss                  -2386.6797
Q Predictions Mean           2380.0527
Q Predictions Std            556.02826
Q Predictions Max            2982.3079
Q Predictions Min            504.03012
V Predictions Mean           2383.1553
V Predictions Std            552.7618
V Predictions Max            2982.5928
V Predictions Min            510.45547
Log Pis Mean                 4.6658983
Log Pis Std                  3.6191392
Log Pis Max                  14.3168125
Log Pis Min                  -3.5530653
Policy mu Mean               -0.130216
Policy mu Std                1.3404944
Policy mu Max                3.1936414
Policy mu Min                -3.302917
Policy log std Mean          -0.7915986
Policy log std Std           0.3858633
Policy log std Max           0.056728423
Policy log std Min           -2.7590108
Z mean eval                  3.2083638
Z variance eval              0.023823222
total_rewards                [7233.45053471 7530.38822644 7264.8425543  7299.21001263 7444.49239554
 7414.23581894 7398.97093193 7304.07329169 7159.08742589 7533.39916996]
total_rewards_mean           7358.2150362032
total_rewards_std            119.55148252229996
total_rewards_max            7533.3991699614635
total_rewards_min            7159.087425885804
Number of train steps total  132000
Number of env steps total    167000
Number of rollouts total     0
Train Time (s)               110.49742769310251
(Previous) Eval Time (s)     22.661297048907727
Sample Time (s)              16.454112232197076
Epoch Time (s)               149.6128369742073
Total Train Time (s)         5026.059207947925
Epoch                        32
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:00:04.986218 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #32 | Epoch Duration: 149.82388639450073
2020-01-13 10:00:04.986462 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #32 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2074342
Z variance train             0.024002941
KL Divergence                36.98029
KL Loss                      3.698029
QF Loss                      269.84805
VF Loss                      99.80007
Policy Loss                  -2383.254
Q Predictions Mean           2380.0378
Q Predictions Std            532.7151
Q Predictions Max            2952.7307
Q Predictions Min            519.86554
V Predictions Mean           2386.915
V Predictions Std            530.6114
V Predictions Max            2957.702
V Predictions Min            518.83185
Log Pis Mean                 3.6713288
Log Pis Std                  3.7784016
Log Pis Max                  12.557894
Log Pis Min                  -6.599111
Policy mu Mean               -0.11337825
Policy mu Std                1.2454667
Policy mu Max                2.8287365
Policy mu Min                -2.7624109
Policy log std Mean          -0.81247115
Policy log std Std           0.39085054
Policy log std Max           0.056197107
Policy log std Min           -2.7375894
Z mean eval                  3.2466874
Z variance eval              0.0039565274
total_rewards                [7119.07493257 7215.75730943 7239.89277708 7325.95222357 7236.71646599
 7340.68625732 7331.26872127 7321.38505567 7380.34054994 7267.28257793]
total_rewards_mean           7277.83568707654
total_rewards_std            73.36538955097811
total_rewards_max            7380.340549938624
total_rewards_min            7119.074932569856
Number of train steps total  136000
Number of env steps total    172000
Number of rollouts total     0
Train Time (s)               108.5492239492014
(Previous) Eval Time (s)     22.872059975750744
Sample Time (s)              15.707033664453775
Epoch Time (s)               147.12831758940592
Total Train Time (s)         5173.021993022412
Epoch                        33
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:02:31.950751 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #33 | Epoch Duration: 146.96407270431519
2020-01-13 10:02:31.951063 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #33 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2458744
Z variance train             0.003942961
KL Divergence                39.39332
KL Loss                      3.9393318
QF Loss                      312.54797
VF Loss                      130.45743
Policy Loss                  -2400.5461
Q Predictions Mean           2404.361
Q Predictions Std            564.9825
Q Predictions Max            3011.356
Q Predictions Min            555.31085
V Predictions Mean           2406.7021
V Predictions Std            556.9794
V Predictions Max            3013.002
V Predictions Min            574.6645
Log Pis Mean                 3.970552
Log Pis Std                  4.115163
Log Pis Max                  14.017586
Log Pis Min                  -5.6731997
Policy mu Mean               -0.08137108
Policy mu Std                1.2971243
Policy mu Max                3.7602806
Policy mu Min                -2.8274157
Policy log std Mean          -0.7920275
Policy log std Std           0.38798356
Policy log std Max           -0.060623407
Policy log std Min           -2.6855347
Z mean eval                  3.2524788
Z variance eval              0.0014559032
total_rewards                [7432.08240691 7347.68414492 7383.47009902 7325.06762953 7379.18002547
 7377.31502861 7356.52482187 5567.21703529 7336.86683767 7224.20167029]
total_rewards_mean           7172.960969957263
total_rewards_std            537.6810886285775
total_rewards_max            7432.082406910196
total_rewards_min            5567.2170352923185
Number of train steps total  140000
Number of env steps total    177000
Number of rollouts total     0
Train Time (s)               111.37160664005205
(Previous) Eval Time (s)     22.70751447370276
Sample Time (s)              16.023662752471864
Epoch Time (s)               150.10278386622667
Total Train Time (s)         5323.654938242398
Epoch                        34
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:05:02.586218 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #34 | Epoch Duration: 150.6348967552185
2020-01-13 10:05:02.586558 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #34 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.252105
Z variance train             0.0014514329
KL Divergence                41.85645
KL Loss                      4.185645
QF Loss                      225.03087
VF Loss                      79.62462
Policy Loss                  -2435.99
Q Predictions Mean           2432.5156
Q Predictions Std            568.7672
Q Predictions Max            3070.2576
Q Predictions Min            562.4124
V Predictions Mean           2432.3354
V Predictions Std            564.71967
V Predictions Max            3051.8987
V Predictions Min            563.5528
Log Pis Mean                 4.26917
Log Pis Std                  3.6459374
Log Pis Max                  12.732267
Log Pis Min                  -4.8419333
Policy mu Mean               -0.16571733
Policy mu Std                1.2632477
Policy mu Max                2.706558
Policy mu Min                -2.8591983
Policy log std Mean          -0.8120008
Policy log std Std           0.39650744
Policy log std Max           -0.01801759
Policy log std Min           -2.8218884
Z mean eval                  3.2722468
Z variance eval              0.0008889494
total_rewards                [7626.87659781 7829.04177391 7786.24353883 7913.84202656 7821.40841684
 7981.11862239 7766.93962981 7669.790862   7974.60256405 7618.60161263]
total_rewards_mean           7798.846564482694
total_rewards_std            125.9572125022765
total_rewards_max            7981.118622386927
total_rewards_min            7618.601612629597
Number of train steps total  144000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               115.82510420214385
(Previous) Eval Time (s)     23.239352982025594
Sample Time (s)              16.61785670556128
Epoch Time (s)               155.68231388973072
Total Train Time (s)         5478.49353460595
Epoch                        35
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:07:37.427424 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #35 | Epoch Duration: 154.84060740470886
2020-01-13 10:07:37.427718 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #35 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2729602
Z variance train             0.0008885636
KL Divergence                43.859993
KL Loss                      4.385999
QF Loss                      275.37384
VF Loss                      92.555244
Policy Loss                  -2522.5645
Q Predictions Mean           2516.771
Q Predictions Std            536.1308
Q Predictions Max            3107.4553
Q Predictions Min            562.6873
V Predictions Mean           2519.8452
V Predictions Std            529.8595
V Predictions Max            3090.1125
V Predictions Min            564.11816
Log Pis Mean                 4.216957
Log Pis Std                  3.598841
Log Pis Max                  13.91431
Log Pis Min                  -5.262604
Policy mu Mean               -0.10188543
Policy mu Std                1.2748665
Policy mu Max                2.8295007
Policy mu Min                -3.1415043
Policy log std Mean          -0.8129587
Policy log std Std           0.39117825
Policy log std Max           -0.10594213
Policy log std Min           -2.7573833
Z mean eval                  3.2628403
Z variance eval              0.0026333944
total_rewards                [7680.17186335 7821.71749621 7951.29767076 7573.14086621 7744.47119744
 7914.96591609 7957.9093202  7791.50093958 7936.62739548 7906.80029575]
total_rewards_mean           7827.860296107389
total_rewards_std            123.61475167670281
total_rewards_max            7957.909320203666
total_rewards_min            7573.140866210304
Number of train steps total  148000
Number of env steps total    187000
Number of rollouts total     0
Train Time (s)               112.08577079931274
(Previous) Eval Time (s)     22.397369297221303
Sample Time (s)              16.63449606159702
Epoch Time (s)               151.11763615813106
Total Train Time (s)         5629.808386695106
Epoch                        36
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:10:08.740472 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #36 | Epoch Duration: 151.31252217292786
2020-01-13 10:10:08.740624 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #36 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2644134
Z variance train             0.0026337346
KL Divergence                41.834892
KL Loss                      4.1834893
QF Loss                      246.87808
VF Loss                      83.2568
Policy Loss                  -2438.8833
Q Predictions Mean           2436.7222
Q Predictions Std            628.5491
Q Predictions Max            3134.4246
Q Predictions Min            562.56854
V Predictions Mean           2437.1099
V Predictions Std            623.6246
V Predictions Max            3126.4302
V Predictions Min            564.8039
Log Pis Mean                 4.2411547
Log Pis Std                  3.5655096
Log Pis Max                  15.121959
Log Pis Min                  -5.3818026
Policy mu Mean               -0.079339184
Policy mu Std                1.2893251
Policy mu Max                2.847384
Policy mu Min                -3.1441557
Policy log std Mean          -0.7875125
Policy log std Std           0.38894248
Policy log std Max           -0.091073245
Policy log std Min           -2.5379133
Z mean eval                  3.2516618
Z variance eval              0.0070478455
total_rewards                [7659.49621673 7838.58038189 7732.98474121 7770.65597086 7780.85475792
 7752.14985215 7689.65945823 7868.35691052 7629.96622407 7766.76790576]
total_rewards_mean           7748.947241933616
total_rewards_std            70.73738137507854
total_rewards_max            7868.356910516362
total_rewards_min            7629.966224069741
Number of train steps total  152000
Number of env steps total    192000
Number of rollouts total     0
Train Time (s)               107.52866009902209
(Previous) Eval Time (s)     22.591964362654835
Sample Time (s)              16.18418791424483
Epoch Time (s)               146.30481237592176
Total Train Time (s)         5775.943606174085
Epoch                        37
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:12:34.881235 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #37 | Epoch Duration: 146.14046382904053
2020-01-13 10:12:34.881492 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #37 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.252689
Z variance train             0.0070269457
KL Divergence                39.359535
KL Loss                      3.9359536
QF Loss                      372.65662
VF Loss                      201.1003
Policy Loss                  -2491.4424
Q Predictions Mean           2490.8
Q Predictions Std            561.065
Q Predictions Max            3083.9011
Q Predictions Min            544.3504
V Predictions Mean           2484.2397
V Predictions Std            554.63135
V Predictions Max            3069.6099
V Predictions Min            548.47784
Log Pis Mean                 3.986986
Log Pis Std                  3.5796604
Log Pis Max                  14.401946
Log Pis Min                  -6.4550753
Policy mu Mean               -0.13467772
Policy mu Std                1.263739
Policy mu Max                2.93953
Policy mu Min                -3.0061865
Policy log std Mean          -0.8261669
Policy log std Std           0.41027817
Policy log std Max           -0.08330649
Policy log std Min           -2.7997646
Z mean eval                  3.2669883
Z variance eval              0.007134106
total_rewards                [7056.93876073 7404.26624995 7252.79043726 7250.79201889 7355.70791967
 7297.68773933 7308.24786282 7090.76103556 7120.29961246 7432.29412812]
total_rewards_mean           7256.978576480889
total_rewards_std            123.62993661721326
total_rewards_max            7432.294128124578
total_rewards_min            7056.938760725487
Number of train steps total  156000
Number of env steps total    197000
Number of rollouts total     0
Train Time (s)               112.74878424592316
(Previous) Eval Time (s)     22.42730404390022
Sample Time (s)              15.79826170252636
Epoch Time (s)               150.97434999234974
Total Train Time (s)         5926.688570137136
Epoch                        38
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:15:05.625866 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #38 | Epoch Duration: 150.74416160583496
2020-01-13 10:15:05.626152 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #38 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2633736
Z variance train             0.0071567283
KL Divergence                40.273506
KL Loss                      4.027351
QF Loss                      297.54376
VF Loss                      127.35591
Policy Loss                  -2530.9988
Q Predictions Mean           2537.3687
Q Predictions Std            621.8495
Q Predictions Max            3164.2102
Q Predictions Min            536.39496
V Predictions Mean           2537.3887
V Predictions Std            617.1577
V Predictions Max            3145.5945
V Predictions Min            533.92615
Log Pis Mean                 4.421155
Log Pis Std                  3.8949006
Log Pis Max                  13.522505
Log Pis Min                  -7.3839407
Policy mu Mean               -0.0388993
Policy mu Std                1.3055217
Policy mu Max                3.195201
Policy mu Min                -3.0798154
Policy log std Mean          -0.83579254
Policy log std Std           0.422939
Policy log std Max           -0.040403724
Policy log std Min           -2.8362622
Z mean eval                  3.2592492
Z variance eval              0.007316211
total_rewards                [7950.34933874 8049.62178836 8122.72752759 7990.84855636 8097.08144685
 7949.85011934 7813.88966469 7831.81837174 8046.53752408 8075.99113574]
total_rewards_mean           7992.871547348566
total_rewards_std            101.17681815701005
total_rewards_max            8122.727527586499
total_rewards_min            7813.889664693732
Number of train steps total  160000
Number of env steps total    202000
Number of rollouts total     0
Train Time (s)               108.99941162765026
(Previous) Eval Time (s)     22.196851865388453
Sample Time (s)              16.033152877818793
Epoch Time (s)               147.2294163708575
Total Train Time (s)         6074.327276316937
Epoch                        39
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:17:33.263933 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #39 | Epoch Duration: 147.63758778572083
2020-01-13 10:17:33.264090 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #39 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2594867
Z variance train             0.007348848
KL Divergence                40.42154
KL Loss                      4.042154
QF Loss                      283.6314
VF Loss                      102.66615
Policy Loss                  -2642.791
Q Predictions Mean           2649.2358
Q Predictions Std            581.96234
Q Predictions Max            3214.6921
Q Predictions Min            577.0834
V Predictions Mean           2643.8372
V Predictions Std            576.69
V Predictions Max            3205.7747
V Predictions Min            572.27783
Log Pis Mean                 4.388714
Log Pis Std                  3.72216
Log Pis Max                  15.572067
Log Pis Min                  -5.507752
Policy mu Mean               -0.12496835
Policy mu Std                1.2933022
Policy mu Max                2.768247
Policy mu Min                -2.9239864
Policy log std Mean          -0.81068754
Policy log std Std           0.40267438
Policy log std Max           -0.03238046
Policy log std Min           -2.961543
Z mean eval                  3.275206
Z variance eval              0.0014054778
total_rewards                [7866.25786102 8071.45765817 8123.40904408 7949.82580103 8217.67088092
 7987.9597229  3721.38103296 8119.77787919 8126.38680678 7964.78297308]
total_rewards_mean           7614.8909660131685
total_rewards_std            1301.6649787306335
total_rewards_max            8217.67088091871
total_rewards_min            3721.381032957035
Number of train steps total  164000
Number of env steps total    207000
Number of rollouts total     0
Train Time (s)               113.82941151410341
(Previous) Eval Time (s)     22.60472722304985
Sample Time (s)              15.426336812786758
Epoch Time (s)               151.86047554994002
Total Train Time (s)         6225.82677037688
Epoch                        40
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:20:04.766208 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #40 | Epoch Duration: 151.50195693969727
2020-01-13 10:20:04.766479 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #40 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2759678
Z variance train             0.001402097
KL Divergence                41.699413
KL Loss                      4.1699414
QF Loss                      262.65265
VF Loss                      81.54721
Policy Loss                  -2624.9194
Q Predictions Mean           2618.9678
Q Predictions Std            578.1961
Q Predictions Max            3271.6545
Q Predictions Min            583.3449
V Predictions Mean           2621.4646
V Predictions Std            569.78076
V Predictions Max            3260.4724
V Predictions Min            605.1135
Log Pis Mean                 4.2593327
Log Pis Std                  3.7599063
Log Pis Max                  14.00721
Log Pis Min                  -5.6853733
Policy mu Mean               -0.11603552
Policy mu Std                1.2788048
Policy mu Max                3.1676202
Policy mu Min                -2.8319674
Policy log std Mean          -0.81739014
Policy log std Std           0.39592898
Policy log std Max           -0.015721738
Policy log std Min           -2.7662537
Z mean eval                  3.2687817
Z variance eval              0.013612034
total_rewards                [8017.40332873 8079.91287116 8113.55274143 8170.82935132 8158.50233879
 8139.34436179 8114.67235711 8144.44754627 8089.43696382 8118.13173076]
total_rewards_mean           8114.623359119156
total_rewards_std            42.295924879723984
total_rewards_max            8170.829351321027
total_rewards_min            8017.403328734833
Number of train steps total  168000
Number of env steps total    212000
Number of rollouts total     0
Train Time (s)               112.48869409179315
(Previous) Eval Time (s)     22.245930220000446
Sample Time (s)              15.57358914334327
Epoch Time (s)               150.30821345513687
Total Train Time (s)         6376.5298605659045
Epoch                        41
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:22:35.469214 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #41 | Epoch Duration: 150.702561378479
2020-01-13 10:22:35.469377 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #41 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2678552
Z variance train             0.013593426
KL Divergence                40.273632
KL Loss                      4.0273633
QF Loss                      297.88522
VF Loss                      100.88108
Policy Loss                  -2637.6648
Q Predictions Mean           2632.3794
Q Predictions Std            543.8698
Q Predictions Max            3273.7314
Q Predictions Min            613.3795
V Predictions Mean           2642.9238
V Predictions Std            538.5504
V Predictions Max            3282.177
V Predictions Min            625.63983
Log Pis Mean                 4.2786226
Log Pis Std                  3.9566438
Log Pis Max                  15.9796505
Log Pis Min                  -5.415206
Policy mu Mean               -0.114359595
Policy mu Std                1.325019
Policy mu Max                3.7539551
Policy mu Min                -2.9495163
Policy log std Mean          -0.8030796
Policy log std Std           0.3873152
Policy log std Max           -0.106573105
Policy log std Min           -2.9461582
Z mean eval                  3.2774024
Z variance eval              0.004323948
total_rewards                [7988.92497893 8044.23840003 7915.97798388 7881.50969931 8062.38442546
 7929.42113672 7927.93240753 7884.28392499 7973.37840178 8045.53300736]
total_rewards_mean           7965.358436598186
total_rewards_std            64.35687077833549
total_rewards_max            8062.384425461413
total_rewards_min            7881.509699310257
Number of train steps total  172000
Number of env steps total    217000
Number of rollouts total     0
Train Time (s)               112.8515988541767
(Previous) Eval Time (s)     22.640018092934042
Sample Time (s)              15.822918137069792
Epoch Time (s)               151.31453508418053
Total Train Time (s)         6527.873559247237
Epoch                        42
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:25:06.814257 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #42 | Epoch Duration: 151.34474349021912
2020-01-13 10:25:06.814476 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #42 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.277998
Z variance train             0.004321971
KL Divergence                40.61319
KL Loss                      4.061319
QF Loss                      247.28549
VF Loss                      95.08162
Policy Loss                  -2675.138
Q Predictions Mean           2674.6877
Q Predictions Std            518.0661
Q Predictions Max            3326.1003
Q Predictions Min            622.59174
V Predictions Mean           2679.1897
V Predictions Std            510.8533
V Predictions Max            3327.1736
V Predictions Min            654.49756
Log Pis Mean                 4.2793775
Log Pis Std                  3.6607244
Log Pis Max                  15.753781
Log Pis Min                  -6.7007074
Policy mu Mean               -0.14734763
Policy mu Std                1.2678721
Policy mu Max                2.8925505
Policy mu Min                -3.006705
Policy log std Mean          -0.83604354
Policy log std Std           0.40918377
Policy log std Max           0.045684397
Policy log std Min           -2.8320613
Z mean eval                  3.2794197
Z variance eval              0.0025780434
total_rewards                [8321.94515978 8203.32296498 8243.98378035 8067.09058542 8158.13552074
 8085.89944263 8326.21252707 8285.47620152 8297.76605781 7451.43309665]
total_rewards_mean           8144.126533696671
total_rewards_std            247.22068538418984
total_rewards_max            8326.2125270703
total_rewards_min            7451.4330966532
Number of train steps total  176000
Number of env steps total    222000
Number of rollouts total     0
Train Time (s)               110.94627068471164
(Previous) Eval Time (s)     22.669916834682226
Sample Time (s)              16.149535922333598
Epoch Time (s)               149.76572344172746
Total Train Time (s)         6677.511515446473
Epoch                        43
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:27:36.453221 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #43 | Epoch Duration: 149.63860535621643
2020-01-13 10:27:36.453467 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #43 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2784653
Z variance train             0.002591059
KL Divergence                41.056927
KL Loss                      4.105693
QF Loss                      428.49786
VF Loss                      188.55945
Policy Loss                  -2703.4553
Q Predictions Mean           2708.681
Q Predictions Std            600.4626
Q Predictions Max            3360.4062
Q Predictions Min            620.23047
V Predictions Mean           2713.6343
V Predictions Std            590.65466
V Predictions Max            3359.5032
V Predictions Min            649.89233
Log Pis Mean                 4.5348387
Log Pis Std                  3.7086837
Log Pis Max                  13.923839
Log Pis Min                  -6.4255023
Policy mu Mean               -0.1217821
Policy mu Std                1.3342977
Policy mu Max                2.9470243
Policy mu Min                -2.8406577
Policy log std Mean          -0.8334504
Policy log std Std           0.40099657
Policy log std Max           -0.09749138
Policy log std Min           -2.924186
Z mean eval                  3.2772796
Z variance eval              0.0034359847
total_rewards                [8221.01385677 8217.58956144 8272.01080103 8336.68148742 8284.55859286
 8340.71811463 8328.1888013  7998.97435307 8286.83764543 8319.17876257]
total_rewards_mean           8260.575197652344
total_rewards_std            96.6770865491259
total_rewards_max            8340.718114630363
total_rewards_min            7998.974353069143
Number of train steps total  180000
Number of env steps total    227000
Number of rollouts total     0
Train Time (s)               113.63978690793738
(Previous) Eval Time (s)     22.542499942239374
Sample Time (s)              16.10921859368682
Epoch Time (s)               152.29150544386357
Total Train Time (s)         6830.2657737648115
Epoch                        44
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:30:09.211658 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #44 | Epoch Duration: 152.75800395011902
2020-01-13 10:30:09.212016 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #44 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2775314
Z variance train             0.0034342103
KL Divergence                39.81651
KL Loss                      3.981651
QF Loss                      226.94037
VF Loss                      103.62396
Policy Loss                  -2752.8713
Q Predictions Mean           2749.134
Q Predictions Std            535.0276
Q Predictions Max            3351.7676
Q Predictions Min            651.8461
V Predictions Mean           2748.1062
V Predictions Std            528.3425
V Predictions Max            3338.487
V Predictions Min            668.83716
Log Pis Mean                 4.1895876
Log Pis Std                  3.642643
Log Pis Max                  15.342759
Log Pis Min                  -5.272438
Policy mu Mean               -0.15206023
Policy mu Std                1.2781668
Policy mu Max                2.9518783
Policy mu Min                -3.0045335
Policy log std Mean          -0.8397839
Policy log std Std           0.41047806
Policy log std Max           0.0008351207
Policy log std Min           -2.8051174
Z mean eval                  3.2644043
Z variance eval              0.010223319
total_rewards                [8110.88352964 8182.68847154 8114.96199384 8185.60600188 8247.39502799
 8178.87920352 8093.90022124 8106.03709018 8044.69921966 8263.36376935]
total_rewards_mean           8152.841452884818
total_rewards_std            66.59779737839847
total_rewards_max            8263.363769346104
total_rewards_min            8044.699219659347
Number of train steps total  184000
Number of env steps total    232000
Number of rollouts total     0
Train Time (s)               117.03577816905454
(Previous) Eval Time (s)     23.008687490131706
Sample Time (s)              16.14441252592951
Epoch Time (s)               156.18887818511575
Total Train Time (s)         6986.818406602833
Epoch                        45
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:32:45.765289 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #45 | Epoch Duration: 156.55302143096924
2020-01-13 10:32:45.765534 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #45 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2656531
Z variance train             0.0102309985
KL Divergence                36.918793
KL Loss                      3.6918793
QF Loss                      310.83057
VF Loss                      236.1654
Policy Loss                  -2754.4517
Q Predictions Mean           2747.4875
Q Predictions Std            606.1836
Q Predictions Max            3390.4956
Q Predictions Min            656.08136
V Predictions Mean           2742.1174
V Predictions Std            600.0941
V Predictions Max            3367.018
V Predictions Min            657.7748
Log Pis Mean                 4.3346806
Log Pis Std                  3.549055
Log Pis Max                  13.777702
Log Pis Min                  -4.982573
Policy mu Mean               -0.13318892
Policy mu Std                1.3068118
Policy mu Max                2.8834462
Policy mu Min                -3.1333675
Policy log std Mean          -0.8195429
Policy log std Std           0.39637005
Policy log std Max           -0.14314122
Policy log std Min           -2.9261463
Z mean eval                  3.2703195
Z variance eval              0.012431434
total_rewards                [8122.44218864 8419.51279079 8168.99827429 8475.24020314 8447.48445715
 8500.92983748 8382.16282512 8490.62190239 8283.31169493 8154.56113978]
total_rewards_mean           8344.526531370087
total_rewards_std            141.59710812370116
total_rewards_max            8500.92983747677
total_rewards_min            8122.442188642577
Number of train steps total  188000
Number of env steps total    237000
Number of rollouts total     0
Train Time (s)               111.91133831301704
(Previous) Eval Time (s)     23.372553561348468
Sample Time (s)              16.167460537981242
Epoch Time (s)               151.45135241234675
Total Train Time (s)         7137.879575183149
Epoch                        46
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:35:16.827372 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #46 | Epoch Duration: 151.06165194511414
2020-01-13 10:35:16.827588 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #46 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2709148
Z variance train             0.012401179
KL Divergence                36.028362
KL Loss                      3.6028364
QF Loss                      182.80072
VF Loss                      84.22084
Policy Loss                  -2716.0713
Q Predictions Mean           2707.1597
Q Predictions Std            698.3343
Q Predictions Max            3444.974
Q Predictions Min            676.39307
V Predictions Mean           2711.6313
V Predictions Std            693.84106
V Predictions Max            3433.3804
V Predictions Min            685.4899
Log Pis Mean                 4.200343
Log Pis Std                  3.6727178
Log Pis Max                  15.96492
Log Pis Min                  -4.5855417
Policy mu Mean               -0.072491236
Policy mu Std                1.3099964
Policy mu Max                2.8813977
Policy mu Min                -2.748857
Policy log std Mean          -0.80670166
Policy log std Std           0.40859404
Policy log std Max           -0.044902682
Policy log std Min           -2.859765
Z mean eval                  3.2772942
Z variance eval              0.013337931
total_rewards                [8264.72903199 8220.11366153 8334.07641756 8399.99174442 8152.46015801
 7898.196795   8286.63585981 8053.4455427  8274.57335204 8175.26907229]
total_rewards_mean           8205.949163535106
total_rewards_std            138.0998410517464
total_rewards_max            8399.991744424715
total_rewards_min            7898.196794998898
Number of train steps total  192000
Number of env steps total    242000
Number of rollouts total     0
Train Time (s)               110.42040917510167
(Previous) Eval Time (s)     22.982543678954244
Sample Time (s)              16.34632107988
Epoch Time (s)               149.7492739339359
Total Train Time (s)         7287.177411741577
Epoch                        47
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:37:46.126121 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #47 | Epoch Duration: 149.29837775230408
2020-01-13 10:37:46.126333 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #47 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.277909
Z variance train             0.013304266
KL Divergence                38.225212
KL Loss                      3.8225212
QF Loss                      272.47015
VF Loss                      140.18935
Policy Loss                  -2871.8406
Q Predictions Mean           2879.474
Q Predictions Std            525.3661
Q Predictions Max            3476.3843
Q Predictions Min            707.2932
V Predictions Mean           2871.6304
V Predictions Std            518.63684
V Predictions Max            3457.1882
V Predictions Min            710.51184
Log Pis Mean                 4.168808
Log Pis Std                  3.643279
Log Pis Max                  14.860039
Log Pis Min                  -7.5414066
Policy mu Mean               -0.0981333
Policy mu Std                1.2886347
Policy mu Max                3.008719
Policy mu Min                -2.9258575
Policy log std Mean          -0.85128456
Policy log std Std           0.41141036
Policy log std Max           -0.13193169
Policy log std Min           -2.991661
Z mean eval                  3.2861743
Z variance eval              0.0057977512
total_rewards                [8233.41554017 8183.38114258 8190.56034212 8304.4902552  8209.04115907
 8309.05041462 8305.0782267  8170.38847475 8219.89464393 8276.09838967]
total_rewards_mean           8240.139858881541
total_rewards_std            51.34860856758966
total_rewards_max            8309.050414623272
total_rewards_min            8170.388474754276
Number of train steps total  196000
Number of env steps total    247000
Number of rollouts total     0
Train Time (s)               115.28401315724477
(Previous) Eval Time (s)     22.531306916847825
Sample Time (s)              16.213625598698854
Epoch Time (s)               154.02894567279145
Total Train Time (s)         7441.670369927306
Epoch                        48
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:40:20.619641 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #48 | Epoch Duration: 154.49316596984863
2020-01-13 10:40:20.619819 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #48 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.286832
Z variance train             0.0058128354
KL Divergence                39.519028
KL Loss                      3.9519029
QF Loss                      247.18552
VF Loss                      155.90321
Policy Loss                  -2799.9138
Q Predictions Mean           2792.6182
Q Predictions Std            621.1474
Q Predictions Max            3436.6406
Q Predictions Min            692.3547
V Predictions Mean           2791.5542
V Predictions Std            614.0352
V Predictions Max            3427.579
V Predictions Min            698.5101
Log Pis Mean                 4.883031
Log Pis Std                  3.6727808
Log Pis Max                  15.246477
Log Pis Min                  -2.899928
Policy mu Mean               -0.12735632
Policy mu Std                1.3325504
Policy mu Max                3.722176
Policy mu Min                -2.8006263
Policy log std Mean          -0.81300783
Policy log std Std           0.4059883
Policy log std Max           -0.12768868
Policy log std Min           -2.8060884
Z mean eval                  3.3054829
Z variance eval              0.004241246
total_rewards                [7956.94539533 7620.84472864 8048.16955473 7936.63580481 7891.58439079
 7737.98480484 8055.95986461 7943.4277514  8053.72751829 7941.81156553]
total_rewards_mean           7918.709137897781
total_rewards_std            133.74456105047457
total_rewards_max            8055.959864606507
total_rewards_min            7620.844728641618
Number of train steps total  200000
Number of env steps total    252000
Number of rollouts total     0
Train Time (s)               116.63774570869282
(Previous) Eval Time (s)     22.995237068273127
Sample Time (s)              16.0194702912122
Epoch Time (s)               155.65245306817815
Total Train Time (s)         7597.853186551016
Epoch                        49
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:42:56.827602 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #49 | Epoch Duration: 156.20759844779968
2020-01-13 10:42:56.827912 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #49 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3040154
Z variance train             0.0042337975
KL Divergence                40.382202
KL Loss                      4.0382204
QF Loss                      243.35544
VF Loss                      115.247665
Policy Loss                  -2871.5916
Q Predictions Mean           2874.646
Q Predictions Std            602.6539
Q Predictions Max            3513.016
Q Predictions Min            706.6306
V Predictions Mean           2876.3257
V Predictions Std            595.8993
V Predictions Max            3510.249
V Predictions Min            720.92615
Log Pis Mean                 4.4287415
Log Pis Std                  3.9092548
Log Pis Max                  16.37917
Log Pis Min                  -8.333274
Policy mu Mean               -0.11799345
Policy mu Std                1.3176612
Policy mu Max                2.9779115
Policy mu Min                -3.6154425
Policy log std Mean          -0.81469274
Policy log std Std           0.41837013
Policy log std Max           0.13096583
Policy log std Min           -2.9740324
Z mean eval                  3.2934868
Z variance eval              0.0061813416
total_rewards                [8428.65194686 8638.10282131 8681.04854435 8371.16278558 8695.51602892
 8386.39403365 8652.71671876 8573.73262414 8580.31361465 8540.12035102]
total_rewards_mean           8554.775946924707
total_rewards_std            114.66827897376372
total_rewards_max            8695.51602892478
total_rewards_min            8371.162785583365
Number of train steps total  204000
Number of env steps total    257000
Number of rollouts total     0
Train Time (s)               111.45005264971405
(Previous) Eval Time (s)     23.55009586084634
Sample Time (s)              15.775772517547011
Epoch Time (s)               150.7759210281074
Total Train Time (s)         7747.5741738923825
Epoch                        50
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:45:26.527542 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #50 | Epoch Duration: 149.69942092895508
2020-01-13 10:45:26.527726 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #50 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2925644
Z variance train             0.006179291
KL Divergence                39.22486
KL Loss                      3.922486
QF Loss                      262.304
VF Loss                      93.485466
Policy Loss                  -2794.5186
Q Predictions Mean           2789.046
Q Predictions Std            643.69965
Q Predictions Max            3541.213
Q Predictions Min            720.4838
V Predictions Mean           2791.7776
V Predictions Std            638.26587
V Predictions Max            3516.6252
V Predictions Min            718.67584
Log Pis Mean                 4.7056227
Log Pis Std                  3.8755386
Log Pis Max                  17.02367
Log Pis Min                  -8.739567
Policy mu Mean               -0.1536703
Policy mu Std                1.306809
Policy mu Max                3.0475452
Policy mu Min                -2.8294468
Policy log std Mean          -0.8255682
Policy log std Std           0.4305131
Policy log std Max           -0.11754185
Policy log std Min           -3.1042013
Z mean eval                  3.3004975
Z variance eval              0.0018510377
total_rewards                [8775.7271657  8668.38073471 8653.64821888 8704.00284271 8537.52248844
 8577.68036329 8568.03593519 8771.25348978 8651.42839866 8650.68849803]
total_rewards_mean           8655.83681353824
total_rewards_std            76.18297429106539
total_rewards_max            8775.727165700218
total_rewards_min            8537.522488437107
Number of train steps total  208000
Number of env steps total    262000
Number of rollouts total     0
Train Time (s)               119.66007532505319
(Previous) Eval Time (s)     22.47333044372499
Sample Time (s)              16.726717200595886
Epoch Time (s)               158.86012296937406
Total Train Time (s)         7906.755397976842
Epoch                        51
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:48:05.714322 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #51 | Epoch Duration: 159.18641328811646
2020-01-13 10:48:05.714592 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #51 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3010948
Z variance train             0.0018508686
KL Divergence                42.215458
KL Loss                      4.2215457
QF Loss                      262.57782
VF Loss                      105.66557
Policy Loss                  -2926.9749
Q Predictions Mean           2922.2583
Q Predictions Std            583.6576
Q Predictions Max            3589.4536
Q Predictions Min            724.18304
V Predictions Mean           2924.5552
V Predictions Std            573.1554
V Predictions Max            3569.089
V Predictions Min            740.33014
Log Pis Mean                 4.770673
Log Pis Std                  3.5255976
Log Pis Max                  14.286886
Log Pis Min                  -3.489866
Policy mu Mean               -0.09186301
Policy mu Std                1.3411119
Policy mu Max                2.9992292
Policy mu Min                -3.3254158
Policy log std Mean          -0.84156424
Policy log std Std           0.45063847
Policy log std Max           -0.023924977
Policy log std Min           -3.0783792
Z mean eval                  3.2995636
Z variance eval              0.0017670349
total_rewards                [8712.49841844 8811.23925656 8984.32995751 8640.61603152 8512.39166649
 8971.52348762 8887.7034795  8841.09150503 8771.02144695 8790.39773087]
total_rewards_mean           8792.281298049202
total_rewards_std            137.48420972340605
total_rewards_max            8984.329957514441
total_rewards_min            8512.391666491145
Number of train steps total  212000
Number of env steps total    267000
Number of rollouts total     0
Train Time (s)               111.85500352922827
(Previous) Eval Time (s)     22.799317946191877
Sample Time (s)              16.010231473017484
Epoch Time (s)               150.66455294843763
Total Train Time (s)         8057.404297064524
Epoch                        52
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:50:36.362780 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #52 | Epoch Duration: 150.64795541763306
2020-01-13 10:50:36.363105 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #52 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2991748
Z variance train             0.0017638548
KL Divergence                42.619484
KL Loss                      4.2619486
QF Loss                      322.59204
VF Loss                      178.09393
Policy Loss                  -2952.212
Q Predictions Mean           2951.1611
Q Predictions Std            544.088
Q Predictions Max            3622.5742
Q Predictions Min            714.35236
V Predictions Mean           2953.0059
V Predictions Std            539.45966
V Predictions Max            3623.936
V Predictions Min            757.2107
Log Pis Mean                 4.3629575
Log Pis Std                  3.743176
Log Pis Max                  14.52302
Log Pis Min                  -6.5653687
Policy mu Mean               -0.14413798
Policy mu Std                1.2898551
Policy mu Max                2.9361708
Policy mu Min                -3.4227812
Policy log std Mean          -0.85307425
Policy log std Std           0.42955777
Policy log std Max           -0.12187305
Policy log std Min           -2.8637013
Z mean eval                  3.3030782
Z variance eval              0.0010563645
total_rewards                [8652.42959559 8731.02928894 8528.7914083  8857.0500556  8754.44725707
 8666.33803522 2576.89453428 8775.43992797 8792.34719427 8787.84289698]
total_rewards_mean           8112.261019419772
total_rewards_std            1847.1947787569716
total_rewards_max            8857.050055598289
total_rewards_min            2576.8945342762395
Number of train steps total  216000
Number of env steps total    272000
Number of rollouts total     0
Train Time (s)               112.4864803547971
(Previous) Eval Time (s)     22.7824142081663
Sample Time (s)              16.267275331541896
Epoch Time (s)               151.5361698945053
Total Train Time (s)         8209.337568723597
Epoch                        53
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:53:08.298526 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #53 | Epoch Duration: 151.9350941181183
2020-01-13 10:53:08.298915 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #53 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3029175
Z variance train             0.0010549191
KL Divergence                44.44686
KL Loss                      4.4446864
QF Loss                      171.20142
VF Loss                      93.851395
Policy Loss                  -2968.5474
Q Predictions Mean           2966.8765
Q Predictions Std            669.4041
Q Predictions Max            3617.6917
Q Predictions Min            747.1031
V Predictions Mean           2966.2493
V Predictions Std            661.98016
V Predictions Max            3609.8901
V Predictions Min            752.80316
Log Pis Mean                 4.373491
Log Pis Std                  3.416782
Log Pis Max                  13.71186
Log Pis Min                  -4.536483
Policy mu Mean               -0.08492031
Policy mu Std                1.28446
Policy mu Max                2.7602987
Policy mu Min                -3.178522
Policy log std Mean          -0.8352596
Policy log std Std           0.431148
Policy log std Max           -0.11076665
Policy log std Min           -2.997023
Z mean eval                  3.2953076
Z variance eval              0.0061735804
total_rewards                [8831.73115198 8915.42197073 9128.1133549  8931.65042491 8747.09243896
 8871.2375512  8839.21935577 8830.17908886 8854.24614008 8565.00106612]
total_rewards_mean           8851.389254352296
total_rewards_std            134.68512440879525
total_rewards_max            9128.11335489836
total_rewards_min            8565.001066122031
Number of train steps total  220000
Number of env steps total    277000
Number of rollouts total     0
Train Time (s)               107.9289987012744
(Previous) Eval Time (s)     23.181073241867125
Sample Time (s)              16.132480083499104
Epoch Time (s)               147.24255202664062
Total Train Time (s)         8356.020891720429
Epoch                        54
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:55:34.983391 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #54 | Epoch Duration: 146.68421006202698
2020-01-13 10:55:34.983665 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #54 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2956624
Z variance train             0.0061907754
KL Divergence                43.691017
KL Loss                      4.369102
QF Loss                      243.6864
VF Loss                      125.926186
Policy Loss                  -3036.1758
Q Predictions Mean           3037.581
Q Predictions Std            592.5401
Q Predictions Max            3644.1067
Q Predictions Min            745.86206
V Predictions Mean           3042.1108
V Predictions Std            584.3582
V Predictions Max            3643.4548
V Predictions Min            753.95685
Log Pis Mean                 4.2103405
Log Pis Std                  4.072939
Log Pis Max                  17.083952
Log Pis Min                  -7.72872
Policy mu Mean               -0.028412826
Policy mu Std                1.2924654
Policy mu Max                3.372621
Policy mu Min                -2.8057556
Policy log std Mean          -0.83210635
Policy log std Std           0.43487749
Policy log std Max           -0.0858168
Policy log std Min           -2.856852
Z mean eval                  3.2950969
Z variance eval              0.0055859257
total_rewards                [8632.40106419 8637.37166701 8596.34246087 8695.87080108 8660.39343958
 8578.14896574 8613.98861731 8612.63119105 8587.19883131 8509.92955096]
total_rewards_mean           8612.427658910732
total_rewards_std            47.8154900027596
total_rewards_max            8695.870801082774
total_rewards_min            8509.929550963729
Number of train steps total  224000
Number of env steps total    282000
Number of rollouts total     0
Train Time (s)               113.19425966404378
(Previous) Eval Time (s)     22.6224127789028
Sample Time (s)              15.956521301995963
Epoch Time (s)               151.77319374494255
Total Train Time (s)         8508.205291005317
Epoch                        55
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:58:07.171280 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #55 | Epoch Duration: 152.18728804588318
2020-01-13 10:58:07.171709 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #55 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.296491
Z variance train             0.0055993525
KL Divergence                43.808315
KL Loss                      4.3808317
QF Loss                      328.92276
VF Loss                      78.9639
Policy Loss                  -3058.0725
Q Predictions Mean           3065.7773
Q Predictions Std            538.38824
Q Predictions Max            3734.6135
Q Predictions Min            776.46155
V Predictions Mean           3059.683
V Predictions Std            532.7477
V Predictions Max            3727.2268
V Predictions Min            778.1008
Log Pis Mean                 4.482578
Log Pis Std                  3.8693144
Log Pis Max                  13.127436
Log Pis Min                  -4.3685136
Policy mu Mean               -0.13442402
Policy mu Std                1.3147271
Policy mu Max                2.8131762
Policy mu Min                -3.468672
Policy log std Mean          -0.86305046
Policy log std Std           0.44892138
Policy log std Max           -0.011871994
Policy log std Min           -3.115674
Z mean eval                  3.3001587
Z variance eval              0.0036424217
total_rewards                [8621.17491491 8701.67392522 8550.0078814  8760.82353811 8586.69127072
 8730.10638546 8532.18474333 8448.8972961  8587.12240073 8627.6288132 ]
total_rewards_mean           8614.631116918183
total_rewards_std            90.8149791928738
total_rewards_max            8760.823538112623
total_rewards_min            8448.8972961
Number of train steps total  228000
Number of env steps total    287000
Number of rollouts total     0
Train Time (s)               112.43516139406711
(Previous) Eval Time (s)     23.036214896012098
Sample Time (s)              16.196566591970623
Epoch Time (s)               151.66794288204983
Total Train Time (s)         8659.18109021755
Epoch                        56
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:00:38.145638 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #56 | Epoch Duration: 150.97366786003113
2020-01-13 11:00:38.145823 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #56 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2976806
Z variance train             0.0036392927
KL Divergence                43.512825
KL Loss                      4.3512826
QF Loss                      273.77838
VF Loss                      310.044
Policy Loss                  -3132.6797
Q Predictions Mean           3136.9453
Q Predictions Std            499.3473
Q Predictions Max            3761.8105
Q Predictions Min            768.53845
V Predictions Mean           3147.918
V Predictions Std            492.94165
V Predictions Max            3771.433
V Predictions Min            773.2354
Log Pis Mean                 4.4279194
Log Pis Std                  3.60419
Log Pis Max                  13.78661
Log Pis Min                  -5.1014543
Policy mu Mean               -0.1143829
Policy mu Std                1.3067088
Policy mu Max                2.989068
Policy mu Min                -2.8075225
Policy log std Mean          -0.8530777
Policy log std Std           0.4323887
Policy log std Max           -0.11687225
Policy log std Min           -3.0801911
Z mean eval                  3.2935417
Z variance eval              0.0026714134
total_rewards                [8911.6382898  8959.46682425 9049.21868894 9104.15602937 9023.36893898
 8818.48432223 8837.67267103 8911.42600703 9132.40768899 9084.73517946]
total_rewards_mean           8983.257464007867
total_rewards_std            105.98111725029119
total_rewards_max            9132.407688989497
total_rewards_min            8818.484322227268
Number of train steps total  232000
Number of env steps total    292000
Number of rollouts total     0
Train Time (s)               110.16400420991704
(Previous) Eval Time (s)     22.34165702899918
Sample Time (s)              16.528492451645434
Epoch Time (s)               149.03415369056165
Total Train Time (s)         8808.444859925192
Epoch                        57
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:03:07.410480 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #57 | Epoch Duration: 149.26451921463013
2020-01-13 11:03:07.410683 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #57 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2967274
Z variance train             0.002691303
KL Divergence                43.678886
KL Loss                      4.367889
QF Loss                      351.53653
VF Loss                      100.61267
Policy Loss                  -3067.9248
Q Predictions Mean           3064.359
Q Predictions Std            561.4143
Q Predictions Max            3742.571
Q Predictions Min            746.7675
V Predictions Mean           3071.542
V Predictions Std            555.6252
V Predictions Max            3730.509
V Predictions Min            772.7465
Log Pis Mean                 4.9498024
Log Pis Std                  3.8128867
Log Pis Max                  17.268024
Log Pis Min                  -4.841809
Policy mu Mean               -0.09042061
Policy mu Std                1.3473277
Policy mu Max                3.231397
Policy mu Min                -3.1304374
Policy log std Mean          -0.8460179
Policy log std Std           0.44221672
Policy log std Max           -0.021169841
Policy log std Min           -2.8927712
Z mean eval                  3.3005824
Z variance eval              0.00095924886
total_rewards                [8952.32699355 8631.98229461 9136.15265659 9051.25953236 8871.63638992
 8981.48048076 9113.79626985 8962.58347643 8876.72303372 8986.70116796]
total_rewards_mean           8956.464229575415
total_rewards_std            136.5522043465544
total_rewards_max            9136.152656594308
total_rewards_min            8631.98229461048
Number of train steps total  236000
Number of env steps total    297000
Number of rollouts total     0
Train Time (s)               109.79193476494402
(Previous) Eval Time (s)     22.571745524182916
Sample Time (s)              15.789851853158325
Epoch Time (s)               148.15353214228526
Total Train Time (s)         8956.872639690991
Epoch                        58
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:05:35.842496 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #58 | Epoch Duration: 148.43163919448853
2020-01-13 11:05:35.842796 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #58 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2981994
Z variance train             0.0009594759
KL Divergence                44.913486
KL Loss                      4.4913487
QF Loss                      320.59332
VF Loss                      152.23444
Policy Loss                  -3129.6646
Q Predictions Mean           3124.713
Q Predictions Std            529.24963
Q Predictions Max            3802.4763
Q Predictions Min            772.73883
V Predictions Mean           3123.742
V Predictions Std            524.6566
V Predictions Max            3793.7556
V Predictions Min            761.49243
Log Pis Mean                 4.6904774
Log Pis Std                  3.7243857
Log Pis Max                  14.270017
Log Pis Min                  -6.044141
Policy mu Mean               -0.12328708
Policy mu Std                1.317857
Policy mu Max                3.7008698
Policy mu Min                -2.7885385
Policy log std Mean          -0.84677744
Policy log std Std           0.4359066
Policy log std Max           -0.056559622
Policy log std Min           -3.2455566
Z mean eval                  3.3098576
Z variance eval              0.0010953962
total_rewards                [9021.14575333 9251.40020731 9195.72834744 9185.65190832 9244.62170417
 9107.20693302 9238.17952315 8877.22686959 8993.52807075 9276.36445164]
total_rewards_mean           9139.105376871052
total_rewards_std            127.46662028214953
total_rewards_max            9276.364451643476
total_rewards_min            8877.22686958965
Number of train steps total  240000
Number of env steps total    302000
Number of rollouts total     0
Train Time (s)               115.67605408607051
(Previous) Eval Time (s)     22.849553643725812
Sample Time (s)              15.954679496586323
Epoch Time (s)               154.48028722638264
Total Train Time (s)         9111.123792756349
Epoch                        59
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:08:10.093189 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #59 | Epoch Duration: 154.2501664161682
2020-01-13 11:08:10.093367 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #59 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3065434
Z variance train             0.001094466
KL Divergence                45.092358
KL Loss                      4.509236
QF Loss                      255.84259
VF Loss                      301.2988
Policy Loss                  -3098.4583
Q Predictions Mean           3098.9634
Q Predictions Std            640.6848
Q Predictions Max            3820.0535
Q Predictions Min            748.24066
V Predictions Mean           3110.1528
V Predictions Std            634.61176
V Predictions Max            3836.278
V Predictions Min            769.4769
Log Pis Mean                 4.650168
Log Pis Std                  3.9634976
Log Pis Max                  14.771341
Log Pis Min                  -5.7687407
Policy mu Mean               -0.10975078
Policy mu Std                1.3083731
Policy mu Max                3.0910177
Policy mu Min                -3.1766853
Policy log std Mean          -0.83588105
Policy log std Std           0.44339317
Policy log std Max           -0.08546817
Policy log std Min           -3.2144237
Z mean eval                  3.2983346
Z variance eval              0.0014567615
total_rewards                [9077.58681523 8970.72038676 9077.72600334 9214.85588796 9289.36108135
 9187.45385628 9112.70108406 9058.20364314 9029.7416324  9204.82647811]
total_rewards_mean           9122.317686864651
total_rewards_std            93.41395052517221
total_rewards_max            9289.361081349913
total_rewards_min            8970.720386764562
Number of train steps total  244000
Number of env steps total    307000
Number of rollouts total     0
Train Time (s)               116.58612247603014
(Previous) Eval Time (s)     22.61914864135906
Sample Time (s)              16.48079398041591
Epoch Time (s)               155.6860650978051
Total Train Time (s)         9266.555288540665
Epoch                        60
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:10:45.527087 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #60 | Epoch Duration: 155.4335560798645
2020-01-13 11:10:45.527317 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #60 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2964127
Z variance train             0.001462295
KL Divergence                44.518555
KL Loss                      4.4518557
QF Loss                      227.60638
VF Loss                      120.51196
Policy Loss                  -3118.8218
Q Predictions Mean           3121.455
Q Predictions Std            632.6186
Q Predictions Max            3837.831
Q Predictions Min            750.8055
V Predictions Mean           3124.7354
V Predictions Std            625.9712
V Predictions Max            3828.5571
V Predictions Min            756.3319
Log Pis Mean                 4.4707003
Log Pis Std                  3.7673151
Log Pis Max                  13.413522
Log Pis Min                  -4.1181326
Policy mu Mean               -0.14961985
Policy mu Std                1.3078014
Policy mu Max                2.956246
Policy mu Min                -2.8610117
Policy log std Mean          -0.8578646
Policy log std Std           0.4385085
Policy log std Max           -0.1472491
Policy log std Min           -2.9513876
Z mean eval                  3.3069663
Z variance eval              0.0025321308
total_rewards                [8843.2964308  9263.61202654 9102.37185016 9401.78954311 9045.7635887
 9104.93472517 9389.14250084 9208.77066724 9421.88270888 9199.51025684]
total_rewards_mean           9198.10742982797
total_rewards_std            173.03428763080694
total_rewards_max            9421.882708882746
total_rewards_min            8843.296430795817
Number of train steps total  248000
Number of env steps total    312000
Number of rollouts total     0
Train Time (s)               109.4252496631816
(Previous) Eval Time (s)     22.36634333897382
Sample Time (s)              15.721190490294248
Epoch Time (s)               147.51278349244967
Total Train Time (s)         9415.30375038879
Epoch                        61
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:13:14.278308 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #61 | Epoch Duration: 148.75077319145203
2020-01-13 11:13:14.278577 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #61 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.306298
Z variance train             0.0025404051
KL Divergence                42.99813
KL Loss                      4.2998133
QF Loss                      379.43683
VF Loss                      174.13097
Policy Loss                  -3214.0325
Q Predictions Mean           3220.222
Q Predictions Std            519.9846
Q Predictions Max            3909.3584
Q Predictions Min            761.55786
V Predictions Mean           3221.5715
V Predictions Std            511.69446
V Predictions Max            3900.0984
V Predictions Min            785.6893
Log Pis Mean                 5.324941
Log Pis Std                  3.6958396
Log Pis Max                  16.102795
Log Pis Min                  -5.2935753
Policy mu Mean               -0.15512848
Policy mu Std                1.3541142
Policy mu Max                3.0482152
Policy mu Min                -3.034178
Policy log std Mean          -0.85904104
Policy log std Std           0.42639837
Policy log std Max           -0.05588731
Policy log std Min           -2.8931308
Z mean eval                  3.2977767
Z variance eval              0.006246851
total_rewards                [8587.4780055  8972.96984266 8772.38003984 8612.27101306 8812.91902437
 9026.91376267 8830.78850115 9047.52971253 8723.34254988 8784.98994818]
total_rewards_mean           8817.15823998379
total_rewards_std            151.03723413170897
total_rewards_max            9047.529712527565
total_rewards_min            8587.478005498444
Number of train steps total  252000
Number of env steps total    317000
Number of rollouts total     0
Train Time (s)               110.56503053894266
(Previous) Eval Time (s)     23.604049650020897
Sample Time (s)              16.378979183733463
Epoch Time (s)               150.54805937269703
Total Train Time (s)         9565.608449595515
Epoch                        62
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:15:44.582579 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #62 | Epoch Duration: 150.30381178855896
2020-01-13 11:15:44.582762 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #62 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2958572
Z variance train             0.0062260553
KL Divergence                43.002438
KL Loss                      4.300244
QF Loss                      313.43024
VF Loss                      149.604
Policy Loss                  -3148.367
Q Predictions Mean           3148.5696
Q Predictions Std            658.89667
Q Predictions Max            3910.6677
Q Predictions Min            788.3013
V Predictions Mean           3154.4495
V Predictions Std            653.38007
V Predictions Max            3909.0774
V Predictions Min            790.50574
Log Pis Mean                 4.57003
Log Pis Std                  3.6484194
Log Pis Max                  13.243933
Log Pis Min                  -4.1322565
Policy mu Mean               -0.13298298
Policy mu Std                1.317695
Policy mu Max                2.8876998
Policy mu Min                -3.06045
Policy log std Mean          -0.8348012
Policy log std Std           0.43175238
Policy log std Max           -0.09414074
Policy log std Min           -3.3058066
Z mean eval                  3.2961166
Z variance eval              0.017829357
total_rewards                [4262.4753569  8856.10814237 8916.50172253 8791.7029399  1245.35877629
 8999.03620233 8604.67412009 8729.58234295 8922.78554077 8808.64753478]
total_rewards_mean           7613.687267891571
total_rewards_std            2523.945757397874
total_rewards_max            8999.036202331767
total_rewards_min            1245.3587762874192
Number of train steps total  256000
Number of env steps total    322000
Number of rollouts total     0
Train Time (s)               112.69677595933899
(Previous) Eval Time (s)     23.359517918899655
Sample Time (s)              16.659180257469416
Epoch Time (s)               152.71547413570806
Total Train Time (s)         9717.94244045997
Epoch                        63
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:18:16.919756 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #63 | Epoch Duration: 152.33683013916016
2020-01-13 11:18:16.920027 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #63 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2955756
Z variance train             0.017936686
KL Divergence                42.184834
KL Loss                      4.2184834
QF Loss                      221.41197
VF Loss                      191.10333
Policy Loss                  -3145.27
Q Predictions Mean           3150.162
Q Predictions Std            635.528
Q Predictions Max            3915.0315
Q Predictions Min            789.9081
V Predictions Mean           3153.9658
V Predictions Std            630.2397
V Predictions Max            3881.7188
V Predictions Min            805.0236
Log Pis Mean                 4.3061676
Log Pis Std                  3.3121684
Log Pis Max                  12.560189
Log Pis Min                  -2.450798
Policy mu Mean               -0.09751441
Policy mu Std                1.289393
Policy mu Max                2.7964532
Policy mu Min                -3.1209407
Policy log std Mean          -0.84839875
Policy log std Std           0.44669792
Policy log std Max           -0.09679508
Policy log std Min           -3.1385214
Z mean eval                  3.3179955
Z variance eval              0.002299289
total_rewards                [8922.87468186 8826.48844846 8937.25026843 8907.52576504 8902.53125003
 8804.80437995 8805.11973051 8935.51820288 8982.5916215  9005.42139844]
total_rewards_mean           8903.012574710077
total_rewards_std            66.74438674874735
total_rewards_max            9005.421398444569
total_rewards_min            8804.804379948897
Number of train steps total  260000
Number of env steps total    327000
Number of rollouts total     0
Train Time (s)               111.35519993212074
(Previous) Eval Time (s)     22.980570496991277
Sample Time (s)              16.356100347824395
Epoch Time (s)               150.6918707769364
Total Train Time (s)         9868.685344751924
Epoch                        64
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:20:47.665525 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #64 | Epoch Duration: 150.74528288841248
2020-01-13 11:20:47.665820 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #64 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3164277
Z variance train             0.002307551
KL Divergence                45.105087
KL Loss                      4.510509
QF Loss                      288.23953
VF Loss                      139.00917
Policy Loss                  -3190.2493
Q Predictions Mean           3187.1294
Q Predictions Std            639.44257
Q Predictions Max            3981.988
Q Predictions Min            788.8052
V Predictions Mean           3190.0518
V Predictions Std            634.4291
V Predictions Max            3968.4836
V Predictions Min            806.6358
Log Pis Mean                 4.8565855
Log Pis Std                  3.7878418
Log Pis Max                  14.6873665
Log Pis Min                  -8.214704
Policy mu Mean               -0.11287707
Policy mu Std                1.3457261
Policy mu Max                3.4205422
Policy mu Min                -3.076737
Policy log std Mean          -0.8480711
Policy log std Std           0.4186219
Policy log std Max           -0.10131031
Policy log std Min           -3.0708046
Z mean eval                  3.318891
Z variance eval              0.0012197641
total_rewards                [9099.97843381 9293.63307184 9261.0531422  8984.50785229 9151.94902665
 8970.09484168 9255.50807441 9259.83289611 9255.11318468 9131.14047603]
total_rewards_mean           9166.281099970114
total_rewards_std            112.77041826570415
total_rewards_max            9293.633071839178
total_rewards_min            8970.094841679156
Number of train steps total  264000
Number of env steps total    332000
Number of rollouts total     0
Train Time (s)               111.39493589941412
(Previous) Eval Time (s)     23.03368124179542
Sample Time (s)              17.06183737842366
Epoch Time (s)               151.4904545196332
Total Train Time (s)         10019.386956893839
Epoch                        65
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:23:18.366499 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #65 | Epoch Duration: 150.70048594474792
2020-01-13 11:23:18.366681 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3190968
Z variance train             0.0012233775
KL Divergence                45.223843
KL Loss                      4.522384
QF Loss                      295.7324
VF Loss                      107.11029
Policy Loss                  -3330.0837
Q Predictions Mean           3329.707
Q Predictions Std            531.14014
Q Predictions Max            4011.2827
Q Predictions Min            823.794
V Predictions Mean           3330.756
V Predictions Std            525.68396
V Predictions Max            3999.4011
V Predictions Min            822.7297
Log Pis Mean                 4.6665497
Log Pis Std                  3.4130533
Log Pis Max                  15.925748
Log Pis Min                  -3.2083552
Policy mu Mean               -0.14230765
Policy mu Std                1.3178576
Policy mu Max                3.2046702
Policy mu Min                -2.813477
Policy log std Mean          -0.85792106
Policy log std Std           0.43253264
Policy log std Max           0.046073854
Policy log std Min           -3.2191927
Z mean eval                  3.316904
Z variance eval              0.00046858285
total_rewards                [8607.19565296 8987.17959219 8694.90465729 8860.59829746 8982.00087094
 9046.74891188 9290.04637475 9317.35129849 9020.16543966 8792.71965418]
total_rewards_mean           8959.891074979241
total_rewards_std            219.45576418642767
total_rewards_max            9317.351298491198
total_rewards_min            8607.195652961269
Number of train steps total  268000
Number of env steps total    337000
Number of rollouts total     0
Train Time (s)               114.6075705033727
(Previous) Eval Time (s)     22.243416647426784
Sample Time (s)              16.275191727560014
Epoch Time (s)               153.1261788783595
Total Train Time (s)         10172.727759841364
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:25:51.708723 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #66 | Epoch Duration: 153.34192419052124
2020-01-13 11:25:51.708926 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #66 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.315791
Z variance train             0.0004681886
KL Divergence                46.00245
KL Loss                      4.600245
QF Loss                      336.49286
VF Loss                      98.91447
Policy Loss                  -3317.289
Q Predictions Mean           3316.2036
Q Predictions Std            534.3876
Q Predictions Max            4005.0254
Q Predictions Min            811.26904
V Predictions Mean           3321.489
V Predictions Std            528.8435
V Predictions Max            4012.6387
V Predictions Min            824.11383
Log Pis Mean                 4.693163
Log Pis Std                  3.5901363
Log Pis Max                  14.726756
Log Pis Min                  -6.1882763
Policy mu Mean               -0.08779479
Policy mu Std                1.3339108
Policy mu Max                3.6185613
Policy mu Min                -2.9852626
Policy log std Mean          -0.87016463
Policy log std Std           0.46188664
Policy log std Max           -0.031747878
Policy log std Min           -3.2491689
Z mean eval                  3.325576
Z variance eval              0.00078253297
total_rewards                [9108.82390489 9309.3647346  8766.65649817 9258.38266864 9196.3451336
 9103.15310307 9275.38965485 9240.75171318 9248.11403667 9499.93536305]
total_rewards_mean           9200.691681071597
total_rewards_std            179.01877891822366
total_rewards_max            9499.935363046216
total_rewards_min            8766.656498168302
Number of train steps total  272000
Number of env steps total    342000
Number of rollouts total     0
Train Time (s)               116.40086278738454
(Previous) Eval Time (s)     22.45888067735359
Sample Time (s)              16.21531151328236
Epoch Time (s)               155.0750549780205
Total Train Time (s)         10328.652030120604
Epoch                        67
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:28:27.636989 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #67 | Epoch Duration: 155.92788887023926
2020-01-13 11:28:27.637282 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #67 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.323478
Z variance train             0.0007820553
KL Divergence                45.64746
KL Loss                      4.5647464
QF Loss                      280.8157
VF Loss                      256.7265
Policy Loss                  -3304.7117
Q Predictions Mean           3313.5647
Q Predictions Std            631.3592
Q Predictions Max            4042.3535
Q Predictions Min            797.38666
V Predictions Mean           3318.9897
V Predictions Std            623.018
V Predictions Max            4030.0205
V Predictions Min            831.2318
Log Pis Mean                 4.7421494
Log Pis Std                  3.7810369
Log Pis Max                  14.644079
Log Pis Min                  -6.5944304
Policy mu Mean               -0.11479815
Policy mu Std                1.3313677
Policy mu Max                3.0132253
Policy mu Min                -3.0526278
Policy log std Mean          -0.86070085
Policy log std Std           0.44723436
Policy log std Max           -0.08642429
Policy log std Min           -3.0954156
Z mean eval                  3.3226724
Z variance eval              0.001502869
total_rewards                [9367.94315507 9395.65864681 9397.05867155 9451.67777825 9477.7561613
 9426.52007695 9373.99722137 9404.27463474 9317.67837456 9516.36535123]
total_rewards_mean           9412.893007183568
total_rewards_std            54.61220886454207
total_rewards_max            9516.36535122914
total_rewards_min            9317.678374563777
Number of train steps total  276000
Number of env steps total    347000
Number of rollouts total     0
Train Time (s)               111.84374458622187
(Previous) Eval Time (s)     23.311384194996208
Sample Time (s)              15.58711874531582
Epoch Time (s)               150.7422475265339
Total Train Time (s)         10479.437369698193
Epoch                        68
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:30:58.423734 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #68 | Epoch Duration: 150.78622698783875
2020-01-13 11:30:58.423999 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #68 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3244033
Z variance train             0.0015098441
KL Divergence                45.97463
KL Loss                      4.597463
QF Loss                      219.42953
VF Loss                      236.29733
Policy Loss                  -3439.111
Q Predictions Mean           3429.72
Q Predictions Std            497.01492
Q Predictions Max            4046.2092
Q Predictions Min            825.9297
V Predictions Mean           3433.773
V Predictions Std            490.83084
V Predictions Max            4033.9944
V Predictions Min            831.31464
Log Pis Mean                 4.9142127
Log Pis Std                  3.6012924
Log Pis Max                  13.4643135
Log Pis Min                  -4.85083
Policy mu Mean               -0.13705584
Policy mu Std                1.318384
Policy mu Max                3.0223444
Policy mu Min                -3.0794437
Policy log std Mean          -0.87325567
Policy log std Std           0.44462982
Policy log std Max           -0.10595429
Policy log std Min           -3.2033923
Z mean eval                  3.3163257
Z variance eval              0.0013040219
total_rewards                [9168.97371421 9278.35648973 9426.63511539 9488.39120388 5121.5127007
 9416.85765461 9072.70971707 9381.84492524 9343.31267712 9267.32938474]
total_rewards_mean           8896.592358268845
total_rewards_std            1263.9818597051437
total_rewards_max            9488.391203876905
total_rewards_min            5121.512700700205
Number of train steps total  280000
Number of env steps total    352000
Number of rollouts total     0
Train Time (s)               111.75836385507137
(Previous) Eval Time (s)     23.355085057206452
Sample Time (s)              15.820680388249457
Epoch Time (s)               150.93412930052727
Total Train Time (s)         10629.906603586394
Epoch                        69
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:33:28.895140 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #69 | Epoch Duration: 150.47093224525452
2020-01-13 11:33:28.895420 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #69 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3176064
Z variance train             0.0013089656
KL Divergence                45.825813
KL Loss                      4.5825815
QF Loss                      392.78067
VF Loss                      112.01821
Policy Loss                  -3296.6262
Q Predictions Mean           3284.592
Q Predictions Std            600.88043
Q Predictions Max            3996.3806
Q Predictions Min            794.2217
V Predictions Mean           3292.1177
V Predictions Std            586.27313
V Predictions Max            4010.9282
V Predictions Min            825.2225
Log Pis Mean                 4.579363
Log Pis Std                  3.6217647
Log Pis Max                  13.658705
Log Pis Min                  -6.45968
Policy mu Mean               -0.09094989
Policy mu Std                1.3136777
Policy mu Max                2.8090897
Policy mu Min                -2.87962
Policy log std Mean          -0.8524588
Policy log std Std           0.44359195
Policy log std Max           -0.11210829
Policy log std Min           -3.261185
Z mean eval                  3.319542
Z variance eval              0.0015363976
total_rewards                [9134.87699216 9288.73808593 9179.40870849 9392.82755324 9362.33361749
 9389.71014178 9429.72292409 9311.45110322 9547.80639108 9180.59040779]
total_rewards_mean           9321.746592526733
total_rewards_std            122.630225543418
total_rewards_max            9547.806391076532
total_rewards_min            9134.876992159285
Number of train steps total  284000
Number of env steps total    357000
Number of rollouts total     0
Train Time (s)               114.34195066569373
(Previous) Eval Time (s)     22.89154753088951
Sample Time (s)              16.07065529609099
Epoch Time (s)               153.30415349267423
Total Train Time (s)         10783.68201718852
Epoch                        70
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:36:02.671956 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #70 | Epoch Duration: 153.7763319015503
2020-01-13 11:36:02.672197 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #70 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3220253
Z variance train             0.0015413465
KL Divergence                44.42192
KL Loss                      4.442192
QF Loss                      244.99023
VF Loss                      131.55742
Policy Loss                  -3380.9785
Q Predictions Mean           3381.511
Q Predictions Std            540.71027
Q Predictions Max            4115.261
Q Predictions Min            822.4748
V Predictions Mean           3373.4834
V Predictions Std            533.76733
V Predictions Max            4106.228
V Predictions Min            816.3761
Log Pis Mean                 4.9485245
Log Pis Std                  3.7651823
Log Pis Max                  14.473335
Log Pis Min                  -4.0577974
Policy mu Mean               -0.15653318
Policy mu Std                1.3473997
Policy mu Max                3.290332
Policy mu Min                -2.9997382
Policy log std Mean          -0.874502
Policy log std Std           0.44857416
Policy log std Max           -0.09768444
Policy log std Min           -3.1086712
Z mean eval                  3.3189073
Z variance eval              0.0031166726
total_rewards                [9146.20184733 9325.17039173 9166.8239104  9395.68663022 9209.56017317
 9189.66930356 9247.5680811  9159.07525195 9211.43641697 9362.37902317]
total_rewards_mean           9241.3571029614
total_rewards_std            84.548858688112
total_rewards_max            9395.686630223776
total_rewards_min            9146.201847326052
Number of train steps total  288000
Number of env steps total    362000
Number of rollouts total     0
Train Time (s)               117.1123698442243
(Previous) Eval Time (s)     23.363405500072986
Sample Time (s)              16.09360772324726
Epoch Time (s)               156.56938306754455
Total Train Time (s)         10939.907448088285
Epoch                        71
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:38:38.898668 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #71 | Epoch Duration: 156.2263162136078
2020-01-13 11:38:38.898854 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #71 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3171113
Z variance train             0.0031174165
KL Divergence                43.850693
KL Loss                      4.3850694
QF Loss                      404.03928
VF Loss                      130.93713
Policy Loss                  -3341.4216
Q Predictions Mean           3339.9749
Q Predictions Std            609.9706
Q Predictions Max            4085.4392
Q Predictions Min            804.75653
V Predictions Mean           3343.7522
V Predictions Std            602.1612
V Predictions Max            4071.4885
V Predictions Min            824.464
Log Pis Mean                 5.42879
Log Pis Std                  3.5873964
Log Pis Max                  14.82877
Log Pis Min                  -1.9944663
Policy mu Mean               -0.06158762
Policy mu Std                1.381677
Policy mu Max                3.4314682
Policy mu Min                -3.1749918
Policy log std Mean          -0.8722825
Policy log std Std           0.44741186
Policy log std Max           -0.09392971
Policy log std Min           -3.1875803
Z mean eval                  3.322583
Z variance eval              0.0011329383
total_rewards                [9262.39329605 9498.3043152  9351.1782447  9463.2391256  9486.606386
 9465.40624119 9509.80392192 9471.88590371 9493.14064301 9600.95445899]
total_rewards_mean           9460.291253637899
total_rewards_std            87.57439259248135
total_rewards_max            9600.95445899415
total_rewards_min            9262.393296045433
Number of train steps total  292000
Number of env steps total    367000
Number of rollouts total     0
Train Time (s)               113.03231612825766
(Previous) Eval Time (s)     23.020063323900104
Sample Time (s)              16.42729680193588
Epoch Time (s)               152.47967625409365
Total Train Time (s)         11092.235586750787
Epoch                        72
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:41:11.230848 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #72 | Epoch Duration: 152.3318178653717
2020-01-13 11:41:11.231170 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #72 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.321069
Z variance train             0.0011344944
KL Divergence                43.97033
KL Loss                      4.397033
QF Loss                      220.06787
VF Loss                      84.472244
Policy Loss                  -3401.9326
Q Predictions Mean           3399.3877
Q Predictions Std            588.72504
Q Predictions Max            4114.062
Q Predictions Min            778.1827
V Predictions Mean           3400.4885
V Predictions Std            584.2053
V Predictions Max            4114.529
V Predictions Min            806.06335
Log Pis Mean                 5.0163016
Log Pis Std                  3.9022124
Log Pis Max                  14.365626
Log Pis Min                  -4.2544994
Policy mu Mean               -0.14421183
Policy mu Std                1.3560472
Policy mu Max                3.3172755
Policy mu Min                -3.0483785
Policy log std Mean          -0.84401935
Policy log std Std           0.43630928
Policy log std Max           -0.067598164
Policy log std Min           -2.987434
Z mean eval                  3.3100052
Z variance eval              0.00801898
total_rewards                [9407.96911079 9462.27485245 9456.46520248 9494.5878405  9441.5146644
 9605.33288809 9523.19279034 9347.56811608 9436.6457285  9443.33713651]
total_rewards_mean           9461.888833014378
total_rewards_std            65.42645586486034
total_rewards_max            9605.332888090808
total_rewards_min            9347.568116079361
Number of train steps total  296000
Number of env steps total    372000
Number of rollouts total     0
Train Time (s)               106.67015752382576
(Previous) Eval Time (s)     22.871861944906414
Sample Time (s)              16.735089662950486
Epoch Time (s)               146.27710913168266
Total Train Time (s)         11239.092819021083
Epoch                        73
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:43:38.087150 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #73 | Epoch Duration: 146.8557550907135
2020-01-13 11:43:38.087317 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #73 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3084683
Z variance train             0.008064324
KL Divergence                41.38846
KL Loss                      4.138846
QF Loss                      374.11212
VF Loss                      82.79316
Policy Loss                  -3354.576
Q Predictions Mean           3354.163
Q Predictions Std            640.1393
Q Predictions Max            4112.8184
Q Predictions Min            779.30963
V Predictions Mean           3355.9866
V Predictions Std            634.17523
V Predictions Max            4102.236
V Predictions Min            799.10974
Log Pis Mean                 4.938592
Log Pis Std                  3.6102996
Log Pis Max                  13.054233
Log Pis Min                  -3.3391762
Policy mu Mean               -0.11041417
Policy mu Std                1.3490908
Policy mu Max                3.0763195
Policy mu Min                -2.9801815
Policy log std Mean          -0.85535383
Policy log std Std           0.4450787
Policy log std Max           -0.03681898
Policy log std Min           -3.100387
Z mean eval                  3.2831047
Z variance eval              0.026139632
total_rewards                [9352.32576644 9433.66265616 9514.37054859 9693.98679253 9330.80114084
 9544.58285216 9383.52528726 9404.32652698 9534.76017697 9631.60452625]
total_rewards_mean           9482.394627417407
total_rewards_std            115.24317653433687
total_rewards_max            9693.986792530599
total_rewards_min            9330.801140844183
Number of train steps total  300000
Number of env steps total    377000
Number of rollouts total     0
Train Time (s)               111.42427693493664
(Previous) Eval Time (s)     23.45020188903436
Sample Time (s)              16.399622633121908
Epoch Time (s)               151.2741014570929
Total Train Time (s)         11389.874198077247
Epoch                        74
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:46:08.872347 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #74 | Epoch Duration: 150.78486919403076
2020-01-13 11:46:08.872624 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #74 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2830734
Z variance train             0.026179457
KL Divergence                37.74807
KL Loss                      3.774807
QF Loss                      268.36023
VF Loss                      125.41214
Policy Loss                  -3358.7056
Q Predictions Mean           3358.8477
Q Predictions Std            719.7687
Q Predictions Max            4157.534
Q Predictions Min            744.65234
V Predictions Mean           3357.1694
V Predictions Std            714.1605
V Predictions Max            4139.473
V Predictions Min            749.3114
Log Pis Mean                 4.600168
Log Pis Std                  3.7252862
Log Pis Max                  14.737322
Log Pis Min                  -4.5945616
Policy mu Mean               -0.10792761
Policy mu Std                1.3308198
Policy mu Max                3.1711626
Policy mu Min                -2.9405
Policy log std Mean          -0.85202533
Policy log std Std           0.46550766
Policy log std Max           -0.015382826
Policy log std Min           -3.0753527
Z mean eval                  3.3243911
Z variance eval              0.008950126
total_rewards                [9566.30907466 9577.46781847 9514.80222159 9695.81894052 9621.83770512
 9516.68305202 9612.92191629 9404.95854287 9534.58731061 9679.08200689]
total_rewards_mean           9572.446858904874
total_rewards_std            81.6397461234057
total_rewards_max            9695.818940518167
total_rewards_min            9404.958542872198
Number of train steps total  304000
Number of env steps total    382000
Number of rollouts total     0
Train Time (s)               118.68912614602596
(Previous) Eval Time (s)     22.96068706922233
Sample Time (s)              17.25345416693017
Epoch Time (s)               158.90326738217846
Total Train Time (s)         11548.773309933953
Epoch                        75
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:48:47.776656 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #75 | Epoch Duration: 158.90379810333252
2020-01-13 11:48:47.776960 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #75 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.323976
Z variance train             0.008956762
KL Divergence                40.139294
KL Loss                      4.0139294
QF Loss                      305.46432
VF Loss                      123.72922
Policy Loss                  -3419.1775
Q Predictions Mean           3418.0635
Q Predictions Std            647.3521
Q Predictions Max            4154.886
Q Predictions Min            754.0562
V Predictions Mean           3416.8704
V Predictions Std            641.54315
V Predictions Max            4150.9346
V Predictions Min            751.0272
Log Pis Mean                 5.1459928
Log Pis Std                  3.6183581
Log Pis Max                  14.800925
Log Pis Min                  -3.306078
Policy mu Mean               -0.046666276
Policy mu Std                1.3422946
Policy mu Max                3.1090372
Policy mu Min                -2.797279
Policy log std Mean          -0.8764377
Policy log std Std           0.45961127
Policy log std Max           -0.13414848
Policy log std Min           -2.9565063
Z mean eval                  3.3337905
Z variance eval              0.015002226
total_rewards                [9483.52211802 9510.55146008 9585.8575778  9684.1684132  9523.29313442
 2346.58337774 9533.66161692 9357.83744262 9623.85544704 9672.24407307]
total_rewards_mean           8832.157466090675
total_rewards_std            2163.788328658941
total_rewards_max            9684.168413198684
total_rewards_min            2346.583377738473
Number of train steps total  308000
Number of env steps total    387000
Number of rollouts total     0
Train Time (s)               115.54089845903218
(Previous) Eval Time (s)     22.96088885003701
Sample Time (s)              17.407338412012905
Epoch Time (s)               155.9091257210821
Total Train Time (s)         11704.505401883274
Epoch                        76
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:51:23.505945 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #76 | Epoch Duration: 155.72878313064575
2020-01-13 11:51:23.506101 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #76 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3315327
Z variance train             0.015106918
KL Divergence                39.159603
KL Loss                      3.9159603
QF Loss                      250.95102
VF Loss                      122.445816
Policy Loss                  -3542.117
Q Predictions Mean           3539.26
Q Predictions Std            544.51337
Q Predictions Max            4197.4683
Q Predictions Min            736.29663
V Predictions Mean           3544.0808
V Predictions Std            539.8858
V Predictions Max            4201.2856
V Predictions Min            744.51733
Log Pis Mean                 5.2141643
Log Pis Std                  3.6153393
Log Pis Max                  15.860195
Log Pis Min                  -3.9964309
Policy mu Mean               -0.07640494
Policy mu Std                1.3688828
Policy mu Max                3.0735488
Policy mu Min                -3.3008935
Policy log std Mean          -0.8653571
Policy log std Std           0.45676863
Policy log std Max           -0.17628098
Policy log std Min           -3.114747
Z mean eval                  3.3510127
Z variance eval              0.0064722397
total_rewards                [9541.77304379 9676.18030688 9597.20606532 9688.63612245 9658.17713133
 9496.53959809 9611.25285913 9322.19458173 9368.77380292 9718.87852265]
total_rewards_mean           9567.96120342979
total_rewards_std            128.75632372956983
total_rewards_max            9718.878522652509
total_rewards_min            9322.194581725085
Number of train steps total  312000
Number of env steps total    392000
Number of rollouts total     0
Train Time (s)               108.81062187207863
(Previous) Eval Time (s)     22.780269108712673
Sample Time (s)              16.38738150615245
Epoch Time (s)               147.97827248694375
Total Train Time (s)         11852.942603080068
Epoch                        77
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:53:51.945269 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #77 | Epoch Duration: 148.4390366077423
2020-01-13 11:53:51.945466 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3522143
Z variance train             0.006470873
KL Divergence                40.52701
KL Loss                      4.0527015
QF Loss                      278.05878
VF Loss                      126.79961
Policy Loss                  -3581.872
Q Predictions Mean           3586.9097
Q Predictions Std            545.07074
Q Predictions Max            4276.1084
Q Predictions Min            729.9324
V Predictions Mean           3587.7656
V Predictions Std            537.4402
V Predictions Max            4278.168
V Predictions Min            747.69037
Log Pis Mean                 4.896769
Log Pis Std                  3.4150124
Log Pis Max                  13.940433
Log Pis Min                  -5.5241575
Policy mu Mean               -0.10203282
Policy mu Std                1.3635345
Policy mu Max                2.764274
Policy mu Min                -3.1646967
Policy log std Mean          -0.87459797
Policy log std Std           0.45585194
Policy log std Max           -0.17388237
Policy log std Min           -3.2037036
Z mean eval                  3.355577
Z variance eval              0.01201407
total_rewards                [9355.72071904 9555.30253564 9466.6251618  9687.30629079 9477.58479722
 9605.5667503  9494.77407951 9426.99011399 9380.35811112 9440.67253281]
total_rewards_mean           9489.090109222965
total_rewards_std            96.80940776033025
total_rewards_max            9687.306290785395
total_rewards_min            9355.720719042767
Number of train steps total  316000
Number of env steps total    397000
Number of rollouts total     0
Train Time (s)               116.03680856293067
(Previous) Eval Time (s)     23.240717665757984
Sample Time (s)              15.892886739224195
Epoch Time (s)               155.17041296791285
Total Train Time (s)         12007.838694123086
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:56:26.842565 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #78 | Epoch Duration: 154.89695763587952
2020-01-13 11:56:26.842728 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3536713
Z variance train             0.0120210005
KL Divergence                40.048172
KL Loss                      4.0048175
QF Loss                      369.44025
VF Loss                      220.17511
Policy Loss                  -3554.9512
Q Predictions Mean           3554.9653
Q Predictions Std            666.4297
Q Predictions Max            4285.933
Q Predictions Min            720.0857
V Predictions Mean           3562.6604
V Predictions Std            664.2349
V Predictions Max            4295.864
V Predictions Min            737.74384
Log Pis Mean                 5.042969
Log Pis Std                  3.820838
Log Pis Max                  15.775566
Log Pis Min                  -5.337655
Policy mu Mean               -0.12651785
Policy mu Std                1.3680366
Policy mu Max                3.096446
Policy mu Min                -2.9188933
Policy log std Mean          -0.87427694
Policy log std Std           0.46720585
Policy log std Max           -0.1349813
Policy log std Min           -3.2269444
Z mean eval                  3.361379
Z variance eval              0.0070340843
total_rewards                [9413.19477801 9415.41313212 9394.35291517 9525.08547977 9508.03524655
 9411.12309599 9522.59397459 9623.2327151  9414.01634178 9473.79107676]
total_rewards_mean           9470.08387558278
total_rewards_std            70.19364911648366
total_rewards_max            9623.232715100674
total_rewards_min            9394.352915165133
Number of train steps total  320000
Number of env steps total    402000
Number of rollouts total     0
Train Time (s)               115.35104324901477
(Previous) Eval Time (s)     22.966977381147444
Sample Time (s)              16.887034901883453
Epoch Time (s)               155.20505553204566
Total Train Time (s)         12162.549758031499
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:59:01.558608 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #79 | Epoch Duration: 154.71572184562683
2020-01-13 11:59:01.558897 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #79 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3610578
Z variance train             0.007044965
KL Divergence                40.574326
KL Loss                      4.0574327
QF Loss                      385.96936
VF Loss                      214.65211
Policy Loss                  -3504.5269
Q Predictions Mean           3511.7778
Q Predictions Std            692.92615
Q Predictions Max            4228.856
Q Predictions Min            707.04675
V Predictions Mean           3516.3252
V Predictions Std            687.6536
V Predictions Max            4224.054
V Predictions Min            713.2465
Log Pis Mean                 5.446905
Log Pis Std                  3.9072902
Log Pis Max                  16.893335
Log Pis Min                  -3.5983481
Policy mu Mean               -0.09538912
Policy mu Std                1.3773279
Policy mu Max                3.2173138
Policy mu Min                -3.1474013
Policy log std Mean          -0.8804173
Policy log std Std           0.46537435
Policy log std Max           -0.09291983
Policy log std Min           -3.0317583
Z mean eval                  3.351792
Z variance eval              0.009166891
total_rewards                [9386.61561258 9468.80553587 9667.76057949 9452.26513607 9581.22895964
 9326.13189222 9530.42902066 9304.71423128 9626.22829501 9592.4608451 ]
total_rewards_mean           9493.664010791712
total_rewards_std            120.09296626608646
total_rewards_max            9667.760579486923
total_rewards_min            9304.714231275226
Number of train steps total  324000
Number of env steps total    407000
Number of rollouts total     0
Train Time (s)               116.29440924106166
(Previous) Eval Time (s)     22.477297235745937
Sample Time (s)              16.00653186859563
Epoch Time (s)               154.77823834540322
Total Train Time (s)         12317.178787097335
Epoch                        80
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:01:36.186080 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #80 | Epoch Duration: 154.62698340415955
2020-01-13 12:01:36.186235 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #80 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3523414
Z variance train             0.009176208
KL Divergence                40.474674
KL Loss                      4.0474677
QF Loss                      249.49335
VF Loss                      93.61436
Policy Loss                  -3575.464
Q Predictions Mean           3578.8071
Q Predictions Std            574.30524
Q Predictions Max            4321.604
Q Predictions Min            653.79407
V Predictions Mean           3570.4443
V Predictions Std            569.3991
V Predictions Max            4298.9766
V Predictions Min            645.53076
Log Pis Mean                 4.953103
Log Pis Std                  3.7931833
Log Pis Max                  17.3562
Log Pis Min                  -4.555927
Policy mu Mean               -0.14332406
Policy mu Std                1.3354207
Policy mu Max                3.6217027
Policy mu Min                -4.1484623
Policy log std Mean          -0.88951874
Policy log std Std           0.47296694
Policy log std Max           0.042911768
Policy log std Min           -3.220768
Z mean eval                  3.3503795
Z variance eval              0.022739481
total_rewards                [9547.70769578 9561.66808621 9588.03864861 9460.5706251  9387.05538346
 9602.17519437 9341.8252008  9603.26780619 9344.84774823 9471.17908372]
total_rewards_mean           9490.83354724744
total_rewards_std            99.15989505670703
total_rewards_max            9603.267806191408
total_rewards_min            9341.825200799298
Number of train steps total  328000
Number of env steps total    412000
Number of rollouts total     0
Train Time (s)               111.7310673580505
(Previous) Eval Time (s)     22.325744600966573
Sample Time (s)              16.39988266583532
Epoch Time (s)               150.4566946248524
Total Train Time (s)         12468.058856944554
Epoch                        81
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:04:07.067748 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #81 | Epoch Duration: 150.8813920021057
2020-01-13 12:04:07.067955 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #81 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3491807
Z variance train             0.022772038
KL Divergence                39.65535
KL Loss                      3.965535
QF Loss                      278.39325
VF Loss                      360.72214
Policy Loss                  -3566.1204
Q Predictions Mean           3568.6018
Q Predictions Std            609.3722
Q Predictions Max            4310.733
Q Predictions Min            711.8893
V Predictions Mean           3581.9624
V Predictions Std            607.9778
V Predictions Max            4311.289
V Predictions Min            706.61945
Log Pis Mean                 4.8388853
Log Pis Std                  3.3891962
Log Pis Max                  12.846286
Log Pis Min                  -4.314707
Policy mu Mean               -0.120226644
Policy mu Std                1.3492732
Policy mu Max                2.865824
Policy mu Min                -3.041879
Policy log std Mean          -0.86772823
Policy log std Std           0.46667835
Policy log std Max           0.24231732
Policy log std Min           -3.1178508
Z mean eval                  3.3578858
Z variance eval              0.015278807
total_rewards                [9779.57927669 9655.95905425 9896.57679891 9713.99052655 9701.0925289
 5990.6529857  9860.40560969 9736.42244387 9709.83946737 9731.88288703]
total_rewards_mean           9377.640157895617
total_rewards_std            1131.1665798905838
total_rewards_max            9896.5767989144
total_rewards_min            5990.652985701545
Number of train steps total  332000
Number of env steps total    417000
Number of rollouts total     0
Train Time (s)               113.86780890682712
(Previous) Eval Time (s)     22.750134625006467
Sample Time (s)              15.63635983504355
Epoch Time (s)               152.25430336687714
Total Train Time (s)         12620.519256254192
Epoch                        82
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:06:39.531239 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #82 | Epoch Duration: 152.46312737464905
2020-01-13 12:06:39.531458 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #82 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3574996
Z variance train             0.015270928
KL Divergence                38.880394
KL Loss                      3.8880394
QF Loss                      268.29272
VF Loss                      242.09096
Policy Loss                  -3487.8765
Q Predictions Mean           3490.5278
Q Predictions Std            751.22864
Q Predictions Max            4313.5996
Q Predictions Min            709.1231
V Predictions Mean           3497.065
V Predictions Std            742.4548
V Predictions Max            4294.9595
V Predictions Min            728.0562
Log Pis Mean                 5.181021
Log Pis Std                  3.8215659
Log Pis Max                  23.184612
Log Pis Min                  -4.297097
Policy mu Mean               -0.10023331
Policy mu Std                1.3439077
Policy mu Max                3.0390282
Policy mu Min                -4.4098196
Policy log std Mean          -0.8866939
Policy log std Std           0.46409386
Policy log std Max           -0.092642784
Policy log std Min           -3.0814652
Z mean eval                  3.3663335
Z variance eval              0.0038273267
total_rewards                [9638.17247901 9487.1406617  9821.62714358 9720.3527865  9777.00870871
 9837.58195345 9797.24886158 9734.7752624  9793.8929124  9767.52684742]
total_rewards_mean           9737.532761673978
total_rewards_std            99.57590343291957
total_rewards_max            9837.581953445071
total_rewards_min            9487.140661699132
Number of train steps total  336000
Number of env steps total    422000
Number of rollouts total     0
Train Time (s)               117.02641464676708
(Previous) Eval Time (s)     22.958644608967006
Sample Time (s)              15.699275881052017
Epoch Time (s)               155.6843351367861
Total Train Time (s)         12776.291505330242
Epoch                        83
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:09:15.305443 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #83 | Epoch Duration: 155.77379369735718
2020-01-13 12:09:15.305707 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3644001
Z variance train             0.0038106642
KL Divergence                42.17828
KL Loss                      4.2178283
QF Loss                      306.9472
VF Loss                      233.5017
Policy Loss                  -3546.0103
Q Predictions Mean           3542.3735
Q Predictions Std            665.2783
Q Predictions Max            4280.721
Q Predictions Min            687.1648
V Predictions Mean           3540.3262
V Predictions Std            649.0328
V Predictions Max            4272.0107
V Predictions Min            712.3601
Log Pis Mean                 5.2520237
Log Pis Std                  3.8036954
Log Pis Max                  13.790169
Log Pis Min                  -5.964398
Policy mu Mean               -0.11098812
Policy mu Std                1.381564
Policy mu Max                2.9382389
Policy mu Min                -3.0891333
Policy log std Mean          -0.8886846
Policy log std Std           0.487915
Policy log std Max           -0.0475443
Policy log std Min           -3.1702454
Z mean eval                  3.3571835
Z variance eval              0.0043074656
total_rewards                [9680.45101814 9742.01639362 9673.12867044 9534.60984797 9930.90553225
 9696.40239256 9688.91155655 9774.08196935 9673.89463969 9826.21709177]
total_rewards_mean           9722.061911234337
total_rewards_std            100.45390731472091
total_rewards_max            9930.905532253508
total_rewards_min            9534.609847974754
Number of train steps total  340000
Number of env steps total    427000
Number of rollouts total     0
Train Time (s)               115.14436462987214
(Previous) Eval Time (s)     23.047829766292125
Sample Time (s)              16.503474716562778
Epoch Time (s)               154.69566911272705
Total Train Time (s)         12931.238565695006
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:11:50.256242 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #84 | Epoch Duration: 154.9503185749054
2020-01-13 12:11:50.256516 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #84 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.357509
Z variance train             0.0043125697
KL Divergence                42.326675
KL Loss                      4.2326674
QF Loss                      282.5667
VF Loss                      109.16291
Policy Loss                  -3525.1147
Q Predictions Mean           3525.5464
Q Predictions Std            666.632
Q Predictions Max            4331.4526
Q Predictions Min            724.1459
V Predictions Mean           3520.6396
V Predictions Std            661.0731
V Predictions Max            4310.185
V Predictions Min            733.8321
Log Pis Mean                 5.532323
Log Pis Std                  3.830499
Log Pis Max                  16.170593
Log Pis Min                  -4.643483
Policy mu Mean               -0.06862482
Policy mu Std                1.4001563
Policy mu Max                3.2954543
Policy mu Min                -3.2793515
Policy log std Mean          -0.8507717
Policy log std Std           0.46842766
Policy log std Max           -0.13099629
Policy log std Min           -3.262535
Z mean eval                  3.3559613
Z variance eval              0.0015112432
total_rewards                [9495.80446474 9803.66166783 9716.88035295 9600.7859691  9754.89261233
 9698.19808714 9713.20693672 9763.06971665 9573.11962031 9675.86213453]
total_rewards_mean           9679.548156231269
total_rewards_std            90.68465940830436
total_rewards_max            9803.661667829467
total_rewards_min            9495.804464740606
Number of train steps total  344000
Number of env steps total    432000
Number of rollouts total     0
Train Time (s)               111.59970424836501
(Previous) Eval Time (s)     23.302171380259097
Sample Time (s)              15.671796306036413
Epoch Time (s)               150.57367193466052
Total Train Time (s)         13081.311917562969
Epoch                        85
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:14:20.329472 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #85 | Epoch Duration: 150.0727574825287
2020-01-13 12:14:20.329669 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #85 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3547282
Z variance train             0.0015122571
KL Divergence                44.538887
KL Loss                      4.453889
QF Loss                      320.93024
VF Loss                      100.58473
Policy Loss                  -3579.5981
Q Predictions Mean           3576.7588
Q Predictions Std            719.01984
Q Predictions Max            4314.1826
Q Predictions Min            745.32544
V Predictions Mean           3578.1406
V Predictions Std            712.4533
V Predictions Max            4297.8374
V Predictions Min            774.2337
Log Pis Mean                 5.2265167
Log Pis Std                  3.5681202
Log Pis Max                  15.324054
Log Pis Min                  -5.8434353
Policy mu Mean               -0.066104606
Policy mu Std                1.382739
Policy mu Max                3.2578146
Policy mu Min                -3.2074013
Policy log std Mean          -0.8769498
Policy log std Std           0.46832567
Policy log std Max           -0.10553193
Policy log std Min           -3.0891302
Z mean eval                  3.3578346
Z variance eval              0.0011229666
total_rewards                [9457.82175414 9693.80198078 9582.69427458 9580.16972251 9611.19333939
 9645.01462453 9736.73196888 9488.62832926 9659.71112245 9511.95980803]
total_rewards_mean           9596.772692453735
total_rewards_std            86.12166931808213
total_rewards_max            9736.731968881137
total_rewards_min            9457.821754143984
Number of train steps total  348000
Number of env steps total    437000
Number of rollouts total     0
Train Time (s)               112.47366007231176
(Previous) Eval Time (s)     22.800985565874726
Sample Time (s)              16.089714402798563
Epoch Time (s)               151.36436004098505
Total Train Time (s)         13232.479831692297
Epoch                        86
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:16:51.501259 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #86 | Epoch Duration: 151.17141008377075
2020-01-13 12:16:51.501547 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #86 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3589387
Z variance train             0.0011205666
KL Divergence                44.91861
KL Loss                      4.491861
QF Loss                      298.3164
VF Loss                      110.68388
Policy Loss                  -3604.7927
Q Predictions Mean           3600.7612
Q Predictions Std            551.31604
Q Predictions Max            4346.9634
Q Predictions Min            749.1649
V Predictions Mean           3605.0122
V Predictions Std            548.6749
V Predictions Max            4350.589
V Predictions Min            755.6525
Log Pis Mean                 5.0448914
Log Pis Std                  3.605228
Log Pis Max                  14.337148
Log Pis Min                  -3.6704545
Policy mu Mean               -0.13241722
Policy mu Std                1.331702
Policy mu Max                3.0101092
Policy mu Min                -2.957913
Policy log std Mean          -0.8950903
Policy log std Std           0.48457843
Policy log std Max           -0.104656726
Policy log std Min           -3.096925
Z mean eval                  3.3398864
Z variance eval              0.0016527504
total_rewards                [1168.26713184 9693.99522681 8451.03594063 9758.31209589 9619.85189347
 5816.09232726 9721.863508   9643.88228319 9672.74928682 9838.18148083]
total_rewards_mean           8338.423117473158
total_rewards_std            2663.259726469007
total_rewards_max            9838.18148082783
total_rewards_min            1168.2671318355096
Number of train steps total  352000
Number of env steps total    442000
Number of rollouts total     0
Train Time (s)               112.51012570410967
(Previous) Eval Time (s)     22.607730793301016
Sample Time (s)              16.76005276106298
Epoch Time (s)               151.87790925847366
Total Train Time (s)         13384.180050386582
Epoch                        87
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:19:23.203707 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #87 | Epoch Duration: 151.7019054889679
2020-01-13 12:19:23.204012 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3415947
Z variance train             0.0016557295
KL Divergence                44.63852
KL Loss                      4.463852
QF Loss                      262.0558
VF Loss                      360.9286
Policy Loss                  -3652.117
Q Predictions Mean           3646.691
Q Predictions Std            512.1003
Q Predictions Max            4312.403
Q Predictions Min            759.2493
V Predictions Mean           3635.9504
V Predictions Std            503.61218
V Predictions Max            4287.11
V Predictions Min            756.1448
Log Pis Mean                 4.8286095
Log Pis Std                  3.561214
Log Pis Max                  13.988458
Log Pis Min                  -6.1367545
Policy mu Mean               -0.14501785
Policy mu Std                1.3168298
Policy mu Max                2.9322243
Policy mu Min                -3.0550973
Policy log std Mean          -0.8772134
Policy log std Std           0.45829841
Policy log std Max           -0.16177309
Policy log std Min           -3.1724315
Z mean eval                  3.3415534
Z variance eval              0.015119024
total_rewards                [9561.8748053  9720.68781411 9851.62573443 9781.08349385 9915.26500517
 9808.4624586  9927.70869576 9948.40271687 9972.59221573 9864.5120866 ]
total_rewards_mean           9835.22150264383
total_rewards_std            118.00505649192618
total_rewards_max            9972.59221573226
total_rewards_min            9561.874805303087
Number of train steps total  356000
Number of env steps total    447000
Number of rollouts total     0
Train Time (s)               113.02076843567193
(Previous) Eval Time (s)     22.431419871747494
Sample Time (s)              16.475363945122808
Epoch Time (s)               151.92755225254223
Total Train Time (s)         13536.34980137879
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:21:55.376326 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #88 | Epoch Duration: 152.17208337783813
2020-01-13 12:21:55.376616 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #88 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3435636
Z variance train             0.01512479
KL Divergence                41.87399
KL Loss                      4.187399
QF Loss                      240.97437
VF Loss                      155.5169
Policy Loss                  -3472.0208
Q Predictions Mean           3464.7114
Q Predictions Std            770.68005
Q Predictions Max            4308.612
Q Predictions Min            698.46716
V Predictions Mean           3466.0645
V Predictions Std            763.65765
V Predictions Max            4300.4814
V Predictions Min            693.7124
Log Pis Mean                 4.652382
Log Pis Std                  3.889395
Log Pis Max                  19.410603
Log Pis Min                  -9.890769
Policy mu Mean               -0.0797892
Policy mu Std                1.3155465
Policy mu Max                2.7644205
Policy mu Min                -3.3335938
Policy log std Mean          -0.8600693
Policy log std Std           0.434207
Policy log std Max           -0.09224039
Policy log std Min           -3.1438217
Z mean eval                  3.3635173
Z variance eval              0.0032380621
total_rewards                [9940.79002609 9627.09137972 9772.60801794 9985.85748347 9753.17307082
 9693.04692398 9755.37989213 9967.98163929 9815.2545887  9665.93096751]
total_rewards_mean           9797.711398965219
total_rewards_std            121.24680828243092
total_rewards_max            9985.857483465277
total_rewards_min            9627.09137971869
Number of train steps total  360000
Number of env steps total    452000
Number of rollouts total     0
Train Time (s)               112.32054239884019
(Previous) Eval Time (s)     22.675629287958145
Sample Time (s)              16.652708143927157
Epoch Time (s)               151.6488798307255
Total Train Time (s)         13688.205241367687
Epoch                        89
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:24:27.233655 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #89 | Epoch Duration: 151.8568058013916
2020-01-13 12:24:27.233912 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #89 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3652146
Z variance train             0.003233082
KL Divergence                43.388687
KL Loss                      4.3388686
QF Loss                      207.33746
VF Loss                      95.06862
Policy Loss                  -3646.0635
Q Predictions Mean           3643.0454
Q Predictions Std            554.60284
Q Predictions Max            4335.326
Q Predictions Min            718.4929
V Predictions Mean           3645.7134
V Predictions Std            548.5218
V Predictions Max            4333.668
V Predictions Min            735.31433
Log Pis Mean                 5.315172
Log Pis Std                  3.6161108
Log Pis Max                  14.684476
Log Pis Min                  -7.261736
Policy mu Mean               -0.13291635
Policy mu Std                1.3564186
Policy mu Max                3.5175517
Policy mu Min                -3.2768688
Policy log std Mean          -0.88779163
Policy log std Std           0.4503658
Policy log std Max           -0.123075485
Policy log std Min           -3.2418356
Z mean eval                  3.3576775
Z variance eval              0.009100052
total_rewards                [9758.03887824 9838.29587297 9632.69001216 9991.34914139 9460.09310479
 9894.30075232 9706.3351104  9647.90789874 9732.21496593 9784.83569659]
total_rewards_mean           9744.606143354722
total_rewards_std            140.8221776134062
total_rewards_max            9991.349141393222
total_rewards_min            9460.093104790287
Number of train steps total  364000
Number of env steps total    457000
Number of rollouts total     0
Train Time (s)               112.60284527391195
(Previous) Eval Time (s)     22.88325067004189
Sample Time (s)              15.829393961001188
Epoch Time (s)               151.31548990495503
Total Train Time (s)         13839.833504680544
Epoch                        90
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:26:58.863094 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #90 | Epoch Duration: 151.6289827823639
2020-01-13 12:26:58.863297 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #90 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3582444
Z variance train             0.00908179
KL Divergence                42.250805
KL Loss                      4.2250805
QF Loss                      272.4172
VF Loss                      62.453815
Policy Loss                  -3655.5762
Q Predictions Mean           3659.0798
Q Predictions Std            613.276
Q Predictions Max            4406.0137
Q Predictions Min            767.6734
V Predictions Mean           3656.4421
V Predictions Std            608.2045
V Predictions Max            4393.149
V Predictions Min            771.32983
Log Pis Mean                 5.336956
Log Pis Std                  4.140762
Log Pis Max                  17.08361
Log Pis Min                  -4.016792
Policy mu Mean               -0.15689111
Policy mu Std                1.3862054
Policy mu Max                3.3549957
Policy mu Min                -3.5505216
Policy log std Mean          -0.8837443
Policy log std Std           0.48350388
Policy log std Max           0.20788074
Policy log std Min           -3.3676608
Z mean eval                  3.3494534
Z variance eval              0.0026914252
total_rewards                [ 9591.11008705  9880.52363236  9809.86246259  9847.89262118
  9804.70044837  9665.22980014  9892.20688629  9901.61101857
  9790.59246086 10111.4811726 ]
total_rewards_mean           9829.521059000152
total_rewards_std            133.3852037598285
total_rewards_max            10111.481172598309
total_rewards_min            9591.11008705372
Number of train steps total  368000
Number of env steps total    462000
Number of rollouts total     0
Train Time (s)               112.5869827712886
(Previous) Eval Time (s)     23.19646980240941
Sample Time (s)              16.54763352451846
Epoch Time (s)               152.33108609821647
Total Train Time (s)         13991.904672625475
Epoch                        91
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:29:30.939756 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #91 | Epoch Duration: 152.07626795768738
2020-01-13 12:29:30.940098 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #91 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.347653
Z variance train             0.0026907003
KL Divergence                42.737648
KL Loss                      4.273765
QF Loss                      327.1728
VF Loss                      88.33396
Policy Loss                  -3609.901
Q Predictions Mean           3612.4346
Q Predictions Std            677.32855
Q Predictions Max            4415.37
Q Predictions Min            763.9064
V Predictions Mean           3612.982
V Predictions Std            669.79803
V Predictions Max            4404.965
V Predictions Min            800.4341
Log Pis Mean                 5.133633
Log Pis Std                  3.7655454
Log Pis Max                  16.261578
Log Pis Min                  -3.7665339
Policy mu Mean               -0.1035796
Policy mu Std                1.3581766
Policy mu Max                2.9082766
Policy mu Min                -3.0668662
Policy log std Mean          -0.88664716
Policy log std Std           0.46706337
Policy log std Max           -0.08105236
Policy log std Min           -3.1476202
Z mean eval                  3.336617
Z variance eval              0.009533231
total_rewards                [9653.56810306 9791.38044699 9679.40115419 9777.98291295 9739.3268813
 9743.81364972 9815.98105958 9761.1446149  9791.14558741 9794.13852477]
total_rewards_mean           9754.788293487249
total_rewards_std            49.82014936826686
total_rewards_max            9815.981059577345
total_rewards_min            9653.568103059513
Number of train steps total  372000
Number of env steps total    467000
Number of rollouts total     0
Train Time (s)               115.56923331692815
(Previous) Eval Time (s)     22.941320194862783
Sample Time (s)              16.982197938952595
Epoch Time (s)               155.49275145074353
Total Train Time (s)         14147.000212475657
Epoch                        92
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:32:06.034730 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #92 | Epoch Duration: 155.094402551651
2020-01-13 12:32:06.034940 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #92 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3352764
Z variance train             0.00951972
KL Divergence                40.117424
KL Loss                      4.0117426
QF Loss                      318.80432
VF Loss                      114.383484
Policy Loss                  -3639.8086
Q Predictions Mean           3640.7485
Q Predictions Std            692.5093
Q Predictions Max            4451.5796
Q Predictions Min            785.1162
V Predictions Mean           3642.7544
V Predictions Std            684.68005
V Predictions Max            4445.18
V Predictions Min            802.21246
Log Pis Mean                 5.135238
Log Pis Std                  3.8750339
Log Pis Max                  14.788235
Log Pis Min                  -5.2965026
Policy mu Mean               -0.11177975
Policy mu Std                1.369794
Policy mu Max                2.991226
Policy mu Min                -2.9857469
Policy log std Mean          -0.86844295
Policy log std Std           0.45878616
Policy log std Max           -0.14371061
Policy log std Min           -3.5006683
Z mean eval                  3.3456109
Z variance eval              0.0055142613
total_rewards                [3469.84362621 9660.3532779  9511.98830968 9463.9613163  9527.09367969
 9355.88115349 9672.97892623 9272.06923717 9445.21342517 9356.62025593]
total_rewards_mean           8873.600320775473
total_rewards_std            1805.356301726844
total_rewards_max            9672.978926226491
total_rewards_min            3469.8436262073355
Number of train steps total  376000
Number of env steps total    472000
Number of rollouts total     0
Train Time (s)               112.03227051906288
(Previous) Eval Time (s)     22.54267140198499
Sample Time (s)              17.386570684146136
Epoch Time (s)               151.961512605194
Total Train Time (s)         14298.679992737249
Epoch                        93
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:34:37.716833 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #93 | Epoch Duration: 151.68172192573547
2020-01-13 12:34:37.717063 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.344942
Z variance train             0.0055232714
KL Divergence                41.26429
KL Loss                      4.126429
QF Loss                      251.90652
VF Loss                      232.90771
Policy Loss                  -3595.5132
Q Predictions Mean           3598.76
Q Predictions Std            637.4217
Q Predictions Max            4417.969
Q Predictions Min            765.82654
V Predictions Mean           3607.3965
V Predictions Std            634.9219
V Predictions Max            4417.9673
V Predictions Min            768.01
Log Pis Mean                 5.0790176
Log Pis Std                  3.9691298
Log Pis Max                  17.786247
Log Pis Min                  -7.6415915
Policy mu Mean               -0.10480874
Policy mu Std                1.3598241
Policy mu Max                3.0352328
Policy mu Min                -3.7418513
Policy log std Mean          -0.86969525
Policy log std Std           0.4472309
Policy log std Max           0.2297771
Policy log std Min           -3.0266967
Z mean eval                  3.3551643
Z variance eval              0.0034437384
total_rewards                [9501.25710804 9489.73620187 9703.30802181 9534.73523435 9403.78270132
 9638.47430639 9595.51591545 9586.67294051 9641.45606411 9795.49589365]
total_rewards_mean           9589.043438750434
total_rewards_std            107.5901047123053
total_rewards_max            9795.495893649893
total_rewards_min            9403.782701323129
Number of train steps total  380000
Number of env steps total    477000
Number of rollouts total     0
Train Time (s)               115.91435174224898
(Previous) Eval Time (s)     22.262528697028756
Sample Time (s)              16.390455985907465
Epoch Time (s)               154.5673364251852
Total Train Time (s)         14454.392885386944
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:37:13.433877 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #94 | Epoch Duration: 155.71659755706787
2020-01-13 12:37:13.434233 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #94 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.355905
Z variance train             0.0034343028
KL Divergence                41.812325
KL Loss                      4.1812325
QF Loss                      315.11346
VF Loss                      145.8973
Policy Loss                  -3641.1665
Q Predictions Mean           3641.7515
Q Predictions Std            670.2589
Q Predictions Max            4430.044
Q Predictions Min            753.0725
V Predictions Mean           3634.587
V Predictions Std            661.8867
V Predictions Max            4433.18
V Predictions Min            779.7892
Log Pis Mean                 5.392857
Log Pis Std                  3.5245674
Log Pis Max                  13.186185
Log Pis Min                  -3.4687514
Policy mu Mean               -0.0989783
Policy mu Std                1.3597871
Policy mu Max                3.0663795
Policy mu Min                -2.6742015
Policy log std Mean          -0.874008
Policy log std Std           0.4653157
Policy log std Max           -0.12964404
Policy log std Min           -3.1045675
Z mean eval                  3.337376
Z variance eval              0.0032917683
total_rewards                [9659.72399063 9807.97743339 9724.27843017 9647.72178998 9542.37172639
 9716.04728811 9682.05911806 9755.26660777 9655.21510373 9903.13426418]
total_rewards_mean           9709.379575240917
total_rewards_std            93.52734875181906
total_rewards_max            9903.134264182972
total_rewards_min            9542.371726386244
Number of train steps total  384000
Number of env steps total    482000
Number of rollouts total     0
Train Time (s)               117.38002979196608
(Previous) Eval Time (s)     23.41147667495534
Sample Time (s)              16.467670751269907
Epoch Time (s)               157.25917721819133
Total Train Time (s)         14610.852178887464
Epoch                        95
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:39:49.895829 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #95 | Epoch Duration: 156.46121406555176
2020-01-13 12:39:49.896308 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #95 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3347614
Z variance train             0.003300768
KL Divergence                42.805084
KL Loss                      4.2805085
QF Loss                      272.49988
VF Loss                      114.34032
Policy Loss                  -3652.111
Q Predictions Mean           3650.4297
Q Predictions Std            707.6548
Q Predictions Max            4403.565
Q Predictions Min            755.8038
V Predictions Mean           3656.92
V Predictions Std            701.6798
V Predictions Max            4412.436
V Predictions Min            766.4913
Log Pis Mean                 4.973942
Log Pis Std                  3.7624547
Log Pis Max                  15.198187
Log Pis Min                  -3.783895
Policy mu Mean               -0.15110521
Policy mu Std                1.353279
Policy mu Max                3.17981
Policy mu Min                -2.9313219
Policy log std Mean          -0.8537145
Policy log std Std           0.44169492
Policy log std Max           0.0916183
Policy log std Min           -3.237782
Z mean eval                  3.328551
Z variance eval              0.008203042
total_rewards                [9472.35876574 9738.26368999 9668.90551835 9801.58829794 9730.52569814
 9727.52157983 9581.83020609 9489.30927294 9572.33729718 9811.68870117]
total_rewards_mean           9659.43290273631
total_rewards_std            117.01746309870869
total_rewards_max            9811.68870116985
total_rewards_min            9472.358765735047
Number of train steps total  388000
Number of env steps total    487000
Number of rollouts total     0
Train Time (s)               114.84330450510606
(Previous) Eval Time (s)     22.613203381653875
Sample Time (s)              16.999887683894485
Epoch Time (s)               154.45639557065442
Total Train Time (s)         14764.856138881296
Epoch                        96
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:42:23.899730 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #96 | Epoch Duration: 154.00314474105835
2020-01-13 12:42:23.899978 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3267944
Z variance train             0.00820539
KL Divergence                41.72706
KL Loss                      4.172706
QF Loss                      450.86285
VF Loss                      88.1252
Policy Loss                  -3733.2002
Q Predictions Mean           3730.5615
Q Predictions Std            504.34256
Q Predictions Max            4455.8926
Q Predictions Min            843.9496
V Predictions Mean           3732.6577
V Predictions Std            500.46436
V Predictions Max            4451.706
V Predictions Min            804.67896
Log Pis Mean                 4.9808073
Log Pis Std                  3.424604
Log Pis Max                  14.826147
Log Pis Min                  -7.278683
Policy mu Mean               -0.08947242
Policy mu Std                1.3296598
Policy mu Max                2.952079
Policy mu Min                -3.1303256
Policy log std Mean          -0.9197097
Policy log std Std           0.46906936
Policy log std Max           -0.04271713
Policy log std Min           -3.1220598
Z mean eval                  3.334041
Z variance eval              0.0070990473
total_rewards                [9704.80542827 9419.29374142 9737.5955851  9690.3167101  9784.47023773
 9661.76880332 9616.78034736 9643.66110622 9717.40662826 9607.13062684]
total_rewards_mean           9658.322921461795
total_rewards_std            95.17386158453597
total_rewards_max            9784.470237727523
total_rewards_min            9419.293741424908
Number of train steps total  392000
Number of env steps total    492000
Number of rollouts total     0
Train Time (s)               110.59187303483486
(Previous) Eval Time (s)     22.159656852018088
Sample Time (s)              15.777489388827235
Epoch Time (s)               148.52901927568018
Total Train Time (s)         14913.86455985671
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:44:52.909619 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #97 | Epoch Duration: 149.00940251350403
2020-01-13 12:44:52.909862 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #97 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3358238
Z variance train             0.007085122
KL Divergence                40.46583
KL Loss                      4.046583
QF Loss                      262.66876
VF Loss                      166.86328
Policy Loss                  -3675.0215
Q Predictions Mean           3669.2407
Q Predictions Std            711.16455
Q Predictions Max            4415.5884
Q Predictions Min            728.54126
V Predictions Mean           3667.228
V Predictions Std            703.44775
V Predictions Max            4421.1196
V Predictions Min            758.3384
Log Pis Mean                 5.1939754
Log Pis Std                  3.694126
Log Pis Max                  18.615011
Log Pis Min                  -3.5037072
Policy mu Mean               -0.06289112
Policy mu Std                1.3634092
Policy mu Max                3.364873
Policy mu Min                -3.4194155
Policy log std Mean          -0.91103834
Policy log std Std           0.483565
Policy log std Max           -0.13496014
Policy log std Min           -3.191496
Z mean eval                  3.3232994
Z variance eval              0.01712574
total_rewards                [9761.94203511 9929.06511437 6304.09056482 9806.86868484 9880.22351994
 9909.33399322 9844.80625641 9938.80987234 9689.52749228 9716.66441359]
total_rewards_mean           9478.13319469243
total_rewards_std            1061.243057837286
total_rewards_max            9938.809872335267
total_rewards_min            6304.090564820858
Number of train steps total  396000
Number of env steps total    497000
Number of rollouts total     0
Train Time (s)               115.59433436114341
(Previous) Eval Time (s)     22.639774876181036
Sample Time (s)              15.524867986794561
Epoch Time (s)               153.758977224119
Total Train Time (s)         15068.313332884107
Epoch                        98
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:47:27.362478 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #98 | Epoch Duration: 154.45244002342224
2020-01-13 12:47:27.362736 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #98 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3229527
Z variance train             0.01701823
KL Divergence                40.191586
KL Loss                      4.019159
QF Loss                      609.3578
VF Loss                      436.95773
Policy Loss                  -3772.5864
Q Predictions Mean           3775.1597
Q Predictions Std            537.7796
Q Predictions Max            4457.2715
Q Predictions Min            742.9057
V Predictions Mean           3786.442
V Predictions Std            529.9068
V Predictions Max            4463.025
V Predictions Min            792.361
Log Pis Mean                 5.246085
Log Pis Std                  3.555423
Log Pis Max                  13.662275
Log Pis Min                  -3.6382997
Policy mu Mean               -0.06376399
Policy mu Std                1.3622047
Policy mu Max                3.1873388
Policy mu Min                -3.0561047
Policy log std Mean          -0.88624173
Policy log std Std           0.4689948
Policy log std Max           -0.17523247
Policy log std Min           -3.376042
Z mean eval                  3.3302703
Z variance eval              0.012841776
total_rewards                [ 9731.14156687 10037.69461731  9825.47496    10048.19980972
  9829.61622259  9811.394373    7073.90674705  9816.02181151
  9840.88185432  9670.89987253]
total_rewards_mean           9568.523183489418
total_rewards_std            838.9793449033158
total_rewards_max            10048.199809717993
total_rewards_min            7073.906747050275
Number of train steps total  400000
Number of env steps total    502000
Number of rollouts total     0
Train Time (s)               117.23518055584282
(Previous) Eval Time (s)     23.332978394813836
Sample Time (s)              16.442298544105142
Epoch Time (s)               157.0104574947618
Total Train Time (s)         15225.060120827984
Epoch                        99
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:50:04.109037 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #99 | Epoch Duration: 156.74611902236938
2020-01-13 12:50:04.109268 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #99 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3280234
Z variance train             0.012826266
KL Divergence                40.349678
KL Loss                      4.034968
QF Loss                      257.60077
VF Loss                      118.10318
Policy Loss                  -3753.8381
Q Predictions Mean           3750.96
Q Predictions Std            624.8125
Q Predictions Max            4521.902
Q Predictions Min            768.8141
V Predictions Mean           3756.6768
V Predictions Std            620.77875
V Predictions Max            4519.7627
V Predictions Min            774.51843
Log Pis Mean                 5.486839
Log Pis Std                  3.6630237
Log Pis Max                  16.223383
Log Pis Min                  -5.9137216
Policy mu Mean               -0.092012234
Policy mu Std                1.428527
Policy mu Max                3.163085
Policy mu Min                -3.4798143
Policy log std Mean          -0.88038415
Policy log std Std           0.4522753
Policy log std Max           -0.1655064
Policy log std Min           -3.208674
Z mean eval                  3.3564591
Z variance eval              0.007719394
total_rewards                [9691.32638377 9772.37906984 9949.94501813 9659.55738659 9704.82055687
 9971.66626815 9802.31021502 9635.31244468 9814.05848776 9769.48635938]
total_rewards_mean           9777.086219018249
total_rewards_std            107.84923667260728
total_rewards_max            9971.66626814562
total_rewards_min            9635.312444682611
Number of train steps total  404000
Number of env steps total    507000
Number of rollouts total     0
Train Time (s)               116.29573408607394
(Previous) Eval Time (s)     23.06834561098367
Sample Time (s)              17.567114875186235
Epoch Time (s)               156.93119457224384
Total Train Time (s)         15381.435492895544
Epoch                        100
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:52:40.488136 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #100 | Epoch Duration: 156.37871980667114
2020-01-13 12:52:40.488345 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #100 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3554077
Z variance train             0.0077121994
KL Divergence                41.66225
KL Loss                      4.166225
QF Loss                      617.8651
VF Loss                      181.22252
Policy Loss                  -3739.0908
Q Predictions Mean           3746.4116
Q Predictions Std            522.66296
Q Predictions Max            4446.3457
Q Predictions Min            759.17596
V Predictions Mean           3748.4548
V Predictions Std            517.31805
V Predictions Max            4436.465
V Predictions Min            765.5386
Log Pis Mean                 5.3152504
Log Pis Std                  3.8615694
Log Pis Max                  17.5168
Log Pis Min                  -5.18486
Policy mu Mean               -0.16351277
Policy mu Std                1.381764
Policy mu Max                2.9365246
Policy mu Min                -3.4645925
Policy log std Mean          -0.8607444
Policy log std Std           0.4734345
Policy log std Max           -0.013636291
Policy log std Min           -3.229783
Z mean eval                  3.3342896
Z variance eval              0.012119653
total_rewards                [ 9662.41981678  9986.32575831 10104.87314948 10028.85379854
 10045.31851011 10049.10655289  9949.44757298  9916.16475618
 10030.63018279 10083.01301444]
total_rewards_mean           9985.615311251384
total_rewards_std            120.74252647605817
total_rewards_max            10104.873149481919
total_rewards_min            9662.419816783979
Number of train steps total  408000
Number of env steps total    512000
Number of rollouts total     0
Train Time (s)               115.81437643896788
(Previous) Eval Time (s)     22.515536647755653
Sample Time (s)              16.347961094696075
Epoch Time (s)               154.6778741814196
Total Train Time (s)         15536.457062427886
Epoch                        101
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:55:15.509460 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #101 | Epoch Duration: 155.0209765434265
2020-01-13 12:55:15.509663 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #101 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.335096
Z variance train             0.012124919
KL Divergence                38.90834
KL Loss                      3.890834
QF Loss                      328.7857
VF Loss                      105.28926
Policy Loss                  -3775.8198
Q Predictions Mean           3779.2441
Q Predictions Std            547.7155
Q Predictions Max            4484.2686
Q Predictions Min            771.8576
V Predictions Mean           3775.2144
V Predictions Std            543.1651
V Predictions Max            4460.911
V Predictions Min            739.81165
Log Pis Mean                 5.504406
Log Pis Std                  3.696885
Log Pis Max                  14.167382
Log Pis Min                  -6.902904
Policy mu Mean               -0.14517201
Policy mu Std                1.3743153
Policy mu Max                3.0647032
Policy mu Min                -2.6638663
Policy log std Mean          -0.885935
Policy log std Std           0.48667103
Policy log std Max           -0.19241518
Policy log std Min           -3.3163855
Z mean eval                  3.3345065
Z variance eval              0.008061295
total_rewards                [ 9444.55637136  9739.73887581 10092.81037042 10232.1556162
 10015.13775747  9789.49390223 10071.98274376  9817.10383488
  9882.55335293  9980.08003506]
total_rewards_mean           9906.561286010601
total_rewards_std            211.85385317634464
total_rewards_max            10232.155616200207
total_rewards_min            9444.556371363098
Number of train steps total  412000
Number of env steps total    517000
Number of rollouts total     0
Train Time (s)               112.48509279405698
(Previous) Eval Time (s)     22.8583269007504
Sample Time (s)              15.966712429188192
Epoch Time (s)               151.31013212399557
Total Train Time (s)         15687.364034221973
Epoch                        102
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:57:46.419821 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #102 | Epoch Duration: 150.90996479988098
2020-01-13 12:57:46.420110 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #102 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3310275
Z variance train             0.008042512
KL Divergence                39.88363
KL Loss                      3.988363
QF Loss                      348.1712
VF Loss                      138.99437
Policy Loss                  -3651.46
Q Predictions Mean           3652.023
Q Predictions Std            729.4982
Q Predictions Max            4482.945
Q Predictions Min            750.81274
V Predictions Mean           3656.4353
V Predictions Std            727.403
V Predictions Max            4491.2603
V Predictions Min            750.47644
Log Pis Mean                 5.053694
Log Pis Std                  3.8377588
Log Pis Max                  14.994763
Log Pis Min                  -4.7098737
Policy mu Mean               -0.07214507
Policy mu Std                1.3616229
Policy mu Max                3.0804014
Policy mu Min                -2.9876308
Policy log std Mean          -0.8815555
Policy log std Std           0.47352913
Policy log std Max           0.040088773
Policy log std Min           -3.0447822
Z mean eval                  3.3281875
Z variance eval              0.010274852
total_rewards                [10192.99346669 10349.76471737 10064.97976675  9965.22375396
 10322.91093449 10063.00982784 10372.20647758 10060.05680673
 10232.46892383 10016.79553967]
total_rewards_mean           10164.041021491388
total_rewards_std            141.64360503322303
total_rewards_max            10372.206477582395
total_rewards_min            9965.22375395624
Number of train steps total  416000
Number of env steps total    522000
Number of rollouts total     0
Train Time (s)               116.40385803300887
(Previous) Eval Time (s)     22.457862661220133
Sample Time (s)              16.164125179871917
Epoch Time (s)               155.02584587410092
Total Train Time (s)         15842.34829659015
Epoch                        103
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:00:21.405900 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #103 | Epoch Duration: 154.9855761528015
2020-01-13 13:00:21.406139 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #103 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3285632
Z variance train             0.010250055
KL Divergence                39.100983
KL Loss                      3.9100983
QF Loss                      833.6776
VF Loss                      138.60574
Policy Loss                  -3870.791
Q Predictions Mean           3869.121
Q Predictions Std            549.75616
Q Predictions Max            4519.575
Q Predictions Min            748.01385
V Predictions Mean           3869.9766
V Predictions Std            545.2956
V Predictions Max            4504.3677
V Predictions Min            749.6933
Log Pis Mean                 5.571663
Log Pis Std                  3.5946717
Log Pis Max                  13.943357
Log Pis Min                  -3.28006
Policy mu Mean               -0.11433494
Policy mu Std                1.3675413
Policy mu Max                3.0282967
Policy mu Min                -3.1949534
Policy log std Mean          -0.8968403
Policy log std Std           0.48207304
Policy log std Max           -0.19636413
Policy log std Min           -3.495482
Z mean eval                  3.320404
Z variance eval              0.008511224
total_rewards                [ 9778.52606861  9720.44846129  6320.24838249  9775.63597593
  9786.52706816  9740.40249548  9676.30193265 10043.36833498
 10070.7164591   9684.8479413 ]
total_rewards_mean           9459.702312000154
total_rewards_std            1054.6487318691584
total_rewards_max            10070.716459103855
total_rewards_min            6320.248382488052
Number of train steps total  420000
Number of env steps total    527000
Number of rollouts total     0
Train Time (s)               114.43702291930094
(Previous) Eval Time (s)     22.417289331089705
Sample Time (s)              16.133253084961325
Epoch Time (s)               152.98756533535197
Total Train Time (s)         15996.09772737138
Epoch                        104
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:02:55.156773 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #104 | Epoch Duration: 153.75044918060303
2020-01-13 13:02:55.156976 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #104 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3223038
Z variance train             0.00853301
KL Divergence                39.92431
KL Loss                      3.992431
QF Loss                      606.5072
VF Loss                      249.17656
Policy Loss                  -3714.5007
Q Predictions Mean           3707.9717
Q Predictions Std            625.43036
Q Predictions Max            4488.521
Q Predictions Min            703.703
V Predictions Mean           3704.0874
V Predictions Std            615.23773
V Predictions Max            4478.979
V Predictions Min            728.7471
Log Pis Mean                 5.349768
Log Pis Std                  3.8179348
Log Pis Max                  17.31957
Log Pis Min                  -2.960412
Policy mu Mean               -0.18070889
Policy mu Std                1.3846654
Policy mu Max                3.4694338
Policy mu Min                -3.7089095
Policy log std Mean          -0.8683683
Policy log std Std           0.45400155
Policy log std Max           -0.060525388
Policy log std Min           -3.2589397
Z mean eval                  3.329185
Z variance eval              0.005434771
total_rewards                [10007.68723168  5295.37366566 10160.6137779  10073.41531898
 10205.15283702 10128.17977263 10125.25751821  9899.84513595
 10019.18749653 10035.96511312]
total_rewards_mean           9595.067786767606
total_rewards_std            1435.6515417610194
total_rewards_max            10205.152837023796
total_rewards_min            5295.373665656139
Number of train steps total  424000
Number of env steps total    532000
Number of rollouts total     0
Train Time (s)               112.391579604242
(Previous) Eval Time (s)     23.17988583492115
Sample Time (s)              16.373615510296077
Epoch Time (s)               151.94508094945922
Total Train Time (s)         16147.398411983624
Epoch                        105
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:05:26.459431 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #105 | Epoch Duration: 151.3022940158844
2020-01-13 13:05:26.459634 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #105 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3299778
Z variance train             0.0054449276
KL Divergence                41.22393
KL Loss                      4.122393
QF Loss                      331.7107
VF Loss                      128.86533
Policy Loss                  -3709.066
Q Predictions Mean           3708.8018
Q Predictions Std            674.4927
Q Predictions Max            4478.5596
Q Predictions Min            719.40674
V Predictions Mean           3704.754
V Predictions Std            672.34595
V Predictions Max            4465.8013
V Predictions Min            695.3062
Log Pis Mean                 5.223263
Log Pis Std                  4.09881
Log Pis Max                  14.864316
Log Pis Min                  -7.4138546
Policy mu Mean               -0.12802663
Policy mu Std                1.3949387
Policy mu Max                3.556646
Policy mu Min                -3.8135042
Policy log std Mean          -0.8719886
Policy log std Std           0.46505663
Policy log std Max           0.065773845
Policy log std Min           -3.2633276
Z mean eval                  3.3233514
Z variance eval              0.00813189
total_rewards                [ 9789.8618524   9945.64359515  9794.75524329  9860.99753091
  9966.43253145  9856.16124305  9849.75836341  9851.98610879
  9905.46789608 10078.3637796 ]
total_rewards_mean           9889.94281441421
total_rewards_std            82.95067228735611
total_rewards_max            10078.363779604391
total_rewards_min            9789.861852403876
Number of train steps total  428000
Number of env steps total    537000
Number of rollouts total     0
Train Time (s)               113.3258579550311
(Previous) Eval Time (s)     22.536805307026953
Sample Time (s)              16.413250906858593
Epoch Time (s)               152.27591416891664
Total Train Time (s)         16299.864230814856
Epoch                        106
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:07:58.926235 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #106 | Epoch Duration: 152.46643352508545
2020-01-13 13:07:58.926424 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3234406
Z variance train             0.008129016
KL Divergence                40.774273
KL Loss                      4.0774274
QF Loss                      596.44714
VF Loss                      412.9638
Policy Loss                  -3808.6575
Q Predictions Mean           3807.476
Q Predictions Std            612.37
Q Predictions Max            4511.1387
Q Predictions Min            688.1211
V Predictions Mean           3822.768
V Predictions Std            608.7267
V Predictions Max            4515.432
V Predictions Min            731.7954
Log Pis Mean                 5.2897916
Log Pis Std                  4.0131426
Log Pis Max                  30.075657
Log Pis Min                  -5.2863593
Policy mu Mean               -0.08932823
Policy mu Std                1.3722932
Policy mu Max                4.2069426
Policy mu Min                -3.8465414
Policy log std Mean          -0.89271814
Policy log std Std           0.49897966
Policy log std Max           -0.09089756
Policy log std Min           -3.2718234
Z mean eval                  3.3404865
Z variance eval              0.008906839
total_rewards                [9536.50076473 9632.111716   9727.92857904 9872.06470926 9918.28084234
 9737.68099684 9974.25234677 9625.63687391 9736.50890633 9726.29492558]
total_rewards_mean           9748.7260660794
total_rewards_std            130.3148973901053
total_rewards_max            9974.25234676705
total_rewards_min            9536.500764734807
Number of train steps total  432000
Number of env steps total    542000
Number of rollouts total     0
Train Time (s)               107.37772839190438
(Previous) Eval Time (s)     22.72702720761299
Sample Time (s)              16.54624795773998
Epoch Time (s)               146.65100355725735
Total Train Time (s)         16446.462459383998
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:10:25.527006 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #107 | Epoch Duration: 146.60042715072632
2020-01-13 13:10:25.527223 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #107 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.340451
Z variance train             0.008905509
KL Divergence                40.524265
KL Loss                      4.052427
QF Loss                      385.1176
VF Loss                      173.7967
Policy Loss                  -3735.3025
Q Predictions Mean           3737.5264
Q Predictions Std            702.09955
Q Predictions Max            4521.009
Q Predictions Min            658.20264
V Predictions Mean           3741.336
V Predictions Std            691.26447
V Predictions Max            4521.012
V Predictions Min            724.3209
Log Pis Mean                 4.7900867
Log Pis Std                  3.6676176
Log Pis Max                  16.17081
Log Pis Min                  -5.729347
Policy mu Mean               -0.091058135
Policy mu Std                1.3244698
Policy mu Max                2.9381597
Policy mu Min                -3.2716544
Policy log std Mean          -0.86490726
Policy log std Std           0.45094278
Policy log std Max           0.0036593676
Policy log std Min           -2.9541366
Z mean eval                  3.3284965
Z variance eval              0.007347662
total_rewards                [9179.24608521 9467.93515322 9270.76414864 9291.41717587 9712.80784167
 9464.01795861 9620.58151329 4144.56253169 9343.31198781 9618.94999414]
total_rewards_mean           8911.359439017036
total_rewards_std            1597.3578965059496
total_rewards_max            9712.807841665202
total_rewards_min            4144.562531694924
Number of train steps total  436000
Number of env steps total    547000
Number of rollouts total     0
Train Time (s)               119.72173029184341
(Previous) Eval Time (s)     22.676154281944036
Sample Time (s)              15.973220578860492
Epoch Time (s)               158.37110515264794
Total Train Time (s)         16604.516063244082
Epoch                        108
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:13:03.582286 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #108 | Epoch Duration: 158.05491256713867
2020-01-13 13:13:03.582492 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #108 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3273113
Z variance train             0.0073529175
KL Divergence                39.783554
KL Loss                      3.9783554
QF Loss                      232.24835
VF Loss                      141.49341
Policy Loss                  -3813.4878
Q Predictions Mean           3811.6064
Q Predictions Std            620.753
Q Predictions Max            4538.1064
Q Predictions Min            670.77374
V Predictions Mean           3807.6895
V Predictions Std            614.3826
V Predictions Max            4540.8193
V Predictions Min            713.252
Log Pis Mean                 4.9236674
Log Pis Std                  3.5569668
Log Pis Max                  14.187565
Log Pis Min                  -5.2728777
Policy mu Mean               -0.048977535
Policy mu Std                1.3484462
Policy mu Max                3.3070543
Policy mu Min                -3.3417118
Policy log std Mean          -0.89099616
Policy log std Std           0.47357774
Policy log std Max           0.011148691
Policy log std Min           -3.0048418
Z mean eval                  3.329387
Z variance eval              0.008348532
total_rewards                [ 9752.64603879  5476.74844436  9994.48030258 10027.19989971
 10092.35413257 10254.77596979 10050.16150785 10037.19086173
 10105.52519449 10106.59048887]
total_rewards_mean           9589.767284073716
total_rewards_std            1376.1790081163938
total_rewards_max            10254.775969790036
total_rewards_min            5476.748444360265
Number of train steps total  440000
Number of env steps total    552000
Number of rollouts total     0
Train Time (s)               116.83984165964648
(Previous) Eval Time (s)     22.359659471083432
Sample Time (s)              15.733919709920883
Epoch Time (s)               154.9334208406508
Total Train Time (s)         16760.050838932395
Epoch                        109
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:15:39.119644 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #109 | Epoch Duration: 155.5369791984558
2020-01-13 13:15:39.119909 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #109 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3283048
Z variance train             0.008341992
KL Divergence                40.070045
KL Loss                      4.0070047
QF Loss                      395.73004
VF Loss                      205.69618
Policy Loss                  -3803.4265
Q Predictions Mean           3807.3276
Q Predictions Std            663.952
Q Predictions Max            4563.8984
Q Predictions Min            730.72046
V Predictions Mean           3811.5261
V Predictions Std            661.67004
V Predictions Max            4559.5503
V Predictions Min            726.842
Log Pis Mean                 5.369186
Log Pis Std                  3.6284995
Log Pis Max                  15.221279
Log Pis Min                  -4.775813
Policy mu Mean               -0.15996285
Policy mu Std                1.3725449
Policy mu Max                3.131214
Policy mu Min                -3.585684
Policy log std Mean          -0.8717033
Policy log std Std           0.46137458
Policy log std Max           -0.15691024
Policy log std Min           -3.1842413
Z mean eval                  3.3275154
Z variance eval              0.00967131
total_rewards                [9703.58529056 9766.67527542 9981.38821903 9968.78516166 9514.98321085
 9853.80188354 9972.79322365 9816.43344486 9815.64108446 9924.32035287]
total_rewards_mean           9831.840714689684
total_rewards_std            138.42510676451866
total_rewards_max            9981.388219033386
total_rewards_min            9514.983210847406
Number of train steps total  444000
Number of env steps total    557000
Number of rollouts total     0
Train Time (s)               103.51821297314018
(Previous) Eval Time (s)     22.962951064575464
Sample Time (s)              16.382879747077823
Epoch Time (s)               142.86404378479347
Total Train Time (s)         16903.016141568776
Epoch                        110
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:18:02.086863 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #110 | Epoch Duration: 142.96669626235962
2020-01-13 13:18:02.087141 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #110 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.33
Z variance train             0.009662611
KL Divergence                39.505417
KL Loss                      3.9505417
QF Loss                      403.24933
VF Loss                      169.73395
Policy Loss                  -3830.2363
Q Predictions Mean           3833.7134
Q Predictions Std            661.5246
Q Predictions Max            4523.534
Q Predictions Min            719.70514
V Predictions Mean           3829.2466
V Predictions Std            654.1765
V Predictions Max            4506.518
V Predictions Min            736.034
Log Pis Mean                 5.6002736
Log Pis Std                  3.7387102
Log Pis Max                  17.25003
Log Pis Min                  -3.8283825
Policy mu Mean               -0.16631518
Policy mu Std                1.371648
Policy mu Max                3.0802333
Policy mu Min                -3.992791
Policy log std Mean          -0.91445655
Policy log std Std           0.47398642
Policy log std Max           -0.067255944
Policy log std Min           -3.3287416
Z mean eval                  3.320956
Z variance eval              0.018143749
total_rewards                [10001.52823167 10249.42736513 10292.37440488 10204.40652054
 10132.74015746  9949.93803824 10328.85925494  9978.7185604
  9971.08973208 10196.34984405]
total_rewards_mean           10130.543210939406
total_rewards_std            136.81461490302655
total_rewards_max            10328.859254940022
total_rewards_min            9949.93803824468
Number of train steps total  448000
Number of env steps total    562000
Number of rollouts total     0
Train Time (s)               114.88564976165071
(Previous) Eval Time (s)     23.065304009709507
Sample Time (s)              16.74885086994618
Epoch Time (s)               154.6998046413064
Total Train Time (s)         17057.74666176224
Epoch                        111
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:20:36.821979 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #111 | Epoch Duration: 154.73464131355286
2020-01-13 13:20:36.822263 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #111 | Started Training: True
