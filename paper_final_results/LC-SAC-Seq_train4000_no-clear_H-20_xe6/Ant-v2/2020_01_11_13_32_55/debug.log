---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0017109148
Z variance train             0.6929817
KL Divergence                0.1493422
KL Loss                      0.014934219
QF Loss                      48.016277
VF Loss                      28.137676
Policy Loss                  -5.2688565
Q Predictions Mean           -0.013576328
Q Predictions Std            0.001662409
Q Predictions Max            -0.009497662
Q Predictions Min            -0.020241419
V Predictions Mean           -0.0012215257
V Predictions Std            0.0021012065
V Predictions Max            0.0041699195
V Predictions Min            -0.007149723
Log Pis Mean                 -5.3011913
Log Pis Std                  0.6033106
Log Pis Max                  -3.7279606
Log Pis Min                  -6.8028903
Policy mu Mean               0.00015567378
Policy mu Std                0.0015492962
Policy mu Max                0.004443978
Policy mu Min                -0.004172774
Policy log std Mean          0.00014733805
Policy log std Std           0.0013431344
Policy log std Max           0.0033795
Policy log std Min           -0.004493091
Z mean eval                  0.08375068
Z variance eval              0.006429388
total_rewards                [ 52.57680443 127.11332454  74.27185542  57.21932037  -1.31848895
  26.30312986  18.59944144  12.16255967 107.00190924  15.52016421]
total_rewards_mean           48.94500202399554
total_rewards_std            40.78490989362067
total_rewards_max            127.11332453568153
total_rewards_min            -1.3184889466180456
Number of train steps total  4000
Number of env steps total    7000
Number of rollouts total     0
Train Time (s)               123.06964845396578
(Previous) Eval Time (s)     0
Sample Time (s)              30.994635230395943
Epoch Time (s)               154.06428368436173
Total Train Time (s)         166.5102694858797
Epoch                        0
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:35:41.734438 UTC | [2020_01_11_13_32_55] Iteration #0 | Epoch Duration: 166.51378321647644
2020-01-11 13:35:41.734639 UTC | [2020_01_11_13_32_55] Iteration #0 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.085030824
Z variance train             0.006409418
KL Divergence                10.2189865
KL Loss                      1.0218986
QF Loss                      143.78802
VF Loss                      33.843353
Policy Loss                  -60.64493
Q Predictions Mean           55.327568
Q Predictions Std            23.898285
Q Predictions Max            113.15752
Q Predictions Min            -29.417454
V Predictions Mean           59.33542
V Predictions Std            21.96989
V Predictions Max            107.609215
V Predictions Min            -31.244488
Log Pis Mean                 -2.6689954
Log Pis Std                  1.6823254
Log Pis Max                  1.5249523
Log Pis Min                  -8.948553
Policy mu Mean               0.0117622325
Policy mu Std                0.404579
Policy mu Max                1.2924107
Policy mu Min                -1.464595
Policy log std Mean          -0.746586
Policy log std Std           0.10628098
Policy log std Max           -0.4132852
Policy log std Min           -1.0970511
Z mean eval                  0.17380162
Z variance eval              0.0035803698
total_rewards                [ 22.49783228 -45.83483893   8.73884156 -11.78724246  17.94737442
 148.12894761   8.5115196   -7.64029873 -78.04361716 -47.52116593]
total_rewards_mean           1.4997352239530877
total_rewards_std            57.917165146643725
total_rewards_max            148.12894760648325
total_rewards_min            -78.04361716299118
Number of train steps total  8000
Number of env steps total    12000
Number of rollouts total     0
Train Time (s)               122.32161203911528
(Previous) Eval Time (s)     12.448948327917606
Sample Time (s)              25.12967684911564
Epoch Time (s)               159.90023721614853
Total Train Time (s)         332.25906802807003
Epoch                        1
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:38:27.484628 UTC | [2020_01_11_13_32_55] Iteration #1 | Epoch Duration: 165.74985074996948
2020-01-11 13:38:27.484818 UTC | [2020_01_11_13_32_55] Iteration #1 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.17324594
Z variance train             0.0035756764
KL Divergence                11.807198
KL Loss                      1.1807197
QF Loss                      209.79443
VF Loss                      70.16202
Policy Loss                  -102.73893
Q Predictions Mean           97.31128
Q Predictions Std            30.892776
Q Predictions Max            190.84755
Q Predictions Min            -10.72219
V Predictions Mean           104.97782
V Predictions Std            26.586487
V Predictions Max            208.78287
V Predictions Min            6.201895
Log Pis Mean                 -2.1403828
Log Pis Std                  2.148826
Log Pis Max                  5.874132
Log Pis Min                  -8.230244
Policy mu Mean               -0.028139975
Policy mu Std                0.49209496
Policy mu Max                1.5799152
Policy mu Min                -1.9559181
Policy log std Mean          -0.7630995
Policy log std Std           0.13742839
Policy log std Max           -0.39410028
Policy log std Min           -1.2131187
Z mean eval                  0.24830571
Z variance eval              0.0076069953
total_rewards                [ -89.92913467  -58.86195087 -146.0202839    27.79307019  -20.51017095
  -19.29345171  -79.46478788    9.09769787   35.14995333   37.09971343]
total_rewards_mean           -30.49393451776021
total_rewards_std            58.43782091051426
total_rewards_max            37.099713432011086
total_rewards_min            -146.02028390211694
Number of train steps total  12000
Number of env steps total    17000
Number of rollouts total     0
Train Time (s)               123.98249562410638
(Previous) Eval Time (s)     18.29809045419097
Sample Time (s)              23.119712899439037
Epoch Time (s)               165.40029897773638
Total Train Time (s)         497.8729549306445
Epoch                        2
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:41:13.100096 UTC | [2020_01_11_13_32_55] Iteration #2 | Epoch Duration: 165.6151306629181
2020-01-11 13:41:13.100407 UTC | [2020_01_11_13_32_55] Iteration #2 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.24084973
Z variance train             0.007900812
KL Divergence                10.38657
KL Loss                      1.0386571
QF Loss                      191.04214
VF Loss                      65.96287
Policy Loss                  -129.9924
Q Predictions Mean           125.6443
Q Predictions Std            35.936962
Q Predictions Max            182.22464
Q Predictions Min            -18.154387
V Predictions Mean           133.25455
V Predictions Std            29.12214
V Predictions Max            192.01135
V Predictions Min            -6.9372087
Log Pis Mean                 -2.121131
Log Pis Std                  2.1497214
Log Pis Max                  8.813948
Log Pis Min                  -7.1292076
Policy mu Mean               -0.00082059123
Policy mu Std                0.4827601
Policy mu Max                1.8056209
Policy mu Min                -2.252897
Policy log std Mean          -0.74532235
Policy log std Std           0.19330612
Policy log std Max           -0.23747626
Policy log std Min           -1.5718069
Z mean eval                  0.3226971
Z variance eval              0.010043765
total_rewards                [   3.31763623  -52.25346085 -165.97536513  -12.74516609 -205.5709627
 -227.63957066 -146.63526851  -65.18265344   23.92199991 -118.86518541]
total_rewards_mean           -96.7627996658531
total_rewards_std            84.47033057745296
total_rewards_max            23.92199990540312
total_rewards_min            -227.63957066038202
Number of train steps total  16000
Number of env steps total    22000
Number of rollouts total     0
Train Time (s)               130.7860498279333
(Previous) Eval Time (s)     18.512571373954415
Sample Time (s)              23.580601431429386
Epoch Time (s)               172.8792226333171
Total Train Time (s)         678.1387837058865
Epoch                        3
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:44:13.365822 UTC | [2020_01_11_13_32_55] Iteration #3 | Epoch Duration: 180.26520657539368
2020-01-11 13:44:13.365977 UTC | [2020_01_11_13_32_55] Iteration #3 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.32143873
Z variance train             0.009999362
KL Divergence                10.417576
KL Loss                      1.0417576
QF Loss                      220.12698
VF Loss                      55.865746
Policy Loss                  -147.10097
Q Predictions Mean           142.65405
Q Predictions Std            37.32608
Q Predictions Max            216.88016
Q Predictions Min            -17.298553
V Predictions Mean           149.64017
V Predictions Std            29.541142
V Predictions Max            217.16461
V Predictions Min            -15.334118
Log Pis Mean                 -2.22862
Log Pis Std                  2.2073662
Log Pis Max                  3.640186
Log Pis Min                  -10.259195
Policy mu Mean               -0.038704533
Policy mu Std                0.4784508
Policy mu Max                1.9223268
Policy mu Min                -1.8649889
Policy log std Mean          -0.7348311
Policy log std Std           0.19009574
Policy log std Max           -0.27298057
Policy log std Min           -1.6592216
Z mean eval                  0.3644764
Z variance eval              0.011190532
total_rewards                [ 31.8295089  -70.72943398  40.72633541  -0.50741129 -49.8853661
  18.55264369  61.35180361  -1.99664235  72.73399798  15.07125621]
total_rewards_mean           11.71466920860746
total_rewards_std            42.91909311085721
total_rewards_max            72.7339979766443
total_rewards_min            -70.7294339750063
Number of train steps total  20000
Number of env steps total    27000
Number of rollouts total     0
Train Time (s)               131.22618506196886
(Previous) Eval Time (s)     25.89821292180568
Sample Time (s)              25.665514981374145
Epoch Time (s)               182.7899129651487
Total Train Time (s)         849.4518667454831
Epoch                        4
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:47:04.680724 UTC | [2020_01_11_13_32_55] Iteration #4 | Epoch Duration: 171.31462264060974
2020-01-11 13:47:04.680925 UTC | [2020_01_11_13_32_55] Iteration #4 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.36764115
Z variance train             0.011161178
KL Divergence                10.390575
KL Loss                      1.0390576
QF Loss                      219.66113
VF Loss                      45.231075
Policy Loss                  -165.32121
Q Predictions Mean           160.56381
Q Predictions Std            36.541515
Q Predictions Max            235.49922
Q Predictions Min            -22.418514
V Predictions Mean           164.1188
V Predictions Std            32.198853
V Predictions Max            242.52318
V Predictions Min            -16.75799
Log Pis Mean                 -2.3940628
Log Pis Std                  2.271951
Log Pis Max                  9.620693
Log Pis Min                  -8.029825
Policy mu Mean               -0.0009035268
Policy mu Std                0.44582042
Policy mu Max                2.5591419
Policy mu Min                -1.8311666
Policy log std Mean          -0.7064431
Policy log std Std           0.20180348
Policy log std Max           -0.22288552
Policy log std Min           -2.0494075
Z mean eval                  0.42499432
Z variance eval              0.006183776
total_rewards                [ -0.71951361  18.70249054  94.57733198 -71.97073122   3.91019029
  24.10150871  60.93998951  22.25768483 237.61994684  45.24027917]
total_rewards_mean           43.46591770476309
total_rewards_std            76.74456324368417
total_rewards_max            237.6199468447468
total_rewards_min            -71.97073122170528
Number of train steps total  24000
Number of env steps total    32000
Number of rollouts total     0
Train Time (s)               129.93172251386568
(Previous) Eval Time (s)     14.422480341047049
Sample Time (s)              24.425719623919576
Epoch Time (s)               168.7799224788323
Total Train Time (s)         1023.9819236076437
Epoch                        5
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:49:59.211998 UTC | [2020_01_11_13_32_55] Iteration #5 | Epoch Duration: 174.5309340953827
2020-01-11 13:49:59.212187 UTC | [2020_01_11_13_32_55] Iteration #5 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.42469472
Z variance train             0.006180788
KL Divergence                12.26118
KL Loss                      1.226118
QF Loss                      136.84729
VF Loss                      42.10608
Policy Loss                  -179.58405
Q Predictions Mean           175.00179
Q Predictions Std            39.054348
Q Predictions Max            256.9231
Q Predictions Min            -11.174517
V Predictions Mean           179.64398
V Predictions Std            31.195425
V Predictions Max            255.56346
V Predictions Min            -4.349333
Log Pis Mean                 -2.4380784
Log Pis Std                  2.4640496
Log Pis Max                  8.556068
Log Pis Min                  -7.8731527
Policy mu Mean               -0.026553445
Policy mu Std                0.44837537
Policy mu Max                1.7427495
Policy mu Min                -2.0330796
Policy log std Mean          -0.73685
Policy log std Std           0.22799897
Policy log std Max           -0.27918708
Policy log std Min           -1.8988283
Z mean eval                  0.4504723
Z variance eval              0.0071868547
total_rewards                [ 24.47244752  21.76455555 215.19018314   2.49673521  17.24702525
  30.53280282 151.65447766  68.18578319 -19.03126553 248.785812  ]
total_rewards_mean           76.12985568041009
total_rewards_std            89.75675951289277
total_rewards_max            248.78581199554742
total_rewards_min            -19.031265526902022
Number of train steps total  28000
Number of env steps total    37000
Number of rollouts total     0
Train Time (s)               132.6645523700863
(Previous) Eval Time (s)     20.173072314821184
Sample Time (s)              25.249137839768082
Epoch Time (s)               178.08676252467558
Total Train Time (s)         1203.7484186426736
Epoch                        6
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:52:58.980014 UTC | [2020_01_11_13_32_55] Iteration #6 | Epoch Duration: 179.76768493652344
2020-01-11 13:52:58.980210 UTC | [2020_01_11_13_32_55] Iteration #6 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.44779652
Z variance train             0.0071840347
KL Divergence                12.165957
KL Loss                      1.2165958
QF Loss                      175.91783
VF Loss                      70.363754
Policy Loss                  -190.35194
Q Predictions Mean           183.54425
Q Predictions Std            42.57729
Q Predictions Max            252.0089
Q Predictions Min            -27.419626
V Predictions Mean           191.65385
V Predictions Std            33.35852
V Predictions Max            251.90836
V Predictions Min            15.388095
Log Pis Mean                 -2.2993069
Log Pis Std                  2.3780968
Log Pis Max                  7.0864162
Log Pis Min                  -10.225211
Policy mu Mean               0.022317462
Policy mu Std                0.42835408
Policy mu Max                1.7194912
Policy mu Min                -1.5832372
Policy log std Mean          -0.7740879
Policy log std Std           0.21689774
Policy log std Max           -0.24525942
Policy log std Min           -1.8721459
Z mean eval                  0.45592386
Z variance eval              0.022035312
total_rewards                [228.06148228 102.54195248  -8.68430981  31.66950638  46.1010976
  13.54972258  47.03160111 114.17789842 182.17200719  25.82006254]
total_rewards_mean           78.24410207835918
total_rewards_std            73.34484132994996
total_rewards_max            228.0614822848377
total_rewards_min            -8.684309806498845
Number of train steps total  32000
Number of env steps total    42000
Number of rollouts total     0
Train Time (s)               130.2975765550509
(Previous) Eval Time (s)     21.853479486890137
Sample Time (s)              25.74895716831088
Epoch Time (s)               177.90001321025193
Total Train Time (s)         1381.8410735903308
Epoch                        7
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:55:57.073398 UTC | [2020_01_11_13_32_55] Iteration #7 | Epoch Duration: 178.09305667877197
2020-01-11 13:55:57.073562 UTC | [2020_01_11_13_32_55] Iteration #7 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.45486432
Z variance train             0.022142444
KL Divergence                11.843322
KL Loss                      1.1843323
QF Loss                      155.35262
VF Loss                      43.254677
Policy Loss                  -205.7564
Q Predictions Mean           203.55139
Q Predictions Std            35.919403
Q Predictions Max            299.36923
Q Predictions Min            1.4743106
V Predictions Mean           206.5678
V Predictions Std            32.501827
V Predictions Max            287.38577
V Predictions Min            -7.6294994
Log Pis Mean                 -2.3024526
Log Pis Std                  1.987922
Log Pis Max                  6.836476
Log Pis Min                  -7.591044
Policy mu Mean               0.02274612
Policy mu Std                0.4194047
Policy mu Max                1.8833025
Policy mu Min                -1.8201888
Policy log std Mean          -0.77294755
Policy log std Std           0.18830407
Policy log std Max           -0.19281426
Policy log std Min           -1.8948393
Z mean eval                  0.4833518
Z variance eval              0.011805141
total_rewards                [ 37.51929321 182.07695464 258.93693614 179.54435885  54.37757708
 -37.38090056 434.43603808 123.45782327  80.37415421 333.79444078]
total_rewards_mean           164.71366757047645
total_rewards_std            137.38551485050846
total_rewards_max            434.4360380815989
total_rewards_min            -37.380900560942806
Number of train steps total  36000
Number of env steps total    47000
Number of rollouts total     0
Train Time (s)               124.06635475391522
(Previous) Eval Time (s)     22.046045140363276
Sample Time (s)              24.96832229848951
Epoch Time (s)               171.080722192768
Total Train Time (s)         1557.6035151388496
Epoch                        8
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:58:52.836447 UTC | [2020_01_11_13_32_55] Iteration #8 | Epoch Duration: 175.76277494430542
2020-01-11 13:58:52.836563 UTC | [2020_01_11_13_32_55] Iteration #8 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.4825657
Z variance train             0.011826336
KL Divergence                12.332348
KL Loss                      1.2332348
QF Loss                      150.02525
VF Loss                      55.46862
Policy Loss                  -229.68102
Q Predictions Mean           223.60959
Q Predictions Std            46.04305
Q Predictions Max            326.92947
Q Predictions Min            -30.71513
V Predictions Mean           232.21626
V Predictions Std            33.99306
V Predictions Max            318.19278
V Predictions Min            8.068067
Log Pis Mean                 -2.1944544
Log Pis Std                  2.5114117
Log Pis Max                  9.697251
Log Pis Min                  -7.608303
Policy mu Mean               0.028482947
Policy mu Std                0.44470462
Policy mu Max                2.049109
Policy mu Min                -2.395031
Policy log std Mean          -0.7798243
Policy log std Std           0.18404032
Policy log std Max           -0.27578378
Policy log std Min           -1.8268155
Z mean eval                  0.49576682
Z variance eval              0.021422016
total_rewards                [155.53488848  91.03082944 312.64053801 241.51590443 306.44445142
  75.07994775  95.66420806 212.50051329 349.92334286 176.71233977]
total_rewards_mean           201.7046963515387
total_rewards_std            94.46206241561136
total_rewards_max            349.9233428585002
total_rewards_min            75.07994775070253
Number of train steps total  40000
Number of env steps total    52000
Number of rollouts total     0
Train Time (s)               124.11327697336674
(Previous) Eval Time (s)     26.727725279983133
Sample Time (s)              23.838210505899042
Epoch Time (s)               174.6792127592489
Total Train Time (s)         1732.498856982682
Epoch                        9
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:01:47.733673 UTC | [2020_01_11_13_32_55] Iteration #9 | Epoch Duration: 174.89701318740845
2020-01-11 14:01:47.733871 UTC | [2020_01_11_13_32_55] Iteration #9 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.49584684
Z variance train             0.021468107
KL Divergence                11.621584
KL Loss                      1.1621584
QF Loss                      174.32169
VF Loss                      72.44249
Policy Loss                  -249.05316
Q Predictions Mean           244.1824
Q Predictions Std            45.521988
Q Predictions Max            317.29407
Q Predictions Min            -40.6178
V Predictions Mean           245.32019
V Predictions Std            41.007687
V Predictions Max            314.56238
V Predictions Min            -10.859045
Log Pis Mean                 -2.1453886
Log Pis Std                  2.3216941
Log Pis Max                  10.085251
Log Pis Min                  -9.008323
Policy mu Mean               0.025634076
Policy mu Std                0.41964123
Policy mu Max                2.1362522
Policy mu Min                -2.286629
Policy log std Mean          -0.82605517
Policy log std Std           0.17562397
Policy log std Max           -0.35380062
Policy log std Min           -1.7028874
Z mean eval                  0.50889146
Z variance eval              0.034922574
total_rewards                [168.22960908  68.57323926  97.20257368 222.0980415   47.35014032
 132.56185474 454.43012876  23.26191993  26.65585595 105.14388673]
total_rewards_mean           134.55072499347403
total_rewards_std            122.21649088855946
total_rewards_max            454.43012875878276
total_rewards_min            23.261919928883128
Number of train steps total  44000
Number of env steps total    57000
Number of rollouts total     0
Train Time (s)               124.66729190712795
(Previous) Eval Time (s)     26.94512279704213
Sample Time (s)              25.122801335528493
Epoch Time (s)               176.73521603969857
Total Train Time (s)         1895.9379354165867
Epoch                        10
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:04:31.174246 UTC | [2020_01_11_13_32_55] Iteration #10 | Epoch Duration: 163.44024276733398
2020-01-11 14:04:31.174441 UTC | [2020_01_11_13_32_55] Iteration #10 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.50894034
Z variance train             0.034970883
KL Divergence                10.956755
KL Loss                      1.0956755
QF Loss                      145.74893
VF Loss                      47.412853
Policy Loss                  -259.63885
Q Predictions Mean           253.38507
Q Predictions Std            56.917816
Q Predictions Max            343.80466
Q Predictions Min            -37.611637
V Predictions Mean           258.11636
V Predictions Std            46.830547
V Predictions Max            343.219
V Predictions Min            -22.99261
Log Pis Mean                 -2.4047265
Log Pis Std                  2.7094958
Log Pis Max                  12.471117
Log Pis Min                  -11.433502
Policy mu Mean               -0.012259796
Policy mu Std                0.44195324
Policy mu Max                2.2753315
Policy mu Min                -2.0683863
Policy log std Mean          -0.7886828
Policy log std Std           0.19329846
Policy log std Max           -0.26397967
Policy log std Min           -2.0418847
Z mean eval                  0.5087822
Z variance eval              0.036160573
total_rewards                [108.60493362  48.65165616 143.339735    33.61305448 159.52019845
 649.79075624  85.99892858 138.24640508 125.35010815  22.17529441]
total_rewards_mean           151.52910701734785
total_rewards_std            172.22497720061344
total_rewards_max            649.7907562379577
total_rewards_min            22.17529440904337
Number of train steps total  48000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               123.85066616674885
(Previous) Eval Time (s)     13.649815203156322
Sample Time (s)              25.590221566148102
Epoch Time (s)               163.09070293605328
Total Train Time (s)         2068.8574514808133
Epoch                        11
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:07:24.094898 UTC | [2020_01_11_13_32_55] Iteration #11 | Epoch Duration: 172.92032194137573
2020-01-11 14:07:24.095089 UTC | [2020_01_11_13_32_55] Iteration #11 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.5075644
Z variance train             0.036177013
KL Divergence                11.3779125
KL Loss                      1.1377913
QF Loss                      215.7384
VF Loss                      57.0638
Policy Loss                  -262.51126
Q Predictions Mean           261.28668
Q Predictions Std            62.785877
Q Predictions Max            354.58948
Q Predictions Min            -29.98668
V Predictions Mean           259.9297
V Predictions Std            60.091385
V Predictions Max            353.96283
V Predictions Min            -16.455694
Log Pis Mean                 -1.9458406
Log Pis Std                  2.8434598
Log Pis Max                  13.113173
Log Pis Min                  -9.213228
Policy mu Mean               0.02388841
Policy mu Std                0.47263178
Policy mu Max                2.6770647
Policy mu Min                -2.635378
Policy log std Mean          -0.80444455
Policy log std Std           0.19246931
Policy log std Max           -0.24876772
Policy log std Min           -1.9235326
Z mean eval                  0.528853
Z variance eval              0.01850233
total_rewards                [130.96512106 405.55519447 253.40258162  42.75532875 217.72023207
 414.79825833  53.76083585 175.07463884  29.599839    35.23863588]
total_rewards_mean           175.88706658675676
total_rewards_std            139.07700255731615
total_rewards_max            414.79825832697384
total_rewards_min            29.59983899733173
Number of train steps total  52000
Number of env steps total    67000
Number of rollouts total     0
Train Time (s)               123.47566376486793
(Previous) Eval Time (s)     23.479024191386998
Sample Time (s)              24.95508074341342
Epoch Time (s)               171.90976869966835
Total Train Time (s)         2239.3627368337475
Epoch                        12
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:10:14.601420 UTC | [2020_01_11_13_32_55] Iteration #12 | Epoch Duration: 170.50611233711243
2020-01-11 14:10:14.601620 UTC | [2020_01_11_13_32_55] Iteration #12 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.5276619
Z variance train             0.018490044
KL Divergence                12.672764
KL Loss                      1.2672764
QF Loss                      226.56187
VF Loss                      74.39109
Policy Loss                  -283.30185
Q Predictions Mean           278.27008
Q Predictions Std            61.47854
Q Predictions Max            375.90338
Q Predictions Min            -75.20094
V Predictions Mean           283.7173
V Predictions Std            54.720932
V Predictions Max            370.8687
V Predictions Min            11.772729
Log Pis Mean                 -2.2038217
Log Pis Std                  2.6763227
Log Pis Max                  14.547447
Log Pis Min                  -8.048466
Policy mu Mean               0.015631905
Policy mu Std                0.44548765
Policy mu Max                2.5912402
Policy mu Min                -2.7440994
Policy log std Mean          -0.8005626
Policy log std Std           0.18033475
Policy log std Max           -0.17954418
Policy log std Min           -2.0276196
Z mean eval                  0.5083598
Z variance eval              0.02064883
total_rewards                [ 80.51612775  75.96538898 107.21465415 112.51421914 247.97026379
  93.61438106  59.41477497  25.69918862 351.21962586  58.19389458]
total_rewards_mean           121.23225189054176
total_rewards_std            95.19488039684306
total_rewards_max            351.21962585623106
total_rewards_min            25.699188622494763
Number of train steps total  56000
Number of env steps total    72000
Number of rollouts total     0
Train Time (s)               125.05973242782056
(Previous) Eval Time (s)     22.075051710009575
Sample Time (s)              25.00921943085268
Epoch Time (s)               172.14400356868282
Total Train Time (s)         2411.9434160953388
Epoch                        13
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:13:07.183611 UTC | [2020_01_11_13_32_55] Iteration #13 | Epoch Duration: 172.5818543434143
2020-01-11 14:13:07.183808 UTC | [2020_01_11_13_32_55] Iteration #13 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.51091063
Z variance train             0.020753514
KL Divergence                12.999017
KL Loss                      1.2999017
QF Loss                      283.01483
VF Loss                      94.8802
Policy Loss                  -294.5562
Q Predictions Mean           290.44363
Q Predictions Std            60.45083
Q Predictions Max            411.16455
Q Predictions Min            -41.37903
V Predictions Mean           293.13928
V Predictions Std            54.126575
V Predictions Max            408.94104
V Predictions Min            -9.4105015
Log Pis Mean                 -1.8449669
Log Pis Std                  2.4850307
Log Pis Max                  12.398063
Log Pis Min                  -9.230882
Policy mu Mean               0.05460895
Policy mu Std                0.43609753
Policy mu Max                2.3006716
Policy mu Min                -2.1832504
Policy log std Mean          -0.857389
Policy log std Std           0.20891748
Policy log std Max           -0.34998968
Policy log std Min           -1.7169943
Z mean eval                  0.5243813
Z variance eval              0.039320238
total_rewards                [128.14578987  69.36009642 385.38004912 150.61191605 536.95968916
 122.07732046  84.65610957 140.49070422  65.17634464 234.43391248]
total_rewards_mean           191.72919319927013
total_rewards_std            146.34655880560516
total_rewards_max            536.9596891608255
total_rewards_min            65.17634464377831
Number of train steps total  60000
Number of env steps total    77000
Number of rollouts total     0
Train Time (s)               124.16200537513942
(Previous) Eval Time (s)     22.51245492277667
Sample Time (s)              25.000015614554286
Epoch Time (s)               171.67447591247037
Total Train Time (s)         2585.0730821825564
Epoch                        14
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:16:00.314508 UTC | [2020_01_11_13_32_55] Iteration #14 | Epoch Duration: 173.13056325912476
2020-01-11 14:16:00.314703 UTC | [2020_01_11_13_32_55] Iteration #14 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.5291968
Z variance train             0.039188404
KL Divergence                12.111681
KL Loss                      1.2111682
QF Loss                      214.32101
VF Loss                      65.41511
Policy Loss                  -310.41095
Q Predictions Mean           305.31763
Q Predictions Std            68.86442
Q Predictions Max            420.36404
Q Predictions Min            -20.125723
V Predictions Mean           306.57214
V Predictions Std            63.345097
V Predictions Max            427.57697
V Predictions Min            -9.706187
Log Pis Mean                 -2.0721312
Log Pis Std                  2.5026145
Log Pis Max                  9.768969
Log Pis Min                  -7.8024273
Policy mu Mean               0.016898517
Policy mu Std                0.44023916
Policy mu Max                2.3867843
Policy mu Min                -2.7123108
Policy log std Mean          -0.851596
Policy log std Std           0.20858021
Policy log std Max           -0.17688444
Policy log std Min           -1.8237929
Z mean eval                  0.5412743
Z variance eval              0.029004073
total_rewards                [256.24287417 114.5940434  319.58318715 177.94621979  56.60700606
 101.29205937  59.97650091  30.83494844  89.10825901 269.95976329]
total_rewards_mean           147.6144861584415
total_rewards_std            96.70629529997214
total_rewards_max            319.5831871534204
total_rewards_min            30.834948437026135
Number of train steps total  64000
Number of env steps total    82000
Number of rollouts total     0
Train Time (s)               124.78992729401216
(Previous) Eval Time (s)     23.9681829190813
Sample Time (s)              23.578539710491896
Epoch Time (s)               172.33664992358536
Total Train Time (s)         2767.281857433729
Epoch                        15
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:19:02.524682 UTC | [2020_01_11_13_32_55] Iteration #15 | Epoch Duration: 182.20984053611755
2020-01-11 14:19:02.524865 UTC | [2020_01_11_13_32_55] Iteration #15 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.54120415
Z variance train             0.028934503
KL Divergence                12.559959
KL Loss                      1.255996
QF Loss                      215.63356
VF Loss                      76.62897
Policy Loss                  -317.23352
Q Predictions Mean           312.8731
Q Predictions Std            72.984184
Q Predictions Max            461.09677
Q Predictions Min            -41.808243
V Predictions Mean           319.14484
V Predictions Std            65.41082
V Predictions Max            450.78207
V Predictions Min            11.966644
Log Pis Mean                 -2.068573
Log Pis Std                  2.116562
Log Pis Max                  8.678667
Log Pis Min                  -7.1060977
Policy mu Mean               0.020983893
Policy mu Std                0.42051822
Policy mu Max                1.9688859
Policy mu Min                -1.5923693
Policy log std Mean          -0.8181585
Policy log std Std           0.20345959
Policy log std Max           -0.13909024
Policy log std Min           -1.6438975
Z mean eval                  0.5451977
Z variance eval              0.03544331
total_rewards                [ 70.51966607 150.08708228  48.24716984 386.87898444  89.53816469
 221.5440309  106.80472728   3.94311305 673.15294438 505.91060602]
total_rewards_mean           225.6626488950301
total_rewards_std            211.6289320466418
total_rewards_max            673.1529443791223
total_rewards_min            3.9431130541736796
Number of train steps total  68000
Number of env steps total    87000
Number of rollouts total     0
Train Time (s)               125.8243023948744
(Previous) Eval Time (s)     33.84102235222235
Sample Time (s)              26.073258351068944
Epoch Time (s)               185.7385830981657
Total Train Time (s)         2944.1227156179957
Epoch                        16
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:21:59.366330 UTC | [2020_01_11_13_32_55] Iteration #16 | Epoch Duration: 176.84134030342102
2020-01-11 14:21:59.366502 UTC | [2020_01_11_13_32_55] Iteration #16 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.54603857
Z variance train             0.035297584
KL Divergence                12.143524
KL Loss                      1.2143525
QF Loss                      365.5384
VF Loss                      62.432583
Policy Loss                  -336.1535
Q Predictions Mean           333.08704
Q Predictions Std            78.51119
Q Predictions Max            465.579
Q Predictions Min            -14.084609
V Predictions Mean           333.99884
V Predictions Std            73.3096
V Predictions Max            463.0224
V Predictions Min            37.474068
Log Pis Mean                 -2.0764785
Log Pis Std                  2.169581
Log Pis Max                  7.94185
Log Pis Min                  -9.052576
Policy mu Mean               0.0031582098
Policy mu Std                0.4294147
Policy mu Max                2.30084
Policy mu Min                -2.3848712
Policy log std Mean          -0.82613945
Policy log std Std           0.20799069
Policy log std Max           -0.28369385
Policy log std Min           -1.8056445
Z mean eval                  0.56381345
Z variance eval              0.04894107
total_rewards                [139.2095029  468.71034681 112.2951321  123.44324521 133.78271511
 538.51137745  36.64816512 381.76032632 469.98067273 -23.12516651]
total_rewards_mean           238.12163172236723
total_rewards_std            193.9822029884152
total_rewards_max            538.5113774461176
total_rewards_min            -23.125166510000046
Number of train steps total  72000
Number of env steps total    92000
Number of rollouts total     0
Train Time (s)               125.25825576903298
(Previous) Eval Time (s)     24.943365186918527
Sample Time (s)              24.299660546239465
Epoch Time (s)               174.50128150219098
Total Train Time (s)         3119.0247675799765
Epoch                        17
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:24:54.269525 UTC | [2020_01_11_13_32_55] Iteration #17 | Epoch Duration: 174.90290141105652
2020-01-11 14:24:54.269695 UTC | [2020_01_11_13_32_55] Iteration #17 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.5635482
Z variance train             0.048786897
KL Divergence                11.772051
KL Loss                      1.1772051
QF Loss                      280.17212
VF Loss                      86.67886
Policy Loss                  -336.28445
Q Predictions Mean           335.57852
Q Predictions Std            88.21757
Q Predictions Max            470.439
Q Predictions Min            -9.347402
V Predictions Mean           334.55414
V Predictions Std            83.014534
V Predictions Max            461.9202
V Predictions Min            15.16815
Log Pis Mean                 -1.719363
Log Pis Std                  2.9972646
Log Pis Max                  16.892172
Log Pis Min                  -10.630461
Policy mu Mean               0.0769807
Policy mu Std                0.46770352
Policy mu Max                4.039031
Policy mu Min                -2.5402637
Policy log std Mean          -0.85770977
Policy log std Std           0.20531163
Policy log std Max           -0.17676789
Policy log std Min           -1.9283592
Z mean eval                  0.5855473
Z variance eval              0.049439855
total_rewards                [ 48.44364    408.21564595 325.81201724 277.65000154 611.31801736
 390.65884208 241.93284579 605.09738994 489.15337787 309.89470593]
total_rewards_mean           370.8176483700115
total_rewards_std            162.31964410926133
total_rewards_max            611.3180173591732
total_rewards_min            48.44363999818903
Number of train steps total  76000
Number of env steps total    97000
Number of rollouts total     0
Train Time (s)               125.15219196910039
(Previous) Eval Time (s)     25.344577947165817
Sample Time (s)              23.977277639321983
Epoch Time (s)               174.47404755558819
Total Train Time (s)         3299.319255731534
Epoch                        18
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:27:54.565787 UTC | [2020_01_11_13_32_55] Iteration #18 | Epoch Duration: 180.29596138000488
2020-01-11 14:27:54.565988 UTC | [2020_01_11_13_32_55] Iteration #18 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.58592856
Z variance train             0.049475856
KL Divergence                12.058988
KL Loss                      1.2058988
QF Loss                      390.30994
VF Loss                      58.176716
Policy Loss                  -357.20502
Q Predictions Mean           354.54645
Q Predictions Std            94.06098
Q Predictions Max            491.3247
Q Predictions Min            -0.7145544
V Predictions Mean           359.75067
V Predictions Std            92.34455
V Predictions Max            493.57422
V Predictions Min            -22.38379
Log Pis Mean                 -2.0188417
Log Pis Std                  2.4270277
Log Pis Max                  10.861258
Log Pis Min                  -9.303408
Policy mu Mean               0.015252704
Policy mu Std                0.4358165
Policy mu Max                2.3710587
Policy mu Min                -3.037974
Policy log std Mean          -0.8327787
Policy log std Std           0.19921882
Policy log std Max           -0.13223386
Policy log std Min           -1.5929905
Z mean eval                  0.599451
Z variance eval              0.036300063
total_rewards                [188.05496052 770.4637042  555.03065172 248.9841796  122.50919973
 283.5063661  748.35304553 582.12352491 165.69586973  99.47482944]
total_rewards_mean           376.4196331501598
total_rewards_std            247.7394875859879
total_rewards_max            770.4637041988108
total_rewards_min            99.47482944191371
Number of train steps total  80000
Number of env steps total    102000
Number of rollouts total     0
Train Time (s)               126.05583244701847
(Previous) Eval Time (s)     31.166148049756885
Sample Time (s)              25.46781483059749
Epoch Time (s)               182.68979532737285
Total Train Time (s)         3473.144830028992
Epoch                        19
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:30:48.392512 UTC | [2020_01_11_13_32_55] Iteration #19 | Epoch Duration: 173.82639622688293
2020-01-11 14:30:48.392688 UTC | [2020_01_11_13_32_55] Iteration #19 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.5983969
Z variance train             0.036185745
KL Divergence                13.201427
KL Loss                      1.3201427
QF Loss                      242.57431
VF Loss                      57.577168
Policy Loss                  -366.68292
Q Predictions Mean           362.951
Q Predictions Std            98.8007
Q Predictions Max            513.4716
Q Predictions Min            -6.8439364
V Predictions Mean           367.23383
V Predictions Std            97.531746
V Predictions Max            527.0235
V Predictions Min            -6.738491
Log Pis Mean                 -1.9813116
Log Pis Std                  2.5547593
Log Pis Max                  12.170391
Log Pis Min                  -8.65017
Policy mu Mean               0.07660031
Policy mu Std                0.45653898
Policy mu Max                2.154957
Policy mu Min                -2.195016
Policy log std Mean          -0.84669375
Policy log std Std           0.2131157
Policy log std Max           -0.2915946
Policy log std Min           -1.8028734
Z mean eval                  0.6253277
Z variance eval              0.029073233
total_rewards                [454.14903327 119.66778561 742.38408986  59.00961385  11.82301043
 202.50206545 320.99278475  93.6441223  203.78574005 441.46791499]
total_rewards_mean           264.94261605577367
total_rewards_std            215.08535610712596
total_rewards_max            742.3840898603069
total_rewards_min            11.823010426555637
Number of train steps total  84000
Number of env steps total    107000
Number of rollouts total     0
Train Time (s)               125.64830269897357
(Previous) Eval Time (s)     22.302341185044497
Sample Time (s)              25.120093803387135
Epoch Time (s)               173.0707376874052
Total Train Time (s)         3650.374745430425
Epoch                        20
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:33:45.624226 UTC | [2020_01_11_13_32_55] Iteration #20 | Epoch Duration: 177.2314109802246
2020-01-11 14:33:45.624400 UTC | [2020_01_11_13_32_55] Iteration #20 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6246209
Z variance train             0.029075315
KL Divergence                13.747562
KL Loss                      1.3747562
QF Loss                      381.81558
VF Loss                      101.45451
Policy Loss                  -402.0608
Q Predictions Mean           397.90125
Q Predictions Std            105.29186
Q Predictions Max            566.14996
Q Predictions Min            -4.363206
V Predictions Mean           404.41412
V Predictions Std            99.982956
V Predictions Max            558.9871
V Predictions Min            9.68392
Log Pis Mean                 -1.4473393
Log Pis Std                  2.4729276
Log Pis Max                  11.209261
Log Pis Min                  -9.53768
Policy mu Mean               0.04420628
Policy mu Std                0.45752808
Policy mu Max                2.5942523
Policy mu Min                -2.0569038
Policy log std Mean          -0.8797466
Policy log std Std           0.21036051
Policy log std Max           -0.20944592
Policy log std Min           -1.8804166
Z mean eval                  0.64448166
Z variance eval              0.026240602
total_rewards                [ 86.14837091 369.37847992  54.08846417  46.75988525  19.914832
 269.71980162  92.20235711 234.05340116 518.64103361  40.6389332 ]
total_rewards_mean           173.15455589619842
total_rewards_std            160.06771554551642
total_rewards_max            518.6410336117865
total_rewards_min            19.91483200392904
Number of train steps total  88000
Number of env steps total    112000
Number of rollouts total     0
Train Time (s)               126.08322884561494
(Previous) Eval Time (s)     26.462590710725635
Sample Time (s)              25.104989684186876
Epoch Time (s)               177.65080924052745
Total Train Time (s)         3822.5102782449685
Epoch                        21
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:36:37.760678 UTC | [2020_01_11_13_32_55] Iteration #21 | Epoch Duration: 172.1361541748047
2020-01-11 14:36:37.760859 UTC | [2020_01_11_13_32_55] Iteration #21 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6438068
Z variance train             0.02626288
KL Divergence                14.024788
KL Loss                      1.4024788
QF Loss                      384.9339
VF Loss                      70.54036
Policy Loss                  -395.66663
Q Predictions Mean           395.39093
Q Predictions Std            115.19498
Q Predictions Max            554.2468
Q Predictions Min            -14.803562
V Predictions Mean           397.31586
V Predictions Std            110.824425
V Predictions Max            547.54767
V Predictions Min            34.186253
Log Pis Mean                 -1.9928337
Log Pis Std                  2.4577892
Log Pis Max                  13.42887
Log Pis Min                  -8.43576
Policy mu Mean               -0.004348119
Policy mu Std                0.45541307
Policy mu Max                2.7225854
Policy mu Min                -2.522723
Policy log std Mean          -0.84202373
Policy log std Std           0.22090086
Policy log std Max           -0.14585322
Policy log std Min           -1.6161731
Z mean eval                  0.6484505
Z variance eval              0.035930004
total_rewards                [1531.32326259  252.32964632  960.36804787  461.32458864 1131.20517586
  115.43897622  986.57088355 1089.14357206  604.75902393  869.64146765]
total_rewards_mean           800.2104644684233
total_rewards_std            414.113193365049
total_rewards_max            1531.3232625900282
total_rewards_min            115.438976223242
Number of train steps total  92000
Number of env steps total    117000
Number of rollouts total     0
Train Time (s)               133.6143636358902
(Previous) Eval Time (s)     20.947596462909132
Sample Time (s)              23.482604432385415
Epoch Time (s)               178.04456453118473
Total Train Time (s)         4010.5379891004413
Epoch                        22
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:39:45.789785 UTC | [2020_01_11_13_32_55] Iteration #22 | Epoch Duration: 188.0287926197052
2020-01-11 14:39:45.789994 UTC | [2020_01_11_13_32_55] Iteration #22 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.64584446
Z variance train             0.035857942
KL Divergence                14.163355
KL Loss                      1.4163355
QF Loss                      355.55292
VF Loss                      82.59404
Policy Loss                  -412.4552
Q Predictions Mean           409.50696
Q Predictions Std            125.806175
Q Predictions Max            601.677
Q Predictions Min            -13.642004
V Predictions Mean           414.66052
V Predictions Std            119.285446
V Predictions Max            594.74347
V Predictions Min            -0.574209
Log Pis Mean                 -1.4336461
Log Pis Std                  2.4137866
Log Pis Max                  11.857355
Log Pis Min                  -7.0843124
Policy mu Mean               0.048283268
Policy mu Std                0.44476682
Policy mu Max                2.069776
Policy mu Min                -2.2723184
Policy log std Mean          -0.8865081
Policy log std Std           0.2329552
Policy log std Max           -0.15034848
Policy log std Min           -1.953048
Z mean eval                  0.65246844
Z variance eval              0.016081102
total_rewards                [  43.30435937  366.28367886  170.87881579 1517.13718086  856.36204257
  850.02733579  292.36385472  532.73146126  256.37111666  636.37079101]
total_rewards_mean           552.1830636896002
total_rewards_std            413.97563019266744
total_rewards_max            1517.1371808577014
total_rewards_min            43.30435936919859
Number of train steps total  96000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               132.83271860470995
(Previous) Eval Time (s)     30.931360807735473
Sample Time (s)              24.829457303974777
Epoch Time (s)               188.5935367164202
Total Train Time (s)         4189.135843269527
Epoch                        23
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:42:44.389530 UTC | [2020_01_11_13_32_55] Iteration #23 | Epoch Duration: 178.59939527511597
2020-01-11 14:42:44.389745 UTC | [2020_01_11_13_32_55] Iteration #23 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6523885
Z variance train             0.01610844
KL Divergence                15.672382
KL Loss                      1.5672382
QF Loss                      392.6203
VF Loss                      157.32236
Policy Loss                  -429.8705
Q Predictions Mean           425.3729
Q Predictions Std            131.16924
Q Predictions Max            606.03
Q Predictions Min            -60.402283
V Predictions Mean           429.87048
V Predictions Std            126.18954
V Predictions Max            607.6486
V Predictions Min            -25.69485
Log Pis Mean                 -1.3613718
Log Pis Std                  2.333418
Log Pis Max                  7.457777
Log Pis Min                  -8.665246
Policy mu Mean               0.038037654
Policy mu Std                0.4847736
Policy mu Max                1.87163
Policy mu Min                -1.8770009
Policy log std Mean          -0.8781522
Policy log std Std           0.22914886
Policy log std Max           -0.27008697
Policy log std Min           -1.9106448
Z mean eval                  0.67914355
Z variance eval              0.017708458
total_rewards                [ 831.41636413  320.55675742 1645.37532942  138.88216293  365.11590339
 1502.34286276 1159.56361051  729.76652392  436.37227248 1176.85974753]
total_rewards_mean           830.6251534497547
total_rewards_std            496.3956941486592
total_rewards_max            1645.3753294215007
total_rewards_min            138.88216292904468
Number of train steps total  100000
Number of env steps total    127000
Number of rollouts total     0
Train Time (s)               131.16491990583017
(Previous) Eval Time (s)     20.936815542168915
Sample Time (s)              26.033069156110287
Epoch Time (s)               178.13480460410938
Total Train Time (s)         4375.933451904915
Epoch                        24
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:45:51.188224 UTC | [2020_01_11_13_32_55] Iteration #24 | Epoch Duration: 186.79833436012268
2020-01-11 14:45:51.188432 UTC | [2020_01_11_13_32_55] Iteration #24 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.680591
Z variance train             0.017718356
KL Divergence                16.67933
KL Loss                      1.6679331
QF Loss                      319.52722
VF Loss                      98.17567
Policy Loss                  -462.11102
Q Predictions Mean           459.3029
Q Predictions Std            133.78416
Q Predictions Max            658.51074
Q Predictions Min            -15.569179
V Predictions Mean           458.7323
V Predictions Std            128.74997
V Predictions Max            657.0375
V Predictions Min            59.91122
Log Pis Mean                 -1.4036005
Log Pis Std                  2.487359
Log Pis Max                  14.570078
Log Pis Min                  -8.826414
Policy mu Mean               0.030037273
Policy mu Std                0.48854372
Policy mu Max                2.0873783
Policy mu Min                -3.2043612
Policy log std Mean          -0.8794505
Policy log std Std           0.2181394
Policy log std Max           -0.31800467
Policy log std Min           -1.7377315
Z mean eval                  0.6889494
Z variance eval              0.019793203
total_rewards                [1756.58731718 1785.30127925 1853.02792343 1716.56154426  966.95779201
 1608.08509194  638.53068425  905.27067809 1405.90536754  616.10951817]
total_rewards_mean           1325.2337196106062
total_rewards_std            468.5182894496041
total_rewards_max            1853.0279234282016
total_rewards_min            616.109518174905
Number of train steps total  104000
Number of env steps total    132000
Number of rollouts total     0
Train Time (s)               133.4921351680532
(Previous) Eval Time (s)     29.599946268368512
Sample Time (s)              26.874898091424257
Epoch Time (s)               189.96697952784598
Total Train Time (s)         4564.309119671583
Epoch                        25
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:48:59.563788 UTC | [2020_01_11_13_32_55] Iteration #25 | Epoch Duration: 188.37523913383484
2020-01-11 14:48:59.563912 UTC | [2020_01_11_13_32_55] Iteration #25 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6863367
Z variance train             0.01969337
KL Divergence                16.39464
KL Loss                      1.639464
QF Loss                      396.62433
VF Loss                      113.76192
Policy Loss                  -458.90915
Q Predictions Mean           454.85632
Q Predictions Std            140.11473
Q Predictions Max            650.04285
Q Predictions Min            -41.40447
V Predictions Mean           452.86304
V Predictions Std            138.59592
V Predictions Max            630.22394
V Predictions Min            60.119057
Log Pis Mean                 -1.448392
Log Pis Std                  2.2840147
Log Pis Max                  7.3298
Log Pis Min                  -8.415315
Policy mu Mean               0.021839125
Policy mu Std                0.46668845
Policy mu Max                1.6586897
Policy mu Min                -1.744531
Policy log std Mean          -0.885189
Policy log std Std           0.2507009
Policy log std Max           -0.2889264
Policy log std Min           -2.1753392
Z mean eval                  0.69673234
Z variance eval              0.02266776
total_rewards                [  63.21973675  804.59860044 1168.37652524  738.27606019  237.78371991
 1532.86730674  269.89503855 1613.59892909  682.88817776  467.34391418]
total_rewards_mean           757.8848008841484
total_rewards_std            508.44388927039256
total_rewards_max            1613.5989290865352
total_rewards_min            63.21973674991505
Number of train steps total  108000
Number of env steps total    137000
Number of rollouts total     0
Train Time (s)               128.13060902897269
(Previous) Eval Time (s)     28.007806869223714
Sample Time (s)              26.306243719067425
Epoch Time (s)               182.44465961726382
Total Train Time (s)         4743.54020306794
Epoch                        26
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:51:58.797046 UTC | [2020_01_11_13_32_55] Iteration #26 | Epoch Duration: 179.23303723335266
2020-01-11 14:51:58.797226 UTC | [2020_01_11_13_32_55] Iteration #26 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.69721854
Z variance train             0.022746595
KL Divergence                15.918161
KL Loss                      1.5918162
QF Loss                      448.583
VF Loss                      58.880432
Policy Loss                  -473.6962
Q Predictions Mean           470.4438
Q Predictions Std            158.15582
Q Predictions Max            713.51416
Q Predictions Min            -2.3465428
V Predictions Mean           474.7744
V Predictions Std            156.89626
V Predictions Max            707.8365
V Predictions Min            17.611782
Log Pis Mean                 -0.93261904
Log Pis Std                  2.4648268
Log Pis Max                  13.229776
Log Pis Min                  -7.3790727
Policy mu Mean               0.08232781
Policy mu Std                0.5212436
Policy mu Max                2.2158208
Policy mu Min                -2.237403
Policy log std Mean          -0.8822911
Policy log std Std           0.22035371
Policy log std Max           -0.2921546
Policy log std Min           -1.75407
Z mean eval                  0.72508335
Z variance eval              0.009630328
total_rewards                [ 123.95032006  161.3239888    27.11553239  416.78246866 1262.62499081
 1098.84792001  667.79428416  113.92163884  535.28690185  761.64116898]
total_rewards_mean           516.9289214560694
total_rewards_std            408.7691516199869
total_rewards_max            1262.6249908058312
total_rewards_min            27.115532391845893
Number of train steps total  112000
Number of env steps total    142000
Number of rollouts total     0
Train Time (s)               125.6469896780327
(Previous) Eval Time (s)     24.795793069992214
Sample Time (s)              24.809839333873242
Epoch Time (s)               175.25262208189815
Total Train Time (s)         4922.5968985641375
Epoch                        27
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:54:57.855460 UTC | [2020_01_11_13_32_55] Iteration #27 | Epoch Duration: 179.05808568000793
2020-01-11 14:54:57.855678 UTC | [2020_01_11_13_32_55] Iteration #27 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7283595
Z variance train             0.009625343
KL Divergence                17.66587
KL Loss                      1.7665871
QF Loss                      315.20483
VF Loss                      109.4363
Policy Loss                  -493.2267
Q Predictions Mean           488.4367
Q Predictions Std            172.17839
Q Predictions Max            704.70386
Q Predictions Min            -61.494514
V Predictions Mean           495.07104
V Predictions Std            166.73668
V Predictions Max            701.82007
V Predictions Min            4.9790273
Log Pis Mean                 -0.9347755
Log Pis Std                  2.7608886
Log Pis Max                  11.207882
Log Pis Min                  -8.198203
Policy mu Mean               0.016838143
Policy mu Std                0.53601015
Policy mu Max                2.4962108
Policy mu Min                -2.239148
Policy log std Mean          -0.8935312
Policy log std Std           0.23993762
Policy log std Max           -0.2800901
Policy log std Min           -1.9529214
Z mean eval                  0.70471853
Z variance eval              0.012980552
total_rewards                [1910.12663944   49.03692571  110.81805808 1071.40859298  294.29946062
 1557.04614945  432.94193225  181.02365414 1459.38931138  139.9635453 ]
total_rewards_mean           720.6054269353779
total_rewards_std            670.7520943595422
total_rewards_max            1910.126639437738
total_rewards_min            49.03692571175215
Number of train steps total  116000
Number of env steps total    147000
Number of rollouts total     0
Train Time (s)               125.79534159367904
(Previous) Eval Time (s)     28.60091347619891
Sample Time (s)              24.056035346817225
Epoch Time (s)               178.45229041669518
Total Train Time (s)         5098.082273679785
Epoch                        28
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:57:53.342226 UTC | [2020_01_11_13_32_55] Iteration #28 | Epoch Duration: 175.48631882667542
2020-01-11 14:57:53.342597 UTC | [2020_01_11_13_32_55] Iteration #28 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.70513165
Z variance train             0.01291615
KL Divergence                17.867704
KL Loss                      1.7867705
QF Loss                      302.7345
VF Loss                      185.06538
Policy Loss                  -520.23444
Q Predictions Mean           515.2423
Q Predictions Std            152.00313
Q Predictions Max            713.4533
Q Predictions Min            85.601105
V Predictions Mean           516.3721
V Predictions Std            150.68156
V Predictions Max            718.7704
V Predictions Min            68.891075
Log Pis Mean                 -1.4483992
Log Pis Std                  2.2814333
Log Pis Max                  6.834565
Log Pis Min                  -6.9891844
Policy mu Mean               0.019647036
Policy mu Std                0.49186537
Policy mu Max                2.007307
Policy mu Min                -2.01058
Policy log std Mean          -0.8756958
Policy log std Std           0.22280474
Policy log std Max           -0.24192232
Policy log std Min           -2.10078
Z mean eval                  0.7437132
Z variance eval              0.023583466
total_rewards                [1934.9002844   945.94667663 1272.88548691  615.57554386  123.09225903
 1846.08727679  825.2817196   261.20483392 1495.10731617 1738.90913289]
total_rewards_mean           1105.8990530204132
total_rewards_std            619.6254080439071
total_rewards_max            1934.9002844024528
total_rewards_min            123.09225902767963
Number of train steps total  120000
Number of env steps total    152000
Number of rollouts total     0
Train Time (s)               125.04726972198114
(Previous) Eval Time (s)     25.63460813416168
Sample Time (s)              25.15310513600707
Epoch Time (s)               175.8349829921499
Total Train Time (s)         5279.488837233745
Epoch                        29
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:00:54.749843 UTC | [2020_01_11_13_32_55] Iteration #29 | Epoch Duration: 181.40709233283997
2020-01-11 15:00:54.750033 UTC | [2020_01_11_13_32_55] Iteration #29 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.73808855
Z variance train             0.023535656
KL Divergence                16.323551
KL Loss                      1.6323551
QF Loss                      397.4015
VF Loss                      89.06246
Policy Loss                  -543.23004
Q Predictions Mean           542.78046
Q Predictions Std            159.8196
Q Predictions Max            728.94775
Q Predictions Min            8.061236
V Predictions Mean           548.2646
V Predictions Std            157.24138
V Predictions Max            730.34906
V Predictions Min            101.88231
Log Pis Mean                 -1.3131186
Log Pis Std                  2.3769484
Log Pis Max                  7.141165
Log Pis Min                  -8.254576
Policy mu Mean               0.028120685
Policy mu Std                0.5026915
Policy mu Max                1.9680156
Policy mu Min                -1.7506508
Policy log std Mean          -0.88982934
Policy log std Std           0.23852001
Policy log std Max           -0.27109486
Policy log std Min           -1.9449382
Z mean eval                  0.7477046
Z variance eval              0.016666237
total_rewards                [1009.04191688  571.72281514  190.70940091  478.18888533 1907.10117064
  712.76340336  878.41100684  977.2861212  1150.78726354  611.56134435]
total_rewards_mean           848.7573328200717
total_rewards_std            444.55105000100144
total_rewards_max            1907.101170642158
total_rewards_min            190.7094009085529
Number of train steps total  124000
Number of env steps total    157000
Number of rollouts total     0
Train Time (s)               125.1886495091021
(Previous) Eval Time (s)     31.206414768937975
Sample Time (s)              25.769057732075453
Epoch Time (s)               182.16412201011553
Total Train Time (s)         5455.6501160538755
Epoch                        30
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:03:50.912506 UTC | [2020_01_11_13_32_55] Iteration #30 | Epoch Duration: 176.16233944892883
2020-01-11 15:03:50.912684 UTC | [2020_01_11_13_32_55] Iteration #30 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7502469
Z variance train             0.016554791
KL Divergence                17.136202
KL Loss                      1.7136202
QF Loss                      547.1887
VF Loss                      133.48888
Policy Loss                  -540.5321
Q Predictions Mean           539.36237
Q Predictions Std            171.63968
Q Predictions Max            755.98553
Q Predictions Min            18.646225
V Predictions Mean           538.0287
V Predictions Std            167.23782
V Predictions Max            745.4856
V Predictions Min            28.83528
Log Pis Mean                 -1.2447388
Log Pis Std                  2.1916428
Log Pis Max                  10.386367
Log Pis Min                  -6.9639444
Policy mu Mean               0.04109314
Policy mu Std                0.5200619
Policy mu Max                1.9742287
Policy mu Min                -1.5083072
Policy log std Mean          -0.88311255
Policy log std Std           0.2468893
Policy log std Max           -0.27571055
Policy log std Min           -2.2620647
Z mean eval                  0.7599273
Z variance eval              0.021592116
total_rewards                [ 365.1459223   417.83015599  826.43098174 2086.13979948  352.828835
   83.26446923 1088.25242329   54.07288264   94.4870296   475.21665195]
total_rewards_mean           584.3669151236442
total_rewards_std            590.0365358711285
total_rewards_max            2086.1397994847835
total_rewards_min            54.072882642867114
Number of train steps total  128000
Number of env steps total    162000
Number of rollouts total     0
Train Time (s)               125.98747837496921
(Previous) Eval Time (s)     25.20431058201939
Sample Time (s)              25.857785106636584
Epoch Time (s)               177.0495740636252
Total Train Time (s)         5636.7970792460255
Epoch                        31
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:06:52.060485 UTC | [2020_01_11_13_32_55] Iteration #31 | Epoch Duration: 181.14767265319824
2020-01-11 15:06:52.060664 UTC | [2020_01_11_13_32_55] Iteration #31 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7599648
Z variance train             0.021531591
KL Divergence                17.800337
KL Loss                      1.7800337
QF Loss                      306.47778
VF Loss                      106.224754
Policy Loss                  -567.6981
Q Predictions Mean           566.67474
Q Predictions Std            172.67729
Q Predictions Max            802.7319
Q Predictions Min            21.602024
V Predictions Mean           564.5437
V Predictions Std            171.56322
V Predictions Max            764.4333
V Predictions Min            3.5347495
Log Pis Mean                 -1.3174052
Log Pis Std                  2.2973685
Log Pis Max                  8.0649185
Log Pis Min                  -7.38842
Policy mu Mean               0.028519787
Policy mu Std                0.5123021
Policy mu Max                2.0487628
Policy mu Min                -2.0208707
Policy log std Mean          -0.8804943
Policy log std Std           0.22806108
Policy log std Max           -0.28854585
Policy log std Min           -2.11886
Z mean eval                  0.76802856
Z variance eval              0.02542239
total_rewards                [ 184.06524982  773.9888467   144.83969586  892.40407349  532.66297417
  397.40213179   45.87217936  141.14899149 1532.65467227 2065.75111006]
total_rewards_mean           671.0789925001925
total_rewards_std            634.5766906617262
total_rewards_max            2065.751110058569
total_rewards_min            45.87217935887878
Number of train steps total  132000
Number of env steps total    167000
Number of rollouts total     0
Train Time (s)               125.33609185088426
(Previous) Eval Time (s)     29.30204317998141
Sample Time (s)              24.340255348943174
Epoch Time (s)               178.97839037980884
Total Train Time (s)         5812.39425641764
Epoch                        32
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:09:47.657730 UTC | [2020_01_11_13_32_55] Iteration #32 | Epoch Duration: 175.59695482254028
2020-01-11 15:09:47.657849 UTC | [2020_01_11_13_32_55] Iteration #32 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.77066636
Z variance train             0.025514718
KL Divergence                17.530079
KL Loss                      1.7530079
QF Loss                      490.106
VF Loss                      246.1917
Policy Loss                  -574.30817
Q Predictions Mean           570.2642
Q Predictions Std            200.89078
Q Predictions Max            820.19324
Q Predictions Min            2.5012977
V Predictions Mean           565.8081
V Predictions Std            194.79486
V Predictions Max            795.3523
V Predictions Min            85.205215
Log Pis Mean                 -1.1538473
Log Pis Std                  2.6057243
Log Pis Max                  10.309552
Log Pis Min                  -8.335784
Policy mu Mean               0.099656925
Policy mu Std                0.53260577
Policy mu Max                2.1844072
Policy mu Min                -1.8814348
Policy log std Mean          -0.8946066
Policy log std Std           0.24529189
Policy log std Max           -0.29081985
Policy log std Min           -1.9683027
Z mean eval                  0.757516
Z variance eval              0.026491022
total_rewards                [ 250.72839853 2091.17053233 -119.82937364 1894.11435135  320.45984528
  631.99648251  400.41877832  448.29701302  501.47456606  432.93460701]
total_rewards_mean           685.1765200767588
total_rewards_std            681.5825066600264
total_rewards_max            2091.1705323296746
total_rewards_min            -119.8293736389557
Number of train steps total  136000
Number of env steps total    172000
Number of rollouts total     0
Train Time (s)               126.41388407582417
(Previous) Eval Time (s)     25.920317240059376
Sample Time (s)              22.78710697684437
Epoch Time (s)               175.12130829272792
Total Train Time (s)         5988.825811969116
Epoch                        33
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:12:44.091717 UTC | [2020_01_11_13_32_55] Iteration #33 | Epoch Duration: 176.43377161026
2020-01-11 15:12:44.091903 UTC | [2020_01_11_13_32_55] Iteration #33 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7568837
Z variance train             0.026457172
KL Divergence                17.337646
KL Loss                      1.7337646
QF Loss                      336.3694
VF Loss                      66.04157
Policy Loss                  -546.0017
Q Predictions Mean           542.449
Q Predictions Std            216.60916
Q Predictions Max            819.0118
Q Predictions Min            -4.600542
V Predictions Mean           544.4952
V Predictions Std            212.7195
V Predictions Max            811.53595
V Predictions Min            6.8459816
Log Pis Mean                 -0.9176176
Log Pis Std                  2.8334055
Log Pis Max                  17.705904
Log Pis Min                  -8.960157
Policy mu Mean               0.045971416
Policy mu Std                0.5356207
Policy mu Max                1.9283274
Policy mu Min                -2.1766167
Policy log std Mean          -0.8936336
Policy log std Std           0.26544538
Policy log std Max           -0.26460564
Policy log std Min           -1.9295645
Z mean eval                  0.77751267
Z variance eval              0.017867634
total_rewards                [1350.3422217  2185.82131047  891.12950347 1789.23898918  699.09143853
  237.43968575 1513.97476265 2050.62590759 1675.9115425   543.02031046]
total_rewards_mean           1293.659567230288
total_rewards_std            633.0102135808191
total_rewards_max            2185.8213104671304
total_rewards_min            237.43968575468614
Number of train steps total  140000
Number of env steps total    177000
Number of rollouts total     0
Train Time (s)               125.72507652034983
(Previous) Eval Time (s)     27.232383725233376
Sample Time (s)              24.35420347796753
Epoch Time (s)               177.31166372355074
Total Train Time (s)         6163.830156819895
Epoch                        34
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:15:39.096383 UTC | [2020_01_11_13_32_55] Iteration #34 | Epoch Duration: 175.0043704509735
2020-01-11 15:15:39.096500 UTC | [2020_01_11_13_32_55] Iteration #34 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.77806824
Z variance train             0.017833367
KL Divergence                18.156975
KL Loss                      1.8156976
QF Loss                      424.3365
VF Loss                      77.803246
Policy Loss                  -586.0151
Q Predictions Mean           584.1627
Q Predictions Std            204.93127
Q Predictions Max            826.70593
Q Predictions Min            -30.158377
V Predictions Mean           586.2443
V Predictions Std            201.80382
V Predictions Max            816.4277
V Predictions Min            3.6390676
Log Pis Mean                 -1.3035271
Log Pis Std                  2.2508647
Log Pis Max                  5.9717684
Log Pis Min                  -6.882897
Policy mu Mean               0.046323992
Policy mu Std                0.52575296
Policy mu Max                2.0236893
Policy mu Min                -2.1619625
Policy log std Mean          -0.8817761
Policy log std Std           0.22697507
Policy log std Max           -0.2003488
Policy log std Min           -1.7972369
Z mean eval                  0.78457224
Z variance eval              0.01309145
total_rewards                [1608.66485771 1242.26274255  300.68317788  621.24785126 2213.67512766
  145.71015387  471.28286823 1358.57424214 2147.98203328 2351.76257477]
total_rewards_mean           1246.1845629343877
total_rewards_std            788.140439236115
total_rewards_max            2351.7625747703787
total_rewards_min            145.71015386508975
Number of train steps total  144000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               125.66594886314124
(Previous) Eval Time (s)     24.92475626897067
Sample Time (s)              25.20315990317613
Epoch Time (s)               175.79386503528804
Total Train Time (s)         6339.276710573584
Epoch                        35
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:18:34.545587 UTC | [2020_01_11_13_32_55] Iteration #35 | Epoch Duration: 175.44895935058594
2020-01-11 15:18:34.545866 UTC | [2020_01_11_13_32_55] Iteration #35 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.787894
Z variance train             0.013049389
KL Divergence                17.599274
KL Loss                      1.7599274
QF Loss                      473.81964
VF Loss                      167.99379
Policy Loss                  -581.34894
Q Predictions Mean           575.1034
Q Predictions Std            226.8476
Q Predictions Max            873.5771
Q Predictions Min            10.593535
V Predictions Mean           575.01154
V Predictions Std            225.01744
V Predictions Max            860.0405
V Predictions Min            13.889943
Log Pis Mean                 -0.71828604
Log Pis Std                  2.679866
Log Pis Max                  8.83442
Log Pis Min                  -7.3898053
Policy mu Mean               0.07216155
Policy mu Std                0.569136
Policy mu Max                2.6637158
Policy mu Min                -2.2980998
Policy log std Mean          -0.90528095
Policy log std Std           0.27004606
Policy log std Max           -0.1690259
Policy log std Min           -2.1145298
Z mean eval                  0.78290546
Z variance eval              0.013112888
total_rewards                [  39.66546318 2131.74258105 1654.5751237  2065.30265756 2098.06451195
  840.00147735 1569.24623137 2080.41394279 1934.45339827 2199.94600801]
total_rewards_mean           1661.3411395216372
total_rewards_std            665.4664036541855
total_rewards_max            2199.9460080084923
total_rewards_min            39.66546317640413
Number of train steps total  148000
Number of env steps total    187000
Number of rollouts total     0
Train Time (s)               125.34336195094511
(Previous) Eval Time (s)     24.57934611197561
Sample Time (s)              25.959650367498398
Epoch Time (s)               175.88235843041912
Total Train Time (s)         6523.6383762802
Epoch                        36
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:21:38.908092 UTC | [2020_01_11_13_32_55] Iteration #36 | Epoch Duration: 184.36203622817993
2020-01-11 15:21:38.908265 UTC | [2020_01_11_13_32_55] Iteration #36 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7840488
Z variance train             0.013116503
KL Divergence                17.765974
KL Loss                      1.7765974
QF Loss                      450.97247
VF Loss                      188.0482
Policy Loss                  -602.6277
Q Predictions Mean           596.7726
Q Predictions Std            213.09111
Q Predictions Max            838.8436
Q Predictions Min            -1.3310971
V Predictions Mean           596.2788
V Predictions Std            212.98584
V Predictions Max            833.2825
V Predictions Min            55.478764
Log Pis Mean                 -0.9221666
Log Pis Std                  2.5935442
Log Pis Max                  8.757491
Log Pis Min                  -7.744424
Policy mu Mean               0.09036941
Policy mu Std                0.5226816
Policy mu Max                2.312826
Policy mu Min                -1.9464014
Policy log std Mean          -0.90076053
Policy log std Std           0.2563056
Policy log std Max           -0.29392833
Policy log std Min           -2.156591
Z mean eval                  0.7923409
Z variance eval              0.014971507
total_rewards                [2090.42239921 2246.38562472 2003.19059407  389.16401658 2438.73612985
 2267.66338183 1984.72922355  388.97982322 2237.63317973 1133.65049249]
total_rewards_mean           1718.0554865252393
total_rewards_std            744.0121656547226
total_rewards_max            2438.7361298457263
total_rewards_min            388.9798232182162
Number of train steps total  152000
Number of env steps total    192000
Number of rollouts total     0
Train Time (s)               126.24048133101314
(Previous) Eval Time (s)     33.0587520939298
Sample Time (s)              25.06628032028675
Epoch Time (s)               184.3655137452297
Total Train Time (s)         6706.350689617917
Epoch                        37
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:24:41.621556 UTC | [2020_01_11_13_32_55] Iteration #37 | Epoch Duration: 182.71316361427307
2020-01-11 15:24:41.621739 UTC | [2020_01_11_13_32_55] Iteration #37 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7885744
Z variance train             0.014982486
KL Divergence                18.178724
KL Loss                      1.8178724
QF Loss                      656.30853
VF Loss                      258.30096
Policy Loss                  -610.78723
Q Predictions Mean           604.55975
Q Predictions Std            221.73428
Q Predictions Max            864.5389
Q Predictions Min            -109.268295
V Predictions Mean           614.9912
V Predictions Std            216.1107
V Predictions Max            865.74316
V Predictions Min            57.42846
Log Pis Mean                 -0.76988006
Log Pis Std                  2.6501515
Log Pis Max                  12.57423
Log Pis Min                  -7.386525
Policy mu Mean               0.031897835
Policy mu Std                0.51242995
Policy mu Max                2.4969547
Policy mu Min                -1.7823087
Policy log std Mean          -0.93417937
Policy log std Std           0.26869658
Policy log std Max           -0.20876515
Policy log std Min           -2.203895
Z mean eval                  0.79548323
Z variance eval              0.020035487
total_rewards                [ 700.47503598  455.08188715 1535.16256116  119.9394653  1212.39876026
  972.11919028 2078.30677114  503.41408976 2041.26942423  -47.594077  ]
total_rewards_mean           957.0573108259821
total_rewards_std            711.7615271779127
total_rewards_max            2078.3067711401304
total_rewards_min            -47.594076997881245
Number of train steps total  156000
Number of env steps total    197000
Number of rollouts total     0
Train Time (s)               125.57465405017138
(Previous) Eval Time (s)     31.40608550142497
Sample Time (s)              25.386208320967853
Epoch Time (s)               182.3669478725642
Total Train Time (s)         6879.3890990307555
Epoch                        38
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:27:34.661224 UTC | [2020_01_11_13_32_55] Iteration #38 | Epoch Duration: 173.0393681526184
2020-01-11 15:27:34.661371 UTC | [2020_01_11_13_32_55] Iteration #38 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7943779
Z variance train             0.019980777
KL Divergence                17.546602
KL Loss                      1.7546602
QF Loss                      798.08203
VF Loss                      140.72873
Policy Loss                  -622.7958
Q Predictions Mean           619.709
Q Predictions Std            233.81906
Q Predictions Max            872.78485
Q Predictions Min            -5.032867
V Predictions Mean           622.563
V Predictions Std            228.46288
V Predictions Max            879.3278
V Predictions Min            49.43608
Log Pis Mean                 -0.7368337
Log Pis Std                  2.958499
Log Pis Max                  11.131329
Log Pis Min                  -9.162087
Policy mu Mean               0.047775403
Policy mu Std                0.5653848
Policy mu Max                2.320907
Policy mu Min                -2.2288225
Policy log std Mean          -0.9186958
Policy log std Std           0.28290275
Policy log std Max           -0.35711366
Policy log std Min           -2.281341
Z mean eval                  0.8036485
Z variance eval              0.016607188
total_rewards                [  20.63479148 2417.84720493 2420.67629685 2169.38566218  300.63970305
 2333.56730008 1347.36182518 2363.143969     62.06952242  104.11346688]
total_rewards_mean           1353.9439742063228
total_rewards_std            1050.291485940397
total_rewards_max            2420.676296851393
total_rewards_min            20.63479147939155
Number of train steps total  160000
Number of env steps total    202000
Number of rollouts total     0
Train Time (s)               125.9053034610115
(Previous) Eval Time (s)     22.078167446423322
Sample Time (s)              24.677830835804343
Epoch Time (s)               172.66130174323916
Total Train Time (s)         7062.336998006795
Epoch                        39
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:30:37.609565 UTC | [2020_01_11_13_32_55] Iteration #39 | Epoch Duration: 182.94808888435364
2020-01-11 15:30:37.609714 UTC | [2020_01_11_13_32_55] Iteration #39 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.804733
Z variance train             0.016602468
KL Divergence                18.376457
KL Loss                      1.8376458
QF Loss                      546.09216
VF Loss                      142.48352
Policy Loss                  -632.7651
Q Predictions Mean           627.9855
Q Predictions Std            234.74077
Q Predictions Max            891.9972
Q Predictions Min            17.123306
V Predictions Mean           630.28723
V Predictions Std            232.29892
V Predictions Max            876.0216
V Predictions Min            51.743244
Log Pis Mean                 -0.49256927
Log Pis Std                  2.7058742
Log Pis Max                  12.446697
Log Pis Min                  -7.610877
Policy mu Mean               0.033098828
Policy mu Std                0.56225926
Policy mu Max                3.0254633
Policy mu Min                -2.988424
Policy log std Mean          -0.930675
Policy log std Std           0.26854864
Policy log std Max           -0.31045216
Policy log std Min           -1.9081061
Z mean eval                  0.81735975
Z variance eval              0.015836341
total_rewards                [1314.70017511  205.93107764 2101.87096652 1235.84681337 1828.76917809
 2130.38027209  421.33876276 2116.25085398  183.17388963 2113.86320723]
total_rewards_mean           1365.212519642869
total_rewards_std            782.2341082089977
total_rewards_max            2130.380272093231
total_rewards_min            183.17388962852544
Number of train steps total  164000
Number of env steps total    207000
Number of rollouts total     0
Train Time (s)               131.07309862598777
(Previous) Eval Time (s)     32.364644926041365
Sample Time (s)              23.76567591773346
Epoch Time (s)               187.2034194697626
Total Train Time (s)         7245.820448952261
Epoch                        40
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:33:41.095075 UTC | [2020_01_11_13_32_55] Iteration #40 | Epoch Duration: 183.4852397441864
2020-01-11 15:33:41.095325 UTC | [2020_01_11_13_32_55] Iteration #40 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8187068
Z variance train             0.015887847
KL Divergence                18.827105
KL Loss                      1.8827105
QF Loss                      497.96313
VF Loss                      131.79349
Policy Loss                  -635.8689
Q Predictions Mean           630.7607
Q Predictions Std            244.42693
Q Predictions Max            919.4077
Q Predictions Min            -38.162964
V Predictions Mean           632.97144
V Predictions Std            241.2547
V Predictions Max            904.7617
V Predictions Min            19.710426
Log Pis Mean                 -1.0859146
Log Pis Std                  2.4890523
Log Pis Max                  10.292225
Log Pis Min                  -7.79408
Policy mu Mean               0.06921731
Policy mu Std                0.5184396
Policy mu Max                2.1099985
Policy mu Min                -1.9446115
Policy log std Mean          -0.9060863
Policy log std Std           0.24322112
Policy log std Max           -0.28086504
Policy log std Min           -1.955609
Z mean eval                  0.81776637
Z variance eval              0.022920892
total_rewards                [ 295.16882844  241.22233136  245.11907835 2573.90113199 2068.53480128
  558.60619536  502.38208438  -24.04391242  983.01179594 1562.95602167]
total_rewards_mean           900.6858356371619
total_rewards_std            834.925158070379
total_rewards_max            2573.9011319946667
total_rewards_min            -24.043912416433667
Number of train steps total  168000
Number of env steps total    212000
Number of rollouts total     0
Train Time (s)               136.33583637699485
(Previous) Eval Time (s)     28.646132532972842
Sample Time (s)              26.152984836604446
Epoch Time (s)               191.13495374657214
Total Train Time (s)         7427.386712094303
Epoch                        41
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:36:42.663028 UTC | [2020_01_11_13_32_55] Iteration #41 | Epoch Duration: 181.56755566596985
2020-01-11 15:36:42.663277 UTC | [2020_01_11_13_32_55] Iteration #41 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8186778
Z variance train             0.02294322
KL Divergence                17.821583
KL Loss                      1.7821583
QF Loss                      495.53345
VF Loss                      146.97583
Policy Loss                  -664.39655
Q Predictions Mean           661.4531
Q Predictions Std            245.57426
Q Predictions Max            942.95886
Q Predictions Min            -9.014097
V Predictions Mean           668.9005
V Predictions Std            239.3476
V Predictions Max            933.83826
V Predictions Min            46.41203
Log Pis Mean                 -0.90637195
Log Pis Std                  2.5873058
Log Pis Max                  7.9191575
Log Pis Min                  -9.3591
Policy mu Mean               0.025969345
Policy mu Std                0.5775364
Policy mu Max                1.8871803
Policy mu Min                -1.974525
Policy log std Mean          -0.899712
Policy log std Std           0.27295896
Policy log std Max           -0.23451805
Policy log std Min           -2.6061468
Z mean eval                  0.8368314
Z variance eval              0.032679435
total_rewards                [ 891.95736227 1977.2113682   215.14748574  466.25144133  271.84447895
 2071.45587269  876.05781331 1147.16931929 2233.90503251 2184.38988374]
total_rewards_mean           1233.5390058022529
total_rewards_std            772.1814061803465
total_rewards_max            2233.9050325086328
total_rewards_min            215.14748573770854
Number of train steps total  172000
Number of env steps total    217000
Number of rollouts total     0
Train Time (s)               134.9040307868272
(Previous) Eval Time (s)     19.078349522780627
Sample Time (s)              25.495207979809493
Epoch Time (s)               179.47758828941733
Total Train Time (s)         7607.466649215668
Epoch                        42
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:39:42.744352 UTC | [2020_01_11_13_32_55] Iteration #42 | Epoch Duration: 180.0809383392334
2020-01-11 15:39:42.744537 UTC | [2020_01_11_13_32_55] Iteration #42 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8383497
Z variance train             0.03273553
KL Divergence                17.864437
KL Loss                      1.7864437
QF Loss                      500.57913
VF Loss                      98.54775
Policy Loss                  -657.11444
Q Predictions Mean           654.20557
Q Predictions Std            252.45203
Q Predictions Max            955.6535
Q Predictions Min            31.393864
V Predictions Mean           656.3386
V Predictions Std            250.85368
V Predictions Max            953.1464
V Predictions Min            56.495335
Log Pis Mean                 -0.79789555
Log Pis Std                  2.6656778
Log Pis Max                  11.101202
Log Pis Min                  -8.27791
Policy mu Mean               -0.008643118
Policy mu Std                0.5527068
Policy mu Max                2.119039
Policy mu Min                -2.1923745
Policy log std Mean          -0.88878775
Policy log std Std           0.25169355
Policy log std Max           -0.30199355
Policy log std Min           -1.9066098
Z mean eval                  0.8251422
Z variance eval              0.03642284
total_rewards                [1398.62409225 1668.25000791  179.70276712 2155.6184898   341.17711066
 1718.5615477   356.41447016 1631.50797171   93.25123467   12.12576886]
total_rewards_mean           955.5233460855188
total_rewards_std            784.569367660065
total_rewards_max            2155.618489804293
total_rewards_min            12.125768855177038
Number of train steps total  176000
Number of env steps total    222000
Number of rollouts total     0
Train Time (s)               135.1776237669401
(Previous) Eval Time (s)     19.681318640243262
Sample Time (s)              25.681853973306715
Epoch Time (s)               180.54079638049006
Total Train Time (s)         7791.24269412877
Epoch                        43
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:42:46.522532 UTC | [2020_01_11_13_32_55] Iteration #43 | Epoch Duration: 183.77783751487732
2020-01-11 15:42:46.522866 UTC | [2020_01_11_13_32_55] Iteration #43 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8242177
Z variance train             0.036525954
KL Divergence                16.46532
KL Loss                      1.646532
QF Loss                      694.94116
VF Loss                      155.67563
Policy Loss                  -659.5883
Q Predictions Mean           656.79346
Q Predictions Std            262.87762
Q Predictions Max            933.0602
Q Predictions Min            -7.313562
V Predictions Mean           653.53796
V Predictions Std            259.9527
V Predictions Max            927.4499
V Predictions Min            -21.775555
Log Pis Mean                 -0.7563485
Log Pis Std                  2.7633696
Log Pis Max                  11.328501
Log Pis Min                  -8.624754
Policy mu Mean               0.07180473
Policy mu Std                0.58416164
Policy mu Max                2.5646691
Policy mu Min                -1.853247
Policy log std Mean          -0.881889
Policy log std Std           0.25509283
Policy log std Max           -0.2027229
Policy log std Min           -2.1485026
Z mean eval                  0.8446434
Z variance eval              0.05877443
total_rewards                [ -23.49482928 2272.46375728  171.59382453  948.05571196 2356.54368788
  183.99790702  839.84112847 2340.00036182 1140.7041574    27.75375635]
total_rewards_mean           1025.745946343061
total_rewards_std            929.5920926461548
total_rewards_max            2356.543687875669
total_rewards_min            -23.49482928405022
Number of train steps total  180000
Number of env steps total    227000
Number of rollouts total     0
Train Time (s)               133.8462900677696
(Previous) Eval Time (s)     22.917940173763782
Sample Time (s)              25.13200576370582
Epoch Time (s)               181.8962360052392
Total Train Time (s)         7973.092126372736
Epoch                        44
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:45:48.373284 UTC | [2020_01_11_13_32_55] Iteration #44 | Epoch Duration: 181.85019636154175
2020-01-11 15:45:48.373478 UTC | [2020_01_11_13_32_55] Iteration #44 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.84198284
Z variance train             0.059501678
KL Divergence                16.016258
KL Loss                      1.6016258
QF Loss                      610.43115
VF Loss                      128.82138
Policy Loss                  -704.23486
Q Predictions Mean           699.2994
Q Predictions Std            250.48083
Q Predictions Max            941.4511
Q Predictions Min            73.88993
V Predictions Mean           699.4391
V Predictions Std            247.47023
V Predictions Max            930.04144
V Predictions Min            51.297256
Log Pis Mean                 -0.49411452
Log Pis Std                  2.4081008
Log Pis Max                  6.073936
Log Pis Min                  -7.418024
Policy mu Mean               0.042564325
Policy mu Std                0.5884198
Policy mu Max                1.9336038
Policy mu Min                -2.4575922
Policy log std Mean          -0.8911953
Policy log std Std           0.24237257
Policy log std Max           -0.276703
Policy log std Min           -1.8574368
Z mean eval                  0.8532349
Z variance eval              0.050279744
total_rewards                [-108.47384463 1378.90203393   24.75168351  468.50155304 1573.65491772
 1812.60859537 1061.50745818  833.69572973  581.0168721    -4.61245653]
total_rewards_mean           762.1552542410642
total_rewards_std            651.6000064109021
total_rewards_max            1812.608595374897
total_rewards_min            -108.47384463419964
Number of train steps total  184000
Number of env steps total    232000
Number of rollouts total     0
Train Time (s)               125.80451006675139
(Previous) Eval Time (s)     22.871513959020376
Sample Time (s)              26.324593487661332
Epoch Time (s)               175.0006175134331
Total Train Time (s)         8150.006968299858
Epoch                        45
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:48:45.289280 UTC | [2020_01_11_13_32_55] Iteration #45 | Epoch Duration: 176.9156711101532
2020-01-11 15:48:45.289459 UTC | [2020_01_11_13_32_55] Iteration #45 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.85285026
Z variance train             0.050096713
KL Divergence                16.345675
KL Loss                      1.6345675
QF Loss                      760.6096
VF Loss                      113.6784
Policy Loss                  -695.90436
Q Predictions Mean           694.1046
Q Predictions Std            250.59256
Q Predictions Max            977.56
Q Predictions Min            96.91671
V Predictions Mean           693.001
V Predictions Std            249.62146
V Predictions Max            964.12177
V Predictions Min            85.483345
Log Pis Mean                 -0.5522641
Log Pis Std                  2.3580084
Log Pis Max                  8.905122
Log Pis Min                  -6.8421803
Policy mu Mean               0.07687683
Policy mu Std                0.5440869
Policy mu Max                2.0330715
Policy mu Min                -1.8594761
Policy log std Mean          -0.9327756
Policy log std Std           0.2537182
Policy log std Max           -0.29013377
Policy log std Min           -2.132825
Z mean eval                  0.84497184
Z variance eval              0.028530782
total_rewards                [ 1.90868608e+03 -6.88454134e+01  1.64664821e+03  1.81223112e+00
  2.37980251e+03  2.33977754e+03  1.89797405e+03  5.96768256e+02
  1.11961407e+03  3.70355581e+02]
total_rewards_mean           1219.2593117683055
total_rewards_std            893.3363792945546
total_rewards_max            2379.802511013663
total_rewards_min            -68.8454133880685
Number of train steps total  188000
Number of env steps total    237000
Number of rollouts total     0
Train Time (s)               126.6446228902787
(Previous) Eval Time (s)     24.786187783814967
Sample Time (s)              24.681345224380493
Epoch Time (s)               176.11215589847416
Total Train Time (s)         8329.487577046268
Epoch                        46
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:51:44.771812 UTC | [2020_01_11_13_32_55] Iteration #46 | Epoch Duration: 179.48219919204712
2020-01-11 15:51:44.772021 UTC | [2020_01_11_13_32_55] Iteration #46 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8456017
Z variance train             0.02848599
KL Divergence                18.284428
KL Loss                      1.8284428
QF Loss                      502.42786
VF Loss                      80.35744
Policy Loss                  -725.8601
Q Predictions Mean           724.36334
Q Predictions Std            248.0141
Q Predictions Max            968.396
Q Predictions Min            6.3984838
V Predictions Mean           725.2075
V Predictions Std            244.93906
V Predictions Max            973.3407
V Predictions Min            13.433778
Log Pis Mean                 -0.45341843
Log Pis Std                  2.4164598
Log Pis Max                  5.6136894
Log Pis Min                  -8.173456
Policy mu Mean               0.04722492
Policy mu Std                0.56452614
Policy mu Max                1.8529675
Policy mu Min                -2.1403904
Policy log std Mean          -0.9413166
Policy log std Std           0.23867925
Policy log std Max           -0.21983641
Policy log std Min           -1.8738759
Z mean eval                  0.8376535
Z variance eval              0.060958445
total_rewards                [ 466.57135767 2691.32617302 2385.59453857  168.39951256  -13.33534248
  155.91573768   -4.81446947 1420.5509423  1746.50039508  964.05537369]
total_rewards_mean           998.0764218615717
total_rewards_std            961.2971321018086
total_rewards_max            2691.3261730186628
total_rewards_min            -13.335342481043769
Number of train steps total  192000
Number of env steps total    242000
Number of rollouts total     0
Train Time (s)               126.02282190695405
(Previous) Eval Time (s)     28.155919077806175
Sample Time (s)              24.571541210170835
Epoch Time (s)               178.75028219493106
Total Train Time (s)         8502.940098692197
Epoch                        47
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:54:38.224073 UTC | [2020_01_11_13_32_55] Iteration #47 | Epoch Duration: 173.4519326686859
2020-01-11 15:54:38.224192 UTC | [2020_01_11_13_32_55] Iteration #47 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.83785284
Z variance train             0.06105548
KL Divergence                17.222776
KL Loss                      1.7222776
QF Loss                      586.67456
VF Loss                      196.51309
Policy Loss                  -706.39044
Q Predictions Mean           705.88745
Q Predictions Std            254.19554
Q Predictions Max            967.10297
Q Predictions Min            29.407558
V Predictions Mean           713.13403
V Predictions Std            256.2783
V Predictions Max            969.44867
V Predictions Min            6.099176
Log Pis Mean                 -0.32401985
Log Pis Std                  2.8435423
Log Pis Max                  12.856312
Log Pis Min                  -6.3496637
Policy mu Mean               0.013321747
Policy mu Std                0.59171623
Policy mu Max                2.777774
Policy mu Min                -2.3656468
Policy log std Mean          -0.9145709
Policy log std Std           0.2661927
Policy log std Max           -0.04219973
Policy log std Min           -2.2373013
Z mean eval                  0.84524524
Z variance eval              0.033802815
total_rewards                [ 747.26650075  312.17086995  776.97955824 2201.35553134  174.84189417
  628.48894712  709.74260133  115.27131376 1896.38787584  644.79717131]
total_rewards_mean           820.7302263825355
total_rewards_std            657.5850277962167
total_rewards_max            2201.3555313416264
total_rewards_min            115.2713137597952
Number of train steps total  196000
Number of env steps total    247000
Number of rollouts total     0
Train Time (s)               126.25621558027342
(Previous) Eval Time (s)     22.857274861074984
Sample Time (s)              24.89548086654395
Epoch Time (s)               174.00897130789235
Total Train Time (s)         8670.60289611714
Epoch                        48
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:57:25.890165 UTC | [2020_01_11_13_32_55] Iteration #48 | Epoch Duration: 167.6658535003662
2020-01-11 15:57:25.890364 UTC | [2020_01_11_13_32_55] Iteration #48 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8492729
Z variance train             0.033930413
KL Divergence                18.640345
KL Loss                      1.8640345
QF Loss                      609.333
VF Loss                      271.4426
Policy Loss                  -697.1043
Q Predictions Mean           692.55164
Q Predictions Std            277.67798
Q Predictions Max            996.7868
Q Predictions Min            -1.484637
V Predictions Mean           687.93225
V Predictions Std            273.4485
V Predictions Max            979.6314
V Predictions Min            -13.5370455
Log Pis Mean                 -0.5416063
Log Pis Std                  3.0245867
Log Pis Max                  14.87431
Log Pis Min                  -7.7471313
Policy mu Mean               0.021860195
Policy mu Std                0.5713947
Policy mu Max                2.3468227
Policy mu Min                -2.977677
Policy log std Mean          -0.9253502
Policy log std Std           0.30703825
Policy log std Max           -0.047538757
Policy log std Min           -2.6912148
Z mean eval                  0.8409277
Z variance eval              0.03575108
total_rewards                [ 477.85609653   52.68965077  317.08310128   70.22494888  538.54618244
 1004.99466639 1738.66685276  224.68124256 1537.73012948 2475.09125061]
total_rewards_mean           843.7564121714404
total_rewards_std            779.8415261946606
total_rewards_max            2475.091250612112
total_rewards_min            52.68965077091854
Number of train steps total  200000
Number of env steps total    252000
Number of rollouts total     0
Train Time (s)               126.91347189992666
(Previous) Eval Time (s)     16.51387388492003
Sample Time (s)              25.653751553967595
Epoch Time (s)               169.0810973388143
Total Train Time (s)         8843.24358126428
Epoch                        49
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:00:18.529988 UTC | [2020_01_11_13_32_55] Iteration #49 | Epoch Duration: 172.63950777053833
2020-01-11 16:00:18.530107 UTC | [2020_01_11_13_32_55] Iteration #49 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8405762
Z variance train             0.035702445
KL Divergence                18.641432
KL Loss                      1.8641433
QF Loss                      743.97327
VF Loss                      140.27599
Policy Loss                  -725.95026
Q Predictions Mean           720.7717
Q Predictions Std            269.2994
Q Predictions Max            1006.78156
Q Predictions Min            -46.949154
V Predictions Mean           731.4605
V Predictions Std            264.6647
V Predictions Max            1002.4575
V Predictions Min            90.9486
Log Pis Mean                 -0.42881125
Log Pis Std                  2.837774
Log Pis Max                  13.239417
Log Pis Min                  -7.1004133
Policy mu Mean               0.034151964
Policy mu Std                0.5642846
Policy mu Max                2.208765
Policy mu Min                -2.5005896
Policy log std Mean          -0.9483154
Policy log std Std           0.2883871
Policy log std Max           -0.28523058
Policy log std Min           -2.2700322
Z mean eval                  0.8607036
Z variance eval              0.07634913
total_rewards                [ 785.51367878  799.9454458  2475.82136344  731.07072174 1148.61080768
   24.7410999   530.64665312  771.97046078  568.16637138  874.57241539]
total_rewards_mean           871.1059018015578
total_rewards_std            601.4963396215873
total_rewards_max            2475.82136343731
total_rewards_min            24.741099896667073
Number of train steps total  204000
Number of env steps total    257000
Number of rollouts total     0
Train Time (s)               126.31766733666882
(Previous) Eval Time (s)     20.071935954038054
Sample Time (s)              23.928589562885463
Epoch Time (s)               170.31819285359234
Total Train Time (s)         9015.22086599702
Epoch                        50
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:03:10.509256 UTC | [2020_01_11_13_32_55] Iteration #50 | Epoch Duration: 171.97905492782593
2020-01-11 16:03:10.509425 UTC | [2020_01_11_13_32_55] Iteration #50 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8564833
Z variance train             0.07622816
KL Divergence                17.268103
KL Loss                      1.7268103
QF Loss                      610.7407
VF Loss                      223.52322
Policy Loss                  -722.114
Q Predictions Mean           714.99194
Q Predictions Std            271.29645
Q Predictions Max            980.4551
Q Predictions Min            -106.785095
V Predictions Mean           715.1666
V Predictions Std            262.48492
V Predictions Max            974.7498
V Predictions Min            24.76604
Log Pis Mean                 -0.46883202
Log Pis Std                  2.9445662
Log Pis Max                  11.113976
Log Pis Min                  -7.169797
Policy mu Mean               0.029300278
Policy mu Std                0.6011078
Policy mu Max                2.306597
Policy mu Min                -2.6237442
Policy log std Mean          -0.9462824
Policy log std Std           0.27418742
Policy log std Max           -0.2489829
Policy log std Min           -2.2631123
Z mean eval                  0.8569533
Z variance eval              0.05237869
total_rewards                [  40.13292888  521.16315598 1792.2065131  1077.66519473 2524.27815559
  850.25015587  755.43322007  179.03013057 2458.50940362 2699.58577951]
total_rewards_mean           1289.8254637933883
total_rewards_std            950.7764939652071
total_rewards_max            2699.58577950502
total_rewards_min            40.132928884940014
Number of train steps total  208000
Number of env steps total    262000
Number of rollouts total     0
Train Time (s)               128.48183460207656
(Previous) Eval Time (s)     21.732529938220978
Sample Time (s)              23.93890363071114
Epoch Time (s)               174.15326817100868
Total Train Time (s)         9196.055280325934
Epoch                        51
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:06:11.345697 UTC | [2020_01_11_13_32_55] Iteration #51 | Epoch Duration: 180.8361415863037
2020-01-11 16:06:11.345893 UTC | [2020_01_11_13_32_55] Iteration #51 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.860139
Z variance train             0.05226434
KL Divergence                16.813412
KL Loss                      1.6813412
QF Loss                      543.8037
VF Loss                      190.53055
Policy Loss                  -749.5875
Q Predictions Mean           745.8888
Q Predictions Std            270.92633
Q Predictions Max            1025.6611
Q Predictions Min            5.4493017
V Predictions Mean           741.85455
V Predictions Std            266.41998
V Predictions Max            1014.2677
V Predictions Min            51.438255
Log Pis Mean                 -0.7194087
Log Pis Std                  2.9604862
Log Pis Max                  10.832129
Log Pis Min                  -8.98059
Policy mu Mean               0.06694156
Policy mu Std                0.5631464
Policy mu Max                1.9101496
Policy mu Min                -1.9951457
Policy log std Mean          -0.93716705
Policy log std Std           0.27315533
Policy log std Max           -0.13556385
Policy log std Min           -2.0494454
Z mean eval                  0.86310846
Z variance eval              0.039255157
total_rewards                [1571.11473813 1520.74846934  595.07540808 1893.5498502   844.03960019
  360.31873728  685.47034796  571.667568   1100.3870999   537.77343433]
total_rewards_mean           968.0145253403573
total_rewards_std            498.9148096427034
total_rewards_max            1893.5498501998213
total_rewards_min            360.31873727674093
Number of train steps total  212000
Number of env steps total    267000
Number of rollouts total     0
Train Time (s)               126.99237988004461
(Previous) Eval Time (s)     28.41504619223997
Sample Time (s)              24.903201424051076
Epoch Time (s)               180.31062749633566
Total Train Time (s)         9367.310567767825
Epoch                        52
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:09:02.602196 UTC | [2020_01_11_13_32_55] Iteration #52 | Epoch Duration: 171.256174325943
2020-01-11 16:09:02.602381 UTC | [2020_01_11_13_32_55] Iteration #52 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8638094
Z variance train             0.039113767
KL Divergence                18.33926
KL Loss                      1.8339261
QF Loss                      945.3413
VF Loss                      175.45471
Policy Loss                  -727.0141
Q Predictions Mean           719.5515
Q Predictions Std            290.13974
Q Predictions Max            1017.1377
Q Predictions Min            -9.049314
V Predictions Mean           720.453
V Predictions Std            282.88477
V Predictions Max            996.99786
V Predictions Min            37.342888
Log Pis Mean                 -0.46548805
Log Pis Std                  2.9776845
Log Pis Max                  14.690637
Log Pis Min                  -6.757197
Policy mu Mean               0.037727423
Policy mu Std                0.59302884
Policy mu Max                2.164382
Policy mu Min                -2.5016267
Policy log std Mean          -0.9370233
Policy log std Std           0.29356986
Policy log std Max           -0.19467294
Policy log std Min           -2.2708719
Z mean eval                  0.8643851
Z variance eval              0.039128356
total_rewards                [ 867.79095432 2633.8480594   182.01905553 2431.4742164   940.44081978
 1441.19134876  862.02995243 1610.46573161 2457.54654359  951.17101762]
total_rewards_mean           1437.7977699440912
total_rewards_std            787.7314605185045
total_rewards_max            2633.8480593964046
total_rewards_min            182.01905553421287
Number of train steps total  216000
Number of env steps total    272000
Number of rollouts total     0
Train Time (s)               127.23232505004853
(Previous) Eval Time (s)     19.3602738189511
Sample Time (s)              25.126804781146348
Epoch Time (s)               171.71940365014598
Total Train Time (s)         9543.76228998322
Epoch                        53
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:11:59.055688 UTC | [2020_01_11_13_32_55] Iteration #53 | Epoch Duration: 176.4531729221344
2020-01-11 16:11:59.055882 UTC | [2020_01_11_13_32_55] Iteration #53 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8634173
Z variance train             0.039265886
KL Divergence                18.79985
KL Loss                      1.8799851
QF Loss                      576.7193
VF Loss                      294.10956
Policy Loss                  -724.46814
Q Predictions Mean           720.34393
Q Predictions Std            313.0508
Q Predictions Max            1054.1609
Q Predictions Min            -39.717373
V Predictions Mean           722.02954
V Predictions Std            306.97424
V Predictions Max            1039.2329
V Predictions Min            12.14985
Log Pis Mean                 -0.4424157
Log Pis Std                  2.8756385
Log Pis Max                  11.830001
Log Pis Min                  -6.805096
Policy mu Mean               -0.0083208475
Policy mu Std                0.55858713
Policy mu Max                2.2005763
Policy mu Min                -2.475532
Policy log std Mean          -0.960769
Policy log std Std           0.28839684
Policy log std Max           -0.32464024
Policy log std Min           -2.3268485
Z mean eval                  0.85899895
Z variance eval              0.046619676
total_rewards                [1034.25288097  996.24757851  789.12302389 2695.89201013 1546.24671412
   54.03143758  406.7653307   -79.34236974 2589.65589285 1659.20489887]
total_rewards_mean           1169.2077397886303
total_rewards_std            911.4329285079386
total_rewards_max            2695.892010130199
total_rewards_min            -79.34236973792997
Number of train steps total  220000
Number of env steps total    277000
Number of rollouts total     0
Train Time (s)               126.60790498601273
(Previous) Eval Time (s)     24.09373795473948
Sample Time (s)              25.040266897063702
Epoch Time (s)               175.7419098378159
Total Train Time (s)         9720.479429763276
Epoch                        54
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:14:55.774213 UTC | [2020_01_11_13_32_55] Iteration #54 | Epoch Duration: 176.71819496154785
2020-01-11 16:14:55.774408 UTC | [2020_01_11_13_32_55] Iteration #54 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.85924214
Z variance train             0.046307568
KL Divergence                17.366962
KL Loss                      1.7366962
QF Loss                      651.7549
VF Loss                      136.10489
Policy Loss                  -774.7694
Q Predictions Mean           769.9918
Q Predictions Std            281.18155
Q Predictions Max            1036.0132
Q Predictions Min            -22.204233
V Predictions Mean           778.9347
V Predictions Std            280.2534
V Predictions Max            1032.3411
V Predictions Min            4.3519335
Log Pis Mean                 -0.5830561
Log Pis Std                  2.6876738
Log Pis Max                  9.654328
Log Pis Min                  -8.097537
Policy mu Mean               0.05562467
Policy mu Std                0.56515676
Policy mu Max                1.8929049
Policy mu Min                -1.941447
Policy log std Mean          -0.9264306
Policy log std Std           0.25751817
Policy log std Max           -0.24558699
Policy log std Min           -2.331977
Z mean eval                  0.8761754
Z variance eval              0.025444662
total_rewards                [1061.63408401  914.73815854 2378.00360939  145.31326552 1153.62720555
 1194.85047159  202.70391791 1678.50962031  406.59520685 1586.28071142]
total_rewards_mean           1072.2256251101085
total_rewards_std            666.4656770844572
total_rewards_max            2378.00360938979
total_rewards_min            145.3132655234612
Number of train steps total  224000
Number of env steps total    282000
Number of rollouts total     0
Train Time (s)               126.46560489106923
(Previous) Eval Time (s)     25.0696769640781
Sample Time (s)              23.897761055268347
Epoch Time (s)               175.43304291041568
Total Train Time (s)         9898.120193038601
Epoch                        55
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:17:53.416832 UTC | [2020_01_11_13_32_55] Iteration #55 | Epoch Duration: 177.6422917842865
2020-01-11 16:17:53.417029 UTC | [2020_01_11_13_32_55] Iteration #55 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8795465
Z variance train             0.025361946
KL Divergence                18.893007
KL Loss                      1.8893007
QF Loss                      824.8265
VF Loss                      216.64172
Policy Loss                  -783.8082
Q Predictions Mean           778.64343
Q Predictions Std            288.41907
Q Predictions Max            1075.1777
Q Predictions Min            -5.8647423
V Predictions Mean           775.56696
V Predictions Std            285.56628
V Predictions Max            1066.2046
V Predictions Min            9.7018385
Log Pis Mean                 -0.16298044
Log Pis Std                  3.036521
Log Pis Max                  10.791923
Log Pis Min                  -7.842062
Policy mu Mean               -0.012850042
Policy mu Std                0.60640883
Policy mu Max                2.9378784
Policy mu Min                -2.4908195
Policy log std Mean          -0.9507739
Policy log std Std           0.29066747
Policy log std Max           -0.23343277
Policy log std Min           -2.4490087
Z mean eval                  0.89212114
Z variance eval              0.031540543
total_rewards                [1623.12928002 2544.18008322 1848.01351238  747.87853283 2460.92903613
 2566.05879387 2118.55147477   97.90298159 1754.5459007  2824.40508345]
total_rewards_mean           1858.5594678952173
total_rewards_std            820.5982228141993
total_rewards_max            2824.4050834515956
total_rewards_min            97.90298159027216
Number of train steps total  228000
Number of env steps total    287000
Number of rollouts total     0
Train Time (s)               127.75542735727504
(Previous) Eval Time (s)     27.278577781748027
Sample Time (s)              22.110043805092573
Epoch Time (s)               177.14404894411564
Total Train Time (s)         10072.336369452998
Epoch                        56
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:20:47.634649 UTC | [2020_01_11_13_32_55] Iteration #56 | Epoch Duration: 174.2174859046936
2020-01-11 16:20:47.634845 UTC | [2020_01_11_13_32_55] Iteration #56 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89246416
Z variance train             0.03145086
KL Divergence                18.6156
KL Loss                      1.8615601
QF Loss                      1043.6439
VF Loss                      216.27332
Policy Loss                  -768.4052
Q Predictions Mean           764.4315
Q Predictions Std            288.78967
Q Predictions Max            1075.014
Q Predictions Min            12.51948
V Predictions Mean           765.8063
V Predictions Std            287.6429
V Predictions Max            1079.2698
V Predictions Min            22.88461
Log Pis Mean                 -0.30225876
Log Pis Std                  3.0915332
Log Pis Max                  13.458205
Log Pis Min                  -6.8225646
Policy mu Mean               0.030247122
Policy mu Std                0.5830227
Policy mu Max                2.6604238
Policy mu Min                -2.6985643
Policy log std Mean          -0.96891975
Policy log std Std           0.3218455
Policy log std Max           -0.14693123
Policy log std Min           -2.3116927
Z mean eval                  0.9048454
Z variance eval              0.043072756
total_rewards                [ 703.52287745 2059.31008645  784.75914177  631.56176356  461.82311972
  211.67021947 2660.75578352  237.43989959 1160.9104364    40.01345322]
total_rewards_mean           895.1766781138143
total_rewards_std            805.0096168113479
total_rewards_max            2660.755783523366
total_rewards_min            40.0134532160216
Number of train steps total  232000
Number of env steps total    292000
Number of rollouts total     0
Train Time (s)               126.32607761817053
(Previous) Eval Time (s)     24.35165914427489
Sample Time (s)              25.6605198350735
Epoch Time (s)               176.33825659751892
Total Train Time (s)         10256.119708673563
Epoch                        57
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:23:51.418737 UTC | [2020_01_11_13_32_55] Iteration #57 | Epoch Duration: 183.78376746177673
2020-01-11 16:23:51.418893 UTC | [2020_01_11_13_32_55] Iteration #57 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9022748
Z variance train             0.04315966
KL Divergence                17.824339
KL Loss                      1.7824339
QF Loss                      943.8574
VF Loss                      244.75859
Policy Loss                  -747.6035
Q Predictions Mean           743.06836
Q Predictions Std            313.71512
Q Predictions Max            1064.6669
Q Predictions Min            -9.362322
V Predictions Mean           741.3704
V Predictions Std            310.07925
V Predictions Max            1050.566
V Predictions Min            -26.028835
Log Pis Mean                 -0.19302888
Log Pis Std                  3.1424737
Log Pis Max                  11.30927
Log Pis Min                  -10.02799
Policy mu Mean               0.082654014
Policy mu Std                0.61533475
Policy mu Max                2.3979926
Policy mu Min                -2.093487
Policy log std Mean          -0.9310897
Policy log std Std           0.2973296
Policy log std Max           -0.15759009
Policy log std Min           -2.292118
Z mean eval                  0.873404
Z variance eval              0.020075448
total_rewards                [2675.6564076   276.70663701 2836.49379835 2554.92036655 1328.80460071
 2725.55088139 2804.0379835  2678.07397335  799.63957056 2100.11722152]
total_rewards_mean           2078.000144054078
total_rewards_std            889.2214131252953
total_rewards_max            2836.4937983460886
total_rewards_min            276.7066370070541
Number of train steps total  236000
Number of env steps total    297000
Number of rollouts total     0
Train Time (s)               127.72399373119697
(Previous) Eval Time (s)     31.796869184821844
Sample Time (s)              23.752214019652456
Epoch Time (s)               183.27307693567127
Total Train Time (s)         10442.046132287476
Epoch                        58
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:26:57.347665 UTC | [2020_01_11_13_32_55] Iteration #58 | Epoch Duration: 185.92864441871643
2020-01-11 16:26:57.347860 UTC | [2020_01_11_13_32_55] Iteration #58 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8728526
Z variance train             0.020078892
KL Divergence                19.28822
KL Loss                      1.9288219
QF Loss                      562.3633
VF Loss                      97.2012
Policy Loss                  -779.3152
Q Predictions Mean           774.8933
Q Predictions Std            301.9453
Q Predictions Max            1062.3119
Q Predictions Min            -34.835236
V Predictions Mean           781.17505
V Predictions Std            297.56577
V Predictions Max            1067.7239
V Predictions Min            -22.612738
Log Pis Mean                 -0.3473501
Log Pis Std                  2.771926
Log Pis Max                  9.1737385
Log Pis Min                  -6.9576626
Policy mu Mean               0.020654645
Policy mu Std                0.57914466
Policy mu Max                2.2367573
Policy mu Min                -2.0712838
Policy log std Mean          -0.9511922
Policy log std Std           0.28482547
Policy log std Max           -0.25847512
Policy log std Min           -2.2578967
Z mean eval                  0.8728201
Z variance eval              0.030669073
total_rewards                [ 594.66841227 1519.01212567  325.19231693  395.93955306  348.79466991
 1493.64656071 1731.43810639  148.70771458   45.05215934  434.60163045]
total_rewards_mean           703.705324930608
total_rewards_std            594.564767940323
total_rewards_max            1731.438106393033
total_rewards_min            45.05215934414594
Number of train steps total  240000
Number of env steps total    302000
Number of rollouts total     0
Train Time (s)               133.08700967300683
(Previous) Eval Time (s)     34.452165519818664
Sample Time (s)              25.702171940356493
Epoch Time (s)               193.241347133182
Total Train Time (s)         10613.017939783167
Epoch                        59
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:29:48.319094 UTC | [2020_01_11_13_32_55] Iteration #59 | Epoch Duration: 170.97111821174622
2020-01-11 16:29:48.319221 UTC | [2020_01_11_13_32_55] Iteration #59 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.87602216
Z variance train             0.030607233
KL Divergence                18.065176
KL Loss                      1.8065176
QF Loss                      971.12585
VF Loss                      325.66257
Policy Loss                  -791.14484
Q Predictions Mean           787.98126
Q Predictions Std            303.23846
Q Predictions Max            1069.8601
Q Predictions Min            -42.896015
V Predictions Mean           800.5425
V Predictions Std            299.57574
V Predictions Max            1073.6262
V Predictions Min            5.6558876
Log Pis Mean                 -0.32901388
Log Pis Std                  3.1830592
Log Pis Max                  15.945686
Log Pis Min                  -8.524189
Policy mu Mean               -0.0030623553
Policy mu Std                0.6052842
Policy mu Max                2.835762
Policy mu Min                -2.8731637
Policy log std Mean          -0.92383754
Policy log std Std           0.28804356
Policy log std Max           -0.08109915
Policy log std Min           -2.5143452
Z mean eval                  0.86646926
Z variance eval              0.022983614
total_rewards                [ 772.59754943  836.63076168  210.23298985 2724.28257107  582.05396738
  593.11667501  490.39662571   50.46149614  917.66672117  109.33146922]
total_rewards_mean           728.6770826645486
total_rewards_std            723.9297990363093
total_rewards_max            2724.2825710675297
total_rewards_min            50.461496138356814
Number of train steps total  244000
Number of env steps total    307000
Number of rollouts total     0
Train Time (s)               136.61681617517024
(Previous) Eval Time (s)     12.181567022111267
Sample Time (s)              25.534096208401024
Epoch Time (s)               174.33247940568253
Total Train Time (s)         10796.385271491017
Epoch                        60
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:32:51.689084 UTC | [2020_01_11_13_32_55] Iteration #60 | Epoch Duration: 183.36971020698547
2020-01-11 16:32:51.689288 UTC | [2020_01_11_13_32_55] Iteration #60 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8652975
Z variance train             0.02301374
KL Divergence                19.31451
KL Loss                      1.9314511
QF Loss                      941.06635
VF Loss                      261.7601
Policy Loss                  -806.75757
Q Predictions Mean           804.6033
Q Predictions Std            284.77512
Q Predictions Max            1064.0824
Q Predictions Min            -31.157387
V Predictions Mean           812.81793
V Predictions Std            280.0474
V Predictions Max            1061.5269
V Predictions Min            46.64357
Log Pis Mean                 -0.29193076
Log Pis Std                  2.833113
Log Pis Max                  11.983274
Log Pis Min                  -8.653289
Policy mu Mean               0.053844728
Policy mu Std                0.59192616
Policy mu Max                1.9733257
Policy mu Min                -2.184417
Policy log std Mean          -0.94409746
Policy log std Std           0.31873757
Policy log std Max           -0.062129974
Policy log std Min           -2.7431886
Z mean eval                  0.8589095
Z variance eval              0.047406588
total_rewards                [ -29.10703245  103.97411611 2406.58769417 2744.44238231  421.26099435
   17.98178008 2661.86285926  552.63575507  510.14737735 2875.20951679]
total_rewards_mean           1226.4995443027783
total_rewards_std            1199.5023666124966
total_rewards_max            2875.2095167946877
total_rewards_min            -29.107032453868324
Number of train steps total  248000
Number of env steps total    312000
Number of rollouts total     0
Train Time (s)               134.94464450376108
(Previous) Eval Time (s)     21.218392156995833
Sample Time (s)              26.65420054504648
Epoch Time (s)               182.8172372058034
Total Train Time (s)         10980.608064561151
Epoch                        61
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:35:55.913608 UTC | [2020_01_11_13_32_55] Iteration #61 | Epoch Duration: 184.2241837978363
2020-01-11 16:35:55.913809 UTC | [2020_01_11_13_32_55] Iteration #61 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8601785
Z variance train             0.04737831
KL Divergence                16.74996
KL Loss                      1.674996
QF Loss                      732.67834
VF Loss                      184.53511
Policy Loss                  -777.52344
Q Predictions Mean           774.43414
Q Predictions Std            302.19028
Q Predictions Max            1078.4062
Q Predictions Min            -37.705944
V Predictions Mean           782.2864
V Predictions Std            299.46326
V Predictions Max            1087.9929
V Predictions Min            16.004692
Log Pis Mean                 -0.2075177
Log Pis Std                  3.4136727
Log Pis Max                  19.024914
Log Pis Min                  -8.940397
Policy mu Mean               -0.016238974
Policy mu Std                0.5938252
Policy mu Max                3.3063288
Policy mu Min                -2.4235988
Policy log std Mean          -0.9302683
Policy log std Std           0.3261736
Policy log std Max           -0.21093047
Policy log std Min           -2.4961307
Z mean eval                  0.87977105
Z variance eval              0.04563976
total_rewards                [2688.57211006 2676.09611453 2419.36913575  831.9414654   115.62951401
  493.01281888  119.90579098  436.92134063  353.19230011  810.11093559]
total_rewards_mean           1094.4751525938439
total_rewards_std            1009.9187806524543
total_rewards_max            2688.572110062695
total_rewards_min            115.62951400737208
Number of train steps total  252000
Number of env steps total    317000
Number of rollouts total     0
Train Time (s)               137.87435268284753
(Previous) Eval Time (s)     22.62492987792939
Sample Time (s)              25.748530592769384
Epoch Time (s)               186.2478131535463
Total Train Time (s)         11158.12205673987
Epoch                        62
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:38:53.428951 UTC | [2020_01_11_13_32_55] Iteration #62 | Epoch Duration: 177.51500701904297
2020-01-11 16:38:53.429117 UTC | [2020_01_11_13_32_55] Iteration #62 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8800371
Z variance train             0.045569167
KL Divergence                17.593637
KL Loss                      1.7593638
QF Loss                      425.46912
VF Loss                      284.4891
Policy Loss                  -794.7063
Q Predictions Mean           792.69415
Q Predictions Std            315.00363
Q Predictions Max            1109.6213
Q Predictions Min            16.616648
V Predictions Mean           798.1698
V Predictions Std            311.33618
V Predictions Max            1105.2108
V Predictions Min            69.470955
Log Pis Mean                 -0.6546161
Log Pis Std                  2.751153
Log Pis Max                  9.159031
Log Pis Min                  -9.07529
Policy mu Mean               0.032279335
Policy mu Std                0.545331
Policy mu Max                1.9849923
Policy mu Min                -1.8622243
Policy log std Mean          -0.92868817
Policy log std Std           0.28926992
Policy log std Max           -0.12795532
Policy log std Min           -2.38563
Z mean eval                  0.8876271
Z variance eval              0.03826394
total_rewards                [  67.29077646 2461.68707595  571.77837801 2004.26163134 1027.99121186
 2726.41575116 2208.69419833  918.21353292  920.64966106   80.95982746]
total_rewards_mean           1298.7942044541562
total_rewards_std            927.6566110014707
total_rewards_max            2726.4157511605094
total_rewards_min            67.2907764590175
Number of train steps total  256000
Number of env steps total    322000
Number of rollouts total     0
Train Time (s)               135.7686329940334
(Previous) Eval Time (s)     13.891772394999862
Sample Time (s)              24.226368663832545
Epoch Time (s)               173.8867740528658
Total Train Time (s)         11335.553621347062
Epoch                        63
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:41:50.860782 UTC | [2020_01_11_13_32_55] Iteration #63 | Epoch Duration: 177.431556224823
2020-01-11 16:41:50.860899 UTC | [2020_01_11_13_32_55] Iteration #63 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8923038
Z variance train             0.03815834
KL Divergence                18.553148
KL Loss                      1.8553149
QF Loss                      1475.1218
VF Loss                      332.57254
Policy Loss                  -833.7322
Q Predictions Mean           832.239
Q Predictions Std            288.06635
Q Predictions Max            1110.4092
Q Predictions Min            6.236568
V Predictions Mean           826.6604
V Predictions Std            283.50342
V Predictions Max            1112.4547
V Predictions Min            34.268276
Log Pis Mean                 -0.13596113
Log Pis Std                  3.016039
Log Pis Max                  10.755865
Log Pis Min                  -8.790883
Policy mu Mean               -0.02197463
Policy mu Std                0.60023063
Policy mu Max                2.0229824
Policy mu Min                -2.5621662
Policy log std Mean          -0.9733187
Policy log std Std           0.31358722
Policy log std Max           -0.12412816
Policy log std Min           -2.398
Z mean eval                  0.8906323
Z variance eval              0.029264271
total_rewards                [1231.59755846 2680.78770268 2570.62281056  556.47814507 1222.30110785
   79.62903641 1367.95696441  596.19467664  319.50568971  292.41278983]
total_rewards_mean           1091.748648161321
total_rewards_std            872.7415402841499
total_rewards_max            2680.7877026835017
total_rewards_min            79.6290364085153
Number of train steps total  260000
Number of env steps total    327000
Number of rollouts total     0
Train Time (s)               127.31277647335082
(Previous) Eval Time (s)     17.43618936976418
Sample Time (s)              24.230940291192383
Epoch Time (s)               168.97990613430738
Total Train Time (s)         11504.727169611957
Epoch                        64
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:44:40.036920 UTC | [2020_01_11_13_32_55] Iteration #64 | Epoch Duration: 169.17592549324036
2020-01-11 16:44:40.037104 UTC | [2020_01_11_13_32_55] Iteration #64 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8910344
Z variance train             0.029186824
KL Divergence                18.6692
KL Loss                      1.8669201
QF Loss                      1679.7229
VF Loss                      296.69046
Policy Loss                  -828.2825
Q Predictions Mean           823.94507
Q Predictions Std            307.4753
Q Predictions Max            1111.4117
Q Predictions Min            86.25655
V Predictions Mean           829.0155
V Predictions Std            307.6694
V Predictions Max            1111.5228
V Predictions Min            89.90286
Log Pis Mean                 -0.43305987
Log Pis Std                  2.9780052
Log Pis Max                  12.764259
Log Pis Min                  -6.2108464
Policy mu Mean               0.060068298
Policy mu Std                0.6063041
Policy mu Max                1.9356104
Policy mu Min                -2.187111
Policy log std Mean          -0.9337871
Policy log std Std           0.30547675
Policy log std Max           -0.22214788
Policy log std Min           -2.3561609
Z mean eval                  0.89441335
Z variance eval              0.038145382
total_rewards                [ 474.32987782 2906.48763993 2784.43576225 2128.76028495 2829.12883906
 2782.584592   2900.82908821 2784.62456977 2781.2988518  2833.13531691]
total_rewards_mean           2520.561482269007
total_rewards_std            714.3549299937317
total_rewards_max            2906.4876399274767
total_rewards_min            474.32987781734516
Number of train steps total  264000
Number of env steps total    332000
Number of rollouts total     0
Train Time (s)               126.57309194793925
(Previous) Eval Time (s)     17.63186544785276
Sample Time (s)              25.379527353681624
Epoch Time (s)               169.58448474947363
Total Train Time (s)         11690.59943688009
Epoch                        65
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:47:45.910866 UTC | [2020_01_11_13_32_55] Iteration #65 | Epoch Duration: 185.8736298084259
2020-01-11 16:47:45.911051 UTC | [2020_01_11_13_32_55] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8947753
Z variance train             0.038057983
KL Divergence                18.692135
KL Loss                      1.8692135
QF Loss                      708.47363
VF Loss                      118.85889
Policy Loss                  -804.87616
Q Predictions Mean           803.8272
Q Predictions Std            290.21106
Q Predictions Max            1091.6124
Q Predictions Min            41.915764
V Predictions Mean           808.01013
V Predictions Std            288.8737
V Predictions Max            1086.2333
V Predictions Min            33.004288
Log Pis Mean                 -0.3483764
Log Pis Std                  2.6842031
Log Pis Max                  9.489105
Log Pis Min                  -7.7697945
Policy mu Mean               0.012044422
Policy mu Std                0.5681857
Policy mu Max                2.099799
Policy mu Min                -2.3727872
Policy log std Mean          -0.9413464
Policy log std Std           0.29150778
Policy log std Max           -0.16783261
Policy log std Min           -2.1093867
Z mean eval                  0.8812095
Z variance eval              0.037498455
total_rewards                [2784.12976829 2789.28771072  781.57196202 2079.91626417  278.23378927
 1428.91541273  327.7592774   813.29137509 1317.08055104 1138.28498829]
total_rewards_mean           1373.847109902025
total_rewards_std            866.736885058874
total_rewards_max            2789.2877107225513
total_rewards_min            278.23378926538965
Number of train steps total  268000
Number of env steps total    337000
Number of rollouts total     0
Train Time (s)               127.78966892324388
(Previous) Eval Time (s)     33.920677720569074
Sample Time (s)              25.24507993320003
Epoch Time (s)               186.955426577013
Total Train Time (s)         11870.50296567753
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:50:45.815683 UTC | [2020_01_11_13_32_55] Iteration #66 | Epoch Duration: 179.90450763702393
2020-01-11 16:50:45.815858 UTC | [2020_01_11_13_32_55] Iteration #66 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8823906
Z variance train             0.03760002
KL Divergence                18.948458
KL Loss                      1.8948458
QF Loss                      895.1641
VF Loss                      692.16327
Policy Loss                  -820.5643
Q Predictions Mean           813.7376
Q Predictions Std            329.7444
Q Predictions Max            1140.9568
Q Predictions Min            -111.94073
V Predictions Mean           826.7527
V Predictions Std            315.86978
V Predictions Max            1146.0142
V Predictions Min            44.32304
Log Pis Mean                 0.10295984
Log Pis Std                  3.4242556
Log Pis Max                  13.896326
Log Pis Min                  -8.770798
Policy mu Mean               0.03749693
Policy mu Std                0.63366467
Policy mu Max                2.3408713
Policy mu Min                -2.4167318
Policy log std Mean          -0.94944155
Policy log std Std           0.33391592
Policy log std Max           -0.18696839
Policy log std Min           -2.475894
Z mean eval                  0.9075329
Z variance eval              0.028471539
total_rewards                [1656.49647064 2068.60677866 2753.03360827  437.86086231 2724.85522664
 1561.31948689  201.91162333   67.18833132  827.01940987 1310.84430063]
total_rewards_mean           1360.9136098564595
total_rewards_std            926.4601025760691
total_rewards_max            2753.033608271011
total_rewards_min            67.18833132391877
Number of train steps total  272000
Number of env steps total    342000
Number of rollouts total     0
Train Time (s)               128.1822716970928
(Previous) Eval Time (s)     26.869450571015477
Sample Time (s)              26.109762541484088
Epoch Time (s)               181.16148480959237
Total Train Time (s)         12049.763549780007
Epoch                        67
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:53:45.078197 UTC | [2020_01_11_13_32_55] Iteration #67 | Epoch Duration: 179.26220226287842
2020-01-11 16:53:45.078373 UTC | [2020_01_11_13_32_55] Iteration #67 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9078515
Z variance train             0.028421858
KL Divergence                18.891125
KL Loss                      1.8891125
QF Loss                      602.5925
VF Loss                      119.27662
Policy Loss                  -826.9944
Q Predictions Mean           823.2356
Q Predictions Std            320.5897
Q Predictions Max            1138.8943
Q Predictions Min            -55.8844
V Predictions Mean           830.4109
V Predictions Std            319.9044
V Predictions Max            1140.4005
V Predictions Min            30.736464
Log Pis Mean                 -0.21637502
Log Pis Std                  3.1420114
Log Pis Max                  16.179247
Log Pis Min                  -7.025348
Policy mu Mean               0.05252946
Policy mu Std                0.6040604
Policy mu Max                1.9405416
Policy mu Min                -2.193995
Policy log std Mean          -0.9310808
Policy log std Std           0.30999056
Policy log std Max           -0.24174505
Policy log std Min           -2.4020317
Z mean eval                  0.900366
Z variance eval              0.03801131
total_rewards                [1652.68910368 2819.81300271 2721.83873746 1314.63987952 1285.80443315
  428.55808635  823.34575056  954.96568116 1336.41763314  357.72212928]
total_rewards_mean           1369.5794437015925
total_rewards_std            800.170119780972
total_rewards_max            2819.8130027051675
total_rewards_min            357.7221292813575
Number of train steps total  276000
Number of env steps total    347000
Number of rollouts total     0
Train Time (s)               126.65613101702183
(Previous) Eval Time (s)     24.969799382146448
Sample Time (s)              25.11697041383013
Epoch Time (s)               176.7429008129984
Total Train Time (s)         12224.982883919962
Epoch                        68
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:56:40.299384 UTC | [2020_01_11_13_32_55] Iteration #68 | Epoch Duration: 175.22087144851685
2020-01-11 16:56:40.299591 UTC | [2020_01_11_13_32_55] Iteration #68 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8999635
Z variance train             0.037916284
KL Divergence                18.068647
KL Loss                      1.8068647
QF Loss                      535.61804
VF Loss                      126.411575
Policy Loss                  -860.62756
Q Predictions Mean           856.08136
Q Predictions Std            303.76904
Q Predictions Max            1148.8894
Q Predictions Min            -62.35194
V Predictions Mean           855.1515
V Predictions Std            300.98465
V Predictions Max            1148.6473
V Predictions Min            22.669456
Log Pis Mean                 -0.65785366
Log Pis Std                  2.8870537
Log Pis Max                  11.112955
Log Pis Min                  -7.171411
Policy mu Mean               0.015616256
Policy mu Std                0.59167767
Policy mu Max                2.0665135
Policy mu Min                -2.589263
Policy log std Mean          -0.91261256
Policy log std Std           0.27480578
Policy log std Max           -0.10478681
Policy log std Min           -2.3411736
Z mean eval                  0.8797393
Z variance eval              0.043868445
total_rewards                [ 513.89028641   56.36267784  150.95574259 1288.1167677    48.44854295
 1887.73643387  831.01025638 2756.76588301  459.18509772  674.12628178]
total_rewards_mean           866.6597970233892
total_rewards_std            834.2559479164347
total_rewards_max            2756.7658830088003
total_rewards_min            48.44854294946185
Number of train steps total  280000
Number of env steps total    352000
Number of rollouts total     0
Train Time (s)               128.18316253367811
(Previous) Eval Time (s)     23.44737189495936
Sample Time (s)              25.034263597801328
Epoch Time (s)               176.6647980264388
Total Train Time (s)         12399.08962838538
Epoch                        69
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:59:34.407362 UTC | [2020_01_11_13_32_55] Iteration #69 | Epoch Duration: 174.10762476921082
2020-01-11 16:59:34.407539 UTC | [2020_01_11_13_32_55] Iteration #69 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8836101
Z variance train             0.04391756
KL Divergence                17.44126
KL Loss                      1.744126
QF Loss                      680.3842
VF Loss                      344.9617
Policy Loss                  -859.2769
Q Predictions Mean           856.6483
Q Predictions Std            301.20874
Q Predictions Max            1156.28
Q Predictions Min            43.19943
V Predictions Mean           855.40234
V Predictions Std            293.6666
V Predictions Max            1136.0338
V Predictions Min            7.135612
Log Pis Mean                 0.14379813
Log Pis Std                  2.9187312
Log Pis Max                  10.071147
Log Pis Min                  -6.0827966
Policy mu Mean               0.014001705
Policy mu Std                0.6063316
Policy mu Max                3.1917443
Policy mu Min                -2.0287578
Policy log std Mean          -0.9824482
Policy log std Std           0.31090987
Policy log std Max           -0.20565861
Policy log std Min           -2.321567
Z mean eval                  0.8836093
Z variance eval              0.023293799
total_rewards                [2750.70189018   33.3190813   374.71190404  179.29786546  556.15599216
 2945.084449    903.70820078 3038.54070886  989.35424674 2261.21165101]
total_rewards_mean           1403.208598953486
total_rewards_std            1147.7906634373353
total_rewards_max            3038.5407088576535
total_rewards_min            33.31908130321267
Number of train steps total  284000
Number of env steps total    357000
Number of rollouts total     0
Train Time (s)               127.73656588001177
(Previous) Eval Time (s)     20.88988573802635
Sample Time (s)              24.628064395859838
Epoch Time (s)               173.25451601389796
Total Train Time (s)         12574.967942700256
Epoch                        70
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:02:30.287175 UTC | [2020_01_11_13_32_55] Iteration #70 | Epoch Duration: 175.8795084953308
2020-01-11 17:02:30.287392 UTC | [2020_01_11_13_32_55] Iteration #70 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.88341916
Z variance train             0.023273084
KL Divergence                19.109833
KL Loss                      1.9109833
QF Loss                      814.01514
VF Loss                      207.9213
Policy Loss                  -834.93317
Q Predictions Mean           834.6485
Q Predictions Std            319.67432
Q Predictions Max            1164.4027
Q Predictions Min            6.5154247
V Predictions Mean           828.19293
V Predictions Std            315.9875
V Predictions Max            1134.0785
V Predictions Min            21.566683
Log Pis Mean                 -0.26886383
Log Pis Std                  3.0319824
Log Pis Max                  10.719946
Log Pis Min                  -10.2506075
Policy mu Mean               0.071760215
Policy mu Std                0.5948404
Policy mu Max                2.4851766
Policy mu Min                -2.4395523
Policy log std Mean          -0.9219251
Policy log std Std           0.3183796
Policy log std Max           -0.10437232
Policy log std Min           -2.3451948
Z mean eval                  0.8818963
Z variance eval              0.019752596
total_rewards                [2793.78688465 1597.34842914 1547.82234031 2219.9449123  1212.9063743
  -40.58166261  673.16768498 2511.76263272  336.13640327 1358.53027079]
total_rewards_mean           1421.0824269845825
total_rewards_std            876.322492381262
total_rewards_max            2793.7868846541173
total_rewards_min            -40.58166261188801
Number of train steps total  288000
Number of env steps total    362000
Number of rollouts total     0
Train Time (s)               127.88397791283205
(Previous) Eval Time (s)     23.51456751069054
Sample Time (s)              25.07780602760613
Epoch Time (s)               176.47635145112872
Total Train Time (s)         12755.131826178636
Epoch                        71
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:05:30.453154 UTC | [2020_01_11_13_32_55] Iteration #71 | Epoch Duration: 180.16562581062317
2020-01-11 17:05:30.453347 UTC | [2020_01_11_13_32_55] Iteration #71 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.881106
Z variance train             0.019899013
KL Divergence                19.775373
KL Loss                      1.9775374
QF Loss                      1224.8132
VF Loss                      257.1111
Policy Loss                  -855.90674
Q Predictions Mean           846.5917
Q Predictions Std            306.32086
Q Predictions Max            1161.1167
Q Predictions Min            -104.60922
V Predictions Mean           858.17224
V Predictions Std            297.72525
V Predictions Max            1162.8783
V Predictions Min            8.883615
Log Pis Mean                 -0.38450852
Log Pis Std                  3.2639642
Log Pis Max                  24.450745
Log Pis Min                  -8.176684
Policy mu Mean               -0.0057392027
Policy mu Std                0.6231568
Policy mu Max                2.2423534
Policy mu Min                -4.645875
Policy log std Mean          -0.9220077
Policy log std Std           0.30156544
Policy log std Max           -0.008861601
Policy log std Min           -2.306682
Z mean eval                  0.8977764
Z variance eval              0.030238967
total_rewards                [1955.68711279 1678.5909252  2564.35165796 1950.6804598   562.66096335
  863.6642094  2072.01105627 2932.06537025 -155.71465405 3083.66937775]
total_rewards_mean           1750.7666478728129
total_rewards_std            992.8544188341688
total_rewards_max            3083.669377754908
total_rewards_min            -155.71465404906456
Number of train steps total  292000
Number of env steps total    367000
Number of rollouts total     0
Train Time (s)               128.2501603900455
(Previous) Eval Time (s)     27.203479659743607
Sample Time (s)              24.108039462938905
Epoch Time (s)               179.561679512728
Total Train Time (s)         12932.587446966209
Epoch                        72
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:08:27.910330 UTC | [2020_01_11_13_32_55] Iteration #72 | Epoch Duration: 177.45684695243835
2020-01-11 17:08:27.910520 UTC | [2020_01_11_13_32_55] Iteration #72 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89831364
Z variance train             0.03031527
KL Divergence                20.17519
KL Loss                      2.017519
QF Loss                      816.15967
VF Loss                      404.75577
Policy Loss                  -866.0476
Q Predictions Mean           861.5809
Q Predictions Std            309.27927
Q Predictions Max            1178.2152
Q Predictions Min            24.138416
V Predictions Mean           873.911
V Predictions Std            302.86716
V Predictions Max            1183.8954
V Predictions Min            32.236546
Log Pis Mean                 -0.27221572
Log Pis Std                  3.0009925
Log Pis Max                  9.44373
Log Pis Min                  -7.4010534
Policy mu Mean               0.031090245
Policy mu Std                0.58487713
Policy mu Max                2.7285903
Policy mu Min                -2.0854735
Policy log std Mean          -0.949959
Policy log std Std           0.3174485
Policy log std Max           0.17427409
Policy log std Min           -2.0650125
Z mean eval                  0.90128213
Z variance eval              0.023377245
total_rewards                [2592.26980626 2960.84807364 3165.00362917 1793.75498257  108.92254845
  595.3449057  2413.28336992 3034.52410739 1389.82825694  609.59675949]
total_rewards_mean           1866.3376439535216
total_rewards_std            1076.611843448918
total_rewards_max            3165.0036291701276
total_rewards_min            108.92254845026955
Number of train steps total  296000
Number of env steps total    372000
Number of rollouts total     0
Train Time (s)               127.68228369485587
(Previous) Eval Time (s)     25.09831455303356
Sample Time (s)              24.527687816414982
Epoch Time (s)               177.3082860643044
Total Train Time (s)         13112.281142572407
Epoch                        73
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:11:27.605695 UTC | [2020_01_11_13_32_55] Iteration #73 | Epoch Duration: 179.69504070281982
2020-01-11 17:11:27.605875 UTC | [2020_01_11_13_32_55] Iteration #73 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9013871
Z variance train             0.023408916
KL Divergence                19.075726
KL Loss                      1.9075726
QF Loss                      926.9216
VF Loss                      199.37955
Policy Loss                  -857.8938
Q Predictions Mean           854.3959
Q Predictions Std            317.55457
Q Predictions Max            1192.862
Q Predictions Min            -59.941444
V Predictions Mean           861.64417
V Predictions Std            317.1138
V Predictions Max            1188.5282
V Predictions Min            86.613495
Log Pis Mean                 -0.3180483
Log Pis Std                  3.4120662
Log Pis Max                  12.757264
Log Pis Min                  -8.062759
Policy mu Mean               0.077230416
Policy mu Std                0.6126627
Policy mu Max                2.6624267
Policy mu Min                -1.9905835
Policy log std Mean          -0.9337609
Policy log std Std           0.321937
Policy log std Max           0.0010860562
Policy log std Min           -2.5833373
Z mean eval                  0.92003644
Z variance eval              0.030160299
total_rewards                [2685.69043302 3183.87587978 1676.89153459 2748.69041681 2980.10915994
  554.06655553 1717.43364409   46.16214689  284.4920703  2162.66047584]
total_rewards_mean           1804.0072316775615
total_rewards_std            1098.6640850219123
total_rewards_max            3183.875879778304
total_rewards_min            46.16214689051555
Number of train steps total  300000
Number of env steps total    377000
Number of rollouts total     0
Train Time (s)               128.66988916601986
(Previous) Eval Time (s)     27.48472803272307
Sample Time (s)              25.47852000501007
Epoch Time (s)               181.633137203753
Total Train Time (s)         13289.805953919422
Epoch                        74
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:14:25.132131 UTC | [2020_01_11_13_32_55] Iteration #74 | Epoch Duration: 177.52612829208374
2020-01-11 17:14:25.132312 UTC | [2020_01_11_13_32_55] Iteration #74 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9194231
Z variance train             0.030236593
KL Divergence                19.219093
KL Loss                      1.9219093
QF Loss                      666.01636
VF Loss                      184.43124
Policy Loss                  -900.1689
Q Predictions Mean           896.61206
Q Predictions Std            296.4135
Q Predictions Max            1170.8721
Q Predictions Min            0.55469215
V Predictions Mean           891.6472
V Predictions Std            292.58456
V Predictions Max            1146.9249
V Predictions Min            24.35786
Log Pis Mean                 0.030106887
Log Pis Std                  3.3509097
Log Pis Max                  17.20805
Log Pis Min                  -11.153411
Policy mu Mean               0.061080486
Policy mu Std                0.5895287
Policy mu Max                1.8934034
Policy mu Min                -1.9895257
Policy log std Mean          -0.97518593
Policy log std Std           0.305999
Policy log std Max           -0.12235618
Policy log std Min           -2.4674993
Z mean eval                  0.9031297
Z variance eval              0.028844643
total_rewards                [2080.89890456 2913.86935796 2983.97147654 3040.10150585 1193.98096735
  684.73485185  338.17208369 2954.95504553  192.46871286  478.86094427]
total_rewards_mean           1686.2013850455783
total_rewards_std            1163.6688004756709
total_rewards_max            3040.101505850219
total_rewards_min            192.4687128599317
Number of train steps total  304000
Number of env steps total    382000
Number of rollouts total     0
Train Time (s)               128.29948330810294
(Previous) Eval Time (s)     23.377413137815893
Sample Time (s)              25.504551108926535
Epoch Time (s)               177.18144755484536
Total Train Time (s)         13472.76535679726
Epoch                        75
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:17:28.093430 UTC | [2020_01_11_13_32_55] Iteration #75 | Epoch Duration: 182.96098136901855
2020-01-11 17:17:28.093615 UTC | [2020_01_11_13_32_55] Iteration #75 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9030167
Z variance train             0.028857991
KL Divergence                17.862446
KL Loss                      1.7862446
QF Loss                      545.2938
VF Loss                      238.1027
Policy Loss                  -885.3701
Q Predictions Mean           884.8463
Q Predictions Std            291.7996
Q Predictions Max            1152.5715
Q Predictions Min            128.27106
V Predictions Mean           890.87744
V Predictions Std            293.56192
V Predictions Max            1152.0046
V Predictions Min            114.52612
Log Pis Mean                 -0.27347124
Log Pis Std                  2.742173
Log Pis Max                  10.72497
Log Pis Min                  -6.751123
Policy mu Mean               0.04034475
Policy mu Std                0.5973482
Policy mu Max                2.43174
Policy mu Min                -2.2922666
Policy log std Mean          -0.9441313
Policy log std Std           0.2830306
Policy log std Max           -0.20125574
Policy log std Min           -2.0505161
Z mean eval                  0.92248935
Z variance eval              0.029812831
total_rewards                [1040.20878852 3081.32120193 1970.61000704  293.69060784 3044.13560091
   98.00888289 2950.08420511 1007.5474935  1260.90565532 1373.91756902]
total_rewards_mean           1612.0430012096062
total_rewards_std            1050.3025703859998
total_rewards_max            3081.321201933306
total_rewards_min            98.00888288500151
Number of train steps total  308000
Number of env steps total    387000
Number of rollouts total     0
Train Time (s)               127.70879210019484
(Previous) Eval Time (s)     29.15661619696766
Sample Time (s)              25.177737726829946
Epoch Time (s)               182.04314602399245
Total Train Time (s)         13645.663778160699
Epoch                        76
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:20:20.994119 UTC | [2020_01_11_13_32_55] Iteration #76 | Epoch Duration: 172.90037202835083
2020-01-11 17:20:20.994301 UTC | [2020_01_11_13_32_55] Iteration #76 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9221288
Z variance train             0.029643353
KL Divergence                18.174942
KL Loss                      1.8174943
QF Loss                      691.6666
VF Loss                      264.81854
Policy Loss                  -900.2689
Q Predictions Mean           900.9042
Q Predictions Std            297.8729
Q Predictions Max            1192.6458
Q Predictions Min            -98.87337
V Predictions Mean           902.7192
V Predictions Std            295.48547
V Predictions Max            1175.0483
V Predictions Min            88.58818
Log Pis Mean                 -0.2347267
Log Pis Std                  3.047247
Log Pis Max                  12.925882
Log Pis Min                  -8.180966
Policy mu Mean               0.02606143
Policy mu Std                0.5899021
Policy mu Max                2.2961233
Policy mu Min                -2.121237
Policy log std Mean          -0.9572336
Policy log std Std           0.30472934
Policy log std Max           -0.20094019
Policy log std Min           -2.798149
Z mean eval                  0.91047764
Z variance eval              0.015298967
total_rewards                [2914.59029529  498.47195641  653.01084183  394.57058372 3038.95039601
 1148.83790774 3212.311647   2771.80976535 3086.0290903  1226.67855476]
total_rewards_mean           1894.5261038403837
total_rewards_std            1140.9806206855717
total_rewards_max            3212.311647000274
total_rewards_min            394.57058371508293
Number of train steps total  312000
Number of env steps total    392000
Number of rollouts total     0
Train Time (s)               128.05060189776123
(Previous) Eval Time (s)     20.01350917061791
Sample Time (s)              24.864223956130445
Epoch Time (s)               172.92833502450958
Total Train Time (s)         13821.53008694807
Epoch                        77
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:23:16.863266 UTC | [2020_01_11_13_32_55] Iteration #77 | Epoch Duration: 175.8688259124756
2020-01-11 17:23:16.863466 UTC | [2020_01_11_13_32_55] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9110328
Z variance train             0.015258001
KL Divergence                20.572857
KL Loss                      2.0572858
QF Loss                      581.13947
VF Loss                      106.321495
Policy Loss                  -893.57513
Q Predictions Mean           891.5685
Q Predictions Std            309.35037
Q Predictions Max            1191.2113
Q Predictions Min            101.72515
V Predictions Mean           891.79333
V Predictions Std            305.57483
V Predictions Max            1169.9475
V Predictions Min            105.46559
Log Pis Mean                 -0.5866776
Log Pis Std                  2.812248
Log Pis Max                  13.236121
Log Pis Min                  -7.7420483
Policy mu Mean               0.005340372
Policy mu Std                0.5876962
Policy mu Max                3.3104124
Policy mu Min                -3.133334
Policy log std Mean          -0.91178817
Policy log std Std           0.29972157
Policy log std Max           -0.09711194
Policy log std Min           -2.3670301
Z mean eval                  0.9117039
Z variance eval              0.011299284
total_rewards                [1872.31296172 3048.1621188  3061.61856128 2160.02719901  982.50615701
 2983.91154611 2986.77366248 3108.99185098 2945.28576771 2958.99683609]
total_rewards_mean           2610.858666119186
total_rewards_std            675.0043209664825
total_rewards_max            3108.9918509811178
total_rewards_min            982.5061570117613
Number of train steps total  316000
Number of env steps total    397000
Number of rollouts total     0
Train Time (s)               136.32099086977541
(Previous) Eval Time (s)     22.95363569399342
Sample Time (s)              24.22069558268413
Epoch Time (s)               183.49532214645296
Total Train Time (s)         14017.721350826323
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:26:33.055341 UTC | [2020_01_11_13_32_55] Iteration #78 | Epoch Duration: 196.1917245388031
2020-01-11 17:26:33.055576 UTC | [2020_01_11_13_32_55] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91227514
Z variance train             0.011351247
KL Divergence                19.690437
KL Loss                      1.9690437
QF Loss                      703.3451
VF Loss                      348.45032
Policy Loss                  -868.44684
Q Predictions Mean           862.7954
Q Predictions Std            339.66653
Q Predictions Max            1166.1151
Q Predictions Min            -131.43036
V Predictions Mean           867.4281
V Predictions Std            328.99216
V Predictions Max            1154.325
V Predictions Min            -13.927808
Log Pis Mean                 -0.0767194
Log Pis Std                  3.484038
Log Pis Max                  15.63332
Log Pis Min                  -8.779481
Policy mu Mean               0.008109766
Policy mu Std                0.5970094
Policy mu Max                2.0198386
Policy mu Min                -2.9796195
Policy log std Mean          -0.9678967
Policy log std Std           0.33127964
Policy log std Max           -0.14338529
Policy log std Min           -2.593214
Z mean eval                  0.94851
Z variance eval              0.010603373
total_rewards                [2368.27809699  398.73978963 2830.9333946  -146.2817845   595.62400015
 1550.79918128  142.78202427  334.2403888   267.80083568  719.40379146]
total_rewards_mean           906.2319718349265
total_rewards_std            952.4631981773445
total_rewards_max            2830.9333946014394
total_rewards_min            -146.28178450488838
Number of train steps total  320000
Number of env steps total    402000
Number of rollouts total     0
Train Time (s)               135.89020953234285
(Previous) Eval Time (s)     35.64971918798983
Sample Time (s)              25.27552195964381
Epoch Time (s)               196.8154506799765
Total Train Time (s)         14202.118388935458
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:29:37.453960 UTC | [2020_01_11_13_32_55] Iteration #79 | Epoch Duration: 184.39823865890503
2020-01-11 17:29:37.454150 UTC | [2020_01_11_13_32_55] Iteration #79 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94703853
Z variance train             0.01060239
KL Divergence                20.463924
KL Loss                      2.0463924
QF Loss                      690.95483
VF Loss                      426.35574
Policy Loss                  -912.76526
Q Predictions Mean           911.56665
Q Predictions Std            296.65836
Q Predictions Max            1153.5797
Q Predictions Min            33.616096
V Predictions Mean           916.8447
V Predictions Std            292.72757
V Predictions Max            1156.302
V Predictions Min            21.315416
Log Pis Mean                 -0.30838725
Log Pis Std                  3.0186813
Log Pis Max                  12.502851
Log Pis Min                  -7.4599643
Policy mu Mean               0.02093013
Policy mu Std                0.59359866
Policy mu Max                3.0463388
Policy mu Min                -2.5896554
Policy log std Mean          -0.93699807
Policy log std Std           0.31640697
Policy log std Max           0.07771802
Policy log std Min           -2.2888336
Z mean eval                  0.9210762
Z variance eval              0.030015653
total_rewards                [1250.51098784  573.24643008    5.46642914   61.42677154 1224.52167985
 1764.46185282 3018.18486311 1334.27441669 2964.31178258 3005.38400895]
total_rewards_mean           1520.1789222594598
total_rewards_std            1100.3970747221485
total_rewards_max            3018.184863109168
total_rewards_min            5.466429141595608
Number of train steps total  324000
Number of env steps total    407000
Number of rollouts total     0
Train Time (s)               135.44647793704644
(Previous) Eval Time (s)     23.232154564000666
Sample Time (s)              25.709919136483222
Epoch Time (s)               184.38855163753033
Total Train Time (s)         14384.18159117829
Epoch                        80
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:32:39.519134 UTC | [2020_01_11_13_32_55] Iteration #80 | Epoch Duration: 182.0648546218872
2020-01-11 17:32:39.519326 UTC | [2020_01_11_13_32_55] Iteration #80 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92110175
Z variance train             0.029889226
KL Divergence                18.517017
KL Loss                      1.8517017
QF Loss                      563.1919
VF Loss                      439.03476
Policy Loss                  -892.05066
Q Predictions Mean           887.26917
Q Predictions Std            318.63916
Q Predictions Max            1205.9745
Q Predictions Min            -23.120445
V Predictions Mean           878.3188
V Predictions Std            315.4055
V Predictions Max            1176.669
V Predictions Min            17.342766
Log Pis Mean                 -0.4170872
Log Pis Std                  3.1698625
Log Pis Max                  12.490094
Log Pis Min                  -7.701598
Policy mu Mean               -0.045991257
Policy mu Std                0.5964
Policy mu Max                2.2451508
Policy mu Min                -2.5964205
Policy log std Mean          -0.9435078
Policy log std Std           0.32588357
Policy log std Max           -0.17943966
Policy log std Min           -2.5166192
Z mean eval                  0.93341935
Z variance eval              0.018627053
total_rewards                [ -61.27373486 3023.17643109 3138.06463662 3036.49842767 2885.92051996
 1107.00428821 1299.99651634  -81.82216621  510.62367     753.7240011 ]
total_rewards_mean           1561.191258993087
total_rewards_std            1261.6441277393578
total_rewards_max            3138.0646366170927
total_rewards_min            -81.82216621264378
Number of train steps total  328000
Number of env steps total    412000
Number of rollouts total     0
Train Time (s)               137.17538879904896
(Previous) Eval Time (s)     20.90804422320798
Sample Time (s)              26.172271861694753
Epoch Time (s)               184.2557048839517
Total Train Time (s)         14577.059757084586
Epoch                        81
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:35:52.398977 UTC | [2020_01_11_13_32_55] Iteration #81 | Epoch Duration: 192.87951850891113
2020-01-11 17:35:52.399171 UTC | [2020_01_11_13_32_55] Iteration #81 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.933976
Z variance train             0.018673766
KL Divergence                19.363037
KL Loss                      1.9363037
QF Loss                      1018.9253
VF Loss                      484.50436
Policy Loss                  -919.80975
Q Predictions Mean           914.6233
Q Predictions Std            315.52567
Q Predictions Max            1210.0143
Q Predictions Min            -88.57072
V Predictions Mean           927.64197
V Predictions Std            312.34555
V Predictions Max            1196.8849
V Predictions Min            30.057833
Log Pis Mean                 -0.046830427
Log Pis Std                  3.423108
Log Pis Max                  14.403344
Log Pis Min                  -8.438577
Policy mu Mean               -0.0022572803
Policy mu Std                0.59069604
Policy mu Max                2.2289853
Policy mu Min                -2.8284717
Policy log std Mean          -0.97523195
Policy log std Std           0.3268753
Policy log std Max           -0.21416521
Policy log std Min           -2.8807888
Z mean eval                  0.9199734
Z variance eval              0.02840066
total_rewards                [ 789.62049234  110.51817086 1014.47933591 1380.08814664 1174.63291518
   81.06956598  503.8328715   -33.72441509 1460.97980124 1838.63276631]
total_rewards_mean           832.012965087239
total_rewards_std            616.7189595162906
total_rewards_max            1838.632766311156
total_rewards_min            -33.724415085186344
Number of train steps total  332000
Number of env steps total    417000
Number of rollouts total     0
Train Time (s)               131.8740193620324
(Previous) Eval Time (s)     29.531482764985412
Sample Time (s)              26.134235395118594
Epoch Time (s)               187.53973752213642
Total Train Time (s)         14757.58998122206
Epoch                        82
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:38:52.931242 UTC | [2020_01_11_13_32_55] Iteration #82 | Epoch Duration: 180.53190755844116
2020-01-11 17:38:52.931440 UTC | [2020_01_11_13_32_55] Iteration #82 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9190942
Z variance train             0.028463881
KL Divergence                19.259153
KL Loss                      1.9259154
QF Loss                      1209.9551
VF Loss                      140.73477
Policy Loss                  -915.4419
Q Predictions Mean           916.5216
Q Predictions Std            318.48288
Q Predictions Max            1205.2084
Q Predictions Min            11.159833
V Predictions Mean           917.2666
V Predictions Std            315.8086
V Predictions Max            1197.5815
V Predictions Min            -52.06977
Log Pis Mean                 -0.28919452
Log Pis Std                  2.9576669
Log Pis Max                  10.7234335
Log Pis Min                  -9.003244
Policy mu Mean               0.059703987
Policy mu Std                0.616889
Policy mu Max                2.4437528
Policy mu Min                -2.6150208
Policy log std Mean          -0.9191253
Policy log std Std           0.30715188
Policy log std Max           -0.0868361
Policy log std Min           -2.3006544
Z mean eval                  0.9213289
Z variance eval              0.020238305
total_rewards                [ 722.80727878  109.46559934  338.4202995   349.91984395  119.46264323
 2700.51251767  817.69438313 1301.67742982  820.28725176 1270.41640465]
total_rewards_mean           855.066365184595
total_rewards_std            735.9943492084121
total_rewards_max            2700.51251767284
total_rewards_min            109.46559933848462
Number of train steps total  336000
Number of env steps total    422000
Number of rollouts total     0
Train Time (s)               128.82472228072584
(Previous) Eval Time (s)     22.52329749474302
Sample Time (s)              25.83293705433607
Epoch Time (s)               177.18095682980493
Total Train Time (s)         14933.827610742766
Epoch                        83
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:41:49.170286 UTC | [2020_01_11_13_32_55] Iteration #83 | Epoch Duration: 176.2387158870697
2020-01-11 17:41:49.170464 UTC | [2020_01_11_13_32_55] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9208196
Z variance train             0.020277722
KL Divergence                19.336222
KL Loss                      1.9336222
QF Loss                      559.9652
VF Loss                      99.07974
Policy Loss                  -881.4013
Q Predictions Mean           879.90234
Q Predictions Std            335.55023
Q Predictions Max            1209.9263
Q Predictions Min            -19.484047
V Predictions Mean           883.26733
V Predictions Std            333.70627
V Predictions Max            1197.6283
V Predictions Min            20.658129
Log Pis Mean                 -0.5441152
Log Pis Std                  2.9397912
Log Pis Max                  9.938046
Log Pis Min                  -8.025243
Policy mu Mean               -0.028377095
Policy mu Std                0.579294
Policy mu Max                1.9526207
Policy mu Min                -2.8802533
Policy log std Mean          -0.91318876
Policy log std Std           0.2915108
Policy log std Max           -0.23794484
Policy log std Min           -2.055314
Z mean eval                  0.9234341
Z variance eval              0.0150608625
total_rewards                [ 482.87367143 2890.08274955 1590.04425004  109.12850739 2098.63039237
 1617.74147346 2614.7701027   850.56125981  388.37071687 1892.91057488]
total_rewards_mean           1453.5113698491891
total_rewards_std            911.849681184757
total_rewards_max            2890.082749545277
total_rewards_min            109.12850739383944
Number of train steps total  340000
Number of env steps total    427000
Number of rollouts total     0
Train Time (s)               128.84242576919496
(Previous) Eval Time (s)     21.580702553037554
Sample Time (s)              26.283874631859362
Epoch Time (s)               176.70700295409188
Total Train Time (s)         15107.893011364155
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:44:43.237450 UTC | [2020_01_11_13_32_55] Iteration #84 | Epoch Duration: 174.06682324409485
2020-01-11 17:44:43.237892 UTC | [2020_01_11_13_32_55] Iteration #84 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9220568
Z variance train             0.015026355
KL Divergence                20.789545
KL Loss                      2.0789545
QF Loss                      893.8751
VF Loss                      197.50629
Policy Loss                  -910.3876
Q Predictions Mean           906.21155
Q Predictions Std            312.3697
Q Predictions Max            1209.6438
Q Predictions Min            2.4145744
V Predictions Mean           907.9319
V Predictions Std            309.23502
V Predictions Max            1215.3309
V Predictions Min            58.98646
Log Pis Mean                 -0.21269059
Log Pis Std                  3.3609314
Log Pis Max                  14.036285
Log Pis Min                  -9.011365
Policy mu Mean               0.042901844
Policy mu Std                0.5966348
Policy mu Max                2.4370403
Policy mu Min                -3.201782
Policy log std Mean          -0.91574246
Policy log std Std           0.33853087
Policy log std Max           -0.124374986
Policy log std Min           -2.3838925
Z mean eval                  0.9296328
Z variance eval              0.032532457
total_rewards                [1501.85868792   66.42108439  876.04414965 2433.43929176  -99.95115112
  153.35650259  258.93757207  585.4304749  1348.41497271  454.63046173]
total_rewards_mean           757.8582046597761
total_rewards_std            753.2448862151626
total_rewards_max            2433.439291762104
total_rewards_min            -99.95115112490473
Number of train steps total  344000
Number of env steps total    432000
Number of rollouts total     0
Train Time (s)               128.38482331391424
(Previous) Eval Time (s)     18.940159248188138
Sample Time (s)              25.368657676503062
Epoch Time (s)               172.69364023860544
Total Train Time (s)         15281.360302138608
Epoch                        85
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:47:36.706415 UTC | [2020_01_11_13_32_55] Iteration #85 | Epoch Duration: 173.46837091445923
2020-01-11 17:47:36.706596 UTC | [2020_01_11_13_32_55] Iteration #85 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9275864
Z variance train             0.032646284
KL Divergence                19.955866
KL Loss                      1.9955866
QF Loss                      854.6699
VF Loss                      412.7098
Policy Loss                  -959.42584
Q Predictions Mean           954.0947
Q Predictions Std            287.41113
Q Predictions Max            1217.0884
Q Predictions Min            60.54989
V Predictions Mean           953.6904
V Predictions Std            283.90762
V Predictions Max            1216.7827
V Predictions Min            77.86649
Log Pis Mean                 -0.19031172
Log Pis Std                  3.1398509
Log Pis Max                  9.411382
Log Pis Min                  -8.457005
Policy mu Mean               0.028355796
Policy mu Std                0.598347
Policy mu Max                2.1919563
Policy mu Min                -2.615663
Policy log std Mean          -0.9547809
Policy log std Std           0.32727632
Policy log std Max           -0.20292157
Policy log std Min           -2.2449396
Z mean eval                  0.92871535
Z variance eval              0.013906376
total_rewards                [4.00137657e+02 2.82322790e+03 2.67989108e+03 4.15747789e+02
 2.98105154e+03 2.71371309e+03 1.99594328e-01 9.27294068e+02
 3.01332725e+03 2.79185697e+03]
total_rewards_mean           1874.64469357162
total_rewards_std            1196.9899273882302
total_rewards_max            3013.3272509865433
total_rewards_min            0.1995943280148751
Number of train steps total  348000
Number of env steps total    437000
Number of rollouts total     0
Train Time (s)               127.55972318118438
(Previous) Eval Time (s)     19.71454352280125
Sample Time (s)              24.87120232731104
Epoch Time (s)               172.14546903129667
Total Train Time (s)         15465.510532222223
Epoch                        86
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:50:40.858566 UTC | [2020_01_11_13_32_55] Iteration #86 | Epoch Duration: 184.15183758735657
2020-01-11 17:50:40.858758 UTC | [2020_01_11_13_32_55] Iteration #86 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9296482
Z variance train             0.013967669
KL Divergence                20.981146
KL Loss                      2.0981147
QF Loss                      1792.9912
VF Loss                      292.0186
Policy Loss                  -929.23285
Q Predictions Mean           924.1185
Q Predictions Std            323.9325
Q Predictions Max            1205.4993
Q Predictions Min            62.1915
V Predictions Mean           925.9001
V Predictions Std            320.81845
V Predictions Max            1218.1335
V Predictions Min            121.77649
Log Pis Mean                 -0.2997269
Log Pis Std                  3.267966
Log Pis Max                  12.975581
Log Pis Min                  -9.647949
Policy mu Mean               0.025078975
Policy mu Std                0.60694146
Policy mu Max                2.4317935
Policy mu Min                -2.3051097
Policy log std Mean          -0.9462573
Policy log std Std           0.3255463
Policy log std Max           -0.15513992
Policy log std Min           -2.961823
Z mean eval                  0.9295365
Z variance eval              0.02577379
total_rewards                [1542.88829578 3024.7003623  2321.56281881 2010.48738825  556.50182619
 3001.99463458 1103.00114978 3125.10503593  610.09355842 -103.07815658]
total_rewards_mean           1719.3256913455978
total_rewards_std            1099.4371311153263
total_rewards_max            3125.105035931042
total_rewards_min            -103.07815658381048
Number of train steps total  352000
Number of env steps total    442000
Number of rollouts total     0
Train Time (s)               128.66194219281897
(Previous) Eval Time (s)     31.720582068897784
Sample Time (s)              24.662660943344235
Epoch Time (s)               185.045185205061
Total Train Time (s)         15647.154712579213
Epoch                        87
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:53:42.504501 UTC | [2020_01_11_13_32_55] Iteration #87 | Epoch Duration: 181.6456117630005
2020-01-11 17:53:42.504685 UTC | [2020_01_11_13_32_55] Iteration #87 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92921054
Z variance train             0.025785085
KL Divergence                20.606903
KL Loss                      2.0606904
QF Loss                      690.885
VF Loss                      176.99016
Policy Loss                  -943.7974
Q Predictions Mean           941.0545
Q Predictions Std            315.73392
Q Predictions Max            1244.8798
Q Predictions Min            -8.864897
V Predictions Mean           944.9993
V Predictions Std            310.56192
V Predictions Max            1222.8859
V Predictions Min            0.32631046
Log Pis Mean                 0.04378432
Log Pis Std                  2.964583
Log Pis Max                  10.055119
Log Pis Min                  -7.768811
Policy mu Mean               -0.013974087
Policy mu Std                0.5845048
Policy mu Max                2.2296343
Policy mu Min                -2.4900312
Policy log std Mean          -0.98659706
Policy log std Std           0.32927412
Policy log std Max           -0.18085134
Policy log std Min           -2.5960917
Z mean eval                  0.9469862
Z variance eval              0.014570129
total_rewards                [1403.63762517  122.70007785 2382.68313895 3195.83584107 2141.5067554
  434.01396495 1132.38966157 3081.75619362 1725.75164731 2772.21054883]
total_rewards_mean           1839.2485454709872
total_rewards_std            1013.1517358402064
total_rewards_max            3195.8358410694163
total_rewards_min            122.7000778481758
Number of train steps total  356000
Number of env steps total    447000
Number of rollouts total     0
Train Time (s)               129.32318759383634
(Previous) Eval Time (s)     28.320690577849746
Sample Time (s)              24.499837117269635
Epoch Time (s)               182.14371528895572
Total Train Time (s)         15828.833276080899
Epoch                        88
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:56:44.184900 UTC | [2020_01_11_13_32_55] Iteration #88 | Epoch Duration: 181.68008303642273
2020-01-11 17:56:44.185089 UTC | [2020_01_11_13_32_55] Iteration #88 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9496648
Z variance train             0.014566469
KL Divergence                22.5952
KL Loss                      2.25952
QF Loss                      564.3952
VF Loss                      145.59389
Policy Loss                  -912.2334
Q Predictions Mean           911.4208
Q Predictions Std            338.06042
Q Predictions Max            1226.002
Q Predictions Min            -41.23236
V Predictions Mean           911.88525
V Predictions Std            333.5921
V Predictions Max            1227.5807
V Predictions Min            0.4143802
Log Pis Mean                 -0.09990692
Log Pis Std                  3.1257663
Log Pis Max                  9.905152
Log Pis Min                  -8.399582
Policy mu Mean               0.026512187
Policy mu Std                0.60011727
Policy mu Max                2.7016268
Policy mu Min                -2.4426305
Policy log std Mean          -0.9564235
Policy log std Std           0.31154713
Policy log std Max           -0.18287903
Policy log std Min           -2.2646449
Z mean eval                  0.92956287
Z variance eval              0.018274482
total_rewards                [2646.66623485 2980.28680729 2930.62575908 1092.4649294  3090.91848885
  894.75464909 2943.8262939   904.04235258 2970.16485682 2911.96360276]
total_rewards_mean           2336.5713974612745
total_rewards_std            906.2295366506935
total_rewards_max            3090.918488854815
total_rewards_min            894.7546490876038
Number of train steps total  360000
Number of env steps total    452000
Number of rollouts total     0
Train Time (s)               128.16174293961376
(Previous) Eval Time (s)     27.85673422878608
Sample Time (s)              25.788954694289714
Epoch Time (s)               181.80743186268955
Total Train Time (s)         16012.267729968764
Epoch                        89
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:59:47.621106 UTC | [2020_01_11_13_32_55] Iteration #89 | Epoch Duration: 183.4358811378479
2020-01-11 17:59:47.621295 UTC | [2020_01_11_13_32_55] Iteration #89 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92653
Z variance train             0.01826363
KL Divergence                21.964409
KL Loss                      2.196441
QF Loss                      1192.6912
VF Loss                      722.15137
Policy Loss                  -935.90656
Q Predictions Mean           929.9635
Q Predictions Std            312.6257
Q Predictions Max            1221.359
Q Predictions Min            -77.29477
V Predictions Mean           938.0471
V Predictions Std            300.66858
V Predictions Max            1213.0321
V Predictions Min            131.51593
Log Pis Mean                 -0.19188266
Log Pis Std                  3.3422182
Log Pis Max                  18.948092
Log Pis Min                  -8.911379
Policy mu Mean               -0.008850779
Policy mu Std                0.587639
Policy mu Max                2.1536808
Policy mu Min                -2.3300784
Policy log std Mean          -0.96438676
Policy log std Std           0.31790236
Policy log std Max           -0.26454538
Policy log std Min           -2.5575428
Z mean eval                  0.9333644
Z variance eval              0.014974892
total_rewards                [ 100.49732143 3151.14729371  551.83496676 1376.01725448 3087.24169071
  530.38718694 2659.9750065  3155.26417617 1956.10683608 3171.39399098]
total_rewards_mean           1973.9865723754651
total_rewards_std            1178.9473735486308
total_rewards_max            3171.393990984636
total_rewards_min            100.49732142732566
Number of train steps total  364000
Number of env steps total    457000
Number of rollouts total     0
Train Time (s)               127.34389370074496
(Previous) Eval Time (s)     29.4848910048604
Sample Time (s)              24.70728688593954
Epoch Time (s)               181.5360715915449
Total Train Time (s)         16186.802595647052
Epoch                        90
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:02:42.158768 UTC | [2020_01_11_13_32_55] Iteration #90 | Epoch Duration: 174.53732585906982
2020-01-11 18:02:42.158996 UTC | [2020_01_11_13_32_55] Iteration #90 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93609256
Z variance train             0.014986125
KL Divergence                21.569336
KL Loss                      2.1569335
QF Loss                      6904.985
VF Loss                      198.90582
Policy Loss                  -899.63495
Q Predictions Mean           901.86584
Q Predictions Std            352.32315
Q Predictions Max            1217.4781
Q Predictions Min            -9.307185
V Predictions Mean           908.8899
V Predictions Std            351.43814
V Predictions Max            1217.2068
V Predictions Min            -22.908836
Log Pis Mean                 -0.5548438
Log Pis Std                  3.1674025
Log Pis Max                  13.464413
Log Pis Min                  -8.353008
Policy mu Mean               0.01488618
Policy mu Std                0.60284454
Policy mu Max                2.3680377
Policy mu Min                -2.5787187
Policy log std Mean          -0.9151672
Policy log std Std           0.34279156
Policy log std Max           -0.095847905
Policy log std Min           -2.7437675
Z mean eval                  0.9501295
Z variance eval              0.011601282
total_rewards                [1246.30376708 1708.63359582  140.34902137 2187.72879189  207.65683524
  440.07325525  207.32204212  301.05791004 1793.77701554  -54.60749213]
total_rewards_mean           817.82947422196
total_rewards_std            786.2015362115326
total_rewards_max            2187.7287918879447
total_rewards_min            -54.60749212751492
Number of train steps total  368000
Number of env steps total    462000
Number of rollouts total     0
Train Time (s)               128.75738063827157
(Previous) Eval Time (s)     22.485791567713022
Sample Time (s)              24.954127134289593
Epoch Time (s)               176.19729934027418
Total Train Time (s)         16355.522073395085
Epoch                        91
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:05:30.880035 UTC | [2020_01_11_13_32_55] Iteration #91 | Epoch Duration: 168.7209014892578
2020-01-11 18:05:30.880218 UTC | [2020_01_11_13_32_55] Iteration #91 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.950765
Z variance train             0.011562926
KL Divergence                22.363297
KL Loss                      2.2363298
QF Loss                      734.55493
VF Loss                      326.38705
Policy Loss                  -994.7849
Q Predictions Mean           991.82336
Q Predictions Std            279.3202
Q Predictions Max            1223.8721
Q Predictions Min            51.206936
V Predictions Mean           983.6792
V Predictions Std            274.1641
V Predictions Max            1203.5271
V Predictions Min            117.52564
Log Pis Mean                 0.12105666
Log Pis Std                  3.0409007
Log Pis Max                  16.681974
Log Pis Min                  -6.83086
Policy mu Mean               -0.016377926
Policy mu Std                0.62162733
Policy mu Max                2.0786192
Policy mu Min                -2.2168512
Policy log std Mean          -0.98852617
Policy log std Std           0.29711813
Policy log std Max           -0.20323205
Policy log std Min           -2.4264994
Z mean eval                  0.9457439
Z variance eval              0.02557413
total_rewards                [ -51.76140162 2951.44823252   52.97153588  274.98083749 2954.4709739
  533.70839672  986.54129704 2923.42434687 1700.1465012  3255.26413141]
total_rewards_mean           1558.1194851429605
total_rewards_std            1285.9021260798513
total_rewards_max            3255.2641314117186
total_rewards_min            -51.761401620938415
Number of train steps total  372000
Number of env steps total    467000
Number of rollouts total     0
Train Time (s)               128.44183490797877
(Previous) Eval Time (s)     15.009019896853715
Sample Time (s)              23.084754252806306
Epoch Time (s)               166.5356090576388
Total Train Time (s)         16538.473484845832
Epoch                        92
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:08:33.832605 UTC | [2020_01_11_13_32_55] Iteration #92 | Epoch Duration: 182.95224404335022
2020-01-11 18:08:33.832790 UTC | [2020_01_11_13_32_55] Iteration #92 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94478244
Z variance train             0.025625288
KL Divergence                20.678112
KL Loss                      2.0678113
QF Loss                      2435.1086
VF Loss                      133.058
Policy Loss                  -955.1576
Q Predictions Mean           951.68054
Q Predictions Std            320.97513
Q Predictions Max            1240.9312
Q Predictions Min            51.428875
V Predictions Mean           957.33386
V Predictions Std            315.87946
V Predictions Max            1239.1987
V Predictions Min            52.32936
Log Pis Mean                 -0.15624559
Log Pis Std                  3.1835427
Log Pis Max                  10.433073
Log Pis Min                  -8.493497
Policy mu Mean               0.0053267707
Policy mu Std                0.6354954
Policy mu Max                2.7696748
Policy mu Min                -2.4392397
Policy log std Mean          -0.9428377
Policy log std Std           0.31556675
Policy log std Max           -0.01867199
Policy log std Min           -2.1212244
Z mean eval                  0.97914803
Z variance eval              0.02310333
total_rewards                [3217.6402647  3155.42028048  122.04495733  909.45454669 2996.36655857
 3091.53304597 3161.18643703 1290.17833459 3052.29024312  -58.02184563]
total_rewards_mean           2093.80928228503
total_rewards_std            1297.1047248746445
total_rewards_max            3217.6402646967417
total_rewards_min            -58.021845631380884
Number of train steps total  376000
Number of env steps total    472000
Number of rollouts total     0
Train Time (s)               127.9795900718309
(Previous) Eval Time (s)     31.42532106395811
Sample Time (s)              25.559482502751052
Epoch Time (s)               184.96439363854006
Total Train Time (s)         16718.535725410562
Epoch                        93
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:11:33.895261 UTC | [2020_01_11_13_32_55] Iteration #93 | Epoch Duration: 180.06236147880554
2020-01-11 18:11:33.895383 UTC | [2020_01_11_13_32_55] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98021
Z variance train             0.023125438
KL Divergence                21.656906
KL Loss                      2.1656907
QF Loss                      1103.6005
VF Loss                      308.18896
Policy Loss                  -968.3999
Q Predictions Mean           966.8235
Q Predictions Std            286.2936
Q Predictions Max            1213.962
Q Predictions Min            114.057274
V Predictions Mean           982.20715
V Predictions Std            286.25873
V Predictions Max            1237.3927
V Predictions Min            129.27106
Log Pis Mean                 -0.32748097
Log Pis Std                  2.9571872
Log Pis Max                  11.5273
Log Pis Min                  -8.327637
Policy mu Mean               -0.007604424
Policy mu Std                0.6011438
Policy mu Max                1.9485519
Policy mu Min                -3.0533404
Policy log std Mean          -0.94414663
Policy log std Std           0.29744777
Policy log std Max           -0.20164895
Policy log std Min           -2.5524604
Z mean eval                  0.9649342
Z variance eval              0.020648371
total_rewards                [1449.83097414  642.32309107 2283.17772305  854.4741424  3110.69998233
  366.65410613  933.22860264  506.66866088  237.96802772 1627.74689867]
total_rewards_mean           1201.2772209015488
total_rewards_std            875.8797226806334
total_rewards_max            3110.6999823337783
total_rewards_min            237.96802771515473
Number of train steps total  380000
Number of env steps total    477000
Number of rollouts total     0
Train Time (s)               128.47317807096988
(Previous) Eval Time (s)     26.522962382994592
Sample Time (s)              24.766487060580403
Epoch Time (s)               179.76262751454487
Total Train Time (s)         16891.003976267762
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:14:26.366376 UTC | [2020_01_11_13_32_55] Iteration #94 | Epoch Duration: 172.47089624404907
2020-01-11 18:14:26.366554 UTC | [2020_01_11_13_32_55] Iteration #94 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96496373
Z variance train             0.020697366
KL Divergence                21.764557
KL Loss                      2.1764557
QF Loss                      1260.1687
VF Loss                      371.9323
Policy Loss                  -996.9129
Q Predictions Mean           993.96277
Q Predictions Std            278.43274
Q Predictions Max            1270.076
Q Predictions Min            -87.055435
V Predictions Mean           989.6633
V Predictions Std            269.94836
V Predictions Max            1240.9247
V Predictions Min            124.12648
Log Pis Mean                 0.23409027
Log Pis Std                  3.1859226
Log Pis Max                  11.747463
Log Pis Min                  -7.8460493
Policy mu Mean               0.044312462
Policy mu Std                0.6384968
Policy mu Max                2.2523167
Policy mu Min                -2.093274
Policy log std Mean          -0.97377634
Policy log std Std           0.30963537
Policy log std Max           -0.24045104
Policy log std Min           -2.4979196
Z mean eval                  0.94731224
Z variance eval              0.014114487
total_rewards                [ -26.55561586  -35.5251091   273.65996178 2983.14543034 1798.6245545
 1323.99615926  883.21650215 3070.95076004  982.47660966 1430.87801171]
total_rewards_mean           1268.4867264480322
total_rewards_std            1053.4194875064084
total_rewards_max            3070.9507600435245
total_rewards_min            -35.525109104711824
Number of train steps total  384000
Number of env steps total    482000
Number of rollouts total     0
Train Time (s)               129.69758752221242
(Previous) Eval Time (s)     19.230914271902293
Sample Time (s)              24.96541084907949
Epoch Time (s)               173.8939126431942
Total Train Time (s)         17070.60023560794
Epoch                        95
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:17:25.966136 UTC | [2020_01_11_13_32_55] Iteration #95 | Epoch Duration: 179.59944438934326
2020-01-11 18:17:25.966428 UTC | [2020_01_11_13_32_55] Iteration #95 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94796515
Z variance train             0.014210703
KL Divergence                21.513544
KL Loss                      2.1513546
QF Loss                      717.8439
VF Loss                      306.0109
Policy Loss                  -962.6717
Q Predictions Mean           961.41675
Q Predictions Std            336.20636
Q Predictions Max            1234.7904
Q Predictions Min            -19.596485
V Predictions Mean           951.02356
V Predictions Std            330.22098
V Predictions Max            1228.8524
V Predictions Min            8.123793
Log Pis Mean                 -0.10316426
Log Pis Std                  3.010755
Log Pis Max                  10.432833
Log Pis Min                  -7.157581
Policy mu Mean               0.076028325
Policy mu Std                0.60105354
Policy mu Max                2.6716282
Policy mu Min                -2.6919827
Policy log std Mean          -0.9609853
Policy log std Std           0.32148325
Policy log std Max           -0.09739852
Policy log std Min           -2.3539333
Z mean eval                  0.93945944
Z variance eval              0.015933864
total_rewards                [1649.60280027 2840.41108982 1986.83911691 3024.34329629 1580.61718287
  523.98210215 3252.83135549 2557.89615941 2548.01710274 2567.38364124]
total_rewards_mean           2253.192384718162
total_rewards_std            780.7079999256224
total_rewards_max            3252.8313554895944
total_rewards_min            523.982102145745
Number of train steps total  388000
Number of env steps total    487000
Number of rollouts total     0
Train Time (s)               134.53625255078077
(Previous) Eval Time (s)     24.93612466333434
Sample Time (s)              24.596212500240654
Epoch Time (s)               184.06858971435577
Total Train Time (s)         17258.883949087933
Epoch                        96
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:20:34.251612 UTC | [2020_01_11_13_32_55] Iteration #96 | Epoch Duration: 188.28493213653564
2020-01-11 18:20:34.251976 UTC | [2020_01_11_13_32_55] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93899757
Z variance train             0.015919369
KL Divergence                20.447346
KL Loss                      2.0447347
QF Loss                      521.131
VF Loss                      146.6474
Policy Loss                  -954.35944
Q Predictions Mean           953.2842
Q Predictions Std            342.5541
Q Predictions Max            1251.1246
Q Predictions Min            141.39388
V Predictions Mean           951.1465
V Predictions Std            338.5382
V Predictions Max            1243.0669
V Predictions Min            142.84526
Log Pis Mean                 -0.27415854
Log Pis Std                  3.0554602
Log Pis Max                  12.072514
Log Pis Min                  -6.4220676
Policy mu Mean               0.017898511
Policy mu Std                0.58141845
Policy mu Max                2.9242516
Policy mu Min                -2.6030414
Policy log std Mean          -0.9311838
Policy log std Std           0.33173501
Policy log std Max           -0.1466487
Policy log std Min           -2.8484385
Z mean eval                  0.97714406
Z variance eval              0.01106227
total_rewards                [1293.66785394  303.76248523  860.54657827 1242.97794381  189.38591824
 2122.18729909  848.67710912  663.87632665 1650.83724542 2750.42017755]
total_rewards_mean           1192.6338937315752
total_rewards_std            762.7733632045405
total_rewards_max            2750.420177548963
total_rewards_min            189.38591824302884
Number of train steps total  392000
Number of env steps total    492000
Number of rollouts total     0
Train Time (s)               138.51215023826808
(Previous) Eval Time (s)     29.15211065299809
Sample Time (s)              26.360012048855424
Epoch Time (s)               194.0242729401216
Total Train Time (s)         17447.156540883705
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:23:42.525254 UTC | [2020_01_11_13_32_55] Iteration #97 | Epoch Duration: 188.27306199073792
2020-01-11 18:23:42.525451 UTC | [2020_01_11_13_32_55] Iteration #97 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97889805
Z variance train             0.011071006
KL Divergence                21.029823
KL Loss                      2.1029823
QF Loss                      813.00665
VF Loss                      161.73389
Policy Loss                  -946.4665
Q Predictions Mean           943.7045
Q Predictions Std            348.23303
Q Predictions Max            1264.8987
Q Predictions Min            10.834587
V Predictions Mean           952.2129
V Predictions Std            346.87857
V Predictions Max            1264.0128
V Predictions Min            -36.85603
Log Pis Mean                 -0.008822456
Log Pis Std                  3.3572226
Log Pis Max                  17.38328
Log Pis Min                  -8.060212
Policy mu Mean               0.010842333
Policy mu Std                0.61699843
Policy mu Max                2.3866339
Policy mu Min                -2.6090636
Policy log std Mean          -0.95948684
Policy log std Std           0.33549163
Policy log std Max           -0.19192058
Policy log std Min           -2.6505504
Z mean eval                  0.98075753
Z variance eval              0.012888512
total_rewards                [ -15.55426165  761.38274287 1463.01115805 2331.13499302 2873.06759263
 2753.08189843 3135.88978197  441.18240331  248.24552689 1634.44720762]
total_rewards_mean           1562.5889043147467
total_rewards_std            1110.5478047634688
total_rewards_max            3135.8897819685085
total_rewards_min            -15.554261646263793
Number of train steps total  396000
Number of env steps total    497000
Number of rollouts total     0
Train Time (s)               135.97897382685915
(Previous) Eval Time (s)     23.400535909924656
Sample Time (s)              26.770294763613492
Epoch Time (s)               186.1498045003973
Total Train Time (s)         17628.698273389135
Epoch                        98
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:26:44.069585 UTC | [2020_01_11_13_32_55] Iteration #98 | Epoch Duration: 181.5439748764038
2020-01-11 18:26:44.069876 UTC | [2020_01_11_13_32_55] Iteration #98 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.981764
Z variance train             0.012882033
KL Divergence                20.892952
KL Loss                      2.0892951
QF Loss                      1025.397
VF Loss                      259.65668
Policy Loss                  -949.1368
Q Predictions Mean           946.25757
Q Predictions Std            362.51816
Q Predictions Max            1262.0933
Q Predictions Min            -5.15749
V Predictions Mean           950.3487
V Predictions Std            356.47556
V Predictions Max            1257.4609
V Predictions Min            4.1800327
Log Pis Mean                 -0.068124175
Log Pis Std                  3.3696826
Log Pis Max                  14.781274
Log Pis Min                  -7.647274
Policy mu Mean               0.03341924
Policy mu Std                0.5927572
Policy mu Max                2.4671235
Policy mu Min                -2.3196614
Policy log std Mean          -1.0010196
Policy log std Std           0.360501
Policy log std Max           -0.16700214
Policy log std Min           -2.6450183
Z mean eval                  0.9357274
Z variance eval              0.0260632
total_rewards                [2001.46890219 3213.36337296 3046.32033078 1851.09346557 1749.30366958
 3312.69369981  820.49784774 3077.20479675   48.82802529 1237.44440891]
total_rewards_mean           2035.8218519571553
total_rewards_std            1063.1346188347168
total_rewards_max            3312.69369980842
total_rewards_min            48.82802528953948
Number of train steps total  400000
Number of env steps total    502000
Number of rollouts total     0
Train Time (s)               139.06990089314058
(Previous) Eval Time (s)     18.794271123129874
Sample Time (s)              25.175360202789307
Epoch Time (s)               183.03953221905977
Total Train Time (s)         17821.957126197405
Epoch                        99
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:29:57.329741 UTC | [2020_01_11_13_32_55] Iteration #99 | Epoch Duration: 193.25970458984375
2020-01-11 18:29:57.329934 UTC | [2020_01_11_13_32_55] Iteration #99 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93407315
Z variance train             0.026094407
KL Divergence                20.725826
KL Loss                      2.0725827
QF Loss                      582.78925
VF Loss                      142.9263
Policy Loss                  -949.4412
Q Predictions Mean           950.5613
Q Predictions Std            332.5782
Q Predictions Max            1257.9894
Q Predictions Min            52.956913
V Predictions Mean           950.5841
V Predictions Std            331.4945
V Predictions Max            1257.0645
V Predictions Min            -23.262617
Log Pis Mean                 -0.65081275
Log Pis Std                  3.0107079
Log Pis Max                  8.445386
Log Pis Min                  -10.6803875
Policy mu Mean               0.01893795
Policy mu Std                0.5831713
Policy mu Max                2.5830443
Policy mu Min                -2.2046032
Policy log std Mean          -0.9209776
Policy log std Std           0.30508137
Policy log std Max           0.11310136
Policy log std Min           -2.1799393
Z mean eval                  0.94615334
Z variance eval              0.011299982
total_rewards                [ 106.56186858 3105.90684312  322.97713466  402.22755511   39.20248168
  166.36030366 1130.42243904  168.24710242 1455.85898792  189.3510013 ]
total_rewards_mean           708.7115717472832
total_rewards_std            916.0866129371194
total_rewards_max            3105.906843118513
total_rewards_min            39.20248167638658
Number of train steps total  404000
Number of env steps total    507000
Number of rollouts total     0
Train Time (s)               138.46461350703612
(Previous) Eval Time (s)     29.014091577846557
Sample Time (s)              25.587689887732267
Epoch Time (s)               193.06639497261494
Total Train Time (s)         18014.703772357665
Epoch                        100
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:33:10.078616 UTC | [2020_01_11_13_32_55] Iteration #100 | Epoch Duration: 192.74855017662048
2020-01-11 18:33:10.078806 UTC | [2020_01_11_13_32_55] Iteration #100 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9456717
Z variance train             0.011296958
KL Divergence                21.29836
KL Loss                      2.129836
QF Loss                      772.2884
VF Loss                      211.13478
Policy Loss                  -966.2125
Q Predictions Mean           963.397
Q Predictions Std            340.64285
Q Predictions Max            1280.8344
Q Predictions Min            6.8847094
V Predictions Mean           964.5934
V Predictions Std            337.12338
V Predictions Max            1277.9795
V Predictions Min            13.228276
Log Pis Mean                 -0.39793187
Log Pis Std                  3.244078
Log Pis Max                  13.523053
Log Pis Min                  -7.417486
Policy mu Mean               0.035086956
Policy mu Std                0.5865345
Policy mu Max                2.4000392
Policy mu Min                -2.1026416
Policy log std Mean          -0.9486713
Policy log std Std           0.3454283
Policy log std Max           -0.087424636
Policy log std Min           -2.685075
Z mean eval                  0.977787
Z variance eval              0.010471659
total_rewards                [ 486.46365751 2927.15462221  921.96612583 1107.16887823  726.13487704
  600.49506223  535.23377782 3108.01775276 1897.13992928 1508.40993109]
total_rewards_mean           1381.818461399477
total_rewards_std            921.6864483729554
total_rewards_max            3108.017752756508
total_rewards_min            486.4636575088107
Number of train steps total  408000
Number of env steps total    512000
Number of rollouts total     0
Train Time (s)               129.6002829768695
(Previous) Eval Time (s)     28.69589018402621
Sample Time (s)              24.39943317323923
Epoch Time (s)               182.69560633413494
Total Train Time (s)         18196.493661431596
Epoch                        101
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:36:11.869779 UTC | [2020_01_11_13_32_55] Iteration #101 | Epoch Duration: 181.79084467887878
2020-01-11 18:36:11.869942 UTC | [2020_01_11_13_32_55] Iteration #101 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.978693
Z variance train             0.010466166
KL Divergence                22.33686
KL Loss                      2.2336862
QF Loss                      832.65454
VF Loss                      188.225
Policy Loss                  -979.7033
Q Predictions Mean           978.5243
Q Predictions Std            332.50458
Q Predictions Max            1277.7211
Q Predictions Min            125.39609
V Predictions Mean           977.4453
V Predictions Std            331.36545
V Predictions Max            1264.3989
V Predictions Min            131.20384
Log Pis Mean                 -0.10896756
Log Pis Std                  3.2042146
Log Pis Max                  9.283158
Log Pis Min                  -8.077206
Policy mu Mean               0.0016353149
Policy mu Std                0.61169785
Policy mu Max                2.1519663
Policy mu Min                -2.4255595
Policy log std Mean          -0.9508028
Policy log std Std           0.3130502
Policy log std Max           -0.09654498
Policy log std Min           -2.1187434
Z mean eval                  0.9631609
Z variance eval              0.023960263
total_rewards                [3004.23326956 2022.81540994 1405.14825501 3167.16172101 3370.20240485
 2254.79017454 1398.08360466 3057.82470137 3306.57867074 3085.53085548]
total_rewards_mean           2607.236906716183
total_rewards_std            731.2282574894559
total_rewards_max            3370.202404847242
total_rewards_min            1398.083604657323
Number of train steps total  412000
Number of env steps total    517000
Number of rollouts total     0
Train Time (s)               128.46448516799137
(Previous) Eval Time (s)     27.790810038801283
Sample Time (s)              25.50717340176925
Epoch Time (s)               181.7624686085619
Total Train Time (s)         18382.350307268556
Epoch                        102
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:39:17.728983 UTC | [2020_01_11_13_32_55] Iteration #102 | Epoch Duration: 185.8589243888855
2020-01-11 18:39:17.729172 UTC | [2020_01_11_13_32_55] Iteration #102 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9649744
Z variance train             0.024010014
KL Divergence                21.361296
KL Loss                      2.1361296
QF Loss                      778.9158
VF Loss                      327.1449
Policy Loss                  -995.5383
Q Predictions Mean           993.1442
Q Predictions Std            322.31747
Q Predictions Max            1255.2037
Q Predictions Min            139.0462
V Predictions Mean           994.10187
V Predictions Std            318.4308
V Predictions Max            1256.7367
V Predictions Min            145.27684
Log Pis Mean                 0.12528673
Log Pis Std                  3.5293005
Log Pis Max                  26.919025
Log Pis Min                  -9.527027
Policy mu Mean               -0.0037991249
Policy mu Std                0.6029986
Policy mu Max                3.0685601
Policy mu Min                -3.9448776
Policy log std Mean          -1.0016255
Policy log std Std           0.35241726
Policy log std Max           -0.033920348
Policy log std Min           -2.6469584
Z mean eval                  0.9519844
Z variance eval              0.013169423
total_rewards                [2970.63513572  582.7516115   530.16232506 3340.38634205 3049.73379906
   80.81008241 2540.31695368  121.29757391  767.50021345 2582.19864103]
total_rewards_mean           1656.579267786746
total_rewards_std            1272.5216340487314
total_rewards_max            3340.3863420465796
total_rewards_min            80.81008241164328
Number of train steps total  416000
Number of env steps total    522000
Number of rollouts total     0
Train Time (s)               128.65297231636941
(Previous) Eval Time (s)     31.886894655879587
Sample Time (s)              25.206889391411096
Epoch Time (s)               185.7467563636601
Total Train Time (s)         18559.57698091492
Epoch                        103
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:42:14.957063 UTC | [2020_01_11_13_32_55] Iteration #103 | Epoch Duration: 177.22776293754578
2020-01-11 18:42:14.957227 UTC | [2020_01_11_13_32_55] Iteration #103 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95133334
Z variance train             0.01316236
KL Divergence                22.550419
KL Loss                      2.2550418
QF Loss                      664.9302
VF Loss                      443.85498
Policy Loss                  -1002.8884
Q Predictions Mean           1001.11694
Q Predictions Std            312.93344
Q Predictions Max            1319.4266
Q Predictions Min            -7.9594216
V Predictions Mean           1013.3134
V Predictions Std            311.96097
V Predictions Max            1303.331
V Predictions Min            -31.607605
Log Pis Mean                 -0.005142316
Log Pis Std                  3.0656312
Log Pis Max                  12.201761
Log Pis Min                  -8.157361
Policy mu Mean               0.024982233
Policy mu Std                0.6022715
Policy mu Max                2.2849576
Policy mu Min                -2.698685
Policy log std Mean          -0.98637635
Policy log std Std           0.3271407
Policy log std Max           -0.17518604
Policy log std Min           -2.251101
Z mean eval                  0.9490175
Z variance eval              0.015217727
total_rewards                [ 322.08312714 1159.08785552  528.66156728 2177.87428317 3181.53483436
  819.14508055 1714.44150275 3398.8089753   136.83851463 3212.33184051]
total_rewards_mean           1665.0807581213423
total_rewards_std            1198.6274503693649
total_rewards_max            3398.808975303091
total_rewards_min            136.8385146342192
Number of train steps total  420000
Number of env steps total    527000
Number of rollouts total     0
Train Time (s)               129.28940570307896
(Previous) Eval Time (s)     23.367619181983173
Sample Time (s)              25.76033646753058
Epoch Time (s)               178.4173613525927
Total Train Time (s)         18747.902878626715
Epoch                        104
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:45:23.285209 UTC | [2020_01_11_13_32_55] Iteration #104 | Epoch Duration: 188.32786107063293
2020-01-11 18:45:23.285419 UTC | [2020_01_11_13_32_55] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.948839
Z variance train             0.015239012
KL Divergence                21.954033
KL Loss                      2.1954033
QF Loss                      723.6731
VF Loss                      347.45154
Policy Loss                  -1034.1327
Q Predictions Mean           1033.2021
Q Predictions Std            293.6467
Q Predictions Max            1301.5494
Q Predictions Min            -7.565036
V Predictions Mean           1026.2935
V Predictions Std            286.94803
V Predictions Max            1290.0841
V Predictions Min            15.127728
Log Pis Mean                 0.48174423
Log Pis Std                  3.3063562
Log Pis Max                  13.421814
Log Pis Min                  -6.8578434
Policy mu Mean               0.022364816
Policy mu Std                0.6603324
Policy mu Max                2.892241
Policy mu Min                -3.2727878
Policy log std Mean          -1.001503
Policy log std Std           0.32870507
Policy log std Max           -0.10163468
Policy log std Min           -2.4883687
Z mean eval                  0.96784866
Z variance eval              0.020050284
total_rewards                [ 178.25494035   66.77294483 3329.99732659  115.928402   1810.06247234
  946.5035589   872.31740701 1082.48777801 3261.49301477  324.80691139]
total_rewards_mean           1198.8624756200616
total_rewards_std            1166.7729637309444
total_rewards_max            3329.997326594704
total_rewards_min            66.77294482624755
Number of train steps total  424000
Number of env steps total    532000
Number of rollouts total     0
Train Time (s)               128.70771966781467
(Previous) Eval Time (s)     33.277770476881415
Sample Time (s)              26.008988292887807
Epoch Time (s)               187.9944784375839
Total Train Time (s)         18925.528271947056
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:48:20.913255 UTC | [2020_01_11_13_32_55] Iteration #105 | Epoch Duration: 177.62769865989685
2020-01-11 18:48:20.913439 UTC | [2020_01_11_13_32_55] Iteration #105 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9658333
Z variance train             0.020055156
KL Divergence                21.816053
KL Loss                      2.1816053
QF Loss                      715.5203
VF Loss                      179.3924
Policy Loss                  -1009.30914
Q Predictions Mean           1011.088
Q Predictions Std            322.61902
Q Predictions Max            1297.8573
Q Predictions Min            -95.22499
V Predictions Mean           1015.60156
V Predictions Std            320.11432
V Predictions Max            1293.8545
V Predictions Min            32.087826
Log Pis Mean                 0.09683168
Log Pis Std                  2.81827
Log Pis Max                  8.128945
Log Pis Min                  -8.435231
Policy mu Mean               0.0027463806
Policy mu Std                0.6180842
Policy mu Max                2.6579857
Policy mu Min                -2.240213
Policy log std Mean          -0.9508871
Policy log std Std           0.3068779
Policy log std Max           -0.10541117
Policy log std Min           -2.5575378
Z mean eval                  0.9581255
Z variance eval              0.016197959
total_rewards                [1594.53672895 1441.69861862 3161.28488448 3224.48455664   12.05190263
 3392.06322666  565.53997466 3232.89882528 2420.24311097 3125.64664305]
total_rewards_mean           2217.0448471952604
total_rewards_std            1173.206658348112
total_rewards_max            3392.063226663947
total_rewards_min            12.051902632821804
Number of train steps total  428000
Number of env steps total    537000
Number of rollouts total     0
Train Time (s)               128.95616305572912
(Previous) Eval Time (s)     22.910688433796167
Sample Time (s)              25.881925246678293
Epoch Time (s)               177.74877673620358
Total Train Time (s)         19107.17500415165
Epoch                        106
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:51:22.560203 UTC | [2020_01_11_13_32_55] Iteration #106 | Epoch Duration: 181.6466519832611
2020-01-11 18:51:22.560331 UTC | [2020_01_11_13_32_55] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.957384
Z variance train             0.016168159
KL Divergence                21.98736
KL Loss                      2.198736
QF Loss                      1020.6611
VF Loss                      155.74677
Policy Loss                  -974.9642
Q Predictions Mean           972.6997
Q Predictions Std            355.84512
Q Predictions Max            1278.7732
Q Predictions Min            -54.599148
V Predictions Mean           970.26666
V Predictions Std            355.13638
V Predictions Max            1270.6476
V Predictions Min            39.61059
Log Pis Mean                 -0.24015066
Log Pis Std                  3.2080626
Log Pis Max                  12.059891
Log Pis Min                  -8.2875185
Policy mu Mean               0.047589537
Policy mu Std                0.5971564
Policy mu Max                2.7466614
Policy mu Min                -2.3231847
Policy log std Mean          -0.9605131
Policy log std Std           0.3424039
Policy log std Max           -0.1345712
Policy log std Min           -2.5600228
Z mean eval                  0.9687769
Z variance eval              0.012123607
total_rewards                [3252.40260627  853.43329696  873.37711231    3.60202385 3211.56370186
  543.84319025  533.93381132  546.78696555 2246.16611785 3178.12201152]
total_rewards_mean           1524.3230837739043
total_rewards_std            1231.8016439176486
total_rewards_max            3252.4026062681187
total_rewards_min            3.6020238498198367
Number of train steps total  432000
Number of env steps total    542000
Number of rollouts total     0
Train Time (s)               128.69651034194976
(Previous) Eval Time (s)     26.80820358125493
Sample Time (s)              23.21371701452881
Epoch Time (s)               178.7184309377335
Total Train Time (s)         19286.690154057927
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:54:22.077912 UTC | [2020_01_11_13_32_55] Iteration #107 | Epoch Duration: 179.51746535301208
2020-01-11 18:54:22.078113 UTC | [2020_01_11_13_32_55] Iteration #107 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96905005
Z variance train             0.012141688
KL Divergence                23.18113
KL Loss                      2.318113
QF Loss                      868.47974
VF Loss                      3143.071
Policy Loss                  -1011.8765
Q Predictions Mean           1013.6808
Q Predictions Std            318.95706
Q Predictions Max            1289.9589
Q Predictions Min            44.212955
V Predictions Mean           1018.4508
V Predictions Std            311.56924
V Predictions Max            1280.7847
V Predictions Min            2.0402148
Log Pis Mean                 -0.1516764
Log Pis Std                  3.0174637
Log Pis Max                  11.622478
Log Pis Min                  -7.531828
Policy mu Mean               0.016870527
Policy mu Std                0.5970681
Policy mu Max                2.157927
Policy mu Min                -2.1438599
Policy log std Mean          -0.9662901
Policy log std Std           0.3399912
Policy log std Max           -0.17905897
Policy log std Min           -2.9735665
Z mean eval                  0.9882717
Z variance eval              0.013594007
total_rewards                [1800.18482153 3281.29809104 3231.38757796 3275.09928861 3239.51116845
 3220.64732114 3170.62524204  538.34425035  623.4437217  1363.55167751]
total_rewards_mean           2374.4093160342604
total_rewards_std            1107.0304227499305
total_rewards_max            3281.298091036042
total_rewards_min            538.3442503524144
Number of train steps total  436000
Number of env steps total    547000
Number of rollouts total     0
Train Time (s)               130.61239150585607
(Previous) Eval Time (s)     27.606892965734005
Sample Time (s)              24.104577366262674
Epoch Time (s)               182.32386183785275
Total Train Time (s)         19471.243350786157
Epoch                        108
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:57:26.631944 UTC | [2020_01_11_13_32_55] Iteration #108 | Epoch Duration: 184.55371856689453
2020-01-11 18:57:26.632067 UTC | [2020_01_11_13_32_55] Iteration #108 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9886941
Z variance train             0.013598904
KL Divergence                22.91934
KL Loss                      2.291934
QF Loss                      1194.5492
VF Loss                      262.83942
Policy Loss                  -1002.8132
Q Predictions Mean           1000.0062
Q Predictions Std            336.5928
Q Predictions Max            1289.6595
Q Predictions Min            130.84822
V Predictions Mean           999.649
V Predictions Std            334.58157
V Predictions Max            1296.5378
V Predictions Min            128.38136
Log Pis Mean                 0.3965087
Log Pis Std                  3.5012796
Log Pis Max                  15.8088665
Log Pis Min                  -6.8092127
Policy mu Mean               0.020892056
Policy mu Std                0.6367022
Policy mu Max                2.941037
Policy mu Min                -2.4681244
Policy log std Mean          -0.9800256
Policy log std Std           0.3593033
Policy log std Max           -0.07400775
Policy log std Min           -2.61666
Z mean eval                  0.9747385
Z variance eval              0.012743086
total_rewards                [1420.7328808   878.7156988    87.89720651 -118.4884704  1991.91902973
  965.93375897 1844.47933175 3180.70715042 1564.76562813 2700.61349805]
total_rewards_mean           1451.7275712745893
total_rewards_std            994.9289114778354
total_rewards_max            3180.707150422513
total_rewards_min            -118.48847039936277
Number of train steps total  440000
Number of env steps total    552000
Number of rollouts total     0
Train Time (s)               129.10827083420008
(Previous) Eval Time (s)     29.83633590117097
Sample Time (s)              24.413716637529433
Epoch Time (s)               183.3583233729005
Total Train Time (s)         19649.17749733245
Epoch                        109
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:00:24.569127 UTC | [2020_01_11_13_32_55] Iteration #109 | Epoch Duration: 177.93695759773254
2020-01-11 19:00:24.569410 UTC | [2020_01_11_13_32_55] Iteration #109 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9736575
Z variance train             0.012722699
KL Divergence                23.430758
KL Loss                      2.3430758
QF Loss                      866.9888
VF Loss                      251.19052
Policy Loss                  -968.2238
Q Predictions Mean           962.19434
Q Predictions Std            375.53586
Q Predictions Max            1291.1305
Q Predictions Min            -9.723053
V Predictions Mean           965.0327
V Predictions Std            366.50497
V Predictions Max            1276.9542
V Predictions Min            0.7953756
Log Pis Mean                 0.3806255
Log Pis Std                  3.4406316
Log Pis Max                  16.574963
Log Pis Min                  -6.1583066
Policy mu Mean               0.025560196
Policy mu Std                0.61798877
Policy mu Max                2.1322954
Policy mu Min                -2.9807742
Policy log std Mean          -0.9944463
Policy log std Std           0.3710055
Policy log std Max           -0.112552226
Policy log std Min           -2.4169867
Z mean eval                  0.96483964
Z variance eval              0.019850817
total_rewards                [2988.91786192 -131.33305902 2779.106335    211.92802215 1910.69480923
  890.7696846   820.48697967 1050.89763511 1463.62069442 2684.79882046]
total_rewards_mean           1466.9887783534896
total_rewards_std            1037.8248098354356
total_rewards_max            2988.9178619152003
total_rewards_min            -131.3330590186811
Number of train steps total  444000
Number of env steps total    557000
Number of rollouts total     0
Train Time (s)               130.17648734617978
(Previous) Eval Time (s)     24.41463571973145
Sample Time (s)              23.297603257466108
Epoch Time (s)               177.88872632337734
Total Train Time (s)         19826.872826603707
Epoch                        110
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:03:22.265837 UTC | [2020_01_11_13_32_55] Iteration #110 | Epoch Duration: 177.69623017311096
2020-01-11 19:03:22.266025 UTC | [2020_01_11_13_32_55] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9686756
Z variance train             0.019905154
KL Divergence                22.976528
KL Loss                      2.297653
QF Loss                      1100.6417
VF Loss                      459.33063
Policy Loss                  -1019.57245
Q Predictions Mean           1017.8868
Q Predictions Std            320.95197
Q Predictions Max            1313.347
Q Predictions Min            62.402103
V Predictions Mean           1007.8107
V Predictions Std            318.24722
V Predictions Max            1281.9094
V Predictions Min            -22.398855
Log Pis Mean                 -0.012730941
Log Pis Std                  3.444001
Log Pis Max                  14.620626
Log Pis Min                  -8.492954
Policy mu Mean               0.026464555
Policy mu Std                0.6456549
Policy mu Max                2.448225
Policy mu Min                -2.7069929
Policy log std Mean          -0.92315835
Policy log std Std           0.32088387
Policy log std Max           -0.009773493
Policy log std Min           -2.437292
Z mean eval                  0.9706825
Z variance eval              0.01565643
total_rewards                [ 464.88706199 1297.55125519  539.97687463  587.59115995 2891.61576639
 2463.58271721 1041.26519044 3168.87194474 3049.85686181 2857.13814767]
total_rewards_mean           1836.2336980017467
total_rewards_std            1088.144526989476
total_rewards_max            3168.871944738355
total_rewards_min            464.8870619882865
Number of train steps total  448000
Number of env steps total    562000
Number of rollouts total     0
Train Time (s)               130.1316909189336
(Previous) Eval Time (s)     24.22183559415862
Sample Time (s)              25.679103394504637
Epoch Time (s)               180.03262990759686
Total Train Time (s)         20007.43816184951
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:06:22.833322 UTC | [2020_01_11_13_32_55] Iteration #111 | Epoch Duration: 180.56716752052307
2020-01-11 19:06:22.833517 UTC | [2020_01_11_13_32_55] Iteration #111 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97232324
Z variance train             0.015546048
KL Divergence                22.28597
KL Loss                      2.2285972
QF Loss                      1107.4856
VF Loss                      424.97018
Policy Loss                  -996.259
Q Predictions Mean           989.85095
Q Predictions Std            365.46136
Q Predictions Max            1306.9072
Q Predictions Min            37.77914
V Predictions Mean           988.98193
V Predictions Std            363.18832
V Predictions Max            1307.5862
V Predictions Min            -6.082671
Log Pis Mean                 -0.49212754
Log Pis Std                  3.1764152
Log Pis Max                  12.119877
Log Pis Min                  -7.340779
Policy mu Mean               0.034241065
Policy mu Std                0.5982345
Policy mu Max                2.4481642
Policy mu Min                -2.5963442
Policy log std Mean          -0.91442657
Policy log std Std           0.31766376
Policy log std Max           0.059092283
Policy log std Min           -2.5296774
Z mean eval                  1.0357844
Z variance eval              0.011922773
total_rewards                [3082.17352868 2079.79351214 2243.4101277   158.89028176 3289.74375922
   28.31659023  533.06368319 2891.83976421 2248.65261368  598.30054336]
total_rewards_mean           1715.418440416866
total_rewards_std            1197.554910621039
total_rewards_max            3289.7437592175775
total_rewards_min            28.316590225163544
Number of train steps total  452000
Number of env steps total    567000
Number of rollouts total     0
Train Time (s)               130.6061944309622
(Previous) Eval Time (s)     24.756051897071302
Sample Time (s)              26.267679069191217
Epoch Time (s)               181.62992539722472
Total Train Time (s)         20195.123102408368
Epoch                        112
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:09:30.519909 UTC | [2020_01_11_13_32_55] Iteration #112 | Epoch Duration: 187.68626403808594
2020-01-11 19:09:30.520080 UTC | [2020_01_11_13_32_55] Iteration #112 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0350987
Z variance train             0.012025995
KL Divergence                22.148115
KL Loss                      2.2148116
QF Loss                      1175.4629
VF Loss                      170.57732
Policy Loss                  -1030.0554
Q Predictions Mean           1031.2097
Q Predictions Std            328.09613
Q Predictions Max            1312.4948
Q Predictions Min            130.66829
V Predictions Mean           1025.1111
V Predictions Std            324.72992
V Predictions Max            1300.581
V Predictions Min            133.72182
Log Pis Mean                 -0.22995955
Log Pis Std                  3.209237
Log Pis Max                  9.97415
Log Pis Min                  -7.553031
Policy mu Mean               -0.028733728
Policy mu Std                0.5915783
Policy mu Max                2.0125642
Policy mu Min                -2.6535444
Policy log std Mean          -0.985495
Policy log std Std           0.3359363
Policy log std Max           -0.16151577
Policy log std Min           -2.2039826
Z mean eval                  0.9833013
Z variance eval              0.013703252
total_rewards                [ -12.92128831  394.58548273  422.16761201 2818.64576394 3030.65838249
  589.51331783 3269.05320162 1014.36274947 1159.02300036 1355.86002093]
total_rewards_mean           1404.0948243069386
total_rewards_std            1139.902577377049
total_rewards_max            3269.0532016150664
total_rewards_min            -12.921288313340664
Number of train steps total  456000
Number of env steps total    572000
Number of rollouts total     0
Train Time (s)               129.0356445852667
(Previous) Eval Time (s)     30.812062861863524
Sample Time (s)              25.920206477399915
Epoch Time (s)               185.76791392453015
Total Train Time (s)         20370.931610383093
Epoch                        113
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:12:26.330464 UTC | [2020_01_11_13_32_55] Iteration #113 | Epoch Duration: 175.81025910377502
2020-01-11 19:12:26.330651 UTC | [2020_01_11_13_32_55] Iteration #113 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9839392
Z variance train             0.013690779
KL Divergence                21.034998
KL Loss                      2.1035
QF Loss                      2492.9556
VF Loss                      258.3417
Policy Loss                  -999.66943
Q Predictions Mean           994.90704
Q Predictions Std            350.4284
Q Predictions Max            1261.9026
Q Predictions Min            27.483643
V Predictions Mean           995.0626
V Predictions Std            345.45218
V Predictions Max            1257.0405
V Predictions Min            -18.407724
Log Pis Mean                 -0.12910436
Log Pis Std                  3.1943424
Log Pis Max                  14.873304
Log Pis Min                  -7.865416
Policy mu Mean               0.021826133
Policy mu Std                0.607316
Policy mu Max                1.9194924
Policy mu Min                -2.3437326
Policy log std Mean          -0.9592409
Policy log std Std           0.34570163
Policy log std Max           -0.09375489
Policy log std Min           -2.8531828
Z mean eval                  0.9848083
Z variance eval              0.016526941
total_rewards                [3491.7497537  3474.03175814 3227.82781685 3292.90426991  835.81366496
 3121.26136115 2180.40037293 3374.26087829 1497.31223848 3406.28688873]
total_rewards_mean           2790.184900314839
total_rewards_std            899.8533048039346
total_rewards_max            3491.749753696693
total_rewards_min            835.8136649612854
Number of train steps total  460000
Number of env steps total    577000
Number of rollouts total     0
Train Time (s)               132.2965660910122
(Previous) Eval Time (s)     20.85408684099093
Sample Time (s)              24.762939349748194
Epoch Time (s)               177.91359228175133
Total Train Time (s)         20560.477023832034
Epoch                        114
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:15:35.877913 UTC | [2020_01_11_13_32_55] Iteration #114 | Epoch Duration: 189.54712843894958
2020-01-11 19:15:35.878099 UTC | [2020_01_11_13_32_55] Iteration #114 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9844017
Z variance train             0.016463002
KL Divergence                21.410488
KL Loss                      2.141049
QF Loss                      723.7168
VF Loss                      267.66202
Policy Loss                  -1056.1488
Q Predictions Mean           1053.8479
Q Predictions Std            304.0828
Q Predictions Max            1300.035
Q Predictions Min            21.263083
V Predictions Mean           1049.1335
V Predictions Std            298.14047
V Predictions Max            1286.3691
V Predictions Min            -34.183754
Log Pis Mean                 -0.18960042
Log Pis Std                  3.3666205
Log Pis Max                  14.585301
Log Pis Min                  -8.4409895
Policy mu Mean               0.016423136
Policy mu Std                0.59587634
Policy mu Max                2.6677723
Policy mu Min                -3.0853992
Policy log std Mean          -1.0052788
Policy log std Std           0.3075453
Policy log std Max           0.033373594
Policy log std Min           -2.3557537
Z mean eval                  0.9765161
Z variance eval              0.027765099
total_rewards                [ 105.98244068  450.85052918  423.94982887  624.01850548  316.46898211
 3046.6821965   830.53422286 3423.08483625 1040.9896623   -13.67885498]
total_rewards_mean           1024.8882349246219
total_rewards_std            1146.8757819312582
total_rewards_max            3423.0848362532647
total_rewards_min            -13.678854978207038
Number of train steps total  464000
Number of env steps total    582000
Number of rollouts total     0
Train Time (s)               139.9836513963528
(Previous) Eval Time (s)     32.48728895699605
Sample Time (s)              26.13578762114048
Epoch Time (s)               198.60672797448933
Total Train Time (s)         20758.581996506546
Epoch                        115
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:18:53.984953 UTC | [2020_01_11_13_32_55] Iteration #115 | Epoch Duration: 198.10672545433044
2020-01-11 19:18:53.985143 UTC | [2020_01_11_13_32_55] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9754597
Z variance train             0.027672082
KL Divergence                20.688955
KL Loss                      2.0688956
QF Loss                      567.28064
VF Loss                      133.9811
Policy Loss                  -1043.1184
Q Predictions Mean           1042.3137
Q Predictions Std            323.93115
Q Predictions Max            1323.254
Q Predictions Min            8.645458
V Predictions Mean           1038.5016
V Predictions Std            319.59973
V Predictions Max            1312.5435
V Predictions Min            81.172195
Log Pis Mean                 0.19326967
Log Pis Std                  3.3187275
Log Pis Max                  15.179933
Log Pis Min                  -7.9394617
Policy mu Mean               0.051687248
Policy mu Std                0.5950338
Policy mu Max                4.3292484
Policy mu Min                -2.7008412
Policy log std Mean          -1.004674
Policy log std Std           0.32517347
Policy log std Max           -0.187141
Policy log std Min           -2.7120004
Z mean eval                  0.9846573
Z variance eval              0.031984143
total_rewards                [ 791.87526263 1232.98474419  -24.34628916  131.21197402  890.86001729
 3237.82556334 3548.02431126 2485.93702809 3467.72561892 3317.93322909]
total_rewards_mean           1908.0031459658853
total_rewards_std            1372.5769317400498
total_rewards_max            3548.024311256448
total_rewards_min            -24.3462891623419
Number of train steps total  468000
Number of env steps total    587000
Number of rollouts total     0
Train Time (s)               138.78308425610885
(Previous) Eval Time (s)     31.986820319201797
Sample Time (s)              26.449894330929965
Epoch Time (s)               197.2197989062406
Total Train Time (s)         20956.861955584493
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:22:12.268107 UTC | [2020_01_11_13_32_55] Iteration #116 | Epoch Duration: 198.28282690048218
2020-01-11 19:22:12.268349 UTC | [2020_01_11_13_32_55] Iteration #116 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9858109
Z variance train             0.03202913
KL Divergence                20.30197
KL Loss                      2.030197
QF Loss                      633.5841
VF Loss                      207.57678
Policy Loss                  -1027.2853
Q Predictions Mean           1029.6395
Q Predictions Std            331.1003
Q Predictions Max            1302.9077
Q Predictions Min            34.9493
V Predictions Mean           1027.8248
V Predictions Std            329.0571
V Predictions Max            1296.7328
V Predictions Min            0.8491563
Log Pis Mean                 -0.1709317
Log Pis Std                  3.2987237
Log Pis Max                  17.013649
Log Pis Min                  -8.35985
Policy mu Mean               0.026727542
Policy mu Std                0.6049982
Policy mu Max                2.4915385
Policy mu Min                -2.8789856
Policy log std Mean          -0.94634444
Policy log std Std           0.32392418
Policy log std Max           -0.12304646
Policy log std Min           -2.5431294
Z mean eval                  0.98931533
Z variance eval              0.028636748
total_rewards                [2851.34730529 2291.07673271  267.76566842 2404.35980243  325.45106009
  343.64203147  459.12076077  151.0624427  3216.84562085 2926.61753657]
total_rewards_mean           1523.7288961303407
total_rewards_std            1240.3695820555445
total_rewards_max            3216.845620849219
total_rewards_min            151.0624427029458
Number of train steps total  472000
Number of env steps total    592000
Number of rollouts total     0
Train Time (s)               139.6396733140573
(Previous) Eval Time (s)     33.04948938312009
Sample Time (s)              25.56861874088645
Epoch Time (s)               198.25778143806383
Total Train Time (s)         21148.73751938995
Epoch                        117
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:25:24.145132 UTC | [2020_01_11_13_32_55] Iteration #117 | Epoch Duration: 191.87664008140564
2020-01-11 19:25:24.145329 UTC | [2020_01_11_13_32_55] Iteration #117 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99192727
Z variance train             0.028749079
KL Divergence                19.279985
KL Loss                      1.9279985
QF Loss                      1007.3794
VF Loss                      442.3595
Policy Loss                  -1039.8344
Q Predictions Mean           1036.8973
Q Predictions Std            306.25314
Q Predictions Max            1297.4495
Q Predictions Min            102.010605
V Predictions Mean           1050.1373
V Predictions Std            302.55066
V Predictions Max            1315.3635
V Predictions Min            100.53046
Log Pis Mean                 0.37668014
Log Pis Std                  3.0489805
Log Pis Max                  9.35684
Log Pis Min                  -7.7166986
Policy mu Mean               0.022071976
Policy mu Std                0.6732826
Policy mu Max                2.1512015
Policy mu Min                -2.3691716
Policy log std Mean          -0.9720738
Policy log std Std           0.31311497
Policy log std Max           -0.11510986
Policy log std Min           -2.4531078
Z mean eval                  0.96374685
Z variance eval              0.019977683
total_rewards                [1571.67741248 1478.74337753 3381.97753262  367.88646746   84.56378685
 3096.59564849 3129.09980223 1148.18332516 1608.85502091 2586.49564813]
total_rewards_mean           1845.4078021862515
total_rewards_std            1102.664281037995
total_rewards_max            3381.977532624299
total_rewards_min            84.56378685498724
Number of train steps total  476000
Number of env steps total    597000
Number of rollouts total     0
Train Time (s)               138.07710139779374
(Previous) Eval Time (s)     26.6679803179577
Sample Time (s)              24.898224246688187
Epoch Time (s)               189.64330596243963
Total Train Time (s)         21339.3485800568
Epoch                        118
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:28:34.758870 UTC | [2020_01_11_13_32_55] Iteration #118 | Epoch Duration: 190.613383769989
2020-01-11 19:28:34.759131 UTC | [2020_01_11_13_32_55] Iteration #118 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96539134
Z variance train             0.020082472
KL Divergence                19.758308
KL Loss                      1.9758309
QF Loss                      1285.0631
VF Loss                      364.4157
Policy Loss                  -1017.80133
Q Predictions Mean           1019.6832
Q Predictions Std            374.35986
Q Predictions Max            1340.1273
Q Predictions Min            44.1841
V Predictions Mean           1026.9291
V Predictions Std            373.68176
V Predictions Max            1354.5686
V Predictions Min            33.641212
Log Pis Mean                 0.66801876
Log Pis Std                  3.7168515
Log Pis Max                  12.5293255
Log Pis Min                  -7.536403
Policy mu Mean               0.022914428
Policy mu Std                0.6411481
Policy mu Max                2.3250382
Policy mu Min                -2.4825644
Policy log std Mean          -1.013123
Policy log std Std           0.386485
Policy log std Max           -0.138273
Policy log std Min           -2.5826976
Z mean eval                  0.98095435
Z variance eval              0.022442695
total_rewards                [ -13.25576711 2743.13668439 1561.20483409 3534.26832421 1869.3465197
 3338.39018827 3193.88832003  890.07680238 1633.19155383 2222.46426766]
total_rewards_mean           2097.271172746221
total_rewards_std            1081.9912584285055
total_rewards_max            3534.26832420996
total_rewards_min            -13.255767109558036
Number of train steps total  480000
Number of env steps total    602000
Number of rollouts total     0
Train Time (s)               130.00373163307086
(Previous) Eval Time (s)     27.637683345004916
Sample Time (s)              24.492870569694787
Epoch Time (s)               182.13428554777056
Total Train Time (s)         21518.38564232085
Epoch                        119
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:31:33.796021 UTC | [2020_01_11_13_32_55] Iteration #119 | Epoch Duration: 179.03671312332153
2020-01-11 19:31:33.796138 UTC | [2020_01_11_13_32_55] Iteration #119 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98083085
Z variance train             0.022418167
KL Divergence                20.617918
KL Loss                      2.061792
QF Loss                      955.25934
VF Loss                      178.78516
Policy Loss                  -1043.1256
Q Predictions Mean           1037.844
Q Predictions Std            340.46548
Q Predictions Max            1304.212
Q Predictions Min            -237.18524
V Predictions Mean           1040.979
V Predictions Std            329.93887
V Predictions Max            1306.1604
V Predictions Min            -8.054148
Log Pis Mean                 0.32248154
Log Pis Std                  3.1604257
Log Pis Max                  12.306334
Log Pis Min                  -9.678636
Policy mu Mean               0.0043171938
Policy mu Std                0.62369
Policy mu Max                2.3497546
Policy mu Min                -2.663221
Policy log std Mean          -0.9825616
Policy log std Std           0.33383372
Policy log std Max           -0.17685896
Policy log std Min           -2.4830477
Z mean eval                  1.0274141
Z variance eval              0.020205533
total_rewards                [ -19.77900801 1074.29050526  136.93328692 3422.38536325  386.76171295
  218.82565836  340.47257435 1446.20811829 1497.27117333  486.29179132]
total_rewards_mean           898.9661176011402
total_rewards_std            984.264814570093
total_rewards_max            3422.385363252413
total_rewards_min            -19.77900801488363
Number of train steps total  484000
Number of env steps total    607000
Number of rollouts total     0
Train Time (s)               130.07797574810684
(Previous) Eval Time (s)     24.539839368779212
Sample Time (s)              24.08461975492537
Epoch Time (s)               178.70243487181142
Total Train Time (s)         21694.93121654028
Epoch                        120
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:34:30.344250 UTC | [2020_01_11_13_32_55] Iteration #120 | Epoch Duration: 176.54801750183105
2020-01-11 19:34:30.344414 UTC | [2020_01_11_13_32_55] Iteration #120 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0302445
Z variance train             0.020238401
KL Divergence                21.286942
KL Loss                      2.1286943
QF Loss                      976.41504
VF Loss                      359.35202
Policy Loss                  -1067.4794
Q Predictions Mean           1066.8364
Q Predictions Std            335.8732
Q Predictions Max            1338.4579
Q Predictions Min            -26.999569
V Predictions Mean           1063.8359
V Predictions Std            328.48538
V Predictions Max            1318.526
V Predictions Min            80.91988
Log Pis Mean                 0.114966646
Log Pis Std                  3.0432072
Log Pis Max                  14.996973
Log Pis Min                  -8.660323
Policy mu Mean               0.023893502
Policy mu Std                0.6210433
Policy mu Max                2.2060025
Policy mu Min                -2.672372
Policy log std Mean          -0.9746858
Policy log std Std           0.3286502
Policy log std Max           -0.0955528
Policy log std Min           -2.8529851
Z mean eval                  0.9944817
Z variance eval              0.015058776
total_rewards                [3213.44008003 3103.54900293 3277.08260195  -42.56120352 3264.19738442
 3244.62048294  526.54453755 3272.16937028 2280.0229537    31.07458354]
total_rewards_mean           2217.0139793825974
total_rewards_std            1375.2870256618999
total_rewards_max            3277.082601949235
total_rewards_min            -42.56120351671461
Number of train steps total  488000
Number of env steps total    612000
Number of rollouts total     0
Train Time (s)               130.04064080724493
(Previous) Eval Time (s)     22.385110882110894
Sample Time (s)              25.2711815899238
Epoch Time (s)               177.69693327927962
Total Train Time (s)         21884.43107520556
Epoch                        121
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:37:39.846142 UTC | [2020_01_11_13_32_55] Iteration #121 | Epoch Duration: 189.50160455703735
2020-01-11 19:37:39.846315 UTC | [2020_01_11_13_32_55] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99286544
Z variance train             0.015093865
KL Divergence                22.350977
KL Loss                      2.2350976
QF Loss                      942.02356
VF Loss                      100.03904
Policy Loss                  -1037.4884
Q Predictions Mean           1036.2241
Q Predictions Std            364.394
Q Predictions Max            1330.292
Q Predictions Min            45.04521
V Predictions Mean           1032.6722
V Predictions Std            361.6497
V Predictions Max            1324.9303
V Predictions Min            85.13931
Log Pis Mean                 -0.21536694
Log Pis Std                  3.1082292
Log Pis Max                  11.259902
Log Pis Min                  -8.250549
Policy mu Mean               0.032982178
Policy mu Std                0.5831212
Policy mu Max                2.22011
Policy mu Min                -2.2792392
Policy log std Mean          -0.9554491
Policy log std Std           0.33284155
Policy log std Max           -0.17814815
Policy log std Min           -2.3343692
Z mean eval                  0.9887649
Z variance eval              0.0097531425
total_rewards                [ 335.16897485  281.79236023 2385.16099159 2565.8303892  3107.12001547
 3312.71311276  534.11217327 1780.3958134  3419.4403477   903.28996137]
total_rewards_mean           1862.5024139843208
total_rewards_std            1198.6210563275338
total_rewards_max            3419.440347702069
total_rewards_min            281.7923602349663
Number of train steps total  492000
Number of env steps total    617000
Number of rollouts total     0
Train Time (s)               129.42007500724867
(Previous) Eval Time (s)     34.189442825037986
Sample Time (s)              24.97416061675176
Epoch Time (s)               188.58367844903842
Total Train Time (s)         22066.87586650485
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:40:42.293342 UTC | [2020_01_11_13_32_55] Iteration #122 | Epoch Duration: 182.44689846038818
2020-01-11 19:40:42.293526 UTC | [2020_01_11_13_32_55] Iteration #122 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9887396
Z variance train             0.0097686285
KL Divergence                22.236568
KL Loss                      2.223657
QF Loss                      829.0939
VF Loss                      179.513
Policy Loss                  -1057.9856
Q Predictions Mean           1057.5669
Q Predictions Std            333.79187
Q Predictions Max            1349.6409
Q Predictions Min            105.949356
V Predictions Mean           1064.412
V Predictions Std            336.11447
V Predictions Max            1350.8439
V Predictions Min            108.85047
Log Pis Mean                 -0.26907748
Log Pis Std                  2.9426744
Log Pis Max                  10.485552
Log Pis Min                  -10.642763
Policy mu Mean               -0.02184942
Policy mu Std                0.59594214
Policy mu Max                2.4750652
Policy mu Min                -2.675193
Policy log std Mean          -0.97712374
Policy log std Std           0.3165343
Policy log std Max           -0.11258656
Policy log std Min           -2.596435
Z mean eval                  0.99308664
Z variance eval              0.0047120126
total_rewards                [ 791.19321766 3223.57369686 3168.64279096 3164.66173085  808.71661211
   76.45521694 2674.6617163   632.32002923 3095.57347453 3471.73503029]
total_rewards_mean           2110.7533515730383
total_rewards_std            1279.4150661170183
total_rewards_max            3471.7350302943532
total_rewards_min            76.45521693781443
Number of train steps total  496000
Number of env steps total    622000
Number of rollouts total     0
Train Time (s)               129.71003039414063
(Previous) Eval Time (s)     28.052302272059023
Sample Time (s)              25.0517626167275
Epoch Time (s)               182.81409528292716
Total Train Time (s)         22244.22872794047
Epoch                        123
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:43:39.654742 UTC | [2020_01_11_13_32_55] Iteration #123 | Epoch Duration: 177.36108350753784
2020-01-11 19:43:39.654936 UTC | [2020_01_11_13_32_55] Iteration #123 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9925003
Z variance train             0.004703562
KL Divergence                22.934004
KL Loss                      2.2934005
QF Loss                      1035.606
VF Loss                      345.094
Policy Loss                  -1017.02734
Q Predictions Mean           1019.32733
Q Predictions Std            372.22263
Q Predictions Max            1320.9707
Q Predictions Min            -28.263237
V Predictions Mean           1016.0907
V Predictions Std            368.66174
V Predictions Max            1308.0946
V Predictions Min            -18.05732
Log Pis Mean                 -0.31853154
Log Pis Std                  3.354303
Log Pis Max                  13.389202
Log Pis Min                  -9.222841
Policy mu Mean               0.019980634
Policy mu Std                0.59588027
Policy mu Max                3.3128235
Policy mu Min                -2.0552192
Policy log std Mean          -0.93627125
Policy log std Std           0.32968453
Policy log std Max           -0.1115312
Policy log std Min           -2.5242212
Z mean eval                  0.99980307
Z variance eval              0.020094173
total_rewards                [2796.7061883   195.16947367  468.78651734 3339.30668453  506.72928799
  927.01372597 3281.71360814 1273.63574859 3387.75389071 3201.88494266]
total_rewards_mean           1937.8700067913294
total_rewards_std            1300.5325748542339
total_rewards_max            3387.753890707844
total_rewards_min            195.16947367073504
Number of train steps total  500000
Number of env steps total    627000
Number of rollouts total     0
Train Time (s)               130.44507026765496
(Previous) Eval Time (s)     22.59894774109125
Sample Time (s)              24.933562570717186
Epoch Time (s)               177.9775805794634
Total Train Time (s)         22427.50655503152
Epoch                        124
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:46:42.928169 UTC | [2020_01_11_13_32_55] Iteration #124 | Epoch Duration: 183.27310490608215
2020-01-11 19:46:42.928356 UTC | [2020_01_11_13_32_55] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99926025
Z variance train             0.020144375
KL Divergence                20.34285
KL Loss                      2.034285
QF Loss                      537.8968
VF Loss                      111.809586
Policy Loss                  -1075.2205
Q Predictions Mean           1075.6309
Q Predictions Std            327.19827
Q Predictions Max            1337.9409
Q Predictions Min            26.567226
V Predictions Mean           1072.3555
V Predictions Std            327.2748
V Predictions Max            1331.0798
V Predictions Min            10.6498785
Log Pis Mean                 -0.09082684
Log Pis Std                  2.9337428
Log Pis Max                  10.549009
Log Pis Min                  -11.3897
Policy mu Mean               -0.030766543
Policy mu Std                0.6041772
Policy mu Max                2.4556959
Policy mu Min                -2.4267516
Policy log std Mean          -0.9762385
Policy log std Std           0.322782
Policy log std Max           -0.12966174
Policy log std Min           -2.8965979
Z mean eval                  1.040472
Z variance eval              0.022871373
total_rewards                [2457.59931072 2188.38933671   17.75885645 2299.25334754 1905.88825994
  690.06640039 3324.25960615 3166.67927322  253.92243596 1312.23637992]
total_rewards_mean           1761.605320701201
total_rewards_std            1098.034275429142
total_rewards_max            3324.259606153614
total_rewards_min            17.758856451479943
Number of train steps total  504000
Number of env steps total    632000
Number of rollouts total     0
Train Time (s)               130.5391263179481
(Previous) Eval Time (s)     27.89416185906157
Sample Time (s)              26.16158091649413
Epoch Time (s)               184.5948690935038
Total Train Time (s)         22605.02086478658
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:49:40.444415 UTC | [2020_01_11_13_32_55] Iteration #125 | Epoch Duration: 177.51592111587524
2020-01-11 19:49:40.444579 UTC | [2020_01_11_13_32_55] Iteration #125 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0398486
Z variance train             0.022878071
KL Divergence                20.155619
KL Loss                      2.0155618
QF Loss                      611.8108
VF Loss                      210.52477
Policy Loss                  -1058.8289
Q Predictions Mean           1060.8972
Q Predictions Std            333.73618
Q Predictions Max            1343.0634
Q Predictions Min            19.295845
V Predictions Mean           1064.3489
V Predictions Std            334.7775
V Predictions Max            1335.0151
V Predictions Min            7.628341
Log Pis Mean                 0.23668838
Log Pis Std                  3.1980135
Log Pis Max                  15.505271
Log Pis Min                  -8.200588
Policy mu Mean               0.050767843
Policy mu Std                0.63227123
Policy mu Max                3.1285775
Policy mu Min                -1.9450809
Policy log std Mean          -0.96917605
Policy log std Std           0.33565238
Policy log std Max           0.038574815
Policy log std Min           -2.5726743
Z mean eval                  0.9953909
Z variance eval              0.016240496
total_rewards                [1590.71626384 1181.66654777 1268.65571742  961.67457965   94.77998207
 2405.72583135 1793.57646993 2577.71391578 3611.66024648 3634.65706871]
total_rewards_mean           1912.0826623009925
total_rewards_std            1086.8884792307033
total_rewards_max            3634.6570687141398
total_rewards_min            94.7799820679312
Number of train steps total  508000
Number of env steps total    637000
Number of rollouts total     0
Train Time (s)               130.1460701120086
(Previous) Eval Time (s)     20.81487748073414
Sample Time (s)              25.685684086289257
Epoch Time (s)               176.646631679032
Total Train Time (s)         22779.93832093198
Epoch                        126
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:52:35.364430 UTC | [2020_01_11_13_32_55] Iteration #126 | Epoch Duration: 174.9197313785553
2020-01-11 19:52:35.364646 UTC | [2020_01_11_13_32_55] Iteration #126 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99530935
Z variance train             0.01626754
KL Divergence                20.931103
KL Loss                      2.0931103
QF Loss                      502.25388
VF Loss                      114.384575
Policy Loss                  -1091.9585
Q Predictions Mean           1084.8215
Q Predictions Std            308.73483
Q Predictions Max            1333.7008
Q Predictions Min            -41.72052
V Predictions Mean           1091.8943
V Predictions Std            301.1652
V Predictions Max            1327.8793
V Predictions Min            65.32785
Log Pis Mean                 0.21855387
Log Pis Std                  3.2161248
Log Pis Max                  18.978668
Log Pis Min                  -6.869161
Policy mu Mean               0.00039524643
Policy mu Std                0.61772037
Policy mu Max                2.07385
Policy mu Min                -2.2383254
Policy log std Mean          -0.99889255
Policy log std Std           0.31906533
Policy log std Max           -0.18184167
Policy log std Min           -2.8923807
Z mean eval                  1.0031192
Z variance eval              0.0156743
total_rewards                [2161.88562882 2692.32955378 3628.1188317  3377.24740086  719.38711912
 3382.02274252 2744.9033134  3282.12465926   34.93713147 2087.83556575]
total_rewards_mean           2411.079194667271
total_rewards_std            1139.346980592934
total_rewards_max            3628.118831701742
total_rewards_min            34.9371314723678
Number of train steps total  512000
Number of env steps total    642000
Number of rollouts total     0
Train Time (s)               130.0607363563031
(Previous) Eval Time (s)     19.087645478080958
Sample Time (s)              25.90107250539586
Epoch Time (s)               175.0494543397799
Total Train Time (s)         22960.960334484465
Epoch                        127
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:55:36.388045 UTC | [2020_01_11_13_32_55] Iteration #127 | Epoch Duration: 181.02319025993347
2020-01-11 19:55:36.388478 UTC | [2020_01_11_13_32_55] Iteration #127 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0017711
Z variance train             0.015689023
KL Divergence                21.815727
KL Loss                      2.1815727
QF Loss                      546.10376
VF Loss                      148.91489
Policy Loss                  -1079.7649
Q Predictions Mean           1076.082
Q Predictions Std            323.82742
Q Predictions Max            1360.3662
Q Predictions Min            54.59344
V Predictions Mean           1083.3479
V Predictions Std            324.31494
V Predictions Max            1372.217
V Predictions Min            44.14088
Log Pis Mean                 0.26771754
Log Pis Std                  2.918547
Log Pis Max                  9.512672
Log Pis Min                  -7.70531
Policy mu Mean               0.018487316
Policy mu Std                0.6148502
Policy mu Max                2.5108495
Policy mu Min                -2.032289
Policy log std Mean          -0.99837834
Policy log std Std           0.30526435
Policy log std Max           -0.24765813
Policy log std Min           -2.261712
Z mean eval                  0.99910086
Z variance eval              0.016944602
total_rewards                [ 478.63964966 2583.11579438 3384.34602858 2075.60601494 3520.63251038
 3230.29334421 1624.48488045  695.86395823  366.95377789 1052.03747783]
total_rewards_mean           1901.197343654713
total_rewards_std            1170.9941146069802
total_rewards_max            3520.632510376754
total_rewards_min            366.9537778899639
Number of train steps total  516000
Number of env steps total    647000
Number of rollouts total     0
Train Time (s)               129.82894091075286
(Previous) Eval Time (s)     25.061009929981083
Sample Time (s)              24.54870826518163
Epoch Time (s)               179.43865910591558
Total Train Time (s)         23138.36365920771
Epoch                        128
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:58:33.793539 UTC | [2020_01_11_13_32_55] Iteration #128 | Epoch Duration: 177.40479016304016
2020-01-11 19:58:33.793711 UTC | [2020_01_11_13_32_55] Iteration #128 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.000848
Z variance train             0.016921727
KL Divergence                21.11562
KL Loss                      2.111562
QF Loss                      628.1548
VF Loss                      185.4445
Policy Loss                  -1042.4562
Q Predictions Mean           1040.6722
Q Predictions Std            368.4679
Q Predictions Max            1324.402
Q Predictions Min            7.834277
V Predictions Mean           1043.5369
V Predictions Std            364.05814
V Predictions Max            1316.6329
V Predictions Min            -0.67177653
Log Pis Mean                 -0.18272698
Log Pis Std                  3.2595072
Log Pis Max                  12.454149
Log Pis Min                  -7.8389654
Policy mu Mean               0.019177534
Policy mu Std                0.6219036
Policy mu Max                2.861611
Policy mu Min                -2.4009714
Policy log std Mean          -0.94954526
Policy log std Std           0.3328084
Policy log std Max           0.22973156
Policy log std Min           -2.7050822
Z mean eval                  1.0127685
Z variance eval              0.010071824
total_rewards                [1621.4372712  2395.2341136   212.55405437 1182.12408805 2828.35263322
  302.91448871  465.49435166 2765.7884912  2118.87284053 3370.94336608]
total_rewards_mean           1726.3715698619956
total_rewards_std            1087.0005502826511
total_rewards_max            3370.9433660784016
total_rewards_min            212.55405437144822
Number of train steps total  520000
Number of env steps total    652000
Number of rollouts total     0
Train Time (s)               130.94387248437852
(Previous) Eval Time (s)     23.02679738495499
Sample Time (s)              25.334569925442338
Epoch Time (s)               179.30523979477584
Total Train Time (s)         23320.341580971144
Epoch                        129
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:01:35.774144 UTC | [2020_01_11_13_32_55] Iteration #129 | Epoch Duration: 181.9802987575531
2020-01-11 20:01:35.774400 UTC | [2020_01_11_13_32_55] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0143683
Z variance train             0.010036921
KL Divergence                22.048409
KL Loss                      2.204841
QF Loss                      547.1825
VF Loss                      173.20724
Policy Loss                  -1054.2052
Q Predictions Mean           1053.2668
Q Predictions Std            369.35754
Q Predictions Max            1370.5621
Q Predictions Min            3.4271293
V Predictions Mean           1052.5435
V Predictions Std            367.19855
V Predictions Max            1379.3958
V Predictions Min            11.281111
Log Pis Mean                 -0.17160808
Log Pis Std                  3.1738873
Log Pis Max                  13.61767
Log Pis Min                  -7.471353
Policy mu Mean               0.025554799
Policy mu Std                0.60518664
Policy mu Max                3.6492612
Policy mu Min                -3.460446
Policy log std Mean          -0.9528388
Policy log std Std           0.3339931
Policy log std Max           0.82651806
Policy log std Min           -2.206059
Z mean eval                  1.006421
Z variance eval              0.014854866
total_rewards                [ 618.49982563 3269.22278429  282.2568081   488.33041426 2551.86491179
 3386.2904885  3068.93281368 3717.4573901  3571.10794106 2910.71360959]
total_rewards_mean           2386.4676986997606
total_rewards_std            1299.15726083536
total_rewards_max            3717.4573901005874
total_rewards_min            282.2568080982613
Number of train steps total  524000
Number of env steps total    657000
Number of rollouts total     0
Train Time (s)               130.6861273511313
(Previous) Eval Time (s)     25.701537569984794
Sample Time (s)              23.421728091314435
Epoch Time (s)               179.80939301243052
Total Train Time (s)         23498.97373078391
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:04:34.409236 UTC | [2020_01_11_13_32_55] Iteration #130 | Epoch Duration: 178.6346333026886
2020-01-11 20:04:34.409427 UTC | [2020_01_11_13_32_55] Iteration #130 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0089988
Z variance train             0.014886697
KL Divergence                20.932938
KL Loss                      2.093294
QF Loss                      1164.8214
VF Loss                      219.96756
Policy Loss                  -1076.1011
Q Predictions Mean           1075.0483
Q Predictions Std            338.324
Q Predictions Max            1340.51
Q Predictions Min            16.13365
V Predictions Mean           1069.2092
V Predictions Std            335.76053
V Predictions Max            1335.6877
V Predictions Min            4.7968206
Log Pis Mean                 -0.009023601
Log Pis Std                  2.9548037
Log Pis Max                  8.526506
Log Pis Min                  -7.5082517
Policy mu Mean               -8.925353e-05
Policy mu Std                0.61042064
Policy mu Max                2.542583
Policy mu Min                -2.4915981
Policy log std Mean          -0.97756016
Policy log std Std           0.32782346
Policy log std Max           0.32501304
Policy log std Min           -2.267582
Z mean eval                  1.0295182
Z variance eval              0.01557384
total_rewards                [ 853.38751792 2689.42698741 2192.21138028  146.11157089  853.00600106
 3269.70522242 3361.08002292 3309.4158352   390.71068329  768.28374012]
total_rewards_mean           1783.3338961502145
total_rewards_std            1240.8153595587842
total_rewards_max            3361.0800229155475
total_rewards_min            146.11157089127894
Number of train steps total  528000
Number of env steps total    662000
Number of rollouts total     0
Train Time (s)               130.80842259479687
(Previous) Eval Time (s)     24.52644272428006
Sample Time (s)              25.37015211675316
Epoch Time (s)               180.7050174358301
Total Train Time (s)         23684.154803329147
Epoch                        131
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:07:39.591042 UTC | [2020_01_11_13_32_55] Iteration #131 | Epoch Duration: 185.1814832687378
2020-01-11 20:07:39.591236 UTC | [2020_01_11_13_32_55] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0276135
Z variance train             0.015572779
KL Divergence                20.583187
KL Loss                      2.0583189
QF Loss                      2229.6357
VF Loss                      240.33022
Policy Loss                  -1034.0701
Q Predictions Mean           1033.2565
Q Predictions Std            377.7665
Q Predictions Max            1357.5897
Q Predictions Min            20.069025
V Predictions Mean           1039.4658
V Predictions Std            377.88504
V Predictions Max            1358.1333
V Predictions Min            57.09454
Log Pis Mean                 0.34668896
Log Pis Std                  3.3069255
Log Pis Max                  12.483818
Log Pis Min                  -5.9695234
Policy mu Mean               0.036760204
Policy mu Std                0.62495285
Policy mu Max                2.0925534
Policy mu Min                -2.4826248
Policy log std Mean          -0.95739496
Policy log std Std           0.34959227
Policy log std Max           -0.18570697
Policy log std Min           -2.422708
Z mean eval                  1.0395014
Z variance eval              0.013098407
total_rewards                [3241.47625987 2897.92153518  939.71710885 1693.88751019 2078.24842783
 3388.60959415  237.14063635 3579.01974598 3306.09557861 3231.97071493]
total_rewards_mean           2459.408711193544
total_rewards_std            1105.1624691498093
total_rewards_max            3579.019745983332
total_rewards_min            237.14063635326545
Number of train steps total  532000
Number of env steps total    667000
Number of rollouts total     0
Train Time (s)               132.9004169558175
(Previous) Eval Time (s)     29.00259160064161
Sample Time (s)              25.470248461235315
Epoch Time (s)               187.3732570176944
Total Train Time (s)         23875.443651252426
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:10:50.882659 UTC | [2020_01_11_13_32_55] Iteration #132 | Epoch Duration: 191.29128098487854
2020-01-11 20:10:50.882899 UTC | [2020_01_11_13_32_55] Iteration #132 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.036227
Z variance train             0.013085561
KL Divergence                21.813786
KL Loss                      2.1813786
QF Loss                      851.9043
VF Loss                      245.70943
Policy Loss                  -1066.9355
Q Predictions Mean           1065.2522
Q Predictions Std            360.1987
Q Predictions Max            1360.7734
Q Predictions Min            -36.78573
V Predictions Mean           1071.2792
V Predictions Std            357.17877
V Predictions Max            1356.6508
V Predictions Min            56.643158
Log Pis Mean                 0.39480442
Log Pis Std                  3.472446
Log Pis Max                  16.253029
Log Pis Min                  -6.7940054
Policy mu Mean               0.0146674765
Policy mu Std                0.6118634
Policy mu Max                2.2455294
Policy mu Min                -2.2758658
Policy log std Mean          -1.0263946
Policy log std Std           0.36502144
Policy log std Max           -0.16834128
Policy log std Min           -2.649237
Z mean eval                  1.014077
Z variance eval              0.010042851
total_rewards                [1736.76415975 3308.54215569  576.8900238   312.81802495  449.17964624
  967.31331362 1940.08528275 3332.88258732 1072.86448828 3547.63741734]
total_rewards_mean           1724.4977099741632
total_rewards_std            1200.0332805135624
total_rewards_max            3547.637417336768
total_rewards_min            312.8180249490474
Number of train steps total  536000
Number of env steps total    672000
Number of rollouts total     0
Train Time (s)               141.01602818910033
(Previous) Eval Time (s)     32.92024666303769
Sample Time (s)              26.919421781320125
Epoch Time (s)               200.85569663345814
Total Train Time (s)         24066.000717787072
Epoch                        133
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:14:01.442192 UTC | [2020_01_11_13_32_55] Iteration #133 | Epoch Duration: 190.55914306640625
2020-01-11 20:14:01.442392 UTC | [2020_01_11_13_32_55] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0143509
Z variance train             0.010044267
KL Divergence                23.033096
KL Loss                      2.3033097
QF Loss                      1466.6958
VF Loss                      740.4475
Policy Loss                  -1058.9265
Q Predictions Mean           1060.9348
Q Predictions Std            361.34225
Q Predictions Max            1355.8905
Q Predictions Min            86.435616
V Predictions Mean           1064.0754
V Predictions Std            358.05838
V Predictions Max            1356.662
V Predictions Min            83.75863
Log Pis Mean                 -0.08233443
Log Pis Std                  3.3524954
Log Pis Max                  16.832855
Log Pis Min                  -8.3637085
Policy mu Mean               -0.0035098423
Policy mu Std                0.60888684
Policy mu Max                2.5208726
Policy mu Min                -2.5009818
Policy log std Mean          -0.98220384
Policy log std Std           0.36364272
Policy log std Max           -0.22716963
Policy log std Min           -3.275931
Z mean eval                  1.0674701
Z variance eval              0.007095673
total_rewards                [  87.7709001  1925.99907286 1129.92087822   11.55566696 3484.70536108
 3357.00610382  612.42863623 3404.5362927  2348.42981124 1027.07611345]
total_rewards_mean           1738.9428836663556
total_rewards_std            1292.4168412724348
total_rewards_max            3484.7053610755474
total_rewards_min            11.555666960911283
Number of train steps total  540000
Number of env steps total    677000
Number of rollouts total     0
Train Time (s)               139.6677634571679
(Previous) Eval Time (s)     22.62330953683704
Sample Time (s)              25.438556446228176
Epoch Time (s)               187.7296294402331
Total Train Time (s)         24255.526654363144
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:17:10.970689 UTC | [2020_01_11_13_32_55] Iteration #134 | Epoch Duration: 189.5281584262848
2020-01-11 20:17:10.970893 UTC | [2020_01_11_13_32_55] Iteration #134 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0686537
Z variance train             0.0070906365
KL Divergence                23.558498
KL Loss                      2.35585
QF Loss                      1475.8638
VF Loss                      192.36493
Policy Loss                  -1023.8532
Q Predictions Mean           1025.9802
Q Predictions Std            389.59326
Q Predictions Max            1380.4833
Q Predictions Min            -10.739005
V Predictions Mean           1030.1627
V Predictions Std            388.20236
V Predictions Max            1352.4952
V Predictions Min            -9.619183
Log Pis Mean                 0.027300857
Log Pis Std                  3.2260003
Log Pis Max                  13.097272
Log Pis Min                  -7.6366324
Policy mu Mean               0.044735402
Policy mu Std                0.60060334
Policy mu Max                2.368491
Policy mu Min                -2.258241
Policy log std Mean          -0.9794018
Policy log std Std           0.33687234
Policy log std Max           0.34837347
Policy log std Min           -2.866365
Z mean eval                  1.0068241
Z variance eval              0.0059475545
total_rewards                [-201.05191917 3497.6691791  3641.69789184  543.37313427 2780.26774018
 2570.64283605 1640.50754392  990.88677031  727.77204679  110.88879769]
total_rewards_mean           1630.265402098362
total_rewards_std            1334.4227221805977
total_rewards_max            3641.697891844214
total_rewards_min            -201.05191916539906
Number of train steps total  544000
Number of env steps total    682000
Number of rollouts total     0
Train Time (s)               139.82003629673272
(Previous) Eval Time (s)     24.42137712566182
Sample Time (s)              26.382403023075312
Epoch Time (s)               190.62381644546986
Total Train Time (s)         24448.578157423995
Epoch                        135
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:20:24.024354 UTC | [2020_01_11_13_32_55] Iteration #135 | Epoch Duration: 193.05332350730896
2020-01-11 20:20:24.024538 UTC | [2020_01_11_13_32_55] Iteration #135 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0069487
Z variance train             0.005945692
KL Divergence                23.102673
KL Loss                      2.3102672
QF Loss                      529.1835
VF Loss                      205.17427
Policy Loss                  -1059.554
Q Predictions Mean           1057.275
Q Predictions Std            368.03964
Q Predictions Max            1374.4717
Q Predictions Min            91.309525
V Predictions Mean           1061.7247
V Predictions Std            365.72278
V Predictions Max            1385.1107
V Predictions Min            84.75272
Log Pis Mean                 -0.03832136
Log Pis Std                  2.9997022
Log Pis Max                  11.45864
Log Pis Min                  -7.246533
Policy mu Mean               0.033193357
Policy mu Std                0.61617386
Policy mu Max                2.577031
Policy mu Min                -2.5477724
Policy log std Mean          -0.96042407
Policy log std Std           0.35770682
Policy log std Max           -0.043434978
Policy log std Min           -2.6415455
Z mean eval                  1.0104046
Z variance eval              0.0064931912
total_rewards                [3281.49042915 1428.4751396   762.73605676  687.59913476 1529.21228604
 1979.80068354 2713.27447057 1269.85764331 -129.52706543 3120.16374965]
total_rewards_mean           1664.3082527960582
total_rewards_std            1055.8767330914775
total_rewards_max            3281.4904291546536
total_rewards_min            -129.52706543454428
Number of train steps total  548000
Number of env steps total    687000
Number of rollouts total     0
Train Time (s)               138.23283205972984
(Previous) Eval Time (s)     26.850471761077642
Sample Time (s)              26.32934773294255
Epoch Time (s)               191.41265155375004
Total Train Time (s)         24645.60991241224
Epoch                        136
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:23:41.058391 UTC | [2020_01_11_13_32_55] Iteration #136 | Epoch Duration: 197.0337109565735
2020-01-11 20:23:41.058605 UTC | [2020_01_11_13_32_55] Iteration #136 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0063704
Z variance train             0.006481084
KL Divergence                24.05093
KL Loss                      2.405093
QF Loss                      1668.5542
VF Loss                      510.1724
Policy Loss                  -1096.8596
Q Predictions Mean           1096.5306
Q Predictions Std            328.8213
Q Predictions Max            1373.4773
Q Predictions Min            -33.057934
V Predictions Mean           1102.4254
V Predictions Std            326.70526
V Predictions Max            1380.7128
V Predictions Min            -23.22089
Log Pis Mean                 0.41449332
Log Pis Std                  2.994057
Log Pis Max                  10.724728
Log Pis Min                  -6.2752533
Policy mu Mean               0.023317581
Policy mu Std                0.6090332
Policy mu Max                2.5996783
Policy mu Min                -2.6121178
Policy log std Mean          -1.0413866
Policy log std Std           0.33413285
Policy log std Max           -0.1824798
Policy log std Min           -2.671485
Z mean eval                  1.049085
Z variance eval              0.0045618326
total_rewards                [3177.88971948 3409.60256065 2140.27899381   98.8526191  3349.97106377
 2942.76322098 1491.82458589 1452.81579024 3258.99179195  -35.26661641]
total_rewards_mean           2128.7723729459185
total_rewards_std            1258.525629327693
total_rewards_max            3409.60256064584
total_rewards_min            -35.26661640872699
Number of train steps total  552000
Number of env steps total    692000
Number of rollouts total     0
Train Time (s)               130.41252245986834
(Previous) Eval Time (s)     32.471177268307656
Sample Time (s)              24.165427522268146
Epoch Time (s)               187.04912725044414
Total Train Time (s)         24830.775256389752
Epoch                        137
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:26:46.224842 UTC | [2020_01_11_13_32_55] Iteration #137 | Epoch Duration: 185.16612005233765
2020-01-11 20:26:46.224962 UTC | [2020_01_11_13_32_55] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0502591
Z variance train             0.0045785406
KL Divergence                24.692041
KL Loss                      2.4692042
QF Loss                      1252.4209
VF Loss                      258.4178
Policy Loss                  -1095.4724
Q Predictions Mean           1091.7319
Q Predictions Std            324.19125
Q Predictions Max            1342.6775
Q Predictions Min            47.5755
V Predictions Mean           1092.9557
V Predictions Std            322.9425
V Predictions Max            1340.3027
V Predictions Min            1.8909502
Log Pis Mean                 0.21660227
Log Pis Std                  3.2122774
Log Pis Max                  12.770905
Log Pis Min                  -9.081355
Policy mu Mean               0.024870113
Policy mu Std                0.6136372
Policy mu Max                2.347893
Policy mu Min                -2.9497166
Policy log std Mean          -1.0037506
Policy log std Std           0.32831684
Policy log std Max           -0.08999264
Policy log std Min           -2.565606
Z mean eval                  1.0280886
Z variance eval              0.018147716
total_rewards                [ 227.14998084   62.40149286  -11.89786006 1648.77090034   11.71588757
 3167.23813724  654.31159556   78.30775935  928.43936868  373.67909205]
total_rewards_mean           714.0116354448929
total_rewards_std            956.2101296228182
total_rewards_max            3167.238137243064
total_rewards_min            -11.897860056761278
Number of train steps total  556000
Number of env steps total    697000
Number of rollouts total     0
Train Time (s)               130.33081654226407
(Previous) Eval Time (s)     30.587892359122634
Sample Time (s)              24.182437804993242
Epoch Time (s)               185.10114670637995
Total Train Time (s)         25005.57287764363
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:29:41.026039 UTC | [2020_01_11_13_32_55] Iteration #138 | Epoch Duration: 174.8009488582611
2020-01-11 20:29:41.026301 UTC | [2020_01_11_13_32_55] Iteration #138 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0273516
Z variance train             0.018082282
KL Divergence                22.980764
KL Loss                      2.2980764
QF Loss                      997.7579
VF Loss                      1588.1459
Policy Loss                  -1050.136
Q Predictions Mean           1047.5392
Q Predictions Std            391.3674
Q Predictions Max            1359.3098
Q Predictions Min            -144.20328
V Predictions Mean           1047.7559
V Predictions Std            378.09305
V Predictions Max            1335.8693
V Predictions Min            -19.28271
Log Pis Mean                 0.33036646
Log Pis Std                  3.433485
Log Pis Max                  19.426598
Log Pis Min                  -6.834855
Policy mu Mean               -0.062877685
Policy mu Std                0.6276487
Policy mu Max                2.1416466
Policy mu Min                -3.7423737
Policy log std Mean          -0.9792656
Policy log std Std           0.37200192
Policy log std Max           -0.18470943
Policy log std Min           -2.9966931
Z mean eval                  1.0349243
Z variance eval              0.013153876
total_rewards                [-100.18477961  414.56579236  427.90420414 3243.58060173 3317.41494265
  347.51989198   75.12664701 2301.07577567 3330.81917803  951.92050115]
total_rewards_mean           1430.97427551177
total_rewards_std            1372.4452592052382
total_rewards_max            3330.81917803313
total_rewards_min            -100.18477960851625
Number of train steps total  560000
Number of env steps total    702000
Number of rollouts total     0
Train Time (s)               131.03475522296503
(Previous) Eval Time (s)     20.28738002013415
Sample Time (s)              24.230842096265405
Epoch Time (s)               175.5529773393646
Total Train Time (s)         25184.672249447554
Epoch                        139
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:32:40.126938 UTC | [2020_01_11_13_32_55] Iteration #139 | Epoch Duration: 179.10043621063232
2020-01-11 20:32:40.127114 UTC | [2020_01_11_13_32_55] Iteration #139 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0342821
Z variance train             0.013131656
KL Divergence                23.294697
KL Loss                      2.3294697
QF Loss                      717.35974
VF Loss                      226.68654
Policy Loss                  -1065.8696
Q Predictions Mean           1067.4221
Q Predictions Std            378.1511
Q Predictions Max            1368.6051
Q Predictions Min            86.49444
V Predictions Mean           1062.1924
V Predictions Std            378.13928
V Predictions Max            1350.0131
V Predictions Min            82.406296
Log Pis Mean                 0.0156908
Log Pis Std                  3.2755773
Log Pis Max                  12.800061
Log Pis Min                  -7.959271
Policy mu Mean               0.025970003
Policy mu Std                0.6190824
Policy mu Max                3.4562428
Policy mu Min                -2.1452148
Policy log std Mean          -0.96655214
Policy log std Std           0.329378
Policy log std Max           -0.124343276
Policy log std Min           -2.4580212
Z mean eval                  1.0515826
Z variance eval              0.013085591
total_rewards                [ 112.87364811 1183.10262657 2814.29052741 2679.47491188 1172.60559583
 3056.62810523  368.14279066 3060.60167746 1479.69680916 3453.48034227]
total_rewards_mean           1938.0897034575596
total_rewards_std            1152.7008456621834
total_rewards_max            3453.4803422679065
total_rewards_min            112.87364811307978
Number of train steps total  564000
Number of env steps total    707000
Number of rollouts total     0
Train Time (s)               130.72058094711974
(Previous) Eval Time (s)     23.834545983932912
Sample Time (s)              25.8366521820426
Epoch Time (s)               180.39177911309525
Total Train Time (s)         25367.86360577494
Epoch                        140
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:35:43.320589 UTC | [2020_01_11_13_32_55] Iteration #140 | Epoch Duration: 183.1933286190033
2020-01-11 20:35:43.320779 UTC | [2020_01_11_13_32_55] Iteration #140 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0541716
Z variance train             0.013060093
KL Divergence                22.898819
KL Loss                      2.289882
QF Loss                      727.26373
VF Loss                      224.56207
Policy Loss                  -1074.8076
Q Predictions Mean           1072.8623
Q Predictions Std            361.9624
Q Predictions Max            1368.934
Q Predictions Min            20.092468
V Predictions Mean           1074.2528
V Predictions Std            360.87805
V Predictions Max            1366.3079
V Predictions Min            -24.243338
Log Pis Mean                 -0.03610851
Log Pis Std                  3.0234792
Log Pis Max                  11.778784
Log Pis Min                  -7.240127
Policy mu Mean               -0.020727934
Policy mu Std                0.59945154
Policy mu Max                2.681815
Policy mu Min                -2.4083173
Policy log std Mean          -0.97733897
Policy log std Std           0.3419494
Policy log std Max           -0.16309565
Policy log std Min           -2.7441874
Z mean eval                  1.0318592
Z variance eval              0.009017983
total_rewards                [3347.43729163  794.58203652 1541.33672387 1685.70195035 1781.60674393
   56.5746884  2800.53035895  871.24367908 3353.16253693 3421.90404559]
total_rewards_mean           1965.4080055241077
total_rewards_std            1147.0922428256322
total_rewards_max            3421.9040455896575
total_rewards_min            56.57468840455817
Number of train steps total  568000
Number of env steps total    712000
Number of rollouts total     0
Train Time (s)               130.28044542111456
(Previous) Eval Time (s)     26.635785893071443
Sample Time (s)              24.222702239174396
Epoch Time (s)               181.1389335533604
Total Train Time (s)         25549.916568972636
Epoch                        141
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:38:45.376060 UTC | [2020_01_11_13_32_55] Iteration #141 | Epoch Duration: 182.05514693260193
2020-01-11 20:38:45.376261 UTC | [2020_01_11_13_32_55] Iteration #141 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0315143
Z variance train             0.009007553
KL Divergence                23.504244
KL Loss                      2.3504245
QF Loss                      1208.2227
VF Loss                      923.9626
Policy Loss                  -1117.3921
Q Predictions Mean           1113.0426
Q Predictions Std            351.69025
Q Predictions Max            1416.7445
Q Predictions Min            -14.091368
V Predictions Mean           1110.9304
V Predictions Std            352.89755
V Predictions Max            1425.5538
V Predictions Min            -59.135223
Log Pis Mean                 0.16011871
Log Pis Std                  2.898839
Log Pis Max                  11.793655
Log Pis Min                  -8.902908
Policy mu Mean               0.040767122
Policy mu Std                0.6167134
Policy mu Max                2.2366865
Policy mu Min                -2.9082234
Policy log std Mean          -0.982343
Policy log std Std           0.3375726
Policy log std Max           0.02919662
Policy log std Min           -2.860004
Z mean eval                  0.9882268
Z variance eval              0.008958559
total_rewards                [1386.48771922 2376.55117425  697.99168279 1449.03549684 3568.41245298
   33.52008647 3066.39129557   31.64803087  946.3850276  1827.12492629]
total_rewards_mean           1538.3547892875497
total_rewards_std            1134.211782930704
total_rewards_max            3568.4124529812652
total_rewards_min            31.648030872380946
Number of train steps total  572000
Number of env steps total    717000
Number of rollouts total     0
Train Time (s)               131.0634388588369
(Previous) Eval Time (s)     27.55166418571025
Sample Time (s)              24.581863118335605
Epoch Time (s)               183.19696616288275
Total Train Time (s)         25722.91193722142
Epoch                        142
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:41:38.373212 UTC | [2020_01_11_13_32_55] Iteration #142 | Epoch Duration: 172.9968225955963
2020-01-11 20:41:38.373378 UTC | [2020_01_11_13_32_55] Iteration #142 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98646677
Z variance train             0.008956232
KL Divergence                22.578661
KL Loss                      2.2578661
QF Loss                      2689.8638
VF Loss                      157.32022
Policy Loss                  -1075.3619
Q Predictions Mean           1072.6578
Q Predictions Std            367.91052
Q Predictions Max            1390.3099
Q Predictions Min            35.32283
V Predictions Mean           1074.0498
V Predictions Std            366.54987
V Predictions Max            1375.7625
V Predictions Min            62.24585
Log Pis Mean                 -0.07311693
Log Pis Std                  3.269311
Log Pis Max                  11.616325
Log Pis Min                  -9.653461
Policy mu Mean               0.017204005
Policy mu Std                0.5887189
Policy mu Max                2.1596856
Policy mu Min                -2.4039874
Policy log std Mean          -0.95680046
Policy log std Std           0.3368588
Policy log std Max           -0.13452041
Policy log std Min           -2.7435308
Z mean eval                  1.0207396
Z variance eval              0.007397027
total_rewards                [ 635.16838413 1789.65096348 3519.68383704 3550.78341909 1134.97821528
 1130.73288668  111.13080126  764.65224899 1152.55661032 3447.01942211]
total_rewards_mean           1723.6356788388598
total_rewards_std            1235.6145142851703
total_rewards_max            3550.783419092414
total_rewards_min            111.13080126461
Number of train steps total  576000
Number of env steps total    722000
Number of rollouts total     0
Train Time (s)               129.28837214270607
(Previous) Eval Time (s)     17.3511410811916
Sample Time (s)              26.000862491317093
Epoch Time (s)               172.64037571521476
Total Train Time (s)         25902.25195256155
Epoch                        143
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:44:37.715272 UTC | [2020_01_11_13_32_55] Iteration #143 | Epoch Duration: 179.34176778793335
2020-01-11 20:44:37.715452 UTC | [2020_01_11_13_32_55] Iteration #143 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0214977
Z variance train             0.007387463
KL Divergence                24.711636
KL Loss                      2.4711635
QF Loss                      772.8298
VF Loss                      320.12402
Policy Loss                  -1085.6792
Q Predictions Mean           1084.984
Q Predictions Std            362.89352
Q Predictions Max            1386.2084
Q Predictions Min            6.560856
V Predictions Mean           1090.3188
V Predictions Std            360.9513
V Predictions Max            1397.7046
V Predictions Min            12.704409
Log Pis Mean                 0.29544678
Log Pis Std                  3.4739425
Log Pis Max                  14.182514
Log Pis Min                  -9.422519
Policy mu Mean               0.02344732
Policy mu Std                0.6399936
Policy mu Max                2.3851767
Policy mu Min                -2.6728525
Policy log std Mean          -0.993518
Policy log std Std           0.34078506
Policy log std Max           -0.06278205
Policy log std Min           -2.7411125
Z mean eval                  1.0169241
Z variance eval              0.007850472
total_rewards                [3123.41466941 2539.88240621 1966.58649634 3527.6349425    32.98305095
 2036.95497214 3350.83167903 3453.68428913 2344.22323769 1867.33280128]
total_rewards_mean           2424.3528544678184
total_rewards_std            1001.6047558343155
total_rewards_max            3527.634942498292
total_rewards_min            32.983050953782225
Number of train steps total  580000
Number of env steps total    727000
Number of rollouts total     0
Train Time (s)               131.357275523711
(Previous) Eval Time (s)     24.05219417065382
Sample Time (s)              25.11304117226973
Epoch Time (s)               180.52251086663455
Total Train Time (s)         26086.714312194847
Epoch                        144
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:47:42.179957 UTC | [2020_01_11_13_32_55] Iteration #144 | Epoch Duration: 184.46437788009644
2020-01-11 20:47:42.180141 UTC | [2020_01_11_13_32_55] Iteration #144 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0144426
Z variance train             0.007839789
KL Divergence                24.922783
KL Loss                      2.4922783
QF Loss                      1565.5881
VF Loss                      487.732
Policy Loss                  -1122.3505
Q Predictions Mean           1120.6599
Q Predictions Std            328.66458
Q Predictions Max            1390.5422
Q Predictions Min            78.5261
V Predictions Mean           1119.1973
V Predictions Std            329.55533
V Predictions Max            1397.2556
V Predictions Min            71.2388
Log Pis Mean                 0.35188502
Log Pis Std                  3.3319342
Log Pis Max                  15.66613
Log Pis Min                  -7.2977095
Policy mu Mean               0.036751047
Policy mu Std                0.6244528
Policy mu Max                3.1520407
Policy mu Min                -2.0042272
Policy log std Mean          -1.0203278
Policy log std Std           0.34348077
Policy log std Max           -0.13620251
Policy log std Min           -2.9922333
Z mean eval                  1.0281708
Z variance eval              0.011433795
total_rewards                [3281.50477639 3357.69421136  554.69170242  798.56137795  820.80116157
 3509.0090775  3543.9519178  1903.64563672 3456.19398874 3460.09937285]
total_rewards_mean           2468.6153223306837
total_rewards_std            1230.245373640744
total_rewards_max            3543.951917803259
total_rewards_min            554.6917024228303
Number of train steps total  584000
Number of env steps total    732000
Number of rollouts total     0
Train Time (s)               129.4121500630863
(Previous) Eval Time (s)     27.99377554934472
Sample Time (s)              24.83905761083588
Epoch Time (s)               182.2449832232669
Total Train Time (s)         26271.06014768593
Epoch                        145
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:50:46.528376 UTC | [2020_01_11_13_32_55] Iteration #145 | Epoch Duration: 184.34810400009155
2020-01-11 20:50:46.528573 UTC | [2020_01_11_13_32_55] Iteration #145 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0301871
Z variance train             0.011452736
KL Divergence                23.5542
KL Loss                      2.3554199
QF Loss                      1074.7137
VF Loss                      166.15692
Policy Loss                  -1114.5719
Q Predictions Mean           1114.8699
Q Predictions Std            328.21805
Q Predictions Max            1377.1385
Q Predictions Min            32.830933
V Predictions Mean           1113.0354
V Predictions Std            324.77454
V Predictions Max            1362.6263
V Predictions Min            -6.286329
Log Pis Mean                 0.3215838
Log Pis Std                  3.357098
Log Pis Max                  14.129016
Log Pis Min                  -10.532898
Policy mu Mean               0.03289385
Policy mu Std                0.6374761
Policy mu Max                4.4089766
Policy mu Min                -2.5244865
Policy log std Mean          -0.99941576
Policy log std Std           0.32441464
Policy log std Max           -0.25323075
Policy log std Min           -2.5353856
Z mean eval                  1.0392084
Z variance eval              0.0069333566
total_rewards                [1325.61224892 3376.01457186 3253.58630683 2280.6654317  2979.78320151
  954.11074443 3525.86617939 1306.51555114 1935.55786752 3343.61579009]
total_rewards_mean           2428.1327893377575
total_rewards_std            940.1060427329708
total_rewards_max            3525.8661793901474
total_rewards_min            954.110744428922
Number of train steps total  588000
Number of env steps total    737000
Number of rollouts total     0
Train Time (s)               131.65779998572543
(Previous) Eval Time (s)     30.09655935317278
Sample Time (s)              25.78756888024509
Epoch Time (s)               187.5419282191433
Total Train Time (s)         26454.30873171147
Epoch                        146
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:53:49.778890 UTC | [2020_01_11_13_32_55] Iteration #146 | Epoch Duration: 183.25018668174744
2020-01-11 20:53:49.779079 UTC | [2020_01_11_13_32_55] Iteration #146 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.041097
Z variance train             0.0069183894
KL Divergence                24.970482
KL Loss                      2.4970481
QF Loss                      679.74304
VF Loss                      393.65814
Policy Loss                  -1070.3661
Q Predictions Mean           1069.2491
Q Predictions Std            387.18808
Q Predictions Max            1408.6289
Q Predictions Min            -21.801647
V Predictions Mean           1066.9297
V Predictions Std            382.85037
V Predictions Max            1380.0713
V Predictions Min            -25.339092
Log Pis Mean                 -0.24769403
Log Pis Std                  3.3251057
Log Pis Max                  16.552212
Log Pis Min                  -9.677664
Policy mu Mean               0.035945244
Policy mu Std                0.59093624
Policy mu Max                2.328108
Policy mu Min                -1.9476236
Policy log std Mean          -0.9396838
Policy log std Std           0.33286822
Policy log std Max           0.23844421
Policy log std Min           -2.6892395
Z mean eval                  1.0646781
Z variance eval              0.009530597
total_rewards                [1753.79270111  715.37960688 3410.24246926 1211.13731772 3396.86234686
 3371.74800995 3668.53738561  571.09192211  298.21232441  539.16126161]
total_rewards_mean           1893.6165345510483
total_rewards_std            1337.8200461318781
total_rewards_max            3668.5373856088254
total_rewards_min            298.212324410614
Number of train steps total  592000
Number of env steps total    742000
Number of rollouts total     0
Train Time (s)               131.94850762281567
(Previous) Eval Time (s)     25.804505061823875
Sample Time (s)              24.6899032802321
Epoch Time (s)               182.44291596487164
Total Train Time (s)         26641.19070312474
Epoch                        147
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:56:56.663126 UTC | [2020_01_11_13_32_55] Iteration #147 | Epoch Duration: 186.88390827178955
2020-01-11 20:56:56.663360 UTC | [2020_01_11_13_32_55] Iteration #147 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0612546
Z variance train             0.009538556
KL Divergence                24.841146
KL Loss                      2.4841146
QF Loss                      1905.9111
VF Loss                      162.31387
Policy Loss                  -1099.1321
Q Predictions Mean           1098.8926
Q Predictions Std            367.66547
Q Predictions Max            1389.1378
Q Predictions Min            50.274036
V Predictions Mean           1102.007
V Predictions Std            361.2783
V Predictions Max            1382.2223
V Predictions Min            62.28058
Log Pis Mean                 0.16786084
Log Pis Std                  3.4243643
Log Pis Max                  16.155556
Log Pis Min                  -7.607153
Policy mu Mean               0.032941505
Policy mu Std                0.6490693
Policy mu Max                3.9208612
Policy mu Min                -2.5274668
Policy log std Mean          -0.9704316
Policy log std Std           0.33965278
Policy log std Max           -0.059928298
Policy log std Min           -2.6463895
Z mean eval                  1.0634688
Z variance eval              0.013336776
total_rewards                [2103.87125696 3392.07606025  182.1805766  1048.75433473  302.218305
  995.08022026   13.81391625  568.28720872 1248.21058391 3543.49945087]
total_rewards_mean           1339.799191354166
total_rewards_std            1209.710324603864
total_rewards_max            3543.4994508680193
total_rewards_min            13.813916252284063
Number of train steps total  596000
Number of env steps total    747000
Number of rollouts total     0
Train Time (s)               131.3754555103369
(Previous) Eval Time (s)     30.24522037198767
Sample Time (s)              24.34991269093007
Epoch Time (s)               185.97058857325464
Total Train Time (s)         26817.194492201786
Epoch                        148
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:59:52.669595 UTC | [2020_01_11_13_32_55] Iteration #148 | Epoch Duration: 176.00608897209167
2020-01-11 20:59:52.669807 UTC | [2020_01_11_13_32_55] Iteration #148 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0669751
Z variance train             0.0132973315
KL Divergence                24.520046
KL Loss                      2.4520047
QF Loss                      605.45593
VF Loss                      658.2317
Policy Loss                  -1143.7325
Q Predictions Mean           1144.1129
Q Predictions Std            319.4395
Q Predictions Max            1424.8591
Q Predictions Min            -181.76268
V Predictions Mean           1152.5493
V Predictions Std            315.01508
V Predictions Max            1418.6295
V Predictions Min            -9.241186
Log Pis Mean                 -0.12913412
Log Pis Std                  3.1561172
Log Pis Max                  18.559326
Log Pis Min                  -6.6340055
Policy mu Mean               0.042422116
Policy mu Std                0.6104881
Policy mu Max                3.4823346
Policy mu Min                -2.30369
Policy log std Mean          -0.9596915
Policy log std Std           0.31648335
Policy log std Max           -0.16618687
Policy log std Min           -3.035222
Z mean eval                  1.0305076
Z variance eval              0.014933209
total_rewards                [ 884.95613437 3326.32822667 2432.79889721 3437.79304241 3171.22461474
 3487.48624041  556.332516   3399.81928694 3402.18863842 3400.29082391]
total_rewards_mean           2749.921842107441
total_rewards_std            1057.743117958175
total_rewards_max            3487.486240405411
total_rewards_min            556.3325160049134
Number of train steps total  600000
Number of env steps total    752000
Number of rollouts total     0
Train Time (s)               131.60136640677229
(Previous) Eval Time (s)     20.280412634834647
Sample Time (s)              24.618900404777378
Epoch Time (s)               176.5006794463843
Total Train Time (s)         27005.570211253595
Epoch                        149
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:03:01.050362 UTC | [2020_01_11_13_32_55] Iteration #149 | Epoch Duration: 188.3804075717926
2020-01-11 21:03:01.050537 UTC | [2020_01_11_13_32_55] Iteration #149 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0319798
Z variance train             0.01488827
KL Divergence                23.09478
KL Loss                      2.309478
QF Loss                      659.1365
VF Loss                      264.79382
Policy Loss                  -1115.7614
Q Predictions Mean           1111.1458
Q Predictions Std            356.51187
Q Predictions Max            1416.2268
Q Predictions Min            -26.586649
V Predictions Mean           1114.0405
V Predictions Std            349.99295
V Predictions Max            1404.7338
V Predictions Min            -16.157476
Log Pis Mean                 0.49382842
Log Pis Std                  3.193644
Log Pis Max                  14.27802
Log Pis Min                  -7.4057803
Policy mu Mean               0.039352845
Policy mu Std                0.6479607
Policy mu Max                2.8755276
Policy mu Min                -2.565144
Policy log std Mean          -1.0035024
Policy log std Std           0.34964675
Policy log std Max           0.12248486
Policy log std Min           -2.612783
Z mean eval                  1.0268424
Z variance eval              0.017398303
total_rewards                [ 997.78704989 2110.92830787  317.90532358   62.42993294 2698.94638829
 1867.67142773  222.79840773 2326.54797781 1903.07135888  389.58866858]
total_rewards_mean           1289.7674843318132
total_rewards_std            944.9862270347797
total_rewards_max            2698.9463882896234
total_rewards_min            62.42993293890052
Number of train steps total  604000
Number of env steps total    757000
Number of rollouts total     0
Train Time (s)               133.24493265897036
(Previous) Eval Time (s)     32.159797011874616
Sample Time (s)              26.237026848830283
Epoch Time (s)               191.64175651967525
Total Train Time (s)         27184.907573165372
Epoch                        150
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:06:00.390478 UTC | [2020_01_11_13_32_55] Iteration #150 | Epoch Duration: 179.33979773521423
2020-01-11 21:06:00.390714 UTC | [2020_01_11_13_32_55] Iteration #150 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.024183
Z variance train             0.017433075
KL Divergence                23.170624
KL Loss                      2.3170624
QF Loss                      803.96625
VF Loss                      221.32492
Policy Loss                  -1104.9512
Q Predictions Mean           1100.6666
Q Predictions Std            376.1401
Q Predictions Max            1384.7611
Q Predictions Min            -56.60631
V Predictions Mean           1100.5813
V Predictions Std            366.08972
V Predictions Max            1378.9058
V Predictions Min            -20.098454
Log Pis Mean                 0.08621869
Log Pis Std                  3.2882483
Log Pis Max                  16.533306
Log Pis Min                  -10.313126
Policy mu Mean               0.03294477
Policy mu Std                0.64014906
Policy mu Max                2.9992328
Policy mu Min                -2.542278
Policy log std Mean          -0.97442776
Policy log std Std           0.3487899
Policy log std Max           -0.15269387
Policy log std Min           -2.773472
Z mean eval                  1.0416868
Z variance eval              0.009351206
total_rewards                [ 808.12862508 3388.87316231 1078.68709616  729.72486219 2851.10387157
 3347.20624519  302.1624965  1475.7691994  3259.59120861 3352.2006767 ]
total_rewards_mean           2059.3447443707364
total_rewards_std            1220.1866132582952
total_rewards_max            3388.873162309592
total_rewards_min            302.1624964954349
Number of train steps total  608000
Number of env steps total    762000
Number of rollouts total     0
Train Time (s)               140.60346899088472
(Previous) Eval Time (s)     19.85751676466316
Sample Time (s)              25.10519486805424
Epoch Time (s)               185.56618062360212
Total Train Time (s)         27374.05398181686
Epoch                        151
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:09:09.539013 UTC | [2020_01_11_13_32_55] Iteration #151 | Epoch Duration: 189.14816975593567
2020-01-11 21:09:09.539243 UTC | [2020_01_11_13_32_55] Iteration #151 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0399637
Z variance train             0.009308942
KL Divergence                24.993315
KL Loss                      2.4993315
QF Loss                      1331.0841
VF Loss                      224.77284
Policy Loss                  -1063.4484
Q Predictions Mean           1059.786
Q Predictions Std            415.09082
Q Predictions Max            1420.4343
Q Predictions Min            -41.462803
V Predictions Mean           1067.2488
V Predictions Std            407.6809
V Predictions Max            1408.4037
V Predictions Min            -27.695211
Log Pis Mean                 -0.14797832
Log Pis Std                  3.040123
Log Pis Max                  13.177002
Log Pis Min                  -6.5707617
Policy mu Mean               0.0019864808
Policy mu Std                0.59331816
Policy mu Max                2.3921788
Policy mu Min                -2.4287236
Policy log std Mean          -0.9533994
Policy log std Std           0.34559977
Policy log std Max           -0.0409379
Policy log std Min           -2.5975475
Z mean eval                  1.0230509
Z variance eval              0.014124644
total_rewards                [ 246.58977563 3374.51484564 1669.28080358 3323.95192678  307.58143956
 3222.16773424 3468.27567315 1134.69718848 2403.82876698 1399.80524634]
total_rewards_mean           2055.069340039995
total_rewards_std            1207.5390023814955
total_rewards_max            3468.2756731535937
total_rewards_min            246.58977562801584
Number of train steps total  612000
Number of env steps total    767000
Number of rollouts total     0
Train Time (s)               140.39160032430664
(Previous) Eval Time (s)     23.43910459568724
Sample Time (s)              25.560245194472373
Epoch Time (s)               189.39095011446625
Total Train Time (s)         27564.978356843814
Epoch                        152
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:12:20.465970 UTC | [2020_01_11_13_32_55] Iteration #152 | Epoch Duration: 190.92657852172852
2020-01-11 21:12:20.466165 UTC | [2020_01_11_13_32_55] Iteration #152 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.022613
Z variance train             0.014113195
KL Divergence                24.237143
KL Loss                      2.4237144
QF Loss                      577.7286
VF Loss                      315.11227
Policy Loss                  -1120.455
Q Predictions Mean           1118.8228
Q Predictions Std            328.93744
Q Predictions Max            1369.0508
Q Predictions Min            40.96045
V Predictions Mean           1127.6814
V Predictions Std            329.44153
V Predictions Max            1376.7792
V Predictions Min            39.52555
Log Pis Mean                 0.09183456
Log Pis Std                  3.170581
Log Pis Max                  12.351532
Log Pis Min                  -9.660963
Policy mu Mean               0.042029988
Policy mu Std                0.62243295
Policy mu Max                3.460408
Policy mu Min                -2.5002694
Policy log std Mean          -0.99592865
Policy log std Std           0.31816512
Policy log std Max           -0.19741672
Policy log std Min           -2.4417124
Z mean eval                  1.0250515
Z variance eval              0.012144273
total_rewards                [ 896.89828771   78.59263747  669.32994802 2549.20746402 1727.59770416
 1118.65711151  332.57546829  724.81471378 1510.93668386 1487.34446573]
total_rewards_mean           1109.5954484540148
total_rewards_std            693.6942854816588
total_rewards_max            2549.2074640158335
total_rewards_min            78.5926374713074
Number of train steps total  616000
Number of env steps total    772000
Number of rollouts total     0
Train Time (s)               139.36745102889836
(Previous) Eval Time (s)     24.974368693772703
Sample Time (s)              26.395483262371272
Epoch Time (s)               190.73730298504233
Total Train Time (s)         27742.573574516922
Epoch                        153
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:15:18.063880 UTC | [2020_01_11_13_32_55] Iteration #153 | Epoch Duration: 177.5975432395935
2020-01-11 21:15:18.064218 UTC | [2020_01_11_13_32_55] Iteration #153 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0237491
Z variance train             0.012148041
KL Divergence                22.401085
KL Loss                      2.2401085
QF Loss                      847.4321
VF Loss                      217.49103
Policy Loss                  -1113.896
Q Predictions Mean           1115.4878
Q Predictions Std            359.71497
Q Predictions Max            1402.3533
Q Predictions Min            4.4873214
V Predictions Mean           1118.8729
V Predictions Std            359.30225
V Predictions Max            1421.5361
V Predictions Min            -8.940779
Log Pis Mean                 0.13641685
Log Pis Std                  3.3387976
Log Pis Max                  10.655294
Log Pis Min                  -9.776389
Policy mu Mean               0.0033174586
Policy mu Std                0.6654742
Policy mu Max                3.0464933
Policy mu Min                -2.543052
Policy log std Mean          -0.96036434
Policy log std Std           0.34071624
Policy log std Max           0.19999492
Policy log std Min           -2.647964
Z mean eval                  1.0223968
Z variance eval              0.012896923
total_rewards                [ 134.98316922 3520.77488155 3546.51530782 3512.6698876  3275.56623569
 1333.60603323 1891.65026964 3354.8670803   380.20527176 1322.78300301]
total_rewards_mean           2227.362113981439
total_rewards_std            1302.1098620890216
total_rewards_max            3546.5153078246567
total_rewards_min            134.9831692161087
Number of train steps total  620000
Number of env steps total    777000
Number of rollouts total     0
Train Time (s)               137.86804717499763
(Previous) Eval Time (s)     11.834221438039094
Sample Time (s)              26.22903684200719
Epoch Time (s)               175.9313054550439
Total Train Time (s)         27939.010930684395
Epoch                        154
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:18:34.503419 UTC | [2020_01_11_13_32_55] Iteration #154 | Epoch Duration: 196.43898820877075
2020-01-11 21:18:34.503621 UTC | [2020_01_11_13_32_55] Iteration #154 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0253901
Z variance train             0.0129454415
KL Divergence                22.717548
KL Loss                      2.271755
QF Loss                      835.3872
VF Loss                      806.46985
Policy Loss                  -1098.6404
Q Predictions Mean           1098.4379
Q Predictions Std            376.22763
Q Predictions Max            1412.4852
Q Predictions Min            -62.69135
V Predictions Mean           1094.2747
V Predictions Std            369.7148
V Predictions Max            1399.9578
V Predictions Min            -15.316363
Log Pis Mean                 -0.2674092
Log Pis Std                  3.2564387
Log Pis Max                  15.381529
Log Pis Min                  -11.834074
Policy mu Mean               0.005573369
Policy mu Std                0.62403286
Policy mu Max                2.5264966
Policy mu Min                -3.0957782
Policy log std Mean          -0.936689
Policy log std Std           0.32434908
Policy log std Max           -0.21480566
Policy log std Min           -2.513032
Z mean eval                  1.0599147
Z variance eval              0.015819004
total_rewards                [ -14.33252052 1260.07885633   22.56136578  184.14605865  555.95888742
 3167.43977086 3283.83966835 1095.13775198  721.83921739 3231.68382058]
total_rewards_mean           1350.8352876818726
total_rewards_std            1290.9062711413771
total_rewards_max            3283.839668350953
total_rewards_min            -14.33252052260253
Number of train steps total  624000
Number of env steps total    782000
Number of rollouts total     0
Train Time (s)               129.41203165380284
(Previous) Eval Time (s)     32.341624666936696
Sample Time (s)              25.681269615422934
Epoch Time (s)               187.43492593616247
Total Train Time (s)         28115.32015854586
Epoch                        155
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:21:30.813562 UTC | [2020_01_11_13_32_55] Iteration #155 | Epoch Duration: 176.30982613563538
2020-01-11 21:21:30.813678 UTC | [2020_01_11_13_32_55] Iteration #155 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0600475
Z variance train             0.015854638
KL Divergence                21.8775
KL Loss                      2.18775
QF Loss                      1338.4738
VF Loss                      321.42487
Policy Loss                  -1131.6025
Q Predictions Mean           1132.8461
Q Predictions Std            348.33664
Q Predictions Max            1422.2355
Q Predictions Min            27.14661
V Predictions Mean           1134.3408
V Predictions Std            346.73367
V Predictions Max            1415.154
V Predictions Min            32.61672
Log Pis Mean                 0.2504089
Log Pis Std                  3.5440547
Log Pis Max                  20.738117
Log Pis Min                  -6.8173985
Policy mu Mean               0.01149871
Policy mu Std                0.6418319
Policy mu Max                3.2843993
Policy mu Min                -4.377906
Policy log std Mean          -1.0001831
Policy log std Std           0.3296836
Policy log std Max           -0.2857244
Policy log std Min           -2.8140306
Z mean eval                  1.0471739
Z variance eval              0.018561859
total_rewards                [1435.30198825 1681.12137321 3400.70866807 3458.96208871 3470.25350579
 3307.87713658 3325.20762861 3394.49124587 1728.4341629  3259.94855197]
total_rewards_mean           2846.2306349964038
total_rewards_std            811.4337387023603
total_rewards_max            3470.2535057919927
total_rewards_min            1435.3019882525873
Number of train steps total  628000
Number of env steps total    787000
Number of rollouts total     0
Train Time (s)               131.5866714422591
(Previous) Eval Time (s)     21.216141239739954
Sample Time (s)              22.3848543507047
Epoch Time (s)               175.18766703270376
Total Train Time (s)         28302.466963909566
Epoch                        156
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:24:37.963768 UTC | [2020_01_11_13_32_55] Iteration #156 | Epoch Duration: 187.149968624115
2020-01-11 21:24:37.964071 UTC | [2020_01_11_13_32_55] Iteration #156 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0500398
Z variance train             0.018556083
KL Divergence                20.854734
KL Loss                      2.0854735
QF Loss                      804.2075
VF Loss                      322.96283
Policy Loss                  -1059.051
Q Predictions Mean           1057.5927
Q Predictions Std            405.4905
Q Predictions Max            1386.9294
Q Predictions Min            -8.833746
V Predictions Mean           1059.8925
V Predictions Std            404.10568
V Predictions Max            1387.5005
V Predictions Min            -16.966135
Log Pis Mean                 0.22967184
Log Pis Std                  3.1852727
Log Pis Max                  13.257445
Log Pis Min                  -7.1433735
Policy mu Mean               0.017943006
Policy mu Std                0.6134767
Policy mu Max                2.6118286
Policy mu Min                -2.0752158
Policy log std Mean          -0.99238324
Policy log std Std           0.35026494
Policy log std Max           -0.1785348
Policy log std Min           -2.7481084
Z mean eval                  1.0347561
Z variance eval              0.019816078
total_rewards                [3261.85474906 2846.64800242 3081.91811681 3254.8031104  3465.43515053
 2537.25467617 2302.15406362 3319.49644458 3296.61125258 3401.96794483]
total_rewards_mean           3076.814351100288
total_rewards_std            370.68881953507633
total_rewards_max            3465.435150530489
total_rewards_min            2302.1540636183195
Number of train steps total  632000
Number of env steps total    792000
Number of rollouts total     0
Train Time (s)               132.16745830373839
(Previous) Eval Time (s)     33.1781100849621
Sample Time (s)              24.32759749982506
Epoch Time (s)               189.67316588852555
Total Train Time (s)         28491.664529205766
Epoch                        157
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:27:47.161674 UTC | [2020_01_11_13_32_55] Iteration #157 | Epoch Duration: 189.1974458694458
2020-01-11 21:27:47.161792 UTC | [2020_01_11_13_32_55] Iteration #157 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0324991
Z variance train             0.01984701
KL Divergence                21.001915
KL Loss                      2.1001916
QF Loss                      4748.8354
VF Loss                      714.0464
Policy Loss                  -1117.0427
Q Predictions Mean           1115.7936
Q Predictions Std            338.6212
Q Predictions Max            1377.7838
Q Predictions Min            11.032557
V Predictions Mean           1122.374
V Predictions Std            332.71158
V Predictions Max            1375.3291
V Predictions Min            -44.85665
Log Pis Mean                 0.2310326
Log Pis Std                  2.940908
Log Pis Max                  11.349175
Log Pis Min                  -7.4239163
Policy mu Mean               0.01580229
Policy mu Std                0.6288052
Policy mu Max                2.5782094
Policy mu Min                -2.0413873
Policy log std Mean          -0.99977016
Policy log std Std           0.345232
Policy log std Max           -0.002798915
Policy log std Min           -2.4963033
Z mean eval                  1.0040022
Z variance eval              0.02147011
total_rewards                [3443.98619838  731.19320915 1543.22727716 2233.8486149  3641.71353323
 3470.13418113 1399.65297881 3388.48318161 3468.3604671  3573.24766704]
total_rewards_mean           2689.3847308523605
total_rewards_std            1047.9404013464678
total_rewards_max            3641.7135332320336
total_rewards_min            731.1932091483443
Number of train steps total  636000
Number of env steps total    797000
Number of rollouts total     0
Train Time (s)               131.81798722269014
(Previous) Eval Time (s)     32.7020039469935
Sample Time (s)              25.787156012374908
Epoch Time (s)               190.30714718205854
Total Train Time (s)         28681.02999344282
Epoch                        158
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:30:56.532166 UTC | [2020_01_11_13_32_55] Iteration #158 | Epoch Duration: 189.3702907562256
2020-01-11 21:30:56.532296 UTC | [2020_01_11_13_32_55] Iteration #158 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0042092
Z variance train             0.021534551
KL Divergence                20.456745
KL Loss                      2.0456746
QF Loss                      687.16113
VF Loss                      491.16043
Policy Loss                  -1117.6781
Q Predictions Mean           1117.5837
Q Predictions Std            347.81424
Q Predictions Max            1370.0682
Q Predictions Min            -7.9717298
V Predictions Mean           1114.776
V Predictions Std            343.4369
V Predictions Max            1363.9573
V Predictions Min            -19.692183
Log Pis Mean                 0.12092443
Log Pis Std                  3.2956917
Log Pis Max                  11.25119
Log Pis Min                  -8.8279915
Policy mu Mean               0.053000275
Policy mu Std                0.6098676
Policy mu Max                2.585102
Policy mu Min                -2.6215847
Policy log std Mean          -1.0086887
Policy log std Std           0.33793828
Policy log std Max           -0.10343504
Policy log std Min           -2.764208
Z mean eval                  1.0475938
Z variance eval              0.01141566
total_rewards                [3697.0004708  3534.72694863 3586.99363266 2654.98433528 3787.5323803
 3627.10316918 3631.05751709 3517.97494444 3672.54301404 3087.1194148 ]
total_rewards_mean           3479.7035827224486
total_rewards_std            327.7324812611222
total_rewards_max            3787.5323803018473
total_rewards_min            2654.9843352841535
Number of train steps total  640000
Number of env steps total    802000
Number of rollouts total     0
Train Time (s)               130.66265188576654
(Previous) Eval Time (s)     31.764828024897724
Sample Time (s)              24.791611853055656
Epoch Time (s)               187.21909176371992
Total Train Time (s)         28871.029800001532
Epoch                        159
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:34:06.534379 UTC | [2020_01_11_13_32_55] Iteration #159 | Epoch Duration: 190.00198578834534
2020-01-11 21:34:06.534555 UTC | [2020_01_11_13_32_55] Iteration #159 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0467371
Z variance train             0.011415696
KL Divergence                21.326881
KL Loss                      2.1326883
QF Loss                      713.60266
VF Loss                      362.29095
Policy Loss                  -1146.5745
Q Predictions Mean           1141.9799
Q Predictions Std            308.89618
Q Predictions Max            1402.3074
Q Predictions Min            -2.191439
V Predictions Mean           1149.19
V Predictions Std            303.93335
V Predictions Max            1405.328
V Predictions Min            25.94726
Log Pis Mean                 0.34172547
Log Pis Std                  3.372001
Log Pis Max                  17.506817
Log Pis Min                  -8.307866
Policy mu Mean               -0.0025891755
Policy mu Std                0.6415976
Policy mu Max                2.5336282
Policy mu Min                -2.8533282
Policy log std Mean          -1.0106907
Policy log std Std           0.31284642
Policy log std Max           0.3463819
Policy log std Min           -2.6213808
Z mean eval                  1.0315826
Z variance eval              0.014129164
total_rewards                [2860.74327696   11.72500329 2817.1913836  2936.74788306 2289.23145598
 1337.35229223  409.69712107  741.43943914 3595.55288517  996.74666662]
total_rewards_mean           1799.6427407118438
total_rewards_std            1184.3177573547807
total_rewards_max            3595.5528851673375
total_rewards_min            11.725003286347993
Number of train steps total  644000
Number of env steps total    807000
Number of rollouts total     0
Train Time (s)               131.46034366590902
(Previous) Eval Time (s)     34.54740958381444
Sample Time (s)              24.468180570285767
Epoch Time (s)               190.47593382000923
Total Train Time (s)         29049.841354146134
Epoch                        160
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:37:05.348636 UTC | [2020_01_11_13_32_55] Iteration #160 | Epoch Duration: 178.81393313407898
2020-01-11 21:37:05.348882 UTC | [2020_01_11_13_32_55] Iteration #160 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0300066
Z variance train             0.014151059
KL Divergence                21.720362
KL Loss                      2.1720362
QF Loss                      933.95087
VF Loss                      369.6302
Policy Loss                  -1131.7186
Q Predictions Mean           1134.2281
Q Predictions Std            358.24762
Q Predictions Max            1418.6877
Q Predictions Min            83.40021
V Predictions Mean           1127.169
V Predictions Std            349.83865
V Predictions Max            1411.6442
V Predictions Min            88.47011
Log Pis Mean                 0.13445145
Log Pis Std                  3.1495
Log Pis Max                  11.025267
Log Pis Min                  -7.577123
Policy mu Mean               -0.04806502
Policy mu Std                0.6404999
Policy mu Max                3.2527163
Policy mu Min                -2.5545297
Policy log std Mean          -0.9875133
Policy log std Std           0.31110963
Policy log std Max           -0.23422372
Policy log std Min           -2.2215254
Z mean eval                  1.0323837
Z variance eval              0.017369725
total_rewards                [3494.74676506 1853.81678053 3167.42835217   58.49669137  336.78583793
 3592.50434356 1344.13004175  307.12053318  990.92885939 3489.525498  ]
total_rewards_mean           1863.5483702948543
total_rewards_std            1379.7477852187847
total_rewards_max            3592.5043435622642
total_rewards_min            58.496691373021996
Number of train steps total  648000
Number of env steps total    812000
Number of rollouts total     0
Train Time (s)               131.54737655818462
(Previous) Eval Time (s)     22.885039758868515
Sample Time (s)              23.857809152454138
Epoch Time (s)               178.29022546950728
Total Train Time (s)         29229.854732259642
Epoch                        161
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:40:05.363894 UTC | [2020_01_11_13_32_55] Iteration #161 | Epoch Duration: 180.01483345031738
2020-01-11 21:40:05.364080 UTC | [2020_01_11_13_32_55] Iteration #161 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0367092
Z variance train             0.01745753
KL Divergence                21.20876
KL Loss                      2.120876
QF Loss                      790.5885
VF Loss                      250.44606
Policy Loss                  -1103.0046
Q Predictions Mean           1097.7065
Q Predictions Std            397.0693
Q Predictions Max            1385.1648
Q Predictions Min            -55.315235
V Predictions Mean           1103.6616
V Predictions Std            390.4185
V Predictions Max            1386.9785
V Predictions Min            -30.877354
Log Pis Mean                 -0.062052965
Log Pis Std                  3.4982185
Log Pis Max                  14.751739
Log Pis Min                  -10.086768
Policy mu Mean               0.021768901
Policy mu Std                0.61737764
Policy mu Max                2.4067757
Policy mu Min                -2.4121497
Policy log std Mean          -0.97712624
Policy log std Std           0.33535117
Policy log std Max           0.081220865
Policy log std Min           -2.8258886
Z mean eval                  1.0589149
Z variance eval              0.015033431
total_rewards                [3535.25763061 1132.43693413 3532.73693813 2845.3027485  3772.18624523
 3451.72549603 3482.61325957 3348.59670234 3261.96189129 3421.23306875]
total_rewards_mean           3178.405091457639
total_rewards_std            718.6496173651092
total_rewards_max            3772.1862452275054
total_rewards_min            1132.436934131125
Number of train steps total  652000
Number of env steps total    817000
Number of rollouts total     0
Train Time (s)               130.37832484114915
(Previous) Eval Time (s)     24.60935948509723
Sample Time (s)              24.795976786408573
Epoch Time (s)               179.78366111265495
Total Train Time (s)         29416.470778554212
Epoch                        162
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:43:11.982278 UTC | [2020_01_11_13_32_55] Iteration #162 | Epoch Duration: 186.61807107925415
2020-01-11 21:43:11.982469 UTC | [2020_01_11_13_32_55] Iteration #162 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0610397
Z variance train             0.014999285
KL Divergence                22.265556
KL Loss                      2.2265556
QF Loss                      951.3418
VF Loss                      139.14268
Policy Loss                  -1122.0796
Q Predictions Mean           1122.4163
Q Predictions Std            348.58762
Q Predictions Max            1410.4927
Q Predictions Min            -10.555249
V Predictions Mean           1122.8556
V Predictions Std            347.30945
V Predictions Max            1390.9937
V Predictions Min            32.68736
Log Pis Mean                 0.013324991
Log Pis Std                  2.9269238
Log Pis Max                  9.433226
Log Pis Min                  -10.247859
Policy mu Mean               -0.0047166455
Policy mu Std                0.6399371
Policy mu Max                2.1215434
Policy mu Min                -2.0654337
Policy log std Mean          -0.96623254
Policy log std Std           0.30677834
Policy log std Max           -0.09853339
Policy log std Min           -2.233185
Z mean eval                  1.0494422
Z variance eval              0.011508242
total_rewards                [2682.73042739 3556.62749648 2014.99831684 1423.40948063 1844.89227364
 3657.33439375 1581.86079185  259.04743663 3666.96845196 3599.38681336]
total_rewards_mean           2428.7255882524796
total_rewards_std            1126.8198258348339
total_rewards_max            3666.9684519562543
total_rewards_min            259.04743662977774
Number of train steps total  656000
Number of env steps total    822000
Number of rollouts total     0
Train Time (s)               131.52362890169024
(Previous) Eval Time (s)     31.443467083387077
Sample Time (s)              25.189630016684532
Epoch Time (s)               188.15672600176185
Total Train Time (s)         29596.930957889184
Epoch                        163
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:46:12.446079 UTC | [2020_01_11_13_32_55] Iteration #163 | Epoch Duration: 180.46345949172974
2020-01-11 21:46:12.446338 UTC | [2020_01_11_13_32_55] Iteration #163 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0486418
Z variance train             0.011506908
KL Divergence                21.751724
KL Loss                      2.1751726
QF Loss                      656.6338
VF Loss                      170.63419
Policy Loss                  -1141.5533
Q Predictions Mean           1140.4519
Q Predictions Std            365.0604
Q Predictions Max            1425.6564
Q Predictions Min            -3.4662042
V Predictions Mean           1136.7812
V Predictions Std            360.89282
V Predictions Max            1411.3179
V Predictions Min            8.440736
Log Pis Mean                 0.35588348
Log Pis Std                  3.1240895
Log Pis Max                  13.304182
Log Pis Min                  -7.3111544
Policy mu Mean               0.055189658
Policy mu Std                0.6449303
Policy mu Max                2.4675617
Policy mu Min                -2.498776
Policy log std Mean          -0.99638945
Policy log std Std           0.31790635
Policy log std Max           -0.18624926
Policy log std Min           -2.524725
Z mean eval                  1.0818512
Z variance eval              0.013261175
total_rewards                [3379.11926312 3134.0174767  3264.03275965 3608.28435489 3544.63155837
 3123.78970578 2777.29681381 1734.67882039 3442.87786848 1063.25487484]
total_rewards_mean           2907.198349602863
total_rewards_std            801.5608585555711
total_rewards_max            3608.2843548906394
total_rewards_min            1063.2548748442885
Number of train steps total  660000
Number of env steps total    827000
Number of rollouts total     0
Train Time (s)               131.29671399015933
(Previous) Eval Time (s)     23.749871756881475
Sample Time (s)              24.468703558668494
Epoch Time (s)               179.5152893057093
Total Train Time (s)         29787.062161005102
Epoch                        164
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:49:22.579030 UTC | [2020_01_11_13_32_55] Iteration #164 | Epoch Duration: 190.1325032711029
2020-01-11 21:49:22.579219 UTC | [2020_01_11_13_32_55] Iteration #164 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0793071
Z variance train             0.013351562
KL Divergence                21.765924
KL Loss                      2.1765926
QF Loss                      4423.8506
VF Loss                      188.0569
Policy Loss                  -1122.0377
Q Predictions Mean           1123.8386
Q Predictions Std            382.4891
Q Predictions Max            1425.8594
Q Predictions Min            -52.660236
V Predictions Mean           1125.6876
V Predictions Std            377.80444
V Predictions Max            1417.4839
V Predictions Min            1.1813921
Log Pis Mean                 0.666033
Log Pis Std                  3.3844762
Log Pis Max                  9.830871
Log Pis Min                  -7.336584
Policy mu Mean               0.027692704
Policy mu Std                0.6054978
Policy mu Max                2.8220112
Policy mu Min                -1.9934877
Policy log std Mean          -1.0477886
Policy log std Std           0.35427997
Policy log std Max           -0.12694359
Policy log std Min           -2.3919048
Z mean eval                  1.0138758
Z variance eval              0.010337881
total_rewards                [ 286.13120946  878.30324412 3329.72579006 1756.82148853 2317.60291932
 3253.25789669 3343.25355619 3285.20203786 3485.94467024 3237.90804962]
total_rewards_mean           2517.4150862085007
total_rewards_std            1105.1570866095703
total_rewards_max            3485.944670243329
total_rewards_min            286.131209458037
Number of train steps total  664000
Number of env steps total    832000
Number of rollouts total     0
Train Time (s)               130.80384211381897
(Previous) Eval Time (s)     34.36682503903285
Sample Time (s)              24.650127154774964
Epoch Time (s)               189.82079430762678
Total Train Time (s)         29968.984038998373
Epoch                        165
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:52:24.502802 UTC | [2020_01_11_13_32_55] Iteration #165 | Epoch Duration: 181.92345881462097
2020-01-11 21:52:24.502959 UTC | [2020_01_11_13_32_55] Iteration #165 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0146222
Z variance train             0.010368128
KL Divergence                22.1762
KL Loss                      2.2176201
QF Loss                      2281.3396
VF Loss                      378.23898
Policy Loss                  -1094.9432
Q Predictions Mean           1092.8939
Q Predictions Std            390.41763
Q Predictions Max            1406.601
Q Predictions Min            -49.335648
V Predictions Mean           1094.7561
V Predictions Std            383.5875
V Predictions Max            1394.922
V Predictions Min            -17.934734
Log Pis Mean                 0.61220145
Log Pis Std                  3.7526674
Log Pis Max                  21.185846
Log Pis Min                  -5.7857366
Policy mu Mean               0.0046671927
Policy mu Std                0.62861073
Policy mu Max                2.6785138
Policy mu Min                -3.0179546
Policy log std Mean          -1.0121372
Policy log std Std           0.37631038
Policy log std Max           0.78228664
Policy log std Min           -3.1350627
Z mean eval                  1.0253289
Z variance eval              0.013745328
total_rewards                [3598.31151905 3562.89104055 1739.72366457 3546.54331366 3370.6777219
 2039.27553084 3581.10244428 2130.99450088  450.76521239 3335.82764023]
total_rewards_mean           2735.6112588360647
total_rewards_std            1030.8946241915755
total_rewards_max            3598.3115190543567
total_rewards_min            450.76521239229766
Number of train steps total  668000
Number of env steps total    837000
Number of rollouts total     0
Train Time (s)               130.99461466399953
(Previous) Eval Time (s)     26.469179786276072
Sample Time (s)              25.22802910581231
Epoch Time (s)               182.6918235560879
Total Train Time (s)         30152.76353085134
Epoch                        166
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:55:28.285492 UTC | [2020_01_11_13_32_55] Iteration #166 | Epoch Duration: 183.78240275382996
2020-01-11 21:55:28.285701 UTC | [2020_01_11_13_32_55] Iteration #166 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0271237
Z variance train             0.013737802
KL Divergence                21.938013
KL Loss                      2.1938014
QF Loss                      890.88513
VF Loss                      450.62692
Policy Loss                  -1133.6584
Q Predictions Mean           1129.528
Q Predictions Std            355.7468
Q Predictions Max            1425.0629
Q Predictions Min            21.970404
V Predictions Mean           1124.8898
V Predictions Std            353.58237
V Predictions Max            1414.105
V Predictions Min            41.118145
Log Pis Mean                 0.34150505
Log Pis Std                  3.234587
Log Pis Max                  12.851091
Log Pis Min                  -7.6227403
Policy mu Mean               0.016635038
Policy mu Std                0.6369273
Policy mu Max                2.183495
Policy mu Min                -3.2146573
Policy log std Mean          -0.99692553
Policy log std Std           0.32871678
Policy log std Max           0.06631839
Policy log std Min           -2.6482167
Z mean eval                  1.0441362
Z variance eval              0.024081323
total_rewards                [ -15.42767401 3334.1895016  3625.73882814 1459.22914842 3267.46121372
 3449.93441794 2440.58529318 3525.02816591   66.62633881 3349.17380975]
total_rewards_mean           2450.253904346015
total_rewards_std            1361.5058625476872
total_rewards_max            3625.738828136536
total_rewards_min            -15.427674011350067
Number of train steps total  672000
Number of env steps total    842000
Number of rollouts total     0
Train Time (s)               130.96625693701208
(Previous) Eval Time (s)     27.559438230935484
Sample Time (s)              25.689654666930437
Epoch Time (s)               184.215349834878
Total Train Time (s)         30338.118408694398
Epoch                        167
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:58:33.642982 UTC | [2020_01_11_13_32_55] Iteration #167 | Epoch Duration: 185.3571252822876
2020-01-11 21:58:33.643176 UTC | [2020_01_11_13_32_55] Iteration #167 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0452671
Z variance train             0.02410547
KL Divergence                21.762451
KL Loss                      2.1762452
QF Loss                      733.85144
VF Loss                      234.32623
Policy Loss                  -1128.5079
Q Predictions Mean           1125.4785
Q Predictions Std            378.20645
Q Predictions Max            1427.405
Q Predictions Min            -10.997331
V Predictions Mean           1128.4144
V Predictions Std            374.75897
V Predictions Max            1419.1652
V Predictions Min            -39.2116
Log Pis Mean                 0.260139
Log Pis Std                  3.1247635
Log Pis Max                  11.846241
Log Pis Min                  -9.073822
Policy mu Mean               0.017040573
Policy mu Std                0.6315314
Policy mu Max                2.217731
Policy mu Min                -2.5193443
Policy log std Mean          -0.99735844
Policy log std Std           0.31398952
Policy log std Max           0.029282212
Policy log std Min           -2.2364588
Z mean eval                  1.0416226
Z variance eval              0.013866274
total_rewards                [3455.66595046  -12.45716282 3065.53475528 3275.13452004 3409.27940008
 3403.19883323  467.08532023 1845.39563335 3368.93039439  708.34130542]
total_rewards_mean           2298.6108949675076
total_rewards_std            1338.2717515940983
total_rewards_max            3455.665950462468
total_rewards_min            -12.457162816192389
Number of train steps total  676000
Number of env steps total    847000
Number of rollouts total     0
Train Time (s)               133.8375626290217
(Previous) Eval Time (s)     28.70092626521364
Sample Time (s)              26.44500053394586
Epoch Time (s)               188.9834894281812
Total Train Time (s)         30527.99243121408
Epoch                        168
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:01:43.519071 UTC | [2020_01_11_13_32_55] Iteration #168 | Epoch Duration: 189.87572932243347
2020-01-11 22:01:43.519292 UTC | [2020_01_11_13_32_55] Iteration #168 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0413973
Z variance train             0.0138671845
KL Divergence                23.38245
KL Loss                      2.3382452
QF Loss                      558.9984
VF Loss                      134.99199
Policy Loss                  -1160.9725
Q Predictions Mean           1163.8772
Q Predictions Std            350.43134
Q Predictions Max            1449.2778
Q Predictions Min            80.57638
V Predictions Mean           1165.6481
V Predictions Std            348.45523
V Predictions Max            1443.1283
V Predictions Min            82.96864
Log Pis Mean                 0.32785627
Log Pis Std                  2.8671103
Log Pis Max                  10.220399
Log Pis Min                  -7.1087465
Policy mu Mean               0.016728545
Policy mu Std                0.60405654
Policy mu Max                2.5481749
Policy mu Min                -2.6868663
Policy log std Mean          -1.0296173
Policy log std Std           0.32825089
Policy log std Max           0.2036767
Policy log std Min           -2.4258556
Z mean eval                  1.0521646
Z variance eval              0.010573217
total_rewards                [3347.25964059 1616.98047345 3355.73106136 3474.24307248 2387.62444945
   22.8510315  3481.58156077  589.42026395 3373.88873636  146.52347693]
total_rewards_mean           2179.61037668235
total_rewards_std            1386.280935530658
total_rewards_max            3481.581560773161
total_rewards_min            22.85103149887319
Number of train steps total  680000
Number of env steps total    852000
Number of rollouts total     0
Train Time (s)               141.69602313591167
(Previous) Eval Time (s)     29.592805542051792
Sample Time (s)              26.459671673364937
Epoch Time (s)               197.7485003513284
Total Train Time (s)         30724.211292779073
Epoch                        169
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:04:59.740485 UTC | [2020_01_11_13_32_55] Iteration #169 | Epoch Duration: 196.22104716300964
2020-01-11 22:04:59.740679 UTC | [2020_01_11_13_32_55] Iteration #169 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0511916
Z variance train             0.010592995
KL Divergence                23.403223
KL Loss                      2.3403223
QF Loss                      537.6892
VF Loss                      179.3866
Policy Loss                  -1107.7604
Q Predictions Mean           1103.5583
Q Predictions Std            407.89096
Q Predictions Max            1439.4943
Q Predictions Min            19.857225
V Predictions Mean           1105.6958
V Predictions Std            403.35254
V Predictions Max            1446.2461
V Predictions Min            3.7856438
Log Pis Mean                 -0.023640491
Log Pis Std                  2.9999971
Log Pis Max                  10.069609
Log Pis Min                  -6.5874786
Policy mu Mean               0.008625513
Policy mu Std                0.608751
Policy mu Max                2.8152099
Policy mu Min                -2.5758862
Policy log std Mean          -0.95917183
Policy log std Std           0.3404973
Policy log std Max           0.01742673
Policy log std Min           -2.6808593
Z mean eval                  1.0329046
Z variance eval              0.022875084
total_rewards                [3280.04448534  190.44864881 2594.96787979  684.86035927 3187.47538096
  762.19642561 1294.65663867  152.0920735  2529.22479738  865.16666666]
total_rewards_mean           1554.1133355970987
total_rewards_std            1158.9164709637075
total_rewards_max            3280.0444853378235
total_rewards_min            152.0920734959719
Number of train steps total  684000
Number of env steps total    857000
Number of rollouts total     0
Train Time (s)               140.97268085414544
(Previous) Eval Time (s)     28.064956521149725
Sample Time (s)              24.380498766433448
Epoch Time (s)               193.4181361417286
Total Train Time (s)         30910.748506483622
Epoch                        170
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:08:06.280448 UTC | [2020_01_11_13_32_55] Iteration #170 | Epoch Duration: 186.53961515426636
2020-01-11 22:08:06.280689 UTC | [2020_01_11_13_32_55] Iteration #170 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0307033
Z variance train             0.022835242
KL Divergence                23.519444
KL Loss                      2.3519444
QF Loss                      600.54297
VF Loss                      223.83568
Policy Loss                  -1171.5804
Q Predictions Mean           1169.469
Q Predictions Std            329.31686
Q Predictions Max            1395.9103
Q Predictions Min            43.396545
V Predictions Mean           1161.5846
V Predictions Std            322.26486
V Predictions Max            1386.4702
V Predictions Min            54.32952
Log Pis Mean                 -0.020514764
Log Pis Std                  2.7983537
Log Pis Max                  8.917072
Log Pis Min                  -7.874622
Policy mu Mean               0.026009642
Policy mu Std                0.6192999
Policy mu Max                2.7973387
Policy mu Min                -2.1123462
Policy log std Mean          -0.9745568
Policy log std Std           0.2920759
Policy log std Max           -0.1523059
Policy log std Min           -2.2750459
Z mean eval                  1.0969999
Z variance eval              0.008290582
total_rewards                [ 537.35842115 1730.02742217 3443.16596728 3260.15046509 3560.83165155
   94.98776272 3073.41277576 3465.42940596  334.44270561 3239.00665616]
total_rewards_mean           2273.881323344428
total_rewards_std            1371.3856855949143
total_rewards_max            3560.831651546643
total_rewards_min            94.9877627212311
Number of train steps total  688000
Number of env steps total    862000
Number of rollouts total     0
Train Time (s)               140.92814687779173
(Previous) Eval Time (s)     21.18610797729343
Sample Time (s)              26.081776081584394
Epoch Time (s)               188.19603093666956
Total Train Time (s)         31106.42537121754
Epoch                        171
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:11:21.959662 UTC | [2020_01_11_13_32_55] Iteration #171 | Epoch Duration: 195.6788330078125
2020-01-11 22:11:21.959863 UTC | [2020_01_11_13_32_55] Iteration #171 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.099045
Z variance train             0.008245909
KL Divergence                25.614807
KL Loss                      2.5614808
QF Loss                      926.5112
VF Loss                      474.91455
Policy Loss                  -1131.5988
Q Predictions Mean           1130.8647
Q Predictions Std            386.55142
Q Predictions Max            1435.5422
Q Predictions Min            30.587336
V Predictions Mean           1122.6233
V Predictions Std            380.58102
V Predictions Max            1415.4443
V Predictions Min            34.764587
Log Pis Mean                 0.050705887
Log Pis Std                  3.49771
Log Pis Max                  10.610366
Log Pis Min                  -8.997246
Policy mu Mean               0.028778972
Policy mu Std                0.634799
Policy mu Max                2.8542695
Policy mu Min                -2.5711577
Policy log std Mean          -0.9829396
Policy log std Std           0.3535555
Policy log std Max           0.022051692
Policy log std Min           -2.3324914
Z mean eval                  1.0315474
Z variance eval              0.01475012
total_rewards                [3227.25937105 3306.13482937 3296.49546481 3373.36631121  322.24982737
 3313.24282699  594.44999505  436.98066203 2407.30862564 1006.30922557]
total_rewards_mean           2128.3797139100197
total_rewards_std            1293.2807145137328
total_rewards_max            3373.3663112137974
total_rewards_min            322.24982736531757
Number of train steps total  692000
Number of env steps total    867000
Number of rollouts total     0
Train Time (s)               140.45046962192282
(Previous) Eval Time (s)     28.668495987076312
Sample Time (s)              26.31190192559734
Epoch Time (s)               195.43086753459647
Total Train Time (s)         31299.57615627488
Epoch                        172
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:14:35.113448 UTC | [2020_01_11_13_32_55] Iteration #172 | Epoch Duration: 193.1534082889557
2020-01-11 22:14:35.113774 UTC | [2020_01_11_13_32_55] Iteration #172 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0304601
Z variance train             0.014685457
KL Divergence                25.620548
KL Loss                      2.5620549
QF Loss                      1163.397
VF Loss                      454.34625
Policy Loss                  -1113.2415
Q Predictions Mean           1114.2207
Q Predictions Std            389.42886
Q Predictions Max            1421.5088
Q Predictions Min            68.38875
V Predictions Mean           1122.8505
V Predictions Std            389.2328
V Predictions Max            1454.3875
V Predictions Min            69.63256
Log Pis Mean                 -0.05865583
Log Pis Std                  3.402007
Log Pis Max                  15.588329
Log Pis Min                  -8.01854
Policy mu Mean               -0.023793748
Policy mu Std                0.6379903
Policy mu Max                2.7159667
Policy mu Min                -2.7438672
Policy log std Mean          -0.9449048
Policy log std Std           0.33632624
Policy log std Max           -0.09769666
Policy log std Min           -2.5898118
Z mean eval                  1.035828
Z variance eval              0.014416452
total_rewards                [3421.00306236 3560.30815932 3471.87417552 2149.01012514 3465.26930814
 3632.34193458 1374.0677598  1030.27142275 3605.50191457 3637.22859733]
total_rewards_mean           2934.6876459514447
total_rewards_std            964.7741602860121
total_rewards_max            3637.228597333194
total_rewards_min            1030.2714227460174
Number of train steps total  696000
Number of env steps total    872000
Number of rollouts total     0
Train Time (s)               131.17316624103114
(Previous) Eval Time (s)     26.390656442847103
Sample Time (s)              23.485818279907107
Epoch Time (s)               181.04964096378535
Total Train Time (s)         31484.10455197422
Epoch                        173
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:17:39.643930 UTC | [2020_01_11_13_32_55] Iteration #173 | Epoch Duration: 184.52997493743896
2020-01-11 22:17:39.644119 UTC | [2020_01_11_13_32_55] Iteration #173 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0358903
Z variance train             0.014410186
KL Divergence                23.376076
KL Loss                      2.3376076
QF Loss                      842.0234
VF Loss                      595.35834
Policy Loss                  -1152.4822
Q Predictions Mean           1152.7041
Q Predictions Std            364.28012
Q Predictions Max            1438.2802
Q Predictions Min            -3.98034
V Predictions Mean           1159.6313
V Predictions Std            361.85553
V Predictions Max            1430.5514
V Predictions Min            7.129505
Log Pis Mean                 0.1714918
Log Pis Std                  3.3146634
Log Pis Max                  13.022614
Log Pis Min                  -9.444908
Policy mu Mean               0.019028876
Policy mu Std                0.61807996
Policy mu Max                2.8424785
Policy mu Min                -2.1145594
Policy log std Mean          -1.0022101
Policy log std Std           0.36044532
Policy log std Max           0.0793407
Policy log std Min           -2.7539847
Z mean eval                  1.0632516
Z variance eval              0.011852862
total_rewards                [3671.00499737 1664.32080763  219.04226083 3661.61776583 1207.09465285
 3756.21911815  208.20954066 3236.22510647 3003.32566724 3710.49331658]
total_rewards_mean           2433.7553233606027
total_rewards_std            1390.701452849489
total_rewards_max            3756.219118148053
total_rewards_min            208.20954065678092
Number of train steps total  700000
Number of env steps total    877000
Number of rollouts total     0
Train Time (s)               131.6069470476359
(Previous) Eval Time (s)     29.870708347763866
Sample Time (s)              24.778847929555923
Epoch Time (s)               186.2565033249557
Total Train Time (s)         31666.82280122349
Epoch                        174
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:20:42.364662 UTC | [2020_01_11_13_32_55] Iteration #174 | Epoch Duration: 182.72039413452148
2020-01-11 22:20:42.364851 UTC | [2020_01_11_13_32_55] Iteration #174 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0618703
Z variance train             0.011844744
KL Divergence                22.044804
KL Loss                      2.2044804
QF Loss                      1183.8424
VF Loss                      266.65765
Policy Loss                  -1142.114
Q Predictions Mean           1135.8978
Q Predictions Std            377.22696
Q Predictions Max            1442.0704
Q Predictions Min            -81.11579
V Predictions Mean           1142.7515
V Predictions Std            364.73947
V Predictions Max            1446.2335
V Predictions Min            54.95708
Log Pis Mean                 0.60106933
Log Pis Std                  3.1548164
Log Pis Max                  11.609957
Log Pis Min                  -7.650136
Policy mu Mean               -0.015222771
Policy mu Std                0.63918525
Policy mu Max                2.1525898
Policy mu Min                -2.344908
Policy log std Mean          -1.0071251
Policy log std Std           0.33144194
Policy log std Max           -0.10196346
Policy log std Min           -2.8899097
Z mean eval                  1.0259178
Z variance eval              0.018208578
total_rewards                [1571.87110396  745.46101221 3400.8818854   368.19343168 3454.22329053
 2478.60864733  622.74062584  414.70266189 3359.96414743 3363.71017264]
total_rewards_mean           1978.0356978902048
total_rewards_std            1297.7153547025166
total_rewards_max            3454.2232905289575
total_rewards_min            368.1934316781386
Number of train steps total  704000
Number of env steps total    882000
Number of rollouts total     0
Train Time (s)               131.88674642378464
(Previous) Eval Time (s)     26.334235523827374
Sample Time (s)              24.538400050718337
Epoch Time (s)               182.75938199833035
Total Train Time (s)         31845.49612804083
Epoch                        175
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:23:41.039640 UTC | [2020_01_11_13_32_55] Iteration #175 | Epoch Duration: 178.674663066864
2020-01-11 22:23:41.039805 UTC | [2020_01_11_13_32_55] Iteration #175 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0260522
Z variance train             0.01825933
KL Divergence                22.450447
KL Loss                      2.2450447
QF Loss                      963.31683
VF Loss                      243.00906
Policy Loss                  -1175.8253
Q Predictions Mean           1175.9172
Q Predictions Std            331.32178
Q Predictions Max            1434.025
Q Predictions Min            98.9203
V Predictions Mean           1170.6632
V Predictions Std            328.1977
V Predictions Max            1425.963
V Predictions Min            110.584854
Log Pis Mean                 0.28397107
Log Pis Std                  3.336843
Log Pis Max                  17.474407
Log Pis Min                  -8.101631
Policy mu Mean               0.030883083
Policy mu Std                0.5944098
Policy mu Max                2.6924748
Policy mu Min                -2.6327062
Policy log std Mean          -1.0521175
Policy log std Std           0.33100498
Policy log std Max           -0.08737147
Policy log std Min           -2.9691873
Z mean eval                  1.0879687
Z variance eval              0.014270897
total_rewards                [  25.3197948  3845.8768559  3512.95105233 1150.51606219  799.22964662
  211.16577607 1251.16066246  654.08793447 2266.72585594 3612.94692993]
total_rewards_mean           1732.9980570715356
total_rewards_std            1388.9249150642333
total_rewards_max            3845.876855896161
total_rewards_min            25.31979479769638
Number of train steps total  708000
Number of env steps total    887000
Number of rollouts total     0
Train Time (s)               132.70886438898742
(Previous) Eval Time (s)     22.249205171130598
Sample Time (s)              25.839884280227125
Epoch Time (s)               180.79795384034514
Total Train Time (s)         32025.99793126248
Epoch                        176
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:26:41.544115 UTC | [2020_01_11_13_32_55] Iteration #176 | Epoch Duration: 180.50419664382935
2020-01-11 22:26:41.544295 UTC | [2020_01_11_13_32_55] Iteration #176 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0865746
Z variance train             0.014240636
KL Divergence                22.557661
KL Loss                      2.2557662
QF Loss                      712.4453
VF Loss                      182.21967
Policy Loss                  -1174.2482
Q Predictions Mean           1175.597
Q Predictions Std            341.54514
Q Predictions Max            1445.4657
Q Predictions Min            49.638676
V Predictions Mean           1174.2705
V Predictions Std            339.72305
V Predictions Max            1425.8918
V Predictions Min            42.954277
Log Pis Mean                 0.07971929
Log Pis Std                  3.027739
Log Pis Max                  12.4337845
Log Pis Min                  -7.185435
Policy mu Mean               0.027354626
Policy mu Std                0.6103925
Policy mu Max                2.222752
Policy mu Min                -2.1657896
Policy log std Mean          -0.9751667
Policy log std Std           0.31645533
Policy log std Max           -0.1819182
Policy log std Min           -2.6713774
Z mean eval                  1.0619085
Z variance eval              0.012170949
total_rewards                [ 321.14937881 3363.78197974 1541.59856716 1519.05047741 2747.13699495
 3595.64028738 2916.2120266  3646.68325018  267.73062333 3771.90489598]
total_rewards_mean           2369.088848154587
total_rewards_std            1286.5968758270837
total_rewards_max            3771.9048959756983
total_rewards_min            267.73062333425725
Number of train steps total  712000
Number of env steps total    892000
Number of rollouts total     0
Train Time (s)               132.3377050999552
(Previous) Eval Time (s)     21.955082399304956
Sample Time (s)              24.3685881360434
Epoch Time (s)               178.66137563530356
Total Train Time (s)         32208.469512998126
Epoch                        177
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:29:44.018126 UTC | [2020_01_11_13_32_55] Iteration #177 | Epoch Duration: 182.47369956970215
2020-01-11 22:29:44.018319 UTC | [2020_01_11_13_32_55] Iteration #177 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0611508
Z variance train             0.012155531
KL Divergence                22.089554
KL Loss                      2.2089555
QF Loss                      917.19
VF Loss                      177.86288
Policy Loss                  -1165.2499
Q Predictions Mean           1164.5525
Q Predictions Std            367.52997
Q Predictions Max            1454.6124
Q Predictions Min            16.963469
V Predictions Mean           1163.9363
V Predictions Std            359.61523
V Predictions Max            1445.4016
V Predictions Min            17.56521
Log Pis Mean                 0.56899506
Log Pis Std                  3.254479
Log Pis Max                  15.772745
Log Pis Min                  -6.2288857
Policy mu Mean               0.0033860817
Policy mu Std                0.6624362
Policy mu Max                2.7708716
Policy mu Min                -2.6006083
Policy log std Mean          -0.984398
Policy log std Std           0.33932063
Policy log std Max           0.0008714199
Policy log std Min           -2.5010748
Z mean eval                  1.0731727
Z variance eval              0.00901146
total_rewards                [ 130.47872889 3559.1512513  1422.94420824   11.8057404   626.07510653
  885.76493127 2442.90638064 3492.16116744 1811.20839238 3584.98995633]
total_rewards_mean           1796.7485863425632
total_rewards_std            1337.8563705582533
total_rewards_max            3584.989956328649
total_rewards_min            11.805740400674498
Number of train steps total  716000
Number of env steps total    897000
Number of rollouts total     0
Train Time (s)               132.967494988814
(Previous) Eval Time (s)     25.76709672017023
Sample Time (s)              25.83782743709162
Epoch Time (s)               184.57241914607584
Total Train Time (s)         32391.198661427945
Epoch                        178
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:32:46.748199 UTC | [2020_01_11_13_32_55] Iteration #178 | Epoch Duration: 182.72976684570312
2020-01-11 22:32:46.748318 UTC | [2020_01_11_13_32_55] Iteration #178 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0718198
Z variance train             0.00901554
KL Divergence                24.264906
KL Loss                      2.4264905
QF Loss                      1133.9673
VF Loss                      192.98615
Policy Loss                  -1143.3007
Q Predictions Mean           1143.544
Q Predictions Std            364.2283
Q Predictions Max            1431.3448
Q Predictions Min            26.2806
V Predictions Mean           1138.4683
V Predictions Std            366.72128
V Predictions Max            1437.0717
V Predictions Min            13.395246
Log Pis Mean                 0.16808003
Log Pis Std                  3.35569
Log Pis Max                  16.795874
Log Pis Min                  -6.612114
Policy mu Mean               0.0019446868
Policy mu Std                0.6332542
Policy mu Max                3.204652
Policy mu Min                -2.17978
Policy log std Mean          -1.0152516
Policy log std Std           0.33863947
Policy log std Max           0.3032081
Policy log std Min           -2.602737
Z mean eval                  1.055825
Z variance eval              0.015153857
total_rewards                [1966.48307662  133.11079129  189.7113389  2940.16135476 1660.36007916
  403.32608323 3718.50826844  887.83381821  145.92485421 1185.18677534]
total_rewards_mean           1323.0606440143306
total_rewards_std            1184.119951217392
total_rewards_max            3718.5082684408235
total_rewards_min            133.11079128865165
Number of train steps total  720000
Number of env steps total    902000
Number of rollouts total     0
Train Time (s)               132.02122528199106
(Previous) Eval Time (s)     23.924123355187476
Sample Time (s)              23.538789376150817
Epoch Time (s)               179.48413801332936
Total Train Time (s)         32563.259063789155
Epoch                        179
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:35:38.812134 UTC | [2020_01_11_13_32_55] Iteration #179 | Epoch Duration: 172.06371688842773
2020-01-11 22:35:38.812322 UTC | [2020_01_11_13_32_55] Iteration #179 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0603435
Z variance train             0.015198055
KL Divergence                21.896463
KL Loss                      2.1896465
QF Loss                      1350.7383
VF Loss                      404.49536
Policy Loss                  -1189.7301
Q Predictions Mean           1185.4836
Q Predictions Std            350.32352
Q Predictions Max            1444.8635
Q Predictions Min            27.25647
V Predictions Mean           1177.1504
V Predictions Std            343.26202
V Predictions Max            1418.3329
V Predictions Min            45.540054
Log Pis Mean                 0.056837365
Log Pis Std                  3.0021365
Log Pis Max                  10.528751
Log Pis Min                  -7.0617795
Policy mu Mean               0.030106876
Policy mu Std                0.631059
Policy mu Max                2.6870847
Policy mu Min                -2.5410776
Policy log std Mean          -1.0138087
Policy log std Std           0.3220221
Policy log std Max           -0.0031513572
Policy log std Min           -2.7306066
Z mean eval                  1.0632541
Z variance eval              0.022522196
total_rewards                [1567.28572171  269.79764631 3618.90940141  650.26874507 3288.68292242
  308.62690763 1287.22941478  153.21376922 3112.06961185  872.20395512]
total_rewards_mean           1512.8288095520577
total_rewards_std            1272.7472999676427
total_rewards_max            3618.909401410746
total_rewards_min            153.21376922304526
Number of train steps total  724000
Number of env steps total    907000
Number of rollouts total     0
Train Time (s)               132.62602265691385
(Previous) Eval Time (s)     16.503200360108167
Sample Time (s)              22.966375082731247
Epoch Time (s)               172.09559809975326
Total Train Time (s)         32740.100937860552
Epoch                        180
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:38:35.656811 UTC | [2020_01_11_13_32_55] Iteration #180 | Epoch Duration: 176.8443570137024
2020-01-11 22:38:35.656995 UTC | [2020_01_11_13_32_55] Iteration #180 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0643709
Z variance train             0.022614881
KL Divergence                20.934769
KL Loss                      2.093477
QF Loss                      1070.6475
VF Loss                      324.4773
Policy Loss                  -1130.8547
Q Predictions Mean           1129.3523
Q Predictions Std            410.7153
Q Predictions Max            1437.836
Q Predictions Min            -92.69605
V Predictions Mean           1124.7961
V Predictions Std            408.76086
V Predictions Max            1423.805
V Predictions Min            -69.84193
Log Pis Mean                 0.07230408
Log Pis Std                  3.312614
Log Pis Max                  11.379593
Log Pis Min                  -8.41713
Policy mu Mean               0.00903817
Policy mu Std                0.63244134
Policy mu Max                2.1619918
Policy mu Min                -2.7743511
Policy log std Mean          -0.97621477
Policy log std Std           0.3555488
Policy log std Max           -0.015332341
Policy log std Min           -2.7275763
Z mean eval                  1.0324239
Z variance eval              0.01077535
total_rewards                [3213.14656192 3512.82880796 3628.53646314 1479.66779898 3626.23979768
 3510.87787233 1764.43168743 3675.34681296 3543.90124825 2957.59950056]
total_rewards_mean           3091.257655120725
total_rewards_std            765.8416651986684
total_rewards_max            3675.3468129613693
total_rewards_min            1479.6677989811378
Number of train steps total  728000
Number of env steps total    912000
Number of rollouts total     0
Train Time (s)               133.10586432693526
(Previous) Eval Time (s)     21.251620477996767
Sample Time (s)              25.422776190564036
Epoch Time (s)               179.78026099549606
Total Train Time (s)         32930.31205717707
Epoch                        181
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:41:45.870608 UTC | [2020_01_11_13_32_55] Iteration #181 | Epoch Duration: 190.21345782279968
2020-01-11 22:41:45.870805 UTC | [2020_01_11_13_32_55] Iteration #181 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0319815
Z variance train             0.010767133
KL Divergence                22.832748
KL Loss                      2.283275
QF Loss                      710.8006
VF Loss                      276.24417
Policy Loss                  -1145.1912
Q Predictions Mean           1141.5864
Q Predictions Std            394.1524
Q Predictions Max            1478.3508
Q Predictions Min            -33.6748
V Predictions Mean           1139.511
V Predictions Std            390.95547
V Predictions Max            1442.6372
V Predictions Min            -27.455376
Log Pis Mean                 0.055952437
Log Pis Std                  3.2321868
Log Pis Max                  8.961234
Log Pis Min                  -7.9943027
Policy mu Mean               -0.012851399
Policy mu Std                0.6434602
Policy mu Max                2.2500346
Policy mu Min                -2.7851202
Policy log std Mean          -0.9669055
Policy log std Std           0.32565182
Policy log std Max           -0.113783
Policy log std Min           -2.740591
Z mean eval                  1.089474
Z variance eval              0.015171243
total_rewards                [3610.21769342 3572.32669229 3559.65288673   36.1655237  3551.64106806
 3685.8669738  2144.32983393 2395.38745772 3563.81851933 1762.91995419]
total_rewards_mean           2788.232660315844
total_rewards_std            1143.2280204159501
total_rewards_max            3685.866973798142
total_rewards_min            36.16552369546628
Number of train steps total  732000
Number of env steps total    917000
Number of rollouts total     0
Train Time (s)               131.5927643030882
(Previous) Eval Time (s)     31.684490035753697
Sample Time (s)              25.033567137550563
Epoch Time (s)               188.31082147639245
Total Train Time (s)         33120.40886552259
Epoch                        182
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:44:55.969107 UTC | [2020_01_11_13_32_55] Iteration #182 | Epoch Duration: 190.09813475608826
2020-01-11 22:44:55.969295 UTC | [2020_01_11_13_32_55] Iteration #182 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.090544
Z variance train             0.01513965
KL Divergence                23.581347
KL Loss                      2.3581347
QF Loss                      569.1105
VF Loss                      226.53772
Policy Loss                  -1170.6895
Q Predictions Mean           1171.4117
Q Predictions Std            370.97137
Q Predictions Max            1460.7587
Q Predictions Min            56.844166
V Predictions Mean           1174.4799
V Predictions Std            367.58023
V Predictions Max            1465.0231
V Predictions Min            74.86489
Log Pis Mean                 0.6779895
Log Pis Std                  3.2168713
Log Pis Max                  12.676565
Log Pis Min                  -6.7240944
Policy mu Mean               -0.008582849
Policy mu Std                0.6653273
Policy mu Max                2.3684669
Policy mu Min                -2.4947295
Policy log std Mean          -0.996285
Policy log std Std           0.3282612
Policy log std Max           -0.11319733
Policy log std Min           -2.7060885
Z mean eval                  1.0549443
Z variance eval              0.007167724
total_rewards                [  23.38332913  739.97872862 3181.88442446 1416.20346387  140.00738621
  402.5842892  3498.18319245   64.04021802 1067.0172918  1508.98671495]
total_rewards_mean           1204.2269038721852
total_rewards_std            1183.8556273043998
total_rewards_max            3498.1831924531652
total_rewards_min            23.383329128240682
Number of train steps total  736000
Number of env steps total    922000
Number of rollouts total     0
Train Time (s)               132.62708123819903
(Previous) Eval Time (s)     33.471509078051895
Sample Time (s)              25.488329750020057
Epoch Time (s)               191.58692006627098
Total Train Time (s)         33292.94211531244
Epoch                        183
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:47:48.505048 UTC | [2020_01_11_13_32_55] Iteration #183 | Epoch Duration: 172.5356228351593
2020-01-11 22:47:48.505232 UTC | [2020_01_11_13_32_55] Iteration #183 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0541583
Z variance train             0.0071698255
KL Divergence                24.570606
KL Loss                      2.4570606
QF Loss                      1366.1438
VF Loss                      303.77878
Policy Loss                  -1156.7655
Q Predictions Mean           1152.3269
Q Predictions Std            367.11597
Q Predictions Max            1434.715
Q Predictions Min            18.00078
V Predictions Mean           1152.0337
V Predictions Std            363.59274
V Predictions Max            1421.8909
V Predictions Min            -6.8537607
Log Pis Mean                 0.3307686
Log Pis Std                  3.259655
Log Pis Max                  10.016876
Log Pis Min                  -6.514146
Policy mu Mean               0.022642987
Policy mu Std                0.659921
Policy mu Max                2.6152587
Policy mu Min                -2.2205052
Policy log std Mean          -0.983946
Policy log std Std           0.3458441
Policy log std Max           -0.07824916
Policy log std Min           -2.5865927
Z mean eval                  1.0889531
Z variance eval              0.011184622
total_rewards                [3214.08540028 3614.55025681 2083.30547081  757.35197091  626.0830927
 3505.39522167 3395.53464606 3667.44330945 2588.01143983  519.62493879]
total_rewards_mean           2397.1385747306194
total_rewards_std            1243.9338284883224
total_rewards_max            3667.4433094455944
total_rewards_min            519.6249387943087
Number of train steps total  740000
Number of env steps total    927000
Number of rollouts total     0
Train Time (s)               132.30146498279646
(Previous) Eval Time (s)     14.419922997243702
Sample Time (s)              24.31755546433851
Epoch Time (s)               171.03894344437867
Total Train Time (s)         33477.92214544304
Epoch                        184
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:50:53.487447 UTC | [2020_01_11_13_32_55] Iteration #184 | Epoch Duration: 184.98208379745483
2020-01-11 22:50:53.487631 UTC | [2020_01_11_13_32_55] Iteration #184 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.08574
Z variance train             0.011149918
KL Divergence                23.923578
KL Loss                      2.3923578
QF Loss                      688.87006
VF Loss                      426.00983
Policy Loss                  -1127.399
Q Predictions Mean           1126.8519
Q Predictions Std            411.2722
Q Predictions Max            1444.0172
Q Predictions Min            2.7294946
V Predictions Mean           1123.3931
V Predictions Std            411.26108
V Predictions Max            1442.0038
V Predictions Min            -38.613503
Log Pis Mean                 0.25010943
Log Pis Std                  3.229988
Log Pis Max                  13.3635235
Log Pis Min                  -8.118093
Policy mu Mean               0.0014492252
Policy mu Std                0.6285825
Policy mu Max                2.520685
Policy mu Min                -2.7701144
Policy log std Mean          -0.96935546
Policy log std Std           0.32537156
Policy log std Max           -0.11972648
Policy log std Min           -2.6070466
Z mean eval                  1.0798086
Z variance eval              0.007688546
total_rewards                [3312.19476102 3557.20661507 3548.1706748  3548.0469883  3485.47701823
 3532.72334845 1858.26346737  689.68151167 1408.02443421  857.54816663]
total_rewards_mean           2579.73369857329
total_rewards_std            1163.0845076224423
total_rewards_max            3557.206615070024
total_rewards_min            689.6815116703223
Number of train steps total  744000
Number of env steps total    932000
Number of rollouts total     0
Train Time (s)               131.94683976192027
(Previous) Eval Time (s)     28.36272875359282
Sample Time (s)              25.078976186923683
Epoch Time (s)               185.38854470243677
Total Train Time (s)         33661.46662578639
Epoch                        185
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:53:57.034978 UTC | [2020_01_11_13_32_55] Iteration #185 | Epoch Duration: 183.54720044136047
2020-01-11 22:53:57.035168 UTC | [2020_01_11_13_32_55] Iteration #185 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0800879
Z variance train             0.007678447
KL Divergence                24.668022
KL Loss                      2.4668024
QF Loss                      660.0629
VF Loss                      235.33612
Policy Loss                  -1172.5234
Q Predictions Mean           1168.9714
Q Predictions Std            387.92062
Q Predictions Max            1463.6787
Q Predictions Min            -23.572088
V Predictions Mean           1166.7188
V Predictions Std            383.9297
V Predictions Max            1464.1438
V Predictions Min            -28.78034
Log Pis Mean                 0.2502398
Log Pis Std                  3.1707208
Log Pis Max                  10.173816
Log Pis Min                  -7.03667
Policy mu Mean               0.039909802
Policy mu Std                0.6322433
Policy mu Max                2.825391
Policy mu Min                -2.5801692
Policy log std Mean          -1.0000225
Policy log std Std           0.32133257
Policy log std Max           -0.14169705
Policy log std Min           -2.2008643
Z mean eval                  1.0496128
Z variance eval              0.016725399
total_rewards                [3340.52344781  529.98491629 3517.4159663  3316.48609526 3319.02428227
 3289.49690302 3253.0403468  3314.06807136 3363.06693579 2383.83559756]
total_rewards_mean           2962.694256243873
total_rewards_std            862.0107637698272
total_rewards_max            3517.4159662970496
total_rewards_min            529.9849162892913
Number of train steps total  748000
Number of env steps total    937000
Number of rollouts total     0
Train Time (s)               134.28678404027596
(Previous) Eval Time (s)     26.521034320816398
Sample Time (s)              25.74540790822357
Epoch Time (s)               186.55322626931593
Total Train Time (s)         33853.35052142665
Epoch                        186
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:57:08.921250 UTC | [2020_01_11_13_32_55] Iteration #186 | Epoch Duration: 191.8858425617218
2020-01-11 22:57:08.921451 UTC | [2020_01_11_13_32_55] Iteration #186 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0526774
Z variance train             0.016753463
KL Divergence                23.338844
KL Loss                      2.3338845
QF Loss                      940.2814
VF Loss                      866.269
Policy Loss                  -1129.0753
Q Predictions Mean           1129.0544
Q Predictions Std            398.68658
Q Predictions Max            1422.4523
Q Predictions Min            -1.1579037
V Predictions Mean           1127.3395
V Predictions Std            401.068
V Predictions Max            1410.0094
V Predictions Min            6.2407656
Log Pis Mean                 0.18327771
Log Pis Std                  3.5101862
Log Pis Max                  12.712291
Log Pis Min                  -8.343847
Policy mu Mean               0.046407275
Policy mu Std                0.61557084
Policy mu Max                2.3716886
Policy mu Min                -2.4107926
Policy log std Mean          -1.0342329
Policy log std Std           0.38051993
Policy log std Max           -0.21300954
Policy log std Min           -2.8725698
Z mean eval                  1.0187577
Z variance eval              0.011267443
total_rewards                [3638.57368129 1022.67975788 1676.13271613 3684.16842189  757.2172781
  213.73227026  542.41674569 3578.55576967 3718.0645685  2335.6545124 ]
total_rewards_mean           2116.7195721805642
total_rewards_std            1373.3614105839524
total_rewards_max            3718.0645684977185
total_rewards_min            213.73227025799878
Number of train steps total  752000
Number of env steps total    942000
Number of rollouts total     0
Train Time (s)               142.13984590303153
(Previous) Eval Time (s)     31.853291337378323
Sample Time (s)              26.300202093552798
Epoch Time (s)               200.29333933396265
Total Train Time (s)         34051.66510000639
Epoch                        187
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:00:27.238391 UTC | [2020_01_11_13_32_55] Iteration #187 | Epoch Duration: 198.31679105758667
2020-01-11 23:00:27.238617 UTC | [2020_01_11_13_32_55] Iteration #187 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0183451
Z variance train             0.011312382
KL Divergence                25.061207
KL Loss                      2.5061207
QF Loss                      1005.33105
VF Loss                      160.44138
Policy Loss                  -1163.9196
Q Predictions Mean           1161.9238
Q Predictions Std            364.97873
Q Predictions Max            1456.8324
Q Predictions Min            17.808208
V Predictions Mean           1166.3906
V Predictions Std            362.5048
V Predictions Max            1430.2827
V Predictions Min            28.650486
Log Pis Mean                 0.5176641
Log Pis Std                  3.2307577
Log Pis Max                  12.837008
Log Pis Min                  -6.9325113
Policy mu Mean               -0.013083588
Policy mu Std                0.64251834
Policy mu Max                2.2266269
Policy mu Min                -2.3135338
Policy log std Mean          -1.0076072
Policy log std Std           0.3263557
Policy log std Max           -0.20786315
Policy log std Min           -2.8921728
Z mean eval                  1.0831608
Z variance eval              0.0098429285
total_rewards                [ 550.05029089 3514.63279621  895.88421748  263.00455669 3316.08021883
 3657.31544487 3483.47576597 3734.30705964 3608.36323813  826.12948767]
total_rewards_mean           2384.9243076384837
total_rewards_std            1442.3283783016757
total_rewards_max            3734.3070596371367
total_rewards_min            263.004556685991
Number of train steps total  756000
Number of env steps total    947000
Number of rollouts total     0
Train Time (s)               141.54304427513853
(Previous) Eval Time (s)     29.876374907791615
Sample Time (s)              25.634031345136464
Epoch Time (s)               197.0534505280666
Total Train Time (s)         34242.44106985582
Epoch                        188
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:03:38.017178 UTC | [2020_01_11_13_32_55] Iteration #188 | Epoch Duration: 190.77842497825623
2020-01-11 23:03:38.017363 UTC | [2020_01_11_13_32_55] Iteration #188 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.084671
Z variance train             0.009899849
KL Divergence                25.365171
KL Loss                      2.5365171
QF Loss                      1549.0255
VF Loss                      529.54944
Policy Loss                  -1163.2866
Q Predictions Mean           1163.043
Q Predictions Std            366.50284
Q Predictions Max            1462.6385
Q Predictions Min            -54.241913
V Predictions Mean           1163.2781
V Predictions Std            364.7879
V Predictions Max            1453.6451
V Predictions Min            -32.604603
Log Pis Mean                 0.25380483
Log Pis Std                  3.1670814
Log Pis Max                  12.385482
Log Pis Min                  -6.8817663
Policy mu Mean               0.023794683
Policy mu Std                0.634586
Policy mu Max                2.4947734
Policy mu Min                -2.1878417
Policy log std Mean          -0.98514605
Policy log std Std           0.31857243
Policy log std Max           -0.17357004
Policy log std Min           -2.3540263
Z mean eval                  1.081108
Z variance eval              0.015346055
total_rewards                [2409.41098138 2015.07791282  929.06120794 1914.47715281 1672.91754628
  163.92522534  687.32377792 1072.23528778 1574.5035649  3575.93929917]
total_rewards_mean           1601.4871956336947
total_rewards_std            919.8149717359271
total_rewards_max            3575.9392991676064
total_rewards_min            163.92522533898347
Number of train steps total  760000
Number of env steps total    952000
Number of rollouts total     0
Train Time (s)               141.2901167529635
(Previous) Eval Time (s)     23.600980080664158
Sample Time (s)              25.049173591658473
Epoch Time (s)               189.94027042528614
Total Train Time (s)         34425.71338960854
Epoch                        189
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:06:41.293018 UTC | [2020_01_11_13_32_55] Iteration #189 | Epoch Duration: 183.2755184173584
2020-01-11 23:06:41.293250 UTC | [2020_01_11_13_32_55] Iteration #189 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0812871
Z variance train             0.015320793
KL Divergence                24.952515
KL Loss                      2.4952514
QF Loss                      1497.9092
VF Loss                      923.1953
Policy Loss                  -1196.2303
Q Predictions Mean           1193.8071
Q Predictions Std            354.23785
Q Predictions Max            1451.7415
Q Predictions Min            -122.94151
V Predictions Mean           1195.5527
V Predictions Std            345.8646
V Predictions Max            1452.4982
V Predictions Min            -36.075417
Log Pis Mean                 0.31799954
Log Pis Std                  3.3421435
Log Pis Max                  15.082437
Log Pis Min                  -8.716793
Policy mu Mean               -0.0105037615
Policy mu Std                0.6657055
Policy mu Max                2.502247
Policy mu Min                -2.8550465
Policy log std Mean          -0.9609605
Policy log std Std           0.31099686
Policy log std Max           0.005875945
Policy log std Min           -2.5449438
Z mean eval                  1.0422785
Z variance eval              0.018003142
total_rewards                [1412.28434291 1912.02481071 2709.66657854 3502.30532341 3654.52371074
  995.87728054   17.5877999   664.33910967 3455.65997789  606.15110313]
total_rewards_mean           1893.0420037417402
total_rewards_std            1285.3294186348426
total_rewards_max            3654.5237107410876
total_rewards_min            17.58779989795321
Number of train steps total  764000
Number of env steps total    957000
Number of rollouts total     0
Train Time (s)               140.08012285502627
(Previous) Eval Time (s)     16.93580160336569
Sample Time (s)              26.868067786563188
Epoch Time (s)               183.88399224495515
Total Train Time (s)         34614.708014188334
Epoch                        190
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:09:50.291868 UTC | [2020_01_11_13_32_55] Iteration #190 | Epoch Duration: 188.9984495639801
2020-01-11 23:09:50.292167 UTC | [2020_01_11_13_32_55] Iteration #190 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0424426
Z variance train             0.018018167
KL Divergence                24.94665
KL Loss                      2.494665
QF Loss                      1420.602
VF Loss                      310.84543
Policy Loss                  -1173.3142
Q Predictions Mean           1173.1721
Q Predictions Std            374.28082
Q Predictions Max            1446.3485
Q Predictions Min            46.067467
V Predictions Mean           1175.2004
V Predictions Std            374.84827
V Predictions Max            1456.5967
V Predictions Min            49.42639
Log Pis Mean                 0.07384795
Log Pis Std                  3.3357384
Log Pis Max                  15.886929
Log Pis Min                  -7.405237
Policy mu Mean               0.057758894
Policy mu Std                0.62192374
Policy mu Max                3.1641164
Policy mu Min                -3.5898337
Policy log std Mean          -0.97762835
Policy log std Std           0.325669
Policy log std Max           -0.04614973
Policy log std Min           -2.9930496
Z mean eval                  1.1129003
Z variance eval              0.014979077
total_rewards                [3454.17679119 2343.57460331 2914.3158525  3304.02379951 1979.84750591
 3665.48276842 3798.28296702   51.56319077  923.46125239  967.62866632]
total_rewards_mean           2340.2357397341157
total_rewards_std            1250.6284204205285
total_rewards_max            3798.28296702055
total_rewards_min            51.56319076979165
Number of train steps total  768000
Number of env steps total    962000
Number of rollouts total     0
Train Time (s)               131.57062179781497
(Previous) Eval Time (s)     22.049773213919252
Sample Time (s)              26.405885443557054
Epoch Time (s)               180.02628045529127
Total Train Time (s)         34797.48240750376
Epoch                        191
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:12:53.068905 UTC | [2020_01_11_13_32_55] Iteration #191 | Epoch Duration: 182.77657461166382
2020-01-11 23:12:53.069147 UTC | [2020_01_11_13_32_55] Iteration #191 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1153386
Z variance train             0.014922582
KL Divergence                25.766567
KL Loss                      2.5766568
QF Loss                      960.05426
VF Loss                      148.17018
Policy Loss                  -1198.4089
Q Predictions Mean           1199.094
Q Predictions Std            358.89755
Q Predictions Max            1466.4729
Q Predictions Min            25.218405
V Predictions Mean           1198.8086
V Predictions Std            358.80496
V Predictions Max            1452.0071
V Predictions Min            -13.89294
Log Pis Mean                 0.45571068
Log Pis Std                  3.2655141
Log Pis Max                  17.275806
Log Pis Min                  -9.82961
Policy mu Mean               0.010407032
Policy mu Std                0.6529667
Policy mu Max                2.5971828
Policy mu Min                -2.3817015
Policy log std Mean          -0.9839282
Policy log std Std           0.32015717
Policy log std Max           -0.09169102
Policy log std Min           -2.5372248
Z mean eval                  1.0555809
Z variance eval              0.016867222
total_rewards                [1819.6130427  3842.56415026 1343.58627715  584.32762725 2129.45355683
  170.62738099  193.50980769 2854.38178422 1934.64042636 1610.44491199]
total_rewards_mean           1648.3148965444464
total_rewards_std            1101.7498679797252
total_rewards_max            3842.5641502601256
total_rewards_min            170.62738098620568
Number of train steps total  772000
Number of env steps total    967000
Number of rollouts total     0
Train Time (s)               132.41115022590384
(Previous) Eval Time (s)     24.799637081101537
Sample Time (s)              25.06523119751364
Epoch Time (s)               182.27601850451902
Total Train Time (s)         34976.36023949925
Epoch                        192
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:15:51.949695 UTC | [2020_01_11_13_32_55] Iteration #192 | Epoch Duration: 178.8803927898407
2020-01-11 23:15:51.949895 UTC | [2020_01_11_13_32_55] Iteration #192 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0520505
Z variance train             0.01692143
KL Divergence                24.903013
KL Loss                      2.4903014
QF Loss                      920.0624
VF Loss                      185.47238
Policy Loss                  -1179.7284
Q Predictions Mean           1180.52
Q Predictions Std            391.33636
Q Predictions Max            1478.6509
Q Predictions Min            -28.161396
V Predictions Mean           1186.3042
V Predictions Std            389.036
V Predictions Max            1463.9366
V Predictions Min            19.160412
Log Pis Mean                 0.35940015
Log Pis Std                  3.473417
Log Pis Max                  12.756037
Log Pis Min                  -7.331373
Policy mu Mean               -0.039976716
Policy mu Std                0.66196305
Policy mu Max                2.6072688
Policy mu Min                -2.632229
Policy log std Mean          -0.99017936
Policy log std Std           0.34451848
Policy log std Max           0.07338345
Policy log std Min           -2.3313627
Z mean eval                  1.0561353
Z variance eval              0.01004336
total_rewards                [3561.24909473 3579.18007555 3414.72517667 1355.53185117 1457.40482064
 3615.34529041 3730.3283685  2963.97448477  131.68020201  141.28033971]
total_rewards_mean           2395.069970417255
total_rewards_std            1398.562933908809
total_rewards_max            3730.328368503588
total_rewards_min            131.6802020134263
Number of train steps total  776000
Number of env steps total    972000
Number of rollouts total     0
Train Time (s)               132.92927420698106
(Previous) Eval Time (s)     21.40361404698342
Sample Time (s)              24.208759795408696
Epoch Time (s)               178.54164804937318
Total Train Time (s)         35155.91659212671
Epoch                        193
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:18:51.508411 UTC | [2020_01_11_13_32_55] Iteration #193 | Epoch Duration: 179.55838060379028
2020-01-11 23:18:51.508593 UTC | [2020_01_11_13_32_55] Iteration #193 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0570742
Z variance train             0.010046816
KL Divergence                26.146517
KL Loss                      2.6146517
QF Loss                      559.21
VF Loss                      309.94852
Policy Loss                  -1174.309
Q Predictions Mean           1175.4087
Q Predictions Std            372.94797
Q Predictions Max            1460.2759
Q Predictions Min            62.74156
V Predictions Mean           1175.9768
V Predictions Std            370.7742
V Predictions Max            1460.1514
V Predictions Min            53.121952
Log Pis Mean                 0.43519282
Log Pis Std                  3.3638494
Log Pis Max                  13.398365
Log Pis Min                  -9.057673
Policy mu Mean               0.020170381
Policy mu Std                0.6539354
Policy mu Max                3.1982868
Policy mu Min                -2.266254
Policy log std Mean          -1.0047746
Policy log std Std           0.33487663
Policy log std Max           -0.2297824
Policy log std Min           -2.7291708
Z mean eval                  1.0647867
Z variance eval              0.009371595
total_rewards                [ 244.31063791 3691.54240692   13.81814296 2440.29437786  519.79032818
 2424.01112461 3424.37116047  388.42186238 3639.04865399 3486.87319017]
total_rewards_mean           2027.2481885450482
total_rewards_std            1482.201386374285
total_rewards_max            3691.5424069206492
total_rewards_min            13.818142961892393
Number of train steps total  780000
Number of env steps total    977000
Number of rollouts total     0
Train Time (s)               132.37232252582908
(Previous) Eval Time (s)     22.420035218819976
Sample Time (s)              23.969937881454825
Epoch Time (s)               178.76229562610388
Total Train Time (s)         35330.985726914834
Epoch                        194
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:21:46.579989 UTC | [2020_01_11_13_32_55] Iteration #194 | Epoch Duration: 175.0712628364563
2020-01-11 23:21:46.580183 UTC | [2020_01_11_13_32_55] Iteration #194 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0696181
Z variance train             0.0093709435
KL Divergence                27.327425
KL Loss                      2.7327425
QF Loss                      538.1139
VF Loss                      146.0651
Policy Loss                  -1180.588
Q Predictions Mean           1179.4766
Q Predictions Std            396.19397
Q Predictions Max            1469.3105
Q Predictions Min            26.367996
V Predictions Mean           1178.6958
V Predictions Std            394.91052
V Predictions Max            1468.0372
V Predictions Min            2.2208633
Log Pis Mean                 -0.015791513
Log Pis Std                  3.0011075
Log Pis Max                  12.311227
Log Pis Min                  -7.021963
Policy mu Mean               0.01083157
Policy mu Std                0.6116881
Policy mu Max                2.894491
Policy mu Min                -2.3443809
Policy log std Mean          -0.98238635
Policy log std Std           0.32633674
Policy log std Max           -0.13899684
Policy log std Min           -2.330052
Z mean eval                  1.053917
Z variance eval              0.010797244
total_rewards                [1660.84920996 3767.29082449 1482.99744955 3474.99628466  427.14273006
 3440.52117525 1011.5333349  1194.97688602 3678.24398119 3730.77701433]
total_rewards_mean           2386.932889041219
total_rewards_std            1271.6240376436087
total_rewards_max            3767.2908244903247
total_rewards_min            427.142730064829
Number of train steps total  784000
Number of env steps total    982000
Number of rollouts total     0
Train Time (s)               133.44165704399347
(Previous) Eval Time (s)     18.728679791092873
Sample Time (s)              25.439489784184843
Epoch Time (s)               177.6098266192712
Total Train Time (s)         35513.57373886742
Epoch                        195
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:24:49.171280 UTC | [2020_01_11_13_32_55] Iteration #195 | Epoch Duration: 182.59096336364746
2020-01-11 23:24:49.171475 UTC | [2020_01_11_13_32_55] Iteration #195 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0576884
Z variance train             0.010714516
KL Divergence                25.131248
KL Loss                      2.513125
QF Loss                      850.12134
VF Loss                      436.70715
Policy Loss                  -1187.2595
Q Predictions Mean           1186.9016
Q Predictions Std            366.04526
Q Predictions Max            1455.6044
Q Predictions Min            -22.283113
V Predictions Mean           1178.744
V Predictions Std            365.68417
V Predictions Max            1454.1644
V Predictions Min            3.6565847
Log Pis Mean                 0.06062167
Log Pis Std                  2.9347942
Log Pis Max                  10.872322
Log Pis Min                  -9.419171
Policy mu Mean               0.037998557
Policy mu Std                0.6067119
Policy mu Max                3.2745435
Policy mu Min                -1.9683005
Policy log std Mean          -1.0046434
Policy log std Std           0.3119836
Policy log std Max           0.08059406
Policy log std Min           -2.3337917
Z mean eval                  1.0483085
Z variance eval              0.021637859
total_rewards                [3434.6073306  2834.25441035 1899.97211957  944.63324909 3484.4281458
 3695.65088245 1018.59258245 3660.59691405 2442.90045224 1110.5038878 ]
total_rewards_mean           2452.6139974397697
total_rewards_std            1077.7826530807877
total_rewards_max            3695.6508824489893
total_rewards_min            944.6332490865458
Number of train steps total  788000
Number of env steps total    987000
Number of rollouts total     0
Train Time (s)               132.4666300700046
(Previous) Eval Time (s)     23.7094113281928
Sample Time (s)              24.06827130354941
Epoch Time (s)               180.24431270174682
Total Train Time (s)         35696.52980049793
Epoch                        196
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:27:52.129348 UTC | [2020_01_11_13_32_55] Iteration #196 | Epoch Duration: 182.95774292945862
2020-01-11 23:27:52.129529 UTC | [2020_01_11_13_32_55] Iteration #196 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0486073
Z variance train             0.021759175
KL Divergence                21.484335
KL Loss                      2.1484334
QF Loss                      544.3274
VF Loss                      166.63908
Policy Loss                  -1204.4854
Q Predictions Mean           1204.0228
Q Predictions Std            348.92374
Q Predictions Max            1450.6956
Q Predictions Min            -64.14227
V Predictions Mean           1211.9075
V Predictions Std            349.16098
V Predictions Max            1447.1202
V Predictions Min            -12.5314
Log Pis Mean                 0.44275922
Log Pis Std                  3.087626
Log Pis Max                  10.161209
Log Pis Min                  -7.7254868
Policy mu Mean               0.03329909
Policy mu Std                0.65870935
Policy mu Max                2.7326932
Policy mu Min                -2.4649613
Policy log std Mean          -0.98951006
Policy log std Std           0.30694407
Policy log std Max           0.5196618
Policy log std Min           -2.3760588
Z mean eval                  1.0869961
Z variance eval              0.015243779
total_rewards                [3509.49701165   98.79485055 3504.9179729   768.48550199  548.97060667
  962.31809521 3665.90819209 3557.25974105 1543.27382993 3802.25960861]
total_rewards_mean           2196.168541064538
total_rewards_std            1453.5839803766366
total_rewards_max            3802.2596086119206
total_rewards_min            98.79485054785545
Number of train steps total  792000
Number of env steps total    992000
Number of rollouts total     0
Train Time (s)               133.31406959984452
(Previous) Eval Time (s)     26.42255361797288
Sample Time (s)              24.266434161458164
Epoch Time (s)               184.00305737927556
Total Train Time (s)         35877.96441665478
Epoch                        197
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:30:53.566574 UTC | [2020_01_11_13_32_55] Iteration #197 | Epoch Duration: 181.43691039085388
2020-01-11 23:30:53.566768 UTC | [2020_01_11_13_32_55] Iteration #197 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0886413
Z variance train             0.015217764
KL Divergence                21.84992
KL Loss                      2.184992
QF Loss                      770.7856
VF Loss                      210.38853
Policy Loss                  -1206.4528
Q Predictions Mean           1205.1809
Q Predictions Std            354.79553
Q Predictions Max            1488.4446
Q Predictions Min            1.6303312
V Predictions Mean           1206.8496
V Predictions Std            351.0178
V Predictions Max            1485.3209
V Predictions Min            -24.315128
Log Pis Mean                 0.44727013
Log Pis Std                  3.1120126
Log Pis Max                  10.713747
Log Pis Min                  -7.773192
Policy mu Mean               -0.0050924597
Policy mu Std                0.6419407
Policy mu Max                2.4592116
Policy mu Min                -2.466864
Policy log std Mean          -1.0140209
Policy log std Std           0.31768847
Policy log std Max           0.07341707
Policy log std Min           -2.4872155
Z mean eval                  1.1066567
Z variance eval              0.0060582887
total_rewards                [3504.24467569 3689.78998418 3621.01582379  542.85532717 3664.31812608
 2914.23114058  626.19758868 3685.7478487  2545.46074515 3553.98841852]
total_rewards_mean           2834.7849678538396
total_rewards_std            1181.004039590985
total_rewards_max            3689.7899841798
total_rewards_min            542.8553271668444
Number of train steps total  796000
Number of env steps total    997000
Number of rollouts total     0
Train Time (s)               132.26387842232361
(Previous) Eval Time (s)     23.856061019934714
Sample Time (s)              25.30609151860699
Epoch Time (s)               181.42603096086532
Total Train Time (s)         36064.80351322098
Epoch                        198
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:34:00.408354 UTC | [2020_01_11_13_32_55] Iteration #198 | Epoch Duration: 186.8414545059204
2020-01-11 23:34:00.408545 UTC | [2020_01_11_13_32_55] Iteration #198 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.105128
Z variance train             0.0060664294
KL Divergence                23.607414
KL Loss                      2.3607414
QF Loss                      1057.5044
VF Loss                      477.25854
Policy Loss                  -1153.6285
Q Predictions Mean           1153.3102
Q Predictions Std            418.80276
Q Predictions Max            1461.6483
Q Predictions Min            -16.964418
V Predictions Mean           1157.0986
V Predictions Std            414.4279
V Predictions Max            1455.8622
V Predictions Min            -40.34882
Log Pis Mean                 0.01738201
Log Pis Std                  3.135796
Log Pis Max                  10.704486
Log Pis Min                  -8.944579
Policy mu Mean               0.006051652
Policy mu Std                0.6354867
Policy mu Max                4.0892935
Policy mu Min                -2.5054615
Policy log std Mean          -1.0064821
Policy log std Std           0.33556688
Policy log std Max           0.22704458
Policy log std Min           -2.5389771
Z mean eval                  1.0816691
Z variance eval              0.0062895147
total_rewards                [3493.24704906  410.50737761 2614.12582493  176.09720495 3456.79244768
 3579.77114524 1840.07257378 1937.63214774 3774.59639966 1725.45426116]
total_rewards_mean           2300.8296431806875
total_rewards_std            1242.0553981469786
total_rewards_max            3774.596399660624
total_rewards_min            176.09720494646632
Number of train steps total  800000
Number of env steps total    1002000
Number of rollouts total     0
Train Time (s)               133.14546592533588
(Previous) Eval Time (s)     29.271174882072955
Sample Time (s)              24.808469214942306
Epoch Time (s)               187.22511002235115
Total Train Time (s)         36247.5278023649
Epoch                        199
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:37:03.135499 UTC | [2020_01_11_13_32_55] Iteration #199 | Epoch Duration: 182.72681951522827
2020-01-11 23:37:03.135691 UTC | [2020_01_11_13_32_55] Iteration #199 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0793887
Z variance train             0.0062904037
KL Divergence                24.740936
KL Loss                      2.4740937
QF Loss                      1290.4863
VF Loss                      295.17645
Policy Loss                  -1169.132
Q Predictions Mean           1166.011
Q Predictions Std            393.5244
Q Predictions Max            1463.6987
Q Predictions Min            -8.622584
V Predictions Mean           1167.1191
V Predictions Std            390.65073
V Predictions Max            1461.6046
V Predictions Min            -18.510654
Log Pis Mean                 0.45257902
Log Pis Std                  3.2748609
Log Pis Max                  13.294435
Log Pis Min                  -8.109097
Policy mu Mean               0.061555848
Policy mu Std                0.64846295
Policy mu Max                2.6744785
Policy mu Min                -2.4934666
Policy log std Mean          -1.0053082
Policy log std Std           0.3432092
Policy log std Max           -0.11438179
Policy log std Min           -2.580476
Z mean eval                  1.0947617
Z variance eval              0.024210164
total_rewards                [ 363.43084326 2583.68430182 2349.93513086  381.31300804 1480.99367575
 1894.02578488  374.88913359  293.26243883 1069.59281349 1677.04622477]
total_rewards_mean           1246.8173355288548
total_rewards_std            830.2590008851505
total_rewards_max            2583.684301820431
total_rewards_min            293.2624388294505
Number of train steps total  804000
Number of env steps total    1007000
Number of rollouts total     0
Train Time (s)               131.42700571613386
(Previous) Eval Time (s)     24.772480810061097
Sample Time (s)              24.51631401060149
Epoch Time (s)               180.71580053679645
Total Train Time (s)         36423.44603057392
Epoch                        200
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:39:59.056757 UTC | [2020_01_11_13_32_55] Iteration #200 | Epoch Duration: 175.92092370986938
2020-01-11 23:39:59.056954 UTC | [2020_01_11_13_32_55] Iteration #200 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0849044
Z variance train             0.024099024
KL Divergence                22.362896
KL Loss                      2.2362897
QF Loss                      916.3036
VF Loss                      327.16858
Policy Loss                  -1186.2499
Q Predictions Mean           1184.1766
Q Predictions Std            389.0588
Q Predictions Max            1514.9194
Q Predictions Min            -44.478676
V Predictions Mean           1184.0552
V Predictions Std            379.7749
V Predictions Max            1508.506
V Predictions Min            6.3821692
Log Pis Mean                 0.6203134
Log Pis Std                  3.340049
Log Pis Max                  12.278319
Log Pis Min                  -6.818414
Policy mu Mean               0.055823117
Policy mu Std                0.6595058
Policy mu Max                3.343079
Policy mu Min                -2.304464
Policy log std Mean          -1.0029486
Policy log std Std           0.34557557
Policy log std Max           -0.034611344
Policy log std Min           -2.573846
Z mean eval                  1.1492226
Z variance eval              0.0076411567
total_rewards                [3522.18266057 3569.19592239  556.90423242 1834.39691465 3425.58023233
 1168.02550668 1099.21924757  857.62106616  213.6306915  2306.42525034]
total_rewards_mean           1855.3181724614346
total_rewards_std            1216.7968297220784
total_rewards_max            3569.1959223901617
total_rewards_min            213.63069150094054
Number of train steps total  808000
Number of env steps total    1012000
Number of rollouts total     0
Train Time (s)               133.34780225576833
(Previous) Eval Time (s)     19.977201084140688
Sample Time (s)              25.67992008663714
Epoch Time (s)               179.00492342654616
Total Train Time (s)         36607.62014671229
Epoch                        201
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:43:03.231577 UTC | [2020_01_11_13_32_55] Iteration #201 | Epoch Duration: 184.17450594902039
2020-01-11 23:43:03.231696 UTC | [2020_01_11_13_32_55] Iteration #201 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1510544
Z variance train             0.007647942
KL Divergence                23.23013
KL Loss                      2.323013
QF Loss                      993.3085
VF Loss                      216.84023
Policy Loss                  -1193.0236
Q Predictions Mean           1189.9797
Q Predictions Std            377.05847
Q Predictions Max            1470.5582
Q Predictions Min            -33.708755
V Predictions Mean           1191.9153
V Predictions Std            375.82913
V Predictions Max            1463.6415
V Predictions Min            -28.292496
Log Pis Mean                 0.19100268
Log Pis Std                  3.055976
Log Pis Max                  17.601967
Log Pis Min                  -6.195464
Policy mu Mean               -0.0075301016
Policy mu Std                0.6277848
Policy mu Max                3.6923883
Policy mu Min                -2.9314723
Policy log std Mean          -0.99976397
Policy log std Std           0.34979725
Policy log std Max           0.32179153
Policy log std Min           -3.1252053
Z mean eval                  1.1098408
Z variance eval              0.005662441
total_rewards                [3688.01686513 1702.10159506 3873.63872703 3847.83732567 2452.54656671
 3623.86106007 3180.98272662 3742.22839821 2060.77990877  357.07661223]
total_rewards_mean           2852.906978550728
total_rewards_std            1120.8639838333645
total_rewards_max            3873.638727034176
total_rewards_min            357.07661223178667
Number of train steps total  812000
Number of env steps total    1017000
Number of rollouts total     0
Train Time (s)               132.3761030738242
(Previous) Eval Time (s)     25.14641440100968
Sample Time (s)              24.603469332214445
Epoch Time (s)               182.12598680704832
Total Train Time (s)         36792.668629529886
Epoch                        202
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:46:08.283943 UTC | [2020_01_11_13_32_55] Iteration #202 | Epoch Duration: 185.05214047431946
2020-01-11 23:46:08.284145 UTC | [2020_01_11_13_32_55] Iteration #202 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1109383
Z variance train             0.0056341277
KL Divergence                25.220757
KL Loss                      2.5220757
QF Loss                      759.84296
VF Loss                      373.7715
Policy Loss                  -1162.5549
Q Predictions Mean           1160.8082
Q Predictions Std            400.85352
Q Predictions Max            1462.8387
Q Predictions Min            -15.677206
V Predictions Mean           1155.9402
V Predictions Std            398.89996
V Predictions Max            1452.0557
V Predictions Min            -6.656102
Log Pis Mean                 0.027406663
Log Pis Std                  3.1979194
Log Pis Max                  10.623229
Log Pis Min                  -8.849979
Policy mu Mean               -0.03384061
Policy mu Std                0.655613
Policy mu Max                2.5078044
Policy mu Min                -2.0548003
Policy log std Mean          -0.937086
Policy log std Std           0.31629682
Policy log std Max           -0.1760664
Policy log std Min           -2.4988375
Z mean eval                  1.0474293
Z variance eval              0.005399053
total_rewards                [ 615.693067   3749.43749846 2064.34840162 2088.86622427  585.26371301
 1700.08387271 3599.61520994 2225.37396295 3916.50297834 3844.06352158]
total_rewards_mean           2438.924844988952
total_rewards_std            1218.0668946608218
total_rewards_max            3916.502978337591
total_rewards_min            585.2637130139179
Number of train steps total  816000
Number of env steps total    1022000
Number of rollouts total     0
Train Time (s)               132.97429264010862
(Previous) Eval Time (s)     28.072262569796294
Sample Time (s)              24.36126160947606
Epoch Time (s)               185.40781681938097
Total Train Time (s)         36977.48837810615
Epoch                        203
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:49:13.105907 UTC | [2020_01_11_13_32_55] Iteration #203 | Epoch Duration: 184.8216269016266
2020-01-11 23:49:13.106082 UTC | [2020_01_11_13_32_55] Iteration #203 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.048146
Z variance train             0.0053996425
KL Divergence                25.278702
KL Loss                      2.5278702
QF Loss                      2899.5833
VF Loss                      373.93076
Policy Loss                  -1188.9563
Q Predictions Mean           1183.772
Q Predictions Std            379.38547
Q Predictions Max            1467.2025
Q Predictions Min            5.2421837
V Predictions Mean           1187.7267
V Predictions Std            373.69824
V Predictions Max            1454.7986
V Predictions Min            7.393887
Log Pis Mean                 0.26185438
Log Pis Std                  2.9828768
Log Pis Max                  9.092999
Log Pis Min                  -7.334831
Policy mu Mean               0.014296442
Policy mu Std                0.6135531
Policy mu Max                2.354634
Policy mu Min                -2.4700303
Policy log std Mean          -0.9968346
Policy log std Std           0.31467554
Policy log std Max           -0.20073175
Policy log std Min           -2.4943821
Z mean eval                  1.1169226
Z variance eval              0.008760245
total_rewards                [3363.91233183 3516.59364479   38.55006124 3587.09850137 3582.86306323
 3453.90348325  482.30453846 3579.6930093  1596.68356282 3604.73448285]
total_rewards_mean           2680.633667912128
total_rewards_std            1343.496036121243
total_rewards_max            3604.7344828452806
total_rewards_min            38.55006124099749
Number of train steps total  820000
Number of env steps total    1027000
Number of rollouts total     0
Train Time (s)               135.96356343105435
(Previous) Eval Time (s)     27.485736172180623
Sample Time (s)              26.07544945180416
Epoch Time (s)               189.52474905503914
Total Train Time (s)         37173.09534625802
Epoch                        204
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:52:28.716014 UTC | [2020_01_11_13_32_55] Iteration #204 | Epoch Duration: 195.6097972393036
2020-01-11 23:52:28.716221 UTC | [2020_01_11_13_32_55] Iteration #204 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1198586
Z variance train             0.008751452
KL Divergence                24.32803
KL Loss                      2.432803
QF Loss                      952.6298
VF Loss                      408.65057
Policy Loss                  -1222.4576
Q Predictions Mean           1218.5613
Q Predictions Std            359.8021
Q Predictions Max            1474.9899
Q Predictions Min            -34.04319
V Predictions Mean           1207.1682
V Predictions Std            347.4722
V Predictions Max            1453.1317
V Predictions Min            2.7341506
Log Pis Mean                 0.39666355
Log Pis Std                  3.1818633
Log Pis Max                  14.256878
Log Pis Min                  -6.304839
Policy mu Mean               -0.0011470094
Policy mu Std                0.6773895
Policy mu Max                3.0080156
Policy mu Min                -2.361339
Policy log std Mean          -0.9679992
Policy log std Std           0.30286738
Policy log std Max           0.0476799
Policy log std Min           -2.9094205
Z mean eval                  1.0699013
Z variance eval              0.009317699
total_rewards                [3796.76560397 3509.92058163 1642.52245739 1788.88487508  293.46602184
 3671.23978722 1006.46993671 2669.03751992 3531.213201   2614.65110308]
total_rewards_mean           2452.417108783909
total_rewards_std            1161.7313744940088
total_rewards_max            3796.7656039736066
total_rewards_min            293.466021836726
Number of train steps total  824000
Number of env steps total    1032000
Number of rollouts total     0
Train Time (s)               144.35718233929947
(Previous) Eval Time (s)     33.5703048016876
Sample Time (s)              24.91422183252871
Epoch Time (s)               202.84170897351578
Total Train Time (s)         37372.02541068336
Epoch                        205
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:55:47.648831 UTC | [2020_01_11_13_32_55] Iteration #205 | Epoch Duration: 198.93246793746948
2020-01-11 23:55:47.649022 UTC | [2020_01_11_13_32_55] Iteration #205 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0716051
Z variance train             0.009284231
KL Divergence                24.579487
KL Loss                      2.4579487
QF Loss                      508.6109
VF Loss                      105.61156
Policy Loss                  -1237.6925
Q Predictions Mean           1236.4847
Q Predictions Std            310.73514
Q Predictions Max            1459.6471
Q Predictions Min            -2.4475126
V Predictions Mean           1234.3665
V Predictions Std            308.58725
V Predictions Max            1455.8999
V Predictions Min            0.21697819
Log Pis Mean                 0.37818035
Log Pis Std                  3.1880732
Log Pis Max                  18.931
Log Pis Min                  -6.5849533
Policy mu Mean               0.03072299
Policy mu Std                0.6315777
Policy mu Max                3.3104787
Policy mu Min                -2.7351983
Policy log std Mean          -1.0223523
Policy log std Std           0.301619
Policy log std Max           0.07035732
Policy log std Min           -2.57278
Z mean eval                  1.1129792
Z variance eval              0.008832223
total_rewards                [1839.45404412 3254.32741645  562.21437664 3466.31075906 3609.66194009
 3726.74574627  102.99713864 3649.98148487 3596.27056133 3311.90773708]
total_rewards_mean           2711.98712045734
total_rewards_std            1300.3866048667262
total_rewards_max            3726.745746273728
total_rewards_min            102.99713864397958
Number of train steps total  828000
Number of env steps total    1037000
Number of rollouts total     0
Train Time (s)               142.5075973314233
(Previous) Eval Time (s)     29.66068059299141
Sample Time (s)              24.310551004949957
Epoch Time (s)               196.47882892936468
Total Train Time (s)         37567.400834497064
Epoch                        206
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:59:03.026852 UTC | [2020_01_11_13_32_55] Iteration #206 | Epoch Duration: 195.37769556045532
2020-01-11 23:59:03.027041 UTC | [2020_01_11_13_32_55] Iteration #206 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1120294
Z variance train             0.008846207
KL Divergence                23.613781
KL Loss                      2.3613782
QF Loss                      1007.19226
VF Loss                      342.24603
Policy Loss                  -1249.894
Q Predictions Mean           1252.658
Q Predictions Std            313.28632
Q Predictions Max            1470.2495
Q Predictions Min            -7.757209
V Predictions Mean           1255.9153
V Predictions Std            313.059
V Predictions Max            1463.2462
V Predictions Min            -31.598225
Log Pis Mean                 0.4726868
Log Pis Std                  3.4559987
Log Pis Max                  16.995674
Log Pis Min                  -9.992644
Policy mu Mean               0.024748031
Policy mu Std                0.64096147
Policy mu Max                2.793754
Policy mu Min                -3.0431864
Policy log std Mean          -1.0482233
Policy log std Std           0.34154058
Policy log std Max           -0.21439475
Policy log std Min           -2.687228
Z mean eval                  1.110439
Z variance eval              0.018823022
total_rewards                [  98.1202154   971.60314576 3577.77585438  518.50886143 3590.05533834
  664.13132155 1617.66769382 3618.48121246 1964.4699409  3660.95078497]
total_rewards_mean           2028.1764369024907
total_rewards_std            1385.2617354453253
total_rewards_max            3660.950784970194
total_rewards_min            98.12021540320113
Number of train steps total  832000
Number of env steps total    1042000
Number of rollouts total     0
Train Time (s)               142.8438429259695
(Previous) Eval Time (s)     28.559175200294703
Sample Time (s)              26.10602048970759
Epoch Time (s)               197.5090386159718
Total Train Time (s)         37764.87923715729
Epoch                        207
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:02:20.508292 UTC | [2020_01_11_13_32_55] Iteration #207 | Epoch Duration: 197.4811134338379
2020-01-12 00:02:20.508496 UTC | [2020_01_11_13_32_55] Iteration #207 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1118948
Z variance train             0.01895327
KL Divergence                21.452053
KL Loss                      2.1452053
QF Loss                      1527.9268
VF Loss                      458.8549
Policy Loss                  -1225.7272
Q Predictions Mean           1224.9878
Q Predictions Std            335.65485
Q Predictions Max            1484.5264
Q Predictions Min            18.257914
V Predictions Mean           1230.5897
V Predictions Std            334.43677
V Predictions Max            1480.8997
V Predictions Min            1.0538199
Log Pis Mean                 0.2537904
Log Pis Std                  3.0334485
Log Pis Max                  9.932827
Log Pis Min                  -10.586102
Policy mu Mean               -0.02662461
Policy mu Std                0.64151055
Policy mu Max                2.0636182
Policy mu Min                -2.6114385
Policy log std Mean          -0.9969033
Policy log std Std           0.3579471
Policy log std Max           -0.10677993
Policy log std Min           -2.6337748
Z mean eval                  1.0868788
Z variance eval              0.011352564
total_rewards                [1368.10292325 1662.24003862 1452.26237076 3558.34538189  358.87631687
 3733.75519088 3455.14661649 1704.56578974  619.58299007 1760.53139707]
total_rewards_mean           1967.3409015630448
total_rewards_std            1144.4644933818006
total_rewards_max            3733.755190876369
total_rewards_min            358.8763168664277
Number of train steps total  836000
Number of env steps total    1047000
Number of rollouts total     0
Train Time (s)               142.01313100429252
(Previous) Eval Time (s)     28.53091100882739
Sample Time (s)              24.784925284329802
Epoch Time (s)               195.3289672974497
Total Train Time (s)         37958.151280708145
Epoch                        208
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:05:33.782792 UTC | [2020_01_11_13_32_55] Iteration #208 | Epoch Duration: 193.274160861969
2020-01-12 00:05:33.782973 UTC | [2020_01_11_13_32_55] Iteration #208 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0867329
Z variance train             0.011330751
KL Divergence                22.346207
KL Loss                      2.2346208
QF Loss                      2670.086
VF Loss                      328.97058
Policy Loss                  -1223.4402
Q Predictions Mean           1220.3091
Q Predictions Std            327.24097
Q Predictions Max            1501.6846
Q Predictions Min            -1.7163181
V Predictions Mean           1233.4739
V Predictions Std            323.703
V Predictions Max            1483.4812
V Predictions Min            31.7937
Log Pis Mean                 0.54972357
Log Pis Std                  3.3085644
Log Pis Max                  12.951121
Log Pis Min                  -6.8792233
Policy mu Mean               0.0325642
Policy mu Std                0.6615609
Policy mu Max                2.7476335
Policy mu Min                -2.7455397
Policy log std Mean          -1.0155585
Policy log std Std           0.3285926
Policy log std Max           -0.16109186
Policy log std Min           -2.647365
Z mean eval                  1.052136
Z variance eval              0.012914784
total_rewards                [3258.11366038 3629.41162399  838.00802054 2125.84460454  233.67818435
 2214.45214362 3713.21745676 2334.47713097 3333.1167951  1901.71466107]
total_rewards_mean           2358.2034281301576
total_rewards_std            1109.9788002142107
total_rewards_max            3713.217456755317
total_rewards_min            233.678184345897
Number of train steps total  840000
Number of env steps total    1052000
Number of rollouts total     0
Train Time (s)               133.3693643240258
(Previous) Eval Time (s)     26.475749277044088
Sample Time (s)              24.658374567050487
Epoch Time (s)               184.50348816812038
Total Train Time (s)         38143.27622653218
Epoch                        209
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:08:38.910637 UTC | [2020_01_11_13_32_55] Iteration #209 | Epoch Duration: 185.1275281906128
2020-01-12 00:08:38.910840 UTC | [2020_01_11_13_32_55] Iteration #209 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0557604
Z variance train             0.012920474
KL Divergence                22.825775
KL Loss                      2.2825775
QF Loss                      1848.9194
VF Loss                      290.53943
Policy Loss                  -1267.8611
Q Predictions Mean           1264.267
Q Predictions Std            291.31714
Q Predictions Max            1489.5469
Q Predictions Min            3.9127874
V Predictions Mean           1265.3918
V Predictions Std            290.44888
V Predictions Max            1481.9817
V Predictions Min            -22.01144
Log Pis Mean                 0.509868
Log Pis Std                  3.2022414
Log Pis Max                  13.753579
Log Pis Min                  -7.026857
Policy mu Mean               -0.01670294
Policy mu Std                0.65642756
Policy mu Max                3.0478175
Policy mu Min                -2.462504
Policy log std Mean          -1.0210694
Policy log std Std           0.31346396
Policy log std Max           -0.12931848
Policy log std Min           -2.5518508
Z mean eval                  1.0579181
Z variance eval              0.025617236
total_rewards                [2829.83184255 3581.48009173 3589.31721233 3506.36799059 3379.93864545
 3667.29025359  708.03475263 3779.66471582 3495.07596328 3481.67269073]
total_rewards_mean           3201.8674158702197
total_rewards_std            865.5053606495328
total_rewards_max            3779.664715815662
total_rewards_min            708.0347526295249
Number of train steps total  844000
Number of env steps total    1057000
Number of rollouts total     0
Train Time (s)               133.52533205691725
(Previous) Eval Time (s)     27.099439254961908
Sample Time (s)              23.857737835962325
Epoch Time (s)               184.48250914784148
Total Train Time (s)         38332.04314639885
Epoch                        210
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:11:47.680145 UTC | [2020_01_11_13_32_55] Iteration #210 | Epoch Duration: 188.7691638469696
2020-01-12 00:11:47.680338 UTC | [2020_01_11_13_32_55] Iteration #210 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0579144
Z variance train             0.02567277
KL Divergence                21.548954
KL Loss                      2.1548955
QF Loss                      1608.9637
VF Loss                      414.21637
Policy Loss                  -1221.029
Q Predictions Mean           1219.6654
Q Predictions Std            376.539
Q Predictions Max            1482.0376
Q Predictions Min            46.01023
V Predictions Mean           1208.5938
V Predictions Std            373.5755
V Predictions Max            1488.6453
V Predictions Min            33.777264
Log Pis Mean                 0.66682756
Log Pis Std                  3.4493542
Log Pis Max                  20.76072
Log Pis Min                  -9.919243
Policy mu Mean               0.030564975
Policy mu Std                0.6348283
Policy mu Max                3.3463168
Policy mu Min                -3.068379
Policy log std Mean          -1.0247259
Policy log std Std           0.322855
Policy log std Max           -0.20503038
Policy log std Min           -2.8050528
Z mean eval                  1.0730486
Z variance eval              0.012733193
total_rewards                [ 267.64387338    7.80370874 2630.99357871 3752.71605409 3909.70249306
 3744.47518292 3568.87234043  314.57926294 3682.66551474 3577.04423579]
total_rewards_mean           2545.6496244805276
total_rewards_std            1573.9544993887316
total_rewards_max            3909.702493064199
total_rewards_min            7.803708743392136
Number of train steps total  848000
Number of env steps total    1062000
Number of rollouts total     0
Train Time (s)               132.24699150631204
(Previous) Eval Time (s)     31.385771117638797
Sample Time (s)              25.42577379522845
Epoch Time (s)               189.0585364191793
Total Train Time (s)         38513.36234013736
Epoch                        211
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:14:49.002449 UTC | [2020_01_11_13_32_55] Iteration #211 | Epoch Duration: 181.32197952270508
2020-01-12 00:14:49.002637 UTC | [2020_01_11_13_32_55] Iteration #211 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0736932
Z variance train             0.012647432
KL Divergence                23.782932
KL Loss                      2.3782933
QF Loss                      836.15247
VF Loss                      206.79688
Policy Loss                  -1253.7786
Q Predictions Mean           1254.854
Q Predictions Std            331.37473
Q Predictions Max            1508.5841
Q Predictions Min            40.73948
V Predictions Mean           1251.8163
V Predictions Std            331.31644
V Predictions Max            1484.5504
V Predictions Min            -10.904397
Log Pis Mean                 0.25066644
Log Pis Std                  3.1669211
Log Pis Max                  16.492195
Log Pis Min                  -10.748024
Policy mu Mean               -0.042273782
Policy mu Std                0.61236227
Policy mu Max                2.600468
Policy mu Min                -2.7847826
Policy log std Mean          -1.0292077
Policy log std Std           0.3287634
Policy log std Max           -0.040920258
Policy log std Min           -2.9462805
Z mean eval                  1.070895
Z variance eval              0.012288852
total_rewards                [2884.53936173 3641.36751754 2500.70831416 3717.65634255 3727.48556405
 3512.19461187 1513.6146565  3735.61010448 3515.16209111 3654.1598556 ]
total_rewards_mean           3240.2498419613758
total_rewards_std            696.2158916444204
total_rewards_max            3735.610104482314
total_rewards_min            1513.614656504074
Number of train steps total  852000
Number of env steps total    1067000
Number of rollouts total     0
Train Time (s)               132.14389237202704
(Previous) Eval Time (s)     23.648896250873804
Sample Time (s)              25.034578394610435
Epoch Time (s)               180.82736701751128
Total Train Time (s)         38700.87082866393
Epoch                        212
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:17:56.517329 UTC | [2020_01_11_13_32_55] Iteration #212 | Epoch Duration: 187.51453351974487
2020-01-12 00:17:56.517769 UTC | [2020_01_11_13_32_55] Iteration #212 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0705574
Z variance train             0.012248136
KL Divergence                24.617672
KL Loss                      2.4617672
QF Loss                      425.0
VF Loss                      98.60116
Policy Loss                  -1205.9457
Q Predictions Mean           1205.2161
Q Predictions Std            393.18555
Q Predictions Max            1491.654
Q Predictions Min            36.394325
V Predictions Mean           1203.1971
V Predictions Std            391.0464
V Predictions Max            1469.4349
V Predictions Min            46.337578
Log Pis Mean                 -0.26012924
Log Pis Std                  2.9112446
Log Pis Max                  6.9870663
Log Pis Min                  -9.277669
Policy mu Mean               0.017270701
Policy mu Std                0.6241051
Policy mu Max                2.6001587
Policy mu Min                -2.9586477
Policy log std Mean          -0.9428819
Policy log std Std           0.29506883
Policy log std Max           -0.16724944
Policy log std Min           -1.9838884
Z mean eval                  1.0976821
Z variance eval              0.01578724
total_rewards                [ -33.48189752 3193.99929859 1339.72022127  780.75734861 2146.66881349
 1947.02243964 1700.45479202 3619.94088173 3130.65791724 3514.20815338]
total_rewards_mean           2133.9947968445804
total_rewards_std            1166.7530474871414
total_rewards_max            3619.9408817260687
total_rewards_min            -33.48189752139932
Number of train steps total  856000
Number of env steps total    1072000
Number of rollouts total     0
Train Time (s)               132.54391280701384
(Previous) Eval Time (s)     30.33573976205662
Sample Time (s)              26.009115042630583
Epoch Time (s)               188.88876761170104
Total Train Time (s)         38882.35001245048
Epoch                        213
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:20:57.996090 UTC | [2020_01_11_13_32_55] Iteration #213 | Epoch Duration: 181.4780478477478
2020-01-12 00:20:57.996304 UTC | [2020_01_11_13_32_55] Iteration #213 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0960575
Z variance train             0.015796734
KL Divergence                23.316515
KL Loss                      2.3316514
QF Loss                      2372.011
VF Loss                      297.01276
Policy Loss                  -1232.5421
Q Predictions Mean           1236.1925
Q Predictions Std            366.10516
Q Predictions Max            1481.2855
Q Predictions Min            17.620668
V Predictions Mean           1224.3665
V Predictions Std            362.69193
V Predictions Max            1468.6799
V Predictions Min            -16.14521
Log Pis Mean                 0.1655561
Log Pis Std                  3.064884
Log Pis Max                  9.423395
Log Pis Min                  -8.951895
Policy mu Mean               -0.033090502
Policy mu Std                0.62404126
Policy mu Max                2.8019621
Policy mu Min                -2.128552
Policy log std Mean          -0.9935852
Policy log std Std           0.2989825
Policy log std Max           -0.0038883686
Policy log std Min           -2.3661263
Z mean eval                  1.10169
Z variance eval              0.014314987
total_rewards                [ 456.39134604 3193.1302067   496.350099   3564.37172066 3645.6036482
 2556.90519927 3745.54851006 2746.5149554  1704.98810138  237.43251127]
total_rewards_mean           2234.7236297964255
total_rewards_std            1333.4021362006572
total_rewards_max            3745.5485100584697
total_rewards_min            237.4325112655244
Number of train steps total  860000
Number of env steps total    1077000
Number of rollouts total     0
Train Time (s)               133.68387957988307
(Previous) Eval Time (s)     22.924640640150756
Sample Time (s)              24.851467460393906
Epoch Time (s)               181.45998768042773
Total Train Time (s)         39061.96080398373
Epoch                        214
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:23:57.609468 UTC | [2020_01_11_13_32_55] Iteration #214 | Epoch Duration: 179.6130268573761
2020-01-12 00:23:57.609670 UTC | [2020_01_11_13_32_55] Iteration #214 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1007787
Z variance train             0.0144174965
KL Divergence                23.963356
KL Loss                      2.3963356
QF Loss                      658.9058
VF Loss                      259.15088
Policy Loss                  -1228.7397
Q Predictions Mean           1232.0588
Q Predictions Std            364.88702
Q Predictions Max            1485.4468
Q Predictions Min            -1.4303939
V Predictions Mean           1229.2354
V Predictions Std            360.2225
V Predictions Max            1481.969
V Predictions Min            14.6645565
Log Pis Mean                 0.34394872
Log Pis Std                  3.018639
Log Pis Max                  14.727978
Log Pis Min                  -6.642699
Policy mu Mean               0.00031886064
Policy mu Std                0.64594823
Policy mu Max                2.5549288
Policy mu Min                -2.048413
Policy log std Mean          -0.9711468
Policy log std Std           0.31396237
Policy log std Max           -0.09145838
Policy log std Min           -3.3039756
Z mean eval                  1.0752188
Z variance eval              0.021428037
total_rewards                [3516.34977856 1152.58623297  997.11617864  453.56373022 2264.17742525
 3254.05887353 1938.19299295  962.96942416 3715.61282041   56.92492457]
total_rewards_mean           1831.1552381267204
total_rewards_std            1247.8043233201356
total_rewards_max            3715.6128204074926
total_rewards_min            56.924924567962556
Number of train steps total  864000
Number of env steps total    1082000
Number of rollouts total     0
Train Time (s)               136.3225920163095
(Previous) Eval Time (s)     21.077351448126137
Sample Time (s)              23.527525937650353
Epoch Time (s)               180.927469402086
Total Train Time (s)         39246.35927714128
Epoch                        215
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:27:02.011462 UTC | [2020_01_11_13_32_55] Iteration #215 | Epoch Duration: 184.4016363620758
2020-01-12 00:27:02.011776 UTC | [2020_01_11_13_32_55] Iteration #215 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0693965
Z variance train             0.02164492
KL Divergence                21.424568
KL Loss                      2.1424568
QF Loss                      918.64215
VF Loss                      412.33786
Policy Loss                  -1250.7874
Q Predictions Mean           1253.5787
Q Predictions Std            373.03424
Q Predictions Max            1491.6654
Q Predictions Min            -86.12673
V Predictions Mean           1251.6519
V Predictions Std            370.15237
V Predictions Max            1503.5632
V Predictions Min            -25.878414
Log Pis Mean                 0.22461239
Log Pis Std                  3.4835432
Log Pis Max                  21.02975
Log Pis Min                  -7.163423
Policy mu Mean               -0.01617075
Policy mu Std                0.64465886
Policy mu Max                3.042692
Policy mu Min                -3.9543293
Policy log std Mean          -0.9996741
Policy log std Std           0.32015666
Policy log std Max           -0.081296444
Policy log std Min           -2.5982502
Z mean eval                  1.0639846
Z variance eval              0.019496683
total_rewards                [3492.86226427 3584.8019805  3852.40093616 3749.61217925  942.53239922
  106.00292964  182.6361664   -25.52218827 3714.43856825  205.68357744]
total_rewards_mean           1980.544881288019
total_rewards_std            1717.5234246950708
total_rewards_max            3852.4009361647627
total_rewards_min            -25.522188271007135
Number of train steps total  868000
Number of env steps total    1087000
Number of rollouts total     0
Train Time (s)               134.3787533128634
(Previous) Eval Time (s)     24.55120241921395
Sample Time (s)              24.410853050183505
Epoch Time (s)               183.34080878226086
Total Train Time (s)         39434.41372267343
Epoch                        216
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:30:10.067970 UTC | [2020_01_11_13_32_55] Iteration #216 | Epoch Duration: 188.05599403381348
2020-01-12 00:30:10.068150 UTC | [2020_01_11_13_32_55] Iteration #216 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.062212
Z variance train             0.019504555
KL Divergence                20.913479
KL Loss                      2.091348
QF Loss                      1114.7151
VF Loss                      177.78416
Policy Loss                  -1263.5192
Q Predictions Mean           1263.8887
Q Predictions Std            325.34302
Q Predictions Max            1491.5647
Q Predictions Min            -73.0193
V Predictions Mean           1258.9492
V Predictions Std            320.4731
V Predictions Max            1469.6658
V Predictions Min            21.058403
Log Pis Mean                 0.72957283
Log Pis Std                  3.2636955
Log Pis Max                  18.866074
Log Pis Min                  -6.2348156
Policy mu Mean               0.048684895
Policy mu Std                0.64692366
Policy mu Max                2.927121
Policy mu Min                -3.4405034
Policy log std Mean          -1.0518938
Policy log std Std           0.31812903
Policy log std Max           0.3186803
Policy log std Min           -2.9380422
Z mean eval                  1.0728227
Z variance eval              0.025488943
total_rewards                [1215.68100933    5.75792175 1684.01767726 3565.36982413 3652.43922668
 3499.57439278 3551.28968944  397.55756991 3345.3173242  3755.58832051]
total_rewards_mean           2467.259295600275
total_rewards_std            1407.2896653053
total_rewards_max            3755.5883205148775
total_rewards_min            5.757921745152588
Number of train steps total  872000
Number of env steps total    1092000
Number of rollouts total     0
Train Time (s)               141.45329150231555
(Previous) Eval Time (s)     29.266056074295193
Sample Time (s)              26.00521646393463
Epoch Time (s)               196.72456404054537
Total Train Time (s)         39629.57629214972
Epoch                        217
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:33:25.234350 UTC | [2020_01_11_13_32_55] Iteration #217 | Epoch Duration: 195.1660349369049
2020-01-12 00:33:25.234676 UTC | [2020_01_11_13_32_55] Iteration #217 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0757345
Z variance train             0.025553998
KL Divergence                22.648464
KL Loss                      2.2648466
QF Loss                      608.5745
VF Loss                      171.58244
Policy Loss                  -1277.945
Q Predictions Mean           1279.6782
Q Predictions Std            366.91663
Q Predictions Max            1533.1842
Q Predictions Min            -8.205301
V Predictions Mean           1280.285
V Predictions Std            365.27686
V Predictions Max            1523.0885
V Predictions Min            6.9683514
Log Pis Mean                 0.42520326
Log Pis Std                  3.3827848
Log Pis Max                  12.876457
Log Pis Min                  -6.6118126
Policy mu Mean               0.01698752
Policy mu Std                0.61668146
Policy mu Max                2.7922115
Policy mu Min                -2.7470665
Policy log std Mean          -1.0138404
Policy log std Std           0.327305
Policy log std Max           -0.16755414
Policy log std Min           -2.4888592
Z mean eval                  1.0863227
Z variance eval              0.008291875
total_rewards                [1096.0572914  2280.6798624  3613.2636567   983.75641922 2328.96865023
  185.7311715  3316.56835971 3060.60360631 3420.16151229 3843.3652103 ]
total_rewards_mean           2412.915574006355
total_rewards_std            1204.124144946671
total_rewards_max            3843.365210295941
total_rewards_min            185.73117150463963
Number of train steps total  876000
Number of env steps total    1097000
Number of rollouts total     0
Train Time (s)               141.08338884124532
(Previous) Eval Time (s)     27.707178895827383
Sample Time (s)              26.495885741896927
Epoch Time (s)               195.28645347896963
Total Train Time (s)         39824.12434082758
Epoch                        218
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:36:39.785532 UTC | [2020_01_11_13_32_55] Iteration #218 | Epoch Duration: 194.55067229270935
2020-01-12 00:36:39.785782 UTC | [2020_01_11_13_32_55] Iteration #218 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0881058
Z variance train             0.008312276
KL Divergence                24.524624
KL Loss                      2.4524624
QF Loss                      1328.8059
VF Loss                      350.3999
Policy Loss                  -1242.3926
Q Predictions Mean           1238.1527
Q Predictions Std            380.89194
Q Predictions Max            1500.0076
Q Predictions Min            -7.1189365
V Predictions Mean           1250.7693
V Predictions Std            372.2864
V Predictions Max            1500.6761
V Predictions Min            13.167014
Log Pis Mean                 0.4181275
Log Pis Std                  3.5002854
Log Pis Max                  19.842459
Log Pis Min                  -7.384148
Policy mu Mean               0.04057954
Policy mu Std                0.6581764
Policy mu Max                2.9627724
Policy mu Min                -3.7680974
Policy log std Mean          -1.005985
Policy log std Std           0.34324256
Policy log std Max           0.41397607
Policy log std Min           -2.8629768
Z mean eval                  1.1000979
Z variance eval              0.016139256
total_rewards                [3303.78861887 3500.79236185 3553.42753152 1580.04716849 1943.43313071
 3575.29763798 3780.47749832 3730.61754466 3633.87580013 3604.1787362 ]
total_rewards_mean           3220.593602873872
total_rewards_std            744.0491740131978
total_rewards_max            3780.4774983233306
total_rewards_min            1580.0471684859706
Number of train steps total  880000
Number of env steps total    1102000
Number of rollouts total     0
Train Time (s)               140.63902930077165
(Previous) Eval Time (s)     26.970986532978714
Sample Time (s)              26.77979901107028
Epoch Time (s)               194.38981484482065
Total Train Time (s)         40024.18310419982
Epoch                        219
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:39:59.847387 UTC | [2020_01_11_13_32_55] Iteration #219 | Epoch Duration: 200.061443567276
2020-01-12 00:39:59.847612 UTC | [2020_01_11_13_32_55] Iteration #219 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0977187
Z variance train             0.016039439
KL Divergence                24.825481
KL Loss                      2.4825482
QF Loss                      759.61273
VF Loss                      250.45773
Policy Loss                  -1251.2219
Q Predictions Mean           1255.6838
Q Predictions Std            365.873
Q Predictions Max            1520.8336
Q Predictions Min            28.309635
V Predictions Mean           1252.1884
V Predictions Std            369.07358
V Predictions Max            1508.1483
V Predictions Min            7.778494
Log Pis Mean                 0.41328046
Log Pis Std                  3.0764978
Log Pis Max                  11.753748
Log Pis Min                  -9.244797
Policy mu Mean               -0.026939888
Policy mu Std                0.6405228
Policy mu Max                2.2391915
Policy mu Min                -2.5115378
Policy log std Mean          -1.0133924
Policy log std Std           0.33176306
Policy log std Max           -0.21049386
Policy log std Min           -2.53127
Z mean eval                  1.08092
Z variance eval              0.0062038004
total_rewards                [ 189.53498622 3742.74435856 3211.1947493   675.75417676  582.95049977
 3834.19649167 3592.12736632 2694.60807727 1888.76252237  284.49066549]
total_rewards_mean           2069.6363893719977
total_rewards_std            1443.3319424249084
total_rewards_max            3834.1964916733914
total_rewards_min            189.53498621866922
Number of train steps total  884000
Number of env steps total    1107000
Number of rollouts total     0
Train Time (s)               141.60639145364985
(Previous) Eval Time (s)     32.64221474574879
Sample Time (s)              26.96136165317148
Epoch Time (s)               201.20996785257012
Total Train Time (s)         40213.370061043184
Epoch                        220
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:43:09.038890 UTC | [2020_01_11_13_32_55] Iteration #220 | Epoch Duration: 189.1910948753357
2020-01-12 00:43:09.039237 UTC | [2020_01_11_13_32_55] Iteration #220 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0818202
Z variance train             0.0061926264
KL Divergence                25.673855
KL Loss                      2.5673854
QF Loss                      1101.39
VF Loss                      279.35934
Policy Loss                  -1272.6089
Q Predictions Mean           1271.937
Q Predictions Std            348.20026
Q Predictions Max            1523.9648
Q Predictions Min            38.838993
V Predictions Mean           1272.2292
V Predictions Std            346.3917
V Predictions Max            1516.4452
V Predictions Min            -15.326189
Log Pis Mean                 0.3089279
Log Pis Std                  3.1753209
Log Pis Max                  15.567063
Log Pis Min                  -9.035038
Policy mu Mean               -0.013910215
Policy mu Std                0.65620595
Policy mu Max                2.774839
Policy mu Min                -2.354434
Policy log std Mean          -0.98115456
Policy log std Std           0.29980278
Policy log std Max           -0.1290828
Policy log std Min           -3.218794
Z mean eval                  1.1058227
Z variance eval              0.012495899
total_rewards                [1482.62598512 1474.8583363  3802.41807834  905.7180805  1304.51564311
 1565.50819842  752.30757836 3617.7558786  2372.34778025 3723.94018909]
total_rewards_mean           2100.199574808651
total_rewards_std            1133.409840344455
total_rewards_max            3802.418078339573
total_rewards_min            752.3075783566096
Number of train steps total  888000
Number of env steps total    1112000
Number of rollouts total     0
Train Time (s)               134.64257027674466
(Previous) Eval Time (s)     20.62284307507798
Sample Time (s)              25.782081163022667
Epoch Time (s)               181.0474945148453
Total Train Time (s)         40400.76148490934
Epoch                        221
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:46:16.433115 UTC | [2020_01_11_13_32_55] Iteration #221 | Epoch Duration: 187.39372038841248
2020-01-12 00:46:16.433309 UTC | [2020_01_11_13_32_55] Iteration #221 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1058385
Z variance train             0.012512868
KL Divergence                24.612823
KL Loss                      2.4612825
QF Loss                      6485.1465
VF Loss                      406.35648
Policy Loss                  -1254.7711
Q Predictions Mean           1251.1189
Q Predictions Std            363.31085
Q Predictions Max            1483.48
Q Predictions Min            15.007399
V Predictions Mean           1249.0833
V Predictions Std            351.59674
V Predictions Max            1494.1852
V Predictions Min            20.91345
Log Pis Mean                 0.42224306
Log Pis Std                  3.415631
Log Pis Max                  14.039562
Log Pis Min                  -9.405972
Policy mu Mean               -0.005685879
Policy mu Std                0.6327137
Policy mu Max                2.5636995
Policy mu Min                -2.3497639
Policy log std Mean          -1.0198784
Policy log std Std           0.35462284
Policy log std Max           -0.07725763
Policy log std Min           -3.0604022
Z mean eval                  1.1116064
Z variance eval              0.009293703
total_rewards                [1809.70042565 3163.91726287 3779.94430465   63.71015221 1853.73716532
 2061.47587528  387.69937592 1038.73432845 3631.77147727 3332.57019237]
total_rewards_mean           2112.326055997877
total_rewards_std            1271.5858037101818
total_rewards_max            3779.944304654792
total_rewards_min            63.71015220983035
Number of train steps total  892000
Number of env steps total    1117000
Number of rollouts total     0
Train Time (s)               134.56466000387445
(Previous) Eval Time (s)     26.968620824161917
Sample Time (s)              24.392234277911484
Epoch Time (s)               185.92551510594785
Total Train Time (s)         40583.13171237288
Epoch                        222
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:49:18.805751 UTC | [2020_01_11_13_32_55] Iteration #222 | Epoch Duration: 182.372314453125
2020-01-12 00:49:18.805946 UTC | [2020_01_11_13_32_55] Iteration #222 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1113921
Z variance train             0.009271389
KL Divergence                24.641632
KL Loss                      2.4641633
QF Loss                      1305.0872
VF Loss                      385.02243
Policy Loss                  -1312.5774
Q Predictions Mean           1309.5352
Q Predictions Std            287.5902
Q Predictions Max            1517.301
Q Predictions Min            -0.30783188
V Predictions Mean           1309.9458
V Predictions Std            282.83344
V Predictions Max            1501.2993
V Predictions Min            10.772975
Log Pis Mean                 0.65921736
Log Pis Std                  2.9116101
Log Pis Max                  11.9026165
Log Pis Min                  -8.992328
Policy mu Mean               0.03481049
Policy mu Std                0.66464967
Policy mu Max                2.65883
Policy mu Min                -2.1336405
Policy log std Mean          -1.016572
Policy log std Std           0.2897361
Policy log std Max           0.09254098
Policy log std Min           -2.387194
Z mean eval                  1.1486063
Z variance eval              0.0131363105
total_rewards                [1816.80009962 3294.81222141 1622.84954252 3571.89793025 3533.47319676
 3334.47585311 2747.63993308 1144.38696711  838.40267277  437.67095494]
total_rewards_mean           2234.240937155352
total_rewards_std            1139.6536171779542
total_rewards_max            3571.897930249381
total_rewards_min            437.6709549392323
Number of train steps total  896000
Number of env steps total    1122000
Number of rollouts total     0
Train Time (s)               136.3380500287749
(Previous) Eval Time (s)     23.415113179944456
Sample Time (s)              23.989272168371826
Epoch Time (s)               183.74243537709117
Total Train Time (s)         40773.19757097494
Epoch                        223
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:52:28.875654 UTC | [2020_01_11_13_32_55] Iteration #223 | Epoch Duration: 190.06956338882446
2020-01-12 00:52:28.875890 UTC | [2020_01_11_13_32_55] Iteration #223 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.154849
Z variance train             0.013165407
KL Divergence                24.373327
KL Loss                      2.4373329
QF Loss                      1415.7732
VF Loss                      366.51993
Policy Loss                  -1312.793
Q Predictions Mean           1312.1049
Q Predictions Std            299.63208
Q Predictions Max            1545.7242
Q Predictions Min            0.13580525
V Predictions Mean           1311.8616
V Predictions Std            298.6643
V Predictions Max            1550.5197
V Predictions Min            3.7892642
Log Pis Mean                 0.27615964
Log Pis Std                  2.9327748
Log Pis Max                  14.45008
Log Pis Min                  -6.6786804
Policy mu Mean               0.0044922517
Policy mu Std                0.6343506
Policy mu Max                2.642264
Policy mu Min                -2.2974865
Policy log std Mean          -0.9974288
Policy log std Std           0.29518482
Policy log std Max           -0.03906846
Policy log std Min           -2.240316
Z mean eval                  1.1149518
Z variance eval              0.015961614
total_rewards                [3448.69931119 1268.55614093 3475.09742688 3713.7264211  3441.01845338
 3555.66904772  971.14513031  353.53725741 3574.65284973 1098.45351277]
total_rewards_mean           2490.0555551430343
total_rewards_std            1300.127145610009
total_rewards_max            3713.7264210962267
total_rewards_min            353.53725741337325
Number of train steps total  900000
Number of env steps total    1127000
Number of rollouts total     0
Train Time (s)               144.14647118700668
(Previous) Eval Time (s)     29.74189442396164
Sample Time (s)              25.451589991804212
Epoch Time (s)               199.33995560277253
Total Train Time (s)         40972.87475721538
Epoch                        224
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:55:48.555411 UTC | [2020_01_11_13_32_55] Iteration #224 | Epoch Duration: 199.67926478385925
2020-01-12 00:55:48.555599 UTC | [2020_01_11_13_32_55] Iteration #224 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1199565
Z variance train             0.015908545
KL Divergence                23.42346
KL Loss                      2.342346
QF Loss                      1951.4004
VF Loss                      953.498
Policy Loss                  -1254.3142
Q Predictions Mean           1252.8463
Q Predictions Std            361.61322
Q Predictions Max            1504.668
Q Predictions Min            -18.167181
V Predictions Mean           1252.9003
V Predictions Std            350.81174
V Predictions Max            1498.7091
V Predictions Min            -51.47367
Log Pis Mean                 0.89632463
Log Pis Std                  3.7752316
Log Pis Max                  15.581293
Log Pis Min                  -8.728551
Policy mu Mean               -0.007529107
Policy mu Std                0.6691036
Policy mu Max                3.4138691
Policy mu Min                -2.3384194
Policy log std Mean          -1.050328
Policy log std Std           0.38820675
Policy log std Max           0.58115256
Policy log std Min           -3.2017832
Z mean eval                  1.073714
Z variance eval              0.02457396
total_rewards                [3668.44085105  692.76992604 3776.62107784  627.03729112 2807.07436384
 3867.54359058 3876.80941554 3805.75491816 3737.68584433 1010.05674452]
total_rewards_mean           2786.9794023018067
total_rewards_std            1351.3837663053557
total_rewards_max            3876.809415538325
total_rewards_min            627.0372911169488
Number of train steps total  904000
Number of env steps total    1132000
Number of rollouts total     0
Train Time (s)               142.42123942496255
(Previous) Eval Time (s)     30.080877903848886
Sample Time (s)              23.95302554126829
Epoch Time (s)               196.45514287007973
Total Train Time (s)         41168.918506358285
Epoch                        225
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:59:04.603135 UTC | [2020_01_11_13_32_55] Iteration #225 | Epoch Duration: 196.04734897613525
2020-01-12 00:59:04.603462 UTC | [2020_01_11_13_32_55] Iteration #225 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0719025
Z variance train             0.024427127
KL Divergence                23.31838
KL Loss                      2.3318381
QF Loss                      1331.5648
VF Loss                      411.12668
Policy Loss                  -1271.8503
Q Predictions Mean           1273.9231
Q Predictions Std            364.49268
Q Predictions Max            1519.114
Q Predictions Min            -22.012918
V Predictions Mean           1265.1421
V Predictions Std            362.4119
V Predictions Max            1499.6602
V Predictions Min            -64.339005
Log Pis Mean                 0.8846361
Log Pis Std                  3.3464544
Log Pis Max                  14.2732315
Log Pis Min                  -6.0490694
Policy mu Mean               -0.0067179045
Policy mu Std                0.68061376
Policy mu Max                3.1639605
Policy mu Min                -2.7447362
Policy log std Mean          -1.0323623
Policy log std Std           0.33705407
Policy log std Max           -0.10887021
Policy log std Min           -2.6243725
Z mean eval                  1.1169382
Z variance eval              0.018494133
total_rewards                [1942.39775257 3742.11524872 3040.78336135  847.21775474  441.33464237
 1599.71795624  107.04357997  855.08939792 3525.39023441  790.22414289]
total_rewards_mean           1689.1314071186007
total_rewards_std            1255.3154323431895
total_rewards_max            3742.1152487208064
total_rewards_min            107.04357996931049
Number of train steps total  908000
Number of env steps total    1137000
Number of rollouts total     0
Train Time (s)               142.88205075077713
(Previous) Eval Time (s)     29.672742359805852
Sample Time (s)              26.46447065845132
Epoch Time (s)               199.0192637690343
Total Train Time (s)         41357.92241969751
Epoch                        226
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:02:13.609862 UTC | [2020_01_11_13_32_55] Iteration #226 | Epoch Duration: 189.00623846054077
2020-01-12 01:02:13.610053 UTC | [2020_01_11_13_32_55] Iteration #226 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1185104
Z variance train             0.018446252
KL Divergence                24.568302
KL Loss                      2.4568303
QF Loss                      870.0429
VF Loss                      598.3389
Policy Loss                  -1309.2672
Q Predictions Mean           1307.1259
Q Predictions Std            280.30756
Q Predictions Max            1512.0591
Q Predictions Min            -26.877516
V Predictions Mean           1309.3613
V Predictions Std            277.1038
V Predictions Max            1508.8228
V Predictions Min            -4.9379363
Log Pis Mean                 0.53220236
Log Pis Std                  3.2128732
Log Pis Max                  10.898887
Log Pis Min                  -6.2125773
Policy mu Mean               -0.0423786
Policy mu Std                0.6656665
Policy mu Max                2.277436
Policy mu Min                -2.5567863
Policy log std Mean          -1.0115917
Policy log std Std           0.32588887
Policy log std Max           -0.14030206
Policy log std Min           -2.6417031
Z mean eval                  1.0918646
Z variance eval              0.011736362
total_rewards                [ 807.9770964  3716.51527401 2000.39953335  679.37170834 3645.76722029
 2472.56315628 1673.96682654  333.82878171  689.24965474 3880.44696768]
total_rewards_mean           1990.0086219330792
total_rewards_std            1310.6807910919938
total_rewards_max            3880.446967676436
total_rewards_min            333.8287817125921
Number of train steps total  912000
Number of env steps total    1142000
Number of rollouts total     0
Train Time (s)               142.3188235987909
(Previous) Eval Time (s)     19.65929233795032
Sample Time (s)              24.692460472229868
Epoch Time (s)               186.6705764089711
Total Train Time (s)         41546.59022366628
Epoch                        227
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:05:22.280548 UTC | [2020_01_11_13_32_55] Iteration #227 | Epoch Duration: 188.6703634262085
2020-01-12 01:05:22.280737 UTC | [2020_01_11_13_32_55] Iteration #227 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0937958
Z variance train             0.011758627
KL Divergence                25.352594
KL Loss                      2.5352595
QF Loss                      397.19376
VF Loss                      97.48872
Policy Loss                  -1269.8619
Q Predictions Mean           1272.436
Q Predictions Std            349.61777
Q Predictions Max            1518.542
Q Predictions Min            -14.234312
V Predictions Mean           1267.7211
V Predictions Std            348.7234
V Predictions Max            1504.7859
V Predictions Min            -32.947426
Log Pis Mean                 -0.06331875
Log Pis Std                  2.6726027
Log Pis Max                  8.274482
Log Pis Min                  -8.230217
Policy mu Mean               -9.0443296e-05
Policy mu Std                0.5940399
Policy mu Max                2.0216806
Policy mu Min                -2.213365
Policy log std Mean          -0.97320217
Policy log std Std           0.27813038
Policy log std Max           -0.14820337
Policy log std Min           -2.054911
Z mean eval                  1.1324246
Z variance eval              0.015616288
total_rewards                [3818.09682257  140.47228853 3019.55872991 3640.01779255 3776.54880431
 3876.53428899 3588.85680059 3673.79141284  585.62953974 3750.63967992]
total_rewards_mean           2987.0146159947008
total_rewards_std            1334.8869807518263
total_rewards_max            3876.534288992972
total_rewards_min            140.47228852710603
Number of train steps total  916000
Number of env steps total    1147000
Number of rollouts total     0
Train Time (s)               133.56472975621
(Previous) Eval Time (s)     21.658657957799733
Sample Time (s)              24.672124478500336
Epoch Time (s)               179.89551219251007
Total Train Time (s)         41738.970371694304
Epoch                        228
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:08:34.664144 UTC | [2020_01_11_13_32_55] Iteration #228 | Epoch Duration: 192.38327288627625
2020-01-12 01:08:34.664335 UTC | [2020_01_11_13_32_55] Iteration #228 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1331587
Z variance train             0.015654156
KL Divergence                25.667831
KL Loss                      2.5667832
QF Loss                      1403.8076
VF Loss                      207.20784
Policy Loss                  -1293.5707
Q Predictions Mean           1291.8024
Q Predictions Std            314.13406
Q Predictions Max            1520.4401
Q Predictions Min            -0.76774406
V Predictions Mean           1296.061
V Predictions Std            310.29346
V Predictions Max            1531.1339
V Predictions Min            -1.0984614
Log Pis Mean                 0.56024575
Log Pis Std                  3.1612165
Log Pis Max                  12.157008
Log Pis Min                  -7.7024317
Policy mu Mean               0.0072372835
Policy mu Std                0.6496368
Policy mu Max                3.754754
Policy mu Min                -2.727748
Policy log std Mean          -1.0338279
Policy log std Std           0.31913933
Policy log std Max           -0.117219806
Policy log std Min           -2.349689
Z mean eval                  1.0939689
Z variance eval              0.014192233
total_rewards                [ 833.85070206 1995.79934691 1151.00558751  687.13152845 3246.7500388
 3521.43618252  682.89318787 3313.81415294 1835.50723021 1338.83842265]
total_rewards_mean           1860.7026379921513
total_rewards_std            1067.9196420328722
total_rewards_max            3521.436182523079
total_rewards_min            682.8931878731847
Number of train steps total  920000
Number of env steps total    1152000
Number of rollouts total     0
Train Time (s)               133.6775011071004
(Previous) Eval Time (s)     34.14605333190411
Sample Time (s)              23.862692300230265
Epoch Time (s)               191.68624673923478
Total Train Time (s)         41917.840338435024
Epoch                        229
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:11:33.535060 UTC | [2020_01_11_13_32_55] Iteration #229 | Epoch Duration: 178.87061214447021
2020-01-12 01:11:33.535179 UTC | [2020_01_11_13_32_55] Iteration #229 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0852699
Z variance train             0.014232064
KL Divergence                24.866861
KL Loss                      2.4866862
QF Loss                      811.2523
VF Loss                      225.60869
Policy Loss                  -1284.2063
Q Predictions Mean           1286.5544
Q Predictions Std            348.2629
Q Predictions Max            1520.4188
Q Predictions Min            6.0769033
V Predictions Mean           1282.4629
V Predictions Std            347.3037
V Predictions Max            1500.8677
V Predictions Min            -48.32183
Log Pis Mean                 0.39436102
Log Pis Std                  3.6336298
Log Pis Max                  19.919683
Log Pis Min                  -10.618059
Policy mu Mean               -0.037692025
Policy mu Std                0.66106546
Policy mu Max                2.411751
Policy mu Min                -2.7973244
Policy log std Mean          -0.9973864
Policy log std Std           0.30585748
Policy log std Max           -0.10598534
Policy log std Min           -2.5831587
Z mean eval                  1.1304312
Z variance eval              0.019829892
total_rewards                [1493.61277926 2997.65616288 3507.89350897 3573.9437133  2578.05265828
 3752.25282931  830.28841023  408.03483868 3870.79567729 1170.64407954]
total_rewards_mean           2418.317465773879
total_rewards_std            1254.8989322889809
total_rewards_max            3870.7956772881553
total_rewards_min            408.03483868365817
Number of train steps total  924000
Number of env steps total    1157000
Number of rollouts total     0
Train Time (s)               140.8360832571052
(Previous) Eval Time (s)     21.33012383012101
Sample Time (s)              23.832105798646808
Epoch Time (s)               185.99831288587302
Total Train Time (s)         42112.41651728656
Epoch                        230
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:14:48.115018 UTC | [2020_01_11_13_32_55] Iteration #230 | Epoch Duration: 194.57971262931824
2020-01-12 01:14:48.115465 UTC | [2020_01_11_13_32_55] Iteration #230 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1308423
Z variance train             0.019842839
KL Divergence                24.695665
KL Loss                      2.4695666
QF Loss                      1296.1259
VF Loss                      394.8526
Policy Loss                  -1266.1719
Q Predictions Mean           1261.0234
Q Predictions Std            379.42258
Q Predictions Max            1484.1409
Q Predictions Min            -33.251953
V Predictions Mean           1265.9255
V Predictions Std            360.91638
V Predictions Max            1488.1051
V Predictions Min            -35.71776
Log Pis Mean                 0.25599238
Log Pis Std                  3.3483083
Log Pis Max                  15.689112
Log Pis Min                  -6.3374743
Policy mu Mean               -0.00062961504
Policy mu Std                0.6218385
Policy mu Max                2.6838183
Policy mu Min                -2.5279903
Policy log std Mean          -1.0202571
Policy log std Std           0.34636766
Policy log std Max           0.30463994
Policy log std Min           -2.5904386
Z mean eval                  1.0917704
Z variance eval              0.013418767
total_rewards                [1922.58329408  154.58094192 2786.23140707  605.46810954 1230.94204764
 1534.7110831  3473.68680668 1291.29908577  864.62857674  -66.3942228 ]
total_rewards_mean           1379.773712973611
total_rewards_std            1056.8180755057135
total_rewards_max            3473.6868066789484
total_rewards_min            -66.394222797589
Number of train steps total  928000
Number of env steps total    1162000
Number of rollouts total     0
Train Time (s)               142.12835807772353
(Previous) Eval Time (s)     29.911130152177066
Sample Time (s)              26.705602574627846
Epoch Time (s)               198.74509080452845
Total Train Time (s)         42304.155556078535
Epoch                        231
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:17:59.857090 UTC | [2020_01_11_13_32_55] Iteration #231 | Epoch Duration: 191.74148035049438
2020-01-12 01:17:59.857303 UTC | [2020_01_11_13_32_55] Iteration #231 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0909982
Z variance train             0.013464024
KL Divergence                25.234203
KL Loss                      2.5234203
QF Loss                      729.943
VF Loss                      239.8881
Policy Loss                  -1249.5857
Q Predictions Mean           1250.3683
Q Predictions Std            410.75482
Q Predictions Max            1570.9822
Q Predictions Min            -41.86465
V Predictions Mean           1251.9294
V Predictions Std            408.20425
V Predictions Max            1546.3418
V Predictions Min            -47.744987
Log Pis Mean                 0.28292185
Log Pis Std                  3.2579274
Log Pis Max                  16.27496
Log Pis Min                  -7.207704
Policy mu Mean               -0.0090999035
Policy mu Std                0.6603421
Policy mu Max                3.0651796
Policy mu Min                -2.8311617
Policy log std Mean          -0.9727833
Policy log std Std           0.33001742
Policy log std Max           -0.060336232
Policy log std Min           -3.007756
Z mean eval                  1.1126122
Z variance eval              0.014385499
total_rewards                [3494.88368214 1819.52542759 3957.48162016 3741.20659459 3991.33277174
 3683.44279031 1328.6994877  3936.25449001 1024.97535905  485.22521775]
total_rewards_mean           2746.30274410334
total_rewards_std            1334.369982032343
total_rewards_max            3991.3327717362363
total_rewards_min            485.2252177548609
Number of train steps total  932000
Number of env steps total    1167000
Number of rollouts total     0
Train Time (s)               141.511988859158
(Previous) Eval Time (s)     22.907135244924575
Sample Time (s)              26.91302130371332
Epoch Time (s)               191.3321454077959
Total Train Time (s)         42500.98313027108
Epoch                        232
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:21:16.687431 UTC | [2020_01_11_13_32_55] Iteration #232 | Epoch Duration: 196.82998919487
2020-01-12 01:21:16.687613 UTC | [2020_01_11_13_32_55] Iteration #232 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1097248
Z variance train             0.01427986
KL Divergence                25.84386
KL Loss                      2.584386
QF Loss                      1731.2622
VF Loss                      262.68542
Policy Loss                  -1251.6057
Q Predictions Mean           1255.6359
Q Predictions Std            405.94492
Q Predictions Max            1535.552
Q Predictions Min            -49.4687
V Predictions Mean           1259.3384
V Predictions Std            406.65204
V Predictions Max            1516.5984
V Predictions Min            -38.819504
Log Pis Mean                 0.07077549
Log Pis Std                  3.1830018
Log Pis Max                  12.176937
Log Pis Min                  -7.2391853
Policy mu Mean               -0.03008537
Policy mu Std                0.61649793
Policy mu Max                2.52269
Policy mu Min                -2.0901897
Policy log std Mean          -1.0026889
Policy log std Std           0.33768663
Policy log std Max           0.15134811
Policy log std Min           -2.7032666
Z mean eval                  1.0896224
Z variance eval              0.015930312
total_rewards                [1219.86652235 3691.6143301  1089.7706966  3522.10195385 3586.7624787
 1480.68825839 3596.38917427 3614.04018004 3676.95381985 3782.49702195]
total_rewards_mean           2926.068443608466
total_rewards_std            1094.0751847737474
total_rewards_max            3782.497021946302
total_rewards_min            1089.7706966015462
Number of train steps total  936000
Number of env steps total    1172000
Number of rollouts total     0
Train Time (s)               143.10426920605823
(Previous) Eval Time (s)     28.404561972711235
Sample Time (s)              26.936016423627734
Epoch Time (s)               198.4448476023972
Total Train Time (s)         42705.24721303815
Epoch                        233
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:24:40.954678 UTC | [2020_01_11_13_32_55] Iteration #233 | Epoch Duration: 204.2669312953949
2020-01-12 01:24:40.954876 UTC | [2020_01_11_13_32_55] Iteration #233 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0877376
Z variance train             0.015937563
KL Divergence                24.99393
KL Loss                      2.4993932
QF Loss                      1298.1342
VF Loss                      1081.2346
Policy Loss                  -1287.4752
Q Predictions Mean           1290.6006
Q Predictions Std            330.66293
Q Predictions Max            1500.3173
Q Predictions Min            -39.433628
V Predictions Mean           1289.8513
V Predictions Std            332.3336
V Predictions Max            1498.8451
V Predictions Min            -58.314312
Log Pis Mean                 0.7077663
Log Pis Std                  3.0737863
Log Pis Max                  14.72376
Log Pis Min                  -9.407326
Policy mu Mean               0.004690918
Policy mu Std                0.6456781
Policy mu Max                2.360896
Policy mu Min                -2.7703135
Policy log std Mean          -1.0407724
Policy log std Std           0.3389514
Policy log std Max           -0.076281905
Policy log std Min           -2.98283
Z mean eval                  1.1100242
Z variance eval              0.021488687
total_rewards                [3610.42672353 3575.47111351  975.65635487 2766.02323753 3689.51625234
 1932.8601773  3812.44712209 2631.31109412 3618.773459   2440.08990384]
total_rewards_mean           2905.257543811789
total_rewards_std            887.3184650677003
total_rewards_max            3812.4471220855303
total_rewards_min            975.6563548656294
Number of train steps total  940000
Number of env steps total    1177000
Number of rollouts total     0
Train Time (s)               137.9006255227141
(Previous) Eval Time (s)     34.226230308413506
Sample Time (s)              26.974111033137888
Epoch Time (s)               199.1009668642655
Total Train Time (s)         42900.222753489856
Epoch                        234
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:27:55.932479 UTC | [2020_01_11_13_32_55] Iteration #234 | Epoch Duration: 194.97747898101807
2020-01-12 01:27:55.932605 UTC | [2020_01_11_13_32_55] Iteration #234 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1056355
Z variance train             0.021450981
KL Divergence                24.099234
KL Loss                      2.4099233
QF Loss                      3076.5474
VF Loss                      323.86624
Policy Loss                  -1303.1844
Q Predictions Mean           1302.2319
Q Predictions Std            339.08157
Q Predictions Max            1546.6464
Q Predictions Min            -38.10552
V Predictions Mean           1295.2219
V Predictions Std            333.94135
V Predictions Max            1551.3104
V Predictions Min            -41.939335
Log Pis Mean                 0.6430027
Log Pis Std                  3.7063513
Log Pis Max                  19.748001
Log Pis Min                  -7.163849
Policy mu Mean               0.0503954
Policy mu Std                0.6331047
Policy mu Max                2.9130275
Policy mu Min                -3.014654
Policy log std Mean          -1.0443811
Policy log std Std           0.3814682
Policy log std Max           -0.16541278
Policy log std Min           -3.289426
Z mean eval                  1.1139661
Z variance eval              0.014916171
total_rewards                [1873.97984177 3766.12209714 3491.35323603 3612.4621901  3297.26403028
 3645.40711281 1449.28761195 3674.94255611 3634.98277957 1224.26378728]
total_rewards_mean           2967.006524304109
total_rewards_std            968.6140378871363
total_rewards_max            3766.1220971426574
total_rewards_min            1224.263787279939
Number of train steps total  944000
Number of env steps total    1182000
Number of rollouts total     0
Train Time (s)               132.66529058199376
(Previous) Eval Time (s)     30.102355488575995
Sample Time (s)              23.205521180760115
Epoch Time (s)               185.97316725132987
Total Train Time (s)         43087.6554558631
Epoch                        235
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:31:03.366982 UTC | [2020_01_11_13_32_55] Iteration #235 | Epoch Duration: 187.43429279327393
2020-01-12 01:31:03.367104 UTC | [2020_01_11_13_32_55] Iteration #235 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1163349
Z variance train             0.014939411
KL Divergence                25.319454
KL Loss                      2.5319455
QF Loss                      1636.4121
VF Loss                      484.3739
Policy Loss                  -1256.8484
Q Predictions Mean           1252.5997
Q Predictions Std            389.30865
Q Predictions Max            1559.7097
Q Predictions Min            -42.46092
V Predictions Mean           1252.8663
V Predictions Std            381.3186
V Predictions Max            1550.8424
V Predictions Min            -37.75999
Log Pis Mean                 0.4017341
Log Pis Std                  3.2143655
Log Pis Max                  11.393919
Log Pis Min                  -7.2598495
Policy mu Mean               0.012377116
Policy mu Std                0.6409511
Policy mu Max                2.9130425
Policy mu Min                -2.7732258
Policy log std Mean          -0.99773115
Policy log std Std           0.3329019
Policy log std Max           -0.16026258
Policy log std Min           -2.8223135
Z mean eval                  1.110422
Z variance eval              0.015009776
total_rewards                [1441.14180906 3721.13374344 3671.92264999 3065.28922384 3069.11482868
 3533.24129507 3628.42020271 1992.90444478 2777.08386173 3700.4422716 ]
total_rewards_mean           3060.0694330902625
total_rewards_std            748.8871493877009
total_rewards_max            3721.133743443103
total_rewards_min            1441.1418090607983
Number of train steps total  948000
Number of env steps total    1187000
Number of rollouts total     0
Train Time (s)               136.39296751003712
(Previous) Eval Time (s)     31.563106569927186
Sample Time (s)              25.056183229666203
Epoch Time (s)               193.0122573096305
Total Train Time (s)         43279.49162882054
Epoch                        236
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:34:15.206718 UTC | [2020_01_11_13_32_55] Iteration #236 | Epoch Duration: 191.83951258659363
2020-01-12 01:34:15.206907 UTC | [2020_01_11_13_32_55] Iteration #236 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1105306
Z variance train             0.014967183
KL Divergence                24.936438
KL Loss                      2.4936438
QF Loss                      1251.8053
VF Loss                      600.88824
Policy Loss                  -1297.4615
Q Predictions Mean           1302.2572
Q Predictions Std            328.2263
Q Predictions Max            1533.6129
Q Predictions Min            -17.794859
V Predictions Mean           1307.2075
V Predictions Std            325.3399
V Predictions Max            1536.4559
V Predictions Min            -19.750114
Log Pis Mean                 0.27798575
Log Pis Std                  3.172148
Log Pis Max                  14.762722
Log Pis Min                  -7.5208416
Policy mu Mean               -0.013139376
Policy mu Std                0.6179572
Policy mu Max                3.0009844
Policy mu Min                -2.5379865
Policy log std Mean          -1.0311961
Policy log std Std           0.32750314
Policy log std Max           0.046326756
Policy log std Min           -2.7697463
Z mean eval                  1.15851
Z variance eval              0.007819412
total_rewards                [ 716.31536478   74.45126434 3495.6769858  1699.37721909 1109.02498943
 3806.95959618 3615.86904783  400.88455236 1189.00939934 3003.16506648]
total_rewards_mean           1911.0733485633784
total_rewards_std            1359.967526678433
total_rewards_max            3806.959596178011
total_rewards_min            74.45126434258458
Number of train steps total  952000
Number of env steps total    1192000
Number of rollouts total     0
Train Time (s)               144.19030097080395
(Previous) Eval Time (s)     30.390049200039357
Sample Time (s)              26.77108589420095
Epoch Time (s)               201.35143606504425
Total Train Time (s)         43475.840961569455
Epoch                        237
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:37:31.559272 UTC | [2020_01_11_13_32_55] Iteration #237 | Epoch Duration: 196.35218334197998
2020-01-12 01:37:31.559474 UTC | [2020_01_11_13_32_55] Iteration #237 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1581475
Z variance train             0.007832257
KL Divergence                26.882393
KL Loss                      2.6882393
QF Loss                      942.7141
VF Loss                      375.2742
Policy Loss                  -1267.2789
Q Predictions Mean           1266.1588
Q Predictions Std            401.60355
Q Predictions Max            1530.058
Q Predictions Min            -73.516014
V Predictions Mean           1260.5386
V Predictions Std            393.2239
V Predictions Max            1505.7352
V Predictions Min            -70.94702
Log Pis Mean                 0.02135352
Log Pis Std                  3.0212727
Log Pis Max                  13.478744
Log Pis Min                  -11.400648
Policy mu Mean               -0.044494934
Policy mu Std                0.62343776
Policy mu Max                2.7355008
Policy mu Min                -2.4251235
Policy log std Mean          -1.0168493
Policy log std Std           0.34404805
Policy log std Max           -0.08838773
Policy log std Min           -2.897729
Z mean eval                  1.1324618
Z variance eval              0.009878302
total_rewards                [3567.8604963  3781.48268933 3782.71387371 3650.99619999 2646.25797126
 3603.72778131 3921.78351849 3705.85078092  686.61787391 3842.04899868]
total_rewards_mean           3318.9340183902123
total_rewards_std            940.7838716087172
total_rewards_max            3921.7835184945498
total_rewards_min            686.6178739142571
Number of train steps total  956000
Number of env steps total    1197000
Number of rollouts total     0
Train Time (s)               143.22559531684965
(Previous) Eval Time (s)     25.39037266978994
Sample Time (s)              24.931523168925196
Epoch Time (s)               193.54749115556479
Total Train Time (s)         43676.72705504624
Epoch                        238
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:40:52.449383 UTC | [2020_01_11_13_32_55] Iteration #238 | Epoch Duration: 200.88974857330322
2020-01-12 01:40:52.449694 UTC | [2020_01_11_13_32_55] Iteration #238 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.133194
Z variance train             0.00985317
KL Divergence                27.293947
KL Loss                      2.7293947
QF Loss                      689.1727
VF Loss                      200.27126
Policy Loss                  -1317.3967
Q Predictions Mean           1320.5798
Q Predictions Std            323.85214
Q Predictions Max            1560.541
Q Predictions Min            3.032271
V Predictions Mean           1316.0085
V Predictions Std            324.19733
V Predictions Max            1551.675
V Predictions Min            2.7554493
Log Pis Mean                 0.435826
Log Pis Std                  3.2
Log Pis Max                  13.021786
Log Pis Min                  -9.371531
Policy mu Mean               0.017252682
Policy mu Std                0.6102956
Policy mu Max                2.5661833
Policy mu Min                -1.957608
Policy log std Mean          -1.0389713
Policy log std Std           0.32777786
Policy log std Max           -0.1250394
Policy log std Min           -2.826705
Z mean eval                  1.088959
Z variance eval              0.014141597
total_rewards                [3345.61905205  383.85268731 3912.31773446 3762.52714366 2380.91424747
 1609.02558537 3888.29162084 3535.97872213  479.83759006  346.18279725]
total_rewards_mean           2364.4547180592413
total_rewards_std            1453.5009127539993
total_rewards_max            3912.3177344601604
total_rewards_min            346.1827972482572
Number of train steps total  960000
Number of env steps total    1202000
Number of rollouts total     0
Train Time (s)               143.60343924723566
(Previous) Eval Time (s)     32.73226436600089
Sample Time (s)              25.414110955316573
Epoch Time (s)               201.74981456855312
Total Train Time (s)         43874.519920059945
Epoch                        239
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:44:10.244867 UTC | [2020_01_11_13_32_55] Iteration #239 | Epoch Duration: 197.79498100280762
2020-01-12 01:44:10.245139 UTC | [2020_01_11_13_32_55] Iteration #239 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0913858
Z variance train             0.014172825
KL Divergence                25.633606
KL Loss                      2.5633607
QF Loss                      841.1891
VF Loss                      209.61731
Policy Loss                  -1299.144
Q Predictions Mean           1298.3547
Q Predictions Std            364.63004
Q Predictions Max            1543.1305
Q Predictions Min            -48.123383
V Predictions Mean           1295.5791
V Predictions Std            366.0431
V Predictions Max            1542.8842
V Predictions Min            -75.97966
Log Pis Mean                 0.42620084
Log Pis Std                  3.1190236
Log Pis Max                  11.516611
Log Pis Min                  -8.718924
Policy mu Mean               -0.0044760015
Policy mu Std                0.651045
Policy mu Max                2.843618
Policy mu Min                -2.270577
Policy log std Mean          -0.9941054
Policy log std Std           0.30909345
Policy log std Max           -0.17138946
Policy log std Min           -2.3111494
Z mean eval                  1.1644706
Z variance eval              0.009456401
total_rewards                [3343.74639175 3685.89006426 1395.56266027 1602.43843319 3508.645739
  135.67473747 3757.5983039    15.38761221  -19.5818574  1055.45238369]
total_rewards_mean           1848.081446834977
total_rewards_std            1506.3507811719649
total_rewards_max            3757.5983038963777
total_rewards_min            -19.581857395130797
Number of train steps total  964000
Number of env steps total    1207000
Number of rollouts total     0
Train Time (s)               142.19008601270616
(Previous) Eval Time (s)     28.77710985718295
Sample Time (s)              25.57507944619283
Epoch Time (s)               196.54227531608194
Total Train Time (s)         44063.045611916576
Epoch                        240
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:47:18.773262 UTC | [2020_01_11_13_32_55] Iteration #240 | Epoch Duration: 188.52796411514282
2020-01-12 01:47:18.773449 UTC | [2020_01_11_13_32_55] Iteration #240 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1688219
Z variance train             0.009499229
KL Divergence                26.944036
KL Loss                      2.6944036
QF Loss                      3454.492
VF Loss                      1185.4095
Policy Loss                  -1290.6708
Q Predictions Mean           1289.7521
Q Predictions Std            380.87442
Q Predictions Max            1534.4591
Q Predictions Min            -19.645561
V Predictions Mean           1294.1024
V Predictions Std            384.55396
V Predictions Max            1526.5652
V Predictions Min            -12.241435
Log Pis Mean                 -0.030060465
Log Pis Std                  3.0218267
Log Pis Max                  11.064659
Log Pis Min                  -8.2362
Policy mu Mean               0.037603214
Policy mu Std                0.6173785
Policy mu Max                2.9152443
Policy mu Min                -2.069185
Policy log std Mean          -0.9731724
Policy log std Std           0.3103968
Policy log std Max           -0.2026074
Policy log std Min           -2.5936022
Z mean eval                  1.1753519
Z variance eval              0.011444651
total_rewards                [ 944.82428856 3661.52760336  232.24508087 3585.75978666 2149.13770741
  193.83618048 3474.1789522  1785.61863338  174.72826461 3582.49595935]
total_rewards_mean           1978.4352456877618
total_rewards_std            1443.9028377657257
total_rewards_max            3661.5276033561986
total_rewards_min            174.72826461451342
Number of train steps total  968000
Number of env steps total    1212000
Number of rollouts total     0
Train Time (s)               133.98773219808936
(Previous) Eval Time (s)     20.762494463007897
Sample Time (s)              24.56498747272417
Epoch Time (s)               179.31521413382143
Total Train Time (s)         44244.703221284784
Epoch                        241
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:50:20.434863 UTC | [2020_01_11_13_32_55] Iteration #241 | Epoch Duration: 181.66126775741577
2020-01-12 01:50:20.435092 UTC | [2020_01_11_13_32_55] Iteration #241 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1726946
Z variance train             0.011422023
KL Divergence                26.99541
KL Loss                      2.699541
QF Loss                      780.6435
VF Loss                      549.511
Policy Loss                  -1333.2849
Q Predictions Mean           1335.4377
Q Predictions Std            315.49265
Q Predictions Max            1530.0415
Q Predictions Min            -8.330686
V Predictions Mean           1332.5961
V Predictions Std            311.6021
V Predictions Max            1543.417
V Predictions Min            -7.0659103
Log Pis Mean                 0.32768527
Log Pis Std                  3.299513
Log Pis Max                  21.237217
Log Pis Min                  -7.9150486
Policy mu Mean               -0.013691283
Policy mu Std                0.6324988
Policy mu Max                2.789087
Policy mu Min                -3.8352017
Policy log std Mean          -1.0088351
Policy log std Std           0.30794728
Policy log std Max           0.04494953
Policy log std Min           -2.618804
Z mean eval                  1.1325271
Z variance eval              0.0151099935
total_rewards                [3460.61025918 3851.47522473 3545.81671391 3324.21858331 2764.79010983
  975.65553097 3768.19328031  169.04201718 1721.96612636  335.58562706]
total_rewards_mean           2391.7353472834993
total_rewards_std            1383.1326522706445
total_rewards_max            3851.475224729879
total_rewards_min            169.04201717545877
Number of train steps total  972000
Number of env steps total    1217000
Number of rollouts total     0
Train Time (s)               134.1103988350369
(Previous) Eval Time (s)     23.10815158067271
Sample Time (s)              24.22673498140648
Epoch Time (s)               181.4452853971161
Total Train Time (s)         44426.35800286569
Epoch                        242
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:53:22.091912 UTC | [2020_01_11_13_32_55] Iteration #242 | Epoch Duration: 181.65668296813965
2020-01-12 01:53:22.092098 UTC | [2020_01_11_13_32_55] Iteration #242 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1368511
Z variance train             0.015051298
KL Divergence                26.166264
KL Loss                      2.6166265
QF Loss                      1888.295
VF Loss                      211.37297
Policy Loss                  -1239.1936
Q Predictions Mean           1239.3129
Q Predictions Std            427.17798
Q Predictions Max            1518.4614
Q Predictions Min            -31.166645
V Predictions Mean           1242.2944
V Predictions Std            428.4424
V Predictions Max            1525.8688
V Predictions Min            -44.241642
Log Pis Mean                 0.2921156
Log Pis Std                  3.424816
Log Pis Max                  18.21449
Log Pis Min                  -9.633715
Policy mu Mean               -0.0038206778
Policy mu Std                0.642198
Policy mu Max                2.303379
Policy mu Min                -3.020439
Policy log std Mean          -0.9899671
Policy log std Std           0.35751995
Policy log std Max           0.02033019
Policy log std Min           -2.9643078
Z mean eval                  1.1269299
Z variance eval              0.011430195
total_rewards                [3382.56539056 3878.94861933  776.39064137 2296.15137994 3766.41898758
 3684.73416297 3824.04426012 3908.09329389 1151.15782113 2053.19139433]
total_rewards_mean           2872.1695951223182
total_rewards_std            1143.238712550185
total_rewards_max            3908.0932938911956
total_rewards_min            776.3906413713534
Number of train steps total  976000
Number of env steps total    1222000
Number of rollouts total     0
Train Time (s)               139.44774212921038
(Previous) Eval Time (s)     23.319254355039448
Sample Time (s)              24.954530193004757
Epoch Time (s)               187.7215266772546
Total Train Time (s)         44621.523712550756
Epoch                        243
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:56:37.259930 UTC | [2020_01_11_13_32_55] Iteration #243 | Epoch Duration: 195.16772317886353
2020-01-12 01:56:37.260050 UTC | [2020_01_11_13_32_55] Iteration #243 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1279461
Z variance train             0.011376546
KL Divergence                27.835136
KL Loss                      2.7835138
QF Loss                      1134.8625
VF Loss                      484.59076
Policy Loss                  -1266.8429
Q Predictions Mean           1270.2573
Q Predictions Std            408.75876
Q Predictions Max            1544.9232
Q Predictions Min            -47.290367
V Predictions Mean           1263.2954
V Predictions Std            405.94635
V Predictions Max            1533.0964
V Predictions Min            -46.534035
Log Pis Mean                 0.26728165
Log Pis Std                  3.6148088
Log Pis Max                  12.823219
Log Pis Min                  -8.152109
Policy mu Mean               -0.00030208565
Policy mu Std                0.6543576
Policy mu Max                2.7961087
Policy mu Min                -2.3547623
Policy log std Mean          -1.0274146
Policy log std Std           0.35236707
Policy log std Max           -0.11300254
Policy log std Min           -2.7676778
Z mean eval                  1.1151797
Z variance eval              0.01984673
total_rewards                [1853.36744393 2746.10456797 1537.59810044 2362.62368308  448.38364442
  835.82286392 2472.79709105 1019.61783336  252.32821523 3709.75242135]
total_rewards_mean           1723.8395864759527
total_rewards_std            1052.8987062275512
total_rewards_max            3709.7524213494207
total_rewards_min            252.3282152311314
Number of train steps total  980000
Number of env steps total    1227000
Number of rollouts total     0
Train Time (s)               141.76298629585654
(Previous) Eval Time (s)     30.765158767811954
Sample Time (s)              25.819460827391595
Epoch Time (s)               198.34760589106008
Total Train Time (s)         44816.81684222445
Epoch                        244
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:59:52.557747 UTC | [2020_01_11_13_32_55] Iteration #244 | Epoch Duration: 195.29758048057556
2020-01-12 01:59:52.558008 UTC | [2020_01_11_13_32_55] Iteration #244 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1128538
Z variance train             0.019809362
KL Divergence                26.898272
KL Loss                      2.6898272
QF Loss                      1894.8663
VF Loss                      1038.3296
Policy Loss                  -1333.9801
Q Predictions Mean           1332.7126
Q Predictions Std            329.35037
Q Predictions Max            1557.9342
Q Predictions Min            -53.25052
V Predictions Mean           1344.2373
V Predictions Std            319.75296
V Predictions Max            1554.4991
V Predictions Min            -67.054245
Log Pis Mean                 0.57851434
Log Pis Std                  3.5413933
Log Pis Max                  17.911678
Log Pis Min                  -8.833855
Policy mu Mean               0.036158755
Policy mu Std                0.66368145
Policy mu Max                3.017
Policy mu Min                -2.2481608
Policy log std Mean          -1.0193537
Policy log std Std           0.33570504
Policy log std Max           -0.122399986
Policy log std Min           -2.8555014
Z mean eval                  1.1213624
Z variance eval              0.020169267
total_rewards                [ 140.57540276 1451.07528691  924.00180172 3524.94024773 2027.39224436
  194.40314999 3030.26984501 3990.60381518  407.77685164 1645.5735704 ]
total_rewards_mean           1733.6612215697455
total_rewards_std            1322.0556749581917
total_rewards_max            3990.603815177054
total_rewards_min            140.57540276310215
Number of train steps total  984000
Number of env steps total    1232000
Number of rollouts total     0
Train Time (s)               141.37846103310585
(Previous) Eval Time (s)     27.714667288120836
Sample Time (s)              26.604271359741688
Epoch Time (s)               195.69739968096837
Total Train Time (s)         45008.638517956715
Epoch                        245
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:03:04.382210 UTC | [2020_01_11_13_32_55] Iteration #245 | Epoch Duration: 191.82402801513672
2020-01-12 02:03:04.382474 UTC | [2020_01_11_13_32_55] Iteration #245 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1223638
Z variance train             0.020015871
KL Divergence                26.912415
KL Loss                      2.6912415
QF Loss                      707.79803
VF Loss                      374.84695
Policy Loss                  -1303.947
Q Predictions Mean           1308.839
Q Predictions Std            388.8103
Q Predictions Max            1581.5214
Q Predictions Min            -33.196205
V Predictions Mean           1307.3932
V Predictions Std            385.21933
V Predictions Max            1581.564
V Predictions Min            -22.310133
Log Pis Mean                 0.3311638
Log Pis Std                  3.5277028
Log Pis Max                  14.770179
Log Pis Min                  -13.958178
Policy mu Mean               0.03281466
Policy mu Std                0.6362935
Policy mu Max                2.3961349
Policy mu Min                -3.132491
Policy log std Mean          -0.9899535
Policy log std Std           0.3380799
Policy log std Max           -0.16364157
Policy log std Min           -2.9151978
Z mean eval                  1.1580551
Z variance eval              0.020505998
total_rewards                [3702.00235485 2092.46410657 1472.2047727  3739.48059014 2070.02785928
 3730.73050193 3695.05728985 1671.87404213 3926.22359825 3261.63388593]
total_rewards_mean           2936.1699001631455
total_rewards_std            934.2834996244259
total_rewards_max            3926.2235982510556
total_rewards_min            1472.2047727026504
Number of train steps total  988000
Number of env steps total    1237000
Number of rollouts total     0
Train Time (s)               142.75010201334953
(Previous) Eval Time (s)     23.840914650354534
Sample Time (s)              26.992689998820424
Epoch Time (s)               193.5837066625245
Total Train Time (s)         45211.560838181525
Epoch                        246
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:06:27.307914 UTC | [2020_01_11_13_32_55] Iteration #246 | Epoch Duration: 202.92528629302979
2020-01-12 02:06:27.308110 UTC | [2020_01_11_13_32_55] Iteration #246 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1578913
Z variance train             0.02045059
KL Divergence                26.151358
KL Loss                      2.615136
QF Loss                      3768.8228
VF Loss                      568.8187
Policy Loss                  -1342.8008
Q Predictions Mean           1339.2378
Q Predictions Std            357.63336
Q Predictions Max            1561.7367
Q Predictions Min            -51.6456
V Predictions Mean           1334.4766
V Predictions Std            350.2149
V Predictions Max            1563.8987
V Predictions Min            -90.95708
Log Pis Mean                 0.39351636
Log Pis Std                  3.024094
Log Pis Max                  11.87376
Log Pis Min                  -7.354633
Policy mu Mean               -0.008755959
Policy mu Std                0.64499
Policy mu Max                2.6646924
Policy mu Min                -2.6324115
Policy log std Mean          -0.99893904
Policy log std Std           0.31045687
Policy log std Max           -0.059762955
Policy log std Min           -2.504779
Z mean eval                  1.156556
Z variance eval              0.014581989
total_rewards                [3470.91445818 1438.74981873 3756.62356668 1012.10671615 3955.88338819
  280.66774313 1715.08858302 3665.1393121  3748.66637346 3662.47097772]
total_rewards_mean           2670.6310937352696
total_rewards_std            1322.8711382849397
total_rewards_max            3955.883388191204
total_rewards_min            280.6677431255947
Number of train steps total  992000
Number of env steps total    1242000
Number of rollouts total     0
Train Time (s)               138.9271859130822
(Previous) Eval Time (s)     33.18208905681968
Sample Time (s)              26.725170857738703
Epoch Time (s)               198.8344458276406
Total Train Time (s)         45401.61141569959
Epoch                        247
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:09:37.364730 UTC | [2020_01_11_13_32_55] Iteration #247 | Epoch Duration: 190.05647706985474
2020-01-12 02:09:37.364926 UTC | [2020_01_11_13_32_55] Iteration #247 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1515402
Z variance train             0.0145533085
KL Divergence                26.287016
KL Loss                      2.6287017
QF Loss                      1447.5293
VF Loss                      233.59161
Policy Loss                  -1332.1948
Q Predictions Mean           1334.0753
Q Predictions Std            347.7211
Q Predictions Max            1545.3396
Q Predictions Min            -35.627365
V Predictions Mean           1331.2336
V Predictions Std            343.4716
V Predictions Max            1529.9019
V Predictions Min            -29.580078
Log Pis Mean                 0.19456053
Log Pis Std                  3.0545602
Log Pis Max                  10.870672
Log Pis Min                  -7.8602886
Policy mu Mean               0.0005236445
Policy mu Std                0.62210363
Policy mu Max                2.9154966
Policy mu Min                -2.5132172
Policy log std Mean          -1.005589
Policy log std Std           0.33005884
Policy log std Max           0.059523463
Policy log std Min           -2.7383108
Z mean eval                  1.1370829
Z variance eval              0.01319808
total_rewards                [3476.78667851  616.99287298 2175.93673695  839.9091928  1709.11108408
 1594.72997628 2885.76817158 1547.05935125 3737.78960954 1094.33496838]
total_rewards_mean           1967.8418642373992
total_rewards_std            1026.5852659047061
total_rewards_max            3737.789609539804
total_rewards_min            616.9928729828799
Number of train steps total  996000
Number of env steps total    1247000
Number of rollouts total     0
Train Time (s)               134.72840944305062
(Previous) Eval Time (s)     24.40372649533674
Sample Time (s)              25.62274016905576
Epoch Time (s)               184.75487610744312
Total Train Time (s)         45588.89906216599
Epoch                        248
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:12:44.652093 UTC | [2020_01_11_13_32_55] Iteration #248 | Epoch Duration: 187.28702235221863
2020-01-12 02:12:44.652293 UTC | [2020_01_11_13_32_55] Iteration #248 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1379465
Z variance train             0.01321693
KL Divergence                26.237068
KL Loss                      2.6237068
QF Loss                      807.96155
VF Loss                      158.0143
Policy Loss                  -1327.6819
Q Predictions Mean           1328.1816
Q Predictions Std            355.52786
Q Predictions Max            1576.3638
Q Predictions Min            3.4515018
V Predictions Mean           1328.1796
V Predictions Std            357.2264
V Predictions Max            1548.7595
V Predictions Min            12.343153
Log Pis Mean                 0.47399718
Log Pis Std                  3.1223052
Log Pis Max                  15.257924
Log Pis Min                  -7.8334675
Policy mu Mean               0.020945817
Policy mu Std                0.6408942
Policy mu Max                2.7381256
Policy mu Min                -2.619793
Policy log std Mean          -1.0058953
Policy log std Std           0.31035647
Policy log std Max           -0.14182311
Policy log std Min           -2.8960886
Z mean eval                  1.1185749
Z variance eval              0.014916432
total_rewards                [ 680.14853107  680.04330731 3793.41170762 3741.90453557 2426.85314439
  402.93601058 1910.84499199 1830.54245966 2084.70868876 3681.81475853]
total_rewards_mean           2123.320813546611
total_rewards_std            1232.3931278098867
total_rewards_max            3793.41170762428
total_rewards_min            402.9360105762852
Number of train steps total  1000000
Number of env steps total    1252000
Number of rollouts total     0
Train Time (s)               135.15688984515145
(Previous) Eval Time (s)     26.935564508195966
Sample Time (s)              25.40862980624661
Epoch Time (s)               187.50108415959403
Total Train Time (s)         45772.093382920604
Epoch                        249
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:15:47.850224 UTC | [2020_01_11_13_32_55] Iteration #249 | Epoch Duration: 183.19776725769043
2020-01-12 02:15:47.850543 UTC | [2020_01_11_13_32_55] Iteration #249 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1188751
Z variance train             0.014806509
KL Divergence                26.040401
KL Loss                      2.6040401
QF Loss                      730.0835
VF Loss                      209.659
Policy Loss                  -1352.7946
Q Predictions Mean           1357.6265
Q Predictions Std            311.90274
Q Predictions Max            1565.8385
Q Predictions Min            -36.613277
V Predictions Mean           1356.194
V Predictions Std            312.34213
V Predictions Max            1565.9419
V Predictions Min            7.5250525
Log Pis Mean                 0.7243804
Log Pis Std                  2.9358516
Log Pis Max                  10.872857
Log Pis Min                  -7.726671
Policy mu Mean               -0.0047915066
Policy mu Std                0.64962167
Policy mu Max                2.6393468
Policy mu Min                -2.6651382
Policy log std Mean          -1.0122964
Policy log std Std           0.2902726
Policy log std Max           -0.20952708
Policy log std Min           -2.7625246
Z mean eval                  1.1523206
Z variance eval              0.015769076
total_rewards                [ 886.73380227 1237.61007351  785.63831344 1979.74841845 1449.14051399
 3622.46596305 1025.37766328  433.56196865 1044.86368583 1965.52996942]
total_rewards_mean           1443.067037189411
total_rewards_std            862.9526957033348
total_rewards_max            3622.465963046524
total_rewards_min            433.56196864899886
Number of train steps total  1004000
Number of env steps total    1257000
Number of rollouts total     0
Train Time (s)               143.6788191460073
(Previous) Eval Time (s)     22.631871296092868
Sample Time (s)              25.6275395443663
Epoch Time (s)               191.93822998646647
Total Train Time (s)         45963.1556006507
Epoch                        250
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:18:58.915108 UTC | [2020_01_11_13_32_55] Iteration #250 | Epoch Duration: 191.0643436908722
2020-01-12 02:18:58.915348 UTC | [2020_01_11_13_32_55] Iteration #250 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1525174
Z variance train             0.015759401
KL Divergence                26.539137
KL Loss                      2.6539137
QF Loss                      1314.4711
VF Loss                      322.67273
Policy Loss                  -1316.1781
Q Predictions Mean           1317.5651
Q Predictions Std            385.41766
Q Predictions Max            1568.2949
Q Predictions Min            -37.490982
V Predictions Mean           1315.356
V Predictions Std            381.65198
V Predictions Max            1567.1768
V Predictions Min            -24.724775
Log Pis Mean                 0.36982757
Log Pis Std                  2.9581628
Log Pis Max                  12.922754
Log Pis Min                  -7.577347
Policy mu Mean               0.015113052
Policy mu Std                0.63959676
Policy mu Max                2.4075449
Policy mu Min                -2.749002
Policy log std Mean          -1.0147115
Policy log std Std           0.30615386
Policy log std Max           -0.23384911
Policy log std Min           -3.1614046
Z mean eval                  1.1290606
Z variance eval              0.012984122
total_rewards                [3541.97856964  286.96318022 3782.75414039 3684.36036831 3635.01606803
 3893.36447034 3895.85453685 3590.71170066 3898.5184871  2324.79365327]
total_rewards_mean           3253.4315174825715
total_rewards_std            1082.0890722687423
total_rewards_max            3898.5184871043666
total_rewards_min            286.963180224105
Number of train steps total  1008000
Number of env steps total    1262000
Number of rollouts total     0
Train Time (s)               142.4741244027391
(Previous) Eval Time (s)     21.757626479957253
Sample Time (s)              26.14381182845682
Epoch Time (s)               190.37556271115318
Total Train Time (s)         46161.07658210024
Epoch                        251
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:22:16.839199 UTC | [2020_01_11_13_32_55] Iteration #251 | Epoch Duration: 197.9236924648285
2020-01-12 02:22:16.839419 UTC | [2020_01_11_13_32_55] Iteration #251 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1306053
Z variance train             0.013022268
KL Divergence                25.901892
KL Loss                      2.5901892
QF Loss                      1169.9602
VF Loss                      232.22075
Policy Loss                  -1329.4541
Q Predictions Mean           1334.7871
Q Predictions Std            348.48077
Q Predictions Max            1610.1798
Q Predictions Min            -44.050674
V Predictions Mean           1326.4814
V Predictions Std            346.0333
V Predictions Max            1579.1483
V Predictions Min            -49.995636
Log Pis Mean                 0.3029853
Log Pis Std                  3.1267776
Log Pis Max                  11.125116
Log Pis Min                  -7.5566425
Policy mu Mean               0.011704933
Policy mu Std                0.6450909
Policy mu Max                2.3291185
Policy mu Min                -2.439324
Policy log std Mean          -1.0063587
Policy log std Std           0.32175976
Policy log std Max           -0.06304693
Policy log std Min           -2.8407893
Z mean eval                  1.1140399
Z variance eval              0.0105010215
total_rewards                [  -5.28742347  221.66160298 3781.39950072 3672.52408047 2904.04953601
 3675.00831746 2310.99167783 2840.95983912 1199.18359268 1462.49103207]
total_rewards_mean           2206.298175586323
total_rewards_std            1344.8385488255753
total_rewards_max            3781.399500724586
total_rewards_min            -5.287423467558632
Number of train steps total  1012000
Number of env steps total    1267000
Number of rollouts total     0
Train Time (s)               143.0154093708843
(Previous) Eval Time (s)     29.305410637985915
Sample Time (s)              26.10512592829764
Epoch Time (s)               198.42594593716785
Total Train Time (s)         46355.73311856529
Epoch                        252
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:25:31.499634 UTC | [2020_01_11_13_32_55] Iteration #252 | Epoch Duration: 194.6600522994995
2020-01-12 02:25:31.500395 UTC | [2020_01_11_13_32_55] Iteration #252 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1142442
Z variance train             0.01056169
KL Divergence                26.782055
KL Loss                      2.6782055
QF Loss                      719.93964
VF Loss                      179.99017
Policy Loss                  -1329.5787
Q Predictions Mean           1329.1978
Q Predictions Std            350.92847
Q Predictions Max            1586.4365
Q Predictions Min            15.15744
V Predictions Mean           1326.9204
V Predictions Std            349.53113
V Predictions Max            1587.049
V Predictions Min            10.642325
Log Pis Mean                 0.68840814
Log Pis Std                  3.2805238
Log Pis Max                  12.741437
Log Pis Min                  -8.2274275
Policy mu Mean               -0.010964187
Policy mu Std                0.6567254
Policy mu Max                3.421573
Policy mu Min                -2.5283566
Policy log std Mean          -1.0220821
Policy log std Std           0.33710715
Policy log std Max           0.013893127
Policy log std Min           -2.598182
Z mean eval                  1.136211
Z variance eval              0.016388588
total_rewards                [2892.37766623  257.2362507  2126.50752834 3751.53778456  672.89358696
  263.26876522 3592.06644326 3772.38040968 1249.69831998 2565.09105458]
total_rewards_mean           2114.305780949497
total_rewards_std            1346.19943677283
total_rewards_max            3772.380409675987
total_rewards_min            257.23625069846474
Number of train steps total  1016000
Number of env steps total    1272000
Number of rollouts total     0
Train Time (s)               141.7769244867377
(Previous) Eval Time (s)     25.539149255957454
Sample Time (s)              26.819068796467036
Epoch Time (s)               194.1351425391622
Total Train Time (s)         46550.87901998125
Epoch                        253
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:28:46.646344 UTC | [2020_01_11_13_32_55] Iteration #253 | Epoch Duration: 195.14577460289001
2020-01-12 02:28:46.646467 UTC | [2020_01_11_13_32_55] Iteration #253 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1412089
Z variance train             0.016202535
KL Divergence                25.03426
KL Loss                      2.503426
QF Loss                      762.87036
VF Loss                      175.94298
Policy Loss                  -1295.2137
Q Predictions Mean           1293.3223
Q Predictions Std            415.69284
Q Predictions Max            1583.1228
Q Predictions Min            -42.50807
V Predictions Mean           1298.7607
V Predictions Std            413.3212
V Predictions Max            1582.4032
V Predictions Min            -50.020363
Log Pis Mean                 0.22881126
Log Pis Std                  3.2714326
Log Pis Max                  14.5942955
Log Pis Min                  -7.163804
Policy mu Mean               0.004833481
Policy mu Std                0.64444214
Policy mu Max                2.4821558
Policy mu Min                -2.233485
Policy log std Mean          -0.9769503
Policy log std Std           0.33738092
Policy log std Max           0.56342125
Policy log std Min           -3.01127
Z mean eval                  1.1374581
Z variance eval              0.014102985
total_rewards                [2339.58815294 1656.80497325 3546.84723894 3722.70120098 3728.91439893
 3154.67034173 3816.95717262  343.4640359   214.57223168 1525.03759066]
total_rewards_mean           2404.9557337618126
total_rewards_std            1331.7222779521362
total_rewards_max            3816.957172615287
total_rewards_min            214.57223167870217
Number of train steps total  1020000
Number of env steps total    1277000
Number of rollouts total     0
Train Time (s)               134.30268877511844
(Previous) Eval Time (s)     26.549404255114496
Sample Time (s)              25.038182786200196
Epoch Time (s)               185.89027581643313
Total Train Time (s)         46736.63727155188
Epoch                        254
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:31:52.408897 UTC | [2020_01_11_13_32_55] Iteration #254 | Epoch Duration: 185.76232504844666
2020-01-12 02:31:52.409087 UTC | [2020_01_11_13_32_55] Iteration #254 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1323035
Z variance train             0.0141066555
KL Divergence                26.618633
KL Loss                      2.6618633
QF Loss                      1214.5371
VF Loss                      491.978
Policy Loss                  -1345.3268
Q Predictions Mean           1342.7957
Q Predictions Std            354.9773
Q Predictions Max            1579.1733
Q Predictions Min            -22.097881
V Predictions Mean           1338.4753
V Predictions Std            346.52325
V Predictions Max            1585.5902
V Predictions Min            -16.52049
Log Pis Mean                 0.08517959
Log Pis Std                  3.4297714
Log Pis Max                  29.576748
Log Pis Min                  -6.9599714
Policy mu Mean               -0.0009567146
Policy mu Std                0.6666652
Policy mu Max                3.1316433
Policy mu Min                -2.837055
Policy log std Mean          -0.96525323
Policy log std Std           0.31431454
Policy log std Max           -0.17480159
Policy log std Min           -2.8100266
Z mean eval                  1.1554124
Z variance eval              0.016333804
total_rewards                [  57.1613185  3713.66831867 1211.75787039 1505.44829413 1178.31605372
 2701.6375772  1606.3882395   969.68041073  -43.97392765 3658.28489436]
total_rewards_mean           1655.8369049553626
total_rewards_std            1253.171680681968
total_rewards_max            3713.6683186678583
total_rewards_min            -43.97392764711895
Number of train steps total  1024000
Number of env steps total    1282000
Number of rollouts total     0
Train Time (s)               134.49149024114013
(Previous) Eval Time (s)     26.420946788974106
Sample Time (s)              25.8778447592631
Epoch Time (s)               186.79028178937733
Total Train Time (s)         46916.172354578506
Epoch                        255
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:34:51.947434 UTC | [2020_01_11_13_32_55] Iteration #255 | Epoch Duration: 179.5381977558136
2020-01-12 02:34:51.947682 UTC | [2020_01_11_13_32_55] Iteration #255 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1583893
Z variance train             0.0163592
KL Divergence                25.650126
KL Loss                      2.5650127
QF Loss                      750.761
VF Loss                      374.378
Policy Loss                  -1390.1302
Q Predictions Mean           1391.1052
Q Predictions Std            248.23257
Q Predictions Max            1553.9847
Q Predictions Min            33.67205
V Predictions Mean           1383.4828
V Predictions Std            246.23393
V Predictions Max            1558.0558
V Predictions Min            33.82234
Log Pis Mean                 0.6536814
Log Pis Std                  3.1507006
Log Pis Max                  13.456725
Log Pis Min                  -8.24815
Policy mu Mean               0.013221934
Policy mu Std                0.6765612
Policy mu Max                2.896538
Policy mu Min                -2.7903159
Policy log std Mean          -1.0110197
Policy log std Std           0.29764777
Policy log std Max           -0.22661984
Policy log std Min           -2.8553998
Z mean eval                  1.1149672
Z variance eval              0.016173687
total_rewards                [3882.04906425 3749.12722194 3458.1060899  3661.8177185  3797.02652974
 3606.67954516 1627.87527729 3773.61700327 3937.0288598   860.05936398]
total_rewards_mean           3235.3386673835194
total_rewards_std            1018.5829881122222
total_rewards_max            3937.028859803363
total_rewards_min            860.0593639772311
Number of train steps total  1028000
Number of env steps total    1287000
Number of rollouts total     0
Train Time (s)               139.69287877203897
(Previous) Eval Time (s)     19.168513849377632
Sample Time (s)              25.49640273815021
Epoch Time (s)               184.3577953595668
Total Train Time (s)         47113.10783368442
Epoch                        256
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:38:08.886649 UTC | [2020_01_11_13_32_55] Iteration #256 | Epoch Duration: 196.93877458572388
2020-01-12 02:38:08.886986 UTC | [2020_01_11_13_32_55] Iteration #256 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1176089
Z variance train             0.016174141
KL Divergence                27.177063
KL Loss                      2.7177064
QF Loss                      553.3848
VF Loss                      181.03967
Policy Loss                  -1307.0049
Q Predictions Mean           1307.7688
Q Predictions Std            421.11642
Q Predictions Max            1571.8445
Q Predictions Min            -68.788956
V Predictions Mean           1309.1575
V Predictions Std            419.3281
V Predictions Max            1578.8516
V Predictions Min            -53.70942
Log Pis Mean                 0.39836475
Log Pis Std                  3.0445259
Log Pis Max                  9.072071
Log Pis Min                  -6.431858
Policy mu Mean               0.021928279
Policy mu Std                0.63513863
Policy mu Max                2.2206626
Policy mu Min                -2.7006152
Policy log std Mean          -0.9983258
Policy log std Std           0.3161965
Policy log std Max           -0.10641658
Policy log std Min           -2.3200743
Z mean eval                  1.1892747
Z variance eval              0.015723515
total_rewards                [ 820.09989397 1115.51996764 3795.49388627 1413.31702896 3503.99452422
 2913.0671421   785.08707729 3763.16190806 1139.42257598 3661.49733155]
total_rewards_mean           2291.066133603535
total_rewards_std            1267.9464024483066
total_rewards_max            3795.4938862719587
total_rewards_min            785.0870772935157
Number of train steps total  1032000
Number of env steps total    1292000
Number of rollouts total     0
Train Time (s)               142.73495939187706
(Previous) Eval Time (s)     31.74915280425921
Sample Time (s)              25.621253616642207
Epoch Time (s)               200.10536581277847
Total Train Time (s)         47309.04556264356
Epoch                        257
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:41:24.825340 UTC | [2020_01_11_13_32_55] Iteration #257 | Epoch Duration: 195.93820905685425
2020-01-12 02:41:24.825461 UTC | [2020_01_11_13_32_55] Iteration #257 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1869966
Z variance train             0.015702998
KL Divergence                26.329811
KL Loss                      2.632981
QF Loss                      661.8507
VF Loss                      208.30948
Policy Loss                  -1328.1085
Q Predictions Mean           1326.9995
Q Predictions Std            374.0494
Q Predictions Max            1575.9244
Q Predictions Min            -57.576454
V Predictions Mean           1327.5118
V Predictions Std            370.3949
V Predictions Max            1570.1293
V Predictions Min            -53.31275
Log Pis Mean                 0.16940019
Log Pis Std                  2.961575
Log Pis Max                  11.787334
Log Pis Min                  -8.351404
Policy mu Mean               0.017947968
Policy mu Std                0.66651016
Policy mu Max                2.3290477
Policy mu Min                -2.6761324
Policy log std Mean          -0.9641189
Policy log std Std           0.3022344
Policy log std Max           -0.086031854
Policy log std Min           -2.3554704
Z mean eval                  1.2102811
Z variance eval              0.014878008
total_rewards                [3617.02228548 3755.04801024 3679.19562587 3393.659155    689.18388734
 3807.63887371 3395.39870625 3560.82719561 3848.78401686 3715.71237313]
total_rewards_mean           3346.2470129473295
total_rewards_std            897.9930808593656
total_rewards_max            3848.784016856197
total_rewards_min            689.1838873404963
Number of train steps total  1036000
Number of env steps total    1297000
Number of rollouts total     0
Train Time (s)               141.29281253600493
(Previous) Eval Time (s)     27.58156958175823
Sample Time (s)              24.782337989192456
Epoch Time (s)               193.65672010695562
Total Train Time (s)         47510.5500792535
Epoch                        258
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:44:46.334027 UTC | [2020_01_11_13_32_55] Iteration #258 | Epoch Duration: 201.50844836235046
2020-01-12 02:44:46.334260 UTC | [2020_01_11_13_32_55] Iteration #258 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2049948
Z variance train             0.0147834
KL Divergence                25.755394
KL Loss                      2.5755394
QF Loss                      1258.0933
VF Loss                      1852.3352
Policy Loss                  -1368.0448
Q Predictions Mean           1366.8271
Q Predictions Std            292.82388
Q Predictions Max            1589.5874
Q Predictions Min            -22.167746
V Predictions Mean           1357.9545
V Predictions Std            267.72812
V Predictions Max            1563.4987
V Predictions Min            -19.263163
Log Pis Mean                 0.57421726
Log Pis Std                  3.5245106
Log Pis Max                  15.657914
Log Pis Min                  -8.800705
Policy mu Mean               0.010386589
Policy mu Std                0.66527456
Policy mu Max                3.8675501
Policy mu Min                -2.4505625
Policy log std Mean          -1.0459816
Policy log std Std           0.308755
Policy log std Max           -0.1829114
Policy log std Min           -2.6632617
Z mean eval                  1.1448705
Z variance eval              0.014142732
total_rewards                [3654.2244122  3463.74902969 2382.94557414 2134.12894506 3475.54971355
 3867.84168038 2846.69109655 3764.9349445    16.97537446  572.92788881]
total_rewards_mean           2617.996865933189
total_rewards_std            1291.9496274580306
total_rewards_max            3867.8416803807304
total_rewards_min            16.97537445848928
Number of train steps total  1040000
Number of env steps total    1302000
Number of rollouts total     0
Train Time (s)               143.59680320881307
(Previous) Eval Time (s)     35.432872973848134
Sample Time (s)              24.971807843539864
Epoch Time (s)               204.00148402620107
Total Train Time (s)         47703.35129061481
Epoch                        259
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:47:59.138049 UTC | [2020_01_11_13_32_55] Iteration #259 | Epoch Duration: 192.80364227294922
2020-01-12 02:47:59.138250 UTC | [2020_01_11_13_32_55] Iteration #259 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1446044
Z variance train             0.01414117
KL Divergence                25.407217
KL Loss                      2.5407217
QF Loss                      968.9663
VF Loss                      269.10464
Policy Loss                  -1306.6876
Q Predictions Mean           1305.7561
Q Predictions Std            407.00873
Q Predictions Max            1567.1263
Q Predictions Min            -59.85576
V Predictions Mean           1308.1799
V Predictions Std            407.25162
V Predictions Max            1561.391
V Predictions Min            -58.60297
Log Pis Mean                 0.48574466
Log Pis Std                  3.5585392
Log Pis Max                  15.802507
Log Pis Min                  -8.598822
Policy mu Mean               -0.02399702
Policy mu Std                0.6767053
Policy mu Max                2.6863408
Policy mu Min                -2.7281895
Policy log std Mean          -1.0020342
Policy log std Std           0.34450638
Policy log std Max           0.078864455
Policy log std Min           -2.6904795
Z mean eval                  1.1741219
Z variance eval              0.015986254
total_rewards                [3451.49459205 3522.01872167 1228.69646711 3333.15476672 2021.55809695
 3513.88596809 3498.44126792 1480.35271464 3561.69712686 3160.10095143]
total_rewards_mean           2877.1400673438015
total_rewards_std            877.168654158623
total_rewards_max            3561.6971268573025
total_rewards_min            1228.696467113681
Number of train steps total  1044000
Number of env steps total    1307000
Number of rollouts total     0
Train Time (s)               139.9457707554102
(Previous) Eval Time (s)     24.2346378210932
Sample Time (s)              26.33507923129946
Epoch Time (s)               190.51548780780286
Total Train Time (s)         47899.55914072553
Epoch                        260
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:51:15.349535 UTC | [2020_01_11_13_32_55] Iteration #260 | Epoch Duration: 196.21114420890808
2020-01-12 02:51:15.349768 UTC | [2020_01_11_13_32_55] Iteration #260 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1752975
Z variance train             0.015984956
KL Divergence                26.465708
KL Loss                      2.646571
QF Loss                      955.2266
VF Loss                      368.29575
Policy Loss                  -1349.143
Q Predictions Mean           1350.5969
Q Predictions Std            357.95096
Q Predictions Max            1597.0734
Q Predictions Min            -83.913795
V Predictions Mean           1347.5997
V Predictions Std            357.55374
V Predictions Max            1591.125
V Predictions Min            26.575315
Log Pis Mean                 0.57186204
Log Pis Std                  3.2085156
Log Pis Max                  12.119028
Log Pis Min                  -8.108463
Policy mu Mean               0.009590473
Policy mu Std                0.6378548
Policy mu Max                2.7412324
Policy mu Min                -2.74417
Policy log std Mean          -1.0386772
Policy log std Std           0.31884363
Policy log std Max           -0.004936576
Policy log std Min           -2.7384448
Z mean eval                  1.1447432
Z variance eval              0.016366798
total_rewards                [1208.28656014 2280.59660216 1637.50446425 1048.1251742   142.1003833
 2762.68110814 1771.14325346 2146.82489504 3596.11802722  129.49210217]
total_rewards_mean           1672.2872570058328
total_rewards_std            1040.3295570921593
total_rewards_max            3596.118027216281
total_rewards_min            129.49210216789587
Number of train steps total  1048000
Number of env steps total    1312000
Number of rollouts total     0
Train Time (s)               133.37659417884424
(Previous) Eval Time (s)     29.92988225677982
Sample Time (s)              24.39967368589714
Epoch Time (s)               187.7061501215212
Total Train Time (s)         48077.103018717375
Epoch                        261
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:54:12.896566 UTC | [2020_01_11_13_32_55] Iteration #261 | Epoch Duration: 177.54665207862854
2020-01-12 02:54:12.896757 UTC | [2020_01_11_13_32_55] Iteration #261 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1455774
Z variance train             0.016376022
KL Divergence                24.9776
KL Loss                      2.49776
QF Loss                      1397.3369
VF Loss                      334.40445
Policy Loss                  -1330.8937
Q Predictions Mean           1338.1415
Q Predictions Std            361.3576
Q Predictions Max            1560.982
Q Predictions Min            -77.09626
V Predictions Mean           1337.584
V Predictions Std            359.3878
V Predictions Max            1557.3873
V Predictions Min            -63.25313
Log Pis Mean                 0.4070427
Log Pis Std                  3.3870177
Log Pis Max                  13.942713
Log Pis Min                  -8.9105
Policy mu Mean               0.005185633
Policy mu Std                0.66784984
Policy mu Max                2.431443
Policy mu Min                -2.557004
Policy log std Mean          -1.0016153
Policy log std Std           0.31871584
Policy log std Max           -0.20102412
Policy log std Min           -2.8390868
Z mean eval                  1.1453377
Z variance eval              0.014993198
total_rewards                [1158.4950979  3735.86136175 2614.35970875    6.41973296  942.08884257
 1910.12076152  243.82563603  601.60576465 2090.46450444 3765.12349295]
total_rewards_mean           1706.836490351557
total_rewards_std            1284.6964920556693
total_rewards_max            3765.123492945424
total_rewards_min            6.419732956251068
Number of train steps total  1052000
Number of env steps total    1317000
Number of rollouts total     0
Train Time (s)               133.4595053428784
(Previous) Eval Time (s)     19.77008334128186
Sample Time (s)              23.904922432731837
Epoch Time (s)               177.1345111168921
Total Train Time (s)         48251.34775093384
Epoch                        262
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:57:07.144313 UTC | [2020_01_11_13_32_55] Iteration #262 | Epoch Duration: 174.24741625785828
2020-01-12 02:57:07.144496 UTC | [2020_01_11_13_32_55] Iteration #262 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1442777
Z variance train             0.015002255
KL Divergence                24.476501
KL Loss                      2.4476502
QF Loss                      1412.106
VF Loss                      273.3056
Policy Loss                  -1338.6555
Q Predictions Mean           1336.3486
Q Predictions Std            348.81265
Q Predictions Max            1562.6536
Q Predictions Min            -70.534874
V Predictions Mean           1341.5973
V Predictions Std            340.80173
V Predictions Max            1575.1599
V Predictions Min            -48.357418
Log Pis Mean                 0.43169957
Log Pis Std                  3.3027363
Log Pis Max                  15.341313
Log Pis Min                  -6.5226583
Policy mu Mean               -0.022507032
Policy mu Std                0.65414375
Policy mu Max                2.8254452
Policy mu Min                -2.8346314
Policy log std Mean          -1.0013887
Policy log std Std           0.3119457
Policy log std Max           -0.17947888
Policy log std Min           -2.757607
Z mean eval                  1.1417596
Z variance eval              0.0116512375
total_rewards                [3206.37963554 1295.92920335 3935.28544871 3568.42389574  156.09081902
  197.04883432 2759.03169155 1301.20179057 1678.64978066 2792.0117878 ]
total_rewards_mean           2089.0052887254033
total_rewards_std            1285.4089636196873
total_rewards_max            3935.2854487083587
total_rewards_min            156.0908190176386
Number of train steps total  1056000
Number of env steps total    1322000
Number of rollouts total     0
Train Time (s)               140.18144733738154
(Previous) Eval Time (s)     16.882667287252843
Sample Time (s)              25.81400057161227
Epoch Time (s)               182.87811519624665
Total Train Time (s)         48442.49047394702
Epoch                        263
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:00:18.290290 UTC | [2020_01_11_13_32_55] Iteration #263 | Epoch Duration: 191.14565992355347
2020-01-12 03:00:18.290483 UTC | [2020_01_11_13_32_55] Iteration #263 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1413636
Z variance train             0.011665564
KL Divergence                24.548988
KL Loss                      2.4548988
QF Loss                      1910.4238
VF Loss                      838.176
Policy Loss                  -1339.6239
Q Predictions Mean           1337.8145
Q Predictions Std            347.89938
Q Predictions Max            1586.8749
Q Predictions Min            0.3458141
V Predictions Mean           1338.352
V Predictions Std            350.0682
V Predictions Max            1588.8778
V Predictions Min            -55.433804
Log Pis Mean                 0.94995165
Log Pis Std                  3.4869838
Log Pis Max                  14.849005
Log Pis Min                  -7.0640574
Policy mu Mean               0.039854065
Policy mu Std                0.6732653
Policy mu Max                3.1958368
Policy mu Min                -2.8125734
Policy log std Mean          -1.0273316
Policy log std Std           0.35991257
Policy log std Max           1.4248191
Policy log std Min           -2.8618271
Z mean eval                  1.1287215
Z variance eval              0.015601629
total_rewards                [3617.20454664 1810.26676518 3060.9465914   580.17757573  196.1869932
 3570.32942978 2380.63205513 3513.14725695 3852.43436251  304.49908557]
total_rewards_mean           2288.5824662111168
total_rewards_std            1393.5731741334043
total_rewards_max            3852.434362510069
total_rewards_min            196.18699320489173
Number of train steps total  1060000
Number of env steps total    1327000
Number of rollouts total     0
Train Time (s)               139.28195474203676
(Previous) Eval Time (s)     25.149820093996823
Sample Time (s)              26.92478091130033
Epoch Time (s)               191.3565557473339
Total Train Time (s)         48635.867269822396
Epoch                        264
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:03:31.670781 UTC | [2020_01_11_13_32_55] Iteration #264 | Epoch Duration: 193.3801543712616
2020-01-12 03:03:31.671030 UTC | [2020_01_11_13_32_55] Iteration #264 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1288284
Z variance train             0.015688587
KL Divergence                24.173897
KL Loss                      2.4173896
QF Loss                      671.3595
VF Loss                      311.8558
Policy Loss                  -1350.8429
Q Predictions Mean           1353.365
Q Predictions Std            344.96606
Q Predictions Max            1556.6554
Q Predictions Min            13.035381
V Predictions Mean           1352.6426
V Predictions Std            345.63953
V Predictions Max            1553.4154
V Predictions Min            10.398675
Log Pis Mean                 0.3872879
Log Pis Std                  3.1862056
Log Pis Max                  12.702055
Log Pis Min                  -9.964231
Policy mu Mean               0.0046115713
Policy mu Std                0.6234001
Policy mu Max                2.6440086
Policy mu Min                -2.2898486
Policy log std Mean          -1.0348666
Policy log std Std           0.33348888
Policy log std Max           -0.11707282
Policy log std Min           -2.7181847
Z mean eval                  1.1737453
Z variance eval              0.03289814
total_rewards                [3350.82315603 1479.06218737 3828.20462311 3500.20468951  581.04392117
  213.99982718 3760.31422803 1464.21483779 3415.29069079 2441.55697274]
total_rewards_mean           2403.471513370319
total_rewards_std            1298.005324676633
total_rewards_max            3828.2046231063578
total_rewards_min            213.99982717795393
Number of train steps total  1064000
Number of env steps total    1332000
Number of rollouts total     0
Train Time (s)               140.14578970195726
(Previous) Eval Time (s)     27.173045731149614
Sample Time (s)              27.122195329982787
Epoch Time (s)               194.44103076308966
Total Train Time (s)         48830.67022942752
Epoch                        265
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:06:46.477141 UTC | [2020_01_11_13_32_55] Iteration #265 | Epoch Duration: 194.8059525489807
2020-01-12 03:06:46.477354 UTC | [2020_01_11_13_32_55] Iteration #265 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1760066
Z variance train             0.0331449
KL Divergence                24.933838
KL Loss                      2.493384
QF Loss                      592.6727
VF Loss                      108.5773
Policy Loss                  -1320.6625
Q Predictions Mean           1322.9556
Q Predictions Std            382.56534
Q Predictions Max            1568.1495
Q Predictions Min            -39.930607
V Predictions Mean           1318.3397
V Predictions Std            381.89847
V Predictions Max            1560.6569
V Predictions Min            -40.663036
Log Pis Mean                 0.028009955
Log Pis Std                  2.827725
Log Pis Max                  13.022194
Log Pis Min                  -6.828492
Policy mu Mean               -0.006467128
Policy mu Std                0.649531
Policy mu Max                3.2577775
Policy mu Min                -2.3052557
Policy log std Mean          -0.9611089
Policy log std Std           0.298293
Policy log std Max           -0.07117212
Policy log std Min           -2.614161
Z mean eval                  1.1653311
Z variance eval              0.012953763
total_rewards                [3738.89499402   57.42950837 1130.21404316 3538.96819568 3749.72404741
 3662.64980028 3764.60213286 3716.26470958 3632.08099197  362.25988559]
total_rewards_mean           2735.3088308917695
total_rewards_std            1474.6762611876188
total_rewards_max            3764.60213285694
total_rewards_min            57.42950837216091
Number of train steps total  1068000
Number of env steps total    1337000
Number of rollouts total     0
Train Time (s)               140.49715048912913
(Previous) Eval Time (s)     27.537606372032315
Sample Time (s)              26.043538603466004
Epoch Time (s)               194.07829546462744
Total Train Time (s)         49024.41880402109
Epoch                        266
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:10:00.228488 UTC | [2020_01_11_13_32_55] Iteration #266 | Epoch Duration: 193.75096583366394
2020-01-12 03:10:00.228748 UTC | [2020_01_11_13_32_55] Iteration #266 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1655287
Z variance train             0.012949253
KL Divergence                26.092422
KL Loss                      2.6092422
QF Loss                      729.20905
VF Loss                      203.41162
Policy Loss                  -1384.6038
Q Predictions Mean           1387.6917
Q Predictions Std            287.1289
Q Predictions Max            1582.4838
Q Predictions Min            3.4026327
V Predictions Mean           1384.073
V Predictions Std            282.57007
V Predictions Max            1575.0763
V Predictions Min            9.302378
Log Pis Mean                 0.1574383
Log Pis Std                  3.1685314
Log Pis Max                  18.196785
Log Pis Min                  -11.270414
Policy mu Mean               -0.0062276027
Policy mu Std                0.6500536
Policy mu Max                3.1607149
Policy mu Min                -2.5453053
Policy log std Mean          -1.0016862
Policy log std Std           0.27414754
Policy log std Max           0.04148209
Policy log std Min           -2.2730885
Z mean eval                  1.1246895
Z variance eval              0.008206923
total_rewards                [2853.41810622  430.18572535 3968.60958809 3544.08167678 3703.27776902
 3735.91476905  205.78069045 3602.02949091 3782.31269897  863.0408988 ]
total_rewards_mean           2668.865141363911
total_rewards_std            1454.2364560677809
total_rewards_max            3968.6095880903
total_rewards_min            205.78069044931775
Number of train steps total  1072000
Number of env steps total    1342000
Number of rollouts total     0
Train Time (s)               136.75629619602114
(Previous) Eval Time (s)     27.20993343135342
Sample Time (s)              26.21695842873305
Epoch Time (s)               190.1831880561076
Total Train Time (s)         49214.46000397205
Epoch                        267
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:13:10.273099 UTC | [2020_01_11_13_32_55] Iteration #267 | Epoch Duration: 190.0441906452179
2020-01-12 03:13:10.273288 UTC | [2020_01_11_13_32_55] Iteration #267 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1230936
Z variance train             0.008196733
KL Divergence                26.8171
KL Loss                      2.68171
QF Loss                      1468.7122
VF Loss                      457.21545
Policy Loss                  -1384.0057
Q Predictions Mean           1383.2213
Q Predictions Std            311.2097
Q Predictions Max            1595.8868
Q Predictions Min            -1.7465236
V Predictions Mean           1384.8052
V Predictions Std            307.1814
V Predictions Max            1589.7627
V Predictions Min            -31.30039
Log Pis Mean                 0.43287852
Log Pis Std                  3.2859552
Log Pis Max                  15.798045
Log Pis Min                  -8.593397
Policy mu Mean               0.03208752
Policy mu Std                0.6339084
Policy mu Max                3.2683153
Policy mu Min                -2.2012753
Policy log std Mean          -1.0257514
Policy log std Std           0.28680173
Policy log std Max           -0.16254437
Policy log std Min           -2.4160347
Z mean eval                  1.172096
Z variance eval              0.0077488264
total_rewards                [  -9.37107728 3600.63707009 1778.22333058 1274.78428485 3820.89856154
  897.52497827 3158.31061074 1800.00962803 3623.03571588 1539.51860474]
total_rewards_mean           2148.357170743731
total_rewards_std            1253.54400780554
total_rewards_max            3820.8985615375595
total_rewards_min            -9.371077283759353
Number of train steps total  1076000
Number of env steps total    1347000
Number of rollouts total     0
Train Time (s)               132.82185212988406
(Previous) Eval Time (s)     27.070534749887884
Sample Time (s)              24.134884912054986
Epoch Time (s)               184.02727179182693
Total Train Time (s)         49391.10849440936
Epoch                        268
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:16:06.924655 UTC | [2020_01_11_13_32_55] Iteration #268 | Epoch Duration: 176.65122628211975
2020-01-12 03:16:06.924851 UTC | [2020_01_11_13_32_55] Iteration #268 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1715418
Z variance train             0.0077805356
KL Divergence                26.49075
KL Loss                      2.649075
QF Loss                      724.5796
VF Loss                      740.7106
Policy Loss                  -1341.7527
Q Predictions Mean           1343.5974
Q Predictions Std            397.78156
Q Predictions Max            1581.1039
Q Predictions Min            -46.23617
V Predictions Mean           1339.8379
V Predictions Std            393.27832
V Predictions Max            1580.8379
V Predictions Min            -47.552464
Log Pis Mean                 0.29199043
Log Pis Std                  3.2008321
Log Pis Max                  13.410913
Log Pis Min                  -8.764572
Policy mu Mean               -0.022308849
Policy mu Std                0.65760887
Policy mu Max                2.2121758
Policy mu Min                -2.5569077
Policy log std Mean          -0.9729905
Policy log std Std           0.31175584
Policy log std Max           -0.045200944
Policy log std Min           -2.4438338
Z mean eval                  1.1796224
Z variance eval              0.010219513
total_rewards                [3377.12361452 3811.10189682 2948.93642936 1307.69769654 3828.62135998
 3733.48350585 3294.72813645 3632.54443733 3721.69870567  913.97124276]
total_rewards_mean           3056.9907025274697
total_rewards_std            1010.8450538757569
total_rewards_max            3828.6213599831344
total_rewards_min            913.9712427599668
Number of train steps total  1080000
Number of env steps total    1352000
Number of rollouts total     0
Train Time (s)               135.07303241780028
(Previous) Eval Time (s)     19.69419598998502
Sample Time (s)              23.551070945803076
Epoch Time (s)               178.31829935358837
Total Train Time (s)         49578.184762945864
Epoch                        269
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:19:14.004416 UTC | [2020_01_11_13_32_55] Iteration #269 | Epoch Duration: 187.07941126823425
2020-01-12 03:19:14.004669 UTC | [2020_01_11_13_32_55] Iteration #269 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1788132
Z variance train             0.010205493
KL Divergence                26.072426
KL Loss                      2.6072426
QF Loss                      936.30786
VF Loss                      242.11195
Policy Loss                  -1376.076
Q Predictions Mean           1376.3943
Q Predictions Std            328.74664
Q Predictions Max            1585.3771
Q Predictions Min            -63.921734
V Predictions Mean           1374.2382
V Predictions Std            325.71634
V Predictions Max            1590.6797
V Predictions Min            -52.45414
Log Pis Mean                 0.5823976
Log Pis Std                  3.4635077
Log Pis Max                  16.321777
Log Pis Min                  -7.202564
Policy mu Mean               -0.041286394
Policy mu Std                0.65206856
Policy mu Max                2.6527457
Policy mu Min                -2.427607
Policy log std Mean          -1.0208678
Policy log std Std           0.3315449
Policy log std Max           -0.10317749
Policy log std Min           -2.7911146
Z mean eval                  1.1564623
Z variance eval              0.017722404
total_rewards                [2856.64443974 3709.80942211 3672.79120435 1713.1475581  3567.36867445
 3804.13315779 3404.84550726 1218.29668417 3778.13007151 2081.25981229]
total_rewards_mean           2980.642653176682
total_rewards_std            915.7370940824409
total_rewards_max            3804.133157788922
total_rewards_min            1218.2966841668378
Number of train steps total  1084000
Number of env steps total    1357000
Number of rollouts total     0
Train Time (s)               142.75749116344377
(Previous) Eval Time (s)     28.454968182835728
Sample Time (s)              25.483248630538583
Epoch Time (s)               196.69570797681808
Total Train Time (s)         49773.99731950322
Epoch                        270
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:22:29.819897 UTC | [2020_01_11_13_32_55] Iteration #270 | Epoch Duration: 195.81507325172424
2020-01-12 03:22:29.820082 UTC | [2020_01_11_13_32_55] Iteration #270 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1584516
Z variance train             0.017722514
KL Divergence                25.489841
KL Loss                      2.5489843
QF Loss                      1666.2883
VF Loss                      1008.63574
Policy Loss                  -1356.6694
Q Predictions Mean           1358.1558
Q Predictions Std            349.4658
Q Predictions Max            1624.4523
Q Predictions Min            -84.82161
V Predictions Mean           1347.0316
V Predictions Std            350.00186
V Predictions Max            1607.49
V Predictions Min            -82.67913
Log Pis Mean                 0.52519035
Log Pis Std                  3.5821815
Log Pis Max                  19.574558
Log Pis Min                  -8.066735
Policy mu Mean               -0.019771358
Policy mu Std                0.6260779
Policy mu Max                2.6091208
Policy mu Min                -3.199452
Policy log std Mean          -1.0580117
Policy log std Std           0.34878242
Policy log std Max           -0.04846388
Policy log std Min           -3.3734334
Z mean eval                  1.1612636
Z variance eval              0.019408345
total_rewards                [3583.64753552 3773.41624642 2144.62257963 3666.02417595 3783.61813837
 1862.99505655 2636.36931905  429.65462908 1517.55558272   10.90533427]
total_rewards_mean           2340.880859756221
total_rewards_std            1324.6797370298405
total_rewards_max            3783.6181383726307
total_rewards_min            10.905334269862406
Number of train steps total  1088000
Number of env steps total    1362000
Number of rollouts total     0
Train Time (s)               140.86091698426753
(Previous) Eval Time (s)     27.574038073886186
Sample Time (s)              26.221238401718438
Epoch Time (s)               194.65619345987216
Total Train Time (s)         49963.42711941525
Epoch                        271
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:25:39.253153 UTC | [2020_01_11_13_32_55] Iteration #271 | Epoch Duration: 189.43291878700256
2020-01-12 03:25:39.253459 UTC | [2020_01_11_13_32_55] Iteration #271 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1617448
Z variance train             0.019424753
KL Divergence                26.205006
KL Loss                      2.6205006
QF Loss                      12401.411
VF Loss                      726.9369
Policy Loss                  -1375.4292
Q Predictions Mean           1375.1389
Q Predictions Std            355.22653
Q Predictions Max            1642.6774
Q Predictions Min            -83.51094
V Predictions Mean           1374.7468
V Predictions Std            348.77924
V Predictions Max            1632.7778
V Predictions Min            -80.11368
Log Pis Mean                 0.31286284
Log Pis Std                  3.177166
Log Pis Max                  12.370474
Log Pis Min                  -7.9510984
Policy mu Mean               0.0031906364
Policy mu Std                0.6673217
Policy mu Max                3.1031785
Policy mu Min                -2.3960965
Policy log std Mean          -1.0088607
Policy log std Std           0.33848262
Policy log std Max           -0.1701138
Policy log std Min           -3.0230112
Z mean eval                  1.1927412
Z variance eval              0.019898789
total_rewards                [ 3.39232001e+03 -2.12046316e+00  5.73537339e+02  8.41701655e+02
  5.06313802e+02  3.74616062e+03  2.36775541e+03  1.77184505e+02
  1.48358766e+03  3.66740403e+03]
total_rewards_mean           1675.384457220693
total_rewards_std            1416.1473540503534
total_rewards_max            3746.1606237389456
total_rewards_min            -2.12046316168977
Number of train steps total  1092000
Number of env steps total    1367000
Number of rollouts total     0
Train Time (s)               141.80717269098386
(Previous) Eval Time (s)     22.350399387069046
Sample Time (s)              26.519234566017985
Epoch Time (s)               190.6768066440709
Total Train Time (s)         50155.18628611276
Epoch                        272
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:28:51.015750 UTC | [2020_01_11_13_32_55] Iteration #272 | Epoch Duration: 191.76213002204895
2020-01-12 03:28:51.015969 UTC | [2020_01_11_13_32_55] Iteration #272 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1896093
Z variance train             0.020069238
KL Divergence                26.300928
KL Loss                      2.6300929
QF Loss                      1460.152
VF Loss                      559.3804
Policy Loss                  -1358.775
Q Predictions Mean           1362.3838
Q Predictions Std            357.20776
Q Predictions Max            1586.9248
Q Predictions Min            -33.1254
V Predictions Mean           1350.4799
V Predictions Std            347.47507
V Predictions Max            1577.4708
V Predictions Min            -41.13218
Log Pis Mean                 0.7386335
Log Pis Std                  3.3919911
Log Pis Max                  14.201534
Log Pis Min                  -7.983946
Policy mu Mean               0.00018970156
Policy mu Std                0.64409244
Policy mu Max                2.6741805
Policy mu Min                -2.4130297
Policy log std Mean          -1.0789762
Policy log std Std           0.33726513
Policy log std Max           -0.1763035
Policy log std Min           -2.823854
Z mean eval                  1.1898152
Z variance eval              0.027662683
total_rewards                [ 653.11316224 3329.36789658 1384.72148712  329.79472569  731.92207174
  816.78941494  955.34016387  696.48018116 3919.84488778  554.33204737]
total_rewards_mean           1337.1706038505265
total_rewards_std            1180.266733216611
total_rewards_max            3919.8448877794435
total_rewards_min            329.7947256936451
Number of train steps total  1096000
Number of env steps total    1372000
Number of rollouts total     0
Train Time (s)               140.1140182330273
(Previous) Eval Time (s)     23.435295911040157
Sample Time (s)              26.230271679814905
Epoch Time (s)               189.77958582388237
Total Train Time (s)         50334.14547824254
Epoch                        273
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:31:49.978794 UTC | [2020_01_11_13_32_55] Iteration #273 | Epoch Duration: 178.96265268325806
2020-01-12 03:31:49.979108 UTC | [2020_01_11_13_32_55] Iteration #273 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1894917
Z variance train             0.027625818
KL Divergence                26.17817
KL Loss                      2.617817
QF Loss                      2117.8225
VF Loss                      202.96724
Policy Loss                  -1376.9462
Q Predictions Mean           1378.2529
Q Predictions Std            329.83896
Q Predictions Max            1617.849
Q Predictions Min            -103.13036
V Predictions Mean           1376.4165
V Predictions Std            327.10583
V Predictions Max            1608.8185
V Predictions Min            -82.4299
Log Pis Mean                 0.55426466
Log Pis Std                  3.0305417
Log Pis Max                  10.274101
Log Pis Min                  -9.882534
Policy mu Mean               0.006244426
Policy mu Std                0.65610117
Policy mu Max                2.665359
Policy mu Min                -2.6318908
Policy log std Mean          -1.0147892
Policy log std Std           0.30602118
Policy log std Max           0.0066173077
Policy log std Min           -2.3264077
Z mean eval                  1.1618087
Z variance eval              0.009041965
total_rewards                [3225.97620017 2502.76090851 2932.59674872  545.61034054  395.74481369
  688.35072864 2963.61126378  435.12456929  504.32429506 3991.62827639]
total_rewards_mean           1818.5728144791901
total_rewards_std            1352.282633777744
total_rewards_max            3991.628276386438
total_rewards_min            395.74481369426763
Number of train steps total  1100000
Number of env steps total    1377000
Number of rollouts total     0
Train Time (s)               133.94637242890894
(Previous) Eval Time (s)     12.617956445086747
Sample Time (s)              25.813649117015302
Epoch Time (s)               172.377977991011
Total Train Time (s)         50511.715107428376
Epoch                        274
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:34:47.551827 UTC | [2020_01_11_13_32_55] Iteration #274 | Epoch Duration: 177.57249760627747
2020-01-12 03:34:47.552124 UTC | [2020_01_11_13_32_55] Iteration #274 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1634126
Z variance train             0.009055613
KL Divergence                26.777746
KL Loss                      2.6777747
QF Loss                      2186.0825
VF Loss                      156.05914
Policy Loss                  -1387.1405
Q Predictions Mean           1389.3864
Q Predictions Std            339.47842
Q Predictions Max            1590.1088
Q Predictions Min            -67.438446
V Predictions Mean           1388.7898
V Predictions Std            340.58673
V Predictions Max            1587.1603
V Predictions Min            -76.738884
Log Pis Mean                 0.35020387
Log Pis Std                  2.9650383
Log Pis Max                  9.028927
Log Pis Min                  -6.97823
Policy mu Mean               0.012576381
Policy mu Std                0.64230925
Policy mu Max                2.6679509
Policy mu Min                -2.2226145
Policy log std Mean          -1.0096109
Policy log std Std           0.2999412
Policy log std Max           -0.106462955
Policy log std Min           -2.3373685
Z mean eval                  1.1350162
Z variance eval              0.007912221
total_rewards                [3704.04874172  708.67784442 3833.15937693 2383.89010495  302.91072627
 3833.29062758 3840.40529499 2095.55752699 3299.75308299 3283.56834907]
total_rewards_mean           2728.5261675902575
total_rewards_std            1254.8239466696295
total_rewards_max            3840.4052949861234
total_rewards_min            302.9107262701544
Number of train steps total  1104000
Number of env steps total    1382000
Number of rollouts total     0
Train Time (s)               132.86268321191892
(Previous) Eval Time (s)     17.812108794692904
Sample Time (s)              23.062130175996572
Epoch Time (s)               173.7369221826084
Total Train Time (s)         50695.03003910184
Epoch                        275
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:37:50.869737 UTC | [2020_01_11_13_32_55] Iteration #275 | Epoch Duration: 183.3174021244049
2020-01-12 03:37:50.869926 UTC | [2020_01_11_13_32_55] Iteration #275 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1339124
Z variance train             0.007907806
KL Divergence                26.791882
KL Loss                      2.6791883
QF Loss                      1458.0902
VF Loss                      520.8198
Policy Loss                  -1341.1975
Q Predictions Mean           1340.7529
Q Predictions Std            394.7726
Q Predictions Max            1577.7935
Q Predictions Min            -115.85182
V Predictions Mean           1345.3088
V Predictions Std            392.23486
V Predictions Max            1583.7615
V Predictions Min            -115.726555
Log Pis Mean                 1.0094004
Log Pis Std                  3.286887
Log Pis Max                  13.743792
Log Pis Min                  -6.309475
Policy mu Mean               0.0029369406
Policy mu Std                0.68487847
Policy mu Max                2.945042
Policy mu Min                -2.4154775
Policy log std Mean          -1.0331225
Policy log std Std           0.3503853
Policy log std Max           -0.11429441
Policy log std Min           -3.038299
Z mean eval                  1.1357939
Z variance eval              0.009092778
total_rewards                [3547.95082273 2293.75059586 1320.74704096 2437.85476063 3633.43328371
 3771.63707002 3156.28827553 3754.44562403 3489.87505174 3731.04216926]
total_rewards_mean           3113.702469446642
total_rewards_std            785.5144503424272
total_rewards_max            3771.637070023506
total_rewards_min            1320.7470409602597
Number of train steps total  1108000
Number of env steps total    1387000
Number of rollouts total     0
Train Time (s)               137.77938460186124
(Previous) Eval Time (s)     27.392271284013987
Sample Time (s)              24.125929452944547
Epoch Time (s)               189.29758533881977
Total Train Time (s)         50886.58964493126
Epoch                        276
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:41:02.432773 UTC | [2020_01_11_13_32_55] Iteration #276 | Epoch Duration: 191.56271123886108
2020-01-12 03:41:02.432975 UTC | [2020_01_11_13_32_55] Iteration #276 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1368744
Z variance train             0.009109196
KL Divergence                26.322046
KL Loss                      2.6322048
QF Loss                      1057.3486
VF Loss                      472.75085
Policy Loss                  -1351.2764
Q Predictions Mean           1350.583
Q Predictions Std            385.6533
Q Predictions Max            1638.3392
Q Predictions Min            -33.516457
V Predictions Mean           1358.1584
V Predictions Std            375.08884
V Predictions Max            1641.6272
V Predictions Min            -35.49718
Log Pis Mean                 0.73141587
Log Pis Std                  3.9596436
Log Pis Max                  31.36834
Log Pis Min                  -6.424488
Policy mu Mean               0.015353691
Policy mu Std                0.6403457
Policy mu Max                2.702831
Policy mu Min                -3.5216413
Policy log std Mean          -1.0621305
Policy log std Std           0.36160213
Policy log std Max           -0.10762739
Policy log std Min           -2.9582963
Z mean eval                  1.1453099
Z variance eval              0.012426305
total_rewards                [ 604.99541492   42.69903058 1163.25089545  -96.86442162 3354.71188753
  150.23434415 2187.57723597 1357.73553657 1389.9458365    10.43246808]
total_rewards_mean           1016.4718228124008
total_rewards_std            1059.9947536384725
total_rewards_max            3354.711887532536
total_rewards_min            -96.86442162443511
Number of train steps total  1112000
Number of env steps total    1392000
Number of rollouts total     0
Train Time (s)               142.1275672921911
(Previous) Eval Time (s)     29.65707413619384
Sample Time (s)              26.579307564999908
Epoch Time (s)               198.36394899338484
Total Train Time (s)         51068.78886054503
Epoch                        277
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:44:04.636188 UTC | [2020_01_11_13_32_55] Iteration #277 | Epoch Duration: 182.20304250717163
2020-01-12 03:44:04.636655 UTC | [2020_01_11_13_32_55] Iteration #277 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1422966
Z variance train             0.012414072
KL Divergence                26.220915
KL Loss                      2.6220915
QF Loss                      560.00635
VF Loss                      189.288
Policy Loss                  -1379.6613
Q Predictions Mean           1380.664
Q Predictions Std            333.6941
Q Predictions Max            1577.3062
Q Predictions Min            -138.70927
V Predictions Mean           1382.2734
V Predictions Std            332.10965
V Predictions Max            1589.2126
V Predictions Min            -146.80731
Log Pis Mean                 0.27498078
Log Pis Std                  2.760926
Log Pis Max                  10.543276
Log Pis Min                  -7.5986023
Policy mu Mean               0.0051946584
Policy mu Std                0.6591766
Policy mu Max                2.977652
Policy mu Min                -2.7142432
Policy log std Mean          -0.97022665
Policy log std Std           0.27048087
Policy log std Max           0.021122813
Policy log std Min           -2.2111292
Z mean eval                  1.1466753
Z variance eval              0.025657132
total_rewards                [ -37.43561439  123.63384462  309.80802323  230.78653606 3838.44584414
  859.97178938  126.50450226 1795.68011986  178.05233323 2233.54406238]
total_rewards_mean           965.899144075489
total_rewards_std            1207.0803119406014
total_rewards_max            3838.445844135542
total_rewards_min            -37.43561438809568
Number of train steps total  1116000
Number of env steps total    1397000
Number of rollouts total     0
Train Time (s)               141.96170108485967
(Previous) Eval Time (s)     13.495749680325389
Sample Time (s)              26.49223254621029
Epoch Time (s)               181.94968331139535
Total Train Time (s)         51248.11356467893
Epoch                        278
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:47:03.963330 UTC | [2020_01_11_13_32_55] Iteration #278 | Epoch Duration: 179.326354265213
2020-01-12 03:47:03.963519 UTC | [2020_01_11_13_32_55] Iteration #278 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1469986
Z variance train             0.025698777
KL Divergence                25.014849
KL Loss                      2.5014849
QF Loss                      969.6898
VF Loss                      472.76382
Policy Loss                  -1341.2042
Q Predictions Mean           1342.8357
Q Predictions Std            416.61572
Q Predictions Max            1631.1698
Q Predictions Min            -93.74235
V Predictions Mean           1348.9427
V Predictions Std            412.72168
V Predictions Max            1618.9126
V Predictions Min            -88.38634
Log Pis Mean                 0.27652675
Log Pis Std                  3.1066325
Log Pis Max                  10.551372
Log Pis Min                  -7.471289
Policy mu Mean               0.043035474
Policy mu Std                0.6275669
Policy mu Max                2.7187622
Policy mu Min                -2.190775
Policy log std Mean          -0.99605227
Policy log std Std           0.3087563
Policy log std Max           -0.09104115
Policy log std Min           -2.5369735
Z mean eval                  1.1627986
Z variance eval              0.011592565
total_rewards                [3909.81930951  743.2492974   995.29332053  245.04010292  922.19892014
 1438.2844449  2481.76072941 2663.49653613  526.36126572 1812.24480078]
total_rewards_mean           1573.7748727450457
total_rewards_std            1088.8451223660395
total_rewards_max            3909.8193095119937
total_rewards_min            245.04010291918553
Number of train steps total  1120000
Number of env steps total    1402000
Number of rollouts total     0
Train Time (s)               142.8118072571233
(Previous) Eval Time (s)     10.872045713011175
Sample Time (s)              24.723437468521297
Epoch Time (s)               178.40729043865576
Total Train Time (s)         51430.934728287626
Epoch                        279
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:50:06.788118 UTC | [2020_01_11_13_32_55] Iteration #279 | Epoch Duration: 182.82447147369385
2020-01-12 03:50:06.788416 UTC | [2020_01_11_13_32_55] Iteration #279 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1657436
Z variance train             0.011534911
KL Divergence                26.324059
KL Loss                      2.632406
QF Loss                      1056.1932
VF Loss                      228.48581
Policy Loss                  -1392.8595
Q Predictions Mean           1395.198
Q Predictions Std            294.6985
Q Predictions Max            1591.464
Q Predictions Min            -50.83451
V Predictions Mean           1403.3221
V Predictions Std            293.75415
V Predictions Max            1578.0387
V Predictions Min            -30.132837
Log Pis Mean                 0.47996265
Log Pis Std                  3.0399604
Log Pis Max                  11.01556
Log Pis Min                  -8.239685
Policy mu Mean               0.002228582
Policy mu Std                0.68325967
Policy mu Max                2.4046435
Policy mu Min                -2.606439
Policy log std Mean          -0.9781914
Policy log std Std           0.268018
Policy log std Max           -0.13046443
Policy log std Min           -2.5141459
Z mean eval                  1.1753043
Z variance eval              0.016304435
total_rewards                [1487.12609116 3803.80912219 2698.53640509  464.12888592 3690.31463579
 3196.88534938 3658.8668292  3829.60331279  315.48717536 1192.42377129]
total_rewards_mean           2433.7181578158443
total_rewards_std            1355.0370529275835
total_rewards_max            3829.6033127873015
total_rewards_min            315.487175357132
Number of train steps total  1124000
Number of env steps total    1407000
Number of rollouts total     0
Train Time (s)               141.36923410277814
(Previous) Eval Time (s)     15.28886828199029
Sample Time (s)              24.799156181048602
Epoch Time (s)               181.45725856581703
Total Train Time (s)         51620.88021093048
Epoch                        280
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:53:16.736937 UTC | [2020_01_11_13_32_55] Iteration #280 | Epoch Duration: 189.9483778476715
2020-01-12 03:53:16.737169 UTC | [2020_01_11_13_32_55] Iteration #280 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.177329
Z variance train             0.016391393
KL Divergence                26.300905
KL Loss                      2.6300905
QF Loss                      1285.4032
VF Loss                      247.18185
Policy Loss                  -1328.0199
Q Predictions Mean           1333.8522
Q Predictions Std            417.61658
Q Predictions Max            1598.2458
Q Predictions Min            -105.07578
V Predictions Mean           1339.3254
V Predictions Std            420.09952
V Predictions Max            1580.5083
V Predictions Min            -99.22567
Log Pis Mean                 0.41093856
Log Pis Std                  3.3837266
Log Pis Max                  10.364038
Log Pis Min                  -9.138803
Policy mu Mean               0.049048588
Policy mu Std                0.6455508
Policy mu Max                2.4342642
Policy mu Min                -2.596382
Policy log std Mean          -1.0045384
Policy log std Std           0.31618717
Policy log std Max           -0.041620255
Policy log std Min           -2.6298046
Z mean eval                  1.269474
Z variance eval              0.009250642
total_rewards                [3796.57251575 2384.06685001 1063.3531996  1636.51495735 3761.96879061
 3814.01175284 2477.59251483 3263.36208337 1006.36894618  132.19512358]
total_rewards_mean           2333.6006734106154
total_rewards_std            1263.6084603822987
total_rewards_max            3814.011752839335
total_rewards_min            132.19512357837118
Number of train steps total  1128000
Number of env steps total    1412000
Number of rollouts total     0
Train Time (s)               132.70203645620495
(Previous) Eval Time (s)     23.779630691744387
Sample Time (s)              23.648489816579968
Epoch Time (s)               180.1301569645293
Total Train Time (s)         51803.381834593136
Epoch                        281
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:56:19.241542 UTC | [2020_01_11_13_32_55] Iteration #281 | Epoch Duration: 182.50421857833862
2020-01-12 03:56:19.241846 UTC | [2020_01_11_13_32_55] Iteration #281 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2697062
Z variance train             0.009220853
KL Divergence                27.540304
KL Loss                      2.7540305
QF Loss                      1045.5005
VF Loss                      194.25447
Policy Loss                  -1354.8391
Q Predictions Mean           1354.9692
Q Predictions Std            387.17184
Q Predictions Max            1591.3684
Q Predictions Min            -87.77192
V Predictions Mean           1353.7773
V Predictions Std            386.4741
V Predictions Max            1600.3033
V Predictions Min            -104.3115
Log Pis Mean                 0.26720858
Log Pis Std                  3.035709
Log Pis Max                  10.791913
Log Pis Min                  -7.3060474
Policy mu Mean               0.0068705915
Policy mu Std                0.664914
Policy mu Max                2.6402388
Policy mu Min                -2.7625816
Policy log std Mean          -0.97598135
Policy log std Std           0.31351975
Policy log std Max           -0.18216759
Policy log std Min           -2.5000067
Z mean eval                  1.1323994
Z variance eval              0.010274054
total_rewards                [ 652.03882569 3537.33208801 1041.10615861 2451.22459559 2255.76236674
 3079.47257518 3949.55844041  773.73485184 3772.72930766 1348.27755661]
total_rewards_mean           2286.1236766343304
total_rewards_std            1207.778697613962
total_rewards_max            3949.5584404072133
total_rewards_min            652.0388256900128
Number of train steps total  1132000
Number of env steps total    1417000
Number of rollouts total     0
Train Time (s)               133.39092005090788
(Previous) Eval Time (s)     26.153366470243782
Sample Time (s)              24.49491170560941
Epoch Time (s)               184.03919822676107
Total Train Time (s)         51989.185455577914
Epoch                        282
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:59:25.048518 UTC | [2020_01_11_13_32_55] Iteration #282 | Epoch Duration: 185.8064637184143
2020-01-12 03:59:25.048706 UTC | [2020_01_11_13_32_55] Iteration #282 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1321076
Z variance train             0.010284915
KL Divergence                27.830908
KL Loss                      2.7830908
QF Loss                      569.52527
VF Loss                      131.97893
Policy Loss                  -1354.8865
Q Predictions Mean           1355.6582
Q Predictions Std            377.593
Q Predictions Max            1593.4614
Q Predictions Min            -114.88273
V Predictions Mean           1359.2285
V Predictions Std            372.6921
V Predictions Max            1598.9304
V Predictions Min            -90.40996
Log Pis Mean                 0.48487717
Log Pis Std                  3.118948
Log Pis Max                  15.678753
Log Pis Min                  -6.443083
Policy mu Mean               0.0345568
Policy mu Std                0.663975
Policy mu Max                2.6744587
Policy mu Min                -2.926937
Policy log std Mean          -0.97941566
Policy log std Std           0.2987439
Policy log std Max           -0.14665508
Policy log std Min           -2.5753603
Z mean eval                  1.1629595
Z variance eval              0.016191835
total_rewards                [3880.37945859   98.46501383 3698.53361856 3679.49134513 3798.43985905
 3887.68166955  137.83047986 1320.23868669  174.23118661  310.43530116]
total_rewards_mean           2098.572661903702
total_rewards_std            1722.6648993753295
total_rewards_max            3887.6816695537805
total_rewards_min            98.46501383486303
Number of train steps total  1136000
Number of env steps total    1422000
Number of rollouts total     0
Train Time (s)               139.50370161794126
(Previous) Eval Time (s)     27.920283421874046
Sample Time (s)              24.402589777950197
Epoch Time (s)               191.8265748177655
Total Train Time (s)         52183.72613781225
Epoch                        283
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:02:39.592389 UTC | [2020_01_11_13_32_55] Iteration #283 | Epoch Duration: 194.54354000091553
2020-01-12 04:02:39.592602 UTC | [2020_01_11_13_32_55] Iteration #283 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1613517
Z variance train             0.016210495
KL Divergence                27.833004
KL Loss                      2.7833004
QF Loss                      1053.8174
VF Loss                      221.15396
Policy Loss                  -1359.4691
Q Predictions Mean           1361.1973
Q Predictions Std            368.08252
Q Predictions Max            1589.596
Q Predictions Min            -94.93377
V Predictions Mean           1364.769
V Predictions Std            362.49048
V Predictions Max            1603.6956
V Predictions Min            -99.45606
Log Pis Mean                 0.4970799
Log Pis Std                  3.1258154
Log Pis Max                  19.677153
Log Pis Min                  -7.387359
Policy mu Mean               0.01776878
Policy mu Std                0.6705811
Policy mu Max                2.498348
Policy mu Min                -2.8420126
Policy log std Mean          -0.9902357
Policy log std Std           0.32486403
Policy log std Max           -0.114032686
Policy log std Min           -2.9189978
Z mean eval                  1.1394246
Z variance eval              0.010136254
total_rewards                [3774.35620946  172.10536606 3188.56205424 3853.45511511 2534.4687235
 3926.04214878 2425.70939976 2702.29105741 3822.94594107 1847.17892797]
total_rewards_mean           2824.7114943359047
total_rewards_std            1120.3680852393136
total_rewards_max            3926.0421487841586
total_rewards_min            172.10536605714864
Number of train steps total  1140000
Number of env steps total    1427000
Number of rollouts total     0
Train Time (s)               141.74675989476964
(Previous) Eval Time (s)     30.636860812082887
Sample Time (s)              26.792926324997097
Epoch Time (s)               199.17654703184962
Total Train Time (s)         52382.27554040542
Epoch                        284
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:05:58.145054 UTC | [2020_01_11_13_32_55] Iteration #284 | Epoch Duration: 198.55231738090515
2020-01-12 04:05:58.145237 UTC | [2020_01_11_13_32_55] Iteration #284 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1386298
Z variance train             0.0100621255
KL Divergence                28.427769
KL Loss                      2.842777
QF Loss                      870.8387
VF Loss                      213.06232
Policy Loss                  -1332.8302
Q Predictions Mean           1335.0576
Q Predictions Std            398.54517
Q Predictions Max            1598.3738
Q Predictions Min            -113.46374
V Predictions Mean           1333.7188
V Predictions Std            396.34518
V Predictions Max            1597.0488
V Predictions Min            -103.125244
Log Pis Mean                 0.032025114
Log Pis Std                  3.1326165
Log Pis Max                  15.381057
Log Pis Min                  -6.485584
Policy mu Mean               0.072196245
Policy mu Std                0.6115429
Policy mu Max                2.9644847
Policy mu Min                -2.4518135
Policy log std Mean          -0.97952545
Policy log std Std           0.31795168
Policy log std Max           -0.14576411
Policy log std Min           -2.8274374
Z mean eval                  1.1794579
Z variance eval              0.0151935
total_rewards                [1302.59747362 3959.2268236  2217.3711278   238.32384267 1684.17531962
 2363.50126556 3712.11723281  897.77039099 1218.27290563  999.89874799]
total_rewards_mean           1859.3255130285884
total_rewards_std            1151.8347841935743
total_rewards_max            3959.226823596341
total_rewards_min            238.32384266751274
Number of train steps total  1144000
Number of env steps total    1432000
Number of rollouts total     0
Train Time (s)               140.54026543768123
(Previous) Eval Time (s)     30.012293376028538
Sample Time (s)              25.42781005613506
Epoch Time (s)               195.98036886984482
Total Train Time (s)         52570.15775480261
Epoch                        285
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:09:06.030783 UTC | [2020_01_11_13_32_55] Iteration #285 | Epoch Duration: 187.88539934158325
2020-01-12 04:09:06.030972 UTC | [2020_01_11_13_32_55] Iteration #285 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1798191
Z variance train             0.015153441
KL Divergence                26.308697
KL Loss                      2.6308696
QF Loss                      1320.5187
VF Loss                      411.23196
Policy Loss                  -1405.8783
Q Predictions Mean           1407.5093
Q Predictions Std            263.03305
Q Predictions Max            1602.3381
Q Predictions Min            -51.111332
V Predictions Mean           1409.6394
V Predictions Std            255.2485
V Predictions Max            1588.2545
V Predictions Min            -54.912636
Log Pis Mean                 0.7911056
Log Pis Std                  3.2006483
Log Pis Max                  18.936161
Log Pis Min                  -7.722459
Policy mu Mean               0.0074132252
Policy mu Std                0.6698184
Policy mu Max                3.518703
Policy mu Min                -2.6602886
Policy log std Mean          -1.0374773
Policy log std Std           0.31100908
Policy log std Max           -0.14573699
Policy log std Min           -2.5481572
Z mean eval                  1.1738358
Z variance eval              0.010127736
total_rewards                [3741.32728488 4059.73485808 3514.31149915 2374.81980941 3797.73247429
  846.33887751 2064.44260207 3880.82218682 3872.2732103  3956.78543114]
total_rewards_mean           3210.858823363891
total_rewards_std            1023.9826113273627
total_rewards_max            4059.7348580771745
total_rewards_min            846.3388775062143
Number of train steps total  1148000
Number of env steps total    1437000
Number of rollouts total     0
Train Time (s)               141.11967473477125
(Previous) Eval Time (s)     21.9168803691864
Sample Time (s)              25.61207009991631
Epoch Time (s)               188.64862520387396
Total Train Time (s)         52765.96177046839
Epoch                        286
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:12:21.838032 UTC | [2020_01_11_13_32_55] Iteration #286 | Epoch Duration: 195.80692172050476
2020-01-12 04:12:21.838218 UTC | [2020_01_11_13_32_55] Iteration #286 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1731107
Z variance train             0.0101204235
KL Divergence                27.47104
KL Loss                      2.7471042
QF Loss                      689.23914
VF Loss                      148.07799
Policy Loss                  -1393.6656
Q Predictions Mean           1396.5066
Q Predictions Std            330.2282
Q Predictions Max            1623.9349
Q Predictions Min            -40.613018
V Predictions Mean           1390.85
V Predictions Std            329.38297
V Predictions Max            1616.1182
V Predictions Min            -36.907288
Log Pis Mean                 0.72348136
Log Pis Std                  2.9885013
Log Pis Max                  13.851634
Log Pis Min                  -6.4890695
Policy mu Mean               0.03635977
Policy mu Std                0.6368788
Policy mu Max                2.7334
Policy mu Min                -2.013396
Policy log std Mean          -1.0339261
Policy log std Std           0.3074145
Policy log std Max           -0.06559944
Policy log std Min           -2.446159
Z mean eval                  1.1464498
Z variance eval              0.015199505
total_rewards                [  28.55630414 3673.48855361 3910.27506221 3645.68353693 2497.20128789
  781.70850078  445.17987578  258.68466144 1541.2491607  2748.40927897]
total_rewards_mean           1953.04362224523
total_rewards_std            1448.246770893947
total_rewards_max            3910.275062212968
total_rewards_min            28.55630414142785
Number of train steps total  1152000
Number of env steps total    1442000
Number of rollouts total     0
Train Time (s)               139.103212792892
(Previous) Eval Time (s)     29.074853286147118
Sample Time (s)              26.302975272294134
Epoch Time (s)               194.48104135133326
Total Train Time (s)         52957.45506631443
Epoch                        287
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:15:33.335253 UTC | [2020_01_11_13_32_55] Iteration #287 | Epoch Duration: 191.49686336517334
2020-01-12 04:15:33.335500 UTC | [2020_01_11_13_32_55] Iteration #287 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1466706
Z variance train             0.01520851
KL Divergence                25.62144
KL Loss                      2.562144
QF Loss                      953.2492
VF Loss                      322.07507
Policy Loss                  -1367.3269
Q Predictions Mean           1368.0896
Q Predictions Std            388.28482
Q Predictions Max            1599.8169
Q Predictions Min            -121.0246
V Predictions Mean           1377.06
V Predictions Std            379.22812
V Predictions Max            1618.9731
V Predictions Min            -102.139694
Log Pis Mean                 0.547176
Log Pis Std                  3.053553
Log Pis Max                  14.413866
Log Pis Min                  -9.260748
Policy mu Mean               0.047865354
Policy mu Std                0.66186035
Policy mu Max                2.7206676
Policy mu Min                -2.5824943
Policy log std Mean          -0.98883545
Policy log std Std           0.32494855
Policy log std Max           0.21694541
Policy log std Min           -3.0223646
Z mean eval                  1.1891073
Z variance eval              0.02175462
total_rewards                [3672.17868519 3713.61513223  912.98488599 3919.4815134  2861.97973214
 2367.79005121 3788.09595461 3535.77257522 3649.0059123  3748.81643809]
total_rewards_mean           3216.972088036415
total_rewards_std            894.4384519559256
total_rewards_max            3919.4815133969905
total_rewards_min            912.9848859868061
Number of train steps total  1156000
Number of env steps total    1447000
Number of rollouts total     0
Train Time (s)               134.11366182100028
(Previous) Eval Time (s)     26.090296240057796
Sample Time (s)              24.997030542232096
Epoch Time (s)               185.20098860329017
Total Train Time (s)         53147.65964446543
Epoch                        288
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:18:43.542543 UTC | [2020_01_11_13_32_55] Iteration #288 | Epoch Duration: 190.20690059661865
2020-01-12 04:18:43.542724 UTC | [2020_01_11_13_32_55] Iteration #288 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1942763
Z variance train             0.021691903
KL Divergence                24.829712
KL Loss                      2.4829712
QF Loss                      1462.5002
VF Loss                      157.50116
Policy Loss                  -1394.6486
Q Predictions Mean           1397.2025
Q Predictions Std            341.4494
Q Predictions Max            1598.0438
Q Predictions Min            -132.1284
V Predictions Mean           1399.4535
V Predictions Std            340.45444
V Predictions Max            1613.0067
V Predictions Min            -121.630806
Log Pis Mean                 0.37169904
Log Pis Std                  2.9556975
Log Pis Max                  11.822252
Log Pis Min                  -6.1615496
Policy mu Mean               -0.03304363
Policy mu Std                0.6572513
Policy mu Max                2.89499
Policy mu Min                -2.4702277
Policy log std Mean          -0.9986149
Policy log std Std           0.28498417
Policy log std Max           -0.14484799
Policy log std Min           -2.353869
Z mean eval                  1.1349108
Z variance eval              0.019169904
total_rewards                [3778.46152539 3836.35457329   14.21471048 1024.8526367   696.46008736
 2871.17954733 3769.3613501  3892.9642923  3804.83927538 3837.84681011]
total_rewards_mean           2752.653480845146
total_rewards_std            1468.7326408890722
total_rewards_max            3892.964292295961
total_rewards_min            14.214710483283334
Number of train steps total  1160000
Number of env steps total    1452000
Number of rollouts total     0
Train Time (s)               134.7965585240163
(Previous) Eval Time (s)     31.095863334834576
Sample Time (s)              24.71132858330384
Epoch Time (s)               190.6037504421547
Total Train Time (s)         53334.6484758975
Epoch                        289
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:21:50.535092 UTC | [2020_01_11_13_32_55] Iteration #289 | Epoch Duration: 186.99223566055298
2020-01-12 04:21:50.535322 UTC | [2020_01_11_13_32_55] Iteration #289 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1343595
Z variance train             0.019228693
KL Divergence                25.063488
KL Loss                      2.5063488
QF Loss                      2184.779
VF Loss                      383.47217
Policy Loss                  -1365.556
Q Predictions Mean           1367.6917
Q Predictions Std            347.02347
Q Predictions Max            1574.657
Q Predictions Min            -123.51309
V Predictions Mean           1371.9957
V Predictions Std            344.38577
V Predictions Max            1578.8069
V Predictions Min            -122.73425
Log Pis Mean                 0.90906405
Log Pis Std                  3.5725021
Log Pis Max                  16.541674
Log Pis Min                  -7.6591115
Policy mu Mean               0.008989019
Policy mu Std                0.6757827
Policy mu Max                2.928748
Policy mu Min                -2.7151647
Policy log std Mean          -1.0264394
Policy log std Std           0.34655583
Policy log std Max           -0.1684928
Policy log std Min           -2.821262
Z mean eval                  1.2022834
Z variance eval              0.010251294
total_rewards                [2596.66336635 1219.46379113 1573.67960802 1155.98742911 2187.77232343
 2633.75864231 1459.01867103 2795.70688984 1195.88626755 1088.75139934]
total_rewards_mean           1790.668838810962
total_rewards_std            652.751600075791
total_rewards_max            2795.7068898448088
total_rewards_min            1088.751399340357
Number of train steps total  1164000
Number of env steps total    1457000
Number of rollouts total     0
Train Time (s)               143.99380005709827
(Previous) Eval Time (s)     27.48400217294693
Sample Time (s)              25.94748641969636
Epoch Time (s)               197.42528864974156
Total Train Time (s)         53526.82840800984
Epoch                        290
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:25:02.718917 UTC | [2020_01_11_13_32_55] Iteration #290 | Epoch Duration: 192.18344736099243
2020-01-12 04:25:02.719157 UTC | [2020_01_11_13_32_55] Iteration #290 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2002228
Z variance train             0.010206443
KL Divergence                27.010479
KL Loss                      2.701048
QF Loss                      614.15393
VF Loss                      211.26895
Policy Loss                  -1382.1473
Q Predictions Mean           1388.7026
Q Predictions Std            347.00223
Q Predictions Max            1623.3024
Q Predictions Min            -152.6334
V Predictions Mean           1385.96
V Predictions Std            343.1761
V Predictions Max            1623.1233
V Predictions Min            -153.3353
Log Pis Mean                 0.042940833
Log Pis Std                  2.8339381
Log Pis Max                  9.799273
Log Pis Min                  -7.828173
Policy mu Mean               0.022738669
Policy mu Std                0.65836626
Policy mu Max                2.595737
Policy mu Min                -2.5053303
Policy log std Mean          -0.98113024
Policy log std Std           0.26941127
Policy log std Max           -0.14431751
Policy log std Min           -2.3629365
Z mean eval                  1.1839514
Z variance eval              0.01709793
total_rewards                [3291.94141899 2823.01488503 1611.49484577 3369.23299688  234.91725139
 3753.15163666 1572.22237455 1755.71748014 3776.2354801  1101.87763657]
total_rewards_mean           2328.9806006075696
total_rewards_std            1169.7555602478255
total_rewards_max            3776.2354800998255
total_rewards_min            234.91725138620868
Number of train steps total  1168000
Number of env steps total    1462000
Number of rollouts total     0
Train Time (s)               141.81848791101947
(Previous) Eval Time (s)     22.24168910412118
Sample Time (s)              25.78589668124914
Epoch Time (s)               189.8460736963898
Total Train Time (s)         53716.29485485423
Epoch                        291
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:28:12.188500 UTC | [2020_01_11_13_32_55] Iteration #291 | Epoch Duration: 189.4691503047943
2020-01-12 04:28:12.188679 UTC | [2020_01_11_13_32_55] Iteration #291 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1856284
Z variance train             0.017205603
KL Divergence                25.863827
KL Loss                      2.5863826
QF Loss                      994.38983
VF Loss                      594.1692
Policy Loss                  -1360.1688
Q Predictions Mean           1362.1422
Q Predictions Std            367.86588
Q Predictions Max            1589.7017
Q Predictions Min            -139.39273
V Predictions Mean           1356.5458
V Predictions Std            365.88797
V Predictions Max            1569.147
V Predictions Min            -130.45284
Log Pis Mean                 0.7932352
Log Pis Std                  3.401608
Log Pis Max                  15.802818
Log Pis Min                  -7.118352
Policy mu Mean               0.004036945
Policy mu Std                0.68272567
Policy mu Max                2.7666647
Policy mu Min                -2.9822109
Policy log std Mean          -1.0306926
Policy log std Std           0.32959113
Policy log std Max           -0.18656415
Policy log std Min           -2.5163922
Z mean eval                  1.1290312
Z variance eval              0.016446894
total_rewards                [3313.40166679 1053.26073385 3821.44828385 1030.58414545 3761.73248418
  909.25004946  535.02682079  626.87413868 1034.18474346 1128.11656403]
total_rewards_mean           1721.3879630547958
total_rewards_std            1269.668111665311
total_rewards_max            3821.448283845169
total_rewards_min            535.0268207857192
Number of train steps total  1172000
Number of env steps total    1467000
Number of rollouts total     0
Train Time (s)               141.52365129813552
(Previous) Eval Time (s)     21.86440480640158
Sample Time (s)              25.166379696223885
Epoch Time (s)               188.55443580076098
Total Train Time (s)         53902.10726128565
Epoch                        292
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:31:18.003927 UTC | [2020_01_11_13_32_55] Iteration #292 | Epoch Duration: 185.81512451171875
2020-01-12 04:31:18.004124 UTC | [2020_01_11_13_32_55] Iteration #292 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1261063
Z variance train             0.016399119
KL Divergence                26.248726
KL Loss                      2.6248727
QF Loss                      2293.6416
VF Loss                      175.79425
Policy Loss                  -1378.4487
Q Predictions Mean           1381.21
Q Predictions Std            351.37524
Q Predictions Max            1613.5299
Q Predictions Min            -95.015785
V Predictions Mean           1380.7238
V Predictions Std            353.23047
V Predictions Max            1607.7242
V Predictions Min            -82.6979
Log Pis Mean                 0.38280421
Log Pis Std                  2.9678364
Log Pis Max                  9.3702
Log Pis Min                  -6.543582
Policy mu Mean               0.02774273
Policy mu Std                0.65651494
Policy mu Max                2.6303947
Policy mu Min                -2.3957083
Policy log std Mean          -0.98973197
Policy log std Std           0.30976605
Policy log std Max           -0.104846716
Policy log std Min           -2.6734056
Z mean eval                  1.1730323
Z variance eval              0.009355916
total_rewards                [ 798.17233026 3678.8673318  3860.61640525 1017.88861313  665.43487896
  381.90653874 2922.01443897  573.60431474 2324.61780322 2549.10336722]
total_rewards_mean           1877.2226022292848
total_rewards_std            1273.9535144401423
total_rewards_max            3860.616405246766
total_rewards_min            381.9065387393453
Number of train steps total  1176000
Number of env steps total    1472000
Number of rollouts total     0
Train Time (s)               140.86827939003706
(Previous) Eval Time (s)     19.1247546072118
Sample Time (s)              25.8802498918958
Epoch Time (s)               185.87328388914466
Total Train Time (s)         54096.125588143244
Epoch                        293
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:34:32.025812 UTC | [2020_01_11_13_32_55] Iteration #293 | Epoch Duration: 194.02153134346008
2020-01-12 04:34:32.026083 UTC | [2020_01_11_13_32_55] Iteration #293 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1713287
Z variance train             0.009350586
KL Divergence                26.832272
KL Loss                      2.6832273
QF Loss                      665.76624
VF Loss                      1032.1498
Policy Loss                  -1363.2957
Q Predictions Mean           1361.7725
Q Predictions Std            388.68396
Q Predictions Max            1605.2216
Q Predictions Min            -75.646286
V Predictions Mean           1364.3447
V Predictions Std            378.10104
V Predictions Max            1600.8116
V Predictions Min            -84.47179
Log Pis Mean                 0.95102066
Log Pis Std                  3.43585
Log Pis Max                  18.704292
Log Pis Min                  -6.412132
Policy mu Mean               -0.026143506
Policy mu Std                0.6537822
Policy mu Max                2.894665
Policy mu Min                -2.3826776
Policy log std Mean          -1.0627867
Policy log std Std           0.32043314
Policy log std Max           -0.19196558
Policy log std Min           -2.6506808
Z mean eval                  1.181477
Z variance eval              0.0097321095
total_rewards                [3625.68696568 3917.56423815 3806.94626709  600.54719755 3768.16766125
 3505.08440217 3711.39548201 3881.32588389 2093.52736288 3822.576616  ]
total_rewards_mean           3273.282207666788
total_rewards_std            1025.7411113236012
total_rewards_max            3917.5642381500934
total_rewards_min            600.5471975511693
Number of train steps total  1180000
Number of env steps total    1477000
Number of rollouts total     0
Train Time (s)               134.60899238521233
(Previous) Eval Time (s)     27.27262421278283
Sample Time (s)              26.833295141812414
Epoch Time (s)               188.71491173980758
Total Train Time (s)         54288.78876070166
Epoch                        294
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:37:44.692296 UTC | [2020_01_11_13_32_55] Iteration #294 | Epoch Duration: 192.66606259346008
2020-01-12 04:37:44.692493 UTC | [2020_01_11_13_32_55] Iteration #294 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1810877
Z variance train             0.009744205
KL Divergence                27.333618
KL Loss                      2.733362
QF Loss                      2979.1382
VF Loss                      259.94864
Policy Loss                  -1342.5752
Q Predictions Mean           1346.2278
Q Predictions Std            400.01413
Q Predictions Max            1585.0829
Q Predictions Min            -146.36607
V Predictions Mean           1345.264
V Predictions Std            400.17422
V Predictions Max            1580.7692
V Predictions Min            -138.14546
Log Pis Mean                 0.55216587
Log Pis Std                  3.0249212
Log Pis Max                  14.988116
Log Pis Min                  -8.620712
Policy mu Mean               -0.0052915933
Policy mu Std                0.63384277
Policy mu Max                2.2237093
Policy mu Min                -2.804928
Policy log std Mean          -1.0104153
Policy log std Std           0.33170798
Policy log std Max           0.13092864
Policy log std Min           -3.190473
Z mean eval                  1.1777121
Z variance eval              0.009189033
total_rewards                [ 434.7135147   435.29794181 3825.83611573 1536.64685755 1547.86319359
 3172.91505483 1744.32542439 1219.07422925 1129.63458962 3635.28393764]
total_rewards_mean           1868.1590859124194
total_rewards_std            1181.5256735122994
total_rewards_max            3825.8361157333247
total_rewards_min            434.71351470280746
Number of train steps total  1184000
Number of env steps total    1482000
Number of rollouts total     0
Train Time (s)               134.9895401932299
(Previous) Eval Time (s)     31.22334855608642
Sample Time (s)              25.213462331332266
Epoch Time (s)               191.4263510806486
Total Train Time (s)         54472.10481699929
Epoch                        295
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:40:48.012012 UTC | [2020_01_11_13_32_55] Iteration #295 | Epoch Duration: 183.31938481330872
2020-01-12 04:40:48.012199 UTC | [2020_01_11_13_32_55] Iteration #295 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1780581
Z variance train             0.009198502
KL Divergence                27.879856
KL Loss                      2.7879856
QF Loss                      669.2932
VF Loss                      314.17014
Policy Loss                  -1377.8086
Q Predictions Mean           1380.0728
Q Predictions Std            368.93005
Q Predictions Max            1627.1206
Q Predictions Min            -134.00996
V Predictions Mean           1385.1296
V Predictions Std            367.5236
V Predictions Max            1633.3641
V Predictions Min            -131.81996
Log Pis Mean                 0.27793834
Log Pis Std                  2.8942292
Log Pis Max                  11.666714
Log Pis Min                  -8.6798115
Policy mu Mean               -0.014773111
Policy mu Std                0.6273236
Policy mu Max                2.5107703
Policy mu Min                -2.2644475
Policy log std Mean          -1.0014415
Policy log std Std           0.30797103
Policy log std Max           -0.18740785
Policy log std Min           -2.7341995
Z mean eval                  1.1961515
Z variance eval              0.01111676
total_rewards                [1983.18963831 3723.21327968  175.4501013  3574.79612926  332.96958378
  982.76527673 3508.71995109 3651.05190313 3248.81335755  587.34741791]
total_rewards_mean           2176.831663874288
total_rewards_std            1443.5063107512353
total_rewards_max            3723.2132796844126
total_rewards_min            175.4501013035319
Number of train steps total  1188000
Number of env steps total    1487000
Number of rollouts total     0
Train Time (s)               138.0931988907978
(Previous) Eval Time (s)     23.11606133170426
Sample Time (s)              24.902864473871887
Epoch Time (s)               186.11212469637394
Total Train Time (s)         54658.953045600094
Epoch                        296
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:43:54.863691 UTC | [2020_01_11_13_32_55] Iteration #296 | Epoch Duration: 186.85134482383728
2020-01-12 04:43:54.863964 UTC | [2020_01_11_13_32_55] Iteration #296 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2006499
Z variance train             0.011110651
KL Divergence                28.368494
KL Loss                      2.8368495
QF Loss                      1135.425
VF Loss                      394.79553
Policy Loss                  -1334.229
Q Predictions Mean           1338.4443
Q Predictions Std            401.47018
Q Predictions Max            1591.2932
Q Predictions Min            -91.70955
V Predictions Mean           1336.4102
V Predictions Std            400.76254
V Predictions Max            1586.5001
V Predictions Min            -101.25912
Log Pis Mean                 0.41274387
Log Pis Std                  3.5161815
Log Pis Max                  22.808537
Log Pis Min                  -6.457232
Policy mu Mean               0.031465385
Policy mu Std                0.66119474
Policy mu Max                2.499962
Policy mu Min                -2.4786842
Policy log std Mean          -0.9876998
Policy log std Std           0.31646955
Policy log std Max           -0.08084154
Policy log std Min           -3.234806
Z mean eval                  1.1662256
Z variance eval              0.013449421
total_rewards                [2744.74862738  713.34828899  803.47773826  666.11599869  479.77196537
  330.44112593 3607.24631605 2899.7433112   792.57176579 4040.73937107]
total_rewards_mean           1707.8204508741314
total_rewards_std            1366.7898626005458
total_rewards_max            4040.7393710673787
total_rewards_min            330.4411259311764
Number of train steps total  1192000
Number of env steps total    1492000
Number of rollouts total     0
Train Time (s)               143.47038439614698
(Previous) Eval Time (s)     23.854959232732654
Sample Time (s)              24.836050987243652
Epoch Time (s)               192.1613946161233
Total Train Time (s)         54846.86750465166
Epoch                        297
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:47:02.779726 UTC | [2020_01_11_13_32_55] Iteration #297 | Epoch Duration: 187.91560411453247
2020-01-12 04:47:02.779853 UTC | [2020_01_11_13_32_55] Iteration #297 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1669819
Z variance train             0.013460934
KL Divergence                27.5148
KL Loss                      2.7514799
QF Loss                      943.86
VF Loss                      323.99142
Policy Loss                  -1368.3544
Q Predictions Mean           1367.331
Q Predictions Std            371.97302
Q Predictions Max            1599.4714
Q Predictions Min            -67.369736
V Predictions Mean           1358.8541
V Predictions Std            366.00922
V Predictions Max            1577.4098
V Predictions Min            -56.514683
Log Pis Mean                 0.46516395
Log Pis Std                  3.2377288
Log Pis Max                  19.288464
Log Pis Min                  -7.0995064
Policy mu Mean               0.010800935
Policy mu Std                0.6685709
Policy mu Max                5.029246
Policy mu Min                -2.4925475
Policy log std Mean          -1.006834
Policy log std Std           0.31539416
Policy log std Max           -0.20479214
Policy log std Min           -2.679428
Z mean eval                  1.1934483
Z variance eval              0.013896212
total_rewards                [3710.89774001 3804.48608878 3976.06524988 3785.63732686   43.90022583
 2619.69571854 3506.84131183 3543.17139075 3763.36831061 3685.48743986]
total_rewards_mean           3243.95508029556
total_rewards_std            1123.168141352486
total_rewards_max            3976.0652498817626
total_rewards_min            43.900225826950965
Number of train steps total  1196000
Number of env steps total    1497000
Number of rollouts total     0
Train Time (s)               141.32043216191232
(Previous) Eval Time (s)     19.60881357593462
Sample Time (s)              25.5878191543743
Epoch Time (s)               186.51706489222124
Total Train Time (s)         55049.42356825434
Epoch                        298
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:50:25.339945 UTC | [2020_01_11_13_32_55] Iteration #298 | Epoch Duration: 202.55998301506042
2020-01-12 04:50:25.340180 UTC | [2020_01_11_13_32_55] Iteration #298 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1896337
Z variance train             0.014034684
KL Divergence                29.422585
KL Loss                      2.9422586
QF Loss                      751.06995
VF Loss                      201.27325
Policy Loss                  -1384.8568
Q Predictions Mean           1388.6011
Q Predictions Std            351.64978
Q Predictions Max            1599.0254
Q Predictions Min            -158.78503
V Predictions Mean           1386.6306
V Predictions Std            351.66745
V Predictions Max            1608.2583
V Predictions Min            -162.37921
Log Pis Mean                 0.19811603
Log Pis Std                  2.9238372
Log Pis Max                  9.530273
Log Pis Min                  -7.9407463
Policy mu Mean               0.018536294
Policy mu Std                0.6656734
Policy mu Max                2.5218637
Policy mu Min                -2.274435
Policy log std Mean          -0.99594903
Policy log std Std           0.28676307
Policy log std Max           -0.1760726
Policy log std Min           -2.62283
Z mean eval                  1.1470953
Z variance eval              0.011290827
total_rewards                [3894.53214783 3902.39466213 3956.87265012 2160.83682966 3555.70332111
 3980.60961349 3202.93841532 2264.49725347  317.76325448 1017.52362544]
total_rewards_mean           2825.3671773072115
total_rewards_std            1261.209497965832
total_rewards_max            3980.609613491702
total_rewards_min            317.76325447898796
Number of train steps total  1200000
Number of env steps total    1502000
Number of rollouts total     0
Train Time (s)               144.17825190210715
(Previous) Eval Time (s)     35.651320533361286
Sample Time (s)              25.918601477518678
Epoch Time (s)               205.7481739129871
Total Train Time (s)         55246.6537200422
Epoch                        299
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:53:42.573454 UTC | [2020_01_11_13_32_55] Iteration #299 | Epoch Duration: 197.23313570022583
2020-01-12 04:53:42.573641 UTC | [2020_01_11_13_32_55] Iteration #299 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1473503
Z variance train             0.011286527
KL Divergence                27.950989
KL Loss                      2.795099
QF Loss                      3633.874
VF Loss                      1315.8177
Policy Loss                  -1357.6182
Q Predictions Mean           1357.7798
Q Predictions Std            375.54874
Q Predictions Max            1592.8776
Q Predictions Min            -120.352
V Predictions Mean           1349.175
V Predictions Std            371.0596
V Predictions Max            1574.4453
V Predictions Min            -137.01299
Log Pis Mean                 0.4201674
Log Pis Std                  3.1609116
Log Pis Max                  11.424637
Log Pis Min                  -7.4555097
Policy mu Mean               0.0085276505
Policy mu Std                0.6697944
Policy mu Max                2.6454184
Policy mu Min                -2.6127582
Policy log std Mean          -0.9819062
Policy log std Std           0.3263589
Policy log std Max           -0.10145652
Policy log std Min           -2.7220573
Z mean eval                  1.1778982
Z variance eval              0.014322171
total_rewards                [3796.70264997  285.69380191 3877.31109307   34.15267495 2078.33786796
 3630.42361216 2116.01963943 3813.31385713 3783.31733717 3830.09890368]
total_rewards_mean           2724.537143741786
total_rewards_std            1442.2817502952298
total_rewards_max            3877.311093074665
total_rewards_min            34.152674945078736
Number of train steps total  1204000
Number of env steps total    1507000
Number of rollouts total     0
Train Time (s)               142.0206813919358
(Previous) Eval Time (s)     27.13583806157112
Sample Time (s)              24.741439182776958
Epoch Time (s)               193.89795863628387
Total Train Time (s)         55443.50595067348
Epoch                        300
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:56:59.429259 UTC | [2020_01_11_13_32_55] Iteration #300 | Epoch Duration: 196.85548400878906
2020-01-12 04:56:59.429454 UTC | [2020_01_11_13_32_55] Iteration #300 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.17724
Z variance train             0.014280871
KL Divergence                27.00705
KL Loss                      2.700705
QF Loss                      1097.802
VF Loss                      374.8672
Policy Loss                  -1358.2714
Q Predictions Mean           1359.0928
Q Predictions Std            381.22882
Q Predictions Max            1588.2399
Q Predictions Min            -42.757774
V Predictions Mean           1367.2942
V Predictions Std            384.12903
V Predictions Max            1585.9027
V Predictions Min            -53.820484
Log Pis Mean                 0.88280445
Log Pis Std                  3.271547
Log Pis Max                  12.826986
Log Pis Min                  -5.767796
Policy mu Mean               -0.012631678
Policy mu Std                0.6603385
Policy mu Max                2.7399173
Policy mu Min                -4.6377087
Policy log std Mean          -1.0431235
Policy log std Std           0.3275227
Policy log std Max           0.4213091
Policy log std Min           -3.0440798
Z mean eval                  1.1937202
Z variance eval              0.010870976
total_rewards                [ 163.18807333  501.95586822  163.94728014 3163.17599844  620.57971474
 2114.12644858 1531.73631772 2869.80702581 1381.53550481 3692.84478317]
total_rewards_mean           1620.2897014974333
total_rewards_std            1226.3835150522705
total_rewards_max            3692.8447831701415
total_rewards_min            163.18807333346996
Number of train steps total  1208000
Number of env steps total    1512000
Number of rollouts total     0
Train Time (s)               133.68001403613016
(Previous) Eval Time (s)     30.093020626809448
Sample Time (s)              24.591147371102124
Epoch Time (s)               188.36418203404173
Total Train Time (s)         55615.9239955605
Epoch                        301
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:59:51.850838 UTC | [2020_01_11_13_32_55] Iteration #301 | Epoch Duration: 172.4212498664856
2020-01-12 04:59:51.851033 UTC | [2020_01_11_13_32_55] Iteration #301 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1914914
Z variance train             0.010848769
KL Divergence                28.164284
KL Loss                      2.8164284
QF Loss                      868.7272
VF Loss                      151.46703
Policy Loss                  -1421.778
Q Predictions Mean           1425.6804
Q Predictions Std            295.62875
Q Predictions Max            1632.795
Q Predictions Min            -153.17058
V Predictions Mean           1428.0906
V Predictions Std            294.4817
V Predictions Max            1626.5605
V Predictions Min            -137.18085
Log Pis Mean                 0.58777046
Log Pis Std                  3.179678
Log Pis Max                  11.120567
Log Pis Min                  -8.129104
Policy mu Mean               0.026049228
Policy mu Std                0.6674968
Policy mu Max                2.4718962
Policy mu Min                -2.7560856
Policy log std Mean          -1.0189799
Policy log std Std           0.27565917
Policy log std Max           -0.16268653
Policy log std Min           -2.6889036
Z mean eval                  1.1926897
Z variance eval              0.0052304263
total_rewards                [2194.20721033 2165.1961564  3767.87137864 4047.39961414 1818.88777799
 1452.13375129 3776.58393622 1187.34802674 3963.14095778 3774.55894628]
total_rewards_mean           2814.732775581879
total_rewards_std            1090.730044301165
total_rewards_max            4047.3996141402913
total_rewards_min            1187.348026736052
Number of train steps total  1212000
Number of env steps total    1517000
Number of rollouts total     0
Train Time (s)               134.43358770385385
(Previous) Eval Time (s)     14.149766725953668
Sample Time (s)              24.53216651175171
Epoch Time (s)               173.11552094155923
Total Train Time (s)         55804.66956700198
Epoch                        302
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:03:00.600240 UTC | [2020_01_11_13_32_55] Iteration #302 | Epoch Duration: 188.74906945228577
2020-01-12 05:03:00.600446 UTC | [2020_01_11_13_32_55] Iteration #302 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1942146
Z variance train             0.005203317
KL Divergence                28.956451
KL Loss                      2.8956451
QF Loss                      627.9224
VF Loss                      173.7702
Policy Loss                  -1381.8081
Q Predictions Mean           1384.5687
Q Predictions Std            364.62476
Q Predictions Max            1623.3372
Q Predictions Min            -168.00975
V Predictions Mean           1388.0583
V Predictions Std            362.84296
V Predictions Max            1607.3944
V Predictions Min            -155.31215
Log Pis Mean                 0.5278483
Log Pis Std                  3.4154985
Log Pis Max                  19.570507
Log Pis Min                  -7.83026
Policy mu Mean               0.00571581
Policy mu Std                0.70375043
Policy mu Max                3.9418085
Policy mu Min                -2.996979
Policy log std Mean          -0.98434097
Policy log std Std           0.28694952
Policy log std Max           0.05384159
Policy log std Min           -2.5503407
Z mean eval                  1.1860306
Z variance eval              0.008302858
total_rewards                [ 448.06870946 1107.96521465 3840.76483104 3814.81887832 3816.27590723
 3741.69434633 3787.57618387  -11.78689694   96.30986352 3765.09007337]
total_rewards_mean           2440.677711085318
total_rewards_std            1681.0378539612873
total_rewards_max            3840.764831043111
total_rewards_min            -11.786896938622924
Number of train steps total  1216000
Number of env steps total    1522000
Number of rollouts total     0
Train Time (s)               140.95165724586695
(Previous) Eval Time (s)     29.782951646018773
Sample Time (s)              24.206985643599182
Epoch Time (s)               194.9415945354849
Total Train Time (s)         55997.09807755193
Epoch                        303
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:06:13.032578 UTC | [2020_01_11_13_32_55] Iteration #303 | Epoch Duration: 192.43196535110474
2020-01-12 05:06:13.032890 UTC | [2020_01_11_13_32_55] Iteration #303 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1856519
Z variance train             0.0082958
KL Divergence                25.687769
KL Loss                      2.5687768
QF Loss                      2132.7705
VF Loss                      167.62231
Policy Loss                  -1380.142
Q Predictions Mean           1381.5349
Q Predictions Std            359.73022
Q Predictions Max            1607.4927
Q Predictions Min            -141.40187
V Predictions Mean           1380.4934
V Predictions Std            355.7784
V Predictions Max            1604.4342
V Predictions Min            -145.79457
Log Pis Mean                 0.59882534
Log Pis Std                  2.998239
Log Pis Max                  13.320256
Log Pis Min                  -6.846298
Policy mu Mean               0.03334166
Policy mu Std                0.6369389
Policy mu Max                3.0457826
Policy mu Min                -2.1611104
Policy log std Mean          -1.0636278
Policy log std Std           0.31383327
Policy log std Max           -0.106882334
Policy log std Min           -3.013083
Z mean eval                  1.1888319
Z variance eval              0.1305228
total_rewards                [ 380.72503685 2068.55167463 3574.75686625  556.82323524 1498.41559561
   93.5079786   166.74314971 2251.55097366 3653.33710487 3424.34455888]
total_rewards_mean           1766.8756174298874
total_rewards_std            1368.1588958033178
total_rewards_max            3653.3371048671092
total_rewards_min            93.507978600493
Number of train steps total  1220000
Number of env steps total    1527000
Number of rollouts total     0
Train Time (s)               141.80244015576318
(Previous) Eval Time (s)     27.27298758784309
Sample Time (s)              27.98998811049387
Epoch Time (s)               197.06541585410014
Total Train Time (s)         56185.10453418456
Epoch                        304
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:09:21.043770 UTC | [2020_01_11_13_32_55] Iteration #304 | Epoch Duration: 188.0106852054596
2020-01-12 05:09:21.044165 UTC | [2020_01_11_13_32_55] Iteration #304 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1915725
Z variance train             0.1330473
KL Divergence                23.629303
KL Loss                      2.3629303
QF Loss                      723.1987
VF Loss                      2064.8
Policy Loss                  -1414.4739
Q Predictions Mean           1414.1742
Q Predictions Std            372.19818
Q Predictions Max            1641.7368
Q Predictions Min            -155.61642
V Predictions Mean           1399.4448
V Predictions Std            358.96988
V Predictions Max            1600.2651
V Predictions Min            -141.10857
Log Pis Mean                 0.13885677
Log Pis Std                  3.0696044
Log Pis Max                  14.5070915
Log Pis Min                  -9.227236
Policy mu Mean               0.0434087
Policy mu Std                0.60014665
Policy mu Max                3.1030293
Policy mu Min                -2.289126
Policy log std Mean          -1.066584
Policy log std Std           0.28868896
Policy log std Max           -0.27130878
Policy log std Min           -3.2553186
Z mean eval                  1.1856501
Z variance eval              0.04746137
total_rewards                [-157.96410981  305.60531426 3963.35647135 3602.31800747 3582.12087188
   29.91283565 3205.32653923 3335.04018186  236.37219746 3712.62004966]
total_rewards_mean           2181.4708359030424
total_rewards_std            1711.2452232275205
total_rewards_max            3963.356471345208
total_rewards_min            -157.96410980524774
Number of train steps total  1224000
Number of env steps total    1532000
Number of rollouts total     0
Train Time (s)               140.4080318310298
(Previous) Eval Time (s)     18.217782726045698
Sample Time (s)              26.692220599856228
Epoch Time (s)               185.31803515693173
Total Train Time (s)         56381.25946687441
Epoch                        305
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:12:37.202420 UTC | [2020_01_11_13_32_55] Iteration #305 | Epoch Duration: 196.15799140930176
2020-01-12 05:12:37.202764 UTC | [2020_01_11_13_32_55] Iteration #305 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1855485
Z variance train             0.047669612
KL Divergence                23.040897
KL Loss                      2.3040898
QF Loss                      1181.9219
VF Loss                      245.79158
Policy Loss                  -1328.9142
Q Predictions Mean           1332.3516
Q Predictions Std            385.04504
Q Predictions Max            1558.2783
Q Predictions Min            -177.56992
V Predictions Mean           1333.065
V Predictions Std            384.39072
V Predictions Max            1563.1044
V Predictions Min            -183.29048
Log Pis Mean                 0.47250518
Log Pis Std                  3.268722
Log Pis Max                  14.529978
Log Pis Min                  -10.190422
Policy mu Mean               0.013136309
Policy mu Std                0.6059552
Policy mu Max                3.3000622
Policy mu Min                -2.6196015
Policy log std Mean          -1.0790263
Policy log std Std           0.3217821
Policy log std Max           -0.14388442
Policy log std Min           -2.7092385
Z mean eval                  1.2188493
Z variance eval              0.013037853
total_rewards                [3497.03199319 4021.20554446 3338.9407509  2434.84860344 2158.59183072
 2725.08113062 3745.69700765 3862.5193333  3670.07772475 2752.00236411]
total_rewards_mean           3220.5996283154027
total_rewards_std            618.9988080798942
total_rewards_max            4021.2055444551374
total_rewards_min            2158.591830724004
Number of train steps total  1228000
Number of env steps total    1537000
Number of rollouts total     0
Train Time (s)               142.87878833757713
(Previous) Eval Time (s)     29.05732745816931
Sample Time (s)              26.970056204590946
Epoch Time (s)               198.9061720003374
Total Train Time (s)         56583.74539316213
Epoch                        306
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:15:59.692119 UTC | [2020_01_11_13_32_55] Iteration #306 | Epoch Duration: 202.48917627334595
2020-01-12 05:15:59.692323 UTC | [2020_01_11_13_32_55] Iteration #306 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2199626
Z variance train             0.013028505
KL Divergence                25.17796
KL Loss                      2.517796
QF Loss                      1461.4519
VF Loss                      289.61197
Policy Loss                  -1366.6218
Q Predictions Mean           1372.0568
Q Predictions Std            362.25116
Q Predictions Max            1620.6334
Q Predictions Min            -32.299004
V Predictions Mean           1373.5537
V Predictions Std            360.04605
V Predictions Max            1600.6292
V Predictions Min            -16.09534
Log Pis Mean                 0.53748477
Log Pis Std                  3.4501004
Log Pis Max                  17.182917
Log Pis Min                  -7.151207
Policy mu Mean               0.052656844
Policy mu Std                0.64753467
Policy mu Max                2.5016024
Policy mu Min                -3.1092405
Policy log std Mean          -1.0318968
Policy log std Std           0.30951533
Policy log std Max           -0.1357609
Policy log std Min           -2.778443
Z mean eval                  1.2416154
Z variance eval              0.0064315908
total_rewards                [2317.80289684 1750.6526822  3750.13207938 3517.90389623 3493.19364303
 3789.60252791 2786.19356743 3295.86935681 3128.93876106 2276.62591839]
total_rewards_mean           3010.691532927266
total_rewards_std            663.0158637692513
total_rewards_max            3789.602527907979
total_rewards_min            1750.652682201816
Number of train steps total  1232000
Number of env steps total    1542000
Number of rollouts total     0
Train Time (s)               137.03140567289665
(Previous) Eval Time (s)     32.63993560196832
Sample Time (s)              26.15152003802359
Epoch Time (s)               195.82286131288856
Total Train Time (s)         56776.97803641157
Epoch                        307
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:19:12.928294 UTC | [2020_01_11_13_32_55] Iteration #307 | Epoch Duration: 193.23583436012268
2020-01-12 05:19:12.928485 UTC | [2020_01_11_13_32_55] Iteration #307 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2388953
Z variance train             0.0064268634
KL Divergence                28.430489
KL Loss                      2.8430488
QF Loss                      3790.009
VF Loss                      228.20952
Policy Loss                  -1392.9388
Q Predictions Mean           1399.1418
Q Predictions Std            355.7737
Q Predictions Max            1618.9915
Q Predictions Min            -144.33998
V Predictions Mean           1393.1523
V Predictions Std            351.6185
V Predictions Max            1603.3401
V Predictions Min            -154.85216
Log Pis Mean                 0.8102639
Log Pis Std                  3.2177548
Log Pis Max                  13.881472
Log Pis Min                  -6.899886
Policy mu Mean               -0.021977173
Policy mu Std                0.66217184
Policy mu Max                2.7004747
Policy mu Min                -2.3018458
Policy log std Mean          -1.0393256
Policy log std Std           0.30721334
Policy log std Max           -0.15253234
Policy log std Min           -2.731211
Z mean eval                  1.202858
Z variance eval              0.0058389916
total_rewards                [ 139.60219661  180.88420027 3911.34667012 2021.13362027 2197.08783566
 2838.84311223 3917.37226619  233.71203024 3983.38692958 3643.59448198]
total_rewards_mean           2306.6963343155508
total_rewards_std            1538.0879722216025
total_rewards_max            3983.386929575343
total_rewards_min            139.60219661246214
Number of train steps total  1236000
Number of env steps total    1547000
Number of rollouts total     0
Train Time (s)               133.51359533471987
(Previous) Eval Time (s)     30.052514205221087
Sample Time (s)              25.28098140610382
Epoch Time (s)               188.84709094604477
Total Train Time (s)         56962.667938770726
Epoch                        308
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:22:18.621859 UTC | [2020_01_11_13_32_55] Iteration #308 | Epoch Duration: 185.6932408809662
2020-01-12 05:22:18.622047 UTC | [2020_01_11_13_32_55] Iteration #308 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2040458
Z variance train             0.005841075
KL Divergence                28.62107
KL Loss                      2.862107
QF Loss                      904.9905
VF Loss                      208.80167
Policy Loss                  -1369.1819
Q Predictions Mean           1372.1361
Q Predictions Std            402.11612
Q Predictions Max            1606.259
Q Predictions Min            -150.4522
V Predictions Mean           1369.269
V Predictions Std            399.1313
V Predictions Max            1594.0111
V Predictions Min            -145.28908
Log Pis Mean                 1.1506861
Log Pis Std                  3.3720021
Log Pis Max                  24.523453
Log Pis Min                  -7.2280397
Policy mu Mean               -0.03540589
Policy mu Std                0.65082973
Policy mu Max                2.667475
Policy mu Min                -3.3037186
Policy log std Mean          -1.0565505
Policy log std Std           0.32924557
Policy log std Max           -0.20575261
Policy log std Min           -3.6172967
Z mean eval                  1.1702421
Z variance eval              0.003529781
total_rewards                [1778.90241138 3735.62688669 1974.34221894 3851.00020789 3097.80251155
 1072.08892592  327.64364277  184.35209432 3827.43973627 3056.44390962]
total_rewards_mean           2290.5642545355317
total_rewards_std            1351.2594572231108
total_rewards_max            3851.0002078931684
total_rewards_min            184.3520943155697
Number of train steps total  1240000
Number of env steps total    1552000
Number of rollouts total     0
Train Time (s)               136.27862686198205
(Previous) Eval Time (s)     26.89829790685326
Sample Time (s)              24.248616091441363
Epoch Time (s)               187.42554086027667
Total Train Time (s)         57147.88198118284
Epoch                        309
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:25:23.839703 UTC | [2020_01_11_13_32_55] Iteration #309 | Epoch Duration: 185.2174952030182
2020-01-12 05:25:23.840027 UTC | [2020_01_11_13_32_55] Iteration #309 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1730461
Z variance train             0.003519734
KL Divergence                30.541128
KL Loss                      3.054113
QF Loss                      1212.2421
VF Loss                      376.57007
Policy Loss                  -1339.562
Q Predictions Mean           1343.4834
Q Predictions Std            416.9222
Q Predictions Max            1616.8455
Q Predictions Min            -178.32034
V Predictions Mean           1346.385
V Predictions Std            415.32126
V Predictions Max            1611.631
V Predictions Min            -188.62666
Log Pis Mean                 0.18776447
Log Pis Std                  2.955129
Log Pis Max                  10.748146
Log Pis Min                  -7.2044897
Policy mu Mean               -0.0078122
Policy mu Std                0.630422
Policy mu Max                2.9024787
Policy mu Min                -2.4510226
Policy log std Mean          -1.015415
Policy log std Std           0.32719624
Policy log std Max           -0.09084964
Policy log std Min           -2.411747
Z mean eval                  1.2110448
Z variance eval              0.003406234
total_rewards                [3836.85415022 3560.80195381 1978.56175483 3896.97340352 4005.79541347
 3712.12563476 3202.27350387 1406.51705037 3204.75989781 1074.64410663]
total_rewards_mean           2987.930686928887
total_rewards_std            1034.8447293543065
total_rewards_max            4005.7954134669117
total_rewards_min            1074.6441066270645
Number of train steps total  1244000
Number of env steps total    1557000
Number of rollouts total     0
Train Time (s)               142.40408976981416
(Previous) Eval Time (s)     24.68990998994559
Sample Time (s)              24.085982643067837
Epoch Time (s)               191.1799824028276
Total Train Time (s)         57342.93860497279
Epoch                        310
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:28:38.902553 UTC | [2020_01_11_13_32_55] Iteration #310 | Epoch Duration: 195.06235480308533
2020-01-12 05:28:38.902742 UTC | [2020_01_11_13_32_55] Iteration #310 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2108977
Z variance train             0.0034156274
KL Divergence                30.118437
KL Loss                      3.0118437
QF Loss                      2743.491
VF Loss                      311.41647
Policy Loss                  -1401.2184
Q Predictions Mean           1408.3655
Q Predictions Std            322.2283
Q Predictions Max            1636.0428
Q Predictions Min            -133.91304
V Predictions Mean           1405.1965
V Predictions Std            323.6993
V Predictions Max            1610.0082
V Predictions Min            -138.74236
Log Pis Mean                 0.33800334
Log Pis Std                  3.2227736
Log Pis Max                  10.785898
Log Pis Min                  -8.015644
Policy mu Mean               -0.020445649
Policy mu Std                0.6408336
Policy mu Max                2.575787
Policy mu Min                -2.3675168
Policy log std Mean          -1.0188938
Policy log std Std           0.31805575
Policy log std Max           -0.09967172
Policy log std Min           -2.4916894
Z mean eval                  1.1701329
Z variance eval              0.009605409
total_rewards                [3351.36404436 3906.69368371 3758.87964517  998.13435803 2285.2214377
 2553.23858954 1044.80428112  731.22206297 1024.38630976 2261.48902315]
total_rewards_mean           2191.543343551295
total_rewards_std            1145.512484969905
total_rewards_max            3906.69368371363
total_rewards_min            731.2220629709961
Number of train steps total  1248000
Number of env steps total    1562000
Number of rollouts total     0
Train Time (s)               142.6222361237742
(Previous) Eval Time (s)     28.57192920986563
Sample Time (s)              24.592756547499448
Epoch Time (s)               195.78692188113928
Total Train Time (s)         57533.262756484095
Epoch                        311
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:31:49.230313 UTC | [2020_01_11_13_32_55] Iteration #311 | Epoch Duration: 190.3274393081665
2020-01-12 05:31:49.230501 UTC | [2020_01_11_13_32_55] Iteration #311 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1700816
Z variance train             0.00971671
KL Divergence                29.159637
KL Loss                      2.915964
QF Loss                      3030.936
VF Loss                      227.39178
Policy Loss                  -1356.2301
Q Predictions Mean           1357.7322
Q Predictions Std            418.49228
Q Predictions Max            1662.6683
Q Predictions Min            -135.0319
V Predictions Mean           1348.5342
V Predictions Std            414.03085
V Predictions Max            1636.1365
V Predictions Min            -134.32904
Log Pis Mean                 0.5800798
Log Pis Std                  3.059891
Log Pis Max                  17.035557
Log Pis Min                  -6.9908485
Policy mu Mean               -0.028731145
Policy mu Std                0.6628744
Policy mu Max                2.3544848
Policy mu Min                -3.8961773
Policy log std Mean          -1.0034031
Policy log std Std           0.30045736
Policy log std Max           -0.13588405
Policy log std Min           -2.2868302
Z mean eval                  1.1860229
Z variance eval              0.0058270106
total_rewards                [ -20.11441896 3828.61611056 1306.61901185 1940.69268449 3680.68107643
 3653.00861048  502.26644827  129.83184082  574.68032703  468.42654881]
total_rewards_mean           1606.4708239784002
total_rewards_std            1484.434439886121
total_rewards_max            3828.6161105573856
total_rewards_min            -20.11441895559754
Number of train steps total  1252000
Number of env steps total    1567000
Number of rollouts total     0
Train Time (s)               142.25819452339783
(Previous) Eval Time (s)     23.112100582104176
Sample Time (s)              23.166622960474342
Epoch Time (s)               188.53691806597635
Total Train Time (s)         57716.6248715953
Epoch                        312
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:34:52.596840 UTC | [2020_01_11_13_32_55] Iteration #312 | Epoch Duration: 183.36619448661804
2020-01-12 05:34:52.597108 UTC | [2020_01_11_13_32_55] Iteration #312 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1847217
Z variance train             0.005842847
KL Divergence                31.469292
KL Loss                      3.1469293
QF Loss                      972.4972
VF Loss                      385.09302
Policy Loss                  -1389.8572
Q Predictions Mean           1393.2578
Q Predictions Std            360.5581
Q Predictions Max            1602.4039
Q Predictions Min            -136.49518
V Predictions Mean           1392.7996
V Predictions Std            359.62112
V Predictions Max            1603.9526
V Predictions Min            -140.85359
Log Pis Mean                 0.66848326
Log Pis Std                  3.2295077
Log Pis Max                  14.406606
Log Pis Min                  -7.96266
Policy mu Mean               0.028288353
Policy mu Std                0.6884363
Policy mu Max                2.6627188
Policy mu Min                -2.739156
Policy log std Mean          -1.0039169
Policy log std Std           0.30593333
Policy log std Max           -0.20811176
Policy log std Min           -2.728269
Z mean eval                  1.1931459
Z variance eval              0.005384392
total_rewards                [ 202.17883165 1446.84102911 3645.16692736  412.4896781  1554.13739436
 3717.83945764 3732.55881208  331.24970339 3570.19116852 3706.59177685]
total_rewards_mean           2231.924477904609
total_rewards_std            1501.3736597038505
total_rewards_max            3732.5588120795232
total_rewards_min            202.17883164690653
Number of train steps total  1256000
Number of env steps total    1572000
Number of rollouts total     0
Train Time (s)               140.3968211649917
(Previous) Eval Time (s)     17.941017218399793
Sample Time (s)              26.62486459640786
Epoch Time (s)               184.96270297979936
Total Train Time (s)         57906.166005418636
Epoch                        313
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:38:02.142410 UTC | [2020_01_11_13_32_55] Iteration #313 | Epoch Duration: 189.54513955116272
2020-01-12 05:38:02.142644 UTC | [2020_01_11_13_32_55] Iteration #313 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1951804
Z variance train             0.0053747073
KL Divergence                31.670269
KL Loss                      3.167027
QF Loss                      1365.3625
VF Loss                      437.32724
Policy Loss                  -1354.0348
Q Predictions Mean           1355.6599
Q Predictions Std            414.568
Q Predictions Max            1623.3822
Q Predictions Min            -176.16035
V Predictions Mean           1345.5991
V Predictions Std            413.4229
V Predictions Max            1618.7045
V Predictions Min            -168.1364
Log Pis Mean                 0.81888354
Log Pis Std                  3.3293767
Log Pis Max                  20.383705
Log Pis Min                  -7.147593
Policy mu Mean               0.0640211
Policy mu Std                0.69069487
Policy mu Max                3.9565802
Policy mu Min                -3.5770862
Policy log std Mean          -1.0128913
Policy log std Std           0.31730768
Policy log std Max           0.38763034
Policy log std Min           -2.888145
Z mean eval                  1.1949668
Z variance eval              0.013798982
total_rewards                [3683.79509935 3917.45811884 3664.48070403 3784.67438123 3293.50431701
 3841.71489241  639.07055044 2001.57738684 2529.56993639 1477.32428439]
total_rewards_mean           2883.3169670937796
total_rewards_std            1101.6221870843524
total_rewards_max            3917.458118837123
total_rewards_min            639.0705504417807
Number of train steps total  1260000
Number of env steps total    1577000
Number of rollouts total     0
Train Time (s)               134.48262223089114
(Previous) Eval Time (s)     22.523074882104993
Sample Time (s)              26.54605873161927
Epoch Time (s)               183.5517558446154
Total Train Time (s)         58096.20069234632
Epoch                        314
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:41:12.178061 UTC | [2020_01_11_13_32_55] Iteration #314 | Epoch Duration: 190.03528833389282
2020-01-12 05:41:12.178184 UTC | [2020_01_11_13_32_55] Iteration #314 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.196336
Z variance train             0.013820425
KL Divergence                30.037462
KL Loss                      3.0037463
QF Loss                      6049.7095
VF Loss                      1942.1589
Policy Loss                  -1373.097
Q Predictions Mean           1373.9752
Q Predictions Std            387.6203
Q Predictions Max            1618.8151
Q Predictions Min            -146.02985
V Predictions Mean           1379.1208
V Predictions Std            369.13055
V Predictions Max            1621.0745
V Predictions Min            -127.595764
Log Pis Mean                 0.67650664
Log Pis Std                  3.7711675
Log Pis Max                  27.285463
Log Pis Min                  -8.482063
Policy mu Mean               0.019513996
Policy mu Std                0.6827252
Policy mu Max                4.8176436
Policy mu Min                -3.6988173
Policy log std Mean          -1.0221636
Policy log std Std           0.33290863
Policy log std Max           -0.17810857
Policy log std Min           -2.7904134
Z mean eval                  1.240238
Z variance eval              0.007455799
total_rewards                [ 459.03132842 1402.85076255 3799.29573099 2614.85358834 3800.00500382
  878.69042114  413.94906636 1776.11908261  531.48019703 1492.04275881]
total_rewards_mean           1716.831794006408
total_rewards_std            1225.660792292866
total_rewards_max            3800.0050038152813
total_rewards_min            413.949066357183
Number of train steps total  1264000
Number of env steps total    1582000
Number of rollouts total     0
Train Time (s)               134.75741056492552
(Previous) Eval Time (s)     29.00621398491785
Sample Time (s)              22.75064321095124
Epoch Time (s)               186.5142677607946
Total Train Time (s)         58276.699050528
Epoch                        315
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:44:12.681080 UTC | [2020_01_11_13_32_55] Iteration #315 | Epoch Duration: 180.50278615951538
2020-01-12 05:44:12.681303 UTC | [2020_01_11_13_32_55] Iteration #315 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2420458
Z variance train             0.007436701
KL Divergence                30.897377
KL Loss                      3.0897377
QF Loss                      1207.353
VF Loss                      802.13025
Policy Loss                  -1392.2596
Q Predictions Mean           1394.3546
Q Predictions Std            356.17108
Q Predictions Max            1606.2422
Q Predictions Min            -103.06403
V Predictions Mean           1394.917
V Predictions Std            354.04498
V Predictions Max            1599.0615
V Predictions Min            -98.48202
Log Pis Mean                 0.29852295
Log Pis Std                  3.3773937
Log Pis Max                  17.400816
Log Pis Min                  -7.895059
Policy mu Mean               0.051062334
Policy mu Std                0.6345641
Policy mu Max                3.2853785
Policy mu Min                -2.56846
Policy log std Mean          -1.0209699
Policy log std Std           0.30860376
Policy log std Max           -0.090345025
Policy log std Min           -2.749079
Z mean eval                  1.2146051
Z variance eval              0.024567515
total_rewards                [1328.59636723 3502.64597447 3541.58928671 3759.69204901  951.26874678
  432.96177759 3899.86055743  528.80664428 -183.98182263 3757.03876523]
total_rewards_mean           2151.847834610812
total_rewards_std            1585.4794742872048
total_rewards_max            3899.860557434453
total_rewards_min            -183.98182262828004
Number of train steps total  1268000
Number of env steps total    1587000
Number of rollouts total     0
Train Time (s)               138.55508025502786
(Previous) Eval Time (s)     22.994428674690425
Sample Time (s)              24.803348364774138
Epoch Time (s)               186.35285729449242
Total Train Time (s)         58468.09447057592
Epoch                        316
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:47:24.079327 UTC | [2020_01_11_13_32_55] Iteration #316 | Epoch Duration: 191.39787793159485
2020-01-12 05:47:24.079506 UTC | [2020_01_11_13_32_55] Iteration #316 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.217377
Z variance train             0.024417307
KL Divergence                28.98667
KL Loss                      2.898667
QF Loss                      732.497
VF Loss                      436.75943
Policy Loss                  -1414.7358
Q Predictions Mean           1414.601
Q Predictions Std            304.4529
Q Predictions Max            1593.368
Q Predictions Min            -210.03502
V Predictions Mean           1413.2083
V Predictions Std            299.14084
V Predictions Max            1590.8351
V Predictions Min            -202.83487
Log Pis Mean                 0.8216883
Log Pis Std                  3.3862457
Log Pis Max                  19.198719
Log Pis Min                  -8.976347
Policy mu Mean               0.014501618
Policy mu Std                0.6758204
Policy mu Max                3.6658134
Policy mu Min                -2.4443982
Policy log std Mean          -1.0220734
Policy log std Std           0.3135391
Policy log std Max           -0.13992363
Policy log std Min           -2.8402867
Z mean eval                  1.2206194
Z variance eval              0.006376542
total_rewards                [3639.03639342 1823.89478893  467.28003507  784.18504085 3438.93396304
 1586.18497089 1897.49175643 3557.81584283  104.13407053   15.24564703]
total_rewards_mean           1731.4202509034008
total_rewards_std            1342.9880292277683
total_rewards_max            3639.0363934195884
total_rewards_min            15.24564702561442
Number of train steps total  1272000
Number of env steps total    1592000
Number of rollouts total     0
Train Time (s)               143.16580333700404
(Previous) Eval Time (s)     28.039148786105216
Sample Time (s)              25.637783819809556
Epoch Time (s)               196.8427359429188
Total Train Time (s)         58651.58423590427
Epoch                        317
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:50:27.573778 UTC | [2020_01_11_13_32_55] Iteration #317 | Epoch Duration: 183.49410676956177
2020-01-12 05:50:27.574131 UTC | [2020_01_11_13_32_55] Iteration #317 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2188005
Z variance train             0.0063331733
KL Divergence                29.820095
KL Loss                      2.9820096
QF Loss                      679.41693
VF Loss                      289.45663
Policy Loss                  -1393.1713
Q Predictions Mean           1392.8375
Q Predictions Std            354.0251
Q Predictions Max            1630.456
Q Predictions Min            -124.06309
V Predictions Mean           1390.1069
V Predictions Std            349.6505
V Predictions Max            1620.7203
V Predictions Min            -131.01358
Log Pis Mean                 0.12934312
Log Pis Std                  3.096299
Log Pis Max                  11.315729
Log Pis Min                  -9.888247
Policy mu Mean               -0.042311255
Policy mu Std                0.65440035
Policy mu Max                2.8409722
Policy mu Min                -2.4074478
Policy log std Mean          -0.98753715
Policy log std Std           0.2943901
Policy log std Max           0.09047949
Policy log std Min           -2.4838805
Z mean eval                  1.2409651
Z variance eval              0.0122396415
total_rewards                [ 9.40531251e+02 -2.67593026e+00  1.93064310e+03  1.89856949e+03
  1.82930716e+03  3.47831339e+02  7.18825024e+02  8.82972016e+02
  8.01158757e+01  3.52050848e+03]
total_rewards_mean           1214.6627807325708
total_rewards_std            1030.8538794749363
total_rewards_max            3520.5084785009503
total_rewards_min            -2.6759302602841615
Number of train steps total  1276000
Number of env steps total    1597000
Number of rollouts total     0
Train Time (s)               142.07242223108187
(Previous) Eval Time (s)     14.690006835386157
Sample Time (s)              24.95311368815601
Epoch Time (s)               181.71554275462404
Total Train Time (s)         58835.25992888678
Epoch                        318
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:53:31.252771 UTC | [2020_01_11_13_32_55] Iteration #318 | Epoch Duration: 183.67842030525208
2020-01-12 05:53:31.252953 UTC | [2020_01_11_13_32_55] Iteration #318 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2386024
Z variance train             0.012274338
KL Divergence                28.578697
KL Loss                      2.8578699
QF Loss                      715.85486
VF Loss                      1260.7214
Policy Loss                  -1406.2269
Q Predictions Mean           1406.6785
Q Predictions Std            324.55472
Q Predictions Max            1648.4132
Q Predictions Min            -98.90081
V Predictions Mean           1411.2013
V Predictions Std            316.8554
V Predictions Max            1650.0823
V Predictions Min            -111.69567
Log Pis Mean                 0.585167
Log Pis Std                  3.1851718
Log Pis Max                  14.790963
Log Pis Min                  -8.170338
Policy mu Mean               -0.014940591
Policy mu Std                0.68482035
Policy mu Max                3.3768096
Policy mu Min                -2.5566587
Policy log std Mean          -1.0126729
Policy log std Std           0.30609357
Policy log std Max           -0.23598188
Policy log std Min           -3.2994728
Z mean eval                  1.1908212
Z variance eval              0.011186082
total_rewards                [2955.85782164  423.88218259 3802.75041061  447.70923357 3700.84576911
 3620.19414666 1029.97225291 3096.65085422 4186.42901901 1102.85699852]
total_rewards_mean           2436.714868882813
total_rewards_std            1428.1795474887394
total_rewards_max            4186.429019010826
total_rewards_min            423.8821825854473
Number of train steps total  1280000
Number of env steps total    1602000
Number of rollouts total     0
Train Time (s)               144.05948427598923
(Previous) Eval Time (s)     16.652620317880064
Sample Time (s)              25.01161943608895
Epoch Time (s)               185.72372402995825
Total Train Time (s)         59032.51976268366
Epoch                        319
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:56:48.516034 UTC | [2020_01_11_13_32_55] Iteration #319 | Epoch Duration: 197.26293921470642
2020-01-12 05:56:48.516261 UTC | [2020_01_11_13_32_55] Iteration #319 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1895664
Z variance train             0.011145638
KL Divergence                28.526655
KL Loss                      2.8526657
QF Loss                      738.8573
VF Loss                      744.8119
Policy Loss                  -1387.7146
Q Predictions Mean           1391.575
Q Predictions Std            352.7977
Q Predictions Max            1614.9327
Q Predictions Min            -199.90103
V Predictions Mean           1393.9739
V Predictions Std            354.219
V Predictions Max            1618.6019
V Predictions Min            -197.06877
Log Pis Mean                 0.4305972
Log Pis Std                  2.939675
Log Pis Max                  8.554989
Log Pis Min                  -7.7506785
Policy mu Mean               0.01221467
Policy mu Std                0.6437471
Policy mu Max                2.337019
Policy mu Min                -2.41017
Policy log std Mean          -1.0045941
Policy log std Std           0.29029885
Policy log std Max           -0.22326118
Policy log std Min           -2.3530822
Z mean eval                  1.1957982
Z variance eval              0.010708208
total_rewards                [3354.16792688   95.24129389  162.66501823 2391.7087971   148.6246005
 3821.35621705  173.39156249 3854.30102873 2836.42685642  -61.40105984]
total_rewards_mean           1677.6482241436802
total_rewards_std            1625.4491591462008
total_rewards_max            3854.301028731309
total_rewards_min            -61.40105984003321
Number of train steps total  1284000
Number of env steps total    1607000
Number of rollouts total     0
Train Time (s)               142.43942221533507
(Previous) Eval Time (s)     28.191478616092354
Sample Time (s)              25.53165763616562
Epoch Time (s)               196.16255846759304
Total Train Time (s)         59223.7769553652
Epoch                        320
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:59:59.776674 UTC | [2020_01_11_13_32_55] Iteration #320 | Epoch Duration: 191.26027488708496
2020-01-12 05:59:59.776891 UTC | [2020_01_11_13_32_55] Iteration #320 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1939352
Z variance train             0.01070177
KL Divergence                27.87192
KL Loss                      2.787192
QF Loss                      1434.8376
VF Loss                      385.91388
Policy Loss                  -1438.1106
Q Predictions Mean           1443.8882
Q Predictions Std            284.1411
Q Predictions Max            1637.3862
Q Predictions Min            -161.69348
V Predictions Mean           1437.9036
V Predictions Std            279.37286
V Predictions Max            1623.705
V Predictions Min            -161.17224
Log Pis Mean                 0.6136623
Log Pis Std                  2.754832
Log Pis Max                  12.689899
Log Pis Min                  -6.342308
Policy mu Mean               0.012453338
Policy mu Std                0.6516337
Policy mu Max                2.6886795
Policy mu Min                -2.211827
Policy log std Mean          -1.0331032
Policy log std Std           0.2964582
Policy log std Max           -0.1895796
Policy log std Min           -2.8398924
Z mean eval                  1.191834
Z variance eval              0.009606245
total_rewards                [3709.53291418 3726.15625114 1115.02293806  241.62043951  884.40628067
 3920.40079829 3739.98222792 1259.98869862 3966.05489331  923.38501056]
total_rewards_mean           2348.6550452258707
total_rewards_std            1486.3954047505256
total_rewards_max            3966.054893311949
total_rewards_min            241.6204395106969
Number of train steps total  1288000
Number of env steps total    1612000
Number of rollouts total     0
Train Time (s)               135.34047212498263
(Previous) Eval Time (s)     23.288856837898493
Sample Time (s)              25.760559919290245
Epoch Time (s)               184.38988888217136
Total Train Time (s)         59406.07668612478
Epoch                        321
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:03:02.080180 UTC | [2020_01_11_13_32_55] Iteration #321 | Epoch Duration: 182.3031554222107
2020-01-12 06:03:02.080369 UTC | [2020_01_11_13_32_55] Iteration #321 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1947968
Z variance train             0.009583183
KL Divergence                27.394554
KL Loss                      2.7394555
QF Loss                      1716.1134
VF Loss                      170.96802
Policy Loss                  -1387.9744
Q Predictions Mean           1390.1943
Q Predictions Std            351.85535
Q Predictions Max            1618.8792
Q Predictions Min            -153.31628
V Predictions Mean           1384.73
V Predictions Std            350.64755
V Predictions Max            1595.9639
V Predictions Min            -173.90791
Log Pis Mean                 0.32097408
Log Pis Std                  3.12839
Log Pis Max                  15.153115
Log Pis Min                  -7.6739354
Policy mu Mean               0.0054263733
Policy mu Std                0.6261978
Policy mu Max                2.6700082
Policy mu Min                -2.5980215
Policy log std Mean          -1.0136883
Policy log std Std           0.29487115
Policy log std Max           -0.19998622
Policy log std Min           -3.3983097
Z mean eval                  1.1930535
Z variance eval              0.011172535
total_rewards                [3711.49964692 3776.46700823 3800.84485402 3759.57446658  526.78674148
 3517.38622132 2116.96250935 3698.67855862 2310.53007145 4027.74173093]
total_rewards_mean           3124.6471808893225
total_rewards_std            1065.6486534527269
total_rewards_max            4027.7417309339894
total_rewards_min            526.7867414793187
Number of train steps total  1292000
Number of env steps total    1617000
Number of rollouts total     0
Train Time (s)               135.02335851732641
(Previous) Eval Time (s)     21.201766790356487
Sample Time (s)              24.22709482163191
Epoch Time (s)               180.4522201293148
Total Train Time (s)         59593.50983644137
Epoch                        322
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:06:09.515033 UTC | [2020_01_11_13_32_55] Iteration #322 | Epoch Duration: 187.43454694747925
2020-01-12 06:06:09.515151 UTC | [2020_01_11_13_32_55] Iteration #322 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1951649
Z variance train             0.01118854
KL Divergence                27.843534
KL Loss                      2.7843535
QF Loss                      1061.888
VF Loss                      150.55888
Policy Loss                  -1419.171
Q Predictions Mean           1421.7734
Q Predictions Std            296.38425
Q Predictions Max            1594.8223
Q Predictions Min            -125.38135
V Predictions Mean           1417.766
V Predictions Std            292.47604
V Predictions Max            1591.5828
V Predictions Min            -136.30745
Log Pis Mean                 0.37308705
Log Pis Std                  3.1519186
Log Pis Max                  12.914571
Log Pis Min                  -7.33273
Policy mu Mean               0.021705389
Policy mu Std                0.64500475
Policy mu Max                2.6813662
Policy mu Min                -3.4416163
Policy log std Mean          -1.0451242
Policy log std Std           0.30053678
Policy log std Max           0.35472918
Policy log std Min           -2.4658797
Z mean eval                  1.1560906
Z variance eval              0.006278573
total_rewards                [3799.21516976  200.40619075 3479.60784048 3201.86277967  687.22311744
  216.95323334 1799.68719072 1704.89463303 3578.77095536 3609.17443825]
total_rewards_mean           2227.7795548787217
total_rewards_std            1403.6524772459802
total_rewards_max            3799.2151697564286
total_rewards_min            200.40619075038586
Number of train steps total  1296000
Number of env steps total    1622000
Number of rollouts total     0
Train Time (s)               140.83309943787754
(Previous) Eval Time (s)     28.183774400036782
Sample Time (s)              24.016596343833953
Epoch Time (s)               193.03347018174827
Total Train Time (s)         59783.4746645242
Epoch                        323
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:09:19.484009 UTC | [2020_01_11_13_32_55] Iteration #323 | Epoch Duration: 189.96874070167542
2020-01-12 06:09:19.484201 UTC | [2020_01_11_13_32_55] Iteration #323 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1572995
Z variance train             0.0062954836
KL Divergence                28.426094
KL Loss                      2.8426094
QF Loss                      818.7505
VF Loss                      184.43417
Policy Loss                  -1413.2571
Q Predictions Mean           1416.6687
Q Predictions Std            333.57422
Q Predictions Max            1614.0585
Q Predictions Min            -165.8132
V Predictions Mean           1420.3136
V Predictions Std            331.75116
V Predictions Max            1597.3672
V Predictions Min            -160.26039
Log Pis Mean                 0.5340988
Log Pis Std                  3.0727344
Log Pis Max                  13.393785
Log Pis Min                  -8.19515
Policy mu Mean               -0.03335428
Policy mu Std                0.6416608
Policy mu Max                2.9623024
Policy mu Min                -2.7134612
Policy log std Mean          -1.0437126
Policy log std Std           0.29124784
Policy log std Max           -0.049463034
Policy log std Min           -2.451759
Z mean eval                  1.2130606
Z variance eval              0.021040594
total_rewards                [3586.95478267 2133.61751131 3845.73929289 3588.77486199 3815.21078713
 2187.95043788 2176.07136856 1798.42398837 2127.11490705 1897.2593068 ]
total_rewards_mean           2715.711724465202
total_rewards_std            823.0108704835509
total_rewards_max            3845.7392928910403
total_rewards_min            1798.423988369409
Number of train steps total  1300000
Number of env steps total    1627000
Number of rollouts total     0
Train Time (s)               140.7042614496313
(Previous) Eval Time (s)     25.118717972189188
Sample Time (s)              26.115442608483136
Epoch Time (s)               191.93842203030363
Total Train Time (s)         59977.51128932601
Epoch                        324
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:12:33.524440 UTC | [2020_01_11_13_32_55] Iteration #324 | Epoch Duration: 194.04010605812073
2020-01-12 06:12:33.524623 UTC | [2020_01_11_13_32_55] Iteration #324 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2114421
Z variance train             0.021056566
KL Divergence                26.275414
KL Loss                      2.6275413
QF Loss                      959.16895
VF Loss                      303.32446
Policy Loss                  -1380.7006
Q Predictions Mean           1383.0841
Q Predictions Std            382.84128
Q Predictions Max            1633.6895
Q Predictions Min            -144.62357
V Predictions Mean           1380.9218
V Predictions Std            384.58173
V Predictions Max            1621.0151
V Predictions Min            -151.60634
Log Pis Mean                 0.8291912
Log Pis Std                  3.2782254
Log Pis Max                  18.085695
Log Pis Min                  -6.523491
Policy mu Mean               0.044180445
Policy mu Std                0.7028741
Policy mu Max                2.8205686
Policy mu Min                -2.3377056
Policy log std Mean          -0.9894749
Policy log std Std           0.31178394
Policy log std Max           -0.041276693
Policy log std Min           -2.586711
Z mean eval                  1.2205043
Z variance eval              0.0077733085
total_rewards                [3667.64818106 1627.5559935  2082.38865756   67.51366945 -229.47673112
 2919.50192526 1658.32373392 1091.28531681 2285.70880984 3962.85984847]
total_rewards_mean           1913.330940472718
total_rewards_std            1314.4939970879634
total_rewards_max            3962.8598484671174
total_rewards_min            -229.47673112335093
Number of train steps total  1304000
Number of env steps total    1632000
Number of rollouts total     0
Train Time (s)               141.82970934780315
(Previous) Eval Time (s)     27.21998690487817
Sample Time (s)              26.25522584328428
Epoch Time (s)               195.3049220959656
Total Train Time (s)         60170.83984145848
Epoch                        325
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:15:46.856778 UTC | [2020_01_11_13_32_55] Iteration #325 | Epoch Duration: 193.33201241493225
2020-01-12 06:15:46.857004 UTC | [2020_01_11_13_32_55] Iteration #325 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2170393
Z variance train             0.007750406
KL Divergence                26.484661
KL Loss                      2.648466
QF Loss                      878.19867
VF Loss                      271.9049
Policy Loss                  -1406.5419
Q Predictions Mean           1407.1544
Q Predictions Std            361.60434
Q Predictions Max            1632.0281
Q Predictions Min            -232.05322
V Predictions Mean           1406.7542
V Predictions Std            352.00204
V Predictions Max            1625.0603
V Predictions Min            -239.7257
Log Pis Mean                 0.6863909
Log Pis Std                  3.2735133
Log Pis Max                  11.734382
Log Pis Min                  -5.7004776
Policy mu Mean               0.022467207
Policy mu Std                0.6544098
Policy mu Max                2.2398028
Policy mu Min                -2.3239238
Policy log std Mean          -1.0397817
Policy log std Std           0.31151277
Policy log std Max           -0.08179128
Policy log std Min           -2.9602036
Z mean eval                  1.2171571
Z variance eval              0.011419913
total_rewards                [3830.61133015 2801.45550298  235.91943695 3718.62931202 3807.21906
 1666.2491026  2295.51232072  526.33466812  271.24889681   14.83919453]
total_rewards_mean           1916.8018824876876
total_rewards_std            1501.859103831356
total_rewards_max            3830.6113301527603
total_rewards_min            14.839194526710791
Number of train steps total  1308000
Number of env steps total    1637000
Number of rollouts total     0
Train Time (s)               142.31886339420453
(Previous) Eval Time (s)     25.24675182905048
Sample Time (s)              25.870174049865454
Epoch Time (s)               193.43578927312046
Total Train Time (s)         60360.919070029166
Epoch                        326
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:18:56.939854 UTC | [2020_01_11_13_32_55] Iteration #326 | Epoch Duration: 190.08270287513733
2020-01-12 06:18:56.940059 UTC | [2020_01_11_13_32_55] Iteration #326 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2181716
Z variance train             0.011427226
KL Divergence                25.615843
KL Loss                      2.5615842
QF Loss                      1098.9751
VF Loss                      287.1444
Policy Loss                  -1372.9529
Q Predictions Mean           1380.3427
Q Predictions Std            336.47214
Q Predictions Max            1596.7047
Q Predictions Min            -154.84053
V Predictions Mean           1380.7893
V Predictions Std            335.43454
V Predictions Max            1604.9552
V Predictions Min            -147.735
Log Pis Mean                 0.86786
Log Pis Std                  3.3866556
Log Pis Max                  20.687332
Log Pis Min                  -8.144033
Policy mu Mean               0.026460899
Policy mu Std                0.67416996
Policy mu Max                3.6057808
Policy mu Min                -2.3242292
Policy log std Mean          -1.0577142
Policy log std Std           0.3293236
Policy log std Max           0.040599108
Policy log std Min           -3.1950347
Z mean eval                  1.2561092
Z variance eval              0.006305603
total_rewards                [2183.31179883 1251.16682757  413.03891774 3689.27071491 1023.62338409
 1539.35279874  615.15660324 1723.99458632 2564.42977803 2460.32051195]
total_rewards_mean           1746.3665921427812
total_rewards_std            949.3729306675133
total_rewards_max            3689.270714905308
total_rewards_min            413.03891774256545
Number of train steps total  1312000
Number of env steps total    1642000
Number of rollouts total     0
Train Time (s)               139.51229777326807
(Previous) Eval Time (s)     21.893214533105493
Sample Time (s)              27.235481448005885
Epoch Time (s)               188.64099375437945
Total Train Time (s)         60548.47744624736
Epoch                        327
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:22:04.500812 UTC | [2020_01_11_13_32_55] Iteration #327 | Epoch Duration: 187.56063318252563
2020-01-12 06:22:04.500936 UTC | [2020_01_11_13_32_55] Iteration #327 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2582257
Z variance train             0.0062998547
KL Divergence                27.355381
KL Loss                      2.7355382
QF Loss                      1863.6908
VF Loss                      285.1526
Policy Loss                  -1356.1594
Q Predictions Mean           1360.6084
Q Predictions Std            399.15942
Q Predictions Max            1635.1973
Q Predictions Min            -218.18782
V Predictions Mean           1360.6952
V Predictions Std            396.5873
V Predictions Max            1617.3707
V Predictions Min            -183.23216
Log Pis Mean                 0.80714405
Log Pis Std                  3.3865786
Log Pis Max                  15.15511
Log Pis Min                  -6.82767
Policy mu Mean               0.03438901
Policy mu Std                0.69082934
Policy mu Max                4.164884
Policy mu Min                -3.2534478
Policy log std Mean          -1.0026115
Policy log std Std           0.34100774
Policy log std Max           1.7178383
Policy log std Min           -2.4419208
Z mean eval                  1.2567099
Z variance eval              0.0054870946
total_rewards                [1003.56411305 1311.9159707   765.88084665  612.25498304  481.42177224
 3783.13803806 3618.07471562 4113.00195097 1374.42061221  -53.43271235]
total_rewards_mean           1701.0240290200993
total_rewards_std            1455.9499893207415
total_rewards_max            4113.001950970679
total_rewards_min            -53.432712350800244
Number of train steps total  1316000
Number of env steps total    1647000
Number of rollouts total     0
Train Time (s)               134.2161966972053
(Previous) Eval Time (s)     20.81238332297653
Sample Time (s)              23.327525416389108
Epoch Time (s)               178.35610543657094
Total Train Time (s)         60729.10410288861
Epoch                        328
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:25:05.131986 UTC | [2020_01_11_13_32_55] Iteration #328 | Epoch Duration: 180.63094973564148
2020-01-12 06:25:05.132174 UTC | [2020_01_11_13_32_55] Iteration #328 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2576245
Z variance train             0.005483362
KL Divergence                28.389435
KL Loss                      2.8389435
QF Loss                      662.3137
VF Loss                      366.25076
Policy Loss                  -1391.8828
Q Predictions Mean           1392.4028
Q Predictions Std            369.06824
Q Predictions Max            1612.1251
Q Predictions Min            -100.162
V Predictions Mean           1378.2036
V Predictions Std            365.83536
V Predictions Max            1602.6907
V Predictions Min            -104.57898
Log Pis Mean                 0.09449922
Log Pis Std                  2.850016
Log Pis Max                  17.112568
Log Pis Min                  -6.287221
Policy mu Mean               0.043684453
Policy mu Std                0.62899446
Policy mu Max                3.2842813
Policy mu Min                -3.3251886
Policy log std Mean          -1.000773
Policy log std Std           0.29749304
Policy log std Max           -0.09647024
Policy log std Min           -2.4774666
Z mean eval                  1.2024138
Z variance eval              0.00803232
total_rewards                [3780.04964333 3904.9450455  3914.10778919 3897.75199915 3768.61679494
 3753.48050621 1016.16526125  710.92110058  652.3343601   959.9149065 ]
total_rewards_mean           2635.828740674766
total_rewards_std            1474.7954399560365
total_rewards_max            3914.1077891940977
total_rewards_min            652.3343600958306
Number of train steps total  1320000
Number of env steps total    1652000
Number of rollouts total     0
Train Time (s)               133.69989211997017
(Previous) Eval Time (s)     23.086922232992947
Sample Time (s)              24.671299915295094
Epoch Time (s)               181.4581142682582
Total Train Time (s)         60913.59825422522
Epoch                        329
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:28:09.630916 UTC | [2020_01_11_13_32_55] Iteration #329 | Epoch Duration: 184.49856805801392
2020-01-12 06:28:09.631292 UTC | [2020_01_11_13_32_55] Iteration #329 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2038963
Z variance train             0.0080409385
KL Divergence                27.87224
KL Loss                      2.787224
QF Loss                      705.55853
VF Loss                      2459.916
Policy Loss                  -1389.1556
Q Predictions Mean           1391.2867
Q Predictions Std            373.96136
Q Predictions Max            1608.0985
Q Predictions Min            -26.885216
V Predictions Mean           1401.7611
V Predictions Std            370.6356
V Predictions Max            1615.4557
V Predictions Min            -18.69419
Log Pis Mean                 0.83407974
Log Pis Std                  3.7517087
Log Pis Max                  29.61093
Log Pis Min                  -9.555888
Policy mu Mean               0.022749636
Policy mu Std                0.6827087
Policy mu Max                4.02525
Policy mu Min                -3.9822564
Policy log std Mean          -1.0168693
Policy log std Std           0.29548568
Policy log std Max           0.50538635
Policy log std Min           -2.633391
Z mean eval                  1.2006352
Z variance eval              0.014864653
total_rewards                [1234.32697874  447.71142798 3369.85727139 4027.81309808 3760.56846534
 3952.46916073 4117.25718561 1144.31378702 3908.36556714 3792.16239614]
total_rewards_mean           2975.4845338175255
total_rewards_std            1358.2749484446733
total_rewards_max            4117.257185614346
total_rewards_min            447.7114279750813
Number of train steps total  1324000
Number of env steps total    1657000
Number of rollouts total     0
Train Time (s)               141.2315913811326
(Previous) Eval Time (s)     26.127025010064244
Sample Time (s)              25.25580827984959
Epoch Time (s)               192.61442467104644
Total Train Time (s)         61108.671046841424
Epoch                        330
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:31:24.707254 UTC | [2020_01_11_13_32_55] Iteration #330 | Epoch Duration: 195.0756552219391
2020-01-12 06:31:24.707616 UTC | [2020_01_11_13_32_55] Iteration #330 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1998327
Z variance train             0.014863024
KL Divergence                27.514427
KL Loss                      2.7514427
QF Loss                      8771.72
VF Loss                      787.42505
Policy Loss                  -1396.8804
Q Predictions Mean           1402.3567
Q Predictions Std            356.81796
Q Predictions Max            1625.1705
Q Predictions Min            -124.75286
V Predictions Mean           1401.343
V Predictions Std            354.57428
V Predictions Max            1624.3816
V Predictions Min            -113.81043
Log Pis Mean                 0.55773747
Log Pis Std                  3.2387185
Log Pis Max                  12.367149
Log Pis Min                  -6.152164
Policy mu Mean               -0.027773092
Policy mu Std                0.6422215
Policy mu Max                2.2336082
Policy mu Min                -2.9461536
Policy log std Mean          -1.0199295
Policy log std Std           0.31117567
Policy log std Max           -0.10660362
Policy log std Min           -2.4454074
Z mean eval                  1.1807168
Z variance eval              0.023668835
total_rewards                [4244.81164825 3512.10563215 -169.1394599   166.83857179 1708.68094476
 3998.03480194  821.83695832 3769.28836868 2814.49728116 1835.31549737]
total_rewards_mean           2270.2270244515275
total_rewards_std            1547.483418401989
total_rewards_max            4244.811648246819
total_rewards_min            -169.13945990276534
Number of train steps total  1328000
Number of env steps total    1662000
Number of rollouts total     0
Train Time (s)               142.78002031100914
(Previous) Eval Time (s)     28.587858573999256
Sample Time (s)              27.81067608995363
Epoch Time (s)               199.17855497496203
Total Train Time (s)         61303.99330127612
Epoch                        331
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:34:40.032843 UTC | [2020_01_11_13_32_55] Iteration #331 | Epoch Duration: 195.325049161911
2020-01-12 06:34:40.033048 UTC | [2020_01_11_13_32_55] Iteration #331 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1810431
Z variance train             0.023500483
KL Divergence                27.44424
KL Loss                      2.744424
QF Loss                      969.0972
VF Loss                      442.67603
Policy Loss                  -1412.9055
Q Predictions Mean           1412.7029
Q Predictions Std            338.0193
Q Predictions Max            1610.2902
Q Predictions Min            -261.35294
V Predictions Mean           1417.6208
V Predictions Std            338.12012
V Predictions Max            1619.22
V Predictions Min            -194.99051
Log Pis Mean                 0.9141953
Log Pis Std                  3.0744014
Log Pis Max                  12.357977
Log Pis Min                  -6.5426497
Policy mu Mean               -0.0066897
Policy mu Std                0.68503016
Policy mu Max                3.5704465
Policy mu Min                -5.3979435
Policy log std Mean          -1.0216985
Policy log std Std           0.3194556
Policy log std Max           0.56227124
Policy log std Min           -2.5897083
Z mean eval                  1.2329128
Z variance eval              0.009201728
total_rewards                [3122.5884735   259.02984872 1299.45859252 3594.24203848 1165.80311865
 3762.14605665 1071.01312812 3941.31080153 2984.4280142  3895.94914623]
total_rewards_mean           2509.596921860931
total_rewards_std            1331.2823419548904
total_rewards_max            3941.310801534537
total_rewards_min            259.0298487152038
Number of train steps total  1332000
Number of env steps total    1667000
Number of rollouts total     0
Train Time (s)               141.3419091538526
(Previous) Eval Time (s)     24.73394047934562
Sample Time (s)              26.016333521343768
Epoch Time (s)               192.092183154542
Total Train Time (s)         61495.69272960443
Epoch                        332
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:37:51.736379 UTC | [2020_01_11_13_32_55] Iteration #332 | Epoch Duration: 191.7031843662262
2020-01-12 06:37:51.736563 UTC | [2020_01_11_13_32_55] Iteration #332 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2330049
Z variance train             0.009200467
KL Divergence                27.39316
KL Loss                      2.739316
QF Loss                      2252.3816
VF Loss                      516.2585
Policy Loss                  -1438.1812
Q Predictions Mean           1438.0028
Q Predictions Std            287.5704
Q Predictions Max            1630.5363
Q Predictions Min            -133.91904
V Predictions Mean           1447.1621
V Predictions Std            284.39493
V Predictions Max            1635.0765
V Predictions Min            -121.71753
Log Pis Mean                 0.2562712
Log Pis Std                  2.894219
Log Pis Max                  12.841936
Log Pis Min                  -8.079332
Policy mu Mean               0.04266107
Policy mu Std                0.63135934
Policy mu Max                3.294369
Policy mu Min                -2.591478
Policy log std Mean          -1.0128343
Policy log std Std           0.27581137
Policy log std Max           -0.18568033
Policy log std Min           -2.8732524
Z mean eval                  1.2471979
Z variance eval              0.015654001
total_rewards                [1842.44697311   73.82943025 1228.94447791 3523.85368901  556.57623678
  578.69503547 2367.29119524 3280.29632391  956.22229946 3989.35380263]
total_rewards_mean           1839.750946379051
total_rewards_std            1316.0340806217594
total_rewards_max            3989.3538026344268
total_rewards_min            73.8294302495046
Number of train steps total  1336000
Number of env steps total    1672000
Number of rollouts total     0
Train Time (s)               141.8999274270609
(Previous) Eval Time (s)     24.344504944980145
Sample Time (s)              26.40095828147605
Epoch Time (s)               192.6453906535171
Total Train Time (s)         61683.3331231433
Epoch                        333
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:40:59.379682 UTC | [2020_01_11_13_32_55] Iteration #333 | Epoch Duration: 187.64299654960632
2020-01-12 06:40:59.379887 UTC | [2020_01_11_13_32_55] Iteration #333 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.252372
Z variance train             0.015770745
KL Divergence                26.726048
KL Loss                      2.6726048
QF Loss                      667.796
VF Loss                      185.34363
Policy Loss                  -1416.4236
Q Predictions Mean           1414.6975
Q Predictions Std            301.35852
Q Predictions Max            1614.3638
Q Predictions Min            -12.55002
V Predictions Mean           1416.914
V Predictions Std            299.92618
V Predictions Max            1618.4717
V Predictions Min            -5.3491497
Log Pis Mean                 0.55494684
Log Pis Std                  2.9734764
Log Pis Max                  18.148212
Log Pis Min                  -7.3726335
Policy mu Mean               -0.0038457415
Policy mu Std                0.6188174
Policy mu Max                3.7679079
Policy mu Min                -2.4931037
Policy log std Mean          -1.0583935
Policy log std Std           0.30237392
Policy log std Max           -0.1263839
Policy log std Min           -2.6000996
Z mean eval                  1.1821172
Z variance eval              0.009183796
total_rewards                [2136.20291038 1639.68400076 3179.54340417 3838.78404493 1414.92316159
 3938.42853381 2244.47684545  607.15054186 1881.41915852  239.87019658]
total_rewards_mean           2112.048279804328
total_rewards_std            1183.5124442792453
total_rewards_max            3938.4285338067366
total_rewards_min            239.87019657844277
Number of train steps total  1340000
Number of env steps total    1677000
Number of rollouts total     0
Train Time (s)               136.6508860248141
(Previous) Eval Time (s)     19.341732516419142
Sample Time (s)              25.860171149484813
Epoch Time (s)               181.85278969071805
Total Train Time (s)         61868.177375069354
Epoch                        334
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:44:04.227732 UTC | [2020_01_11_13_32_55] Iteration #334 | Epoch Duration: 184.8477041721344
2020-01-12 06:44:04.227929 UTC | [2020_01_11_13_32_55] Iteration #334 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1814551
Z variance train             0.009208673
KL Divergence                28.537277
KL Loss                      2.8537278
QF Loss                      942.68054
VF Loss                      312.33975
Policy Loss                  -1398.3829
Q Predictions Mean           1394.5632
Q Predictions Std            363.2428
Q Predictions Max            1604.4198
Q Predictions Min            -234.37727
V Predictions Mean           1393.1621
V Predictions Std            353.37805
V Predictions Max            1597.851
V Predictions Min            -232.5254
Log Pis Mean                 0.8252728
Log Pis Std                  3.3179722
Log Pis Max                  21.071676
Log Pis Min                  -7.6848326
Policy mu Mean               0.004736903
Policy mu Std                0.6762291
Policy mu Max                4.5226326
Policy mu Min                -3.05669
Policy log std Mean          -1.0243524
Policy log std Std           0.32646528
Policy log std Max           -0.16792488
Policy log std Min           -3.0606117
Z mean eval                  1.2422853
Z variance eval              0.003814737
total_rewards                [ 205.20298138 1552.45360029 3943.10816003  131.44681696 3867.80706789
  421.37712449 1093.69781973 3829.51669524 1118.8221519  1652.68840054]
total_rewards_mean           1781.6120818463464
total_rewards_std            1458.0188531885528
total_rewards_max            3943.108160026956
total_rewards_min            131.44681696190312
Number of train steps total  1344000
Number of env steps total    1682000
Number of rollouts total     0
Train Time (s)               134.60256530717015
(Previous) Eval Time (s)     22.336234719958156
Sample Time (s)              24.718343255110085
Epoch Time (s)               181.6571432822384
Total Train Time (s)         62047.452166334726
Epoch                        335
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:47:03.506169 UTC | [2020_01_11_13_32_55] Iteration #335 | Epoch Duration: 179.27810406684875
2020-01-12 06:47:03.506376 UTC | [2020_01_11_13_32_55] Iteration #335 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.234835
Z variance train             0.0038204337
KL Divergence                30.674105
KL Loss                      3.0674105
QF Loss                      954.0601
VF Loss                      331.05392
Policy Loss                  -1418.9869
Q Predictions Mean           1425.8379
Q Predictions Std            333.73544
Q Predictions Max            1650.3986
Q Predictions Min            -184.78487
V Predictions Mean           1420.5409
V Predictions Std            333.68198
V Predictions Max            1635.8525
V Predictions Min            -214.55972
Log Pis Mean                 0.7231773
Log Pis Std                  3.214332
Log Pis Max                  11.656448
Log Pis Min                  -6.256216
Policy mu Mean               -0.0073950374
Policy mu Std                0.66505885
Policy mu Max                3.7257338
Policy mu Min                -2.816771
Policy log std Mean          -1.0375464
Policy log std Std           0.32307717
Policy log std Max           -0.14003527
Policy log std Min           -2.999547
Z mean eval                  1.2296379
Z variance eval              0.010119022
total_rewards                [3852.74576877 3742.5087784  2294.49233156 3715.43352716  722.80808991
 2524.0655672  2361.52880032 3903.54353517  164.05249397 3823.6559937 ]
total_rewards_mean           2710.4834886147974
total_rewards_std            1296.4198068487485
total_rewards_max            3903.5435351656747
total_rewards_min            164.05249397447744
Number of train steps total  1348000
Number of env steps total    1687000
Number of rollouts total     0
Train Time (s)               136.22937172884122
(Previous) Eval Time (s)     19.956875738222152
Sample Time (s)              23.920689173974097
Epoch Time (s)               180.10693664103746
Total Train Time (s)         62234.447212851606
Epoch                        336
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:50:10.505544 UTC | [2020_01_11_13_32_55] Iteration #336 | Epoch Duration: 186.99902606010437
2020-01-12 06:50:10.505747 UTC | [2020_01_11_13_32_55] Iteration #336 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2333574
Z variance train             0.010167695
KL Divergence                26.68428
KL Loss                      2.6684282
QF Loss                      589.18414
VF Loss                      329.8651
Policy Loss                  -1427.4658
Q Predictions Mean           1429.9498
Q Predictions Std            322.60965
Q Predictions Max            1644.0048
Q Predictions Min            -160.76292
V Predictions Mean           1428.5308
V Predictions Std            327.9602
V Predictions Max            1630.122
V Predictions Min            -198.37997
Log Pis Mean                 0.18950507
Log Pis Std                  3.0940216
Log Pis Max                  9.945834
Log Pis Min                  -8.089935
Policy mu Mean               0.011540331
Policy mu Std                0.61101764
Policy mu Max                2.4436743
Policy mu Min                -2.3139153
Policy log std Mean          -1.0335994
Policy log std Std           0.27820775
Policy log std Max           -0.080807805
Policy log std Min           -2.5288227
Z mean eval                  1.2018573
Z variance eval              0.01348795
total_rewards                [4095.51209084 3928.91924168 3762.76132882 3814.84591199 3958.52920642
  304.93551647  340.1384607  2163.51978879 3783.7942849   472.259571  ]
total_rewards_mean           2662.521540161294
total_rewards_std            1585.257638825853
total_rewards_max            4095.512090842683
total_rewards_min            304.9355164696814
Number of train steps total  1352000
Number of env steps total    1692000
Number of rollouts total     0
Train Time (s)               144.1006301320158
(Previous) Eval Time (s)     26.848627767991275
Sample Time (s)              25.860172463115305
Epoch Time (s)               196.80943036312237
Total Train Time (s)         62431.653968740255
Epoch                        337
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:53:27.715649 UTC | [2020_01_11_13_32_55] Iteration #337 | Epoch Duration: 197.20976781845093
2020-01-12 06:53:27.715826 UTC | [2020_01_11_13_32_55] Iteration #337 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2016828
Z variance train             0.013631096
KL Divergence                27.829887
KL Loss                      2.7829888
QF Loss                      874.483
VF Loss                      119.34652
Policy Loss                  -1352.182
Q Predictions Mean           1355.1863
Q Predictions Std            435.61935
Q Predictions Max            1637.4829
Q Predictions Min            -214.99457
V Predictions Mean           1352.1836
V Predictions Std            436.32578
V Predictions Max            1624.3478
V Predictions Min            -239.6778
Log Pis Mean                 0.8425091
Log Pis Std                  3.2907338
Log Pis Max                  16.043533
Log Pis Min                  -7.758566
Policy mu Mean               0.03963171
Policy mu Std                0.6784912
Policy mu Max                3.363473
Policy mu Min                -2.680252
Policy log std Mean          -1.0133423
Policy log std Std           0.34810358
Policy log std Max           -0.11538565
Policy log std Min           -2.9900932
Z mean eval                  1.2540581
Z variance eval              0.009195596
total_rewards                [3780.05617178 3659.1887895  3711.13440373   32.54105509 2206.24829921
 3695.86838956 3948.86738563 3407.275768    373.32552887 3687.1736083 ]
total_rewards_mean           2850.16793996646
total_rewards_std            1402.9315574599427
total_rewards_max            3948.8673856267205
total_rewards_min            32.54105508863614
Number of train steps total  1356000
Number of env steps total    1697000
Number of rollouts total     0
Train Time (s)               142.53282426297665
(Previous) Eval Time (s)     27.248580473009497
Sample Time (s)              24.684326941613108
Epoch Time (s)               194.46573167759925
Total Train Time (s)         62625.49920899933
Epoch                        338
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:56:41.564736 UTC | [2020_01_11_13_32_55] Iteration #338 | Epoch Duration: 193.84877729415894
2020-01-12 06:56:41.564938 UTC | [2020_01_11_13_32_55] Iteration #338 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2536075
Z variance train             0.009223926
KL Divergence                29.044064
KL Loss                      2.9044063
QF Loss                      866.87317
VF Loss                      185.886
Policy Loss                  -1435.8452
Q Predictions Mean           1439.2063
Q Predictions Std            331.41293
Q Predictions Max            1661.5931
Q Predictions Min            -167.9518
V Predictions Mean           1444.9858
V Predictions Std            332.11484
V Predictions Max            1656.2552
V Predictions Min            -182.29665
Log Pis Mean                 0.60572803
Log Pis Std                  2.9866571
Log Pis Max                  18.208061
Log Pis Min                  -6.370289
Policy mu Mean               -0.040453594
Policy mu Std                0.64902824
Policy mu Max                3.7016582
Policy mu Min                -2.2445612
Policy log std Mean          -1.0534189
Policy log std Std           0.28209016
Policy log std Max           -0.20729065
Policy log std Min           -2.422534
Z mean eval                  1.2341058
Z variance eval              0.012138636
total_rewards                [3729.86590969 1057.33748044  837.31131066  679.07234183 2690.54864458
  836.50348855 4011.35697581 2441.62946676 3846.44161959 1205.06109033]
total_rewards_mean           2133.512832824954
total_rewards_std            1300.4590093435684
total_rewards_max            4011.3569758058966
total_rewards_min            679.0723418305552
Number of train steps total  1360000
Number of env steps total    1702000
Number of rollouts total     0
Train Time (s)               143.155897741206
(Previous) Eval Time (s)     26.63132038898766
Sample Time (s)              25.974301465321332
Epoch Time (s)               195.76151959551498
Total Train Time (s)         62816.02778812079
Epoch                        339
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:59:52.095884 UTC | [2020_01_11_13_32_55] Iteration #339 | Epoch Duration: 190.53082370758057
2020-01-12 06:59:52.096019 UTC | [2020_01_11_13_32_55] Iteration #339 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2306781
Z variance train             0.01212128
KL Divergence                28.55635
KL Loss                      2.8556352
QF Loss                      824.1476
VF Loss                      204.61829
Policy Loss                  -1414.7708
Q Predictions Mean           1417.21
Q Predictions Std            332.65234
Q Predictions Max            1633.0731
Q Predictions Min            -260.60162
V Predictions Mean           1413.176
V Predictions Std            332.47314
V Predictions Max            1633.7926
V Predictions Min            -243.71642
Log Pis Mean                 0.54227406
Log Pis Std                  3.2641087
Log Pis Max                  12.24488
Log Pis Min                  -11.237385
Policy mu Mean               0.05541198
Policy mu Std                0.65795827
Policy mu Max                3.3789046
Policy mu Min                -2.4357126
Policy log std Mean          -0.99968064
Policy log std Std           0.267789
Policy log std Max           -0.17272985
Policy log std Min           -2.129427
Z mean eval                  1.2419926
Z variance eval              0.0063424455
total_rewards                [ 562.35252038 1660.2491924  3850.82635388 4035.57694614 4216.02224115
 2009.7359903  3309.97266263 3819.27299545  434.35545864 3981.90599532]
total_rewards_mean           2788.0270356282135
total_rewards_std            1409.1611926867386
total_rewards_max            4216.022241146707
total_rewards_min            434.3554586417049
Number of train steps total  1364000
Number of env steps total    1707000
Number of rollouts total     0
Train Time (s)               141.6236780579202
(Previous) Eval Time (s)     21.400203747674823
Sample Time (s)              25.99712642095983
Epoch Time (s)               189.02100822655484
Total Train Time (s)         63009.16232568119
Epoch                        340
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:03:05.234520 UTC | [2020_01_11_13_32_55] Iteration #340 | Epoch Duration: 193.13838267326355
2020-01-12 07:03:05.234741 UTC | [2020_01_11_13_32_55] Iteration #340 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2416188
Z variance train             0.006341754
KL Divergence                28.897188
KL Loss                      2.8897188
QF Loss                      694.3913
VF Loss                      166.40868
Policy Loss                  -1393.3481
Q Predictions Mean           1394.9272
Q Predictions Std            388.2279
Q Predictions Max            1650.3871
Q Predictions Min            -122.82238
V Predictions Mean           1393.0525
V Predictions Std            387.45398
V Predictions Max            1631.5997
V Predictions Min            -122.13167
Log Pis Mean                 0.59215474
Log Pis Std                  2.843173
Log Pis Max                  11.210041
Log Pis Min                  -8.796863
Policy mu Mean               -0.011578213
Policy mu Std                0.6797417
Policy mu Max                2.4545891
Policy mu Min                -2.6322591
Policy log std Mean          -0.9846974
Policy log std Std           0.28021634
Policy log std Max           -0.1724571
Policy log std Min           -2.4185061
Z mean eval                  1.2284832
Z variance eval              0.01848067
total_rewards                [ 714.20366285 1942.97674899  287.09673417 1236.45565431  103.47878948
 2309.47121825  837.90684054 3438.90008356 3826.1432079  1240.15019765]
total_rewards_mean           1593.6783137697844
total_rewards_std            1206.1599457454731
total_rewards_max            3826.1432078979974
total_rewards_min            103.4787894788355
Number of train steps total  1368000
Number of env steps total    1712000
Number of rollouts total     0
Train Time (s)               133.76680888887495
(Previous) Eval Time (s)     25.51719337468967
Sample Time (s)              25.40433772513643
Epoch Time (s)               184.68833998870105
Total Train Time (s)         63189.40820886148
Epoch                        341
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:06:05.482103 UTC | [2020_01_11_13_32_55] Iteration #341 | Epoch Duration: 180.24723434448242
2020-01-12 07:06:05.482219 UTC | [2020_01_11_13_32_55] Iteration #341 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2282829
Z variance train             0.01845983
KL Divergence                28.47438
KL Loss                      2.847438
QF Loss                      832.99963
VF Loss                      338.92407
Policy Loss                  -1384.3839
Q Predictions Mean           1384.2063
Q Predictions Std            410.3259
Q Predictions Max            1640.342
Q Predictions Min            -33.762863
V Predictions Mean           1387.8845
V Predictions Std            401.65024
V Predictions Max            1631.8215
V Predictions Min            -41.12053
Log Pis Mean                 0.3988701
Log Pis Std                  3.254695
Log Pis Max                  11.895546
Log Pis Min                  -7.133001
Policy mu Mean               0.011579533
Policy mu Std                0.6836222
Policy mu Max                2.6781812
Policy mu Min                -2.452567
Policy log std Mean          -0.9852433
Policy log std Std           0.3053924
Policy log std Max           0.059835672
Policy log std Min           -2.5704806
Z mean eval                  1.2272943
Z variance eval              0.024025168
total_rewards                [3795.42215619  138.03301062   46.68619451   53.57625447  372.37034743
  192.03893187  434.75267123 3628.79121485 2364.83306446 2072.43279034]
total_rewards_mean           1309.893663597832
total_rewards_std            1438.443800033479
total_rewards_max            3795.422156193763
total_rewards_min            46.68619451252374
Number of train steps total  1372000
Number of env steps total    1717000
Number of rollouts total     0
Train Time (s)               134.75483826221898
(Previous) Eval Time (s)     21.075809296686202
Sample Time (s)              23.51581877656281
Epoch Time (s)               179.346466335468
Total Train Time (s)         63364.181160455104
Epoch                        342
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:09:00.259440 UTC | [2020_01_11_13_32_55] Iteration #342 | Epoch Duration: 174.77711868286133
2020-01-12 07:09:00.259635 UTC | [2020_01_11_13_32_55] Iteration #342 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2269223
Z variance train             0.024133213
KL Divergence                28.675144
KL Loss                      2.8675144
QF Loss                      2890.3518
VF Loss                      318.81955
Policy Loss                  -1419.6812
Q Predictions Mean           1423.5007
Q Predictions Std            351.10715
Q Predictions Max            1644.4551
Q Predictions Min            -177.97507
V Predictions Mean           1432.3252
V Predictions Std            352.737
V Predictions Max            1657.4463
V Predictions Min            -167.88034
Log Pis Mean                 1.0457339
Log Pis Std                  3.0161862
Log Pis Max                  13.092828
Log Pis Min                  -9.475408
Policy mu Mean               0.0042971596
Policy mu Std                0.6808158
Policy mu Max                2.6737409
Policy mu Min                -2.7533073
Policy log std Mean          -1.0238007
Policy log std Std           0.30398446
Policy log std Max           -0.1263187
Policy log std Min           -2.2352676
Z mean eval                  1.2166163
Z variance eval              0.011319278
total_rewards                [1214.34160825  336.2464237   974.05303897 2865.63026438  180.60988176
 3690.31611048 2122.80634724  913.56857131 3915.52058289 2046.11548575]
total_rewards_mean           1825.9208314740222
total_rewards_std            1261.6771286224107
total_rewards_max            3915.520582894629
total_rewards_min            180.60988176315436
Number of train steps total  1376000
Number of env steps total    1722000
Number of rollouts total     0
Train Time (s)               138.8849397948943
(Previous) Eval Time (s)     16.506116238888353
Sample Time (s)              25.19246157212183
Epoch Time (s)               180.5835176059045
Total Train Time (s)         63545.47095241444
Epoch                        343
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:12:01.553502 UTC | [2020_01_11_13_32_55] Iteration #343 | Epoch Duration: 181.29372763633728
2020-01-12 07:12:01.553697 UTC | [2020_01_11_13_32_55] Iteration #343 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2190168
Z variance train             0.011278531
KL Divergence                28.924889
KL Loss                      2.892489
QF Loss                      1334.457
VF Loss                      554.11646
Policy Loss                  -1387.3083
Q Predictions Mean           1385.4833
Q Predictions Std            404.87225
Q Predictions Max            1665.0587
Q Predictions Min            -216.34949
V Predictions Mean           1384.2523
V Predictions Std            393.73438
V Predictions Max            1641.5018
V Predictions Min            -171.65355
Log Pis Mean                 0.6582638
Log Pis Std                  3.297411
Log Pis Max                  16.146751
Log Pis Min                  -7.292019
Policy mu Mean               0.03714791
Policy mu Std                0.6941458
Policy mu Max                3.3951576
Policy mu Min                -3.1676943
Policy log std Mean          -0.9913783
Policy log std Std           0.31394324
Policy log std Max           0.2749958
Policy log std Min           -3.1099505
Z mean eval                  1.2180153
Z variance eval              0.013655812
total_rewards                [ 492.71224233  782.28483641 3976.21472316  317.7196377  3953.88772003
 3741.38372831  345.89446412 3784.21150651  956.59570673 3929.58546905]
total_rewards_mean           2228.0490034328873
total_rewards_std            1659.871618857147
total_rewards_max            3976.2147231571316
total_rewards_min            317.71963769791506
Number of train steps total  1380000
Number of env steps total    1727000
Number of rollouts total     0
Train Time (s)               143.62996827904135
(Previous) Eval Time (s)     17.21592869097367
Sample Time (s)              26.8369920370169
Epoch Time (s)               187.68288900703192
Total Train Time (s)         63739.13399892207
Epoch                        344
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:15:15.220618 UTC | [2020_01_11_13_32_55] Iteration #344 | Epoch Duration: 193.6667559146881
2020-01-12 07:15:15.220942 UTC | [2020_01_11_13_32_55] Iteration #344 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2177421
Z variance train             0.013631782
KL Divergence                28.070965
KL Loss                      2.8070965
QF Loss                      889.61206
VF Loss                      420.44498
Policy Loss                  -1406.4396
Q Predictions Mean           1409.6895
Q Predictions Std            357.35892
Q Predictions Max            1626.2661
Q Predictions Min            -138.57478
V Predictions Mean           1409.0166
V Predictions Std            353.84448
V Predictions Max            1629.2783
V Predictions Min            -131.82289
Log Pis Mean                 0.6853276
Log Pis Std                  3.2966087
Log Pis Max                  21.981052
Log Pis Min                  -7.1173835
Policy mu Mean               0.020429783
Policy mu Std                0.642652
Policy mu Max                3.0107884
Policy mu Min                -2.445678
Policy log std Mean          -1.0625753
Policy log std Std           0.3126424
Policy log std Max           -0.12972856
Policy log std Min           -3.3775134
Z mean eval                  1.1988165
Z variance eval              0.0140529275
total_rewards                [1526.15918164 3797.6969478  3744.86845707 2833.23896579 3767.62404627
 1281.29335315 2180.64922712 1625.0412415   460.64388951 1014.17664434]
total_rewards_mean           2223.139195418719
total_rewards_std            1176.9838014612878
total_rewards_max            3797.6969478003257
total_rewards_min            460.6438895135534
Number of train steps total  1384000
Number of env steps total    1732000
Number of rollouts total     0
Train Time (s)               142.35534639004618
(Previous) Eval Time (s)     23.199332125950605
Sample Time (s)              26.415708679240197
Epoch Time (s)               191.97038719523698
Total Train Time (s)         63930.91443670727
Epoch                        345
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:18:27.003773 UTC | [2020_01_11_13_32_55] Iteration #345 | Epoch Duration: 191.78263235092163
2020-01-12 07:18:27.003957 UTC | [2020_01_11_13_32_55] Iteration #345 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1986578
Z variance train             0.014095028
KL Divergence                28.28569
KL Loss                      2.8285692
QF Loss                      5903.4453
VF Loss                      681.0501
Policy Loss                  -1396.0072
Q Predictions Mean           1399.2651
Q Predictions Std            357.45807
Q Predictions Max            1613.678
Q Predictions Min            -229.55798
V Predictions Mean           1396.6086
V Predictions Std            352.73355
V Predictions Max            1610.0098
V Predictions Min            -207.928
Log Pis Mean                 0.8983332
Log Pis Std                  3.6180494
Log Pis Max                  17.356195
Log Pis Min                  -8.214258
Policy mu Mean               0.013981904
Policy mu Std                0.66790134
Policy mu Max                4.1762347
Policy mu Min                -2.79795
Policy log std Mean          -1.061121
Policy log std Std           0.33844754
Policy log std Max           0.11599076
Policy log std Min           -2.832306
Z mean eval                  1.1877053
Z variance eval              0.010318282
total_rewards                [ 548.52816701 3432.80932019 3629.39872093 1334.31642393 4057.87628026
  689.35277441 3259.99192579  769.93261715   69.14768262  478.54486291]
total_rewards_mean           1826.9898775190122
total_rewards_std            1485.0850339401845
total_rewards_max            4057.8762802554484
total_rewards_min            69.14768261505573
Number of train steps total  1388000
Number of env steps total    1737000
Number of rollouts total     0
Train Time (s)               144.2806555009447
(Previous) Eval Time (s)     23.011183010879904
Sample Time (s)              26.43700419459492
Epoch Time (s)               193.72884270641953
Total Train Time (s)         64119.1285917582
Epoch                        346
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:21:35.222315 UTC | [2020_01_11_13_32_55] Iteration #346 | Epoch Duration: 188.21821475028992
2020-01-12 07:21:35.222551 UTC | [2020_01_11_13_32_55] Iteration #346 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1870973
Z variance train             0.01031304
KL Divergence                29.199749
KL Loss                      2.919975
QF Loss                      1021.3543
VF Loss                      314.2894
Policy Loss                  -1419.289
Q Predictions Mean           1422.6011
Q Predictions Std            317.78928
Q Predictions Max            1609.2327
Q Predictions Min            -111.227615
V Predictions Mean           1422.856
V Predictions Std            315.33902
V Predictions Max            1631.78
V Predictions Min            -114.22207
Log Pis Mean                 0.5883698
Log Pis Std                  3.413036
Log Pis Max                  12.68396
Log Pis Min                  -8.401055
Policy mu Mean               0.034669235
Policy mu Std                0.6816917
Policy mu Max                3.2604764
Policy mu Min                -2.312682
Policy log std Mean          -1.0089085
Policy log std Std           0.31764707
Policy log std Max           0.034476757
Policy log std Min           -2.8001394
Z mean eval                  1.2174678
Z variance eval              0.018912788
total_rewards                [ 773.46105328 3437.49866008 1267.10964658 2103.90325926  869.16235417
 3642.95107876  903.86593603 3810.02257567 2771.5542969   338.73111992]
total_rewards_mean           1991.8259980652936
total_rewards_std            1262.0990517368305
total_rewards_max            3810.022575672757
total_rewards_min            338.7311199192783
Number of train steps total  1392000
Number of env steps total    1742000
Number of rollouts total     0
Train Time (s)               143.03898768499494
(Previous) Eval Time (s)     17.500181197188795
Sample Time (s)              25.61385304760188
Epoch Time (s)               186.1530219297856
Total Train Time (s)         64308.60557466466
Epoch                        347
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:24:44.703808 UTC | [2020_01_11_13_32_55] Iteration #347 | Epoch Duration: 189.48110699653625
2020-01-12 07:24:44.704027 UTC | [2020_01_11_13_32_55] Iteration #347 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2178733
Z variance train             0.01895799
KL Divergence                28.92277
KL Loss                      2.892277
QF Loss                      1638.9763
VF Loss                      267.89767
Policy Loss                  -1419.816
Q Predictions Mean           1417.0487
Q Predictions Std            336.84763
Q Predictions Max            1625.6143
Q Predictions Min            -182.11208
V Predictions Mean           1418.8123
V Predictions Std            330.2017
V Predictions Max            1617.618
V Predictions Min            -165.44568
Log Pis Mean                 0.8185029
Log Pis Std                  3.2643795
Log Pis Max                  20.64928
Log Pis Min                  -6.9850407
Policy mu Mean               -0.009174003
Policy mu Std                0.6645856
Policy mu Max                2.9325054
Policy mu Min                -2.476853
Policy log std Mean          -1.027313
Policy log std Std           0.33905786
Policy log std Max           -0.1535505
Policy log std Min           -2.9255533
Z mean eval                  1.2238388
Z variance eval              0.015764797
total_rewards                [3875.07537078 4044.52726562  296.19789031 1161.39905475 3766.20701756
 1061.16539419 3821.77147126 3921.34422348 1865.564516   3997.80980388]
total_rewards_mean           2781.1062007809933
total_rewards_std            1422.0250724834264
total_rewards_max            4044.527265615663
total_rewards_min            296.19789030640584
Number of train steps total  1396000
Number of env steps total    1747000
Number of rollouts total     0
Train Time (s)               135.18137696990743
(Previous) Eval Time (s)     20.827850504778326
Sample Time (s)              24.778000607155263
Epoch Time (s)               180.78722808184102
Total Train Time (s)         64493.71324236831
Epoch                        348
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:27:49.815630 UTC | [2020_01_11_13_32_55] Iteration #348 | Epoch Duration: 185.11144256591797
2020-01-12 07:27:49.815878 UTC | [2020_01_11_13_32_55] Iteration #348 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2223955
Z variance train             0.015767056
KL Divergence                29.564022
KL Loss                      2.9564023
QF Loss                      845.6238
VF Loss                      258.6996
Policy Loss                  -1417.0865
Q Predictions Mean           1422.3717
Q Predictions Std            302.07852
Q Predictions Max            1618.8579
Q Predictions Min            -212.14139
V Predictions Mean           1421.5247
V Predictions Std            303.7315
V Predictions Max            1626.4712
V Predictions Min            -197.83485
Log Pis Mean                 0.92650545
Log Pis Std                  2.9980862
Log Pis Max                  10.98683
Log Pis Min                  -5.5241175
Policy mu Mean               0.01014669
Policy mu Std                0.67458916
Policy mu Max                2.3295054
Policy mu Min                -2.3812428
Policy log std Mean          -1.0307357
Policy log std Std           0.29317003
Policy log std Max           -0.31201702
Policy log std Min           -2.1950464
Z mean eval                  1.1992215
Z variance eval              0.011330659
total_rewards                [3620.39723964  615.05299586  632.28952516 3842.3165544  1003.3526924
 3609.95032493  643.32707819 2857.67038241  294.69951221 4051.55780411]
total_rewards_mean           2117.0614109309145
total_rewards_std            1514.920423396406
total_rewards_max            4051.557804109903
total_rewards_min            294.6995122115897
Number of train steps total  1400000
Number of env steps total    1752000
Number of rollouts total     0
Train Time (s)               135.43781704828143
(Previous) Eval Time (s)     25.151734047103673
Sample Time (s)              24.68941966118291
Epoch Time (s)               185.27897075656801
Total Train Time (s)         64673.82077180082
Epoch                        349
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:30:49.926602 UTC | [2020_01_11_13_32_55] Iteration #349 | Epoch Duration: 180.11057686805725
2020-01-12 07:30:49.926781 UTC | [2020_01_11_13_32_55] Iteration #349 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1995473
Z variance train             0.011314294
KL Divergence                30.344784
KL Loss                      3.0344784
QF Loss                      2140.121
VF Loss                      274.3129
Policy Loss                  -1349.9071
Q Predictions Mean           1350.0447
Q Predictions Std            437.48782
Q Predictions Max            1627.2181
Q Predictions Min            -228.39397
V Predictions Mean           1350.7607
V Predictions Std            436.20428
V Predictions Max            1617.812
V Predictions Min            -291.91794
Log Pis Mean                 0.695127
Log Pis Std                  4.1471996
Log Pis Max                  22.22136
Log Pis Min                  -10.006158
Policy mu Mean               -0.02582768
Policy mu Std                0.71017355
Policy mu Max                4.1483684
Policy mu Min                -4.5807886
Policy log std Mean          -1.0000889
Policy log std Std           0.34338295
Policy log std Max           0.8971077
Policy log std Min           -3.0598032
Z mean eval                  1.2349979
Z variance eval              0.011537576
total_rewards                [3.31074609e-01 3.87617123e+03 6.56849953e+02 1.83619864e+01
 2.43134484e+03 3.75208161e+03 3.25075742e+03 2.84661321e+03
 1.39639217e+02 5.50260839e+01]
total_rewards_mean           1702.7176620853413
total_rewards_std            1585.7720465174004
total_rewards_max            3876.171229413285
total_rewards_min            0.3310746087042573
Number of train steps total  1404000
Number of env steps total    1757000
Number of rollouts total     0
Train Time (s)               141.54309683199972
(Previous) Eval Time (s)     19.982995999976993
Sample Time (s)              24.19237605109811
Epoch Time (s)               185.71846888307482
Total Train Time (s)         64856.253054154105
Epoch                        350
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:33:52.363099 UTC | [2020_01_11_13_32_55] Iteration #350 | Epoch Duration: 182.43618631362915
2020-01-12 07:33:52.363344 UTC | [2020_01_11_13_32_55] Iteration #350 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2308611
Z variance train             0.011522656
KL Divergence                29.241913
KL Loss                      2.9241912
QF Loss                      1303.3269
VF Loss                      576.7793
Policy Loss                  -1404.4556
Q Predictions Mean           1405.229
Q Predictions Std            364.23776
Q Predictions Max            1616.6901
Q Predictions Min            -287.56363
V Predictions Mean           1404.8318
V Predictions Std            361.5958
V Predictions Max            1627.7245
V Predictions Min            -261.63583
Log Pis Mean                 0.30147076
Log Pis Std                  2.9526412
Log Pis Max                  11.992851
Log Pis Min                  -6.808708
Policy mu Mean               0.02225866
Policy mu Std                0.6580021
Policy mu Max                2.9859295
Policy mu Min                -2.1680489
Policy log std Mean          -0.99736166
Policy log std Std           0.3012581
Policy log std Max           -0.21109617
Policy log std Min           -2.4793704
Z mean eval                  1.2450788
Z variance eval              0.0061985827
total_rewards                [1334.74879956 3716.73156451 3372.88967531 2638.77587032 1053.24963797
  605.0664836  3577.33622389  808.48545779 1565.89524941 4049.58850684]
total_rewards_mean           2272.276746918436
total_rewards_std            1268.08410764977
total_rewards_max            4049.5885068408134
total_rewards_min            605.0664836029105
Number of train steps total  1408000
Number of env steps total    1762000
Number of rollouts total     0
Train Time (s)               142.64282830711454
(Previous) Eval Time (s)     16.70033122971654
Sample Time (s)              25.96515727462247
Epoch Time (s)               185.30831681145355
Total Train Time (s)         65049.03183226101
Epoch                        351
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:37:05.146956 UTC | [2020_01_11_13_32_55] Iteration #351 | Epoch Duration: 192.7834370136261
2020-01-12 07:37:05.147302 UTC | [2020_01_11_13_32_55] Iteration #351 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2452695
Z variance train             0.006207717
KL Divergence                29.086222
KL Loss                      2.9086223
QF Loss                      1000.86346
VF Loss                      313.8478
Policy Loss                  -1403.0132
Q Predictions Mean           1399.8175
Q Predictions Std            388.29184
Q Predictions Max            1632.3752
Q Predictions Min            -273.22586
V Predictions Mean           1403.7051
V Predictions Std            380.93063
V Predictions Max            1618.939
V Predictions Min            -266.0773
Log Pis Mean                 0.5003782
Log Pis Std                  3.2378678
Log Pis Max                  12.455326
Log Pis Min                  -8.145241
Policy mu Mean               0.06253497
Policy mu Std                0.63184875
Policy mu Max                3.615688
Policy mu Min                -2.372103
Policy log std Mean          -1.0317237
Policy log std Std           0.32787833
Policy log std Max           -0.1797483
Policy log std Min           -2.9848938
Z mean eval                  1.218561
Z variance eval              0.010501843
total_rewards                [ 552.53353041 3107.55704429 2496.17985486 3666.0056629  1062.4007406
 1597.65346604 3827.63943475 1904.46159891 3487.21790303  145.42835971]
total_rewards_mean           2184.7077595512237
total_rewards_std            1266.651617216209
total_rewards_max            3827.639434753341
total_rewards_min            145.42835971218236
Number of train steps total  1412000
Number of env steps total    1767000
Number of rollouts total     0
Train Time (s)               141.95305647328496
(Previous) Eval Time (s)     24.17506522964686
Sample Time (s)              26.409456295892596
Epoch Time (s)               192.53757799882442
Total Train Time (s)         65241.341000718065
Epoch                        352
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:40:17.459560 UTC | [2020_01_11_13_32_55] Iteration #352 | Epoch Duration: 192.31208276748657
2020-01-12 07:40:17.459727 UTC | [2020_01_11_13_32_55] Iteration #352 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2233431
Z variance train             0.010482655
KL Divergence                28.312918
KL Loss                      2.831292
QF Loss                      11043.697
VF Loss                      697.7805
Policy Loss                  -1431.1107
Q Predictions Mean           1439.4886
Q Predictions Std            351.3823
Q Predictions Max            1686.9758
Q Predictions Min            -34.570763
V Predictions Mean           1432.8428
V Predictions Std            355.39178
V Predictions Max            1682.604
V Predictions Min            -41.56699
Log Pis Mean                 0.62888545
Log Pis Std                  3.2436094
Log Pis Max                  12.672356
Log Pis Min                  -8.038376
Policy mu Mean               0.03200218
Policy mu Std                0.6809525
Policy mu Max                3.929296
Policy mu Min                -2.9683244
Policy log std Mean          -0.9954082
Policy log std Std           0.31510267
Policy log std Max           1.0750003
Policy log std Min           -3.120755
Z mean eval                  1.2426872
Z variance eval              0.009154323
total_rewards                [3671.6156898  2637.20141694  510.41845226 3621.99152128 1159.38430138
 3095.69765228  606.67818211 3937.94814652 1675.0665908  2971.10515701]
total_rewards_mean           2388.710711039416
total_rewards_std            1232.5533629407041
total_rewards_max            3937.948146516478
total_rewards_min            510.41845226370015
Number of train steps total  1416000
Number of env steps total    1772000
Number of rollouts total     0
Train Time (s)               143.38348496891558
(Previous) Eval Time (s)     23.94921399326995
Sample Time (s)              25.55934342322871
Epoch Time (s)               192.89204238541424
Total Train Time (s)         65433.44974832656
Epoch                        353
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:43:29.572569 UTC | [2020_01_11_13_32_55] Iteration #353 | Epoch Duration: 192.1127154827118
2020-01-12 07:43:29.572768 UTC | [2020_01_11_13_32_55] Iteration #353 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2415869
Z variance train             0.009150493
KL Divergence                28.24299
KL Loss                      2.824299
QF Loss                      1837.2021
VF Loss                      1307.5776
Policy Loss                  -1415.225
Q Predictions Mean           1419.0015
Q Predictions Std            366.84402
Q Predictions Max            1629.8483
Q Predictions Min            -156.75888
V Predictions Mean           1415.0475
V Predictions Std            360.50598
V Predictions Max            1623.687
V Predictions Min            -189.55072
Log Pis Mean                 0.49383458
Log Pis Std                  3.1979601
Log Pis Max                  11.550009
Log Pis Min                  -9.320232
Policy mu Mean               0.013810031
Policy mu Std                0.6785729
Policy mu Max                2.943794
Policy mu Min                -2.5507708
Policy log std Mean          -0.9808539
Policy log std Std           0.27260762
Policy log std Max           0.42578435
Policy log std Min           -2.4512181
Z mean eval                  1.1946167
Z variance eval              0.005166725
total_rewards                [3485.79337408 3801.38723301  731.30569851 3724.3698522  1762.99452422
 3154.15943165 2075.31065426 1756.40994365 2272.41082005 2093.47521572]
total_rewards_mean           2485.7616747350216
total_rewards_std            959.8009770446735
total_rewards_max            3801.3872330054987
total_rewards_min            731.3056985057513
Number of train steps total  1420000
Number of env steps total    1777000
Number of rollouts total     0
Train Time (s)               140.2211619517766
(Previous) Eval Time (s)     23.16947411093861
Sample Time (s)              24.62825925182551
Epoch Time (s)               188.0188953145407
Total Train Time (s)         65626.13597424701
Epoch                        354
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:46:42.262548 UTC | [2020_01_11_13_32_55] Iteration #354 | Epoch Duration: 192.68964767456055
2020-01-12 07:46:42.262727 UTC | [2020_01_11_13_32_55] Iteration #354 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.196991
Z variance train             0.005173826
KL Divergence                28.631683
KL Loss                      2.8631685
QF Loss                      1429.72
VF Loss                      438.81372
Policy Loss                  -1416.598
Q Predictions Mean           1415.5645
Q Predictions Std            363.00415
Q Predictions Max            1631.9053
Q Predictions Min            -198.97647
V Predictions Mean           1422.3889
V Predictions Std            356.63895
V Predictions Max            1641.3779
V Predictions Min            -215.18184
Log Pis Mean                 0.58470637
Log Pis Std                  3.3996124
Log Pis Max                  22.666393
Log Pis Min                  -7.7862206
Policy mu Mean               0.033666156
Policy mu Std                0.66918164
Policy mu Max                4.846855
Policy mu Min                -2.2605734
Policy log std Mean          -0.99963075
Policy log std Std           0.30638242
Policy log std Max           0.02660358
Policy log std Min           -3.440038
Z mean eval                  1.2280438
Z variance eval              0.013547657
total_rewards                [3769.26862535 1218.36092347 3998.04837131 2815.79412628 4040.30155832
  216.01984347 3699.07922688 3553.68423627 4003.01941431 3762.70523067]
total_rewards_mean           3107.6281556341883
total_rewards_std            1260.7943619400103
total_rewards_max            4040.301558322813
total_rewards_min            216.0198434731221
Number of train steps total  1424000
Number of env steps total    1782000
Number of rollouts total     0
Train Time (s)               135.1226309351623
(Previous) Eval Time (s)     27.839863415341824
Sample Time (s)              25.071668842807412
Epoch Time (s)               188.03416319331154
Total Train Time (s)         65813.79048871575
Epoch                        355
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:49:49.921243 UTC | [2020_01_11_13_32_55] Iteration #355 | Epoch Duration: 187.65837287902832
2020-01-12 07:49:49.921432 UTC | [2020_01_11_13_32_55] Iteration #355 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.22734
Z variance train             0.013538462
KL Divergence                27.633778
KL Loss                      2.763378
QF Loss                      1330.0779
VF Loss                      181.32562
Policy Loss                  -1416.4844
Q Predictions Mean           1418.7417
Q Predictions Std            338.07846
Q Predictions Max            1615.6716
Q Predictions Min            -261.8127
V Predictions Mean           1415.9382
V Predictions Std            332.9716
V Predictions Max            1609.293
V Predictions Min            -263.0938
Log Pis Mean                 0.45411465
Log Pis Std                  3.07586
Log Pis Max                  13.751499
Log Pis Min                  -7.326456
Policy mu Mean               0.011958883
Policy mu Std                0.6202839
Policy mu Max                2.6053598
Policy mu Min                -2.389759
Policy log std Mean          -1.0443623
Policy log std Std           0.29946092
Policy log std Max           -0.043105125
Policy log std Min           -3.1231728
Z mean eval                  1.2903616
Z variance eval              0.01413576
total_rewards                [ 905.37511376 2656.47775862 4025.12897727 3733.36865716 3759.36949661
 3519.62151638 2356.60989058 3272.42036227 3159.58763726 3852.12999307]
total_rewards_mean           3124.008940298135
total_rewards_std            895.9243136206816
total_rewards_max            4025.1289772688406
total_rewards_min            905.3751137618698
Number of train steps total  1428000
Number of env steps total    1787000
Number of rollouts total     0
Train Time (s)               135.31132873613387
(Previous) Eval Time (s)     27.46375637408346
Sample Time (s)              24.236254333518445
Epoch Time (s)               187.01133944373578
Total Train Time (s)         66002.51812581532
Epoch                        356
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:52:58.653067 UTC | [2020_01_11_13_32_55] Iteration #356 | Epoch Duration: 188.73150372505188
2020-01-12 07:52:58.653246 UTC | [2020_01_11_13_32_55] Iteration #356 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2876527
Z variance train             0.0141380355
KL Divergence                26.323545
KL Loss                      2.6323545
QF Loss                      5554.4727
VF Loss                      417.8808
Policy Loss                  -1386.107
Q Predictions Mean           1384.1614
Q Predictions Std            421.73856
Q Predictions Max            1617.4939
Q Predictions Min            -282.47482
V Predictions Mean           1386.7539
V Predictions Std            409.78165
V Predictions Max            1624.8342
V Predictions Min            -246.13608
Log Pis Mean                 0.61354554
Log Pis Std                  3.282296
Log Pis Max                  17.277195
Log Pis Min                  -7.113587
Policy mu Mean               0.03444554
Policy mu Std                0.64946514
Policy mu Max                2.9731174
Policy mu Min                -4.4419003
Policy log std Mean          -1.02807
Policy log std Std           0.30940664
Policy log std Max           1.3587406
Policy log std Min           -2.9438052
Z mean eval                  1.2316376
Z variance eval              0.010709641
total_rewards                [1441.90365767 2350.9068952   370.37441241 4083.41609662 3829.51602203
 3902.07976462 3893.79569243 3815.25651847 3835.62219824 3878.74535867]
total_rewards_mean           3140.16166163467
total_rewards_std            1231.9525499351025
total_rewards_max            4083.4160966172385
total_rewards_min            370.3744124104644
Number of train steps total  1432000
Number of env steps total    1792000
Number of rollouts total     0
Train Time (s)               143.37757789436728
(Previous) Eval Time (s)     29.183629848994315
Sample Time (s)              26.142795004416257
Epoch Time (s)               198.70400274777785
Total Train Time (s)         66204.9923729361
Epoch                        357
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:56:21.131340 UTC | [2020_01_11_13_32_55] Iteration #357 | Epoch Duration: 202.47796273231506
2020-01-12 07:56:21.131535 UTC | [2020_01_11_13_32_55] Iteration #357 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2329303
Z variance train             0.0107076
KL Divergence                27.297882
KL Loss                      2.7297883
QF Loss                      1174.3379
VF Loss                      242.5512
Policy Loss                  -1410.8191
Q Predictions Mean           1408.7466
Q Predictions Std            359.2745
Q Predictions Max            1624.2203
Q Predictions Min            -173.03958
V Predictions Mean           1404.391
V Predictions Std            357.7751
V Predictions Max            1628.9872
V Predictions Min            -181.84329
Log Pis Mean                 0.80654275
Log Pis Std                  3.292971
Log Pis Max                  12.946226
Log Pis Min                  -9.075867
Policy mu Mean               0.032110747
Policy mu Std                0.6558609
Policy mu Max                3.693061
Policy mu Min                -2.2770982
Policy log std Mean          -1.0665286
Policy log std Std           0.3219989
Policy log std Max           -0.28564656
Policy log std Min           -2.6510067
Z mean eval                  1.2513968
Z variance eval              0.018266028
total_rewards                [3873.85607099 3852.99374249 3694.44440547 3773.25525569  933.26097165
 2530.8940514  3986.08786974 3126.44918101 3155.17808067  445.51475919]
total_rewards_mean           2937.193438831019
total_rewards_std            1206.7003441537643
total_rewards_max            3986.087869740711
total_rewards_min            445.5147591886537
Number of train steps total  1436000
Number of env steps total    1797000
Number of rollouts total     0
Train Time (s)               142.81467629224062
(Previous) Eval Time (s)     32.9571369132027
Sample Time (s)              25.262853999622166
Epoch Time (s)               201.0346672050655
Total Train Time (s)         66400.07183349645
Epoch                        358
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:59:36.215255 UTC | [2020_01_11_13_32_55] Iteration #358 | Epoch Duration: 195.08352661132812
2020-01-12 07:59:36.215573 UTC | [2020_01_11_13_32_55] Iteration #358 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2503474
Z variance train             0.01835482
KL Divergence                26.265997
KL Loss                      2.6265998
QF Loss                      1178.7709
VF Loss                      154.59648
Policy Loss                  -1429.2711
Q Predictions Mean           1432.0017
Q Predictions Std            343.82672
Q Predictions Max            1639.5747
Q Predictions Min            -186.6198
V Predictions Mean           1427.1161
V Predictions Std            344.72565
V Predictions Max            1643.5109
V Predictions Min            -166.5864
Log Pis Mean                 0.77614754
Log Pis Std                  2.6633387
Log Pis Max                  11.731976
Log Pis Min                  -5.8814783
Policy mu Mean               0.023992332
Policy mu Std                0.6667494
Policy mu Max                2.5827162
Policy mu Min                -2.1629803
Policy log std Mean          -1.0285921
Policy log std Std           0.2854808
Policy log std Max           0.14275634
Policy log std Min           -2.6061091
Z mean eval                  1.2449192
Z variance eval              0.01819443
total_rewards                [ -15.11895123  503.54299168 3669.42742669  401.39153306 3889.79142908
 3510.40884477   24.02228312 -206.73972312  500.66296495 3833.40626368]
total_rewards_mean           1611.079506267573
total_rewards_std            1742.5916952566358
total_rewards_max            3889.7914290834447
total_rewards_min            -206.73972311677477
Number of train steps total  1440000
Number of env steps total    1802000
Number of rollouts total     0
Train Time (s)               142.78849453199655
(Previous) Eval Time (s)     27.005627067759633
Sample Time (s)              25.38390920450911
Epoch Time (s)               195.1780308042653
Total Train Time (s)         66587.94231215212
Epoch                        359
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:02:44.089002 UTC | [2020_01_11_13_32_55] Iteration #359 | Epoch Duration: 187.87327313423157
2020-01-12 08:02:44.089178 UTC | [2020_01_11_13_32_55] Iteration #359 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.245801
Z variance train             0.018288482
KL Divergence                26.799028
KL Loss                      2.6799028
QF Loss                      582.07056
VF Loss                      99.35603
Policy Loss                  -1428.1411
Q Predictions Mean           1425.5596
Q Predictions Std            357.1414
Q Predictions Max            1645.2657
Q Predictions Min            -214.07191
V Predictions Mean           1429.2806
V Predictions Std            346.5788
V Predictions Max            1632.9893
V Predictions Min            -178.2722
Log Pis Mean                 0.4882186
Log Pis Std                  2.8666837
Log Pis Max                  9.982216
Log Pis Min                  -7.726553
Policy mu Mean               -0.0019541811
Policy mu Std                0.6700539
Policy mu Max                2.9460866
Policy mu Min                -2.3472354
Policy log std Mean          -0.98525167
Policy log std Std           0.26754922
Policy log std Max           -0.008967519
Policy log std Min           -2.284677
Z mean eval                  1.2020662
Z variance eval              0.024026386
total_rewards                [2433.69418961 2482.11307101 2174.26297608  749.76672886  646.11504681
  530.27293516   51.464365   2989.6429966  1607.0080176  3642.07997605]
total_rewards_mean           1730.6420302787951
total_rewards_std            1136.1598990038976
total_rewards_max            3642.0799760522455
total_rewards_min            51.46436500165405
Number of train steps total  1444000
Number of env steps total    1807000
Number of rollouts total     0
Train Time (s)               142.6293781902641
(Previous) Eval Time (s)     19.700543616898358
Sample Time (s)              26.122377001214772
Epoch Time (s)               188.45229880837724
Total Train Time (s)         66773.90199732268
Epoch                        360
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:05:50.053544 UTC | [2020_01_11_13_32_55] Iteration #360 | Epoch Duration: 185.9642050266266
2020-01-12 08:05:50.053863 UTC | [2020_01_11_13_32_55] Iteration #360 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2018411
Z variance train             0.024118897
KL Divergence                26.994265
KL Loss                      2.6994264
QF Loss                      1881.9297
VF Loss                      196.04643
Policy Loss                  -1388.9972
Q Predictions Mean           1390.1582
Q Predictions Std            415.21408
Q Predictions Max            1637.5933
Q Predictions Min            -228.77782
V Predictions Mean           1388.9917
V Predictions Std            413.19998
V Predictions Max            1637.0731
V Predictions Min            -219.30461
Log Pis Mean                 0.52336013
Log Pis Std                  3.4574385
Log Pis Max                  15.302227
Log Pis Min                  -11.256948
Policy mu Mean               0.01519707
Policy mu Std                0.64031655
Policy mu Max                2.8663275
Policy mu Min                -2.555292
Policy log std Mean          -1.0327061
Policy log std Std           0.3379963
Policy log std Max           -0.1601454
Policy log std Min           -3.0168738
Z mean eval                  1.2321434
Z variance eval              0.012381446
total_rewards                [ 835.39966982 2618.53871944 3448.52618844 2025.3848801  3970.44470382
 3882.8116159  2134.17971506 1086.08460783 2967.7262106  3561.61547536]
total_rewards_mean           2653.0711786370557
total_rewards_std            1059.658025351357
total_rewards_max            3970.444703817166
total_rewards_min            835.3996698162281
Number of train steps total  1448000
Number of env steps total    1812000
Number of rollouts total     0
Train Time (s)               134.8077445141971
(Previous) Eval Time (s)     17.212007545866072
Sample Time (s)              24.92711293604225
Epoch Time (s)               176.94686499610543
Total Train Time (s)         66960.9058157308
Epoch                        361
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:08:57.060767 UTC | [2020_01_11_13_32_55] Iteration #361 | Epoch Duration: 187.00673460960388
2020-01-12 08:08:57.060967 UTC | [2020_01_11_13_32_55] Iteration #361 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2293279
Z variance train             0.012448469
KL Divergence                26.102392
KL Loss                      2.6102393
QF Loss                      1816.2959
VF Loss                      1158.0339
Policy Loss                  -1365.5536
Q Predictions Mean           1368.8958
Q Predictions Std            401.62
Q Predictions Max            1601.9756
Q Predictions Min            -186.76317
V Predictions Mean           1383.7388
V Predictions Std            395.44745
V Predictions Max            1610.588
V Predictions Min            -186.78813
Log Pis Mean                 0.37485802
Log Pis Std                  3.319305
Log Pis Max                  16.233583
Log Pis Min                  -6.5077252
Policy mu Mean               0.021431275
Policy mu Std                0.6324976
Policy mu Max                2.8455412
Policy mu Min                -2.2826445
Policy log std Mean          -1.0419102
Policy log std Std           0.33268744
Policy log std Max           -0.21871889
Policy log std Min           -2.8443508
Z mean eval                  1.1993845
Z variance eval              0.01280186
total_rewards                [3555.84173129 3587.16716185 1955.16251218 3617.18736847 3917.49179906
 3113.73807135 3604.55470051 1101.635191   2659.70306525  212.59124601]
total_rewards_mean           2732.5072846955622
total_rewards_std            1188.2869961546987
total_rewards_max            3917.491799057707
total_rewards_min            212.59124601267422
Number of train steps total  1452000
Number of env steps total    1817000
Number of rollouts total     0
Train Time (s)               134.16835007583722
(Previous) Eval Time (s)     27.271563427057117
Sample Time (s)              24.791618356481194
Epoch Time (s)               186.23153185937554
Total Train Time (s)         67145.96625165408
Epoch                        362
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:12:02.125393 UTC | [2020_01_11_13_32_55] Iteration #362 | Epoch Duration: 185.06428623199463
2020-01-12 08:12:02.125595 UTC | [2020_01_11_13_32_55] Iteration #362 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.197606
Z variance train             0.01276665
KL Divergence                27.598055
KL Loss                      2.7598054
QF Loss                      723.2717
VF Loss                      760.5973
Policy Loss                  -1401.0187
Q Predictions Mean           1398.9353
Q Predictions Std            379.19315
Q Predictions Max            1635.7683
Q Predictions Min            -216.40256
V Predictions Mean           1393.818
V Predictions Std            381.7993
V Predictions Max            1643.412
V Predictions Min            -253.41302
Log Pis Mean                 0.75132823
Log Pis Std                  3.319267
Log Pis Max                  19.113094
Log Pis Min                  -6.817993
Policy mu Mean               0.07474807
Policy mu Std                0.69516355
Policy mu Max                4.1469874
Policy mu Min                -2.3847258
Policy log std Mean          -1.0217053
Policy log std Std           0.32992277
Policy log std Max           0.032550335
Policy log std Min           -3.0314665
Z mean eval                  1.2284157
Z variance eval              0.008841791
total_rewards                [1669.07590837 2298.13508325 4082.57316217  548.9851487   418.87024627
 2576.27331848 3810.1983515  4159.94191362 2906.0557055  3745.09972657]
total_rewards_mean           2621.5208564422455
total_rewards_std            1319.7957410760082
total_rewards_max            4159.941913615783
total_rewards_min            418.870246271875
Number of train steps total  1456000
Number of env steps total    1822000
Number of rollouts total     0
Train Time (s)               137.45848946273327
(Previous) Eval Time (s)     26.103997708298266
Sample Time (s)              24.664625423029065
Epoch Time (s)               188.2271125940606
Total Train Time (s)         67333.19885222707
Epoch                        363
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:15:09.361531 UTC | [2020_01_11_13_32_55] Iteration #363 | Epoch Duration: 187.23580265045166
2020-01-12 08:15:09.361709 UTC | [2020_01_11_13_32_55] Iteration #363 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2285405
Z variance train             0.008828687
KL Divergence                29.60336
KL Loss                      2.960336
QF Loss                      1106.5791
VF Loss                      365.85773
Policy Loss                  -1394.9772
Q Predictions Mean           1399.5609
Q Predictions Std            363.04565
Q Predictions Max            1652.2941
Q Predictions Min            -224.53668
V Predictions Mean           1394.4188
V Predictions Std            360.3102
V Predictions Max            1639.3188
V Predictions Min            -271.46426
Log Pis Mean                 0.21238577
Log Pis Std                  3.2119303
Log Pis Max                  15.091099
Log Pis Min                  -7.8432465
Policy mu Mean               0.05424863
Policy mu Std                0.66932905
Policy mu Max                3.4162576
Policy mu Min                -2.298
Policy log std Mean          -1.0030909
Policy log std Std           0.326393
Policy log std Max           -0.16551983
Policy log std Min           -3.0358195
Z mean eval                  1.2510055
Z variance eval              0.013017982
total_rewards                [3565.95042382   92.5241406  1825.26308594  128.28535408 2527.72372399
  570.60865534 1205.39215815 3537.16502671  456.61860274 2196.1035905 ]
total_rewards_mean           1610.563476188666
total_rewards_std            1258.7421566983514
total_rewards_max            3565.950423821252
total_rewards_min            92.52414060367586
Number of train steps total  1460000
Number of env steps total    1827000
Number of rollouts total     0
Train Time (s)               143.48527820501477
(Previous) Eval Time (s)     25.1123851807788
Sample Time (s)              26.026630284264684
Epoch Time (s)               194.62429367005825
Total Train Time (s)         67521.17538754921
Epoch                        364
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:18:17.342316 UTC | [2020_01_11_13_32_55] Iteration #364 | Epoch Duration: 187.98047184944153
2020-01-12 08:18:17.342507 UTC | [2020_01_11_13_32_55] Iteration #364 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2518051
Z variance train             0.013033156
KL Divergence                28.50329
KL Loss                      2.8503292
QF Loss                      951.9142
VF Loss                      251.70268
Policy Loss                  -1398.3275
Q Predictions Mean           1402.3445
Q Predictions Std            397.12735
Q Predictions Max            1650.5664
Q Predictions Min            -265.14062
V Predictions Mean           1404.0474
V Predictions Std            394.49576
V Predictions Max            1664.4711
V Predictions Min            -230.12596
Log Pis Mean                 0.7427796
Log Pis Std                  3.14823
Log Pis Max                  14.33969
Log Pis Min                  -7.1902685
Policy mu Mean               0.007220624
Policy mu Std                0.68153626
Policy mu Max                2.9056816
Policy mu Min                -2.9918082
Policy log std Mean          -0.98171425
Policy log std Std           0.29356807
Policy log std Max           0.0022786856
Policy log std Min           -2.4669752
Z mean eval                  1.1862695
Z variance eval              0.007253702
total_rewards                [3673.03796919 3250.84117425 1285.24273872 3814.5916674  3856.55182186
 1351.72906884 2609.40818923 1322.80676454 3773.85850053 1397.62884642]
total_rewards_mean           2633.569674095395
total_rewards_std            1111.7377885713836
total_rewards_max            3856.5518218561556
total_rewards_min            1285.2427387191224
Number of train steps total  1464000
Number of env steps total    1832000
Number of rollouts total     0
Train Time (s)               142.89704186702147
(Previous) Eval Time (s)     18.468211888801306
Sample Time (s)              25.490563719533384
Epoch Time (s)               186.85581747535616
Total Train Time (s)         67716.62605630467
Epoch                        365
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:21:32.796923 UTC | [2020_01_11_13_32_55] Iteration #365 | Epoch Duration: 195.45428705215454
2020-01-12 08:21:32.797117 UTC | [2020_01_11_13_32_55] Iteration #365 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.190647
Z variance train             0.00723733
KL Divergence                28.828918
KL Loss                      2.882892
QF Loss                      1297.5157
VF Loss                      863.3932
Policy Loss                  -1411.3818
Q Predictions Mean           1413.4204
Q Predictions Std            347.38425
Q Predictions Max            1624.4675
Q Predictions Min            -32.27779
V Predictions Mean           1413.9379
V Predictions Std            335.2389
V Predictions Max            1613.4305
V Predictions Min            -26.525799
Log Pis Mean                 0.8224822
Log Pis Std                  3.2640347
Log Pis Max                  16.922314
Log Pis Min                  -7.7734137
Policy mu Mean               0.027835244
Policy mu Std                0.654339
Policy mu Max                2.6163592
Policy mu Min                -3.6364214
Policy log std Mean          -1.0567803
Policy log std Std           0.34282592
Policy log std Max           -0.15733624
Policy log std Min           -3.1731234
Z mean eval                  1.2592486
Z variance eval              0.006119888
total_rewards                [3302.45588474 2205.65238275 4047.3685356  2008.79902954 2736.92057978
 3662.87152845 3287.34952687 1617.66894413  444.29609062 4007.47762666]
total_rewards_mean           2732.08601291374
total_rewards_std            1101.4899387436594
total_rewards_max            4047.368535598963
total_rewards_min            444.2960906165903
Number of train steps total  1468000
Number of env steps total    1837000
Number of rollouts total     0
Train Time (s)               144.27367695514113
(Previous) Eval Time (s)     27.066303518600762
Sample Time (s)              24.73647297732532
Epoch Time (s)               196.0764534510672
Total Train Time (s)         67911.2205521008
Epoch                        366
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:24:47.395235 UTC | [2020_01_11_13_32_55] Iteration #366 | Epoch Duration: 194.597971200943
2020-01-12 08:24:47.395419 UTC | [2020_01_11_13_32_55] Iteration #366 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.259515
Z variance train             0.006147412
KL Divergence                30.504139
KL Loss                      3.0504138
QF Loss                      889.06866
VF Loss                      317.59625
Policy Loss                  -1444.8517
Q Predictions Mean           1447.7307
Q Predictions Std            320.35846
Q Predictions Max            1656.8517
Q Predictions Min            -98.62908
V Predictions Mean           1446.4525
V Predictions Std            320.3247
V Predictions Max            1663.3726
V Predictions Min            -122.84781
Log Pis Mean                 0.6651434
Log Pis Std                  3.132914
Log Pis Max                  18.214357
Log Pis Min                  -6.6170454
Policy mu Mean               -0.039459262
Policy mu Std                0.65412873
Policy mu Max                2.7336671
Policy mu Min                -2.733506
Policy log std Mean          -1.0169561
Policy log std Std           0.3052216
Policy log std Max           -0.24436349
Policy log std Min           -2.8587768
Z mean eval                  1.2653762
Z variance eval              0.012468367
total_rewards                [ 900.54599067 4026.76547571 3634.30300466  605.96267971   85.48867146
 1661.55440569 3856.68133266 3622.87981335 1329.65424946  -20.57189691]
total_rewards_mean           1970.326372645664
total_rewards_std            1559.3279403275913
total_rewards_max            4026.765475707414
total_rewards_min            -20.57189690650126
Number of train steps total  1472000
Number of env steps total    1842000
Number of rollouts total     0
Train Time (s)               143.322739941068
(Previous) Eval Time (s)     25.587521474342793
Sample Time (s)              24.969900995958596
Epoch Time (s)               193.88016241136938
Total Train Time (s)         68104.48294234229
Epoch                        367
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:28:00.661859 UTC | [2020_01_11_13_32_55] Iteration #367 | Epoch Duration: 193.26630783081055
2020-01-12 08:28:00.662056 UTC | [2020_01_11_13_32_55] Iteration #367 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2665267
Z variance train             0.012501948
KL Divergence                30.178787
KL Loss                      3.0178788
QF Loss                      795.7106
VF Loss                      271.9724
Policy Loss                  -1406.1372
Q Predictions Mean           1409.404
Q Predictions Std            353.18182
Q Predictions Max            1622.4647
Q Predictions Min            -206.14734
V Predictions Mean           1401.2507
V Predictions Std            352.96747
V Predictions Max            1632.4886
V Predictions Min            -213.67917
Log Pis Mean                 0.6750926
Log Pis Std                  3.3264928
Log Pis Max                  18.279247
Log Pis Min                  -6.3672295
Policy mu Mean               -0.01987295
Policy mu Std                0.6643271
Policy mu Max                5.723228
Policy mu Min                -2.4807818
Policy log std Mean          -1.0193839
Policy log std Std           0.30603534
Policy log std Max           0.19192302
Policy log std Min           -2.7169042
Z mean eval                  1.202668
Z variance eval              0.032592732
total_rewards                [3803.34317104 3585.06784616 2631.98512768 3913.20714996 2869.99937118
 4002.51744955 4006.44707561  125.88038869  260.98817041 3876.86216825]
total_rewards_mean           2907.629791853959
total_rewards_std            1429.6236584354212
total_rewards_max            4006.4470756099854
total_rewards_min            125.88038868544668
Number of train steps total  1476000
Number of env steps total    1847000
Number of rollouts total     0
Train Time (s)               135.05512417899445
(Previous) Eval Time (s)     24.973225164227188
Sample Time (s)              25.28069945424795
Epoch Time (s)               185.3090487974696
Total Train Time (s)         68290.91192643391
Epoch                        368
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:31:07.094738 UTC | [2020_01_11_13_32_55] Iteration #368 | Epoch Duration: 186.43254613876343
2020-01-12 08:31:07.094931 UTC | [2020_01_11_13_32_55] Iteration #368 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.203306
Z variance train             0.032423157
KL Divergence                26.97495
KL Loss                      2.6974952
QF Loss                      5306.9766
VF Loss                      188.96832
Policy Loss                  -1416.8544
Q Predictions Mean           1416.1294
Q Predictions Std            343.22617
Q Predictions Max            1625.8885
Q Predictions Min            -48.494377
V Predictions Mean           1417.7477
V Predictions Std            340.24994
V Predictions Max            1638.162
V Predictions Min            -77.84524
Log Pis Mean                 0.7310624
Log Pis Std                  3.2067735
Log Pis Max                  21.807224
Log Pis Min                  -6.101847
Policy mu Mean               0.0050608143
Policy mu Std                0.65936947
Policy mu Max                2.529309
Policy mu Min                -4.5726905
Policy log std Mean          -1.0351493
Policy log std Std           0.31866837
Policy log std Max           -0.035808265
Policy log std Min           -2.5895708
Z mean eval                  1.248575
Z variance eval              0.0060464456
total_rewards                [3727.47846027  950.27180031 3896.03276388 2312.0139883  3209.30699808
 2911.03403163 2774.36782376 3878.87056764 2284.24583023 3807.31158313]
total_rewards_mean           2975.0933847248984
total_rewards_std            896.6443227146871
total_rewards_max            3896.0327638831363
total_rewards_min            950.2718003098745
Number of train steps total  1480000
Number of env steps total    1852000
Number of rollouts total     0
Train Time (s)               134.90753727499396
(Previous) Eval Time (s)     26.096399639733136
Sample Time (s)              25.101214403286576
Epoch Time (s)               186.10515131801367
Total Train Time (s)         68479.85506900772
Epoch                        369
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:34:16.041962 UTC | [2020_01_11_13_32_55] Iteration #369 | Epoch Duration: 188.94688892364502
2020-01-12 08:34:16.042185 UTC | [2020_01_11_13_32_55] Iteration #369 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2482183
Z variance train             0.0060370537
KL Divergence                29.699928
KL Loss                      2.9699929
QF Loss                      1017.54425
VF Loss                      479.3706
Policy Loss                  -1422.3416
Q Predictions Mean           1424.4358
Q Predictions Std            362.14188
Q Predictions Max            1638.3206
Q Predictions Min            -163.44415
V Predictions Mean           1421.1089
V Predictions Std            362.04904
V Predictions Max            1641.7032
V Predictions Min            -167.04723
Log Pis Mean                 0.23881195
Log Pis Std                  2.9316125
Log Pis Max                  13.498405
Log Pis Min                  -7.1797895
Policy mu Mean               0.016657796
Policy mu Std                0.6290245
Policy mu Max                2.6776023
Policy mu Min                -2.4792657
Policy log std Mean          -1.0172455
Policy log std Std           0.29513222
Policy log std Max           -0.19563884
Policy log std Min           -2.5396266
Z mean eval                  1.2535683
Z variance eval              0.009081069
total_rewards                [ 113.33098985 3905.7349302   790.26874217  481.1665515  1644.10572468
 3985.02131795  630.49330886 1189.44726434 3655.85262928  886.64940765]
total_rewards_mean           1728.2070866490812
total_rewards_std            1442.3539307212438
total_rewards_max            3985.0213179485972
total_rewards_min            113.33098985455501
Number of train steps total  1484000
Number of env steps total    1857000
Number of rollouts total     0
Train Time (s)               141.73118789726868
(Previous) Eval Time (s)     28.937768219038844
Sample Time (s)              25.487362511921674
Epoch Time (s)               196.1563186282292
Total Train Time (s)         68661.20420363825
Epoch                        370
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:37:17.396194 UTC | [2020_01_11_13_32_55] Iteration #370 | Epoch Duration: 181.35384917259216
2020-01-12 08:37:17.396536 UTC | [2020_01_11_13_32_55] Iteration #370 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2539909
Z variance train             0.009044874
KL Divergence                28.779575
KL Loss                      2.8779576
QF Loss                      569.04047
VF Loss                      158.30992
Policy Loss                  -1433.4713
Q Predictions Mean           1434.7865
Q Predictions Std            349.77213
Q Predictions Max            1622.3545
Q Predictions Min            -303.7308
V Predictions Mean           1439.1833
V Predictions Std            349.3104
V Predictions Max            1629.8245
V Predictions Min            -305.3711
Log Pis Mean                 0.6567228
Log Pis Std                  3.2194324
Log Pis Max                  17.374437
Log Pis Min                  -7.4089246
Policy mu Mean               0.00570204
Policy mu Std                0.7093163
Policy mu Max                3.6161258
Policy mu Min                -2.7282288
Policy log std Mean          -0.9911504
Policy log std Std           0.27658537
Policy log std Max           -0.07879722
Policy log std Min           -2.230794
Z mean eval                  1.2380451
Z variance eval              0.011596957
total_rewards                [3894.70403309 1947.17409696   13.33443175 3656.62870201 3782.45727291
  169.48913559  374.62674092 2907.42851281 3743.05435654  141.00702442]
total_rewards_mean           2062.990430699624
total_rewards_std            1634.9788012870774
total_rewards_max            3894.7040330876853
total_rewards_min            13.33443175457722
Number of train steps total  1488000
Number of env steps total    1862000
Number of rollouts total     0
Train Time (s)               143.3231030101888
(Previous) Eval Time (s)     14.134948456194252
Sample Time (s)              26.55956243071705
Epoch Time (s)               184.0176138971001
Total Train Time (s)         68853.69193274202
Epoch                        371
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:40:29.888702 UTC | [2020_01_11_13_32_55] Iteration #371 | Epoch Duration: 192.49198293685913
2020-01-12 08:40:29.888975 UTC | [2020_01_11_13_32_55] Iteration #371 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2364748
Z variance train             0.0116264345
KL Divergence                27.059153
KL Loss                      2.7059152
QF Loss                      1634.8245
VF Loss                      174.60893
Policy Loss                  -1440.7145
Q Predictions Mean           1435.6964
Q Predictions Std            323.01514
Q Predictions Max            1625.926
Q Predictions Min            -242.23386
V Predictions Mean           1441.6892
V Predictions Std            309.22217
V Predictions Max            1631.0294
V Predictions Min            -204.33862
Log Pis Mean                 0.8645109
Log Pis Std                  3.2489412
Log Pis Max                  14.011025
Log Pis Min                  -6.851966
Policy mu Mean               -0.005991888
Policy mu Std                0.6776592
Policy mu Max                2.8361955
Policy mu Min                -2.9035208
Policy log std Mean          -1.0385536
Policy log std Std           0.29656866
Policy log std Max           -0.12537718
Policy log std Min           -2.6055226
Z mean eval                  1.2092557
Z variance eval              0.007653387
total_rewards                [1411.86950281 1561.05740037 1655.19952502 1179.50669524 2533.36078383
 2845.81286972 1475.7249097   847.58313331 3282.78439106 2943.38608901]
total_rewards_mean           1973.628530006489
total_rewards_std            803.8672416535895
total_rewards_max            3282.7843910564857
total_rewards_min            847.5831333056594
Number of train steps total  1492000
Number of env steps total    1867000
Number of rollouts total     0
Train Time (s)               142.83500117016956
(Previous) Eval Time (s)     22.608928265981376
Sample Time (s)              26.096898613497615
Epoch Time (s)               191.54082804964855
Total Train Time (s)         69040.35515840026
Epoch                        372
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:43:36.554933 UTC | [2020_01_11_13_32_55] Iteration #372 | Epoch Duration: 186.6658239364624
2020-01-12 08:43:36.555097 UTC | [2020_01_11_13_32_55] Iteration #372 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2088397
Z variance train             0.007670422
KL Divergence                27.857677
KL Loss                      2.7857678
QF Loss                      1221.7883
VF Loss                      382.30023
Policy Loss                  -1406.6086
Q Predictions Mean           1409.2839
Q Predictions Std            373.0539
Q Predictions Max            1653.4065
Q Predictions Min            -185.07372
V Predictions Mean           1410.1327
V Predictions Std            369.8978
V Predictions Max            1647.7513
V Predictions Min            -157.84776
Log Pis Mean                 1.0848764
Log Pis Std                  3.563493
Log Pis Max                  21.006628
Log Pis Min                  -5.4903307
Policy mu Mean               0.045212783
Policy mu Std                0.70176464
Policy mu Max                5.0659795
Policy mu Min                -2.2794957
Policy log std Mean          -1.0320926
Policy log std Std           0.35800847
Policy log std Max           -0.115528345
Policy log std Min           -3.122096
Z mean eval                  1.2178005
Z variance eval              0.007102595
total_rewards                [1738.56695229 2452.71990376 3907.9589207   170.01168249 3921.25788793
  129.338181   1121.26013905 1004.74987577 1859.22788999  -49.25676769]
total_rewards_mean           1625.5834665273235
total_rewards_std            1379.607689980259
total_rewards_max            3921.257887926022
total_rewards_min            -49.25676769202137
Number of train steps total  1496000
Number of env steps total    1872000
Number of rollouts total     0
Train Time (s)               144.61598926084116
(Previous) Eval Time (s)     17.733514577616006
Sample Time (s)              24.8443925534375
Epoch Time (s)               187.19389639189467
Total Train Time (s)         69232.0560383778
Epoch                        373
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:46:48.261081 UTC | [2020_01_11_13_32_55] Iteration #373 | Epoch Duration: 191.70584177970886
2020-01-12 08:46:48.261395 UTC | [2020_01_11_13_32_55] Iteration #373 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2179605
Z variance train             0.0070963623
KL Divergence                27.780176
KL Loss                      2.7780178
QF Loss                      1892.8748
VF Loss                      499.04645
Policy Loss                  -1402.0253
Q Predictions Mean           1404.0104
Q Predictions Std            377.25754
Q Predictions Max            1623.6047
Q Predictions Min            -270.73233
V Predictions Mean           1394.6483
V Predictions Std            378.60345
V Predictions Max            1609.9436
V Predictions Min            -270.05786
Log Pis Mean                 1.2107177
Log Pis Std                  3.5726924
Log Pis Max                  17.575735
Log Pis Min                  -6.6248703
Policy mu Mean               -0.005832846
Policy mu Std                0.68322545
Policy mu Max                3.387822
Policy mu Min                -2.9786265
Policy log std Mean          -1.0621958
Policy log std Std           0.35100242
Policy log std Max           0.039631486
Policy log std Min           -2.9413495
Z mean eval                  1.2225584
Z variance eval              0.00776597
total_rewards                [3232.46103821   30.01619224 3915.60539517  808.08248943 3582.45261825
 3988.85942651 1411.78419406 2698.37313648 4029.41929625 1680.25815635]
total_rewards_mean           2537.731194293955
total_rewards_std            1382.4860913756368
total_rewards_max            4029.419296246552
total_rewards_min            30.01619224110378
Number of train steps total  1500000
Number of env steps total    1877000
Number of rollouts total     0
Train Time (s)               141.32608494721353
(Previous) Eval Time (s)     22.245128937996924
Sample Time (s)              25.17905784258619
Epoch Time (s)               188.75027172779664
Total Train Time (s)         69422.76511479868
Epoch                        374
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:49:58.974386 UTC | [2020_01_11_13_32_55] Iteration #374 | Epoch Duration: 190.71282744407654
2020-01-12 08:49:58.974610 UTC | [2020_01_11_13_32_55] Iteration #374 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.218981
Z variance train             0.0077641434
KL Divergence                26.932386
KL Loss                      2.6932387
QF Loss                      8986.936
VF Loss                      2021.4497
Policy Loss                  -1362.3456
Q Predictions Mean           1367.7043
Q Predictions Std            418.3209
Q Predictions Max            1643.0854
Q Predictions Min            -175.72832
V Predictions Mean           1367.2834
V Predictions Std            418.36105
V Predictions Max            1643.8318
V Predictions Min            -170.16298
Log Pis Mean                 0.96868235
Log Pis Std                  3.458926
Log Pis Max                  14.2815075
Log Pis Min                  -5.7997675
Policy mu Mean               0.027300425
Policy mu Std                0.6609765
Policy mu Max                3.5127873
Policy mu Min                -2.5690932
Policy log std Mean          -1.0711303
Policy log std Std           0.34264064
Policy log std Max           1.2237163
Policy log std Min           -2.7550993
Z mean eval                  1.2089487
Z variance eval              0.00529369
total_rewards                [ -19.51642869   -4.6798121  2889.4355798  3717.24908271 3297.37336003
 4109.28569939 -243.59576063 4183.0483756  3676.60798278 3934.8598231 ]
total_rewards_mean           2554.00679019706
total_rewards_std            1767.890703319315
total_rewards_max            4183.048375595559
total_rewards_min            -243.59576062828432
Number of train steps total  1504000
Number of env steps total    1882000
Number of rollouts total     0
Train Time (s)               135.79368667211384
(Previous) Eval Time (s)     24.207311561796814
Sample Time (s)              23.498491815291345
Epoch Time (s)               183.499490049202
Total Train Time (s)         69608.07659858512
Epoch                        375
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:53:04.289498 UTC | [2020_01_11_13_32_55] Iteration #375 | Epoch Duration: 185.31474709510803
2020-01-12 08:53:04.289680 UTC | [2020_01_11_13_32_55] Iteration #375 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2099055
Z variance train             0.0053041214
KL Divergence                28.645437
KL Loss                      2.8645437
QF Loss                      615.71204
VF Loss                      821.21277
Policy Loss                  -1384.0203
Q Predictions Mean           1387.2463
Q Predictions Std            404.0806
Q Predictions Max            1640.5604
Q Predictions Min            -240.5171
V Predictions Mean           1385.672
V Predictions Std            397.74863
V Predictions Max            1631.7529
V Predictions Min            -248.89174
Log Pis Mean                 0.81305194
Log Pis Std                  3.0934381
Log Pis Max                  14.914375
Log Pis Min                  -7.811915
Policy mu Mean               0.0034593185
Policy mu Std                0.66343886
Policy mu Max                2.7584286
Policy mu Min                -2.7151608
Policy log std Mean          -1.050549
Policy log std Std           0.3214397
Policy log std Max           -0.15969098
Policy log std Min           -3.1127303
Z mean eval                  1.242913
Z variance eval              0.018190185
total_rewards                [2060.02348855  935.14415955 3151.1905295  3759.65816833  797.57098849
 1306.04943085  174.99070411 3907.7856612  2127.28272756 3945.08033307]
total_rewards_mean           2216.4776191211813
total_rewards_std            1333.708291307992
total_rewards_max            3945.080333070694
total_rewards_min            174.9907041102378
Number of train steps total  1508000
Number of env steps total    1887000
Number of rollouts total     0
Train Time (s)               135.10553496982902
(Previous) Eval Time (s)     26.022268859203905
Sample Time (s)              24.950030753389
Epoch Time (s)               186.07783458242193
Total Train Time (s)         69788.35630021477
Epoch                        376
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:56:04.573492 UTC | [2020_01_11_13_32_55] Iteration #376 | Epoch Duration: 180.2836754322052
2020-01-12 08:56:04.573695 UTC | [2020_01_11_13_32_55] Iteration #376 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2435381
Z variance train             0.018155856
KL Divergence                27.476818
KL Loss                      2.7476819
QF Loss                      1301.6334
VF Loss                      157.99802
Policy Loss                  -1399.4246
Q Predictions Mean           1399.4264
Q Predictions Std            421.50867
Q Predictions Max            1643.4069
Q Predictions Min            -290.4426
V Predictions Mean           1400.7251
V Predictions Std            416.48883
V Predictions Max            1626.8973
V Predictions Min            -299.91086
Log Pis Mean                 0.6125077
Log Pis Std                  3.0315142
Log Pis Max                  13.946676
Log Pis Min                  -9.055105
Policy mu Mean               0.007041169
Policy mu Std                0.67877334
Policy mu Max                2.4516966
Policy mu Min                -3.0791461
Policy log std Mean          -0.98990047
Policy log std Std           0.28411624
Policy log std Max           -0.15094638
Policy log std Min           -2.3993425
Z mean eval                  1.2458537
Z variance eval              0.02031984
total_rewards                [ 844.89773653 1578.04308511 2345.38227096 2645.29316681 2387.6120504
 3792.98003586  309.23029661 3322.13524142  103.72299604 3688.10774333]
total_rewards_mean           2101.740462307726
total_rewards_std            1279.1336275222561
total_rewards_max            3792.980035861385
total_rewards_min            103.72299603806957
Number of train steps total  1512000
Number of env steps total    1892000
Number of rollouts total     0
Train Time (s)               143.22076184581965
(Previous) Eval Time (s)     20.22778471186757
Sample Time (s)              23.539376833476126
Epoch Time (s)               186.98792339116335
Total Train Time (s)         69975.30402834993
Epoch                        377
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:59:11.525097 UTC | [2020_01_11_13_32_55] Iteration #377 | Epoch Duration: 186.9512665271759
2020-01-12 08:59:11.525287 UTC | [2020_01_11_13_32_55] Iteration #377 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2441012
Z variance train             0.020068238
KL Divergence                26.85057
KL Loss                      2.6850572
QF Loss                      968.3724
VF Loss                      360.9768
Policy Loss                  -1431.018
Q Predictions Mean           1432.565
Q Predictions Std            329.8718
Q Predictions Max            1619.2013
Q Predictions Min            -190.62677
V Predictions Mean           1435.0051
V Predictions Std            325.05884
V Predictions Max            1629.2716
V Predictions Min            -187.71703
Log Pis Mean                 0.32936704
Log Pis Std                  2.9758344
Log Pis Max                  8.15174
Log Pis Min                  -7.190941
Policy mu Mean               0.029054634
Policy mu Std                0.6445996
Policy mu Max                2.5752625
Policy mu Min                -2.4147077
Policy log std Mean          -1.0150194
Policy log std Std           0.26767215
Policy log std Max           -0.17874354
Policy log std Min           -2.4349172
Z mean eval                  1.2662473
Z variance eval              0.011137826
total_rewards                [3797.76420667 3961.39665017 3301.78555533 4110.92343473 1463.79727763
 2122.57463746 3931.31755609 1767.25999134  136.66299823 2041.54708719]
total_rewards_mean           2663.5029394841686
total_rewards_std            1280.1468311232986
total_rewards_max            4110.923434733151
total_rewards_min            136.66299823221445
Number of train steps total  1516000
Number of env steps total    1897000
Number of rollouts total     0
Train Time (s)               142.36935743689537
(Previous) Eval Time (s)     20.19078998081386
Sample Time (s)              25.488223937805742
Epoch Time (s)               188.04837135551497
Total Train Time (s)         70166.42470493633
Epoch                        378
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:02:22.655625 UTC | [2020_01_11_13_32_55] Iteration #378 | Epoch Duration: 191.13019251823425
2020-01-12 09:02:22.656021 UTC | [2020_01_11_13_32_55] Iteration #378 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2681012
Z variance train             0.011275089
KL Divergence                28.813532
KL Loss                      2.8813531
QF Loss                      824.864
VF Loss                      478.49628
Policy Loss                  -1416.304
Q Predictions Mean           1418.6716
Q Predictions Std            395.60727
Q Predictions Max            1633.3525
Q Predictions Min            -285.7624
V Predictions Mean           1418.8318
V Predictions Std            396.55505
V Predictions Max            1639.1415
V Predictions Min            -300.75656
Log Pis Mean                 0.3467821
Log Pis Std                  2.9041047
Log Pis Max                  11.796143
Log Pis Min                  -6.4720592
Policy mu Mean               -0.00082075223
Policy mu Std                0.65172696
Policy mu Max                2.9071822
Policy mu Min                -2.6402426
Policy log std Mean          -1.0042863
Policy log std Std           0.2665605
Policy log std Max           -0.07189441
Policy log std Min           -2.2064795
Z mean eval                  1.2295864
Z variance eval              0.009604953
total_rewards                [ 227.11087946  835.62140642 1322.6071924   174.35619162 1320.00166528
  230.77072422  269.25484476 2334.03486827  959.45218077 2324.51209682]
total_rewards_mean           999.7722050018662
total_rewards_std            785.739726062071
total_rewards_max            2334.0348682703866
total_rewards_min            174.35619161619059
Number of train steps total  1520000
Number of env steps total    1902000
Number of rollouts total     0
Train Time (s)               142.58112947409973
(Previous) Eval Time (s)     23.272242196835577
Sample Time (s)              26.201253729872406
Epoch Time (s)               192.0546254008077
Total Train Time (s)         70348.20131378528
Epoch                        379
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:05:24.428905 UTC | [2020_01_11_13_32_55] Iteration #379 | Epoch Duration: 181.77261996269226
2020-01-12 09:05:24.429022 UTC | [2020_01_11_13_32_55] Iteration #379 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2293609
Z variance train             0.009602923
KL Divergence                27.749668
KL Loss                      2.774967
QF Loss                      994.5672
VF Loss                      385.79218
Policy Loss                  -1417.6244
Q Predictions Mean           1419.5817
Q Predictions Std            363.98645
Q Predictions Max            1643.3094
Q Predictions Min            -283.3305
V Predictions Mean           1421.8591
V Predictions Std            357.98288
V Predictions Max            1638.1184
V Predictions Min            -305.08563
Log Pis Mean                 0.90341717
Log Pis Std                  3.6081223
Log Pis Max                  17.645039
Log Pis Min                  -7.33462
Policy mu Mean               0.05616188
Policy mu Std                0.65345633
Policy mu Max                3.0531049
Policy mu Min                -2.491467
Policy log std Mean          -1.0419401
Policy log std Std           0.32998297
Policy log std Max           -0.2623425
Policy log std Min           -3.1865492
Z mean eval                  1.272255
Z variance eval              0.016319284
total_rewards                [1493.14215028  302.20675876 1643.70744436 3998.14524593 3894.66130271
 3768.95047334 3962.28773823 2714.99541308   13.65274242  544.09387232]
total_rewards_mean           2233.584314142996
total_rewards_std            1544.6448193193692
total_rewards_max            3998.1452459298894
total_rewards_min            13.652742415709895
Number of train steps total  1524000
Number of env steps total    1907000
Number of rollouts total     0
Train Time (s)               142.51499499427155
(Previous) Eval Time (s)     12.989817819092423
Sample Time (s)              25.128230268135667
Epoch Time (s)               180.63304308149964
Total Train Time (s)         70538.06872798549
Epoch                        380
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:08:34.301341 UTC | [2020_01_11_13_32_55] Iteration #380 | Epoch Duration: 189.87220001220703
2020-01-12 09:08:34.301615 UTC | [2020_01_11_13_32_55] Iteration #380 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2707596
Z variance train             0.016339082
KL Divergence                25.864931
KL Loss                      2.5864933
QF Loss                      909.3688
VF Loss                      375.94122
Policy Loss                  -1382.0767
Q Predictions Mean           1386.9624
Q Predictions Std            389.18176
Q Predictions Max            1640.7522
Q Predictions Min            -187.86719
V Predictions Mean           1388.8868
V Predictions Std            389.3288
V Predictions Max            1642.3585
V Predictions Min            -182.4834
Log Pis Mean                 0.39599788
Log Pis Std                  3.198982
Log Pis Max                  22.697346
Log Pis Min                  -8.562427
Policy mu Mean               0.03130042
Policy mu Std                0.63842356
Policy mu Max                3.288479
Policy mu Min                -2.8216965
Policy log std Mean          -0.99813527
Policy log std Std           0.29709226
Policy log std Max           0.21375966
Policy log std Min           -2.6004496
Z mean eval                  1.2448257
Z variance eval              0.013230927
total_rewards                [3941.76581373 1611.18333026 3084.56900511 4211.2335477  4218.93858398
 1594.05244235 4073.54044327 4009.90330216 4170.70738606 3874.92255998]
total_rewards_mean           3479.0816414608407
total_rewards_std            988.2165684242908
total_rewards_max            4218.938583981229
total_rewards_min            1594.052442349058
Number of train steps total  1528000
Number of env steps total    1912000
Number of rollouts total     0
Train Time (s)               138.00567754311487
(Previous) Eval Time (s)     22.228598533198237
Sample Time (s)              26.286286873277277
Epoch Time (s)               186.52056294959038
Total Train Time (s)         70732.59739039419
Epoch                        381
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:11:48.833862 UTC | [2020_01_11_13_32_55] Iteration #381 | Epoch Duration: 194.53209376335144
2020-01-12 09:11:48.834055 UTC | [2020_01_11_13_32_55] Iteration #381 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2450469
Z variance train             0.013223371
KL Divergence                26.41977
KL Loss                      2.641977
QF Loss                      1849.0847
VF Loss                      400.98282
Policy Loss                  -1405.139
Q Predictions Mean           1408.5428
Q Predictions Std            359.63834
Q Predictions Max            1642.362
Q Predictions Min            -234.81625
V Predictions Mean           1409.2683
V Predictions Std            355.88644
V Predictions Max            1643.9564
V Predictions Min            -234.3222
Log Pis Mean                 0.91902906
Log Pis Std                  3.1204176
Log Pis Max                  13.510359
Log Pis Min                  -7.078685
Policy mu Mean               -0.00594846
Policy mu Std                0.6914038
Policy mu Max                2.346869
Policy mu Min                -2.1876726
Policy log std Mean          -1.018623
Policy log std Std           0.29325312
Policy log std Max           -0.21841425
Policy log std Min           -2.6262212
Z mean eval                  1.3093306
Z variance eval              0.013746965
total_rewards                [  80.84371829 4221.66892527 2019.38196424  480.4247548  2247.25048017
 1511.68133282 1998.03701224 1350.857805   4196.52926921  908.89895824]
total_rewards_mean           1901.5574220277708
total_rewards_std            1325.4345890709876
total_rewards_max            4221.668925267436
total_rewards_min            80.8437182858882
Number of train steps total  1532000
Number of env steps total    1917000
Number of rollouts total     0
Train Time (s)               134.86229986604303
(Previous) Eval Time (s)     30.239788609091192
Sample Time (s)              25.29952053911984
Epoch Time (s)               190.40160901425406
Total Train Time (s)         70911.41097526718
Epoch                        382
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:14:47.651387 UTC | [2020_01_11_13_32_55] Iteration #382 | Epoch Duration: 178.81720161437988
2020-01-12 09:14:47.651573 UTC | [2020_01_11_13_32_55] Iteration #382 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3109157
Z variance train             0.013706075
KL Divergence                27.259739
KL Loss                      2.7259738
QF Loss                      1345.6262
VF Loss                      851.5745
Policy Loss                  -1397.2814
Q Predictions Mean           1404.8225
Q Predictions Std            379.17526
Q Predictions Max            1636.2769
Q Predictions Min            -303.98053
V Predictions Mean           1393.1926
V Predictions Std            378.64008
V Predictions Max            1645.0366
V Predictions Min            -314.29666
Log Pis Mean                 0.571022
Log Pis Std                  3.2221336
Log Pis Max                  16.267849
Log Pis Min                  -8.1232395
Policy mu Mean               0.038446
Policy mu Std                0.65103924
Policy mu Max                2.262266
Policy mu Min                -2.2587712
Policy log std Mean          -1.0380867
Policy log std Std           0.34509695
Policy log std Max           -0.24694729
Policy log std Min           -3.3150103
Z mean eval                  1.1989408
Z variance eval              0.0067073987
total_rewards                [ 228.07294012 1329.46279915 3372.31853565 1831.54034847 1029.00422204
  152.77477639 2759.02115381 4065.96145705 1347.24471267 3949.6110714 ]
total_rewards_mean           2006.501201674538
total_rewards_std            1375.7549302419366
total_rewards_max            4065.9614570481485
total_rewards_min            152.77477638582542
Number of train steps total  1536000
Number of env steps total    1922000
Number of rollouts total     0
Train Time (s)               137.31071641435847
(Previous) Eval Time (s)     18.655043456237763
Sample Time (s)              24.264484797604382
Epoch Time (s)               180.2302446682006
Total Train Time (s)         71093.76328947255
Epoch                        383
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:17:50.005855 UTC | [2020_01_11_13_32_55] Iteration #383 | Epoch Duration: 182.35416388511658
2020-01-12 09:17:50.005988 UTC | [2020_01_11_13_32_55] Iteration #383 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.197998
Z variance train             0.0067030587
KL Divergence                28.875187
KL Loss                      2.8875186
QF Loss                      1139.7473
VF Loss                      175.12462
Policy Loss                  -1390.6777
Q Predictions Mean           1392.2415
Q Predictions Std            368.96774
Q Predictions Max            1628.3665
Q Predictions Min            -234.47513
V Predictions Mean           1386.8938
V Predictions Std            365.46335
V Predictions Max            1614.747
V Predictions Min            -253.95877
Log Pis Mean                 0.6712399
Log Pis Std                  3.1747346
Log Pis Max                  16.104454
Log Pis Min                  -6.1575336
Policy mu Mean               0.014954114
Policy mu Std                0.67219996
Policy mu Max                3.8088243
Policy mu Min                -2.6759803
Policy log std Mean          -1.0269375
Policy log std Std           0.30004615
Policy log std Max           -0.008965373
Policy log std Min           -2.583522
Z mean eval                  1.2640781
Z variance eval              0.00641589
total_rewards                [3826.44247548 4030.6237613   629.63412534 3711.66153062 2453.34106035
 2307.96446066 4004.70102829 4001.29673914  612.69838088 3895.79380679]
total_rewards_mean           2947.4157368854894
total_rewards_std            1308.9714295706824
total_rewards_max            4030.6237613031335
total_rewards_min            612.6983808766638
Number of train steps total  1540000
Number of env steps total    1927000
Number of rollouts total     0
Train Time (s)               145.26147325802594
(Previous) Eval Time (s)     20.77863080566749
Sample Time (s)              25.894322397653013
Epoch Time (s)               191.93442646134645
Total Train Time (s)         71290.57929807063
Epoch                        384
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:21:06.827358 UTC | [2020_01_11_13_32_55] Iteration #384 | Epoch Duration: 196.8212375640869
2020-01-12 09:21:06.827756 UTC | [2020_01_11_13_32_55] Iteration #384 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2649493
Z variance train             0.006411621
KL Divergence                28.054102
KL Loss                      2.8054101
QF Loss                      3134.4727
VF Loss                      570.3749
Policy Loss                  -1400.0516
Q Predictions Mean           1403.8291
Q Predictions Std            340.83316
Q Predictions Max            1603.6665
Q Predictions Min            -317.345
V Predictions Mean           1403.9713
V Predictions Std            339.38168
V Predictions Max            1601.0164
V Predictions Min            -301.55463
Log Pis Mean                 0.91472226
Log Pis Std                  3.326609
Log Pis Max                  19.918652
Log Pis Min                  -5.9603844
Policy mu Mean               0.0033677213
Policy mu Std                0.66742784
Policy mu Max                3.2109683
Policy mu Min                -3.1986332
Policy log std Mean          -1.0636631
Policy log std Std           0.31380978
Policy log std Max           -0.19452399
Policy log std Min           -2.6297941
Z mean eval                  1.2853724
Z variance eval              0.007222542
total_rewards                [3755.19274474 3933.6743112  3852.47093168 1269.37327904 2067.35865077
 2937.96178386 1050.38839221 1610.93609099  725.42209183  294.28875664]
total_rewards_mean           2149.706703296305
total_rewards_std            1305.0893845786045
total_rewards_max            3933.674311200946
total_rewards_min            294.28875664449737
Number of train steps total  1544000
Number of env steps total    1932000
Number of rollouts total     0
Train Time (s)               143.45805831905454
(Previous) Eval Time (s)     25.665027683135122
Sample Time (s)              25.544693247415125
Epoch Time (s)               194.6677792496048
Total Train Time (s)         71483.58411650127
Epoch                        385
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:24:19.834041 UTC | [2020_01_11_13_32_55] Iteration #385 | Epoch Duration: 193.00606608390808
2020-01-12 09:24:19.834159 UTC | [2020_01_11_13_32_55] Iteration #385 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2862284
Z variance train             0.0072090537
KL Divergence                28.441147
KL Loss                      2.8441148
QF Loss                      1264.7925
VF Loss                      645.154
Policy Loss                  -1405.5007
Q Predictions Mean           1409.0684
Q Predictions Std            357.45566
Q Predictions Max            1649.096
Q Predictions Min            -189.70038
V Predictions Mean           1401.5042
V Predictions Std            355.23264
V Predictions Max            1632.8802
V Predictions Min            -175.72559
Log Pis Mean                 0.73054254
Log Pis Std                  3.3259153
Log Pis Max                  14.3954315
Log Pis Min                  -8.358808
Policy mu Mean               -0.02124566
Policy mu Std                0.66501826
Policy mu Max                2.711841
Policy mu Min                -2.4349499
Policy log std Mean          -1.0493214
Policy log std Std           0.33377275
Policy log std Max           -0.21619332
Policy log std Min           -3.3251405
Z mean eval                  1.2927624
Z variance eval              0.015228733
total_rewards                [ 901.67018574 2630.4106861   233.55424554 3457.14927031  642.33935275
 2764.56376178  766.93394417 2307.388166   1237.51496251  354.86277724]
total_rewards_mean           1529.6387352137767
total_rewards_std            1093.8721540926779
total_rewards_max            3457.1492703107037
total_rewards_min            233.55424554054605
Number of train steps total  1548000
Number of env steps total    1937000
Number of rollouts total     0
Train Time (s)               143.86121183400974
(Previous) Eval Time (s)     24.003021838143468
Sample Time (s)              24.440023277886212
Epoch Time (s)               192.30425695003942
Total Train Time (s)         71665.58190795733
Epoch                        386
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:27:21.837587 UTC | [2020_01_11_13_32_55] Iteration #386 | Epoch Duration: 182.00329518318176
2020-01-12 09:27:21.837874 UTC | [2020_01_11_13_32_55] Iteration #386 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2947886
Z variance train             0.015220983
KL Divergence                26.107521
KL Loss                      2.610752
QF Loss                      1269.6653
VF Loss                      216.51807
Policy Loss                  -1360.6836
Q Predictions Mean           1365.7229
Q Predictions Std            408.03934
Q Predictions Max            1601.9976
Q Predictions Min            -301.38037
V Predictions Mean           1364.0881
V Predictions Std            410.28305
V Predictions Max            1616.469
V Predictions Min            -291.47012
Log Pis Mean                 0.8385688
Log Pis Std                  3.2128844
Log Pis Max                  13.244862
Log Pis Min                  -7.3410482
Policy mu Mean               -0.024863318
Policy mu Std                0.65741843
Policy mu Max                4.7224116
Policy mu Min                -2.7237408
Policy log std Mean          -1.0675349
Policy log std Std           0.29021555
Policy log std Max           -0.22266215
Policy log std Min           -2.7763662
Z mean eval                  1.265291
Z variance eval              0.004980231
total_rewards                [3522.18055563 2113.9808547   724.4160393   661.52380278 3773.94344845
 1710.27246239 1241.34399944 3991.35064425   22.05199836 3643.16271464]
total_rewards_mean           2140.4226519941876
total_rewards_std            1411.9344447383344
total_rewards_max            3991.350644250982
total_rewards_min            22.051998360574977
Number of train steps total  1552000
Number of env steps total    1942000
Number of rollouts total     0
Train Time (s)               143.00050080101937
(Previous) Eval Time (s)     13.701685868669301
Sample Time (s)              27.032400341238827
Epoch Time (s)               183.7345870109275
Total Train Time (s)         71858.68499800982
Epoch                        387
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:30:34.945171 UTC | [2020_01_11_13_32_55] Iteration #387 | Epoch Duration: 193.10713458061218
2020-01-12 09:30:34.945375 UTC | [2020_01_11_13_32_55] Iteration #387 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.263304
Z variance train             0.004963482
KL Divergence                28.953976
KL Loss                      2.8953977
QF Loss                      1142.5378
VF Loss                      314.84018
Policy Loss                  -1448.4519
Q Predictions Mean           1446.9775
Q Predictions Std            298.38007
Q Predictions Max            1643.8635
Q Predictions Min            -207.54301
V Predictions Mean           1452.1423
V Predictions Std            289.30777
V Predictions Max            1642.1747
V Predictions Min            -211.33655
Log Pis Mean                 0.502228
Log Pis Std                  3.1366413
Log Pis Max                  16.434261
Log Pis Min                  -6.8752656
Policy mu Mean               0.008088617
Policy mu Std                0.65064454
Policy mu Max                4.542445
Policy mu Min                -3.0157788
Policy log std Mean          -1.0511161
Policy log std Std           0.2826702
Policy log std Max           0.41373575
Policy log std Min           -2.8236394
Z mean eval                  1.2915615
Z variance eval              0.012776221
total_rewards                [ 657.14074373  734.3542278   -91.98542134 3924.4442719  2698.9466054
  310.26165332 3877.82647035 3937.15956455  124.79519982 3700.72780972]
total_rewards_mean           1987.3671125257783
total_rewards_std            1688.6341420576314
total_rewards_max            3937.1595645469683
total_rewards_min            -91.98542133890746
Number of train steps total  1556000
Number of env steps total    1947000
Number of rollouts total     0
Train Time (s)               135.9832624536939
(Previous) Eval Time (s)     23.073729262221605
Sample Time (s)              26.474448791705072
Epoch Time (s)               185.53144050762057
Total Train Time (s)         72044.77277667308
Epoch                        388
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:33:41.036991 UTC | [2020_01_11_13_32_55] Iteration #388 | Epoch Duration: 186.09148025512695
2020-01-12 09:33:41.037181 UTC | [2020_01_11_13_32_55] Iteration #388 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2925853
Z variance train             0.012751592
KL Divergence                26.612303
KL Loss                      2.6612303
QF Loss                      712.94135
VF Loss                      275.62216
Policy Loss                  -1400.6395
Q Predictions Mean           1406.254
Q Predictions Std            364.23956
Q Predictions Max            1646.2782
Q Predictions Min            -194.73918
V Predictions Mean           1406.1017
V Predictions Std            368.156
V Predictions Max            1644.4598
V Predictions Min            -220.14378
Log Pis Mean                 0.15368551
Log Pis Std                  3.017415
Log Pis Max                  10.977673
Log Pis Min                  -8.583813
Policy mu Mean               0.04592957
Policy mu Std                0.64859366
Policy mu Max                3.1178086
Policy mu Min                -2.3964071
Policy log std Mean          -1.0054655
Policy log std Std           0.26212212
Policy log std Max           -0.203246
Policy log std Min           -2.3868847
Z mean eval                  1.2374413
Z variance eval              0.016579185
total_rewards                [4124.90382413  753.9347117  3522.23662612 4075.15101618 4002.54065043
 2305.2514741  2494.18781638 1229.80268795 2926.87150362 4024.77802725]
total_rewards_mean           2945.9658337864958
total_rewards_std            1168.00801896824
total_rewards_max            4124.9038241344315
total_rewards_min            753.9347117035059
Number of train steps total  1560000
Number of env steps total    1952000
Number of rollouts total     0
Train Time (s)               135.51991967111826
(Previous) Eval Time (s)     23.63339231722057
Sample Time (s)              24.46918773232028
Epoch Time (s)               183.6224997206591
Total Train Time (s)         72232.13604707737
Epoch                        389
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:36:48.404314 UTC | [2020_01_11_13_32_55] Iteration #389 | Epoch Duration: 187.3669991493225
2020-01-12 09:36:48.404506 UTC | [2020_01_11_13_32_55] Iteration #389 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2363044
Z variance train             0.016616698
KL Divergence                27.349976
KL Loss                      2.7349975
QF Loss                      692.6797
VF Loss                      678.3391
Policy Loss                  -1390.4906
Q Predictions Mean           1391.7903
Q Predictions Std            393.67432
Q Predictions Max            1623.383
Q Predictions Min            -261.54163
V Predictions Mean           1392.8784
V Predictions Std            389.80014
V Predictions Max            1634.209
V Predictions Min            -268.7723
Log Pis Mean                 0.56014454
Log Pis Std                  3.2421005
Log Pis Max                  13.82004
Log Pis Min                  -7.7968216
Policy mu Mean               0.020097168
Policy mu Std                0.63519365
Policy mu Max                2.5094366
Policy mu Min                -2.3390913
Policy log std Mean          -1.0214621
Policy log std Std           0.30916873
Policy log std Max           0.69756055
Policy log std Min           -2.6718402
Z mean eval                  1.2263143
Z variance eval              0.01378752
total_rewards                [3682.7378138  2895.16285836 4070.65856913 -114.59168855 4066.32517497
  279.91072502 3342.53669074  546.72505663 3663.84550901 3730.32647397]
total_rewards_mean           2616.3637183083742
total_rewards_std            1596.8167375657572
total_rewards_max            4070.6585691329133
total_rewards_min            -114.59168854657219
Number of train steps total  1564000
Number of env steps total    1957000
Number of rollouts total     0
Train Time (s)               138.9210063777864
(Previous) Eval Time (s)     27.377574999351054
Sample Time (s)              23.540217283181846
Epoch Time (s)               189.8387986603193
Total Train Time (s)         72419.6427866579
Epoch                        390
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:39:55.914924 UTC | [2020_01_11_13_32_55] Iteration #390 | Epoch Duration: 187.51029467582703
2020-01-12 09:39:55.915099 UTC | [2020_01_11_13_32_55] Iteration #390 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2268041
Z variance train             0.013765981
KL Divergence                27.81426
KL Loss                      2.7814262
QF Loss                      1756.991
VF Loss                      260.33105
Policy Loss                  -1425.9397
Q Predictions Mean           1430.154
Q Predictions Std            321.84286
Q Predictions Max            1629.7935
Q Predictions Min            -195.8339
V Predictions Mean           1426.139
V Predictions Std            314.84232
V Predictions Max            1616.2529
V Predictions Min            -189.61693
Log Pis Mean                 0.24165165
Log Pis Std                  3.0085444
Log Pis Max                  10.711706
Log Pis Min                  -10.046223
Policy mu Mean               0.027878767
Policy mu Std                0.6599548
Policy mu Max                2.6276243
Policy mu Min                -2.2496054
Policy log std Mean          -0.99635714
Policy log std Std           0.2935253
Policy log std Max           -0.18889797
Policy log std Min           -2.7504115
Z mean eval                  1.23843
Z variance eval              0.009075895
total_rewards                [ 207.18717011 1648.42611818  208.33793556  346.76165091 1200.46921359
  920.22792014 4124.90809271 3615.00400865 1887.21989805 3340.31892196]
total_rewards_mean           1749.8860929861585
total_rewards_std            1392.5970738829283
total_rewards_max            4124.908092708801
total_rewards_min            207.18717011471546
Number of train steps total  1568000
Number of env steps total    1962000
Number of rollouts total     0
Train Time (s)               145.37438554596156
(Previous) Eval Time (s)     25.048767438624054
Sample Time (s)              26.038954898249358
Epoch Time (s)               196.46210788283497
Total Train Time (s)         72609.51658404572
Epoch                        391
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:43:05.793429 UTC | [2020_01_11_13_32_55] Iteration #391 | Epoch Duration: 189.87819027900696
2020-01-12 09:43:05.793665 UTC | [2020_01_11_13_32_55] Iteration #391 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2378348
Z variance train             0.00905537
KL Divergence                29.079792
KL Loss                      2.9079792
QF Loss                      11356.426
VF Loss                      6532.6646
Policy Loss                  -1396.9628
Q Predictions Mean           1407.5676
Q Predictions Std            372.30197
Q Predictions Max            1620.7953
Q Predictions Min            -267.35043
V Predictions Mean           1399.3368
V Predictions Std            374.6512
V Predictions Max            1615.4749
V Predictions Min            -304.44568
Log Pis Mean                 0.64862955
Log Pis Std                  3.1837752
Log Pis Max                  13.013404
Log Pis Min                  -6.9991903
Policy mu Mean               0.013341013
Policy mu Std                0.67730194
Policy mu Max                2.8870614
Policy mu Min                -2.5654583
Policy log std Mean          -1.0176513
Policy log std Std           0.31376573
Policy log std Max           -0.14354515
Policy log std Min           -2.7888002
Z mean eval                  1.2465537
Z variance eval              0.009837459
total_rewards                [3672.75339306 3667.05102084 4099.39383069 3860.36542362 3968.77674248
 3884.63329253 3757.21577341 3827.25811806 3769.01788655 3844.44072242]
total_rewards_mean           3835.090620364702
total_rewards_std            124.89636147715963
total_rewards_max            4099.393830694779
total_rewards_min            3667.0510208398023
Number of train steps total  1572000
Number of env steps total    1967000
Number of rollouts total     0
Train Time (s)               142.16995735419914
(Previous) Eval Time (s)     18.464486462064087
Sample Time (s)              25.456900571938604
Epoch Time (s)               186.09134438820183
Total Train Time (s)         72812.3570404402
Epoch                        392
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:46:28.637824 UTC | [2020_01_11_13_32_55] Iteration #392 | Epoch Duration: 202.84402084350586
2020-01-12 09:46:28.638013 UTC | [2020_01_11_13_32_55] Iteration #392 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2452328
Z variance train             0.009822076
KL Divergence                29.896503
KL Loss                      2.9896505
QF Loss                      1822.6053
VF Loss                      226.04971
Policy Loss                  -1402.6763
Q Predictions Mean           1402.313
Q Predictions Std            362.7416
Q Predictions Max            1633.8317
Q Predictions Min            -264.82156
V Predictions Mean           1407.4137
V Predictions Std            355.4038
V Predictions Max            1628.7078
V Predictions Min            -261.90753
Log Pis Mean                 0.9470244
Log Pis Std                  3.4819586
Log Pis Max                  16.853006
Log Pis Min                  -8.310844
Policy mu Mean               0.026541423
Policy mu Std                0.6369643
Policy mu Max                3.0395534
Policy mu Min                -2.2607484
Policy log std Mean          -1.0709577
Policy log std Std           0.32019803
Policy log std Max           0.22934115
Policy log std Min           -2.8042045
Z mean eval                  1.2561287
Z variance eval              0.0098220315
total_rewards                [1171.95437107 2036.64838755 2558.14893262 3873.10652632  488.50614128
 1993.31627032  659.25922088  778.94169794 1754.43704412 4134.37500767]
total_rewards_mean           1944.8693599764483
total_rewards_std            1211.0223983398207
total_rewards_max            4134.37500767237
total_rewards_min            488.5061412821853
Number of train steps total  1576000
Number of env steps total    1972000
Number of rollouts total     0
Train Time (s)               145.18740015709773
(Previous) Eval Time (s)     35.21680171182379
Sample Time (s)              25.622079430613667
Epoch Time (s)               206.02628129953519
Total Train Time (s)         73009.36688464694
Epoch                        393
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:49:45.653113 UTC | [2020_01_11_13_32_55] Iteration #393 | Epoch Duration: 197.014954328537
2020-01-12 09:49:45.653382 UTC | [2020_01_11_13_32_55] Iteration #393 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2530984
Z variance train             0.0098455055
KL Divergence                27.87262
KL Loss                      2.787262
QF Loss                      3192.5022
VF Loss                      1523.0269
Policy Loss                  -1386.9948
Q Predictions Mean           1385.6123
Q Predictions Std            396.28973
Q Predictions Max            1647.6797
Q Predictions Min            -220.3703
V Predictions Mean           1384.1213
V Predictions Std            379.84872
V Predictions Max            1635.9792
V Predictions Min            -243.01459
Log Pis Mean                 0.7145784
Log Pis Std                  3.4602869
Log Pis Max                  19.875862
Log Pis Min                  -5.8718705
Policy mu Mean               0.014070708
Policy mu Std                0.68392336
Policy mu Max                3.487212
Policy mu Min                -2.5035625
Policy log std Mean          -1.0266093
Policy log std Std           0.34411973
Policy log std Max           0.22516513
Policy log std Min           -3.3096569
Z mean eval                  1.4012951
Z variance eval              0.013739467
total_rewards                [ 878.11651582  295.85162248 3527.85636286 3401.91190428 3861.13366681
 3653.23829118   90.96036798    5.9965201    32.07152794 3483.32011387]
total_rewards_mean           1923.0456893317191
total_rewards_std            1682.0732813183113
total_rewards_max            3861.133666814228
total_rewards_min            5.996520099049893
Number of train steps total  1580000
Number of env steps total    1977000
Number of rollouts total     0
Train Time (s)               143.40637593204156
(Previous) Eval Time (s)     26.20503892702982
Sample Time (s)              24.777266503777355
Epoch Time (s)               194.38868136284873
Total Train Time (s)         73199.48272974975
Epoch                        394
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:52:55.773891 UTC | [2020_01_11_13_32_55] Iteration #394 | Epoch Duration: 190.12033987045288
2020-01-12 09:52:55.774157 UTC | [2020_01_11_13_32_55] Iteration #394 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4022897
Z variance train             0.013738734
KL Divergence                28.754263
KL Loss                      2.8754263
QF Loss                      4931.115
VF Loss                      326.94293
Policy Loss                  -1410.1566
Q Predictions Mean           1409.1293
Q Predictions Std            333.94778
Q Predictions Max            1627.5905
Q Predictions Min            -152.3174
V Predictions Mean           1410.4429
V Predictions Std            322.16403
V Predictions Max            1622.5
V Predictions Min            -167.43802
Log Pis Mean                 0.89352405
Log Pis Std                  3.4270911
Log Pis Max                  15.540718
Log Pis Min                  -7.5032268
Policy mu Mean               0.024832778
Policy mu Std                0.6680244
Policy mu Max                2.986155
Policy mu Min                -2.8809197
Policy log std Mean          -1.0636597
Policy log std Std           0.31203657
Policy log std Max           -0.23985791
Policy log std Min           -3.026235
Z mean eval                  1.2857735
Z variance eval              0.0122948615
total_rewards                [3767.45840215 4165.96126565  827.6507584  3086.26213662 1022.99877926
 3983.19442511  225.06537668 1209.08458921 1632.1953333  1451.46207373]
total_rewards_mean           2137.1333140127363
total_rewards_std            1388.5717795567816
total_rewards_max            4165.961265645639
total_rewards_min            225.0653766849693
Number of train steps total  1584000
Number of env steps total    1982000
Number of rollouts total     0
Train Time (s)               136.0631259419024
(Previous) Eval Time (s)     21.936329047195613
Sample Time (s)              23.35915136290714
Epoch Time (s)               181.35860635200515
Total Train Time (s)         73376.84375867108
Epoch                        395
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:55:53.138737 UTC | [2020_01_11_13_32_55] Iteration #395 | Epoch Duration: 177.36440873146057
2020-01-12 09:55:53.138914 UTC | [2020_01_11_13_32_55] Iteration #395 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2858589
Z variance train             0.01229219
KL Divergence                28.404251
KL Loss                      2.8404253
QF Loss                      1031.6057
VF Loss                      341.49847
Policy Loss                  -1396.4652
Q Predictions Mean           1399.834
Q Predictions Std            405.50555
Q Predictions Max            1636.8921
Q Predictions Min            -346.83752
V Predictions Mean           1402.4827
V Predictions Std            400.09674
V Predictions Max            1631.7617
V Predictions Min            -340.54788
Log Pis Mean                 0.9860626
Log Pis Std                  3.4371278
Log Pis Max                  14.589394
Log Pis Min                  -6.217612
Policy mu Mean               0.04397115
Policy mu Std                0.6881079
Policy mu Max                3.089621
Policy mu Min                -3.5845168
Policy log std Mean          -1.0469272
Policy log std Std           0.3223512
Policy log std Max           -0.08058834
Policy log std Min           -2.7299027
Z mean eval                  1.2287449
Z variance eval              0.0070277974
total_rewards                [3869.81041015 1396.969847   4121.65893724 3683.32326113 2660.16110259
 3962.34130622  529.70650502 1877.6622022   462.72400935 4023.511817  ]
total_rewards_mean           2658.786939790134
total_rewards_std            1406.2713461119497
total_rewards_max            4121.658937242661
total_rewards_min            462.7240093487044
Number of train steps total  1588000
Number of env steps total    1987000
Number of rollouts total     0
Train Time (s)               135.31615887396038
(Previous) Eval Time (s)     17.941841484978795
Sample Time (s)              24.798880155198276
Epoch Time (s)               178.05688051413745
Total Train Time (s)         73562.36709949514
Epoch                        396
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:58:58.666441 UTC | [2020_01_11_13_32_55] Iteration #396 | Epoch Duration: 185.52737593650818
2020-01-12 09:58:58.666632 UTC | [2020_01_11_13_32_55] Iteration #396 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2316533
Z variance train             0.007022535
KL Divergence                29.395853
KL Loss                      2.9395854
QF Loss                      1575.2388
VF Loss                      436.64313
Policy Loss                  -1370.3776
Q Predictions Mean           1374.7341
Q Predictions Std            415.1415
Q Predictions Max            1635.3275
Q Predictions Min            -307.64774
V Predictions Mean           1368.8267
V Predictions Std            411.8918
V Predictions Max            1631.5839
V Predictions Min            -306.90732
Log Pis Mean                 0.90306246
Log Pis Std                  3.363028
Log Pis Max                  17.772615
Log Pis Min                  -7.993829
Policy mu Mean               0.03475841
Policy mu Std                0.65393096
Policy mu Max                2.9613059
Policy mu Min                -2.7177687
Policy log std Mean          -1.0539954
Policy log std Std           0.34562466
Policy log std Max           -0.102791905
Policy log std Min           -3.1955233
Z mean eval                  1.2699424
Z variance eval              0.0064182403
total_rewards                [3942.88246965 3947.61077096 3496.00441552 3838.35374304 3849.62711165
 2258.69155255 1077.27601619  246.82150978 2214.93101572 1965.92396692]
total_rewards_mean           2683.812257199076
total_rewards_std            1263.7252204814547
total_rewards_max            3947.610770964513
total_rewards_min            246.82150978198706
Number of train steps total  1592000
Number of env steps total    1992000
Number of rollouts total     0
Train Time (s)               143.03279535891488
(Previous) Eval Time (s)     25.412023863289505
Sample Time (s)              25.90739696333185
Epoch Time (s)               194.35221618553624
Total Train Time (s)         73757.33891017409
Epoch                        397
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:02:13.642508 UTC | [2020_01_11_13_32_55] Iteration #397 | Epoch Duration: 194.9757421016693
2020-01-12 10:02:13.642708 UTC | [2020_01_11_13_32_55] Iteration #397 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2670157
Z variance train             0.006426996
KL Divergence                29.410625
KL Loss                      2.9410627
QF Loss                      914.6065
VF Loss                      226.27518
Policy Loss                  -1419.8488
Q Predictions Mean           1421.8429
Q Predictions Std            326.61487
Q Predictions Max            1644.3367
Q Predictions Min            -285.4951
V Predictions Mean           1425.5647
V Predictions Std            321.5116
V Predictions Max            1641.3295
V Predictions Min            -279.89307
Log Pis Mean                 0.5460086
Log Pis Std                  3.1092136
Log Pis Max                  14.213747
Log Pis Min                  -9.252989
Policy mu Mean               0.07736015
Policy mu Std                0.6813848
Policy mu Max                3.2982514
Policy mu Min                -2.5481935
Policy log std Mean          -1.0141245
Policy log std Std           0.29400873
Policy log std Max           0.28788102
Policy log std Min           -2.4471743
Z mean eval                  1.2922906
Z variance eval              0.00661565
total_rewards                [3786.56585541 1611.7157518  4070.72552309 3978.37847811  452.38257467
 4000.25765222 2704.0340772  3915.3690633  4038.42547097 2266.0109929 ]
total_rewards_mean           3082.3865439693645
total_rewards_std            1208.9356786909557
total_rewards_max            4070.7255230939563
total_rewards_min            452.3825746731542
Number of train steps total  1596000
Number of env steps total    1997000
Number of rollouts total     0
Train Time (s)               143.06839310983196
(Previous) Eval Time (s)     26.035176447127014
Sample Time (s)              26.764043069444597
Epoch Time (s)               195.86761262640357
Total Train Time (s)         73956.64740301529
Epoch                        398
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:05:32.955283 UTC | [2020_01_11_13_32_55] Iteration #398 | Epoch Duration: 199.31244134902954
2020-01-12 10:05:32.955472 UTC | [2020_01_11_13_32_55] Iteration #398 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2913752
Z variance train             0.006612795
KL Divergence                30.245295
KL Loss                      3.0245295
QF Loss                      720.8363
VF Loss                      305.47742
Policy Loss                  -1446.6758
Q Predictions Mean           1449.5107
Q Predictions Std            316.95255
Q Predictions Max            1657.0986
Q Predictions Min            -231.4982
V Predictions Mean           1446.3829
V Predictions Std            315.57452
V Predictions Max            1647.5994
V Predictions Min            -259.29538
Log Pis Mean                 0.7332367
Log Pis Std                  3.1418405
Log Pis Max                  14.090265
Log Pis Min                  -9.014153
Policy mu Mean               0.013521782
Policy mu Std                0.6179667
Policy mu Max                2.4969146
Policy mu Min                -2.4058926
Policy log std Mean          -1.0810845
Policy log std Std           0.2968893
Policy log std Max           0.04835677
Policy log std Min           -2.8368814
Z mean eval                  1.2205586
Z variance eval              0.012060905
total_rewards                [ 333.76552694 1024.02053878 4150.22076274  592.18509623 3725.55703203
 1341.99953557 3857.35210968 3593.92662611   88.2298263   295.18288802]
total_rewards_mean           1900.2439942410474
total_rewards_std            1618.5453334996996
total_rewards_max            4150.220762741704
total_rewards_min            88.22982630476884
Number of train steps total  1600000
Number of env steps total    2002000
Number of rollouts total     0
Train Time (s)               141.98083719983697
(Previous) Eval Time (s)     29.4795833947137
Sample Time (s)              27.071857943199575
Epoch Time (s)               198.53227853775024
Total Train Time (s)         74142.83917836053
Epoch                        399
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:08:39.151701 UTC | [2020_01_11_13_32_55] Iteration #399 | Epoch Duration: 186.1960985660553
2020-01-12 10:08:39.151891 UTC | [2020_01_11_13_32_55] Iteration #399 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2205974
Z variance train             0.012062078
KL Divergence                29.235613
KL Loss                      2.9235613
QF Loss                      952.4005
VF Loss                      267.42276
Policy Loss                  -1410.5652
Q Predictions Mean           1415.8467
Q Predictions Std            361.55487
Q Predictions Max            1622.7341
Q Predictions Min            -236.19946
V Predictions Mean           1409.46
V Predictions Std            361.52795
V Predictions Max            1629.6224
V Predictions Min            -233.40735
Log Pis Mean                 0.60397696
Log Pis Std                  2.967795
Log Pis Max                  13.681595
Log Pis Min                  -7.398485
Policy mu Mean               0.056928344
Policy mu Std                0.62269497
Policy mu Max                2.7384865
Policy mu Min                -2.187027
Policy log std Mean          -1.0400941
Policy log std Std           0.2994659
Policy log std Max           1.1863829
Policy log std Min           -3.050333
Z mean eval                  1.286542
Z variance eval              0.014926186
total_rewards                [ 514.12632939 3922.18822385 4000.76061783 4079.15614447 1076.90970123
 3788.60249204 3906.51803451 3826.42407819  396.83428442 4002.96274457]
total_rewards_mean           2951.448265048627
total_rewards_std            1509.2996394494912
total_rewards_max            4079.156144465578
total_rewards_min            396.8342844239964
Number of train steps total  1604000
Number of env steps total    2007000
Number of rollouts total     0
Train Time (s)               144.3187501244247
(Previous) Eval Time (s)     17.142943707294762
Sample Time (s)              25.11979175079614
Epoch Time (s)               186.5814855825156
Total Train Time (s)         74337.48223215481
Epoch                        400
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:11:53.799029 UTC | [2020_01_11_13_32_55] Iteration #400 | Epoch Duration: 194.64700293540955
2020-01-12 10:11:53.799254 UTC | [2020_01_11_13_32_55] Iteration #400 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2862375
Z variance train             0.014869285
KL Divergence                28.51185
KL Loss                      2.851185
QF Loss                      1204.1953
VF Loss                      519.55426
Policy Loss                  -1400.525
Q Predictions Mean           1401.5359
Q Predictions Std            370.0327
Q Predictions Max            1624.5452
Q Predictions Min            -343.70734
V Predictions Mean           1405.6158
V Predictions Std            363.93738
V Predictions Max            1613.4772
V Predictions Min            -347.1787
Log Pis Mean                 0.5031929
Log Pis Std                  3.5392144
Log Pis Max                  23.355953
Log Pis Min                  -11.411829
Policy mu Mean               0.0041756514
Policy mu Std                0.6615711
Policy mu Max                4.2718277
Policy mu Min                -4.5526524
Policy log std Mean          -1.028863
Policy log std Std           0.30603686
Policy log std Max           0.18759918
Policy log std Min           -2.9243388
Z mean eval                  1.225025
Z variance eval              0.00663905
total_rewards                [3940.78791808 3834.30293491 3816.2865607  4048.69430593 1652.08260016
 3898.47886913 2658.43827964 3957.99140214 3367.99327523 2917.92477181]
total_rewards_mean           3409.2980917723194
total_rewards_std            739.7763469679743
total_rewards_max            4048.6943059300734
total_rewards_min            1652.0826001624878
Number of train steps total  1608000
Number of env steps total    2012000
Number of rollouts total     0
Train Time (s)               139.51703684125096
(Previous) Eval Time (s)     25.208081799093634
Sample Time (s)              25.849205256905407
Epoch Time (s)               190.57432389725
Total Train Time (s)         74534.36550545506
Epoch                        401
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:15:10.686678 UTC | [2020_01_11_13_32_55] Iteration #401 | Epoch Duration: 196.88727712631226
2020-01-12 10:15:10.686875 UTC | [2020_01_11_13_32_55] Iteration #401 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2256298
Z variance train             0.0066651786
KL Divergence                28.844004
KL Loss                      2.8844004
QF Loss                      1468.2361
VF Loss                      245.84464
Policy Loss                  -1420.9746
Q Predictions Mean           1423.9408
Q Predictions Std            325.2068
Q Predictions Max            1660.3905
Q Predictions Min            -356.24472
V Predictions Mean           1425.2161
V Predictions Std            326.4894
V Predictions Max            1645.6647
V Predictions Min            -356.50278
Log Pis Mean                 0.5991715
Log Pis Std                  3.478818
Log Pis Max                  17.523438
Log Pis Min                  -9.318992
Policy mu Mean               0.008467489
Policy mu Std                0.62959814
Policy mu Max                3.043582
Policy mu Min                -2.3896642
Policy log std Mean          -1.0801066
Policy log std Std           0.3316763
Policy log std Max           -0.056224465
Policy log std Min           -2.9189427
Z mean eval                  1.33115
Z variance eval              0.011771485
total_rewards                [ 850.69065429 2322.79413884 2413.5736383   212.05690436 4098.14486962
 1564.99536687 1162.78107002 3283.2494035  1017.60389313 1568.99840623]
total_rewards_mean           1849.4888345161519
total_rewards_std            1125.0033583981137
total_rewards_max            4098.14486961597
total_rewards_min            212.0569043583522
Number of train steps total  1612000
Number of env steps total    2017000
Number of rollouts total     0
Train Time (s)               136.50696685537696
(Previous) Eval Time (s)     31.520625703968108
Sample Time (s)              25.435695042368025
Epoch Time (s)               193.4632876017131
Total Train Time (s)         74715.73381880019
Epoch                        402
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:18:12.059144 UTC | [2020_01_11_13_32_55] Iteration #402 | Epoch Duration: 181.37213397026062
2020-01-12 10:18:12.059439 UTC | [2020_01_11_13_32_55] Iteration #402 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3316486
Z variance train             0.011796215
KL Divergence                28.719381
KL Loss                      2.8719382
QF Loss                      1206.5427
VF Loss                      417.18878
Policy Loss                  -1424.0153
Q Predictions Mean           1426.1796
Q Predictions Std            343.8771
Q Predictions Max            1659.3885
Q Predictions Min            -283.0629
V Predictions Mean           1419.3662
V Predictions Std            342.69473
V Predictions Max            1644.1705
V Predictions Min            -271.10464
Log Pis Mean                 0.5720387
Log Pis Std                  3.1113045
Log Pis Max                  13.669143
Log Pis Min                  -8.44919
Policy mu Mean               -0.029854743
Policy mu Std                0.64150816
Policy mu Max                2.4822717
Policy mu Min                -4.457052
Policy log std Mean          -1.0515676
Policy log std Std           0.32975578
Policy log std Max           1.3339903
Policy log std Min           -2.9313765
Z mean eval                  1.2321312
Z variance eval              0.0075234785
total_rewards                [3849.78777995 1365.11679493 4049.23316521   86.89127374  601.16752587
  120.93535026 2557.91942713 1348.42599734 2514.3241723   795.27052285]
total_rewards_mean           1728.9072009575539
total_rewards_std            1374.3566315169305
total_rewards_max            4049.2331652085772
total_rewards_min            86.89127374023448
Number of train steps total  1616000
Number of env steps total    2022000
Number of rollouts total     0
Train Time (s)               136.78750826092437
(Previous) Eval Time (s)     19.429173892829567
Sample Time (s)              24.124245064798743
Epoch Time (s)               180.34092721855268
Total Train Time (s)         74893.21176614799
Epoch                        403
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:21:09.540469 UTC | [2020_01_11_13_32_55] Iteration #403 | Epoch Duration: 177.48090934753418
2020-01-12 10:21:09.540617 UTC | [2020_01_11_13_32_55] Iteration #403 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2345883
Z variance train             0.007514163
KL Divergence                28.791939
KL Loss                      2.879194
QF Loss                      1477.8943
VF Loss                      475.2832
Policy Loss                  -1373.0193
Q Predictions Mean           1373.1677
Q Predictions Std            436.90128
Q Predictions Max            1625.7904
Q Predictions Min            -285.7246
V Predictions Mean           1363.7825
V Predictions Std            430.3585
V Predictions Max            1615.5658
V Predictions Min            -275.68756
Log Pis Mean                 0.97577846
Log Pis Std                  3.651066
Log Pis Max                  18.535824
Log Pis Min                  -7.520876
Policy mu Mean               -0.009175162
Policy mu Std                0.6979456
Policy mu Max                3.1835434
Policy mu Min                -2.9888813
Policy log std Mean          -1.0316904
Policy log std Std           0.32570204
Policy log std Max           0.012572408
Policy log std Min           -3.0639553
Z mean eval                  1.2510836
Z variance eval              0.010812186
total_rewards                [ 125.8933066  2683.28954229 1052.16682846 2348.09773807 1477.98745413
 3304.82324615 1479.12555337  202.922676    302.59487153  626.91997003]
total_rewards_mean           1360.3821186627877
total_rewards_std            1055.9356396149672
total_rewards_max            3304.8232461451353
total_rewards_min            125.89330659567858
Number of train steps total  1620000
Number of env steps total    2027000
Number of rollouts total     0
Train Time (s)               143.80223332811147
(Previous) Eval Time (s)     16.568834867794067
Sample Time (s)              25.017391544301063
Epoch Time (s)               185.3884597402066
Total Train Time (s)         75075.51233365014
Epoch                        404
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:24:11.846422 UTC | [2020_01_11_13_32_55] Iteration #404 | Epoch Duration: 182.30564713478088
2020-01-12 10:24:11.846793 UTC | [2020_01_11_13_32_55] Iteration #404 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2507521
Z variance train             0.010813301
KL Divergence                27.911764
KL Loss                      2.7911766
QF Loss                      1455.7465
VF Loss                      234.35208
Policy Loss                  -1424.8452
Q Predictions Mean           1427.0149
Q Predictions Std            344.43436
Q Predictions Max            1630.5222
Q Predictions Min            -381.4329
V Predictions Mean           1424.8896
V Predictions Std            344.30252
V Predictions Max            1627.105
V Predictions Min            -404.37106
Log Pis Mean                 0.67570376
Log Pis Std                  2.9200673
Log Pis Max                  12.349427
Log Pis Min                  -6.6181793
Policy mu Mean               0.01195099
Policy mu Std                0.6391232
Policy mu Max                3.189285
Policy mu Min                -2.3759737
Policy log std Mean          -1.0777514
Policy log std Std           0.2950111
Policy log std Max           1.0378133
Policy log std Min           -2.8990912
Z mean eval                  1.2482421
Z variance eval              0.019234113
total_rewards                [ 778.34776501 3815.96194902  741.42114581 1539.2464235  1011.77250233
 4244.79927507 4295.73125077 4118.29394496  642.40852967 3999.3620309 ]
total_rewards_mean           2518.7344817035287
total_rewards_std            1597.1657292017305
total_rewards_max            4295.731250768037
total_rewards_min            642.4085296689658
Number of train steps total  1624000
Number of env steps total    2032000
Number of rollouts total     0
Train Time (s)               143.44429886108264
(Previous) Eval Time (s)     13.485649583861232
Sample Time (s)              25.95681978110224
Epoch Time (s)               182.88676822604612
Total Train Time (s)         75267.52014031587
Epoch                        405
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:27:23.857818 UTC | [2020_01_11_13_32_55] Iteration #405 | Epoch Duration: 192.01080131530762
2020-01-12 10:27:23.858067 UTC | [2020_01_11_13_32_55] Iteration #405 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2467877
Z variance train             0.01923536
KL Divergence                27.818626
KL Loss                      2.7818627
QF Loss                      16587.182
VF Loss                      272.87073
Policy Loss                  -1395.1521
Q Predictions Mean           1398.4946
Q Predictions Std            384.11777
Q Predictions Max            1625.7827
Q Predictions Min            -402.6528
V Predictions Mean           1399.9767
V Predictions Std            381.05127
V Predictions Max            1612.0709
V Predictions Min            -395.1015
Log Pis Mean                 0.6128471
Log Pis Std                  2.8980098
Log Pis Max                  13.39133
Log Pis Min                  -6.2160807
Policy mu Mean               -0.005378808
Policy mu Std                0.6692402
Policy mu Max                2.9491234
Policy mu Min                -4.2863927
Policy log std Mean          -1.0255953
Policy log std Std           0.29013515
Policy log std Max           0.87188745
Policy log std Min           -2.4392266
Z mean eval                  1.2755264
Z variance eval              0.027339563
total_rewards                [1583.0277884  1919.48818542 1405.65846609 3723.57995494  999.48345188
 1102.25898925  513.29931039 3981.79390718 1215.62643464   10.72484654]
total_rewards_mean           1645.4941334717914
total_rewards_std            1215.1044994635556
total_rewards_max            3981.793907176645
total_rewards_min            10.7248465379243
Number of train steps total  1628000
Number of env steps total    2037000
Number of rollouts total     0
Train Time (s)               142.65314307203516
(Previous) Eval Time (s)     22.609331178944558
Sample Time (s)              24.823521674145013
Epoch Time (s)               190.08599592512473
Total Train Time (s)         75457.7101054173
Epoch                        406
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:30:34.052460 UTC | [2020_01_11_13_32_55] Iteration #406 | Epoch Duration: 190.1942286491394
2020-01-12 10:30:34.052825 UTC | [2020_01_11_13_32_55] Iteration #406 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2803711
Z variance train             0.027275756
KL Divergence                27.342949
KL Loss                      2.734295
QF Loss                      1375.3091
VF Loss                      913.2839
Policy Loss                  -1430.052
Q Predictions Mean           1431.8074
Q Predictions Std            328.46606
Q Predictions Max            1625.8439
Q Predictions Min            -188.63913
V Predictions Mean           1421.7269
V Predictions Std            325.30856
V Predictions Max            1615.9578
V Predictions Min            -200.02518
Log Pis Mean                 0.97696185
Log Pis Std                  3.5527282
Log Pis Max                  17.170904
Log Pis Min                  -10.237405
Policy mu Mean               -0.037858978
Policy mu Std                0.69390345
Policy mu Max                3.5324223
Policy mu Min                -2.3096395
Policy log std Mean          -1.0674714
Policy log std Std           0.3255553
Policy log std Max           -0.19722015
Policy log std Min           -2.8685446
Z mean eval                  1.2076875
Z variance eval              0.0048105414
total_rewards                [2548.39884378  220.49228185 2936.1358509   109.20692236 3346.00061348
 1550.02800874  417.9685083  3815.5219701  3851.95886943  664.22507975]
total_rewards_mean           1945.9936948686245
total_rewards_std            1446.2659988874973
total_rewards_max            3851.9588694294107
total_rewards_min            109.20692236279582
Number of train steps total  1632000
Number of env steps total    2042000
Number of rollouts total     0
Train Time (s)               142.66141770593822
(Previous) Eval Time (s)     22.71717008529231
Sample Time (s)              25.621253654826432
Epoch Time (s)               190.99984144605696
Total Train Time (s)         75645.13566562952
Epoch                        407
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:33:41.482209 UTC | [2020_01_11_13_32_55] Iteration #407 | Epoch Duration: 187.42914485931396
2020-01-12 10:33:41.482447 UTC | [2020_01_11_13_32_55] Iteration #407 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2068372
Z variance train             0.0048074475
KL Divergence                29.16457
KL Loss                      2.916457
QF Loss                      1151.9294
VF Loss                      255.52835
Policy Loss                  -1381.459
Q Predictions Mean           1385.181
Q Predictions Std            394.7994
Q Predictions Max            1614.3817
Q Predictions Min            -300.87747
V Predictions Mean           1381.2205
V Predictions Std            395.88947
V Predictions Max            1611.2494
V Predictions Min            -315.87466
Log Pis Mean                 0.7602838
Log Pis Std                  3.3059053
Log Pis Max                  16.919369
Log Pis Min                  -7.6395082
Policy mu Mean               0.02278521
Policy mu Std                0.64623773
Policy mu Max                2.7748566
Policy mu Min                -2.7973626
Policy log std Mean          -1.0526354
Policy log std Std           0.31579173
Policy log std Max           0.0422858
Policy log std Min           -2.762319
Z mean eval                  1.2396286
Z variance eval              0.010583289
total_rewards                [ 170.34861306  405.82413603 3766.66124549 2668.0801578   297.59475133
 1903.30764105 3963.19309081 2048.51002208 3705.77330098  843.24940268]
total_rewards_mean           1977.254236131846
total_rewards_std            1430.490059896047
total_rewards_max            3963.193090813211
total_rewards_min            170.34861305791716
Number of train steps total  1636000
Number of env steps total    2047000
Number of rollouts total     0
Train Time (s)               137.42791183385998
(Previous) Eval Time (s)     19.146078403107822
Sample Time (s)              26.28919716645032
Epoch Time (s)               182.86318740341812
Total Train Time (s)         75834.42106311163
Epoch                        408
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:36:50.771726 UTC | [2020_01_11_13_32_55] Iteration #408 | Epoch Duration: 189.28913068771362
2020-01-12 10:36:50.771955 UTC | [2020_01_11_13_32_55] Iteration #408 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2429394
Z variance train             0.010548958
KL Divergence                28.695385
KL Loss                      2.8695385
QF Loss                      1104.9851
VF Loss                      411.02908
Policy Loss                  -1398.0886
Q Predictions Mean           1398.3031
Q Predictions Std            364.97253
Q Predictions Max            1651.5259
Q Predictions Min            -407.73074
V Predictions Mean           1391.8442
V Predictions Std            364.92038
V Predictions Max            1632.958
V Predictions Min            -387.10544
Log Pis Mean                 0.6559321
Log Pis Std                  3.5751162
Log Pis Max                  18.985102
Log Pis Min                  -6.6268897
Policy mu Mean               0.040684342
Policy mu Std                0.703079
Policy mu Max                3.7797997
Policy mu Min                -6.3046985
Policy log std Mean          -1.053997
Policy log std Std           0.31846946
Policy log std Max           0.5934957
Policy log std Min           -2.7094126
Z mean eval                  1.2023187
Z variance eval              0.0077233613
total_rewards                [3785.6139027  1818.9936664  3933.53120166 2662.81019706 3996.48755858
 3941.27710201 3880.23463629 3968.06907237 3530.31770241 4166.0269094 ]
total_rewards_mean           3568.336194887727
total_rewards_std            707.0289051738059
total_rewards_max            4166.026909400695
total_rewards_min            1818.99366639944
Number of train steps total  1640000
Number of env steps total    2052000
Number of rollouts total     0
Train Time (s)               135.46896023815498
(Previous) Eval Time (s)     25.571701540146023
Sample Time (s)              23.13158269505948
Epoch Time (s)               184.17224447336048
Total Train Time (s)         76027.93675371679
Epoch                        409
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:40:04.293086 UTC | [2020_01_11_13_32_55] Iteration #409 | Epoch Duration: 193.5209698677063
2020-01-12 10:40:04.293360 UTC | [2020_01_11_13_32_55] Iteration #409 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2025869
Z variance train             0.0077572763
KL Divergence                29.005028
KL Loss                      2.900503
QF Loss                      1455.8271
VF Loss                      278.72922
Policy Loss                  -1420.8247
Q Predictions Mean           1423.4912
Q Predictions Std            333.42142
Q Predictions Max            1626.5719
Q Predictions Min            -260.037
V Predictions Mean           1414.1576
V Predictions Std            335.04556
V Predictions Max            1617.9296
V Predictions Min            -255.44975
Log Pis Mean                 0.87507194
Log Pis Std                  3.1430295
Log Pis Max                  12.368299
Log Pis Min                  -7.2695427
Policy mu Mean               0.023866596
Policy mu Std                0.6527441
Policy mu Max                3.0302074
Policy mu Min                -2.6144528
Policy log std Mean          -1.0721419
Policy log std Std           0.30477402
Policy log std Max           -0.10578883
Policy log std Min           -2.5315108
Z mean eval                  1.2298973
Z variance eval              0.0068114945
total_rewards                [ 231.37111093 3913.25845116 3763.00744692 1080.38222684 4222.13115646
 4017.94629335 1255.49837434  237.45877825 1195.97589707 3800.49606776]
total_rewards_mean           2371.7525803076833
total_rewards_std            1609.9548919626684
total_rewards_max            4222.131156458545
total_rewards_min            231.37111093308167
Number of train steps total  1644000
Number of env steps total    2057000
Number of rollouts total     0
Train Time (s)               138.3475106167607
(Previous) Eval Time (s)     34.92013870598748
Sample Time (s)              24.648049365263432
Epoch Time (s)               197.91569868801162
Total Train Time (s)         76218.21864366997
Epoch                        410
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:43:14.580149 UTC | [2020_01_11_13_32_55] Iteration #410 | Epoch Duration: 190.28659653663635
2020-01-12 10:43:14.580406 UTC | [2020_01_11_13_32_55] Iteration #410 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2317674
Z variance train             0.006817819
KL Divergence                29.302647
KL Loss                      2.9302647
QF Loss                      922.78723
VF Loss                      225.73486
Policy Loss                  -1401.1677
Q Predictions Mean           1402.0273
Q Predictions Std            331.06815
Q Predictions Max            1612.9856
Q Predictions Min            -134.65744
V Predictions Mean           1399.275
V Predictions Std            326.4075
V Predictions Max            1598.7177
V Predictions Min            -144.98311
Log Pis Mean                 1.2572682
Log Pis Std                  3.6868885
Log Pis Max                  19.788559
Log Pis Min                  -9.86191
Policy mu Mean               0.032342352
Policy mu Std                0.6981471
Policy mu Max                2.3568761
Policy mu Min                -2.990759
Policy log std Mean          -1.0822837
Policy log std Std           0.32000932
Policy log std Max           -0.25290495
Policy log std Min           -2.8056011
Z mean eval                  1.219833
Z variance eval              0.009415673
total_rewards                [ 691.09029856 3959.10045832 3864.75725146  941.63789806 3267.89850641
 2226.65870718 3794.93762205 1348.02685784 3929.98057996 2367.96337942]
total_rewards_mean           2639.205155924662
total_rewards_std            1234.057120609341
total_rewards_max            3959.1004583153263
total_rewards_min            691.0902985594491
Number of train steps total  1648000
Number of env steps total    2062000
Number of rollouts total     0
Train Time (s)               144.32228610897437
(Previous) Eval Time (s)     27.290719693060964
Sample Time (s)              26.26558044599369
Epoch Time (s)               197.87858624802902
Total Train Time (s)         76415.63845249079
Epoch                        411
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:46:32.003318 UTC | [2020_01_11_13_32_55] Iteration #411 | Epoch Duration: 197.4227569103241
2020-01-12 10:46:32.003519 UTC | [2020_01_11_13_32_55] Iteration #411 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.219915
Z variance train             0.009419656
KL Divergence                30.138506
KL Loss                      3.0138507
QF Loss                      1009.8959
VF Loss                      252.96873
Policy Loss                  -1416.2175
Q Predictions Mean           1419.639
Q Predictions Std            313.52832
Q Predictions Max            1667.8495
Q Predictions Min            -127.130005
V Predictions Mean           1420.1306
V Predictions Std            315.22787
V Predictions Max            1655.4993
V Predictions Min            -133.80617
Log Pis Mean                 0.7927791
Log Pis Std                  3.4672117
Log Pis Max                  15.954987
Log Pis Min                  -6.125089
Policy mu Mean               -0.025761642
Policy mu Std                0.69282633
Policy mu Max                3.2999306
Policy mu Min                -2.6262372
Policy log std Mean          -1.04301
Policy log std Std           0.31125394
Policy log std Max           -0.12501287
Policy log std Min           -2.928896
Z mean eval                  1.2983557
Z variance eval              0.0152616035
total_rewards                [ 845.83395055 1991.07360624  738.16915917 3971.1869889   257.10518284
  756.32881033 3861.07015341 2168.26934215  267.03326128 3924.5423344 ]
total_rewards_mean           1878.0612789265367
total_rewards_std            1464.3980887342227
total_rewards_max            3971.1869888988504
total_rewards_min            257.1051828391802
Number of train steps total  1652000
Number of env steps total    2067000
Number of rollouts total     0
Train Time (s)               144.38889477821067
(Previous) Eval Time (s)     26.83446597540751
Sample Time (s)              25.064369089435786
Epoch Time (s)               196.28772984305397
Total Train Time (s)         76606.71157896891
Epoch                        412
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:49:43.079948 UTC | [2020_01_11_13_32_55] Iteration #412 | Epoch Duration: 191.07629871368408
2020-01-12 10:49:43.080106 UTC | [2020_01_11_13_32_55] Iteration #412 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2981104
Z variance train             0.015221469
KL Divergence                29.66519
KL Loss                      2.966519
QF Loss                      1142.7554
VF Loss                      551.68225
Policy Loss                  -1398.3925
Q Predictions Mean           1399.419
Q Predictions Std            367.9831
Q Predictions Max            1650.7443
Q Predictions Min            -181.436
V Predictions Mean           1405.6887
V Predictions Std            364.02707
V Predictions Max            1658.5104
V Predictions Min            -184.02498
Log Pis Mean                 0.78735906
Log Pis Std                  3.4887123
Log Pis Max                  20.767263
Log Pis Min                  -6.6936965
Policy mu Mean               0.04060112
Policy mu Std                0.6529835
Policy mu Max                3.2869453
Policy mu Min                -3.5964372
Policy log std Mean          -1.0578691
Policy log std Std           0.30560264
Policy log std Max           -0.2514912
Policy log std Min           -3.1048489
Z mean eval                  1.2668705
Z variance eval              0.0154818045
total_rewards                [3861.47840521 1710.17942518 3933.61080548 2611.66310063  530.90164167
 3511.16635176 2450.7626901   309.96700373 3840.00500337 3795.10397216]
total_rewards_mean           2655.483839930536
total_rewards_std            1321.9220330259648
total_rewards_max            3933.6108054813785
total_rewards_min            309.9670037347327
Number of train steps total  1656000
Number of env steps total    2072000
Number of rollouts total     0
Train Time (s)               144.74252348812297
(Previous) Eval Time (s)     21.62253374606371
Sample Time (s)              25.837892869953066
Epoch Time (s)               192.20295010413975
Total Train Time (s)         76799.65358636854
Epoch                        413
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:52:56.026266 UTC | [2020_01_11_13_32_55] Iteration #413 | Epoch Duration: 192.94604110717773
2020-01-12 10:52:56.026456 UTC | [2020_01_11_13_32_55] Iteration #413 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2676383
Z variance train             0.015514967
KL Divergence                29.777233
KL Loss                      2.9777234
QF Loss                      4303.6025
VF Loss                      760.38477
Policy Loss                  -1403.1228
Q Predictions Mean           1407.701
Q Predictions Std            377.59457
Q Predictions Max            1656.9231
Q Predictions Min            -445.61282
V Predictions Mean           1408.6669
V Predictions Std            372.6537
V Predictions Max            1651.6698
V Predictions Min            -430.7744
Log Pis Mean                 1.0395548
Log Pis Std                  3.7285783
Log Pis Max                  18.214447
Log Pis Min                  -7.358607
Policy mu Mean               0.08314707
Policy mu Std                0.7092471
Policy mu Max                2.812129
Policy mu Min                -2.3392742
Policy log std Mean          -1.0448458
Policy log std Std           0.3428621
Policy log std Max           -0.05611849
Policy log std Min           -3.3753066
Z mean eval                  1.2431966
Z variance eval              0.0075132228
total_rewards                [3871.83237101 4217.79988885 3834.95349694 2365.42970853 3670.2440429
 1936.70331491 3949.04953589  772.56929845 3826.63668646 1984.23936884]
total_rewards_mean           3042.945771279034
total_rewards_std            1117.209872724034
total_rewards_max            4217.799888851977
total_rewards_min            772.5692984530808
Number of train steps total  1660000
Number of env steps total    2077000
Number of rollouts total     0
Train Time (s)               144.20249670697376
(Previous) Eval Time (s)     22.365270767826587
Sample Time (s)              25.99152943911031
Epoch Time (s)               192.55929691391066
Total Train Time (s)         76996.40558122564
Epoch                        414
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:56:12.782710 UTC | [2020_01_11_13_32_55] Iteration #414 | Epoch Duration: 196.7561230659485
2020-01-12 10:56:12.782910 UTC | [2020_01_11_13_32_55] Iteration #414 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2366891
Z variance train             0.007503301
KL Divergence                31.279732
KL Loss                      3.1279733
QF Loss                      2449.3691
VF Loss                      1056.9507
Policy Loss                  -1430.7109
Q Predictions Mean           1429.2139
Q Predictions Std            298.55762
Q Predictions Max            1623.8788
Q Predictions Min            -416.32983
V Predictions Mean           1436.1792
V Predictions Std            293.5431
V Predictions Max            1630.1635
V Predictions Min            -397.62738
Log Pis Mean                 1.3309299
Log Pis Std                  3.4436529
Log Pis Max                  22.022562
Log Pis Min                  -7.008656
Policy mu Mean               -0.0014230136
Policy mu Std                0.7067929
Policy mu Max                3.0931282
Policy mu Min                -4.1361427
Policy log std Mean          -1.0563822
Policy log std Std           0.28629255
Policy log std Max           1.0627958
Policy log std Min           -2.7528076
Z mean eval                  1.2333424
Z variance eval              0.019120887
total_rewards                [3573.00406712 3994.61161032 4055.48767222 3508.10279594 4069.16979557
 1634.3434149  4169.93928108 4153.37083118  262.80971475 3901.31408462]
total_rewards_mean           3332.2153267712724
total_rewards_std            1248.914739002858
total_rewards_max            4169.939281081634
total_rewards_min            262.80971475418187
Number of train steps total  1664000
Number of env steps total    2082000
Number of rollouts total     0
Train Time (s)               135.36226567719132
(Previous) Eval Time (s)     26.56171532999724
Sample Time (s)              25.507253107149154
Epoch Time (s)               187.4312341143377
Total Train Time (s)         77185.04919178085
Epoch                        415
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:59:21.430984 UTC | [2020_01_11_13_32_55] Iteration #415 | Epoch Duration: 188.6479434967041
2020-01-12 10:59:21.431163 UTC | [2020_01_11_13_32_55] Iteration #415 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.231857
Z variance train             0.019116048
KL Divergence                29.401505
KL Loss                      2.9401505
QF Loss                      2719.29
VF Loss                      208.09825
Policy Loss                  -1430.1268
Q Predictions Mean           1434.0154
Q Predictions Std            298.68692
Q Predictions Max            1617.397
Q Predictions Min            -247.15947
V Predictions Mean           1433.5784
V Predictions Std            296.29385
V Predictions Max            1617.8792
V Predictions Min            -229.80696
Log Pis Mean                 0.7325867
Log Pis Std                  2.836365
Log Pis Max                  7.619185
Log Pis Min                  -5.7514462
Policy mu Mean               -0.009793162
Policy mu Std                0.6622544
Policy mu Max                3.0571704
Policy mu Min                -2.1033144
Policy log std Mean          -1.0494456
Policy log std Std           0.27614495
Policy log std Max           0.020319581
Policy log std Min           -2.2493782
Z mean eval                  1.2265013
Z variance eval              0.0051068678
total_rewards                [3554.59387792 3492.57859771 4022.70740722 3780.54546087  528.8358749
 3748.57751102  152.61751839 2520.42384789  399.11968326  955.75709982]
total_rewards_mean           2315.5756878998423
total_rewards_std            1531.9638205282633
total_rewards_max            4022.70740722445
total_rewards_min            152.61751839347
Number of train steps total  1668000
Number of env steps total    2087000
Number of rollouts total     0
Train Time (s)               136.3857425157912
(Previous) Eval Time (s)     27.778096420690417
Sample Time (s)              25.499452556017786
Epoch Time (s)               189.6632914924994
Total Train Time (s)         77371.98868666636
Epoch                        416
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:02:28.374919 UTC | [2020_01_11_13_32_55] Iteration #416 | Epoch Duration: 186.9435796737671
2020-01-12 11:02:28.375125 UTC | [2020_01_11_13_32_55] Iteration #416 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2276351
Z variance train             0.005107199
KL Divergence                30.446278
KL Loss                      3.044628
QF Loss                      1057.9814
VF Loss                      259.59946
Policy Loss                  -1375.4136
Q Predictions Mean           1381.209
Q Predictions Std            420.1876
Q Predictions Max            1658.7122
Q Predictions Min            -268.77798
V Predictions Mean           1377.3838
V Predictions Std            419.65082
V Predictions Max            1637.1655
V Predictions Min            -274.22235
Log Pis Mean                 0.94515777
Log Pis Std                  3.5652404
Log Pis Max                  19.925047
Log Pis Min                  -7.3873105
Policy mu Mean               0.0051349225
Policy mu Std                0.6793501
Policy mu Max                4.4940653
Policy mu Min                -3.1699126
Policy log std Mean          -1.0414984
Policy log std Std           0.3167945
Policy log std Max           0.558877
Policy log std Min           -2.7418456
Z mean eval                  1.2390429
Z variance eval              0.013635317
total_rewards                [2112.21808363 3905.25541302 1024.98845866 1008.63786912  683.62359542
 3891.22399934  310.36525696 2209.53336697 1428.79842239 3376.15455146]
total_rewards_mean           1995.0799016968801
total_rewards_std            1265.0775800922
total_rewards_max            3905.255413017368
total_rewards_min            310.3652569594509
Number of train steps total  1672000
Number of env steps total    2092000
Number of rollouts total     0
Train Time (s)               142.70229792175815
(Previous) Eval Time (s)     25.058013095054775
Sample Time (s)              24.8159812935628
Epoch Time (s)               192.57629231037572
Total Train Time (s)         77558.97567613283
Epoch                        417
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:05:35.367122 UTC | [2020_01_11_13_32_55] Iteration #417 | Epoch Duration: 186.99182438850403
2020-01-12 11:05:35.367409 UTC | [2020_01_11_13_32_55] Iteration #417 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2391756
Z variance train             0.013606151
KL Divergence                28.463146
KL Loss                      2.8463147
QF Loss                      4017.4236
VF Loss                      778.8129
Policy Loss                  -1407.0164
Q Predictions Mean           1406.1154
Q Predictions Std            358.79407
Q Predictions Max            1646.7871
Q Predictions Min            -262.49985
V Predictions Mean           1414.4641
V Predictions Std            343.5451
V Predictions Max            1656.4218
V Predictions Min            -280.3722
Log Pis Mean                 1.0329907
Log Pis Std                  3.4308424
Log Pis Max                  17.682426
Log Pis Min                  -7.044825
Policy mu Mean               0.010000784
Policy mu Std                0.67167234
Policy mu Max                2.7197018
Policy mu Min                -2.4758909
Policy log std Mean          -1.0521203
Policy log std Std           0.3338056
Policy log std Max           0.14715016
Policy log std Min           -2.999432
Z mean eval                  1.2683954
Z variance eval              0.009074423
total_rewards                [1186.51657061 3847.25663827 3974.22566445 2716.55641668 1451.37056213
 3594.26277329  273.39199601 1346.16699439 2800.21718317 3635.53992989]
total_rewards_mean           2482.550472888896
total_rewards_std            1253.924324378724
total_rewards_max            3974.225664452204
total_rewards_min            273.3919960119232
Number of train steps total  1676000
Number of env steps total    2097000
Number of rollouts total     0
Train Time (s)               143.59158427128568
(Previous) Eval Time (s)     19.473134129773825
Sample Time (s)              25.4141344120726
Epoch Time (s)               188.4788528131321
Total Train Time (s)         77757.92139517423
Epoch                        418
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:08:54.316804 UTC | [2020_01_11_13_32_55] Iteration #418 | Epoch Duration: 198.94923949241638
2020-01-12 11:08:54.316992 UTC | [2020_01_11_13_32_55] Iteration #418 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2692004
Z variance train             0.009077557
KL Divergence                27.565588
KL Loss                      2.756559
QF Loss                      1591.2498
VF Loss                      272.69128
Policy Loss                  -1405.3517
Q Predictions Mean           1408.0593
Q Predictions Std            362.2209
Q Predictions Max            1632.488
Q Predictions Min            -391.3478
V Predictions Mean           1414.6394
V Predictions Std            360.6315
V Predictions Max            1636.0029
V Predictions Min            -381.52115
Log Pis Mean                 0.45076767
Log Pis Std                  3.0826747
Log Pis Max                  14.791059
Log Pis Min                  -10.167915
Policy mu Mean               0.0077059735
Policy mu Std                0.6655136
Policy mu Max                2.3494146
Policy mu Min                -2.1172736
Policy log std Mean          -1.0356716
Policy log std Std           0.2929181
Policy log std Max           -0.14794493
Policy log std Min           -2.4341154
Z mean eval                  1.3008351
Z variance eval              0.005275688
total_rewards                [1561.57208833  558.54754546 3136.46943772 1446.62942389 2099.35489544
  818.27691753 1965.33546327  235.42840547 3566.69895825  265.05626599]
total_rewards_mean           1565.336940133829
total_rewards_std            1093.814289579902
total_rewards_max            3566.6989582451442
total_rewards_min            235.42840546539458
Number of train steps total  1680000
Number of env steps total    2102000
Number of rollouts total     0
Train Time (s)               142.20391242112964
(Previous) Eval Time (s)     29.943123671226203
Sample Time (s)              26.647418041247874
Epoch Time (s)               198.79445413360372
Total Train Time (s)         77943.859996018
Epoch                        419
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:12:00.259736 UTC | [2020_01_11_13_32_55] Iteration #419 | Epoch Duration: 185.94261169433594
2020-01-12 11:12:00.259906 UTC | [2020_01_11_13_32_55] Iteration #419 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3032614
Z variance train             0.0052753687
KL Divergence                29.56588
KL Loss                      2.956588
QF Loss                      964.3618
VF Loss                      346.7217
Policy Loss                  -1354.4673
Q Predictions Mean           1356.8969
Q Predictions Std            429.37482
Q Predictions Max            1641.3423
Q Predictions Min            -218.15019
V Predictions Mean           1355.2925
V Predictions Std            430.27072
V Predictions Max            1647.3403
V Predictions Min            -229.36923
Log Pis Mean                 0.5625842
Log Pis Std                  3.4014478
Log Pis Max                  11.8240185
Log Pis Min                  -9.95936
Policy mu Mean               0.008907998
Policy mu Std                0.65106744
Policy mu Max                2.4965453
Policy mu Min                -2.4853072
Policy log std Mean          -1.01983
Policy log std Std           0.33224916
Policy log std Max           -0.018418431
Policy log std Min           -2.8642654
Z mean eval                  1.2310688
Z variance eval              0.007899048
total_rewards                [ 909.66195228  219.99249236  711.01686321  841.77895129  280.59887779
 3853.08526052  561.79369024  562.71330046 1143.06881285  448.7919595 ]
total_rewards_mean           953.2502160513639
total_rewards_std            1003.4161300538219
total_rewards_max            3853.0852605212463
total_rewards_min            219.9924923554346
Number of train steps total  1684000
Number of env steps total    2107000
Number of rollouts total     0
Train Time (s)               144.17130394512787
(Previous) Eval Time (s)     17.090862195938826
Sample Time (s)              26.309685349464417
Epoch Time (s)               187.57185149053112
Total Train Time (s)         78122.00097677344
Epoch                        420
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:14:58.405757 UTC | [2020_01_11_13_32_55] Iteration #420 | Epoch Duration: 178.14569449424744
2020-01-12 11:14:58.406061 UTC | [2020_01_11_13_32_55] Iteration #420 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2325721
Z variance train             0.007894638
KL Divergence                28.877716
KL Loss                      2.8877716
QF Loss                      699.5502
VF Loss                      1455.8953
Policy Loss                  -1385.0702
Q Predictions Mean           1389.3273
Q Predictions Std            428.2207
Q Predictions Max            1648.255
Q Predictions Min            -387.3885
V Predictions Mean           1386.0201
V Predictions Std            420.1709
V Predictions Max            1651.3679
V Predictions Min            -397.73166
Log Pis Mean                 0.5765071
Log Pis Std                  3.3956645
Log Pis Max                  19.9863
Log Pis Min                  -6.682662
Policy mu Mean               -0.022010893
Policy mu Std                0.66929424
Policy mu Max                3.634692
Policy mu Min                -3.3258648
Policy log std Mean          -1.0391967
Policy log std Std           0.31900316
Policy log std Max           -0.21569407
Policy log std Min           -3.4664247
Z mean eval                  1.2873788
Z variance eval              0.0134368185
total_rewards                [  20.27019547 1533.86114828 4083.47379125 1218.49880376 2214.52339037
  794.51382964   87.17220322 3961.30642477 2693.84265738 1311.19593205]
total_rewards_mean           1791.8658376173983
total_rewards_std            1364.395226180461
total_rewards_max            4083.4737912492023
total_rewards_min            20.270195468471027
Number of train steps total  1688000
Number of env steps total    2112000
Number of rollouts total     0
Train Time (s)               140.3600132158026
(Previous) Eval Time (s)     7.664260646793991
Sample Time (s)              24.55501224612817
Epoch Time (s)               172.57928610872477
Total Train Time (s)         78307.71186859393
Epoch                        421
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:18:04.120477 UTC | [2020_01_11_13_32_55] Iteration #421 | Epoch Duration: 185.71425461769104
2020-01-12 11:18:04.120692 UTC | [2020_01_11_13_32_55] Iteration #421 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.287895
Z variance train             0.013470841
KL Divergence                28.525076
KL Loss                      2.8525076
QF Loss                      10277.132
VF Loss                      191.64464
Policy Loss                  -1406.0175
Q Predictions Mean           1409.3108
Q Predictions Std            392.9581
Q Predictions Max            1640.6956
Q Predictions Min            -286.75778
V Predictions Mean           1401.7903
V Predictions Std            386.47977
V Predictions Max            1624.5074
V Predictions Min            -297.35583
Log Pis Mean                 0.86346596
Log Pis Std                  3.2460492
Log Pis Max                  20.346928
Log Pis Min                  -8.343275
Policy mu Mean               0.04476317
Policy mu Std                0.6782896
Policy mu Max                2.9301393
Policy mu Min                -3.041908
Policy log std Mean          -1.0271809
Policy log std Std           0.2818089
Policy log std Max           -0.16298062
Policy log std Min           -2.4332504
Z mean eval                  1.2495807
Z variance eval              0.0089939665
total_rewards                [3094.87772024  929.4185005  3883.36799487 2446.09413372 3894.53761276
 3980.2433848  3816.82383269 1911.18212431 1422.84088984 4028.11424771]
total_rewards_mean           2940.750044145555
total_rewards_std            1118.3293172181002
total_rewards_max            4028.114247714134
total_rewards_min            929.4185005009955
Number of train steps total  1692000
Number of env steps total    2117000
Number of rollouts total     0
Train Time (s)               135.60214664041996
(Previous) Eval Time (s)     20.798825004138052
Sample Time (s)              25.08053658157587
Epoch Time (s)               181.48150822613388
Total Train Time (s)         78496.1703506168
Epoch                        422
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:21:12.583405 UTC | [2020_01_11_13_32_55] Iteration #422 | Epoch Duration: 188.4625849723816
2020-01-12 11:21:12.583602 UTC | [2020_01_11_13_32_55] Iteration #422 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2485145
Z variance train             0.008986646
KL Divergence                28.842102
KL Loss                      2.8842103
QF Loss                      2411.8196
VF Loss                      1025.9609
Policy Loss                  -1418.041
Q Predictions Mean           1421.0238
Q Predictions Std            331.26428
Q Predictions Max            1649.3859
Q Predictions Min            -76.440346
V Predictions Mean           1419.5521
V Predictions Std            332.07135
V Predictions Max            1641.1836
V Predictions Min            -80.920044
Log Pis Mean                 0.9649881
Log Pis Std                  2.9362516
Log Pis Max                  12.30198
Log Pis Min                  -6.4159336
Policy mu Mean               -0.05955201
Policy mu Std                0.6661973
Policy mu Max                2.9851043
Policy mu Min                -2.7008903
Policy log std Mean          -1.0435295
Policy log std Std           0.30199656
Policy log std Max           0.0060602427
Policy log std Min           -2.8831844
Z mean eval                  1.2855936
Z variance eval              0.0041629663
total_rewards                [ 804.99562059 4046.77199674 3418.09323533 3244.20752109 3789.05959825
 1696.65425172 1874.5159633  2089.53767042 2694.83360071  155.38618547]
total_rewards_mean           2381.4055643654183
total_rewards_std            1221.6202270848703
total_rewards_max            4046.7719967449657
total_rewards_min            155.38618547309702
Number of train steps total  1696000
Number of env steps total    2122000
Number of rollouts total     0
Train Time (s)               136.1339338598773
(Previous) Eval Time (s)     27.77958095399663
Sample Time (s)              25.333210761658847
Epoch Time (s)               189.24672557553276
Total Train Time (s)         78679.28146059485
Epoch                        423
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:24:15.698920 UTC | [2020_01_11_13_32_55] Iteration #423 | Epoch Duration: 183.11517214775085
2020-01-12 11:24:15.699101 UTC | [2020_01_11_13_32_55] Iteration #423 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2858851
Z variance train             0.004155634
KL Divergence                29.477703
KL Loss                      2.9477704
QF Loss                      2167.6665
VF Loss                      652.8916
Policy Loss                  -1406.0531
Q Predictions Mean           1409.3082
Q Predictions Std            336.36053
Q Predictions Max            1626.0685
Q Predictions Min            -382.66663
V Predictions Mean           1409.7903
V Predictions Std            343.13535
V Predictions Max            1615.0142
V Predictions Min            -378.13184
Log Pis Mean                 0.54490536
Log Pis Std                  3.0337136
Log Pis Max                  15.401152
Log Pis Min                  -8.0151615
Policy mu Mean               -0.0102360435
Policy mu Std                0.6487084
Policy mu Max                3.2394974
Policy mu Min                -2.2687986
Policy log std Mean          -1.0360602
Policy log std Std           0.30516723
Policy log std Max           1.0153965
Policy log std Min           -2.8235993
Z mean eval                  1.2632959
Z variance eval              0.012345757
total_rewards                [   7.62726278  989.17899112 1015.32353686 3038.21031709 2191.38808306
 3713.15360108 4106.11765704 1772.49778046 4064.52426738 1431.96878966]
total_rewards_mean           2232.999028654004
total_rewards_std            1361.610244271068
total_rewards_max            4106.117657044078
total_rewards_min            7.627262775400687
Number of train steps total  1700000
Number of env steps total    2127000
Number of rollouts total     0
Train Time (s)               143.08945602970198
(Previous) Eval Time (s)     21.647724306210876
Sample Time (s)              23.560306436382234
Epoch Time (s)               188.2974867722951
Total Train Time (s)         78867.25511726132
Epoch                        424
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:27:23.675453 UTC | [2020_01_11_13_32_55] Iteration #424 | Epoch Duration: 187.97623467445374
2020-01-12 11:27:23.675593 UTC | [2020_01_11_13_32_55] Iteration #424 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2640326
Z variance train             0.012307743
KL Divergence                28.924467
KL Loss                      2.8924468
QF Loss                      913.7948
VF Loss                      190.23708
Policy Loss                  -1391.9418
Q Predictions Mean           1392.3932
Q Predictions Std            365.0708
Q Predictions Max            1640.0338
Q Predictions Min            -354.4355
V Predictions Mean           1389.9203
V Predictions Std            363.8122
V Predictions Max            1636.7676
V Predictions Min            -368.75082
Log Pis Mean                 0.61089206
Log Pis Std                  3.4325001
Log Pis Max                  21.801361
Log Pis Min                  -7.8461895
Policy mu Mean               -0.015085523
Policy mu Std                0.64715374
Policy mu Max                4.7810755
Policy mu Min                -2.3347514
Policy log std Mean          -1.0653828
Policy log std Std           0.30425325
Policy log std Max           -0.091786146
Policy log std Min           -2.9313383
Z mean eval                  1.2318255
Z variance eval              0.012071735
total_rewards                [3614.99824844 3989.78913732 1253.81311279 3986.18896967 4001.27225935
 1091.90375999 2078.5364165  3645.65524153  152.93350507 4072.63029404]
total_rewards_mean           2788.772094469799
total_rewards_std            1417.7142529250455
total_rewards_max            4072.6302940351607
total_rewards_min            152.93350507014046
Number of train steps total  1704000
Number of env steps total    2132000
Number of rollouts total     0
Train Time (s)               143.31771975709125
(Previous) Eval Time (s)     21.326093778945506
Sample Time (s)              26.7268299437128
Epoch Time (s)               191.37064347974956
Total Train Time (s)         79065.88042159425
Epoch                        425
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:30:42.306059 UTC | [2020_01_11_13_32_55] Iteration #425 | Epoch Duration: 198.630352973938
2020-01-12 11:30:42.306290 UTC | [2020_01_11_13_32_55] Iteration #425 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2325621
Z variance train             0.012080355
KL Divergence                27.815752
KL Loss                      2.7815752
QF Loss                      1487.6387
VF Loss                      572.181
Policy Loss                  -1410.5612
Q Predictions Mean           1412.2122
Q Predictions Std            332.94748
Q Predictions Max            1613.687
Q Predictions Min            -366.98096
V Predictions Mean           1407.3546
V Predictions Std            330.7466
V Predictions Max            1604.3414
V Predictions Min            -390.0275
Log Pis Mean                 0.84629285
Log Pis Std                  3.1695533
Log Pis Max                  12.687093
Log Pis Min                  -7.910288
Policy mu Mean               -0.0064955964
Policy mu Std                0.6510812
Policy mu Max                2.6091454
Policy mu Min                -2.1511514
Policy log std Mean          -1.0882831
Policy log std Std           0.31530762
Policy log std Max           -0.24968207
Policy log std Min           -2.996883
Z mean eval                  1.264521
Z variance eval              0.010345595
total_rewards                [3062.20554454  679.68482638 3787.08437634 3771.94450802 2430.05314721
 3722.7653441  2274.78147569  176.80870869 1730.66694168 1183.29541635]
total_rewards_mean           2281.92902890047
total_rewards_std            1253.0792101233928
total_rewards_max            3787.084376337107
total_rewards_min            176.80870869274713
Number of train steps total  1708000
Number of env steps total    2137000
Number of rollouts total     0
Train Time (s)               142.49689171323553
(Previous) Eval Time (s)     28.58542203065008
Sample Time (s)              26.052174725569785
Epoch Time (s)               197.1344884694554
Total Train Time (s)         79257.16825843183
Epoch                        426
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:33:53.599594 UTC | [2020_01_11_13_32_55] Iteration #426 | Epoch Duration: 191.29313015937805
2020-01-12 11:33:53.599895 UTC | [2020_01_11_13_32_55] Iteration #426 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2679183
Z variance train             0.010348982
KL Divergence                29.78112
KL Loss                      2.978112
QF Loss                      1427.8196
VF Loss                      417.6079
Policy Loss                  -1413.1948
Q Predictions Mean           1416.0385
Q Predictions Std            374.09232
Q Predictions Max            1635.8218
Q Predictions Min            -346.39783
V Predictions Mean           1407.2723
V Predictions Std            371.2795
V Predictions Max            1625.13
V Predictions Min            -376.37198
Log Pis Mean                 1.0876253
Log Pis Std                  3.3915784
Log Pis Max                  13.877199
Log Pis Min                  -5.519979
Policy mu Mean               0.008351962
Policy mu Std                0.7026666
Policy mu Max                2.8745098
Policy mu Min                -2.4952507
Policy log std Mean          -1.0627856
Policy log std Std           0.30515262
Policy log std Max           0.15315485
Policy log std Min           -2.6808033
Z mean eval                  1.2635611
Z variance eval              0.0075493967
total_rewards                [3782.84377561 2789.98411781 1812.83065139 1242.12284215 1216.94655579
 1552.11476041  382.8076707  4031.75744549  480.49830519   85.81485411]
total_rewards_mean           1737.7720978649272
total_rewards_std            1313.5636895242098
total_rewards_max            4031.7574454936985
total_rewards_min            85.81485410666114
Number of train steps total  1712000
Number of env steps total    2142000
Number of rollouts total     0
Train Time (s)               143.25793222291395
(Previous) Eval Time (s)     22.743730776943266
Sample Time (s)              24.79397843591869
Epoch Time (s)               190.7956414357759
Total Train Time (s)         79451.09885123698
Epoch                        427
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:37:07.534385 UTC | [2020_01_11_13_32_55] Iteration #427 | Epoch Duration: 193.9343297481537
2020-01-12 11:37:07.534580 UTC | [2020_01_11_13_32_55] Iteration #427 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2667581
Z variance train             0.007523802
KL Divergence                30.621115
KL Loss                      3.0621116
QF Loss                      819.7727
VF Loss                      299.90796
Policy Loss                  -1428.6537
Q Predictions Mean           1429.373
Q Predictions Std            372.2951
Q Predictions Max            1640.1536
Q Predictions Min            -389.22952
V Predictions Mean           1427.8542
V Predictions Std            371.5389
V Predictions Max            1643.5017
V Predictions Min            -384.78668
Log Pis Mean                 0.83667624
Log Pis Std                  3.1415138
Log Pis Max                  13.934071
Log Pis Min                  -6.762699
Policy mu Mean               0.028974492
Policy mu Std                0.65453386
Policy mu Max                2.7708943
Policy mu Min                -3.3724945
Policy log std Mean          -1.0492117
Policy log std Std           0.30612412
Policy log std Max           0.7600205
Policy log std Min           -2.8471928
Z mean eval                  1.230552
Z variance eval              0.0067230635
total_rewards                [ 644.62340335  890.06110273   67.93446798 1047.12388173 3006.08089514
  953.49119876 1712.3710804   239.03275854  718.87237663 2582.22855499]
total_rewards_mean           1186.181972026014
total_rewards_std            914.2349753647077
total_rewards_max            3006.0808951449535
total_rewards_min            67.93446798163512
Number of train steps total  1716000
Number of env steps total    2147000
Number of rollouts total     0
Train Time (s)               139.31975980335847
(Previous) Eval Time (s)     25.881982593331486
Sample Time (s)              26.706580732949078
Epoch Time (s)               191.90832312963903
Total Train Time (s)         79635.85785748437
Epoch                        428
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:40:12.298602 UTC | [2020_01_11_13_32_55] Iteration #428 | Epoch Duration: 184.76388478279114
2020-01-12 11:40:12.298798 UTC | [2020_01_11_13_32_55] Iteration #428 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2303298
Z variance train             0.0067124367
KL Divergence                30.961168
KL Loss                      3.0961168
QF Loss                      1294.4543
VF Loss                      152.95667
Policy Loss                  -1400.1782
Q Predictions Mean           1402.2397
Q Predictions Std            376.21216
Q Predictions Max            1629.3037
Q Predictions Min            -337.63995
V Predictions Mean           1399.9529
V Predictions Std            379.92853
V Predictions Max            1629.9501
V Predictions Min            -369.49118
Log Pis Mean                 0.8776453
Log Pis Std                  2.955422
Log Pis Max                  14.97942
Log Pis Min                  -6.2315807
Policy mu Mean               0.046258632
Policy mu Std                0.65429133
Policy mu Max                3.2348518
Policy mu Min                -2.8595197
Policy log std Mean          -1.0766664
Policy log std Std           0.3007962
Policy log std Max           -0.0033496618
Policy log std Min           -2.3440125
Z mean eval                  1.2395483
Z variance eval              0.01408862
total_rewards                [3976.02730085 4133.94243217 2359.18459399 2487.72034382 4184.81567284
 4197.09058951 1488.67359869 3858.97376207 4015.86494132  273.89391287]
total_rewards_mean           3097.618714812583
total_rewards_std            1309.145861925454
total_rewards_max            4197.090589505438
total_rewards_min            273.8939128719795
Number of train steps total  1720000
Number of env steps total    2152000
Number of rollouts total     0
Train Time (s)               135.75837066210806
(Previous) Eval Time (s)     18.73715933971107
Sample Time (s)              24.66801586886868
Epoch Time (s)               179.1635458706878
Total Train Time (s)         79822.23897522828
Epoch                        429
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:43:18.684264 UTC | [2020_01_11_13_32_55] Iteration #429 | Epoch Duration: 186.38531827926636
2020-01-12 11:43:18.684518 UTC | [2020_01_11_13_32_55] Iteration #429 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.242698
Z variance train             0.014117512
KL Divergence                30.55407
KL Loss                      3.055407
QF Loss                      868.8701
VF Loss                      243.86325
Policy Loss                  -1434.5383
Q Predictions Mean           1439.7505
Q Predictions Std            302.69568
Q Predictions Max            1611.8114
Q Predictions Min            -315.09607
V Predictions Mean           1432.655
V Predictions Std            303.72668
V Predictions Max            1613.6556
V Predictions Min            -340.72983
Log Pis Mean                 0.93279636
Log Pis Std                  3.1276684
Log Pis Max                  15.81395
Log Pis Min                  -7.8030834
Policy mu Mean               0.070327595
Policy mu Std                0.6464955
Policy mu Max                3.6768425
Policy mu Min                -2.4797766
Policy log std Mean          -1.0970705
Policy log std Std           0.27314883
Policy log std Max           -0.0710336
Policy log std Min           -2.5858755
Z mean eval                  1.2566993
Z variance eval              0.01708978
total_rewards                [1173.94101627 4076.57836372  232.66389195  921.37820582 2369.07543461
   86.24034443 2152.00389321 4000.35675969  249.01140239 3838.87088275]
total_rewards_mean           1910.0120194855285
total_rewards_std            1532.0282931554527
total_rewards_max            4076.5783637240193
total_rewards_min            86.24034443265259
Number of train steps total  1724000
Number of env steps total    2157000
Number of rollouts total     0
Train Time (s)               138.3697291072458
(Previous) Eval Time (s)     25.95849471213296
Sample Time (s)              25.22505268501118
Epoch Time (s)               189.55327650438994
Total Train Time (s)         80001.62913760403
Epoch                        430
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:46:18.079352 UTC | [2020_01_11_13_32_55] Iteration #430 | Epoch Duration: 179.39465188980103
2020-01-12 11:46:18.079636 UTC | [2020_01_11_13_32_55] Iteration #430 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.253712
Z variance train             0.017142214
KL Divergence                30.671926
KL Loss                      3.0671928
QF Loss                      1078.0691
VF Loss                      273.8469
Policy Loss                  -1417.311
Q Predictions Mean           1422.0996
Q Predictions Std            369.14444
Q Predictions Max            1638.7555
Q Predictions Min            -305.16895
V Predictions Mean           1423.9934
V Predictions Std            370.49182
V Predictions Max            1644.6957
V Predictions Min            -305.43976
Log Pis Mean                 0.52419853
Log Pis Std                  3.1540534
Log Pis Max                  11.153641
Log Pis Min                  -7.067037
Policy mu Mean               0.014018163
Policy mu Std                0.65254325
Policy mu Max                2.5882523
Policy mu Min                -2.959487
Policy log std Mean          -1.0678688
Policy log std Std           0.31327295
Policy log std Max           0.3861606
Policy log std Min           -3.0377278
Z mean eval                  1.210602
Z variance eval              0.015902087
total_rewards                [ 235.25681518 2063.55418154 4079.51297157 4083.82027763 3875.95965539
 3850.01622778 2298.82499966 1754.62825392  632.33414324 4099.18908155]
total_rewards_mean           2697.309660746717
total_rewards_std            1424.4656613193374
total_rewards_max            4099.189081549677
total_rewards_min            235.25681518238804
Number of train steps total  1728000
Number of env steps total    2162000
Number of rollouts total     0
Train Time (s)               146.1432235389948
(Previous) Eval Time (s)     15.799554897006601
Sample Time (s)              24.26120886579156
Epoch Time (s)               186.20398730179295
Total Train Time (s)         80195.91855056817
Epoch                        431
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:49:32.372869 UTC | [2020_01_11_13_32_55] Iteration #431 | Epoch Duration: 194.29308199882507
2020-01-12 11:49:32.373049 UTC | [2020_01_11_13_32_55] Iteration #431 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2086354
Z variance train             0.015812874
KL Divergence                29.166906
KL Loss                      2.9166906
QF Loss                      3494.769
VF Loss                      877.6579
Policy Loss                  -1392.0789
Q Predictions Mean           1391.8083
Q Predictions Std            367.2175
Q Predictions Max            1617.3687
Q Predictions Min            -303.34576
V Predictions Mean           1387.6189
V Predictions Std            356.13217
V Predictions Max            1609.1216
V Predictions Min            -297.6186
Log Pis Mean                 1.0414132
Log Pis Std                  3.4474072
Log Pis Max                  20.645607
Log Pis Min                  -5.462215
Policy mu Mean               -0.024747618
Policy mu Std                0.6662954
Policy mu Max                3.8804624
Policy mu Min                -2.830677
Policy log std Mean          -1.0633745
Policy log std Std           0.3432162
Policy log std Max           1.3640571
Policy log std Min           -3.2643902
Z mean eval                  1.2349881
Z variance eval              0.027552212
total_rewards                [3753.33995814 1023.33566293 1315.27135237 2609.78847424  305.66971802
 3940.45676704 3816.18316211 2895.32709081 1018.53883723 1057.22919797]
total_rewards_mean           2173.514022085435
total_rewards_std            1309.810697313554
total_rewards_max            3940.456767037446
total_rewards_min            305.66971801559777
Number of train steps total  1732000
Number of env steps total    2167000
Number of rollouts total     0
Train Time (s)               144.98489522980526
(Previous) Eval Time (s)     23.8883107136935
Sample Time (s)              26.07142798602581
Epoch Time (s)               194.94463392952457
Total Train Time (s)         80394.03628340829
Epoch                        432
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:52:50.496230 UTC | [2020_01_11_13_32_55] Iteration #432 | Epoch Duration: 198.12302207946777
2020-01-12 11:52:50.496518 UTC | [2020_01_11_13_32_55] Iteration #432 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2364328
Z variance train             0.027615283
KL Divergence                27.49382
KL Loss                      2.749382
QF Loss                      3199.8364
VF Loss                      186.2263
Policy Loss                  -1439.4962
Q Predictions Mean           1445.2402
Q Predictions Std            345.99713
Q Predictions Max            1675.449
Q Predictions Min            -357.0382
V Predictions Mean           1439.4645
V Predictions Std            349.13904
V Predictions Max            1656.0023
V Predictions Min            -361.60263
Log Pis Mean                 0.98859894
Log Pis Std                  3.104753
Log Pis Max                  11.699804
Log Pis Min                  -7.2214155
Policy mu Mean               0.020808782
Policy mu Std                0.6702915
Policy mu Max                2.9692566
Policy mu Min                -2.511463
Policy log std Mean          -1.0592985
Policy log std Std           0.31694484
Policy log std Max           -0.07386565
Policy log std Min           -2.8715885
Z mean eval                  1.3054636
Z variance eval              0.018812997
total_rewards                [2757.6885297  2491.42095039 1508.97668099 2941.05656663   37.29642016
 3264.74215667 4082.76576442 1602.05313923  263.87747413  153.29445169]
total_rewards_mean           1910.317213400612
total_rewards_std            1350.346015042775
total_rewards_max            4082.7657644175533
total_rewards_min            37.29642015963566
Number of train steps total  1736000
Number of env steps total    2172000
Number of rollouts total     0
Train Time (s)               144.61983552202582
(Previous) Eval Time (s)     27.066261387895793
Sample Time (s)              25.284148055128753
Epoch Time (s)               196.97024496505037
Total Train Time (s)         80592.32800615206
Epoch                        433
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:56:08.792014 UTC | [2020_01_11_13_32_55] Iteration #433 | Epoch Duration: 198.29534363746643
2020-01-12 11:56:08.792192 UTC | [2020_01_11_13_32_55] Iteration #433 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3053135
Z variance train             0.018711224
KL Divergence                27.732086
KL Loss                      2.7732086
QF Loss                      750.012
VF Loss                      335.89172
Policy Loss                  -1403.1621
Q Predictions Mean           1408.8748
Q Predictions Std            399.37732
Q Predictions Max            1626.8793
Q Predictions Min            -375.47858
V Predictions Mean           1392.261
V Predictions Std            398.63104
V Predictions Max            1608.8533
V Predictions Min            -366.66132
Log Pis Mean                 0.5446435
Log Pis Std                  3.1130383
Log Pis Max                  11.318591
Log Pis Min                  -8.251936
Policy mu Mean               0.005879119
Policy mu Std                0.63680047
Policy mu Max                3.0363955
Policy mu Min                -2.636908
Policy log std Mean          -1.0483656
Policy log std Std           0.26833043
Policy log std Max           -0.18621325
Policy log std Min           -2.2760425
Z mean eval                  1.2524118
Z variance eval              0.01995628
total_rewards                [ 986.15286078  666.33409826  115.40998497 3700.74550228 2240.53088867
 3293.57077313 3635.64011533 1321.8660037   272.1175674  3778.38107837]
total_rewards_mean           2001.074887288801
total_rewards_std            1423.5636870809094
total_rewards_max            3778.3810783744975
total_rewards_min            115.40998497321084
Number of train steps total  1740000
Number of env steps total    2177000
Number of rollouts total     0
Train Time (s)               143.6713238582015
(Previous) Eval Time (s)     28.391029816586524
Sample Time (s)              25.960999109316617
Epoch Time (s)               198.02335278410465
Total Train Time (s)         80783.79201140627
Epoch                        434
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:59:20.261172 UTC | [2020_01_11_13_32_55] Iteration #434 | Epoch Duration: 191.4688262939453
2020-01-12 11:59:20.261488 UTC | [2020_01_11_13_32_55] Iteration #434 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2521292
Z variance train             0.019953752
KL Divergence                29.188393
KL Loss                      2.9188392
QF Loss                      1130.0687
VF Loss                      950.65656
Policy Loss                  -1421.519
Q Predictions Mean           1424.8484
Q Predictions Std            352.50333
Q Predictions Max            1650.1178
Q Predictions Min            -282.46576
V Predictions Mean           1416.6506
V Predictions Std            354.14664
V Predictions Max            1649.1526
V Predictions Min            -282.74646
Log Pis Mean                 0.83041465
Log Pis Std                  3.341551
Log Pis Max                  15.480137
Log Pis Min                  -7.3876634
Policy mu Mean               0.04995815
Policy mu Std                0.6673966
Policy mu Max                2.7695608
Policy mu Min                -3.665324
Policy log std Mean          -1.0655832
Policy log std Std           0.32537642
Policy log std Max           0.90612936
Policy log std Min           -2.904704
Z mean eval                  1.2020197
Z variance eval              0.020517478
total_rewards                [3027.54888396 3972.31543356  383.25405027 1257.59481964 2627.42303912
 3921.09639743 2823.3077939  3951.62892254 3983.92161689  355.76917578]
total_rewards_mean           2630.3860133106027
total_rewards_std            1390.9512837165983
total_rewards_max            3983.921616892919
total_rewards_min            355.76917578484984
Number of train steps total  1744000
Number of env steps total    2182000
Number of rollouts total     0
Train Time (s)               136.9700789307244
(Previous) Eval Time (s)     21.836075908038765
Sample Time (s)              24.33362859301269
Epoch Time (s)               183.13978343177587
Total Train Time (s)         80971.0035851486
Epoch                        435
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:02:27.474884 UTC | [2020_01_11_13_32_55] Iteration #435 | Epoch Duration: 187.2132053375244
2020-01-12 12:02:27.475001 UTC | [2020_01_11_13_32_55] Iteration #435 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2014949
Z variance train             0.020484773
KL Divergence                27.734903
KL Loss                      2.7734904
QF Loss                      1279.9797
VF Loss                      939.87537
Policy Loss                  -1375.3661
Q Predictions Mean           1375.8898
Q Predictions Std            406.21762
Q Predictions Max            1640.4377
Q Predictions Min            -360.53903
V Predictions Mean           1381.0862
V Predictions Std            403.973
V Predictions Max            1632.5708
V Predictions Min            -348.00906
Log Pis Mean                 0.648807
Log Pis Std                  3.3521693
Log Pis Max                  16.84834
Log Pis Min                  -8.348064
Policy mu Mean               0.0011636578
Policy mu Std                0.6633884
Policy mu Max                3.5224178
Policy mu Min                -3.0468588
Policy log std Mean          -1.0165515
Policy log std Std           0.2909297
Policy log std Max           -0.08591986
Policy log std Min           -2.3690643
Z mean eval                  1.2229172
Z variance eval              0.020805676
total_rewards                [ 477.53292463 4053.02786714 3945.56880088 2518.42535349 4105.55865537
  486.99839805  993.76816259 3044.6627059  4076.99186217 1028.51942778]
total_rewards_mean           2473.105415799476
total_rewards_std            1497.7512596051547
total_rewards_max            4105.558655369192
total_rewards_min            477.53292462529583
Number of train steps total  1748000
Number of env steps total    2187000
Number of rollouts total     0
Train Time (s)               135.18444126099348
(Previous) Eval Time (s)     25.90913808438927
Sample Time (s)              23.61009804997593
Epoch Time (s)               184.70367739535868
Total Train Time (s)         81152.51853774535
Epoch                        436
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:05:28.994901 UTC | [2020_01_11_13_32_55] Iteration #436 | Epoch Duration: 181.51979517936707
2020-01-12 12:05:28.995118 UTC | [2020_01_11_13_32_55] Iteration #436 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2212875
Z variance train             0.020800972
KL Divergence                28.731606
KL Loss                      2.8731606
QF Loss                      1202.1235
VF Loss                      208.85419
Policy Loss                  -1428.2202
Q Predictions Mean           1426.2827
Q Predictions Std            319.86554
Q Predictions Max            1649.4503
Q Predictions Min            -320.8932
V Predictions Mean           1429.3304
V Predictions Std            308.7825
V Predictions Max            1649.1825
V Predictions Min            -313.47104
Log Pis Mean                 0.7916845
Log Pis Std                  3.2192285
Log Pis Max                  13.342666
Log Pis Min                  -11.383381
Policy mu Mean               0.0004953495
Policy mu Std                0.69395614
Policy mu Max                2.892344
Policy mu Min                -2.2941878
Policy log std Mean          -1.0425508
Policy log std Std           0.30147848
Policy log std Max           -0.2099607
Policy log std Min           -2.7182367
Z mean eval                  1.2736487
Z variance eval              0.009780065
total_rewards                [3803.15737285 1968.3966502  3932.99685904  599.04484871  819.01951919
  226.1557395  3800.56161499 4160.62883449  369.41518533 2774.59109635]
total_rewards_mean           2245.3967720658948
total_rewards_std            1551.1191884988064
total_rewards_max            4160.628834494139
total_rewards_min            226.1557394983532
Number of train steps total  1752000
Number of env steps total    2192000
Number of rollouts total     0
Train Time (s)               141.15469637792557
(Previous) Eval Time (s)     22.724936929065734
Sample Time (s)              23.971477617509663
Epoch Time (s)               187.85111092450097
Total Train Time (s)         81340.98638894549
Epoch                        437
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:08:37.467375 UTC | [2020_01_11_13_32_55] Iteration #437 | Epoch Duration: 188.47210264205933
2020-01-12 12:08:37.467565 UTC | [2020_01_11_13_32_55] Iteration #437 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2721211
Z variance train             0.009778756
KL Divergence                29.239023
KL Loss                      2.9239023
QF Loss                      1143.9692
VF Loss                      383.5668
Policy Loss                  -1393.1329
Q Predictions Mean           1394.6655
Q Predictions Std            377.87375
Q Predictions Max            1626.2502
Q Predictions Min            -328.577
V Predictions Mean           1390.5999
V Predictions Std            366.72968
V Predictions Max            1611.8168
V Predictions Min            -331.57086
Log Pis Mean                 0.6396005
Log Pis Std                  3.2845845
Log Pis Max                  17.511486
Log Pis Min                  -7.7895513
Policy mu Mean               -0.0038275905
Policy mu Std                0.65406656
Policy mu Max                2.6116893
Policy mu Min                -3.444463
Policy log std Mean          -1.0519999
Policy log std Std           0.3073726
Policy log std Max           -0.09716809
Policy log std Min           -2.7525046
Z mean eval                  1.2533174
Z variance eval              0.007972682
total_rewards                [  16.4646905   111.51985907 1237.5896062  1258.10050471  685.99152313
 3666.68324327 1827.73039498  421.14778005 3807.477013   1454.03390813]
total_rewards_mean           1448.6738523051358
total_rewards_std            1272.1950876741016
total_rewards_max            3807.477013003029
total_rewards_min            16.464690498617742
Number of train steps total  1756000
Number of env steps total    2197000
Number of rollouts total     0
Train Time (s)               144.44887179275975
(Previous) Eval Time (s)     23.345628635957837
Sample Time (s)              25.491568692028522
Epoch Time (s)               193.2860691207461
Total Train Time (s)         81529.79108674033
Epoch                        438
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:11:46.276313 UTC | [2020_01_11_13_32_55] Iteration #438 | Epoch Duration: 188.8086154460907
2020-01-12 12:11:46.276489 UTC | [2020_01_11_13_32_55] Iteration #438 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2544132
Z variance train             0.00794883
KL Divergence                30.162716
KL Loss                      3.0162716
QF Loss                      691.8701
VF Loss                      307.59146
Policy Loss                  -1383.2351
Q Predictions Mean           1384.8578
Q Predictions Std            409.1676
Q Predictions Max            1645.1859
Q Predictions Min            -343.1371
V Predictions Mean           1381.6677
V Predictions Std            404.9524
V Predictions Max            1631.3387
V Predictions Min            -339.38766
Log Pis Mean                 0.8933073
Log Pis Std                  3.5609426
Log Pis Max                  20.38468
Log Pis Min                  -5.6250105
Policy mu Mean               0.04872668
Policy mu Std                0.7143508
Policy mu Max                4.801188
Policy mu Min                -5.7660193
Policy log std Mean          -1.04298
Policy log std Std           0.34078637
Policy log std Max           0.3470292
Policy log std Min           -2.935165
Z mean eval                  1.27474
Z variance eval              0.02244419
total_rewards                [ 400.61604478  299.75989854 3962.37039583 2000.77598326 1110.81840818
  859.98694242 1168.51719555  224.03645026  898.31769389 1026.69340931]
total_rewards_mean           1195.189242203535
total_rewards_std            1044.9523211426392
total_rewards_max            3962.3703958337514
total_rewards_min            224.0364502641344
Number of train steps total  1760000
Number of env steps total    2202000
Number of rollouts total     0
Train Time (s)               143.3062842329964
(Previous) Eval Time (s)     18.86783896619454
Sample Time (s)              26.254715737886727
Epoch Time (s)               188.42883893707767
Total Train Time (s)         81713.45515894005
Epoch                        439
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:14:49.946249 UTC | [2020_01_11_13_32_55] Iteration #439 | Epoch Duration: 183.66961646080017
2020-01-12 12:14:49.946517 UTC | [2020_01_11_13_32_55] Iteration #439 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2733176
Z variance train             0.022499157
KL Divergence                27.375206
KL Loss                      2.7375207
QF Loss                      1711.9541
VF Loss                      708.97455
Policy Loss                  -1378.0759
Q Predictions Mean           1380.8325
Q Predictions Std            434.06613
Q Predictions Max            1640.0382
Q Predictions Min            -347.07397
V Predictions Mean           1378.3845
V Predictions Std            432.07468
V Predictions Max            1656.5454
V Predictions Min            -342.1046
Log Pis Mean                 1.1219902
Log Pis Std                  3.955951
Log Pis Max                  22.232033
Log Pis Min                  -6.317319
Policy mu Mean               0.021231119
Policy mu Std                0.6647333
Policy mu Max                4.249076
Policy mu Min                -3.055108
Policy log std Mean          -1.0900037
Policy log std Std           0.35558
Policy log std Max           0.18428397
Policy log std Min           -3.2567608
Z mean eval                  1.2445217
Z variance eval              0.025332486
total_rewards                [3347.28289161 3812.15681974 3838.44172188 3954.57764323  581.99987462
 3933.54388587 3930.24180764 3886.20100105 3848.59909817 4048.97118862]
total_rewards_mean           3518.2015932425384
total_rewards_std            994.9105489596446
total_rewards_max            4048.971188615067
total_rewards_min            581.9998746169779
Number of train steps total  1764000
Number of env steps total    2207000
Number of rollouts total     0
Train Time (s)               144.1241650772281
(Previous) Eval Time (s)     14.10816447623074
Sample Time (s)              25.91696995543316
Epoch Time (s)               184.149299508892
Total Train Time (s)         81913.07312654331
Epoch                        440
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:18:09.569647 UTC | [2020_01_11_13_32_55] Iteration #440 | Epoch Duration: 199.62295579910278
2020-01-12 12:18:09.569929 UTC | [2020_01_11_13_32_55] Iteration #440 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2415994
Z variance train             0.025273472
KL Divergence                27.58397
KL Loss                      2.7583969
QF Loss                      825.5164
VF Loss                      266.22086
Policy Loss                  -1405.1764
Q Predictions Mean           1410.3683
Q Predictions Std            372.2159
Q Predictions Max            1649.1805
Q Predictions Min            -426.82578
V Predictions Mean           1408.0256
V Predictions Std            371.71704
V Predictions Max            1628.358
V Predictions Min            -262.52042
Log Pis Mean                 0.6485394
Log Pis Std                  3.1496828
Log Pis Max                  17.408524
Log Pis Min                  -9.35979
Policy mu Mean               -0.030523904
Policy mu Std                0.6816392
Policy mu Max                2.7471824
Policy mu Min                -3.106864
Policy log std Mean          -1.0117618
Policy log std Std           0.28949976
Policy log std Max           -0.17452556
Policy log std Min           -3.443029
Z mean eval                  1.2648371
Z variance eval              0.0151446
total_rewards                [1021.5158046  1315.94204394  944.71399459 2636.21729625 3898.88099149
 1202.27635395 1873.72689878 1096.75665052 3672.68644299  790.2231747 ]
total_rewards_mean           1845.2939651802685
total_rewards_std            1097.2590131970287
total_rewards_max            3898.8809914879266
total_rewards_min            790.2231747035781
Number of train steps total  1768000
Number of env steps total    2212000
Number of rollouts total     0
Train Time (s)               141.6816720268689
(Previous) Eval Time (s)     29.581381684169173
Sample Time (s)              25.59294122690335
Epoch Time (s)               196.85599493794143
Total Train Time (s)         82099.55616329145
Epoch                        441
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:21:16.056573 UTC | [2020_01_11_13_32_55] Iteration #441 | Epoch Duration: 186.4864890575409
2020-01-12 12:21:16.056755 UTC | [2020_01_11_13_32_55] Iteration #441 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2652617
Z variance train             0.015142647
KL Divergence                29.281515
KL Loss                      2.9281516
QF Loss                      1613.9126
VF Loss                      387.95844
Policy Loss                  -1388.868
Q Predictions Mean           1389.5663
Q Predictions Std            400.36224
Q Predictions Max            1631.0325
Q Predictions Min            -258.7786
V Predictions Mean           1397.0416
V Predictions Std            401.01746
V Predictions Max            1642.3246
V Predictions Min            -241.28644
Log Pis Mean                 0.75772285
Log Pis Std                  3.3665068
Log Pis Max                  13.909864
Log Pis Min                  -8.315958
Policy mu Mean               -0.0044831173
Policy mu Std                0.6548921
Policy mu Max                2.5845406
Policy mu Min                -2.714958
Policy log std Mean          -1.0419605
Policy log std Std           0.31415093
Policy log std Max           -0.29121208
Policy log std Min           -2.497333
Z mean eval                  1.2952487
Z variance eval              0.012018061
total_rewards                [2883.0634704  2441.61452173 2129.70440625 3592.30036802 4064.34822472
 1989.71419266 2689.96035598 3515.71192411  256.84605039 1470.3191215 ]
total_rewards_mean           2503.3582635764333
total_rewards_std            1065.250562262696
total_rewards_max            4064.3482247214884
total_rewards_min            256.8460503889792
Number of train steps total  1772000
Number of env steps total    2217000
Number of rollouts total     0
Train Time (s)               135.80631253216416
(Previous) Eval Time (s)     19.211444716900587
Sample Time (s)              23.508658844046295
Epoch Time (s)               178.52641609311104
Total Train Time (s)         82282.71186130866
Epoch                        442
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:24:19.216600 UTC | [2020_01_11_13_32_55] Iteration #442 | Epoch Duration: 183.15971302986145
2020-01-12 12:24:19.216781 UTC | [2020_01_11_13_32_55] Iteration #442 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2954571
Z variance train             0.012050335
KL Divergence                28.876358
KL Loss                      2.887636
QF Loss                      1400.6604
VF Loss                      275.27866
Policy Loss                  -1403.4814
Q Predictions Mean           1407.8981
Q Predictions Std            417.01556
Q Predictions Max            1663.526
Q Predictions Min            -233.52728
V Predictions Mean           1405.1973
V Predictions Std            419.92725
V Predictions Max            1659.5723
V Predictions Min            -259.1997
Log Pis Mean                 0.8997667
Log Pis Std                  3.185724
Log Pis Max                  13.978014
Log Pis Min                  -7.447263
Policy mu Mean               -0.0063340273
Policy mu Std                0.6699194
Policy mu Max                2.883973
Policy mu Min                -2.4615068
Policy log std Mean          -1.0518787
Policy log std Std           0.31535715
Policy log std Max           -0.13300717
Policy log std Min           -2.466388
Z mean eval                  1.2469913
Z variance eval              0.02212438
total_rewards                [3671.36512774 3977.08381156 3914.55346766 3967.50562258 3207.19027978
 1222.23484115 4188.14537587 2227.18851581 2189.6177715  4115.34896987]
total_rewards_mean           3268.02337835317
total_rewards_std            978.3946161060281
total_rewards_max            4188.145375870143
total_rewards_min            1222.2348411489463
Number of train steps total  1776000
Number of env steps total    2222000
Number of rollouts total     0
Train Time (s)               135.16197600914165
(Previous) Eval Time (s)     23.84439683286473
Sample Time (s)              24.056476266589016
Epoch Time (s)               183.0628491085954
Total Train Time (s)         82471.92926239362
Epoch                        443
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:27:28.438514 UTC | [2020_01_11_13_32_55] Iteration #443 | Epoch Duration: 189.22159695625305
2020-01-12 12:27:28.438703 UTC | [2020_01_11_13_32_55] Iteration #443 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2480816
Z variance train             0.022109268
KL Divergence                27.218279
KL Loss                      2.721828
QF Loss                      1510.1335
VF Loss                      906.07263
Policy Loss                  -1398.0564
Q Predictions Mean           1397.4731
Q Predictions Std            401.0297
Q Predictions Max            1657.9313
Q Predictions Min            -406.79803
V Predictions Mean           1393.0974
V Predictions Std            390.26166
V Predictions Max            1642.2257
V Predictions Min            -408.32874
Log Pis Mean                 0.8522246
Log Pis Std                  3.5220618
Log Pis Max                  17.091785
Log Pis Min                  -8.726079
Policy mu Mean               0.0071333814
Policy mu Std                0.66103417
Policy mu Max                2.7928562
Policy mu Min                -2.4927711
Policy log std Mean          -1.0564021
Policy log std Std           0.31128937
Policy log std Max           -0.234505
Policy log std Min           -2.9193902
Z mean eval                  1.2522672
Z variance eval              0.015602713
total_rewards                [ 196.81372809 1111.06355088 3398.46387238 3989.3862539  1309.77021806
  669.24162145 3878.97268523 3954.41976077 3809.30042686 2105.42935195]
total_rewards_mean           2442.286146956978
total_rewards_std            1445.0325464628434
total_rewards_max            3989.386253896924
total_rewards_min            196.81372809237155
Number of train steps total  1780000
Number of env steps total    2227000
Number of rollouts total     0
Train Time (s)               142.84605687391013
(Previous) Eval Time (s)     30.002849054988474
Sample Time (s)              25.87991144414991
Epoch Time (s)               198.7288173730485
Total Train Time (s)         82665.04130040715
Epoch                        444
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:30:41.556203 UTC | [2020_01_11_13_32_55] Iteration #444 | Epoch Duration: 193.11731910705566
2020-01-12 12:30:41.556522 UTC | [2020_01_11_13_32_55] Iteration #444 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2527678
Z variance train             0.015607022
KL Divergence                27.464682
KL Loss                      2.7464683
QF Loss                      2057.0408
VF Loss                      224.31387
Policy Loss                  -1410.8323
Q Predictions Mean           1406.7365
Q Predictions Std            373.00943
Q Predictions Max            1643.9865
Q Predictions Min            -264.929
V Predictions Mean           1415.2051
V Predictions Std            365.04044
V Predictions Max            1636.3761
V Predictions Min            -250.60559
Log Pis Mean                 1.0219535
Log Pis Std                  3.4418314
Log Pis Max                  15.116128
Log Pis Min                  -9.432441
Policy mu Mean               0.014405534
Policy mu Std                0.6808587
Policy mu Max                2.550395
Policy mu Min                -2.488457
Policy log std Mean          -1.0627537
Policy log std Std           0.3049445
Policy log std Max           -0.06437755
Policy log std Min           -2.7206583
Z mean eval                  1.2616129
Z variance eval              0.021193005
total_rewards                [3910.09441925 3428.88937928 3768.7957964   989.0173841  4051.31816601
 3635.10330139 3824.01565096 3009.70228183 3947.76780744 2098.48080398]
total_rewards_mean           3266.3184990646832
total_rewards_std            940.0416626258279
total_rewards_max            4051.3181660144505
total_rewards_min            989.0173841026451
Number of train steps total  1784000
Number of env steps total    2232000
Number of rollouts total     0
Train Time (s)               144.23193085100502
(Previous) Eval Time (s)     24.39087810460478
Sample Time (s)              24.956854434218258
Epoch Time (s)               193.57966338982806
Total Train Time (s)         82865.70273688808
Epoch                        445
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:34:02.221670 UTC | [2020_01_11_13_32_55] Iteration #445 | Epoch Duration: 200.66498470306396
2020-01-12 12:34:02.221868 UTC | [2020_01_11_13_32_55] Iteration #445 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2626933
Z variance train             0.0212217
KL Divergence                27.209175
KL Loss                      2.7209175
QF Loss                      1398.8187
VF Loss                      772.9119
Policy Loss                  -1381.6798
Q Predictions Mean           1382.5212
Q Predictions Std            417.3277
Q Predictions Max            1651.7314
Q Predictions Min            -369.0995
V Predictions Mean           1378.9288
V Predictions Std            408.1825
V Predictions Max            1645.3469
V Predictions Min            -395.97543
Log Pis Mean                 0.6320324
Log Pis Std                  3.6929224
Log Pis Max                  27.706562
Log Pis Min                  -6.4359713
Policy mu Mean               0.021440266
Policy mu Std                0.66659105
Policy mu Max                4.238547
Policy mu Min                -2.3019745
Policy log std Mean          -1.0275536
Policy log std Std           0.3562268
Policy log std Max           0.4897399
Policy log std Min           -3.5783958
Z mean eval                  1.26509
Z variance eval              0.024540935
total_rewards                [ 585.00244755 3966.0639927   352.41281123  976.17467396 3773.37403217
  303.44375932  665.84278042 1129.95344632 2907.22313382 2063.57573695]
total_rewards_mean           1672.3066814437068
total_rewards_std            1339.5435471146743
total_rewards_max            3966.06399269811
total_rewards_min            303.44375931657856
Number of train steps total  1788000
Number of env steps total    2237000
Number of rollouts total     0
Train Time (s)               143.58303880877793
(Previous) Eval Time (s)     31.47578190313652
Sample Time (s)              24.728266013320535
Epoch Time (s)               199.78708672523499
Total Train Time (s)         83050.96475235606
Epoch                        446
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:37:07.492695 UTC | [2020_01_11_13_32_55] Iteration #446 | Epoch Duration: 185.27067518234253
2020-01-12 12:37:07.493094 UTC | [2020_01_11_13_32_55] Iteration #446 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2686856
Z variance train             0.024416307
KL Divergence                25.988323
KL Loss                      2.5988324
QF Loss                      1252.3947
VF Loss                      663.7101
Policy Loss                  -1387.191
Q Predictions Mean           1394.0696
Q Predictions Std            390.8202
Q Predictions Max            1631.4443
Q Predictions Min            -231.93866
V Predictions Mean           1390.1675
V Predictions Std            388.34476
V Predictions Max            1637.0817
V Predictions Min            -215.1341
Log Pis Mean                 0.8996955
Log Pis Std                  3.2988436
Log Pis Max                  19.461708
Log Pis Min                  -8.588995
Policy mu Mean               0.019981464
Policy mu Std                0.6757778
Policy mu Max                3.0208554
Policy mu Min                -2.503771
Policy log std Mean          -1.0591278
Policy log std Std           0.312697
Policy log std Max           0.055425763
Policy log std Min           -3.1690645
Z mean eval                  1.2418593
Z variance eval              0.019932367
total_rewards                [2925.79284518 3928.25255071 4327.12454005 4107.53066184 3918.94608549
 2955.04249936 1631.05513013 3996.95924107 2693.19921846 1549.69250122]
total_rewards_mean           3203.3595273498445
total_rewards_std            967.1314113581701
total_rewards_max            4327.124540046977
total_rewards_min            1549.6925012225406
Number of train steps total  1792000
Number of env steps total    2242000
Number of rollouts total     0
Train Time (s)               144.49973927112296
(Previous) Eval Time (s)     16.958917943760753
Sample Time (s)              26.865251913666725
Epoch Time (s)               188.32390912855044
Total Train Time (s)         83249.27337462036
Epoch                        447
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:40:25.802565 UTC | [2020_01_11_13_32_55] Iteration #447 | Epoch Duration: 198.30923438072205
2020-01-12 12:40:25.802803 UTC | [2020_01_11_13_32_55] Iteration #447 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.238421
Z variance train             0.01989539
KL Divergence                25.62405
KL Loss                      2.562405
QF Loss                      1178.7197
VF Loss                      549.10785
Policy Loss                  -1415.5673
Q Predictions Mean           1420.5813
Q Predictions Std            352.69022
Q Predictions Max            1643.08
Q Predictions Min            -255.21829
V Predictions Mean           1407.8792
V Predictions Std            353.8346
V Predictions Max            1629.1866
V Predictions Min            -263.59775
Log Pis Mean                 1.2898138
Log Pis Std                  3.1975863
Log Pis Max                  18.923542
Log Pis Min                  -6.2034173
Policy mu Mean               0.0378145
Policy mu Std                0.6682801
Policy mu Max                2.3781173
Policy mu Min                -2.739093
Policy log std Mean          -1.0793247
Policy log std Std           0.31840047
Policy log std Max           0.08725929
Policy log std Min           -3.751163
Z mean eval                  1.2446074
Z variance eval              0.024770359
total_rewards                [ 552.35762875 1845.82875204  664.86458456 1743.02943794  388.23436504
 4215.51070617 1215.21944676  918.07326624  220.57769954  275.56036349]
total_rewards_mean           1203.9256250532565
total_rewards_std            1142.9554435783532
total_rewards_max            4215.5107061659255
total_rewards_min            220.57769954179633
Number of train steps total  1796000
Number of env steps total    2247000
Number of rollouts total     0
Train Time (s)               140.0590770933777
(Previous) Eval Time (s)     26.943798902910203
Sample Time (s)              24.955520960967988
Epoch Time (s)               191.9583969572559
Total Train Time (s)         83425.50125054736
Epoch                        448
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:43:22.035199 UTC | [2020_01_11_13_32_55] Iteration #448 | Epoch Duration: 176.23223757743835
2020-01-12 12:43:22.035402 UTC | [2020_01_11_13_32_55] Iteration #448 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2452934
Z variance train             0.024769697
KL Divergence                26.489645
KL Loss                      2.6489646
QF Loss                      1043.2153
VF Loss                      348.55853
Policy Loss                  -1433.2561
Q Predictions Mean           1436.3158
Q Predictions Std            328.99323
Q Predictions Max            1640.2382
Q Predictions Min            -344.70117
V Predictions Mean           1437.6713
V Predictions Std            327.11398
V Predictions Max            1649.6194
V Predictions Min            -335.90686
Log Pis Mean                 0.40461275
Log Pis Std                  2.884235
Log Pis Max                  9.04228
Log Pis Min                  -6.659648
Policy mu Mean               -0.002320133
Policy mu Std                0.626522
Policy mu Max                2.519914
Policy mu Min                -2.3923717
Policy log std Mean          -1.0548437
Policy log std Std           0.2856037
Policy log std Max           -0.221143
Policy log std Min           -2.8777373
Z mean eval                  1.3217895
Z variance eval              0.01070813
total_rewards                [2143.98527534  911.89792596 1612.79082223  658.73780859 1697.6951147
 1719.35820817 1382.98890598 2529.82603451   90.53948303  439.00516157]
total_rewards_mean           1318.6824740092025
total_rewards_std            736.6130674725498
total_rewards_max            2529.8260345077097
total_rewards_min            90.53948303212985
Number of train steps total  1800000
Number of env steps total    2252000
Number of rollouts total     0
Train Time (s)               136.07789213070646
(Previous) Eval Time (s)     11.217283716890961
Sample Time (s)              24.83835237659514
Epoch Time (s)               172.13352822419256
Total Train Time (s)         83607.16055751313
Epoch                        449
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:46:23.699119 UTC | [2020_01_11_13_32_55] Iteration #449 | Epoch Duration: 181.66357827186584
2020-01-12 12:46:23.699354 UTC | [2020_01_11_13_32_55] Iteration #449 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3188672
Z variance train             0.010737366
KL Divergence                27.569687
KL Loss                      2.7569687
QF Loss                      1419.6687
VF Loss                      279.12332
Policy Loss                  -1436.8187
Q Predictions Mean           1435.5804
Q Predictions Std            308.6176
Q Predictions Max            1636.3646
Q Predictions Min            -211.83652
V Predictions Mean           1434.0576
V Predictions Std            306.44647
V Predictions Max            1619.3436
V Predictions Min            -220.80547
Log Pis Mean                 0.70685756
Log Pis Std                  3.2227075
Log Pis Max                  24.851748
Log Pis Min                  -5.779855
Policy mu Mean               0.012347565
Policy mu Std                0.6523641
Policy mu Max                2.9912868
Policy mu Min                -3.2957351
Policy log std Mean          -1.0456901
Policy log std Std           0.29380557
Policy log std Max           -0.21479696
Policy log std Min           -3.373661
Z mean eval                  1.2324617
Z variance eval              0.024389122
total_rewards                [ 161.22414301  852.67354806 4035.13810088 3952.80923096 2174.83927528
 3930.2775936  3032.34645781 3900.78547356  119.7579035  1836.69484581]
total_rewards_mean           2399.654657247201
total_rewards_std            1518.3119268453781
total_rewards_max            4035.1381008786134
total_rewards_min            119.7579034952447
Number of train steps total  1804000
Number of env steps total    2257000
Number of rollouts total     0
Train Time (s)               138.6916166576557
(Previous) Eval Time (s)     20.746923230122775
Sample Time (s)              24.012366810347885
Epoch Time (s)               183.45090669812635
Total Train Time (s)         83791.41248398367
Epoch                        450
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:49:27.956086 UTC | [2020_01_11_13_32_55] Iteration #450 | Epoch Duration: 184.25658917427063
2020-01-12 12:49:27.956302 UTC | [2020_01_11_13_32_55] Iteration #450 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2312249
Z variance train             0.024414152
KL Divergence                26.275568
KL Loss                      2.6275568
QF Loss                      970.4431
VF Loss                      405.08316
Policy Loss                  -1380.6873
Q Predictions Mean           1380.3174
Q Predictions Std            435.32336
Q Predictions Max            1637.1387
Q Predictions Min            -290.9168
V Predictions Mean           1378.8303
V Predictions Std            426.11493
V Predictions Max            1623.8662
V Predictions Min            -276.80182
Log Pis Mean                 0.85588014
Log Pis Std                  3.5748966
Log Pis Max                  21.348328
Log Pis Min                  -6.7548723
Policy mu Mean               -0.021846343
Policy mu Std                0.67932725
Policy mu Max                2.8284907
Policy mu Min                -3.2789195
Policy log std Mean          -1.0514389
Policy log std Std           0.32660306
Policy log std Max           -0.120078325
Policy log std Min           -3.2299857
Z mean eval                  1.2493968
Z variance eval              0.022198904
total_rewards                [3900.23559135  333.18570077 1090.06797537 1534.30494558 3965.02523706
 3033.85254718  656.53855865 3535.54131511 2563.56004332 3933.27008224]
total_rewards_mean           2454.5581996620467
total_rewards_std            1360.7301714432338
total_rewards_max            3965.0252370556705
total_rewards_min            333.1857007675193
Number of train steps total  1808000
Number of env steps total    2262000
Number of rollouts total     0
Train Time (s)               145.59236267395318
(Previous) Eval Time (s)     21.5522468527779
Sample Time (s)              26.14447098178789
Epoch Time (s)               193.28908050851896
Total Train Time (s)         83986.67884841608
Epoch                        451
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:52:43.228014 UTC | [2020_01_11_13_32_55] Iteration #451 | Epoch Duration: 195.27153778076172
2020-01-12 12:52:43.228361 UTC | [2020_01_11_13_32_55] Iteration #451 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2504865
Z variance train             0.022173068
KL Divergence                27.2696
KL Loss                      2.72696
QF Loss                      1017.1432
VF Loss                      235.45256
Policy Loss                  -1374.1821
Q Predictions Mean           1376.8695
Q Predictions Std            429.0506
Q Predictions Max            1656.5701
Q Predictions Min            -406.0131
V Predictions Mean           1373.5186
V Predictions Std            427.13895
V Predictions Max            1649.9385
V Predictions Min            -399.04214
Log Pis Mean                 1.004068
Log Pis Std                  3.6554687
Log Pis Max                  24.343061
Log Pis Min                  -10.137391
Policy mu Mean               0.0016452428
Policy mu Std                0.6837595
Policy mu Max                2.742493
Policy mu Min                -2.9232504
Policy log std Mean          -1.0466356
Policy log std Std           0.3559556
Policy log std Max           -0.2841146
Policy log std Min           -3.5898376
Z mean eval                  1.2617271
Z variance eval              0.018501407
total_rewards                [2529.42211178 1168.89451706  822.7868176  4127.94036097 3811.05830064
 3813.27492657 3809.87908387 4069.42104618 3752.43840192 4149.48734218]
total_rewards_mean           3205.460290877529
total_rewards_std            1190.4217783210188
total_rewards_max            4149.487342179875
total_rewards_min            822.7868176015859
Number of train steps total  1812000
Number of env steps total    2267000
Number of rollouts total     0
Train Time (s)               144.5870749228634
(Previous) Eval Time (s)     23.5342496689409
Sample Time (s)              26.021911030169576
Epoch Time (s)               194.14323562197387
Total Train Time (s)         84184.80695632426
Epoch                        452
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:56:01.360139 UTC | [2020_01_11_13_32_55] Iteration #452 | Epoch Duration: 198.13153314590454
2020-01-12 12:56:01.360363 UTC | [2020_01_11_13_32_55] Iteration #452 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2613804
Z variance train             0.018537011
KL Divergence                28.895073
KL Loss                      2.8895073
QF Loss                      4020.4207
VF Loss                      502.7835
Policy Loss                  -1441.0853
Q Predictions Mean           1442.2898
Q Predictions Std            306.8157
Q Predictions Max            1651.3517
Q Predictions Min            -119.40017
V Predictions Mean           1443.1152
V Predictions Std            309.32632
V Predictions Max            1651.2274
V Predictions Min            -93.46606
Log Pis Mean                 0.695211
Log Pis Std                  3.1706908
Log Pis Max                  18.286076
Log Pis Min                  -6.762822
Policy mu Mean               0.0073589487
Policy mu Std                0.6395773
Policy mu Max                2.533083
Policy mu Min                -2.4250965
Policy log std Mean          -1.0416367
Policy log std Std           0.3282166
Policy log std Max           2.0
Policy log std Min           -2.7819352
Z mean eval                  1.3343086
Z variance eval              0.020750994
total_rewards                [4081.91252434 4036.68041595 3469.48590574  195.07530149  960.33718396
 1602.40709626 2769.77633541  364.44044752 4140.79950944 4004.31512527]
total_rewards_mean           2562.5229845378285
total_rewards_std            1544.0899907148334
total_rewards_max            4140.799509442992
total_rewards_min            195.07530149143003
Number of train steps total  1816000
Number of env steps total    2272000
Number of rollouts total     0
Train Time (s)               144.35509386425838
(Previous) Eval Time (s)     27.522204698994756
Sample Time (s)              24.792293781414628
Epoch Time (s)               196.66959234466776
Total Train Time (s)         84381.6772779706
Epoch                        453
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:59:18.235170 UTC | [2020_01_11_13_32_55] Iteration #453 | Epoch Duration: 196.87465453147888
2020-01-12 12:59:18.235387 UTC | [2020_01_11_13_32_55] Iteration #453 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3367603
Z variance train             0.020737577
KL Divergence                28.399155
KL Loss                      2.8399155
QF Loss                      2229.9854
VF Loss                      229.59657
Policy Loss                  -1397.2184
Q Predictions Mean           1400.7502
Q Predictions Std            415.1643
Q Predictions Max            1640.5923
Q Predictions Min            -336.25488
V Predictions Mean           1397.9128
V Predictions Std            419.9559
V Predictions Max            1647.6498
V Predictions Min            -333.2687
Log Pis Mean                 0.66847306
Log Pis Std                  3.158874
Log Pis Max                  15.800713
Log Pis Min                  -6.923417
Policy mu Mean               0.019112606
Policy mu Std                0.70336366
Policy mu Max                2.7076864
Policy mu Min                -5.6332383
Policy log std Mean          -1.0192673
Policy log std Std           0.28885698
Policy log std Max           0.2573247
Policy log std Min           -2.603232
Z mean eval                  1.2827193
Z variance eval              0.017869731
total_rewards                [2006.71720724 3748.50366063 2843.63076256 3007.42762397 4266.74570431
 3292.95592672 3717.98711588  711.41349573 2701.28608232  783.60621862]
total_rewards_mean           2708.027379797694
total_rewards_std            1147.3503289821858
total_rewards_max            4266.745704309205
total_rewards_min            711.4134957300874
Number of train steps total  1820000
Number of env steps total    2277000
Number of rollouts total     0
Train Time (s)               143.88073901692405
(Previous) Eval Time (s)     27.726881749927998
Sample Time (s)              25.952474477235228
Epoch Time (s)               197.56009524408728
Total Train Time (s)         84575.86421509692
Epoch                        454
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:02:32.426706 UTC | [2020_01_11_13_32_55] Iteration #454 | Epoch Duration: 194.19117975234985
2020-01-12 13:02:32.426928 UTC | [2020_01_11_13_32_55] Iteration #454 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2838714
Z variance train             0.01787493
KL Divergence                28.87868
KL Loss                      2.887868
QF Loss                      951.669
VF Loss                      374.13348
Policy Loss                  -1411.3163
Q Predictions Mean           1410.487
Q Predictions Std            379.25302
Q Predictions Max            1669.9645
Q Predictions Min            -155.47525
V Predictions Mean           1408.0137
V Predictions Std            371.5438
V Predictions Max            1651.4795
V Predictions Min            -157.09712
Log Pis Mean                 0.8414106
Log Pis Std                  3.297312
Log Pis Max                  20.217768
Log Pis Min                  -6.228917
Policy mu Mean               0.020710967
Policy mu Std                0.6406185
Policy mu Max                3.0446396
Policy mu Min                -2.9198864
Policy log std Mean          -1.0831332
Policy log std Std           0.2945135
Policy log std Max           -0.12877667
Policy log std Min           -2.9366174
Z mean eval                  1.2532179
Z variance eval              0.012481087
total_rewards                [3976.36455641 3991.56197375  210.50967829 3771.33914692 3668.82422586
  774.3859343  1161.76947737  625.90495317 3940.10401465  903.27988928]
total_rewards_mean           2302.4043849997342
total_rewards_std            1585.636785329877
total_rewards_max            3991.561973749181
total_rewards_min            210.50967828849497
Number of train steps total  1824000
Number of env steps total    2282000
Number of rollouts total     0
Train Time (s)               135.92027542786673
(Previous) Eval Time (s)     24.357656170148402
Sample Time (s)              25.862169091124088
Epoch Time (s)               186.14010068913922
Total Train Time (s)         84760.28554999735
Epoch                        455
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:05:36.852523 UTC | [2020_01_11_13_32_55] Iteration #455 | Epoch Duration: 184.42545557022095
2020-01-12 13:05:36.852705 UTC | [2020_01_11_13_32_55] Iteration #455 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2489055
Z variance train             0.0124820005
KL Divergence                28.86914
KL Loss                      2.886914
QF Loss                      1379.0862
VF Loss                      893.98145
Policy Loss                  -1406.0891
Q Predictions Mean           1405.346
Q Predictions Std            371.2472
Q Predictions Max            1640.7129
Q Predictions Min            -239.32759
V Predictions Mean           1401.8348
V Predictions Std            370.0068
V Predictions Max            1642.4951
V Predictions Min            -238.90707
Log Pis Mean                 0.42508438
Log Pis Std                  3.209567
Log Pis Max                  19.100254
Log Pis Min                  -6.63244
Policy mu Mean               0.054252815
Policy mu Std                0.6255695
Policy mu Max                3.0298293
Policy mu Min                -2.1290393
Policy log std Mean          -1.0482241
Policy log std Std           0.31988144
Policy log std Max           0.17034292
Policy log std Min           -2.9445648
Z mean eval                  1.2787846
Z variance eval              0.01831666
total_rewards                [3799.390327   2851.42505999 2346.72711587 2796.5908206  3837.30200918
  589.79882084 2379.21578778  506.15838555 2824.32121328 4029.57059792]
total_rewards_mean           2596.050013800842
total_rewards_std            1170.6035330755037
total_rewards_max            4029.5705979217087
total_rewards_min            506.1583855517364
Number of train steps total  1828000
Number of env steps total    2287000
Number of rollouts total     0
Train Time (s)               136.45058166980743
(Previous) Eval Time (s)     22.642710371874273
Sample Time (s)              24.85531336721033
Epoch Time (s)               183.94860540889204
Total Train Time (s)         84945.48868072033
Epoch                        456
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:08:42.060360 UTC | [2020_01_11_13_32_55] Iteration #456 | Epoch Duration: 185.20751452445984
2020-01-12 13:08:42.060553 UTC | [2020_01_11_13_32_55] Iteration #456 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2738224
Z variance train             0.018319335
KL Divergence                29.17614
KL Loss                      2.917614
QF Loss                      994.9986
VF Loss                      234.47311
Policy Loss                  -1358.5278
Q Predictions Mean           1365.16
Q Predictions Std            439.0929
Q Predictions Max            1622.8815
Q Predictions Min            -344.78952
V Predictions Mean           1353.6777
V Predictions Std            434.75137
V Predictions Max            1609.9268
V Predictions Min            -321.0937
Log Pis Mean                 0.5615394
Log Pis Std                  3.1601527
Log Pis Max                  13.549383
Log Pis Min                  -6.8412457
Policy mu Mean               0.03814564
Policy mu Std                0.6882335
Policy mu Max                3.2077878
Policy mu Min                -2.3666883
Policy log std Mean          -1.0061661
Policy log std Std           0.30745283
Policy log std Max           -0.084015965
Policy log std Min           -2.518068
Z mean eval                  1.2485945
Z variance eval              0.009737496
total_rewards                [1679.59620983 4280.85808037 4155.70703741 3720.76109162 3932.59564336
  178.01225634 4186.03787321  368.54535462 1690.9563008    84.41960224]
total_rewards_mean           2427.748944980439
total_rewards_std            1712.988602060587
total_rewards_max            4280.858080370021
total_rewards_min            84.41960224241728
Number of train steps total  1832000
Number of env steps total    2292000
Number of rollouts total     0
Train Time (s)               141.44508337276056
(Previous) Eval Time (s)     23.901303773280233
Sample Time (s)              25.506076792720705
Epoch Time (s)               190.8524639387615
Total Train Time (s)         85133.90850518504
Epoch                        457
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:11:50.484972 UTC | [2020_01_11_13_32_55] Iteration #457 | Epoch Duration: 188.4242868423462
2020-01-12 13:11:50.485155 UTC | [2020_01_11_13_32_55] Iteration #457 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2473603
Z variance train             0.009697294
KL Divergence                31.102806
KL Loss                      3.1102808
QF Loss                      973.7222
VF Loss                      319.89468
Policy Loss                  -1426.8679
Q Predictions Mean           1428.9336
Q Predictions Std            352.03537
Q Predictions Max            1635.3977
Q Predictions Min            -320.5566
V Predictions Mean           1428.0027
V Predictions Std            354.11618
V Predictions Max            1630.7739
V Predictions Min            -320.18402
Log Pis Mean                 1.1705648
Log Pis Std                  3.3510153
Log Pis Max                  13.342761
Log Pis Min                  -6.9497766
Policy mu Mean               0.021114644
Policy mu Std                0.6889575
Policy mu Max                3.0580852
Policy mu Min                -3.4371626
Policy log std Mean          -1.0607815
Policy log std Std           0.28726822
Policy log std Max           0.19351721
Policy log std Min           -2.2862403
Z mean eval                  1.2619053
Z variance eval              0.008811945
total_rewards                [2234.76214406 3797.9381323   958.5498175   476.18500146 2293.76628289
  279.79797578 3961.70299583 4155.47900556 1409.48631365 1332.64922221]
total_rewards_mean           2090.031689122616
total_rewards_std            1376.484430299433
total_rewards_max            4155.479005561835
total_rewards_min            279.79797577654216
Number of train steps total  1836000
Number of env steps total    2297000
Number of rollouts total     0
Train Time (s)               145.45231789909303
(Previous) Eval Time (s)     21.472652970813215
Sample Time (s)              25.70124127715826
Epoch Time (s)               192.6262121470645
Total Train Time (s)         85325.83525961265
Epoch                        458
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:15:02.417077 UTC | [2020_01_11_13_32_55] Iteration #458 | Epoch Duration: 191.93177247047424
2020-01-12 13:15:02.417365 UTC | [2020_01_11_13_32_55] Iteration #458 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2630855
Z variance train             0.008830346
KL Divergence                30.015835
KL Loss                      3.0015836
QF Loss                      974.0904
VF Loss                      898.054
Policy Loss                  -1410.1962
Q Predictions Mean           1411.6779
Q Predictions Std            378.45908
Q Predictions Max            1662.9094
Q Predictions Min            -180.7745
V Predictions Mean           1409.4001
V Predictions Std            376.5139
V Predictions Max            1645.7477
V Predictions Min            -177.20052
Log Pis Mean                 1.1169866
Log Pis Std                  3.5419617
Log Pis Max                  17.967697
Log Pis Min                  -7.677457
Policy mu Mean               0.028462734
Policy mu Std                0.68712366
Policy mu Max                3.2028599
Policy mu Min                -3.863558
Policy log std Mean          -1.0615239
Policy log std Std           0.3518864
Policy log std Max           -0.0046128035
Policy log std Min           -2.9763074
Z mean eval                  1.2685426
Z variance eval              0.019191477
total_rewards                [3047.01454774 1117.51222451  449.81832286  366.86951204 1805.46814599
  646.39352642 4125.41358019 4106.7251881  1751.44246751 4115.2055024 ]
total_rewards_mean           2153.1863017756323
total_rewards_std            1485.67103782524
total_rewards_max            4125.413580190303
total_rewards_min            366.86951203919915
Number of train steps total  1840000
Number of env steps total    2302000
Number of rollouts total     0
Train Time (s)               144.3195137558505
(Previous) Eval Time (s)     20.777843767311424
Sample Time (s)              26.457477451767772
Epoch Time (s)               191.5548349749297
Total Train Time (s)         85515.8173032892
Epoch                        459
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:18:12.403821 UTC | [2020_01_11_13_32_55] Iteration #459 | Epoch Duration: 189.9863018989563
2020-01-12 13:18:12.404016 UTC | [2020_01_11_13_32_55] Iteration #459 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2679179
Z variance train             0.019194165
KL Divergence                28.341381
KL Loss                      2.8341382
QF Loss                      1253.2864
VF Loss                      368.25165
Policy Loss                  -1399.431
Q Predictions Mean           1404.742
Q Predictions Std            387.0124
Q Predictions Max            1652.3599
Q Predictions Min            -232.43546
V Predictions Mean           1401.2668
V Predictions Std            384.7793
V Predictions Max            1640.3868
V Predictions Min            -237.70908
Log Pis Mean                 0.85320306
Log Pis Std                  3.0815792
Log Pis Max                  15.7329235
Log Pis Min                  -9.783977
Policy mu Mean               0.012472829
Policy mu Std                0.67550355
Policy mu Max                3.9508178
Policy mu Min                -3.5740595
Policy log std Mean          -1.0499135
Policy log std Std           0.31300253
Policy log std Max           0.35033178
Policy log std Min           -2.7557461
Z mean eval                  1.2635977
Z variance eval              0.015424846
total_rewards                [2934.10079967 1319.06535054  635.08712839 2794.23698894 3801.28118669
 1484.4618618  4163.87058656 4060.26231426 4045.38447196 4143.34486345]
total_rewards_mean           2938.1095552256397
total_rewards_std            1274.537387157446
total_rewards_max            4163.8705865633465
total_rewards_min            635.0871283915778
Number of train steps total  1844000
Number of env steps total    2307000
Number of rollouts total     0
Train Time (s)               146.86571060167626
(Previous) Eval Time (s)     19.20894874073565
Sample Time (s)              25.734648650046438
Epoch Time (s)               191.80930799245834
Total Train Time (s)         85714.37794756005
Epoch                        460
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:21:30.969130 UTC | [2020_01_11_13_32_55] Iteration #460 | Epoch Duration: 198.56498169898987
2020-01-12 13:21:30.969323 UTC | [2020_01_11_13_32_55] Iteration #460 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2658494
Z variance train             0.015462516
KL Divergence                28.79993
KL Loss                      2.8799932
QF Loss                      936.7127
VF Loss                      211.29837
Policy Loss                  -1443.5874
Q Predictions Mean           1445.2701
Q Predictions Std            315.01352
Q Predictions Max            1641.5974
Q Predictions Min            -342.69153
V Predictions Mean           1438.2355
V Predictions Std            311.1986
V Predictions Max            1627.9528
V Predictions Min            -330.03586
Log Pis Mean                 0.8018404
Log Pis Std                  3.0751328
Log Pis Max                  13.734076
Log Pis Min                  -8.760235
Policy mu Mean               0.034917556
Policy mu Std                0.6742163
Policy mu Max                3.4258442
Policy mu Min                -2.4391294
Policy log std Mean          -1.057323
Policy log std Std           0.2899105
Policy log std Max           0.5511948
Policy log std Min           -2.429036
Z mean eval                  1.2662065
Z variance eval              0.011244839
total_rewards                [4019.98632166 3823.83459742 4079.96437156 2050.57716711 4362.65933244
 2295.32937679 3290.7107552  3881.11755761 1786.00853968 3875.45754217]
total_rewards_mean           3346.5645561629813
total_rewards_std            896.6724928731036
total_rewards_max            4362.659332438385
total_rewards_min            1786.008539676879
Number of train steps total  1848000
Number of env steps total    2312000
Number of rollouts total     0
Train Time (s)               143.19456713693216
(Previous) Eval Time (s)     25.964231120888144
Sample Time (s)              24.993138873949647
Epoch Time (s)               194.15193713176996
Total Train Time (s)         85910.30062695406
Epoch                        461
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:24:46.894308 UTC | [2020_01_11_13_32_55] Iteration #461 | Epoch Duration: 195.9248707294464
2020-01-12 13:24:46.894429 UTC | [2020_01_11_13_32_55] Iteration #461 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2665024
Z variance train             0.011255688
KL Divergence                30.498213
KL Loss                      3.0498214
QF Loss                      1208.3618
VF Loss                      141.90395
Policy Loss                  -1394.6808
Q Predictions Mean           1398.3113
Q Predictions Std            433.69617
Q Predictions Max            1658.8867
Q Predictions Min            -366.40723
V Predictions Mean           1394.335
V Predictions Std            433.52203
V Predictions Max            1658.3282
V Predictions Min            -371.42798
Log Pis Mean                 0.8070655
Log Pis Std                  3.5923557
Log Pis Max                  19.649685
Log Pis Min                  -7.5498977
Policy mu Mean               0.0008756297
Policy mu Std                0.65847033
Policy mu Max                3.372627
Policy mu Min                -4.2342534
Policy log std Mean          -1.0622803
Policy log std Std           0.33901012
Policy log std Max           -0.10667765
Policy log std Min           -3.2288275
Z mean eval                  1.2366854
Z variance eval              0.026793623
total_rewards                [3909.86546637 3947.1859092  4135.64507894 4078.02760089 2296.67493278
 2843.11362375  498.55661547 3734.77167017 1178.52672838 1484.37905265]
total_rewards_mean           2810.6746678590116
total_rewards_std            1294.2050991602337
total_rewards_max            4135.645078935042
total_rewards_min            498.5566154719735
Number of train steps total  1852000
Number of env steps total    2317000
Number of rollouts total     0
Train Time (s)               136.5576496119611
(Previous) Eval Time (s)     27.736763013061136
Sample Time (s)              24.857358257751912
Epoch Time (s)               189.15177088277414
Total Train Time (s)         86102.40804041643
Epoch                        462
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:27:59.006604 UTC | [2020_01_11_13_32_55] Iteration #462 | Epoch Duration: 192.1120800971985
2020-01-12 13:27:59.006782 UTC | [2020_01_11_13_32_55] Iteration #462 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2395788
Z variance train             0.026831385
KL Divergence                28.380938
KL Loss                      2.8380938
QF Loss                      1388.1624
VF Loss                      264.6056
Policy Loss                  -1409.7793
Q Predictions Mean           1414.1145
Q Predictions Std            365.5721
Q Predictions Max            1658.7578
Q Predictions Min            -317.68015
V Predictions Mean           1412.635
V Predictions Std            360.68704
V Predictions Max            1645.4713
V Predictions Min            -312.9795
Log Pis Mean                 1.1531117
Log Pis Std                  3.4754486
Log Pis Max                  16.82534
Log Pis Min                  -7.660714
Policy mu Mean               0.026707944
Policy mu Std                0.6774393
Policy mu Max                3.3442366
Policy mu Min                -3.836776
Policy log std Mean          -1.0736618
Policy log std Std           0.34324548
Policy log std Max           1.1322541
Policy log std Min           -2.8597288
Z mean eval                  1.2798975
Z variance eval              0.006368269
total_rewards                [3162.41375099 3867.14025234 1592.36277001 2947.49442157  912.25579879
  645.18246015   32.59836428 3940.55514542 4218.44798527 4095.01637746]
total_rewards_mean           2541.3467326282926
total_rewards_std            1514.4806356876027
total_rewards_max            4218.4479852735285
total_rewards_min            32.59836427558494
Number of train steps total  1856000
Number of env steps total    2322000
Number of rollouts total     0
Train Time (s)               135.5899100699462
(Previous) Eval Time (s)     30.696683920919895
Sample Time (s)              23.95566217880696
Epoch Time (s)               190.24225616967306
Total Train Time (s)         86287.44380480004
Epoch                        463
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:31:04.047323 UTC | [2020_01_11_13_32_55] Iteration #463 | Epoch Duration: 185.0404007434845
2020-01-12 13:31:04.047528 UTC | [2020_01_11_13_32_55] Iteration #463 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2799273
Z variance train             0.00636804
KL Divergence                30.20708
KL Loss                      3.020708
QF Loss                      841.19727
VF Loss                      153.23175
Policy Loss                  -1425.2285
Q Predictions Mean           1428.1833
Q Predictions Std            317.453
Q Predictions Max            1651.1614
Q Predictions Min            -52.617195
V Predictions Mean           1424.565
V Predictions Std            317.90863
V Predictions Max            1627.9613
V Predictions Min            -53.938805
Log Pis Mean                 0.9863126
Log Pis Std                  3.1045759
Log Pis Max                  13.382734
Log Pis Min                  -8.494251
Policy mu Mean               -0.0058229375
Policy mu Std                0.68142235
Policy mu Max                2.572342
Policy mu Min                -3.0150073
Policy log std Mean          -1.063842
Policy log std Std           0.31135675
Policy log std Max           -0.1326685
Policy log std Min           -2.7321956
Z mean eval                  1.2665389
Z variance eval              0.012845579
total_rewards                [1153.34760522 2951.40261558 4050.94733756  894.05195324 4077.63536154
 3300.92344102 1328.94632175 1123.07517619 3992.57873594 1667.35268507]
total_rewards_mean           2454.0261233121428
total_rewards_std            1276.6910748985492
total_rewards_max            4077.6353615372386
total_rewards_min            894.0519532410773
Number of train steps total  1860000
Number of env steps total    2327000
Number of rollouts total     0
Train Time (s)               143.06076900055632
(Previous) Eval Time (s)     25.49445210210979
Sample Time (s)              25.522105934564024
Epoch Time (s)               194.07732703723013
Total Train Time (s)         86481.2039483944
Epoch                        464
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:34:17.813337 UTC | [2020_01_11_13_32_55] Iteration #464 | Epoch Duration: 193.7656683921814
2020-01-12 13:34:17.813537 UTC | [2020_01_11_13_32_55] Iteration #464 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2615646
Z variance train             0.012856938
KL Divergence                27.448978
KL Loss                      2.7448978
QF Loss                      700.4879
VF Loss                      122.476685
Policy Loss                  -1425.2151
Q Predictions Mean           1428.4126
Q Predictions Std            350.98917
Q Predictions Max            1651.9673
Q Predictions Min            -125.91657
V Predictions Mean           1426.8923
V Predictions Std            352.3968
V Predictions Max            1659.8301
V Predictions Min            -124.464584
Log Pis Mean                 0.9381578
Log Pis Std                  3.5671372
Log Pis Max                  34.10771
Log Pis Min                  -7.6543927
Policy mu Mean               0.021207118
Policy mu Std                0.712893
Policy mu Max                6.678052
Policy mu Min                -2.8349688
Policy log std Mean          -1.0336049
Policy log std Std           0.28150305
Policy log std Max           0.5302174
Policy log std Min           -2.5592008
Z mean eval                  1.259556
Z variance eval              0.01092476
total_rewards                [ 664.48010393 4069.10650871   66.87649769 4243.58402958 1596.5723106
 3906.44755918  791.35160603 2152.93386092 3800.20997357  944.1610698 ]
total_rewards_mean           2223.572352000345
total_rewards_std            1548.3111005998196
total_rewards_max            4243.584029581107
total_rewards_min            66.87649768669286
Number of train steps total  1864000
Number of env steps total    2332000
Number of rollouts total     0
Train Time (s)               143.20753193693236
(Previous) Eval Time (s)     25.18245959514752
Sample Time (s)              27.461811740882695
Epoch Time (s)               195.85180327296257
Total Train Time (s)         86673.98060263507
Epoch                        465
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:37:30.594213 UTC | [2020_01_11_13_32_55] Iteration #465 | Epoch Duration: 192.78050231933594
2020-01-12 13:37:30.594532 UTC | [2020_01_11_13_32_55] Iteration #465 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.261029
Z variance train             0.0108839
KL Divergence                29.067762
KL Loss                      2.9067762
QF Loss                      1359.7554
VF Loss                      362.7887
Policy Loss                  -1420.8403
Q Predictions Mean           1425.2534
Q Predictions Std            373.83493
Q Predictions Max            1651.7681
Q Predictions Min            -349.61566
V Predictions Mean           1416.8254
V Predictions Std            377.05466
V Predictions Max            1640.2422
V Predictions Min            -361.15234
Log Pis Mean                 0.86383677
Log Pis Std                  3.492077
Log Pis Max                  20.462738
Log Pis Min                  -7.354635
Policy mu Mean               0.013757246
Policy mu Std                0.6835022
Policy mu Max                2.6685085
Policy mu Min                -2.4874659
Policy log std Mean          -1.0477741
Policy log std Std           0.3278987
Policy log std Max           0.026771903
Policy log std Min           -3.3494341
Z mean eval                  1.2898757
Z variance eval              0.0044186437
total_rewards                [4011.18873077  674.02692995  914.22676329 4110.11689044 2985.23006988
 1157.18201035 2821.86299007 4113.41176401  281.28755434 1517.33211885]
total_rewards_mean           2258.5865821964276
total_rewards_std            1441.3826892461325
total_rewards_max            4113.411764005535
total_rewards_min            281.28755434367326
Number of train steps total  1868000
Number of env steps total    2337000
Number of rollouts total     0
Train Time (s)               143.17285525612533
(Previous) Eval Time (s)     22.11069865617901
Sample Time (s)              26.10204506991431
Epoch Time (s)               191.38559898221865
Total Train Time (s)         86862.06129944511
Epoch                        466
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:40:38.679003 UTC | [2020_01_11_13_32_55] Iteration #466 | Epoch Duration: 188.08431005477905
2020-01-12 13:40:38.679246 UTC | [2020_01_11_13_32_55] Iteration #466 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2911141
Z variance train             0.0044292854
KL Divergence                30.749151
KL Loss                      3.0749152
QF Loss                      1082.3982
VF Loss                      227.078
Policy Loss                  -1424.2896
Q Predictions Mean           1424.739
Q Predictions Std            383.4417
Q Predictions Max            1657.3629
Q Predictions Min            -357.88602
V Predictions Mean           1423.79
V Predictions Std            383.1121
V Predictions Max            1656.7662
V Predictions Min            -373.07462
Log Pis Mean                 0.8516461
Log Pis Std                  3.322775
Log Pis Max                  19.663822
Log Pis Min                  -7.9430285
Policy mu Mean               -0.0027196282
Policy mu Std                0.66960716
Policy mu Max                2.8158698
Policy mu Min                -3.17726
Policy log std Mean          -1.0625219
Policy log std Std           0.30321234
Policy log std Max           -0.0883975
Policy log std Min           -2.9802709
Z mean eval                  1.2517867
Z variance eval              0.016355976
total_rewards                [4197.57665663 4098.71012096  431.2217486  1139.8348078  2490.17928211
 3943.7050361  4241.62412643   31.25394805 1945.54765623   70.37004003]
total_rewards_mean           2259.002342293844
total_rewards_std            1685.5146435956667
total_rewards_max            4241.624126426417
total_rewards_min            31.253948045019392
Number of train steps total  1872000
Number of env steps total    2342000
Number of rollouts total     0
Train Time (s)               144.06859938707203
(Previous) Eval Time (s)     18.809018730185926
Sample Time (s)              26.356082839891315
Epoch Time (s)               189.23370095714927
Total Train Time (s)         87056.03910076385
Epoch                        467
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:43:52.662049 UTC | [2020_01_11_13_32_55] Iteration #467 | Epoch Duration: 193.9826741218567
2020-01-12 13:43:52.662237 UTC | [2020_01_11_13_32_55] Iteration #467 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.251788
Z variance train             0.016341392
KL Divergence                28.068842
KL Loss                      2.8068843
QF Loss                      1506.7906
VF Loss                      210.43144
Policy Loss                  -1419.05
Q Predictions Mean           1418.4492
Q Predictions Std            370.79196
Q Predictions Max            1688.6686
Q Predictions Min            -162.35823
V Predictions Mean           1420.9478
V Predictions Std            362.9039
V Predictions Max            1681.4877
V Predictions Min            -155.34094
Log Pis Mean                 0.5795362
Log Pis Std                  3.340641
Log Pis Max                  21.546127
Log Pis Min                  -6.8977637
Policy mu Mean               0.0005328357
Policy mu Std                0.6419231
Policy mu Max                2.632099
Policy mu Min                -2.7611737
Policy log std Mean          -1.0557995
Policy log std Std           0.2983588
Policy log std Max           -0.09703976
Policy log std Min           -2.6173525
Z mean eval                  1.2890214
Z variance eval              0.009108097
total_rewards                [1474.38515454 4208.09185668  153.43017558 4188.29890041 3879.00733265
 3945.74942146 2508.02645167 4217.13861851   -6.97211407  716.91504815]
total_rewards_mean           2528.407084557921
total_rewards_std            1694.783770692864
total_rewards_max            4217.138618510221
total_rewards_min            -6.972114071443016
Number of train steps total  1876000
Number of env steps total    2347000
Number of rollouts total     0
Train Time (s)               140.16471271263435
(Previous) Eval Time (s)     23.557573111727834
Sample Time (s)              25.462256785016507
Epoch Time (s)               189.1845426093787
Total Train Time (s)         87246.63886618987
Epoch                        468
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:47:03.266435 UTC | [2020_01_11_13_32_55] Iteration #468 | Epoch Duration: 190.60406279563904
2020-01-12 13:47:03.266631 UTC | [2020_01_11_13_32_55] Iteration #468 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2908125
Z variance train             0.009094676
KL Divergence                29.705425
KL Loss                      2.9705427
QF Loss                      877.1303
VF Loss                      174.40437
Policy Loss                  -1422.4108
Q Predictions Mean           1425.7041
Q Predictions Std            369.22357
Q Predictions Max            1639.104
Q Predictions Min            -325.10086
V Predictions Mean           1425.4548
V Predictions Std            367.97244
V Predictions Max            1643.1638
V Predictions Min            -340.02817
Log Pis Mean                 0.6093651
Log Pis Std                  2.7318711
Log Pis Max                  10.774891
Log Pis Min                  -6.0536213
Policy mu Mean               0.0020180512
Policy mu Std                0.64135486
Policy mu Max                2.455947
Policy mu Min                -2.1974373
Policy log std Mean          -1.0373912
Policy log std Std           0.27424026
Policy log std Max           -0.25078696
Policy log std Min           -2.505292
Z mean eval                  1.239622
Z variance eval              0.005380217
total_rewards                [3370.3809435   440.52636049 1570.83760124 4002.56812635 1259.18140331
 3954.40113643 4096.8278088  2756.90702237 3963.0654862  4078.2999539 ]
total_rewards_mean           2949.2995842576647
total_rewards_std            1303.9828341710308
total_rewards_max            4096.827808803232
total_rewards_min            440.52636048790816
Number of train steps total  1880000
Number of env steps total    2352000
Number of rollouts total     0
Train Time (s)               137.06760687287897
(Previous) Eval Time (s)     24.976709350012243
Sample Time (s)              25.326096416916698
Epoch Time (s)               187.3704126398079
Total Train Time (s)         87436.37807255657
Epoch                        469
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:50:13.009968 UTC | [2020_01_11_13_32_55] Iteration #469 | Epoch Duration: 189.74320530891418
2020-01-12 13:50:13.010152 UTC | [2020_01_11_13_32_55] Iteration #469 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2374278
Z variance train             0.0053516524
KL Divergence                29.387625
KL Loss                      2.9387624
QF Loss                      1065.0671
VF Loss                      866.40466
Policy Loss                  -1389.765
Q Predictions Mean           1392.5237
Q Predictions Std            432.27682
Q Predictions Max            1671.1997
Q Predictions Min            -216.0945
V Predictions Mean           1379.1118
V Predictions Std            426.29266
V Predictions Max            1654.7119
V Predictions Min            -233.67012
Log Pis Mean                 0.5811193
Log Pis Std                  3.555547
Log Pis Max                  17.352942
Log Pis Min                  -8.6890955
Policy mu Mean               0.03198017
Policy mu Std                0.6763434
Policy mu Max                3.068731
Policy mu Min                -4.0557246
Policy log std Mean          -1.0418875
Policy log std Std           0.31692392
Policy log std Max           -0.24591535
Policy log std Min           -2.5472324
Z mean eval                  1.2799237
Z variance eval              0.008862876
total_rewards                [ 656.68273202 3944.55698624 1844.54874033 3969.52807817 2963.37265634
  967.70819717  370.94380108 3759.12256752 4204.63700924 4301.94855355]
total_rewards_mean           2698.3049321656613
total_rewards_std            1500.4716708691444
total_rewards_max            4301.948553549194
total_rewards_min            370.9438010796486
Number of train steps total  1884000
Number of env steps total    2357000
Number of rollouts total     0
Train Time (s)               138.17260768823326
(Previous) Eval Time (s)     27.349179640877992
Sample Time (s)              24.569209090434015
Epoch Time (s)               190.09099641954526
Total Train Time (s)         87625.63096136646
Epoch                        470
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:53:22.265613 UTC | [2020_01_11_13_32_55] Iteration #470 | Epoch Duration: 189.25533270835876
2020-01-12 13:53:22.265730 UTC | [2020_01_11_13_32_55] Iteration #470 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2797433
Z variance train             0.008882629
KL Divergence                28.735558
KL Loss                      2.873556
QF Loss                      1210.7844
VF Loss                      176.39197
Policy Loss                  -1399.5145
Q Predictions Mean           1404.0536
Q Predictions Std            395.24115
Q Predictions Max            1653.0895
Q Predictions Min            -318.2329
V Predictions Mean           1398.8994
V Predictions Std            394.25436
V Predictions Max            1628.9929
V Predictions Min            -264.31247
Log Pis Mean                 0.77222914
Log Pis Std                  3.3367453
Log Pis Max                  15.59944
Log Pis Min                  -10.858264
Policy mu Mean               -0.0020838254
Policy mu Std                0.63854045
Policy mu Max                2.2699194
Policy mu Min                -2.1476312
Policy log std Mean          -1.0523623
Policy log std Std           0.32154772
Policy log std Max           -0.018699527
Policy log std Min           -2.6072054
Z mean eval                  1.2536792
Z variance eval              0.006327453
total_rewards                [1997.50834363 1369.89638205 3540.6516145  1313.92682106 4076.80889508
 3928.3387587  3803.63215197  208.19561365 1127.9290261  3897.8676695 ]
total_rewards_mean           2526.4755276242645
total_rewards_std            1390.225258653027
total_rewards_max            4076.808895079894
total_rewards_min            208.19561364612784
Number of train steps total  1888000
Number of env steps total    2362000
Number of rollouts total     0
Train Time (s)               146.71734310360625
(Previous) Eval Time (s)     26.513180075213313
Sample Time (s)              25.098915167618543
Epoch Time (s)               198.3294383464381
Total Train Time (s)         87820.88639656454
Epoch                        471
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:56:37.527293 UTC | [2020_01_11_13_32_55] Iteration #471 | Epoch Duration: 195.26146268844604
2020-01-12 13:56:37.527555 UTC | [2020_01_11_13_32_55] Iteration #471 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2535223
Z variance train             0.0063197366
KL Divergence                28.754063
KL Loss                      2.8754063
QF Loss                      752.13446
VF Loss                      328.60544
Policy Loss                  -1414.7361
Q Predictions Mean           1417.1824
Q Predictions Std            375.84155
Q Predictions Max            1644.0131
Q Predictions Min            -319.6415
V Predictions Mean           1414.8376
V Predictions Std            371.9125
V Predictions Max            1638.7344
V Predictions Min            -301.62704
Log Pis Mean                 0.5517186
Log Pis Std                  3.0583827
Log Pis Max                  8.3629875
Log Pis Min                  -8.537816
Policy mu Mean               -0.060456865
Policy mu Std                0.6535532
Policy mu Max                2.819492
Policy mu Min                -2.2250712
Policy log std Mean          -1.0276207
Policy log std Std           0.29694048
Policy log std Max           0.08944869
Policy log std Min           -2.5221195
Z mean eval                  1.3078792
Z variance eval              0.017736204
total_rewards                [1005.08493668 4132.57833947 3755.15468639  193.18309942  486.87815576
  720.28218325  379.48637932 3535.38179885  327.36589144 2020.12534479]
total_rewards_mean           1655.5520815372524
total_rewards_std            1496.8381648299644
total_rewards_max            4132.578339465384
total_rewards_min            193.1830994181341
Number of train steps total  1892000
Number of env steps total    2367000
Number of rollouts total     0
Train Time (s)               145.0426335129887
(Previous) Eval Time (s)     23.44481412600726
Sample Time (s)              25.091353725176305
Epoch Time (s)               193.57880136417225
Total Train Time (s)         88006.6208359627
Epoch                        472
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:59:43.266117 UTC | [2020_01_11_13_32_55] Iteration #472 | Epoch Duration: 185.73840618133545
2020-01-12 13:59:43.266328 UTC | [2020_01_11_13_32_55] Iteration #472 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3106767
Z variance train             0.017747879
KL Divergence                28.977573
KL Loss                      2.8977573
QF Loss                      745.7334
VF Loss                      315.1403
Policy Loss                  -1409.9762
Q Predictions Mean           1410.8195
Q Predictions Std            406.6657
Q Predictions Max            1687.5808
Q Predictions Min            -236.94374
V Predictions Mean           1414.7311
V Predictions Std            398.76547
V Predictions Max            1684.4291
V Predictions Min            -240.27107
Log Pis Mean                 0.6285301
Log Pis Std                  3.2552073
Log Pis Max                  11.771563
Log Pis Min                  -9.567953
Policy mu Mean               0.010333475
Policy mu Std                0.6956614
Policy mu Max                3.1968057
Policy mu Min                -2.33435
Policy log std Mean          -1.0085815
Policy log std Std           0.29133084
Policy log std Max           0.08456075
Policy log std Min           -2.5821738
Z mean eval                  1.378882
Z variance eval              0.65500295
total_rewards                [1101.71411828 1306.60926108 1192.13855913  857.13442457 1050.94031995
 1027.93954513 1073.17375686 1323.72961574  941.76502663 1051.92371661]
total_rewards_mean           1092.7068343981132
total_rewards_std            139.7695995536755
total_rewards_max            1323.7296157413016
total_rewards_min            857.1344245696564
Number of train steps total  1896000
Number of env steps total    2372000
Number of rollouts total     0
Train Time (s)               144.45181028405204
(Previous) Eval Time (s)     15.603994777891785
Sample Time (s)              23.53177839424461
Epoch Time (s)               183.58758345618844
Total Train Time (s)         88211.18295536982
Epoch                        473
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:03:07.832772 UTC | [2020_01_11_13_32_55] Iteration #473 | Epoch Duration: 204.56631445884705
2020-01-12 14:03:07.832958 UTC | [2020_01_11_13_32_55] Iteration #473 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3814323
Z variance train             0.6539853
KL Divergence                25.608927
KL Loss                      2.5608928
QF Loss                      2092.9126
VF Loss                      656.3287
Policy Loss                  -1335.531
Q Predictions Mean           1341.0852
Q Predictions Std            423.4696
Q Predictions Max            1594.727
Q Predictions Min            -389.7795
V Predictions Mean           1339.8687
V Predictions Std            423.4298
V Predictions Max            1587.0012
V Predictions Min            -411.24332
Log Pis Mean                 1.3385751
Log Pis Std                  3.0364363
Log Pis Max                  16.067554
Log Pis Min                  -7.646263
Policy mu Mean               0.022415929
Policy mu Std                0.63908
Policy mu Max                3.4948142
Policy mu Min                -1.9637839
Policy log std Mean          -1.1812665
Policy log std Std           0.30856353
Policy log std Max           -0.2968545
Policy log std Min           -3.4893231
Z mean eval                  1.2783711
Z variance eval              0.013971458
total_rewards                [3409.68552911 4253.33762266   99.48232316 2061.47705689  519.06895131
 1527.49366291 3810.36706402   57.61771913 1643.87401178  180.27903319]
total_rewards_mean           1756.2682974166214
total_rewards_std            1516.2897523357763
total_rewards_max            4253.337622656544
total_rewards_min            57.617719126178926
Number of train steps total  1900000
Number of env steps total    2377000
Number of rollouts total     0
Train Time (s)               144.8442985569127
(Previous) Eval Time (s)     36.58236249629408
Sample Time (s)              25.69477069657296
Epoch Time (s)               207.12143174977973
Total Train Time (s)         88399.48865750479
Epoch                        474
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:06:16.143824 UTC | [2020_01_11_13_32_55] Iteration #474 | Epoch Duration: 188.31074166297913
2020-01-12 14:06:16.144014 UTC | [2020_01_11_13_32_55] Iteration #474 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2781439
Z variance train             0.013968569
KL Divergence                27.061981
KL Loss                      2.7061982
QF Loss                      888.40125
VF Loss                      413.18805
Policy Loss                  -1388.7251
Q Predictions Mean           1389.7037
Q Predictions Std            422.0169
Q Predictions Max            1670.1482
Q Predictions Min            -424.65347
V Predictions Mean           1386.1442
V Predictions Std            416.67987
V Predictions Max            1656.0173
V Predictions Min            -419.06387
Log Pis Mean                 0.76645666
Log Pis Std                  2.9859643
Log Pis Max                  12.268265
Log Pis Min                  -8.0291195
Policy mu Mean               0.056432508
Policy mu Std                0.6613855
Policy mu Max                2.9306037
Policy mu Min                -2.6034892
Policy log std Mean          -1.0835979
Policy log std Std           0.31320938
Policy log std Max           -0.081909776
Policy log std Min           -2.7584414
Z mean eval                  1.2718847
Z variance eval              0.010924087
total_rewards                [4047.27876232 3630.93653273 1408.21469773 4250.48287146 1494.19776841
 1759.47495618 1020.07999845 4230.90570494 4098.92940223 3904.46894636]
total_rewards_mean           2984.49696407961
total_rewards_std            1298.353682609015
total_rewards_max            4250.482871455225
total_rewards_min            1020.0799984515195
Number of train steps total  1904000
Number of env steps total    2382000
Number of rollouts total     0
Train Time (s)               136.29112322581932
(Previous) Eval Time (s)     17.77122580166906
Sample Time (s)              22.74755282793194
Epoch Time (s)               176.80990185542032
Total Train Time (s)         88582.16056196438
Epoch                        475
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:09:18.820428 UTC | [2020_01_11_13_32_55] Iteration #475 | Epoch Duration: 182.67628288269043
2020-01-12 14:09:18.820626 UTC | [2020_01_11_13_32_55] Iteration #475 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2719975
Z variance train             0.01091807
KL Divergence                28.435532
KL Loss                      2.8435533
QF Loss                      1557.4629
VF Loss                      400.96118
Policy Loss                  -1415.0394
Q Predictions Mean           1420.1753
Q Predictions Std            350.84
Q Predictions Max            1664.324
Q Predictions Min            -314.7161
V Predictions Mean           1422.6462
V Predictions Std            351.04385
V Predictions Max            1667.7965
V Predictions Min            -316.4924
Log Pis Mean                 1.0004351
Log Pis Std                  3.216037
Log Pis Max                  16.590252
Log Pis Min                  -8.956633
Policy mu Mean               0.028025135
Policy mu Std                0.6855283
Policy mu Max                2.3117578
Policy mu Min                -2.2522247
Policy log std Mean          -1.0647066
Policy log std Std           0.3339731
Policy log std Max           -0.106253624
Policy log std Min           -2.4378057
Z mean eval                  1.254463
Z variance eval              0.0078026326
total_rewards                [4041.67768714 2979.03317106 4107.90874449  765.26641804 3626.78336159
 2271.33665627   15.11248135  618.14243415 1505.56124884  894.35203533]
total_rewards_mean           2082.517423827709
total_rewards_std            1451.3094897488627
total_rewards_max            4107.908744487388
total_rewards_min            15.112481351429325
Number of train steps total  1908000
Number of env steps total    2387000
Number of rollouts total     0
Train Time (s)               136.79899644013494
(Previous) Eval Time (s)     23.637276753783226
Sample Time (s)              24.32816138723865
Epoch Time (s)               184.76443458115682
Total Train Time (s)         88761.32295708265
Epoch                        476
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:12:17.987793 UTC | [2020_01_11_13_32_55] Iteration #476 | Epoch Duration: 179.16703605651855
2020-01-12 14:12:17.987980 UTC | [2020_01_11_13_32_55] Iteration #476 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2551712
Z variance train             0.007807342
KL Divergence                30.208858
KL Loss                      3.020886
QF Loss                      825.4962
VF Loss                      2619.914
Policy Loss                  -1408.8661
Q Predictions Mean           1406.2042
Q Predictions Std            384.1071
Q Predictions Max            1658.6029
Q Predictions Min            -145.88484
V Predictions Mean           1402.9131
V Predictions Std            375.24423
V Predictions Max            1646.761
V Predictions Min            -147.39142
Log Pis Mean                 0.91560185
Log Pis Std                  3.2023416
Log Pis Max                  11.503868
Log Pis Min                  -8.742988
Policy mu Mean               -0.005258219
Policy mu Std                0.68030024
Policy mu Max                2.7811964
Policy mu Min                -3.1942754
Policy log std Mean          -1.0537939
Policy log std Std           0.3025359
Policy log std Max           -0.122510314
Policy log std Min           -2.4100528
Z mean eval                  1.2803311
Z variance eval              0.014633162
total_rewards                [3663.18734477 4132.94663128 4216.83757692 4098.65938922  142.73245886
 3510.81523995  643.72437954 4006.0124951    85.33660334 4068.73311762]
total_rewards_mean           2856.8985236607464
total_rewards_std            1698.0226878296146
total_rewards_max            4216.837576924051
total_rewards_min            85.33660334208524
Number of train steps total  1912000
Number of env steps total    2392000
Number of rollouts total     0
Train Time (s)               141.26049885619432
(Previous) Eval Time (s)     18.039585418999195
Sample Time (s)              23.617901895195246
Epoch Time (s)               182.91798617038876
Total Train Time (s)         88950.43522341968
Epoch                        477
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:15:27.106008 UTC | [2020_01_11_13_32_55] Iteration #477 | Epoch Duration: 189.11787343025208
2020-01-12 14:15:27.106296 UTC | [2020_01_11_13_32_55] Iteration #477 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2782736
Z variance train             0.0146013945
KL Divergence                30.092781
KL Loss                      3.009278
QF Loss                      1794.6073
VF Loss                      284.17822
Policy Loss                  -1389.2402
Q Predictions Mean           1382.5186
Q Predictions Std            424.91193
Q Predictions Max            1634.2686
Q Predictions Min            -317.9015
V Predictions Mean           1382.5513
V Predictions Std            414.78195
V Predictions Max            1628.6665
V Predictions Min            -335.43896
Log Pis Mean                 1.0297245
Log Pis Std                  3.1711876
Log Pis Max                  10.829105
Log Pis Min                  -7.9439383
Policy mu Mean               0.017507296
Policy mu Std                0.6541647
Policy mu Max                2.8234384
Policy mu Min                -3.0463712
Policy log std Mean          -1.0842344
Policy log std Std           0.3151992
Policy log std Max           -0.08614361
Policy log std Min           -2.4999416
Z mean eval                  1.3591567
Z variance eval              0.008228805
total_rewards                [4116.27478654 3891.43222961 4212.0337218  4151.30982098 3958.70587928
 2116.98328075 4248.60651667 4060.04705663  248.7092942  4141.21535752]
total_rewards_mean           3514.5317944001845
total_rewards_std            1242.6325972102488
total_rewards_max            4248.606516672358
total_rewards_min            248.70929420167306
Number of train steps total  1916000
Number of env steps total    2397000
Number of rollouts total     0
Train Time (s)               145.29530031699687
(Previous) Eval Time (s)     24.239113237708807
Sample Time (s)              26.358407460618764
Epoch Time (s)               195.89282101532444
Total Train Time (s)         89152.3520646831
Epoch                        478
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:18:49.026667 UTC | [2020_01_11_13_32_55] Iteration #478 | Epoch Duration: 201.9202013015747
2020-01-12 14:18:49.026854 UTC | [2020_01_11_13_32_55] Iteration #478 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.35748
Z variance train             0.008211478
KL Divergence                31.141945
KL Loss                      3.1141946
QF Loss                      1537.0098
VF Loss                      608.70233
Policy Loss                  -1417.6699
Q Predictions Mean           1421.1299
Q Predictions Std            372.4985
Q Predictions Max            1649.185
Q Predictions Min            -363.527
V Predictions Mean           1424.0507
V Predictions Std            375.20914
V Predictions Max            1644.091
V Predictions Min            -372.57996
Log Pis Mean                 1.2203227
Log Pis Std                  3.4674761
Log Pis Max                  19.717352
Log Pis Min                  -8.004421
Policy mu Mean               0.027074559
Policy mu Std                0.68394923
Policy mu Max                3.5089388
Policy mu Min                -3.6749294
Policy log std Mean          -1.0928373
Policy log std Std           0.3262054
Policy log std Max           0.0008831024
Policy log std Min           -3.0128486
Z mean eval                  1.3160177
Z variance eval              0.0036845687
total_rewards                [ 988.25611989 3877.6568558   188.25079406 4031.95007461 1897.48558828
  188.13105299 2156.89189239 2161.43295875 4055.37460699 1455.60961898]
total_rewards_mean           2100.10395627444
total_rewards_std            1404.4660491160666
total_rewards_max            4055.3746069889417
total_rewards_min            188.13105299402073
Number of train steps total  1920000
Number of env steps total    2402000
Number of rollouts total     0
Train Time (s)               144.97793995123357
(Previous) Eval Time (s)     30.26615854492411
Sample Time (s)              26.480793196242303
Epoch Time (s)               201.72489169239998
Total Train Time (s)         89348.10599225294
Epoch                        479
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:22:04.785333 UTC | [2020_01_11_13_32_55] Iteration #479 | Epoch Duration: 195.75834798812866
2020-01-12 14:22:04.785514 UTC | [2020_01_11_13_32_55] Iteration #479 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3170834
Z variance train             0.0036874455
KL Divergence                32.26693
KL Loss                      3.226693
QF Loss                      1253.3706
VF Loss                      310.35577
Policy Loss                  -1389.4786
Q Predictions Mean           1393.6154
Q Predictions Std            411.5697
Q Predictions Max            1667.2162
Q Predictions Min            -314.90384
V Predictions Mean           1388.6857
V Predictions Std            410.59747
V Predictions Max            1658.2025
V Predictions Min            -295.12677
Log Pis Mean                 1.2686533
Log Pis Std                  3.375618
Log Pis Max                  14.633198
Log Pis Min                  -6.9252295
Policy mu Mean               0.019485371
Policy mu Std                0.66792035
Policy mu Max                3.1113396
Policy mu Min                -2.6224775
Policy log std Mean          -1.1043396
Policy log std Std           0.32788223
Policy log std Max           0.103067994
Policy log std Min           -2.6418629
Z mean eval                  1.2840507
Z variance eval              0.006169238
total_rewards                [3906.07200078 2128.52012389 3915.85444325 4102.53389099 1536.55854378
 3191.70117559 4048.5454298  2417.81199385 2872.95182263 2618.20970022]
total_rewards_mean           3073.8759124784165
total_rewards_std            857.8428285162996
total_rewards_max            4102.53389099176
total_rewards_min            1536.5585437821
Number of train steps total  1924000
Number of env steps total    2407000
Number of rollouts total     0
Train Time (s)               146.4026445769705
(Previous) Eval Time (s)     24.299193973187357
Sample Time (s)              25.774222243577242
Epoch Time (s)               196.4760607937351
Total Train Time (s)         89550.53399986448
Epoch                        480
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:25:27.218250 UTC | [2020_01_11_13_32_55] Iteration #480 | Epoch Duration: 202.43260526657104
2020-01-12 14:25:27.218432 UTC | [2020_01_11_13_32_55] Iteration #480 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2847556
Z variance train             0.0061444985
KL Divergence                31.740356
KL Loss                      3.1740358
QF Loss                      1530.8594
VF Loss                      890.4309
Policy Loss                  -1413.0525
Q Predictions Mean           1421.5693
Q Predictions Std            355.44165
Q Predictions Max            1643.2048
Q Predictions Min            -332.41116
V Predictions Mean           1406.8052
V Predictions Std            357.82364
V Predictions Max            1637.7137
V Predictions Min            -354.4721
Log Pis Mean                 1.2371027
Log Pis Std                  3.4767842
Log Pis Max                  16.871292
Log Pis Min                  -6.496859
Policy mu Mean               -0.0036832285
Policy mu Std                0.67017376
Policy mu Max                2.7187006
Policy mu Min                -2.6336784
Policy log std Mean          -1.0832632
Policy log std Std           0.34107006
Policy log std Max           -0.16131568
Policy log std Min           -3.0815763
Z mean eval                  1.2774371
Z variance eval              0.003167153
total_rewards                [3931.14232212  727.97857062 1303.11039695 4036.59683335  980.10330248
 4020.87948852 2991.17492963 4034.81443624 4063.34936529 1303.67312532]
total_rewards_mean           2739.282277052189
total_rewards_std            1396.5912267143926
total_rewards_max            4063.349365293728
total_rewards_min            727.9785706211405
Number of train steps total  1928000
Number of env steps total    2412000
Number of rollouts total     0
Train Time (s)               142.06034151278436
(Previous) Eval Time (s)     30.255347757134587
Sample Time (s)              25.80817572493106
Epoch Time (s)               198.12386499485
Total Train Time (s)         89741.87998968735
Epoch                        481
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:28:38.568696 UTC | [2020_01_11_13_32_55] Iteration #481 | Epoch Duration: 191.35014033317566
2020-01-12 14:28:38.568857 UTC | [2020_01_11_13_32_55] Iteration #481 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2784303
Z variance train             0.003164351
KL Divergence                32.445137
KL Loss                      3.2445138
QF Loss                      1655.3043
VF Loss                      392.8418
Policy Loss                  -1347.1294
Q Predictions Mean           1349.5508
Q Predictions Std            463.65076
Q Predictions Max            1644.8472
Q Predictions Min            -346.20737
V Predictions Mean           1336.9607
V Predictions Std            456.5749
V Predictions Max            1630.251
V Predictions Min            -335.00723
Log Pis Mean                 1.079547
Log Pis Std                  3.2356815
Log Pis Max                  15.276214
Log Pis Min                  -8.595445
Policy mu Mean               0.02006113
Policy mu Std                0.66683424
Policy mu Max                2.5059693
Policy mu Min                -2.496041
Policy log std Mean          -1.0715313
Policy log std Std           0.33223712
Policy log std Max           -0.16592729
Policy log std Min           -2.7197537
Z mean eval                  1.2605608
Z variance eval              0.013134623
total_rewards                [2411.07214079 3896.95914681 1807.66105131 3346.90741701 1772.71026678
 3978.48701334 1533.02195977 3825.6482117   238.50837048 4056.24665171]
total_rewards_mean           2686.7222229708127
total_rewards_std            1255.0238434710488
total_rewards_max            4056.2466517109547
total_rewards_min            238.50837047747984
Number of train steps total  1932000
Number of env steps total    2417000
Number of rollouts total     0
Train Time (s)               136.34132685232908
(Previous) Eval Time (s)     23.481303841806948
Sample Time (s)              25.22287984378636
Epoch Time (s)               185.04551053792238
Total Train Time (s)         89927.78316302318
Epoch                        482
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:31:44.477224 UTC | [2020_01_11_13_32_55] Iteration #482 | Epoch Duration: 185.9082407951355
2020-01-12 14:31:44.477412 UTC | [2020_01_11_13_32_55] Iteration #482 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2596309
Z variance train             0.013136089
KL Divergence                30.437042
KL Loss                      3.0437043
QF Loss                      1070.3513
VF Loss                      574.1759
Policy Loss                  -1380.0869
Q Predictions Mean           1385.3693
Q Predictions Std            396.28506
Q Predictions Max            1641.4486
Q Predictions Min            -217.5763
V Predictions Mean           1384.9327
V Predictions Std            398.7757
V Predictions Max            1642.8066
V Predictions Min            -204.02646
Log Pis Mean                 1.0174199
Log Pis Std                  3.3098025
Log Pis Max                  17.791565
Log Pis Min                  -5.4506683
Policy mu Mean               0.012681352
Policy mu Std                0.6712866
Policy mu Max                2.5494657
Policy mu Min                -3.2473812
Policy log std Mean          -1.0726608
Policy log std Std           0.35689452
Policy log std Max           1.5016956
Policy log std Min           -3.5881371
Z mean eval                  1.2806847
Z variance eval              0.0059570037
total_rewards                [4024.37487713 3890.22457081 4117.67914386 4049.34467256 4042.53444709
 2484.02891579 2222.32126902 3928.01585522 2111.27634376 4249.60410978]
total_rewards_mean           3511.9404205028995
total_rewards_std            821.0838374972844
total_rewards_max            4249.604109783376
total_rewards_min            2111.27634376328
Number of train steps total  1936000
Number of env steps total    2422000
Number of rollouts total     0
Train Time (s)               136.97059504315257
(Previous) Eval Time (s)     24.343626049812883
Sample Time (s)              23.87374165095389
Epoch Time (s)               185.18796274391934
Total Train Time (s)         90120.62508731289
Epoch                        483
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:34:57.323803 UTC | [2020_01_11_13_32_55] Iteration #483 | Epoch Duration: 192.84625601768494
2020-01-12 14:34:57.323990 UTC | [2020_01_11_13_32_55] Iteration #483 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2814844
Z variance train             0.005954394
KL Divergence                32.723957
KL Loss                      3.2723958
QF Loss                      1058.0873
VF Loss                      234.74721
Policy Loss                  -1432.1649
Q Predictions Mean           1435.356
Q Predictions Std            368.36102
Q Predictions Max            1673.6755
Q Predictions Min            -415.5615
V Predictions Mean           1430.3711
V Predictions Std            362.34238
V Predictions Max            1665.3572
V Predictions Min            -426.12814
Log Pis Mean                 1.2000694
Log Pis Std                  3.2804964
Log Pis Max                  13.031046
Log Pis Min                  -8.591612
Policy mu Mean               0.047047153
Policy mu Std                0.69059783
Policy mu Max                2.5281298
Policy mu Min                -2.552315
Policy log std Mean          -1.0471158
Policy log std Std           0.3309764
Policy log std Max           -0.012432933
Policy log std Min           -3.0575728
Z mean eval                  1.2862558
Z variance eval              0.017034097
total_rewards                [4059.29469173 1442.57681804 3970.017085   1561.6810263  3906.02286236
 4278.49132983 2373.02594167 2739.42384929 3613.83874493 4072.87544927]
total_rewards_mean           3201.724779841198
total_rewards_std            1029.3061547009474
total_rewards_max            4278.491329834089
total_rewards_min            1442.5768180406044
Number of train steps total  1940000
Number of env steps total    2427000
Number of rollouts total     0
Train Time (s)               145.35181516129524
(Previous) Eval Time (s)     32.001535090152174
Sample Time (s)              25.4632827793248
Epoch Time (s)               202.8166330307722
Total Train Time (s)         90320.52728756145
Epoch                        484
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:38:17.230369 UTC | [2020_01_11_13_32_55] Iteration #484 | Epoch Duration: 199.90625429153442
2020-01-12 14:38:17.230545 UTC | [2020_01_11_13_32_55] Iteration #484 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2851589
Z variance train             0.01716609
KL Divergence                31.18988
KL Loss                      3.118988
QF Loss                      2113.8716
VF Loss                      1186.4056
Policy Loss                  -1411.8547
Q Predictions Mean           1414.1091
Q Predictions Std            379.50668
Q Predictions Max            1646.18
Q Predictions Min            -180.93674
V Predictions Mean           1415.4565
V Predictions Std            367.36676
V Predictions Max            1647.5714
V Predictions Min            -204.26793
Log Pis Mean                 1.1113964
Log Pis Std                  3.2318792
Log Pis Max                  15.545749
Log Pis Min                  -6.396242
Policy mu Mean               -0.03978399
Policy mu Std                0.665883
Policy mu Max                3.2442162
Policy mu Min                -2.5603368
Policy log std Mean          -1.0616572
Policy log std Std           0.3142296
Policy log std Max           -0.23269218
Policy log std Min           -3.1800294
Z mean eval                  1.2980814
Z variance eval              0.008807974
total_rewards                [ 953.59395169 4087.36707078 2331.64678929  215.55552718 1478.11669654
 2342.75317771 1668.17321002 4175.42676985 2816.17958553  886.24726188]
total_rewards_mean           2095.506004045558
total_rewards_std            1256.7462535352006
total_rewards_max            4175.426769845861
total_rewards_min            215.55552717871558
Number of train steps total  1944000
Number of env steps total    2432000
Number of rollouts total     0
Train Time (s)               144.74768203822896
(Previous) Eval Time (s)     29.09076203405857
Sample Time (s)              25.753392164595425
Epoch Time (s)               199.59183623688295
Total Train Time (s)         90515.10856095422
Epoch                        485
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:41:31.816644 UTC | [2020_01_11_13_32_55] Iteration #485 | Epoch Duration: 194.58597254753113
2020-01-12 14:41:31.816838 UTC | [2020_01_11_13_32_55] Iteration #485 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2969308
Z variance train             0.008851627
KL Divergence                31.982323
KL Loss                      3.1982324
QF Loss                      1803.7314
VF Loss                      1137.0511
Policy Loss                  -1386.7986
Q Predictions Mean           1388.6094
Q Predictions Std            424.40982
Q Predictions Max            1653.7253
Q Predictions Min            -449.10428
V Predictions Mean           1387.6089
V Predictions Std            421.84134
V Predictions Max            1638.052
V Predictions Min            -422.17532
Log Pis Mean                 1.3123167
Log Pis Std                  3.2392387
Log Pis Max                  14.234524
Log Pis Min                  -7.5598
Policy mu Mean               -0.015548561
Policy mu Std                0.6865556
Policy mu Max                2.4308271
Policy mu Min                -2.7828271
Policy log std Mean          -1.0750955
Policy log std Std           0.33168456
Policy log std Max           -0.1244908
Policy log std Min           -2.800064
Z mean eval                  1.3208904
Z variance eval              0.017819833
total_rewards                [3779.71500487 3629.10544378  765.16148615 1997.6195717   876.81323935
  967.43985341 3848.27227655   94.14743755  304.43056698 3903.95801786]
total_rewards_mean           2016.6662898217623
total_rewards_std            1523.7962266882653
total_rewards_max            3903.958017859891
total_rewards_min            94.1474375510766
Number of train steps total  1948000
Number of env steps total    2437000
Number of rollouts total     0
Train Time (s)               144.279210222885
(Previous) Eval Time (s)     24.084467619191855
Sample Time (s)              25.855294274166226
Epoch Time (s)               194.2189721162431
Total Train Time (s)         90710.84303749725
Epoch                        486
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:44:47.556182 UTC | [2020_01_11_13_32_55] Iteration #486 | Epoch Duration: 195.7392077445984
2020-01-12 14:44:47.556391 UTC | [2020_01_11_13_32_55] Iteration #486 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3224542
Z variance train             0.017761892
KL Divergence                31.075356
KL Loss                      3.1075356
QF Loss                      741.0478
VF Loss                      361.58014
Policy Loss                  -1460.0125
Q Predictions Mean           1464.3962
Q Predictions Std            304.84885
Q Predictions Max            1646.5475
Q Predictions Min            -379.17523
V Predictions Mean           1456.3518
V Predictions Std            303.2738
V Predictions Max            1648.875
V Predictions Min            -391.56238
Log Pis Mean                 0.8373897
Log Pis Std                  3.3715103
Log Pis Max                  15.284478
Log Pis Min                  -5.91449
Policy mu Mean               -0.022610404
Policy mu Std                0.6896365
Policy mu Max                3.3030725
Policy mu Min                -3.3098867
Policy log std Mean          -1.036852
Policy log std Std           0.32232472
Policy log std Max           -0.04985118
Policy log std Min           -2.9040833
Z mean eval                  1.3430376
Z variance eval              0.0143940495
total_rewards                [4003.93652831 2217.65242627  794.69704259  855.04837616 1553.35500183
 1790.02083462  155.61758161 3897.11529284  631.48427525  169.00742625]
total_rewards_mean           1606.7934785743541
total_rewards_std            1332.3075839009527
total_rewards_max            4003.936528312805
total_rewards_min            155.61758161371117
Number of train steps total  1952000
Number of env steps total    2442000
Number of rollouts total     0
Train Time (s)               144.66716866195202
(Previous) Eval Time (s)     25.604379917960614
Sample Time (s)              26.58072158927098
Epoch Time (s)               196.8522701691836
Total Train Time (s)         90899.3858674625
Epoch                        487
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:47:56.104205 UTC | [2020_01_11_13_32_55] Iteration #487 | Epoch Duration: 188.54767680168152
2020-01-12 14:47:56.104394 UTC | [2020_01_11_13_32_55] Iteration #487 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3442049
Z variance train             0.014434131
KL Divergence                30.867586
KL Loss                      3.0867586
QF Loss                      899.9492
VF Loss                      190.73376
Policy Loss                  -1383.1025
Q Predictions Mean           1384.7041
Q Predictions Std            438.25894
Q Predictions Max            1652.8547
Q Predictions Min            -224.80383
V Predictions Mean           1381.6953
V Predictions Std            435.18082
V Predictions Max            1661.4994
V Predictions Min            -223.47455
Log Pis Mean                 0.74717575
Log Pis Std                  3.508577
Log Pis Max                  16.511162
Log Pis Min                  -9.289669
Policy mu Mean               0.008004992
Policy mu Std                0.65872765
Policy mu Max                3.3504305
Policy mu Min                -2.5620599
Policy log std Mean          -1.0470045
Policy log std Std           0.32433313
Policy log std Max           -0.14966047
Policy log std Min           -2.4617374
Z mean eval                  1.3223944
Z variance eval              0.0100585455
total_rewards                [3722.41181881 1535.52582972 2736.15599628 3069.46647004 2114.19866655
  518.72992316 2937.85865428 4180.65938823 4105.23810602 4031.4217997 ]
total_rewards_mean           2895.16666527732
total_rewards_std            1151.3317477498163
total_rewards_max            4180.6593882264715
total_rewards_min            518.7299231579418
Number of train steps total  1956000
Number of env steps total    2447000
Number of rollouts total     0
Train Time (s)               137.0284484210424
(Previous) Eval Time (s)     17.29937090165913
Sample Time (s)              25.947112313471735
Epoch Time (s)               180.27493163617328
Total Train Time (s)         91087.59366836818
Epoch                        488
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:51:04.317314 UTC | [2020_01_11_13_32_55] Iteration #488 | Epoch Duration: 188.21278619766235
2020-01-12 14:51:04.317497 UTC | [2020_01_11_13_32_55] Iteration #488 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3225514
Z variance train             0.0100341495
KL Divergence                29.89014
KL Loss                      2.9890141
QF Loss                      6869.5
VF Loss                      1699.5969
Policy Loss                  -1398.2797
Q Predictions Mean           1392.5746
Q Predictions Std            409.03116
Q Predictions Max            1640.1393
Q Predictions Min            -143.3307
V Predictions Mean           1392.9336
V Predictions Std            389.3949
V Predictions Max            1626.2155
V Predictions Min            -148.16228
Log Pis Mean                 1.3973737
Log Pis Std                  4.097639
Log Pis Max                  22.502644
Log Pis Min                  -10.943005
Policy mu Mean               -0.032481246
Policy mu Std                0.7348146
Policy mu Max                3.8574429
Policy mu Min                -4.374435
Policy log std Mean          -1.0562446
Policy log std Std           0.36509627
Policy log std Max           -0.097458005
Policy log std Min           -3.4195967
Z mean eval                  1.2848465
Z variance eval              0.008321035
total_rewards                [ 326.39004742 1729.65141559   44.72723996   35.89587903  549.66216162
  873.88692842  341.459415    744.66331553 4278.04778348 3315.29477197]
total_rewards_mean           1223.9678958027303
total_rewards_std            1383.8474094747978
total_rewards_max            4278.047783483197
total_rewards_min            35.89587903167412
Number of train steps total  1960000
Number of env steps total    2452000
Number of rollouts total     0
Train Time (s)               137.164143437054
(Previous) Eval Time (s)     25.236731267068535
Sample Time (s)              25.13905849820003
Epoch Time (s)               187.53993320232257
Total Train Time (s)         91260.22008224856
Epoch                        489
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:53:56.948745 UTC | [2020_01_11_13_32_55] Iteration #489 | Epoch Duration: 172.6311023235321
2020-01-12 14:53:56.948983 UTC | [2020_01_11_13_32_55] Iteration #489 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2847246
Z variance train             0.008369548
KL Divergence                30.263443
KL Loss                      3.0263443
QF Loss                      1227.6741
VF Loss                      225.2344
Policy Loss                  -1413.9153
Q Predictions Mean           1415.133
Q Predictions Std            374.99655
Q Predictions Max            1649.2131
Q Predictions Min            -389.86618
V Predictions Mean           1411.2544
V Predictions Std            369.55786
V Predictions Max            1642.1451
V Predictions Min            -399.1764
Log Pis Mean                 1.1585245
Log Pis Std                  3.4212093
Log Pis Max                  29.344578
Log Pis Min                  -8.489636
Policy mu Mean               0.026850367
Policy mu Std                0.66781664
Policy mu Max                3.660962
Policy mu Min                -2.423268
Policy log std Mean          -1.0562893
Policy log std Std           0.34146428
Policy log std Max           0.28078437
Policy log std Min           -4.0762067
Z mean eval                  1.254648
Z variance eval              0.016521571
total_rewards                [ 831.43903974 3932.05994321 3550.07307695 3683.57545327 3998.84501893
  356.00056166 1718.9552478   198.93593337 4054.54607407 2932.78922809]
total_rewards_mean           2525.7219577097176
total_rewards_std            1506.1174000352437
total_rewards_max            4054.5460740701697
total_rewards_min            198.9359333733386
Number of train steps total  1964000
Number of env steps total    2457000
Number of rollouts total     0
Train Time (s)               139.3555060038343
(Previous) Eval Time (s)     10.327514803037047
Sample Time (s)              24.544699685648084
Epoch Time (s)               174.22772049251944
Total Train Time (s)         91446.54853580985
Epoch                        490
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:57:03.282150 UTC | [2020_01_11_13_32_55] Iteration #490 | Epoch Duration: 186.3330042362213
2020-01-12 14:57:03.282404 UTC | [2020_01_11_13_32_55] Iteration #490 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2558155
Z variance train             0.01651601
KL Divergence                28.473639
KL Loss                      2.847364
QF Loss                      754.817
VF Loss                      156.65436
Policy Loss                  -1478.346
Q Predictions Mean           1479.1475
Q Predictions Std            289.1424
Q Predictions Max            1684.1381
Q Predictions Min            -257.88184
V Predictions Mean           1478.7904
V Predictions Std            285.42627
V Predictions Max            1681.5748
V Predictions Min            -245.84984
Log Pis Mean                 0.59057456
Log Pis Std                  3.2278328
Log Pis Max                  11.029369
Log Pis Min                  -9.37649
Policy mu Mean               -0.005332064
Policy mu Std                0.6460332
Policy mu Max                3.0909405
Policy mu Min                -2.6929245
Policy log std Mean          -1.0298209
Policy log std Std           0.27820894
Policy log std Max           -0.0728575
Policy log std Min           -2.4609327
Z mean eval                  1.2567129
Z variance eval              0.009242326
total_rewards                [ 969.69441905 3323.78612647 2044.15237563 3972.97338433 1475.10103019
 2232.16392965 3682.23980863 2833.87065268 3480.00467481 2855.84867486]
total_rewards_mean           2686.983507629387
total_rewards_std            936.302844082515
total_rewards_max            3972.9733843302092
total_rewards_min            969.6944190457352
Number of train steps total  1968000
Number of env steps total    2462000
Number of rollouts total     0
Train Time (s)               145.49867247603834
(Previous) Eval Time (s)     22.43241783697158
Sample Time (s)              26.550185749772936
Epoch Time (s)               194.48127606278285
Total Train Time (s)         91643.72680651955
Epoch                        491
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:00:20.465715 UTC | [2020_01_11_13_32_55] Iteration #491 | Epoch Duration: 197.18314456939697
2020-01-12 15:00:20.465963 UTC | [2020_01_11_13_32_55] Iteration #491 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2580342
Z variance train             0.009274824
KL Divergence                29.875141
KL Loss                      2.9875143
QF Loss                      2082.4736
VF Loss                      653.1263
Policy Loss                  -1392.1045
Q Predictions Mean           1397.3032
Q Predictions Std            424.75845
Q Predictions Max            1659.2782
Q Predictions Min            -382.71976
V Predictions Mean           1392.8723
V Predictions Std            426.592
V Predictions Max            1649.0494
V Predictions Min            -405.885
Log Pis Mean                 1.2636105
Log Pis Std                  3.6501186
Log Pis Max                  20.093006
Log Pis Min                  -8.284058
Policy mu Mean               0.036411855
Policy mu Std                0.69574225
Policy mu Max                2.6849058
Policy mu Min                -3.0989175
Policy log std Mean          -1.0728132
Policy log std Std           0.3514065
Policy log std Max           -0.24612641
Policy log std Min           -3.6255286
Z mean eval                  1.2882392
Z variance eval              0.009304024
total_rewards                [4068.46443237 3336.87554442 3459.66323307 -103.15489505 2797.60135481
 4098.17265541 2488.07078959 3880.1527435  3994.74695373 2935.78907351]
total_rewards_mean           3095.638188536618
total_rewards_std            1195.066050107995
total_rewards_max            4098.172655408278
total_rewards_min            -103.15489505336237
Number of train steps total  1972000
Number of env steps total    2467000
Number of rollouts total     0
Train Time (s)               144.77729445276782
(Previous) Eval Time (s)     25.133905011229217
Sample Time (s)              24.739595751278102
Epoch Time (s)               194.65079521527514
Total Train Time (s)         91845.49689043267
Epoch                        492
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:03:42.238554 UTC | [2020_01_11_13_32_55] Iteration #492 | Epoch Duration: 201.7724485397339
2020-01-12 15:03:42.238674 UTC | [2020_01_11_13_32_55] Iteration #492 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2906547
Z variance train             0.009352642
KL Divergence                30.01552
KL Loss                      3.001552
QF Loss                      1468.6155
VF Loss                      450.3915
Policy Loss                  -1435.0455
Q Predictions Mean           1441.5359
Q Predictions Std            344.3096
Q Predictions Max            1654.3358
Q Predictions Min            -275.64252
V Predictions Mean           1435.251
V Predictions Std            341.37198
V Predictions Max            1646.9728
V Predictions Min            -303.551
Log Pis Mean                 1.3799013
Log Pis Std                  3.1655855
Log Pis Max                  15.369223
Log Pis Min                  -7.069193
Policy mu Mean               0.0412787
Policy mu Std                0.6936836
Policy mu Max                2.6560788
Policy mu Min                -3.677746
Policy log std Mean          -1.0774883
Policy log std Std           0.3048934
Policy log std Max           0.90572166
Policy log std Min           -2.894531
Z mean eval                  1.2969205
Z variance eval              0.005734324
total_rewards                [ 646.39632487 3969.67454898 4407.06236441 4018.80842459  308.55987117
 4222.10351979 1411.95269892 1066.0693408  3510.67446654 1561.03543272]
total_rewards_mean           2512.233699278245
total_rewards_std            1563.6217859363057
total_rewards_max            4407.062364405788
total_rewards_min            308.5598711680299
Number of train steps total  1976000
Number of env steps total    2472000
Number of rollouts total     0
Train Time (s)               147.3889290620573
(Previous) Eval Time (s)     32.25521593214944
Sample Time (s)              26.360260570887476
Epoch Time (s)               206.0044055650942
Total Train Time (s)         92046.22699337825
Epoch                        493
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:07:02.974113 UTC | [2020_01_11_13_32_55] Iteration #493 | Epoch Duration: 200.73533511161804
2020-01-12 15:07:02.974325 UTC | [2020_01_11_13_32_55] Iteration #493 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2977962
Z variance train             0.005728834
KL Divergence                31.336718
KL Loss                      3.1336718
QF Loss                      1078.6381
VF Loss                      1915.5159
Policy Loss                  -1411.0734
Q Predictions Mean           1415.0918
Q Predictions Std            391.9975
Q Predictions Max            1644.9591
Q Predictions Min            -362.7636
V Predictions Mean           1417.0999
V Predictions Std            382.4174
V Predictions Max            1639.9374
V Predictions Min            -354.64227
Log Pis Mean                 0.8504358
Log Pis Std                  3.3559918
Log Pis Max                  16.035961
Log Pis Min                  -7.2879143
Policy mu Mean               -0.0037176793
Policy mu Std                0.7040194
Policy mu Max                2.863473
Policy mu Min                -3.0401409
Policy log std Mean          -1.034765
Policy log std Std           0.305353
Policy log std Max           -0.17990077
Policy log std Min           -2.6189086
Z mean eval                  1.3158462
Z variance eval              0.02655344
total_rewards                [4046.57247817 4033.08195025  125.37423779 3855.79252114 4152.25937797
 4098.31007544 4080.66839745 3767.62283895 4296.62631016   82.63288812]
total_rewards_mean           3253.8941075447437
total_rewards_std            1581.0487202887266
total_rewards_max            4296.6263101596205
total_rewards_min            82.63288811976454
Number of train steps total  1980000
Number of env steps total    2477000
Number of rollouts total     0
Train Time (s)               143.68062480492517
(Previous) Eval Time (s)     26.98576199123636
Sample Time (s)              25.4374162084423
Epoch Time (s)               196.10380300460383
Total Train Time (s)         92243.40660334984
Epoch                        494
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:10:20.158776 UTC | [2020_01_11_13_32_55] Iteration #494 | Epoch Duration: 197.18429446220398
2020-01-12 15:10:20.158970 UTC | [2020_01_11_13_32_55] Iteration #494 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3242841
Z variance train             0.026630346
KL Divergence                28.224604
KL Loss                      2.8224604
QF Loss                      1742.741
VF Loss                      356.4812
Policy Loss                  -1418.4393
Q Predictions Mean           1425.9995
Q Predictions Std            385.9011
Q Predictions Max            1670.6179
Q Predictions Min            -403.43753
V Predictions Mean           1420.0696
V Predictions Std            385.46497
V Predictions Max            1673.4799
V Predictions Min            -388.34824
Log Pis Mean                 1.0461669
Log Pis Std                  3.356106
Log Pis Max                  15.592231
Log Pis Min                  -6.6400805
Policy mu Mean               0.07514736
Policy mu Std                0.7066383
Policy mu Max                3.17468
Policy mu Min                -2.5421615
Policy log std Mean          -1.0644274
Policy log std Std           0.31297764
Policy log std Max           -0.14561653
Policy log std Min           -3.0424757
Z mean eval                  1.2650236
Z variance eval              0.012889152
total_rewards                [ 532.60518429   99.95957541 1543.54067446 4150.83261551 3875.51157655
 2419.18442999 4382.39369995 1122.83836785  216.49672037 3844.71791499]
total_rewards_mean           2218.8080759366494
total_rewards_std            1638.3347380808245
total_rewards_max            4382.3936999520665
total_rewards_min            99.95957541231445
Number of train steps total  1984000
Number of env steps total    2482000
Number of rollouts total     0
Train Time (s)               136.19965146388859
(Previous) Eval Time (s)     28.065871614031494
Sample Time (s)              25.52135776076466
Epoch Time (s)               189.78688083868474
Total Train Time (s)         92426.36106200423
Epoch                        495
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:13:23.118187 UTC | [2020_01_11_13_32_55] Iteration #495 | Epoch Duration: 182.95908665657043
2020-01-12 15:13:23.118357 UTC | [2020_01_11_13_32_55] Iteration #495 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2615731
Z variance train             0.012805479
KL Divergence                29.42314
KL Loss                      2.942314
QF Loss                      1868.2391
VF Loss                      415.54868
Policy Loss                  -1434.6605
Q Predictions Mean           1432.2683
Q Predictions Std            344.69537
Q Predictions Max            1649.119
Q Predictions Min            -200.16927
V Predictions Mean           1421.5616
V Predictions Std            331.98828
V Predictions Max            1633.8627
V Predictions Min            -185.64294
Log Pis Mean                 1.286435
Log Pis Std                  3.2813396
Log Pis Max                  11.447509
Log Pis Min                  -6.8260903
Policy mu Mean               0.012766043
Policy mu Std                0.70072013
Policy mu Max                2.714156
Policy mu Min                -2.4593089
Policy log std Mean          -1.0904515
Policy log std Std           0.3467599
Policy log std Max           0.18273234
Policy log std Min           -3.0396762
Z mean eval                  1.3034637
Z variance eval              0.00839943
total_rewards                [3710.59537231 4028.85126855 3841.44644505 3007.63090306 3705.54588109
 3936.43459611 3209.18641428 4021.80599154 3805.68882664 3794.75550971]
total_rewards_mean           3706.1941208339376
total_rewards_std            320.591904526785
total_rewards_max            4028.851268553416
total_rewards_min            3007.630903055755
Number of train steps total  1988000
Number of env steps total    2487000
Number of rollouts total     0
Train Time (s)               136.65748585015535
(Previous) Eval Time (s)     21.237713812850416
Sample Time (s)              23.994957058224827
Epoch Time (s)               181.8901567212306
Total Train Time (s)         92621.10236654757
Epoch                        496
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:16:37.865943 UTC | [2020_01_11_13_32_55] Iteration #496 | Epoch Duration: 194.74744057655334
2020-01-12 15:16:37.866206 UTC | [2020_01_11_13_32_55] Iteration #496 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3053105
Z variance train             0.008407378
KL Divergence                31.225597
KL Loss                      3.1225598
QF Loss                      798.2832
VF Loss                      485.47467
Policy Loss                  -1450.3907
Q Predictions Mean           1450.771
Q Predictions Std            347.02173
Q Predictions Max            1670.0079
Q Predictions Min            -274.13403
V Predictions Mean           1440.5221
V Predictions Std            345.617
V Predictions Max            1642.3213
V Predictions Min            -285.04398
Log Pis Mean                 0.6107142
Log Pis Std                  3.177225
Log Pis Max                  14.824634
Log Pis Min                  -6.9762497
Policy mu Mean               0.011835732
Policy mu Std                0.6753981
Policy mu Max                3.4099886
Policy mu Min                -3.6141405
Policy log std Mean          -1.0153329
Policy log std Std           0.3020959
Policy log std Max           0.4825977
Policy log std Min           -2.8628566
Z mean eval                  1.3042606
Z variance eval              0.037797194
total_rewards                [4167.19383159 3963.34474605  202.72277675 3952.7073939  3866.32179233
 3834.53904798 1733.42024644 3812.52298788 3934.89339863 3867.81206377]
total_rewards_mean           3333.547828533666
total_rewards_std            1234.8584710973344
total_rewards_max            4167.19383159196
total_rewards_min            202.72277675423447
Number of train steps total  1992000
Number of env steps total    2492000
Number of rollouts total     0
Train Time (s)               144.9440123969689
(Previous) Eval Time (s)     34.094645894132555
Sample Time (s)              26.272939747199416
Epoch Time (s)               205.31159803830087
Total Train Time (s)         92823.86162900645
Epoch                        497
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:20:00.629417 UTC | [2020_01_11_13_32_55] Iteration #497 | Epoch Duration: 202.76303553581238
2020-01-12 15:20:00.629668 UTC | [2020_01_11_13_32_55] Iteration #497 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3058429
Z variance train             0.037840243
KL Divergence                28.8665
KL Loss                      2.88665
QF Loss                      1493.8423
VF Loss                      533.68164
Policy Loss                  -1448.506
Q Predictions Mean           1450.4966
Q Predictions Std            345.23883
Q Predictions Max            1663.0591
Q Predictions Min            -418.14798
V Predictions Mean           1443.759
V Predictions Std            336.45728
V Predictions Max            1646.893
V Predictions Min            -385.84964
Log Pis Mean                 1.2512488
Log Pis Std                  3.9054198
Log Pis Max                  19.452513
Log Pis Min                  -8.617945
Policy mu Mean               -0.025275875
Policy mu Std                0.74106324
Policy mu Max                3.5595307
Policy mu Min                -2.8944964
Policy log std Mean          -1.0541397
Policy log std Std           0.35154465
Policy log std Max           -0.13499516
Policy log std Min           -3.0344005
Z mean eval                  1.2682801
Z variance eval              0.01431724
total_rewards                [3561.93892559 3687.07305459 1260.67628721  782.55828204 4018.66629485
 1140.09552917  399.87373735 4096.62387621 3846.54337301 2731.62707509]
total_rewards_mean           2552.5676435121704
total_rewards_std            1413.4004468019996
total_rewards_max            4096.623876213699
total_rewards_min            399.8737373514286
Number of train steps total  1996000
Number of env steps total    2497000
Number of rollouts total     0
Train Time (s)               144.027944045607
(Previous) Eval Time (s)     31.545667428988963
Sample Time (s)              27.028934423811734
Epoch Time (s)               202.6025458984077
Total Train Time (s)         93021.00051768497
Epoch                        498
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:23:17.773548 UTC | [2020_01_11_13_32_55] Iteration #498 | Epoch Duration: 197.1437418460846
2020-01-12 15:23:17.773742 UTC | [2020_01_11_13_32_55] Iteration #498 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.267654
Z variance train             0.014286744
KL Divergence                32.151062
KL Loss                      3.2151062
QF Loss                      1395.1741
VF Loss                      981.5106
Policy Loss                  -1428.416
Q Predictions Mean           1430.5013
Q Predictions Std            395.29483
Q Predictions Max            1675.8207
Q Predictions Min            -312.3605
V Predictions Mean           1417.4819
V Predictions Std            387.40353
V Predictions Max            1647.246
V Predictions Min            -308.3949
Log Pis Mean                 1.0460932
Log Pis Std                  3.3218048
Log Pis Max                  11.971806
Log Pis Min                  -8.80813
Policy mu Mean               -0.023102783
Policy mu Std                0.6585734
Policy mu Max                2.9391181
Policy mu Min                -2.8515081
Policy log std Mean          -1.0932864
Policy log std Std           0.3125933
Policy log std Max           0.27648997
Policy log std Min           -2.4169402
Z mean eval                  1.2938445
Z variance eval              0.03072593
total_rewards                [1927.69865748   92.9975489  4148.41043089 2910.89566168  354.98835769
 1459.50022091  808.28118484 3891.94239926 3914.87025577  537.57431916]
total_rewards_mean           2004.7159036567493
total_rewards_std            1512.954783880214
total_rewards_max            4148.410430890277
total_rewards_min            92.99754889746859
Number of train steps total  2000000
Number of env steps total    2502000
Number of rollouts total     0
Train Time (s)               142.2268861536868
(Previous) Eval Time (s)     26.086521167773753
Sample Time (s)              24.318316324148327
Epoch Time (s)               192.63172364560887
Total Train Time (s)         93208.71589445043
Epoch                        499
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:26:25.493653 UTC | [2020_01_11_13_32_55] Iteration #499 | Epoch Duration: 187.7197709083557
2020-01-12 15:26:25.493901 UTC | [2020_01_11_13_32_55] Iteration #499 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2942811
Z variance train             0.030637216
KL Divergence                29.66787
KL Loss                      2.966787
QF Loss                      987.06616
VF Loss                      534.766
Policy Loss                  -1433.4686
Q Predictions Mean           1438.1758
Q Predictions Std            368.3224
Q Predictions Max            1664.6685
Q Predictions Min            -408.4486
V Predictions Mean           1436.3065
V Predictions Std            370.76105
V Predictions Max            1656.1346
V Predictions Min            -430.42896
Log Pis Mean                 0.907341
Log Pis Std                  3.6233852
Log Pis Max                  13.655501
Log Pis Min                  -8.402489
Policy mu Mean               0.025353257
Policy mu Std                0.6993912
Policy mu Max                3.0608475
Policy mu Min                -2.567195
Policy log std Mean          -1.0639904
Policy log std Std           0.32366836
Policy log std Max           -0.070690036
Policy log std Min           -2.7742171
Z mean eval                  1.3134326
Z variance eval              0.018142072
total_rewards                [-1.49195634e-01  2.55666489e+03  3.94928537e+03  5.43139549e+02
  4.22259398e+03  4.08260265e+03  4.23225628e+03  1.29072670e+03
  4.15310576e+03  1.18496416e+03]
total_rewards_mean           2621.519014989401
total_rewards_std            1625.826310706187
total_rewards_max            4232.256281753428
total_rewards_min            -0.14919563353715448
Number of train steps total  2004000
Number of env steps total    2507000
Number of rollouts total     0
Train Time (s)               144.77796438522637
(Previous) Eval Time (s)     21.174198522232473
Sample Time (s)              25.9946430712007
Epoch Time (s)               191.94680597865954
Total Train Time (s)         93404.05535210902
Epoch                        500
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:29:40.838418 UTC | [2020_01_11_13_32_55] Iteration #500 | Epoch Duration: 195.34434580802917
2020-01-12 15:29:40.838665 UTC | [2020_01_11_13_32_55] Iteration #500 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3117926
Z variance train             0.018165512
KL Divergence                30.237286
KL Loss                      3.0237286
QF Loss                      1685.8479
VF Loss                      354.37488
Policy Loss                  -1401.9089
Q Predictions Mean           1403.9707
Q Predictions Std            430.1897
Q Predictions Max            1663.0785
Q Predictions Min            -256.35678
V Predictions Mean           1394.8325
V Predictions Std            419.9359
V Predictions Max            1641.9198
V Predictions Min            -261.14014
Log Pis Mean                 1.1233648
Log Pis Std                  3.4049413
Log Pis Max                  19.543686
Log Pis Min                  -6.804589
Policy mu Mean               0.046891056
Policy mu Std                0.6483576
Policy mu Max                2.873164
Policy mu Min                -2.6616824
Policy log std Mean          -1.1058817
Policy log std Std           0.34778216
Policy log std Max           -0.14105988
Policy log std Min           -3.500061
Z mean eval                  1.282762
Z variance eval              0.015336449
total_rewards                [3757.6601445  3986.15111697 4083.66954495 3888.88911331 1915.5578562
 3972.79741939 2419.88536775 4005.84937853 3881.05376806 3480.92235119]
total_rewards_mean           3539.2436060858117
total_rewards_std            712.8342993125289
total_rewards_max            4083.669544945973
total_rewards_min            1915.5578562042754
Number of train steps total  2008000
Number of env steps total    2512000
Number of rollouts total     0
Train Time (s)               138.6395878731273
(Previous) Eval Time (s)     24.571342923212796
Sample Time (s)              26.56087814318016
Epoch Time (s)               189.77180893952027
Total Train Time (s)         93600.37487064395
Epoch                        501
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:32:57.162450 UTC | [2020_01_11_13_32_55] Iteration #501 | Epoch Duration: 196.32364463806152
2020-01-12 15:32:57.162641 UTC | [2020_01_11_13_32_55] Iteration #501 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2837474
Z variance train             0.015392701
KL Divergence                30.330618
KL Loss                      3.0330617
QF Loss                      1692.8042
VF Loss                      235.43402
Policy Loss                  -1390.3357
Q Predictions Mean           1396.9326
Q Predictions Std            436.68045
Q Predictions Max            1697.6511
Q Predictions Min            -445.24136
V Predictions Mean           1394.4308
V Predictions Std            439.9222
V Predictions Max            1663.2028
V Predictions Min            -428.2394
Log Pis Mean                 1.0275798
Log Pis Std                  3.3115308
Log Pis Max                  11.491959
Log Pis Min                  -8.090981
Policy mu Mean               -0.00054012006
Policy mu Std                0.6683028
Policy mu Max                2.7764003
Policy mu Min                -2.541479
Policy log std Mean          -1.0751975
Policy log std Std           0.32351393
Policy log std Max           -0.14511895
Policy log std Min           -2.6259527
Z mean eval                  1.3100343
Z variance eval              0.022592518
total_rewards                [3147.90385117 1752.01974242  520.6047941   632.18608787  312.52820202
   97.66484199 1917.56257381 2964.89604434  578.38403159 1975.59340081]
total_rewards_mean           1389.9343570123424
total_rewards_std            1055.5922374361737
total_rewards_max            3147.903851174972
total_rewards_min            97.66484199159649
Number of train steps total  2012000
Number of env steps total    2517000
Number of rollouts total     0
Train Time (s)               136.70004718191922
(Previous) Eval Time (s)     31.12284636683762
Sample Time (s)              25.339294629637152
Epoch Time (s)               193.162188178394
Total Train Time (s)         93779.88384934282
Epoch                        502
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:35:56.676712 UTC | [2020_01_11_13_32_55] Iteration #502 | Epoch Duration: 179.51394057273865
2020-01-12 15:35:56.676895 UTC | [2020_01_11_13_32_55] Iteration #502 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3109683
Z variance train             0.02256121
KL Divergence                28.93466
KL Loss                      2.893466
QF Loss                      722.2279
VF Loss                      296.39764
Policy Loss                  -1436.0979
Q Predictions Mean           1437.9375
Q Predictions Std            371.02036
Q Predictions Max            1685.6617
Q Predictions Min            -395.47748
V Predictions Mean           1431.5342
V Predictions Std            369.27762
V Predictions Max            1680.3772
V Predictions Min            -387.97354
Log Pis Mean                 0.80503064
Log Pis Std                  3.3185282
Log Pis Max                  13.182997
Log Pis Min                  -8.946641
Policy mu Mean               0.0070430934
Policy mu Std                0.68731916
Policy mu Max                2.44803
Policy mu Min                -3.120989
Policy log std Mean          -1.0376855
Policy log std Std           0.31998298
Policy log std Max           0.34352005
Policy log std Min           -2.8148835
Z mean eval                  1.2589537
Z variance eval              0.01083051
total_rewards                [1106.53196217 3907.01444521 2170.54983857  612.00272155  361.28575998
 1018.37668693 1387.75002296 4046.87181814 1571.27467442 1912.02796828]
total_rewards_mean           1809.36858982189
total_rewards_std            1201.3432907570636
total_rewards_max            4046.871818142986
total_rewards_min            361.28575998479636
Number of train steps total  2016000
Number of env steps total    2522000
Number of rollouts total     0
Train Time (s)               139.6452703010291
(Previous) Eval Time (s)     17.474267178215086
Sample Time (s)              23.89845307217911
Epoch Time (s)               181.01799055142328
Total Train Time (s)         93963.36370490957
Epoch                        503
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:39:00.161600 UTC | [2020_01_11_13_32_55] Iteration #503 | Epoch Duration: 183.48456978797913
2020-01-12 15:39:00.161796 UTC | [2020_01_11_13_32_55] Iteration #503 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2595512
Z variance train             0.010830413
KL Divergence                29.235054
KL Loss                      2.9235055
QF Loss                      2389.2085
VF Loss                      321.50992
Policy Loss                  -1435.772
Q Predictions Mean           1435.833
Q Predictions Std            361.51886
Q Predictions Max            1659.7479
Q Predictions Min            -281.13452
V Predictions Mean           1428.0283
V Predictions Std            359.85486
V Predictions Max            1647.6864
V Predictions Min            -314.08063
Log Pis Mean                 0.9394269
Log Pis Std                  3.3645647
Log Pis Max                  20.498573
Log Pis Min                  -8.497449
Policy mu Mean               0.03574681
Policy mu Std                0.69482607
Policy mu Max                3.6324308
Policy mu Min                -3.0544882
Policy log std Mean          -1.0384609
Policy log std Std           0.29923722
Policy log std Max           -0.17680597
Policy log std Min           -2.552168
Z mean eval                  1.2939126
Z variance eval              0.013693636
total_rewards                [2047.26976282 2536.08043675 4316.25529987 3895.6981626  4272.08476486
 2000.64437683 4016.9100833  4281.44708497 3820.66334789 4134.41596336]
total_rewards_mean           3532.1469283245815
total_rewards_std            898.8563797290575
total_rewards_max            4316.255299867467
total_rewards_min            2000.6443768306726
Number of train steps total  2020000
Number of env steps total    2527000
Number of rollouts total     0
Train Time (s)               146.78061837423593
(Previous) Eval Time (s)     19.940510021988302
Sample Time (s)              26.0016010790132
Epoch Time (s)               192.72272947523743
Total Train Time (s)         94168.32976336963
Epoch                        504
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:42:25.133294 UTC | [2020_01_11_13_32_55] Iteration #504 | Epoch Duration: 204.97135305404663
2020-01-12 15:42:25.133523 UTC | [2020_01_11_13_32_55] Iteration #504 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.293814
Z variance train             0.0137281045
KL Divergence                29.645523
KL Loss                      2.9645524
QF Loss                      8737.921
VF Loss                      2508.3782
Policy Loss                  -1421.1594
Q Predictions Mean           1429.9858
Q Predictions Std            396.8984
Q Predictions Max            1669.3584
Q Predictions Min            -447.9908
V Predictions Mean           1426.9902
V Predictions Std            394.67194
V Predictions Max            1651.2086
V Predictions Min            -433.89133
Log Pis Mean                 1.0976208
Log Pis Std                  3.53312
Log Pis Max                  16.32828
Log Pis Min                  -7.895973
Policy mu Mean               0.05029367
Policy mu Std                0.69884944
Policy mu Max                3.325264
Policy mu Min                -3.897508
Policy log std Mean          -1.0600573
Policy log std Std           0.3081509
Policy log std Max           0.8852452
Policy log std Min           -2.4166896
Z mean eval                  1.3014107
Z variance eval              0.022918755
total_rewards                [1177.845952    464.29336392  116.88815567 2718.7789963   695.13185055
 1251.03579111 3656.0384971  4128.80352022 2539.6815027  4005.55298488]
total_rewards_mean           2075.40506144591
total_rewards_std            1445.3934234790563
total_rewards_max            4128.803520223852
total_rewards_min            116.88815566672871
Number of train steps total  2024000
Number of env steps total    2532000
Number of rollouts total     0
Train Time (s)               145.23421198595315
(Previous) Eval Time (s)     32.188767592888325
Sample Time (s)              24.765008420683444
Epoch Time (s)               202.18798799952492
Total Train Time (s)         94356.53578114929
Epoch                        505
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:45:33.342019 UTC | [2020_01_11_13_32_55] Iteration #505 | Epoch Duration: 188.2083775997162
2020-01-12 15:45:33.342138 UTC | [2020_01_11_13_32_55] Iteration #505 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2997365
Z variance train             0.022881879
KL Divergence                29.133999
KL Loss                      2.9134
QF Loss                      2251.7832
VF Loss                      2903.7222
Policy Loss                  -1384.6038
Q Predictions Mean           1384.9034
Q Predictions Std            433.93356
Q Predictions Max            1662.0521
Q Predictions Min            -384.76624
V Predictions Mean           1392.6769
V Predictions Std            416.2362
V Predictions Max            1662.1504
V Predictions Min            -388.6704
Log Pis Mean                 1.0903251
Log Pis Std                  3.4321992
Log Pis Max                  13.567831
Log Pis Min                  -7.32694
Policy mu Mean               0.032542273
Policy mu Std                0.68766946
Policy mu Max                2.6300745
Policy mu Min                -2.6976743
Policy log std Mean          -1.0679226
Policy log std Std           0.36929178
Policy log std Max           -0.18377244
Policy log std Min           -2.904613
Z mean eval                  1.3347104
Z variance eval              0.024847012
total_rewards                [3972.74727237   30.78825517   96.30751285 2302.13285208 2426.78735786
 4280.65762263  618.82236399 3652.89814781  454.47759119 3952.77844429]
total_rewards_mean           2178.839742022193
total_rewards_std            1655.0007029501999
total_rewards_max            4280.657622632216
total_rewards_min            30.78825516704854
Number of train steps total  2028000
Number of env steps total    2537000
Number of rollouts total     0
Train Time (s)               145.7997703542933
(Previous) Eval Time (s)     18.20878405123949
Sample Time (s)              25.60836720932275
Epoch Time (s)               189.61692161485553
Total Train Time (s)         94547.4263214618
Epoch                        506
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:48:44.238168 UTC | [2020_01_11_13_32_55] Iteration #506 | Epoch Duration: 190.89593148231506
2020-01-12 15:48:44.238354 UTC | [2020_01_11_13_32_55] Iteration #506 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3343642
Z variance train             0.024818636
KL Divergence                30.106663
KL Loss                      3.0106664
QF Loss                      1831.919
VF Loss                      256.90802
Policy Loss                  -1376.6566
Q Predictions Mean           1379.1462
Q Predictions Std            453.901
Q Predictions Max            1667.5032
Q Predictions Min            -405.0447
V Predictions Mean           1377.5242
V Predictions Std            451.68594
V Predictions Max            1667.9496
V Predictions Min            -425.31354
Log Pis Mean                 1.07325
Log Pis Std                  3.7109294
Log Pis Max                  18.201431
Log Pis Min                  -5.8829017
Policy mu Mean               0.024651665
Policy mu Std                0.70099276
Policy mu Max                3.1208508
Policy mu Min                -2.4576616
Policy log std Mean          -1.0775907
Policy log std Std           0.34775215
Policy log std Max           -0.19835865
Policy log std Min           -3.0264683
Z mean eval                  1.2893072
Z variance eval              0.025436878
total_rewards                [3979.66468364 4007.01802537 4043.30875297 2911.38640071 4029.31082211
  205.4094277  3036.32119219 1212.96390883 2311.08900735  274.75915008]
total_rewards_mean           2601.123137094849
total_rewards_std            1464.4014717106425
total_rewards_max            4043.308752969421
total_rewards_min            205.40942770277815
Number of train steps total  2032000
Number of env steps total    2542000
Number of rollouts total     0
Train Time (s)               144.31229431880638
(Previous) Eval Time (s)     19.487397281918675
Sample Time (s)              24.050105481874198
Epoch Time (s)               187.84979708259925
Total Train Time (s)         94739.40297356294
Epoch                        507
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:51:56.219855 UTC | [2020_01_11_13_32_55] Iteration #507 | Epoch Duration: 191.98136806488037
2020-01-12 15:51:56.220044 UTC | [2020_01_11_13_32_55] Iteration #507 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2884296
Z variance train             0.025373599
KL Divergence                30.216599
KL Loss                      3.0216599
QF Loss                      7113.9033
VF Loss                      331.77792
Policy Loss                  -1449.4886
Q Predictions Mean           1455.6062
Q Predictions Std            328.27676
Q Predictions Max            1654.7671
Q Predictions Min            -270.00128
V Predictions Mean           1444.7874
V Predictions Std            328.17877
V Predictions Max            1638.2255
V Predictions Min            -303.473
Log Pis Mean                 0.8556961
Log Pis Std                  3.2341003
Log Pis Max                  12.652581
Log Pis Min                  -7.2663646
Policy mu Mean               0.03963264
Policy mu Std                0.6781981
Policy mu Max                3.020028
Policy mu Min                -2.3439698
Policy log std Mean          -1.0712004
Policy log std Std           0.3181962
Policy log std Max           -0.20289087
Policy log std Min           -2.811482
Z mean eval                  1.330403
Z variance eval              0.011677826
total_rewards                [2017.56032369 1051.65106126 3770.33596978 1003.95987153  539.49775705
  738.89490962  796.0383325  1284.45638091  433.20562626 1189.34639469]
total_rewards_mean           1282.494662728269
total_rewards_std            931.3808814616592
total_rewards_max            3770.3359697794763
total_rewards_min            433.2056262621829
Number of train steps total  2036000
Number of env steps total    2547000
Number of rollouts total     0
Train Time (s)               137.02415766986087
(Previous) Eval Time (s)     23.618672801647335
Sample Time (s)              25.365643518511206
Epoch Time (s)               186.0084739900194
Total Train Time (s)         94915.12534223124
Epoch                        508
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:54:51.948786 UTC | [2020_01_11_13_32_55] Iteration #508 | Epoch Duration: 175.7286033630371
2020-01-12 15:54:51.948985 UTC | [2020_01_11_13_32_55] Iteration #508 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3316035
Z variance train             0.011674328
KL Divergence                31.446354
KL Loss                      3.1446354
QF Loss                      899.5624
VF Loss                      498.6716
Policy Loss                  -1439.3225
Q Predictions Mean           1443.1793
Q Predictions Std            356.18268
Q Predictions Max            1656.6274
Q Predictions Min            -301.21
V Predictions Mean           1443.8083
V Predictions Std            349.01273
V Predictions Max            1650.5662
V Predictions Min            -288.523
Log Pis Mean                 0.93798196
Log Pis Std                  3.8031292
Log Pis Max                  20.682236
Log Pis Min                  -10.773946
Policy mu Mean               0.0338097
Policy mu Std                0.72358936
Policy mu Max                2.9704304
Policy mu Min                -2.8677998
Policy log std Mean          -1.033809
Policy log std Std           0.31079856
Policy log std Max           -0.06384826
Policy log std Min           -2.8854327
Z mean eval                  1.3397894
Z variance eval              0.01327166
total_rewards                [4355.68082694 1371.56842607 3851.10326747 3871.64998048  983.94874171
 3972.34186627  192.72906655  575.8097238  1507.67769433 3505.39311798]
total_rewards_mean           2418.790271159406
total_rewards_std            1544.2017648163906
total_rewards_max            4355.6808269425555
total_rewards_min            192.72906654559003
Number of train steps total  2040000
Number of env steps total    2552000
Number of rollouts total     0
Train Time (s)               136.96283246483654
(Previous) Eval Time (s)     13.338396233972162
Sample Time (s)              25.405702671967447
Epoch Time (s)               175.70693137077615
Total Train Time (s)         95098.89943161001
Epoch                        509
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:57:55.727002 UTC | [2020_01_11_13_32_55] Iteration #509 | Epoch Duration: 183.77786254882812
2020-01-12 15:57:55.727221 UTC | [2020_01_11_13_32_55] Iteration #509 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3410738
Z variance train             0.013239515
KL Divergence                31.537552
KL Loss                      3.1537552
QF Loss                      834.73486
VF Loss                      491.15982
Policy Loss                  -1413.5792
Q Predictions Mean           1419.0189
Q Predictions Std            393.30502
Q Predictions Max            1701.2263
Q Predictions Min            -385.01776
V Predictions Mean           1414.1763
V Predictions Std            393.3342
V Predictions Max            1683.3213
V Predictions Min            -379.51852
Log Pis Mean                 1.6296904
Log Pis Std                  3.7270646
Log Pis Max                  15.342667
Log Pis Min                  -10.267556
Policy mu Mean               0.030372333
Policy mu Std                0.7091097
Policy mu Max                2.802039
Policy mu Min                -2.9846907
Policy log std Mean          -1.119753
Policy log std Std           0.3480526
Policy log std Max           -0.20255172
Policy log std Min           -2.8158026
Z mean eval                  1.3411466
Z variance eval              0.022438878
total_rewards                [2387.38474106  645.39395891 4213.24360196  696.81653469 3994.71008538
 2228.58361868  706.00510153 1657.73371443 1094.81216391 4051.82218697]
total_rewards_mean           2167.6505707531205
total_rewards_std            1383.9334817749284
total_rewards_max            4213.24360195658
total_rewards_min            645.3939589118494
Number of train steps total  2044000
Number of env steps total    2557000
Number of rollouts total     0
Train Time (s)               141.88896255288273
(Previous) Eval Time (s)     21.408924089744687
Sample Time (s)              24.199248610064387
Epoch Time (s)               187.4971352526918
Total Train Time (s)         95284.01517796936
Epoch                        510
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:01:00.848234 UTC | [2020_01_11_13_32_55] Iteration #510 | Epoch Duration: 185.12085342407227
2020-01-12 16:01:00.848515 UTC | [2020_01_11_13_32_55] Iteration #510 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3414863
Z variance train             0.022458227
KL Divergence                29.828121
KL Loss                      2.9828122
QF Loss                      1300.6754
VF Loss                      249.64941
Policy Loss                  -1461.4597
Q Predictions Mean           1463.4506
Q Predictions Std            319.1587
Q Predictions Max            1664.2372
Q Predictions Min            -386.6223
V Predictions Mean           1469.0613
V Predictions Std            313.25116
V Predictions Max            1649.6906
V Predictions Min            -380.75125
Log Pis Mean                 1.2709486
Log Pis Std                  3.285857
Log Pis Max                  14.558659
Log Pis Min                  -6.065787
Policy mu Mean               -0.019661682
Policy mu Std                0.6746459
Policy mu Max                3.0570068
Policy mu Min                -3.0717406
Policy log std Mean          -1.0719893
Policy log std Std           0.32204297
Policy log std Max           0.99208224
Policy log std Min           -2.6428044
Z mean eval                  1.3189166
Z variance eval              0.01708338
total_rewards                [ 273.73263712 1369.02038789 4056.52703448 3866.11015817 4153.36046496
 4167.57862799 2347.19437171 2784.75472268 1170.18430603 1735.1244154 ]
total_rewards_mean           2592.358712643897
total_rewards_std            1356.886578491577
total_rewards_max            4167.578627989959
total_rewards_min            273.7326371241304
Number of train steps total  2048000
Number of env steps total    2562000
Number of rollouts total     0
Train Time (s)               145.9954457259737
(Previous) Eval Time (s)     19.032271542120725
Sample Time (s)              26.85558986151591
Epoch Time (s)               191.88330712961033
Total Train Time (s)         95479.86797295604
Epoch                        511
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:04:16.706969 UTC | [2020_01_11_13_32_55] Iteration #511 | Epoch Duration: 195.8582832813263
2020-01-12 16:04:16.707294 UTC | [2020_01_11_13_32_55] Iteration #511 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3175939
Z variance train             0.017072774
KL Divergence                29.781944
KL Loss                      2.9781945
QF Loss                      619.5276
VF Loss                      280.20776
Policy Loss                  -1451.0651
Q Predictions Mean           1453.6965
Q Predictions Std            329.70587
Q Predictions Max            1641.7091
Q Predictions Min            -251.45947
V Predictions Mean           1452.3301
V Predictions Std            329.6015
V Predictions Max            1649.3469
V Predictions Min            -255.02696
Log Pis Mean                 1.1009288
Log Pis Std                  3.263313
Log Pis Max                  11.694735
Log Pis Min                  -6.7673583
Policy mu Mean               0.026115423
Policy mu Std                0.7007996
Policy mu Max                2.9419222
Policy mu Min                -2.6207814
Policy log std Mean          -1.0498912
Policy log std Std           0.30219135
Policy log std Max           0.063899994
Policy log std Min           -2.585823
Z mean eval                  1.2863686
Z variance eval              0.010414165
total_rewards                [3354.17225793 1953.035115   2811.10238473  270.59238253 1798.03465962
 2350.61215081  -13.296713    965.20359398 2140.26917408  239.53912032]
total_rewards_mean           1586.926412599967
total_rewards_std            1103.8664860375707
total_rewards_max            3354.1722579336624
total_rewards_min            -13.296713003446214
Number of train steps total  2052000
Number of env steps total    2567000
Number of rollouts total     0
Train Time (s)               144.83651724690571
(Previous) Eval Time (s)     23.006897777784616
Sample Time (s)              26.02449626242742
Epoch Time (s)               193.86791128711775
Total Train Time (s)         95675.10305902641
Epoch                        512
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:07:31.945523 UTC | [2020_01_11_13_32_55] Iteration #512 | Epoch Duration: 195.23809456825256
2020-01-12 16:07:31.945651 UTC | [2020_01_11_13_32_55] Iteration #512 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2829837
Z variance train             0.010403354
KL Divergence                30.907501
KL Loss                      3.0907502
QF Loss                      938.9894
VF Loss                      183.09976
Policy Loss                  -1388.542
Q Predictions Mean           1394.535
Q Predictions Std            432.2784
Q Predictions Max            1652.193
Q Predictions Min            -386.32993
V Predictions Mean           1390.9242
V Predictions Std            434.42874
V Predictions Max            1652.0864
V Predictions Min            -387.6177
Log Pis Mean                 1.2655392
Log Pis Std                  3.4553869
Log Pis Max                  14.134876
Log Pis Min                  -6.6864295
Policy mu Mean               0.057960704
Policy mu Std                0.68563426
Policy mu Max                2.9298804
Policy mu Min                -2.3814747
Policy log std Mean          -1.072608
Policy log std Std           0.34846935
Policy log std Max           0.14136577
Policy log std Min           -3.1062422
Z mean eval                  1.3626595
Z variance eval              0.010337135
total_rewards                [2954.02256421  -26.08376846 1778.89156886 3958.73156295 1416.15296826
 1534.70817336 3591.70246716  883.96234081 1124.93447434 4249.80731217]
total_rewards_mean           2146.682966366049
total_rewards_std            1372.928879981397
total_rewards_max            4249.8073121713
total_rewards_min            -26.08376845770575
Number of train steps total  2056000
Number of env steps total    2572000
Number of rollouts total     0
Train Time (s)               146.86560905911028
(Previous) Eval Time (s)     24.376671514939517
Sample Time (s)              25.772248803637922
Epoch Time (s)               197.01452937768772
Total Train Time (s)         95870.84838777874
Epoch                        513
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:10:47.696839 UTC | [2020_01_11_13_32_55] Iteration #513 | Epoch Duration: 195.75108528137207
2020-01-12 16:10:47.697038 UTC | [2020_01_11_13_32_55] Iteration #513 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3637446
Z variance train             0.010345756
KL Divergence                29.806007
KL Loss                      2.9806008
QF Loss                      940.3844
VF Loss                      232.79503
Policy Loss                  -1429.3251
Q Predictions Mean           1431.9941
Q Predictions Std            403.55585
Q Predictions Max            1684.2301
Q Predictions Min            -424.7969
V Predictions Mean           1423.4695
V Predictions Std            398.98825
V Predictions Max            1684.4446
V Predictions Min            -418.5629
Log Pis Mean                 1.204776
Log Pis Std                  3.5761156
Log Pis Max                  13.40851
Log Pis Min                  -11.545773
Policy mu Mean               0.040493995
Policy mu Std                0.7218958
Policy mu Max                2.8877282
Policy mu Min                -3.0803607
Policy log std Mean          -1.0478442
Policy log std Std           0.3305437
Policy log std Max           -0.16379583
Policy log std Min           -2.8831224
Z mean eval                  1.3401893
Z variance eval              0.009820477
total_rewards                [1626.99031322 4234.03375205 3855.5935316   480.03859128 2858.57028826
  342.27955098 3374.35627855  361.10475916 4281.2743608  1845.17253545]
total_rewards_mean           2325.9413961358905
total_rewards_std            1520.1767069616926
total_rewards_max            4281.274360795454
total_rewards_min            342.2795509835008
Number of train steps total  2060000
Number of env steps total    2577000
Number of rollouts total     0
Train Time (s)               143.85153462784365
(Previous) Eval Time (s)     23.11283154692501
Sample Time (s)              25.407910929527134
Epoch Time (s)               192.3722771042958
Total Train Time (s)         96059.42428297456
Epoch                        514
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:13:56.278430 UTC | [2020_01_11_13_32_55] Iteration #514 | Epoch Duration: 188.5812509059906
2020-01-12 16:13:56.278647 UTC | [2020_01_11_13_32_55] Iteration #514 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3395313
Z variance train             0.009822578
KL Divergence                29.770472
KL Loss                      2.9770472
QF Loss                      865.63574
VF Loss                      418.38904
Policy Loss                  -1469.5801
Q Predictions Mean           1476.1576
Q Predictions Std            252.68062
Q Predictions Max            1647.1487
Q Predictions Min            -336.08548
V Predictions Mean           1485.161
V Predictions Std            254.72945
V Predictions Max            1660.8662
V Predictions Min            -348.67404
Log Pis Mean                 1.0100691
Log Pis Std                  2.992218
Log Pis Max                  11.4430485
Log Pis Min                  -6.8944464
Policy mu Mean               0.023965959
Policy mu Std                0.67490375
Policy mu Max                2.738916
Policy mu Min                -2.3189309
Policy log std Mean          -1.0833216
Policy log std Std           0.28229973
Policy log std Max           -0.0038827658
Policy log std Min           -2.326748
Z mean eval                  1.2948315
Z variance eval              0.010634631
total_rewards                [ 648.90573937 4057.33493741 1274.02242581 2776.52949869 2595.04893399
 1455.47144689 4140.94896057 3459.72097342 4091.77284259 1066.16131233]
total_rewards_mean           2556.591707108034
total_rewards_std            1292.392805331401
total_rewards_max            4140.948960571889
total_rewards_min            648.9057393720398
Number of train steps total  2064000
Number of env steps total    2582000
Number of rollouts total     0
Train Time (s)               136.5516701308079
(Previous) Eval Time (s)     19.321418047882617
Sample Time (s)              24.325110780075192
Epoch Time (s)               180.19819895876572
Total Train Time (s)         96242.5501741916
Epoch                        515
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:16:59.408615 UTC | [2020_01_11_13_32_55] Iteration #515 | Epoch Duration: 183.12982749938965
2020-01-12 16:16:59.408818 UTC | [2020_01_11_13_32_55] Iteration #515 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2943789
Z variance train             0.010633259
KL Divergence                30.335531
KL Loss                      3.0335531
QF Loss                      1557.4956
VF Loss                      405.679
Policy Loss                  -1401.5067
Q Predictions Mean           1408.7397
Q Predictions Std            424.718
Q Predictions Max            1668.5024
Q Predictions Min            -406.91394
V Predictions Mean           1404.5529
V Predictions Std            425.3165
V Predictions Max            1653.5889
V Predictions Min            -448.5873
Log Pis Mean                 0.53260195
Log Pis Std                  3.5043542
Log Pis Max                  12.203759
Log Pis Min                  -9.497568
Policy mu Mean               0.043297026
Policy mu Std                0.66312516
Policy mu Max                3.4546578
Policy mu Min                -2.1073143
Policy log std Mean          -1.0397068
Policy log std Std           0.3019504
Policy log std Max           0.12468374
Policy log std Min           -2.7525
Z mean eval                  1.2742943
Z variance eval              0.02033025
total_rewards                [1918.99445126  185.84154637  630.89579441 4087.70017707 1055.88297777
  747.14987647 3717.10145593 3997.97330636 2774.75434777  418.22968694]
total_rewards_mean           1953.4523620354619
total_rewards_std            1483.6634076542414
total_rewards_max            4087.7001770670686
total_rewards_min            185.84154637284902
Number of train steps total  2068000
Number of env steps total    2587000
Number of rollouts total     0
Train Time (s)               137.21033917181194
(Previous) Eval Time (s)     22.252751024905592
Sample Time (s)              25.052558878902346
Epoch Time (s)               184.51564907561988
Total Train Time (s)         96420.38052759506
Epoch                        516
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:19:57.244110 UTC | [2020_01_11_13_32_55] Iteration #516 | Epoch Duration: 177.83516359329224
2020-01-12 16:19:57.244295 UTC | [2020_01_11_13_32_55] Iteration #516 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2680123
Z variance train             0.020196365
KL Divergence                28.720577
KL Loss                      2.8720577
QF Loss                      2117.7864
VF Loss                      326.55093
Policy Loss                  -1441.7218
Q Predictions Mean           1443.4938
Q Predictions Std            335.3478
Q Predictions Max            1662.6458
Q Predictions Min            -382.92307
V Predictions Mean           1436.103
V Predictions Std            328.28476
V Predictions Max            1633.0938
V Predictions Min            -396.8439
Log Pis Mean                 1.2344768
Log Pis Std                  3.5116928
Log Pis Max                  22.420876
Log Pis Min                  -7.2535877
Policy mu Mean               0.033692677
Policy mu Std                0.6997192
Policy mu Max                3.9400623
Policy mu Min                -2.9327536
Policy log std Mean          -1.1034985
Policy log std Std           0.32876524
Policy log std Max           -0.118068695
Policy log std Min           -3.0645556
Z mean eval                  1.2789456
Z variance eval              0.007955411
total_rewards                [ 406.09231731 3999.11145942 4113.18540029 3898.16294936 1660.30505323
  649.23653884 2546.4424999  3821.43419118 2612.80325971 3373.94519105]
total_rewards_mean           2708.0718860310326
total_rewards_std            1319.520186092509
total_rewards_max            4113.185400294836
total_rewards_min            406.0923173137404
Number of train steps total  2072000
Number of env steps total    2592000
Number of rollouts total     0
Train Time (s)               144.1739124902524
(Previous) Eval Time (s)     15.571955785155296
Sample Time (s)              25.27004858199507
Epoch Time (s)               185.01591685740277
Total Train Time (s)         96614.98016466014
Epoch                        517
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:23:11.850008 UTC | [2020_01_11_13_32_55] Iteration #517 | Epoch Duration: 194.60554790496826
2020-01-12 16:23:11.850355 UTC | [2020_01_11_13_32_55] Iteration #517 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2792875
Z variance train             0.007971874
KL Divergence                30.839336
KL Loss                      3.0839336
QF Loss                      1193.8997
VF Loss                      364.67267
Policy Loss                  -1371.2247
Q Predictions Mean           1375.298
Q Predictions Std            433.3219
Q Predictions Max            1656.6754
Q Predictions Min            -416.16095
V Predictions Mean           1364.1367
V Predictions Std            428.85156
V Predictions Max            1660.0172
V Predictions Min            -437.8494
Log Pis Mean                 0.9495487
Log Pis Std                  3.5997958
Log Pis Max                  17.393194
Log Pis Min                  -7.445267
Policy mu Mean               0.008793911
Policy mu Std                0.72155863
Policy mu Max                3.1255636
Policy mu Min                -3.660426
Policy log std Mean          -1.0438178
Policy log std Std           0.31683934
Policy log std Max           0.047947526
Policy log std Min           -3.1325998
Z mean eval                  1.3397686
Z variance eval              0.00835375
total_rewards                [1455.98938925 4044.43780507  302.8814424   995.93749691 3228.67097479
 3279.85555225 2581.05462073  -43.38002505 3336.41672666  242.07363395]
total_rewards_mean           1942.3937616965109
total_rewards_std            1444.5707105883134
total_rewards_max            4044.4378050724863
total_rewards_min            -43.380025053517485
Number of train steps total  2076000
Number of env steps total    2597000
Number of rollouts total     0
Train Time (s)               144.41246785921976
(Previous) Eval Time (s)     25.16114724194631
Sample Time (s)              26.428248720709234
Epoch Time (s)               196.0018638218753
Total Train Time (s)         96809.33817212563
Epoch                        518
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:26:26.213022 UTC | [2020_01_11_13_32_55] Iteration #518 | Epoch Duration: 194.36249423027039
2020-01-12 16:26:26.213210 UTC | [2020_01_11_13_32_55] Iteration #518 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3385617
Z variance train             0.008355302
KL Divergence                31.700481
KL Loss                      3.1700482
QF Loss                      889.1671
VF Loss                      457.77914
Policy Loss                  -1423.0477
Q Predictions Mean           1425.5226
Q Predictions Std            386.31256
Q Predictions Max            1658.4751
Q Predictions Min            -413.61856
V Predictions Mean           1420.7312
V Predictions Std            379.1195
V Predictions Max            1633.5701
V Predictions Min            -366.50568
Log Pis Mean                 1.2860173
Log Pis Std                  3.7602665
Log Pis Max                  17.125654
Log Pis Min                  -7.983838
Policy mu Mean               0.017774824
Policy mu Std                0.69053334
Policy mu Max                3.9414988
Policy mu Min                -3.8654485
Policy log std Mean          -1.094883
Policy log std Std           0.3501331
Policy log std Max           -0.10145056
Policy log std Min           -2.6918259
Z mean eval                  1.2813038
Z variance eval              0.010780793
total_rewards                [2603.15865339 3271.14232686 2479.72819502 4143.57827382 1050.16956104
 3333.67016801 4327.96377696 4175.0099765  1530.7773927  3700.5100792 ]
total_rewards_mean           3061.570840349289
total_rewards_std            1071.3629521211838
total_rewards_max            4327.963776960896
total_rewards_min            1050.1695610357417
Number of train steps total  2080000
Number of env steps total    2602000
Number of rollouts total     0
Train Time (s)               143.47647880902514
(Previous) Eval Time (s)     23.521405200008303
Sample Time (s)              26.448118111584336
Epoch Time (s)               193.44600212061778
Total Train Time (s)         97007.79532656167
Epoch                        519
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:29:44.673956 UTC | [2020_01_11_13_32_55] Iteration #519 | Epoch Duration: 198.46061444282532
2020-01-12 16:29:44.674190 UTC | [2020_01_11_13_32_55] Iteration #519 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.285154
Z variance train             0.010673852
KL Divergence                30.444359
KL Loss                      3.044436
QF Loss                      1753.7781
VF Loss                      207.93036
Policy Loss                  -1460.0621
Q Predictions Mean           1467.273
Q Predictions Std            294.14352
Q Predictions Max            1676.8223
Q Predictions Min            -352.6207
V Predictions Mean           1468.9417
V Predictions Std            294.6685
V Predictions Max            1683.5278
V Predictions Min            -350.80832
Log Pis Mean                 1.1264312
Log Pis Std                  2.9966662
Log Pis Max                  10.198542
Log Pis Min                  -7.6563587
Policy mu Mean               0.029049449
Policy mu Std                0.6863637
Policy mu Max                3.1507976
Policy mu Min                -2.8051949
Policy log std Mean          -1.0703803
Policy log std Std           0.26690105
Policy log std Max           0.4028548
Policy log std Min           -2.1912827
Z mean eval                  1.2967745
Z variance eval              0.015042752
total_rewards                [4177.81040875 1251.83293594 1642.42636049 1058.16785794 4166.22722446
 4232.59973959 4129.98969085 1670.3308813  3534.92339157 2107.59812224]
total_rewards_mean           2797.1906613135084
total_rewards_std            1290.4470655130979
total_rewards_max            4232.599739587072
total_rewards_min            1058.1678579400889
Number of train steps total  2084000
Number of env steps total    2607000
Number of rollouts total     0
Train Time (s)               145.42327713407576
(Previous) Eval Time (s)     28.535625133197755
Sample Time (s)              25.528319428209215
Epoch Time (s)               199.48722169548273
Total Train Time (s)         97202.55515445862
Epoch                        520
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:32:59.439365 UTC | [2020_01_11_13_32_55] Iteration #520 | Epoch Duration: 194.7650294303894
2020-01-12 16:32:59.439590 UTC | [2020_01_11_13_32_55] Iteration #520 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.295225
Z variance train             0.015000488
KL Divergence                29.021101
KL Loss                      2.90211
QF Loss                      791.00574
VF Loss                      246.59712
Policy Loss                  -1417.7817
Q Predictions Mean           1420.8857
Q Predictions Std            393.43155
Q Predictions Max            1702.9095
Q Predictions Min            -399.22574
V Predictions Mean           1412.1676
V Predictions Std            389.81723
V Predictions Max            1667.355
V Predictions Min            -391.7795
Log Pis Mean                 1.0104927
Log Pis Std                  3.371808
Log Pis Max                  21.969614
Log Pis Min                  -8.290155
Policy mu Mean               0.0064305076
Policy mu Std                0.64393723
Policy mu Max                2.5425858
Policy mu Min                -4.115025
Policy log std Mean          -1.090231
Policy log std Std           0.33117864
Policy log std Max           -0.10559738
Policy log std Min           -2.9502769
Z mean eval                  1.2686203
Z variance eval              0.02829586
total_rewards                [1058.22213051 1815.42133956 3587.44191375 1802.21376433  912.65250075
 3949.68896024 2221.73460547 1513.19888086 1737.23332749 4093.95534892]
total_rewards_mean           2269.1762771880394
total_rewards_std            1117.0942618254207
total_rewards_max            4093.9553489204563
total_rewards_min            912.6525007481273
Number of train steps total  2088000
Number of env steps total    2612000
Number of rollouts total     0
Train Time (s)               139.28559428313747
(Previous) Eval Time (s)     23.81301772221923
Sample Time (s)              26.428469168022275
Epoch Time (s)               189.52708117337897
Total Train Time (s)         97387.35889066895
Epoch                        521
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:36:04.247827 UTC | [2020_01_11_13_32_55] Iteration #521 | Epoch Duration: 184.80810546875
2020-01-12 16:36:04.248006 UTC | [2020_01_11_13_32_55] Iteration #521 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2684981
Z variance train             0.028210465
KL Divergence                27.065825
KL Loss                      2.7065825
QF Loss                      1519.9285
VF Loss                      1718.8667
Policy Loss                  -1396.4723
Q Predictions Mean           1395.9906
Q Predictions Std            389.01135
Q Predictions Max            1630.5049
Q Predictions Min            -384.61365
V Predictions Mean           1387.7113
V Predictions Std            380.53918
V Predictions Max            1612.2947
V Predictions Min            -372.21695
Log Pis Mean                 1.3344786
Log Pis Std                  3.4087238
Log Pis Max                  14.164194
Log Pis Min                  -6.4918966
Policy mu Mean               0.032509185
Policy mu Std                0.69409984
Policy mu Max                2.9550872
Policy mu Min                -2.9380536
Policy log std Mean          -1.0723865
Policy log std Std           0.37533578
Policy log std Max           1.0838679
Policy log std Min           -3.238698
Z mean eval                  1.3353242
Z variance eval              0.015655331
total_rewards                [1485.93193571 4256.97141633 4215.6237148  4099.46135793 4111.1030447
  815.51294524  937.99872571 2035.97944218  935.94700828 4094.83430427]
total_rewards_mean           2698.9363895138963
total_rewards_std            1493.2929393998447
total_rewards_max            4256.971416326857
total_rewards_min            815.5129452389349
Number of train steps total  2092000
Number of env steps total    2617000
Number of rollouts total     0
Train Time (s)               135.94776969309896
(Previous) Eval Time (s)     19.093682296574116
Sample Time (s)              25.49259679345414
Epoch Time (s)               180.53404878312722
Total Train Time (s)         97571.64610415231
Epoch                        522
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:39:08.540162 UTC | [2020_01_11_13_32_55] Iteration #522 | Epoch Duration: 184.29202461242676
2020-01-12 16:39:08.540352 UTC | [2020_01_11_13_32_55] Iteration #522 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3358691
Z variance train             0.015587712
KL Divergence                28.497583
KL Loss                      2.8497584
QF Loss                      2917.2505
VF Loss                      176.21487
Policy Loss                  -1414.3494
Q Predictions Mean           1418.8895
Q Predictions Std            358.2737
Q Predictions Max            1653.7528
Q Predictions Min            -252.29207
V Predictions Mean           1413.8462
V Predictions Std            359.24655
V Predictions Max            1647.739
V Predictions Min            -254.83092
Log Pis Mean                 0.87537134
Log Pis Std                  3.4179287
Log Pis Max                  17.8442
Log Pis Min                  -9.06558
Policy mu Mean               0.020662362
Policy mu Std                0.65880847
Policy mu Max                3.912618
Policy mu Min                -2.497372
Policy log std Mean          -1.0704718
Policy log std Std           0.32056025
Policy log std Max           0.19757724
Policy log std Min           -2.9047403
Z mean eval                  1.2908777
Z variance eval              0.010969682
total_rewards                [2983.58797302 2130.26031643  840.26819952  858.97444893 1413.42699549
 4115.11630973  372.73004363 3198.01750927 2269.46024793 4135.55352034]
total_rewards_mean           2231.7395564288363
total_rewards_std            1289.5167314917633
total_rewards_max            4135.5535203378195
total_rewards_min            372.73004363380136
Number of train steps total  2096000
Number of env steps total    2622000
Number of rollouts total     0
Train Time (s)               139.78410527808592
(Previous) Eval Time (s)     22.851274566724896
Sample Time (s)              24.235354074276984
Epoch Time (s)               186.8707339190878
Total Train Time (s)         97754.2380658323
Epoch                        523
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:42:11.138246 UTC | [2020_01_11_13_32_55] Iteration #523 | Epoch Duration: 182.59773540496826
2020-01-12 16:42:11.138534 UTC | [2020_01_11_13_32_55] Iteration #523 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2906654
Z variance train             0.0109464405
KL Divergence                30.5195
KL Loss                      3.0519502
QF Loss                      771.47485
VF Loss                      630.50836
Policy Loss                  -1453.7385
Q Predictions Mean           1457.009
Q Predictions Std            337.222
Q Predictions Max            1680.986
Q Predictions Min            -321.98663
V Predictions Mean           1451.0673
V Predictions Std            341.20856
V Predictions Max            1674.5358
V Predictions Min            -333.85193
Log Pis Mean                 1.0369289
Log Pis Std                  3.1407406
Log Pis Max                  14.683099
Log Pis Min                  -6.348672
Policy mu Mean               0.014562259
Policy mu Std                0.6960617
Policy mu Max                3.546058
Policy mu Min                -2.3375833
Policy log std Mean          -1.0465976
Policy log std Std           0.28718
Policy log std Max           -0.2010063
Policy log std Min           -2.833198
Z mean eval                  1.3250746
Z variance eval              0.0071714707
total_rewards                [2203.1895821  4027.46508608 1020.21731185  708.72787879 3950.90107312
 4176.85106917 3417.75783145 4111.02265657  603.498795   1242.21764385]
total_rewards_mean           2546.1848927997603
total_rewards_std            1460.5368304770066
total_rewards_max            4176.851069174859
total_rewards_min            603.4987950045372
Number of train steps total  2100000
Number of env steps total    2627000
Number of rollouts total     0
Train Time (s)               147.01485707890242
(Previous) Eval Time (s)     18.57786112325266
Sample Time (s)              25.898927494417876
Epoch Time (s)               191.49164569657296
Total Train Time (s)         97948.955742219
Epoch                        524
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:45:25.860928 UTC | [2020_01_11_13_32_55] Iteration #524 | Epoch Duration: 194.72223591804504
2020-01-12 16:45:25.861142 UTC | [2020_01_11_13_32_55] Iteration #524 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.329138
Z variance train             0.0071846046
KL Divergence                31.349468
KL Loss                      3.1349468
QF Loss                      959.0367
VF Loss                      279.50085
Policy Loss                  -1414.2947
Q Predictions Mean           1416.19
Q Predictions Std            414.37802
Q Predictions Max            1707.0424
Q Predictions Min            -377.8552
V Predictions Mean           1413.3965
V Predictions Std            410.72534
V Predictions Max            1667.7018
V Predictions Min            -366.68646
Log Pis Mean                 1.3435147
Log Pis Std                  3.4587555
Log Pis Max                  12.356255
Log Pis Min                  -7.7746534
Policy mu Mean               0.013540193
Policy mu Std                0.70105404
Policy mu Max                2.4605951
Policy mu Min                -2.461208
Policy log std Mean          -1.0564288
Policy log std Std           0.32150885
Policy log std Max           -0.13119572
Policy log std Min           -2.8000336
Z mean eval                  1.3199674
Z variance eval              0.021961661
total_rewards                [3926.44798364 3345.50640117 2517.83230905 3907.36902737  107.25112888
 4147.30555532  112.30843561  973.66348517  137.26645133 3663.32587326]
total_rewards_mean           2283.827665080821
total_rewards_std            1663.3944071213027
total_rewards_max            4147.305555320434
total_rewards_min            107.25112888295011
Number of train steps total  2104000
Number of env steps total    2632000
Number of rollouts total     0
Train Time (s)               145.4624229138717
(Previous) Eval Time (s)     21.80805401178077
Sample Time (s)              25.39457948645577
Epoch Time (s)               192.66505641210824
Total Train Time (s)         98143.02216132777
Epoch                        525
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:48:39.932235 UTC | [2020_01_11_13_32_55] Iteration #525 | Epoch Duration: 194.0709569454193
2020-01-12 16:48:39.932434 UTC | [2020_01_11_13_32_55] Iteration #525 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.322243
Z variance train             0.021987978
KL Divergence                29.169306
KL Loss                      2.9169307
QF Loss                      1303.9268
VF Loss                      151.03659
Policy Loss                  -1426.8696
Q Predictions Mean           1432.019
Q Predictions Std            392.05954
Q Predictions Max            1684.7045
Q Predictions Min            -313.57083
V Predictions Mean           1425.6224
V Predictions Std            390.3814
V Predictions Max            1688.9376
V Predictions Min            -292.33334
Log Pis Mean                 1.0048102
Log Pis Std                  3.412276
Log Pis Max                  11.537733
Log Pis Min                  -8.59389
Policy mu Mean               0.016411336
Policy mu Std                0.7163469
Policy mu Max                3.280347
Policy mu Min                -2.9012642
Policy log std Mean          -1.0189284
Policy log std Std           0.29831302
Policy log std Max           -0.04063618
Policy log std Min           -2.5348728
Z mean eval                  1.2694968
Z variance eval              0.01443187
total_rewards                [3769.7273528    50.93799866 3123.46926187 3938.15203499 3890.86315185
 1942.02769662  267.09178522 2083.27428119  257.27754392 3875.84149108]
total_rewards_mean           2319.8662598201304
total_rewards_std            1551.4748606411274
total_rewards_max            3938.152034987787
total_rewards_min            50.9379986611423
Number of train steps total  2108000
Number of env steps total    2637000
Number of rollouts total     0
Train Time (s)               145.30149942589924
(Previous) Eval Time (s)     23.213598070666194
Sample Time (s)              25.65942705143243
Epoch Time (s)               194.17452454799786
Total Train Time (s)         98338.11122002453
Epoch                        526
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:51:55.028167 UTC | [2020_01_11_13_32_55] Iteration #526 | Epoch Duration: 195.0955572128296
2020-01-12 16:51:55.028543 UTC | [2020_01_11_13_32_55] Iteration #526 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2700906
Z variance train             0.0145311775
KL Divergence                30.019587
KL Loss                      3.0019586
QF Loss                      719.4757
VF Loss                      254.46284
Policy Loss                  -1406.3939
Q Predictions Mean           1409.5482
Q Predictions Std            418.26913
Q Predictions Max            1678.0964
Q Predictions Min            -283.9856
V Predictions Mean           1405.2583
V Predictions Std            415.77512
V Predictions Max            1673.5026
V Predictions Min            -274.12167
Log Pis Mean                 0.68950236
Log Pis Std                  3.2533963
Log Pis Max                  15.008353
Log Pis Min                  -6.5183473
Policy mu Mean               0.057080213
Policy mu Std                0.65040296
Policy mu Max                3.3599784
Policy mu Min                -2.1957579
Policy log std Mean          -1.0512922
Policy log std Std           0.30843642
Policy log std Max           -0.035242796
Policy log std Min           -2.4573698
Z mean eval                  1.3031065
Z variance eval              0.029396381
total_rewards                [ 644.37997776   43.79330118 1397.1428499   184.0763485  2306.73953697
  940.85031994  983.96392707 3344.95724423 4178.8532714  1044.45019721]
total_rewards_mean           1506.9206974162184
total_rewards_std            1288.8676130950687
total_rewards_max            4178.85327140136
total_rewards_min            43.79330118012319
Number of train steps total  2112000
Number of env steps total    2642000
Number of rollouts total     0
Train Time (s)               144.69594759773463
(Previous) Eval Time (s)     24.1342136641033
Sample Time (s)              25.235792006831616
Epoch Time (s)               194.06595326866955
Total Train Time (s)         98528.3903846168
Epoch                        527
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:55:05.312451 UTC | [2020_01_11_13_32_55] Iteration #527 | Epoch Duration: 190.28333020210266
2020-01-12 16:55:05.312668 UTC | [2020_01_11_13_32_55] Iteration #527 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3002428
Z variance train             0.029307505
KL Divergence                29.795279
KL Loss                      2.979528
QF Loss                      914.0419
VF Loss                      204.45332
Policy Loss                  -1442.5852
Q Predictions Mean           1447.6265
Q Predictions Std            362.41675
Q Predictions Max            1669.863
Q Predictions Min            -319.6981
V Predictions Mean           1445.4285
V Predictions Std            359.40402
V Predictions Max            1666.4569
V Predictions Min            -289.0557
Log Pis Mean                 1.3648934
Log Pis Std                  3.171669
Log Pis Max                  17.721395
Log Pis Min                  -6.175971
Policy mu Mean               0.020545214
Policy mu Std                0.72244674
Policy mu Max                3.8019001
Policy mu Min                -2.7551255
Policy log std Mean          -1.0442796
Policy log std Std           0.3097732
Policy log std Max           -0.21767175
Policy log std Min           -2.7342772
Z mean eval                  1.3034697
Z variance eval              0.009446782
total_rewards                [1373.25632067 4012.06483361 3960.725178   4340.78383623 2331.44504258
  384.9457091  4222.63597552  114.73966376 4088.03081077  528.31936545]
total_rewards_mean           2535.6946735676725
total_rewards_std            1692.1444041094062
total_rewards_max            4340.783836230182
total_rewards_min            114.73966375739533
Number of train steps total  2116000
Number of env steps total    2647000
Number of rollouts total     0
Train Time (s)               137.47238699020818
(Previous) Eval Time (s)     20.351529761217535
Sample Time (s)              24.91247521759942
Epoch Time (s)               182.73639196902514
Total Train Time (s)         98717.78590430412
Epoch                        528
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:58:14.713083 UTC | [2020_01_11_13_32_55] Iteration #528 | Epoch Duration: 189.40027689933777
2020-01-12 16:58:14.713278 UTC | [2020_01_11_13_32_55] Iteration #528 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3016084
Z variance train             0.00941479
KL Divergence                32.061108
KL Loss                      3.2061107
QF Loss                      1019.2668
VF Loss                      1681.4691
Policy Loss                  -1443.3716
Q Predictions Mean           1447.5461
Q Predictions Std            344.31778
Q Predictions Max            1648.9645
Q Predictions Min            -425.38165
V Predictions Mean           1446.6467
V Predictions Std            333.75586
V Predictions Max            1647.0997
V Predictions Min            -410.35025
Log Pis Mean                 1.1053565
Log Pis Std                  3.4297419
Log Pis Max                  14.2131605
Log Pis Min                  -11.241764
Policy mu Mean               0.021641705
Policy mu Std                0.69266
Policy mu Max                2.7524407
Policy mu Min                -2.9415898
Policy log std Mean          -1.0626268
Policy log std Std           0.31839004
Policy log std Max           -0.12142062
Policy log std Min           -3.058807
Z mean eval                  1.3258876
Z variance eval              0.010022888
total_rewards                [3135.31965637 1220.37186512 1688.33199973  526.69799492 2363.18325623
 4081.41240342  815.68698444 2558.10692219  204.68333098 1508.03484237]
total_rewards_mean           1810.1829255766402
total_rewards_std            1159.641033187855
total_rewards_max            4081.4124034183187
total_rewards_min            204.683330978752
Number of train steps total  2120000
Number of env steps total    2652000
Number of rollouts total     0
Train Time (s)               137.66370496712625
(Previous) Eval Time (s)     27.015087730251253
Sample Time (s)              23.572760762646794
Epoch Time (s)               188.2515534600243
Total Train Time (s)         98897.52498772787
Epoch                        529
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:01:14.457164 UTC | [2020_01_11_13_32_55] Iteration #529 | Epoch Duration: 179.74375462532043
2020-01-12 17:01:14.457350 UTC | [2020_01_11_13_32_55] Iteration #529 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3261188
Z variance train             0.010023514
KL Divergence                32.38151
KL Loss                      3.2381513
QF Loss                      1211.846
VF Loss                      467.65424
Policy Loss                  -1430.1865
Q Predictions Mean           1432.237
Q Predictions Std            381.01407
Q Predictions Max            1666.2644
Q Predictions Min            -415.4784
V Predictions Mean           1434.4138
V Predictions Std            378.8981
V Predictions Max            1666.4337
V Predictions Min            -407.13
Log Pis Mean                 1.2853966
Log Pis Std                  3.4775019
Log Pis Max                  15.769719
Log Pis Min                  -6.1360893
Policy mu Mean               0.051873572
Policy mu Std                0.7047479
Policy mu Max                2.7360673
Policy mu Min                -2.520542
Policy log std Mean          -1.0542936
Policy log std Std           0.35545862
Policy log std Max           -0.14253283
Policy log std Min           -2.9526153
Z mean eval                  1.3578895
Z variance eval              0.010945121
total_rewards                [4078.21099719 3785.39957126 2794.18458679 4051.48721766  389.10813597
 3313.75431597 1771.14474369 4148.43718264 4263.01870052  243.07762262]
total_rewards_mean           2883.782307431292
total_rewards_std            1474.18926214462
total_rewards_max            4263.018700520927
total_rewards_min            243.07762261550667
Number of train steps total  2124000
Number of env steps total    2657000
Number of rollouts total     0
Train Time (s)               141.7512707519345
(Previous) Eval Time (s)     18.50701485387981
Sample Time (s)              24.4093380975537
Epoch Time (s)               184.667623703368
Total Train Time (s)         99089.07987320703
Epoch                        530
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:04:26.017045 UTC | [2020_01_11_13_32_55] Iteration #530 | Epoch Duration: 191.55955624580383
2020-01-12 17:04:26.017253 UTC | [2020_01_11_13_32_55] Iteration #530 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3586948
Z variance train             0.010969792
KL Divergence                31.027676
KL Loss                      3.1027677
QF Loss                      1315.3735
VF Loss                      533.662
Policy Loss                  -1431.773
Q Predictions Mean           1438.063
Q Predictions Std            353.8984
Q Predictions Max            1659.4406
Q Predictions Min            -311.7193
V Predictions Mean           1438.46
V Predictions Std            355.90506
V Predictions Max            1648.1521
V Predictions Min            -324.6543
Log Pis Mean                 0.89855397
Log Pis Std                  3.5527017
Log Pis Max                  16.230633
Log Pis Min                  -7.3914185
Policy mu Mean               0.045189694
Policy mu Std                0.6631364
Policy mu Max                2.8444045
Policy mu Min                -2.0180092
Policy log std Mean          -1.0572215
Policy log std Std           0.36412403
Policy log std Max           -0.08774376
Policy log std Min           -3.5591755
Z mean eval                  1.2932152
Z variance eval              0.0144748315
total_rewards                [2234.32697645 3524.06903106 3934.04237943 4219.26798864 3817.6593885
 3991.52787425 4163.42389425 1210.72416697 4134.80669599 4248.56938593]
total_rewards_mean           3547.8417781468415
total_rewards_std            962.918288241173
total_rewards_max            4248.569385932141
total_rewards_min            1210.7241669742455
Number of train steps total  2128000
Number of env steps total    2662000
Number of rollouts total     0
Train Time (s)               145.93073209794238
(Previous) Eval Time (s)     25.39862990612164
Sample Time (s)              26.20065561681986
Epoch Time (s)               197.53001762088388
Total Train Time (s)         99292.07625205303
Epoch                        531
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:07:49.019620 UTC | [2020_01_11_13_32_55] Iteration #531 | Epoch Duration: 203.00220775604248
2020-01-12 17:07:49.019924 UTC | [2020_01_11_13_32_55] Iteration #531 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2923496
Z variance train             0.014308112
KL Divergence                29.79057
KL Loss                      2.979057
QF Loss                      1533.2002
VF Loss                      339.72055
Policy Loss                  -1461.9895
Q Predictions Mean           1468.6958
Q Predictions Std            254.26247
Q Predictions Max            1642.6161
Q Predictions Min            -299.62762
V Predictions Mean           1457.5483
V Predictions Std            248.33255
V Predictions Max            1632.9237
V Predictions Min            -382.65518
Log Pis Mean                 1.0770252
Log Pis Std                  3.2526414
Log Pis Max                  21.097385
Log Pis Min                  -6.7295246
Policy mu Mean               0.024015255
Policy mu Std                0.7146458
Policy mu Max                2.6135798
Policy mu Min                -2.9286401
Policy log std Mean          -1.0285151
Policy log std Std           0.2859347
Policy log std Max           -0.20076388
Policy log std Min           -3.013766
Z mean eval                  1.3225873
Z variance eval              0.0081288945
total_rewards                [2124.64412779 4156.60428779  696.59839289 3910.77902683 2425.3758195
 4050.92336488 1832.05254582 3743.91423373 4183.88744466 4243.86280399]
total_rewards_mean           3136.864204787002
total_rewards_std            1198.0303561549872
total_rewards_max            4243.862803985735
total_rewards_min            696.5983928897066
Number of train steps total  2132000
Number of env steps total    2667000
Number of rollouts total     0
Train Time (s)               144.6673274957575
(Previous) Eval Time (s)     30.87039415491745
Sample Time (s)              24.900744766928256
Epoch Time (s)               200.4384664176032
Total Train Time (s)         99488.28417742904
Epoch                        532
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:11:05.232551 UTC | [2020_01_11_13_32_55] Iteration #532 | Epoch Duration: 196.21247220039368
2020-01-12 17:11:05.232749 UTC | [2020_01_11_13_32_55] Iteration #532 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3219541
Z variance train             0.008099046
KL Divergence                31.294165
KL Loss                      3.1294165
QF Loss                      5480.1416
VF Loss                      1710.7393
Policy Loss                  -1431.7977
Q Predictions Mean           1439.1427
Q Predictions Std            333.80228
Q Predictions Max            1640.6405
Q Predictions Min            -252.7531
V Predictions Mean           1443.3359
V Predictions Std            330.372
V Predictions Max            1640.6544
V Predictions Min            -249.113
Log Pis Mean                 1.0665095
Log Pis Std                  3.3451831
Log Pis Max                  18.616173
Log Pis Min                  -12.043747
Policy mu Mean               0.0034651933
Policy mu Std                0.6733001
Policy mu Max                2.9978623
Policy mu Min                -3.257702
Policy log std Mean          -1.0807017
Policy log std Std           0.31852013
Policy log std Max           0.6699331
Policy log std Min           -3.0073874
Z mean eval                  1.3405864
Z variance eval              0.006425372
total_rewards                [3963.11696354 1075.03875024  981.91767202 4243.90617742 4106.41964844
 1782.69536587 4293.3767527  3073.87266216 2270.33780161  190.64909755]
total_rewards_mean           2598.133089155227
total_rewards_std            1464.4860477710222
total_rewards_max            4293.376752701791
total_rewards_min            190.6490975520697
Number of train steps total  2136000
Number of env steps total    2672000
Number of rollouts total     0
Train Time (s)               146.769579004962
(Previous) Eval Time (s)     26.64403010578826
Sample Time (s)              26.232342338189483
Epoch Time (s)               199.64595144893974
Total Train Time (s)         99687.66177618317
Epoch                        533
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:14:24.615474 UTC | [2020_01_11_13_32_55] Iteration #533 | Epoch Duration: 199.38258910179138
2020-01-12 17:14:24.615699 UTC | [2020_01_11_13_32_55] Iteration #533 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3398435
Z variance train             0.006420943
KL Divergence                31.70548
KL Loss                      3.1705482
QF Loss                      907.3963
VF Loss                      504.65933
Policy Loss                  -1448.4493
Q Predictions Mean           1453.9845
Q Predictions Std            316.91882
Q Predictions Max            1679.1498
Q Predictions Min            -230.69261
V Predictions Mean           1455.007
V Predictions Std            317.74164
V Predictions Max            1673.726
V Predictions Min            -213.85857
Log Pis Mean                 1.4137044
Log Pis Std                  3.8517609
Log Pis Max                  16.835373
Log Pis Min                  -7.6700773
Policy mu Mean               0.019370925
Policy mu Std                0.69956195
Policy mu Max                3.0935252
Policy mu Min                -2.6946027
Policy log std Mean          -1.1050642
Policy log std Std           0.36850265
Policy log std Max           -0.17052668
Policy log std Min           -3.148859
Z mean eval                  1.3294934
Z variance eval              0.004728016
total_rewards                [3.99432365e+03 4.20054204e+03 2.18797468e+03 2.31657831e+00
 3.21031066e+03 3.98584481e+03 4.08486107e+03 4.33688776e+02
 1.40089781e+03 4.29741559e+03]
total_rewards_mean           2779.8175676735277
total_rewards_std            1568.7600560596604
total_rewards_max            4297.415594978434
total_rewards_min            2.316578309638686
Number of train steps total  2140000
Number of env steps total    2677000
Number of rollouts total     0
Train Time (s)               143.31451158877462
(Previous) Eval Time (s)     26.380286049097776
Sample Time (s)              25.107310984283686
Epoch Time (s)               194.80210862215608
Total Train Time (s)         99882.77682484314
Epoch                        534
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:17:39.736005 UTC | [2020_01_11_13_32_55] Iteration #534 | Epoch Duration: 195.12016558647156
2020-01-12 17:17:39.736197 UTC | [2020_01_11_13_32_55] Iteration #534 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.329828
Z variance train             0.0047248616
KL Divergence                32.38293
KL Loss                      3.2382932
QF Loss                      1773.5609
VF Loss                      346.82413
Policy Loss                  -1424.613
Q Predictions Mean           1426.7378
Q Predictions Std            388.44626
Q Predictions Max            1684.3354
Q Predictions Min            -383.6266
V Predictions Mean           1428.1074
V Predictions Std            389.66672
V Predictions Max            1688.5719
V Predictions Min            -388.93225
Log Pis Mean                 1.262763
Log Pis Std                  3.5821977
Log Pis Max                  16.47936
Log Pis Min                  -8.188059
Policy mu Mean               -0.018115632
Policy mu Std                0.7068508
Policy mu Max                4.087754
Policy mu Min                -2.62153
Policy log std Mean          -1.0827768
Policy log std Std           0.3415196
Policy log std Max           -0.053642154
Policy log std Min           -3.555916
Z mean eval                  1.3406231
Z variance eval              0.008434428
total_rewards                [2245.00180593 3937.42842408 3031.59433207  878.54777672  907.0580656
  550.50698425  134.59441158 4031.90596018 3922.70844186 1743.89568749]
total_rewards_mean           2138.324188976589
total_rewards_std            1435.6353998182126
total_rewards_max            4031.9059601782897
total_rewards_min            134.59441157616462
Number of train steps total  2144000
Number of env steps total    2682000
Number of rollouts total     0
Train Time (s)               137.66102572670206
(Previous) Eval Time (s)     26.697942974977195
Sample Time (s)              25.404299098532647
Epoch Time (s)               189.7632678002119
Total Train Time (s)         100063.54002837138
Epoch                        535
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:20:40.504702 UTC | [2020_01_11_13_32_55] Iteration #535 | Epoch Duration: 180.76835680007935
2020-01-12 17:20:40.504909 UTC | [2020_01_11_13_32_55] Iteration #535 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3367134
Z variance train             0.008487689
KL Divergence                31.223913
KL Loss                      3.1223915
QF Loss                      886.07263
VF Loss                      254.336
Policy Loss                  -1460.3949
Q Predictions Mean           1463.4785
Q Predictions Std            295.37653
Q Predictions Max            1650.7308
Q Predictions Min            -176.61977
V Predictions Mean           1463.1953
V Predictions Std            288.0367
V Predictions Max            1641.085
V Predictions Min            -178.84776
Log Pis Mean                 1.0998838
Log Pis Std                  3.4983988
Log Pis Max                  22.286324
Log Pis Min                  -5.6308527
Policy mu Mean               -0.030663703
Policy mu Std                0.69266915
Policy mu Max                2.388841
Policy mu Min                -4.3842034
Policy log std Mean          -1.0565572
Policy log std Std           0.3197039
Policy log std Max           0.31197345
Policy log std Min           -2.675589
Z mean eval                  1.2966819
Z variance eval              0.003985773
total_rewards                [2447.22901013 4255.42493858 3162.81410392 4255.10415954 2477.5145487
 4000.97255701 4129.67473343 3994.74931884 4045.90198064  981.86986153]
total_rewards_mean           3375.125521232909
total_rewards_std            1038.4430358412515
total_rewards_max            4255.424938583388
total_rewards_min            981.8698615333535
Number of train steps total  2148000
Number of env steps total    2687000
Number of rollouts total     0
Train Time (s)               138.41432136809453
(Previous) Eval Time (s)     17.70263509033248
Sample Time (s)              24.214415850117803
Epoch Time (s)               180.33137230854481
Total Train Time (s)         100255.3343551727
Epoch                        536
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:23:52.304491 UTC | [2020_01_11_13_32_55] Iteration #536 | Epoch Duration: 191.7994408607483
2020-01-12 17:23:52.304705 UTC | [2020_01_11_13_32_55] Iteration #536 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2958513
Z variance train             0.0039695357
KL Divergence                33.434704
KL Loss                      3.3434703
QF Loss                      1164.8269
VF Loss                      621.2327
Policy Loss                  -1407.9993
Q Predictions Mean           1411.825
Q Predictions Std            417.33163
Q Predictions Max            1663.5355
Q Predictions Min            -391.63235
V Predictions Mean           1408.7703
V Predictions Std            416.76263
V Predictions Max            1668.5034
V Predictions Min            -366.70636
Log Pis Mean                 0.92085695
Log Pis Std                  3.7214625
Log Pis Max                  16.364193
Log Pis Min                  -8.264812
Policy mu Mean               -0.0083370535
Policy mu Std                0.7162207
Policy mu Max                3.136106
Policy mu Min                -2.5852704
Policy log std Mean          -1.0508437
Policy log std Std           0.3268661
Policy log std Max           -0.080667496
Policy log std Min           -2.7982001
Z mean eval                  1.2828362
Z variance eval              0.009717408
total_rewards                [1630.16174468 4061.94960985 3810.74299372 3903.43765307 4145.53414694
 3121.09517442 4232.84435392 3720.98076009 4106.93516616 3772.41150706]
total_rewards_mean           3650.609310989951
total_rewards_std            737.1111746396359
total_rewards_max            4232.844353919389
total_rewards_min            1630.161744678314
Number of train steps total  2152000
Number of env steps total    2692000
Number of rollouts total     0
Train Time (s)               144.31318584363908
(Previous) Eval Time (s)     29.170377747621387
Sample Time (s)              26.045707783661783
Epoch Time (s)               199.52927137492225
Total Train Time (s)         100460.37584775919
Epoch                        537
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:27:17.349305 UTC | [2020_01_11_13_32_55] Iteration #537 | Epoch Duration: 205.0444850921631
2020-01-12 17:27:17.349421 UTC | [2020_01_11_13_32_55] Iteration #537 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.284225
Z variance train             0.009742753
KL Divergence                30.21126
KL Loss                      3.021126
QF Loss                      2085.561
VF Loss                      583.5728
Policy Loss                  -1410.8522
Q Predictions Mean           1414.586
Q Predictions Std            389.52753
Q Predictions Max            1647.4507
Q Predictions Min            -425.81418
V Predictions Mean           1413.6572
V Predictions Std            384.16293
V Predictions Max            1652.9905
V Predictions Min            -390.8356
Log Pis Mean                 1.0523704
Log Pis Std                  3.7093945
Log Pis Max                  25.582981
Log Pis Min                  -8.709709
Policy mu Mean               0.013838536
Policy mu Std                0.6817572
Policy mu Max                2.983842
Policy mu Min                -4.275765
Policy log std Mean          -1.0611603
Policy log std Std           0.33343312
Policy log std Max           -0.0930987
Policy log std Min           -3.8665984
Z mean eval                  1.3059938
Z variance eval              0.00982913
total_rewards                [ 562.28609049  839.07681607 2725.26228041 1779.55628448 1898.37357663
 4255.70879086    4.61755205 1448.61299903 1970.58637729 1599.84346086]
total_rewards_mean           1708.392422818486
total_rewards_std            1126.2386148377984
total_rewards_max            4255.708790861664
total_rewards_min            4.617552053231129
Number of train steps total  2156000
Number of env steps total    2697000
Number of rollouts total     0
Train Time (s)               146.19648943422362
(Previous) Eval Time (s)     34.68504503276199
Sample Time (s)              25.816411481704563
Epoch Time (s)               206.69794594869018
Total Train Time (s)         100647.43369121663
Epoch                        538
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:30:24.412677 UTC | [2020_01_11_13_32_55] Iteration #538 | Epoch Duration: 187.06315660476685
2020-01-12 17:30:24.412859 UTC | [2020_01_11_13_32_55] Iteration #538 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3099012
Z variance train             0.009879041
KL Divergence                30.701685
KL Loss                      3.0701685
QF Loss                      2516.6226
VF Loss                      458.3198
Policy Loss                  -1437.224
Q Predictions Mean           1437.8984
Q Predictions Std            377.18765
Q Predictions Max            1655.184
Q Predictions Min            -275.46375
V Predictions Mean           1439.6481
V Predictions Std            366.90854
V Predictions Max            1648.2142
V Predictions Min            -312.33038
Log Pis Mean                 1.2490554
Log Pis Std                  3.414418
Log Pis Max                  14.601719
Log Pis Min                  -7.687017
Policy mu Mean               0.031495295
Policy mu Std                0.70272446
Policy mu Max                2.685533
Policy mu Min                -2.8105536
Policy log std Mean          -1.0698655
Policy log std Std           0.3385485
Policy log std Max           -0.17909408
Policy log std Min           -2.8464599
Z mean eval                  1.3112773
Z variance eval              0.010577494
total_rewards                [1663.53030799 1183.43686475 1895.03590815  518.70679604  458.990318
 1282.81983908 4195.4407391  4117.99106443 4057.68804246 1250.74726208]
total_rewards_mean           2062.438714207775
total_rewards_std            1411.9706955297759
total_rewards_max            4195.440739097474
total_rewards_min            458.99031800372677
Number of train steps total  2160000
Number of env steps total    2702000
Number of rollouts total     0
Train Time (s)               145.12086230982095
(Previous) Eval Time (s)     15.049877109006047
Sample Time (s)              25.448052785824984
Epoch Time (s)               185.61879220465198
Total Train Time (s)         100839.15879562404
Epoch                        539
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:33:36.143879 UTC | [2020_01_11_13_32_55] Iteration #539 | Epoch Duration: 191.73085808753967
2020-01-12 17:33:36.144268 UTC | [2020_01_11_13_32_55] Iteration #539 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3102504
Z variance train             0.010603352
KL Divergence                30.786373
KL Loss                      3.0786374
QF Loss                      1810.7705
VF Loss                      412.43692
Policy Loss                  -1436.8955
Q Predictions Mean           1436.7804
Q Predictions Std            355.5233
Q Predictions Max            1685.2599
Q Predictions Min            -378.13086
V Predictions Mean           1439.7644
V Predictions Std            350.2515
V Predictions Max            1688.1913
V Predictions Min            -403.42432
Log Pis Mean                 1.0510263
Log Pis Std                  3.2280707
Log Pis Max                  17.344099
Log Pis Min                  -6.6183534
Policy mu Mean               0.016083427
Policy mu Std                0.6809351
Policy mu Max                2.7484696
Policy mu Min                -2.4404712
Policy log std Mean          -1.0579983
Policy log std Std           0.30511984
Policy log std Max           -0.21748018
Policy log std Min           -3.7267175
Z mean eval                  1.29104
Z variance eval              0.0038040846
total_rewards                [ 478.720419   1049.62512851 3173.88818937 3124.15933133 3982.32594189
 4114.78263536 4058.64940152 3808.8125674  4249.3260094  1043.76226313]
total_rewards_mean           2908.4051886910447
total_rewards_std            1396.16875333665
total_rewards_max            4249.326009403967
total_rewards_min            478.7204190042465
Number of train steps total  2164000
Number of env steps total    2707000
Number of rollouts total     0
Train Time (s)               145.8798458641395
(Previous) Eval Time (s)     21.161544234957546
Sample Time (s)              26.98366774013266
Epoch Time (s)               194.0250578392297
Total Train Time (s)         101038.54124890594
Epoch                        540
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:36:55.531093 UTC | [2020_01_11_13_32_55] Iteration #540 | Epoch Duration: 199.38664174079895
2020-01-12 17:36:55.531334 UTC | [2020_01_11_13_32_55] Iteration #540 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2881482
Z variance train             0.0038068094
KL Divergence                32.830612
KL Loss                      3.2830613
QF Loss                      915.1409
VF Loss                      189.8651
Policy Loss                  -1452.4921
Q Predictions Mean           1452.3912
Q Predictions Std            340.3405
Q Predictions Max            1671.4203
Q Predictions Min            -351.4023
V Predictions Mean           1448.8511
V Predictions Std            337.57153
V Predictions Max            1652.6715
V Predictions Min            -333.85345
Log Pis Mean                 1.3569257
Log Pis Std                  3.233094
Log Pis Max                  18.65881
Log Pis Min                  -7.9903975
Policy mu Mean               0.036596023
Policy mu Std                0.67786396
Policy mu Max                3.3898773
Policy mu Min                -2.191773
Policy log std Mean          -1.0980556
Policy log std Std           0.2984616
Policy log std Max           0.10367501
Policy log std Min           -2.5717878
Z mean eval                  1.2998308
Z variance eval              0.008120121
total_rewards                [1844.34010977 4149.44722951 1393.29712022 2809.8456427  2916.76900002
 4082.95287521 1434.74372585 2531.98263264 2545.84868104  172.48552044]
total_rewards_mean           2388.171253739353
total_rewards_std            1165.37379124178
total_rewards_max            4149.447229511147
total_rewards_min            172.48552044168898
Number of train steps total  2168000
Number of env steps total    2712000
Number of rollouts total     0
Train Time (s)               137.958250769414
(Previous) Eval Time (s)     26.522656018845737
Sample Time (s)              26.047822715248913
Epoch Time (s)               190.52872950350866
Total Train Time (s)         101226.4236543253
Epoch                        541
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:40:03.419581 UTC | [2020_01_11_13_32_55] Iteration #541 | Epoch Duration: 187.88807940483093
2020-01-12 17:40:03.419895 UTC | [2020_01_11_13_32_55] Iteration #541 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2999686
Z variance train             0.00809422
KL Divergence                31.997395
KL Loss                      3.1997395
QF Loss                      1913.7565
VF Loss                      653.8094
Policy Loss                  -1391.312
Q Predictions Mean           1392.4788
Q Predictions Std            437.9798
Q Predictions Max            1674.0393
Q Predictions Min            -298.61118
V Predictions Mean           1396.2234
V Predictions Std            433.87695
V Predictions Max            1659.7937
V Predictions Min            -299.84512
Log Pis Mean                 1.7523252
Log Pis Std                  4.1780415
Log Pis Max                  24.62357
Log Pis Min                  -6.225422
Policy mu Mean               0.020638764
Policy mu Std                0.7191985
Policy mu Max                2.738671
Policy mu Min                -3.524987
Policy log std Mean          -1.1183326
Policy log std Std           0.3644889
Policy log std Max           1.1237559
Policy log std Min           -2.9206886
Z mean eval                  1.2987491
Z variance eval              0.012732072
total_rewards                [ 858.68535998 2414.7917057   234.24977674 1591.85209818 3989.21478928
 4184.81452661 4036.2276068   973.80743268 3958.48699846 4052.57869602]
total_rewards_mean           2629.4708990441827
total_rewards_std            1509.1457309323193
total_rewards_max            4184.814526614231
total_rewards_min            234.24977673740563
Number of train steps total  2172000
Number of env steps total    2717000
Number of rollouts total     0
Train Time (s)               137.77764313528314
(Previous) Eval Time (s)     23.88164289901033
Sample Time (s)              24.32254044804722
Epoch Time (s)               185.9818264823407
Total Train Time (s)         101411.03536724113
Epoch                        542
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:43:08.036073 UTC | [2020_01_11_13_32_55] Iteration #542 | Epoch Duration: 184.6159689426422
2020-01-12 17:43:08.036257 UTC | [2020_01_11_13_32_55] Iteration #542 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3015236
Z variance train             0.012786239
KL Divergence                30.481844
KL Loss                      3.0481844
QF Loss                      1315.4082
VF Loss                      1298.2301
Policy Loss                  -1414.6434
Q Predictions Mean           1419.3923
Q Predictions Std            403.90546
Q Predictions Max            1661.8372
Q Predictions Min            -358.08957
V Predictions Mean           1419.2327
V Predictions Std            401.5114
V Predictions Max            1639.8171
V Predictions Min            -373.63153
Log Pis Mean                 1.107283
Log Pis Std                  3.4824092
Log Pis Max                  19.787859
Log Pis Min                  -7.828915
Policy mu Mean               0.01514818
Policy mu Std                0.67341125
Policy mu Max                2.6888506
Policy mu Min                -3.0411177
Policy log std Mean          -1.0858084
Policy log std Std           0.3203733
Policy log std Max           0.7372415
Policy log std Min           -2.565802
Z mean eval                  1.2608602
Z variance eval              0.0066455444
total_rewards                [3836.54990454  126.2487668  4217.59135399 4050.05447544 3996.17241219
 4359.60346768 3881.02376092 3930.18324292 4148.79585354 3035.58041395]
total_rewards_mean           3558.180365197365
total_rewards_std            1192.9406722344886
total_rewards_max            4359.603467683742
total_rewards_min            126.24876680082825
Number of train steps total  2176000
Number of env steps total    2722000
Number of rollouts total     0
Train Time (s)               142.16664359811693
(Previous) Eval Time (s)     22.515482355840504
Sample Time (s)              24.897069587372243
Epoch Time (s)               189.57919554132968
Total Train Time (s)         101608.2859311155
Epoch                        543
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:46:25.292436 UTC | [2020_01_11_13_32_55] Iteration #543 | Epoch Duration: 197.25600838661194
2020-01-12 17:46:25.292755 UTC | [2020_01_11_13_32_55] Iteration #543 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.258859
Z variance train             0.0066344654
KL Divergence                31.642817
KL Loss                      3.1642816
QF Loss                      1096.2467
VF Loss                      516.3942
Policy Loss                  -1410.7382
Q Predictions Mean           1419.1871
Q Predictions Std            378.36783
Q Predictions Max            1630.7562
Q Predictions Min            -381.47305
V Predictions Mean           1413.2859
V Predictions Std            382.90485
V Predictions Max            1663.6434
V Predictions Min            -397.38156
Log Pis Mean                 1.1331366
Log Pis Std                  3.521253
Log Pis Max                  16.593487
Log Pis Min                  -8.6535635
Policy mu Mean               0.035744008
Policy mu Std                0.69099915
Policy mu Max                2.8930447
Policy mu Min                -2.5409498
Policy log std Mean          -1.0892735
Policy log std Std           0.33937553
Policy log std Max           -0.050465465
Policy log std Min           -3.178229
Z mean eval                  1.2887414
Z variance eval              0.010103777
total_rewards                [3324.65935326 4031.69091843 3778.33588651 3817.22739164 4045.8520821
 4039.19585665  839.22207955 3916.07964856 3809.41292652 3915.51560307]
total_rewards_mean           3551.719174630028
total_rewards_std            925.9985198359415
total_rewards_max            4045.8520821040793
total_rewards_min            839.2220795504594
Number of train steps total  2180000
Number of env steps total    2727000
Number of rollouts total     0
Train Time (s)               146.32550936797634
(Previous) Eval Time (s)     30.191964893136173
Sample Time (s)              26.672331059351563
Epoch Time (s)               203.18980532046407
Total Train Time (s)         101815.70870374283
Epoch                        544
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:49:52.721284 UTC | [2020_01_11_13_32_55] Iteration #544 | Epoch Duration: 207.42837238311768
2020-01-12 17:49:52.721565 UTC | [2020_01_11_13_32_55] Iteration #544 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2882335
Z variance train             0.010106236
KL Divergence                30.048767
KL Loss                      3.0048769
QF Loss                      1147.1505
VF Loss                      263.34985
Policy Loss                  -1401.8556
Q Predictions Mean           1406.742
Q Predictions Std            418.46573
Q Predictions Max            1684.1953
Q Predictions Min            -445.99084
V Predictions Mean           1400.7028
V Predictions Std            420.15115
V Predictions Max            1679.2928
V Predictions Min            -460.7018
Log Pis Mean                 0.8887887
Log Pis Std                  2.8500266
Log Pis Max                  9.238289
Log Pis Min                  -6.9565473
Policy mu Mean               0.034375615
Policy mu Std                0.6844163
Policy mu Max                2.5156872
Policy mu Min                -2.8054671
Policy log std Mean          -1.0304176
Policy log std Std           0.28766933
Policy log std Max           0.7269647
Policy log std Min           -2.4253387
Z mean eval                  1.3268591
Z variance eval              0.0090665165
total_rewards                [3399.68878201 1602.64707488 4019.52072163 3899.92981611 4149.29926963
 2498.97254892 3090.25528302 2773.30319792 1635.83873895 2940.33601602]
total_rewards_mean           3000.97914490847
total_rewards_std            863.5730090465462
total_rewards_max            4149.299269631277
total_rewards_min            1602.6470748764136
Number of train steps total  2184000
Number of env steps total    2732000
Number of rollouts total     0
Train Time (s)               145.1496685668826
(Previous) Eval Time (s)     34.43020827090368
Sample Time (s)              26.6855636453256
Epoch Time (s)               206.2654404831119
Total Train Time (s)         102014.20559470216
Epoch                        545
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:53:11.222342 UTC | [2020_01_11_13_32_55] Iteration #545 | Epoch Duration: 198.50056672096252
2020-01-12 17:53:11.222545 UTC | [2020_01_11_13_32_55] Iteration #545 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3281319
Z variance train             0.009014986
KL Divergence                31.703777
KL Loss                      3.1703777
QF Loss                      1070.5613
VF Loss                      343.98453
Policy Loss                  -1414.0933
Q Predictions Mean           1415.581
Q Predictions Std            428.77362
Q Predictions Max            1656.802
Q Predictions Min            -337.3849
V Predictions Mean           1411.2297
V Predictions Std            417.12445
V Predictions Max            1659.8839
V Predictions Min            -341.9309
Log Pis Mean                 1.115602
Log Pis Std                  3.8212419
Log Pis Max                  31.576155
Log Pis Min                  -7.7129717
Policy mu Mean               0.0050227493
Policy mu Std                0.7201972
Policy mu Max                2.9322767
Policy mu Min                -5.4250712
Policy log std Mean          -1.03387
Policy log std Std           0.31538978
Policy log std Max           0.40006053
Policy log std Min           -2.7252736
Z mean eval                  1.3137407
Z variance eval              0.005137737
total_rewards                [ -16.89131966 1147.50362534 1767.10018917 3401.71250536  653.58286826
 2088.67554981  739.99314738 1264.62284662 3711.69295732 2664.82492699]
total_rewards_mean           1742.281729659111
total_rewards_std            1160.6221650844755
total_rewards_max            3711.692957321876
total_rewards_min            -16.891319662495473
Number of train steps total  2188000
Number of env steps total    2737000
Number of rollouts total     0
Train Time (s)               147.70917449798435
(Previous) Eval Time (s)     26.664992469828576
Sample Time (s)              26.064228274393827
Epoch Time (s)               200.43839524220675
Total Train Time (s)         102206.74531644117
Epoch                        546
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:56:23.767522 UTC | [2020_01_11_13_32_55] Iteration #546 | Epoch Duration: 192.5448396205902
2020-01-12 17:56:23.767712 UTC | [2020_01_11_13_32_55] Iteration #546 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3123801
Z variance train             0.0051334277
KL Divergence                32.559433
KL Loss                      3.2559433
QF Loss                      837.9546
VF Loss                      197.15479
Policy Loss                  -1440.4353
Q Predictions Mean           1441.455
Q Predictions Std            377.62973
Q Predictions Max            1694.9178
Q Predictions Min            -414.70068
V Predictions Mean           1435.9153
V Predictions Std            373.98248
V Predictions Max            1666.3448
V Predictions Min            -419.05212
Log Pis Mean                 0.9722454
Log Pis Std                  3.2313619
Log Pis Max                  12.07473
Log Pis Min                  -9.260565
Policy mu Mean               -0.01533329
Policy mu Std                0.7296078
Policy mu Max                2.8949866
Policy mu Min                -2.4681253
Policy log std Mean          -1.0305402
Policy log std Std           0.29052874
Policy log std Max           0.24387181
Policy log std Min           -2.438019
Z mean eval                  1.3290113
Z variance eval              0.010644747
total_rewards                [4095.96207903 4306.59125232 1108.06343604  589.9275119   544.59139502
 4028.19227471 1883.60726452 1444.78550467  540.47354983 2167.69857544]
total_rewards_mean           2070.9892843482003
total_rewards_std            1454.6068025163077
total_rewards_max            4306.5912523240995
total_rewards_min            540.4735498253407
Number of train steps total  2192000
Number of env steps total    2742000
Number of rollouts total     0
Train Time (s)               144.6277655940503
(Previous) Eval Time (s)     18.77106201229617
Sample Time (s)              24.577541830483824
Epoch Time (s)               187.97636943683028
Total Train Time (s)         102393.59171642456
Epoch                        547
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:59:30.619756 UTC | [2020_01_11_13_32_55] Iteration #547 | Epoch Duration: 186.85189986228943
2020-01-12 17:59:30.619978 UTC | [2020_01_11_13_32_55] Iteration #547 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3298478
Z variance train             0.010633994
KL Divergence                32.033768
KL Loss                      3.2033768
QF Loss                      668.0391
VF Loss                      189.33957
Policy Loss                  -1439.032
Q Predictions Mean           1442.8784
Q Predictions Std            370.33713
Q Predictions Max            1680.3259
Q Predictions Min            -285.26218
V Predictions Mean           1436.3336
V Predictions Std            366.76776
V Predictions Max            1671.2798
V Predictions Min            -297.69998
Log Pis Mean                 0.98332953
Log Pis Std                  3.274283
Log Pis Max                  21.359238
Log Pis Min                  -7.206081
Policy mu Mean               0.0044579105
Policy mu Std                0.6880022
Policy mu Max                3.9813054
Policy mu Min                -3.8592715
Policy log std Mean          -1.0616459
Policy log std Std           0.2995134
Policy log std Max           0.0102699995
Policy log std Min           -3.0377378
Z mean eval                  1.3302062
Z variance eval              0.0095072
total_rewards                [2582.64832981 1100.61111536 4145.61694125 2296.37299385 4313.05684338
 2715.94002274 4195.56517628 4085.83328092 4206.58611569 4067.72603779]
total_rewards_mean           3370.9956857086063
total_rewards_std            1059.3450334570018
total_rewards_max            4313.056843378019
total_rewards_min            1100.611115362257
Number of train steps total  2196000
Number of env steps total    2747000
Number of rollouts total     0
Train Time (s)               137.59720385214314
(Previous) Eval Time (s)     17.646111275069416
Sample Time (s)              25.201309280470014
Epoch Time (s)               180.44462440768257
Total Train Time (s)         102583.26634338778
Epoch                        548
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:02:40.299890 UTC | [2020_01_11_13_32_55] Iteration #548 | Epoch Duration: 189.67976903915405
2020-01-12 18:02:40.300047 UTC | [2020_01_11_13_32_55] Iteration #548 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.330152
Z variance train             0.009524839
KL Divergence                32.238083
KL Loss                      3.2238083
QF Loss                      730.6382
VF Loss                      1254.6552
Policy Loss                  -1434.359
Q Predictions Mean           1439.3042
Q Predictions Std            379.6819
Q Predictions Max            1684.0675
Q Predictions Min            -428.4161
V Predictions Mean           1424.6385
V Predictions Std            372.68994
V Predictions Max            1658.7963
V Predictions Min            -442.12183
Log Pis Mean                 0.69033283
Log Pis Std                  3.2968733
Log Pis Max                  15.789148
Log Pis Min                  -6.7670774
Policy mu Mean               0.013419993
Policy mu Std                0.6717752
Policy mu Max                2.8547049
Policy mu Min                -2.455418
Policy log std Mean          -1.0511469
Policy log std Std           0.31830263
Policy log std Max           -0.23429936
Policy log std Min           -2.608206
Z mean eval                  1.3513724
Z variance eval              0.010279349
total_rewards                [1743.25586645  591.90524421 4307.95122183 4270.80260531  335.37314396
 1237.05325623 4223.32215831   38.92229074 4114.87578197 2813.06325963]
total_rewards_mean           2367.652482865398
total_rewards_std            1686.8899539345655
total_rewards_max            4307.951221828916
total_rewards_min            38.9222907395666
Number of train steps total  2200000
Number of env steps total    2752000
Number of rollouts total     0
Train Time (s)               137.81521476618946
(Previous) Eval Time (s)     26.880875355564058
Sample Time (s)              25.09172768937424
Epoch Time (s)               189.78781781112775
Total Train Time (s)         102772.72730465466
Epoch                        549
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:05:49.766085 UTC | [2020_01_11_13_32_55] Iteration #549 | Epoch Duration: 189.46591901779175
2020-01-12 18:05:49.766292 UTC | [2020_01_11_13_32_55] Iteration #549 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3540944
Z variance train             0.01012984
KL Divergence                32.34846
KL Loss                      3.234846
QF Loss                      3774.1553
VF Loss                      693.2648
Policy Loss                  -1467.2803
Q Predictions Mean           1470.5017
Q Predictions Std            330.60162
Q Predictions Max            1666.3301
Q Predictions Min            -453.1926
V Predictions Mean           1457.7227
V Predictions Std            328.31793
V Predictions Max            1645.833
V Predictions Min            -475.94977
Log Pis Mean                 0.98389804
Log Pis Std                  3.6138113
Log Pis Max                  25.289497
Log Pis Min                  -6.3623
Policy mu Mean               0.022470959
Policy mu Std                0.7095043
Policy mu Max                4.242327
Policy mu Min                -3.3297043
Policy log std Mean          -1.0616705
Policy log std Std           0.27658778
Policy log std Max           0.17434037
Policy log std Min           -2.4774315
Z mean eval                  1.3063341
Z variance eval              0.015642487
total_rewards                [4007.8499102  2673.28335462   89.03248252 1618.84187383 2636.62593792
  764.18624871 3199.78558676 1684.91660377 4346.64429831 2671.77122224]
total_rewards_mean           2369.293751887684
total_rewards_std            1278.568676567984
total_rewards_max            4346.644298310245
total_rewards_min            89.03248251700661
Number of train steps total  2204000
Number of env steps total    2757000
Number of rollouts total     0
Train Time (s)               145.23991788411513
(Previous) Eval Time (s)     26.558649748098105
Sample Time (s)              24.742917185183614
Epoch Time (s)               196.54148481739685
Total Train Time (s)         102967.17649380397
Epoch                        550
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:09:04.221825 UTC | [2020_01_11_13_32_55] Iteration #550 | Epoch Duration: 194.45536422729492
2020-01-12 18:09:04.222160 UTC | [2020_01_11_13_32_55] Iteration #550 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.304024
Z variance train             0.015598404
KL Divergence                31.444433
KL Loss                      3.1444433
QF Loss                      1166.4136
VF Loss                      444.0299
Policy Loss                  -1431.9265
Q Predictions Mean           1426.5779
Q Predictions Std            388.67624
Q Predictions Max            1698.6334
Q Predictions Min            -436.6057
V Predictions Mean           1427.7074
V Predictions Std            371.23322
V Predictions Max            1690.7839
V Predictions Min            -402.7765
Log Pis Mean                 1.5103109
Log Pis Std                  3.685175
Log Pis Max                  22.324831
Log Pis Min                  -8.623211
Policy mu Mean               0.030145574
Policy mu Std                0.7050508
Policy mu Max                4.049895
Policy mu Min                -2.584915
Policy log std Mean          -1.0981805
Policy log std Std           0.3594035
Policy log std Max           0.34532225
Policy log std Min           -3.468461
Z mean eval                  1.3115739
Z variance eval              0.014241748
total_rewards                [3116.64149188 3930.39359926 3841.72461705 4023.55253863 2440.84188791
  460.34733325 4109.4174651   878.76032337 4068.37744184 4112.72944109]
total_rewards_mean           3098.2786139389946
total_rewards_std            1319.521362646017
total_rewards_max            4112.729441089362
total_rewards_min            460.3473332531919
Number of train steps total  2208000
Number of env steps total    2762000
Number of rollouts total     0
Train Time (s)               144.75732284318656
(Previous) Eval Time (s)     24.472174531314522
Sample Time (s)              26.11521505471319
Epoch Time (s)               195.34471242921427
Total Train Time (s)         103166.54791486915
Epoch                        551
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:12:23.598092 UTC | [2020_01_11_13_32_55] Iteration #551 | Epoch Duration: 199.37574219703674
2020-01-12 18:12:23.598353 UTC | [2020_01_11_13_32_55] Iteration #551 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3124888
Z variance train             0.0142490845
KL Divergence                31.028858
KL Loss                      3.102886
QF Loss                      792.76166
VF Loss                      223.14137
Policy Loss                  -1441.8334
Q Predictions Mean           1447.0144
Q Predictions Std            356.22916
Q Predictions Max            1670.7343
Q Predictions Min            -396.15598
V Predictions Mean           1438.9045
V Predictions Std            358.01358
V Predictions Max            1667.1553
V Predictions Min            -428.83972
Log Pis Mean                 1.7104162
Log Pis Std                  3.653054
Log Pis Max                  24.358074
Log Pis Min                  -6.1873307
Policy mu Mean               0.0008625202
Policy mu Std                0.72884667
Policy mu Max                4.785571
Policy mu Min                -3.4818237
Policy log std Mean          -1.0906105
Policy log std Std           0.31942803
Policy log std Max           -0.1784612
Policy log std Min           -3.1897595
Z mean eval                  1.3151996
Z variance eval              0.008729899
total_rewards                [4108.21731206   47.78292553  205.01700534 3648.9415448   419.78392148
  489.67005608 4281.65597624 3681.39631563  574.13006358 4200.23277784]
total_rewards_mean           2165.6827898574534
total_rewards_std            1833.236273699716
total_rewards_max            4281.655976235111
total_rewards_min            47.78292553292525
Number of train steps total  2212000
Number of env steps total    2767000
Number of rollouts total     0
Train Time (s)               144.78228202601895
(Previous) Eval Time (s)     28.502879686653614
Sample Time (s)              26.473334989510477
Epoch Time (s)               199.75849670218304
Total Train Time (s)         103356.17826843169
Epoch                        552
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:15:33.234346 UTC | [2020_01_11_13_32_55] Iteration #552 | Epoch Duration: 189.6358461380005
2020-01-12 18:15:33.234559 UTC | [2020_01_11_13_32_55] Iteration #552 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3145665
Z variance train             0.008715004
KL Divergence                31.979204
KL Loss                      3.1979206
QF Loss                      12242.641
VF Loss                      346.16882
Policy Loss                  -1455.4264
Q Predictions Mean           1454.6304
Q Predictions Std            347.76215
Q Predictions Max            1737.0586
Q Predictions Min            -399.50143
V Predictions Mean           1450.6238
V Predictions Std            345.24466
V Predictions Max            1711.7511
V Predictions Min            -380.56766
Log Pis Mean                 1.1917394
Log Pis Std                  3.0989666
Log Pis Max                  13.374624
Log Pis Min                  -6.316641
Policy mu Mean               -0.01681479
Policy mu Std                0.70418894
Policy mu Max                3.2025244
Policy mu Min                -2.4810743
Policy log std Mean          -1.0831542
Policy log std Std           0.31497175
Policy log std Max           -0.037435412
Policy log std Min           -2.8521276
Z mean eval                  1.3223633
Z variance eval              0.015138236
total_rewards                [ 194.33884978 3625.94497072 4089.70376741 2144.28016981 4048.13572844
 3486.94589531   11.15609429 1725.47467049   79.54389634 3987.79535027]
total_rewards_mean           2339.3319392855055
total_rewards_std            1649.7436311785007
total_rewards_max            4089.703767412873
total_rewards_min            11.15609429061442
Number of train steps total  2216000
Number of env steps total    2772000
Number of rollouts total     0
Train Time (s)               145.9669182272628
(Previous) Eval Time (s)     18.379819237161428
Sample Time (s)              25.227813340257853
Epoch Time (s)               189.57455080468208
Total Train Time (s)         103548.59163967334
Epoch                        553
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:18:45.653618 UTC | [2020_01_11_13_32_55] Iteration #553 | Epoch Duration: 192.41888284683228
2020-01-12 18:18:45.653974 UTC | [2020_01_11_13_32_55] Iteration #553 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3195548
Z variance train             0.015125198
KL Divergence                30.882797
KL Loss                      3.0882797
QF Loss                      1034.3262
VF Loss                      134.3105
Policy Loss                  -1491.3777
Q Predictions Mean           1495.3116
Q Predictions Std            243.6648
Q Predictions Max            1693.2267
Q Predictions Min            -415.32617
V Predictions Mean           1491.7424
V Predictions Std            242.87105
V Predictions Max            1666.2921
V Predictions Min            -415.04248
Log Pis Mean                 1.2051828
Log Pis Std                  2.9550016
Log Pis Max                  10.334751
Log Pis Min                  -8.434948
Policy mu Mean               0.015101643
Policy mu Std                0.69285995
Policy mu Max                2.6561189
Policy mu Min                -2.6337757
Policy log std Mean          -1.0904078
Policy log std Std           0.29820463
Policy log std Max           -0.16084218
Policy log std Min           -2.482898
Z mean eval                  1.3031044
Z variance eval              0.0062390678
total_rewards                [1133.42709436 4181.9387271  4303.22230229 3180.39837317 4082.88556014
 4220.50105294 1575.66799553 4109.82874272 4031.57134261 2048.28522994]
total_rewards_mean           3286.7726420799786
total_rewards_std            1169.7104735201121
total_rewards_max            4303.222302287881
total_rewards_min            1133.4270943604786
Number of train steps total  2220000
Number of env steps total    2777000
Number of rollouts total     0
Train Time (s)               139.5942476610653
(Previous) Eval Time (s)     21.223691440187395
Sample Time (s)              26.901328863110393
Epoch Time (s)               187.7192679643631
Total Train Time (s)         103742.87639260339
Epoch                        554
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:21:59.943772 UTC | [2020_01_11_13_32_55] Iteration #554 | Epoch Duration: 194.2895793914795
2020-01-12 18:21:59.943974 UTC | [2020_01_11_13_32_55] Iteration #554 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3052936
Z variance train             0.0062584905
KL Divergence                32.94808
KL Loss                      3.294808
QF Loss                      1113.5281
VF Loss                      304.62842
Policy Loss                  -1478.7546
Q Predictions Mean           1482.3484
Q Predictions Std            317.7071
Q Predictions Max            1680.9113
Q Predictions Min            -346.37314
V Predictions Mean           1475.534
V Predictions Std            316.47327
V Predictions Max            1664.0662
V Predictions Min            -349.8159
Log Pis Mean                 1.1724145
Log Pis Std                  3.1276894
Log Pis Max                  10.128446
Log Pis Min                  -7.625974
Policy mu Mean               0.009241434
Policy mu Std                0.6799803
Policy mu Max                2.467175
Policy mu Min                -2.6487489
Policy log std Mean          -1.0937206
Policy log std Std           0.3096522
Policy log std Max           -0.24752814
Policy log std Min           -2.9554553
Z mean eval                  1.2933632
Z variance eval              0.022466425
total_rewards                [4290.6496501   442.99509485 4380.86147315  677.27151122 2879.88709484
 3964.56648151 3331.96589441 2249.22074197 3899.40576143 4281.50117515]
total_rewards_mean           3039.832487861827
total_rewards_std            1398.5668670529985
total_rewards_max            4380.861473149572
total_rewards_min            442.9950948496726
Number of train steps total  2224000
Number of env steps total    2782000
Number of rollouts total     0
Train Time (s)               137.89019783306867
(Previous) Eval Time (s)     27.793613865040243
Sample Time (s)              24.923444372601807
Epoch Time (s)               190.60725607071072
Total Train Time (s)         103931.97922988422
Epoch                        555
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:25:09.052945 UTC | [2020_01_11_13_32_55] Iteration #555 | Epoch Duration: 189.10880827903748
2020-01-12 18:25:09.053221 UTC | [2020_01_11_13_32_55] Iteration #555 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2972767
Z variance train             0.022209719
KL Divergence                30.90501
KL Loss                      3.090501
QF Loss                      1547.1003
VF Loss                      441.90845
Policy Loss                  -1452.5634
Q Predictions Mean           1456.564
Q Predictions Std            334.96466
Q Predictions Max            1674.9424
Q Predictions Min            -428.5372
V Predictions Mean           1458.0098
V Predictions Std            332.58142
V Predictions Max            1664.0015
V Predictions Min            -438.35226
Log Pis Mean                 1.5469003
Log Pis Std                  3.3627627
Log Pis Max                  18.534513
Log Pis Min                  -8.084186
Policy mu Mean               0.0377583
Policy mu Std                0.70507205
Policy mu Max                3.3529735
Policy mu Min                -2.476846
Policy log std Mean          -1.1020797
Policy log std Std           0.34179583
Policy log std Max           2.0
Policy log std Min           -3.1556373
Z mean eval                  1.4068983
Z variance eval              0.0072749644
total_rewards                [4176.45697324 1467.24377036 1128.45428624 4089.13282637 2546.33577185
 4003.56024354 4096.19360914 4144.3915758  4219.30633943 2304.88878088]
total_rewards_mean           3217.5964176848624
total_rewards_std            1168.0286293497115
total_rewards_max            4219.306339430408
total_rewards_min            1128.4542862383437
Number of train steps total  2228000
Number of env steps total    2787000
Number of rollouts total     0
Train Time (s)               140.47752793878317
(Previous) Eval Time (s)     26.29478096216917
Sample Time (s)              23.60987864015624
Epoch Time (s)               190.38218754110858
Total Train Time (s)         104123.5677619474
Epoch                        556
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:28:20.646476 UTC | [2020_01_11_13_32_55] Iteration #556 | Epoch Duration: 191.59310698509216
2020-01-12 18:28:20.646654 UTC | [2020_01_11_13_32_55] Iteration #556 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4042633
Z variance train             0.007299644
KL Divergence                32.396282
KL Loss                      3.2396283
QF Loss                      1599.7091
VF Loss                      202.15547
Policy Loss                  -1423.5526
Q Predictions Mean           1425.9963
Q Predictions Std            395.09604
Q Predictions Max            1654.6508
Q Predictions Min            -315.03943
V Predictions Mean           1424.9092
V Predictions Std            393.59406
V Predictions Max            1651.8723
V Predictions Min            -291.61127
Log Pis Mean                 1.2856214
Log Pis Std                  3.351159
Log Pis Max                  21.766766
Log Pis Min                  -5.241944
Policy mu Mean               0.023747776
Policy mu Std                0.69973606
Policy mu Max                3.1225433
Policy mu Min                -2.8215392
Policy log std Mean          -1.0807247
Policy log std Std           0.30238217
Policy log std Max           0.111790895
Policy log std Min           -3.160644
Z mean eval                  1.3275317
Z variance eval              0.0067974054
total_rewards                [3886.77991361 1110.22560695  110.45319877 3918.44713293   75.71520815
 4054.6400504  2570.14823177 1480.13834575 2258.48310746 3748.36790435]
total_rewards_mean           2321.3398700144553
total_rewards_std            1490.4099099449065
total_rewards_max            4054.640050404336
total_rewards_min            75.71520815291119
Number of train steps total  2232000
Number of env steps total    2792000
Number of rollouts total     0
Train Time (s)               146.92955143284053
(Previous) Eval Time (s)     27.505379296373576
Sample Time (s)              25.89204302849248
Epoch Time (s)               200.32697375770658
Total Train Time (s)         104316.86941828579
Epoch                        557
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:31:33.954956 UTC | [2020_01_11_13_32_55] Iteration #557 | Epoch Duration: 193.3081510066986
2020-01-12 18:31:33.955256 UTC | [2020_01_11_13_32_55] Iteration #557 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.327205
Z variance train             0.0067902794
KL Divergence                31.010946
KL Loss                      3.1010947
QF Loss                      766.2177
VF Loss                      254.92484
Policy Loss                  -1460.7073
Q Predictions Mean           1462.437
Q Predictions Std            340.1498
Q Predictions Max            1669.414
Q Predictions Min            -480.77667
V Predictions Mean           1463.386
V Predictions Std            341.4916
V Predictions Max            1667.5182
V Predictions Min            -449.7581
Log Pis Mean                 1.1892564
Log Pis Std                  3.2884643
Log Pis Max                  16.058685
Log Pis Min                  -7.588676
Policy mu Mean               0.037758246
Policy mu Std                0.72098565
Policy mu Max                2.780724
Policy mu Min                -2.644574
Policy log std Mean          -1.065572
Policy log std Std           0.3099197
Policy log std Max           -0.17851937
Policy log std Min           -2.3779774
Z mean eval                  1.3315651
Z variance eval              0.009608163
total_rewards                [1888.39165924  238.33047271 1632.21367591 4181.36974154  206.25722613
 1575.88556226 -115.03233858 1661.86616397 -110.91329758  775.41098312]
total_rewards_mean           1193.3779848723316
total_rewards_std            1242.732538050528
total_rewards_max            4181.369741541132
total_rewards_min            -115.03233857805236
Number of train steps total  2236000
Number of env steps total    2797000
Number of rollouts total     0
Train Time (s)               145.96374052995816
(Previous) Eval Time (s)     20.486137355212122
Sample Time (s)              25.270070636179298
Epoch Time (s)               191.71994852134958
Total Train Time (s)         104506.0202113553
Epoch                        558
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:34:43.110750 UTC | [2020_01_11_13_32_55] Iteration #558 | Epoch Duration: 189.1553337574005
2020-01-12 18:34:43.110919 UTC | [2020_01_11_13_32_55] Iteration #558 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3323873
Z variance train             0.009629202
KL Divergence                31.680998
KL Loss                      3.1680999
QF Loss                      966.015
VF Loss                      1156.714
Policy Loss                  -1437.7495
Q Predictions Mean           1444.6497
Q Predictions Std            358.20215
Q Predictions Max            1671.9731
Q Predictions Min            -404.9812
V Predictions Mean           1441.0754
V Predictions Std            356.1174
V Predictions Max            1670.7537
V Predictions Min            -378.74603
Log Pis Mean                 1.0837586
Log Pis Std                  3.1531124
Log Pis Max                  14.785932
Log Pis Min                  -6.73086
Policy mu Mean               0.00018470827
Policy mu Std                0.71269417
Policy mu Max                3.9013526
Policy mu Min                -3.224748
Policy log std Mean          -1.0568956
Policy log std Std           0.32281703
Policy log std Max           0.833253
Policy log std Min           -2.9183526
Z mean eval                  1.3219309
Z variance eval              0.007569016
total_rewards                [2819.22646528  747.67624267 4261.14448716 4156.65123207  215.7492699
 4172.05991335 4034.42882744 1579.11042994 1802.48223167 4142.87448256]
total_rewards_mean           2793.140358203173
total_rewards_std            1502.0325356334422
total_rewards_max            4261.1444871604745
total_rewards_min            215.74926989746172
Number of train steps total  2240000
Number of env steps total    2802000
Number of rollouts total     0
Train Time (s)               146.4764226283878
(Previous) Eval Time (s)     17.921140749007463
Sample Time (s)              25.376024865545332
Epoch Time (s)               189.7735882429406
Total Train Time (s)         104704.65797446994
Epoch                        559
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:38:01.754031 UTC | [2020_01_11_13_32_55] Iteration #559 | Epoch Duration: 198.64298224449158
2020-01-12 18:38:01.754220 UTC | [2020_01_11_13_32_55] Iteration #559 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3235117
Z variance train             0.0075925016
KL Divergence                31.482618
KL Loss                      3.1482618
QF Loss                      1041.117
VF Loss                      236.58318
Policy Loss                  -1429.6655
Q Predictions Mean           1436.3364
Q Predictions Std            389.96487
Q Predictions Max            1663.7242
Q Predictions Min            -403.98373
V Predictions Mean           1428.0336
V Predictions Std            390.04248
V Predictions Max            1662.8569
V Predictions Min            -484.29944
Log Pis Mean                 1.4268554
Log Pis Std                  3.109286
Log Pis Max                  15.275858
Log Pis Min                  -6.7789364
Policy mu Mean               0.021286014
Policy mu Std                0.72168595
Policy mu Max                2.5740075
Policy mu Min                -2.4557748
Policy log std Mean          -1.0733654
Policy log std Std           0.28881377
Policy log std Max           -0.2242943
Policy log std Min           -2.5095363
Z mean eval                  1.3188279
Z variance eval              0.0084853815
total_rewards                [4015.0864937  4067.90967899 4150.06139815 4467.22409757 4130.41526292
 2987.82947297 4158.40132326 3787.1118013   161.6448457  4126.55157476]
total_rewards_mean           3605.223594933097
total_rewards_std            1206.1536916965433
total_rewards_max            4467.224097567409
total_rewards_min            161.64484570312595
Number of train steps total  2244000
Number of env steps total    2807000
Number of rollouts total     0
Train Time (s)               145.33894515270367
(Previous) Eval Time (s)     26.79013864370063
Sample Time (s)              25.071019049733877
Epoch Time (s)               197.20010284613818
Total Train Time (s)         104904.82273833407
Epoch                        560
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:41:21.924406 UTC | [2020_01_11_13_32_55] Iteration #560 | Epoch Duration: 200.17005324363708
2020-01-12 18:41:21.924598 UTC | [2020_01_11_13_32_55] Iteration #560 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3185875
Z variance train             0.008543162
KL Divergence                31.631336
KL Loss                      3.1631336
QF Loss                      15286.793
VF Loss                      1067.4711
Policy Loss                  -1456.0518
Q Predictions Mean           1458.5586
Q Predictions Std            313.69873
Q Predictions Max            1662.9646
Q Predictions Min            -416.55273
V Predictions Mean           1445.2189
V Predictions Std            315.04532
V Predictions Max            1638.2506
V Predictions Min            -416.28137
Log Pis Mean                 1.4386965
Log Pis Std                  3.4053574
Log Pis Max                  14.640795
Log Pis Min                  -8.394096
Policy mu Mean               0.042325333
Policy mu Std                0.6948172
Policy mu Max                3.6554458
Policy mu Min                -2.3084147
Policy log std Mean          -1.1173236
Policy log std Std           0.3253466
Policy log std Max           -0.2640556
Policy log std Min           -2.8433702
Z mean eval                  1.3613422
Z variance eval              0.010935958
total_rewards                [4084.95878567 3410.01385319 3300.69696842 1229.62514557  443.59460568
 3383.05884513 4320.40624113  130.90156498 1411.39210916 3119.23304173]
total_rewards_mean           2483.3881160679857
total_rewards_std            1452.447829414728
total_rewards_max            4320.406241131603
total_rewards_min            130.9015649760711
Number of train steps total  2248000
Number of env steps total    2812000
Number of rollouts total     0
Train Time (s)               137.64686221582815
(Previous) Eval Time (s)     29.759696445893496
Sample Time (s)              25.19399880664423
Epoch Time (s)               192.60055746836588
Total Train Time (s)         105090.54949589912
Epoch                        561
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:44:27.657054 UTC | [2020_01_11_13_32_55] Iteration #561 | Epoch Duration: 185.7323179244995
2020-01-12 18:44:27.657269 UTC | [2020_01_11_13_32_55] Iteration #561 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.36358
Z variance train             0.0109301815
KL Divergence                31.890902
KL Loss                      3.1890903
QF Loss                      1080.8308
VF Loss                      690.5857
Policy Loss                  -1405.821
Q Predictions Mean           1410.5331
Q Predictions Std            447.0008
Q Predictions Max            1676.8494
Q Predictions Min            -456.25504
V Predictions Mean           1401.7278
V Predictions Std            443.11948
V Predictions Max            1667.3225
V Predictions Min            -447.52438
Log Pis Mean                 0.72915095
Log Pis Std                  3.410345
Log Pis Max                  13.906601
Log Pis Min                  -8.012033
Policy mu Mean               -0.013012877
Policy mu Std                0.6884807
Policy mu Max                3.3390713
Policy mu Min                -2.7821448
Policy log std Mean          -1.0432991
Policy log std Std           0.32508337
Policy log std Max           -0.10488951
Policy log std Min           -2.774576
Z mean eval                  1.303266
Z variance eval              0.0029475512
total_rewards                [ 976.53076941 4440.8848286  3898.09610729 4144.13354754 4193.86346537
 4314.65839787 3388.54734603 3485.93929065  687.64598329 1951.06163377]
total_rewards_mean           3148.1361369823107
total_rewards_std            1343.6795512436324
total_rewards_max            4440.884828603727
total_rewards_min            687.6459832856432
Number of train steps total  2252000
Number of env steps total    2817000
Number of rollouts total     0
Train Time (s)               137.36421957286075
(Previous) Eval Time (s)     22.89108137600124
Sample Time (s)              25.150042723398656
Epoch Time (s)               185.40534367226064
Total Train Time (s)         105282.22708788281
Epoch                        562
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:47:39.340008 UTC | [2020_01_11_13_32_55] Iteration #562 | Epoch Duration: 191.68259978294373
2020-01-12 18:47:39.340216 UTC | [2020_01_11_13_32_55] Iteration #562 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3041351
Z variance train             0.0029508695
KL Divergence                33.818733
KL Loss                      3.3818734
QF Loss                      1035.2428
VF Loss                      268.19788
Policy Loss                  -1448.2568
Q Predictions Mean           1449.5256
Q Predictions Std            351.75262
Q Predictions Max            1668.7626
Q Predictions Min            -294.83606
V Predictions Mean           1447.7339
V Predictions Std            343.5522
V Predictions Max            1663.27
V Predictions Min            -305.7728
Log Pis Mean                 1.3489801
Log Pis Std                  3.0270607
Log Pis Max                  16.05732
Log Pis Min                  -6.8963265
Policy mu Mean               0.012770886
Policy mu Std                0.7178183
Policy mu Max                2.815221
Policy mu Min                -2.6223078
Policy log std Mean          -1.0671325
Policy log std Std           0.30638796
Policy log std Max           -0.16984689
Policy log std Min           -2.846434
Z mean eval                  1.3333719
Z variance eval              0.018801283
total_rewards                [ 978.3923642  1032.89510116 4272.7117115  1575.94041304 4308.51066291
 3921.6012316  4311.5805751   181.24260279 4148.01748073 2726.45647493]
total_rewards_mean           2745.7348617959447
total_rewards_std            1567.7240946493582
total_rewards_max            4311.580575098831
total_rewards_min            181.24260278837735
Number of train steps total  2256000
Number of env steps total    2822000
Number of rollouts total     0
Train Time (s)               145.13665054179728
(Previous) Eval Time (s)     29.168006618041545
Sample Time (s)              25.080212098080665
Epoch Time (s)               199.3848692579195
Total Train Time (s)         105479.3812411502
Epoch                        563
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:50:56.499393 UTC | [2020_01_11_13_32_55] Iteration #563 | Epoch Duration: 197.15904355049133
2020-01-12 18:50:56.499566 UTC | [2020_01_11_13_32_55] Iteration #563 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3371279
Z variance train             0.018820472
KL Divergence                31.740795
KL Loss                      3.1740797
QF Loss                      1383.4714
VF Loss                      610.9737
Policy Loss                  -1434.3536
Q Predictions Mean           1443.3093
Q Predictions Std            375.65906
Q Predictions Max            1669.6564
Q Predictions Min            -409.71176
V Predictions Mean           1436.8511
V Predictions Std            380.52887
V Predictions Max            1668.585
V Predictions Min            -400.05756
Log Pis Mean                 1.1553817
Log Pis Std                  3.4599116
Log Pis Max                  20.817863
Log Pis Min                  -8.787375
Policy mu Mean               0.012699071
Policy mu Std                0.70273477
Policy mu Max                2.9620566
Policy mu Min                -4.2402973
Policy log std Mean          -1.0843874
Policy log std Std           0.3477912
Policy log std Max           1.7972114
Policy log std Min           -2.9775841
Z mean eval                  1.3313614
Z variance eval              0.012328172
total_rewards                [ 633.62285772 2117.51038795  682.66316182 1439.08048974 4045.36922141
 4271.32626709 2173.10915993 1373.55388547 4188.04661072 3972.51358811]
total_rewards_mean           2489.6795629959424
total_rewards_std            1413.370407548651
total_rewards_max            4271.326267085412
total_rewards_min            633.6228577206293
Number of train steps total  2260000
Number of env steps total    2827000
Number of rollouts total     0
Train Time (s)               145.65112364897504
(Previous) Eval Time (s)     26.941796495579183
Sample Time (s)              26.93263688776642
Epoch Time (s)               199.52555703232065
Total Train Time (s)         105673.50495384913
Epoch                        564
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:54:10.628958 UTC | [2020_01_11_13_32_55] Iteration #564 | Epoch Duration: 194.1292643547058
2020-01-12 18:54:10.629145 UTC | [2020_01_11_13_32_55] Iteration #564 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3288682
Z variance train             0.012358915
KL Divergence                31.552452
KL Loss                      3.1552453
QF Loss                      1101.6667
VF Loss                      228.90028
Policy Loss                  -1472.7158
Q Predictions Mean           1476.1375
Q Predictions Std            306.04044
Q Predictions Max            1688.1653
Q Predictions Min            -236.36044
V Predictions Mean           1469.0786
V Predictions Std            306.55716
V Predictions Max            1680.6924
V Predictions Min            -256.07275
Log Pis Mean                 1.1794474
Log Pis Std                  3.4568193
Log Pis Max                  18.554504
Log Pis Min                  -7.4572163
Policy mu Mean               0.020576932
Policy mu Std                0.6860752
Policy mu Max                3.0479991
Policy mu Min                -2.6798217
Policy log std Mean          -1.078385
Policy log std Std           0.31953716
Policy log std Max           -0.069187224
Policy log std Min           -3.1186876
Z mean eval                  1.3264453
Z variance eval              0.0077682016
total_rewards                [1554.97680613  157.29176268 3905.63349855 4231.36935249 1902.38517321
  153.89402444 3884.08690688 4239.89686788 2876.60566828 4027.59993163]
total_rewards_mean           2693.373999217426
total_rewards_std            1557.5798162649414
total_rewards_max            4239.896867882539
total_rewards_min            153.89402444012603
Number of train steps total  2264000
Number of env steps total    2832000
Number of rollouts total     0
Train Time (s)               144.96816832013428
(Previous) Eval Time (s)     21.545072060078382
Sample Time (s)              27.0873946538195
Epoch Time (s)               193.60063503403217
Total Train Time (s)         105869.40959384199
Epoch                        565
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:57:26.540608 UTC | [2020_01_11_13_32_55] Iteration #565 | Epoch Duration: 195.91128158569336
2020-01-12 18:57:26.541009 UTC | [2020_01_11_13_32_55] Iteration #565 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3242867
Z variance train             0.007782674
KL Divergence                32.47167
KL Loss                      3.2471669
QF Loss                      801.65845
VF Loss                      354.66656
Policy Loss                  -1415.8324
Q Predictions Mean           1420.8448
Q Predictions Std            407.02914
Q Predictions Max            1666.1519
Q Predictions Min            -447.67752
V Predictions Mean           1426.9922
V Predictions Std            407.13773
V Predictions Max            1677.9556
V Predictions Min            -458.14456
Log Pis Mean                 1.4218585
Log Pis Std                  4.0514097
Log Pis Max                  37.352028
Log Pis Min                  -11.903418
Policy mu Mean               0.026998704
Policy mu Std                0.7176871
Policy mu Max                5.368665
Policy mu Min                -3.6048172
Policy log std Mean          -1.11055
Policy log std Std           0.3084916
Policy log std Max           -0.11896086
Policy log std Min           -2.790208
Z mean eval                  1.2995886
Z variance eval              0.015179999
total_rewards                [3710.58651624 4132.50309256 1298.41973438 1252.77732535 4162.37846911
 4205.32092335 3727.00248867 1223.80932813 4131.17374248  830.05187065]
total_rewards_mean           2867.40234909085
total_rewards_std            1415.4636919197012
total_rewards_max            4205.320923347528
total_rewards_min            830.0518706456984
Number of train steps total  2268000
Number of env steps total    2837000
Number of rollouts total     0
Train Time (s)               146.02457231283188
(Previous) Eval Time (s)     23.85517776105553
Sample Time (s)              26.604989065323025
Epoch Time (s)               196.48473913921043
Total Train Time (s)         106065.82303970633
Epoch                        566
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:00:42.958743 UTC | [2020_01_11_13_32_55] Iteration #566 | Epoch Duration: 196.41746616363525
2020-01-12 19:00:42.959019 UTC | [2020_01_11_13_32_55] Iteration #566 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2998024
Z variance train             0.015194002
KL Divergence                30.535702
KL Loss                      3.0535703
QF Loss                      1512.8613
VF Loss                      194.53944
Policy Loss                  -1474.0786
Q Predictions Mean           1474.68
Q Predictions Std            297.19702
Q Predictions Max            1690.2994
Q Predictions Min            -428.9974
V Predictions Mean           1467.7708
V Predictions Std            292.50665
V Predictions Max            1670.1985
V Predictions Min            -414.93332
Log Pis Mean                 0.96319526
Log Pis Std                  3.4696739
Log Pis Max                  20.32351
Log Pis Min                  -6.5892773
Policy mu Mean               9.893533e-05
Policy mu Std                0.72800505
Policy mu Max                2.9233303
Policy mu Min                -3.647701
Policy log std Mean          -1.044392
Policy log std Std           0.3035558
Policy log std Max           0.67186904
Policy log std Min           -2.8307676
Z mean eval                  1.2807739
Z variance eval              0.013596478
total_rewards                [3802.40608325 2901.0276495  1460.86926712 1266.8866904  4135.7372671
 3981.61773599 2878.04502834 3919.59423316 4015.50576034 3506.60417237]
total_rewards_mean           3186.8293887573077
total_rewards_std            1003.9473504815921
total_rewards_max            4135.737267098136
total_rewards_min            1266.8866904031868
Number of train steps total  2272000
Number of env steps total    2842000
Number of rollouts total     0
Train Time (s)               141.33913386799395
(Previous) Eval Time (s)     23.78752354485914
Sample Time (s)              24.882285269442946
Epoch Time (s)               190.00894268229604
Total Train Time (s)         106259.4766378547
Epoch                        567
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:03:56.617314 UTC | [2020_01_11_13_32_55] Iteration #567 | Epoch Duration: 193.65813946723938
2020-01-12 19:03:56.617489 UTC | [2020_01_11_13_32_55] Iteration #567 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2809175
Z variance train             0.013600327
KL Divergence                30.088343
KL Loss                      3.0088344
QF Loss                      1035.0016
VF Loss                      1954.4806
Policy Loss                  -1407.2318
Q Predictions Mean           1401.4889
Q Predictions Std            421.20895
Q Predictions Max            1653.2928
Q Predictions Min            -354.69885
V Predictions Mean           1398.7592
V Predictions Std            407.52292
V Predictions Max            1639.899
V Predictions Min            -361.26047
Log Pis Mean                 1.3703768
Log Pis Std                  3.4762702
Log Pis Max                  22.357016
Log Pis Min                  -5.4795237
Policy mu Mean               -0.022473395
Policy mu Std                0.70331115
Policy mu Max                3.421506
Policy mu Min                -2.6079705
Policy log std Mean          -1.0649123
Policy log std Std           0.35361665
Policy log std Max           -0.03238237
Policy log std Min           -3.7156856
Z mean eval                  1.2937629
Z variance eval              0.006734874
total_rewards                [4143.64345113  180.39176069  264.51618516 3511.89788651 4024.88357927
 1625.04126741 4037.40973522  771.91962664 1721.38057788  251.61808351]
total_rewards_mean           2053.2702153436217
total_rewards_std            1618.949629363196
total_rewards_max            4143.64345113409
total_rewards_min            180.39176068944494
Number of train steps total  2276000
Number of env steps total    2847000
Number of rollouts total     0
Train Time (s)               137.68412741133943
(Previous) Eval Time (s)     27.43641794519499
Sample Time (s)              24.886898170690984
Epoch Time (s)               190.0074435272254
Total Train Time (s)         106439.93816183042
Epoch                        568
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:06:57.084365 UTC | [2020_01_11_13_32_55] Iteration #568 | Epoch Duration: 180.46673679351807
2020-01-12 19:06:57.084586 UTC | [2020_01_11_13_32_55] Iteration #568 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.29356
Z variance train             0.0067430167
KL Divergence                32.193768
KL Loss                      3.2193768
QF Loss                      893.81146
VF Loss                      396.62106
Policy Loss                  -1465.5333
Q Predictions Mean           1472.1189
Q Predictions Std            312.3151
Q Predictions Max            1690.4174
Q Predictions Min            -377.86694
V Predictions Mean           1476.6064
V Predictions Std            315.4915
V Predictions Max            1709.0902
V Predictions Min            -354.45407
Log Pis Mean                 0.9184095
Log Pis Std                  3.3363519
Log Pis Max                  11.908047
Log Pis Min                  -7.6040063
Policy mu Mean               -0.00087012537
Policy mu Std                0.69448006
Policy mu Max                2.9639027
Policy mu Min                -2.949853
Policy log std Mean          -1.0528986
Policy log std Std           0.28772238
Policy log std Max           -0.24024272
Policy log std Min           -2.4219232
Z mean eval                  1.3146975
Z variance eval              0.013006953
total_rewards                [4092.98711706 1204.39025204 1921.81210294 4315.2805351  4171.37925462
 4107.16451094 3658.33677616  494.06909457 4041.35913834 2833.58369385]
total_rewards_mean           3084.0362475622073
total_rewards_std            1329.0533921308115
total_rewards_max            4315.2805350997005
total_rewards_min            494.0690945731643
Number of train steps total  2280000
Number of env steps total    2852000
Number of rollouts total     0
Train Time (s)               139.55591701809317
(Previous) Eval Time (s)     17.895392489153892
Sample Time (s)              24.503164225723594
Epoch Time (s)               181.95447373297065
Total Train Time (s)         106630.30243014498
Epoch                        569
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:10:07.452959 UTC | [2020_01_11_13_32_55] Iteration #569 | Epoch Duration: 190.36824941635132
2020-01-12 19:10:07.453106 UTC | [2020_01_11_13_32_55] Iteration #569 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.315753
Z variance train             0.012992127
KL Divergence                30.330317
KL Loss                      3.0330317
QF Loss                      1857.976
VF Loss                      307.1772
Policy Loss                  -1379.8279
Q Predictions Mean           1379.2795
Q Predictions Std            468.16138
Q Predictions Max            1679.7231
Q Predictions Min            -448.1253
V Predictions Mean           1376.6127
V Predictions Std            459.90427
V Predictions Max            1688.7816
V Predictions Min            -458.56607
Log Pis Mean                 0.9663514
Log Pis Std                  3.225134
Log Pis Max                  16.791706
Log Pis Min                  -4.999347
Policy mu Mean               0.0035127057
Policy mu Std                0.6635962
Policy mu Max                2.6519291
Policy mu Min                -2.740992
Policy log std Mean          -1.0810041
Policy log std Std           0.31498525
Policy log std Max           -0.12666833
Policy log std Min           -2.7924786
Z mean eval                  1.2568183
Z variance eval              0.014387241
total_rewards                [4004.5304344  3328.93418719 3941.61371006 4248.71086793 2327.80322999
  252.33780053 2653.61675234 3933.93734764  975.78663838 3927.81198716]
total_rewards_mean           2959.508295562679
total_rewards_std            1322.8299105709852
total_rewards_max            4248.710867930763
total_rewards_min            252.33780052594886
Number of train steps total  2284000
Number of env steps total    2857000
Number of rollouts total     0
Train Time (s)               148.30724898399785
(Previous) Eval Time (s)     26.30879647890106
Sample Time (s)              26.369176261126995
Epoch Time (s)               200.9852217240259
Total Train Time (s)         106832.39540941035
Epoch                        570
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:13:29.551501 UTC | [2020_01_11_13_32_55] Iteration #570 | Epoch Duration: 202.0982768535614
2020-01-12 19:13:29.551682 UTC | [2020_01_11_13_32_55] Iteration #570 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2575443
Z variance train             0.014364923
KL Divergence                31.224546
KL Loss                      3.1224546
QF Loss                      1316.646
VF Loss                      300.61664
Policy Loss                  -1461.3691
Q Predictions Mean           1466.0308
Q Predictions Std            347.01303
Q Predictions Max            1683.4802
Q Predictions Min            -428.0431
V Predictions Mean           1460.1045
V Predictions Std            342.01242
V Predictions Max            1682.837
V Predictions Min            -409.4445
Log Pis Mean                 1.0550852
Log Pis Std                  3.0485804
Log Pis Max                  15.776717
Log Pis Min                  -5.831681
Policy mu Mean               0.0319452
Policy mu Std                0.67498815
Policy mu Max                2.5302002
Policy mu Min                -2.1903243
Policy log std Mean          -1.0578194
Policy log std Std           0.32819548
Policy log std Max           -0.20264626
Policy log std Min           -3.2246246
Z mean eval                  1.304756
Z variance eval              0.008306575
total_rewards                [4222.567733    615.67460722  112.1248114   325.76717402 3177.40099993
  -32.40930302 1081.65905221 1393.30916601  283.78338305 2402.10932018]
total_rewards_mean           1358.198694400025
total_rewards_std            1376.2150697194122
total_rewards_max            4222.567732998946
total_rewards_min            -32.40930301963193
Number of train steps total  2288000
Number of env steps total    2862000
Number of rollouts total     0
Train Time (s)               145.3472230131738
(Previous) Eval Time (s)     27.42145642405376
Sample Time (s)              25.729850977193564
Epoch Time (s)               198.4985304144211
Total Train Time (s)         107015.36194016458
Epoch                        571
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:16:32.524138 UTC | [2020_01_11_13_32_55] Iteration #571 | Epoch Duration: 182.97232723236084
2020-01-12 19:16:32.524327 UTC | [2020_01_11_13_32_55] Iteration #571 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3040769
Z variance train             0.008295169
KL Divergence                31.170387
KL Loss                      3.1170387
QF Loss                      1186.5745
VF Loss                      423.34033
Policy Loss                  -1458.5005
Q Predictions Mean           1464.012
Q Predictions Std            333.3668
Q Predictions Max            1712.2609
Q Predictions Min            -295.7697
V Predictions Mean           1461.0981
V Predictions Std            329.95148
V Predictions Max            1685.0775
V Predictions Min            -275.19913
Log Pis Mean                 1.3126609
Log Pis Std                  3.0433714
Log Pis Max                  11.327669
Log Pis Min                  -6.204709
Policy mu Mean               0.07250872
Policy mu Std                0.724017
Policy mu Max                3.1511338
Policy mu Min                -3.968938
Policy log std Mean          -1.076459
Policy log std Std           0.31849092
Policy log std Max           0.054338694
Policy log std Min           -2.886197
Z mean eval                  1.3317465
Z variance eval              0.011076643
total_rewards                [1351.15238812 4134.91643915 3309.96992609   53.68655617 1522.56327296
 1402.22361068  410.79661987  422.93878644   38.60274617 1172.47214776]
total_rewards_mean           1381.9322493413672
total_rewards_std            1295.870542866591
total_rewards_max            4134.916439151821
total_rewards_min            38.60274617315896
Number of train steps total  2292000
Number of env steps total    2867000
Number of rollouts total     0
Train Time (s)               146.1805263790302
(Previous) Eval Time (s)     11.894924907013774
Sample Time (s)              24.785344620700926
Epoch Time (s)               182.8607959067449
Total Train Time (s)         107201.72786847549
Epoch                        572
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:19:38.895483 UTC | [2020_01_11_13_32_55] Iteration #572 | Epoch Duration: 186.3710162639618
2020-01-12 19:19:38.895700 UTC | [2020_01_11_13_32_55] Iteration #572 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3315712
Z variance train             0.0110540865
KL Divergence                28.997562
KL Loss                      2.8997562
QF Loss                      2319.4824
VF Loss                      725.71686
Policy Loss                  -1382.0712
Q Predictions Mean           1387.7194
Q Predictions Std            408.38232
Q Predictions Max            1645.077
Q Predictions Min            -344.6929
V Predictions Mean           1385.8901
V Predictions Std            409.9101
V Predictions Max            1657.3972
V Predictions Min            -362.9524
Log Pis Mean                 1.4638891
Log Pis Std                  3.9693258
Log Pis Max                  20.464918
Log Pis Min                  -5.663745
Policy mu Mean               0.061724007
Policy mu Std                0.7568828
Policy mu Max                3.485524
Policy mu Min                -3.3652802
Policy log std Mean          -1.0435871
Policy log std Std           0.36752895
Policy log std Max           -0.08245152
Policy log std Min           -3.0919895
Z mean eval                  1.3899509
Z variance eval              0.012005103
total_rewards                [4031.33594721  378.1664943  1914.27233334 1285.32901439  364.43148246
   74.65212421  526.42459684 1209.27943568 -248.32640369  650.8649227 ]
total_rewards_mean           1018.6429947454735
total_rewards_std            1170.3848578909028
total_rewards_max            4031.3359472057127
total_rewards_min            -248.32640369240065
Number of train steps total  2296000
Number of env steps total    2872000
Number of rollouts total     0
Train Time (s)               144.90374119579792
(Previous) Eval Time (s)     15.404767374973744
Sample Time (s)              24.76877897279337
Epoch Time (s)               185.07728754356503
Total Train Time (s)         107387.46633036109
Epoch                        573
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:22:44.640111 UTC | [2020_01_11_13_32_55] Iteration #573 | Epoch Duration: 185.7442545890808
2020-01-12 19:22:44.640381 UTC | [2020_01_11_13_32_55] Iteration #573 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.390867
Z variance train             0.011984914
KL Divergence                28.419756
KL Loss                      2.8419757
QF Loss                      1007.068
VF Loss                      328.5622
Policy Loss                  -1466.8293
Q Predictions Mean           1466.2382
Q Predictions Std            378.3251
Q Predictions Max            1725.3096
Q Predictions Min            -368.50085
V Predictions Mean           1462.2303
V Predictions Std            373.32098
V Predictions Max            1704.5583
V Predictions Min            -370.30267
Log Pis Mean                 1.2020538
Log Pis Std                  3.241045
Log Pis Max                  16.84743
Log Pis Min                  -7.5410748
Policy mu Mean               -0.00038188417
Policy mu Std                0.7233364
Policy mu Max                4.185192
Policy mu Min                -3.1666615
Policy log std Mean          -1.0534909
Policy log std Std           0.31532222
Policy log std Max           -0.20918655
Policy log std Min           -2.9429584
Z mean eval                  1.3311188
Z variance eval              0.016960952
total_rewards                [4111.28188722 1747.80842231  122.1332815  4081.4440056  4275.8380627
 1333.29752877 4243.78018195 1978.83965574  481.90978272 4074.57242566]
total_rewards_mean           2645.090523416434
total_rewards_std            1596.429250577872
total_rewards_max            4275.838062700582
total_rewards_min            122.13328149905647
Number of train steps total  2300000
Number of env steps total    2877000
Number of rollouts total     0
Train Time (s)               138.75704886810854
(Previous) Eval Time (s)     16.071361627895385
Sample Time (s)              26.78956219693646
Epoch Time (s)               181.61797269294038
Total Train Time (s)         107575.01931223366
Epoch                        574
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:25:52.197763 UTC | [2020_01_11_13_32_55] Iteration #574 | Epoch Duration: 187.5572109222412
2020-01-12 19:25:52.197946 UTC | [2020_01_11_13_32_55] Iteration #574 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3302528
Z variance train             0.016915444
KL Divergence                26.94022
KL Loss                      2.694022
QF Loss                      2892.4028
VF Loss                      1455.786
Policy Loss                  -1452.9243
Q Predictions Mean           1454.9753
Q Predictions Std            332.62744
Q Predictions Max            1651.7516
Q Predictions Min            -439.62338
V Predictions Mean           1456.4082
V Predictions Std            313.99185
V Predictions Max            1641.0409
V Predictions Min            -445.23694
Log Pis Mean                 1.2343516
Log Pis Std                  3.6804256
Log Pis Max                  19.34047
Log Pis Min                  -6.4228706
Policy mu Mean               0.005872124
Policy mu Std                0.73560953
Policy mu Max                3.5959125
Policy mu Min                -4.926909
Policy log std Mean          -1.0651625
Policy log std Std           0.29151154
Policy log std Max           0.51747704
Policy log std Min           -2.721417
Z mean eval                  1.2943598
Z variance eval              0.013693723
total_rewards                [3475.79800385  222.75873306 4317.07420486 4020.05333759 1059.21214643
  404.75335147 4063.41237808 4158.41963069 3245.77918678 4417.41310762]
total_rewards_mean           2938.4674080429586
total_rewards_std            1603.7766484586364
total_rewards_max            4417.413107621275
total_rewards_min            222.7587330614436
Number of train steps total  2304000
Number of env steps total    2882000
Number of rollouts total     0
Train Time (s)               137.67662700032815
(Previous) Eval Time (s)     22.010253021027893
Sample Time (s)              25.740708967205137
Epoch Time (s)               185.42758898856118
Total Train Time (s)         107766.97251251573
Epoch                        575
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:29:04.156719 UTC | [2020_01_11_13_32_55] Iteration #575 | Epoch Duration: 191.95863914489746
2020-01-12 19:29:04.156913 UTC | [2020_01_11_13_32_55] Iteration #575 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2940791
Z variance train             0.013701996
KL Divergence                27.971378
KL Loss                      2.797138
QF Loss                      1132.6667
VF Loss                      477.14813
Policy Loss                  -1408.7202
Q Predictions Mean           1409.9509
Q Predictions Std            411.32108
Q Predictions Max            1675.7638
Q Predictions Min            -391.9498
V Predictions Mean           1410.3778
V Predictions Std            401.84717
V Predictions Max            1666.564
V Predictions Min            -402.38327
Log Pis Mean                 1.0228522
Log Pis Std                  3.2052386
Log Pis Max                  16.114826
Log Pis Min                  -8.190767
Policy mu Mean               -0.013454133
Policy mu Std                0.6458048
Policy mu Max                2.4270403
Policy mu Min                -2.7678807
Policy log std Mean          -1.0908554
Policy log std Std           0.31147262
Policy log std Max           0.08006847
Policy log std Min           -2.9503238
Z mean eval                  1.2654064
Z variance eval              0.010883279
total_rewards                [4146.96731034 3950.04445161 4097.58349544 2467.19772669 4062.89214482
 4255.98962464 4110.69908476 2188.35100264 4015.99213818 4138.29775053]
total_rewards_mean           3743.4014729635483
total_rewards_std            714.6934137855865
total_rewards_max            4255.9896246388635
total_rewards_min            2188.35100263848
Number of train steps total  2308000
Number of env steps total    2887000
Number of rollouts total     0
Train Time (s)               142.39378127409145
(Previous) Eval Time (s)     28.540916576981544
Sample Time (s)              25.181888019666076
Epoch Time (s)               196.11658587073907
Total Train Time (s)         107964.97339670314
Epoch                        576
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:32:22.163569 UTC | [2020_01_11_13_32_55] Iteration #576 | Epoch Duration: 198.00651931762695
2020-01-12 19:32:22.163757 UTC | [2020_01_11_13_32_55] Iteration #576 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2653438
Z variance train             0.0108834375
KL Divergence                28.909195
KL Loss                      2.8909194
QF Loss                      1653.0088
VF Loss                      306.4424
Policy Loss                  -1425.5426
Q Predictions Mean           1429.9772
Q Predictions Std            395.71542
Q Predictions Max            1684.7527
Q Predictions Min            -379.09717
V Predictions Mean           1430.9365
V Predictions Std            397.37195
V Predictions Max            1656.5164
V Predictions Min            -385.89426
Log Pis Mean                 1.1178395
Log Pis Std                  3.35875
Log Pis Max                  14.344374
Log Pis Min                  -9.513083
Policy mu Mean               0.023457557
Policy mu Std                0.71676236
Policy mu Max                2.6184208
Policy mu Min                -2.608329
Policy log std Mean          -1.0455253
Policy log std Std           0.30248192
Policy log std Max           -0.1269052
Policy log std Min           -2.5540533
Z mean eval                  1.3383284
Z variance eval              0.0103299
total_rewards                [3742.03200289 3659.06741816 4021.09518248 4139.38818846  740.30554648
 1141.05367621 3927.72559269 2125.1278482  3833.04109719 4220.61842054]
total_rewards_mean           3154.9454973303245
total_rewards_std            1243.2853418557033
total_rewards_max            4220.6184205398085
total_rewards_min            740.3055464794488
Number of train steps total  2312000
Number of env steps total    2892000
Number of rollouts total     0
Train Time (s)               146.85097234183922
(Previous) Eval Time (s)     30.430426973849535
Sample Time (s)              26.371285068802536
Epoch Time (s)               203.6526843844913
Total Train Time (s)         108168.3207957875
Epoch                        577
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:35:45.516386 UTC | [2020_01_11_13_32_55] Iteration #577 | Epoch Duration: 203.35248160362244
2020-01-12 19:35:45.516619 UTC | [2020_01_11_13_32_55] Iteration #577 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3387786
Z variance train             0.010336489
KL Divergence                28.05108
KL Loss                      2.805108
QF Loss                      1220.8257
VF Loss                      286.3842
Policy Loss                  -1451.9646
Q Predictions Mean           1455.5776
Q Predictions Std            336.78555
Q Predictions Max            1698.9872
Q Predictions Min            -348.8905
V Predictions Mean           1451.3878
V Predictions Std            335.67142
V Predictions Max            1675.2412
V Predictions Min            -339.2067
Log Pis Mean                 0.77924275
Log Pis Std                  2.9716525
Log Pis Max                  15.572763
Log Pis Min                  -5.883198
Policy mu Mean               0.022491422
Policy mu Std                0.65966594
Policy mu Max                2.290956
Policy mu Min                -3.2072492
Policy log std Mean          -1.0403776
Policy log std Std           0.29472145
Policy log std Max           -0.19895631
Policy log std Min           -2.9008937
Z mean eval                  1.3108426
Z variance eval              0.010310971
total_rewards                [4134.95386452 3767.40713216 4139.84397892  511.44058533  448.49702931
 3770.25585962  271.30470482  731.9894941   775.96843485 4278.15529445]
total_rewards_mean           2282.981637807818
total_rewards_std            1746.458171487554
total_rewards_max            4278.155294447969
total_rewards_min            271.3047048172187
Number of train steps total  2316000
Number of env steps total    2897000
Number of rollouts total     0
Train Time (s)               146.05332886008546
(Previous) Eval Time (s)     30.129783868789673
Sample Time (s)              26.691690606996417
Epoch Time (s)               202.87480333587155
Total Train Time (s)         108362.71727401437
Epoch                        578
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:38:59.918204 UTC | [2020_01_11_13_32_55] Iteration #578 | Epoch Duration: 194.40144395828247
2020-01-12 19:38:59.918426 UTC | [2020_01_11_13_32_55] Iteration #578 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3129537
Z variance train             0.010320369
KL Divergence                28.681007
KL Loss                      2.868101
QF Loss                      1094.4304
VF Loss                      261.3174
Policy Loss                  -1372.108
Q Predictions Mean           1374.6932
Q Predictions Std            467.24997
Q Predictions Max            1692.194
Q Predictions Min            -418.89362
V Predictions Mean           1373.7029
V Predictions Std            465.2476
V Predictions Max            1669.9442
V Predictions Min            -432.82083
Log Pis Mean                 0.4080017
Log Pis Std                  3.0428817
Log Pis Max                  16.022871
Log Pis Min                  -7.5616407
Policy mu Mean               -0.019402258
Policy mu Std                0.651124
Policy mu Max                3.204978
Policy mu Min                -2.5792177
Policy log std Mean          -1.0429416
Policy log std Std           0.2756341
Policy log std Max           -0.266927
Policy log std Min           -2.5073023
Z mean eval                  1.3364109
Z variance eval              0.021941999
total_rewards                [4010.74240041  825.31076196 4021.5168474   685.47762563 2020.13813187
 3795.97202931 3749.77934976 4142.83106459 3663.31769397 4160.80069164]
total_rewards_mean           3107.5886596534415
total_rewards_std            1314.7247640700004
total_rewards_max            4160.800691637274
total_rewards_min            685.4776256263232
Number of train steps total  2320000
Number of env steps total    2902000
Number of rollouts total     0
Train Time (s)               148.07790070585907
(Previous) Eval Time (s)     21.65606976626441
Sample Time (s)              26.34296030551195
Epoch Time (s)               196.07693077763543
Total Train Time (s)         108568.41301494138
Epoch                        579
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:42:25.619529 UTC | [2020_01_11_13_32_55] Iteration #579 | Epoch Duration: 205.70095491409302
2020-01-12 19:42:25.619839 UTC | [2020_01_11_13_32_55] Iteration #579 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3378369
Z variance train             0.021881368
KL Divergence                27.888412
KL Loss                      2.7888412
QF Loss                      5340.8804
VF Loss                      738.08527
Policy Loss                  -1432.8313
Q Predictions Mean           1438.6669
Q Predictions Std            390.25888
Q Predictions Max            1673.2137
Q Predictions Min            -382.4002
V Predictions Mean           1432.6201
V Predictions Std            392.0728
V Predictions Max            1675.793
V Predictions Min            -426.80222
Log Pis Mean                 0.9253647
Log Pis Std                  3.929349
Log Pis Max                  29.27103
Log Pis Min                  -9.972602
Policy mu Mean               0.016878545
Policy mu Std                0.72049165
Policy mu Max                4.8095436
Policy mu Min                -4.997196
Policy log std Mean          -1.0329641
Policy log std Std           0.30214575
Policy log std Max           0.48013496
Policy log std Min           -2.5778956
Z mean eval                  1.2778524
Z variance eval              0.0093784155
total_rewards                [ 526.90876678 1232.41037394 4061.41606312 1797.64690573 -108.58536744
 3615.23069326 1581.47506046 1109.90271316   54.24189176 3351.25931278]
total_rewards_mean           1722.19064135439
total_rewards_std            1411.106277833218
total_rewards_max            4061.416063117238
total_rewards_min            -108.58536743896767
Number of train steps total  2324000
Number of env steps total    2907000
Number of rollouts total     0
Train Time (s)               144.77647713106126
(Previous) Eval Time (s)     31.279738552868366
Sample Time (s)              25.392503979615867
Epoch Time (s)               201.4487196635455
Total Train Time (s)         108760.34392980952
Epoch                        580
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:45:37.555985 UTC | [2020_01_11_13_32_55] Iteration #580 | Epoch Duration: 191.9359312057495
2020-01-12 19:45:37.556168 UTC | [2020_01_11_13_32_55] Iteration #580 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2778028
Z variance train             0.009384065
KL Divergence                29.76625
KL Loss                      2.9766252
QF Loss                      5737.4404
VF Loss                      334.7589
Policy Loss                  -1432.4822
Q Predictions Mean           1440.3152
Q Predictions Std            375.35153
Q Predictions Max            1693.8733
Q Predictions Min            -388.08536
V Predictions Mean           1434.7488
V Predictions Std            372.8087
V Predictions Max            1691.7527
V Predictions Min            -391.55893
Log Pis Mean                 1.3994224
Log Pis Std                  3.802094
Log Pis Max                  23.605907
Log Pis Min                  -7.480873
Policy mu Mean               0.03929081
Policy mu Std                0.74712414
Policy mu Max                3.5299938
Policy mu Min                -3.2880974
Policy log std Mean          -1.070085
Policy log std Std           0.3169947
Policy log std Max           -0.12106407
Policy log std Min           -2.5402648
Z mean eval                  1.3111079
Z variance eval              0.007247073
total_rewards                [1354.29613393 3870.90737732 3113.95073593 -113.2528303  2053.03003977
 3181.06029242 4401.95761081 4336.03703304 1841.71939447 4315.47742039]
total_rewards_mean           2835.518320779077
total_rewards_std            1437.1400919241682
total_rewards_max            4401.957610808723
total_rewards_min            -113.25283029662931
Number of train steps total  2328000
Number of env steps total    2912000
Number of rollouts total     0
Train Time (s)               138.47756856121123
(Previous) Eval Time (s)     21.766517436131835
Sample Time (s)              24.791092758066952
Epoch Time (s)               185.03517875541002
Total Train Time (s)         108950.39709607884
Epoch                        581
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:48:47.615268 UTC | [2020_01_11_13_32_55] Iteration #581 | Epoch Duration: 190.05896186828613
2020-01-12 19:48:47.615481 UTC | [2020_01_11_13_32_55] Iteration #581 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.311898
Z variance train             0.007234156
KL Divergence                30.527584
KL Loss                      3.0527585
QF Loss                      1210.7612
VF Loss                      360.4621
Policy Loss                  -1423.8849
Q Predictions Mean           1421.6381
Q Predictions Std            406.34412
Q Predictions Max            1676.4078
Q Predictions Min            -491.29245
V Predictions Mean           1417.7933
V Predictions Std            391.69955
V Predictions Max            1658.8549
V Predictions Min            -450.1258
Log Pis Mean                 1.4691991
Log Pis Std                  3.6555812
Log Pis Max                  23.084326
Log Pis Min                  -5.496307
Policy mu Mean               0.029791595
Policy mu Std                0.6722099
Policy mu Max                3.2616932
Policy mu Min                -2.5141022
Policy log std Mean          -1.1267709
Policy log std Std           0.35411698
Policy log std Max           0.064739466
Policy log std Min           -3.0085628
Z mean eval                  1.2948849
Z variance eval              0.010104237
total_rewards                [1209.93113944 4503.06247497 3688.29360952  762.83290565 4077.26664979
 4159.51983599  112.03098296 1445.95438853 1418.84919336 1048.43141218]
total_rewards_mean           2242.617259238191
total_rewards_std            1574.0073756863349
total_rewards_max            4503.062474971651
total_rewards_min            112.03098295848503
Number of train steps total  2332000
Number of env steps total    2917000
Number of rollouts total     0
Train Time (s)               139.32856464618817
(Previous) Eval Time (s)     26.78985318588093
Sample Time (s)              24.97432074509561
Epoch Time (s)               191.0927385771647
Total Train Time (s)         109136.66555662546
Epoch                        582
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:51:53.889280 UTC | [2020_01_11_13_32_55] Iteration #582 | Epoch Duration: 186.27365279197693
2020-01-12 19:51:53.889487 UTC | [2020_01_11_13_32_55] Iteration #582 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2945554
Z variance train             0.010090283
KL Divergence                29.948898
KL Loss                      2.99489
QF Loss                      829.13477
VF Loss                      318.45935
Policy Loss                  -1435.0433
Q Predictions Mean           1438.145
Q Predictions Std            381.68896
Q Predictions Max            1691.1632
Q Predictions Min            -227.13145
V Predictions Mean           1440.5288
V Predictions Std            378.7865
V Predictions Max            1687.0161
V Predictions Min            -213.50578
Log Pis Mean                 1.277947
Log Pis Std                  3.1533613
Log Pis Max                  16.0799
Log Pis Min                  -7.1171193
Policy mu Mean               -0.0059922617
Policy mu Std                0.70828635
Policy mu Max                3.172718
Policy mu Min                -2.671384
Policy log std Mean          -1.0647094
Policy log std Std           0.29920104
Policy log std Max           0.33612716
Policy log std Min           -2.5763936
Z mean eval                  1.3396654
Z variance eval              0.010404298
total_rewards                [2301.77483311 3113.52980873  244.02928322 4300.65853647 4265.69351212
  788.84054983 3779.15381223 1520.42339023 3124.75819547 4176.80579437]
total_rewards_mean           2761.5667715772884
total_rewards_std            1410.916753398999
total_rewards_max            4300.658536474153
total_rewards_min            244.02928322401527
Number of train steps total  2336000
Number of env steps total    2922000
Number of rollouts total     0
Train Time (s)               147.09098943462595
(Previous) Eval Time (s)     21.97041689278558
Sample Time (s)              26.034502756316215
Epoch Time (s)               195.09590908372775
Total Train Time (s)         109337.91231600521
Epoch                        583
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:55:15.141226 UTC | [2020_01_11_13_32_55] Iteration #583 | Epoch Duration: 201.25160670280457
2020-01-12 19:55:15.141407 UTC | [2020_01_11_13_32_55] Iteration #583 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3383433
Z variance train             0.010373889
KL Divergence                30.045946
KL Loss                      3.0045946
QF Loss                      3097.5952
VF Loss                      455.12723
Policy Loss                  -1439.9465
Q Predictions Mean           1439.5356
Q Predictions Std            415.34042
Q Predictions Max            1708.4669
Q Predictions Min            -362.70114
V Predictions Mean           1444.9163
V Predictions Std            399.84662
V Predictions Max            1713.8092
V Predictions Min            -362.76456
Log Pis Mean                 1.3933973
Log Pis Std                  3.304376
Log Pis Max                  23.65074
Log Pis Min                  -6.905423
Policy mu Mean               -0.01013384
Policy mu Std                0.69187224
Policy mu Max                3.653906
Policy mu Min                -3.5884788
Policy log std Mean          -1.104461
Policy log std Std           0.31926158
Policy log std Max           -0.17655182
Policy log std Min           -2.8054652
Z mean eval                  1.3076994
Z variance eval              0.020917606
total_rewards                [ 361.95132247   75.05669697 3907.81115396 2638.78415557  666.45024891
  954.31319754 4122.24212694 2348.98610463 2184.0403992   267.23783947]
total_rewards_mean           1752.6873245669467
total_rewards_std            1426.8362744080368
total_rewards_max            4122.242126940299
total_rewards_min            75.05669697211312
Number of train steps total  2340000
Number of env steps total    2927000
Number of rollouts total     0
Train Time (s)               145.8429257948883
(Previous) Eval Time (s)     28.1257508341223
Sample Time (s)              26.341802707873285
Epoch Time (s)               200.31047933688387
Total Train Time (s)         109528.91579114553
Epoch                        584
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:58:26.148095 UTC | [2020_01_11_13_32_55] Iteration #584 | Epoch Duration: 191.00657892227173
2020-01-12 19:58:26.148233 UTC | [2020_01_11_13_32_55] Iteration #584 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3055668
Z variance train             0.02108036
KL Divergence                28.190449
KL Loss                      2.8190448
QF Loss                      1037.4115
VF Loss                      382.25616
Policy Loss                  -1455.5256
Q Predictions Mean           1465.3246
Q Predictions Std            332.38232
Q Predictions Max            1693.9963
Q Predictions Min            -251.33197
V Predictions Mean           1459.7599
V Predictions Std            333.16925
V Predictions Max            1681.2269
V Predictions Min            -249.85065
Log Pis Mean                 1.3792266
Log Pis Std                  3.306255
Log Pis Max                  19.86287
Log Pis Min                  -5.1684117
Policy mu Mean               0.008258261
Policy mu Std                0.70274657
Policy mu Max                3.6311586
Policy mu Min                -6.684005
Policy log std Mean          -1.093389
Policy log std Std           0.32931146
Policy log std Max           0.61570597
Policy log std Min           -2.7655482
Z mean eval                  1.3114246
Z variance eval              0.0090095755
total_rewards                [4190.46860503 1251.77047558 4126.01472624 3951.5920775  4087.33756332
 3853.72076582 1225.47440867 4089.59184428 4065.56858934 4325.57207223]
total_rewards_mean           3516.7111128006936
total_rewards_std            1145.2914998221256
total_rewards_max            4325.572072229652
total_rewards_min            1225.4744086683213
Number of train steps total  2344000
Number of env steps total    2932000
Number of rollouts total     0
Train Time (s)               145.46359758265316
(Previous) Eval Time (s)     18.821477700956166
Sample Time (s)              24.182805560994893
Epoch Time (s)               188.46788084460422
Total Train Time (s)         109729.44660676876
Epoch                        585
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:01:46.685628 UTC | [2020_01_11_13_32_55] Iteration #585 | Epoch Duration: 200.53727531433105
2020-01-12 20:01:46.685946 UTC | [2020_01_11_13_32_55] Iteration #585 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3125578
Z variance train             0.009011237
KL Divergence                31.255135
KL Loss                      3.1255136
QF Loss                      1454.517
VF Loss                      454.62225
Policy Loss                  -1442.749
Q Predictions Mean           1446.0505
Q Predictions Std            356.22427
Q Predictions Max            1669.4543
Q Predictions Min            -442.62515
V Predictions Mean           1444.585
V Predictions Std            356.55527
V Predictions Max            1659.774
V Predictions Min            -445.99283
Log Pis Mean                 1.1128801
Log Pis Std                  3.236072
Log Pis Max                  13.622898
Log Pis Min                  -9.2904215
Policy mu Mean               0.012633684
Policy mu Std                0.68621075
Policy mu Max                2.6852431
Policy mu Min                -2.6881099
Policy log std Mean          -1.0830251
Policy log std Std           0.31000397
Policy log std Max           0.4774388
Policy log std Min           -3.0260642
Z mean eval                  1.3075714
Z variance eval              0.00942474
total_rewards                [ 961.32356679  659.64689064  209.57109583 1673.27593621  751.19721901
  371.94277228 1878.54811887 1351.13119501   42.66155702  616.58959767]
total_rewards_mean           851.5887949313461
total_rewards_std            582.2503444302854
total_rewards_max            1878.548118869795
total_rewards_min            42.66155701793702
Number of train steps total  2348000
Number of env steps total    2937000
Number of rollouts total     0
Train Time (s)               146.00879821320996
(Previous) Eval Time (s)     30.890512065961957
Sample Time (s)              26.420948466751724
Epoch Time (s)               203.32025874592364
Total Train Time (s)         109911.71606774488
Epoch                        586
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:04:48.959913 UTC | [2020_01_11_13_32_55] Iteration #586 | Epoch Duration: 182.27374029159546
2020-01-12 20:04:48.960074 UTC | [2020_01_11_13_32_55] Iteration #586 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3076073
Z variance train             0.009414671
KL Divergence                31.40701
KL Loss                      3.140701
QF Loss                      8387.536
VF Loss                      2089.7969
Policy Loss                  -1456.4276
Q Predictions Mean           1455.9309
Q Predictions Std            399.92102
Q Predictions Max            1688.3456
Q Predictions Min            -469.83368
V Predictions Mean           1459.8342
V Predictions Std            385.36716
V Predictions Max            1683.4998
V Predictions Min            -468.909
Log Pis Mean                 1.3470873
Log Pis Std                  3.6453912
Log Pis Max                  17.141052
Log Pis Min                  -10.623848
Policy mu Mean               0.024427298
Policy mu Std                0.74613
Policy mu Max                3.6508749
Policy mu Min                -2.7750158
Policy log std Mean          -1.0651453
Policy log std Std           0.31532124
Policy log std Max           -0.13881588
Policy log std Min           -2.595788
Z mean eval                  1.2607292
Z variance eval              0.012694712
total_rewards                [3988.43222759 1002.01304385 4338.73819502 4121.31142303 4158.14575405
 2744.0176737  4314.13236211 4263.02625439 4373.19933022 1015.88157229]
total_rewards_mean           3431.8897836242336
total_rewards_std            1292.4639884675275
total_rewards_max            4373.199330215232
total_rewards_min            1002.0130438502293
Number of train steps total  2352000
Number of env steps total    2942000
Number of rollouts total     0
Train Time (s)               140.73516306979582
(Previous) Eval Time (s)     9.843647985719144
Sample Time (s)              25.29641622165218
Epoch Time (s)               175.87522727716714
Total Train Time (s)         110106.93003885355
Epoch                        587
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:08:04.179958 UTC | [2020_01_11_13_32_55] Iteration #587 | Epoch Duration: 195.21975588798523
2020-01-12 20:08:04.180155 UTC | [2020_01_11_13_32_55] Iteration #587 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.257621
Z variance train             0.012682809
KL Divergence                30.371283
KL Loss                      3.0371282
QF Loss                      886.82043
VF Loss                      338.18033
Policy Loss                  -1458.6078
Q Predictions Mean           1464.4991
Q Predictions Std            347.03833
Q Predictions Max            1671.9271
Q Predictions Min            -426.45728
V Predictions Mean           1465.5625
V Predictions Std            346.18863
V Predictions Max            1684.2844
V Predictions Min            -434.84116
Log Pis Mean                 1.2787215
Log Pis Std                  3.3997986
Log Pis Max                  14.294119
Log Pis Min                  -6.029769
Policy mu Mean               0.031877212
Policy mu Std                0.6964095
Policy mu Max                2.90756
Policy mu Min                -4.0916286
Policy log std Mean          -1.0847368
Policy log std Std           0.31242833
Policy log std Max           -0.1927818
Policy log std Min           -2.5883255
Z mean eval                  1.2808867
Z variance eval              0.02977759
total_rewards                [1537.93696504  853.71499276 1285.54863785 1751.82056797  495.27014431
 3531.04519242 4363.71091404 4170.09626459 2949.19877335   35.23186054]
total_rewards_mean           2097.3574312885407
total_rewards_std            1472.099562086109
total_rewards_max            4363.710914040932
total_rewards_min            35.23186054499227
Number of train steps total  2356000
Number of env steps total    2947000
Number of rollouts total     0
Train Time (s)               138.67556400969625
(Previous) Eval Time (s)     29.187740210909396
Sample Time (s)              25.079117029439658
Epoch Time (s)               192.9424212500453
Total Train Time (s)         110288.32302710554
Epoch                        588
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:11:05.576215 UTC | [2020_01_11_13_32_55] Iteration #588 | Epoch Duration: 181.39594435691833
2020-01-12 20:11:05.576333 UTC | [2020_01_11_13_32_55] Iteration #588 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2839775
Z variance train             0.029734451
KL Divergence                28.59067
KL Loss                      2.859067
QF Loss                      1026.8699
VF Loss                      291.3401
Policy Loss                  -1438.4946
Q Predictions Mean           1446.508
Q Predictions Std            387.2086
Q Predictions Max            1694.5422
Q Predictions Min            -445.80048
V Predictions Mean           1442.9039
V Predictions Std            393.75214
V Predictions Max            1694.717
V Predictions Min            -464.56552
Log Pis Mean                 1.0339844
Log Pis Std                  3.5628805
Log Pis Max                  16.443974
Log Pis Min                  -8.394449
Policy mu Mean               -0.01114619
Policy mu Std                0.6851028
Policy mu Max                3.0290027
Policy mu Min                -3.0786934
Policy log std Mean          -1.0741384
Policy log std Std           0.3235361
Policy log std Max           -0.066244125
Policy log std Min           -3.042234
Z mean eval                  1.3444239
Z variance eval              0.01282773
total_rewards                [ 575.99864267 4455.56941584  -38.46730403 1190.17666905 4312.09271724
  467.38237952 4038.66922125 1612.55170482 4262.48945437 4189.57887111]
total_rewards_mean           2506.604177184969
total_rewards_std            1794.892139323156
total_rewards_max            4455.569415838573
total_rewards_min            -38.46730402711843
Number of train steps total  2360000
Number of env steps total    2952000
Number of rollouts total     0
Train Time (s)               141.9486533869058
(Previous) Eval Time (s)     17.640847789123654
Sample Time (s)              23.010175910778344
Epoch Time (s)               182.5996770868078
Total Train Time (s)         110478.12904282473
Epoch                        589
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:14:15.389177 UTC | [2020_01_11_13_32_55] Iteration #589 | Epoch Duration: 189.8127269744873
2020-01-12 20:14:15.389379 UTC | [2020_01_11_13_32_55] Iteration #589 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3452759
Z variance train             0.012798478
KL Divergence                29.675459
KL Loss                      2.967546
QF Loss                      2989.4297
VF Loss                      726.0573
Policy Loss                  -1418.8398
Q Predictions Mean           1421.134
Q Predictions Std            453.85452
Q Predictions Max            1703.3087
Q Predictions Min            -452.9974
V Predictions Mean           1413.9966
V Predictions Std            448.59247
V Predictions Max            1696.4819
V Predictions Min            -468.42236
Log Pis Mean                 1.2431469
Log Pis Std                  3.4555063
Log Pis Max                  16.850052
Log Pis Min                  -5.8478746
Policy mu Mean               0.0010994265
Policy mu Std                0.6866316
Policy mu Max                2.7973537
Policy mu Min                -2.4916005
Policy log std Mean          -1.1007574
Policy log std Std           0.37268743
Policy log std Max           -0.12750983
Policy log std Min           -3.108254
Z mean eval                  1.3070832
Z variance eval              0.022920053
total_rewards                [-176.20435654  652.82534248  563.92222812  655.99785354 2506.67835778
 1695.71743227 1325.21165522  403.23838433 4127.86238537 3970.84623037]
total_rewards_mean           1572.6095512948016
total_rewards_std            1426.8535713593753
total_rewards_max            4127.862385371935
total_rewards_min            -176.20435653515517
Number of train steps total  2364000
Number of env steps total    2957000
Number of rollouts total     0
Train Time (s)               148.36273080902174
(Previous) Eval Time (s)     24.853541191201657
Sample Time (s)              25.138239769730717
Epoch Time (s)               198.35451176995412
Total Train Time (s)         110668.94422068167
Epoch                        590
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:17:26.209486 UTC | [2020_01_11_13_32_55] Iteration #590 | Epoch Duration: 190.8199667930603
2020-01-12 20:17:26.209690 UTC | [2020_01_11_13_32_55] Iteration #590 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3075943
Z variance train             0.022911705
KL Divergence                28.725233
KL Loss                      2.8725233
QF Loss                      1470.015
VF Loss                      813.33606
Policy Loss                  -1436.7491
Q Predictions Mean           1442.561
Q Predictions Std            374.72018
Q Predictions Max            1709.7478
Q Predictions Min            -342.26004
V Predictions Mean           1437.1967
V Predictions Std            375.5814
V Predictions Max            1675.8453
V Predictions Min            -342.17026
Log Pis Mean                 1.3123498
Log Pis Std                  3.844286
Log Pis Max                  18.773327
Log Pis Min                  -7.4221516
Policy mu Mean               0.026463006
Policy mu Std                0.72599703
Policy mu Max                3.586801
Policy mu Min                -2.7973416
Policy log std Mean          -1.0938042
Policy log std Std           0.35004038
Policy log std Max           -0.03527677
Policy log std Min           -3.3498015
Z mean eval                  1.2861925
Z variance eval              0.039410673
total_rewards                [1612.09653931 4238.10229551 4170.84459564 4488.33737182  618.6373104
 1217.3278174  1163.63210838 1361.75617371 2071.11220445 4288.95271677]
total_rewards_mean           2523.0799133389746
total_rewards_std            1489.9597544843302
total_rewards_max            4488.337371817898
total_rewards_min            618.637310395281
Number of train steps total  2368000
Number of env steps total    2962000
Number of rollouts total     0
Train Time (s)               146.85345638822764
(Previous) Eval Time (s)     17.318635158706456
Sample Time (s)              25.332997230812907
Epoch Time (s)               189.505088777747
Total Train Time (s)         110868.36693484988
Epoch                        591
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:20:45.637624 UTC | [2020_01_11_13_32_55] Iteration #591 | Epoch Duration: 199.42779636383057
2020-01-12 20:20:45.637822 UTC | [2020_01_11_13_32_55] Iteration #591 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2865304
Z variance train             0.039426353
KL Divergence                28.257277
KL Loss                      2.8257277
QF Loss                      1057.7911
VF Loss                      224.07854
Policy Loss                  -1440.4587
Q Predictions Mean           1444.5333
Q Predictions Std            391.77512
Q Predictions Max            1684.505
Q Predictions Min            -304.58325
V Predictions Mean           1440.1279
V Predictions Std            393.01816
V Predictions Max            1690.8461
V Predictions Min            -287.18927
Log Pis Mean                 1.2388912
Log Pis Std                  3.3590863
Log Pis Max                  17.30539
Log Pis Min                  -5.812548
Policy mu Mean               0.018483648
Policy mu Std                0.69889194
Policy mu Max                2.743085
Policy mu Min                -2.5327
Policy log std Mean          -1.0811591
Policy log std Std           0.33052236
Policy log std Max           -0.117951155
Policy log std Min           -2.7454467
Z mean eval                  1.3235872
Z variance eval              0.019447204
total_rewards                [ 4.00434970e+03  3.94819225e+03  2.92106513e+02  5.13316020e+02
  3.10003628e+03 -3.27370533e+00  9.30040927e+02  1.77551462e+03
  4.34651962e+03  4.19742910e+03]
total_rewards_mean           2310.423131750851
total_rewards_std            1694.981280674785
total_rewards_max            4346.519622065079
total_rewards_min            -3.2737053259507367
Number of train steps total  2372000
Number of env steps total    2967000
Number of rollouts total     0
Train Time (s)               148.33199083339423
(Previous) Eval Time (s)     27.24094861978665
Sample Time (s)              24.758741334080696
Epoch Time (s)               200.33168078726158
Total Train Time (s)         111064.16311813146
Epoch                        592
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:24:01.439767 UTC | [2020_01_11_13_32_55] Iteration #592 | Epoch Duration: 195.80180048942566
2020-01-12 20:24:01.439986 UTC | [2020_01_11_13_32_55] Iteration #592 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.322943
Z variance train             0.019568324
KL Divergence                29.889671
KL Loss                      2.9889672
QF Loss                      1734.6492
VF Loss                      337.81177
Policy Loss                  -1464.0116
Q Predictions Mean           1467.2622
Q Predictions Std            335.84882
Q Predictions Max            1702.306
Q Predictions Min            -419.23068
V Predictions Mean           1475.4484
V Predictions Std            334.50424
V Predictions Max            1696.7831
V Predictions Min            -418.13678
Log Pis Mean                 1.1646192
Log Pis Std                  2.997108
Log Pis Max                  9.020248
Log Pis Min                  -6.180453
Policy mu Mean               0.03220953
Policy mu Std                0.7059488
Policy mu Max                2.8752663
Policy mu Min                -3.0209045
Policy log std Mean          -1.0679833
Policy log std Std           0.26815286
Policy log std Max           0.34304917
Policy log std Min           -2.2692204
Z mean eval                  1.2739997
Z variance eval              0.008814343
total_rewards                [3951.27882916 4133.25374599 4061.95867883 2566.65312808  446.49599904
 4249.35498441 2567.45272017 4214.68905415  105.26544992 1910.99798305]
total_rewards_mean           2820.7400572796823
total_rewards_std            1499.755001853459
total_rewards_max            4249.354984411239
total_rewards_min            105.26544991939501
Number of train steps total  2376000
Number of env steps total    2972000
Number of rollouts total     0
Train Time (s)               147.14026992907748
(Previous) Eval Time (s)     22.71074420819059
Sample Time (s)              25.578515614382923
Epoch Time (s)               195.429529751651
Total Train Time (s)         111265.78213526914
Epoch                        593
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:27:23.064262 UTC | [2020_01_11_13_32_55] Iteration #593 | Epoch Duration: 201.62413549423218
2020-01-12 20:27:23.064459 UTC | [2020_01_11_13_32_55] Iteration #593 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.275513
Z variance train             0.008817226
KL Divergence                29.48737
KL Loss                      2.948737
QF Loss                      1451.5033
VF Loss                      644.0904
Policy Loss                  -1450.0569
Q Predictions Mean           1451.0968
Q Predictions Std            363.13174
Q Predictions Max            1656.3975
Q Predictions Min            -374.27887
V Predictions Mean           1448.4302
V Predictions Std            355.48907
V Predictions Max            1658.8206
V Predictions Min            -368.77173
Log Pis Mean                 1.4286101
Log Pis Std                  3.6671233
Log Pis Max                  25.465395
Log Pis Min                  -6.6877184
Policy mu Mean               0.034587175
Policy mu Std                0.71337634
Policy mu Max                3.2137141
Policy mu Min                -3.8762028
Policy log std Mean          -1.0941069
Policy log std Std           0.31894103
Policy log std Max           0.8057109
Policy log std Min           -2.621253
Z mean eval                  1.28879
Z variance eval              0.012054206
total_rewards                [ 971.33536064 2671.05375045 4328.04005535  259.88207837 1454.99185225
 4236.8443986   950.53215126 4160.33754317 4319.66280599 2241.96116183]
total_rewards_mean           2559.464115791015
total_rewards_std            1527.565793546265
total_rewards_max            4328.040055352448
total_rewards_min            259.8820783652091
Number of train steps total  2380000
Number of env steps total    2977000
Number of rollouts total     0
Train Time (s)               137.5042846482247
(Previous) Eval Time (s)     28.904963898006827
Sample Time (s)              24.020648588892072
Epoch Time (s)               190.4298971351236
Total Train Time (s)         111448.38458174886
Epoch                        594
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:30:25.672098 UTC | [2020_01_11_13_32_55] Iteration #594 | Epoch Duration: 182.60750007629395
2020-01-12 20:30:25.672288 UTC | [2020_01_11_13_32_55] Iteration #594 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2872561
Z variance train             0.012050504
KL Divergence                30.054543
KL Loss                      3.0054543
QF Loss                      954.1145
VF Loss                      210.0
Policy Loss                  -1407.5269
Q Predictions Mean           1413.1975
Q Predictions Std            441.23355
Q Predictions Max            1702.0844
Q Predictions Min            -384.5755
V Predictions Mean           1402.5443
V Predictions Std            439.03024
V Predictions Max            1689.4083
V Predictions Min            -395.69907
Log Pis Mean                 0.99057007
Log Pis Std                  3.7295918
Log Pis Max                  19.137297
Log Pis Min                  -6.514946
Policy mu Mean               0.045517556
Policy mu Std                0.6957091
Policy mu Max                4.34998
Policy mu Min                -3.4262974
Policy log std Mean          -1.0493901
Policy log std Std           0.322589
Policy log std Max           -0.1154592
Policy log std Min           -2.7809227
Z mean eval                  1.3425367
Z variance eval              0.009888412
total_rewards                [3995.65457332 4186.20893093 2561.4232358  4125.95887905 3045.56483052
 4109.16864188  393.82964219  268.79404339  358.28504206 1802.22681096]
total_rewards_mean           2484.7114630105816
total_rewards_std            1584.3165574378022
total_rewards_max            4186.2089309338035
total_rewards_min            268.7940433920594
Number of train steps total  2384000
Number of env steps total    2982000
Number of rollouts total     0
Train Time (s)               138.09694072976708
(Previous) Eval Time (s)     21.082195855677128
Sample Time (s)              25.460499912966043
Epoch Time (s)               184.63963649841025
Total Train Time (s)         111636.1700366945
Epoch                        595
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:33:33.463621 UTC | [2020_01_11_13_32_55] Iteration #595 | Epoch Duration: 187.79119205474854
2020-01-12 20:33:33.463836 UTC | [2020_01_11_13_32_55] Iteration #595 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3432691
Z variance train             0.009899046
KL Divergence                30.429258
KL Loss                      3.0429258
QF Loss                      756.72986
VF Loss                      339.21942
Policy Loss                  -1456.4214
Q Predictions Mean           1458.8203
Q Predictions Std            345.15894
Q Predictions Max            1710.38
Q Predictions Min            -397.84055
V Predictions Mean           1467.4541
V Predictions Std            348.20328
V Predictions Max            1714.0933
V Predictions Min            -435.51428
Log Pis Mean                 0.9152032
Log Pis Std                  3.1783338
Log Pis Max                  14.167351
Log Pis Min                  -7.096801
Policy mu Mean               0.04120326
Policy mu Std                0.67803836
Policy mu Max                2.8890777
Policy mu Min                -2.817989
Policy log std Mean          -1.0797626
Policy log std Std           0.28424123
Policy log std Max           0.039476514
Policy log std Min           -2.1839352
Z mean eval                  1.3363702
Z variance eval              0.020167196
total_rewards                [ 820.50682499 4337.0045122  2388.45376199 1335.7729076  4256.4519402
  259.60256339  602.71725568  732.37137585 1598.09089723 4408.90264108]
total_rewards_mean           2073.9874680204975
total_rewards_std            1582.2240547541676
total_rewards_max            4408.902641075261
total_rewards_min            259.6025633877195
Number of train steps total  2388000
Number of env steps total    2987000
Number of rollouts total     0
Train Time (s)               146.4361982648261
(Previous) Eval Time (s)     24.233394234906882
Sample Time (s)              25.95674990862608
Epoch Time (s)               196.62634240835905
Total Train Time (s)         111824.41657098476
Epoch                        596
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:36:41.717118 UTC | [2020_01_11_13_32_55] Iteration #596 | Epoch Duration: 188.25313758850098
2020-01-12 20:36:41.717363 UTC | [2020_01_11_13_32_55] Iteration #596 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3363587
Z variance train             0.020208897
KL Divergence                28.25966
KL Loss                      2.8259661
QF Loss                      913.5479
VF Loss                      413.23245
Policy Loss                  -1452.9685
Q Predictions Mean           1454.5898
Q Predictions Std            378.92572
Q Predictions Max            1680.2325
Q Predictions Min            -355.10675
V Predictions Mean           1455.8601
V Predictions Std            365.9469
V Predictions Max            1681.3754
V Predictions Min            -341.5076
Log Pis Mean                 1.4990172
Log Pis Std                  3.860915
Log Pis Max                  33.067608
Log Pis Min                  -5.415084
Policy mu Mean               0.054668695
Policy mu Std                0.72824335
Policy mu Max                5.3311324
Policy mu Min                -3.8636513
Policy log std Mean          -1.0589945
Policy log std Std           0.31619477
Policy log std Max           0.013381243
Policy log std Min           -3.354031
Z mean eval                  1.288795
Z variance eval              0.012327169
total_rewards                [4112.18411689 4452.77440835 4482.76792192  448.30046901  573.61311678
 1544.91523954 4161.88022758 4015.58766181 4080.77285558 4325.80014693]
total_rewards_mean           3219.85961643768
total_rewards_std            1577.520859226648
total_rewards_max            4482.767921922109
total_rewards_min            448.300469008706
Number of train steps total  2392000
Number of env steps total    2992000
Number of rollouts total     0
Train Time (s)               146.1906728032045
(Previous) Eval Time (s)     15.859800212085247
Sample Time (s)              26.58284806413576
Epoch Time (s)               188.6333210794255
Total Train Time (s)         112024.7344175009
Epoch                        597
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:40:02.040563 UTC | [2020_01_11_13_32_55] Iteration #597 | Epoch Duration: 200.32305431365967
2020-01-12 20:40:02.040779 UTC | [2020_01_11_13_32_55] Iteration #597 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2882516
Z variance train             0.012337369
KL Divergence                28.793285
KL Loss                      2.8793285
QF Loss                      780.23096
VF Loss                      253.31969
Policy Loss                  -1460.3059
Q Predictions Mean           1464.5455
Q Predictions Std            354.14014
Q Predictions Max            1721.437
Q Predictions Min            -466.54782
V Predictions Mean           1463.1824
V Predictions Std            354.5721
V Predictions Max            1708.3672
V Predictions Min            -454.71744
Log Pis Mean                 1.0806128
Log Pis Std                  3.352588
Log Pis Max                  18.910189
Log Pis Min                  -6.000857
Policy mu Mean               0.0427946
Policy mu Std                0.6631462
Policy mu Max                2.825067
Policy mu Min                -2.3697457
Policy log std Mean          -1.1107525
Policy log std Std           0.2953582
Policy log std Max           -0.23236686
Policy log std Min           -2.5454454
Z mean eval                  1.2942202
Z variance eval              0.025435666
total_rewards                [ 504.58446183 1571.23654257 3314.76630647 4384.61713105 3769.9584375
 4119.42755989 1303.10310864 4413.05996675  660.09740669  845.08078998]
total_rewards_mean           2488.5931711361836
total_rewards_std            1565.5768662488667
total_rewards_max            4413.059966745108
total_rewards_min            504.5844618319822
Number of train steps total  2396000
Number of env steps total    2997000
Number of rollouts total     0
Train Time (s)               145.05705706775188
(Previous) Eval Time (s)     27.5490713538602
Sample Time (s)              27.018566558603197
Epoch Time (s)               199.62469498021528
Total Train Time (s)         112218.29106915789
Epoch                        598
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:43:15.602840 UTC | [2020_01_11_13_32_55] Iteration #598 | Epoch Duration: 193.56192684173584
2020-01-12 20:43:15.603031 UTC | [2020_01_11_13_32_55] Iteration #598 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2936051
Z variance train             0.025326481
KL Divergence                28.05432
KL Loss                      2.805432
QF Loss                      1234.9065
VF Loss                      979.07104
Policy Loss                  -1431.8423
Q Predictions Mean           1437.4456
Q Predictions Std            378.92572
Q Predictions Max            1676.591
Q Predictions Min            -402.3235
V Predictions Mean           1427.6426
V Predictions Std            379.83643
V Predictions Max            1679.7622
V Predictions Min            -390.58035
Log Pis Mean                 1.1530883
Log Pis Std                  3.5383942
Log Pis Max                  17.36267
Log Pis Min                  -7.610116
Policy mu Mean               0.0033792316
Policy mu Std                0.7141239
Policy mu Max                4.388827
Policy mu Min                -3.7694802
Policy log std Mean          -1.0806504
Policy log std Std           0.30509353
Policy log std Max           0.05866587
Policy log std Min           -2.87956
Z mean eval                  1.3060092
Z variance eval              0.013900058
total_rewards                [2647.14260713 3361.65419168 1358.1077516  1006.13984942 3308.50513557
 4042.6709217  3115.89956905 2037.28808793   12.64585783  337.36372311]
total_rewards_mean           2122.741769502015
total_rewards_std            1317.8494693579225
total_rewards_max            4042.6709217017014
total_rewards_min            12.64585782609991
Number of train steps total  2400000
Number of env steps total    3002000
Number of rollouts total     0
Train Time (s)               146.5782584962435
(Previous) Eval Time (s)     21.485953520983458
Sample Time (s)              25.100541670806706
Epoch Time (s)               193.16475368803367
Total Train Time (s)         112410.78686030349
Epoch                        599
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:46:28.104667 UTC | [2020_01_11_13_32_55] Iteration #599 | Epoch Duration: 192.5014922618866
2020-01-12 20:46:28.104886 UTC | [2020_01_11_13_32_55] Iteration #599 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3058726
Z variance train             0.013880757
KL Divergence                29.72917
KL Loss                      2.972917
QF Loss                      3504.7446
VF Loss                      270.06924
Policy Loss                  -1407.0208
Q Predictions Mean           1409.2466
Q Predictions Std            448.38037
Q Predictions Max            1686.3761
Q Predictions Min            -377.98032
V Predictions Mean           1405.8035
V Predictions Std            445.79398
V Predictions Max            1674.5325
V Predictions Min            -371.11823
Log Pis Mean                 0.8069725
Log Pis Std                  3.3761265
Log Pis Max                  10.842935
Log Pis Min                  -8.502996
Policy mu Mean               0.048387744
Policy mu Std                0.67412966
Policy mu Max                2.5533535
Policy mu Min                -2.6489816
Policy log std Mean          -1.059842
Policy log std Std           0.2952716
Policy log std Max           -0.11752701
Policy log std Min           -2.735456
Z mean eval                  1.3431337
Z variance eval              0.008821681
total_rewards                [2844.48200984 4194.0155295  4382.59700001   14.73363831 4324.17908117
 2461.22840853  262.20575101  309.59603315  702.98534983 4226.16961687]
total_rewards_mean           2372.2192418226323
total_rewards_std            1785.7616300937186
total_rewards_max            4382.5970000113875
total_rewards_min            14.733638307533049
Number of train steps total  2404000
Number of env steps total    3007000
Number of rollouts total     0
Train Time (s)               141.96701136417687
(Previous) Eval Time (s)     20.822300953790545
Sample Time (s)              25.227714212145656
Epoch Time (s)               188.01702653011307
Total Train Time (s)         112597.52343380451
Epoch                        600
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:49:34.846555 UTC | [2020_01_11_13_32_55] Iteration #600 | Epoch Duration: 186.74153852462769
2020-01-12 20:49:34.846735 UTC | [2020_01_11_13_32_55] Iteration #600 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3425852
Z variance train             0.00883165
KL Divergence                31.227356
KL Loss                      3.1227357
QF Loss                      1735.229
VF Loss                      782.1822
Policy Loss                  -1450.6256
Q Predictions Mean           1450.7742
Q Predictions Std            375.70657
Q Predictions Max            1703.1749
Q Predictions Min            -434.81003
V Predictions Mean           1459.074
V Predictions Std            365.14423
V Predictions Max            1706.0105
V Predictions Min            -410.19458
Log Pis Mean                 1.2853959
Log Pis Std                  3.2753167
Log Pis Max                  11.005359
Log Pis Min                  -6.4562054
Policy mu Mean               0.022286132
Policy mu Std                0.7218682
Policy mu Max                3.0610285
Policy mu Min                -2.6465623
Policy log std Mean          -1.0846276
Policy log std Std           0.33810166
Policy log std Max           -0.11106551
Policy log std Min           -2.6652982
Z mean eval                  1.2673224
Z variance eval              0.018080072
total_rewards                [2218.51521152  462.85827708 1300.58909064  317.48848426  765.03019708
 2559.1914639  1919.64297422 -153.51589009  559.41629098 4147.91448112]
total_rewards_mean           1409.713058072055
total_rewards_std            1241.6496665900395
total_rewards_max            4147.914481122178
total_rewards_min            -153.51589009374652
Number of train steps total  2408000
Number of env steps total    3012000
Number of rollouts total     0
Train Time (s)               138.2864955398254
(Previous) Eval Time (s)     19.54646027693525
Sample Time (s)              24.895426955539733
Epoch Time (s)               182.7283827723004
Total Train Time (s)         112776.39348757779
Epoch                        601
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:52:33.722532 UTC | [2020_01_11_13_32_55] Iteration #601 | Epoch Duration: 178.87566828727722
2020-01-12 20:52:33.722698 UTC | [2020_01_11_13_32_55] Iteration #601 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2684023
Z variance train             0.018102448
KL Divergence                28.5511
KL Loss                      2.85511
QF Loss                      1227.2241
VF Loss                      314.97415
Policy Loss                  -1400.574
Q Predictions Mean           1404.584
Q Predictions Std            470.84396
Q Predictions Max            1674.2579
Q Predictions Min            -457.77832
V Predictions Mean           1404.1567
V Predictions Std            468.78195
V Predictions Max            1667.8784
V Predictions Min            -436.89117
Log Pis Mean                 1.0729927
Log Pis Std                  3.243537
Log Pis Max                  12.9666
Log Pis Min                  -7.312952
Policy mu Mean               0.017047307
Policy mu Std                0.6770485
Policy mu Max                2.866362
Policy mu Min                -2.4986022
Policy log std Mean          -1.0912123
Policy log std Std           0.3364809
Policy log std Max           0.19079196
Policy log std Min           -3.2801213
Z mean eval                  1.3027819
Z variance eval              0.011222305
total_rewards                [3762.11182297 4345.99001264 2856.88860024 3228.50607192   14.29193068
  898.88269925  704.46106054 3881.73052747    9.24277067 3953.01716982]
total_rewards_mean           2365.512266621197
total_rewards_std            1663.382621872491
total_rewards_max            4345.990012643721
total_rewards_min            9.242770674373714
Number of train steps total  2412000
Number of env steps total    3017000
Number of rollouts total     0
Train Time (s)               139.79838253604248
(Previous) Eval Time (s)     15.693367036990821
Sample Time (s)              24.695245077833533
Epoch Time (s)               180.18699465086684
Total Train Time (s)         112960.60243705707
Epoch                        602
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:55:37.938580 UTC | [2020_01_11_13_32_55] Iteration #602 | Epoch Duration: 184.21572375297546
2020-01-12 20:55:37.938912 UTC | [2020_01_11_13_32_55] Iteration #602 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3047093
Z variance train             0.011200869
KL Divergence                30.606499
KL Loss                      3.0606499
QF Loss                      2272.8928
VF Loss                      1106.1786
Policy Loss                  -1428.1292
Q Predictions Mean           1427.6628
Q Predictions Std            397.10175
Q Predictions Max            1720.5599
Q Predictions Min            -459.9512
V Predictions Mean           1427.0045
V Predictions Std            392.63248
V Predictions Max            1717.986
V Predictions Min            -457.19882
Log Pis Mean                 1.0925028
Log Pis Std                  3.5374901
Log Pis Max                  18.926662
Log Pis Min                  -8.398338
Policy mu Mean               0.027766962
Policy mu Std                0.6832951
Policy mu Max                3.5327358
Policy mu Min                -2.5002942
Policy log std Mean          -1.0761012
Policy log std Std           0.34859613
Policy log std Max           -0.06372535
Policy log std Min           -3.1698103
Z mean eval                  1.3749564
Z variance eval              0.01084727
total_rewards                [2245.76488333 2146.83192014 3324.33708288  803.38061338 4474.27888401
 3341.32392908 3697.88877094  965.32059584  640.42678858   92.98263678]
total_rewards_mean           2173.2536104969404
total_rewards_std            1425.7386397220478
total_rewards_max            4474.27888401105
total_rewards_min            92.98263677905777
Number of train steps total  2416000
Number of env steps total    3022000
Number of rollouts total     0
Train Time (s)               148.81060464307666
(Previous) Eval Time (s)     19.72175493882969
Sample Time (s)              26.46122316038236
Epoch Time (s)               194.9935827422887
Total Train Time (s)         113157.32959059393
Epoch                        603
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:58:54.671862 UTC | [2020_01_11_13_32_55] Iteration #603 | Epoch Duration: 196.73278069496155
2020-01-12 20:58:54.672058 UTC | [2020_01_11_13_32_55] Iteration #603 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3768971
Z variance train             0.010841387
KL Divergence                29.524706
KL Loss                      2.9524705
QF Loss                      1451.2618
VF Loss                      237.75319
Policy Loss                  -1486.2906
Q Predictions Mean           1488.8987
Q Predictions Std            334.00015
Q Predictions Max            1714.3436
Q Predictions Min            -471.59314
V Predictions Mean           1482.3784
V Predictions Std            328.165
V Predictions Max            1691.4124
V Predictions Min            -489.1481
Log Pis Mean                 1.386796
Log Pis Std                  3.2748425
Log Pis Max                  11.160568
Log Pis Min                  -9.066291
Policy mu Mean               0.027040906
Policy mu Std                0.7257746
Policy mu Max                2.6026905
Policy mu Min                -2.7008293
Policy log std Mean          -1.0692799
Policy log std Std           0.29323828
Policy log std Max           -0.041073322
Policy log std Min           -2.5984752
Z mean eval                  1.3139827
Z variance eval              0.007115635
total_rewards                [6.26790706e+01 1.18423071e+03 1.30404424e+03 4.36450082e+03
 1.34924823e+00 4.45672988e+03 2.74383774e+02 5.53679831e+02
 2.09383933e+03 9.98250685e+02]
total_rewards_mean           1529.3687594364771
total_rewards_std            1561.7618336863131
total_rewards_max            4456.729875967923
total_rewards_min            1.3492482257970764
Number of train steps total  2420000
Number of env steps total    3027000
Number of rollouts total     0
Train Time (s)               147.73591018561274
(Previous) Eval Time (s)     21.46050892211497
Sample Time (s)              25.779475282412022
Epoch Time (s)               194.97589439013973
Total Train Time (s)         113342.18531608116
Epoch                        604
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:01:59.533478 UTC | [2020_01_11_13_32_55] Iteration #604 | Epoch Duration: 184.86128091812134
2020-01-12 21:01:59.533697 UTC | [2020_01_11_13_32_55] Iteration #604 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3154004
Z variance train             0.007119841
KL Divergence                31.172623
KL Loss                      3.1172624
QF Loss                      1131.8922
VF Loss                      324.03363
Policy Loss                  -1479.6305
Q Predictions Mean           1479.5596
Q Predictions Std            343.56775
Q Predictions Max            1682.0991
Q Predictions Min            -473.1461
V Predictions Mean           1470.7754
V Predictions Std            334.7912
V Predictions Max            1670.0613
V Predictions Min            -471.3836
Log Pis Mean                 1.6026678
Log Pis Std                  3.125649
Log Pis Max                  12.598503
Log Pis Min                  -7.021347
Policy mu Mean               0.009199651
Policy mu Std                0.70456874
Policy mu Max                2.714975
Policy mu Min                -2.299524
Policy log std Mean          -1.0957556
Policy log std Std           0.30671072
Policy log std Max           -0.14660823
Policy log std Min           -2.7769194
Z mean eval                  1.3122523
Z variance eval              0.01821142
total_rewards                [1357.12367646  500.33331348 1935.3834659   773.49949685   38.32173703
 3438.43085754 2710.9176292  4138.70990862  394.48118363 3171.56158371]
total_rewards_mean           1845.8762852411205
total_rewards_std            1374.053267759572
total_rewards_max            4138.709908617481
total_rewards_min            38.32173702602798
Number of train steps total  2424000
Number of env steps total    3032000
Number of rollouts total     0
Train Time (s)               145.87541130604222
(Previous) Eval Time (s)     11.345550897996873
Sample Time (s)              23.692039513029158
Epoch Time (s)               180.91300171706825
Total Train Time (s)         113531.6619269643
Epoch                        605
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:05:09.016753 UTC | [2020_01_11_13_32_55] Iteration #605 | Epoch Duration: 189.48285341262817
2020-01-12 21:05:09.017236 UTC | [2020_01_11_13_32_55] Iteration #605 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3124362
Z variance train             0.018260565
KL Divergence                28.655043
KL Loss                      2.8655043
QF Loss                      942.7997
VF Loss                      398.0622
Policy Loss                  -1462.5181
Q Predictions Mean           1465.0398
Q Predictions Std            339.39862
Q Predictions Max            1696.3805
Q Predictions Min            -348.41025
V Predictions Mean           1462.5078
V Predictions Std            338.7047
V Predictions Max            1684.7035
V Predictions Min            -338.17056
Log Pis Mean                 1.6681005
Log Pis Std                  3.7356415
Log Pis Max                  23.851566
Log Pis Min                  -8.671883
Policy mu Mean               -0.014597101
Policy mu Std                0.70997655
Policy mu Max                3.5358205
Policy mu Min                -4.2707844
Policy log std Mean          -1.1238782
Policy log std Std           0.33018768
Policy log std Max           -0.1285218
Policy log std Min           -2.8574953
Z mean eval                  1.2750647
Z variance eval              0.027473083
total_rewards                [4139.08326106 4348.12854025 3789.89766921 2479.61767007 2636.69879864
  220.53194761 4378.12018959 1740.19080573 2012.71152419 4147.70858233]
total_rewards_mean           2989.268898866533
total_rewards_std            1328.3178901510125
total_rewards_max            4378.120189585888
total_rewards_min            220.53194761449433
Number of train steps total  2428000
Number of env steps total    3037000
Number of rollouts total     0
Train Time (s)               146.55859674839303
(Previous) Eval Time (s)     19.91505133593455
Sample Time (s)              25.824746542610228
Epoch Time (s)               192.2983946269378
Total Train Time (s)         113731.92306659976
Epoch                        606
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:08:29.283171 UTC | [2020_01_11_13_32_55] Iteration #606 | Epoch Duration: 200.26569318771362
2020-01-12 21:08:29.283403 UTC | [2020_01_11_13_32_55] Iteration #606 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2750412
Z variance train             0.027447384
KL Divergence                26.411936
KL Loss                      2.6411936
QF Loss                      1353.5217
VF Loss                      1111.0471
Policy Loss                  -1410.2885
Q Predictions Mean           1410.9792
Q Predictions Std            419.83658
Q Predictions Max            1684.3724
Q Predictions Min            -475.21747
V Predictions Mean           1411.6736
V Predictions Std            416.75458
V Predictions Max            1677.2935
V Predictions Min            -505.7769
Log Pis Mean                 1.2747645
Log Pis Std                  3.429485
Log Pis Max                  18.105318
Log Pis Min                  -7.866485
Policy mu Mean               0.0088248765
Policy mu Std                0.6672039
Policy mu Max                2.8886125
Policy mu Min                -3.1348226
Policy log std Mean          -1.1107082
Policy log std Std           0.3351175
Policy log std Max           0.7606672
Policy log std Min           -2.6510959
Z mean eval                  1.2754481
Z variance eval              0.017203595
total_rewards                [1920.23520237  924.36384878 1535.14853802 3718.45285588 4115.65383426
 2144.15772315 1158.66668992 4212.38042709  861.51479275 3966.19981634]
total_rewards_mean           2455.677372855651
total_rewards_std            1323.534500656198
total_rewards_max            4212.380427090343
total_rewards_min            861.5147927482583
Number of train steps total  2432000
Number of env steps total    3042000
Number of rollouts total     0
Train Time (s)               138.95832128403708
(Previous) Eval Time (s)     27.882015668787062
Sample Time (s)              26.86687919823453
Epoch Time (s)               193.70721615105867
Total Train Time (s)         113921.06274652854
Epoch                        607
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:11:38.428679 UTC | [2020_01_11_13_32_55] Iteration #607 | Epoch Duration: 189.1451461315155
2020-01-12 21:11:38.428857 UTC | [2020_01_11_13_32_55] Iteration #607 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2757198
Z variance train             0.017163705
KL Divergence                27.704462
KL Loss                      2.7704463
QF Loss                      1300.9064
VF Loss                      366.63058
Policy Loss                  -1455.8145
Q Predictions Mean           1454.5056
Q Predictions Std            364.45358
Q Predictions Max            1677.7811
Q Predictions Min            -364.7437
V Predictions Mean           1458.759
V Predictions Std            352.84204
V Predictions Max            1678.0004
V Predictions Min            -369.6948
Log Pis Mean                 1.2980602
Log Pis Std                  3.4239886
Log Pis Max                  16.551434
Log Pis Min                  -7.1224837
Policy mu Mean               -0.004330163
Policy mu Std                0.6933964
Policy mu Max                3.0143518
Policy mu Min                -2.5531633
Policy log std Mean          -1.0868666
Policy log std Std           0.3111209
Policy log std Max           -0.036291122
Policy log std Min           -2.5952773
Z mean eval                  1.3906697
Z variance eval              0.15462844
total_rewards                [  51.10535478 1979.1932308  1905.62878231  170.40236338  212.39525819
  146.35781928  739.64383105 1295.31261992   67.94611171   46.43023992]
total_rewards_mean           661.4415611340528
total_rewards_std            741.8516572723327
total_rewards_max            1979.1932307986824
total_rewards_min            46.43023991846903
Number of train steps total  2436000
Number of env steps total    3047000
Number of rollouts total     0
Train Time (s)               137.98918543197215
(Previous) Eval Time (s)     23.319556116126478
Sample Time (s)              23.963054054416716
Epoch Time (s)               185.27179560251534
Total Train Time (s)         114095.28875195514
Epoch                        608
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:14:32.660388 UTC | [2020_01_11_13_32_55] Iteration #608 | Epoch Duration: 174.23140406608582
2020-01-12 21:14:32.660575 UTC | [2020_01_11_13_32_55] Iteration #608 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3930638
Z variance train             0.15399507
KL Divergence                24.956287
KL Loss                      2.4956288
QF Loss                      2669.1724
VF Loss                      597.6229
Policy Loss                  -1486.5881
Q Predictions Mean           1490.617
Q Predictions Std            307.3693
Q Predictions Max            1677.5891
Q Predictions Min            -489.20142
V Predictions Mean           1488.4128
V Predictions Std            310.5259
V Predictions Max            1674.5331
V Predictions Min            -504.58203
Log Pis Mean                 1.923619
Log Pis Std                  3.11011
Log Pis Max                  13.762131
Log Pis Min                  -8.164011
Policy mu Mean               0.00357188
Policy mu Std                0.7295612
Policy mu Max                3.7706869
Policy mu Min                -2.7054553
Policy log std Mean          -1.1485062
Policy log std Std           0.3019254
Policy log std Max           0.10623169
Policy log std Min           -2.8467348
Z mean eval                  1.335915
Z variance eval              0.030818611
total_rewards                [4066.7308542   941.41948515  503.83958446 4116.90276403  629.67008028
 3477.09441902 4544.37016847 2602.64721207 4290.75107353 3214.33512006]
total_rewards_mean           2838.7760761267373
total_rewards_std            1506.4877983383788
total_rewards_max            4544.370168474126
total_rewards_min            503.8395844595359
Number of train steps total  2440000
Number of env steps total    3052000
Number of rollouts total     0
Train Time (s)               142.26974987704307
(Previous) Eval Time (s)     12.278853313997388
Sample Time (s)              24.24293502466753
Epoch Time (s)               178.791538215708
Total Train Time (s)         114289.09018528694
Epoch                        609
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:17:46.468419 UTC | [2020_01_11_13_32_55] Iteration #609 | Epoch Duration: 193.80769419670105
2020-01-12 21:17:46.468706 UTC | [2020_01_11_13_32_55] Iteration #609 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3359164
Z variance train             0.030790474
KL Divergence                26.330051
KL Loss                      2.6330051
QF Loss                      1386.9451
VF Loss                      579.3888
Policy Loss                  -1318.7238
Q Predictions Mean           1319.1365
Q Predictions Std            531.127
Q Predictions Max            1674.5011
Q Predictions Min            -508.8776
V Predictions Mean           1309.8147
V Predictions Std            532.6072
V Predictions Max            1649.056
V Predictions Min            -526.46075
Log Pis Mean                 1.2085543
Log Pis Std                  4.043454
Log Pis Max                  27.51847
Log Pis Min                  -10.354249
Policy mu Mean               0.044834048
Policy mu Std                0.69333625
Policy mu Max                3.2387807
Policy mu Min                -2.4057202
Policy log std Mean          -1.1168046
Policy log std Std           0.34775373
Policy log std Max           -0.20051682
Policy log std Min           -3.1941106
Z mean eval                  1.3552617
Z variance eval              0.009654011
total_rewards                [ 721.37745376 2872.33051835  950.51172757  818.28723304 4371.61612577
 2068.10637635 1211.93324896 3419.74599459 2857.82571267 4233.15818257]
total_rewards_mean           2352.48925736252
total_rewards_std            1328.1569908127544
total_rewards_max            4371.61612576646
total_rewards_min            721.3774537575486
Number of train steps total  2444000
Number of env steps total    3057000
Number of rollouts total     0
Train Time (s)               147.7918466660194
(Previous) Eval Time (s)     27.294667730107903
Sample Time (s)              25.60991775104776
Epoch Time (s)               200.69643214717507
Total Train Time (s)         114481.92843029695
Epoch                        610
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:20:59.312022 UTC | [2020_01_11_13_32_55] Iteration #610 | Epoch Duration: 192.84315967559814
2020-01-12 21:20:59.312205 UTC | [2020_01_11_13_32_55] Iteration #610 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3561864
Z variance train             0.009664396
KL Divergence                29.551197
KL Loss                      2.9551198
QF Loss                      2101.9766
VF Loss                      1094.863
Policy Loss                  -1454.9805
Q Predictions Mean           1458.1362
Q Predictions Std            381.49756
Q Predictions Max            1687.0325
Q Predictions Min            -517.10815
V Predictions Mean           1449.6602
V Predictions Std            365.2316
V Predictions Max            1665.0272
V Predictions Min            -499.19003
Log Pis Mean                 1.4870932
Log Pis Std                  3.1799338
Log Pis Max                  12.021107
Log Pis Min                  -6.8498774
Policy mu Mean               0.0116849905
Policy mu Std                0.70793563
Policy mu Max                2.8374321
Policy mu Min                -3.1098745
Policy log std Mean          -1.0874069
Policy log std Std           0.28721672
Policy log std Max           -0.25779188
Policy log std Min           -2.3906512
Z mean eval                  1.3587065
Z variance eval              0.0061067883
total_rewards                [1907.24102882 1097.35765342 3799.66734862 2279.11711894 3965.18641041
 3838.81526257 4253.66350028 3874.82897547 4031.14176396 1786.08102297]
total_rewards_mean           3083.310008544737
total_rewards_std            1114.1342320181848
total_rewards_max            4253.663500282381
total_rewards_min            1097.3576534176616
Number of train steps total  2448000
Number of env steps total    3062000
Number of rollouts total     0
Train Time (s)               147.29934094985947
(Previous) Eval Time (s)     19.441017359960824
Sample Time (s)              26.05152114946395
Epoch Time (s)               192.79187945928425
Total Train Time (s)         114682.19377018418
Epoch                        611
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:24:19.583257 UTC | [2020_01_11_13_32_55] Iteration #611 | Epoch Duration: 200.27085971832275
2020-01-12 21:24:19.583455 UTC | [2020_01_11_13_32_55] Iteration #611 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3582287
Z variance train             0.006104461
KL Divergence                29.974705
KL Loss                      2.9974706
QF Loss                      1778.1434
VF Loss                      1981.7831
Policy Loss                  -1433.2693
Q Predictions Mean           1431.7834
Q Predictions Std            399.9716
Q Predictions Max            1673.9669
Q Predictions Min            -450.78522
V Predictions Mean           1432.3147
V Predictions Std            383.36963
V Predictions Max            1666.5465
V Predictions Min            -473.9684
Log Pis Mean                 1.0229293
Log Pis Std                  2.9310474
Log Pis Max                  9.160444
Log Pis Min                  -10.664386
Policy mu Mean               0.01739463
Policy mu Std                0.69003886
Policy mu Max                2.662916
Policy mu Min                -2.749099
Policy log std Mean          -1.0751075
Policy log std Std           0.2962917
Policy log std Max           -0.017343521
Policy log std Min           -2.946464
Z mean eval                  1.2847509
Z variance eval              0.012867516
total_rewards                [ 608.53465545 4481.45234572 1549.85313723 4449.20803954 1052.59407587
  654.41843798 4464.32214172 2278.12569957 2890.6261029  1091.10546335]
total_rewards_mean           2352.0240099343496
total_rewards_std            1534.0643439729438
total_rewards_max            4481.452345724183
total_rewards_min            608.5346554462055
Number of train steps total  2452000
Number of env steps total    3067000
Number of rollouts total     0
Train Time (s)               148.78797308774665
(Previous) Eval Time (s)     26.919597669970244
Sample Time (s)              25.650192537810653
Epoch Time (s)               201.35776329552755
Total Train Time (s)         114876.89624333382
Epoch                        612
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:27:34.291700 UTC | [2020_01_11_13_32_55] Iteration #612 | Epoch Duration: 194.70810198783875
2020-01-12 21:27:34.291921 UTC | [2020_01_11_13_32_55] Iteration #612 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2884734
Z variance train             0.012768598
KL Divergence                28.771515
KL Loss                      2.8771515
QF Loss                      1223.7906
VF Loss                      255.95734
Policy Loss                  -1419.88
Q Predictions Mean           1429.8414
Q Predictions Std            399.97906
Q Predictions Max            1699.2037
Q Predictions Min            -376.1806
V Predictions Mean           1419.8826
V Predictions Std            401.79794
V Predictions Max            1687.3716
V Predictions Min            -375.58817
Log Pis Mean                 1.326501
Log Pis Std                  3.2460208
Log Pis Max                  10.625028
Log Pis Min                  -8.724936
Policy mu Mean               -0.021903694
Policy mu Std                0.6905714
Policy mu Max                2.6755922
Policy mu Min                -2.810928
Policy log std Mean          -1.1029962
Policy log std Std           0.31807077
Policy log std Max           -0.22678804
Policy log std Min           -2.5812325
Z mean eval                  1.3272172
Z variance eval              0.0044157472
total_rewards                [ 918.99051746   58.30382617 4543.97183966   72.71973586 4308.44718736
 1173.96392912  382.43183808  430.71555919   17.31913367 4069.43269373]
total_rewards_mean           1597.629626031015
total_rewards_std            1811.352196711647
total_rewards_max            4543.971839661698
total_rewards_min            17.31913366867657
Number of train steps total  2456000
Number of env steps total    3072000
Number of rollouts total     0
Train Time (s)               147.3823194229044
(Previous) Eval Time (s)     20.269543926697224
Sample Time (s)              24.566751336678863
Epoch Time (s)               192.2186146862805
Total Train Time (s)         115063.67334251478
Epoch                        613
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:30:41.074606 UTC | [2020_01_11_13_32_55] Iteration #613 | Epoch Duration: 186.78255152702332
2020-01-12 21:30:41.074798 UTC | [2020_01_11_13_32_55] Iteration #613 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3263601
Z variance train             0.0044121942
KL Divergence                32.6411
KL Loss                      3.2641103
QF Loss                      2958.8682
VF Loss                      532.03735
Policy Loss                  -1403.508
Q Predictions Mean           1405.0228
Q Predictions Std            453.69028
Q Predictions Max            1652.6127
Q Predictions Min            -524.388
V Predictions Mean           1403.4889
V Predictions Std            445.71143
V Predictions Max            1650.5172
V Predictions Min            -511.85992
Log Pis Mean                 1.1963902
Log Pis Std                  3.3842096
Log Pis Max                  16.918655
Log Pis Min                  -7.630721
Policy mu Mean               0.011770948
Policy mu Std                0.70146185
Policy mu Max                3.4418757
Policy mu Min                -2.2764714
Policy log std Mean          -1.0717468
Policy log std Std           0.32909337
Policy log std Max           -0.06365156
Policy log std Min           -2.5721154
Z mean eval                  1.3480386
Z variance eval              0.0046213316
total_rewards                [2409.04070318 2858.59835623 1000.93842446  632.41014974 4213.92630107
 4181.48766365 4263.33601614  781.03627717 1703.40184382 4052.74694523]
total_rewards_mean           2609.6922680680245
total_rewards_std            1436.1875193419526
total_rewards_max            4263.336016138029
total_rewards_min            632.41014973791
Number of train steps total  2460000
Number of env steps total    3077000
Number of rollouts total     0
Train Time (s)               138.87216409528628
(Previous) Eval Time (s)     14.833141122944653
Sample Time (s)              24.09810748230666
Epoch Time (s)               177.8034127005376
Total Train Time (s)         115248.76383041684
Epoch                        614
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:33:46.171391 UTC | [2020_01_11_13_32_55] Iteration #614 | Epoch Duration: 185.09627509117126
2020-01-12 21:33:46.171584 UTC | [2020_01_11_13_32_55] Iteration #614 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3504786
Z variance train             0.0046131527
KL Divergence                32.62629
KL Loss                      3.262629
QF Loss                      870.06476
VF Loss                      359.75235
Policy Loss                  -1461.2289
Q Predictions Mean           1465.315
Q Predictions Std            352.2613
Q Predictions Max            1708.7509
Q Predictions Min            -402.66003
V Predictions Mean           1472.6589
V Predictions Std            352.94275
V Predictions Max            1714.2494
V Predictions Min            -404.32257
Log Pis Mean                 1.2581553
Log Pis Std                  3.2232509
Log Pis Max                  11.495519
Log Pis Min                  -9.863924
Policy mu Mean               -0.014008468
Policy mu Std                0.6805516
Policy mu Max                3.1468444
Policy mu Min                -2.4385915
Policy log std Mean          -1.1008847
Policy log std Std           0.3185009
Policy log std Max           -0.13656747
Policy log std Min           -3.0393238
Z mean eval                  1.31643
Z variance eval              0.018300742
total_rewards                [3972.24364923  325.32943279  835.80288774 4241.86580967  435.29117073
 4240.60202313 4124.47050137 1220.62237014 2780.63369424  192.56574121]
total_rewards_mean           2236.9427280250825
total_rewards_std            1702.3450970273107
total_rewards_max            4241.865809666213
total_rewards_min            192.5657412140685
Number of train steps total  2464000
Number of env steps total    3082000
Number of rollouts total     0
Train Time (s)               138.59804587997496
(Previous) Eval Time (s)     22.125635175034404
Sample Time (s)              23.615286376327276
Epoch Time (s)               184.33896743133664
Total Train Time (s)         115432.10727695795
Epoch                        615
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:36:49.520423 UTC | [2020_01_11_13_32_55] Iteration #615 | Epoch Duration: 183.3487033843994
2020-01-12 21:36:49.520616 UTC | [2020_01_11_13_32_55] Iteration #615 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3175626
Z variance train             0.018306281
KL Divergence                31.649893
KL Loss                      3.1649892
QF Loss                      1108.0876
VF Loss                      235.9194
Policy Loss                  -1461.3829
Q Predictions Mean           1464.7031
Q Predictions Std            359.22635
Q Predictions Max            1697.3788
Q Predictions Min            -360.2396
V Predictions Mean           1458.2695
V Predictions Std            355.60992
V Predictions Max            1691.4032
V Predictions Min            -352.3897
Log Pis Mean                 0.90218055
Log Pis Std                  3.189609
Log Pis Max                  13.641631
Log Pis Min                  -7.250546
Policy mu Mean               -0.019054947
Policy mu Std                0.68115515
Policy mu Max                3.4995565
Policy mu Min                -2.8536148
Policy log std Mean          -1.0548849
Policy log std Std           0.28964466
Policy log std Max           -0.013067365
Policy log std Min           -2.4856722
Z mean eval                  1.3188455
Z variance eval              0.013014093
total_rewards                [3601.72337276 4012.63524565  392.31039393 4395.90565595 4049.39036475
 3664.53146733 4364.24515199 4472.63639189  904.68333432  137.78649159]
total_rewards_mean           2999.5847870161297
total_rewards_std            1682.0035731020898
total_rewards_max            4472.636391885505
total_rewards_min            137.78649159210994
Number of train steps total  2468000
Number of env steps total    3087000
Number of rollouts total     0
Train Time (s)               145.4421687638387
(Previous) Eval Time (s)     21.13503626221791
Sample Time (s)              22.59856367809698
Epoch Time (s)               189.1757687041536
Total Train Time (s)         115625.50324767642
Epoch                        616
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:40:02.922510 UTC | [2020_01_11_13_32_55] Iteration #616 | Epoch Duration: 193.401757478714
2020-01-12 21:40:02.922716 UTC | [2020_01_11_13_32_55] Iteration #616 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3176407
Z variance train             0.012991732
KL Divergence                30.464378
KL Loss                      3.046438
QF Loss                      1823.111
VF Loss                      543.8995
Policy Loss                  -1415.4885
Q Predictions Mean           1417.8241
Q Predictions Std            432.42493
Q Predictions Max            1680.4392
Q Predictions Min            -463.99146
V Predictions Mean           1413.3667
V Predictions Std            433.21643
V Predictions Max            1669.7008
V Predictions Min            -475.89264
Log Pis Mean                 1.5766697
Log Pis Std                  3.4882927
Log Pis Max                  23.381237
Log Pis Min                  -7.3143277
Policy mu Mean               0.018786177
Policy mu Std                0.6921587
Policy mu Max                3.6990805
Policy mu Min                -2.24556
Policy log std Mean          -1.1066811
Policy log std Std           0.33560646
Policy log std Max           -0.12086308
Policy log std Min           -3.0161705
Z mean eval                  1.3000562
Z variance eval              0.021094436
total_rewards                [3216.01883321 4136.08271595 4166.12896516 2704.63425779 1325.5441349
 4241.39062669  491.2961316  4433.43542072 1467.44866225 2187.90451098]
total_rewards_mean           2836.988425925566
total_rewards_std            1349.8191008058707
total_rewards_max            4433.435420723572
total_rewards_min            491.29613160424145
Number of train steps total  2472000
Number of env steps total    3092000
Number of rollouts total     0
Train Time (s)               146.53331725718454
(Previous) Eval Time (s)     25.36074377875775
Sample Time (s)              27.261104576755315
Epoch Time (s)               199.1551656126976
Total Train Time (s)         115826.99083734443
Epoch                        617
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:43:24.415965 UTC | [2020_01_11_13_32_55] Iteration #617 | Epoch Duration: 201.49311208724976
2020-01-12 21:43:24.416140 UTC | [2020_01_11_13_32_55] Iteration #617 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3009146
Z variance train             0.020967545
KL Divergence                28.79243
KL Loss                      2.8792431
QF Loss                      1391.6112
VF Loss                      714.0802
Policy Loss                  -1450.7203
Q Predictions Mean           1453.4712
Q Predictions Std            390.85477
Q Predictions Max            1707.5897
Q Predictions Min            -354.45544
V Predictions Mean           1448.5969
V Predictions Std            388.60165
V Predictions Max            1694.3248
V Predictions Min            -386.98453
Log Pis Mean                 1.3841703
Log Pis Std                  3.555111
Log Pis Max                  17.407166
Log Pis Min                  -8.014694
Policy mu Mean               0.026432272
Policy mu Std                0.704338
Policy mu Max                2.8872595
Policy mu Min                -2.9636996
Policy log std Mean          -1.0867394
Policy log std Std           0.3422894
Policy log std Max           0.33595777
Policy log std Min           -2.8932514
Z mean eval                  1.2962974
Z variance eval              0.0069131874
total_rewards                [  84.35307699 2669.28755779  292.14544066  948.75277754  243.24433634
 2060.57113366  303.69003237 3573.45145973 4188.3877997  4366.38015724]
total_rewards_mean           1873.0263772017322
total_rewards_std            1637.3816419899315
total_rewards_max            4366.380157240199
total_rewards_min            84.35307699397295
Number of train steps total  2476000
Number of env steps total    3097000
Number of rollouts total     0
Train Time (s)               146.0098835020326
(Previous) Eval Time (s)     27.69833697983995
Sample Time (s)              26.104108224622905
Epoch Time (s)               199.81232870649546
Total Train Time (s)         116019.22864429653
Epoch                        618
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:46:36.657151 UTC | [2020_01_11_13_32_55] Iteration #618 | Epoch Duration: 192.24089646339417
2020-01-12 21:46:36.657266 UTC | [2020_01_11_13_32_55] Iteration #618 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2949255
Z variance train             0.0069018165
KL Divergence                31.19546
KL Loss                      3.119546
QF Loss                      1368.3743
VF Loss                      2393.1912
Policy Loss                  -1486.5127
Q Predictions Mean           1488.4745
Q Predictions Std            297.99634
Q Predictions Max            1691.1923
Q Predictions Min            -118.67653
V Predictions Mean           1471.6415
V Predictions Std            297.2942
V Predictions Max            1657.1713
V Predictions Min            -134.28386
Log Pis Mean                 1.1038232
Log Pis Std                  3.5021894
Log Pis Max                  20.381413
Log Pis Min                  -9.177967
Policy mu Mean               0.03161955
Policy mu Std                0.68304
Policy mu Max                3.7301636
Policy mu Min                -2.7499514
Policy log std Mean          -1.0971452
Policy log std Std           0.34722763
Policy log std Max           0.086081386
Policy log std Min           -3.3456936
Z mean eval                  1.3193089
Z variance eval              0.007442037
total_rewards                [3982.11249036  629.42255041 3386.45825632 1835.16840077  516.16153406
  501.97513415 2330.14732644  112.76673154 1198.0491003  3799.32312343]
total_rewards_mean           1829.158464776924
total_rewards_std            1395.06311066338
total_rewards_max            3982.1124903611217
total_rewards_min            112.7667315364031
Number of train steps total  2480000
Number of env steps total    3102000
Number of rollouts total     0
Train Time (s)               148.12441439228132
(Previous) Eval Time (s)     20.126546126790345
Sample Time (s)              25.439019688405097
Epoch Time (s)               193.68998020747676
Total Train Time (s)         116209.51385966875
Epoch                        619
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:49:46.948921 UTC | [2020_01_11_13_32_55] Iteration #619 | Epoch Duration: 190.2915482521057
2020-01-12 21:49:46.949171 UTC | [2020_01_11_13_32_55] Iteration #619 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3161325
Z variance train             0.007394613
KL Divergence                31.038334
KL Loss                      3.1038334
QF Loss                      1024.1868
VF Loss                      281.59674
Policy Loss                  -1428.7036
Q Predictions Mean           1430.1992
Q Predictions Std            423.80542
Q Predictions Max            1697.0182
Q Predictions Min            -445.56763
V Predictions Mean           1421.4607
V Predictions Std            422.98062
V Predictions Max            1686.6094
V Predictions Min            -450.35175
Log Pis Mean                 0.84980464
Log Pis Std                  3.4031036
Log Pis Max                  19.563074
Log Pis Min                  -10.094239
Policy mu Mean               0.006214412
Policy mu Std                0.6907114
Policy mu Max                2.8036952
Policy mu Min                -2.4417374
Policy log std Mean          -1.042882
Policy log std Std           0.33328402
Policy log std Max           -0.049040914
Policy log std Min           -2.9996152
Z mean eval                  1.3110795
Z variance eval              0.0069074994
total_rewards                [-1.70114369e+01  1.18077666e+03  6.59123186e+02  5.77565843e+02
 -2.31186835e-01  1.55923795e+03  2.27522067e+03  2.06769088e+03
  2.72969194e+03  2.49368752e+03]
total_rewards_mean           1352.5752033993624
total_rewards_std            970.6103775028454
total_rewards_max            2729.691937623286
total_rewards_min            -17.011436924109567
Number of train steps total  2484000
Number of env steps total    3107000
Number of rollouts total     0
Train Time (s)               143.8460417049937
(Previous) Eval Time (s)     16.727716375142336
Sample Time (s)              26.108038822654635
Epoch Time (s)               186.68179690279067
Total Train Time (s)         116397.43229907285
Epoch                        620
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:52:54.873088 UTC | [2020_01_11_13_32_55] Iteration #620 | Epoch Duration: 187.92376041412354
2020-01-12 21:52:54.873319 UTC | [2020_01_11_13_32_55] Iteration #620 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3127924
Z variance train             0.0069349706
KL Divergence                32.725403
KL Loss                      3.2725403
QF Loss                      1324.6104
VF Loss                      702.288
Policy Loss                  -1447.0249
Q Predictions Mean           1450.8827
Q Predictions Std            393.0298
Q Predictions Max            1688.3691
Q Predictions Min            -406.59756
V Predictions Mean           1449.4705
V Predictions Std            394.77115
V Predictions Max            1690.3901
V Predictions Min            -431.3426
Log Pis Mean                 1.3493986
Log Pis Std                  3.3318112
Log Pis Max                  15.350791
Log Pis Min                  -7.2268143
Policy mu Mean               8.1357546e-05
Policy mu Std                0.6917602
Policy mu Max                4.12731
Policy mu Min                -3.199591
Policy log std Mean          -1.1110412
Policy log std Std           0.31285313
Policy log std Max           -0.17633736
Policy log std Min           -2.7087584
Z mean eval                  1.283599
Z variance eval              0.004959029
total_rewards                [3020.16429884  215.48833551 4271.85370074 3944.85803352  866.12298629
 1619.42472701   15.81764706 4062.68432337 4293.10993403 4099.28122779]
total_rewards_mean           2640.8805214160866
total_rewards_std            1683.7228497968258
total_rewards_max            4293.109934028724
total_rewards_min            15.817647059912549
Number of train steps total  2488000
Number of env steps total    3112000
Number of rollouts total     0
Train Time (s)               139.09232390392572
(Previous) Eval Time (s)     17.96932383487001
Sample Time (s)              24.38364048115909
Epoch Time (s)               181.44528821995482
Total Train Time (s)         116582.41176248342
Epoch                        621
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:55:59.857865 UTC | [2020_01_11_13_32_55] Iteration #621 | Epoch Duration: 184.98440885543823
2020-01-12 21:55:59.858043 UTC | [2020_01_11_13_32_55] Iteration #621 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2834551
Z variance train             0.004966046
KL Divergence                33.25982
KL Loss                      3.3259819
QF Loss                      1604.2528
VF Loss                      407.34512
Policy Loss                  -1453.1309
Q Predictions Mean           1454.853
Q Predictions Std            359.1142
Q Predictions Max            1672.4169
Q Predictions Min            -509.62076
V Predictions Mean           1449.5203
V Predictions Std            358.49142
V Predictions Max            1676.85
V Predictions Min            -512.85175
Log Pis Mean                 1.5335072
Log Pis Std                  3.487118
Log Pis Max                  21.716637
Log Pis Min                  -7.6227803
Policy mu Mean               0.017847307
Policy mu Std                0.72261655
Policy mu Max                3.3935304
Policy mu Min                -2.6135867
Policy log std Mean          -1.0906334
Policy log std Std           0.35167804
Policy log std Max           0.17060804
Policy log std Min           -3.8809557
Z mean eval                  1.3384527
Z variance eval              0.008586361
total_rewards                [3812.67992494 4216.95670337 1350.89071026 1365.14756986 4638.24751314
 4342.87345911 4393.88243611 1918.08927942 1418.86327057 3991.50565542]
total_rewards_mean           3144.913652220107
total_rewards_std            1356.7393429274753
total_rewards_max            4638.2475131361325
total_rewards_min            1350.890710264543
Number of train steps total  2492000
Number of env steps total    3117000
Number of rollouts total     0
Train Time (s)               140.03114363877103
(Previous) Eval Time (s)     21.508139809127897
Sample Time (s)              24.64352112589404
Epoch Time (s)               186.18280457379296
Total Train Time (s)         116774.43626206182
Epoch                        622
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:59:11.889042 UTC | [2020_01_11_13_32_55] Iteration #622 | Epoch Duration: 192.0308380126953
2020-01-12 21:59:11.889395 UTC | [2020_01_11_13_32_55] Iteration #622 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3396139
Z variance train             0.008586971
KL Divergence                31.917948
KL Loss                      3.1917949
QF Loss                      2295.063
VF Loss                      1006.8231
Policy Loss                  -1469.9741
Q Predictions Mean           1466.1982
Q Predictions Std            362.66226
Q Predictions Max            1717.1608
Q Predictions Min            -310.60468
V Predictions Mean           1468.4617
V Predictions Std            349.1883
V Predictions Max            1694.6454
V Predictions Min            -299.19388
Log Pis Mean                 1.170567
Log Pis Std                  3.8096762
Log Pis Max                  30.149677
Log Pis Min                  -8.597348
Policy mu Mean               0.00076371524
Policy mu Std                0.67388797
Policy mu Max                3.1354263
Policy mu Min                -3.031506
Policy log std Mean          -1.087264
Policy log std Std           0.31853068
Policy log std Max           -0.08110702
Policy log std Min           -2.8375444
Z mean eval                  1.3487073
Z variance eval              0.0059704394
total_rewards                [4373.92900282  407.07481548 2014.96921741 1431.99145948  193.89872795
 4198.43014302 1552.96466278  189.21163284 2015.60072112 1966.75964489]
total_rewards_mean           1834.4830027796338
total_rewards_std            1407.0212818397583
total_rewards_max            4373.929002817797
total_rewards_min            189.2116328404988
Number of train steps total  2496000
Number of env steps total    3122000
Number of rollouts total     0
Train Time (s)               148.95890087494627
(Previous) Eval Time (s)     27.355810530949384
Sample Time (s)              24.66618017386645
Epoch Time (s)               200.9808915797621
Total Train Time (s)         116964.02097558696
Epoch                        623
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:02:21.479933 UTC | [2020_01_11_13_32_55] Iteration #623 | Epoch Duration: 189.59029579162598
2020-01-12 22:02:21.480184 UTC | [2020_01_11_13_32_55] Iteration #623 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3499937
Z variance train             0.005966629
KL Divergence                32.66148
KL Loss                      3.266148
QF Loss                      1135.8157
VF Loss                      324.70312
Policy Loss                  -1467.3818
Q Predictions Mean           1467.6641
Q Predictions Std            360.36823
Q Predictions Max            1707.6284
Q Predictions Min            -327.7092
V Predictions Mean           1465.4072
V Predictions Std            352.80188
V Predictions Max            1692.8206
V Predictions Min            -343.34485
Log Pis Mean                 1.3831669
Log Pis Std                  3.427719
Log Pis Max                  14.958692
Log Pis Min                  -9.217561
Policy mu Mean               0.029035198
Policy mu Std                0.7080885
Policy mu Max                3.7845535
Policy mu Min                -3.16651
Policy log std Mean          -1.0833647
Policy log std Std           0.3198094
Policy log std Max           -0.07036424
Policy log std Min           -2.518693
Z mean eval                  1.3145835
Z variance eval              0.009194317
total_rewards                [1317.30901263 4245.93994033 4205.22930074 1743.22006011 2880.98970234
 4221.61438372 4313.67309224 4188.07105045   15.90693275  739.86464335]
total_rewards_mean           2787.1818118668807
total_rewards_std            1600.6171059515236
total_rewards_max            4313.673092242603
total_rewards_min            15.906932745170222
Number of train steps total  2500000
Number of env steps total    3127000
Number of rollouts total     0
Train Time (s)               147.5156404338777
(Previous) Eval Time (s)     15.964823058340698
Sample Time (s)              25.57040261430666
Epoch Time (s)               189.05086610652506
Total Train Time (s)         117160.89002517564
Epoch                        624
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:05:38.355093 UTC | [2020_01_11_13_32_55] Iteration #624 | Epoch Duration: 196.87476181983948
2020-01-12 22:05:38.355313 UTC | [2020_01_11_13_32_55] Iteration #624 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3116382
Z variance train             0.00923972
KL Divergence                31.70636
KL Loss                      3.170636
QF Loss                      924.04364
VF Loss                      342.0868
Policy Loss                  -1449.0255
Q Predictions Mean           1450.861
Q Predictions Std            351.62128
Q Predictions Max            1667.3595
Q Predictions Min            -302.9692
V Predictions Mean           1444.9949
V Predictions Std            350.14035
V Predictions Max            1671.8798
V Predictions Min            -294.02417
Log Pis Mean                 1.4217187
Log Pis Std                  4.26733
Log Pis Max                  45.4629
Log Pis Min                  -7.96099
Policy mu Mean               0.051746078
Policy mu Std                0.77241766
Policy mu Max                8.221189
Policy mu Min                -3.585563
Policy log std Mean          -1.0562191
Policy log std Std           0.31613815
Policy log std Max           1.0316991
Policy log std Min           -2.6126323
Z mean eval                  1.3058778
Z variance eval              0.014606583
total_rewards                [1745.47331251  465.07808714 1319.37977017 2465.35211481 4376.82759957
 1159.81612262 3995.28205467 3009.95164897 4312.78101075  512.1376712 ]
total_rewards_mean           2336.2079392414516
total_rewards_std            1445.3120537478487
total_rewards_max            4376.827599568819
total_rewards_min            465.0780871412529
Number of train steps total  2504000
Number of env steps total    3132000
Number of rollouts total     0
Train Time (s)               146.88391769304872
(Previous) Eval Time (s)     23.788332608062774
Sample Time (s)              25.494288516696543
Epoch Time (s)               196.16653881780803
Total Train Time (s)         117352.89221119182
Epoch                        625
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:08:50.364751 UTC | [2020_01_11_13_32_55] Iteration #625 | Epoch Duration: 192.0092577934265
2020-01-12 22:08:50.365105 UTC | [2020_01_11_13_32_55] Iteration #625 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3043553
Z variance train             0.014676943
KL Divergence                30.725971
KL Loss                      3.0725973
QF Loss                      1158.4951
VF Loss                      1965.6132
Policy Loss                  -1421.0557
Q Predictions Mean           1424.8383
Q Predictions Std            439.40424
Q Predictions Max            1720.2789
Q Predictions Min            -440.4299
V Predictions Mean           1426.2898
V Predictions Std            437.19412
V Predictions Max            1731.7178
V Predictions Min            -454.2397
Log Pis Mean                 1.1953087
Log Pis Std                  3.5891385
Log Pis Max                  15.828857
Log Pis Min                  -9.457695
Policy mu Mean               0.044870757
Policy mu Std                0.6979921
Policy mu Max                3.7505207
Policy mu Min                -2.5796285
Policy log std Mean          -1.0878785
Policy log std Std           0.3239234
Policy log std Max           -0.19558126
Policy log std Min           -2.6632771
Z mean eval                  1.3386178
Z variance eval              0.024777755
total_rewards                [4082.80501201 2883.46728703 4522.95922854 4307.5919006  4106.02894467
 4313.97373917 4382.17736719 1449.80205674 4236.66718626 2428.66188052]
total_rewards_mean           3671.4134602718395
total_rewards_std            991.2827819975222
total_rewards_max            4522.959228537819
total_rewards_min            1449.8020567387066
Number of train steps total  2508000
Number of env steps total    3137000
Number of rollouts total     0
Train Time (s)               146.3386409408413
(Previous) Eval Time (s)     19.63067730795592
Sample Time (s)              27.323229564353824
Epoch Time (s)               193.29254781315103
Total Train Time (s)         117557.06372001581
Epoch                        626
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:12:14.541592 UTC | [2020_01_11_13_32_55] Iteration #626 | Epoch Duration: 204.17629408836365
2020-01-12 22:12:14.541813 UTC | [2020_01_11_13_32_55] Iteration #626 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3338121
Z variance train             0.024439156
KL Divergence                29.490013
KL Loss                      2.9490013
QF Loss                      997.8119
VF Loss                      221.26553
Policy Loss                  -1459.2004
Q Predictions Mean           1466.7358
Q Predictions Std            359.15228
Q Predictions Max            1688.0181
Q Predictions Min            -533.21826
V Predictions Mean           1462.0181
V Predictions Std            359.20392
V Predictions Max            1685.7811
V Predictions Min            -545.3225
Log Pis Mean                 1.1024799
Log Pis Std                  3.0949275
Log Pis Max                  12.889168
Log Pis Min                  -7.374448
Policy mu Mean               0.06350591
Policy mu Std                0.6583355
Policy mu Max                3.132033
Policy mu Min                -2.6998653
Policy log std Mean          -1.1404803
Policy log std Std           0.31483096
Policy log std Max           -0.1426866
Policy log std Min           -2.5217881
Z mean eval                  1.345836
Z variance eval              0.006188984
total_rewards                [4286.18789347 4574.71863259 4380.99658593 3198.64881662  495.35567472
  118.19040934 3381.6623112  2075.20463583  364.95798872  513.09346513]
total_rewards_mean           2338.9016413528057
total_rewards_std            1744.0542826001379
total_rewards_max            4574.718632589647
total_rewards_min            118.1904093351955
Number of train steps total  2512000
Number of env steps total    3142000
Number of rollouts total     0
Train Time (s)               138.884967753198
(Previous) Eval Time (s)     30.51405082596466
Sample Time (s)              26.49332190863788
Epoch Time (s)               195.89234048780054
Total Train Time (s)         117743.99627485592
Epoch                        627
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:15:21.478518 UTC | [2020_01_11_13_32_55] Iteration #627 | Epoch Duration: 186.9365348815918
2020-01-12 22:15:21.478826 UTC | [2020_01_11_13_32_55] Iteration #627 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3456327
Z variance train             0.006182025
KL Divergence                31.893208
KL Loss                      3.1893208
QF Loss                      2396.2666
VF Loss                      519.2546
Policy Loss                  -1466.6187
Q Predictions Mean           1463.5969
Q Predictions Std            370.41904
Q Predictions Max            1692.9763
Q Predictions Min            -480.72824
V Predictions Mean           1464.73
V Predictions Std            352.91656
V Predictions Max            1694.6792
V Predictions Min            -471.36145
Log Pis Mean                 1.2240652
Log Pis Std                  3.4270277
Log Pis Max                  15.154289
Log Pis Min                  -8.06859
Policy mu Mean               0.009900851
Policy mu Std                0.69710577
Policy mu Max                3.0207958
Policy mu Min                -2.5030766
Policy log std Mean          -1.0715207
Policy log std Std           0.32613784
Policy log std Max           0.11316216
Policy log std Min           -2.9197078
Z mean eval                  1.3121406
Z variance eval              0.005471087
total_rewards                [ 932.01200808 3620.94867848  446.57481943 4192.80406328 1081.22086913
 4268.85988574 2294.76838656 4285.03234079 1078.95712942 3050.7416071 ]
total_rewards_mean           2525.1919788018686
total_rewards_std            1465.7368673017036
total_rewards_max            4285.0323407938995
total_rewards_min            446.57481943212986
Number of train steps total  2516000
Number of env steps total    3147000
Number of rollouts total     0
Train Time (s)               138.2460694387555
(Previous) Eval Time (s)     21.557802428025752
Sample Time (s)              24.76365659199655
Epoch Time (s)               184.56752845877782
Total Train Time (s)         117930.83488545241
Epoch                        628
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:18:28.323015 UTC | [2020_01_11_13_32_55] Iteration #628 | Epoch Duration: 186.84397506713867
2020-01-12 22:18:28.323219 UTC | [2020_01_11_13_32_55] Iteration #628 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3135792
Z variance train             0.00549737
KL Divergence                33.208416
KL Loss                      3.3208416
QF Loss                      1984.8444
VF Loss                      314.52322
Policy Loss                  -1467.3293
Q Predictions Mean           1468.8661
Q Predictions Std            400.8315
Q Predictions Max            1712.6565
Q Predictions Min            -356.37045
V Predictions Mean           1459.9941
V Predictions Std            394.1963
V Predictions Max            1697.4745
V Predictions Min            -346.68512
Log Pis Mean                 0.9838437
Log Pis Std                  4.111683
Log Pis Max                  40.1213
Log Pis Min                  -10.557442
Policy mu Mean               0.031246237
Policy mu Std                0.72724867
Policy mu Max                3.0341978
Policy mu Min                -5.3218975
Policy log std Mean          -1.0418622
Policy log std Std           0.33882573
Policy log std Max           0.20075464
Policy log std Min           -3.6563506
Z mean eval                  1.2779063
Z variance eval              0.009245712
total_rewards                [ 633.65095467 3295.29775321 4120.60189461 2798.77531308 4423.23338732
 2625.32135282   18.51538451 4019.9963743  4014.72717452 4387.86105504]
total_rewards_mean           3033.7980644064532
total_rewards_std            1484.0173679200147
total_rewards_max            4423.233387324396
total_rewards_min            18.51538450976731
Number of train steps total  2520000
Number of env steps total    3152000
Number of rollouts total     0
Train Time (s)               143.76158241182566
(Previous) Eval Time (s)     23.833884686697274
Sample Time (s)              24.940954278223217
Epoch Time (s)               192.53642137674615
Total Train Time (s)         118124.85329655278
Epoch                        629
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:21:42.347417 UTC | [2020_01_11_13_32_55] Iteration #629 | Epoch Duration: 194.0240547657013
2020-01-12 22:21:42.347629 UTC | [2020_01_11_13_32_55] Iteration #629 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.277876
Z variance train             0.00924149
KL Divergence                31.632675
KL Loss                      3.1632676
QF Loss                      2240.9688
VF Loss                      359.05884
Policy Loss                  -1458.9602
Q Predictions Mean           1463.0952
Q Predictions Std            322.29324
Q Predictions Max            1720.9595
Q Predictions Min            -530.9488
V Predictions Mean           1461.227
V Predictions Std            318.75043
V Predictions Max            1686.3934
V Predictions Min            -521.75433
Log Pis Mean                 1.42936
Log Pis Std                  3.293348
Log Pis Max                  13.797437
Log Pis Min                  -7.544045
Policy mu Mean               0.05293578
Policy mu Std                0.7336593
Policy mu Max                2.8288033
Policy mu Min                -2.7677152
Policy log std Mean          -1.0773346
Policy log std Std           0.31776538
Policy log std Max           0.1818471
Policy log std Min           -2.8001614
Z mean eval                  1.3083779
Z variance eval              0.013461749
total_rewards                [  40.28911199 3196.97899497  890.82594522 1148.1651146   512.91186532
 1437.02140056 4416.6329816  4365.91992711 4198.67670676 1949.49230231]
total_rewards_mean           2215.6914350455295
total_rewards_std            1598.9585881006294
total_rewards_max            4416.632981599298
total_rewards_min            40.289111993613766
Number of train steps total  2524000
Number of env steps total    3157000
Number of rollouts total     0
Train Time (s)               147.6955849523656
(Previous) Eval Time (s)     25.321193878073245
Sample Time (s)              26.688946726731956
Epoch Time (s)               199.7057255571708
Total Train Time (s)         118319.34371234244
Epoch                        630
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:24:56.844458 UTC | [2020_01_11_13_32_55] Iteration #630 | Epoch Duration: 194.49667525291443
2020-01-12 22:24:56.844738 UTC | [2020_01_11_13_32_55] Iteration #630 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3084189
Z variance train             0.013435635
KL Divergence                31.590109
KL Loss                      3.159011
QF Loss                      1567.4067
VF Loss                      548.0286
Policy Loss                  -1427.1085
Q Predictions Mean           1430.6326
Q Predictions Std            440.68262
Q Predictions Max            1682.4484
Q Predictions Min            -558.2311
V Predictions Mean           1424.395
V Predictions Std            434.28104
V Predictions Max            1668.2942
V Predictions Min            -500.9666
Log Pis Mean                 1.1260216
Log Pis Std                  3.4837444
Log Pis Max                  13.441987
Log Pis Min                  -8.698908
Policy mu Mean               0.021961259
Policy mu Std                0.7004074
Policy mu Max                3.3212373
Policy mu Min                -2.7814991
Policy log std Mean          -1.0930977
Policy log std Std           0.3267379
Policy log std Max           0.083022356
Policy log std Min           -2.584591
Z mean eval                  1.284993
Z variance eval              0.009701972
total_rewards                [ -34.26618725 4105.63721196 4371.65480226  730.81150573 1431.15034252
 3248.23021382 4347.91434408 2372.87874272 2587.47468506 1655.36136099]
total_rewards_mean           2481.6847021892495
total_rewards_std            1465.7640540471089
total_rewards_max            4371.654802263716
total_rewards_min            -34.26618725364243
Number of train steps total  2528000
Number of env steps total    3162000
Number of rollouts total     0
Train Time (s)               147.0035262675956
(Previous) Eval Time (s)     20.111722948029637
Sample Time (s)              25.02803723560646
Epoch Time (s)               192.1432864512317
Total Train Time (s)         118512.6904546693
Epoch                        631
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:28:10.198607 UTC | [2020_01_11_13_32_55] Iteration #631 | Epoch Duration: 193.35369610786438
2020-01-12 22:28:10.198881 UTC | [2020_01_11_13_32_55] Iteration #631 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2857347
Z variance train             0.009689224
KL Divergence                31.277338
KL Loss                      3.127734
QF Loss                      893.0677
VF Loss                      480.87787
Policy Loss                  -1502.2178
Q Predictions Mean           1501.6597
Q Predictions Std            266.3216
Q Predictions Max            1711.8236
Q Predictions Min            -302.11624
V Predictions Mean           1499.6683
V Predictions Std            244.8023
V Predictions Max            1669.272
V Predictions Min            -305.46646
Log Pis Mean                 1.7368522
Log Pis Std                  3.5873628
Log Pis Max                  20.479486
Log Pis Min                  -6.7038517
Policy mu Mean               0.036890134
Policy mu Std                0.7236102
Policy mu Max                2.5286176
Policy mu Min                -3.1346433
Policy log std Mean          -1.1298528
Policy log std Std           0.3129501
Policy log std Max           -0.06767595
Policy log std Min           -3.491325
Z mean eval                  1.3651764
Z variance eval              0.004009151
total_rewards                [2517.94590079  299.789947   2263.36606123  257.64117154 4631.19854415
 2181.21665807 3440.75234734 1587.23821619 4258.70332339 2004.27028946]
total_rewards_mean           2344.212245916439
total_rewards_std            1392.2385305068515
total_rewards_max            4631.198544145628
total_rewards_min            257.6411715381412
Number of train steps total  2532000
Number of env steps total    3167000
Number of rollouts total     0
Train Time (s)               149.19847542094067
(Previous) Eval Time (s)     21.321762902196497
Sample Time (s)              25.23310716357082
Epoch Time (s)               195.75334548670799
Total Train Time (s)         118705.77302855067
Epoch                        632
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:31:23.284013 UTC | [2020_01_11_13_32_55] Iteration #632 | Epoch Duration: 193.0850055217743
2020-01-12 22:31:23.284134 UTC | [2020_01_11_13_32_55] Iteration #632 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3640317
Z variance train             0.0039996053
KL Divergence                34.550922
KL Loss                      3.4550922
QF Loss                      1732.6274
VF Loss                      756.0823
Policy Loss                  -1488.2083
Q Predictions Mean           1488.5304
Q Predictions Std            322.8371
Q Predictions Max            1694.3473
Q Predictions Min            -317.5417
V Predictions Mean           1479.6956
V Predictions Std            311.8972
V Predictions Max            1704.0856
V Predictions Min            -302.40912
Log Pis Mean                 1.7643086
Log Pis Std                  3.568079
Log Pis Max                  21.083855
Log Pis Min                  -5.731648
Policy mu Mean               0.010791516
Policy mu Std                0.7413891
Policy mu Max                4.0003386
Policy mu Min                -2.6101248
Policy log std Mean          -1.1135458
Policy log std Std           0.3640244
Policy log std Max           -0.24554539
Policy log std Min           -3.183803
Z mean eval                  1.3425709
Z variance eval              0.0027296504
total_rewards                [2283.99715476  596.1613987   486.0161992  4211.41955139 4406.31667452
 4034.38853179 4184.17642945  162.23835227 1926.37104964 4344.46839192]
total_rewards_mean           2663.5553733643333
total_rewards_std            1685.5244791105692
total_rewards_max            4406.3166745217595
total_rewards_min            162.23835226669425
Number of train steps total  2536000
Number of env steps total    3172000
Number of rollouts total     0
Train Time (s)               146.5102063328959
(Previous) Eval Time (s)     18.653065875638276
Sample Time (s)              23.171307295095176
Epoch Time (s)               188.33457950362936
Total Train Time (s)         118897.04878788115
Epoch                        633
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:34:34.566303 UTC | [2020_01_11_13_32_55] Iteration #633 | Epoch Duration: 191.28206253051758
2020-01-12 22:34:34.566501 UTC | [2020_01_11_13_32_55] Iteration #633 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3414608
Z variance train             0.0027324103
KL Divergence                32.323776
KL Loss                      3.2323778
QF Loss                      1280.86
VF Loss                      1358.7869
Policy Loss                  -1433.4995
Q Predictions Mean           1431.6411
Q Predictions Std            405.1115
Q Predictions Max            1664.9923
Q Predictions Min            -555.4596
V Predictions Mean           1426.0764
V Predictions Std            394.4517
V Predictions Max            1669.1823
V Predictions Min            -531.3268
Log Pis Mean                 1.3581707
Log Pis Std                  4.384939
Log Pis Max                  46.356472
Log Pis Min                  -10.222538
Policy mu Mean               0.020696715
Policy mu Std                0.74770373
Policy mu Max                6.890926
Policy mu Min                -4.3084965
Policy log std Mean          -1.0675824
Policy log std Std           0.34404153
Policy log std Max           1.0517273
Policy log std Min           -3.0777054
Z mean eval                  1.2917886
Z variance eval              0.020662066
total_rewards                [1719.06354756 1219.93026551 4184.35371281 4001.72568182 1923.34618574
 1487.96652444 3350.43856687 2268.48028481 4197.90897282 1828.20171977]
total_rewards_mean           2618.141546216027
total_rewards_std            1125.5616283779084
total_rewards_max            4197.908972820242
total_rewards_min            1219.9302655061724
Number of train steps total  2540000
Number of env steps total    3177000
Number of rollouts total     0
Train Time (s)               139.12021252699196
(Previous) Eval Time (s)     21.600207141134888
Sample Time (s)              24.963365333154798
Epoch Time (s)               185.68378500128165
Total Train Time (s)         119084.83484322159
Epoch                        634
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:37:42.358237 UTC | [2020_01_11_13_32_55] Iteration #634 | Epoch Duration: 187.79159927368164
2020-01-12 22:37:42.358420 UTC | [2020_01_11_13_32_55] Iteration #634 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2853545
Z variance train             0.019622834
KL Divergence                31.079811
KL Loss                      3.1079812
QF Loss                      1532.8201
VF Loss                      198.68042
Policy Loss                  -1464.4026
Q Predictions Mean           1471.591
Q Predictions Std            352.15765
Q Predictions Max            1713.6268
Q Predictions Min            -240.48961
V Predictions Mean           1460.6771
V Predictions Std            352.74722
V Predictions Max            1678.6901
V Predictions Min            -257.39734
Log Pis Mean                 1.0608968
Log Pis Std                  3.4283814
Log Pis Max                  18.232286
Log Pis Min                  -8.81456
Policy mu Mean               0.013264484
Policy mu Std                0.69553804
Policy mu Max                2.906286
Policy mu Min                -2.8609102
Policy log std Mean          -1.0478883
Policy log std Std           0.3059392
Policy log std Max           -0.17197055
Policy log std Min           -3.0152922
Z mean eval                  1.3166243
Z variance eval              0.0069407336
total_rewards                [4289.47382869 4308.00619309 1202.56932676   29.28189132  661.13953666
  819.01866916   58.4739986  3921.29136412  768.28705896  343.46264923]
total_rewards_mean           1640.1004516590233
total_rewards_std            1694.1756821789518
total_rewards_max            4308.006193091005
total_rewards_min            29.281891317001374
Number of train steps total  2544000
Number of env steps total    3182000
Number of rollouts total     0
Train Time (s)               138.85623017698526
(Previous) Eval Time (s)     23.707709912676364
Sample Time (s)              25.10896440502256
Epoch Time (s)               187.6729044946842
Total Train Time (s)         119263.03565163072
Epoch                        635
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:40:40.565288 UTC | [2020_01_11_13_32_55] Iteration #635 | Epoch Duration: 178.2067346572876
2020-01-12 22:40:40.565476 UTC | [2020_01_11_13_32_55] Iteration #635 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3159968
Z variance train             0.006938615
KL Divergence                31.182404
KL Loss                      3.1182404
QF Loss                      2181.4233
VF Loss                      1072.189
Policy Loss                  -1443.293
Q Predictions Mean           1445.4626
Q Predictions Std            403.27258
Q Predictions Max            1699.7251
Q Predictions Min            -467.88455
V Predictions Mean           1439.9498
V Predictions Std            395.29266
V Predictions Max            1688.1257
V Predictions Min            -459.7964
Log Pis Mean                 1.1998382
Log Pis Std                  3.5176044
Log Pis Max                  18.269905
Log Pis Min                  -7.5146017
Policy mu Mean               0.04851
Policy mu Std                0.70531064
Policy mu Max                2.7970662
Policy mu Min                -3.8053184
Policy log std Mean          -1.1039329
Policy log std Std           0.37829074
Policy log std Max           1.0838509
Policy log std Min           -3.0002725
Z mean eval                  1.3120531
Z variance eval              0.0055315965
total_rewards                [1234.42067264 2613.1290985  4345.75785672  486.21343443 4316.80276976
 1317.78230216 3040.87282374  358.01160103 4426.50948232 4225.47259172]
total_rewards_mean           2636.497263302426
total_rewards_std            1586.1303776018844
total_rewards_max            4426.5094823241225
total_rewards_min            358.01160103231416
Number of train steps total  2548000
Number of env steps total    3187000
Number of rollouts total     0
Train Time (s)               147.07934139994904
(Previous) Eval Time (s)     14.241142468061298
Sample Time (s)              24.323223064653575
Epoch Time (s)               185.64370693266392
Total Train Time (s)         119459.88265436562
Epoch                        636
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:43:57.418632 UTC | [2020_01_11_13_32_55] Iteration #636 | Epoch Duration: 196.85300946235657
2020-01-12 22:43:57.418877 UTC | [2020_01_11_13_32_55] Iteration #636 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3116025
Z variance train             0.005519779
KL Divergence                32.11907
KL Loss                      3.211907
QF Loss                      1425.8884
VF Loss                      526.8953
Policy Loss                  -1462.2065
Q Predictions Mean           1465.5526
Q Predictions Std            396.36157
Q Predictions Max            1711.2871
Q Predictions Min            -545.3829
V Predictions Mean           1461.1624
V Predictions Std            387.76733
V Predictions Max            1681.0314
V Predictions Min            -564.12415
Log Pis Mean                 1.480904
Log Pis Std                  3.439445
Log Pis Max                  18.602882
Log Pis Min                  -6.73525
Policy mu Mean               0.0567567
Policy mu Std                0.74213207
Policy mu Max                3.707989
Policy mu Min                -2.9190493
Policy log std Mean          -1.0560195
Policy log std Std           0.3033107
Policy log std Max           -0.17859185
Policy log std Min           -2.7622843
Z mean eval                  1.2837979
Z variance eval              0.005166522
total_rewards                [ 424.16275622 3592.26769181 4214.90476305 2706.75737116  595.16709693
 4339.50260601 2176.82832979  316.7043133  3970.42164002 4307.16297003]
total_rewards_mean           2664.387953831009
total_rewards_std            1597.7145535483874
total_rewards_max            4339.502606005865
total_rewards_min            316.70431329983137
Number of train steps total  2552000
Number of env steps total    3192000
Number of rollouts total     0
Train Time (s)               146.12289264285937
(Previous) Eval Time (s)     25.45001460192725
Sample Time (s)              26.320495219435543
Epoch Time (s)               197.89340246422216
Total Train Time (s)         119653.84037031513
Epoch                        637
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:47:11.382561 UTC | [2020_01_11_13_32_55] Iteration #637 | Epoch Duration: 193.96353483200073
2020-01-12 22:47:11.382778 UTC | [2020_01_11_13_32_55] Iteration #637 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2810087
Z variance train             0.005185763
KL Divergence                31.064636
KL Loss                      3.1064637
QF Loss                      3668.9546
VF Loss                      1392.6488
Policy Loss                  -1392.1309
Q Predictions Mean           1395.9568
Q Predictions Std            467.56152
Q Predictions Max            1694.7628
Q Predictions Min            -478.57874
V Predictions Mean           1380.1487
V Predictions Std            464.61172
V Predictions Max            1667.4417
V Predictions Min            -473.76566
Log Pis Mean                 0.8978098
Log Pis Std                  3.2593415
Log Pis Max                  12.369123
Log Pis Min                  -5.907222
Policy mu Mean               0.009928702
Policy mu Std                0.6840294
Policy mu Max                2.8728724
Policy mu Min                -2.5627403
Policy log std Mean          -1.082468
Policy log std Std           0.34896374
Policy log std Max           0.11573565
Policy log std Min           -2.684065
Z mean eval                  1.3840076
Z variance eval              0.005087833
total_rewards                [ 817.43132993  167.53585555  146.54185842 4260.63585847 4353.69193552
  777.06753953  377.09596767  323.63721551 2466.60800321  174.84213829]
total_rewards_mean           1386.508770210384
total_rewards_std            1598.962902615496
total_rewards_max            4353.691935516546
total_rewards_min            146.54185842278343
Number of train steps total  2556000
Number of env steps total    3197000
Number of rollouts total     0
Train Time (s)               145.93290291214362
(Previous) Eval Time (s)     21.519628970418125
Sample Time (s)              24.251957814209163
Epoch Time (s)               191.7044896967709
Total Train Time (s)         119838.28474042378
Epoch                        638
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:50:15.832974 UTC | [2020_01_11_13_32_55] Iteration #638 | Epoch Duration: 184.45005917549133
2020-01-12 22:50:15.833166 UTC | [2020_01_11_13_32_55] Iteration #638 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.384773
Z variance train             0.0050921
KL Divergence                31.879196
KL Loss                      3.1879196
QF Loss                      1220.9729
VF Loss                      481.60083
Policy Loss                  -1486.3634
Q Predictions Mean           1487.0516
Q Predictions Std            322.383
Q Predictions Max            1720.259
Q Predictions Min            -519.2889
V Predictions Mean           1485.3782
V Predictions Std            314.2034
V Predictions Max            1707.5354
V Predictions Min            -496.68314
Log Pis Mean                 1.3728076
Log Pis Std                  3.559244
Log Pis Max                  18.405262
Log Pis Min                  -6.255453
Policy mu Mean               0.04527396
Policy mu Std                0.7255131
Policy mu Max                4.893825
Policy mu Min                -2.486268
Policy log std Mean          -1.0903621
Policy log std Std           0.33045295
Policy log std Max           0.22721446
Policy log std Min           -3.1706007
Z mean eval                  1.29401
Z variance eval              0.007404484
total_rewards                [ 191.53634299 4602.0862737  1580.07296157 2548.12568025 3406.21708344
 4172.32253257  656.66827423 4428.04589851 1724.49876393 3770.66967215]
total_rewards_mean           2708.02434833419
total_rewards_std            1520.2874786041812
total_rewards_max            4602.086273698827
total_rewards_min            191.5363429930602
Number of train steps total  2560000
Number of env steps total    3202000
Number of rollouts total     0
Train Time (s)               147.82916617719457
(Previous) Eval Time (s)     14.264874038286507
Sample Time (s)              23.876433473546058
Epoch Time (s)               185.97047368902713
Total Train Time (s)         120032.4792719204
Epoch                        639
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:53:30.034590 UTC | [2020_01_11_13_32_55] Iteration #639 | Epoch Duration: 194.20126819610596
2020-01-12 22:53:30.034901 UTC | [2020_01_11_13_32_55] Iteration #639 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2941843
Z variance train             0.0074312957
KL Divergence                30.625103
KL Loss                      3.0625103
QF Loss                      1038.6987
VF Loss                      308.8049
Policy Loss                  -1430.6144
Q Predictions Mean           1433.915
Q Predictions Std            425.10794
Q Predictions Max            1707.613
Q Predictions Min            -475.02902
V Predictions Mean           1434.6703
V Predictions Std            421.5561
V Predictions Max            1700.5387
V Predictions Min            -470.7115
Log Pis Mean                 1.7020607
Log Pis Std                  3.3670928
Log Pis Max                  20.02185
Log Pis Min                  -8.501377
Policy mu Mean               0.03358221
Policy mu Std                0.7181484
Policy mu Max                3.069573
Policy mu Min                -2.6962264
Policy log std Mean          -1.1127558
Policy log std Std           0.34592837
Policy log std Max           -0.08456838
Policy log std Min           -2.954805
Z mean eval                  1.2545447
Z variance eval              0.011012588
total_rewards                [ 551.45137285  913.20690488 2133.29078996 1774.80406263 1545.33889505
 4290.59966504 4306.4333397  2735.92343922 4237.53584513 1472.78927003]
total_rewards_mean           2396.137358450183
total_rewards_std            1355.6527339573227
total_rewards_max            4306.433339695064
total_rewards_min            551.4513728511206
Number of train steps total  2564000
Number of env steps total    3207000
Number of rollouts total     0
Train Time (s)               143.21786680119112
(Previous) Eval Time (s)     22.495223726145923
Sample Time (s)              26.372604911681265
Epoch Time (s)               192.0856954390183
Total Train Time (s)         120221.76644726004
Epoch                        640
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:56:39.327408 UTC | [2020_01_11_13_32_55] Iteration #640 | Epoch Duration: 189.29234266281128
2020-01-12 22:56:39.327594 UTC | [2020_01_11_13_32_55] Iteration #640 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2524108
Z variance train             0.011006167
KL Divergence                29.91137
KL Loss                      2.991137
QF Loss                      4913.847
VF Loss                      204.93709
Policy Loss                  -1484.142
Q Predictions Mean           1486.6384
Q Predictions Std            304.1304
Q Predictions Max            1717.9276
Q Predictions Min            -496.22488
V Predictions Mean           1482.7207
V Predictions Std            302.6091
V Predictions Max            1703.3967
V Predictions Min            -497.88214
Log Pis Mean                 1.576411
Log Pis Std                  3.0284066
Log Pis Max                  11.067749
Log Pis Min                  -8.759978
Policy mu Mean               0.051657617
Policy mu Std                0.732544
Policy mu Max                3.0938873
Policy mu Min                -2.843573
Policy log std Mean          -1.0745953
Policy log std Std           0.3138211
Policy log std Max           -0.15392494
Policy log std Min           -2.5417616
Z mean eval                  1.342266
Z variance eval              0.009387588
total_rewards                [3653.79921762 4335.75273213  493.24704323  925.22977226 1429.37029059
 2248.25072199  116.72895743  880.92246139 4212.17698885 4213.37540134]
total_rewards_mean           2250.8853586823016
total_rewards_std            1611.3920162920012
total_rewards_max            4335.752732131524
total_rewards_min            116.72895742913423
Number of train steps total  2568000
Number of env steps total    3212000
Number of rollouts total     0
Train Time (s)               139.45873827813193
(Previous) Eval Time (s)     19.70148430718109
Sample Time (s)              25.12089106813073
Epoch Time (s)               184.28111365344375
Total Train Time (s)         120405.07455888297
Epoch                        641
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:59:42.641636 UTC | [2020_01_11_13_32_55] Iteration #641 | Epoch Duration: 183.31391191482544
2020-01-12 22:59:42.641812 UTC | [2020_01_11_13_32_55] Iteration #641 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3443265
Z variance train             0.009372855
KL Divergence                30.054804
KL Loss                      3.0054805
QF Loss                      2185.5547
VF Loss                      373.84442
Policy Loss                  -1436.3444
Q Predictions Mean           1438.0891
Q Predictions Std            413.57266
Q Predictions Max            1687.2284
Q Predictions Min            -519.6081
V Predictions Mean           1434.7053
V Predictions Std            410.55032
V Predictions Max            1674.4442
V Predictions Min            -498.87366
Log Pis Mean                 1.2476474
Log Pis Std                  3.617129
Log Pis Max                  17.912617
Log Pis Min                  -7.071455
Policy mu Mean               0.031996462
Policy mu Std                0.7101209
Policy mu Max                3.194345
Policy mu Min                -2.930331
Policy log std Mean          -1.0751415
Policy log std Std           0.31918362
Policy log std Max           0.29605556
Policy log std Min           -2.8234196
Z mean eval                  1.2613182
Z variance eval              0.006506873
total_rewards                [4354.75428236 4481.73671268 4332.5559627  4249.57725608 1361.0763402
  877.72934499 1069.99480566  580.60806527  679.41198345 4129.77362002]
total_rewards_mean           2611.721837341248
total_rewards_std            1711.445304495898
total_rewards_max            4481.73671267854
total_rewards_min            580.6080652728612
Number of train steps total  2572000
Number of env steps total    3217000
Number of rollouts total     0
Train Time (s)               140.7400740487501
(Previous) Eval Time (s)     18.73398470832035
Sample Time (s)              24.401596544776112
Epoch Time (s)               183.87565530184656
Total Train Time (s)         120593.56815918861
Epoch                        642
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:02:51.141599 UTC | [2020_01_11_13_32_55] Iteration #642 | Epoch Duration: 188.49966096878052
2020-01-12 23:02:51.141783 UTC | [2020_01_11_13_32_55] Iteration #642 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2620412
Z variance train             0.006530788
KL Divergence                31.107586
KL Loss                      3.1107585
QF Loss                      689.91956
VF Loss                      164.18921
Policy Loss                  -1471.8046
Q Predictions Mean           1473.0289
Q Predictions Std            355.2156
Q Predictions Max            1698.1964
Q Predictions Min            -519.8651
V Predictions Mean           1473.6212
V Predictions Std            355.07404
V Predictions Max            1698.8387
V Predictions Min            -503.42407
Log Pis Mean                 1.4200087
Log Pis Std                  3.381377
Log Pis Max                  12.680395
Log Pis Min                  -8.166862
Policy mu Mean               0.032275334
Policy mu Std                0.7088027
Policy mu Max                3.000924
Policy mu Min                -2.5182202
Policy log std Mean          -1.1007774
Policy log std Std           0.30104557
Policy log std Max           -0.21877122
Policy log std Min           -2.5131154
Z mean eval                  1.274586
Z variance eval              0.010605372
total_rewards                [4131.12045219 4297.51510995 3699.99495873 4523.91103954  202.11756315
 4417.75849177 4147.62283503 2417.55403405 4088.95921265  497.9615623 ]
total_rewards_mean           3242.4515259356526
total_rewards_std            1553.3172428399935
total_rewards_max            4523.911039544955
total_rewards_min            202.11756314678266
Number of train steps total  2576000
Number of env steps total    3222000
Number of rollouts total     0
Train Time (s)               149.06874144310132
(Previous) Eval Time (s)     23.3576027341187
Sample Time (s)              24.18312967196107
Epoch Time (s)               196.6094738491811
Total Train Time (s)         120797.04837916186
Epoch                        643
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:06:14.628926 UTC | [2020_01_11_13_32_55] Iteration #643 | Epoch Duration: 203.4869785308838
2020-01-12 23:06:14.629198 UTC | [2020_01_11_13_32_55] Iteration #643 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.274245
Z variance train             0.01062313
KL Divergence                30.72669
KL Loss                      3.072669
QF Loss                      1221.3455
VF Loss                      241.63596
Policy Loss                  -1433.1267
Q Predictions Mean           1435.699
Q Predictions Std            414.44345
Q Predictions Max            1688.6029
Q Predictions Min            -494.02057
V Predictions Mean           1431.8097
V Predictions Std            415.26895
V Predictions Max            1680.0923
V Predictions Min            -526.2726
Log Pis Mean                 1.4997748
Log Pis Std                  3.703716
Log Pis Max                  22.854706
Log Pis Min                  -6.126228
Policy mu Mean               0.020292189
Policy mu Std                0.6934456
Policy mu Max                3.2257884
Policy mu Min                -3.0098417
Policy log std Mean          -1.1208069
Policy log std Std           0.31890213
Policy log std Max           0.011371851
Policy log std Min           -3.0924082
Z mean eval                  1.3105608
Z variance eval              0.006022792
total_rewards                [4574.28588495 4094.967752    869.83248223 2147.07010958 3438.06117951
 1771.52718121  733.92678924 4115.31298819 3857.41772821 4305.53049551]
total_rewards_mean           2990.793259063452
total_rewards_std            1395.0345799819731
total_rewards_max            4574.285884954342
total_rewards_min            733.9267892395593
Number of train steps total  2580000
Number of env steps total    3227000
Number of rollouts total     0
Train Time (s)               148.10887818597257
(Previous) Eval Time (s)     30.234742905944586
Sample Time (s)              25.92313156137243
Epoch Time (s)               204.2667526532896
Total Train Time (s)         120997.42497925088
Epoch                        644
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:09:35.011290 UTC | [2020_01_11_13_32_55] Iteration #644 | Epoch Duration: 200.3819396495819
2020-01-12 23:09:35.011480 UTC | [2020_01_11_13_32_55] Iteration #644 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3117965
Z variance train             0.006010156
KL Divergence                33.0645
KL Loss                      3.30645
QF Loss                      1581.1738
VF Loss                      1046.705
Policy Loss                  -1442.1044
Q Predictions Mean           1445.602
Q Predictions Std            407.51492
Q Predictions Max            1689.9895
Q Predictions Min            -391.91293
V Predictions Mean           1444.8069
V Predictions Std            396.9543
V Predictions Max            1696.4885
V Predictions Min            -418.52744
Log Pis Mean                 1.7946697
Log Pis Std                  3.7097125
Log Pis Max                  16.36149
Log Pis Min                  -6.1799846
Policy mu Mean               0.0093944045
Policy mu Std                0.725063
Policy mu Max                3.3798976
Policy mu Min                -2.4173803
Policy log std Mean          -1.1149918
Policy log std Std           0.355218
Policy log std Max           -0.30368614
Policy log std Min           -3.211223
Z mean eval                  1.3418376
Z variance eval              0.013287296
total_rewards                [3843.61897974 4392.95116417  330.24141325  371.11258547  231.32606823
  852.91649678 4651.72004971 2397.969811   2051.65416361 4371.4537869 ]
total_rewards_mean           2349.4964518852894
total_rewards_std            1749.442908866792
total_rewards_max            4651.720049707608
total_rewards_min            231.326068226031
Number of train steps total  2584000
Number of env steps total    3232000
Number of rollouts total     0
Train Time (s)               147.85363017302006
(Previous) Eval Time (s)     26.349491173867136
Sample Time (s)              25.132610322441906
Epoch Time (s)               199.3357316693291
Total Train Time (s)         121190.54462023824
Epoch                        645
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:12:48.138240 UTC | [2020_01_11_13_32_55] Iteration #645 | Epoch Duration: 193.12659883499146
2020-01-12 23:12:48.138558 UTC | [2020_01_11_13_32_55] Iteration #645 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3404907
Z variance train             0.013156509
KL Divergence                31.993544
KL Loss                      3.1993544
QF Loss                      2156.29
VF Loss                      286.99603
Policy Loss                  -1476.9846
Q Predictions Mean           1481.4803
Q Predictions Std            335.82526
Q Predictions Max            1692.8134
Q Predictions Min            -273.04782
V Predictions Mean           1471.8209
V Predictions Std            336.89264
V Predictions Max            1685.7382
V Predictions Min            -278.7633
Log Pis Mean                 1.2820251
Log Pis Std                  3.6760883
Log Pis Max                  25.61813
Log Pis Min                  -7.0015726
Policy mu Mean               0.028919153
Policy mu Std                0.7125474
Policy mu Max                2.793063
Policy mu Min                -3.4902997
Policy log std Mean          -1.103789
Policy log std Std           0.32863393
Policy log std Max           -0.12459469
Policy log std Min           -2.9130812
Z mean eval                  1.306327
Z variance eval              0.009897664
total_rewards                [ 439.33654588 1493.34857317 1469.38815044  794.65130639  672.61471163
 1080.04138675   -6.14774976 2269.6256119   989.54972638 3715.33188912]
total_rewards_mean           1291.7740151889222
total_rewards_std            1003.987828683119
total_rewards_max            3715.3318891202507
total_rewards_min            -6.147749759981625
Number of train steps total  2588000
Number of env steps total    3237000
Number of rollouts total     0
Train Time (s)               147.44259201874956
(Previous) Eval Time (s)     20.139958989806473
Sample Time (s)              25.60469316318631
Epoch Time (s)               193.18724417174235
Total Train Time (s)         121378.33269800711
Epoch                        646
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:15:55.932568 UTC | [2020_01_11_13_32_55] Iteration #646 | Epoch Duration: 187.79382729530334
2020-01-12 23:15:55.932821 UTC | [2020_01_11_13_32_55] Iteration #646 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.306864
Z variance train             0.009905899
KL Divergence                30.727116
KL Loss                      3.0727117
QF Loss                      1549.5242
VF Loss                      404.73734
Policy Loss                  -1376.3988
Q Predictions Mean           1374.0879
Q Predictions Std            511.33377
Q Predictions Max            1705.7578
Q Predictions Min            -487.38898
V Predictions Mean           1373.8953
V Predictions Std            499.52048
V Predictions Max            1694.3822
V Predictions Min            -468.67847
Log Pis Mean                 1.2518916
Log Pis Std                  3.8366523
Log Pis Max                  22.127235
Log Pis Min                  -9.296761
Policy mu Mean               -0.009949643
Policy mu Std                0.7393835
Policy mu Max                8.262305
Policy mu Min                -3.321272
Policy log std Mean          -1.0697076
Policy log std Std           0.3895977
Policy log std Max           1.6310062
Policy log std Min           -3.1192107
Z mean eval                  1.3190305
Z variance eval              0.013344273
total_rewards                [2208.31326579 1015.07884012 4477.21407371 4261.59159239 2114.94521827
 3194.70369031 4295.13395292 3772.13226824  962.21668921 4363.79950625]
total_rewards_mean           3066.5129097210256
total_rewards_std            1319.2238852583662
total_rewards_max            4477.214073708973
total_rewards_min            962.2166892101412
Number of train steps total  2592000
Number of env steps total    3242000
Number of rollouts total     0
Train Time (s)               139.3902437821962
(Previous) Eval Time (s)     14.746200264897197
Sample Time (s)              25.583239801228046
Epoch Time (s)               179.71968384832144
Total Train Time (s)         121571.84601528896
Epoch                        647
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:19:09.452862 UTC | [2020_01_11_13_32_55] Iteration #647 | Epoch Duration: 193.51988768577576
2020-01-12 23:19:09.453137 UTC | [2020_01_11_13_32_55] Iteration #647 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3187164
Z variance train             0.013347027
KL Divergence                31.37223
KL Loss                      3.137223
QF Loss                      1245.1454
VF Loss                      356.666
Policy Loss                  -1436.0309
Q Predictions Mean           1443.2107
Q Predictions Std            436.56717
Q Predictions Max            1702.5454
Q Predictions Min            -515.2498
V Predictions Mean           1443.3455
V Predictions Std            437.79062
V Predictions Max            1703.5242
V Predictions Min            -547.912
Log Pis Mean                 1.4113004
Log Pis Std                  3.8187099
Log Pis Max                  20.024261
Log Pis Min                  -9.5015335
Policy mu Mean               0.042476505
Policy mu Std                0.74142677
Policy mu Max                3.246232
Policy mu Min                -3.2448092
Policy log std Mean          -1.0598803
Policy log std Std           0.35619798
Policy log std Max           -0.021446705
Policy log std Min           -3.0637617
Z mean eval                  1.3643563
Z variance eval              0.0071292906
total_rewards                [4434.55228121  125.28654189 1151.7156414  4637.54939931  803.43013842
 1242.91660466 4455.13783675 1584.29117156    7.76619777 3904.65375073]
total_rewards_mean           2234.7299563702486
total_rewards_std            1799.13976066852
total_rewards_max            4637.549399311677
total_rewards_min            7.766197769540655
Number of train steps total  2596000
Number of env steps total    3247000
Number of rollouts total     0
Train Time (s)               138.91741960402578
(Previous) Eval Time (s)     28.545955516863614
Sample Time (s)              24.322372088674456
Epoch Time (s)               191.78574720956385
Total Train Time (s)         121750.9375315751
Epoch                        648
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:22:08.550586 UTC | [2020_01_11_13_32_55] Iteration #648 | Epoch Duration: 179.09729027748108
2020-01-12 23:22:08.550812 UTC | [2020_01_11_13_32_55] Iteration #648 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.373722
Z variance train             0.007148427
KL Divergence                32.171364
KL Loss                      3.2171364
QF Loss                      7761.1143
VF Loss                      362.1848
Policy Loss                  -1466.1705
Q Predictions Mean           1474.9097
Q Predictions Std            344.8024
Q Predictions Max            1691.5267
Q Predictions Min            -271.75027
V Predictions Mean           1471.9199
V Predictions Std            344.8503
V Predictions Max            1699.9165
V Predictions Min            -280.87933
Log Pis Mean                 1.524061
Log Pis Std                  3.5302575
Log Pis Max                  18.40097
Log Pis Min                  -8.079812
Policy mu Mean               0.050856102
Policy mu Std                0.73050725
Policy mu Max                3.3258648
Policy mu Min                -3.0425966
Policy log std Mean          -1.1012332
Policy log std Std           0.32130212
Policy log std Max           0.30135107
Policy log std Min           -2.9635222
Z mean eval                  1.339494
Z variance eval              0.010562485
total_rewards                [3473.91440803 4112.88449427  990.4433658   426.97391263  546.37821633
 1253.9551497  1140.77127344 4687.73670815 3699.090595   4572.94798898]
total_rewards_mean           2490.509611233756
total_rewards_std            1669.2242353849485
total_rewards_max            4687.736708148983
total_rewards_min            426.97391262674296
Number of train steps total  2600000
Number of env steps total    3252000
Number of rollouts total     0
Train Time (s)               144.72111023496836
(Previous) Eval Time (s)     15.857163495849818
Sample Time (s)              24.655122466385365
Epoch Time (s)               185.23339619720355
Total Train Time (s)         121942.05192827852
Epoch                        649
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:25:19.671377 UTC | [2020_01_11_13_32_55] Iteration #649 | Epoch Duration: 191.12042379379272
2020-01-12 23:25:19.671574 UTC | [2020_01_11_13_32_55] Iteration #649 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3365419
Z variance train             0.010638444
KL Divergence                32.025124
KL Loss                      3.2025125
QF Loss                      1791.5269
VF Loss                      1608.4065
Policy Loss                  -1426.6703
Q Predictions Mean           1428.0095
Q Predictions Std            423.5653
Q Predictions Max            1705.9185
Q Predictions Min            -410.37247
V Predictions Mean           1419.3367
V Predictions Std            412.56635
V Predictions Max            1695.7599
V Predictions Min            -399.42828
Log Pis Mean                 1.1478988
Log Pis Std                  3.3805058
Log Pis Max                  20.055164
Log Pis Min                  -8.539642
Policy mu Mean               0.03189152
Policy mu Std                0.69196844
Policy mu Max                5.5993643
Policy mu Min                -2.5598173
Policy log std Mean          -1.0648773
Policy log std Std           0.30552587
Policy log std Max           0.36865783
Policy log std Min           -2.4510756
Z mean eval                  1.307337
Z variance eval              0.007000198
total_rewards                [2688.7848088  1697.04448585 2626.04219764 4298.0264072  4242.18846204
  472.80608108 4494.20848521 4575.5799378  4366.83734523 4535.28828635]
total_rewards_mean           3399.68064971969
total_rewards_std            1374.48265207216
total_rewards_max            4575.579937800099
total_rewards_min            472.80608107662187
Number of train steps total  2604000
Number of env steps total    3257000
Number of rollouts total     0
Train Time (s)               148.0606857901439
(Previous) Eval Time (s)     21.743807565886527
Sample Time (s)              24.745290440041572
Epoch Time (s)               194.549783796072
Total Train Time (s)         122142.63479500683
Epoch                        650
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:28:40.260602 UTC | [2020_01_11_13_32_55] Iteration #650 | Epoch Duration: 200.58889198303223
2020-01-12 23:28:40.260793 UTC | [2020_01_11_13_32_55] Iteration #650 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3076969
Z variance train             0.0069883442
KL Divergence                32.636074
KL Loss                      3.2636075
QF Loss                      1983.9299
VF Loss                      216.8334
Policy Loss                  -1463.1744
Q Predictions Mean           1469.9644
Q Predictions Std            373.27847
Q Predictions Max            1708.6014
Q Predictions Min            -379.12607
V Predictions Mean           1463.9751
V Predictions Std            372.8228
V Predictions Max            1705.6257
V Predictions Min            -408.75827
Log Pis Mean                 1.4853475
Log Pis Std                  3.5819497
Log Pis Max                  18.770966
Log Pis Min                  -8.306587
Policy mu Mean               0.012253514
Policy mu Std                0.7013272
Policy mu Max                3.4220397
Policy mu Min                -2.4689019
Policy log std Mean          -1.106147
Policy log std Std           0.30923805
Policy log std Max           -0.2333296
Policy log std Min           -2.5933886
Z mean eval                  1.2915394
Z variance eval              0.013634895
total_rewards                [4158.53303705 3139.07361876  684.64833635 1560.85996927 4353.78644691
  871.66958087 3488.85779504 4400.07299432 3397.62799491 4436.07700573]
total_rewards_mean           3049.1206779196227
total_rewards_std            1398.267815999111
total_rewards_max            4436.077005730955
total_rewards_min            684.6483363454837
Number of train steps total  2608000
Number of env steps total    3262000
Number of rollouts total     0
Train Time (s)               147.33124220883474
(Previous) Eval Time (s)     27.782512884121388
Sample Time (s)              24.752720315940678
Epoch Time (s)               199.8664754088968
Total Train Time (s)         122339.59221997671
Epoch                        651
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:31:57.224119 UTC | [2020_01_11_13_32_55] Iteration #651 | Epoch Duration: 196.96317625045776
2020-01-12 23:31:57.224352 UTC | [2020_01_11_13_32_55] Iteration #651 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2937143
Z variance train             0.013842213
KL Divergence                29.172302
KL Loss                      2.9172304
QF Loss                      2891.9736
VF Loss                      299.14413
Policy Loss                  -1460.9207
Q Predictions Mean           1458.5957
Q Predictions Std            359.9276
Q Predictions Max            1696.418
Q Predictions Min            -445.36993
V Predictions Mean           1463.6338
V Predictions Std            354.11334
V Predictions Max            1693.5339
V Predictions Min            -438.62604
Log Pis Mean                 1.7119011
Log Pis Std                  3.3174603
Log Pis Max                  16.346241
Log Pis Min                  -7.491803
Policy mu Mean               0.016425805
Policy mu Std                0.7118659
Policy mu Max                2.8932507
Policy mu Min                -2.9885888
Policy log std Mean          -1.1494794
Policy log std Std           0.3564817
Policy log std Max           -0.26432616
Policy log std Min           -2.9161644
Z mean eval                  1.2830632
Z variance eval              0.006562747
total_rewards                [1667.31737751 4298.74381302 2897.00688248 4034.196776   4372.66921543
  587.46740399 3870.84412247 2163.71399836 2046.79057868 4521.80721738]
total_rewards_mean           3046.0557385334096
total_rewards_std            1300.327696357504
total_rewards_max            4521.807217384225
total_rewards_min            587.4674039871817
Number of train steps total  2612000
Number of env steps total    3267000
Number of rollouts total     0
Train Time (s)               148.4679245329462
(Previous) Eval Time (s)     24.878820951562375
Sample Time (s)              25.87776556517929
Epoch Time (s)               199.22451104968786
Total Train Time (s)         122539.70682367869
Epoch                        652
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:35:17.344895 UTC | [2020_01_11_13_32_55] Iteration #652 | Epoch Duration: 200.1204047203064
2020-01-12 23:35:17.345085 UTC | [2020_01_11_13_32_55] Iteration #652 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2831331
Z variance train             0.0065731755
KL Divergence                30.732075
KL Loss                      3.0732076
QF Loss                      777.9955
VF Loss                      339.7293
Policy Loss                  -1458.729
Q Predictions Mean           1461.3457
Q Predictions Std            389.7978
Q Predictions Max            1696.2566
Q Predictions Min            -400.6192
V Predictions Mean           1456.4144
V Predictions Std            384.87527
V Predictions Max            1681.531
V Predictions Min            -412.83362
Log Pis Mean                 1.3072579
Log Pis Std                  3.57516
Log Pis Max                  12.457219
Log Pis Min                  -12.280115
Policy mu Mean               0.029644962
Policy mu Std                0.7185433
Policy mu Max                2.6581914
Policy mu Min                -3.5911117
Policy log std Mean          -1.1116796
Policy log std Std           0.33485618
Policy log std Max           -0.043483615
Policy log std Min           -2.8415222
Z mean eval                  1.3439882
Z variance eval              0.0070164367
total_rewards                [1713.27431029  210.73496687 3147.25004751 4338.47557199 4346.62393982
 1014.28672907 1689.4327003  2806.20393835 3700.51983022  164.74780183]
total_rewards_mean           2313.1549836256404
total_rewards_std            1502.4074328779038
total_rewards_max            4346.623939821784
total_rewards_min            164.74780183063646
Number of train steps total  2616000
Number of env steps total    3272000
Number of rollouts total     0
Train Time (s)               145.16490509267896
(Previous) Eval Time (s)     25.774332116823643
Sample Time (s)              23.038983261212707
Epoch Time (s)               193.9782204707153
Total Train Time (s)         122726.40799226938
Epoch                        653
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:38:24.050522 UTC | [2020_01_11_13_32_55] Iteration #653 | Epoch Duration: 186.7053074836731
2020-01-12 23:38:24.050639 UTC | [2020_01_11_13_32_55] Iteration #653 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3447449
Z variance train             0.007014858
KL Divergence                30.383179
KL Loss                      3.038318
QF Loss                      799.234
VF Loss                      204.25961
Policy Loss                  -1471.0356
Q Predictions Mean           1476.0005
Q Predictions Std            325.20953
Q Predictions Max            1675.1484
Q Predictions Min            -548.5437
V Predictions Mean           1470.3591
V Predictions Std            322.3633
V Predictions Max            1678.8771
V Predictions Min            -542.18884
Log Pis Mean                 1.5321711
Log Pis Std                  3.218987
Log Pis Max                  13.289765
Log Pis Min                  -7.064086
Policy mu Mean               -0.00272735
Policy mu Std                0.70233697
Policy mu Max                3.262351
Policy mu Min                -2.6571927
Policy log std Mean          -1.1200305
Policy log std Std           0.30747107
Policy log std Max           -0.13951194
Policy log std Min           -2.4796875
Z mean eval                  1.3108184
Z variance eval              0.0040782937
total_rewards                [ 669.35340928 2154.80484144 2563.5493043  4439.303751    817.84616713
 4228.70731666 4115.26838742 2967.22100483 1216.24306731 2971.1587363 ]
total_rewards_mean           2614.345598569215
total_rewards_std            1327.4070733232727
total_rewards_max            4439.303751002208
total_rewards_min            669.3534092836592
Number of train steps total  2620000
Number of env steps total    3277000
Number of rollouts total     0
Train Time (s)               139.00884329201654
(Previous) Eval Time (s)     18.50109211402014
Sample Time (s)              24.729774795938283
Epoch Time (s)               182.23971020197496
Total Train Time (s)         122913.82347921003
Epoch                        654
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:41:31.472268 UTC | [2020_01_11_13_32_55] Iteration #654 | Epoch Duration: 187.42153215408325
2020-01-12 23:41:31.472449 UTC | [2020_01_11_13_32_55] Iteration #654 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3123182
Z variance train             0.004085793
KL Divergence                31.551537
KL Loss                      3.1551538
QF Loss                      1460.6433
VF Loss                      257.43698
Policy Loss                  -1464.4196
Q Predictions Mean           1468.0371
Q Predictions Std            371.80414
Q Predictions Max            1699.3986
Q Predictions Min            -553.9276
V Predictions Mean           1473.8694
V Predictions Std            366.88156
V Predictions Max            1686.4147
V Predictions Min            -548.14136
Log Pis Mean                 1.0905284
Log Pis Std                  3.3001676
Log Pis Max                  10.677635
Log Pis Min                  -7.3580074
Policy mu Mean               0.035916038
Policy mu Std                0.70479804
Policy mu Max                3.4015
Policy mu Min                -3.0566275
Policy log std Mean          -1.0973303
Policy log std Std           0.30953968
Policy log std Max           -0.018821836
Policy log std Min           -2.663381
Z mean eval                  1.2441456
Z variance eval              0.013652297
total_rewards                [ 354.34523934 2833.76461972 4625.67593826 1488.6596864   899.95937335
 1237.32725417 1128.23183432 3410.66069746 2393.50558803  747.97197868]
total_rewards_mean           1912.0102209741956
total_rewards_std            1294.0512864208572
total_rewards_max            4625.675938262432
total_rewards_min            354.3452393432618
Number of train steps total  2624000
Number of env steps total    3282000
Number of rollouts total     0
Train Time (s)               139.1797485682182
(Previous) Eval Time (s)     23.682582812849432
Sample Time (s)              25.46198714338243
Epoch Time (s)               188.32431852445006
Total Train Time (s)         123095.15856543137
Epoch                        655
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:44:32.811838 UTC | [2020_01_11_13_32_55] Iteration #655 | Epoch Duration: 181.33927488327026
2020-01-12 23:44:32.811955 UTC | [2020_01_11_13_32_55] Iteration #655 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.244821
Z variance train             0.013585724
KL Divergence                28.027058
KL Loss                      2.8027058
QF Loss                      1131.3494
VF Loss                      523.63544
Policy Loss                  -1436.0728
Q Predictions Mean           1440.696
Q Predictions Std            390.86218
Q Predictions Max            1660.8257
Q Predictions Min            -334.85358
V Predictions Mean           1434.8713
V Predictions Std            388.86734
V Predictions Max            1669.2087
V Predictions Min            -356.71277
Log Pis Mean                 1.4096074
Log Pis Std                  3.4764605
Log Pis Max                  21.706198
Log Pis Min                  -9.707446
Policy mu Mean               0.036795326
Policy mu Std                0.69265676
Policy mu Max                4.059215
Policy mu Min                -2.7322483
Policy log std Mean          -1.110672
Policy log std Std           0.310452
Policy log std Max           -0.17004722
Policy log std Min           -2.566847
Z mean eval                  1.2967297
Z variance eval              0.016717894
total_rewards                [4097.34803803 1021.25848204 4641.01434277 4391.8310474    12.89469284
 4311.76531411  913.57185123 2285.3949312    23.91419499 4257.66850929]
total_rewards_mean           2595.6661403899243
total_rewards_std            1845.5633212280347
total_rewards_max            4641.014342771794
total_rewards_min            12.894692838101307
Number of train steps total  2628000
Number of env steps total    3287000
Number of rollouts total     0
Train Time (s)               147.87352546537295
(Previous) Eval Time (s)     16.69712950894609
Sample Time (s)              25.799272462259978
Epoch Time (s)               190.36992743657902
Total Train Time (s)         123293.36744990479
Epoch                        656
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:47:51.024754 UTC | [2020_01_11_13_32_55] Iteration #656 | Epoch Duration: 198.21271562576294
2020-01-12 23:47:51.024886 UTC | [2020_01_11_13_32_55] Iteration #656 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.299927
Z variance train             0.01674866
KL Divergence                29.072752
KL Loss                      2.9072752
QF Loss                      1377.6831
VF Loss                      398.4497
Policy Loss                  -1478.6864
Q Predictions Mean           1481.3146
Q Predictions Std            363.6045
Q Predictions Max            1728.2018
Q Predictions Min            -418.82462
V Predictions Mean           1469.6869
V Predictions Std            360.8954
V Predictions Max            1717.8723
V Predictions Min            -403.84308
Log Pis Mean                 1.260031
Log Pis Std                  3.3094485
Log Pis Max                  11.025777
Log Pis Min                  -6.355112
Policy mu Mean               0.007913697
Policy mu Std                0.69959486
Policy mu Max                3.266023
Policy mu Min                -2.9553611
Policy log std Mean          -1.0937774
Policy log std Std           0.33732787
Policy log std Max           -0.020534992
Policy log std Min           -2.9480515
Z mean eval                  1.3254201
Z variance eval              0.014490858
total_rewards                [ 566.11099157 1267.88399125  719.1063764  3249.32505346 3396.55981435
 4096.6446357  4151.76589233 4634.48654427 4275.91205908   54.74068072]
total_rewards_mean           2641.2536039129664
total_rewards_std            1690.0353436640485
total_rewards_max            4634.486544270473
total_rewards_min            54.74068072275666
Number of train steps total  2632000
Number of env steps total    3292000
Number of rollouts total     0
Train Time (s)               146.7489479095675
(Previous) Eval Time (s)     24.539533424191177
Sample Time (s)              25.27134319767356
Epoch Time (s)               196.55982453143224
Total Train Time (s)         123489.38229615986
Epoch                        657
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:51:07.046251 UTC | [2020_01_11_13_32_55] Iteration #657 | Epoch Duration: 196.02125453948975
2020-01-12 23:51:07.046625 UTC | [2020_01_11_13_32_55] Iteration #657 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.32528
Z variance train             0.0145786535
KL Divergence                28.824493
KL Loss                      2.8824494
QF Loss                      1643.507
VF Loss                      243.17119
Policy Loss                  -1438.0721
Q Predictions Mean           1440.2341
Q Predictions Std            409.57928
Q Predictions Max            1712.2372
Q Predictions Min            -438.0709
V Predictions Mean           1434.9526
V Predictions Std            404.11035
V Predictions Max            1685.2587
V Predictions Min            -432.42245
Log Pis Mean                 1.660893
Log Pis Std                  3.5633163
Log Pis Max                  17.285099
Log Pis Min                  -10.606061
Policy mu Mean               0.040944353
Policy mu Std                0.7341745
Policy mu Max                3.7808778
Policy mu Min                -2.9473226
Policy log std Mean          -1.1083966
Policy log std Std           0.31165087
Policy log std Max           -0.1465435
Policy log std Min           -3.2103677
Z mean eval                  1.2981613
Z variance eval              0.0076140575
total_rewards                [2703.99984131 2356.78840398 3242.94300431 4352.85542734 4555.3502344
 4425.17265119  896.54852088 4400.7152686  3904.81019632 1313.03859128]
total_rewards_mean           3215.2222139600767
total_rewards_std            1281.7423087318773
total_rewards_max            4555.350234400776
total_rewards_min            896.5485208798883
Number of train steps total  2636000
Number of env steps total    3297000
Number of rollouts total     0
Train Time (s)               147.3266499801539
(Previous) Eval Time (s)     24.000542267691344
Sample Time (s)              25.80746770929545
Epoch Time (s)               197.13465995714068
Total Train Time (s)         123691.4509150139
Epoch                        658
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:54:29.121293 UTC | [2020_01_11_13_32_55] Iteration #658 | Epoch Duration: 202.07443070411682
2020-01-12 23:54:29.121488 UTC | [2020_01_11_13_32_55] Iteration #658 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2981699
Z variance train             0.007633765
KL Divergence                31.415329
KL Loss                      3.141533
QF Loss                      1253.0403
VF Loss                      680.0308
Policy Loss                  -1483.0391
Q Predictions Mean           1489.6566
Q Predictions Std            360.0207
Q Predictions Max            1741.2894
Q Predictions Min            -496.88516
V Predictions Mean           1482.8955
V Predictions Std            356.73383
V Predictions Max            1735.2053
V Predictions Min            -513.2959
Log Pis Mean                 1.1610506
Log Pis Std                  3.2024033
Log Pis Max                  17.823086
Log Pis Min                  -6.9322166
Policy mu Mean               0.030220522
Policy mu Std                0.6870055
Policy mu Max                2.9199998
Policy mu Min                -2.6670492
Policy log std Mean          -1.0861032
Policy log std Std           0.29648426
Policy log std Max           0.04380858
Policy log std Min           -3.719293
Z mean eval                  1.2962099
Z variance eval              0.009945208
total_rewards                [4135.00789748  458.50364629 4130.07692456 4108.9281489  3039.53379605
 4157.8866319  4048.69442643  688.41108038  694.42511369 4244.20099325]
total_rewards_mean           2970.566865893049
total_rewards_std            1577.807289213611
total_rewards_max            4244.200993248669
total_rewards_min            458.50364628984676
Number of train steps total  2640000
Number of env steps total    3302000
Number of rollouts total     0
Train Time (s)               146.81732191797346
(Previous) Eval Time (s)     28.93988027004525
Sample Time (s)              27.03928344277665
Epoch Time (s)               202.79648563079536
Total Train Time (s)         123890.8645001091
Epoch                        659
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:57:48.541202 UTC | [2020_01_11_13_32_55] Iteration #659 | Epoch Duration: 199.41957712173462
2020-01-12 23:57:48.541399 UTC | [2020_01_11_13_32_55] Iteration #659 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2993481
Z variance train             0.009968943
KL Divergence                30.91877
KL Loss                      3.091877
QF Loss                      2149.7366
VF Loss                      471.46347
Policy Loss                  -1473.4497
Q Predictions Mean           1475.1995
Q Predictions Std            377.60144
Q Predictions Max            1704.9623
Q Predictions Min            -542.3531
V Predictions Mean           1464.9639
V Predictions Std            372.27087
V Predictions Max            1688.0562
V Predictions Min            -517.36273
Log Pis Mean                 1.8169649
Log Pis Std                  3.782626
Log Pis Max                  24.916927
Log Pis Min                  -6.957505
Policy mu Mean               0.01062744
Policy mu Std                0.72571796
Policy mu Max                4.008145
Policy mu Min                -4.2531066
Policy log std Mean          -1.1502038
Policy log std Std           0.32780826
Policy log std Max           0.1798203
Policy log std Min           -3.4542665
Z mean eval                  1.3098814
Z variance eval              0.016862858
total_rewards                [3908.53526548 3792.7084421  4452.10821318 1756.43906832 4556.55851076
 4078.28725534 3097.64691253  371.73133036 4336.0011374  2847.73494683]
total_rewards_mean           3319.7751082295085
total_rewards_std            1280.5200687724348
total_rewards_max            4556.5585107562165
total_rewards_min            371.7313303586347
Number of train steps total  2644000
Number of env steps total    3307000
Number of rollouts total     0
Train Time (s)               139.30789258982986
(Previous) Eval Time (s)     25.562550243921578
Sample Time (s)              26.42303637554869
Epoch Time (s)               191.29347920930013
Total Train Time (s)         124083.5555808437
Epoch                        660
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:01:01.238467 UTC | [2020_01_11_13_32_55] Iteration #660 | Epoch Duration: 192.6969335079193
2020-01-13 00:01:01.238649 UTC | [2020_01_11_13_32_55] Iteration #660 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3095143
Z variance train             0.01689396
KL Divergence                29.460136
KL Loss                      2.9460137
QF Loss                      3190.079
VF Loss                      383.68076
Policy Loss                  -1451.27
Q Predictions Mean           1454.4482
Q Predictions Std            380.33432
Q Predictions Max            1739.8088
Q Predictions Min            -440.38736
V Predictions Mean           1456.0037
V Predictions Std            377.19836
V Predictions Max            1736.0953
V Predictions Min            -431.95444
Log Pis Mean                 1.5356021
Log Pis Std                  3.6324484
Log Pis Max                  20.317644
Log Pis Min                  -6.5538535
Policy mu Mean               0.03574153
Policy mu Std                0.7032074
Policy mu Max                3.102006
Policy mu Min                -2.8275573
Policy log std Mean          -1.1324977
Policy log std Std           0.3592498
Policy log std Max           0.095994234
Policy log std Min           -3.1790957
Z mean eval                  1.2939599
Z variance eval              0.009652571
total_rewards                [3997.57614847  397.48719794  564.50089708 1760.79878087 4040.18638885
   15.8493779    13.5616679  4382.97568831  886.95269565   82.50219579]
total_rewards_mean           1614.239103876414
total_rewards_std            1727.0644070005842
total_rewards_max            4382.975688309291
total_rewards_min            13.56166789869508
Number of train steps total  2648000
Number of env steps total    3312000
Number of rollouts total     0
Train Time (s)               139.19623361807317
(Previous) Eval Time (s)     26.965687926858664
Sample Time (s)              25.118295665364712
Epoch Time (s)               191.28021721029654
Total Train Time (s)         124260.9995902474
Epoch                        661
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:03:58.690052 UTC | [2020_01_11_13_32_55] Iteration #661 | Epoch Duration: 177.45124983787537
2020-01-13 00:03:58.690321 UTC | [2020_01_11_13_32_55] Iteration #661 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2960323
Z variance train             0.009581034
KL Divergence                31.692062
KL Loss                      3.1692064
QF Loss                      1104.8162
VF Loss                      588.55975
Policy Loss                  -1471.062
Q Predictions Mean           1474.3265
Q Predictions Std            378.2211
Q Predictions Max            1709.4211
Q Predictions Min            -490.2892
V Predictions Mean           1464.1101
V Predictions Std            372.9869
V Predictions Max            1711.9106
V Predictions Min            -465.1946
Log Pis Mean                 0.9335488
Log Pis Std                  3.2650542
Log Pis Max                  13.43821
Log Pis Min                  -7.895652
Policy mu Mean               -0.0006123809
Policy mu Std                0.6736316
Policy mu Max                2.6742525
Policy mu Min                -2.3674724
Policy log std Mean          -1.0866331
Policy log std Std           0.31066185
Policy log std Max           0.9190147
Policy log std Min           -2.7294621
Z mean eval                  1.2810216
Z variance eval              0.020000461
total_rewards                [4041.13187638 1152.20118826 1778.48755855 4346.89720964  970.93625819
 1611.28897339 4666.27484048  957.88498292 4158.70600854 2135.97243006]
total_rewards_mean           2581.9781326401862
total_rewards_std            1453.9114409509643
total_rewards_max            4666.274840475502
total_rewards_min            957.8849829237664
Number of train steps total  2652000
Number of env steps total    3317000
Number of rollouts total     0
Train Time (s)               143.52711321786046
(Previous) Eval Time (s)     13.136393213644624
Sample Time (s)              24.47045939974487
Epoch Time (s)               181.13396583124995
Total Train Time (s)         124451.0561285452
Epoch                        662
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:07:08.753364 UTC | [2020_01_11_13_32_55] Iteration #662 | Epoch Duration: 190.06284976005554
2020-01-13 00:07:08.753748 UTC | [2020_01_11_13_32_55] Iteration #662 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2773983
Z variance train             0.02010501
KL Divergence                30.679705
KL Loss                      3.0679705
QF Loss                      1235.2434
VF Loss                      321.24222
Policy Loss                  -1484.6085
Q Predictions Mean           1487.0104
Q Predictions Std            332.97473
Q Predictions Max            1702.8466
Q Predictions Min            -459.37003
V Predictions Mean           1482.3872
V Predictions Std            327.5219
V Predictions Max            1700.7391
V Predictions Min            -476.27576
Log Pis Mean                 1.6635448
Log Pis Std                  3.4042413
Log Pis Max                  22.69256
Log Pis Min                  -6.997218
Policy mu Mean               0.03900601
Policy mu Std                0.72167814
Policy mu Max                2.8571374
Policy mu Min                -3.372407
Policy log std Mean          -1.1090825
Policy log std Std           0.3183628
Policy log std Max           1.006653
Policy log std Min           -2.6316543
Z mean eval                  1.2967558
Z variance eval              0.009362737
total_rewards                [1050.63392897 1951.20246499 3347.47871191 3001.92297353  431.98125107
 1357.14980259 1638.81966699 3157.70733477  808.27932775 1724.99967823]
total_rewards_mean           1847.0175140805695
total_rewards_std            965.7996307258544
total_rewards_max            3347.4787119149887
total_rewards_min            431.98125106752207
Number of train steps total  2656000
Number of env steps total    3322000
Number of rollouts total     0
Train Time (s)               148.42803489184007
(Previous) Eval Time (s)     22.064956091344357
Sample Time (s)              26.187827438116074
Epoch Time (s)               196.6808184213005
Total Train Time (s)         124647.02107935166
Epoch                        663
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:10:24.724936 UTC | [2020_01_11_13_32_55] Iteration #663 | Epoch Duration: 195.97101068496704
2020-01-13 00:10:24.725150 UTC | [2020_01_11_13_32_55] Iteration #663 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.296747
Z variance train             0.009371423
KL Divergence                31.767944
KL Loss                      3.1767945
QF Loss                      725.0914
VF Loss                      257.1607
Policy Loss                  -1466.5675
Q Predictions Mean           1470.1364
Q Predictions Std            409.99124
Q Predictions Max            1738.2722
Q Predictions Min            -453.83646
V Predictions Mean           1461.7537
V Predictions Std            408.23825
V Predictions Max            1726.7126
V Predictions Min            -461.1472
Log Pis Mean                 1.4839222
Log Pis Std                  3.3702185
Log Pis Max                  14.584197
Log Pis Min                  -6.8466077
Policy mu Mean               0.028729104
Policy mu Std                0.7270049
Policy mu Max                3.2421427
Policy mu Min                -3.166474
Policy log std Mean          -1.0687327
Policy log std Std           0.31207272
Policy log std Max           -0.025828362
Policy log std Min           -2.3384004
Z mean eval                  1.3458637
Z variance eval              0.013294024
total_rewards                [3935.03881772  759.59461283 1798.22889878  899.85542769 4535.34056973
 4406.42039044  256.74190393  475.49260654 2578.4452537  2618.58672389]
total_rewards_mean           2226.3745205234104
total_rewards_std            1559.5091247317855
total_rewards_max            4535.340569725092
total_rewards_min            256.7419039331537
Number of train steps total  2660000
Number of env steps total    3327000
Number of rollouts total     0
Train Time (s)               148.0075789517723
(Previous) Eval Time (s)     21.354846177157015
Sample Time (s)              25.465374449267983
Epoch Time (s)               194.8277995781973
Total Train Time (s)         124842.56999745034
Epoch                        664
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:13:40.280504 UTC | [2020_01_11_13_32_55] Iteration #664 | Epoch Duration: 195.55519890785217
2020-01-13 00:13:40.280763 UTC | [2020_01_11_13_32_55] Iteration #664 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3474878
Z variance train             0.013304886
KL Divergence                31.361015
KL Loss                      3.1361015
QF Loss                      7805.3765
VF Loss                      538.9204
Policy Loss                  -1472.1764
Q Predictions Mean           1479.1289
Q Predictions Std            386.45697
Q Predictions Max            1737.7946
Q Predictions Min            -436.9516
V Predictions Mean           1467.4263
V Predictions Std            381.44916
V Predictions Max            1708.0217
V Predictions Min            -441.53903
Log Pis Mean                 1.6494771
Log Pis Std                  3.6065211
Log Pis Max                  16.077103
Log Pis Min                  -6.288933
Policy mu Mean               0.014139176
Policy mu Std                0.72904164
Policy mu Max                3.219651
Policy mu Min                -2.8114712
Policy log std Mean          -1.1296468
Policy log std Std           0.33574817
Policy log std Max           0.6171967
Policy log std Min           -2.8470545
Z mean eval                  1.3460954
Z variance eval              0.029596945
total_rewards                [4504.73917924 4128.80804958 4487.32374801 4263.61035059    9.11383002
 3000.32030598 4324.15158805  275.66846647  829.73132202  415.77873409]
total_rewards_mean           2623.9245574036813
total_rewards_std            1882.6042833662766
total_rewards_max            4504.739179239333
total_rewards_min            9.113830022424384
Number of train steps total  2664000
Number of env steps total    3332000
Number of rollouts total     0
Train Time (s)               149.19562629517168
(Previous) Eval Time (s)     22.081799142062664
Sample Time (s)              25.081307812128216
Epoch Time (s)               196.35873324936256
Total Train Time (s)         125038.22206831258
Epoch                        665
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:16:55.938381 UTC | [2020_01_11_13_32_55] Iteration #665 | Epoch Duration: 195.6574683189392
2020-01-13 00:16:55.938597 UTC | [2020_01_11_13_32_55] Iteration #665 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3464905
Z variance train             0.02957348
KL Divergence                29.57282
KL Loss                      2.957282
QF Loss                      4799.4575
VF Loss                      3588.445
Policy Loss                  -1469.314
Q Predictions Mean           1475.6973
Q Predictions Std            367.47083
Q Predictions Max            1714.2882
Q Predictions Min            -460.01633
V Predictions Mean           1470.4506
V Predictions Std            372.83298
V Predictions Max            1683.4862
V Predictions Min            -456.25754
Log Pis Mean                 2.0393443
Log Pis Std                  3.3948958
Log Pis Max                  16.976322
Log Pis Min                  -5.0991526
Policy mu Mean               0.034636013
Policy mu Std                0.76925707
Policy mu Max                4.5070157
Policy mu Min                -2.907418
Policy log std Mean          -1.1166594
Policy log std Std           0.34835464
Policy log std Max           -0.096767664
Policy log std Min           -2.912249
Z mean eval                  1.3294742
Z variance eval              0.022160262
total_rewards                [1173.13613959 4371.4574383  4225.5123834   742.92995715  404.12102498
  148.94148934 1346.58250309 1186.16857515 -164.28453462  619.4965917 ]
total_rewards_mean           1405.4061568078605
total_rewards_std            1515.1787629259518
total_rewards_max            4371.457438296695
total_rewards_min            -164.28453461865803
Number of train steps total  2668000
Number of env steps total    3337000
Number of rollouts total     0
Train Time (s)               147.35773999197409
(Previous) Eval Time (s)     21.380198150407523
Sample Time (s)              23.738733787555248
Epoch Time (s)               192.47667192993686
Total Train Time (s)         125223.37832264602
Epoch                        666
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:20:01.101136 UTC | [2020_01_11_13_32_55] Iteration #666 | Epoch Duration: 185.16240167617798
2020-01-13 00:20:01.101318 UTC | [2020_01_11_13_32_55] Iteration #666 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3255178
Z variance train             0.022226056
KL Divergence                31.150375
KL Loss                      3.1150377
QF Loss                      1025.967
VF Loss                      280.45343
Policy Loss                  -1454.1216
Q Predictions Mean           1454.8833
Q Predictions Std            415.98615
Q Predictions Max            1747.4117
Q Predictions Min            -499.68228
V Predictions Mean           1455.2329
V Predictions Std            417.57065
V Predictions Max            1744.3053
V Predictions Min            -501.7315
Log Pis Mean                 1.1500144
Log Pis Std                  3.3537886
Log Pis Max                  13.861881
Log Pis Min                  -7.1245217
Policy mu Mean               0.03665407
Policy mu Std                0.6991023
Policy mu Max                3.435221
Policy mu Min                -2.6683254
Policy log std Mean          -1.0807072
Policy log std Std           0.3027023
Policy log std Max           -0.28152466
Policy log std Min           -2.556723
Z mean eval                  1.3055317
Z variance eval              0.012587443
total_rewards                [2213.19460826 1477.38068981 4050.8800041   282.27476215  728.1033789
 3052.08211407   55.75688986 2760.64036899 3164.24346348   96.67951495]
total_rewards_mean           1788.1235794571567
total_rewards_std            1381.582427342598
total_rewards_max            4050.880004104206
total_rewards_min            55.756889856014595
Number of train steps total  2672000
Number of env steps total    3342000
Number of rollouts total     0
Train Time (s)               139.29078728938475
(Previous) Eval Time (s)     14.065502690616995
Sample Time (s)              24.538617614656687
Epoch Time (s)               177.89490759465843
Total Train Time (s)         125401.74043762498
Epoch                        667
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:22:59.469258 UTC | [2020_01_11_13_32_55] Iteration #667 | Epoch Duration: 178.36780524253845
2020-01-13 00:22:59.469459 UTC | [2020_01_11_13_32_55] Iteration #667 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3058232
Z variance train             0.01260999
KL Divergence                33.43339
KL Loss                      3.3433392
QF Loss                      1236.021
VF Loss                      517.22314
Policy Loss                  -1414.1896
Q Predictions Mean           1418.7313
Q Predictions Std            477.26468
Q Predictions Max            1709.3627
Q Predictions Min            -494.34766
V Predictions Mean           1414.8707
V Predictions Std            476.13657
V Predictions Max            1705.7523
V Predictions Min            -502.7289
Log Pis Mean                 1.432987
Log Pis Std                  3.6839721
Log Pis Max                  14.575927
Log Pis Min                  -6.4799223
Policy mu Mean               -0.002484019
Policy mu Std                0.6928421
Policy mu Max                3.1883535
Policy mu Min                -3.3349726
Policy log std Mean          -1.1066666
Policy log std Std           0.32265115
Policy log std Max           0.326694
Policy log std Min           -2.6088967
Z mean eval                  1.2888244
Z variance eval              0.0061822897
total_rewards                [ 963.76167004 4455.99765536 4589.72955704 4679.52505946 4498.94132848
  914.00178085 2931.61834683 1344.54365009 4343.76366768 4470.47115324]
total_rewards_mean           3319.235386907561
total_rewards_std            1546.173972640769
total_rewards_max            4679.525059460996
total_rewards_min            914.001780847845
Number of train steps total  2676000
Number of env steps total    3347000
Number of rollouts total     0
Train Time (s)               138.54538080794737
(Previous) Eval Time (s)     14.538102221209556
Sample Time (s)              24.26121588377282
Epoch Time (s)               177.34469891292974
Total Train Time (s)         125593.8923552921
Epoch                        668
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:26:11.627428 UTC | [2020_01_11_13_32_55] Iteration #668 | Epoch Duration: 192.15782618522644
2020-01-13 00:26:11.627736 UTC | [2020_01_11_13_32_55] Iteration #668 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2893347
Z variance train             0.0062007275
KL Divergence                33.886467
KL Loss                      3.3886468
QF Loss                      1116.3771
VF Loss                      309.3007
Policy Loss                  -1465.7687
Q Predictions Mean           1470.9323
Q Predictions Std            392.28677
Q Predictions Max            1717.6807
Q Predictions Min            -459.20135
V Predictions Mean           1471.0327
V Predictions Std            394.27032
V Predictions Max            1730.9766
V Predictions Min            -459.59937
Log Pis Mean                 1.3902206
Log Pis Std                  3.0832996
Log Pis Max                  11.788992
Log Pis Min                  -7.1092453
Policy mu Mean               0.019002195
Policy mu Std                0.69649756
Policy mu Max                2.9992068
Policy mu Min                -2.7171257
Policy log std Mean          -1.1082563
Policy log std Std           0.31847045
Policy log std Max           -0.10159862
Policy log std Min           -2.82366
Z mean eval                  1.3417847
Z variance eval              0.006642348
total_rewards                [3439.65207709 1057.374482   2648.472226   4616.96941687 3879.62954523
 3849.18457195 1093.92670937 2277.14237222 4637.36494296 4315.07280519]
total_rewards_mean           3181.478914887586
total_rewards_std            1282.0602680991867
total_rewards_max            4637.364942964949
total_rewards_min            1057.3744819955225
Number of train steps total  2680000
Number of env steps total    3352000
Number of rollouts total     0
Train Time (s)               147.87824936397374
(Previous) Eval Time (s)     29.350916258990765
Sample Time (s)              25.811071122530848
Epoch Time (s)               203.04023674549535
Total Train Time (s)         125794.4604010582
Epoch                        669
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:29:32.202121 UTC | [2020_01_11_13_32_55] Iteration #669 | Epoch Duration: 200.57409858703613
2020-01-13 00:29:32.202313 UTC | [2020_01_11_13_32_55] Iteration #669 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3422095
Z variance train             0.006655152
KL Divergence                32.859047
KL Loss                      3.2859046
QF Loss                      855.7185
VF Loss                      374.5562
Policy Loss                  -1462.8628
Q Predictions Mean           1463.7006
Q Predictions Std            416.76605
Q Predictions Max            1764.4282
Q Predictions Min            -501.00272
V Predictions Mean           1457.1263
V Predictions Std            410.99844
V Predictions Max            1768.3673
V Predictions Min            -490.61545
Log Pis Mean                 1.3752499
Log Pis Std                  3.7057598
Log Pis Max                  17.120996
Log Pis Min                  -10.119277
Policy mu Mean               -0.006711834
Policy mu Std                0.71740735
Policy mu Max                2.8653798
Policy mu Min                -3.1271112
Policy log std Mean          -1.108685
Policy log std Std           0.3466841
Policy log std Max           0.30365407
Policy log std Min           -2.580099
Z mean eval                  1.2740567
Z variance eval              0.014922244
total_rewards                [4034.5101405  4306.91006128 3044.9831059  4160.0792296  2680.26654075
 3282.38687418 4057.948641   1684.26649088 2098.28379782 4447.35542851]
total_rewards_mean           3379.699031040365
total_rewards_std            928.6888912582193
total_rewards_max            4447.355428505398
total_rewards_min            1684.266490884786
Number of train steps total  2684000
Number of env steps total    3357000
Number of rollouts total     0
Train Time (s)               147.06782537698746
(Previous) Eval Time (s)     26.88438408076763
Sample Time (s)              24.674684166442603
Epoch Time (s)               198.6268936241977
Total Train Time (s)         125994.62772829877
Epoch                        670
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:32:52.375429 UTC | [2020_01_11_13_32_55] Iteration #670 | Epoch Duration: 200.17298436164856
2020-01-13 00:32:52.375608 UTC | [2020_01_11_13_32_55] Iteration #670 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2744262
Z variance train             0.014917338
KL Divergence                30.626934
KL Loss                      3.0626934
QF Loss                      1043.3345
VF Loss                      213.83139
Policy Loss                  -1456.294
Q Predictions Mean           1461.2168
Q Predictions Std            397.08676
Q Predictions Max            1721.541
Q Predictions Min            -477.34265
V Predictions Mean           1459.9272
V Predictions Std            397.59595
V Predictions Max            1707.2896
V Predictions Min            -452.69403
Log Pis Mean                 1.4811717
Log Pis Std                  3.4996393
Log Pis Max                  20.006218
Log Pis Min                  -7.64116
Policy mu Mean               0.0040458264
Policy mu Std                0.71163666
Policy mu Max                2.795393
Policy mu Min                -2.694195
Policy log std Mean          -1.1100318
Policy log std Std           0.33755302
Policy log std Max           -0.12389505
Policy log std Min           -2.6083941
Z mean eval                  1.2695758
Z variance eval              0.011542235
total_rewards                [1466.59934881 4499.64026888 4281.42461746 4243.86649659 4259.25632319
 4310.12860193 4554.11564197 3722.53331993 4538.86616652 4438.92824193]
total_rewards_mean           4031.5359027200584
total_rewards_std            884.7002345810658
total_rewards_max            4554.115641966449
total_rewards_min            1466.599348805949
Number of train steps total  2688000
Number of env steps total    3362000
Number of rollouts total     0
Train Time (s)               146.01150459982455
(Previous) Eval Time (s)     28.43010107288137
Sample Time (s)              24.92575003625825
Epoch Time (s)               199.36735570896417
Total Train Time (s)         126197.93480062904
Epoch                        671
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:36:15.689633 UTC | [2020_01_11_13_32_55] Iteration #671 | Epoch Duration: 203.31386184692383
2020-01-13 00:36:15.689940 UTC | [2020_01_11_13_32_55] Iteration #671 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2726191
Z variance train             0.011529697
KL Divergence                30.63657
KL Loss                      3.063657
QF Loss                      794.5154
VF Loss                      195.99696
Policy Loss                  -1461.043
Q Predictions Mean           1465.3517
Q Predictions Std            345.73337
Q Predictions Max            1702.6455
Q Predictions Min            -361.46518
V Predictions Mean           1459.5825
V Predictions Std            348.71436
V Predictions Max            1704.0074
V Predictions Min            -365.10962
Log Pis Mean                 0.8881635
Log Pis Std                  3.0912554
Log Pis Max                  13.1357565
Log Pis Min                  -6.2179794
Policy mu Mean               -0.010178957
Policy mu Std                0.6723043
Policy mu Max                2.3756552
Policy mu Min                -2.819832
Policy log std Mean          -1.0962182
Policy log std Std           0.3017347
Policy log std Max           -0.15082324
Policy log std Min           -2.4652164
Z mean eval                  1.2802074
Z variance eval              0.0127971545
total_rewards                [4207.91543668 4095.96544129 1088.48501801 1797.50082772  421.44256326
 4201.38581984  387.12696749 4407.26945003 2576.78042908 2145.0471212 ]
total_rewards_mean           2532.8919074591568
total_rewards_std            1529.3152845971545
total_rewards_max            4407.269450027442
total_rewards_min            387.12696749187296
Number of train steps total  2692000
Number of env steps total    3367000
Number of rollouts total     0
Train Time (s)               148.62682513380423
(Previous) Eval Time (s)     32.376281353179365
Sample Time (s)              27.323814471717924
Epoch Time (s)               208.32692095870152
Total Train Time (s)         126397.21234843414
Epoch                        672
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:39:34.973263 UTC | [2020_01_11_13_32_55] Iteration #672 | Epoch Duration: 199.28312993049622
2020-01-13 00:39:34.973451 UTC | [2020_01_11_13_32_55] Iteration #672 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2779624
Z variance train             0.012789005
KL Divergence                30.545544
KL Loss                      3.0545545
QF Loss                      1370.8252
VF Loss                      369.0241
Policy Loss                  -1506.7352
Q Predictions Mean           1512.9755
Q Predictions Std            303.51285
Q Predictions Max            1724.2855
Q Predictions Min            -402.38806
V Predictions Mean           1511.5002
V Predictions Std            308.98514
V Predictions Max            1708.6476
V Predictions Min            -418.4612
Log Pis Mean                 1.5978351
Log Pis Std                  3.6357725
Log Pis Max                  17.311954
Log Pis Min                  -10.166091
Policy mu Mean               0.010078763
Policy mu Std                0.6980553
Policy mu Max                3.370943
Policy mu Min                -2.960569
Policy log std Mean          -1.1360996
Policy log std Std           0.32149035
Policy log std Max           -0.070216656
Policy log std Min           -3.069067
Z mean eval                  1.2723209
Z variance eval              0.01329686
total_rewards                [1425.3293922   111.55577006 4340.8611065   259.65635945 4241.09224713
  158.93955653  797.1799666  2433.73162587  575.43221086 4342.33825179]
total_rewards_mean           1868.6116486994906
total_rewards_std            1726.125855200058
total_rewards_max            4342.338251785615
total_rewards_min            111.55577006309996
Number of train steps total  2696000
Number of env steps total    3372000
Number of rollouts total     0
Train Time (s)               142.73194428673014
(Previous) Eval Time (s)     23.33203162997961
Sample Time (s)              25.06848958740011
Epoch Time (s)               191.13246550410986
Total Train Time (s)         126582.01089032833
Epoch                        673
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:42:39.781251 UTC | [2020_01_11_13_32_55] Iteration #673 | Epoch Duration: 184.80766701698303
2020-01-13 00:42:39.781520 UTC | [2020_01_11_13_32_55] Iteration #673 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2730027
Z variance train             0.013322113
KL Divergence                30.229904
KL Loss                      3.0229905
QF Loss                      17698.104
VF Loss                      1075.5547
Policy Loss                  -1441.739
Q Predictions Mean           1441.677
Q Predictions Std            446.29022
Q Predictions Max            1733.6533
Q Predictions Min            -425.85434
V Predictions Mean           1440.9479
V Predictions Std            440.48407
V Predictions Max            1728.1577
V Predictions Min            -441.87225
Log Pis Mean                 1.2071426
Log Pis Std                  3.4311347
Log Pis Max                  11.561506
Log Pis Min                  -9.025911
Policy mu Mean               -0.0025032829
Policy mu Std                0.7352818
Policy mu Max                3.0269272
Policy mu Min                -2.9310029
Policy log std Mean          -1.04758
Policy log std Std           0.3398807
Policy log std Max           -0.18693483
Policy log std Min           -2.9024432
Z mean eval                  1.2839615
Z variance eval              0.017223964
total_rewards                [4196.63431455 4346.51770471 4319.21974566 2342.15364008  118.40594415
  709.10939785 4254.33860234 2572.46787949 4233.26622368 4637.92080156]
total_rewards_mean           3173.0034254084294
total_rewards_std            1569.4103210499013
total_rewards_max            4637.920801564468
total_rewards_min            118.40594415452242
Number of train steps total  2700000
Number of env steps total    3377000
Number of rollouts total     0
Train Time (s)               140.08701350400224
(Previous) Eval Time (s)     17.00684992596507
Sample Time (s)              23.59170826524496
Epoch Time (s)               180.68557169521227
Total Train Time (s)         126773.52017419273
Epoch                        674
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:45:51.294220 UTC | [2020_01_11_13_32_55] Iteration #674 | Epoch Duration: 191.51248455047607
2020-01-13 00:45:51.294471 UTC | [2020_01_11_13_32_55] Iteration #674 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2831153
Z variance train             0.017118746
KL Divergence                30.763634
KL Loss                      3.0763633
QF Loss                      1227.3761
VF Loss                      263.5434
Policy Loss                  -1468.8925
Q Predictions Mean           1467.7606
Q Predictions Std            392.89716
Q Predictions Max            1739.6866
Q Predictions Min            -472.95697
V Predictions Mean           1471.248
V Predictions Std            380.42834
V Predictions Max            1740.5085
V Predictions Min            -479.0824
Log Pis Mean                 1.7714214
Log Pis Std                  3.5791929
Log Pis Max                  29.303396
Log Pis Min                  -7.61688
Policy mu Mean               -0.03950713
Policy mu Std                0.73040324
Policy mu Max                4.919488
Policy mu Min                -3.798975
Policy log std Mean          -1.1092105
Policy log std Std           0.34163874
Policy log std Max           -0.17145431
Policy log std Min           -3.2527723
Z mean eval                  1.297971
Z variance eval              0.026518766
total_rewards                [ -13.13031366 4285.62874197 1193.30673813 4359.07308749 4222.05248514
 4455.25050549  232.27561615 2322.40398392 4399.06643522 4160.98939806]
total_rewards_mean           2961.6916677921313
total_rewards_std            1756.821694834572
total_rewards_max            4455.250505489391
total_rewards_min            -13.13031365560278
Number of train steps total  2704000
Number of env steps total    3382000
Number of rollouts total     0
Train Time (s)               140.58931153360754
(Previous) Eval Time (s)     27.833354035858065
Sample Time (s)              24.62012639408931
Epoch Time (s)               193.04279196355492
Total Train Time (s)         126963.35726165818
Epoch                        675
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:49:01.137555 UTC | [2020_01_11_13_32_55] Iteration #675 | Epoch Duration: 189.84293270111084
2020-01-13 00:49:01.137750 UTC | [2020_01_11_13_32_55] Iteration #675 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.300968
Z variance train             0.02653912
KL Divergence                29.10087
KL Loss                      2.910087
QF Loss                      5591.335
VF Loss                      363.75314
Policy Loss                  -1497.0211
Q Predictions Mean           1500.2993
Q Predictions Std            322.4521
Q Predictions Max            1744.765
Q Predictions Min            -500.13348
V Predictions Mean           1491.1713
V Predictions Std            317.82
V Predictions Max            1728.6797
V Predictions Min            -483.12286
Log Pis Mean                 1.6079402
Log Pis Std                  3.2087
Log Pis Max                  16.694897
Log Pis Min                  -8.565614
Policy mu Mean               0.026657982
Policy mu Std                0.7188866
Policy mu Max                2.6691291
Policy mu Min                -2.2308626
Policy log std Mean          -1.1162093
Policy log std Std           0.34358788
Policy log std Max           0.5275105
Policy log std Min           -3.2707515
Z mean eval                  1.3120363
Z variance eval              0.016801171
total_rewards                [3146.61125523 2507.71011626  186.40881235  868.448758    198.33208839
 4500.34148973  397.77621163 4384.38893658  311.94959822 1981.83553579]
total_rewards_mean           1848.3802802180762
total_rewards_std            1628.254075758974
total_rewards_max            4500.341489726327
total_rewards_min            186.40881235303053
Number of train steps total  2708000
Number of env steps total    3387000
Number of rollouts total     0
Train Time (s)               149.5076199369505
(Previous) Eval Time (s)     24.63320611603558
Sample Time (s)              26.65116463508457
Epoch Time (s)               200.79199068807065
Total Train Time (s)         127154.37486974895
Epoch                        676
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:52:12.164515 UTC | [2020_01_11_13_32_55] Iteration #676 | Epoch Duration: 191.0266296863556
2020-01-13 00:52:12.164952 UTC | [2020_01_11_13_32_55] Iteration #676 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3135837
Z variance train             0.016868543
KL Divergence                29.932478
KL Loss                      2.9932477
QF Loss                      3101.1235
VF Loss                      408.2575
Policy Loss                  -1469.9886
Q Predictions Mean           1474.9252
Q Predictions Std            391.0901
Q Predictions Max            1722.7115
Q Predictions Min            -506.02615
V Predictions Mean           1457.3223
V Predictions Std            389.08554
V Predictions Max            1703.4578
V Predictions Min            -500.36804
Log Pis Mean                 1.5004821
Log Pis Std                  3.1337655
Log Pis Max                  11.653152
Log Pis Min                  -8.391007
Policy mu Mean               0.055141233
Policy mu Std                0.695978
Policy mu Max                2.6413357
Policy mu Min                -2.7162619
Policy log std Mean          -1.107448
Policy log std Std           0.29816407
Policy log std Max           -0.16176176
Policy log std Min           -2.3158402
Z mean eval                  1.2931851
Z variance eval              0.0236985
total_rewards                [4240.58257675 2765.20763275 3047.98341168 2537.69941244  165.40841346
 3155.90355954 4435.08934089 2185.10567411  773.59259936 3867.27448122]
total_rewards_mean           2717.3847102208033
total_rewards_std            1322.9998982158982
total_rewards_max            4435.089340887408
total_rewards_min            165.40841346020537
Number of train steps total  2712000
Number of env steps total    3392000
Number of rollouts total     0
Train Time (s)               148.4578411160037
(Previous) Eval Time (s)     14.867413338273764
Sample Time (s)              24.434075119439512
Epoch Time (s)               187.75932957371697
Total Train Time (s)         127349.30454760743
Epoch                        677
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:55:27.100591 UTC | [2020_01_11_13_32_55] Iteration #677 | Epoch Duration: 194.93535017967224
2020-01-13 00:55:27.100799 UTC | [2020_01_11_13_32_55] Iteration #677 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2924144
Z variance train             0.02365956
KL Divergence                29.832638
KL Loss                      2.9832637
QF Loss                      2172.5203
VF Loss                      228.52371
Policy Loss                  -1441.2292
Q Predictions Mean           1444.8689
Q Predictions Std            406.76025
Q Predictions Max            1711.8202
Q Predictions Min            -500.0742
V Predictions Mean           1444.626
V Predictions Std            402.46115
V Predictions Max            1700.6398
V Predictions Min            -492.70413
Log Pis Mean                 1.5269617
Log Pis Std                  3.3625863
Log Pis Max                  18.486649
Log Pis Min                  -10.067091
Policy mu Mean               -0.02004245
Policy mu Std                0.6890226
Policy mu Max                2.581807
Policy mu Min                -2.5505724
Policy log std Mean          -1.1302315
Policy log std Std           0.32650337
Policy log std Max           0.02139771
Policy log std Min           -2.6766262
Z mean eval                  1.2962089
Z variance eval              0.017046576
total_rewards                [1035.38852127 3023.18916379 3460.61699063 2259.4395097   173.5596173
 4529.86283266 2296.39673803  605.96321411 2769.01924357 1888.36969729]
total_rewards_mean           2204.1805528344366
total_rewards_std            1270.131377953807
total_rewards_max            4529.862832663124
total_rewards_min            173.55961729594958
Number of train steps total  2716000
Number of env steps total    3397000
Number of rollouts total     0
Train Time (s)               149.69638762623072
(Previous) Eval Time (s)     22.043105795048177
Sample Time (s)              25.25885853311047
Epoch Time (s)               196.99835195438936
Total Train Time (s)         127544.04246002575
Epoch                        678
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:58:41.844836 UTC | [2020_01_11_13_32_55] Iteration #678 | Epoch Duration: 194.74390268325806
2020-01-13 00:58:41.845018 UTC | [2020_01_11_13_32_55] Iteration #678 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2968013
Z variance train             0.017033245
KL Divergence                30.032753
KL Loss                      3.0032754
QF Loss                      1603.9177
VF Loss                      270.40903
Policy Loss                  -1468.1665
Q Predictions Mean           1470.9602
Q Predictions Std            400.69022
Q Predictions Max            1742.8118
Q Predictions Min            -503.13873
V Predictions Mean           1465.0135
V Predictions Std            398.4452
V Predictions Max            1696.0953
V Predictions Min            -509.5354
Log Pis Mean                 1.5202683
Log Pis Std                  4.2374735
Log Pis Max                  45.554466
Log Pis Min                  -7.1948266
Policy mu Mean               0.014260648
Policy mu Std                0.7967222
Policy mu Max                4.3472924
Policy mu Min                -9.924583
Policy log std Mean          -1.077395
Policy log std Std           0.33969834
Policy log std Max           2.0
Policy log std Min           -2.9127772
Z mean eval                  1.3119107
Z variance eval              0.026837826
total_rewards                [4023.12145207 4186.18375089   85.32994376  804.57230436 3137.68935043
 4361.07279068  828.66692213  296.33254232 2555.25478763 2548.16315988]
total_rewards_mean           2282.6387004154035
total_rewards_std            1578.6348136360305
total_rewards_max            4361.072790682473
total_rewards_min            85.32994375520542
Number of train steps total  2720000
Number of env steps total    3402000
Number of rollouts total     0
Train Time (s)               147.5956518049352
(Previous) Eval Time (s)     19.788254929240793
Sample Time (s)              24.985525504220277
Epoch Time (s)               192.36943223839626
Total Train Time (s)         127741.62134055793
Epoch                        679
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:01:59.430448 UTC | [2020_01_11_13_32_55] Iteration #679 | Epoch Duration: 197.58529567718506
2020-01-13 01:01:59.430642 UTC | [2020_01_11_13_32_55] Iteration #679 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.312258
Z variance train             0.02691852
KL Divergence                30.75003
KL Loss                      3.0750031
QF Loss                      2186.6753
VF Loss                      1548.0524
Policy Loss                  -1397.7439
Q Predictions Mean           1401.2556
Q Predictions Std            492.96844
Q Predictions Max            1726.5398
Q Predictions Min            -503.87604
V Predictions Mean           1401.0564
V Predictions Std            491.64978
V Predictions Max            1715.0555
V Predictions Min            -500.9518
Log Pis Mean                 1.3232386
Log Pis Std                  3.6173174
Log Pis Max                  24.057768
Log Pis Min                  -8.405155
Policy mu Mean               0.0037459785
Policy mu Std                0.7235385
Policy mu Max                2.9594095
Policy mu Min                -5.2743096
Policy log std Mean          -1.0641358
Policy log std Std           0.33028102
Policy log std Max           0.1937939
Policy log std Min           -2.6275754
Z mean eval                  1.352383
Z variance eval              0.031849995
total_rewards                [ 253.22064452 1254.23960155 1120.19894746 4506.18326768 1990.3560004
 1760.71937966 4622.01778165   40.57370785  513.45038051   20.66752162]
total_rewards_mean           1608.1627232882797
total_rewards_std            1613.2668822149292
total_rewards_max            4622.017781646163
total_rewards_min            20.667521619171772
Number of train steps total  2724000
Number of env steps total    3407000
Number of rollouts total     0
Train Time (s)               139.33986010216177
(Previous) Eval Time (s)     25.00373293692246
Sample Time (s)              22.914149140473455
Epoch Time (s)               187.25774217955768
Total Train Time (s)         127919.11494814791
Epoch                        680
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:04:56.931114 UTC | [2020_01_11_13_32_55] Iteration #680 | Epoch Duration: 177.5003113746643
2020-01-13 01:04:56.931415 UTC | [2020_01_11_13_32_55] Iteration #680 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3520406
Z variance train             0.03182071
KL Divergence                30.00433
KL Loss                      3.000433
QF Loss                      3119.0417
VF Loss                      1693.1655
Policy Loss                  -1444.6733
Q Predictions Mean           1451.525
Q Predictions Std            448.14218
Q Predictions Max            1717.7015
Q Predictions Min            -497.66528
V Predictions Mean           1452.1969
V Predictions Std            450.0987
V Predictions Max            1725.2418
V Predictions Min            -535.9354
Log Pis Mean                 1.5617888
Log Pis Std                  3.470206
Log Pis Max                  11.910845
Log Pis Min                  -6.64207
Policy mu Mean               0.016258284
Policy mu Std                0.7241284
Policy mu Max                2.3418353
Policy mu Min                -2.7752604
Policy log std Mean          -1.075498
Policy log std Std           0.3499838
Policy log std Max           0.47731137
Policy log std Min           -2.8565216
Z mean eval                  1.2696086
Z variance eval              0.009496178
total_rewards                [ 652.42540397 4368.02076901 4314.0567348  4620.76467203 2633.97052509
 4224.60351251 4353.87494674 2708.34921695 4525.99099923  524.52418615]
total_rewards_mean           3292.658096646409
total_rewards_std            1512.8787407508653
total_rewards_max            4620.764672033697
total_rewards_min            524.5241861451041
Number of train steps total  2728000
Number of env steps total    3412000
Number of rollouts total     0
Train Time (s)               139.23704361217096
(Previous) Eval Time (s)     15.246029161848128
Sample Time (s)              22.185063337907195
Epoch Time (s)               176.6681361119263
Total Train Time (s)         128106.81803618558
Epoch                        681
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:08:04.640448 UTC | [2020_01_11_13_32_55] Iteration #681 | Epoch Duration: 187.70886611938477
2020-01-13 01:08:04.640639 UTC | [2020_01_11_13_32_55] Iteration #681 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2698672
Z variance train             0.009472879
KL Divergence                31.606524
KL Loss                      3.1606524
QF Loss                      1132.706
VF Loss                      344.55536
Policy Loss                  -1508.1625
Q Predictions Mean           1512.3337
Q Predictions Std            290.16516
Q Predictions Max            1729.7979
Q Predictions Min            -490.6628
V Predictions Mean           1505.6917
V Predictions Std            288.69687
V Predictions Max            1732.6978
V Predictions Min            -462.37857
Log Pis Mean                 1.2810469
Log Pis Std                  3.207381
Log Pis Max                  12.162804
Log Pis Min                  -11.048385
Policy mu Mean               0.0523633
Policy mu Std                0.68498254
Policy mu Max                4.248706
Policy mu Min                -2.224416
Policy log std Mean          -1.1043525
Policy log std Std           0.2888102
Policy log std Max           -0.2168988
Policy log std Min           -2.6091447
Z mean eval                  1.3059359
Z variance eval              0.020100484
total_rewards                [4640.12339521  424.15870024 4363.30569587 2221.76035976 4501.43265302
 4348.74249359  854.18514094 4507.30262951 4074.97369534 4188.95286195]
total_rewards_mean           3412.4937625437997
total_rewards_std            1536.4497315293747
total_rewards_max            4640.123395208231
total_rewards_min            424.15870024492204
Number of train steps total  2732000
Number of env steps total    3417000
Number of rollouts total     0
Train Time (s)               144.95374103914946
(Previous) Eval Time (s)     26.28646571189165
Sample Time (s)              25.049420638475567
Epoch Time (s)               196.28962738951668
Total Train Time (s)         128304.21762770182
Epoch                        682
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:11:22.046216 UTC | [2020_01_11_13_32_55] Iteration #682 | Epoch Duration: 197.40544319152832
2020-01-13 01:11:22.046401 UTC | [2020_01_11_13_32_55] Iteration #682 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3071926
Z variance train             0.020037506
KL Divergence                31.368769
KL Loss                      3.1368768
QF Loss                      1524.7571
VF Loss                      366.19864
Policy Loss                  -1469.9889
Q Predictions Mean           1471.523
Q Predictions Std            393.50323
Q Predictions Max            1729.7439
Q Predictions Min            -456.1491
V Predictions Mean           1466.3472
V Predictions Std            387.8106
V Predictions Max            1721.2806
V Predictions Min            -461.55045
Log Pis Mean                 1.4788299
Log Pis Std                  3.3604872
Log Pis Max                  14.791522
Log Pis Min                  -6.2339816
Policy mu Mean               0.036680344
Policy mu Std                0.6893523
Policy mu Max                2.8099976
Policy mu Min                -3.1763806
Policy log std Mean          -1.13358
Policy log std Std           0.33607936
Policy log std Max           -0.01566875
Policy log std Min           -2.7698631
Z mean eval                  1.2942473
Z variance eval              0.0122869555
total_rewards                [4.47305738e+03 2.39507005e+03 4.18681656e+03 4.71119802e+03
 4.32942665e+03 3.58085709e+03 1.49166899e+03 3.00902892e+02
 3.27790790e+00 9.24407230e+02]
total_rewards_mean           2639.668276097847
total_rewards_std            1747.2139953151338
total_rewards_max            4711.198018734249
total_rewards_min            3.2779079024359667
Number of train steps total  2736000
Number of env steps total    3422000
Number of rollouts total     0
Train Time (s)               148.52118882117793
(Previous) Eval Time (s)     27.4018916063942
Sample Time (s)              25.240584332495928
Epoch Time (s)               201.16366476006806
Total Train Time (s)         128503.65585966315
Epoch                        683
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:14:41.490996 UTC | [2020_01_11_13_32_55] Iteration #683 | Epoch Duration: 199.44446468353271
2020-01-13 01:14:41.491176 UTC | [2020_01_11_13_32_55] Iteration #683 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2937226
Z variance train             0.012282212
KL Divergence                32.92784
KL Loss                      3.2927842
QF Loss                      890.49286
VF Loss                      443.5634
Policy Loss                  -1505.3451
Q Predictions Mean           1507.4956
Q Predictions Std            352.06485
Q Predictions Max            1731.851
Q Predictions Min            -500.05527
V Predictions Mean           1497.3284
V Predictions Std            345.847
V Predictions Max            1707.2821
V Predictions Min            -485.64398
Log Pis Mean                 1.5607774
Log Pis Std                  3.3174381
Log Pis Max                  15.590048
Log Pis Min                  -6.1526904
Policy mu Mean               0.053735696
Policy mu Std                0.7080722
Policy mu Max                4.2252083
Policy mu Min                -3.176598
Policy log std Mean          -1.1323279
Policy log std Std           0.3181045
Policy log std Max           0.5012748
Policy log std Min           -3.1902232
Z mean eval                  1.3218021
Z variance eval              0.0073218257
total_rewards                [4131.05390261 1172.97814796 4359.79976168  265.78838875 1572.77998164
 4171.22280782  565.32375168  811.84692883 4379.01303411 4294.31706281]
total_rewards_mean           2572.412376789597
total_rewards_std            1726.7097121652287
total_rewards_max            4379.013034113706
total_rewards_min            265.7883887503359
Number of train steps total  2740000
Number of env steps total    3427000
Number of rollouts total     0
Train Time (s)               146.75962484488264
(Previous) Eval Time (s)     25.682223208714277
Sample Time (s)              25.734892471693456
Epoch Time (s)               198.17674052529037
Total Train Time (s)         128703.50082592294
Epoch                        684
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:18:01.342729 UTC | [2020_01_11_13_32_55] Iteration #684 | Epoch Duration: 199.85136699676514
2020-01-13 01:18:01.342925 UTC | [2020_01_11_13_32_55] Iteration #684 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3246617
Z variance train             0.007339265
KL Divergence                30.825764
KL Loss                      3.0825765
QF Loss                      1241.0823
VF Loss                      259.85907
Policy Loss                  -1489.148
Q Predictions Mean           1498.0627
Q Predictions Std            335.12054
Q Predictions Max            1735.6735
Q Predictions Min            -418.41898
V Predictions Mean           1491.5618
V Predictions Std            338.1312
V Predictions Max            1717.3971
V Predictions Min            -437.7858
Log Pis Mean                 1.6279808
Log Pis Std                  3.6384287
Log Pis Max                  23.173744
Log Pis Min                  -6.352627
Policy mu Mean               0.010157075
Policy mu Std                0.76676315
Policy mu Max                3.3623834
Policy mu Min                -5.1639047
Policy log std Mean          -1.0630606
Policy log std Std           0.34037098
Policy log std Max           1.048852
Policy log std Min           -2.8498726
Z mean eval                  1.292807
Z variance eval              0.021864807
total_rewards                [2922.77706865 4510.1910445  4282.62574479 4344.68833524 4189.7190761
 4067.61801863 1105.68989862 2269.17511883 4399.60837348 1574.9168426 ]
total_rewards_mean           3366.7009521433065
total_rewards_std            1227.3052226157283
total_rewards_max            4510.191044495841
total_rewards_min            1105.6898986177332
Number of train steps total  2744000
Number of env steps total    3432000
Number of rollouts total     0
Train Time (s)               148.37962202634662
(Previous) Eval Time (s)     27.356478676199913
Sample Time (s)              24.68069064663723
Epoch Time (s)               200.41679134918377
Total Train Time (s)         128903.19019600516
Epoch                        685
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:21:21.039836 UTC | [2020_01_11_13_32_55] Iteration #685 | Epoch Duration: 199.69675755500793
2020-01-13 01:21:21.040073 UTC | [2020_01_11_13_32_55] Iteration #685 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2938032
Z variance train             0.021883866
KL Divergence                28.576376
KL Loss                      2.8576376
QF Loss                      3053.9978
VF Loss                      573.2497
Policy Loss                  -1481.8733
Q Predictions Mean           1486.6504
Q Predictions Std            387.88516
Q Predictions Max            1710.4349
Q Predictions Min            -484.4391
V Predictions Mean           1478.6028
V Predictions Std            378.0269
V Predictions Max            1703.5367
V Predictions Min            -459.6603
Log Pis Mean                 1.59831
Log Pis Std                  3.6495657
Log Pis Max                  14.582497
Log Pis Min                  -7.61528
Policy mu Mean               0.023869362
Policy mu Std                0.69524676
Policy mu Max                2.9646235
Policy mu Min                -2.3993533
Policy log std Mean          -1.1420267
Policy log std Std           0.35444087
Policy log std Max           0.16094708
Policy log std Min           -3.0631843
Z mean eval                  1.276082
Z variance eval              0.010274136
total_rewards                [ 315.95884088 4061.60710331 4327.55864158 1434.42543813 3892.20732866
 4355.18035512 3597.82591832 2235.79279628  906.37654862 2609.45579853]
total_rewards_mean           2773.638876942886
total_rewards_std            1419.220517800252
total_rewards_max            4355.1803551213325
total_rewards_min            315.95884088068595
Number of train steps total  2748000
Number of env steps total    3437000
Number of rollouts total     0
Train Time (s)               145.44781593512744
(Previous) Eval Time (s)     26.636054336093366
Sample Time (s)              26.885357121005654
Epoch Time (s)               198.96922739222646
Total Train Time (s)         129097.56719376612
Epoch                        686
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:24:35.423688 UTC | [2020_01_11_13_32_55] Iteration #686 | Epoch Duration: 194.383465051651
2020-01-13 01:24:35.423906 UTC | [2020_01_11_13_32_55] Iteration #686 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2907069
Z variance train             0.010235543
KL Divergence                29.904543
KL Loss                      2.9904544
QF Loss                      2175.7827
VF Loss                      339.40405
Policy Loss                  -1461.186
Q Predictions Mean           1464.5249
Q Predictions Std            418.11838
Q Predictions Max            1736.129
Q Predictions Min            -391.50107
V Predictions Mean           1463.0438
V Predictions Std            416.3846
V Predictions Max            1729.6766
V Predictions Min            -384.07358
Log Pis Mean                 1.2928826
Log Pis Std                  3.1612322
Log Pis Max                  15.38484
Log Pis Min                  -7.1936045
Policy mu Mean               0.0077830884
Policy mu Std                0.6745744
Policy mu Max                2.5884826
Policy mu Min                -3.0143695
Policy log std Mean          -1.11443
Policy log std Std           0.32224137
Policy log std Max           0.3855772
Policy log std Min           -2.9757867
Z mean eval                  1.2768443
Z variance eval              0.014926787
total_rewards                [1633.39862509  707.22984947 2784.92396077 4359.9871658  3762.32658701
 4526.89974845 3695.50345018 1212.04210628 3817.9874128  1634.10399187]
total_rewards_mean           2813.4402897728987
total_rewards_std            1334.1675411491835
total_rewards_max            4526.899748447808
total_rewards_min            707.2298494728177
Number of train steps total  2752000
Number of env steps total    3442000
Number of rollouts total     0
Train Time (s)               140.14314811583608
(Previous) Eval Time (s)     22.049839930143207
Sample Time (s)              24.5000556926243
Epoch Time (s)               186.6930437386036
Total Train Time (s)         129285.41134810215
Epoch                        687
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:27:43.274463 UTC | [2020_01_11_13_32_55] Iteration #687 | Epoch Duration: 187.85031986236572
2020-01-13 01:27:43.274933 UTC | [2020_01_11_13_32_55] Iteration #687 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.272668
Z variance train             0.014948115
KL Divergence                28.115803
KL Loss                      2.8115804
QF Loss                      2306.6987
VF Loss                      446.2973
Policy Loss                  -1460.2064
Q Predictions Mean           1461.0208
Q Predictions Std            404.63342
Q Predictions Max            1707.5482
Q Predictions Min            -415.72336
V Predictions Mean           1471.837
V Predictions Std            399.53537
V Predictions Max            1718.6019
V Predictions Min            -415.17166
Log Pis Mean                 1.9349828
Log Pis Std                  3.5822008
Log Pis Max                  21.585443
Log Pis Min                  -5.5549645
Policy mu Mean               0.025536308
Policy mu Std                0.73639107
Policy mu Max                2.871299
Policy mu Min                -3.5943415
Policy log std Mean          -1.129688
Policy log std Std           0.3657733
Policy log std Max           -0.0139558315
Policy log std Min           -3.0738587
Z mean eval                  1.3131974
Z variance eval              0.33021393
total_rewards                [ 229.82117225 1408.08148085  222.91884127 3221.74280382 3765.08317272
 1142.21756059 3806.19010667 3648.93695864 1076.4700501  3705.4229848 ]
total_rewards_mean           2222.6885131717045
total_rewards_std            1457.1435083864592
total_rewards_max            3806.190106673885
total_rewards_min            222.91884127338133
Number of train steps total  2756000
Number of env steps total    3447000
Number of rollouts total     0
Train Time (s)               141.8322713621892
(Previous) Eval Time (s)     23.206819413229823
Sample Time (s)              24.534683735109866
Epoch Time (s)               189.5737745105289
Total Train Time (s)         129478.29247385776
Epoch                        688
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:30:56.162586 UTC | [2020_01_11_13_32_55] Iteration #688 | Epoch Duration: 192.88728976249695
2020-01-13 01:30:56.162780 UTC | [2020_01_11_13_32_55] Iteration #688 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3173052
Z variance train             0.33104226
KL Divergence                24.462255
KL Loss                      2.4462256
QF Loss                      14529.771
VF Loss                      3010.4148
Policy Loss                  -1298.7969
Q Predictions Mean           1305.5603
Q Predictions Std            385.77493
Q Predictions Max            1567.0676
Q Predictions Min            -397.91162
V Predictions Mean           1300.0706
V Predictions Std            391.7343
V Predictions Max            1600.7314
V Predictions Min            -430.3452
Log Pis Mean                 2.148728
Log Pis Std                  3.7875621
Log Pis Max                  18.380693
Log Pis Min                  -7.620477
Policy mu Mean               0.09656831
Policy mu Std                0.61429083
Policy mu Max                2.983937
Policy mu Min                -3.3802633
Policy log std Mean          -1.2987231
Policy log std Std           0.40682077
Policy log std Max           -0.10353279
Policy log std Min           -2.9924717
Z mean eval                  1.2621567
Z variance eval              0.017740158
total_rewards                [2291.89136579  151.7134877  3599.05962319 4836.49219326  804.31776616
   54.09490781  238.9038819  3262.08439557 4384.74437157 2617.89267106]
total_rewards_mean           2224.119466401205
total_rewards_std            1719.9146534442737
total_rewards_max            4836.492193261955
total_rewards_min            54.09490781160291
Number of train steps total  2760000
Number of env steps total    3452000
Number of rollouts total     0
Train Time (s)               149.82312565902248
(Previous) Eval Time (s)     26.52005612757057
Sample Time (s)              25.468438657466322
Epoch Time (s)               201.81162044405937
Total Train Time (s)         129675.47043308243
Epoch                        689
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:34:13.346764 UTC | [2020_01_11_13_32_55] Iteration #689 | Epoch Duration: 197.1838526725769
2020-01-13 01:34:13.346946 UTC | [2020_01_11_13_32_55] Iteration #689 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2593099
Z variance train             0.01774013
KL Divergence                27.08454
KL Loss                      2.708454
QF Loss                      6111.326
VF Loss                      1331.372
Policy Loss                  -1371.5187
Q Predictions Mean           1375.4863
Q Predictions Std            381.37604
Q Predictions Max            1653.1394
Q Predictions Min            -320.30566
V Predictions Mean           1363.8115
V Predictions Std            386.07254
V Predictions Max            1650.5417
V Predictions Min            -332.8554
Log Pis Mean                 1.5992175
Log Pis Std                  3.264702
Log Pis Max                  15.4471245
Log Pis Min                  -5.6858473
Policy mu Mean               -0.0066911876
Policy mu Std                0.648901
Policy mu Max                2.570818
Policy mu Min                -2.5880015
Policy log std Mean          -1.1713171
Policy log std Std           0.34819323
Policy log std Max           -0.02132523
Policy log std Min           -2.9183455
Z mean eval                  1.3160475
Z variance eval              0.043775372
total_rewards                [1605.79082338 4141.55826876 4511.78319989 3748.04204294 1376.25887723
 4279.82251826 1366.10305855  322.63389115  490.7409066  3826.43686407]
total_rewards_mean           2566.9170450824545
total_rewards_std            1590.8547981642344
total_rewards_max            4511.783199886294
total_rewards_min            322.6338911538668
Number of train steps total  2764000
Number of env steps total    3457000
Number of rollouts total     0
Train Time (s)               149.26884445175529
(Previous) Eval Time (s)     21.891890704166144
Sample Time (s)              24.443772923666984
Epoch Time (s)               195.6045080795884
Total Train Time (s)         129870.5339685292
Epoch                        690
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:37:28.417496 UTC | [2020_01_11_13_32_55] Iteration #690 | Epoch Duration: 195.0704071521759
2020-01-13 01:37:28.417752 UTC | [2020_01_11_13_32_55] Iteration #690 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3196933
Z variance train             0.044018485
KL Divergence                26.70607
KL Loss                      2.670607
QF Loss                      986.94934
VF Loss                      954.78143
Policy Loss                  -1444.7262
Q Predictions Mean           1449.5436
Q Predictions Std            424.33984
Q Predictions Max            1729.5643
Q Predictions Min            -499.10278
V Predictions Mean           1438.3522
V Predictions Std            419.61465
V Predictions Max            1708.7712
V Predictions Min            -539.2148
Log Pis Mean                 1.6715784
Log Pis Std                  4.1027913
Log Pis Max                  29.664295
Log Pis Min                  -7.5980506
Policy mu Mean               0.02293907
Policy mu Std                0.7142707
Policy mu Max                4.24993
Policy mu Min                -5.3406496
Policy log std Mean          -1.1503167
Policy log std Std           0.33938992
Policy log std Max           -0.2281928
Policy log std Min           -2.634574
Z mean eval                  1.2730526
Z variance eval              0.03464087
total_rewards                [1910.7387601  4616.50936425 2715.48746832 4634.27772158  480.64559441
  787.77616986 2733.37665728 1222.41062158 1549.93657003 1181.58609688]
total_rewards_mean           2183.2745024297988
total_rewards_std            1405.7846284669283
total_rewards_max            4634.277721584575
total_rewards_min            480.64559441322103
Number of train steps total  2768000
Number of env steps total    3462000
Number of rollouts total     0
Train Time (s)               148.38715457497165
(Previous) Eval Time (s)     21.357428070623428
Sample Time (s)              25.94360731774941
Epoch Time (s)               195.68818996334448
Total Train Time (s)         130064.72409079503
Epoch                        691
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:40:42.614233 UTC | [2020_01_11_13_32_55] Iteration #691 | Epoch Duration: 194.1963312625885
2020-01-13 01:40:42.614433 UTC | [2020_01_11_13_32_55] Iteration #691 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2696406
Z variance train             0.034793604
KL Divergence                29.295116
KL Loss                      2.9295118
QF Loss                      1156.0044
VF Loss                      396.94342
Policy Loss                  -1433.6102
Q Predictions Mean           1437.5642
Q Predictions Std            398.46802
Q Predictions Max            1700.2517
Q Predictions Min            -548.11255
V Predictions Mean           1441.3982
V Predictions Std            396.0479
V Predictions Max            1710.8134
V Predictions Min            -511.96454
Log Pis Mean                 1.226677
Log Pis Std                  3.2989225
Log Pis Max                  13.312346
Log Pis Min                  -6.0460024
Policy mu Mean               0.012602003
Policy mu Std                0.7014486
Policy mu Max                3.722172
Policy mu Min                -2.6206787
Policy log std Mean          -1.1056323
Policy log std Std           0.31497678
Policy log std Max           -0.23750687
Policy log std Min           -2.365408
Z mean eval                  1.3069527
Z variance eval              0.013819942
total_rewards                [2793.91114208 3585.41372775 4281.84570632 3821.23416632 4494.99455788
 4388.85945398 1232.94418041 4477.22711273 4376.61751971 4297.94984421]
total_rewards_mean           3775.0997411391363
total_rewards_std            987.0823091520361
total_rewards_max            4494.994557876975
total_rewards_min            1232.9441804052517
Number of train steps total  2772000
Number of env steps total    3467000
Number of rollouts total     0
Train Time (s)               146.38653898099437
(Previous) Eval Time (s)     19.865252395160496
Sample Time (s)              26.059374335687608
Epoch Time (s)               192.31116571184248
Total Train Time (s)         130267.37875219248
Epoch                        692
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:44:05.275475 UTC | [2020_01_11_13_32_55] Iteration #692 | Epoch Duration: 202.66090989112854
2020-01-13 01:44:05.275661 UTC | [2020_01_11_13_32_55] Iteration #692 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3056773
Z variance train             0.0138235185
KL Divergence                31.348028
KL Loss                      3.1348028
QF Loss                      1405.25
VF Loss                      1033.3486
Policy Loss                  -1462.1952
Q Predictions Mean           1466.0947
Q Predictions Std            400.695
Q Predictions Max            1682.1917
Q Predictions Min            -442.31616
V Predictions Mean           1460.7772
V Predictions Std            392.16113
V Predictions Max            1685.9238
V Predictions Min            -441.37076
Log Pis Mean                 1.6630399
Log Pis Std                  3.8974006
Log Pis Max                  22.642008
Log Pis Min                  -6.106996
Policy mu Mean               0.057309695
Policy mu Std                0.72390944
Policy mu Max                3.53635
Policy mu Min                -3.5432498
Policy log std Mean          -1.1142719
Policy log std Std           0.32362583
Policy log std Max           0.28511906
Policy log std Min           -2.9486246
Z mean eval                  1.3945034
Z variance eval              0.021121942
total_rewards                [ 526.78939709 1484.20028092 1065.63237067 4318.70173935  229.6932382
 4444.31471465  541.06742794 2141.59143391    8.87754527  390.39582403]
total_rewards_mean           1515.12639720376
total_rewards_std            1553.942805214509
total_rewards_max            4444.314714653245
total_rewards_min            8.87754527280102
Number of train steps total  2776000
Number of env steps total    3472000
Number of rollouts total     0
Train Time (s)               140.13056197110564
(Previous) Eval Time (s)     30.21455997368321
Sample Time (s)              26.113756815437227
Epoch Time (s)               196.45887876022607
Total Train Time (s)         130448.23925419897
Epoch                        693
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:47:06.142769 UTC | [2020_01_11_13_32_55] Iteration #693 | Epoch Duration: 180.86696553230286
2020-01-13 01:47:06.143004 UTC | [2020_01_11_13_32_55] Iteration #693 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3923218
Z variance train             0.020960532
KL Divergence                31.239437
KL Loss                      3.1239438
QF Loss                      4042.526
VF Loss                      613.5826
Policy Loss                  -1493.1738
Q Predictions Mean           1495.7456
Q Predictions Std            322.63153
Q Predictions Max            1716.5104
Q Predictions Min            -215.0228
V Predictions Mean           1499.735
V Predictions Std            315.9108
V Predictions Max            1728.92
V Predictions Min            -243.8285
Log Pis Mean                 1.3977315
Log Pis Std                  3.458771
Log Pis Max                  15.438501
Log Pis Min                  -8.062653
Policy mu Mean               0.023129731
Policy mu Std                0.71290874
Policy mu Max                3.1845174
Policy mu Min                -3.1130211
Policy log std Mean          -1.1093911
Policy log std Std           0.33658528
Policy log std Max           -0.13463283
Policy log std Min           -3.5858822
Z mean eval                  1.3081828
Z variance eval              0.01477057
total_rewards                [2013.48390572 2157.43902053  677.74866591 2433.46249323  569.74090455
 3033.38866506  972.67398094  800.73570263  575.62948714  696.4096799 ]
total_rewards_mean           1393.0712505609101
total_rewards_std            872.5209460857228
total_rewards_max            3033.388665055815
total_rewards_min            569.7409045543909
Number of train steps total  2780000
Number of env steps total    3477000
Number of rollouts total     0
Train Time (s)               138.79029162228107
(Previous) Eval Time (s)     14.62232234608382
Sample Time (s)              22.421608129981905
Epoch Time (s)               175.8342220983468
Total Train Time (s)         130623.77075137105
Epoch                        694
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:50:01.680377 UTC | [2020_01_11_13_32_55] Iteration #694 | Epoch Duration: 175.53723454475403
2020-01-13 01:50:01.680549 UTC | [2020_01_11_13_32_55] Iteration #694 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3099544
Z variance train             0.014823702
KL Divergence                31.267984
KL Loss                      3.1267984
QF Loss                      1335.2562
VF Loss                      266.49365
Policy Loss                  -1460.3387
Q Predictions Mean           1463.6973
Q Predictions Std            385.7758
Q Predictions Max            1704.0358
Q Predictions Min            -444.28656
V Predictions Mean           1463.5088
V Predictions Std            383.649
V Predictions Max            1699.3817
V Predictions Min            -427.8302
Log Pis Mean                 1.4864589
Log Pis Std                  3.4233518
Log Pis Max                  11.515924
Log Pis Min                  -8.794769
Policy mu Mean               0.011468126
Policy mu Std                0.7054649
Policy mu Max                2.8776355
Policy mu Min                -2.6696181
Policy log std Mean          -1.1302795
Policy log std Std           0.3178407
Policy log std Max           -0.22766542
Policy log std Min           -2.6577313
Z mean eval                  1.3109397
Z variance eval              0.015596191
total_rewards                [ 728.20548194 3869.0340236  1086.32677075 2936.07454882 3117.11488034
 3122.37905472  638.57972469 1319.38630173 3153.38553219 4366.8989256 ]
total_rewards_mean           2433.7385244373786
total_rewards_std            1292.183501404808
total_rewards_max            4366.898925596522
total_rewards_min            638.5797246853933
Number of train steps total  2784000
Number of env steps total    3482000
Number of rollouts total     0
Train Time (s)               143.67724050022662
(Previous) Eval Time (s)     14.325015624985099
Sample Time (s)              24.778714747168124
Epoch Time (s)               182.78097087237984
Total Train Time (s)         130814.3566771308
Epoch                        695
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:53:12.273165 UTC | [2020_01_11_13_32_55] Iteration #695 | Epoch Duration: 190.59248185157776
2020-01-13 01:53:12.273353 UTC | [2020_01_11_13_32_55] Iteration #695 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3104398
Z variance train             0.01560235
KL Divergence                31.03512
KL Loss                      3.103512
QF Loss                      936.8259
VF Loss                      2295.3967
Policy Loss                  -1487.2175
Q Predictions Mean           1491.0483
Q Predictions Std            348.09366
Q Predictions Max            1698.912
Q Predictions Min            -369.30997
V Predictions Mean           1488.7007
V Predictions Std            336.9493
V Predictions Max            1700.6332
V Predictions Min            -357.7028
Log Pis Mean                 1.7578377
Log Pis Std                  3.5056536
Log Pis Max                  24.996578
Log Pis Min                  -6.480788
Policy mu Mean               0.0013884865
Policy mu Std                0.6968887
Policy mu Max                3.014364
Policy mu Min                -3.4720364
Policy log std Mean          -1.1433823
Policy log std Std           0.33283013
Policy log std Max           -0.051697493
Policy log std Min           -3.0883708
Z mean eval                  1.3083897
Z variance eval              0.011354121
total_rewards                [4487.86266632 4116.66567963  122.62450436 1124.13372668 3770.02661696
 4362.73271272 4554.49115051 4339.64394916 1684.58137134 2782.94752819]
total_rewards_mean           3134.5709905887156
total_rewards_std            1533.5010950736394
total_rewards_max            4554.491150512869
total_rewards_min            122.62450436470041
Number of train steps total  2788000
Number of env steps total    3487000
Number of rollouts total     0
Train Time (s)               148.91952731180936
(Previous) Eval Time (s)     22.136212499812245
Sample Time (s)              25.089684141799808
Epoch Time (s)               196.1454239534214
Total Train Time (s)         131014.04368321784
Epoch                        696
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:56:31.971866 UTC | [2020_01_11_13_32_55] Iteration #696 | Epoch Duration: 199.69837522506714
2020-01-13 01:56:31.972054 UTC | [2020_01_11_13_32_55] Iteration #696 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3105129
Z variance train             0.011368015
KL Divergence                31.537058
KL Loss                      3.1537058
QF Loss                      983.6071
VF Loss                      260.4397
Policy Loss                  -1478.7925
Q Predictions Mean           1482.3695
Q Predictions Std            391.54123
Q Predictions Max            1738.0177
Q Predictions Min            -361.41315
V Predictions Mean           1474.3591
V Predictions Std            391.05753
V Predictions Max            1697.623
V Predictions Min            -388.6731
Log Pis Mean                 1.3855398
Log Pis Std                  3.5437376
Log Pis Max                  21.12365
Log Pis Min                  -5.460368
Policy mu Mean               0.036447912
Policy mu Std                0.7121798
Policy mu Max                3.9032843
Policy mu Min                -2.6623304
Policy log std Mean          -1.0844495
Policy log std Std           0.32488462
Policy log std Max           -0.14652371
Policy log std Min           -2.8782434
Z mean eval                  1.2841276
Z variance eval              0.01180433
total_rewards                [4297.4646749  1935.21304712 1083.17054111 4419.01806826 4429.42428986
 4363.47987826    8.32668261   84.20981921 4205.10704092 1629.29983659]
total_rewards_mean           2645.471387883852
total_rewards_std            1786.9947575571537
total_rewards_max            4429.424289860742
total_rewards_min            8.326682606879404
Number of train steps total  2792000
Number of env steps total    3492000
Number of rollouts total     0
Train Time (s)               148.05630303686485
(Previous) Eval Time (s)     25.688801856245846
Sample Time (s)              25.343935484997928
Epoch Time (s)               199.08904037810862
Total Train Time (s)         131212.72056803387
Epoch                        697
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:59:50.655235 UTC | [2020_01_11_13_32_55] Iteration #697 | Epoch Duration: 198.68303084373474
2020-01-13 01:59:50.655416 UTC | [2020_01_11_13_32_55] Iteration #697 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.284579
Z variance train             0.011680109
KL Divergence                30.735106
KL Loss                      3.0735106
QF Loss                      1165.1306
VF Loss                      284.449
Policy Loss                  -1445.6859
Q Predictions Mean           1451.2305
Q Predictions Std            393.20184
Q Predictions Max            1700.2616
Q Predictions Min            -268.19928
V Predictions Mean           1440.803
V Predictions Std            394.8895
V Predictions Max            1689.8369
V Predictions Min            -285.3313
Log Pis Mean                 1.5858984
Log Pis Std                  3.2153187
Log Pis Max                  14.063482
Log Pis Min                  -9.220131
Policy mu Mean               -0.021780388
Policy mu Std                0.70836776
Policy mu Max                2.5489283
Policy mu Min                -3.4162838
Policy log std Mean          -1.1054033
Policy log std Std           0.32416195
Policy log std Max           0.041060448
Policy log std Min           -2.7704172
Z mean eval                  1.2634336
Z variance eval              0.010336306
total_rewards                [1349.46429317 4381.77347    4583.32113066  336.98946861 4586.50690171
  107.86468405  433.63563992 3226.49159128 2404.09557434 4474.19978486]
total_rewards_mean           2588.4342538590217
total_rewards_std            1805.147520172422
total_rewards_max            4586.506901709378
total_rewards_min            107.86468404619674
Number of train steps total  2796000
Number of env steps total    3497000
Number of rollouts total     0
Train Time (s)               150.23212925810367
(Previous) Eval Time (s)     25.28233302384615
Sample Time (s)              25.93076090142131
Epoch Time (s)               201.44522318337113
Total Train Time (s)         131413.39235358592
Epoch                        698
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:03:11.334600 UTC | [2020_01_11_13_32_55] Iteration #698 | Epoch Duration: 200.67900896072388
2020-01-13 02:03:11.335350 UTC | [2020_01_11_13_32_55] Iteration #698 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2618612
Z variance train             0.010311676
KL Divergence                30.494045
KL Loss                      3.0494046
QF Loss                      1279.7234
VF Loss                      272.01477
Policy Loss                  -1469.6351
Q Predictions Mean           1473.8383
Q Predictions Std            369.97998
Q Predictions Max            1721.4856
Q Predictions Min            -382.97156
V Predictions Mean           1473.2172
V Predictions Std            370.61023
V Predictions Max            1712.4982
V Predictions Min            -403.01593
Log Pis Mean                 1.9996324
Log Pis Std                  3.4561393
Log Pis Max                  16.54562
Log Pis Min                  -6.2553644
Policy mu Mean               -0.0039164424
Policy mu Std                0.746016
Policy mu Max                4.948384
Policy mu Min                -3.0475192
Policy log std Mean          -1.1270635
Policy log std Std           0.36856696
Policy log std Max           -0.06147802
Policy log std Min           -3.2376304
Z mean eval                  1.3172965
Z variance eval              0.0077595464
total_rewards                [4201.30109503 4138.58544653 4328.12683398 4533.51328196 2029.43640955
 4085.23971064  611.3690546   638.59164596 4188.63798584  756.47152193]
total_rewards_mean           2951.1272986019007
total_rewards_std            1633.371544304659
total_rewards_max            4533.513281960258
total_rewards_min            611.3690546025283
Number of train steps total  2800000
Number of env steps total    3502000
Number of rollouts total     0
Train Time (s)               146.15672761993483
(Previous) Eval Time (s)     24.515713409986347
Sample Time (s)              25.484606111887842
Epoch Time (s)               196.15704714180902
Total Train Time (s)         131612.5092722224
Epoch                        699
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:06:30.457396 UTC | [2020_01_11_13_32_55] Iteration #699 | Epoch Duration: 199.12166714668274
2020-01-13 02:06:30.457583 UTC | [2020_01_11_13_32_55] Iteration #699 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3188746
Z variance train             0.0076654614
KL Divergence                31.982498
KL Loss                      3.1982498
QF Loss                      1210.996
VF Loss                      272.70337
Policy Loss                  -1441.4539
Q Predictions Mean           1446.3014
Q Predictions Std            431.9392
Q Predictions Max            1739.644
Q Predictions Min            -401.4758
V Predictions Mean           1449.3052
V Predictions Std            435.06403
V Predictions Max            1742.5875
V Predictions Min            -443.86154
Log Pis Mean                 1.5617998
Log Pis Std                  3.9436843
Log Pis Max                  23.526686
Log Pis Min                  -9.133554
Policy mu Mean               0.019419484
Policy mu Std                0.71705246
Policy mu Max                4.25654
Policy mu Min                -4.3865356
Policy log std Mean          -1.1278667
Policy log std Std           0.34471434
Policy log std Max           0.8354176
Policy log std Min           -3.0738306
Z mean eval                  1.2850983
Z variance eval              0.016451603
total_rewards                [2064.77360966  958.38151514 1418.14549769 1391.05731257  512.40838769
 2131.32384328 1093.31636881 4337.02468806 4584.68413577 2985.48656027]
total_rewards_mean           2147.6601918932365
total_rewards_std            1332.1488438938488
total_rewards_max            4584.684135767105
total_rewards_min            512.4083876942623
Number of train steps total  2804000
Number of env steps total    3507000
Number of rollouts total     0
Train Time (s)               140.43556250771508
(Previous) Eval Time (s)     27.479949763044715
Sample Time (s)              24.192363364156336
Epoch Time (s)               192.10787563491613
Total Train Time (s)         131793.6451395657
Epoch                        700
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:09:31.599386 UTC | [2020_01_11_13_32_55] Iteration #700 | Epoch Duration: 181.14167070388794
2020-01-13 02:09:31.599584 UTC | [2020_01_11_13_32_55] Iteration #700 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2859409
Z variance train             0.016472917
KL Divergence                31.422718
KL Loss                      3.1422718
QF Loss                      985.56537
VF Loss                      226.11378
Policy Loss                  -1487.7944
Q Predictions Mean           1491.3074
Q Predictions Std            366.4556
Q Predictions Max            1721.3802
Q Predictions Min            -415.17688
V Predictions Mean           1483.7349
V Predictions Std            368.75253
V Predictions Max            1722.9102
V Predictions Min            -440.02832
Log Pis Mean                 1.0446951
Log Pis Std                  3.2979095
Log Pis Max                  12.732624
Log Pis Min                  -9.801536
Policy mu Mean               -0.02190254
Policy mu Std                0.6897593
Policy mu Max                2.4124427
Policy mu Min                -2.7152371
Policy log std Mean          -1.0906507
Policy log std Std           0.32937485
Policy log std Max           -0.20788145
Policy log std Min           -3.3381383
Z mean eval                  1.2832637
Z variance eval              0.021189101
total_rewards                [3730.88689061 4598.60786623 4428.15773944 3696.03480799 1314.37636926
 4297.47324365 1756.98411568 4644.16952732  844.64365975  862.31066608]
total_rewards_mean           3017.364488600364
total_rewards_std            1536.2047029076227
total_rewards_max            4644.169527315061
total_rewards_min            844.6436597533526
Number of train steps total  2808000
Number of env steps total    3512000
Number of rollouts total     0
Train Time (s)               139.94229433173314
(Previous) Eval Time (s)     16.51337897218764
Sample Time (s)              23.15843919152394
Epoch Time (s)               179.61411249544472
Total Train Time (s)         131983.44270043774
Epoch                        701
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:12:41.404167 UTC | [2020_01_11_13_32_55] Iteration #701 | Epoch Duration: 189.8044502735138
2020-01-13 02:12:41.404374 UTC | [2020_01_11_13_32_55] Iteration #701 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2834047
Z variance train             0.021152528
KL Divergence                29.457895
KL Loss                      2.9457896
QF Loss                      1548.6284
VF Loss                      679.839
Policy Loss                  -1460.0912
Q Predictions Mean           1466.2571
Q Predictions Std            400.5503
Q Predictions Max            1725.8251
Q Predictions Min            -357.38297
V Predictions Mean           1456.6775
V Predictions Std            400.52646
V Predictions Max            1723.9329
V Predictions Min            -378.1796
Log Pis Mean                 1.7553324
Log Pis Std                  3.3745313
Log Pis Max                  17.942562
Log Pis Min                  -5.117771
Policy mu Mean               -0.0016768926
Policy mu Std                0.7043752
Policy mu Max                3.7215037
Policy mu Min                -2.681885
Policy log std Mean          -1.1281574
Policy log std Std           0.3309791
Policy log std Max           0.41382897
Policy log std Min           -2.6669781
Z mean eval                  1.3178494
Z variance eval              0.010494092
total_rewards                [ 727.81325465  144.95117842 4115.46746576  160.67447672 3982.24017169
 3846.43533153 3762.47128044 4343.03588521 1601.09263674  103.03711426]
total_rewards_mean           2278.721879540613
total_rewards_std            1784.192936408702
total_rewards_max            4343.035885210354
total_rewards_min            103.03711425641514
Number of train steps total  2812000
Number of env steps total    3517000
Number of rollouts total     0
Train Time (s)               148.3040381288156
(Previous) Eval Time (s)     26.703356723766774
Sample Time (s)              26.134827200789005
Epoch Time (s)               201.14222205337137
Total Train Time (s)         132178.2656001211
Epoch                        702
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:15:56.233829 UTC | [2020_01_11_13_32_55] Iteration #702 | Epoch Duration: 194.82931518554688
2020-01-13 02:15:56.234027 UTC | [2020_01_11_13_32_55] Iteration #702 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3181448
Z variance train             0.01049705
KL Divergence                30.97471
KL Loss                      3.097471
QF Loss                      1173.8685
VF Loss                      441.08392
Policy Loss                  -1465.7946
Q Predictions Mean           1467.9373
Q Predictions Std            406.7208
Q Predictions Max            1719.5913
Q Predictions Min            -416.1913
V Predictions Mean           1470.7671
V Predictions Std            408.31244
V Predictions Max            1731.6954
V Predictions Min            -435.2418
Log Pis Mean                 1.3459305
Log Pis Std                  3.7705078
Log Pis Max                  34.46609
Log Pis Min                  -6.67844
Policy mu Mean               0.03924514
Policy mu Std                0.75280434
Policy mu Max                4.653796
Policy mu Min                -6.030017
Policy log std Mean          -1.0503232
Policy log std Std           0.31839624
Policy log std Max           1.4711691
Policy log std Min           -2.5756283
Z mean eval                  1.3183186
Z variance eval              0.012710777
total_rewards                [2204.19809369 2642.30345449  259.65768565 4416.20453926  186.96746443
 2255.34742181  507.04137789 4479.29785543 4461.68867961 1952.73577489]
total_rewards_mean           2336.544234715463
total_rewards_std            1611.7922869571319
total_rewards_max            4479.297855432378
total_rewards_min            186.96746443346962
Number of train steps total  2816000
Number of env steps total    3522000
Number of rollouts total     0
Train Time (s)               147.03569470718503
(Previous) Eval Time (s)     20.390014769043773
Sample Time (s)              24.64084948413074
Epoch Time (s)               192.06655896035954
Total Train Time (s)         132368.56811256846
Epoch                        703
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:19:06.542841 UTC | [2020_01_11_13_32_55] Iteration #703 | Epoch Duration: 190.30867314338684
2020-01-13 02:19:06.543044 UTC | [2020_01_11_13_32_55] Iteration #703 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3187662
Z variance train             0.0127326995
KL Divergence                28.814163
KL Loss                      2.8814163
QF Loss                      4414.038
VF Loss                      521.37164
Policy Loss                  -1478.8326
Q Predictions Mean           1484.2661
Q Predictions Std            397.154
Q Predictions Max            1703.3345
Q Predictions Min            -417.1897
V Predictions Mean           1477.4159
V Predictions Std            398.25238
V Predictions Max            1707.6105
V Predictions Min            -504.57538
Log Pis Mean                 1.9760451
Log Pis Std                  4.1816173
Log Pis Max                  28.163176
Log Pis Min                  -7.199539
Policy mu Mean               0.03620188
Policy mu Std                0.73146236
Policy mu Max                5.1798177
Policy mu Min                -3.4870927
Policy log std Mean          -1.1646504
Policy log std Std           0.35341793
Policy log std Max           0.0311414
Policy log std Min           -3.3773017
Z mean eval                  1.3287908
Z variance eval              0.009866009
total_rewards                [3011.75459326  264.29895824 1651.62284426 1166.44532622  601.57882112
 2742.15389208  626.6732543  4563.15142223 4438.81633279 1883.08458065]
total_rewards_mean           2094.958002513321
total_rewards_std            1472.6152027917205
total_rewards_max            4563.151422228142
total_rewards_min            264.29895823743107
Number of train steps total  2820000
Number of env steps total    3527000
Number of rollouts total     0
Train Time (s)               146.1648326390423
(Previous) Eval Time (s)     18.631687585730106
Sample Time (s)              24.39599504414946
Epoch Time (s)               189.19251526892185
Total Train Time (s)         132556.31336266082
Epoch                        704
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:22:14.296030 UTC | [2020_01_11_13_32_55] Iteration #704 | Epoch Duration: 187.75281953811646
2020-01-13 02:22:14.296365 UTC | [2020_01_11_13_32_55] Iteration #704 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3273968
Z variance train             0.009843904
KL Divergence                31.310448
KL Loss                      3.1310449
QF Loss                      1329.4065
VF Loss                      589.7884
Policy Loss                  -1443.239
Q Predictions Mean           1448.3462
Q Predictions Std            474.95142
Q Predictions Max            1750.3793
Q Predictions Min            -460.82327
V Predictions Mean           1442.7644
V Predictions Std            471.29956
V Predictions Max            1742.7025
V Predictions Min            -442.3864
Log Pis Mean                 1.4885454
Log Pis Std                  3.7545319
Log Pis Max                  15.693034
Log Pis Min                  -5.9348373
Policy mu Mean               0.012877801
Policy mu Std                0.7234146
Policy mu Max                3.5073829
Policy mu Min                -2.6766734
Policy log std Mean          -1.0839003
Policy log std Std           0.33287627
Policy log std Max           0.8232111
Policy log std Min           -2.8636408
Z mean eval                  1.3015354
Z variance eval              0.01674081
total_rewards                [ 351.23208156 3970.67809969 1224.81470313 1999.18460196 4492.46904659
 4144.52131217 4429.07867267  253.93118372 1576.32998766  318.97734288]
total_rewards_mean           2276.1217032036247
total_rewards_std            1708.9872834491339
total_rewards_max            4492.469046592123
total_rewards_min            253.9311837202609
Number of train steps total  2824000
Number of env steps total    3532000
Number of rollouts total     0
Train Time (s)               148.17275452893227
(Previous) Eval Time (s)     17.191624683793634
Sample Time (s)              26.448484594468027
Epoch Time (s)               191.81286380719393
Total Train Time (s)         132749.58809036855
Epoch                        705
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:25:27.577009 UTC | [2020_01_11_13_32_55] Iteration #705 | Epoch Duration: 193.28049087524414
2020-01-13 02:25:27.577263 UTC | [2020_01_11_13_32_55] Iteration #705 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2973707
Z variance train             0.016835744
KL Divergence                30.808867
KL Loss                      3.0808866
QF Loss                      1457.6494
VF Loss                      308.1599
Policy Loss                  -1525.2018
Q Predictions Mean           1530.2952
Q Predictions Std            302.53915
Q Predictions Max            1728.7794
Q Predictions Min            -409.64478
V Predictions Mean           1528.0653
V Predictions Std            304.0071
V Predictions Max            1729.3208
V Predictions Min            -424.20154
Log Pis Mean                 1.7128661
Log Pis Std                  3.2537208
Log Pis Max                  18.669455
Log Pis Min                  -7.876313
Policy mu Mean               0.028313484
Policy mu Std                0.69240046
Policy mu Max                2.6892989
Policy mu Min                -2.774291
Policy log std Mean          -1.1563973
Policy log std Std           0.30059558
Policy log std Max           -0.18496656
Policy log std Min           -3.0907502
Z mean eval                  1.3059313
Z variance eval              0.011356306
total_rewards                [ 266.40991581  300.31790505  529.78824176 4299.17254264  927.16188712
 2743.74820235   11.25916959 4416.1772044  4253.6343818  2797.8448137 ]
total_rewards_mean           2054.5514264218045
total_rewards_std            1747.1342784586768
total_rewards_max            4416.177204401084
total_rewards_min            11.259169592479088
Number of train steps total  2828000
Number of env steps total    3537000
Number of rollouts total     0
Train Time (s)               143.35931746009737
(Previous) Eval Time (s)     18.65882821381092
Sample Time (s)              25.809540953021497
Epoch Time (s)               187.8276866269298
Total Train Time (s)         132935.48080902267
Epoch                        706
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:28:33.476195 UTC | [2020_01_11_13_32_55] Iteration #706 | Epoch Duration: 185.89877700805664
2020-01-13 02:28:33.476429 UTC | [2020_01_11_13_32_55] Iteration #706 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3069463
Z variance train             0.011351882
KL Divergence                30.716137
KL Loss                      3.0716138
QF Loss                      1351.756
VF Loss                      318.17545
Policy Loss                  -1496.4012
Q Predictions Mean           1498.3368
Q Predictions Std            362.4553
Q Predictions Max            1728.4624
Q Predictions Min            -425.96466
V Predictions Mean           1500.6704
V Predictions Std            345.40234
V Predictions Max            1723.9863
V Predictions Min            -411.44012
Log Pis Mean                 1.3906641
Log Pis Std                  3.465928
Log Pis Max                  18.227505
Log Pis Min                  -10.413708
Policy mu Mean               0.028233638
Policy mu Std                0.7206963
Policy mu Max                3.8780077
Policy mu Min                -3.3752074
Policy log std Mean          -1.1319977
Policy log std Std           0.31354302
Policy log std Max           0.0037060976
Policy log std Min           -2.7899542
Z mean eval                  1.3416231
Z variance eval              0.010353478
total_rewards                [4228.09012446 3519.49382404   55.43400162 4371.57264381 4158.8662829
  161.86985946  342.14125825 4453.50591209    8.98455639 2732.07058263]
total_rewards_mean           2403.202904564065
total_rewards_std            1906.8533696206944
total_rewards_max            4453.505912087034
total_rewards_min            8.984556394623196
Number of train steps total  2832000
Number of env steps total    3542000
Number of rollouts total     0
Train Time (s)               140.1452309419401
(Previous) Eval Time (s)     16.729504246730357
Sample Time (s)              23.91127405455336
Epoch Time (s)               180.78600924322382
Total Train Time (s)         133122.64373712242
Epoch                        707
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:31:40.644267 UTC | [2020_01_11_13_32_55] Iteration #707 | Epoch Duration: 187.1677122116089
2020-01-13 02:31:40.644417 UTC | [2020_01_11_13_32_55] Iteration #707 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.344218
Z variance train             0.010298558
KL Divergence                30.339207
KL Loss                      3.0339208
QF Loss                      2583.0747
VF Loss                      835.3393
Policy Loss                  -1477.4728
Q Predictions Mean           1479.9281
Q Predictions Std            402.2216
Q Predictions Max            1749.3832
Q Predictions Min            -418.27176
V Predictions Mean           1473.3755
V Predictions Std            396.0465
V Predictions Max            1750.5239
V Predictions Min            -400.72906
Log Pis Mean                 1.7674884
Log Pis Std                  4.1292505
Log Pis Max                  32.6361
Log Pis Min                  -6.7830563
Policy mu Mean               -0.003222996
Policy mu Std                0.7155836
Policy mu Max                3.0553937
Policy mu Min                -4.7745028
Policy log std Mean          -1.1314045
Policy log std Std           0.36174792
Policy log std Max           -0.15740931
Policy log std Min           -2.9787169
Z mean eval                  1.3067049
Z variance eval              0.009686729
total_rewards                [4229.88497046 4413.59113868  159.46126707 4294.26978273 2155.1977121
  136.95807146 4341.76572314 3178.89696629  389.56643536 1747.43514738]
total_rewards_mean           2504.70272146816
total_rewards_std            1729.9647119640013
total_rewards_max            4413.591138682294
total_rewards_min            136.95807146280427
Number of train steps total  2836000
Number of env steps total    3547000
Number of rollouts total     0
Train Time (s)               142.2661292408593
(Previous) Eval Time (s)     23.110889190342277
Sample Time (s)              24.417158574331552
Epoch Time (s)               189.79417700553313
Total Train Time (s)         133316.1263528089
Epoch                        708
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:34:54.133648 UTC | [2020_01_11_13_32_55] Iteration #708 | Epoch Duration: 193.48911237716675
2020-01-13 02:34:54.133839 UTC | [2020_01_11_13_32_55] Iteration #708 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3063811
Z variance train             0.009729375
KL Divergence                31.685793
KL Loss                      3.1685793
QF Loss                      1010.7523
VF Loss                      307.5132
Policy Loss                  -1436.5709
Q Predictions Mean           1442.1001
Q Predictions Std            454.23105
Q Predictions Max            1733.3822
Q Predictions Min            -442.81693
V Predictions Mean           1441.6251
V Predictions Std            450.35788
V Predictions Max            1739.0986
V Predictions Min            -409.10037
Log Pis Mean                 1.2682822
Log Pis Std                  3.2842493
Log Pis Max                  12.109476
Log Pis Min                  -7.054817
Policy mu Mean               -0.0021879298
Policy mu Std                0.70708936
Policy mu Max                3.5964015
Policy mu Min                -2.9438267
Policy log std Mean          -1.0886867
Policy log std Std           0.31966537
Policy log std Max           0.009405851
Policy log std Min           -2.5141525
Z mean eval                  1.3240126
Z variance eval              0.0048608123
total_rewards                [ -75.56685567 1399.65695489 2107.27986574 4529.78838373  297.74432771
 4532.73972427 4535.99328757 1503.83555466  369.0927928  4318.88621641]
total_rewards_mean           2351.9450252105535
total_rewards_std            1840.327480962092
total_rewards_max            4535.99328757181
total_rewards_min            -75.56685566855089
Number of train steps total  2840000
Number of env steps total    3552000
Number of rollouts total     0
Train Time (s)               150.81094528688118
(Previous) Eval Time (s)     26.805425392929465
Sample Time (s)              26.27422812161967
Epoch Time (s)               203.89059880143031
Total Train Time (s)         133515.99210429844
Epoch                        709
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:38:14.003363 UTC | [2020_01_11_13_32_55] Iteration #709 | Epoch Duration: 199.86940836906433
2020-01-13 02:38:14.003484 UTC | [2020_01_11_13_32_55] Iteration #709 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3235874
Z variance train             0.004849716
KL Divergence                32.301136
KL Loss                      3.2301137
QF Loss                      3309.9873
VF Loss                      1204.3562
Policy Loss                  -1490.1793
Q Predictions Mean           1496.114
Q Predictions Std            360.74246
Q Predictions Max            1730.6499
Q Predictions Min            -132.01865
V Predictions Mean           1498.7916
V Predictions Std            356.23984
V Predictions Max            1733.856
V Predictions Min            -146.2568
Log Pis Mean                 1.3143495
Log Pis Std                  3.3543422
Log Pis Max                  20.35827
Log Pis Min                  -5.613309
Policy mu Mean               0.0040286044
Policy mu Std                0.68229467
Policy mu Max                3.4821541
Policy mu Min                -2.7078552
Policy log std Mean          -1.1025747
Policy log std Std           0.32697174
Policy log std Max           -0.20677531
Policy log std Min           -2.8713708
Z mean eval                  1.2900584
Z variance eval              0.0066583552
total_rewards                [3818.92955396 4337.65901637 4587.38368957 4423.84904917 4301.50981296
 2024.93717981 4571.40021765 1838.62427756 4439.38291055 4420.74724526]
total_rewards_mean           3876.4422952865307
total_rewards_std            993.9171388411454
total_rewards_max            4587.3836895697805
total_rewards_min            1838.624277562405
Number of train steps total  2844000
Number of env steps total    3557000
Number of rollouts total     0
Train Time (s)               148.02240462508053
(Previous) Eval Time (s)     22.783819830976427
Sample Time (s)              25.806583704426885
Epoch Time (s)               196.61280816048384
Total Train Time (s)         133723.0103130429
Epoch                        710
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:41:41.028004 UTC | [2020_01_11_13_32_55] Iteration #710 | Epoch Duration: 207.02440309524536
2020-01-13 02:41:41.028285 UTC | [2020_01_11_13_32_55] Iteration #710 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2890596
Z variance train             0.006664303
KL Divergence                30.60081
KL Loss                      3.060081
QF Loss                      4211.536
VF Loss                      573.9868
Policy Loss                  -1488.6649
Q Predictions Mean           1491.9539
Q Predictions Std            349.11996
Q Predictions Max            1725.8673
Q Predictions Min            -402.21872
V Predictions Mean           1478.3654
V Predictions Std            347.9057
V Predictions Max            1711.0023
V Predictions Min            -406.9292
Log Pis Mean                 1.3926721
Log Pis Std                  3.272543
Log Pis Max                  14.693027
Log Pis Min                  -6.8755054
Policy mu Mean               0.007880697
Policy mu Std                0.7151873
Policy mu Max                5.3020406
Policy mu Min                -3.3008776
Policy log std Mean          -1.1178489
Policy log std Std           0.31541738
Policy log std Max           1.3036609
Policy log std Min           -2.5613792
Z mean eval                  1.3206203
Z variance eval              0.009118265
total_rewards                [2182.2200545  1283.71436515 4216.5170707  4480.80783964  869.75089318
 4505.38226193   14.75359303 3692.31756857 1292.70093213 4502.092498  ]
total_rewards_mean           2704.025707682564
total_rewards_std            1666.6549421279192
total_rewards_max            4505.382261925106
total_rewards_min            14.753593031848776
Number of train steps total  2848000
Number of env steps total    3562000
Number of rollouts total     0
Train Time (s)               150.6436158050783
(Previous) Eval Time (s)     33.19504604488611
Sample Time (s)              24.864120660815388
Epoch Time (s)               208.7027825107798
Total Train Time (s)         133921.4755268246
Epoch                        711
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:44:59.499717 UTC | [2020_01_11_13_32_55] Iteration #711 | Epoch Duration: 198.4712679386139
2020-01-13 02:44:59.499961 UTC | [2020_01_11_13_32_55] Iteration #711 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3232616
Z variance train             0.009143545
KL Divergence                30.700886
KL Loss                      3.0700886
QF Loss                      2654.9106
VF Loss                      957.97095
Policy Loss                  -1433.2975
Q Predictions Mean           1435.574
Q Predictions Std            463.7467
Q Predictions Max            1705.7406
Q Predictions Min            -434.74738
V Predictions Mean           1419.2803
V Predictions Std            462.91428
V Predictions Max            1692.175
V Predictions Min            -436.97348
Log Pis Mean                 1.2994461
Log Pis Std                  3.6076615
Log Pis Max                  22.882332
Log Pis Min                  -6.9163594
Policy mu Mean               0.014836949
Policy mu Std                0.6941224
Policy mu Max                4.573289
Policy mu Min                -2.9081233
Policy log std Mean          -1.1328177
Policy log std Std           0.356689
Policy log std Max           0.514436
Policy log std Min           -3.1050425
Z mean eval                  1.3416059
Z variance eval              0.014628167
total_rewards                [2934.50551481  739.83245761 1120.20816582  100.66785108 4339.8274351
 4170.13016295 4185.79256521 2626.9485167  4126.63517237 2063.45537802]
total_rewards_mean           2640.800321965807
total_rewards_std            1503.934281192399
total_rewards_max            4339.827435102773
total_rewards_min            100.66785108293017
Number of train steps total  2852000
Number of env steps total    3567000
Number of rollouts total     0
Train Time (s)               148.65155009925365
(Previous) Eval Time (s)     22.9631943278946
Sample Time (s)              24.08286144863814
Epoch Time (s)               195.6976058757864
Total Train Time (s)         134116.65956081124
Epoch                        712
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:48:14.690286 UTC | [2020_01_11_13_32_55] Iteration #712 | Epoch Duration: 195.19017028808594
2020-01-13 02:48:14.690490 UTC | [2020_01_11_13_32_55] Iteration #712 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3409455
Z variance train             0.014636816
KL Divergence                31.60853
KL Loss                      3.1608531
QF Loss                      1606.8638
VF Loss                      578.1851
Policy Loss                  -1426.4633
Q Predictions Mean           1424.0176
Q Predictions Std            484.50375
Q Predictions Max            1722.491
Q Predictions Min            -381.9909
V Predictions Mean           1423.8093
V Predictions Std            472.6467
V Predictions Max            1706.5034
V Predictions Min            -366.35522
Log Pis Mean                 1.879102
Log Pis Std                  4.001284
Log Pis Max                  20.183172
Log Pis Min                  -7.7754507
Policy mu Mean               0.046064716
Policy mu Std                0.71835244
Policy mu Max                3.0221107
Policy mu Min                -3.6810231
Policy log std Mean          -1.1401179
Policy log std Std           0.38943908
Policy log std Max           -0.119540095
Policy log std Min           -3.10753
Z mean eval                  1.3203595
Z variance eval              0.009382062
total_rewards                [4164.82397966 4430.11592338 3965.67593192 4436.40648885 4419.31853236
 3150.39099205 4505.84949055 4493.20806877  758.84307834 4240.61303108]
total_rewards_mean           3856.524551694656
total_rewards_std            1102.621313055583
total_rewards_max            4505.84949055164
total_rewards_min            758.843078336756
Number of train steps total  2856000
Number of env steps total    3572000
Number of rollouts total     0
Train Time (s)               140.07948862900957
(Previous) Eval Time (s)     22.45542911021039
Sample Time (s)              24.308015586342663
Epoch Time (s)               186.84293332556263
Total Train Time (s)         134311.78172378568
Epoch                        713
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:51:29.819721 UTC | [2020_01_11_13_32_55] Iteration #713 | Epoch Duration: 195.12908601760864
2020-01-13 02:51:29.819943 UTC | [2020_01_11_13_32_55] Iteration #713 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3217914
Z variance train             0.009362245
KL Divergence                31.747715
KL Loss                      3.1747715
QF Loss                      5258.6074
VF Loss                      899.2423
Policy Loss                  -1485.7653
Q Predictions Mean           1493.1233
Q Predictions Std            328.6165
Q Predictions Max            1760.5425
Q Predictions Min            -282.28967
V Predictions Mean           1487.0737
V Predictions Std            334.59375
V Predictions Max            1726.752
V Predictions Min            -298.50043
Log Pis Mean                 1.7475973
Log Pis Std                  3.9716544
Log Pis Max                  31.033176
Log Pis Min                  -5.619062
Policy mu Mean               0.057163514
Policy mu Std                0.7403202
Policy mu Max                4.1322174
Policy mu Min                -3.792916
Policy log std Mean          -1.1483424
Policy log std Std           0.34803733
Policy log std Max           -0.14181209
Policy log std Min           -2.8981953
Z mean eval                  1.3115003
Z variance eval              0.0064235306
total_rewards                [4277.64156103 1579.72081587 4252.97319588 4213.13395676 1680.88669462
 3057.9566381   224.23416623  247.70383936  786.5880977  4064.77745172]
total_rewards_mean           2438.5616417276674
total_rewards_std            1630.8108020132136
total_rewards_max            4277.641561026643
total_rewards_min            224.23416623106786
Number of train steps total  2860000
Number of env steps total    3577000
Number of rollouts total     0
Train Time (s)               141.09999678609893
(Previous) Eval Time (s)     30.741265394724905
Sample Time (s)              25.228190946392715
Epoch Time (s)               197.06945312721655
Total Train Time (s)         134501.51596027194
Epoch                        714
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:54:39.561243 UTC | [2020_01_11_13_32_55] Iteration #714 | Epoch Duration: 189.7411470413208
2020-01-13 02:54:39.561478 UTC | [2020_01_11_13_32_55] Iteration #714 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3083776
Z variance train             0.006429767
KL Divergence                32.133793
KL Loss                      3.2133794
QF Loss                      707.2163
VF Loss                      373.30325
Policy Loss                  -1495.4435
Q Predictions Mean           1498.1617
Q Predictions Std            354.3626
Q Predictions Max            1709.7651
Q Predictions Min            -409.49362
V Predictions Mean           1482.9556
V Predictions Std            354.36017
V Predictions Max            1686.2699
V Predictions Min            -422.23828
Log Pis Mean                 1.062671
Log Pis Std                  2.9430473
Log Pis Max                  15.073885
Log Pis Min                  -6.368325
Policy mu Mean               0.0014891368
Policy mu Std                0.65764487
Policy mu Max                3.4644716
Policy mu Min                -2.3168004
Policy log std Mean          -1.1132255
Policy log std Std           0.3124963
Policy log std Max           0.28721797
Policy log std Min           -3.0941505
Z mean eval                  1.29105
Z variance eval              0.010976085
total_rewards                [1999.69966793 1821.88916618 2394.36101368 2029.21411705 3461.54398346
 4255.20316434 3551.97373932 1962.55820202 4235.25668338 4525.04353021]
total_rewards_mean           3023.674326756083
total_rewards_std            1035.0507298840878
total_rewards_max            4525.043530213741
total_rewards_min            1821.8891661788684
Number of train steps total  2864000
Number of env steps total    3582000
Number of rollouts total     0
Train Time (s)               147.87909609964117
(Previous) Eval Time (s)     23.412570727989078
Sample Time (s)              25.480250956490636
Epoch Time (s)               196.7719177841209
Total Train Time (s)         134700.80528871808
Epoch                        715
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:57:58.857223 UTC | [2020_01_11_13_32_55] Iteration #715 | Epoch Duration: 199.2956051826477
2020-01-13 02:57:58.857409 UTC | [2020_01_11_13_32_55] Iteration #715 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2910889
Z variance train             0.010966663
KL Divergence                28.911486
KL Loss                      2.8911486
QF Loss                      1370.2496
VF Loss                      350.89328
Policy Loss                  -1470.9906
Q Predictions Mean           1474.5037
Q Predictions Std            430.35056
Q Predictions Max            1755.5691
Q Predictions Min            -411.80966
V Predictions Mean           1469.8232
V Predictions Std            426.1639
V Predictions Max            1744.1257
V Predictions Min            -414.3051
Log Pis Mean                 1.3275723
Log Pis Std                  3.6970446
Log Pis Max                  21.541424
Log Pis Min                  -7.2534
Policy mu Mean               -0.007349361
Policy mu Std                0.6849846
Policy mu Max                3.7379725
Policy mu Min                -3.2794545
Policy log std Mean          -1.0926703
Policy log std Std           0.34099358
Policy log std Max           -0.022768378
Policy log std Min           -3.9626427
Z mean eval                  1.2551022
Z variance eval              0.01365723
total_rewards                [1126.67121759 1104.34450558 1486.08810932 1394.24705377 4483.1060992
  213.7546423  2552.69780751 4493.79390467 4535.54480888 1842.02120327]
total_rewards_mean           2323.226935207058
total_rewards_std            1532.5176519350252
total_rewards_max            4535.544808876542
total_rewards_min            213.75464229501011
Number of train steps total  2868000
Number of env steps total    3587000
Number of rollouts total     0
Train Time (s)               148.33723830012605
(Previous) Eval Time (s)     25.935881740879267
Sample Time (s)              26.461916382890195
Epoch Time (s)               200.7350364238955
Total Train Time (s)         134897.82203202555
Epoch                        716
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:01:15.881105 UTC | [2020_01_11_13_32_55] Iteration #716 | Epoch Duration: 197.02355861663818
2020-01-13 03:01:15.881322 UTC | [2020_01_11_13_32_55] Iteration #716 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2521851
Z variance train             0.013645597
KL Divergence                29.133846
KL Loss                      2.9133847
QF Loss                      1426.9023
VF Loss                      351.45398
Policy Loss                  -1455.4135
Q Predictions Mean           1460.46
Q Predictions Std            416.0387
Q Predictions Max            1744.6204
Q Predictions Min            -414.73395
V Predictions Mean           1447.9443
V Predictions Std            411.87637
V Predictions Max            1712.8229
V Predictions Min            -411.253
Log Pis Mean                 1.5808822
Log Pis Std                  4.001083
Log Pis Max                  23.249393
Log Pis Min                  -6.9143734
Policy mu Mean               0.003661355
Policy mu Std                0.7558935
Policy mu Max                4.3627877
Policy mu Min                -5.1350503
Policy log std Mean          -1.0965772
Policy log std Std           0.3367216
Policy log std Max           0.82482576
Policy log std Min           -2.4338713
Z mean eval                  1.2908279
Z variance eval              0.008419334
total_rewards                [ 506.24438514 4449.85847719 1836.92261361 3938.06169986  137.84707884
  950.44719242 1367.21136391 2032.27502251 3284.37056022 4143.18626539]
total_rewards_mean           2264.6424659083996
total_rewards_std            1500.9638993269393
total_rewards_max            4449.858477187347
total_rewards_min            137.84707883700148
Number of train steps total  2872000
Number of env steps total    3592000
Number of rollouts total     0
Train Time (s)               146.66583862528205
(Previous) Eval Time (s)     22.223984553012997
Sample Time (s)              24.698563390877098
Epoch Time (s)               193.58838656917214
Total Train Time (s)         135093.75439032493
Epoch                        717
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:04:31.817750 UTC | [2020_01_11_13_32_55] Iteration #717 | Epoch Duration: 195.93630981445312
2020-01-13 03:04:31.817876 UTC | [2020_01_11_13_32_55] Iteration #717 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2897936
Z variance train             0.008373543
KL Divergence                30.255878
KL Loss                      3.0255878
QF Loss                      888.0359
VF Loss                      258.84235
Policy Loss                  -1510.0626
Q Predictions Mean           1518.2593
Q Predictions Std            352.62527
Q Predictions Max            1738.3434
Q Predictions Min            -354.5165
V Predictions Mean           1513.4792
V Predictions Std            355.11285
V Predictions Max            1728.836
V Predictions Min            -374.12146
Log Pis Mean                 1.3645942
Log Pis Std                  3.2873712
Log Pis Max                  16.174112
Log Pis Min                  -10.924583
Policy mu Mean               0.035092175
Policy mu Std                0.7224235
Policy mu Max                3.1414094
Policy mu Min                -2.2758615
Policy log std Mean          -1.093025
Policy log std Std           0.30350336
Policy log std Max           -0.09223986
Policy log std Min           -2.642633
Z mean eval                  1.3099507
Z variance eval              0.008776653
total_rewards                [2988.38287132 4545.01886386 4572.19839053 4494.90752452  662.68144849
 2601.67388725 4472.77364009 3188.17204178 4266.93978629  552.25248561]
total_rewards_mean           3234.50009397541
total_rewards_std            1482.1156677044162
total_rewards_max            4572.198390529035
total_rewards_min            552.2524856118757
Number of train steps total  2876000
Number of env steps total    3597000
Number of rollouts total     0
Train Time (s)               146.76109854783863
(Previous) Eval Time (s)     24.571594808716327
Sample Time (s)              24.425208332017064
Epoch Time (s)               195.75790168857202
Total Train Time (s)         135296.30403769203
Epoch                        718
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:07:54.373893 UTC | [2020_01_11_13_32_55] Iteration #718 | Epoch Duration: 202.55591702461243
2020-01-13 03:07:54.374083 UTC | [2020_01_11_13_32_55] Iteration #718 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3093703
Z variance train             0.008748877
KL Divergence                29.26682
KL Loss                      2.9266822
QF Loss                      1636.869
VF Loss                      424.85147
Policy Loss                  -1461.6202
Q Predictions Mean           1459.5405
Q Predictions Std            392.13916
Q Predictions Max            1721.1298
Q Predictions Min            -183.68945
V Predictions Mean           1469.154
V Predictions Std            382.7281
V Predictions Max            1725.6744
V Predictions Min            -183.21259
Log Pis Mean                 1.9007676
Log Pis Std                  3.741487
Log Pis Max                  21.719421
Log Pis Min                  -8.641167
Policy mu Mean               -0.012108553
Policy mu Std                0.7051228
Policy mu Max                3.6483696
Policy mu Min                -3.8641136
Policy log std Mean          -1.1614515
Policy log std Std           0.32753837
Policy log std Max           0.4081458
Policy log std Min           -2.969336
Z mean eval                  1.272877
Z variance eval              0.021000898
total_rewards                [ -38.64375984 2506.00293361 1367.65051141 4160.74592265 1034.52559297
 3926.30170026  758.69573751   47.57112111  335.07696617 1362.99145123]
total_rewards_mean           1546.0918177056842
total_rewards_std            1435.0544330044272
total_rewards_max            4160.745922647056
total_rewards_min            -38.64375984308094
Number of train steps total  2880000
Number of env steps total    3602000
Number of rollouts total     0
Train Time (s)               142.7676138742827
(Previous) Eval Time (s)     31.369271375704557
Sample Time (s)              24.984027836937457
Epoch Time (s)               199.1209130869247
Total Train Time (s)         135479.95256461296
Epoch                        719
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:10:58.028870 UTC | [2020_01_11_13_32_55] Iteration #719 | Epoch Duration: 183.65465474128723
2020-01-13 03:10:58.029051 UTC | [2020_01_11_13_32_55] Iteration #719 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.273495
Z variance train             0.020955341
KL Divergence                29.124287
KL Loss                      2.9124286
QF Loss                      1741.2571
VF Loss                      292.5444
Policy Loss                  -1498.2571
Q Predictions Mean           1502.1978
Q Predictions Std            335.99164
Q Predictions Max            1738.5646
Q Predictions Min            -251.48083
V Predictions Mean           1499.6836
V Predictions Std            330.9436
V Predictions Max            1737.5354
V Predictions Min            -246.4699
Log Pis Mean                 1.6128806
Log Pis Std                  3.2106633
Log Pis Max                  13.611444
Log Pis Min                  -5.1938777
Policy mu Mean               0.036909048
Policy mu Std                0.71240705
Policy mu Max                2.73268
Policy mu Min                -2.8676589
Policy log std Mean          -1.1066835
Policy log std Std           0.30430448
Policy log std Max           -0.09872222
Policy log std Min           -2.7858353
Z mean eval                  1.3202469
Z variance eval              0.011393547
total_rewards                [2032.83736923 4578.31145926 4312.47281655 3819.01581421  536.3129409
  595.25114896 1838.94152779 1033.51022749  833.67816918 2301.16396079]
total_rewards_mean           2188.149543434838
total_rewards_std            1465.5327571966927
total_rewards_max            4578.311459264492
total_rewards_min            536.3129408951323
Number of train steps total  2884000
Number of env steps total    3607000
Number of rollouts total     0
Train Time (s)               140.1465520709753
(Previous) Eval Time (s)     15.90262148482725
Sample Time (s)              24.953307861462235
Epoch Time (s)               181.0024814172648
Total Train Time (s)         135662.42979375552
Epoch                        720
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:14:00.512748 UTC | [2020_01_11_13_32_55] Iteration #720 | Epoch Duration: 182.48356461524963
2020-01-13 03:14:00.512950 UTC | [2020_01_11_13_32_55] Iteration #720 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3195367
Z variance train             0.011388948
KL Divergence                29.985638
KL Loss                      2.9985638
QF Loss                      2908.291
VF Loss                      978.6079
Policy Loss                  -1463.5604
Q Predictions Mean           1467.2812
Q Predictions Std            422.41718
Q Predictions Max            1723.4606
Q Predictions Min            -265.5359
V Predictions Mean           1458.5845
V Predictions Std            412.5143
V Predictions Max            1703.3655
V Predictions Min            -271.45825
Log Pis Mean                 1.6373355
Log Pis Std                  3.7607925
Log Pis Max                  29.697556
Log Pis Min                  -7.6425524
Policy mu Mean               0.020888563
Policy mu Std                0.73156613
Policy mu Max                3.902518
Policy mu Min                -4.3298287
Policy log std Mean          -1.0981131
Policy log std Std           0.32229793
Policy log std Max           -0.04911828
Policy log std Min           -2.7434552
Z mean eval                  1.297556
Z variance eval              0.010562121
total_rewards                [1641.12772573   26.01104229 3502.89783856 4605.37099018  439.72859739
 4498.74336518 3984.94592455 2670.40332293 1472.91101385 3566.53070219]
total_rewards_mean           2640.8670522863194
total_rewards_std            1573.6719248582367
total_rewards_max            4605.370990183658
total_rewards_min            26.011042287725648
Number of train steps total  2888000
Number of env steps total    3612000
Number of rollouts total     0
Train Time (s)               142.0260882419534
(Previous) Eval Time (s)     17.38335512019694
Sample Time (s)              25.032938262913376
Epoch Time (s)               184.44238162506372
Total Train Time (s)         135853.37234990904
Epoch                        721
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:17:11.459796 UTC | [2020_01_11_13_32_55] Iteration #721 | Epoch Duration: 190.94672560691833
2020-01-13 03:17:11.459923 UTC | [2020_01_11_13_32_55] Iteration #721 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2999649
Z variance train             0.010542827
KL Divergence                28.964867
KL Loss                      2.8964868
QF Loss                      1127.1377
VF Loss                      418.80157
Policy Loss                  -1474.4569
Q Predictions Mean           1478.8264
Q Predictions Std            410.68054
Q Predictions Max            1721.1545
Q Predictions Min            -360.3438
V Predictions Mean           1466.7163
V Predictions Std            412.08536
V Predictions Max            1703.5082
V Predictions Min            -374.38495
Log Pis Mean                 1.0958722
Log Pis Std                  2.9856348
Log Pis Max                  15.273411
Log Pis Min                  -5.9471574
Policy mu Mean               0.043440565
Policy mu Std                0.66399103
Policy mu Max                3.3561063
Policy mu Min                -2.403941
Policy log std Mean          -1.0858697
Policy log std Std           0.31173214
Policy log std Max           -0.10791206
Policy log std Min           -3.1367092
Z mean eval                  1.3161461
Z variance eval              0.011413374
total_rewards                [4170.88376186 3738.0376182  3465.47580273 1347.28759065 1526.0139834
 2173.53523598 4433.42239821 1330.23165269 4250.23952133 1351.1681609 ]
total_rewards_mean           2778.629572597145
total_rewards_std            1278.8274262908697
total_rewards_max            4433.422398214024
total_rewards_min            1330.2316526859954
Number of train steps total  2892000
Number of env steps total    3617000
Number of rollouts total     0
Train Time (s)               149.57673310115933
(Previous) Eval Time (s)     23.88736259425059
Sample Time (s)              23.533575505483896
Epoch Time (s)               196.99767120089382
Total Train Time (s)         136051.36774960952
Epoch                        722
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:20:29.462677 UTC | [2020_01_11_13_32_55] Iteration #722 | Epoch Duration: 198.0026490688324
2020-01-13 03:20:29.462888 UTC | [2020_01_11_13_32_55] Iteration #722 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3156846
Z variance train             0.0114084985
KL Divergence                28.9602
KL Loss                      2.89602
QF Loss                      1257.9243
VF Loss                      414.44382
Policy Loss                  -1485.1168
Q Predictions Mean           1488.4803
Q Predictions Std            373.41962
Q Predictions Max            1735.5657
Q Predictions Min            -410.899
V Predictions Mean           1481.4934
V Predictions Std            368.0601
V Predictions Max            1727.974
V Predictions Min            -391.43607
Log Pis Mean                 2.0153608
Log Pis Std                  4.123874
Log Pis Max                  25.967232
Log Pis Min                  -6.641906
Policy mu Mean               -0.041377872
Policy mu Std                0.74858963
Policy mu Max                4.900582
Policy mu Min                -2.973772
Policy log std Mean          -1.1236974
Policy log std Std           0.3713228
Policy log std Max           0.13023925
Policy log std Min           -3.4112194
Z mean eval                  1.3252404
Z variance eval              0.014116334
total_rewards                [ 751.42528051 4275.61866843  380.91821081 4246.0076612   822.53707366
 4377.60143763 2949.94826848  323.4809488  4455.10075481  328.50033601]
total_rewards_mean           2291.113864033084
total_rewards_std            1820.1603999145889
total_rewards_max            4455.100754807586
total_rewards_min            323.48094879842847
Number of train steps total  2896000
Number of env steps total    3622000
Number of rollouts total     0
Train Time (s)               149.40132253617048
(Previous) Eval Time (s)     24.891991388052702
Sample Time (s)              25.526128068566322
Epoch Time (s)               199.8194419927895
Total Train Time (s)         136250.69207600597
Epoch                        723
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:23:48.791256 UTC | [2020_01_11_13_32_55] Iteration #723 | Epoch Duration: 199.32824540138245
2020-01-13 03:23:48.791380 UTC | [2020_01_11_13_32_55] Iteration #723 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3258417
Z variance train             0.014155464
KL Divergence                29.172731
KL Loss                      2.9172733
QF Loss                      803.7879
VF Loss                      272.97287
Policy Loss                  -1479.5415
Q Predictions Mean           1484.5558
Q Predictions Std            395.71457
Q Predictions Max            1768.1763
Q Predictions Min            -420.12402
V Predictions Mean           1478.932
V Predictions Std            396.53256
V Predictions Max            1745.6396
V Predictions Min            -412.12943
Log Pis Mean                 1.7323637
Log Pis Std                  4.094474
Log Pis Max                  32.293068
Log Pis Min                  -7.565503
Policy mu Mean               -0.012075342
Policy mu Std                0.71945953
Policy mu Max                4.5294676
Policy mu Min                -2.7693307
Policy log std Mean          -1.1264043
Policy log std Std           0.3424019
Policy log std Max           -0.080174804
Policy log std Min           -3.1007357
Z mean eval                  1.3255544
Z variance eval              0.012518786
total_rewards                [1546.09501336  899.69021634 2501.44681178 1876.18655864 1211.94623609
 3162.03259287 1430.49560763 1163.46023378  789.95737132 1056.78842634]
total_rewards_mean           1563.809906815421
total_rewards_std            716.2545502312025
total_rewards_max            3162.0325928651373
total_rewards_min            789.9573713236844
Number of train steps total  2900000
Number of env steps total    3627000
Number of rollouts total     0
Train Time (s)               149.9366910760291
(Previous) Eval Time (s)     24.40045997267589
Sample Time (s)              26.128824235405773
Epoch Time (s)               200.46597528411075
Total Train Time (s)         136440.0796040236
Epoch                        724
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:26:58.186795 UTC | [2020_01_11_13_32_55] Iteration #724 | Epoch Duration: 189.39527463912964
2020-01-13 03:26:58.187125 UTC | [2020_01_11_13_32_55] Iteration #724 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3241861
Z variance train             0.0123817045
KL Divergence                30.050608
KL Loss                      3.005061
QF Loss                      926.2809
VF Loss                      190.89944
Policy Loss                  -1478.052
Q Predictions Mean           1483.486
Q Predictions Std            387.74088
Q Predictions Max            1744.7521
Q Predictions Min            -262.61725
V Predictions Mean           1474.1304
V Predictions Std            387.67325
V Predictions Max            1746.1934
V Predictions Min            -275.55255
Log Pis Mean                 1.1341798
Log Pis Std                  3.4392786
Log Pis Max                  13.321398
Log Pis Min                  -8.4437275
Policy mu Mean               0.013328329
Policy mu Std                0.7106789
Policy mu Max                3.4591432
Policy mu Min                -2.7110431
Policy log std Mean          -1.0919688
Policy log std Std           0.30427718
Policy log std Max           0.0017764568
Policy log std Min           -2.5802293
Z mean eval                  1.2811141
Z variance eval              0.008625365
total_rewards                [2862.65603661 1412.21943625 4216.14969255 4573.64734857 4468.79680064
  696.55200022 3168.30862411 1269.03109117  322.3979861  3202.87189648]
total_rewards_mean           2619.2630912701416
total_rewards_std            1508.1186304584955
total_rewards_max            4573.647348570817
total_rewards_min            322.3979860964284
Number of train steps total  2904000
Number of env steps total    3632000
Number of rollouts total     0
Train Time (s)               148.0091327270493
(Previous) Eval Time (s)     13.329372426029295
Sample Time (s)              25.513282503001392
Epoch Time (s)               186.85178765607998
Total Train Time (s)         136637.61285728868
Epoch                        725
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:30:15.726120 UTC | [2020_01_11_13_32_55] Iteration #725 | Epoch Duration: 197.53868079185486
2020-01-13 03:30:15.726300 UTC | [2020_01_11_13_32_55] Iteration #725 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2791984
Z variance train             0.008644213
KL Divergence                31.046957
KL Loss                      3.1046958
QF Loss                      1416.2437
VF Loss                      170.04256
Policy Loss                  -1495.4727
Q Predictions Mean           1498.5635
Q Predictions Std            390.0948
Q Predictions Max            1746.7065
Q Predictions Min            -401.90067
V Predictions Mean           1493.4285
V Predictions Std            389.06635
V Predictions Max            1736.4594
V Predictions Min            -395.77902
Log Pis Mean                 1.4980562
Log Pis Std                  3.3686078
Log Pis Max                  11.346297
Log Pis Min                  -7.045474
Policy mu Mean               -0.028922115
Policy mu Std                0.7156555
Policy mu Max                2.4797878
Policy mu Min                -3.131121
Policy log std Mean          -1.0970638
Policy log std Std           0.3216825
Policy log std Max           -0.24299675
Policy log std Min           -2.8375423
Z mean eval                  1.3088522
Z variance eval              0.0067458274
total_rewards                [3314.13496515  126.77904893 4715.82633844   99.40090744 4404.43572194
 4202.10321898 4794.91114455   60.69686936 1913.02728974 4331.21362184]
total_rewards_mean           2796.252912637864
total_rewards_std            1937.235811923068
total_rewards_max            4794.911144548314
total_rewards_min            60.696869355275865
Number of train steps total  2908000
Number of env steps total    3637000
Number of rollouts total     0
Train Time (s)               141.13686678512022
(Previous) Eval Time (s)     24.015918660908937
Sample Time (s)              24.779546762816608
Epoch Time (s)               189.93233220884576
Total Train Time (s)         136825.60020280723
Epoch                        726
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:33:23.720426 UTC | [2020_01_11_13_32_55] Iteration #726 | Epoch Duration: 187.99398922920227
2020-01-13 03:33:23.720621 UTC | [2020_01_11_13_32_55] Iteration #726 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3089656
Z variance train             0.006728596
KL Divergence                30.794113
KL Loss                      3.0794113
QF Loss                      8001.126
VF Loss                      1699.864
Policy Loss                  -1478.9287
Q Predictions Mean           1486.5464
Q Predictions Std            381.01166
Q Predictions Max            1712.4331
Q Predictions Min            -364.52295
V Predictions Mean           1476.915
V Predictions Std            392.01126
V Predictions Max            1708.3816
V Predictions Min            -390.21286
Log Pis Mean                 1.766624
Log Pis Std                  3.9104652
Log Pis Max                  20.376652
Log Pis Min                  -8.908883
Policy mu Mean               0.046059858
Policy mu Std                0.71824586
Policy mu Max                3.1792116
Policy mu Min                -2.4133844
Policy log std Mean          -1.1147422
Policy log std Std           0.37444818
Policy log std Max           0.39729905
Policy log std Min           -3.4988332
Z mean eval                  1.3609517
Z variance eval              0.006730738
total_rewards                [1170.11110417 4241.66801076 3056.47207798 4412.81758469  475.86902745
 4453.0346248  2558.40064356 4322.2160209  4505.85189722 4404.59855434]
total_rewards_mean           3360.103954586568
total_rewards_std            1423.3420489222763
total_rewards_max            4505.851897220712
total_rewards_min            475.869027454145
Number of train steps total  2912000
Number of env steps total    3642000
Number of rollouts total     0
Train Time (s)               140.21554962126538
(Previous) Eval Time (s)     22.077230092138052
Sample Time (s)              25.268810883164406
Epoch Time (s)               187.56159059656784
Total Train Time (s)         137017.64078861056
Epoch                        727
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:36:35.767905 UTC | [2020_01_11_13_32_55] Iteration #727 | Epoch Duration: 192.04713892936707
2020-01-13 03:36:35.768105 UTC | [2020_01_11_13_32_55] Iteration #727 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3623284
Z variance train             0.006724543
KL Divergence                30.624882
KL Loss                      3.0624883
QF Loss                      1157.8228
VF Loss                      335.48077
Policy Loss                  -1480.0282
Q Predictions Mean           1484.295
Q Predictions Std            389.12057
Q Predictions Max            1737.3328
Q Predictions Min            -379.6059
V Predictions Mean           1477.332
V Predictions Std            388.2287
V Predictions Max            1715.1531
V Predictions Min            -371.3346
Log Pis Mean                 1.7183878
Log Pis Std                  3.9382317
Log Pis Max                  23.409977
Log Pis Min                  -8.049808
Policy mu Mean               0.025945717
Policy mu Std                0.7154554
Policy mu Max                3.296634
Policy mu Min                -3.4971936
Policy log std Mean          -1.119309
Policy log std Std           0.33825135
Policy log std Max           -0.06858599
Policy log std Min           -3.1697643
Z mean eval                  1.2771366
Z variance eval              0.010112156
total_rewards                [4.38272743e+03 4.13729889e+03 1.43038409e+03 1.02338747e+03
 3.61736822e+02 1.78047912e+03 1.89296665e+03 2.72703213e+00
 5.74995835e+02 3.88370394e+03]
total_rewards_mean           1947.0407283623354
total_rewards_std            1542.9598994290207
total_rewards_max            4382.727429446817
total_rewards_min            2.7270321289712776
Number of train steps total  2916000
Number of env steps total    3647000
Number of rollouts total     0
Train Time (s)               146.86696107080206
(Previous) Eval Time (s)     26.562441943679005
Sample Time (s)              25.276709975209087
Epoch Time (s)               198.70611298969015
Total Train Time (s)         137210.3010413004
Epoch                        728
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:39:48.435143 UTC | [2020_01_11_13_32_55] Iteration #728 | Epoch Duration: 192.666894197464
2020-01-13 03:39:48.435425 UTC | [2020_01_11_13_32_55] Iteration #728 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2757267
Z variance train             0.010103866
KL Divergence                29.930101
KL Loss                      2.9930103
QF Loss                      2883.8284
VF Loss                      520.46387
Policy Loss                  -1457.91
Q Predictions Mean           1461.0793
Q Predictions Std            404.42392
Q Predictions Max            1729.7616
Q Predictions Min            -364.12088
V Predictions Mean           1461.056
V Predictions Std            401.9335
V Predictions Max            1708.7548
V Predictions Min            -368.35382
Log Pis Mean                 1.909466
Log Pis Std                  4.20647
Log Pis Max                  37.815117
Log Pis Min                  -5.798298
Policy mu Mean               -0.0054688617
Policy mu Std                0.69560826
Policy mu Max                5.1324944
Policy mu Min                -3.1066613
Policy log std Mean          -1.1674273
Policy log std Std           0.41697866
Policy log std Max           2.0
Policy log std Min           -3.5264916
Z mean eval                  1.3079343
Z variance eval              0.016975518
total_rewards                [2094.73145907 4292.96144319 4488.17682907 4478.34954897 1581.30114889
 3924.95916966 3021.21095077 2429.28955335 4482.06984641 4428.33846343]
total_rewards_mean           3522.1388412814595
total_rewards_std            1076.8591552429552
total_rewards_max            4488.176829065956
total_rewards_min            1581.3011488898658
Number of train steps total  2920000
Number of env steps total    3652000
Number of rollouts total     0
Train Time (s)               148.44827976590022
(Previous) Eval Time (s)     20.522903201635927
Sample Time (s)              26.583151118829846
Epoch Time (s)               195.554334086366
Total Train Time (s)         137413.155177305
Epoch                        729
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:43:11.296678 UTC | [2020_01_11_13_32_55] Iteration #729 | Epoch Duration: 202.86110925674438
2020-01-13 03:43:11.296929 UTC | [2020_01_11_13_32_55] Iteration #729 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3062761
Z variance train             0.01699197
KL Divergence                29.155796
KL Loss                      2.9155796
QF Loss                      1100.7554
VF Loss                      334.3437
Policy Loss                  -1478.5023
Q Predictions Mean           1493.7495
Q Predictions Std            394.122
Q Predictions Max            1734.6326
Q Predictions Min            -424.30597
V Predictions Mean           1470.5509
V Predictions Std            393.13565
V Predictions Max            1722.8726
V Predictions Min            -376.61948
Log Pis Mean                 1.6051208
Log Pis Std                  3.5897675
Log Pis Max                  14.915344
Log Pis Min                  -6.801296
Policy mu Mean               0.028940212
Policy mu Std                0.72398174
Policy mu Max                2.9599605
Policy mu Min                -2.471818
Policy log std Mean          -1.1179148
Policy log std Std           0.3355311
Policy log std Max           0.5628934
Policy log std Min           -2.7167447
Z mean eval                  1.2573955
Z variance eval              0.012627209
total_rewards                [ 360.83297053  475.59652292 4468.26962213 1144.54148784 4474.45532686
 2971.29008362  711.55543382 4382.16301719 4810.37832279 2624.01746403]
total_rewards_mean           2642.3100251725255
total_rewards_std            1743.5012120717872
total_rewards_max            4810.378322793587
total_rewards_min            360.83297052990446
Number of train steps total  2924000
Number of env steps total    3657000
Number of rollouts total     0
Train Time (s)               146.5695504345931
(Previous) Eval Time (s)     27.829306575935334
Sample Time (s)              25.895913789980114
Epoch Time (s)               200.29477080050856
Total Train Time (s)         137606.8076923862
Epoch                        730
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:46:24.955346 UTC | [2020_01_11_13_32_55] Iteration #730 | Epoch Duration: 193.6582555770874
2020-01-13 03:46:24.955531 UTC | [2020_01_11_13_32_55] Iteration #730 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2582405
Z variance train             0.012620846
KL Divergence                30.852697
KL Loss                      3.0852697
QF Loss                      944.6927
VF Loss                      218.47507
Policy Loss                  -1514.7736
Q Predictions Mean           1517.7755
Q Predictions Std            354.68713
Q Predictions Max            1744.7622
Q Predictions Min            -212.16505
V Predictions Mean           1512.8572
V Predictions Std            351.7377
V Predictions Max            1731.5308
V Predictions Min            -188.28413
Log Pis Mean                 1.5276237
Log Pis Std                  3.0596921
Log Pis Max                  13.276878
Log Pis Min                  -7.0869946
Policy mu Mean               0.012277194
Policy mu Std                0.7031444
Policy mu Max                2.9558523
Policy mu Min                -2.5947015
Policy log std Mean          -1.1116545
Policy log std Std           0.29631457
Policy log std Max           -0.107353926
Policy log std Min           -2.7982016
Z mean eval                  1.2895172
Z variance eval              0.016422154
total_rewards                [ 552.73513467 2142.258491   1200.89773564 1252.88430329   12.13481229
   23.26806378 4305.49784211 2712.35413423  185.06961852 2301.35921393]
total_rewards_mean           1468.8459349463265
total_rewards_std            1325.0263576178709
total_rewards_max            4305.4978421147525
total_rewards_min            12.13481228720667
Number of train steps total  2928000
Number of env steps total    3662000
Number of rollouts total     0
Train Time (s)               149.2356237238273
(Previous) Eval Time (s)     21.192469091154635
Sample Time (s)              25.941733004059643
Epoch Time (s)               196.36982581904158
Total Train Time (s)         137794.21828046022
Epoch                        731
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:49:32.373833 UTC | [2020_01_11_13_32_55] Iteration #731 | Epoch Duration: 187.41816115379333
2020-01-13 03:49:32.374043 UTC | [2020_01_11_13_32_55] Iteration #731 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2885945
Z variance train             0.016444571
KL Divergence                28.914774
KL Loss                      2.8914773
QF Loss                      938.3633
VF Loss                      1411.6771
Policy Loss                  -1493.8115
Q Predictions Mean           1498.1194
Q Predictions Std            381.4201
Q Predictions Max            1758.288
Q Predictions Min            -401.75177
V Predictions Mean           1494.989
V Predictions Std            384.59976
V Predictions Max            1758.2578
V Predictions Min            -424.37552
Log Pis Mean                 1.6636267
Log Pis Std                  3.3321986
Log Pis Max                  15.814875
Log Pis Min                  -8.226759
Policy mu Mean               0.0018107735
Policy mu Std                0.7073068
Policy mu Max                2.9422858
Policy mu Min                -3.0071099
Policy log std Mean          -1.1125582
Policy log std Std           0.32167938
Policy log std Max           0.27131248
Policy log std Min           -2.655335
Z mean eval                  1.3135225
Z variance eval              0.015062543
total_rewards                [ 666.02048937 3160.41721873  885.78490297 4454.72399886 2965.38354888
 3745.2264045   795.72046533 2311.72736156 2877.26708241 4171.93234732]
total_rewards_mean           2603.420381993757
total_rewards_std            1332.8234870189497
total_rewards_max            4454.7239988556175
total_rewards_min            666.0204893690485
Number of train steps total  2932000
Number of env steps total    3667000
Number of rollouts total     0
Train Time (s)               145.6023510498926
(Previous) Eval Time (s)     12.240396783221513
Sample Time (s)              25.612172218505293
Epoch Time (s)               183.4549200516194
Total Train Time (s)         137986.194978124
Epoch                        732
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:52:44.356644 UTC | [2020_01_11_13_32_55] Iteration #732 | Epoch Duration: 191.98242902755737
2020-01-13 03:52:44.356836 UTC | [2020_01_11_13_32_55] Iteration #732 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3141093
Z variance train             0.0150328595
KL Divergence                29.332443
KL Loss                      2.9332445
QF Loss                      2737.33
VF Loss                      529.7191
Policy Loss                  -1493.3723
Q Predictions Mean           1499.767
Q Predictions Std            432.72418
Q Predictions Max            1759.1421
Q Predictions Min            -388.0744
V Predictions Mean           1496.1305
V Predictions Std            432.91385
V Predictions Max            1746.2899
V Predictions Min            -412.66135
Log Pis Mean                 1.4437901
Log Pis Std                  4.3664885
Log Pis Max                  38.80565
Log Pis Min                  -7.84009
Policy mu Mean               -0.006152425
Policy mu Std                0.75137395
Policy mu Max                3.1740928
Policy mu Min                -4.1286387
Policy log std Mean          -1.0691108
Policy log std Std           0.33542144
Policy log std Max           0.37468672
Policy log std Min           -3.2878451
Z mean eval                  1.2723634
Z variance eval              0.010363826
total_rewards                [4409.53468721 4297.25052098  466.85006244  750.89695497 3655.95115129
  774.01051115 3605.68401235 4257.14126824 4252.21769496 4500.31453168]
total_rewards_mean           3096.9851395257915
total_rewards_std            1618.717089150929
total_rewards_max            4500.314531679399
total_rewards_min            466.8500624415622
Number of train steps total  2936000
Number of env steps total    3672000
Number of rollouts total     0
Train Time (s)               140.10002238862216
(Previous) Eval Time (s)     20.7675039623864
Sample Time (s)              23.916297782212496
Epoch Time (s)               184.78382413322106
Total Train Time (s)         138173.16234380007
Epoch                        733
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:55:51.328447 UTC | [2020_01_11_13_32_55] Iteration #733 | Epoch Duration: 186.97149634361267
2020-01-13 03:55:51.328565 UTC | [2020_01_11_13_32_55] Iteration #733 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2659413
Z variance train             0.01033962
KL Divergence                29.297222
KL Loss                      2.9297223
QF Loss                      919.75195
VF Loss                      321.90976
Policy Loss                  -1474.5306
Q Predictions Mean           1475.9065
Q Predictions Std            407.94662
Q Predictions Max            1717.943
Q Predictions Min            -277.59875
V Predictions Mean           1475.3741
V Predictions Std            406.2702
V Predictions Max            1730.5477
V Predictions Min            -302.4926
Log Pis Mean                 1.5554872
Log Pis Std                  3.3845372
Log Pis Max                  20.913708
Log Pis Min                  -6.976774
Policy mu Mean               -0.008806075
Policy mu Std                0.7081161
Policy mu Max                2.7347522
Policy mu Min                -3.9895847
Policy log std Mean          -1.1212016
Policy log std Std           0.34144342
Policy log std Max           0.037128925
Policy log std Min           -2.8803148
Z mean eval                  1.2627518
Z variance eval              0.008612323
total_rewards                [4446.22144697 2145.20682058 4260.59512405 4493.86914645 1278.90322759
 4393.52445025 4489.54033909  293.96027516 4401.19080681  420.99641349]
total_rewards_mean           3062.4008050431207
total_rewards_std            1722.326781595615
total_rewards_max            4493.869146450542
total_rewards_min            293.9602751588416
Number of train steps total  2940000
Number of env steps total    3677000
Number of rollouts total     0
Train Time (s)               141.13393921824172
(Previous) Eval Time (s)     22.95484145404771
Sample Time (s)              23.372914128471166
Epoch Time (s)               187.4616948007606
Total Train Time (s)         138362.62262789812
Epoch                        734
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:59:00.796629 UTC | [2020_01_11_13_32_55] Iteration #734 | Epoch Duration: 189.46793937683105
2020-01-13 03:59:00.796939 UTC | [2020_01_11_13_32_55] Iteration #734 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.263768
Z variance train             0.008591583
KL Divergence                28.587162
KL Loss                      2.8587162
QF Loss                      1832.9524
VF Loss                      489.756
Policy Loss                  -1484.4097
Q Predictions Mean           1488.3741
Q Predictions Std            412.00873
Q Predictions Max            1758.9786
Q Predictions Min            -407.0484
V Predictions Mean           1489.22
V Predictions Std            410.08093
V Predictions Max            1748.2789
V Predictions Min            -401.58182
Log Pis Mean                 1.5589142
Log Pis Std                  3.2341175
Log Pis Max                  13.69044
Log Pis Min                  -6.84669
Policy mu Mean               0.03726066
Policy mu Std                0.6996702
Policy mu Max                3.2672045
Policy mu Min                -2.531516
Policy log std Mean          -1.136543
Policy log std Std           0.34735024
Policy log std Max           0.019323349
Policy log std Min           -2.8515177
Z mean eval                  1.306447
Z variance eval              0.014146867
total_rewards                [2257.21575117 4472.79429135 2631.21996099  945.91028983 4322.26783603
 1223.98658635 4298.14979022 3775.51316609 2592.18847461 4566.40251181]
total_rewards_mean           3108.5648658438263
total_rewards_std            1294.8910344931112
total_rewards_max            4566.402511812787
total_rewards_min            945.9102898314662
Number of train steps total  2944000
Number of env steps total    3682000
Number of rollouts total     0
Train Time (s)               149.98702897317708
(Previous) Eval Time (s)     24.960728533100337
Sample Time (s)              25.670548935886472
Epoch Time (s)               200.61830644216388
Total Train Time (s)         138564.59849895537
Epoch                        735
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:02:22.779564 UTC | [2020_01_11_13_32_55] Iteration #735 | Epoch Duration: 201.9824583530426
2020-01-13 04:02:22.779751 UTC | [2020_01_11_13_32_55] Iteration #735 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.302252
Z variance train             0.014082971
KL Divergence                27.903795
KL Loss                      2.7903795
QF Loss                      1670.7917
VF Loss                      1150.3416
Policy Loss                  -1455.2458
Q Predictions Mean           1454.888
Q Predictions Std            444.2716
Q Predictions Max            1741.6482
Q Predictions Min            -412.68826
V Predictions Mean           1453.654
V Predictions Std            433.39444
V Predictions Max            1743.3087
V Predictions Min            -403.48148
Log Pis Mean                 1.5588355
Log Pis Std                  3.6669533
Log Pis Max                  19.99506
Log Pis Min                  -7.8930244
Policy mu Mean               0.043427147
Policy mu Std                0.7100883
Policy mu Max                3.0775948
Policy mu Min                -3.3072002
Policy log std Mean          -1.1293149
Policy log std Std           0.35567382
Policy log std Max           0.06509638
Policy log std Min           -2.885574
Z mean eval                  1.2877017
Z variance eval              0.011361739
total_rewards                [ 365.60108162 1384.2314831  2986.10239211 4305.16989873 4158.03562686
 2121.31911361 4229.48992824   96.6673912   499.50688394  459.45578351]
total_rewards_mean           2060.5579582903997
total_rewards_std            1648.9347090070091
total_rewards_max            4305.169898726112
total_rewards_min            96.66739119767156
Number of train steps total  2948000
Number of env steps total    3687000
Number of rollouts total     0
Train Time (s)               148.66087340610102
(Previous) Eval Time (s)     26.324539387132972
Sample Time (s)              24.637072432786226
Epoch Time (s)               199.62248522602022
Total Train Time (s)         138755.65263202833
Epoch                        736
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:05:33.840674 UTC | [2020_01_11_13_32_55] Iteration #736 | Epoch Duration: 191.06078791618347
2020-01-13 04:05:33.840884 UTC | [2020_01_11_13_32_55] Iteration #736 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2853482
Z variance train             0.0113838725
KL Divergence                28.278389
KL Loss                      2.827839
QF Loss                      1322.637
VF Loss                      405.1297
Policy Loss                  -1463.3604
Q Predictions Mean           1465.8005
Q Predictions Std            396.3997
Q Predictions Max            1717.2166
Q Predictions Min            -296.97766
V Predictions Mean           1457.0548
V Predictions Std            399.53244
V Predictions Max            1704.634
V Predictions Min            -293.88068
Log Pis Mean                 1.8047974
Log Pis Std                  3.3457334
Log Pis Max                  18.013845
Log Pis Min                  -6.982582
Policy mu Mean               -0.003120957
Policy mu Std                0.7153217
Policy mu Max                4.081913
Policy mu Min                -2.520832
Policy log std Mean          -1.1533315
Policy log std Std           0.35460374
Policy log std Max           0.49097705
Policy log std Min           -3.3327963
Z mean eval                  1.2703117
Z variance eval              0.01671104
total_rewards                [4221.19626608 4556.92188226 4595.30907819 4535.30736947 2643.16472443
 4307.43156598 1040.39161908   41.31916844 4418.31138176 3105.74893691]
total_rewards_mean           3346.5101992596783
total_rewards_std            1551.4563692235802
total_rewards_max            4595.309078188918
total_rewards_min            41.319168435966404
Number of train steps total  2952000
Number of env steps total    3692000
Number of rollouts total     0
Train Time (s)               148.0273408172652
(Previous) Eval Time (s)     17.762507724110037
Sample Time (s)              25.26507438905537
Epoch Time (s)               191.05492293043062
Total Train Time (s)         138956.91480627144
Epoch                        737
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:08:55.111462 UTC | [2020_01_11_13_32_55] Iteration #737 | Epoch Duration: 201.27040767669678
2020-01-13 04:08:55.111806 UTC | [2020_01_11_13_32_55] Iteration #737 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2680471
Z variance train             0.01670654
KL Divergence                27.079206
KL Loss                      2.7079208
QF Loss                      1435.7137
VF Loss                      450.11798
Policy Loss                  -1460.6462
Q Predictions Mean           1464.2211
Q Predictions Std            356.5952
Q Predictions Max            1705.8401
Q Predictions Min            -386.98062
V Predictions Mean           1464.5115
V Predictions Std            355.64365
V Predictions Max            1709.5104
V Predictions Min            -407.06613
Log Pis Mean                 1.6896197
Log Pis Std                  3.5183141
Log Pis Max                  17.4765
Log Pis Min                  -6.0722427
Policy mu Mean               0.04434452
Policy mu Std                0.6961354
Policy mu Max                3.1064954
Policy mu Min                -2.5622284
Policy log std Mean          -1.1399157
Policy log std Std           0.34639883
Policy log std Max           0.224931
Policy log std Min           -3.0729947
Z mean eval                  1.3113991
Z variance eval              0.013779399
total_rewards                [4441.66861963  917.95512532  191.60450078 4046.30243507  932.18348869
 4269.10095987 2394.58360101 1540.16828143   99.6960001  4273.30301869]
total_rewards_mean           2310.656603059751
total_rewards_std            1704.7109446583463
total_rewards_max            4441.668619634142
total_rewards_min            99.69600010343106
Number of train steps total  2956000
Number of env steps total    3697000
Number of rollouts total     0
Train Time (s)               148.11427334789187
(Previous) Eval Time (s)     27.977639698889107
Sample Time (s)              27.4630964002572
Epoch Time (s)               203.55500944703817
Total Train Time (s)         139154.38462631637
Epoch                        738
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:12:12.585271 UTC | [2020_01_11_13_32_55] Iteration #738 | Epoch Duration: 197.47331261634827
2020-01-13 04:12:12.585390 UTC | [2020_01_11_13_32_55] Iteration #738 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3133255
Z variance train             0.013787938
KL Divergence                28.359293
KL Loss                      2.8359294
QF Loss                      1525.6279
VF Loss                      189.26581
Policy Loss                  -1500.363
Q Predictions Mean           1504.674
Q Predictions Std            370.49106
Q Predictions Max            1753.037
Q Predictions Min            -382.21082
V Predictions Mean           1499.3716
V Predictions Std            373.03528
V Predictions Max            1744.4274
V Predictions Min            -401.13617
Log Pis Mean                 1.5653759
Log Pis Std                  3.559091
Log Pis Max                  19.900871
Log Pis Min                  -6.2268953
Policy mu Mean               0.013161607
Policy mu Std                0.70914894
Policy mu Max                2.8592203
Policy mu Min                -2.8865318
Policy log std Mean          -1.1142485
Policy log std Std           0.35199782
Policy log std Max           0.11400151
Policy log std Min           -3.4674592
Z mean eval                  1.3048502
Z variance eval              0.01536783
total_rewards                [1248.65356697 4040.25313664 4480.50300102 1133.10671904 4415.20062116
 3886.55442773 2491.57660591 1896.93193651 2953.74483024 1661.41119164]
total_rewards_mean           2820.793603686079
total_rewards_std            1247.5317968242769
total_rewards_max            4480.503001017402
total_rewards_min            1133.1067190439567
Number of train steps total  2960000
Number of env steps total    3702000
Number of rollouts total     0
Train Time (s)               141.2651325687766
(Previous) Eval Time (s)     21.895530524197966
Sample Time (s)              25.481893214862794
Epoch Time (s)               188.64255630783737
Total Train Time (s)         139343.7194694765
Epoch                        739
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:15:21.927174 UTC | [2020_01_11_13_32_55] Iteration #739 | Epoch Duration: 189.3416793346405
2020-01-13 04:15:21.927472 UTC | [2020_01_11_13_32_55] Iteration #739 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3016723
Z variance train             0.01536714
KL Divergence                27.297113
KL Loss                      2.7297113
QF Loss                      5494.872
VF Loss                      265.13098
Policy Loss                  -1456.3026
Q Predictions Mean           1466.248
Q Predictions Std            437.55728
Q Predictions Max            1742.1998
Q Predictions Min            -373.03894
V Predictions Mean           1460.5757
V Predictions Std            441.63297
V Predictions Max            1716.5374
V Predictions Min            -375.4845
Log Pis Mean                 1.3362637
Log Pis Std                  3.5596597
Log Pis Max                  11.659615
Log Pis Min                  -9.927958
Policy mu Mean               0.03122419
Policy mu Std                0.68729573
Policy mu Max                3.372161
Policy mu Min                -2.4957376
Policy log std Mean          -1.132653
Policy log std Std           0.33340946
Policy log std Max           -0.103747845
Policy log std Min           -2.6436853
Z mean eval                  1.2734268
Z variance eval              0.010948809
total_rewards                [2584.45573455 3973.60400437  630.50182672  167.14448482 1963.66405044
  441.74022846 3501.19392447  436.77643441 4385.96487681 3180.49041168]
total_rewards_mean           2126.553597673165
total_rewards_std            1533.7717778115805
total_rewards_max            4385.964876805503
total_rewards_min            167.1444848249926
Number of train steps total  2964000
Number of env steps total    3707000
Number of rollouts total     0
Train Time (s)               140.8142254827544
(Previous) Eval Time (s)     22.594294376671314
Sample Time (s)              25.03553066868335
Epoch Time (s)               188.44405052810907
Total Train Time (s)         139526.42227998888
Epoch                        740
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:18:24.636598 UTC | [2020_01_11_13_32_55] Iteration #740 | Epoch Duration: 182.70899176597595
2020-01-13 04:18:24.636762 UTC | [2020_01_11_13_32_55] Iteration #740 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2716972
Z variance train             0.010953364
KL Divergence                28.349203
KL Loss                      2.8349204
QF Loss                      1503.6333
VF Loss                      315.7866
Policy Loss                  -1451.9904
Q Predictions Mean           1457.1252
Q Predictions Std            420.68958
Q Predictions Max            1716.5505
Q Predictions Min            -429.9524
V Predictions Mean           1452.2891
V Predictions Std            417.2071
V Predictions Max            1703.6752
V Predictions Min            -360.97797
Log Pis Mean                 1.2223709
Log Pis Std                  3.356484
Log Pis Max                  18.020815
Log Pis Min                  -6.082734
Policy mu Mean               -0.017714404
Policy mu Std                0.6980913
Policy mu Max                3.6056526
Policy mu Min                -2.889691
Policy log std Mean          -1.0864062
Policy log std Std           0.34153637
Policy log std Max           -0.0011262894
Policy log std Min           -3.7110481
Z mean eval                  1.2969201
Z variance eval              0.022572612
total_rewards                [1279.05000129  632.24869154   88.15055626  412.69197581 4219.69428798
 3663.27952467 2005.11057059 1939.80514631  300.02272922 4547.60491449]
total_rewards_mean           1908.7658398154822
total_rewards_std            1598.7306042883986
total_rewards_max            4547.6049144855415
total_rewards_min            88.15055625586038
Number of train steps total  2968000
Number of env steps total    3712000
Number of rollouts total     0
Train Time (s)               145.09590411605313
(Previous) Eval Time (s)     16.858927206136286
Sample Time (s)              24.938779689371586
Epoch Time (s)               186.893611011561
Total Train Time (s)         139716.83518877905
Epoch                        741
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:21:35.061749 UTC | [2020_01_11_13_32_55] Iteration #741 | Epoch Duration: 190.42482709884644
2020-01-13 04:21:35.062217 UTC | [2020_01_11_13_32_55] Iteration #741 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2986674
Z variance train             0.02255499
KL Divergence                28.354202
KL Loss                      2.8354204
QF Loss                      1391.2261
VF Loss                      335.6265
Policy Loss                  -1506.0668
Q Predictions Mean           1509.8933
Q Predictions Std            360.9473
Q Predictions Max            1750.272
Q Predictions Min            -209.62035
V Predictions Mean           1497.5271
V Predictions Std            359.86475
V Predictions Max            1737.639
V Predictions Min            -223.81696
Log Pis Mean                 1.5462661
Log Pis Std                  3.319377
Log Pis Max                  14.98115
Log Pis Min                  -7.0192523
Policy mu Mean               0.070204385
Policy mu Std                0.72240174
Policy mu Max                3.445883
Policy mu Min                -2.51082
Policy log std Mean          -1.1035666
Policy log std Std           0.31902763
Policy log std Max           0.25702214
Policy log std Min           -3.1016197
Z mean eval                  1.3403231
Z variance eval              0.018543065
total_rewards                [4109.88891074  627.35107941  542.42592066  707.24404241 1784.30768024
 2128.36685757 1551.62616389 4188.13760097 1928.37242527 3227.2526273 ]
total_rewards_mean           2079.497330848141
total_rewards_std            1289.6357697687088
total_rewards_max            4188.13760097335
total_rewards_min            542.4259206644788
Number of train steps total  2972000
Number of env steps total    3717000
Number of rollouts total     0
Train Time (s)               149.7357169459574
(Previous) Eval Time (s)     20.389768947847188
Sample Time (s)              25.280946620274335
Epoch Time (s)               195.40643251407892
Total Train Time (s)         139911.41021470074
Epoch                        742
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:24:49.639311 UTC | [2020_01_11_13_32_55] Iteration #742 | Epoch Duration: 194.57678604125977
2020-01-13 04:24:49.639592 UTC | [2020_01_11_13_32_55] Iteration #742 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3385562
Z variance train             0.018476423
KL Divergence                28.039574
KL Loss                      2.8039575
QF Loss                      19870.291
VF Loss                      575.7889
Policy Loss                  -1439.9846
Q Predictions Mean           1448.3494
Q Predictions Std            443.96643
Q Predictions Max            1735.3932
Q Predictions Min            -366.61777
V Predictions Mean           1443.9607
V Predictions Std            440.77896
V Predictions Max            1723.2538
V Predictions Min            -351.89502
Log Pis Mean                 1.9725095
Log Pis Std                  3.523734
Log Pis Max                  19.47575
Log Pis Min                  -7.8206806
Policy mu Mean               0.0711395
Policy mu Std                0.72035384
Policy mu Max                3.2139397
Policy mu Min                -2.9112816
Policy log std Mean          -1.1464744
Policy log std Std           0.3550418
Policy log std Max           -0.051370382
Policy log std Min           -2.560379
Z mean eval                  1.3448821
Z variance eval              0.012985731
total_rewards                [4397.15873243 4172.50283206 1777.21938981 4394.43249594 2366.4884831
 4741.0836551  4608.24785416  358.58984243 2492.35561333 3131.41378634]
total_rewards_mean           3243.9492684707866
total_rewards_std            1394.3646470314447
total_rewards_max            4741.083655102951
total_rewards_min            358.58984242691236
Number of train steps total  2976000
Number of env steps total    3722000
Number of rollouts total     0
Train Time (s)               148.02274530706927
(Previous) Eval Time (s)     19.559762362856418
Sample Time (s)              25.976542230695486
Epoch Time (s)               193.55904990062118
Total Train Time (s)         140110.21552068833
Epoch                        743
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:28:08.450529 UTC | [2020_01_11_13_32_55] Iteration #743 | Epoch Duration: 198.8107852935791
2020-01-13 04:28:08.450703 UTC | [2020_01_11_13_32_55] Iteration #743 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3469744
Z variance train             0.012982348
KL Divergence                29.425093
KL Loss                      2.9425094
QF Loss                      8923.746
VF Loss                      263.23578
Policy Loss                  -1464.3854
Q Predictions Mean           1467.3441
Q Predictions Std            426.8009
Q Predictions Max            1727.979
Q Predictions Min            -249.77084
V Predictions Mean           1460.0171
V Predictions Std            423.5951
V Predictions Max            1716.8088
V Predictions Min            -276.69266
Log Pis Mean                 1.6792006
Log Pis Std                  3.4802868
Log Pis Max                  21.970936
Log Pis Min                  -6.8247776
Policy mu Mean               0.041448455
Policy mu Std                0.6974998
Policy mu Max                2.8104517
Policy mu Min                -2.6291997
Policy log std Mean          -1.1279896
Policy log std Std           0.34772536
Policy log std Max           -0.00017940998
Policy log std Min           -3.3936734
Z mean eval                  1.289447
Z variance eval              0.008902884
total_rewards                [2640.36292461 4670.68475957   65.97397091 4555.01067647 3547.66855676
 1691.54879511  851.6172333  4425.34608552  293.74459426 4609.35681787]
total_rewards_mean           2735.131441436713
total_rewards_std            1783.7750101890354
total_rewards_max            4670.684759571123
total_rewards_min            65.97397090664109
Number of train steps total  2980000
Number of env steps total    3727000
Number of rollouts total     0
Train Time (s)               150.364270624239
(Previous) Eval Time (s)     24.81116220774129
Sample Time (s)              26.412091102451086
Epoch Time (s)               201.58752393443137
Total Train Time (s)         140308.99520620983
Epoch                        744
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:31:27.236903 UTC | [2020_01_11_13_32_55] Iteration #744 | Epoch Duration: 198.7860803604126
2020-01-13 04:31:27.237085 UTC | [2020_01_11_13_32_55] Iteration #744 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2900106
Z variance train             0.008915256
KL Divergence                29.941305
KL Loss                      2.9941306
QF Loss                      902.53845
VF Loss                      165.55016
Policy Loss                  -1482.1996
Q Predictions Mean           1484.1604
Q Predictions Std            420.48175
Q Predictions Max            1759.4294
Q Predictions Min            -342.37683
V Predictions Mean           1482.681
V Predictions Std            421.11768
V Predictions Max            1769.4408
V Predictions Min            -361.74557
Log Pis Mean                 1.4896524
Log Pis Std                  3.4597366
Log Pis Max                  11.167392
Log Pis Min                  -9.183225
Policy mu Mean               0.009839568
Policy mu Std                0.7129234
Policy mu Max                3.1568143
Policy mu Min                -2.6956387
Policy log std Mean          -1.0901524
Policy log std Std           0.3100073
Policy log std Max           -0.15091038
Policy log std Min           -2.606958
Z mean eval                  1.2724946
Z variance eval              0.014864187
total_rewards                [4166.93071355 4531.85725319 4440.51734387 -125.5727897  2441.09202593
 3305.48304224 4329.93691513  237.12140347  306.98125555 1494.19356981]
total_rewards_mean           2512.8540733036525
total_rewards_std            1802.976128243722
total_rewards_max            4531.857253185155
total_rewards_min            -125.57278969646305
Number of train steps total  2984000
Number of env steps total    3732000
Number of rollouts total     0
Train Time (s)               146.84418710740283
(Previous) Eval Time (s)     22.009380761068314
Sample Time (s)              26.430110272951424
Epoch Time (s)               195.28367814142257
Total Train Time (s)         140504.23008500785
Epoch                        745
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:34:42.478864 UTC | [2020_01_11_13_32_55] Iteration #745 | Epoch Duration: 195.24164724349976
2020-01-13 04:34:42.479062 UTC | [2020_01_11_13_32_55] Iteration #745 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2715677
Z variance train             0.014885761
KL Divergence                29.30248
KL Loss                      2.930248
QF Loss                      1886.6781
VF Loss                      2128.831
Policy Loss                  -1446.7349
Q Predictions Mean           1458.6196
Q Predictions Std            467.44876
Q Predictions Max            1737.2336
Q Predictions Min            -424.0142
V Predictions Mean           1450.9845
V Predictions Std            464.07187
V Predictions Max            1724.2781
V Predictions Min            -367.52148
Log Pis Mean                 1.5500839
Log Pis Std                  3.5065155
Log Pis Max                  13.440975
Log Pis Min                  -8.148782
Policy mu Mean               0.031770937
Policy mu Std                0.71543723
Policy mu Max                3.7473931
Policy mu Min                -2.5947413
Policy log std Mean          -1.1220993
Policy log std Std           0.3526273
Policy log std Max           0.22188354
Policy log std Min           -2.834365
Z mean eval                  1.2700145
Z variance eval              0.019133788
total_rewards                [1326.92196637  905.29688332  442.76356111 2509.25008669 4641.79028854
 3380.15757308  701.08067814  617.90669784 4478.13682689  178.82002763]
total_rewards_mean           1918.2124589611553
total_rewards_std            1618.8872935449608
total_rewards_max            4641.790288536585
total_rewards_min            178.82002763230082
Number of train steps total  2988000
Number of env steps total    3737000
Number of rollouts total     0
Train Time (s)               140.355253436137
(Previous) Eval Time (s)     21.966988786123693
Sample Time (s)              23.519916040357202
Epoch Time (s)               185.8421582626179
Total Train Time (s)         140685.75291588483
Epoch                        746
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:37:44.008593 UTC | [2020_01_11_13_32_55] Iteration #746 | Epoch Duration: 181.5293984413147
2020-01-13 04:37:44.008787 UTC | [2020_01_11_13_32_55] Iteration #746 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2713152
Z variance train             0.01919644
KL Divergence                27.839275
KL Loss                      2.7839277
QF Loss                      1101.7361
VF Loss                      170.98505
Policy Loss                  -1504.411
Q Predictions Mean           1505.5411
Q Predictions Std            372.82693
Q Predictions Max            1763.5045
Q Predictions Min            -367.75497
V Predictions Mean           1506.4219
V Predictions Std            367.74374
V Predictions Max            1730.91
V Predictions Min            -375.35123
Log Pis Mean                 1.3322589
Log Pis Std                  3.2752953
Log Pis Max                  18.478046
Log Pis Min                  -6.173423
Policy mu Mean               0.02897601
Policy mu Std                0.7258102
Policy mu Max                2.7042534
Policy mu Min                -2.9989367
Policy log std Mean          -1.0878463
Policy log std Std           0.29564077
Policy log std Max           -0.13840711
Policy log std Min           -2.9193864
Z mean eval                  1.2967776
Z variance eval              0.008445986
total_rewards                [ 581.18691154 3799.35208797 4556.61942255 2833.34970201 4384.85671532
 4584.99627441 1491.95669813 4764.63795886  725.49462351 4474.95597211]
total_rewards_mean           3219.7406366413597
total_rewards_std            1600.7701351980704
total_rewards_max            4764.637958862062
total_rewards_min            581.1869115360774
Number of train steps total  2992000
Number of env steps total    3742000
Number of rollouts total     0
Train Time (s)               141.12913936423138
(Previous) Eval Time (s)     17.653879708144814
Sample Time (s)              24.828935341443866
Epoch Time (s)               183.61195441382006
Total Train Time (s)         140876.5839978396
Epoch                        747
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:40:54.846784 UTC | [2020_01_11_13_32_55] Iteration #747 | Epoch Duration: 190.83785557746887
2020-01-13 04:40:54.846984 UTC | [2020_01_11_13_32_55] Iteration #747 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.297046
Z variance train             0.008458788
KL Divergence                30.327274
KL Loss                      3.0327275
QF Loss                      1017.2195
VF Loss                      198.96562
Policy Loss                  -1479.0151
Q Predictions Mean           1481.5098
Q Predictions Std            397.80826
Q Predictions Max            1718.2784
Q Predictions Min            -416.1056
V Predictions Mean           1484.1174
V Predictions Std            399.06778
V Predictions Max            1731.5221
V Predictions Min            -408.5565
Log Pis Mean                 1.9746242
Log Pis Std                  3.3301764
Log Pis Max                  15.133585
Log Pis Min                  -5.4480486
Policy mu Mean               0.03806629
Policy mu Std                0.7346296
Policy mu Max                3.0264328
Policy mu Min                -2.6935017
Policy log std Mean          -1.1219788
Policy log std Std           0.31429031
Policy log std Max           0.4386711
Policy log std Min           -3.00914
Z mean eval                  1.311189
Z variance eval              0.025315085
total_rewards                [4479.82891862 4600.26133852 4285.9768221  4359.99251736 4438.24823188
 2897.61211421 4346.87739786 1958.63603583 4358.74162501 3192.40320692]
total_rewards_mean           3891.8578208315184
total_rewards_std            846.2091332767526
total_rewards_max            4600.261338521953
total_rewards_min            1958.6360358284567
Number of train steps total  2996000
Number of env steps total    3747000
Number of rollouts total     0
Train Time (s)               149.34443998895586
(Previous) Eval Time (s)     24.879375716205686
Sample Time (s)              25.848676815629005
Epoch Time (s)               200.07249252079055
Total Train Time (s)         141082.85270749964
Epoch                        748
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:44:21.123567 UTC | [2020_01_11_13_32_55] Iteration #748 | Epoch Duration: 206.2763843536377
2020-01-13 04:44:21.123936 UTC | [2020_01_11_13_32_55] Iteration #748 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3121799
Z variance train             0.025220972
KL Divergence                30.026741
KL Loss                      3.002674
QF Loss                      1787.7554
VF Loss                      238.91675
Policy Loss                  -1506.9711
Q Predictions Mean           1514.973
Q Predictions Std            347.0249
Q Predictions Max            1751.6857
Q Predictions Min            -329.24915
V Predictions Mean           1505.6724
V Predictions Std            346.68045
V Predictions Max            1750.2512
V Predictions Min            -335.12387
Log Pis Mean                 1.4039316
Log Pis Std                  3.2804072
Log Pis Max                  15.946255
Log Pis Min                  -6.27273
Policy mu Mean               0.033355493
Policy mu Std                0.69805926
Policy mu Max                4.7822433
Policy mu Min                -2.5882463
Policy log std Mean          -1.1396978
Policy log std Std           0.31256115
Policy log std Max           -0.15461075
Policy log std Min           -2.4027746
Z mean eval                  1.4016306
Z variance eval              0.013574572
total_rewards                [4388.30299597 1560.51548836 4432.57919932  485.64723886   94.07544734
 3374.3444675  4399.96628484  358.20337953 4585.31345362 4439.93811497]
total_rewards_mean           2811.8886070308126
total_rewards_std            1847.4323171887506
total_rewards_max            4585.313453624835
total_rewards_min            94.07544733538866
Number of train steps total  3000000
Number of env steps total    3752000
Number of rollouts total     0
Train Time (s)               148.16086243186146
(Previous) Eval Time (s)     31.082883893046528
Sample Time (s)              26.713643138296902
Epoch Time (s)               205.9573894632049
Total Train Time (s)         141284.61162190698
Epoch                        749
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:47:42.886011 UTC | [2020_01_11_13_32_55] Iteration #749 | Epoch Duration: 201.76191639900208
2020-01-13 04:47:42.886128 UTC | [2020_01_11_13_32_55] Iteration #749 | Started Training: True
2020-01-13 04:47:43.516986 UTC | [2020_01_11_13_32_55] Variant:
2020-01-13 04:47:43.517223 UTC | [2020_01_11_13_32_55] {
  "env_name": "HalfCheetah-v2",
  "n_train_tasks": 1,
  "n_eval_tasks": 1,
  "latent_size": 5,
  "net_size": 300,
  "path_to_weights": null,
  "env_params": {
    "n_tasks": 2,
    "randomize_tasks": true
  },
  "algo_params": {
    "meta_batch": 1,
    "num_iterations": 750,
    "num_initial_steps": 2000,
    "num_tasks_sample": 5,
    "num_steps_prior": 400,
    "num_steps_posterior": 0,
    "num_extra_rl_steps_posterior": 600,
    "num_train_steps_per_itr": 4000,
    "num_evals": 2,
    "num_steps_per_eval": 600,
    "batch_size": 256,
    "embedding_batch_size": 20,
    "embedding_mini_batch_size": 20,
    "max_path_length": 200,
    "discount": 0.99,
    "soft_target_tau": 0.005,
    "policy_lr": 0.0003,
    "qf_lr": 0.0003,
    "vf_lr": 0.0003,
    "context_lr": 0.0003,
    "reward_scale": 5.0,
    "sparse_rewards": false,
    "kl_lambda": 0.1,
    "use_information_bottleneck": true,
    "use_next_obs_in_context": false,
    "update_post_train": 1,
    "num_exp_traj_eval": 2,
    "recurrent": true,
    "dump_eval_paths": false
  },
  "util_params": {
    "base_log_dir": "./test/train4000_no-clear_H-20_s3",
    "use_gpu": true,
    "gpu_id": 0,
    "debug": false,
    "docker": false
  }
}
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0019530611
Z variance train             0.69260883
KL Divergence                0.14976072
KL Loss                      0.014976072
QF Loss                      30.072021
VF Loss                      16.352331
Policy Loss                  -4.0086412
Q Predictions Mean           -0.006684159
Q Predictions Std            0.0022229382
Q Predictions Max            -0.0018604228
Q Predictions Min            -0.012359737
V Predictions Mean           0.0002574473
V Predictions Std            0.0015592332
V Predictions Max            0.0041628233
V Predictions Min            -0.0041609993
Log Pis Mean                 -4.035728
Log Pis Std                  0.53440696
Log Pis Max                  -2.344994
Log Pis Min                  -5.7029934
Policy mu Mean               0.00053918344
Policy mu Std                0.0013700707
Policy mu Max                0.0043439977
Policy mu Min                -0.002454193
Policy log std Mean          -0.0006518511
Policy log std Std           0.0012498002
Policy log std Max           0.0031305198
Policy log std Min           -0.003774563
Z mean eval                  0.41251212
Z variance eval              0.029696528
total_rewards                [-263.57235197 -313.19398235 -253.22628164 -273.35500782 -283.03149898
 -279.75429145 -279.4459174  -264.21310072 -256.9009236  -268.0589264 ]
total_rewards_mean           -273.4752282347443
total_rewards_std            16.253952313645584
total_rewards_max            -253.22628163849856
total_rewards_min            -313.1939823519828
Number of train steps total  4000
Number of env steps total    7000
Number of rollouts total     0
Train Time (s)               128.64814642211422
(Previous) Eval Time (s)     0
Sample Time (s)              29.706222897861153
Epoch Time (s)               158.35436931997538
Total Train Time (s)         186.90178753435612
Epoch                        0
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:50:50.502535 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #0 | Epoch Duration: 186.90386962890625
2020-01-13 04:50:50.502655 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #0 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.4168915
Z variance train             0.029556906
KL Divergence                7.12335
KL Loss                      0.71233505
QF Loss                      73.067245
VF Loss                      13.690603
Policy Loss                  -68.97317
Q Predictions Mean           64.9538
Q Predictions Std            19.291653
Q Predictions Max            122.526566
Q Predictions Min            9.026272
V Predictions Mean           69.222305
V Predictions Std            18.603779
V Predictions Max            125.88093
V Predictions Min            21.3865
Log Pis Mean                 -2.1012383
Log Pis Std                  1.8905243
Log Pis Max                  3.6459236
Log Pis Min                  -6.7317634
Policy mu Mean               0.010876273
Policy mu Std                0.69954926
Policy mu Max                1.8733157
Policy mu Min                -1.9749867
Policy log std Mean          -0.2430314
Policy log std Std           0.109738626
Policy log std Max           -0.020024715
Policy log std Min           -0.61912674
Z mean eval                  0.8459414
Z variance eval              0.022192145
total_rewards                [ -53.13113265  -52.11204489  -85.51223372    3.07012314   35.12486895
  -21.32466606   -5.35043451 -118.42374128  -85.99649534  -18.50876853]
total_rewards_mean           -40.21645248982065
total_rewards_std            44.90656846885862
total_rewards_max            35.12486895008706
total_rewards_min            -118.4237412835663
Number of train steps total  8000
Number of env steps total    12000
Number of rollouts total     0
Train Time (s)               129.17045164760202
(Previous) Eval Time (s)     28.54906950192526
Sample Time (s)              23.07123115239665
Epoch Time (s)               180.79075230192393
Total Train Time (s)         368.0781780765392
Epoch                        1
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:53:51.681013 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #1 | Epoch Duration: 181.17825198173523
2020-01-13 04:53:51.681206 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #1 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8447755
Z variance train             0.022183126
KL Divergence                9.90311
KL Loss                      0.99031097
QF Loss                      91.25952
VF Loss                      32.377754
Policy Loss                  -123.001915
Q Predictions Mean           119.57558
Q Predictions Std            32.308617
Q Predictions Max            219.00769
Q Predictions Min            50.593933
V Predictions Mean           126.21886
V Predictions Std            33.239532
V Predictions Max            220.56844
V Predictions Min            57.21777
Log Pis Mean                 -1.9645396
Log Pis Std                  2.0900936
Log Pis Max                  4.771961
Log Pis Min                  -6.9988966
Policy mu Mean               -0.11662211
Policy mu Std                0.6912752
Policy mu Max                3.0196316
Policy mu Min                -2.22548
Policy log std Mean          -0.28233495
Policy log std Std           0.14612423
Policy log std Max           0.08432025
Policy log std Min           -0.74318475
Z mean eval                  1.0454212
Z variance eval              0.013096554
total_rewards                [360.71050293 658.38997218 934.20530035 732.25145273 993.0732366
 776.31762251 727.80537594 306.35057557 847.81230195 755.00019089]
total_rewards_mean           709.19165316359
total_rewards_std            210.76502999327943
total_rewards_max            993.0732365957152
total_rewards_min            306.3505755699643
Number of train steps total  12000
Number of env steps total    17000
Number of rollouts total     0
Train Time (s)               125.08997519593686
(Previous) Eval Time (s)     28.936210989952087
Sample Time (s)              21.127477985341102
Epoch Time (s)               175.15366417123005
Total Train Time (s)         541.3898109733127
Epoch                        2
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:56:44.993389 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #2 | Epoch Duration: 173.3120460510254
2020-01-13 04:56:44.993575 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #2 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0446813
Z variance train             0.013067638
KL Divergence                12.702362
KL Loss                      1.2702363
QF Loss                      60.92475
VF Loss                      16.649487
Policy Loss                  -187.25542
Q Predictions Mean           182.58957
Q Predictions Std            57.630684
Q Predictions Max            302.25827
Q Predictions Min            103.68844
V Predictions Mean           186.50906
V Predictions Std            57.039124
V Predictions Max            302.3349
V Predictions Min            107.32439
Log Pis Mean                 -2.2650628
Log Pis Std                  1.7857271
Log Pis Max                  2.8376656
Log Pis Min                  -6.960513
Policy mu Mean               -0.037323747
Policy mu Std                0.61639565
Policy mu Max                2.4663985
Policy mu Min                -1.8832737
Policy log std Mean          -0.341673
Policy log std Std           0.17324038
Policy log std Max           0.13234699
Policy log std Min           -1.0033957
Z mean eval                  1.1524985
Z variance eval              0.01714981
total_rewards                [2021.00537098 1353.67650591  692.58216712  926.76370928  446.34530332
  328.01957074  397.68463296  297.18196824  426.59368523  255.50406242]
total_rewards_mean           714.5356976182226
total_rewards_std            543.176476647035
total_rewards_max            2021.0053709819517
total_rewards_min            255.50406242001105
Number of train steps total  16000
Number of env steps total    22000
Number of rollouts total     0
Train Time (s)               122.63736859569326
(Previous) Eval Time (s)     27.0942023107782
Sample Time (s)              20.82736107846722
Epoch Time (s)               170.55893198493868
Total Train Time (s)         712.4034570464864
Epoch                        3
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:59:36.008783 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #3 | Epoch Duration: 171.01507425308228
2020-01-13 04:59:36.008977 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #3 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1531117
Z variance train             0.017161602
KL Divergence                12.808952
KL Loss                      1.2808952
QF Loss                      106.311035
VF Loss                      22.107367
Policy Loss                  -256.68375
Q Predictions Mean           254.36862
Q Predictions Std            90.49488
Q Predictions Max            447.87985
Q Predictions Min            125.10891
V Predictions Mean           258.5239
V Predictions Std            88.964516
V Predictions Max            441.9377
V Predictions Min            130.85806
Log Pis Mean                 -1.2606807
Log Pis Std                  2.2323582
Log Pis Max                  4.6179934
Log Pis Min                  -7.2981896
Policy mu Mean               0.027960977
Policy mu Std                0.75242317
Policy mu Max                2.3881683
Policy mu Min                -1.9909483
Policy log std Mean          -0.39661703
Policy log std Std           0.21069807
Policy log std Max           0.18281797
Policy log std Min           -1.1988239
Z mean eval                  1.3873724
Z variance eval              0.015330422
total_rewards                [2161.45089817 2140.389563   2219.23947071 2220.63960063 2370.01047189
 2295.95518411  385.82150584 2210.30720653 2155.05275174 2213.41993892]
total_rewards_mean           2037.228659154814
total_rewards_std            554.3060209624529
total_rewards_max            2370.0104718852185
total_rewards_min            385.82150584380923
Number of train steps total  20000
Number of env steps total    27000
Number of rollouts total     0
Train Time (s)               123.0724608679302
(Previous) Eval Time (s)     27.550037991721183
Sample Time (s)              21.85994529351592
Epoch Time (s)               172.4824441531673
Total Train Time (s)         885.7268639518879
Epoch                        4
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:02:29.333225 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #4 | Epoch Duration: 173.3241012096405
2020-01-13 05:02:29.333502 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #4 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3888525
Z variance train             0.015359682
KL Divergence                15.3641205
KL Loss                      1.5364121
QF Loss                      136.03438
VF Loss                      28.846882
Policy Loss                  -358.59708
Q Predictions Mean           355.17712
Q Predictions Std            131.96811
Q Predictions Max            597.04645
Q Predictions Min            149.2025
V Predictions Mean           356.79733
V Predictions Std            128.99985
V Predictions Max            573.87695
V Predictions Min            151.9281
Log Pis Mean                 -0.19758832
Log Pis Std                  3.0011601
Log Pis Max                  8.792863
Log Pis Min                  -5.8803906
Policy mu Mean               0.004874474
Policy mu Std                0.9105834
Policy mu Max                2.5368156
Policy mu Min                -2.2518578
Policy log std Mean          -0.45925698
Policy log std Std           0.22502053
Policy log std Max           0.068648666
Policy log std Min           -1.3470342
Z mean eval                  1.6123501
Z variance eval              0.00846571
total_rewards                [2692.83795408 2515.03315049 2552.26804566 2677.40507992 2494.75423274
 2739.1760681  2641.26731724 2605.60410794 2657.66574805 2679.83119861]
total_rewards_mean           2625.5842902828963
total_rewards_std            77.09862756687049
total_rewards_max            2739.1760680999023
total_rewards_min            2494.754232743648
Number of train steps total  24000
Number of env steps total    32000
Number of rollouts total     0
Train Time (s)               129.74283995199949
(Previous) Eval Time (s)     28.39135857997462
Sample Time (s)              21.994118144270033
Epoch Time (s)               180.12831667624414
Total Train Time (s)         1065.3359134476632
Epoch                        5
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:05:28.943101 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #5 | Epoch Duration: 179.60942101478577
2020-01-13 05:05:28.943333 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #5 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6117465
Z variance train             0.00849103
KL Divergence                18.669346
KL Loss                      1.8669347
QF Loss                      116.89687
VF Loss                      42.621017
Policy Loss                  -462.16455
Q Predictions Mean           455.185
Q Predictions Std            165.67967
Q Predictions Max            730.5332
Q Predictions Min            167.9455
V Predictions Mean           459.74316
V Predictions Std            164.10025
V Predictions Max            722.6899
V Predictions Min            173.9784
Log Pis Mean                 -0.42441562
Log Pis Std                  2.5088913
Log Pis Max                  7.5955787
Log Pis Min                  -5.1910496
Policy mu Mean               0.018225195
Policy mu Std                0.8645351
Policy mu Max                2.3146482
Policy mu Min                -2.087457
Policy log std Mean          -0.4890952
Policy log std Std           0.2144586
Policy log std Max           -0.014461324
Policy log std Min           -1.3625927
Z mean eval                  1.7243465
Z variance eval              0.0065839575
total_rewards                [2828.15949946 3003.46162819 2618.42025184 2849.37148156 2886.86075529
 2801.19709226 2885.85563237 2877.08196868 2941.6142615  2729.42906276]
total_rewards_mean           2842.1451633918978
total_rewards_std            102.82513861192376
total_rewards_max            3003.4616281862714
total_rewards_min            2618.4202518373545
Number of train steps total  28000
Number of env steps total    37000
Number of rollouts total     0
Train Time (s)               128.22781651793048
(Previous) Eval Time (s)     27.87213307712227
Sample Time (s)              23.790333015378565
Epoch Time (s)               179.8902826104313
Total Train Time (s)         1246.89247624157
Epoch                        6
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:08:30.501710 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #6 | Epoch Duration: 181.55820393562317
2020-01-13 05:08:30.502067 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #6 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7251089
Z variance train             0.0065787444
KL Divergence                20.391747
KL Loss                      2.0391748
QF Loss                      134.31175
VF Loss                      40.960236
Policy Loss                  -580.0475
Q Predictions Mean           579.718
Q Predictions Std            206.4138
Q Predictions Max            870.69086
Q Predictions Min            195.83714
V Predictions Mean           580.6615
V Predictions Std            203.8655
V Predictions Max            868.5578
V Predictions Min            199.73068
Log Pis Mean                 -0.10618477
Log Pis Std                  3.0337222
Log Pis Max                  7.239845
Log Pis Min                  -11.61224
Policy mu Mean               0.044077694
Policy mu Std                0.88678974
Policy mu Max                2.2588856
Policy mu Min                -2.1539214
Policy log std Mean          -0.5460806
Policy log std Std           0.22719783
Policy log std Max           -0.021850228
Policy log std Min           -1.3467463
Z mean eval                  1.8142908
Z variance eval              0.009204874
total_rewards                [3347.80944526 3372.50182389 3363.35057416 3554.07241599 3298.20620523
 3482.82224545 3395.70623033 3244.49874631 3546.72529796 3565.81554856]
total_rewards_mean           3417.1508533155807
total_rewards_std            107.73284658862255
total_rewards_max            3565.8155485602647
total_rewards_min            3244.498746308841
Number of train steps total  32000
Number of env steps total    42000
Number of rollouts total     0
Train Time (s)               128.20434849569574
(Previous) Eval Time (s)     29.539598107803613
Sample Time (s)              23.35998937813565
Epoch Time (s)               181.103935981635
Total Train Time (s)         1426.6319704223424
Epoch                        7
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:11:30.242388 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #7 | Epoch Duration: 179.74012517929077
2020-01-13 05:11:30.242592 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #7 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8144636
Z variance train             0.0092092585
KL Divergence                20.36407
KL Loss                      2.0364072
QF Loss                      162.71606
VF Loss                      47.666504
Policy Loss                  -661.4111
Q Predictions Mean           656.20465
Q Predictions Std            229.68564
Q Predictions Max            1039.9319
Q Predictions Min            206.13573
V Predictions Mean           661.4815
V Predictions Std            228.50308
V Predictions Max            1015.10895
V Predictions Min            210.74792
Log Pis Mean                 0.37200865
Log Pis Std                  3.0531464
Log Pis Max                  8.052788
Log Pis Min                  -6.4546986
Policy mu Mean               -0.05631427
Policy mu Std                0.93361336
Policy mu Max                2.65058
Policy mu Min                -2.106049
Policy log std Mean          -0.5996502
Policy log std Std           0.2529432
Policy log std Max           -0.08380608
Policy log std Min           -1.5444207
Z mean eval                  1.8094561
Z variance eval              0.016029088
total_rewards                [1696.25278236 3266.1503735  3469.77596612 3760.59448379 2421.45311777
 3612.62973335 3673.69008255 3708.72939744 3450.22057745 3648.23049407]
total_rewards_mean           3270.7727008384772
total_rewards_std            642.3158423852061
total_rewards_max            3760.5944837888283
total_rewards_min            1696.2527823554542
Number of train steps total  36000
Number of env steps total    47000
Number of rollouts total     0
Train Time (s)               129.65291046677157
(Previous) Eval Time (s)     28.175388231873512
Sample Time (s)              23.530622941441834
Epoch Time (s)               181.35892164008692
Total Train Time (s)         1607.578623380512
Epoch                        8
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:14:31.190045 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #8 | Epoch Duration: 180.94730138778687
2020-01-13 05:14:31.190237 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #8 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8093636
Z variance train             0.016028073
KL Divergence                18.622683
KL Loss                      1.8622683
QF Loss                      187.48602
VF Loss                      95.89601
Policy Loss                  -762.35724
Q Predictions Mean           762.6053
Q Predictions Std            278.57016
Q Predictions Max            1122.8439
Q Predictions Min            204.99916
V Predictions Mean           767.28094
V Predictions Std            278.54306
V Predictions Max            1123.581
V Predictions Min            203.67255
Log Pis Mean                 0.64439094
Log Pis Std                  3.2203631
Log Pis Max                  10.009582
Log Pis Min                  -11.538987
Policy mu Mean               -0.08419856
Policy mu Std                0.9791118
Policy mu Max                2.5454803
Policy mu Min                -2.656161
Policy log std Mean          -0.5911507
Policy log std Std           0.26712713
Policy log std Max           -0.014669597
Policy log std Min           -1.7054617
Z mean eval                  1.897831
Z variance eval              0.008491794
total_rewards                [4317.83454654 4110.1667456  4271.29119976 4034.56462958 4067.58577139
 4208.73634556 3933.93500836 4078.414103   3855.50575947 1369.87768186]
total_rewards_mean           3824.791179112427
total_rewards_std            829.3396094120194
total_rewards_max            4317.834546536084
total_rewards_min            1369.8776818553506
Number of train steps total  40000
Number of env steps total    52000
Number of rollouts total     0
Train Time (s)               127.45694114081562
(Previous) Eval Time (s)     27.763393457978964
Sample Time (s)              22.461656449362636
Epoch Time (s)               177.68199104815722
Total Train Time (s)         1784.161436028313
Epoch                        9
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:17:27.773891 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #9 | Epoch Duration: 176.5835211277008
2020-01-13 05:17:27.774075 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #9 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8956875
Z variance train             0.008445034
KL Divergence                21.439865
KL Loss                      2.1439865
QF Loss                      136.04855
VF Loss                      131.9807
Policy Loss                  -862.9387
Q Predictions Mean           862.7285
Q Predictions Std            304.90073
Q Predictions Max            1271.9165
Q Predictions Min            220.9783
V Predictions Mean           869.53784
V Predictions Std            305.00006
V Predictions Max            1278.8065
V Predictions Min            221.02731
Log Pis Mean                 1.1002226
Log Pis Std                  3.3312573
Log Pis Max                  11.755883
Log Pis Min                  -8.076817
Policy mu Mean               -0.12638126
Policy mu Std                1.0221453
Policy mu Max                2.6664343
Policy mu Min                -2.6290972
Policy log std Mean          -0.60542154
Policy log std Std           0.2676194
Policy log std Max           0.019006029
Policy log std Min           -1.8004013
Z mean eval                  1.9335282
Z variance eval              0.013410993
total_rewards                [4348.89696951 4047.47515992 4158.50573746 4411.96623812 4242.5369209
 4224.41158034 4208.84563058 4261.04679558 4345.19868463 4116.13574685]
total_rewards_mean           4236.501946389965
total_rewards_std            106.34275513343165
total_rewards_max            4411.966238122231
total_rewards_min            4047.4751599205033
Number of train steps total  44000
Number of env steps total    57000
Number of rollouts total     0
Train Time (s)               122.70811059232801
(Previous) Eval Time (s)     26.664538546931
Sample Time (s)              21.260485434904695
Epoch Time (s)               170.6331345741637
Total Train Time (s)         1955.7479200907983
Epoch                        10
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:20:19.361485 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #10 | Epoch Duration: 171.58727025985718
2020-01-13 05:20:19.361660 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #10 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9330829
Z variance train             0.013407258
KL Divergence                21.686853
KL Loss                      2.1686854
QF Loss                      242.14912
VF Loss                      84.31851
Policy Loss                  -1011.228
Q Predictions Mean           1009.56006
Q Predictions Std            280.9735
Q Predictions Max            1401.9012
Q Predictions Min            228.86476
V Predictions Mean           1014.52386
V Predictions Std            277.50854
V Predictions Max            1400.5823
V Predictions Min            230.50734
Log Pis Mean                 1.4761403
Log Pis Std                  3.234308
Log Pis Max                  11.345076
Log Pis Min                  -6.1701055
Policy mu Mean               -0.16003454
Policy mu Std                1.0491173
Policy mu Max                2.5130434
Policy mu Min                -2.6139758
Policy log std Mean          -0.6539487
Policy log std Std           0.27059346
Policy log std Max           -0.029707983
Policy log std Min           -1.8897686
Z mean eval                  1.9739945
Z variance eval              0.012944192
total_rewards                [1100.10430158 4480.01292414 4337.52276954 2270.29407369 4342.90642105
 4266.59998371 4447.56000187 2313.91177171  909.12664821 4434.77606332]
total_rewards_mean           3290.2814958810436
total_rewards_std            1402.961163592106
total_rewards_max            4480.012924139078
total_rewards_min            909.1266482089594
Number of train steps total  48000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               122.78400045400485
(Previous) Eval Time (s)     27.61835214914754
Sample Time (s)              22.328372603282332
Epoch Time (s)               172.73072520643473
Total Train Time (s)         2128.1301995650865
Epoch                        11
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:23:11.747737 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #11 | Epoch Duration: 172.38592910766602
2020-01-13 05:23:11.747942 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #11 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9733126
Z variance train             0.012898557
KL Divergence                22.61325
KL Loss                      2.2613251
QF Loss                      300.03424
VF Loss                      75.33944
Policy Loss                  -1054.1493
Q Predictions Mean           1044.8965
Q Predictions Std            343.54358
Q Predictions Max            1510.7007
Q Predictions Min            235.12935
V Predictions Mean           1054.6638
V Predictions Std            341.78918
V Predictions Max            1524.8688
V Predictions Min            234.97946
Log Pis Mean                 1.7826343
Log Pis Std                  3.2466025
Log Pis Max                  9.2254505
Log Pis Min                  -5.375907
Policy mu Mean               -0.070112854
Policy mu Std                1.0907068
Policy mu Max                2.5802805
Policy mu Min                -2.5417898
Policy log std Mean          -0.666735
Policy log std Std           0.27321073
Policy log std Max           -0.06354383
Policy log std Min           -1.9690183
Z mean eval                  2.012433
Z variance eval              0.028847065
total_rewards                [4826.53730344 4670.58501924 4793.06726701 4708.82188529 4580.67974327
 4805.46318906 4921.04487718 4877.35102189 5010.58336924 4830.09819252]
total_rewards_mean           4802.423186812981
total_rewards_std            118.22553856256233
total_rewards_max            5010.583369238006
total_rewards_min            4580.679743266746
Number of train steps total  52000
Number of env steps total    67000
Number of rollouts total     0
Train Time (s)               129.57221927819774
(Previous) Eval Time (s)     27.273227415047586
Sample Time (s)              22.463956688065082
Epoch Time (s)               179.3094033813104
Total Train Time (s)         2309.2906246990897
Epoch                        12
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:26:12.907028 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #12 | Epoch Duration: 181.15891361236572
2020-01-13 05:26:12.907339 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #12 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0124767
Z variance train             0.028822288
KL Divergence                19.948526
KL Loss                      1.9948527
QF Loss                      300.45972
VF Loss                      75.663635
Policy Loss                  -1158.6844
Q Predictions Mean           1156.8402
Q Predictions Std            355.24152
Q Predictions Max            1595.5333
Q Predictions Min            237.08743
V Predictions Mean           1160.1675
V Predictions Std            352.96494
V Predictions Max            1600.5157
V Predictions Min            238.53593
Log Pis Mean                 2.0812213
Log Pis Std                  3.5720465
Log Pis Max                  10.83307
Log Pis Min                  -7.1530313
Policy mu Mean               -0.09093547
Policy mu Std                1.1156846
Policy mu Max                2.9271843
Policy mu Min                -2.662121
Policy log std Mean          -0.689069
Policy log std Std           0.28843305
Policy log std Max           0.067103595
Policy log std Min           -2.1973782
Z mean eval                  3.6567218
Z variance eval              0.49369374
total_rewards                [ -36.8091144  -156.1985081  -174.6814037  -128.81790582 -154.86527045
 -197.63797299 -127.66125361   89.27293924  158.03670667 -213.91174586]
total_rewards_mean           -94.3273529019358
total_rewards_std            119.13393505753616
total_rewards_max            158.03670666722545
total_rewards_min            -213.91174585927416
Number of train steps total  56000
Number of env steps total    72000
Number of rollouts total     0
Train Time (s)               130.1818589628674
(Previous) Eval Time (s)     29.122396487742662
Sample Time (s)              21.434017781168222
Epoch Time (s)               180.7382732317783
Total Train Time (s)         2490.0648383456282
Epoch                        13
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:29:13.682733 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #13 | Epoch Duration: 180.7751545906067
2020-01-13 05:29:13.683045 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #13 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6372764
Z variance train             0.4981719
KL Divergence                34.176537
KL Loss                      3.4176538
QF Loss                      126.903725
VF Loss                      39.71082
Policy Loss                  -126.471565
Q Predictions Mean           125.07967
Q Predictions Std            83.78963
Q Predictions Max            286.08456
Q Predictions Min            -5.269777
V Predictions Mean           126.79259
V Predictions Std            81.80393
V Predictions Max            284.20685
V Predictions Min            5.2241635
Log Pis Mean                 -1.0013871
Log Pis Std                  2.427872
Log Pis Max                  5.6562815
Log Pis Min                  -7.979854
Policy mu Mean               0.031507198
Policy mu Std                0.79861003
Policy mu Max                2.0504718
Policy mu Min                -2.1677756
Policy log std Mean          -0.42148766
Policy log std Std           0.14036319
Policy log std Max           -0.008866459
Policy log std Min           -0.95062184
Z mean eval                  3.3755288
Z variance eval              0.1052945
total_rewards                [3295.73236044 2180.79173795 1144.69896815 2952.72799889  796.64186604
  748.15212671 1644.70985189 3092.68897045 2419.83583234 1108.08118181]
total_rewards_mean           1938.406089466124
total_rewards_std            928.4436372484946
total_rewards_max            3295.7323604354574
total_rewards_min            748.1521267073686
Number of train steps total  60000
Number of env steps total    77000
Number of rollouts total     0
Train Time (s)               128.93980638682842
(Previous) Eval Time (s)     29.158937103115022
Sample Time (s)              22.863312010187656
Epoch Time (s)               180.9620555001311
Total Train Time (s)         2669.323775230907
Epoch                        14
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:32:12.942591 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #14 | Epoch Duration: 179.2593710422516
2020-01-13 05:32:12.942777 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #14 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3997025
Z variance train             0.102890216
KL Divergence                32.982258
KL Loss                      3.2982259
QF Loss                      307.0948
VF Loss                      86.77702
Policy Loss                  -315.21948
Q Predictions Mean           314.04953
Q Predictions Std            170.81084
Q Predictions Max            695.43976
Q Predictions Min            32.024178
V Predictions Mean           319.6922
V Predictions Std            167.2148
V Predictions Max            679.3502
V Predictions Min            42.6675
Log Pis Mean                 1.4561081
Log Pis Std                  3.2725234
Log Pis Max                  11.223267
Log Pis Min                  -7.195695
Policy mu Mean               -0.24651778
Policy mu Std                1.0413717
Policy mu Max                2.525249
Policy mu Min                -2.667503
Policy log std Mean          -0.5262465
Policy log std Std           0.23187946
Policy log std Max           -0.021392733
Policy log std Min           -1.9235295
Z mean eval                  3.1349173
Z variance eval              0.04281784
total_rewards                [4234.56314653 4264.00896932 4260.53749549 4385.13189164 4228.74799611
 4319.0442779  4369.6858946  4322.21367329 4302.15962112 4284.55897609]
total_rewards_mean           4297.0651942081295
total_rewards_std            50.327056756764094
total_rewards_max            4385.13189164424
total_rewards_min            4228.747996108382
Number of train steps total  64000
Number of env steps total    82000
Number of rollouts total     0
Train Time (s)               131.34337706072256
(Previous) Eval Time (s)     27.455909217707813
Sample Time (s)              21.889320896472782
Epoch Time (s)               180.68860717490315
Total Train Time (s)         2850.9766789362766
Epoch                        15
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:35:14.596884 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #15 | Epoch Duration: 181.65394949913025
2020-01-13 05:35:14.597115 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #15 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1758802
Z variance train             0.046649802
KL Divergence                31.605791
KL Loss                      3.1605792
QF Loss                      257.94617
VF Loss                      152.63263
Policy Loss                  -514.93146
Q Predictions Mean           513.5797
Q Predictions Std            237.39479
Q Predictions Max            913.9772
Q Predictions Min            76.94611
V Predictions Mean           520.4238
V Predictions Std            232.5832
V Predictions Max            907.5188
V Predictions Min            83.43394
Log Pis Mean                 2.2776074
Log Pis Std                  3.6150987
Log Pis Max                  10.84625
Log Pis Min                  -7.027669
Policy mu Mean               -0.078368105
Policy mu Std                1.1698179
Policy mu Max                3.0654695
Policy mu Min                -3.3193562
Policy log std Mean          -0.57341456
Policy log std Std           0.28467968
Policy log std Max           0.045040518
Policy log std Min           -2.0528831
Z mean eval                  3.3715692
Z variance eval              0.07636393
total_rewards                [5060.17853444 4900.46065305 5195.35539736 5141.54338901 4854.80626351
 4988.26022568 5019.56588247  806.61992041 5206.96528536 5013.65166856]
total_rewards_mean           4618.740721985028
total_rewards_std            1275.429370275107
total_rewards_max            5206.965285361491
total_rewards_min            806.6199204090998
Number of train steps total  68000
Number of env steps total    87000
Number of rollouts total     0
Train Time (s)               129.2152941408567
(Previous) Eval Time (s)     28.420892297755927
Sample Time (s)              22.666839251760393
Epoch Time (s)               180.30302569037303
Total Train Time (s)         3029.9026152384467
Epoch                        16
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:38:13.524586 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #16 | Epoch Duration: 178.9273064136505
2020-01-13 05:38:13.524849 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #16 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3687186
Z variance train             0.07645639
KL Divergence                33.66046
KL Loss                      3.3660462
QF Loss                      237.19162
VF Loss                      369.51147
Policy Loss                  -707.0577
Q Predictions Mean           703.8412
Q Predictions Std            274.73364
Q Predictions Max            1142.3159
Q Predictions Min            111.46911
V Predictions Mean           720.35065
V Predictions Std            272.94214
V Predictions Max            1137.61
V Predictions Min            117.03512
Log Pis Mean                 1.7108302
Log Pis Std                  3.4725194
Log Pis Max                  10.953691
Log Pis Min                  -6.251592
Policy mu Mean               -0.044311758
Policy mu Std                1.1341559
Policy mu Max                2.626416
Policy mu Min                -2.6953824
Policy log std Mean          -0.6024892
Policy log std Std           0.30754912
Policy log std Max           0.19851574
Policy log std Min           -2.1112213
Z mean eval                  3.6421828
Z variance eval              0.06564971
total_rewards                [5100.37908094 5426.29536096 5414.56345856 5334.96555087 5251.70967878
 5410.08125922 5302.84874723 5329.47500375 5202.39073643 5209.62421043]
total_rewards_mean           5298.2333087168245
total_rewards_std            101.5565236546283
total_rewards_max            5426.295360962948
total_rewards_min            5100.379080936579
Number of train steps total  72000
Number of env steps total    92000
Number of rollouts total     0
Train Time (s)               123.16809961525723
(Previous) Eval Time (s)     27.044835323933512
Sample Time (s)              22.352531130425632
Epoch Time (s)               172.56546606961638
Total Train Time (s)         3200.117924714461
Epoch                        17
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:41:03.740636 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #17 | Epoch Duration: 170.21561741828918
2020-01-13 05:41:03.740820 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #17 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6449714
Z variance train             0.06561594
KL Divergence                39.27327
KL Loss                      3.927327
QF Loss                      363.82822
VF Loss                      160.76335
Policy Loss                  -995.2493
Q Predictions Mean           993.6718
Q Predictions Std            292.72653
Q Predictions Max            1423.2843
Q Predictions Min            161.0471
V Predictions Mean           987.3785
V Predictions Std            285.86142
V Predictions Max            1393.9546
V Predictions Min            159.66449
Log Pis Mean                 1.8569582
Log Pis Std                  3.3206835
Log Pis Max                  11.496464
Log Pis Min                  -6.363332
Policy mu Mean               -0.11534414
Policy mu Std                1.0850831
Policy mu Max                2.6259472
Policy mu Min                -2.533559
Policy log std Mean          -0.6613539
Policy log std Std           0.32039866
Policy log std Max           0.16139877
Policy log std Min           -2.2334356
Z mean eval                  3.7705321
Z variance eval              0.07586223
total_rewards                [5804.5543989  5677.39840781 5740.51428601 5729.73457723 5728.1389424
 5805.91113306 5675.50516567 5831.91568631 5775.27409792 5769.91253117]
total_rewards_mean           5753.885922648181
total_rewards_std            50.49331181306233
total_rewards_max            5831.91568631039
total_rewards_min            5675.505165665409
Number of train steps total  76000
Number of env steps total    97000
Number of rollouts total     0
Train Time (s)               123.52586705423892
(Previous) Eval Time (s)     24.694634588900954
Sample Time (s)              21.79766699159518
Epoch Time (s)               170.01816863473505
Total Train Time (s)         3373.6552481832914
Epoch                        18
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:43:57.280102 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #18 | Epoch Duration: 173.53914546966553
2020-01-13 05:43:57.280290 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #18 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7682464
Z variance train             0.075497925
KL Divergence                41.249226
KL Loss                      4.1249228
QF Loss                      300.16595
VF Loss                      136.98318
Policy Loss                  -1150.2463
Q Predictions Mean           1142.3959
Q Predictions Std            338.14542
Q Predictions Max            1605.4017
Q Predictions Min            188.82161
V Predictions Mean           1155.4961
V Predictions Std            335.60846
V Predictions Max            1599.3436
V Predictions Min            186.57741
Log Pis Mean                 2.4569607
Log Pis Std                  3.4554188
Log Pis Max                  11.9238205
Log Pis Min                  -5.389331
Policy mu Mean               -0.071816504
Policy mu Std                1.1479833
Policy mu Max                2.898211
Policy mu Min                -3.1957533
Policy log std Mean          -0.6823408
Policy log std Std           0.32499877
Policy log std Max           0.012519717
Policy log std Min           -2.4453304
Z mean eval                  3.1633363
Z variance eval              0.04837089
total_rewards                [5900.72564731 5680.03199623 5735.05006899 5739.75548267 5544.28907136
 4424.9149741  5558.81733279 2579.11898236 5798.69777445 5919.16863554]
total_rewards_mean           5288.056996580424
total_rewards_std            990.6675961979083
total_rewards_max            5919.16863553579
total_rewards_min            2579.1189823609384
Number of train steps total  80000
Number of env steps total    102000
Number of rollouts total     0
Train Time (s)               129.22394039388746
(Previous) Eval Time (s)     28.215255594812334
Sample Time (s)              22.336782671511173
Epoch Time (s)               179.77597866021097
Total Train Time (s)         3552.1223400854506
Epoch                        19
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:46:55.747397 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #19 | Epoch Duration: 178.46697330474854
2020-01-13 05:46:55.747574 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #19 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1631436
Z variance train             0.048215784
KL Divergence                30.778343
KL Loss                      3.0778344
QF Loss                      319.99094
VF Loss                      123.188354
Policy Loss                  -1183.7705
Q Predictions Mean           1179.4932
Q Predictions Std            367.69342
Q Predictions Max            1649.735
Q Predictions Min            140.87694
V Predictions Mean           1182.5483
V Predictions Std            362.66364
V Predictions Max            1645.4651
V Predictions Min            140.99182
Log Pis Mean                 2.6175241
Log Pis Std                  3.6392217
Log Pis Max                  14.787273
Log Pis Min                  -6.9086266
Policy mu Mean               -0.07920305
Policy mu Std                1.20897
Policy mu Max                2.7068806
Policy mu Min                -2.7520669
Policy log std Mean          -0.66368383
Policy log std Std           0.31987143
Policy log std Max           0.059047997
Policy log std Min           -2.5051956
Z mean eval                  3.3186173
Z variance eval              0.036925163
total_rewards                [6134.95951347 5943.31704412 5901.98211124 2865.08261409 6060.52561289
 5912.80791059 6297.59360798 5961.1806568  5886.05327594 6102.51571282]
total_rewards_mean           5706.601805992893
total_rewards_std            955.1305974972731
total_rewards_max            6297.593607980664
total_rewards_min            2865.0826140942327
Number of train steps total  84000
Number of env steps total    107000
Number of rollouts total     0
Train Time (s)               130.8296263399534
(Previous) Eval Time (s)     26.905895155854523
Sample Time (s)              23.317497067153454
Epoch Time (s)               181.05301856296137
Total Train Time (s)         3735.1258157845587
Epoch                        20
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:49:58.751738 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #20 | Epoch Duration: 183.0040476322174
2020-01-13 05:49:58.751860 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #20 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3154252
Z variance train             0.03694842
KL Divergence                33.74419
KL Loss                      3.374419
QF Loss                      305.75467
VF Loss                      272.01028
Policy Loss                  -1361.9922
Q Predictions Mean           1365.5519
Q Predictions Std            408.49115
Q Predictions Max            1918.805
Q Predictions Min            184.03975
V Predictions Mean           1373.8362
V Predictions Std            404.64392
V Predictions Max            1918.8484
V Predictions Min            193.62068
Log Pis Mean                 2.5569022
Log Pis Std                  3.5145495
Log Pis Max                  11.4427185
Log Pis Min                  -7.5079527
Policy mu Mean               -0.15488313
Policy mu Std                1.1716411
Policy mu Max                2.7621584
Policy mu Min                -3.3829222
Policy log std Mean          -0.6833522
Policy log std Std           0.31158516
Policy log std Max           -0.0071877837
Policy log std Min           -2.4105546
Z mean eval                  3.014462
Z variance eval              0.015547341
total_rewards                [6215.96184663 6009.27284372 6039.24191201 6383.7608607  6162.07084103
 6449.81955384 6205.79210816 6302.5590537  6111.97093298 6249.61023152]
total_rewards_mean           6213.006018428192
total_rewards_std            133.8513767658066
total_rewards_max            6449.819553837399
total_rewards_min            6009.2728437196165
Number of train steps total  88000
Number of env steps total    112000
Number of rollouts total     0
Train Time (s)               129.4730632849969
(Previous) Eval Time (s)     28.85653845826164
Sample Time (s)              22.905380211304873
Epoch Time (s)               181.2349819545634
Total Train Time (s)         3915.6751098893583
Epoch                        21
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:52:59.302881 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #21 | Epoch Duration: 180.55091547966003
2020-01-13 05:52:59.303078 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #21 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0140688
Z variance train             0.015512285
KL Divergence                31.418806
KL Loss                      3.1418808
QF Loss                      441.72858
VF Loss                      130.98154
Policy Loss                  -1398.5823
Q Predictions Mean           1387.2682
Q Predictions Std            447.0148
Q Predictions Max            1937.486
Q Predictions Min            141.20197
V Predictions Mean           1398.7803
V Predictions Std            439.5104
V Predictions Max            1944.1055
V Predictions Min            169.8765
Log Pis Mean                 2.8534946
Log Pis Std                  3.7383325
Log Pis Max                  14.879341
Log Pis Min                  -7.782638
Policy mu Mean               -0.20583676
Policy mu Std                1.200687
Policy mu Max                2.8253536
Policy mu Min                -3.233415
Policy log std Mean          -0.6688176
Policy log std Std           0.32994142
Policy log std Max           -0.013836741
Policy log std Min           -2.481128
Z mean eval                  3.191815
Z variance eval              0.022232845
total_rewards                [6199.72661119 6444.25730971 6392.39381991 6379.86881536 6087.57578696
 6257.83963798 6191.44067251 6302.61832722 6445.36946509 6089.82633546]
total_rewards_mean           6279.091678138143
total_rewards_std            128.61095077236965
total_rewards_max            6445.369465094959
total_rewards_min            6087.575786955633
Number of train steps total  92000
Number of env steps total    117000
Number of rollouts total     0
Train Time (s)               131.9691874613054
(Previous) Eval Time (s)     28.172040863893926
Sample Time (s)              22.722415299154818
Epoch Time (s)               182.86364362435415
Total Train Time (s)         4098.744801192079
Epoch                        22
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:56:02.374064 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #22 | Epoch Duration: 183.07084488868713
2020-01-13 05:56:02.374255 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #22 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1919568
Z variance train             0.022225413
KL Divergence                34.592155
KL Loss                      3.4592156
QF Loss                      488.9791
VF Loss                      126.824455
Policy Loss                  -1581.8475
Q Predictions Mean           1582.3805
Q Predictions Std            460.6288
Q Predictions Max            2130.2314
Q Predictions Min            157.48376
V Predictions Mean           1584.9608
V Predictions Std            454.4133
V Predictions Max            2112.9177
V Predictions Min            202.4124
Log Pis Mean                 2.9491231
Log Pis Std                  3.6250567
Log Pis Max                  16.33096
Log Pis Min                  -7.3068986
Policy mu Mean               -0.16622105
Policy mu Std                1.2103369
Policy mu Max                3.1126993
Policy mu Min                -2.9261339
Policy log std Mean          -0.6901393
Policy log std Std           0.31965294
Policy log std Max           0.046164215
Policy log std Min           -2.4398572
Z mean eval                  3.0484207
Z variance eval              0.005374048
total_rewards                [6285.28100117 6448.44017453 6460.18274573 6531.74776013 6423.82712875
 6340.75804291 6300.91029289 6325.68889468 6403.57601156 6413.08522562]
total_rewards_mean           6393.349727797934
total_rewards_std            74.5964718613045
total_rewards_max            6531.747760128963
total_rewards_min            6285.281001172277
Number of train steps total  96000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               130.93837029207498
(Previous) Eval Time (s)     28.378850155044347
Sample Time (s)              22.857169268652797
Epoch Time (s)               182.17438971577212
Total Train Time (s)         4280.332204652019
Epoch                        23
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:59:03.962929 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #23 | Epoch Duration: 181.58852195739746
2020-01-13 05:59:03.963228 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #23 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0520778
Z variance train             0.0053817253
KL Divergence                35.592052
KL Loss                      3.5592053
QF Loss                      237.66092
VF Loss                      549.8726
Policy Loss                  -1674.9352
Q Predictions Mean           1663.0486
Q Predictions Std            461.66718
Q Predictions Max            2198.0571
Q Predictions Min            177.30984
V Predictions Mean           1655.0222
V Predictions Std            454.30902
V Predictions Max            2179.1755
V Predictions Min            183.76224
Log Pis Mean                 2.7996504
Log Pis Std                  3.4347994
Log Pis Max                  12.336286
Log Pis Min                  -5.319101
Policy mu Mean               -0.121140935
Policy mu Std                1.1818665
Policy mu Max                2.9963696
Policy mu Min                -2.5996115
Policy log std Mean          -0.7100165
Policy log std Std           0.35074544
Policy log std Max           0.07099396
Policy log std Min           -2.466443
Z mean eval                  2.9871888
Z variance eval              0.012042919
total_rewards                [1594.42680131 6417.9397775  6568.55467735 6604.43979352 6543.88342012
 6515.1274927  6470.28228793 6560.58037607 6536.13591469 6494.69219029]
total_rewards_mean           6030.606273148825
total_rewards_std            1479.5853030887333
total_rewards_max            6604.439793520932
total_rewards_min            1594.4268013091976
Number of train steps total  100000
Number of env steps total    127000
Number of rollouts total     0
Train Time (s)               123.67821048386395
(Previous) Eval Time (s)     27.79266486596316
Sample Time (s)              21.284809654578567
Epoch Time (s)               172.75568500440568
Total Train Time (s)         4452.0807642238215
Epoch                        24
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:01:55.712884 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #24 | Epoch Duration: 171.74947834014893
2020-01-13 06:01:55.713134 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #24 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.9814115
Z variance train             0.01214691
KL Divergence                33.56402
KL Loss                      3.356402
QF Loss                      414.94223
VF Loss                      156.36028
Policy Loss                  -1708.2306
Q Predictions Mean           1695.4175
Q Predictions Std            510.81042
Q Predictions Max            2268.0173
Q Predictions Min            132.98538
V Predictions Mean           1710.2576
V Predictions Std            507.53253
V Predictions Max            2283.7993
V Predictions Min            114.58119
Log Pis Mean                 3.1766524
Log Pis Std                  3.7197855
Log Pis Max                  14.154161
Log Pis Min                  -5.966485
Policy mu Mean               -0.19161926
Policy mu Std                1.208029
Policy mu Max                2.7934895
Policy mu Min                -2.9292579
Policy log std Mean          -0.6942255
Policy log std Std           0.34347638
Policy log std Max           0.12611717
Policy log std Min           -2.491851
Z mean eval                  9.477341
Z variance eval              0.002764418
total_rewards                [6306.62993922 6660.55980334 6501.94735716 6586.42007741 6579.02267331
 6502.22277983 6634.27119599 6585.31519917 6587.05770547 5801.11891017]
total_rewards_mean           6474.456564107585
total_rewards_std            243.24673983422852
total_rewards_max            6660.559803344428
total_rewards_min            5801.118910170033
Number of train steps total  104000
Number of env steps total    132000
Number of rollouts total     0
Train Time (s)               123.96559700090438
(Previous) Eval Time (s)     26.786147165112197
Sample Time (s)              20.660265852697194
Epoch Time (s)               171.41201001871377
Total Train Time (s)         4623.670172691811
Epoch                        25
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:04:47.303335 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #25 | Epoch Duration: 171.59004092216492
2020-01-13 06:04:47.303514 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #25 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2101562
Z variance train             0.013140964
KL Divergence                36.363773
KL Loss                      3.6363773
QF Loss                      8564.728
VF Loss                      4372.785
Policy Loss                  -1904.6907
Q Predictions Mean           1865.479
Q Predictions Std            532.69855
Q Predictions Max            2463.7375
Q Predictions Min            177.88124
V Predictions Mean           1843.4552
V Predictions Std            512.55035
V Predictions Max            2418.921
V Predictions Min            209.83717
Log Pis Mean                 3.3248105
Log Pis Std                  3.8009684
Log Pis Max                  14.595114
Log Pis Min                  -8.16495
Policy mu Mean               -0.1663709
Policy mu Std                1.2217265
Policy mu Max                2.891216
Policy mu Min                -2.8842776
Policy log std Mean          -0.71254236
Policy log std Std           0.352639
Policy log std Max           0.028416514
Policy log std Min           -2.4217834
Z mean eval                  3.363985
Z variance eval              0.00442891
total_rewards                [6697.67107497 6665.57472359 6611.69822326 6752.29447785 6626.67684108
 6776.37790482 6921.27372518 6767.35397044 6839.03303231 6835.24044818]
total_rewards_mean           6749.319442169623
total_rewards_std            94.72434620816757
total_rewards_max            6921.2737251814415
total_rewards_min            6611.698223257581
Number of train steps total  108000
Number of env steps total    137000
Number of rollouts total     0
Train Time (s)               128.87589364731684
(Previous) Eval Time (s)     26.963851255830377
Sample Time (s)              21.942118760198355
Epoch Time (s)               177.78186366334558
Total Train Time (s)         4803.0697855656035
Epoch                        26
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:07:46.704190 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #26 | Epoch Duration: 179.40053987503052
2020-01-13 06:07:46.704367 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #26 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.364259
Z variance train             0.0044291676
KL Divergence                40.76333
KL Loss                      4.076333
QF Loss                      324.02594
VF Loss                      134.93645
Policy Loss                  -2020.1102
Q Predictions Mean           2018.3379
Q Predictions Std            554.0734
Q Predictions Max            2623.944
Q Predictions Min            274.7603
V Predictions Mean           2020.5652
V Predictions Std            552.72217
V Predictions Max            2625.1394
V Predictions Min            267.43265
Log Pis Mean                 3.6147532
Log Pis Std                  4.1372495
Log Pis Max                  15.715808
Log Pis Min                  -5.683863
Policy mu Mean               -0.17974214
Policy mu Std                1.2549546
Policy mu Max                2.970281
Policy mu Min                -3.0822823
Policy log std Mean          -0.7199883
Policy log std Std           0.35645357
Policy log std Max           0.0359928
Policy log std Min           -2.6361003
Z mean eval                  3.356264
Z variance eval              0.0022607388
total_rewards                [6416.79489534 6372.5523814  6405.74086524 6492.62109844 6448.65998807
 6468.97455898 6523.98373537 6540.10499206 6328.97775426 6419.70765679]
total_rewards_mean           6441.811792595114
total_rewards_std            63.026991420651754
total_rewards_max            6540.104992064311
total_rewards_min            6328.977754256333
Number of train steps total  112000
Number of env steps total    142000
Number of rollouts total     0
Train Time (s)               130.24461879162118
(Previous) Eval Time (s)     28.58218658901751
Sample Time (s)              21.65817698603496
Epoch Time (s)               180.48498236667365
Total Train Time (s)         4983.560703010298
Epoch                        27
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:10:47.196576 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #27 | Epoch Duration: 180.49207091331482
2020-01-13 06:10:47.196775 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #27 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3540566
Z variance train             0.002264163
KL Divergence                42.00614
KL Loss                      4.2006145
QF Loss                      449.69196
VF Loss                      127.19615
Policy Loss                  -2106.7776
Q Predictions Mean           2097.3752
Q Predictions Std            508.61044
Q Predictions Max            2660.1777
Q Predictions Min            255.56567
V Predictions Mean           2107.7368
V Predictions Std            503.51538
V Predictions Max            2643.1108
V Predictions Min            263.97794
Log Pis Mean                 3.054508
Log Pis Std                  3.7534738
Log Pis Max                  19.287638
Log Pis Min                  -6.237936
Policy mu Mean               -0.12243194
Policy mu Std                1.2241416
Policy mu Max                3.3089013
Policy mu Min                -2.9619744
Policy log std Mean          -0.7442003
Policy log std Std           0.35709494
Policy log std Max           0.031048
Policy log std Min           -2.6519399
Z mean eval                  3.3839574
Z variance eval              0.0018778114
total_rewards                [6921.73107686 7040.73250632 6868.88238975 6901.54474338 6816.96750326
 7058.40852783 6730.48924246 6843.82644776 7052.387959   7137.74885931]
total_rewards_mean           6937.271925594064
total_rewards_std            122.87401588977333
total_rewards_max            7137.748859310405
total_rewards_min            6730.489242464658
Number of train steps total  116000
Number of env steps total    147000
Number of rollouts total     0
Train Time (s)               130.59882841305807
(Previous) Eval Time (s)     28.588906107936054
Sample Time (s)              22.64557435316965
Epoch Time (s)               181.83330887416378
Total Train Time (s)         5163.869703121018
Epoch                        28
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:13:47.507353 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #28 | Epoch Duration: 180.31040501594543
2020-01-13 06:13:47.507719 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #28 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3848312
Z variance train             0.0018795282
KL Divergence                43.644745
KL Loss                      4.364475
QF Loss                      360.82114
VF Loss                      178.77127
Policy Loss                  -2152.8962
Q Predictions Mean           2150.8745
Q Predictions Std            535.33636
Q Predictions Max            2753.7183
Q Predictions Min            239.64326
V Predictions Mean           2158.2087
V Predictions Std            531.1472
V Predictions Max            2724.2712
V Predictions Min            250.45001
Log Pis Mean                 3.555103
Log Pis Std                  3.891474
Log Pis Max                  12.9723835
Log Pis Min                  -6.598531
Policy mu Mean               -0.18763006
Policy mu Std                1.264201
Policy mu Max                2.8253288
Policy mu Min                -2.9070144
Policy log std Mean          -0.7354279
Policy log std Std           0.37099883
Policy log std Max           0.088061154
Policy log std Min           -2.5716176
Z mean eval                  3.368135
Z variance eval              0.01702785
total_rewards                [6920.44113527 7066.86259714 6897.65810578 7022.18359356 6854.99637406
 7027.72569622 6900.64631461 7078.46042743 7221.07026113 7128.98953236]
total_rewards_mean           7011.903403756875
total_rewards_std            111.21223126679905
total_rewards_max            7221.070261131195
total_rewards_min            6854.996374064471
Number of train steps total  120000
Number of env steps total    152000
Number of rollouts total     0
Train Time (s)               131.88447309238836
(Previous) Eval Time (s)     27.065633257851005
Sample Time (s)              22.365810960531235
Epoch Time (s)               181.3159173107706
Total Train Time (s)         5346.034134052694
Epoch                        29
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:16:49.672857 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #29 | Epoch Duration: 182.16489100456238
2020-01-13 06:16:49.673046 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #29 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3679378
Z variance train             0.01704571
KL Divergence                40.32138
KL Loss                      4.0321383
QF Loss                      313.42676
VF Loss                      142.77972
Policy Loss                  -2158.2234
Q Predictions Mean           2154.0327
Q Predictions Std            535.416
Q Predictions Max            2745.9343
Q Predictions Min            221.1774
V Predictions Mean           2160.1472
V Predictions Std            526.2562
V Predictions Max            2721.8105
V Predictions Min            236.2797
Log Pis Mean                 3.5804894
Log Pis Std                  3.7363822
Log Pis Max                  16.892467
Log Pis Min                  -5.189193
Policy mu Mean               -0.17499824
Policy mu Std                1.253051
Policy mu Max                2.8261294
Policy mu Min                -2.754617
Policy log std Mean          -0.73798424
Policy log std Std           0.35006654
Policy log std Max           -0.06612271
Policy log std Min           -2.7007744
Z mean eval                  3.368475
Z variance eval              0.021518553
total_rewards                [7163.8042281  7056.53720762 7159.85593267 7194.66096308 7102.25325951
 7082.15223487 7121.75020434 7033.68951604 7010.36461299 7269.90113668]
total_rewards_mean           7119.496929589644
total_rewards_std            75.36364656601455
total_rewards_max            7269.901136679905
total_rewards_min            7010.364612986954
Number of train steps total  124000
Number of env steps total    157000
Number of rollouts total     0
Train Time (s)               130.60673607327044
(Previous) Eval Time (s)     27.91426402889192
Sample Time (s)              22.62748222472146
Epoch Time (s)               181.14848232688382
Total Train Time (s)         5526.663192850538
Epoch                        30
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:19:50.303132 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #30 | Epoch Duration: 180.6299479007721
2020-01-13 06:19:50.303382 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #30 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.369891
Z variance train             0.021530043
KL Divergence                38.198654
KL Loss                      3.8198655
QF Loss                      263.0645
VF Loss                      295.64322
Policy Loss                  -2162.6565
Q Predictions Mean           2154.368
Q Predictions Std            562.03955
Q Predictions Max            2727.499
Q Predictions Min            217.64743
V Predictions Mean           2149.3108
V Predictions Std            558.32587
V Predictions Max            2718.0288
V Predictions Min            209.06416
Log Pis Mean                 3.3862288
Log Pis Std                  3.620476
Log Pis Max                  13.890592
Log Pis Min                  -5.745482
Policy mu Mean               -0.10334504
Policy mu Std                1.2282255
Policy mu Max                2.908636
Policy mu Min                -3.664404
Policy log std Mean          -0.73917836
Policy log std Std           0.38054654
Policy log std Max           -0.0107058585
Policy log std Min           -2.775342
Z mean eval                  3.392859
Z variance eval              0.023717308
total_rewards                [7076.0030021  6946.92322854 6803.33423468 6734.21322237 6830.48559058
 7199.43087604 7265.80388501 1051.86046697 6901.04815702 2721.26764457]
total_rewards_mean           5953.037030788399
total_rewards_std            2073.48654447131
total_rewards_max            7265.803885005732
total_rewards_min            1051.860466968329
Number of train steps total  128000
Number of env steps total    162000
Number of rollouts total     0
Train Time (s)               124.3733270871453
(Previous) Eval Time (s)     27.395411149132997
Sample Time (s)              21.152085807174444
Epoch Time (s)               172.92082404345274
Total Train Time (s)         5699.098671669606
Epoch                        31
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:22:42.740147 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #31 | Epoch Duration: 172.43662405014038
2020-01-13 06:22:42.740339 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #31 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3926091
Z variance train             0.023670942
KL Divergence                38.39347
KL Loss                      3.8393471
QF Loss                      384.14142
VF Loss                      127.45589
Policy Loss                  -2327.983
Q Predictions Mean           2319.4482
Q Predictions Std            542.7313
Q Predictions Max            2944.1096
Q Predictions Min            225.09384
V Predictions Mean           2322.6406
V Predictions Std            537.61487
V Predictions Max            2938.5366
V Predictions Min            236.86671
Log Pis Mean                 3.5351095
Log Pis Std                  4.29892
Log Pis Max                  20.472887
Log Pis Min                  -9.235671
Policy mu Mean               -0.16896981
Policy mu Std                1.2432203
Policy mu Max                3.3368623
Policy mu Min                -3.007094
Policy log std Mean          -0.74196553
Policy log std Std           0.36051998
Policy log std Max           0.0043044686
Policy log std Min           -2.6688557
Z mean eval                  3.415507
Z variance eval              0.006382107
total_rewards                [7391.39757778 7391.11496515 7584.22095997 7366.41607186 7508.39413887
 7226.20245224 7245.20584877 7369.73124807 7596.850535   7662.05897335]
total_rewards_mean           7434.159277104578
total_rewards_std            140.6438650998211
total_rewards_max            7662.058973352278
total_rewards_min            7226.202452235691
Number of train steps total  132000
Number of env steps total    167000
Number of rollouts total     0
Train Time (s)               124.21886191377416
(Previous) Eval Time (s)     26.910898922011256
Sample Time (s)              22.150590432807803
Epoch Time (s)               173.28035126859322
Total Train Time (s)         5871.903611478861
Epoch                        32
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:25:35.545185 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #32 | Epoch Duration: 172.80472469329834
2020-01-13 06:25:35.545306 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #32 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.415795
Z variance train             0.00637673
KL Divergence                41.399868
KL Loss                      4.139987
QF Loss                      343.3113
VF Loss                      121.057175
Policy Loss                  -2391.5566
Q Predictions Mean           2391.8481
Q Predictions Std            561.4024
Q Predictions Max            2961.9128
Q Predictions Min            230.6759
V Predictions Mean           2389.1333
V Predictions Std            553.5094
V Predictions Max            2925.8203
V Predictions Min            242.88972
Log Pis Mean                 3.9520717
Log Pis Std                  3.7068655
Log Pis Max                  11.90935
Log Pis Min                  -5.810215
Policy mu Mean               -0.16803765
Policy mu Std                1.2945057
Policy mu Max                2.9174583
Policy mu Min                -2.7500472
Policy log std Mean          -0.7534251
Policy log std Std           0.36012858
Policy log std Max           -0.029353082
Policy log std Min           -2.8747842
Z mean eval                  3.3946183
Z variance eval              0.015025425
total_rewards                [4772.92320262 7066.79274801 6799.97276844 6975.5475733  6967.72121032
 6764.83662654 6988.16189612 6911.46571808 6808.60985494 6840.71252176]
total_rewards_mean           6689.674412013311
total_rewards_std            645.619572360354
total_rewards_max            7066.792748014703
total_rewards_min            4772.923202624776
Number of train steps total  136000
Number of env steps total    172000
Number of rollouts total     0
Train Time (s)               127.82706660265103
(Previous) Eval Time (s)     26.43495371611789
Sample Time (s)              21.531948121264577
Epoch Time (s)               175.7939684400335
Total Train Time (s)         6049.802428117488
Epoch                        33
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:28:33.446462 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #33 | Epoch Duration: 177.90104126930237
2020-01-13 06:28:33.446651 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #33 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3958008
Z variance train             0.014995404
KL Divergence                39.124454
KL Loss                      3.9124455
QF Loss                      278.10175
VF Loss                      275.4385
Policy Loss                  -2406.154
Q Predictions Mean           2404.661
Q Predictions Std            517.94354
Q Predictions Max            2963.874
Q Predictions Min            227.84941
V Predictions Mean           2407.6348
V Predictions Std            507.6895
V Predictions Max            2960.4585
V Predictions Min            212.2672
Log Pis Mean                 3.6348429
Log Pis Std                  3.3478744
Log Pis Max                  14.952033
Log Pis Min                  -4.0045137
Policy mu Mean               -0.15339136
Policy mu Std                1.2603524
Policy mu Max                3.081188
Policy mu Min                -3.1712935
Policy log std Mean          -0.74263173
Policy log std Std           0.36738974
Policy log std Max           0.032737613
Policy log std Min           -2.8910902
Z mean eval                  3.410253
Z variance eval              0.017239574
total_rewards                [7364.78578203 7680.06804702 7542.42246319 7613.85510542 7468.79627806
 7695.7554621  7574.99713862 7585.1682485  7531.1072544  7618.73743178]
total_rewards_mean           7567.569321112298
total_rewards_std            93.3017784919783
total_rewards_max            7695.75546210005
total_rewards_min            7364.785782030168
Number of train steps total  140000
Number of env steps total    177000
Number of rollouts total     0
Train Time (s)               131.33876786893234
(Previous) Eval Time (s)     28.54165337001905
Sample Time (s)              22.60622285399586
Epoch Time (s)               182.48664409294724
Total Train Time (s)         6232.187437824439
Epoch                        34
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:31:35.833035 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #34 | Epoch Duration: 182.38624382019043
2020-01-13 06:31:35.833238 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #34 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.410155
Z variance train             0.01722094
KL Divergence                39.911186
KL Loss                      3.9911187
QF Loss                      505.76843
VF Loss                      167.14012
Policy Loss                  -2395.6917
Q Predictions Mean           2398.0562
Q Predictions Std            546.89514
Q Predictions Max            2985.2983
Q Predictions Min            199.58653
V Predictions Mean           2400.9512
V Predictions Std            545.8722
V Predictions Max            2963.514
V Predictions Min            186.07184
Log Pis Mean                 3.7800748
Log Pis Std                  3.8016832
Log Pis Max                  14.067865
Log Pis Min                  -8.1299305
Policy mu Mean               -0.16407019
Policy mu Std                1.264267
Policy mu Max                3.5213206
Policy mu Min                -3.9881349
Policy log std Mean          -0.7676994
Policy log std Std           0.38152665
Policy log std Max           0.1456837
Policy log std Min           -2.7185261
Z mean eval                  3.418686
Z variance eval              0.004933527
total_rewards                [7357.44014433 7531.16507138 7661.02347492 7708.65023159 7592.85100747
 7730.66508159 7406.34914696 7429.18571631 7505.47912845 7768.88225712]
total_rewards_mean           7569.16912601049
total_rewards_std            138.15024297969043
total_rewards_max            7768.882257118361
total_rewards_min            7357.4401443304505
Number of train steps total  144000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               130.86598667968065
(Previous) Eval Time (s)     28.440871933009475
Sample Time (s)              22.931124384514987
Epoch Time (s)               182.2379829972051
Total Train Time (s)         6411.745204178616
Epoch                        35
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:34:35.392643 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #35 | Epoch Duration: 179.55925750732422
2020-01-13 06:34:35.392843 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #35 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.4185174
Z variance train             0.004946901
KL Divergence                41.80832
KL Loss                      4.180832
QF Loss                      384.024
VF Loss                      167.93312
Policy Loss                  -2388.0576
Q Predictions Mean           2392.252
Q Predictions Std            605.82153
Q Predictions Max            3010.9783
Q Predictions Min            203.85043
V Predictions Mean           2393.4004
V Predictions Std            602.55493
V Predictions Max            2995.9248
V Predictions Min            202.51698
Log Pis Mean                 4.0495825
Log Pis Std                  4.015967
Log Pis Max                  14.71815
Log Pis Min                  -5.208635
Policy mu Mean               -0.21080653
Policy mu Std                1.2606459
Policy mu Max                2.9202344
Policy mu Min                -2.8052158
Policy log std Mean          -0.76762843
Policy log std Std           0.38451442
Policy log std Max           -0.06486833
Policy log std Min           -2.8510044
Z mean eval                  3.3967462
Z variance eval              0.009118256
total_rewards                [7325.98793747 7710.24803546 7390.92139749 7461.44166392 7630.91357368
 7286.01879593 7426.81495377 7374.0746163  7383.56259071 7418.17745104]
total_rewards_mean           7440.816101576378
total_rewards_std            125.39304419423871
total_rewards_max            7710.2480354593
total_rewards_min            7286.018795926657
Number of train steps total  148000
Number of env steps total    187000
Number of rollouts total     0
Train Time (s)               131.52333965478465
(Previous) Eval Time (s)     25.761528888717294
Sample Time (s)              21.12066461984068
Epoch Time (s)               178.40553316334262
Total Train Time (s)         6593.68142091576
Epoch                        36
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:37:37.330271 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #36 | Epoch Duration: 181.93728160858154
2020-01-13 06:37:37.330472 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #36 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3985229
Z variance train             0.00911618
KL Divergence                40.174393
KL Loss                      4.0174394
QF Loss                      303.7586
VF Loss                      358.1023
Policy Loss                  -2458.1055
Q Predictions Mean           2454.3914
Q Predictions Std            559.61475
Q Predictions Max            3020.643
Q Predictions Min            213.38478
V Predictions Mean           2441.8145
V Predictions Std            554.6061
V Predictions Max            2988.5947
V Predictions Min            196.81848
Log Pis Mean                 3.886384
Log Pis Std                  3.412249
Log Pis Max                  14.009374
Log Pis Min                  -6.8719893
Policy mu Mean               -0.19674887
Policy mu Std                1.2505951
Policy mu Max                2.9575226
Policy mu Min                -3.1030357
Policy log std Mean          -0.7693289
Policy log std Std           0.38266784
Policy log std Max           0.029661119
Policy log std Min           -2.8090234
Z mean eval                  3.3917117
Z variance eval              0.0059808707
total_rewards                [7743.72059154 7900.54613814 7796.02597706 7570.63560244 7780.3673192
 7464.42584969 7733.82255555 7618.28797302 7598.81193103 7826.09923954]
total_rewards_mean           7703.27431772023
total_rewards_std            128.021138149459
total_rewards_max            7900.546138141448
total_rewards_min            7464.4258496868215
Number of train steps total  152000
Number of env steps total    192000
Number of rollouts total     0
Train Time (s)               130.36791248898953
(Previous) Eval Time (s)     29.292922229971737
Sample Time (s)              22.704581846948713
Epoch Time (s)               182.36541656590998
Total Train Time (s)         6775.943894474767
Epoch                        37
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:40:39.594003 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #37 | Epoch Duration: 182.26338911056519
2020-01-13 06:40:39.594186 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #37 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.391723
Z variance train             0.0059894114
KL Divergence                39.69423
KL Loss                      3.969423
QF Loss                      314.1435
VF Loss                      117.77113
Policy Loss                  -2411.3508
Q Predictions Mean           2413.044
Q Predictions Std            638.0413
Q Predictions Max            3141.971
Q Predictions Min            200.99226
V Predictions Mean           2412.7578
V Predictions Std            634.0952
V Predictions Max            3121.505
V Predictions Min            189.0161
Log Pis Mean                 3.5530791
Log Pis Std                  3.9879923
Log Pis Max                  18.64146
Log Pis Min                  -5.52571
Policy mu Mean               -0.15933558
Policy mu Std                1.2628475
Policy mu Max                3.1929355
Policy mu Min                -3.613269
Policy log std Mean          -0.7486895
Policy log std Std           0.3834308
Policy log std Max           0.07609749
Policy log std Min           -2.8316727
Z mean eval                  7.8169646
Z variance eval              0.0007744687
total_rewards                [4446.17939381 5027.98079373 4766.06583762 4459.24040771 4721.62308153
 2651.48531155 4937.10508287 4631.30974823 4749.87281979 5011.0660355 ]
total_rewards_mean           4540.192851234188
total_rewards_std            658.4838239067251
total_rewards_max            5027.980793731976
total_rewards_min            2651.485311545611
Number of train steps total  156000
Number of env steps total    197000
Number of rollouts total     0
Train Time (s)               124.34976431494579
(Previous) Eval Time (s)     29.19048273609951
Sample Time (s)              22.49545202497393
Epoch Time (s)               176.03569907601923
Total Train Time (s)         6950.346490285825
Epoch                        38
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:43:33.997997 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #38 | Epoch Duration: 174.40367722511292
2020-01-13 06:43:33.998176 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #38 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.356248
Z variance train             0.0014850373
KL Divergence                61.565628
KL Loss                      6.156563
QF Loss                      1007.4302
VF Loss                      822.5626
Policy Loss                  -2887.7136
Q Predictions Mean           2880.8662
Q Predictions Std            730.55
Q Predictions Max            3616.023
Q Predictions Min            415.80075
V Predictions Mean           2893.511
V Predictions Std            724.7676
V Predictions Max            3598.0002
V Predictions Min            356.52258
Log Pis Mean                 6.5633764
Log Pis Std                  3.5425432
Log Pis Max                  17.562056
Log Pis Min                  -1.6971936
Policy mu Mean               -0.38044238
Policy mu Std                1.5865487
Policy mu Max                4.05868
Policy mu Min                -3.4371777
Policy log std Mean          -0.6185374
Policy log std Std           0.263035
Policy log std Max           0.15739709
Policy log std Min           -2.352823
Z mean eval                  7.53898
Z variance eval              0.008837871
total_rewards                [7387.51227714 7131.16941271 7076.4180615  7434.53309309 7395.43584218
 6148.79678045 6935.33755671 6941.53552717 6812.17428016 7236.02614423]
total_rewards_mean           7049.8938975348265
total_rewards_std            362.8551354138219
total_rewards_max            7434.533093093278
total_rewards_min            6148.7967804544605
Number of train steps total  160000
Number of env steps total    202000
Number of rollouts total     0
Train Time (s)               123.93092840211466
(Previous) Eval Time (s)     27.55806744005531
Sample Time (s)              22.390155404806137
Epoch Time (s)               173.8791512469761
Total Train Time (s)         7124.8775896169245
Epoch                        39
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:46:28.530821 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #39 | Epoch Duration: 174.5325014591217
2020-01-13 06:46:28.531024 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #39 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 7.540281
Z variance train             0.00880448
KL Divergence                158.28616
KL Loss                      15.828616
QF Loss                      440.76166
VF Loss                      371.85687
Policy Loss                  -4210.1973
Q Predictions Mean           4205.6724
Q Predictions Std            439.56882
Q Predictions Max            4787.033
Q Predictions Min            2627.316
V Predictions Mean           4197.7124
V Predictions Std            430.52396
V Predictions Max            4775.9136
V Predictions Min            2646.406
Log Pis Mean                 4.247784
Log Pis Std                  3.969136
Log Pis Max                  13.03201
Log Pis Min                  -5.510717
Policy mu Mean               -0.18736033
Policy mu Std                1.3571726
Policy mu Max                3.1965795
Policy mu Min                -2.9096346
Policy log std Mean          -0.719217
Policy log std Std           0.34845948
Policy log std Max           -0.10737461
Policy log std Min           -2.59317
Z mean eval                  7.122419
Z variance eval              0.0024085948
total_rewards                [7391.46859105 7336.68244265 7298.36075348 7252.39857829 7101.69394447
 7308.33169017 7428.92241526 7553.52152855 7414.32864329 7562.75229799]
total_rewards_mean           7364.846088518901
total_rewards_std            131.27421961357905
total_rewards_max            7562.752297987683
total_rewards_min            7101.693944466147
Number of train steps total  164000
Number of env steps total    207000
Number of rollouts total     0
Train Time (s)               127.10390446800739
(Previous) Eval Time (s)     28.211067607160658
Sample Time (s)              21.827735122293234
Epoch Time (s)               177.14270719746128
Total Train Time (s)         7302.783194030635
Epoch                        40
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:49:26.437858 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #40 | Epoch Duration: 177.90668439865112
2020-01-13 06:49:26.438058 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #40 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 7.0635223
Z variance train             0.0024416
KL Divergence                141.17947
KL Loss                      14.117948
QF Loss                      492.424
VF Loss                      217.04385
Policy Loss                  -3719.1963
Q Predictions Mean           3726.165
Q Predictions Std            455.58917
Q Predictions Max            4326.4126
Q Predictions Min            2122.094
V Predictions Mean           3724.0374
V Predictions Std            449.4443
V Predictions Max            4290.7197
V Predictions Min            2110.593
Log Pis Mean                 4.476159
Log Pis Std                  3.717535
Log Pis Max                  15.208763
Log Pis Min                  -5.536269
Policy mu Mean               -0.1344362
Policy mu Std                1.3509029
Policy mu Max                3.412309
Policy mu Min                -3.372918
Policy log std Mean          -0.7486086
Policy log std Std           0.3737554
Policy log std Max           0.040775955
Policy log std Min           -2.742665
Z mean eval                  6.469229
Z variance eval              0.00051688607
total_rewards                [7607.67659517 7708.83864596 7360.79758703 7685.51807401 7537.10400054
 7819.73667212 7397.02741359 7344.84078812 7880.055385   7586.05368929]
total_rewards_mean           7592.764885083258
total_rewards_std            176.94128171734766
total_rewards_max            7880.055384995133
total_rewards_min            7344.840788122569
Number of train steps total  168000
Number of env steps total    212000
Number of rollouts total     0
Train Time (s)               132.99273821897805
(Previous) Eval Time (s)     28.974702620878816
Sample Time (s)              23.1246376093477
Epoch Time (s)               185.09207844920456
Total Train Time (s)         7487.0971093191765
Epoch                        41
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:52:30.756392 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #41 | Epoch Duration: 184.31819701194763
2020-01-13 06:52:30.756577 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #41 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 6.4435143
Z variance train             0.0005231936
KL Divergence                122.53022
KL Loss                      12.253022
QF Loss                      480.09
VF Loss                      144.85696
Policy Loss                  -3334.437
Q Predictions Mean           3327.6113
Q Predictions Std            449.6911
Q Predictions Max            3930.2617
Q Predictions Min            1640.3894
V Predictions Mean           3328.0815
V Predictions Std            441.59085
V Predictions Max            3917.6636
V Predictions Min            1668.5714
Log Pis Mean                 4.049115
Log Pis Std                  3.5930111
Log Pis Max                  14.160757
Log Pis Min                  -3.3161836
Policy mu Mean               -0.19513953
Policy mu Std                1.3023746
Policy mu Max                2.9269068
Policy mu Min                -2.9805179
Policy log std Mean          -0.7454252
Policy log std Std           0.3586232
Policy log std Max           0.08292717
Policy log std Min           -2.8626118
Z mean eval                  5.9100075
Z variance eval              0.0011522796
total_rewards                [ 303.86780121 7575.20935409 7192.20424461 7404.23337393 7173.64188988
 7700.98690918 7376.69037718 7482.8584416  7592.11607787  637.04663489]
total_rewards_mean           6043.885510444057
total_rewards_std            2792.1713627473114
total_rewards_max            7700.986909180761
total_rewards_min            303.8678012057293
Number of train steps total  172000
Number of env steps total    217000
Number of rollouts total     0
Train Time (s)               131.34181896736845
(Previous) Eval Time (s)     28.200401954352856
Sample Time (s)              22.40496197482571
Epoch Time (s)               181.94718289654702
Total Train Time (s)         7668.916126232594
Epoch                        42
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:55:32.573687 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #42 | Epoch Duration: 181.816969871521
2020-01-13 06:55:32.573874 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #42 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 5.961417
Z variance train             0.0014101805
KL Divergence                105.23638
KL Loss                      10.523639
QF Loss                      506.94095
VF Loss                      323.92108
Policy Loss                  -3066.1062
Q Predictions Mean           3060.3022
Q Predictions Std            461.94983
Q Predictions Max            3624.1926
Q Predictions Min            1346.7979
V Predictions Mean           3075.8147
V Predictions Std            455.77115
V Predictions Max            3637.096
V Predictions Min            1360.6877
Log Pis Mean                 3.819763
Log Pis Std                  3.565827
Log Pis Max                  18.071178
Log Pis Min                  -4.194158
Policy mu Mean               -0.24173456
Policy mu Std                1.2627019
Policy mu Max                3.5205917
Policy mu Min                -2.9567776
Policy log std Mean          -0.76247907
Policy log std Std           0.38714254
Policy log std Max           -0.110877454
Policy log std Min           -2.85556
Z mean eval                  5.7620134
Z variance eval              0.000961837
total_rewards                [7588.94864524 7495.86311347 7753.48702539 7797.29315137 7809.13240659
 7645.38842009 7737.11246513 7551.52032391 7700.79648668 7730.48289614]
total_rewards_mean           7681.002493401099
total_rewards_std            100.97907501707135
total_rewards_max            7809.132406592099
total_rewards_min            7495.863113471708
Number of train steps total  176000
Number of env steps total    222000
Number of rollouts total     0
Train Time (s)               131.3628118862398
(Previous) Eval Time (s)     28.069844174198806
Sample Time (s)              21.86061109509319
Epoch Time (s)               181.2932671555318
Total Train Time (s)         7851.501659675967
Epoch                        43
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:58:35.160785 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #43 | Epoch Duration: 182.58677077293396
2020-01-13 06:58:35.160974 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #43 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 5.7267466
Z variance train             0.0011891719
KL Divergence                99.159
KL Loss                      9.9159
QF Loss                      385.4707
VF Loss                      199.87318
Policy Loss                  -2927.0635
Q Predictions Mean           2929.0203
Q Predictions Std            487.89417
Q Predictions Max            3495.9185
Q Predictions Min            1159.437
V Predictions Mean           2920.5796
V Predictions Std            482.7934
V Predictions Max            3486.8613
V Predictions Min            1182.4769
Log Pis Mean                 3.418363
Log Pis Std                  3.4434237
Log Pis Max                  15.692614
Log Pis Min                  -5.0192823
Policy mu Mean               -0.1548476
Policy mu Std                1.2567714
Policy mu Max                3.2762864
Policy mu Min                -3.8904636
Policy log std Mean          -0.7644818
Policy log std Std           0.3714174
Policy log std Max           -0.09060651
Policy log std Min           -2.7254562
Z mean eval                  5.670408
Z variance eval              0.0043845614
total_rewards                [7435.57393826 7976.89346622 7489.68298868 7599.03284966 7810.07800415
 7799.1117261  7838.12702529 7921.81882125 7819.35450466 7673.53337717]
total_rewards_mean           7736.320670143975
total_rewards_std            171.17119483079435
total_rewards_max            7976.893466223064
total_rewards_min            7435.573938256636
Number of train steps total  180000
Number of env steps total    227000
Number of rollouts total     0
Train Time (s)               130.46092393202707
(Previous) Eval Time (s)     29.363004392012954
Sample Time (s)              22.927199005614966
Epoch Time (s)               182.751127329655
Total Train Time (s)         8032.681008758955
Epoch                        44
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:01:36.342346 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #44 | Epoch Duration: 181.1811945438385
2020-01-13 07:01:36.342723 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #44 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 5.623129
Z variance train             0.0032165602
KL Divergence                93.77828
KL Loss                      9.377829
QF Loss                      356.27252
VF Loss                      183.03604
Policy Loss                  -2910.9128
Q Predictions Mean           2905.997
Q Predictions Std            391.77246
Q Predictions Max            3420.2063
Q Predictions Min            1064.3763
V Predictions Mean           2915.5107
V Predictions Std            382.81158
V Predictions Max            3429.0825
V Predictions Min            1086.5221
Log Pis Mean                 4.0505066
Log Pis Std                  3.6240976
Log Pis Max                  13.73336
Log Pis Min                  -3.9885378
Policy mu Mean               -0.2021703
Policy mu Std                1.3056633
Policy mu Max                3.081521
Policy mu Min                -3.0423486
Policy log std Mean          -0.7717147
Policy log std Std           0.3654263
Policy log std Max           -0.09651458
Policy log std Min           -2.6813548
Z mean eval                  5.493882
Z variance eval              0.0013881263
total_rewards                [7425.89420742 6601.90333347 6823.63240453 2328.53725662 7136.72252934
 6447.3264748  7478.35497462 7242.3369918  7008.54875915 7145.79714161]
total_rewards_mean           6563.905407335997
total_rewards_std            1446.539776448769
total_rewards_max            7478.354974623319
total_rewards_min            2328.5372566162414
Number of train steps total  184000
Number of env steps total    232000
Number of rollouts total     0
Train Time (s)               123.8461787449196
(Previous) Eval Time (s)     27.79269085265696
Sample Time (s)              23.266112086828798
Epoch Time (s)               174.90498168440536
Total Train Time (s)         8207.166106893215
Epoch                        45
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:04:30.828289 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #45 | Epoch Duration: 174.4853127002716
2020-01-13 07:04:30.828466 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #45 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 5.5591545
Z variance train             0.0032828175
KL Divergence                93.4801
KL Loss                      9.34801
QF Loss                      464.04825
VF Loss                      297.89996
Policy Loss                  -2814.1897
Q Predictions Mean           2815.7659
Q Predictions Std            508.49158
Q Predictions Max            3449.9985
Q Predictions Min            974.53595
V Predictions Mean           2802.8408
V Predictions Std            503.35428
V Predictions Max            3411.425
V Predictions Min            974.0304
Log Pis Mean                 3.8504326
Log Pis Std                  3.3352702
Log Pis Max                  12.849827
Log Pis Min                  -5.471044
Policy mu Mean               -0.21714121
Policy mu Std                1.2590709
Policy mu Max                3.2108207
Policy mu Min                -2.8092034
Policy log std Mean          -0.7666324
Policy log std Std           0.386784
Policy log std Max           0.08706123
Policy log std Min           -2.8592772
Z mean eval                  5.430449
Z variance eval              0.0045804763
total_rewards                [7740.15169112 7990.33451193 7492.50346408 7765.7067554  7532.11611504
 7738.33417302 7720.74687952 7745.67888926 7624.4789795  7838.87990636]
total_rewards_mean           7718.893136520824
total_rewards_std            136.70096037612794
total_rewards_max            7990.334511931624
total_rewards_min            7492.503464081124
Number of train steps total  188000
Number of env steps total    237000
Number of rollouts total     0
Train Time (s)               124.28909775894135
(Previous) Eval Time (s)     27.37271016696468
Sample Time (s)              22.2019661096856
Epoch Time (s)               173.86377403559163
Total Train Time (s)         8380.403791649733
Epoch                        46
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:07:24.067549 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #46 | Epoch Duration: 173.23894929885864
2020-01-13 07:07:24.067739 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #46 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 5.4443455
Z variance train             0.0027354502
KL Divergence                90.87773
KL Loss                      9.087773
QF Loss                      450.27203
VF Loss                      189.2945
Policy Loss                  -2726.2747
Q Predictions Mean           2723.1904
Q Predictions Std            544.6779
Q Predictions Max            3369.3965
Q Predictions Min            853.70294
V Predictions Mean           2722.2148
V Predictions Std            541.69385
V Predictions Max            3347.4858
V Predictions Min            836.4533
Log Pis Mean                 3.8039794
Log Pis Std                  3.6829245
Log Pis Max                  14.317963
Log Pis Min                  -4.3727436
Policy mu Mean               -0.2005703
Policy mu Std                1.2751745
Policy mu Max                3.5703764
Policy mu Min                -2.9876456
Policy log std Mean          -0.74464846
Policy log std Std           0.374902
Policy log std Max           0.06195891
Policy log std Min           -2.8269613
Z mean eval                  5.3222575
Z variance eval              0.0015945116
total_rewards                [8195.99791556 7622.13295536 7927.82841862 7981.72126705 7846.85104192
 8061.74803373 8204.2647792  8381.62024647 8220.41359884 7974.00893407]
total_rewards_mean           8041.658719082438
total_rewards_std            208.15145266018123
total_rewards_max            8381.620246471495
total_rewards_min            7622.132955356568
Number of train steps total  192000
Number of env steps total    242000
Number of rollouts total     0
Train Time (s)               126.60221681231633
(Previous) Eval Time (s)     26.747544733807445
Sample Time (s)              21.14319601561874
Epoch Time (s)               174.49295756174251
Total Train Time (s)         8555.038663551211
Epoch                        47
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:10:18.703685 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #47 | Epoch Duration: 174.63580513000488
2020-01-13 07:10:18.703872 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #47 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 5.3508396
Z variance train             0.001257532
KL Divergence                88.34534
KL Loss                      8.834534
QF Loss                      300.31873
VF Loss                      114.656456
Policy Loss                  -2770.933
Q Predictions Mean           2767.4893
Q Predictions Std            507.77872
Q Predictions Max            3383.1443
Q Predictions Min            787.3309
V Predictions Mean           2770.516
V Predictions Std            499.44485
V Predictions Max            3379.9631
V Predictions Min            799.0975
Log Pis Mean                 3.5820646
Log Pis Std                  3.5358806
Log Pis Max                  17.728653
Log Pis Min                  -8.306018
Policy mu Mean               -0.2621764
Policy mu Std                1.2376082
Policy mu Max                3.5008852
Policy mu Min                -3.2709427
Policy log std Mean          -0.7714205
Policy log std Std           0.37045628
Policy log std Max           0.30115557
Policy log std Min           -2.879496
Z mean eval                  4.8801894
Z variance eval              0.0021537587
total_rewards                [7393.02312551 7329.97577017 7337.2829375  7279.78059458 7198.03417921
 7144.19790399 7399.854236   7286.97141655 7316.14421288 7461.96726311]
total_rewards_mean           7314.723163949115
total_rewards_std            89.71562794986966
total_rewards_max            7461.967263108873
total_rewards_min            7144.197903994131
Number of train steps total  196000
Number of env steps total    247000
Number of rollouts total     0
Train Time (s)               133.00923406006768
(Previous) Eval Time (s)     26.890074975788593
Sample Time (s)              21.658544899430126
Epoch Time (s)               181.5578539352864
Total Train Time (s)         8738.388100989163
Epoch                        48
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:13:22.054680 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #48 | Epoch Duration: 183.3506715297699
2020-01-13 07:13:22.054866 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #48 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 5.11819
Z variance train             0.002176383
KL Divergence                79.558655
KL Loss                      7.9558654
QF Loss                      296.49542
VF Loss                      221.02493
Policy Loss                  -2749.544
Q Predictions Mean           2751.7014
Q Predictions Std            474.5765
Q Predictions Max            3341.9788
Q Predictions Min            710.0936
V Predictions Mean           2740.6763
V Predictions Std            469.19342
V Predictions Max            3335.582
V Predictions Min            699.71234
Log Pis Mean                 3.9802594
Log Pis Std                  3.49751
Log Pis Max                  13.489878
Log Pis Min                  -4.1543527
Policy mu Mean               -0.22827792
Policy mu Std                1.2733775
Policy mu Max                2.8813465
Policy mu Min                -2.8365357
Policy log std Mean          -0.7861069
Policy log std Std           0.39420313
Policy log std Max           -0.06695843
Policy log std Min           -2.8935401
Z mean eval                  4.6691136
Z variance eval              0.004302767
total_rewards                [7827.55861431 7637.97246117 7550.13260597 7727.49831447 7586.90716651
 7876.53463253 7616.41622934 7761.60644399 7494.25089445 7510.82622939]
total_rewards_mean           7658.970359215069
total_rewards_std            126.23635394595091
total_rewards_max            7876.534632534817
total_rewards_min            7494.250894445095
Number of train steps total  200000
Number of env steps total    252000
Number of rollouts total     0
Train Time (s)               131.5939783398062
(Previous) Eval Time (s)     28.68253478780389
Sample Time (s)              22.35519685409963
Epoch Time (s)               182.63170998170972
Total Train Time (s)         8920.775985493325
Epoch                        49
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:16:24.444097 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #49 | Epoch Duration: 182.38909196853638
2020-01-13 07:16:24.444280 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #49 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.7067394
Z variance train             0.003955703
KL Divergence                69.30983
KL Loss                      6.930983
QF Loss                      326.04016
VF Loss                      121.64311
Policy Loss                  -2616.804
Q Predictions Mean           2615.397
Q Predictions Std            464.40408
Q Predictions Max            3277.6162
Q Predictions Min            628.86694
V Predictions Mean           2616.1445
V Predictions Std            460.17175
V Predictions Max            3261.529
V Predictions Min            623.23584
Log Pis Mean                 3.9920146
Log Pis Std                  3.6384716
Log Pis Max                  14.235765
Log Pis Min                  -7.084605
Policy mu Mean               -0.21443896
Policy mu Std                1.2852045
Policy mu Max                3.0693839
Policy mu Min                -3.2101567
Policy log std Mean          -0.7633578
Policy log std Std           0.37905386
Policy log std Max           0.22964925
Policy log std Min           -2.7972345
Z mean eval                  4.719513
Z variance eval              0.013344797
total_rewards                [7542.54550499 7720.87749394 7676.30441367 7688.45206476 7707.09290159
 7733.52337924 7541.04181153 7660.34732614 7613.40437093 7602.01523987]
total_rewards_mean           7648.560450665575
total_rewards_std            66.76551028943156
total_rewards_max            7733.523379237498
total_rewards_min            7541.041811527895
Number of train steps total  204000
Number of env steps total    257000
Number of rollouts total     0
Train Time (s)               130.97803143179044
(Previous) Eval Time (s)     28.43958068219945
Sample Time (s)              22.114906116388738
Epoch Time (s)               181.53251823037863
Total Train Time (s)         9103.378563253209
Epoch                        50
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:19:27.048252 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #50 | Epoch Duration: 182.6038315296173
2020-01-13 07:19:27.048448 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #50 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.831874
Z variance train             0.012733774
KL Divergence                72.61289
KL Loss                      7.261289
QF Loss                      694.4816
VF Loss                      501.3216
Policy Loss                  -2650.1665
Q Predictions Mean           2640.797
Q Predictions Std            623.74615
Q Predictions Max            3274.4795
Q Predictions Min            597.46844
V Predictions Mean           2650.5327
V Predictions Std            617.4161
V Predictions Max            3259.2273
V Predictions Min            613.54767
Log Pis Mean                 4.2329335
Log Pis Std                  3.8957267
Log Pis Max                  14.583266
Log Pis Min                  -4.9672318
Policy mu Mean               -0.24238475
Policy mu Std                1.2968491
Policy mu Max                2.8609474
Policy mu Min                -2.95461
Policy log std Mean          -0.74605244
Policy log std Std           0.39322323
Policy log std Max           0.0800544
Policy log std Min           -2.956986
Z mean eval                  4.6091413
Z variance eval              0.008766644
total_rewards                [7903.89717408 7992.91388602 7680.14465047 8088.73617996 8178.03914432
 7917.96855039 7897.20944694 7870.97183736 7943.02555429 8005.18913383]
total_rewards_mean           7947.809555767021
total_rewards_std            126.94225871909559
total_rewards_max            8178.039144321089
total_rewards_min            7680.1446504703545
Number of train steps total  208000
Number of env steps total    262000
Number of rollouts total     0
Train Time (s)               130.43664111662656
(Previous) Eval Time (s)     29.51051245769486
Sample Time (s)              23.545325379818678
Epoch Time (s)               183.4924789541401
Total Train Time (s)         9286.093431876507
Epoch                        51
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:22:29.765248 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #51 | Epoch Duration: 182.71664762496948
2020-01-13 07:22:29.765441 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #51 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.6129737
Z variance train             0.008899837
KL Divergence                66.30618
KL Loss                      6.6306186
QF Loss                      1246.6649
VF Loss                      295.1234
Policy Loss                  -2706.33
Q Predictions Mean           2701.1768
Q Predictions Std            526.52386
Q Predictions Max            3284.4558
Q Predictions Min            531.60077
V Predictions Mean           2697.0825
V Predictions Std            514.4078
V Predictions Max            3275.7214
V Predictions Min            569.1726
Log Pis Mean                 4.1159744
Log Pis Std                  3.7089832
Log Pis Max                  15.591346
Log Pis Min                  -4.8883476
Policy mu Mean               -0.23694785
Policy mu Std                1.3204699
Policy mu Max                4.358325
Policy mu Min                -3.4334202
Policy log std Mean          -0.74839765
Policy log std Std           0.36917824
Policy log std Max           -0.07504159
Policy log std Min           -2.8136508
Z mean eval                  4.574062
Z variance eval              0.00591669
total_rewards                [7790.58320413 7866.11400919 7934.71360414 7736.49661466 8080.27279736
 8042.14211445 8201.42794577 7855.24102121 8008.51119869 7830.34256108]
total_rewards_mean           7934.584507067087
total_rewards_std            138.3074399700581
total_rewards_max            8201.427945769823
total_rewards_min            7736.496614662217
Number of train steps total  212000
Number of env steps total    267000
Number of rollouts total     0
Train Time (s)               125.6267337189056
(Previous) Eval Time (s)     28.73419920168817
Sample Time (s)              23.209635026287287
Epoch Time (s)               177.57056794688106
Total Train Time (s)         9462.81576545583
Epoch                        52
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:25:26.488741 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #52 | Epoch Duration: 176.72316217422485
2020-01-13 07:25:26.488925 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #52 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.574677
Z variance train             0.0059210444
KL Divergence                65.73551
KL Loss                      6.573551
QF Loss                      476.87927
VF Loss                      141.32498
Policy Loss                  -2679.4902
Q Predictions Mean           2677.4836
Q Predictions Std            539.3348
Q Predictions Max            3283.9404
Q Predictions Min            498.21783
V Predictions Mean           2676.0786
V Predictions Std            531.4512
V Predictions Max            3287.9558
V Predictions Min            503.8214
Log Pis Mean                 4.111562
Log Pis Std                  3.7182226
Log Pis Max                  14.325725
Log Pis Min                  -4.1821365
Policy mu Mean               -0.19313832
Policy mu Std                1.3073052
Policy mu Max                3.6136494
Policy mu Min                -3.1813486
Policy log std Mean          -0.77486867
Policy log std Std           0.41555092
Policy log std Max           0.044783473
Policy log std Min           -3.021843
Z mean eval                  4.5509434
Z variance eval              0.012688577
total_rewards                [8024.04967854 8033.49670506 7922.30413436 8030.31425395 8018.74697666
 8187.99678218 8244.22643012 8026.94662022 8164.27099571 8089.54439449]
total_rewards_mean           8074.189697129262
total_rewards_std            92.02443892125419
total_rewards_max            8244.22643011736
total_rewards_min            7922.304134355288
Number of train steps total  216000
Number of env steps total    272000
Number of rollouts total     0
Train Time (s)               124.27852843794972
(Previous) Eval Time (s)     27.886442764196545
Sample Time (s)              22.186740580014884
Epoch Time (s)               174.35171178216115
Total Train Time (s)         9637.482929336373
Epoch                        53
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:28:21.157386 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #53 | Epoch Duration: 174.66830897331238
2020-01-13 07:28:21.157584 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #53 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.5518093
Z variance train             0.012682167
KL Divergence                63.841972
KL Loss                      6.384197
QF Loss                      312.54572
VF Loss                      124.68711
Policy Loss                  -2726.1404
Q Predictions Mean           2724.3906
Q Predictions Std            535.17914
Q Predictions Max            3253.3306
Q Predictions Min            488.987
V Predictions Mean           2728.8223
V Predictions Std            529.2452
V Predictions Max            3248.6348
V Predictions Min            450.76382
Log Pis Mean                 4.251011
Log Pis Std                  3.6546917
Log Pis Max                  15.73107
Log Pis Min                  -5.4752955
Policy mu Mean               -0.25586656
Policy mu Std                1.3018329
Policy mu Max                4.0280795
Policy mu Min                -2.9480474
Policy log std Mean          -0.760626
Policy log std Std           0.3876312
Policy log std Max           -0.0708316
Policy log std Min           -2.9977393
Z mean eval                  4.5344515
Z variance eval              0.00262758
total_rewards                [8015.56856535 7956.54161877 8298.49600743 8235.74284108 8109.46419038
 8010.83806713 8169.1622099  7991.17591683 8057.95676981 8064.81617826]
total_rewards_mean           8090.976236494031
total_rewards_std            106.01533999499135
total_rewards_max            8298.496007433087
total_rewards_min            7956.541618774164
Number of train steps total  220000
Number of env steps total    277000
Number of rollouts total     0
Train Time (s)               126.81078449776396
(Previous) Eval Time (s)     28.2026887931861
Sample Time (s)              21.413192899432033
Epoch Time (s)               176.4266661903821
Total Train Time (s)         9813.47123510763
Epoch                        54
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:31:17.148667 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #54 | Epoch Duration: 175.99092078208923
2020-01-13 07:31:17.148973 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #54 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.5349092
Z variance train             0.0026320368
KL Divergence                65.02669
KL Loss                      6.502669
QF Loss                      890.21094
VF Loss                      140.24919
Policy Loss                  -2776.118
Q Predictions Mean           2774.9087
Q Predictions Std            501.82367
Q Predictions Max            3365.1958
Q Predictions Min            459.97623
V Predictions Mean           2777.8105
V Predictions Std            494.4401
V Predictions Max            3372.7944
V Predictions Min            471.2885
Log Pis Mean                 4.4853077
Log Pis Std                  4.1273856
Log Pis Max                  18.671728
Log Pis Min                  -7.703239
Policy mu Mean               -0.21836627
Policy mu Std                1.3114694
Policy mu Max                3.058072
Policy mu Min                -3.730681
Policy log std Mean          -0.7830098
Policy log std Std           0.4112998
Policy log std Max           0.23645622
Policy log std Min           -2.9528756
Z mean eval                  4.5442505
Z variance eval              0.002575981
total_rewards                [7997.56220298 8298.6578522  8236.87263571 6065.26629655 8434.01158772
 8089.15970851 8043.59433726 8114.09381592 8466.10001577 8173.55546991]
total_rewards_mean           7991.887392253515
total_rewards_std            659.2762367246754
total_rewards_max            8466.100015771994
total_rewards_min            6065.266296553797
Number of train steps total  224000
Number of env steps total    282000
Number of rollouts total     0
Train Time (s)               133.78882164973766
(Previous) Eval Time (s)     27.766575323883444
Sample Time (s)              22.80811979761347
Epoch Time (s)               184.36351677123457
Total Train Time (s)         9997.992075181566
Epoch                        55
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:34:21.670210 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #55 | Epoch Duration: 184.52104353904724
2020-01-13 07:34:21.670417 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #55 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.5416155
Z variance train             0.0025799114
KL Divergence                64.94575
KL Loss                      6.494575
QF Loss                      838.8258
VF Loss                      178.12497
Policy Loss                  -2809.3967
Q Predictions Mean           2799.4536
Q Predictions Std            576.3462
Q Predictions Max            3439.5942
Q Predictions Min            436.38202
V Predictions Mean           2808.3933
V Predictions Std            571.0926
V Predictions Max            3435.7483
V Predictions Min            456.12225
Log Pis Mean                 4.4960775
Log Pis Std                  3.7553554
Log Pis Max                  19.476492
Log Pis Min                  -3.5072556
Policy mu Mean               -0.27057076
Policy mu Std                1.3378793
Policy mu Max                4.34295
Policy mu Min                -3.1769655
Policy log std Mean          -0.7828698
Policy log std Std           0.41663247
Policy log std Max           0.16481483
Policy log std Min           -3.0790558
Z mean eval                  4.715295
Z variance eval              0.0037367516
total_rewards                [8049.3777458  7745.94532902 7798.33060779 8099.68046717 7873.51451576
 8121.75842875 7987.03968757 8190.66469436 8038.24923769 7785.1870414 ]
total_rewards_mean           7968.974775530184
total_rewards_std            149.30349320139177
total_rewards_max            8190.664694360967
total_rewards_min            7745.945329017936
Number of train steps total  228000
Number of env steps total    287000
Number of rollouts total     0
Train Time (s)               131.50941702071577
(Previous) Eval Time (s)     27.923735563177615
Sample Time (s)              21.530928615015
Epoch Time (s)               180.9640811989084
Total Train Time (s)         10179.985387261026
Epoch                        56
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:37:23.665319 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #56 | Epoch Duration: 181.99473690986633
2020-01-13 07:37:23.665562 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #56 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.8549323
Z variance train             0.0033642836
KL Divergence                72.05112
KL Loss                      7.205112
QF Loss                      349.38937
VF Loss                      220.54715
Policy Loss                  -2937.3125
Q Predictions Mean           2937.3633
Q Predictions Std            589.39325
Q Predictions Max            3553.245
Q Predictions Min            468.6817
V Predictions Mean           2945.8462
V Predictions Std            582.2389
V Predictions Max            3568.128
V Predictions Min            487.04367
Log Pis Mean                 4.3473535
Log Pis Std                  3.6187038
Log Pis Max                  12.781433
Log Pis Min                  -7.2430353
Policy mu Mean               -0.19281645
Policy mu Std                1.3195086
Policy mu Max                2.9843397
Policy mu Min                -2.7627556
Policy log std Mean          -0.77594346
Policy log std Std           0.39965075
Policy log std Max           -0.058538973
Policy log std Min           -2.9148946
Z mean eval                  4.698317
Z variance eval              0.0059100226
total_rewards                [8343.49838277 8498.8251554  8158.49228641 8198.55353516 8425.14645754
 8367.36593972 8460.7223577  8241.61467012 8319.32810463 8336.79311849]
total_rewards_mean           8335.034000792752
total_rewards_std            105.18231587115453
total_rewards_max            8498.825155396831
total_rewards_min            8158.492286406892
Number of train steps total  232000
Number of env steps total    292000
Number of rollouts total     0
Train Time (s)               131.21592629002407
(Previous) Eval Time (s)     28.953989091329277
Sample Time (s)              22.706174031831324
Epoch Time (s)               182.87608941318467
Total Train Time (s)         10362.259973902721
Epoch                        57
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:40:25.942784 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #57 | Epoch Duration: 182.27703166007996
2020-01-13 07:40:25.943169 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #57 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.6973677
Z variance train             0.0059734443
KL Divergence                68.362724
KL Loss                      6.8362727
QF Loss                      458.02362
VF Loss                      234.83226
Policy Loss                  -2960.9048
Q Predictions Mean           2958.226
Q Predictions Std            472.1582
Q Predictions Max            3502.9507
Q Predictions Min            464.2772
V Predictions Mean           2954.812
V Predictions Std            466.51505
V Predictions Max            3469.8875
V Predictions Min            462.5132
Log Pis Mean                 4.0563674
Log Pis Std                  3.7873363
Log Pis Max                  14.7896595
Log Pis Min                  -5.8254414
Policy mu Mean               -0.20743501
Policy mu Std                1.3271854
Policy mu Max                2.8729346
Policy mu Min                -3.5241907
Policy log std Mean          -0.76318836
Policy log std Std           0.37930366
Policy log std Max           -0.10924691
Policy log std Min           -2.9367054
Z mean eval                  4.710659
Z variance eval              0.0051563764
total_rewards                [8405.25590409 8507.51642598 8591.44006959 8557.59995755 8326.79993359
 8374.15130329 8675.07908649 8640.68367634 8309.03748713 8291.72650186]
total_rewards_mean           8467.929034590261
total_rewards_std            136.5839616184966
total_rewards_max            8675.079086489846
total_rewards_min            8291.726501857862
Number of train steps total  236000
Number of env steps total    297000
Number of rollouts total     0
Train Time (s)               131.2583814440295
(Previous) Eval Time (s)     28.354531548917294
Sample Time (s)              23.831338742747903
Epoch Time (s)               183.4442517356947
Total Train Time (s)         10546.018132793251
Epoch                        58
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:43:29.701403 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #58 | Epoch Duration: 183.75795340538025
2020-01-13 07:43:29.701613 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #58 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.706686
Z variance train             0.005223279
KL Divergence                69.08265
KL Loss                      6.908265
QF Loss                      402.12677
VF Loss                      228.85547
Policy Loss                  -2915.3108
Q Predictions Mean           2911.8125
Q Predictions Std            572.66296
Q Predictions Max            3564.2192
Q Predictions Min            424.30087
V Predictions Mean           2911.4355
V Predictions Std            566.1912
V Predictions Max            3565.124
V Predictions Min            452.69348
Log Pis Mean                 4.4786873
Log Pis Std                  3.7735772
Log Pis Max                  22.389915
Log Pis Min                  -5.1472006
Policy mu Mean               -0.22493614
Policy mu Std                1.323865
Policy mu Max                4.510534
Policy mu Min                -4.816546
Policy log std Mean          -0.7837855
Policy log std Std           0.41088498
Policy log std Max           0.04565817
Policy log std Min           -3.0831487
Z mean eval                  4.547004
Z variance eval              0.023663232
total_rewards                [8183.9336598  8240.75825557 8004.3613867  8417.28399576 8018.08186028
 8022.35251991 7965.6333007  8157.12753182 8167.24566318 7870.67163907]
total_rewards_mean           8104.744981280337
total_rewards_std            150.870682870578
total_rewards_max            8417.283995761807
total_rewards_min            7870.671639073405
Number of train steps total  240000
Number of env steps total    302000
Number of rollouts total     0
Train Time (s)               126.61669434094802
(Previous) Eval Time (s)     28.667854321654886
Sample Time (s)              23.397623443976045
Epoch Time (s)               178.68217210657895
Total Train Time (s)         10722.836440061219
Epoch                        59
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:46:26.521212 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #59 | Epoch Duration: 176.81945419311523
2020-01-13 07:46:26.521402 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #59 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.5474205
Z variance train             0.023577705
KL Divergence                63.906754
KL Loss                      6.3906755
QF Loss                      473.03946
VF Loss                      214.9246
Policy Loss                  -2853.4382
Q Predictions Mean           2846.8394
Q Predictions Std            504.88998
Q Predictions Max            3412.1917
Q Predictions Min            402.96848
V Predictions Mean           2847.6357
V Predictions Std            497.1201
V Predictions Max            3395.836
V Predictions Min            421.82544
Log Pis Mean                 4.0035915
Log Pis Std                  3.684828
Log Pis Max                  12.412982
Log Pis Min                  -5.4041085
Policy mu Mean               -0.20074236
Policy mu Std                1.2992398
Policy mu Max                2.7506773
Policy mu Min                -2.8800025
Policy log std Mean          -0.77121335
Policy log std Std           0.41093597
Policy log std Max           0.098380685
Policy log std Min           -3.0169005
Z mean eval                  4.6439567
Z variance eval              0.005315568
total_rewards                [8548.87305661 8444.15595123 8229.94722755  734.67417054 8514.81232446
 8316.15923592 8364.86428247 8566.19665824 8492.47047157 8336.77793877]
total_rewards_mean           7654.893131736998
total_rewards_std            2309.1128883064885
total_rewards_max            8566.196658241484
total_rewards_min            734.6741705415711
Number of train steps total  244000
Number of env steps total    307000
Number of rollouts total     0
Train Time (s)               125.24847406195477
(Previous) Eval Time (s)     26.80474398797378
Sample Time (s)              21.73873801296577
Epoch Time (s)               173.79195606289431
Total Train Time (s)         10897.803137970623
Epoch                        60
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:49:21.490237 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #60 | Epoch Duration: 174.9686689376831
2020-01-13 07:49:21.490559 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #60 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.550454
Z variance train             0.014725186
KL Divergence                62.113113
KL Loss                      6.2113113
QF Loss                      338.1706
VF Loss                      218.94194
Policy Loss                  -2886.2454
Q Predictions Mean           2886.9375
Q Predictions Std            544.65295
Q Predictions Max            3527.7583
Q Predictions Min            405.88803
V Predictions Mean           2894.556
V Predictions Std            541.34485
V Predictions Max            3537.2732
V Predictions Min            410.65002
Log Pis Mean                 4.015834
Log Pis Std                  3.8238883
Log Pis Max                  14.339666
Log Pis Min                  -5.729001
Policy mu Mean               -0.21732694
Policy mu Std                1.282814
Policy mu Max                2.8550706
Policy mu Min                -2.6617014
Policy log std Mean          -0.7907942
Policy log std Std           0.40502998
Policy log std Max           0.08093727
Policy log std Min           -3.0574312
Z mean eval                  4.645438
Z variance eval              0.0044473284
total_rewards                [8697.84288334 8458.99000657 8604.87010547 8671.45826249 8791.99553015
 8529.11705946 8505.76162751 8318.80624584 8675.76369761 8907.91123195]
total_rewards_mean           8616.251665038759
total_rewards_std            161.96691662933765
total_rewards_max            8907.911231947084
total_rewards_min            8318.806245843783
Number of train steps total  248000
Number of env steps total    312000
Number of rollouts total     0
Train Time (s)               126.11553329974413
(Previous) Eval Time (s)     27.981112139765173
Sample Time (s)              21.194306084420532
Epoch Time (s)               175.29095152392983
Total Train Time (s)         11073.506379215047
Epoch                        61
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:52:17.194624 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #61 | Epoch Duration: 175.7038402557373
2020-01-13 07:52:17.194820 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #61 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.555279
Z variance train             0.0071027502
KL Divergence                63.783978
KL Loss                      6.378398
QF Loss                      313.32718
VF Loss                      87.55612
Policy Loss                  -2935.9277
Q Predictions Mean           2939.3203
Q Predictions Std            556.81604
Q Predictions Max            3573.9644
Q Predictions Min            391.6268
V Predictions Mean           2938.6162
V Predictions Std            547.6314
V Predictions Max            3565.1292
V Predictions Min            410.96634
Log Pis Mean                 4.0511446
Log Pis Std                  3.705382
Log Pis Max                  18.582909
Log Pis Min                  -6.747936
Policy mu Mean               -0.2350455
Policy mu Std                1.2804716
Policy mu Max                3.4010372
Policy mu Min                -2.8123143
Policy log std Mean          -0.7809406
Policy log std Std           0.39496478
Policy log std Max           0.004609108
Policy log std Min           -3.048041
Z mean eval                  4.6434054
Z variance eval              0.0030791447
total_rewards                [8987.03231697 8628.57613681 8782.6629787  8514.07432827 8788.4766697
 8393.6595719  8440.38080168 8726.08852157 8330.91296497 8397.76987371]
total_rewards_mean           8598.963416427123
total_rewards_std            205.94420050102065
total_rewards_max            8987.032316965156
total_rewards_min            8330.912964966852
Number of train steps total  252000
Number of env steps total    317000
Number of rollouts total     0
Train Time (s)               133.53332139691338
(Previous) Eval Time (s)     28.39367841789499
Sample Time (s)              22.478477237280458
Epoch Time (s)               184.40547705208883
Total Train Time (s)         11257.915684292559
Epoch                        62
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:55:21.605491 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #62 | Epoch Duration: 184.41052222251892
2020-01-13 07:55:21.605718 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #62 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.622979
Z variance train             0.0034333665
KL Divergence                67.26976
KL Loss                      6.726976
QF Loss                      337.7072
VF Loss                      234.66699
Policy Loss                  -2930.2078
Q Predictions Mean           2935.5308
Q Predictions Std            643.6263
Q Predictions Max            3631.3206
Q Predictions Min            384.08514
V Predictions Mean           2941.209
V Predictions Std            642.5195
V Predictions Max            3640.3303
V Predictions Min            387.6131
Log Pis Mean                 4.576394
Log Pis Std                  4.117794
Log Pis Max                  14.017086
Log Pis Min                  -6.8794365
Policy mu Mean               -0.18846053
Policy mu Std                1.3534186
Policy mu Max                3.0361557
Policy mu Min                -2.9096653
Policy log std Mean          -0.7716894
Policy log std Std           0.40146664
Policy log std Max           0.004668534
Policy log std Min           -3.09507
Z mean eval                  5.171567
Z variance eval              0.010342627
total_rewards                [8242.67958779 8353.61799057 8386.00770163 8544.97583028 8580.27861271
 8051.65151104 8498.54836095 8518.698605   8430.88397847 4578.9902491 ]
total_rewards_mean           8018.633242754309
total_rewards_std            1156.39207305286
total_rewards_max            8580.278612711321
total_rewards_min            4578.990249099893
Number of train steps total  256000
Number of env steps total    322000
Number of rollouts total     0
Train Time (s)               131.72530746972188
(Previous) Eval Time (s)     28.39835686609149
Sample Time (s)              23.070007730275393
Epoch Time (s)               183.19367206608877
Total Train Time (s)         11441.269616983831
Epoch                        63
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:58:24.961314 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #63 | Epoch Duration: 183.3554368019104
2020-01-13 07:58:24.961558 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #63 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 5.0929475
Z variance train             0.015936267
KL Divergence                75.83998
KL Loss                      7.583998
QF Loss                      578.9237
VF Loss                      120.07394
Policy Loss                  -3279.4568
Q Predictions Mean           3275.016
Q Predictions Std            379.95743
Q Predictions Max            3835.488
Q Predictions Min            474.02957
V Predictions Mean           3277.1875
V Predictions Std            373.88358
V Predictions Max            3820.5486
V Predictions Min            529.7462
Log Pis Mean                 4.763856
Log Pis Std                  3.5551302
Log Pis Max                  15.297841
Log Pis Min                  -3.8929582
Policy mu Mean               -0.29606637
Policy mu Std                1.359971
Policy mu Max                2.919155
Policy mu Min                -2.7663417
Policy log std Mean          -0.7496996
Policy log std Std           0.38420305
Policy log std Max           -0.055962384
Policy log std Min           -2.8449283
Z mean eval                  5.0645685
Z variance eval              0.008438756
total_rewards                [8164.35636154 8270.48755679 7994.7852803  8162.77561544 8242.55329796
 8358.49230624 8155.60452507 8163.16819731 8156.90929501 8241.35257194]
total_rewards_mean           8191.048500760025
total_rewards_std            90.97328480231825
total_rewards_max            8358.492306237216
total_rewards_min            7994.785280300405
Number of train steps total  260000
Number of env steps total    327000
Number of rollouts total     0
Train Time (s)               130.90277990698814
(Previous) Eval Time (s)     28.559675393160433
Sample Time (s)              21.9006875785999
Epoch Time (s)               181.36314287874848
Total Train Time (s)         11623.090091811027
Epoch                        64
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:01:26.784297 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #64 | Epoch Duration: 181.82254433631897
2020-01-13 08:01:26.784652 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #64 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 5.0647078
Z variance train             0.008460633
KL Divergence                77.76866
KL Loss                      7.7768664
QF Loss                      295.18915
VF Loss                      117.7565
Policy Loss                  -3089.5383
Q Predictions Mean           3089.9836
Q Predictions Std            688.6021
Q Predictions Max            3783.388
Q Predictions Min            491.55112
V Predictions Mean           3091.8499
V Predictions Std            687.07874
V Predictions Max            3777.5962
V Predictions Min            488.34174
Log Pis Mean                 4.4303794
Log Pis Std                  3.561003
Log Pis Max                  15.965987
Log Pis Min                  -2.9004164
Policy mu Mean               -0.2656146
Policy mu Std                1.325396
Policy mu Max                3.1183438
Policy mu Min                -2.959721
Policy log std Mean          -0.76815104
Policy log std Std           0.40580377
Policy log std Max           0.100411296
Policy log std Min           -3.081511
Z mean eval                  4.738929
Z variance eval              0.0030588196
total_rewards                [8050.1313215  8171.20588596 8237.29829234 8263.35609903 8220.15021323
 8083.07564885 8542.97812676 8498.52465843 8207.21099297 7984.27472174]
total_rewards_mean           8225.82059608118
total_rewards_std            170.13099191093096
total_rewards_max            8542.978126763657
total_rewards_min            7984.2747217391125
Number of train steps total  264000
Number of env steps total    332000
Number of rollouts total     0
Train Time (s)               131.58324314793572
(Previous) Eval Time (s)     29.01871086517349
Sample Time (s)              22.09740902343765
Epoch Time (s)               182.69936303654686
Total Train Time (s)         11804.532922822516
Epoch                        65
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:04:28.227088 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #65 | Epoch Duration: 181.4421980381012
2020-01-13 08:04:28.227245 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.73771
Z variance train             0.0030104103
KL Divergence                69.71306
KL Loss                      6.971306
QF Loss                      303.948
VF Loss                      140.87256
Policy Loss                  -3007.176
Q Predictions Mean           3001.2432
Q Predictions Std            537.36487
Q Predictions Max            3690.7566
Q Predictions Min            413.39725
V Predictions Mean           3009.8853
V Predictions Std            527.09644
V Predictions Max            3708.2952
V Predictions Min            416.44217
Log Pis Mean                 4.155425
Log Pis Std                  3.535913
Log Pis Max                  15.421663
Log Pis Min                  -5.0046606
Policy mu Mean               -0.24363594
Policy mu Std                1.2945492
Policy mu Max                3.009164
Policy mu Min                -2.6228065
Policy log std Mean          -0.7749901
Policy log std Std           0.3697338
Policy log std Max           -0.068703234
Policy log std Min           -2.7345724
Z mean eval                  4.827036
Z variance eval              0.0042243577
total_rewards                [8846.17967999 8500.18667409 8663.1232452  8726.96658192 8749.28257814
 8557.44366468 8631.31255892 8534.07381496 8425.99679483 8598.13218919]
total_rewards_mean           8623.269778193106
total_rewards_std            120.39976672130797
total_rewards_max            8846.17967998535
total_rewards_min            8425.996794829616
Number of train steps total  268000
Number of env steps total    337000
Number of rollouts total     0
Train Time (s)               127.9292626506649
(Previous) Eval Time (s)     27.761176724918187
Sample Time (s)              23.177788485307246
Epoch Time (s)               178.86822786089033
Total Train Time (s)         11983.23627223121
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:07:26.932547 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #66 | Epoch Duration: 178.70517706871033
2020-01-13 08:07:26.932752 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #66 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.8615546
Z variance train             0.0016565906
KL Divergence                74.06086
KL Loss                      7.406086
QF Loss                      315.52966
VF Loss                      223.81673
Policy Loss                  -3051.4963
Q Predictions Mean           3043.034
Q Predictions Std            536.48254
Q Predictions Max            3723.0625
Q Predictions Min            421.60968
V Predictions Mean           3039.7354
V Predictions Std            528.0461
V Predictions Max            3697.3098
V Predictions Min            415.2433
Log Pis Mean                 4.5434227
Log Pis Std                  3.966586
Log Pis Max                  28.513037
Log Pis Min                  -5.5849824
Policy mu Mean               -0.22270137
Policy mu Std                1.3152044
Policy mu Max                5.0367503
Policy mu Min                -3.988746
Policy log std Mean          -0.80430657
Policy log std Std           0.4099555
Policy log std Max           0.1507237
Policy log std Min           -3.2132363
Z mean eval                  4.976413
Z variance eval              0.0018253202
total_rewards                [8612.18039934 8636.69440015 8764.85992041 8877.10347475 8723.37498024
 8678.97165902 8636.91125984 8964.84529271 4978.13821037 8474.98850771]
total_rewards_mean           8334.806810454891
total_rewards_std            1126.5712949544015
total_rewards_max            8964.845292714184
total_rewards_min            4978.13821037383
Number of train steps total  272000
Number of env steps total    342000
Number of rollouts total     0
Train Time (s)               125.06877675186843
(Previous) Eval Time (s)     27.59768818411976
Sample Time (s)              22.425265073776245
Epoch Time (s)               175.09173000976443
Total Train Time (s)         12158.727290404495
Epoch                        67
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:10:22.425627 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #67 | Epoch Duration: 175.49273037910461
2020-01-13 08:10:22.425803 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #67 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.924299
Z variance train             0.0026507992
KL Divergence                74.62145
KL Loss                      7.4621453
QF Loss                      739.5469
VF Loss                      876.24194
Policy Loss                  -3099.9094
Q Predictions Mean           3106.9756
Q Predictions Std            585.32184
Q Predictions Max            3726.853
Q Predictions Min            394.30975
V Predictions Mean           3115.7742
V Predictions Std            578.38043
V Predictions Max            3721.7158
V Predictions Min            425.56485
Log Pis Mean                 4.979582
Log Pis Std                  3.6203728
Log Pis Max                  17.315815
Log Pis Min                  -3.2321448
Policy mu Mean               -0.22603501
Policy mu Std                1.3635781
Policy mu Max                2.8867717
Policy mu Min                -3.3878434
Policy log std Mean          -0.80504274
Policy log std Std           0.4174822
Policy log std Max           0.1298601
Policy log std Min           -2.9519327
Z mean eval                  4.9562488
Z variance eval              0.0011314498
total_rewards                [8720.78686297 8499.72834727 8850.81365007 8614.98664679 8485.07066588
 8770.15412052 8518.59269313 8802.804095   8705.38987237 8781.67287809]
total_rewards_mean           8674.999983210892
total_rewards_std            128.6685157294781
total_rewards_max            8850.813650070662
total_rewards_min            8485.070665884527
Number of train steps total  276000
Number of env steps total    347000
Number of rollouts total     0
Train Time (s)               126.55808382900432
(Previous) Eval Time (s)     27.998335810843855
Sample Time (s)              21.386825560126454
Epoch Time (s)               175.94324519997463
Total Train Time (s)         12335.056958278175
Epoch                        68
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:13:18.755173 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #68 | Epoch Duration: 176.32925415039062
2020-01-13 08:13:18.755331 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #68 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.9565234
Z variance train             0.0011335359
KL Divergence                77.65419
KL Loss                      7.765419
QF Loss                      397.41803
VF Loss                      210.41989
Policy Loss                  -3126.7144
Q Predictions Mean           3127.3735
Q Predictions Std            570.65845
Q Predictions Max            3768.065
Q Predictions Min            400.00684
V Predictions Mean           3133.3596
V Predictions Std            562.6983
V Predictions Max            3766.3342
V Predictions Min            409.95743
Log Pis Mean                 4.279785
Log Pis Std                  3.7596533
Log Pis Max                  17.128819
Log Pis Min                  -5.039361
Policy mu Mean               -0.16507305
Policy mu Std                1.2903209
Policy mu Max                2.8771946
Policy mu Min                -3.1333356
Policy log std Mean          -0.7998689
Policy log std Std           0.38814384
Policy log std Max           0.04670787
Policy log std Min           -2.9172359
Z mean eval                  4.655746
Z variance eval              0.0075351237
total_rewards                [8819.9859555  8965.93543132 8847.70916286 8327.64657348 8622.72016103
 8808.00661938 8234.56419552 8588.25843054 6157.33162558 8793.52821863]
total_rewards_mean           8416.568637382468
total_rewards_std            785.0423071892651
total_rewards_max            8965.935431320708
total_rewards_min            6157.3316255786485
Number of train steps total  280000
Number of env steps total    352000
Number of rollouts total     0
Train Time (s)               133.4200849318877
(Previous) Eval Time (s)     28.38402446685359
Sample Time (s)              22.60063308198005
Epoch Time (s)               184.40474248072132
Total Train Time (s)         12520.337171851192
Epoch                        69
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:16:24.038434 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #69 | Epoch Duration: 185.28298377990723
2020-01-13 08:16:24.038676 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #69 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.65573
Z variance train             0.007505073
KL Divergence                67.714874
KL Loss                      6.7714877
QF Loss                      254.34314
VF Loss                      143.41982
Policy Loss                  -3035.4219
Q Predictions Mean           3036.603
Q Predictions Std            523.4931
Q Predictions Max            3690.1497
Q Predictions Min            355.76608
V Predictions Mean           3030.331
V Predictions Std            516.31696
V Predictions Max            3673.4226
V Predictions Min            349.5423
Log Pis Mean                 4.4087343
Log Pis Std                  3.68077
Log Pis Max                  14.664467
Log Pis Min                  -6.0758123
Policy mu Mean               -0.17890292
Policy mu Std                1.3284725
Policy mu Max                2.8276508
Policy mu Min                -3.0519664
Policy log std Mean          -0.7887003
Policy log std Std           0.4130273
Policy log std Max           -0.000105023384
Policy log std Min           -2.9983225
Z mean eval                  4.5676394
Z variance eval              0.010230911
total_rewards                [8483.55476962 8296.66936636 8262.65820736 8443.83981968 8856.80489264
 8899.69988403 8529.29981192 8614.7255678  8260.26129293 8429.68224318]
total_rewards_mean           8507.71958555216
total_rewards_std            215.4094618935636
total_rewards_max            8899.699884026808
total_rewards_min            8260.261292928179
Number of train steps total  284000
Number of env steps total    357000
Number of rollouts total     0
Train Time (s)               132.26086341682822
(Previous) Eval Time (s)     29.261817943304777
Sample Time (s)              22.87351594120264
Epoch Time (s)               184.39619730133563
Total Train Time (s)         12702.982449773233
Epoch                        70
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:19:26.685847 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #70 | Epoch Duration: 182.64699053764343
2020-01-13 08:19:26.686168 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #70 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.531625
Z variance train             0.015105613
KL Divergence                62.468872
KL Loss                      6.246887
QF Loss                      379.82013
VF Loss                      178.22691
Policy Loss                  -2947.744
Q Predictions Mean           2951.178
Q Predictions Std            606.30695
Q Predictions Max            3729.4324
Q Predictions Min            342.69452
V Predictions Mean           2947.0571
V Predictions Std            604.1956
V Predictions Max            3727.8882
V Predictions Min            332.91168
Log Pis Mean                 4.280775
Log Pis Std                  4.0695033
Log Pis Max                  16.803745
Log Pis Min                  -6.945936
Policy mu Mean               -0.18161422
Policy mu Std                1.3031939
Policy mu Max                2.9954686
Policy mu Min                -3.0419002
Policy log std Mean          -0.795269
Policy log std Std           0.41091698
Policy log std Max           0.19705504
Policy log std Min           -3.1186957
Z mean eval                  4.696352
Z variance eval              0.0012935159
total_rewards                [8582.75918136 8606.34664749 8957.06411555 8993.09243827 8306.69015555
 8977.43302417 8657.72328733 8649.17092442 8799.14678702 8676.4244866 ]
total_rewards_mean           8720.585104775451
total_rewards_std            204.12803670443358
total_rewards_max            8993.092438270325
total_rewards_min            8306.69015554874
Number of train steps total  288000
Number of env steps total    362000
Number of rollouts total     0
Train Time (s)               131.88673154218122
(Previous) Eval Time (s)     27.512242319993675
Sample Time (s)              22.559390482958406
Epoch Time (s)               181.9583643451333
Total Train Time (s)         12886.20628886437
Epoch                        71
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:22:29.911018 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #71 | Epoch Duration: 183.2246720790863
2020-01-13 08:22:29.911259 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #71 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.6184974
Z variance train             0.0029173265
KL Divergence                67.748245
KL Loss                      6.7748246
QF Loss                      343.70886
VF Loss                      208.74295
Policy Loss                  -3040.2676
Q Predictions Mean           3034.8638
Q Predictions Std            609.2816
Q Predictions Max            3743.897
Q Predictions Min            313.23755
V Predictions Mean           3033.107
V Predictions Std            607.26056
V Predictions Max            3753.5508
V Predictions Min            304.5158
Log Pis Mean                 4.1587095
Log Pis Std                  3.802006
Log Pis Max                  16.298756
Log Pis Min                  -7.277996
Policy mu Mean               -0.20753324
Policy mu Std                1.2981234
Policy mu Max                4.2304068
Policy mu Min                -2.6737318
Policy log std Mean          -0.786683
Policy log std Std           0.41285002
Policy log std Max           0.16211224
Policy log std Min           -3.054181
Z mean eval                  4.607639
Z variance eval              0.0043062344
total_rewards                [8874.50656585 8787.64007763 8815.02143949 8977.43322987 8772.78852036
 8868.05040468 8984.42444493 8772.41844031 8281.68543101 8459.78097343]
total_rewards_mean           8759.37495275591
total_rewards_std            211.05725884261034
total_rewards_max            8984.424444930086
total_rewards_min            8281.68543100703
Number of train steps total  292000
Number of env steps total    367000
Number of rollouts total     0
Train Time (s)               132.90216265898198
(Previous) Eval Time (s)     28.77821715408936
Sample Time (s)              23.471243362873793
Epoch Time (s)               185.15162317594513
Total Train Time (s)         13071.038168592378
Epoch                        72
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:25:34.743012 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #72 | Epoch Duration: 184.83163142204285
2020-01-13 08:25:34.743129 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #72 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.627799
Z variance train             0.0031263027
KL Divergence                70.983604
KL Loss                      7.0983605
QF Loss                      383.84778
VF Loss                      125.43919
Policy Loss                  -3139.1396
Q Predictions Mean           3137.6008
Q Predictions Std            511.17123
Q Predictions Max            3798.2405
Q Predictions Min            318.2698
V Predictions Mean           3139.372
V Predictions Std            504.1115
V Predictions Max            3794.9924
V Predictions Min            326.11984
Log Pis Mean                 4.80915
Log Pis Std                  3.6060238
Log Pis Max                  14.707764
Log Pis Min                  -2.8070116
Policy mu Mean               -0.2248108
Policy mu Std                1.3458599
Policy mu Max                2.8533478
Policy mu Min                -2.792532
Policy log std Mean          -0.8045972
Policy log std Std           0.42445427
Policy log std Max           0.061629534
Policy log std Min           -3.0906606
Z mean eval                  4.6127024
Z variance eval              0.0028747623
total_rewards                [8940.2309631  9221.29603641 9015.55079948 9394.69704568 8917.7153002
 9171.62354716 8634.76623244 8783.68479929 9020.48261751 8863.36715289]
total_rewards_mean           8996.341449416472
total_rewards_std            210.69871051650713
total_rewards_max            9394.69704568181
total_rewards_min            8634.766232436345
Number of train steps total  296000
Number of env steps total    372000
Number of rollouts total     0
Train Time (s)               127.62952772015706
(Previous) Eval Time (s)     28.457918826956302
Sample Time (s)              23.45896413223818
Epoch Time (s)               179.54641067935154
Total Train Time (s)         13250.356568559539
Epoch                        73
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:28:34.064143 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #73 | Epoch Duration: 179.32090497016907
2020-01-13 08:28:34.064324 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #73 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.6135736
Z variance train             0.002896437
KL Divergence                68.51015
KL Loss                      6.8510146
QF Loss                      333.8465
VF Loss                      142.21646
Policy Loss                  -3127.1414
Q Predictions Mean           3129.2737
Q Predictions Std            555.9776
Q Predictions Max            3731.2288
Q Predictions Min            317.1713
V Predictions Mean           3126.1606
V Predictions Std            553.45917
V Predictions Max            3724.5923
V Predictions Min            298.615
Log Pis Mean                 4.981517
Log Pis Std                  3.7809837
Log Pis Max                  14.2521
Log Pis Min                  -6.4354467
Policy mu Mean               -0.18670858
Policy mu Std                1.3666313
Policy mu Max                2.8340065
Policy mu Min                -3.0836504
Policy log std Mean          -0.78808004
Policy log std Std           0.39919823
Policy log std Max           -0.0044201612
Policy log std Min           -3.0479116
Z mean eval                  4.5412436
Z variance eval              0.0018751379
total_rewards                [8818.54693805 8788.60101963 8971.8992529  8829.46902056 9316.91456353
 8892.66078128 7193.72239958 8809.26444112 9173.24498891 8967.9974618 ]
total_rewards_mean           8776.232086735432
total_rewards_std            552.1573851487803
total_rewards_max            9316.914563526258
total_rewards_min            7193.722399581276
Number of train steps total  300000
Number of env steps total    377000
Number of rollouts total     0
Train Time (s)               125.66642750008032
(Previous) Eval Time (s)     28.232032511848956
Sample Time (s)              22.182379654143006
Epoch Time (s)               176.08083966607228
Total Train Time (s)         13424.868036698084
Epoch                        74
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:31:28.576038 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #74 | Epoch Duration: 174.5115978717804
2020-01-13 08:31:28.576158 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #74 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.544152
Z variance train             0.0018741839
KL Divergence                67.16718
KL Loss                      6.716718
QF Loss                      320.04175
VF Loss                      260.8922
Policy Loss                  -3067.7974
Q Predictions Mean           3065.7258
Q Predictions Std            651.90234
Q Predictions Max            3781.8474
Q Predictions Min            287.7528
V Predictions Mean           3057.1504
V Predictions Std            645.06195
V Predictions Max            3776.5427
V Predictions Min            274.5775
Log Pis Mean                 4.1582623
Log Pis Std                  3.7666352
Log Pis Max                  16.999905
Log Pis Min                  -5.4947844
Policy mu Mean               -0.25501764
Policy mu Std                1.2968422
Policy mu Max                3.3299274
Policy mu Min                -4.6079845
Policy log std Mean          -0.79963017
Policy log std Std           0.40044785
Policy log std Max           0.16728342
Policy log std Min           -2.9809594
Z mean eval                  4.5320625
Z variance eval              0.004011242
total_rewards                [8079.39542819 8672.40598485 8820.19788597 8681.85371005 8481.64972311
 7843.97122592 9022.4072441  8641.25588773 8402.10334399 8492.26584969]
total_rewards_mean           8513.750628358519
total_rewards_std            327.6515377046815
total_rewards_max            9022.407244100274
total_rewards_min            7843.971225917825
Number of train steps total  304000
Number of env steps total    382000
Number of rollouts total     0
Train Time (s)               126.83097609691322
(Previous) Eval Time (s)     26.662404865957797
Sample Time (s)              21.1673315721564
Epoch Time (s)               174.66071253502741
Total Train Time (s)         13601.25746855652
Epoch                        75
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:34:24.968843 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #75 | Epoch Duration: 176.39253950119019
2020-01-13 08:34:24.969207 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #75 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.528167
Z variance train             0.004014621
KL Divergence                64.48695
KL Loss                      6.4486957
QF Loss                      439.34158
VF Loss                      197.44888
Policy Loss                  -3103.5413
Q Predictions Mean           3107.2646
Q Predictions Std            573.7078
Q Predictions Max            3803.658
Q Predictions Min            260.78992
V Predictions Mean           3111.4026
V Predictions Std            566.2822
V Predictions Max            3787.415
V Predictions Min            260.5708
Log Pis Mean                 4.349223
Log Pis Std                  3.9016194
Log Pis Max                  15.294027
Log Pis Min                  -4.341483
Policy mu Mean               -0.2346478
Policy mu Std                1.308714
Policy mu Max                3.2260828
Policy mu Min                -2.9572687
Policy log std Mean          -0.7950814
Policy log std Std           0.40319526
Policy log std Max           0.09663439
Policy log std Min           -3.053862
Z mean eval                  4.534758
Z variance eval              0.0045419945
total_rewards                [8936.99288667 9002.01433325 8815.68999189 8638.91916869 8859.45164154
 8989.29059663 9143.32139982 8912.19467403 9058.26002953 8834.88079944]
total_rewards_mean           8919.101552146603
total_rewards_std            134.779755077205
total_rewards_max            9143.321399816934
total_rewards_min            8638.919168685048
Number of train steps total  308000
Number of env steps total    387000
Number of rollouts total     0
Train Time (s)               133.80378579720855
(Previous) Eval Time (s)     28.39385389816016
Sample Time (s)              22.871452586259693
Epoch Time (s)               185.0690922816284
Total Train Time (s)         13785.549550652038
Epoch                        76
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:37:29.261939 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #76 | Epoch Duration: 184.29250264167786
2020-01-13 08:37:29.262143 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #76 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.335687
Z variance train             0.004864622
KL Divergence                60.845703
KL Loss                      6.0845704
QF Loss                      329.0802
VF Loss                      195.60011
Policy Loss                  -3088.0212
Q Predictions Mean           3084.2158
Q Predictions Std            630.9181
Q Predictions Max            3805.0017
Q Predictions Min            264.17743
V Predictions Mean           3082.7793
V Predictions Std            625.86774
V Predictions Max            3805.6863
V Predictions Min            266.15237
Log Pis Mean                 4.6358194
Log Pis Std                  3.7151704
Log Pis Max                  16.392267
Log Pis Min                  -9.603733
Policy mu Mean               -0.19558962
Policy mu Std                1.3572478
Policy mu Max                3.702754
Policy mu Min                -2.9542434
Policy log std Mean          -0.7879862
Policy log std Std           0.4209628
Policy log std Max           0.06887245
Policy log std Min           -3.1273448
Z mean eval                  4.3930025
Z variance eval              0.002388372
total_rewards                [8269.06196553 8555.07599405 8436.05193032 8507.42609322 8699.21556843
 8309.30463368 8827.41325192 8459.37785819 8649.69646118 8874.64460531]
total_rewards_mean           8558.726836184778
total_rewards_std            193.31078672302917
total_rewards_max            8874.644605311722
total_rewards_min            8269.06196553361
Number of train steps total  312000
Number of env steps total    392000
Number of rollouts total     0
Train Time (s)               132.35175290331244
(Previous) Eval Time (s)     27.616905617062002
Sample Time (s)              22.424512377474457
Epoch Time (s)               182.3931708978489
Total Train Time (s)         13968.946128548123
Epoch                        77
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:40:32.658831 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #77 | Epoch Duration: 183.39656591415405
2020-01-13 08:40:32.658946 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.392553
Z variance train             0.0023864233
KL Divergence                63.35706
KL Loss                      6.335706
QF Loss                      360.73767
VF Loss                      231.10927
Policy Loss                  -3232.055
Q Predictions Mean           3236.0542
Q Predictions Std            476.8605
Q Predictions Max            3899.7478
Q Predictions Min            262.02448
V Predictions Mean           3239.1104
V Predictions Std            471.42914
V Predictions Max            3869.349
V Predictions Min            297.3832
Log Pis Mean                 4.8838043
Log Pis Std                  3.2941108
Log Pis Max                  13.600811
Log Pis Min                  -2.7962441
Policy mu Mean               -0.14693712
Policy mu Std                1.3361763
Policy mu Max                3.0775626
Policy mu Min                -2.683378
Policy log std Mean          -0.79850197
Policy log std Std           0.40129575
Policy log std Max           0.104843855
Policy log std Min           -3.1371593
Z mean eval                  4.40778
Z variance eval              0.0014199972
total_rewards                [8783.32251249 8980.69890754 8971.3039254  8824.62526547 8811.59965071
 8658.21254462 8871.45608121 8933.67683415 8754.9668233  8656.10673683]
total_rewards_mean           8824.59692817304
total_rewards_std            110.80547987334806
total_rewards_max            8980.698907542792
total_rewards_min            8656.106736832486
Number of train steps total  316000
Number of env steps total    397000
Number of rollouts total     0
Train Time (s)               132.1341349799186
(Previous) Eval Time (s)     28.619925318751484
Sample Time (s)              22.684521184302866
Epoch Time (s)               183.43858148297295
Total Train Time (s)         14152.249249810353
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:43:35.964801 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #78 | Epoch Duration: 183.30575037002563
2020-01-13 08:43:35.964992 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.4082747
Z variance train             0.0014216725
KL Divergence                63.86139
KL Loss                      6.386139
QF Loss                      531.5808
VF Loss                      134.6705
Policy Loss                  -3184.993
Q Predictions Mean           3190.7017
Q Predictions Std            579.1824
Q Predictions Max            3873.7554
Q Predictions Min            261.88123
V Predictions Mean           3190.739
V Predictions Std            573.8764
V Predictions Max            3866.5225
V Predictions Min            281.42337
Log Pis Mean                 4.932661
Log Pis Std                  3.417538
Log Pis Max                  13.224075
Log Pis Min                  -6.740942
Policy mu Mean               -0.2320258
Policy mu Std                1.3635553
Policy mu Max                3.0576317
Policy mu Min                -2.7698781
Policy log std Mean          -0.7908614
Policy log std Std           0.4176402
Policy log std Max           -0.08990902
Policy log std Min           -2.8986633
Z mean eval                  4.386775
Z variance eval              0.0020131683
total_rewards                [9033.98468053 9252.90076641 9321.48477132 9087.67971092 9190.10028908
 9131.9304017  8918.18605567 8796.18533397 9083.54716943 9245.12696242]
total_rewards_mean           9106.112614144546
total_rewards_std            152.4467529526222
total_rewards_max            9321.4847713229
total_rewards_min            8796.185333966205
Number of train steps total  320000
Number of env steps total    402000
Number of rollouts total     0
Train Time (s)               131.87925387592986
(Previous) Eval Time (s)     28.48671645205468
Sample Time (s)              21.96107752621174
Epoch Time (s)               182.32704785419628
Total Train Time (s)         14334.056756286882
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:46:37.774506 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #79 | Epoch Duration: 181.8093400001526
2020-01-13 08:46:37.774830 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #79 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.385272
Z variance train             0.0020322115
KL Divergence                64.01684
KL Loss                      6.401684
QF Loss                      301.22388
VF Loss                      376.60535
Policy Loss                  -3164.545
Q Predictions Mean           3165.2554
Q Predictions Std            647.56177
Q Predictions Max            3845.7737
Q Predictions Min            248.99721
V Predictions Mean           3151.9043
V Predictions Std            640.40295
V Predictions Max            3821.5933
V Predictions Min            246.16675
Log Pis Mean                 4.338442
Log Pis Std                  3.7407913
Log Pis Max                  13.098749
Log Pis Min                  -5.47559
Policy mu Mean               -0.21995707
Policy mu Std                1.2832711
Policy mu Max                3.0695682
Policy mu Min                -2.813689
Policy log std Mean          -0.8304782
Policy log std Std           0.4191825
Policy log std Max           -0.06693232
Policy log std Min           -2.9567246
Z mean eval                  4.377904
Z variance eval              0.0013186485
total_rewards                [8902.51730837 8747.58952727 8697.9729437  8691.02050869 8690.10567447
 8600.07084636 8840.61271643 8534.11898379 8740.45929386 8605.06475336]
total_rewards_mean           8704.95325562934
total_rewards_std            105.42260317528196
total_rewards_max            8902.517308367957
total_rewards_min            8534.118983793443
Number of train steps total  324000
Number of env steps total    407000
Number of rollouts total     0
Train Time (s)               128.0479786200449
(Previous) Eval Time (s)     27.968616320751607
Sample Time (s)              22.928351339884102
Epoch Time (s)               178.9449462806806
Total Train Time (s)         14513.123747770209
Epoch                        80
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:49:36.846735 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #80 | Epoch Duration: 179.07168245315552
2020-01-13 08:49:36.847141 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #80 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.350086
Z variance train             0.0012017217
KL Divergence                63.595062
KL Loss                      6.359506
QF Loss                      484.88818
VF Loss                      213.22083
Policy Loss                  -3179.1736
Q Predictions Mean           3178.1519
Q Predictions Std            620.12494
Q Predictions Max            3848.9233
Q Predictions Min            238.3488
V Predictions Mean           3173.8008
V Predictions Std            614.3065
V Predictions Max            3845.0586
V Predictions Min            228.574
Log Pis Mean                 4.8629513
Log Pis Std                  3.735241
Log Pis Max                  14.30586
Log Pis Min                  -3.228425
Policy mu Mean               -0.25050297
Policy mu Std                1.3221279
Policy mu Max                2.7047415
Policy mu Min                -3.0008118
Policy log std Mean          -0.8042283
Policy log std Std           0.40367535
Policy log std Max           0.0070618987
Policy log std Min           -3.045741
Z mean eval                  4.3378367
Z variance eval              0.00096159463
total_rewards                [8967.3677356  9114.96536901 9292.66874828 9091.76591405 9170.87095133
 9241.45546888 9375.47992655 9235.19760314 9191.74929621 9111.43770388]
total_rewards_mean           9179.295871693012
total_rewards_std            109.4872830771152
total_rewards_max            9375.479926548694
total_rewards_min            8967.367735601603
Number of train steps total  328000
Number of env steps total    412000
Number of rollouts total     0
Train Time (s)               124.89635625807568
(Previous) Eval Time (s)     28.09492342406884
Sample Time (s)              22.50604216940701
Epoch Time (s)               175.49732185155153
Total Train Time (s)         14688.818035913631
Epoch                        81
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:52:32.539249 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #81 | Epoch Duration: 175.6917746067047
2020-01-13 08:52:32.539444 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #81 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.3265924
Z variance train             0.0010693287
KL Divergence                63.251297
KL Loss                      6.32513
QF Loss                      506.22308
VF Loss                      223.36899
Policy Loss                  -3143.422
Q Predictions Mean           3148.0583
Q Predictions Std            674.6445
Q Predictions Max            3919.8062
Q Predictions Min            228.64468
V Predictions Mean           3145.9736
V Predictions Std            671.3218
V Predictions Max            3885.597
V Predictions Min            235.97478
Log Pis Mean                 4.7353516
Log Pis Std                  3.6070747
Log Pis Max                  18.544365
Log Pis Min                  -3.4464192
Policy mu Mean               -0.20434916
Policy mu Std                1.3469135
Policy mu Max                3.3939855
Policy mu Min                -3.1321104
Policy log std Mean          -0.7994773
Policy log std Std           0.41965517
Policy log std Max           0.22043931
Policy log std Min           -3.0972083
Z mean eval                  4.1182194
Z variance eval              0.0010611529
total_rewards                [9105.17290488 3698.95314551 8756.4788248  8824.93845308 8832.21437989
 8901.53700419 8981.46655363 9238.30357935 9056.63739398 9436.2154822 ]
total_rewards_mean           8483.191772151064
total_rewards_std            1606.8500726388713
total_rewards_max            9436.215482200943
total_rewards_min            3698.953145511315
Number of train steps total  332000
Number of env steps total    417000
Number of rollouts total     0
Train Time (s)               127.40553108463064
(Previous) Eval Time (s)     28.288983006961644
Sample Time (s)              22.2095674299635
Epoch Time (s)               177.90408152155578
Total Train Time (s)         14866.681584910955
Epoch                        82
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:55:30.404628 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #82 | Epoch Duration: 177.86504340171814
2020-01-13 08:55:30.404819 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #82 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.114473
Z variance train             0.0010945383
KL Divergence                58.142067
KL Loss                      5.8142066
QF Loss                      435.30774
VF Loss                      190.64308
Policy Loss                  -3151.3665
Q Predictions Mean           3153.1016
Q Predictions Std            603.6979
Q Predictions Max            3845.4336
Q Predictions Min            193.14853
V Predictions Mean           3160.3145
V Predictions Std            602.37805
V Predictions Max            3848.8076
V Predictions Min            207.51016
Log Pis Mean                 4.5712633
Log Pis Std                  3.9914396
Log Pis Max                  16.385029
Log Pis Min                  -4.9357977
Policy mu Mean               -0.22355843
Policy mu Std                1.3110437
Policy mu Max                2.6962771
Policy mu Min                -2.7735636
Policy log std Mean          -0.7955262
Policy log std Std           0.40823117
Policy log std Max           0.20150936
Policy log std Min           -2.9328804
Z mean eval                  4.1947036
Z variance eval              0.00059469824
total_rewards                [9277.58549512 9297.5803467  9132.36415338 8829.16231794 9169.96558633
 9365.16793888 9190.11382752 9326.02346334 9202.50858981 9223.77659311]
total_rewards_mean           9201.424831213177
total_rewards_std            142.24981863391085
total_rewards_max            9365.167938878689
total_rewards_min            8829.162317944483
Number of train steps total  336000
Number of env steps total    422000
Number of rollouts total     0
Train Time (s)               133.43195722158998
(Previous) Eval Time (s)     28.249599159229547
Sample Time (s)              22.60166082298383
Epoch Time (s)               184.28321720380336
Total Train Time (s)         15052.27593638841
Epoch                        83
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:58:36.000791 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #83 | Epoch Duration: 185.5958333015442
2020-01-13 08:58:36.000981 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1991987
Z variance train             0.0005688486
KL Divergence                61.0489
KL Loss                      6.1048903
QF Loss                      291.8236
VF Loss                      118.982376
Policy Loss                  -3127.1106
Q Predictions Mean           3123.538
Q Predictions Std            679.76733
Q Predictions Max            3864.5195
Q Predictions Min            185.22824
V Predictions Mean           3131.6738
V Predictions Std            674.77216
V Predictions Max            3859.2488
V Predictions Min            214.3381
Log Pis Mean                 4.6480293
Log Pis Std                  3.8294358
Log Pis Max                  14.126593
Log Pis Min                  -3.7111635
Policy mu Mean               -0.2391743
Policy mu Std                1.3275514
Policy mu Max                3.3286848
Policy mu Min                -3.0615883
Policy log std Mean          -0.8037259
Policy log std Std           0.40066075
Policy log std Max           -0.10190362
Policy log std Min           -3.0237706
Z mean eval                  4.2582445
Z variance eval              0.0013670253
total_rewards                [9336.37399358 9397.92685548 9324.29504415 9293.90046916 9211.03466239
 9208.07107219 9376.95354663 9526.34963729 9148.31000796 9412.63902404]
total_rewards_mean           9323.585431287453
total_rewards_std            107.32969454721166
total_rewards_max            9526.349637287954
total_rewards_min            9148.310007960588
Number of train steps total  340000
Number of env steps total    427000
Number of rollouts total     0
Train Time (s)               131.87652385793626
(Previous) Eval Time (s)     29.561870905105025
Sample Time (s)              21.290298308245838
Epoch Time (s)               182.72869307128713
Total Train Time (s)         15232.549700662028
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:01:36.277283 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #84 | Epoch Duration: 180.2761332988739
2020-01-13 09:01:36.277598 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #84 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2466836
Z variance train             0.0016184527
KL Divergence                60.437386
KL Loss                      6.043739
QF Loss                      266.11227
VF Loss                      181.92657
Policy Loss                  -3243.748
Q Predictions Mean           3244.6238
Q Predictions Std            664.94
Q Predictions Max            3915.0537
Q Predictions Min            205.17787
V Predictions Mean           3251.188
V Predictions Std            661.8764
V Predictions Max            3903.2805
V Predictions Min            209.71362
Log Pis Mean                 4.893407
Log Pis Std                  3.8599324
Log Pis Max                  22.914513
Log Pis Min                  -5.5387177
Policy mu Mean               -0.18215342
Policy mu Std                1.3914977
Policy mu Max                3.4065938
Policy mu Min                -5.225232
Policy log std Mean          -0.796693
Policy log std Std           0.42353746
Policy log std Max           0.016124845
Policy log std Min           -3.144209
Z mean eval                  4.2431135
Z variance eval              0.0039134165
total_rewards                [9238.77907375 9589.26750858 9509.44427545 9568.77081357 9506.89980506
 9566.85047496 9326.27393713 9709.51622562 9433.90060751 9512.04850952]
total_rewards_mean           9496.175123114224
total_rewards_std            128.05704432236084
total_rewards_max            9709.516225620608
total_rewards_min            9238.779073747493
Number of train steps total  344000
Number of env steps total    432000
Number of rollouts total     0
Train Time (s)               131.2120385277085
(Previous) Eval Time (s)     27.108961118850857
Sample Time (s)              22.155757036525756
Epoch Time (s)               180.4767566830851
Total Train Time (s)         15415.105972137768
Epoch                        85
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:04:38.833643 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #85 | Epoch Duration: 182.5558865070343
2020-01-13 09:04:38.833770 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #85 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2373624
Z variance train             0.0040450366
KL Divergence                58.917496
KL Loss                      5.89175
QF Loss                      417.39157
VF Loss                      232.5984
Policy Loss                  -3151.0686
Q Predictions Mean           3150.636
Q Predictions Std            753.4452
Q Predictions Max            4024.265
Q Predictions Min            194.67506
V Predictions Mean           3159.1003
V Predictions Std            748.4291
V Predictions Max            3996.5857
V Predictions Min            204.89682
Log Pis Mean                 4.471898
Log Pis Std                  3.925524
Log Pis Max                  15.333836
Log Pis Min                  -5.990817
Policy mu Mean               -0.20062809
Policy mu Std                1.288779
Policy mu Max                3.4062524
Policy mu Min                -3.4609458
Policy log std Mean          -0.8277302
Policy log std Std           0.43371928
Policy log std Max           0.13979888
Policy log std Min           -3.1608133
Z mean eval                  4.3328934
Z variance eval              0.0011760422
total_rewards                [9174.93425826 9535.36904436 9305.42663432 9371.10686903 9183.2178926
 9374.93852908 9064.21082439 9352.10260251 9427.8489569  9237.77769329]
total_rewards_mean           9302.69333047239
total_rewards_std            131.84655975702543
total_rewards_max            9535.369044358065
total_rewards_min            9064.210824393915
Number of train steps total  348000
Number of env steps total    437000
Number of rollouts total     0
Train Time (s)               132.82809175690636
(Previous) Eval Time (s)     29.1877611130476
Sample Time (s)              22.48569788923487
Epoch Time (s)               184.50155075918883
Total Train Time (s)         15599.36365357181
Epoch                        86
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:07:43.093859 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #86 | Epoch Duration: 184.25999069213867
2020-01-13 09:07:43.094039 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #86 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.3248224
Z variance train             0.0011616686
KL Divergence                62.58232
KL Loss                      6.258232
QF Loss                      347.28735
VF Loss                      224.76749
Policy Loss                  -3361.6829
Q Predictions Mean           3362.5898
Q Predictions Std            501.43588
Q Predictions Max            4011.2073
Q Predictions Min            203.76631
V Predictions Mean           3370.12
V Predictions Std            495.99484
V Predictions Max            4023.4243
V Predictions Min            225.44656
Log Pis Mean                 4.800463
Log Pis Std                  3.577114
Log Pis Max                  14.491385
Log Pis Min                  -5.190125
Policy mu Mean               -0.16939759
Policy mu Std                1.3530377
Policy mu Max                2.813226
Policy mu Min                -2.736352
Policy log std Mean          -0.8297243
Policy log std Std           0.43234307
Policy log std Max           -0.22359163
Policy log std Min           -3.18752
Z mean eval                  4.2164006
Z variance eval              0.0019751408
total_rewards                [8725.97561538 9072.64426484 9568.06626884 9205.55301116 8506.22897769
 9006.43676086 9387.11751593 8941.06328327 9586.95814832 9678.73614387]
total_rewards_mean           9167.87799901616
total_rewards_std            369.5774663323586
total_rewards_max            9678.736143872708
total_rewards_min            8506.228977685345
Number of train steps total  352000
Number of env steps total    442000
Number of rollouts total     0
Train Time (s)               129.6162635772489
(Previous) Eval Time (s)     28.945874540135264
Sample Time (s)              23.111089711543173
Epoch Time (s)               181.67322782892734
Total Train Time (s)         15777.331223567482
Epoch                        87
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:10:41.063363 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #87 | Epoch Duration: 177.96918487548828
2020-01-13 09:10:41.063563 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2186522
Z variance train             0.001960031
KL Divergence                59.17098
KL Loss                      5.917098
QF Loss                      333.05267
VF Loss                      134.17642
Policy Loss                  -3282.7747
Q Predictions Mean           3284.5586
Q Predictions Std            646.0852
Q Predictions Max            4065.5642
Q Predictions Min            210.63321
V Predictions Mean           3280.423
V Predictions Std            642.7227
V Predictions Max            4058.5237
V Predictions Min            209.82555
Log Pis Mean                 4.9470596
Log Pis Std                  3.648111
Log Pis Max                  14.835518
Log Pis Min                  -4.736827
Policy mu Mean               -0.21017577
Policy mu Std                1.3413514
Policy mu Max                3.0281606
Policy mu Min                -2.8936877
Policy log std Mean          -0.81051844
Policy log std Std           0.40958467
Policy log std Max           -0.0085353255
Policy log std Min           -3.1330514
Z mean eval                  4.2301
Z variance eval              0.0016906597
total_rewards                [9413.00778074 9417.70548735 9381.03762811 9434.46309    9577.97822396
 9425.29169912 9437.99110056 9504.93167991 9330.72320002 9235.6384035 ]
total_rewards_mean           9415.876829327377
total_rewards_std            87.23137881856847
total_rewards_max            9577.978223960181
total_rewards_min            9235.638403496223
Number of train steps total  356000
Number of env steps total    447000
Number of rollouts total     0
Train Time (s)               125.57788266520947
(Previous) Eval Time (s)     25.241514859721065
Sample Time (s)              22.216113133355975
Epoch Time (s)               173.0355106582865
Total Train Time (s)         15952.933321595658
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:13:36.667612 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #88 | Epoch Duration: 175.6038920879364
2020-01-13 09:13:36.667893 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #88 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2134247
Z variance train             0.0023809536
KL Divergence                59.898964
KL Loss                      5.9898963
QF Loss                      754.2267
VF Loss                      205.64088
Policy Loss                  -3251.668
Q Predictions Mean           3262.3489
Q Predictions Std            729.41046
Q Predictions Max            4044.4136
Q Predictions Min            196.7179
V Predictions Mean           3256.4314
V Predictions Std            723.4112
V Predictions Max            4047.3228
V Predictions Min            218.85909
Log Pis Mean                 4.5860934
Log Pis Std                  3.8416367
Log Pis Max                  16.957983
Log Pis Min                  -6.7019277
Policy mu Mean               -0.19979824
Policy mu Std                1.3116693
Policy mu Max                3.0264761
Policy mu Min                -3.274552
Policy log std Mean          -0.81402475
Policy log std Std           0.40580913
Policy log std Max           0.034369826
Policy log std Min           -3.0454104
Z mean eval                  4.1425686
Z variance eval              0.0053036776
total_rewards                [9655.16336648 9722.75973291 9828.5253173  8054.5201933  9831.92211646
 9793.57009585 9619.24576051 9528.45910797 9608.41580722 9735.86851857]
total_rewards_mean           9537.845001656655
total_rewards_std            503.5363932414392
total_rewards_max            9831.922116460262
total_rewards_min            8054.520193301192
Number of train steps total  360000
Number of env steps total    452000
Number of rollouts total     0
Train Time (s)               125.80993436696008
(Previous) Eval Time (s)     27.809551286976784
Sample Time (s)              22.03291506320238
Epoch Time (s)               175.65240071713924
Total Train Time (s)         16129.059781727381
Epoch                        89
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:16:32.795718 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #89 | Epoch Duration: 176.1276617050171
2020-01-13 09:16:32.795904 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #89 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1436043
Z variance train             0.0055097146
KL Divergence                57.08989
KL Loss                      5.708989
QF Loss                      763.57007
VF Loss                      401.49554
Policy Loss                  -3298.822
Q Predictions Mean           3297.0225
Q Predictions Std            579.30975
Q Predictions Max            4066.0535
Q Predictions Min            212.0442
V Predictions Mean           3282.7021
V Predictions Std            568.6651
V Predictions Max            4042.6277
V Predictions Min            212.93808
Log Pis Mean                 4.845907
Log Pis Std                  3.9084766
Log Pis Max                  15.429817
Log Pis Min                  -7.5633802
Policy mu Mean               -0.21787243
Policy mu Std                1.3520814
Policy mu Max                2.8270938
Policy mu Min                -4.0021453
Policy log std Mean          -0.834419
Policy log std Std           0.40972254
Policy log std Max           -0.087714076
Policy log std Min           -3.0897694
Z mean eval                  4.245582
Z variance eval              0.0043912064
total_rewards                [9504.77829842 9757.77370429 9798.00736144 9754.64630164 9738.14273995
 9751.06239889 9355.26199447 9809.65323344 9602.88727576 9749.19059738]
total_rewards_mean           9682.140390568971
total_rewards_std            140.58174692819958
total_rewards_max            9809.653233439612
total_rewards_min            9355.261994474875
Number of train steps total  364000
Number of env steps total    457000
Number of rollouts total     0
Train Time (s)               131.76995726302266
(Previous) Eval Time (s)     28.284503024071455
Sample Time (s)              22.9178291647695
Epoch Time (s)               182.97228945186362
Total Train Time (s)         16311.882927137893
Epoch                        90
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:19:35.621063 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #90 | Epoch Duration: 182.82499384880066
2020-01-13 09:19:35.621337 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #90 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2436647
Z variance train             0.0043637888
KL Divergence                59.63336
KL Loss                      5.9633365
QF Loss                      514.6864
VF Loss                      165.38696
Policy Loss                  -3340.948
Q Predictions Mean           3344.1958
Q Predictions Std            660.64215
Q Predictions Max            4117.06
Q Predictions Min            192.40031
V Predictions Mean           3344.731
V Predictions Std            654.38605
V Predictions Max            4116.005
V Predictions Min            207.55789
Log Pis Mean                 4.742959
Log Pis Std                  3.8629758
Log Pis Max                  15.80952
Log Pis Min                  -5.7628036
Policy mu Mean               -0.1992373
Policy mu Std                1.3529391
Policy mu Max                3.3413992
Policy mu Min                -2.9627879
Policy log std Mean          -0.82022256
Policy log std Std           0.42740443
Policy log std Max           -0.03831935
Policy log std Min           -3.0195088
Z mean eval                  4.216512
Z variance eval              0.0029717032
total_rewards                [9366.65591075 8794.84906451 9277.07520708 9173.21024812 9163.48366514
 9438.12008545 9535.27135703 8892.04616149 9435.04607295 9448.70907645]
total_rewards_mean           9252.446684896597
total_rewards_std            235.2558463282671
total_rewards_max            9535.271357026892
total_rewards_min            8794.849064511598
Number of train steps total  368000
Number of env steps total    462000
Number of rollouts total     0
Train Time (s)               131.9591387170367
(Previous) Eval Time (s)     28.13682090025395
Sample Time (s)              22.096608455758542
Epoch Time (s)               182.1925680730492
Total Train Time (s)         16494.666092271917
Epoch                        91
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:22:38.405415 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #91 | Epoch Duration: 182.78391981124878
2020-01-13 09:22:38.405684 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #91 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1963534
Z variance train             0.0030793636
KL Divergence                58.096428
KL Loss                      5.809643
QF Loss                      392.8606
VF Loss                      137.34369
Policy Loss                  -3382.6497
Q Predictions Mean           3387.4822
Q Predictions Std            637.52856
Q Predictions Max            4095.707
Q Predictions Min            185.20189
V Predictions Mean           3389.5767
V Predictions Std            634.4478
V Predictions Max            4095.3582
V Predictions Min            188.22447
Log Pis Mean                 4.7140555
Log Pis Std                  3.8514273
Log Pis Max                  15.908123
Log Pis Min                  -5.7288136
Policy mu Mean               -0.22430582
Policy mu Std                1.3531857
Policy mu Max                2.8278375
Policy mu Min                -2.8666487
Policy log std Mean          -0.81817913
Policy log std Std           0.424647
Policy log std Max           0.012949705
Policy log std Min           -3.055278
Z mean eval                  4.046065
Z variance eval              0.0015833369
total_rewards                [9535.27563593 9766.06680732 9409.19027245 9628.37894701 9703.88394219
 9717.23206363 9646.976206   9893.54509993 9571.55169686 9638.0710511 ]
total_rewards_mean           9651.017172242431
total_rewards_std            125.74699066588379
total_rewards_max            9893.545099928699
total_rewards_min            9409.19027245213
Number of train steps total  372000
Number of env steps total    467000
Number of rollouts total     0
Train Time (s)               132.25348411407322
(Previous) Eval Time (s)     28.727822793181986
Sample Time (s)              23.50584598677233
Epoch Time (s)               184.48715289402753
Total Train Time (s)         16679.563241257332
Epoch                        92
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:25:43.304426 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #92 | Epoch Duration: 184.89854669570923
2020-01-13 09:25:43.304651 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #92 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.0463862
Z variance train             0.001584419
KL Divergence                55.358192
KL Loss                      5.5358195
QF Loss                      325.6584
VF Loss                      135.61577
Policy Loss                  -3360.5696
Q Predictions Mean           3358.8303
Q Predictions Std            450.9842
Q Predictions Max            4125.282
Q Predictions Min            186.24396
V Predictions Mean           3356.0386
V Predictions Std            445.62833
V Predictions Max            4123.4097
V Predictions Min            183.19798
Log Pis Mean                 4.7816825
Log Pis Std                  3.4874513
Log Pis Max                  14.410654
Log Pis Min                  -4.5326843
Policy mu Mean               -0.26128408
Policy mu Std                1.3287342
Policy mu Max                2.9734757
Policy mu Min                -3.2132049
Policy log std Mean          -0.85179067
Policy log std Std           0.44357368
Policy log std Max           0.031066656
Policy log std Min           -3.1135664
Z mean eval                  4.143338
Z variance eval              0.0011620997
total_rewards                [ 9503.40380187  9839.76312677  9724.51073878 10073.4149183
  9826.21403865  9683.7545336   9725.98103806  9732.02595314
  9859.99677939  9776.37918932]
total_rewards_mean           9774.544411787663
total_rewards_std            138.55753522464508
total_rewards_max            10073.414918296387
total_rewards_min            9503.403801874407
Number of train steps total  376000
Number of env steps total    472000
Number of rollouts total     0
Train Time (s)               133.7442728341557
(Previous) Eval Time (s)     29.138829801697284
Sample Time (s)              23.32200347352773
Epoch Time (s)               186.20510610938072
Total Train Time (s)         16864.903140531387
Epoch                        93
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:28:48.646681 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #93 | Epoch Duration: 185.34185433387756
2020-01-13 09:28:48.647079 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.142495
Z variance train             0.0011650186
KL Divergence                58.103832
KL Loss                      5.8103833
QF Loss                      358.6636
VF Loss                      97.31552
Policy Loss                  -3410.1313
Q Predictions Mean           3411.1504
Q Predictions Std            659.6175
Q Predictions Max            4139.4688
Q Predictions Min            146.2346
V Predictions Mean           3412.9194
V Predictions Std            654.1855
V Predictions Max            4137.1465
V Predictions Min            165.6151
Log Pis Mean                 4.387864
Log Pis Std                  3.5955963
Log Pis Max                  14.893922
Log Pis Min                  -5.9563293
Policy mu Mean               -0.16320539
Policy mu Std                1.283684
Policy mu Max                2.761848
Policy mu Min                -2.6941803
Policy log std Mean          -0.8334039
Policy log std Std           0.4229458
Policy log std Max           0.07874358
Policy log std Min           -3.0537596
Z mean eval                  4.1362495
Z variance eval              0.0005998602
total_rewards                [9438.0777931  9553.16477947 9362.86339981 9589.39839706 9161.34593989
 9495.3604583  9603.16355392 9309.86663634 9169.06144138 9307.39917092]
total_rewards_mean           9398.970157020052
total_rewards_std            154.75981513782622
total_rewards_max            9603.163553917204
total_rewards_min            9161.345939894618
Number of train steps total  380000
Number of env steps total    477000
Number of rollouts total     0
Train Time (s)               129.93450400792062
(Previous) Eval Time (s)     28.275117261800915
Sample Time (s)              22.441273720469326
Epoch Time (s)               180.65089499019086
Total Train Time (s)         17043.836589789484
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:31:47.582002 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #94 | Epoch Duration: 178.93451833724976
2020-01-13 09:31:47.582191 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #94 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.212447
Z variance train             0.00058175804
KL Divergence                61.345192
KL Loss                      6.134519
QF Loss                      439.86594
VF Loss                      287.55606
Policy Loss                  -3413.6023
Q Predictions Mean           3414.3198
Q Predictions Std            679.29224
Q Predictions Max            4219.821
Q Predictions Min            157.40073
V Predictions Mean           3420.2998
V Predictions Std            682.28815
V Predictions Max            4212.1714
V Predictions Min            138.88687
Log Pis Mean                 4.725069
Log Pis Std                  3.8689244
Log Pis Max                  13.932928
Log Pis Min                  -5.1991067
Policy mu Mean               -0.1766551
Policy mu Std                1.3660367
Policy mu Max                3.2944534
Policy mu Min                -3.077553
Policy log std Mean          -0.8113515
Policy log std Std           0.41326627
Policy log std Max           0.3026898
Policy log std Min           -2.869808
Z mean eval                  4.0796056
Z variance eval              0.00084440224
total_rewards                [9366.09094302 9430.54949744 9458.15545298 9124.07144323 9347.0344463
 9337.67541153 9433.79659709 9309.08702579 9266.53963492 9259.83645052]
total_rewards_mean           9333.283690282165
total_rewards_std            95.20800070299268
total_rewards_max            9458.155452981115
total_rewards_min            9124.071443230638
Number of train steps total  384000
Number of env steps total    482000
Number of rollouts total     0
Train Time (s)               125.91709931194782
(Previous) Eval Time (s)     26.5583404218778
Sample Time (s)              22.04434875352308
Epoch Time (s)               174.5197884873487
Total Train Time (s)         17220.036493122112
Epoch                        95
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:34:43.783946 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #95 | Epoch Duration: 176.20161318778992
2020-01-13 09:34:43.784154 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #95 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1113176
Z variance train             0.0010414086
KL Divergence                60.2818
KL Loss                      6.02818
QF Loss                      491.5495
VF Loss                      235.71161
Policy Loss                  -3422.6506
Q Predictions Mean           3417.666
Q Predictions Std            634.36993
Q Predictions Max            4167.073
Q Predictions Min            150.55171
V Predictions Mean           3415.717
V Predictions Std            629.8995
V Predictions Max            4152.6387
V Predictions Min            152.0306
Log Pis Mean                 5.3187046
Log Pis Std                  3.7057438
Log Pis Max                  16.458855
Log Pis Min                  -4.499894
Policy mu Mean               -0.24951835
Policy mu Std                1.3964951
Policy mu Max                3.360164
Policy mu Min                -2.9495683
Policy log std Mean          -0.8505227
Policy log std Std           0.45155427
Policy log std Max           0.12682354
Policy log std Min           -3.1193342
Z mean eval                  4.215837
Z variance eval              0.0006169983
total_rewards                [ 9939.17672498 10001.11080701 10008.39966596  9939.20247792
  9926.19333153 10016.70151964  9861.28490968  9761.36050326
 10009.28341349 10040.27398071]
total_rewards_mean           9950.298733417583
total_rewards_std            81.48046686344091
total_rewards_max            10040.273980713731
total_rewards_min            9761.360503258107
Number of train steps total  388000
Number of env steps total    487000
Number of rollouts total     0
Train Time (s)               126.58553216094151
(Previous) Eval Time (s)     28.23986380500719
Sample Time (s)              20.612416121643037
Epoch Time (s)               175.43781208759174
Total Train Time (s)         17395.410007324535
Epoch                        96
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:37:39.159448 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #96 | Epoch Duration: 175.37514352798462
2020-01-13 09:37:39.159670 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.189868
Z variance train             0.00059991784
KL Divergence                62.060368
KL Loss                      6.206037
QF Loss                      849.5805
VF Loss                      268.00708
Policy Loss                  -3466.5862
Q Predictions Mean           3465.6099
Q Predictions Std            606.571
Q Predictions Max            4288.8374
Q Predictions Min            127.0925
V Predictions Mean           3475.3167
V Predictions Std            598.7902
V Predictions Max            4289.2627
V Predictions Min            131.71857
Log Pis Mean                 5.144658
Log Pis Std                  3.745441
Log Pis Max                  14.866226
Log Pis Min                  -5.9348435
Policy mu Mean               -0.16835444
Policy mu Std                1.3817351
Policy mu Max                3.4856842
Policy mu Min                -2.8809314
Policy log std Mean          -0.83864427
Policy log std Std           0.4362507
Policy log std Max           0.19962144
Policy log std Min           -3.1677728
Z mean eval                  4.2437716
Z variance eval              0.0007448328
total_rewards                [8940.3423036  9194.1850687  9197.6656807  9042.66793255 9004.17482379
 9025.04556691 9420.11678243 9141.82227508 8896.36211607 9139.10273214]
total_rewards_mean           9100.14852819709
total_rewards_std            144.6404637992881
total_rewards_max            9420.116782434938
total_rewards_min            8896.36211607174
Number of train steps total  392000
Number of env steps total    492000
Number of rollouts total     0
Train Time (s)               132.7130275531672
(Previous) Eval Time (s)     28.176869826857
Sample Time (s)              22.69130978686735
Epoch Time (s)               183.58120716689155
Total Train Time (s)         17579.24264140753
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:40:42.994220 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #97 | Epoch Duration: 183.83439254760742
2020-01-13 09:40:42.994496 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #97 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.238675
Z variance train             0.00071035966
KL Divergence                62.589447
KL Loss                      6.258945
QF Loss                      443.2702
VF Loss                      198.75668
Policy Loss                  -3515.1755
Q Predictions Mean           3515.9941
Q Predictions Std            628.9685
Q Predictions Max            4333.261
Q Predictions Min            140.93678
V Predictions Mean           3518.913
V Predictions Std            623.1512
V Predictions Max            4341.1787
V Predictions Min            154.9601
Log Pis Mean                 4.676612
Log Pis Std                  3.7678318
Log Pis Max                  15.833999
Log Pis Min                  -4.518657
Policy mu Mean               -0.20043136
Policy mu Std                1.32847
Policy mu Max                3.3296766
Policy mu Min                -2.7093558
Policy log std Mean          -0.8301015
Policy log std Std           0.43234786
Policy log std Max           0.00038135052
Policy log std Min           -3.098933
Z mean eval                  4.2246194
Z variance eval              0.0064742276
total_rewards                [9647.64398191 9645.1912485  9359.08467799 9249.30521577 9474.19247487
 9371.9482709  9446.46595319 9489.57580194 9586.66579535 9511.69601958]
total_rewards_mean           9478.17694400074
total_rewards_std            121.86360319331754
total_rewards_max            9647.64398190533
total_rewards_min            9249.30521576721
Number of train steps total  396000
Number of env steps total    497000
Number of rollouts total     0
Train Time (s)               132.53984078532085
(Previous) Eval Time (s)     28.429637335706502
Sample Time (s)              23.52311647636816
Epoch Time (s)               184.4925945973955
Total Train Time (s)         17764.209511563648
Epoch                        98
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:43:47.963149 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #98 | Epoch Duration: 184.96849060058594
2020-01-13 09:43:47.963382 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #98 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.203927
Z variance train             0.0049817273
KL Divergence                59.5402
KL Loss                      5.95402
QF Loss                      339.67624
VF Loss                      207.09546
Policy Loss                  -3555.1206
Q Predictions Mean           3558.787
Q Predictions Std            553.5646
Q Predictions Max            4328.0127
Q Predictions Min            144.19147
V Predictions Mean           3558.6174
V Predictions Std            550.2383
V Predictions Max            4319.38
V Predictions Min            161.15636
Log Pis Mean                 4.8891253
Log Pis Std                  3.975299
Log Pis Max                  15.220361
Log Pis Min                  -6.9182878
Policy mu Mean               -0.17808765
Policy mu Std                1.3479283
Policy mu Max                2.8056965
Policy mu Min                -2.996431
Policy log std Mean          -0.85237724
Policy log std Std           0.43307486
Policy log std Max           -0.008065462
Policy log std Min           -3.1000037
Z mean eval                  4.234784
Z variance eval              0.0011795232
total_rewards                [9546.28723761 9721.65630398 9752.69205538 9446.57145196 9837.5855663
 9693.37562432 9627.84332816 9561.80057713 9464.80959093 9506.5143464 ]
total_rewards_mean           9615.913608217536
total_rewards_std            125.06975673651964
total_rewards_max            9837.585566296566
total_rewards_min            9446.571451956373
Number of train steps total  400000
Number of env steps total    502000
Number of rollouts total     0
Train Time (s)               132.2540004849434
(Previous) Eval Time (s)     28.905225599650294
Sample Time (s)              22.74491461366415
Epoch Time (s)               183.90414069825783
Total Train Time (s)         17947.635411181487
Epoch                        99
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:46:51.391721 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #99 | Epoch Duration: 183.42817068099976
2020-01-13 09:46:51.392048 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #99 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1875734
Z variance train             0.0014983667
KL Divergence                59.626297
KL Loss                      5.96263
QF Loss                      374.40552
VF Loss                      163.17352
Policy Loss                  -3507.5735
Q Predictions Mean           3510.437
Q Predictions Std            594.692
Q Predictions Max            4332.4946
Q Predictions Min            124.76495
V Predictions Mean           3511.8916
V Predictions Std            588.90735
V Predictions Max            4325.024
V Predictions Min            139.23953
Log Pis Mean                 4.6702766
Log Pis Std                  3.7471123
Log Pis Max                  13.564155
Log Pis Min                  -6.438959
Policy mu Mean               -0.17368996
Policy mu Std                1.3362014
Policy mu Max                3.8251958
Policy mu Min                -2.8975344
Policy log std Mean          -0.8393777
Policy log std Std           0.43093306
Policy log std Max           -0.01896143
Policy log std Min           -3.080351
Z mean eval                  4.186348
Z variance eval              0.0013020219
total_rewards                [ 9654.89390483  9897.20475424 10099.7397804  10202.04941787
 10103.5307342   9999.22632481  9650.56526796  9937.28340248
  9848.14269281 10143.39143718]
total_rewards_mean           9953.602771678608
total_rewards_std            184.1979922895253
total_rewards_max            10202.049417867804
total_rewards_min            9650.56526795707
Number of train steps total  404000
Number of env steps total    507000
Number of rollouts total     0
Train Time (s)               134.21979535697028
(Previous) Eval Time (s)     28.428820088040084
Sample Time (s)              23.477197002619505
Epoch Time (s)               186.12581244762987
Total Train Time (s)         18133.08343358198
Epoch                        100
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:49:56.842270 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #100 | Epoch Duration: 185.45002269744873
2020-01-13 09:49:56.842568 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #100 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.077981
Z variance train             0.0014351183
KL Divergence                57.1352
KL Loss                      5.71352
QF Loss                      488.47607
VF Loss                      143.12752
Policy Loss                  -3473.7012
Q Predictions Mean           3465.3237
Q Predictions Std            545.5958
Q Predictions Max            4240.5513
Q Predictions Min            125.92985
V Predictions Mean           3477.1753
V Predictions Std            536.0514
V Predictions Max            4229.185
V Predictions Min            126.25458
Log Pis Mean                 5.1818476
Log Pis Std                  3.8648345
Log Pis Max                  20.800652
Log Pis Min                  -5.372179
Policy mu Mean               -0.19297433
Policy mu Std                1.389198
Policy mu Max                4.513483
Policy mu Min                -3.2552714
Policy log std Mean          -0.8561546
Policy log std Std           0.44835255
Policy log std Max           0.0022770166
Policy log std Min           -3.2995822
Z mean eval                  4.1636276
Z variance eval              0.0030235418
total_rewards                [10105.6421495   9797.86973446 10060.84926209  9801.70835074
  9771.6416944   9728.05029196  9955.29195544  9745.73757273
  9859.97250235 10188.49547278]
total_rewards_mean           9901.525898645317
total_rewards_std            156.83055392793636
total_rewards_max            10188.49547278461
total_rewards_min            9728.05029195833
Number of train steps total  408000
Number of env steps total    512000
Number of rollouts total     0
Train Time (s)               130.13644758611917
(Previous) Eval Time (s)     27.752603566739708
Sample Time (s)              22.618199357762933
Epoch Time (s)               180.50725051062182
Total Train Time (s)         18312.722502973396
Epoch                        101
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:52:56.482622 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #101 | Epoch Duration: 179.63989090919495
2020-01-13 09:52:56.482826 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #101 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1713233
Z variance train             0.0031184885
KL Divergence                58.204304
KL Loss                      5.8204303
QF Loss                      507.70197
VF Loss                      156.36745
Policy Loss                  -3491.1658
Q Predictions Mean           3493.1907
Q Predictions Std            690.74695
Q Predictions Max            4287.843
Q Predictions Min            124.42046
V Predictions Mean           3492.5781
V Predictions Std            688.874
V Predictions Max            4273.3984
V Predictions Min            114.38542
Log Pis Mean                 4.78537
Log Pis Std                  3.7048957
Log Pis Max                  14.457867
Log Pis Min                  -5.8430777
Policy mu Mean               -0.14174531
Policy mu Std                1.3360156
Policy mu Max                3.202446
Policy mu Min                -3.0791588
Policy log std Mean          -0.8482669
Policy log std Std           0.42690185
Policy log std Max           0.049307466
Policy log std Min           -3.2794812
Z mean eval                  4.1431093
Z variance eval              0.0026784497
total_rewards                [ 9788.98878152  9747.27168144 10034.53527233 10124.93720025
  9973.12823994 10111.80006821 10025.09860858  9987.07366641
 10054.85070895  9822.60744455]
total_rewards_mean           9967.029167216273
total_rewards_std            127.60237623945866
total_rewards_max            10124.937200245775
total_rewards_min            9747.271681437653
Number of train steps total  412000
Number of env steps total    517000
Number of rollouts total     0
Train Time (s)               126.60996990278363
(Previous) Eval Time (s)     26.884922807104886
Sample Time (s)              22.286880671046674
Epoch Time (s)               175.7817733809352
Total Train Time (s)         18489.014066384174
Epoch                        102
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:55:52.776102 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #102 | Epoch Duration: 176.2931170463562
2020-01-13 09:55:52.776316 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #102 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.115442
Z variance train             0.003019175
KL Divergence                57.92279
KL Loss                      5.7922792
QF Loss                      404.2864
VF Loss                      352.7924
Policy Loss                  -3482.2305
Q Predictions Mean           3482.0623
Q Predictions Std            655.8032
Q Predictions Max            4320.3057
Q Predictions Min            126.47497
V Predictions Mean           3495.806
V Predictions Std            649.51434
V Predictions Max            4296.954
V Predictions Min            143.99202
Log Pis Mean                 5.101115
Log Pis Std                  3.6332586
Log Pis Max                  15.327793
Log Pis Min                  -6.799707
Policy mu Mean               -0.20129459
Policy mu Std                1.3519852
Policy mu Max                2.7551117
Policy mu Min                -3.6185086
Policy log std Mean          -0.8569724
Policy log std Std           0.428317
Policy log std Max           -0.043427706
Policy log std Min           -3.2153113
Z mean eval                  4.130889
Z variance eval              0.0031534042
total_rewards                [9452.65581617 9960.90444518 9633.59759152 9724.69072073 9084.32966606
 8962.41602646 9369.66658962 8817.99988741 9526.04725979 8746.83926589]
total_rewards_mean           9327.914726881982
total_rewards_std            387.1297019394173
total_rewards_max            9960.90444517617
total_rewards_min            8746.839265890605
Number of train steps total  416000
Number of env steps total    522000
Number of rollouts total     0
Train Time (s)               127.32333960011601
(Previous) Eval Time (s)     27.395910979714245
Sample Time (s)              21.25514837540686
Epoch Time (s)               175.97439895523712
Total Train Time (s)         18665.06683918368
Epoch                        103
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:58:48.831178 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #103 | Epoch Duration: 176.05470442771912
2020-01-13 09:58:48.831402 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #103 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.132844
Z variance train             0.0031373403
KL Divergence                57.658493
KL Loss                      5.7658496
QF Loss                      533.59247
VF Loss                      178.26414
Policy Loss                  -3540.8809
Q Predictions Mean           3539.9263
Q Predictions Std            656.9074
Q Predictions Max            4340.3853
Q Predictions Min            115.850136
V Predictions Mean           3540.9648
V Predictions Std            652.89166
V Predictions Max            4330.4414
V Predictions Min            121.42484
Log Pis Mean                 4.609371
Log Pis Std                  3.8985581
Log Pis Max                  14.726259
Log Pis Min                  -6.26457
Policy mu Mean               -0.105119705
Policy mu Std                1.3683072
Policy mu Max                2.8663497
Policy mu Min                -3.3090136
Policy log std Mean          -0.8311663
Policy log std Std           0.42756656
Policy log std Max           0.021351695
Policy log std Min           -3.1842585
Z mean eval                  4.1681604
Z variance eval              0.010943787
total_rewards                [9592.93369916 9703.98876796 9680.52512056 9762.29412549 9632.13444184
 9713.51514132 9685.00684301 9518.14129384 9693.23642741 9648.34532116]
total_rewards_mean           9663.01211817515
total_rewards_std            65.46573651867685
total_rewards_max            9762.294125493863
total_rewards_min            9518.141293839317
Number of train steps total  420000
Number of env steps total    527000
Number of rollouts total     0
Train Time (s)               134.26926898630336
(Previous) Eval Time (s)     27.47586070559919
Sample Time (s)              21.720078841783106
Epoch Time (s)               183.46520853368565
Total Train Time (s)         18849.61027243035
Epoch                        104
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:01:53.376404 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #104 | Epoch Duration: 184.54485774040222
2020-01-13 10:01:53.376586 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.019462
Z variance train             0.016493745
KL Divergence                53.14279
KL Loss                      5.314279
QF Loss                      754.21185
VF Loss                      196.25763
Policy Loss                  -3550.2964
Q Predictions Mean           3554.4712
Q Predictions Std            594.9418
Q Predictions Max            4333.58
Q Predictions Min            121.19352
V Predictions Mean           3547.625
V Predictions Std            592.63495
V Predictions Max            4331.1367
V Predictions Min            117.50138
Log Pis Mean                 5.1086864
Log Pis Std                  3.8722215
Log Pis Max                  14.698073
Log Pis Min                  -5.4959664
Policy mu Mean               -0.23060127
Policy mu Std                1.3464444
Policy mu Max                3.1165864
Policy mu Min                -2.8257244
Policy log std Mean          -0.8605104
Policy log std Std           0.44976562
Policy log std Max           0.013916731
Policy log std Min           -3.1736283
Z mean eval                  4.1127825
Z variance eval              0.010174734
total_rewards                [9457.38857628 9670.5956895  9701.93760914 9737.92434163 9445.26494535
 9564.2322661  9520.2782271  9561.12380818 9561.73205419 9498.25442609]
total_rewards_mean           9571.873194356102
total_rewards_std            95.77618834559497
total_rewards_max            9737.9243416259
total_rewards_min            9445.264945349563
Number of train steps total  424000
Number of env steps total    532000
Number of rollouts total     0
Train Time (s)               133.38536123000085
(Previous) Eval Time (s)     28.555181351024657
Sample Time (s)              23.358277328312397
Epoch Time (s)               185.2988199093379
Total Train Time (s)         19035.600542239845
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:04:59.372800 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #105 | Epoch Duration: 185.99603843688965
2020-01-13 10:04:59.373066 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #105 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1513634
Z variance train             0.009897578
KL Divergence                57.332184
KL Loss                      5.7332187
QF Loss                      403.1955
VF Loss                      271.14166
Policy Loss                  -3525.9097
Q Predictions Mean           3527.9019
Q Predictions Std            548.6944
Q Predictions Max            4306.489
Q Predictions Min            114.32874
V Predictions Mean           3515.5325
V Predictions Std            542.7485
V Predictions Max            4265.9995
V Predictions Min            139.60571
Log Pis Mean                 5.083396
Log Pis Std                  4.2358947
Log Pis Max                  21.814663
Log Pis Min                  -3.682997
Policy mu Mean               -0.16202463
Policy mu Std                1.3931605
Policy mu Max                3.7970867
Policy mu Min                -4.389512
Policy log std Mean          -0.8458147
Policy log std Std           0.41943422
Policy log std Max           0.2443403
Policy log std Min           -3.0771751
Z mean eval                  4.104113
Z variance eval              0.0029443312
total_rewards                [ 9508.03588592  9767.75216442  9577.89810703 10002.80462051
  9949.67543656  9743.95794457 10111.89073515 10023.93254897
  9713.46119788  9770.22736742]
total_rewards_mean           9816.963600842328
total_rewards_std            188.46875964111535
total_rewards_max            10111.890735146299
total_rewards_min            9508.035885918212
Number of train steps total  428000
Number of env steps total    537000
Number of rollouts total     0
Train Time (s)               132.58355807792395
(Previous) Eval Time (s)     29.251997352112085
Sample Time (s)              23.166900928132236
Epoch Time (s)               185.00245635816827
Total Train Time (s)         19220.31965712551
Epoch                        106
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:08:04.089636 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #106 | Epoch Duration: 184.71639680862427
2020-01-13 10:08:04.089893 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #106 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1037035
Z variance train             0.002936383
KL Divergence                56.348732
KL Loss                      5.6348734
QF Loss                      525.56085
VF Loss                      119.4398
Policy Loss                  -3527.736
Q Predictions Mean           3527.8997
Q Predictions Std            559.7401
Q Predictions Max            4332.281
Q Predictions Min            108.86336
V Predictions Mean           3527.1694
V Predictions Std            553.67163
V Predictions Max            4335.615
V Predictions Min            115.01583
Log Pis Mean                 5.076823
Log Pis Std                  3.7442098
Log Pis Max                  14.854084
Log Pis Min                  -4.4790916
Policy mu Mean               -0.15676606
Policy mu Std                1.3783944
Policy mu Max                3.06009
Policy mu Min                -3.3052092
Policy log std Mean          -0.858233
Policy log std Std           0.44715023
Policy log std Max           0.06773114
Policy log std Min           -3.26502
Z mean eval                  3.9262862
Z variance eval              0.0031607382
total_rewards                [10093.43190275  9693.16522913 10383.35449414  9785.81377944
 10004.61273014 10385.78676745 10130.82933822  9695.07609021
  9607.83257173  9881.51907542]
total_rewards_mean           9966.142197863679
total_rewards_std            266.65157596949945
total_rewards_max            10385.78676744592
total_rewards_min            9607.832571731642
Number of train steps total  432000
Number of env steps total    542000
Number of rollouts total     0
Train Time (s)               134.2566686468199
(Previous) Eval Time (s)     28.965502437669784
Sample Time (s)              21.848107914440334
Epoch Time (s)               185.07027899893
Total Train Time (s)         19403.123883164953
Epoch                        107
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:11:06.897028 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #107 | Epoch Duration: 182.8069202899933
2020-01-13 10:11:06.897388 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #107 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9238372
Z variance train             0.0031645435
KL Divergence                52.55062
KL Loss                      5.255062
QF Loss                      404.8935
VF Loss                      374.339
Policy Loss                  -3496.3516
Q Predictions Mean           3502.809
Q Predictions Std            588.7744
Q Predictions Max            4325.1333
Q Predictions Min            99.55968
V Predictions Mean           3511.4004
V Predictions Std            586.68
V Predictions Max            4352.4746
V Predictions Min            103.84236
Log Pis Mean                 5.400411
Log Pis Std                  3.701072
Log Pis Max                  16.235222
Log Pis Min                  -4.076196
Policy mu Mean               -0.20711982
Policy mu Std                1.3812007
Policy mu Max                3.1840737
Policy mu Min                -3.8598046
Policy log std Mean          -0.84227324
Policy log std Std           0.44294694
Policy log std Max           0.12451708
Policy log std Min           -3.1737118
Z mean eval                  3.941481
Z variance eval              0.0025952044
total_rewards                [ 9968.31845094 10202.92071118 10230.37866308 10232.88052085
 10208.42927023 10388.25864852 10210.09493443 10021.75721004
 10118.04157447 10031.3604854 ]
total_rewards_mean           10161.244046912661
total_rewards_std            119.67032387757618
total_rewards_max            10388.258648519128
total_rewards_min            9968.31845093585
Number of train steps total  436000
Number of env steps total    547000
Number of rollouts total     0
Train Time (s)               130.95973612414673
(Previous) Eval Time (s)     26.701504923868924
Sample Time (s)              23.37297834455967
Epoch Time (s)               181.03421939257532
Total Train Time (s)         19585.851901967544
Epoch                        108
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:14:09.626371 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #108 | Epoch Duration: 182.72879242897034
2020-01-13 10:14:09.626561 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #108 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9400704
Z variance train             0.0025996873
KL Divergence                53.4517
KL Loss                      5.34517
QF Loss                      541.19946
VF Loss                      462.68198
Policy Loss                  -3584.7817
Q Predictions Mean           3589.7124
Q Predictions Std            526.5024
Q Predictions Max            4326.203
Q Predictions Min            131.11441
V Predictions Mean           3601.2017
V Predictions Std            518.77527
V Predictions Max            4346.2217
V Predictions Min            125.6353
Log Pis Mean                 5.3853693
Log Pis Std                  3.9874616
Log Pis Max                  19.947828
Log Pis Min                  -6.6139774
Policy mu Mean               -0.18852532
Policy mu Std                1.409359
Policy mu Max                4.266905
Policy mu Min                -3.51699
Policy log std Mean          -0.85340375
Policy log std Std           0.43554938
Policy log std Max           -0.14741698
Policy log std Min           -3.2362552
Z mean eval                  3.9282117
Z variance eval              0.0016620759
total_rewards                [ 9886.77617206  9689.40445112 10090.0922531  10004.82465701
  9820.24715162  9347.94894625 10009.82521439  9848.07498696
  9843.36979905  9971.40591331]
total_rewards_mean           9851.196954485556
total_rewards_std            200.5032935666494
total_rewards_max            10090.092253097115
total_rewards_min            9347.948946246
Number of train steps total  440000
Number of env steps total    552000
Number of rollouts total     0
Train Time (s)               126.2443143450655
(Previous) Eval Time (s)     28.39567580865696
Sample Time (s)              22.264645640272647
Epoch Time (s)               176.9046357939951
Total Train Time (s)         19761.427901913412
Epoch                        109
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:17:05.204308 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #109 | Epoch Duration: 175.57761025428772
2020-01-13 10:17:05.204491 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #109 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9272988
Z variance train             0.0016634471
KL Divergence                53.77393
KL Loss                      5.3773932
QF Loss                      433.56888
VF Loss                      157.04802
Policy Loss                  -3599.4858
Q Predictions Mean           3598.668
Q Predictions Std            505.59326
Q Predictions Max            4391.283
Q Predictions Min            190.59554
V Predictions Mean           3600.003
V Predictions Std            498.05725
V Predictions Max            4404.624
V Predictions Min            200.6599
Log Pis Mean                 5.213046
Log Pis Std                  3.8243475
Log Pis Max                  19.025768
Log Pis Min                  -3.717221
Policy mu Mean               -0.14901341
Policy mu Std                1.3730416
Policy mu Max                2.8420396
Policy mu Min                -3.0444894
Policy log std Mean          -0.8605943
Policy log std Std           0.4219555
Policy log std Max           -0.13029668
Policy log std Min           -3.1234684
Z mean eval                  3.9868188
Z variance eval              0.0015226982
total_rewards                [ 9682.50781123 10153.01633095 10103.70048651  9564.6570642
  9701.65967468  9988.22896843  9779.34532645 10001.11905877
  9882.26594899  9617.74225571]
total_rewards_mean           9847.424292592925
total_rewards_std            197.36175394217565
total_rewards_max            10153.016330945742
total_rewards_min            9564.657064203739
Number of train steps total  444000
Number of env steps total    557000
Number of rollouts total     0
Train Time (s)               127.24277216382325
(Previous) Eval Time (s)     27.0682628932409
Sample Time (s)              22.094168033450842
Epoch Time (s)               176.405203090515
Total Train Time (s)         19939.174020526465
Epoch                        110
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:20:02.952816 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #110 | Epoch Duration: 177.74817490577698
2020-01-13 10:20:02.953032 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #110 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9860115
Z variance train             0.0015053233
KL Divergence                54.88092
KL Loss                      5.488092
QF Loss                      703.41144
VF Loss                      464.87433
Policy Loss                  -3534.0735
Q Predictions Mean           3534.9614
Q Predictions Std            680.3877
Q Predictions Max            4401.4946
Q Predictions Min            117.562065
V Predictions Mean           3549.1743
V Predictions Std            677.4895
V Predictions Max            4432.8364
V Predictions Min            124.05634
Log Pis Mean                 5.1443214
Log Pis Std                  3.420136
Log Pis Max                  15.929393
Log Pis Min                  -5.184099
Policy mu Mean               -0.19578487
Policy mu Std                1.369478
Policy mu Max                3.0019753
Policy mu Min                -3.1130922
Policy log std Mean          -0.8511564
Policy log std Std           0.41295946
Policy log std Max           0.26300526
Policy log std Min           -2.934394
Z mean eval                  3.9731307
Z variance eval              0.006694986
total_rewards                [10096.27654876  9961.82990256 10127.71483626 10261.32207579
 10042.89032501 10193.21570165 10175.68552713 10158.36858053
  2223.09039438  9924.54779884]
total_rewards_mean           9316.494169092311
total_rewards_std            2366.5303331201267
total_rewards_max            10261.322075793621
total_rewards_min            2223.0903943789594
Number of train steps total  448000
Number of env steps total    562000
Number of rollouts total     0
Train Time (s)               134.3895362308249
(Previous) Eval Time (s)     28.410904198884964
Sample Time (s)              22.329187664669007
Epoch Time (s)               185.12962809437886
Total Train Time (s)         20124.849924476817
Epoch                        111
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:23:08.630603 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #111 | Epoch Duration: 185.67741298675537
2020-01-13 10:23:08.630802 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #111 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9709353
Z variance train             0.006709397
KL Divergence                54.473038
KL Loss                      5.447304
QF Loss                      423.38983
VF Loss                      162.49876
Policy Loss                  -3603.6091
Q Predictions Mean           3599.7131
Q Predictions Std            642.2436
Q Predictions Max            4474.8164
Q Predictions Min            115.397606
V Predictions Mean           3608.6777
V Predictions Std            638.05896
V Predictions Max            4486.9053
V Predictions Min            132.37057
Log Pis Mean                 5.058613
Log Pis Std                  3.5131617
Log Pis Max                  14.23855
Log Pis Min                  -5.1096554
Policy mu Mean               -0.1591969
Policy mu Std                1.3594048
Policy mu Max                2.8540092
Policy mu Min                -3.1559913
Policy log std Mean          -0.85716087
Policy log std Std           0.4533721
Policy log std Max           -0.02319169
Policy log std Min           -3.2109244
Z mean eval                  3.9558105
Z variance eval              0.0015268422
total_rewards                [10270.31648438 10139.59072562  8154.90184646 10268.93954737
 10254.10043112 10317.28013791 10196.47837188 10429.49060696
 10239.949333   10201.59023797]
total_rewards_mean           10047.263772266455
total_rewards_std            635.0942891091779
total_rewards_max            10429.490606955022
total_rewards_min            8154.901846460883
Number of train steps total  452000
Number of env steps total    567000
Number of rollouts total     0
Train Time (s)               133.44742369325832
(Previous) Eval Time (s)     28.958332371897995
Sample Time (s)              23.41054787673056
Epoch Time (s)               185.81630394188687
Total Train Time (s)         20310.5046437392
Epoch                        112
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:26:14.287472 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #112 | Epoch Duration: 185.65652418136597
2020-01-13 10:26:14.287689 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #112 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9582343
Z variance train             0.0015242776
KL Divergence                55.472153
KL Loss                      5.5472155
QF Loss                      513.4134
VF Loss                      125.80414
Policy Loss                  -3623.4788
Q Predictions Mean           3624.294
Q Predictions Std            697.5033
Q Predictions Max            4524.61
Q Predictions Min            132.83997
V Predictions Mean           3620.981
V Predictions Std            693.37683
V Predictions Max            4495.676
V Predictions Min            127.32433
Log Pis Mean                 5.178778
Log Pis Std                  3.8155694
Log Pis Max                  15.034607
Log Pis Min                  -4.1262445
Policy mu Mean               -0.19851506
Policy mu Std                1.3746853
Policy mu Max                2.852719
Policy mu Min                -3.1421022
Policy log std Mean          -0.8543856
Policy log std Std           0.45905522
Policy log std Max           0.21631467
Policy log std Min           -3.2863975
Z mean eval                  3.945734
Z variance eval              0.0046657715
total_rewards                [8769.55314778 9072.07686582 9159.08740113 9100.69735097 9246.96039308
 9153.83451397 9263.2144053  9169.82766874 9443.81560592 9146.69446636]
total_rewards_mean           9152.57618190732
total_rewards_std            161.93331445582547
total_rewards_max            9443.815605919064
total_rewards_min            8769.553147780167
Number of train steps total  456000
Number of env steps total    572000
Number of rollouts total     0
Train Time (s)               132.72025835700333
(Previous) Eval Time (s)     28.798125398810953
Sample Time (s)              22.55975513206795
Epoch Time (s)               184.07813888788223
Total Train Time (s)         20494.168766328134
Epoch                        113
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:29:17.954469 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #113 | Epoch Duration: 183.66662883758545
2020-01-13 10:29:17.954713 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #113 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9428735
Z variance train             0.00466703
KL Divergence                54.28098
KL Loss                      5.428098
QF Loss                      452.48438
VF Loss                      255.53871
Policy Loss                  -3584.7476
Q Predictions Mean           3588.5688
Q Predictions Std            707.1795
Q Predictions Max            4523.419
Q Predictions Min            109.8078
V Predictions Mean           3593.8257
V Predictions Std            693.40985
V Predictions Max            4515.1245
V Predictions Min            138.54797
Log Pis Mean                 5.1443543
Log Pis Std                  3.9891336
Log Pis Max                  24.481428
Log Pis Min                  -5.684178
Policy mu Mean               -0.19834451
Policy mu Std                1.3611063
Policy mu Max                3.507192
Policy mu Min                -4.5783353
Policy log std Mean          -0.85585785
Policy log std Std           0.43556842
Policy log std Max           0.010107636
Policy log std Min           -3.1758392
Z mean eval                  3.778214
Z variance eval              0.0073921815
total_rewards                [ 9384.50235988 10073.4132987   9988.78520262  9935.66645292
 10134.7346958   9920.38072299  8269.29268371 10024.94286854
  9764.17260584  5295.02932588]
total_rewards_mean           9279.0920216894
total_rewards_std            1428.433916408581
total_rewards_max            10134.734695795596
total_rewards_min            5295.029325882087
Number of train steps total  460000
Number of env steps total    577000
Number of rollouts total     0
Train Time (s)               134.16592431999743
(Previous) Eval Time (s)     28.386231007054448
Sample Time (s)              23.149614667054266
Epoch Time (s)               185.70176999410614
Total Train Time (s)         20679.902706727386
Epoch                        114
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:32:23.691003 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #114 | Epoch Duration: 185.73610615730286
2020-01-13 10:32:23.691349 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #114 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7761161
Z variance train             0.0073638475
KL Divergence                49.343002
KL Loss                      4.9343004
QF Loss                      541.70447
VF Loss                      181.77979
Policy Loss                  -3633.961
Q Predictions Mean           3635.7432
Q Predictions Std            633.736
Q Predictions Max            4418.172
Q Predictions Min            114.41016
V Predictions Mean           3641.7632
V Predictions Std            630.3402
V Predictions Max            4412.0903
V Predictions Min            113.91119
Log Pis Mean                 5.1725574
Log Pis Std                  3.7789009
Log Pis Max                  14.846628
Log Pis Min                  -7.259469
Policy mu Mean               -0.19325264
Policy mu Std                1.3740426
Policy mu Max                2.8430057
Policy mu Min                -2.933311
Policy log std Mean          -0.87882775
Policy log std Std           0.47015908
Policy log std Max           0.022040129
Policy log std Min           -3.2465918
Z mean eval                  3.810643
Z variance eval              0.0025586423
total_rewards                [1957.43114084 9135.14706275 9904.16473485 9686.02232608 9619.04267076
 9700.27643362 9940.15318453 9615.54506607 9834.03246847 9747.41511876]
total_rewards_mean           8913.92302067246
total_rewards_std            2328.5341541213843
total_rewards_max            9940.153184527464
total_rewards_min            1957.431140844164
Number of train steps total  464000
Number of env steps total    582000
Number of rollouts total     0
Train Time (s)               130.80517798662186
(Previous) Eval Time (s)     28.420138728339225
Sample Time (s)              21.94676245516166
Epoch Time (s)               181.17207917012274
Total Train Time (s)         20859.79803963285
Epoch                        115
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:35:23.587949 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #115 | Epoch Duration: 179.89635062217712
2020-01-13 10:35:23.588143 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #115 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.8107057
Z variance train             0.0025722939
KL Divergence                50.562195
KL Loss                      5.0562196
QF Loss                      361.46164
VF Loss                      132.73099
Policy Loss                  -3597.0588
Q Predictions Mean           3592.4216
Q Predictions Std            698.7403
Q Predictions Max            4490.8457
Q Predictions Min            118.29474
V Predictions Mean           3594.9097
V Predictions Std            691.9035
V Predictions Max            4493.149
V Predictions Min            116.70571
Log Pis Mean                 5.491509
Log Pis Std                  4.1669455
Log Pis Max                  26.990969
Log Pis Min                  -5.8869743
Policy mu Mean               -0.17480713
Policy mu Std                1.4037472
Policy mu Max                4.3260713
Policy mu Min                -3.326886
Policy log std Mean          -0.8547023
Policy log std Std           0.4265619
Policy log std Max           0.06863278
Policy log std Min           -3.2495883
Z mean eval                  3.7816627
Z variance eval              0.009077453
total_rewards                [10144.88848442  9178.2060882  10446.65439028 10194.58168823
 10437.93847258 10283.41120105 10260.86287143 10324.96111489
 10052.92718037 10193.03240218]
total_rewards_mean           10151.746389361826
total_rewards_std            344.85567858732367
total_rewards_max            10446.654390281297
total_rewards_min            9178.206088195257
Number of train steps total  468000
Number of env steps total    587000
Number of rollouts total     0
Train Time (s)               127.25287741236389
(Previous) Eval Time (s)     27.14407953293994
Sample Time (s)              22.201232238207012
Epoch Time (s)               176.59818918351084
Total Train Time (s)         21037.448758827057
Epoch                        116
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:38:21.240243 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #116 | Epoch Duration: 177.6519238948822
2020-01-13 10:38:21.240567 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #116 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7793174
Z variance train             0.009141325
KL Divergence                48.29167
KL Loss                      4.8291674
QF Loss                      436.49762
VF Loss                      227.07005
Policy Loss                  -3592.417
Q Predictions Mean           3590.7744
Q Predictions Std            708.98004
Q Predictions Max            4507.0923
Q Predictions Min            114.59108
V Predictions Mean           3597.3232
V Predictions Std            705.08624
V Predictions Max            4498.0063
V Predictions Min            120.47054
Log Pis Mean                 5.2792683
Log Pis Std                  3.779743
Log Pis Max                  14.346617
Log Pis Min                  -5.076584
Policy mu Mean               -0.12693746
Policy mu Std                1.3867947
Policy mu Max                3.1032653
Policy mu Min                -2.9479082
Policy log std Mean          -0.8716912
Policy log std Std           0.4580582
Policy log std Max           0.13325894
Policy log std Min           -3.1905022
Z mean eval                  3.8468184
Z variance eval              0.008686625
total_rewards                [ 9886.99862247 10238.12135107 10198.72453566 10156.78601675
 10475.16218553 10142.28703329  8913.84766062 10089.11322494
 10489.99018712  5440.76125411]
total_rewards_mean           9603.179207154975
total_rewards_std            1449.80405807165
total_rewards_max            10489.990187118092
total_rewards_min            5440.76125411345
Number of train steps total  472000
Number of env steps total    592000
Number of rollouts total     0
Train Time (s)               127.45756244286895
(Previous) Eval Time (s)     28.19748226366937
Sample Time (s)              21.91870435094461
Epoch Time (s)               177.57374905748293
Total Train Time (s)         21214.565452727955
Epoch                        117
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:41:18.357702 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #117 | Epoch Duration: 177.11693596839905
2020-01-13 10:41:18.357822 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #117 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7888904
Z variance train             0.009683805
KL Divergence                47.78974
KL Loss                      4.778974
QF Loss                      999.50134
VF Loss                      302.34436
Policy Loss                  -3719.2358
Q Predictions Mean           3716.3286
Q Predictions Std            498.9877
Q Predictions Max            4501.723
Q Predictions Min            132.59424
V Predictions Mean           3708.647
V Predictions Std            495.01028
V Predictions Max            4492.3647
V Predictions Min            110.44777
Log Pis Mean                 5.4607882
Log Pis Std                  3.6391294
Log Pis Max                  15.661228
Log Pis Min                  -3.9239264
Policy mu Mean               -0.15206511
Policy mu Std                1.3865205
Policy mu Max                2.7808251
Policy mu Min                -2.877512
Policy log std Mean          -0.864126
Policy log std Std           0.43022582
Policy log std Max           -0.17037678
Policy log std Min           -3.1277988
Z mean eval                  3.8165486
Z variance eval              0.0033297564
total_rewards                [9489.76966292 9725.91408449 9476.58653751 9580.58059182 9604.18042662
 4767.51605109 9521.31559371 9639.11256266 9512.99442779 9692.77126975]
total_rewards_mean           9101.074120834917
total_rewards_std            1446.7604794806743
total_rewards_max            9725.914084485154
total_rewards_min            4767.516051092267
Number of train steps total  476000
Number of env steps total    597000
Number of rollouts total     0
Train Time (s)               134.3401231369935
(Previous) Eval Time (s)     27.74035754892975
Sample Time (s)              21.78125383378938
Epoch Time (s)               183.86173451971263
Total Train Time (s)         21400.04573975969
Epoch                        118
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:44:23.841085 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #118 | Epoch Duration: 185.48316097259521
2020-01-13 10:44:23.841509 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #118 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.8417149
Z variance train             0.0030156628
KL Divergence                50.45858
KL Loss                      5.045858
QF Loss                      465.19623
VF Loss                      142.74266
Policy Loss                  -3687.3726
Q Predictions Mean           3682.2249
Q Predictions Std            711.7055
Q Predictions Max            4542.221
Q Predictions Min            102.73226
V Predictions Mean           3681.3833
V Predictions Std            704.07263
V Predictions Max            4543.025
V Predictions Min            118.51032
Log Pis Mean                 5.1006937
Log Pis Std                  3.8756456
Log Pis Max                  16.208221
Log Pis Min                  -4.141711
Policy mu Mean               -0.15841384
Policy mu Std                1.3829333
Policy mu Max                2.8547318
Policy mu Min                -3.3402226
Policy log std Mean          -0.8666911
Policy log std Std           0.45062584
Policy log std Max           1.000373
Policy log std Min           -3.3126125
Z mean eval                  3.8801568
Z variance eval              0.0031973743
total_rewards                [10097.393594   10347.96601687  8401.20769963 10232.1824632
 10215.31396624 10367.92200431 10403.73040945 10296.42820967
 10522.40093798 10116.03282319]
total_rewards_mean           10100.057812454144
total_rewards_std            579.6082044814666
total_rewards_max            10522.400937978167
total_rewards_min            8401.207699633016
Number of train steps total  480000
Number of env steps total    602000
Number of rollouts total     0
Train Time (s)               132.84829054074362
(Previous) Eval Time (s)     29.361401072703302
Sample Time (s)              23.1753563368693
Epoch Time (s)               185.38504795031622
Total Train Time (s)         21585.36837689206
Epoch                        119
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:47:29.166183 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #119 | Epoch Duration: 185.32451033592224
2020-01-13 10:47:29.166467 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #119 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.8661747
Z variance train             0.0032788385
KL Divergence                50.576504
KL Loss                      5.0576506
QF Loss                      514.6913
VF Loss                      264.63348
Policy Loss                  -3687.0837
Q Predictions Mean           3689.4387
Q Predictions Std            621.9247
Q Predictions Max            4535.0093
Q Predictions Min            98.218994
V Predictions Mean           3694.6582
V Predictions Std            617.7839
V Predictions Max            4525.104
V Predictions Min            111.98873
Log Pis Mean                 5.0751886
Log Pis Std                  3.6686454
Log Pis Max                  16.45525
Log Pis Min                  -3.461298
Policy mu Mean               -0.15739138
Policy mu Std                1.370658
Policy mu Max                3.3749087
Policy mu Min                -2.8204908
Policy log std Mean          -0.84899616
Policy log std Std           0.4169531
Policy log std Max           0.048369884
Policy log std Min           -3.1640816
Z mean eval                  3.8359787
Z variance eval              0.00582751
total_rewards                [10243.51406387  9976.0117529  10030.45677322 10154.98299273
 10271.28456119  9969.00517777 10378.17780292 10183.89655422
  6770.81591378  9895.6169439 ]
total_rewards_mean           9787.376253651102
total_rewards_std            1016.0044967300411
total_rewards_max            10378.177802916636
total_rewards_min            6770.81591378244
Number of train steps total  484000
Number of env steps total    607000
Number of rollouts total     0
Train Time (s)               132.86862050462514
(Previous) Eval Time (s)     29.300471667200327
Sample Time (s)              22.948136522900313
Epoch Time (s)               185.11722869472578
Total Train Time (s)         21769.778197424952
Epoch                        120
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:50:33.577794 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #120 | Epoch Duration: 184.4111647605896
2020-01-13 10:50:33.577977 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #120 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7903717
Z variance train             0.006533752
KL Divergence                47.89654
KL Loss                      4.7896543
QF Loss                      624.27545
VF Loss                      262.76593
Policy Loss                  -3705.4084
Q Predictions Mean           3704.0342
Q Predictions Std            631.1593
Q Predictions Max            4467.5386
Q Predictions Min            113.54145
V Predictions Mean           3708.711
V Predictions Std            628.7777
V Predictions Max            4444.424
V Predictions Min            110.23787
Log Pis Mean                 5.1698313
Log Pis Std                  3.5772495
Log Pis Max                  14.843591
Log Pis Min                  -4.2568064
Policy mu Mean               -0.18617086
Policy mu Std                1.3572984
Policy mu Max                3.1648574
Policy mu Min                -3.0510888
Policy log std Mean          -0.87940854
Policy log std Std           0.4504313
Policy log std Max           0.008494258
Policy log std Min           -3.180536
Z mean eval                  3.758358
Z variance eval              0.0160913
total_rewards                [10298.19211162 10289.65607574 10286.70631462 10517.47832334
  9484.86116055 10563.73742131 10248.32442349 10305.56494935
 10490.60256163 10295.46401012]
total_rewards_mean           10278.058735177216
total_rewards_std            285.62731276259467
total_rewards_max            10563.737421310849
total_rewards_min            9484.861160546245
Number of train steps total  488000
Number of env steps total    612000
Number of rollouts total     0
Train Time (s)               134.5337265310809
(Previous) Eval Time (s)     28.594026838894933
Sample Time (s)              23.099091161042452
Epoch Time (s)               186.2268445310183
Total Train Time (s)         21956.086879869923
Epoch                        121
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:53:39.889803 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #121 | Epoch Duration: 186.31164813041687
2020-01-13 10:53:39.890206 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #121 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7584393
Z variance train             0.016120277
KL Divergence                45.322144
KL Loss                      4.5322146
QF Loss                      512.21106
VF Loss                      165.91997
Policy Loss                  -3686.0293
Q Predictions Mean           3687.799
Q Predictions Std            659.08435
Q Predictions Max            4575.3486
Q Predictions Min            125.33646
V Predictions Mean           3684.9407
V Predictions Std            654.35486
V Predictions Max            4563.871
V Predictions Min            110.8804
Log Pis Mean                 5.652858
Log Pis Std                  4.0737042
Log Pis Max                  16.1928
Log Pis Min                  -5.6468267
Policy mu Mean               -0.21447508
Policy mu Std                1.3998061
Policy mu Max                3.8285768
Policy mu Min                -3.276926
Policy log std Mean          -0.8634145
Policy log std Std           0.4684224
Policy log std Max           -0.1542294
Policy log std Min           -3.215527
Z mean eval                  3.694804
Z variance eval              0.007511724
total_rewards                [10328.92466968  3333.91380822 10149.3536958   9637.99354843
 10408.36850729  3613.57360698  3955.29821636 10415.30422764
 10236.64763817 10206.79890977]
total_rewards_mean           8228.617682834996
total_rewards_std            3017.998851487835
total_rewards_max            10415.304227642984
total_rewards_min            3333.9138082236504
Number of train steps total  492000
Number of env steps total    617000
Number of rollouts total     0
Train Time (s)               130.6301235742867
(Previous) Eval Time (s)     28.678442707285285
Sample Time (s)              23.084256908856332
Epoch Time (s)               182.39282319042832
Total Train Time (s)         22137.871247783303
Epoch                        122
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:56:41.675424 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #122 | Epoch Duration: 181.7849407196045
2020-01-13 10:56:41.675621 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #122 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6766517
Z variance train             0.007832304
KL Divergence                45.418858
KL Loss                      4.541886
QF Loss                      647.5845
VF Loss                      215.7023
Policy Loss                  -3675.247
Q Predictions Mean           3674.004
Q Predictions Std            565.8366
Q Predictions Max            4448.4663
Q Predictions Min            110.77151
V Predictions Mean           3685.8364
V Predictions Std            561.847
V Predictions Max            4451.1772
V Predictions Min            131.94765
Log Pis Mean                 5.3766527
Log Pis Std                  3.932691
Log Pis Max                  16.301487
Log Pis Min                  -5.0916576
Policy mu Mean               -0.19860995
Policy mu Std                1.3659537
Policy mu Max                2.9542952
Policy mu Min                -2.7827704
Policy log std Mean          -0.88321996
Policy log std Std           0.44761312
Policy log std Max           0.47951567
Policy log std Min           -3.1870756
Z mean eval                  3.6510491
Z variance eval              0.018250015
total_rewards                [ 9768.12706695 10327.22130601 10123.38339756 10151.17045924
 10187.82420136 10270.36857244  9934.73549896 10162.50744603
  9711.8755332   3979.21628979]
total_rewards_mean           9461.64297715276
total_rewards_std            1837.7303769713126
total_rewards_max            10327.221306007328
total_rewards_min            3979.2162897898993
Number of train steps total  496000
Number of env steps total    622000
Number of rollouts total     0
Train Time (s)               127.36883275723085
(Previous) Eval Time (s)     28.070221239235252
Sample Time (s)              21.970930335577577
Epoch Time (s)               177.40998433204368
Total Train Time (s)         22315.531334175263
Epoch                        123
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:59:39.336534 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #123 | Epoch Duration: 177.66078329086304
2020-01-13 10:59:39.336658 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #123 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7174957
Z variance train             0.015550931
KL Divergence                44.390053
KL Loss                      4.4390054
QF Loss                      634.17786
VF Loss                      320.89963
Policy Loss                  -3746.6838
Q Predictions Mean           3752.164
Q Predictions Std            626.9962
Q Predictions Max            4628.42
Q Predictions Min            98.946335
V Predictions Mean           3758.4048
V Predictions Std            623.3378
V Predictions Max            4624.668
V Predictions Min            113.16422
Log Pis Mean                 5.3608556
Log Pis Std                  3.6116102
Log Pis Max                  17.020687
Log Pis Min                  -6.438633
Policy mu Mean               -0.17278488
Policy mu Std                1.3941579
Policy mu Max                3.0513337
Policy mu Min                -3.1385815
Policy log std Mean          -0.8904591
Policy log std Std           0.46367684
Policy log std Max           0.15754777
Policy log std Min           -3.219965
Z mean eval                  3.724237
Z variance eval              0.0056765927
total_rewards                [10291.32469736 10529.94732484 10588.28537245 10502.74663828
 10434.34782403 10345.58275289 10478.11721772 10517.47102765
 10470.13544337 10445.51172765]
total_rewards_mean           10460.34700262285
total_rewards_std            83.25882784806599
total_rewards_max            10588.285372451111
total_rewards_min            10291.324697360897
Number of train steps total  500000
Number of env steps total    627000
Number of rollouts total     0
Train Time (s)               127.53810244007036
(Previous) Eval Time (s)     28.32070450205356
Sample Time (s)              21.091114210430533
Epoch Time (s)               176.94992115255445
Total Train Time (s)         22491.09045035811
Epoch                        124
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:02:34.899518 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #124 | Epoch Duration: 175.5627408027649
2020-01-13 11:02:34.899775 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #124 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.732966
Z variance train             0.005403927
KL Divergence                47.12993
KL Loss                      4.712993
QF Loss                      469.9269
VF Loss                      151.62474
Policy Loss                  -3748.8447
Q Predictions Mean           3748.0752
Q Predictions Std            569.6287
Q Predictions Max            4631.812
Q Predictions Min            98.28988
V Predictions Mean           3751.3813
V Predictions Std            567.0406
V Predictions Max            4651.954
V Predictions Min            88.75472
Log Pis Mean                 5.1421733
Log Pis Std                  3.519014
Log Pis Max                  15.468786
Log Pis Min                  -4.7493057
Policy mu Mean               -0.20625162
Policy mu Std                1.3515512
Policy mu Max                2.8814926
Policy mu Min                -3.0167258
Policy log std Mean          -0.8893252
Policy log std Std           0.45175695
Policy log std Max           0.059093
Policy log std Min           -3.240084
Z mean eval                  3.7085178
Z variance eval              0.009797065
total_rewards                [10080.55824452 10320.33997348 10122.55061895 10171.91439313
 10107.78243881 10156.26852208 10183.61065694 10256.27969499
 10207.29905986 10026.26589336]
total_rewards_mean           10163.286949610974
total_rewards_std            81.33026551918205
total_rewards_max            10320.339973484171
total_rewards_min            10026.265893355894
Number of train steps total  504000
Number of env steps total    632000
Number of rollouts total     0
Train Time (s)               135.82365114893764
(Previous) Eval Time (s)     26.93318514805287
Sample Time (s)              21.938651223666966
Epoch Time (s)               184.69548752065748
Total Train Time (s)         22678.07592544239
Epoch                        125
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:05:41.887427 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #125 | Epoch Duration: 186.98745369911194
2020-01-13 11:05:41.887764 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #125 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6751618
Z variance train             0.009949646
KL Divergence                45.885185
KL Loss                      4.5885186
QF Loss                      432.97815
VF Loss                      152.61378
Policy Loss                  -3764.062
Q Predictions Mean           3770.3928
Q Predictions Std            656.4294
Q Predictions Max            4659.3203
Q Predictions Min            77.65591
V Predictions Mean           3766.4482
V Predictions Std            655.3862
V Predictions Max            4652.127
V Predictions Min            84.18514
Log Pis Mean                 5.499713
Log Pis Std                  3.9639757
Log Pis Max                  19.380007
Log Pis Min                  -6.2480116
Policy mu Mean               -0.18010135
Policy mu Std                1.4016353
Policy mu Max                3.3133981
Policy mu Min                -2.9357016
Policy log std Mean          -0.86987275
Policy log std Std           0.45007503
Policy log std Max           -0.030405521
Policy log std Min           -3.04031
Z mean eval                  3.7223067
Z variance eval              0.007077203
total_rewards                [10230.88859872 10210.39058316  7992.39621803 10180.25775106
 10046.33999753  9786.90277791 10164.66094844  9920.81896883
 10473.85483398 10218.06741743]
total_rewards_mean           9922.457809509313
total_rewards_std            667.3413009041572
total_rewards_max            10473.85483397963
total_rewards_min            7992.396218033584
Number of train steps total  508000
Number of env steps total    637000
Number of rollouts total     0
Train Time (s)               133.6156832240522
(Previous) Eval Time (s)     29.224757002666593
Sample Time (s)              22.62706335214898
Epoch Time (s)               185.46750357886776
Total Train Time (s)         22863.201219165698
Epoch                        126
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:08:47.015773 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #126 | Epoch Duration: 185.12778329849243
2020-01-13 11:08:47.016121 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #126 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.719164
Z variance train             0.0070721703
KL Divergence                47.75181
KL Loss                      4.775181
QF Loss                      493.8089
VF Loss                      464.43027
Policy Loss                  -3747.747
Q Predictions Mean           3750.315
Q Predictions Std            573.27625
Q Predictions Max            4589.436
Q Predictions Min            47.991352
V Predictions Mean           3764.3503
V Predictions Std            566.7216
V Predictions Max            4596.9473
V Predictions Min            70.54614
Log Pis Mean                 5.5354486
Log Pis Std                  3.6626782
Log Pis Max                  16.056078
Log Pis Min                  -8.371956
Policy mu Mean               -0.12998696
Policy mu Std                1.3895427
Policy mu Max                3.2099817
Policy mu Min                -2.739328
Policy log std Mean          -0.87407225
Policy log std Std           0.41468626
Policy log std Max           0.013068914
Policy log std Min           -3.214371
Z mean eval                  3.7238514
Z variance eval              0.0045744395
total_rewards                [ 9860.15260524  9767.66094137  9923.92042284 10039.68105288
  9889.5818958  10006.53528206  9984.44852009  9821.74462469
  9827.28987465  9791.71014916]
total_rewards_mean           9891.272536878998
total_rewards_std            89.52650556963174
total_rewards_max            10039.681052875976
total_rewards_min            9767.660941370403
Number of train steps total  512000
Number of env steps total    642000
Number of rollouts total     0
Train Time (s)               133.2440248238854
(Previous) Eval Time (s)     28.884619650430977
Sample Time (s)              22.614310306496918
Epoch Time (s)               184.7429547808133
Total Train Time (s)         23047.58335255226
Epoch                        127
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:11:51.400792 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #127 | Epoch Duration: 184.384375333786
2020-01-13 11:11:51.401236 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #127 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7240167
Z variance train             0.004572462
KL Divergence                48.53683
KL Loss                      4.853683
QF Loss                      475.87677
VF Loss                      316.53302
Policy Loss                  -3766.585
Q Predictions Mean           3769.9507
Q Predictions Std            634.4499
Q Predictions Max            4607.6616
Q Predictions Min            60.055626
V Predictions Mean           3778.5513
V Predictions Std            631.25757
V Predictions Max            4629.641
V Predictions Min            58.924755
Log Pis Mean                 5.4082565
Log Pis Std                  3.7302787
Log Pis Max                  14.712792
Log Pis Min                  -2.9215007
Policy mu Mean               -0.20265508
Policy mu Std                1.3986028
Policy mu Max                3.036539
Policy mu Min                -3.3207638
Policy log std Mean          -0.8781142
Policy log std Std           0.46597847
Policy log std Max           0.23203278
Policy log std Min           -3.404939
Z mean eval                  3.7260985
Z variance eval              0.0006460681
total_rewards                [ 9982.07881699 10529.26879222 10356.01214401 10344.69342202
 10367.59090568 10088.37992049 10359.46096291 10389.35801499
 10299.06375786 10549.82497319]
total_rewards_mean           10326.573171035854
total_rewards_std            165.83034374706799
total_rewards_max            10549.824973189814
total_rewards_min            9982.078816985957
Number of train steps total  516000
Number of env steps total    647000
Number of rollouts total     0
Train Time (s)               133.88283569784835
(Previous) Eval Time (s)     28.525680297985673
Sample Time (s)              23.377098966389894
Epoch Time (s)               185.78561496222392
Total Train Time (s)         23233.933479648083
Epoch                        128
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:14:57.752153 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #128 | Epoch Duration: 186.35061645507812
2020-01-13 11:14:57.752502 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #128 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7266183
Z variance train             0.0006467265
KL Divergence                52.4542
KL Loss                      5.24542
QF Loss                      486.1215
VF Loss                      169.8411
Policy Loss                  -3854.06
Q Predictions Mean           3854.3005
Q Predictions Std            666.1274
Q Predictions Max            4633.564
Q Predictions Min            55.296196
V Predictions Mean           3852.2983
V Predictions Std            666.07776
V Predictions Max            4634.997
V Predictions Min            47.793762
Log Pis Mean                 5.268845
Log Pis Std                  4.2003126
Log Pis Max                  20.01983
Log Pis Min                  -5.3277454
Policy mu Mean               -0.2542655
Policy mu Std                1.3769295
Policy mu Max                2.8665557
Policy mu Min                -3.7812796
Policy log std Mean          -0.88432217
Policy log std Std           0.46801072
Policy log std Max           -0.0989759
Policy log std Min           -3.2617388
Z mean eval                  3.7150092
Z variance eval              0.0018052539
total_rewards                [10162.19593268 10197.56732775 10254.93490524  9939.93010773
  9675.88403447  9674.53232761 10477.50613401 10218.62383303
  3611.20981435 10133.83836943]
total_rewards_mean           9434.62227862869
total_rewards_std            1955.9847261121863
total_rewards_max            10477.50613401093
total_rewards_min            3611.2098143518424
Number of train steps total  520000
Number of env steps total    652000
Number of rollouts total     0
Train Time (s)               129.69783131033182
(Previous) Eval Time (s)     29.09028129791841
Sample Time (s)              22.00566910300404
Epoch Time (s)               180.79378171125427
Total Train Time (s)         23413.906033306383
Epoch                        129
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:17:57.726718 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #129 | Epoch Duration: 179.9739954471588
2020-01-13 11:17:57.726928 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #129 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7142684
Z variance train             0.0017854093
KL Divergence                51.880276
KL Loss                      5.188028
QF Loss                      370.19092
VF Loss                      195.24687
Policy Loss                  -3785.5312
Q Predictions Mean           3785.8687
Q Predictions Std            713.1662
Q Predictions Max            4611.824
Q Predictions Min            39.540035
V Predictions Mean           3792.5059
V Predictions Std            712.5899
V Predictions Max            4615.487
V Predictions Min            27.169197
Log Pis Mean                 5.125399
Log Pis Std                  3.8993652
Log Pis Max                  14.231577
Log Pis Min                  -3.8823276
Policy mu Mean               -0.18868642
Policy mu Std                1.3427827
Policy mu Max                3.2366796
Policy mu Min                -2.8084931
Policy log std Mean          -0.887801
Policy log std Std           0.46774638
Policy log std Max           -0.0059306026
Policy log std Min           -3.1951914
Z mean eval                  3.6961007
Z variance eval              0.008768398
total_rewards                [10069.05563519 10321.46117102 10406.61654614 10454.76339002
 10464.80049689 10345.69620501 10160.10641554 10324.72906143
 10133.03526793 10244.86403697]
total_rewards_mean           10292.512822612478
total_rewards_std            129.96167996778962
total_rewards_max            10464.800496885964
total_rewards_min            10069.055635192724
Number of train steps total  524000
Number of env steps total    657000
Number of rollouts total     0
Train Time (s)               127.74901134800166
(Previous) Eval Time (s)     28.270156115759164
Sample Time (s)              21.786563403438777
Epoch Time (s)               177.8057308671996
Total Train Time (s)         23591.805509653874
Epoch                        130
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:20:55.628167 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #130 | Epoch Duration: 177.90110087394714
2020-01-13 11:20:55.628347 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #130 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6619873
Z variance train             0.0091309
KL Divergence                48.1762
KL Loss                      4.8176203
QF Loss                      608.0592
VF Loss                      184.21085
Policy Loss                  -3759.4321
Q Predictions Mean           3759.7427
Q Predictions Std            670.5095
Q Predictions Max            4597.831
Q Predictions Min            5.9585037
V Predictions Mean           3752.3193
V Predictions Std            665.432
V Predictions Max            4578.0596
V Predictions Min            11.336635
Log Pis Mean                 5.335786
Log Pis Std                  4.0775385
Log Pis Max                  18.875221
Log Pis Min                  -6.480069
Policy mu Mean               -0.21176545
Policy mu Std                1.3819836
Policy mu Max                3.611637
Policy mu Min                -3.5176508
Policy log std Mean          -0.90971994
Policy log std Std           0.477963
Policy log std Max           0.19906259
Policy log std Min           -3.3747792
Z mean eval                  3.7125545
Z variance eval              0.0018056212
total_rewards                [ 9829.25787231  9840.86384259  9811.37726915  9977.58594521
  9767.19427495 10003.8943194   9961.2686131   9831.27741193
  9799.21932767  9848.06427759]
total_rewards_mean           9867.00031538879
total_rewards_std            78.26071790266208
total_rewards_max            10003.894319401554
total_rewards_min            9767.194274947227
Number of train steps total  528000
Number of env steps total    662000
Number of rollouts total     0
Train Time (s)               129.27174861123785
(Previous) Eval Time (s)     28.365213186014444
Sample Time (s)              21.809026898816228
Epoch Time (s)               179.44598869606853
Total Train Time (s)         23771.406402693596
Epoch                        131
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:23:55.231639 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #131 | Epoch Duration: 179.6031301021576
2020-01-13 11:23:55.231931 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #131 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6769643
Z variance train             0.0019305827
KL Divergence                51.279495
KL Loss                      5.1279497
QF Loss                      579.9872
VF Loss                      468.76892
Policy Loss                  -3785.6309
Q Predictions Mean           3781.521
Q Predictions Std            624.1742
Q Predictions Max            4648.3057
Q Predictions Min            -7.387533
V Predictions Mean           3770.6084
V Predictions Std            614.9255
V Predictions Max            4620.852
V Predictions Min            10.590668
Log Pis Mean                 5.4057236
Log Pis Std                  4.2037787
Log Pis Max                  19.22245
Log Pis Min                  -5.100568
Policy mu Mean               -0.22717507
Policy mu Std                1.3796407
Policy mu Max                3.1562302
Policy mu Min                -3.2082975
Policy log std Mean          -0.87718886
Policy log std Std           0.4433725
Policy log std Max           0.23794353
Policy log std Min           -3.3224015
Z mean eval                  3.708271
Z variance eval              0.0005767093
total_rewards                [10458.89484312 10558.48355002  9869.89587493 10602.12130231
 10558.04962695 10518.87605598 10359.390748   10597.10359502
 10350.06859239 10542.1782362 ]
total_rewards_mean           10441.506242492052
total_rewards_std            208.69578262937554
total_rewards_max            10602.12130231028
total_rewards_min            9869.895874932066
Number of train steps total  532000
Number of env steps total    667000
Number of rollouts total     0
Train Time (s)               136.4221535101533
(Previous) Eval Time (s)     28.522011290304363
Sample Time (s)              20.993925400078297
Epoch Time (s)               185.93809020053595
Total Train Time (s)         23957.629383116495
Epoch                        132
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:27:01.456771 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #132 | Epoch Duration: 186.2246720790863
2020-01-13 11:27:01.456978 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #132 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.710917
Z variance train             0.00057659775
KL Divergence                52.839294
KL Loss                      5.2839293
QF Loss                      759.283
VF Loss                      228.50203
Policy Loss                  -3838.781
Q Predictions Mean           3836.2002
Q Predictions Std            737.43024
Q Predictions Max            4709.1284
Q Predictions Min            -8.6767235
V Predictions Mean           3828.0764
V Predictions Std            731.0546
V Predictions Max            4703.3164
V Predictions Min            1.2365763
Log Pis Mean                 5.3391776
Log Pis Std                  3.873743
Log Pis Max                  16.582737
Log Pis Min                  -4.7486944
Policy mu Mean               -0.21114223
Policy mu Std                1.3953866
Policy mu Max                2.96196
Policy mu Min                -2.8723075
Policy log std Mean          -0.8937581
Policy log std Std           0.46897602
Policy log std Max           0.09574276
Policy log std Min           -3.274331
Z mean eval                  3.7036128
Z variance eval              0.0011741011
total_rewards                [10360.47787913 10286.57149248  9944.89122293 10066.09281358
 10264.38657461 10206.10686292 10508.73413472  2793.00732424
  9976.16026558 10298.43264627]
total_rewards_mean           9470.486121645903
total_rewards_std            2231.976429324037
total_rewards_max            10508.734134715693
total_rewards_min            2793.0073242426915
Number of train steps total  536000
Number of env steps total    672000
Number of rollouts total     0
Train Time (s)               134.48672204790637
(Previous) Eval Time (s)     28.808222969062626
Sample Time (s)              21.292879166081548
Epoch Time (s)               184.58782418305054
Total Train Time (s)         24141.927901800256
Epoch                        133
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:30:05.757922 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #133 | Epoch Duration: 184.30077934265137
2020-01-13 11:30:05.758220 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #133 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7018929
Z variance train             0.0011722024
KL Divergence                51.6166
KL Loss                      5.16166
QF Loss                      426.92633
VF Loss                      261.6759
Policy Loss                  -3835.8413
Q Predictions Mean           3838.4045
Q Predictions Std            692.5305
Q Predictions Max            4716.782
Q Predictions Min            33.522522
V Predictions Mean           3848.937
V Predictions Std            691.9285
V Predictions Max            4733.3237
V Predictions Min            8.299043
Log Pis Mean                 5.612073
Log Pis Std                  3.7497196
Log Pis Max                  15.554518
Log Pis Min                  -7.1565084
Policy mu Mean               -0.1391507
Policy mu Std                1.4025109
Policy mu Max                3.1299593
Policy mu Min                -2.878912
Policy log std Mean          -0.87137896
Policy log std Std           0.4531173
Policy log std Max           -0.04542041
Policy log std Min           -3.0614836
Z mean eval                  3.6833405
Z variance eval              0.0007395594
total_rewards                [10472.21575869 10589.62866749 10709.61939356 10535.99484306
  5668.70376266 10498.70998654  9852.64517593 10775.08407481
  6023.14015021 10711.02847382]
total_rewards_mean           9583.677028678165
total_rewards_std            1886.280333040356
total_rewards_max            10775.084074810646
total_rewards_min            5668.703762664031
Number of train steps total  540000
Number of env steps total    677000
Number of rollouts total     0
Train Time (s)               134.20733813103288
(Previous) Eval Time (s)     28.520822381135076
Sample Time (s)              21.560944257304072
Epoch Time (s)               184.28910476947203
Total Train Time (s)         24326.070459160488
Epoch                        134
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:33:09.904735 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #134 | Epoch Duration: 184.14631843566895
2020-01-13 11:33:09.905062 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #134 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6822228
Z variance train             0.00073719857
KL Divergence                53.391018
KL Loss                      5.339102
QF Loss                      597.584
VF Loss                      140.09476
Policy Loss                  -3772.3057
Q Predictions Mean           3769.5317
Q Predictions Std            745.9135
Q Predictions Max            4665.6484
Q Predictions Min            -3.8582513
V Predictions Mean           3772.3215
V Predictions Std            742.85614
V Predictions Max            4672.687
V Predictions Min            1.1657789
Log Pis Mean                 4.7448797
Log Pis Std                  3.887059
Log Pis Max                  17.308165
Log Pis Min                  -4.668476
Policy mu Mean               -0.17236882
Policy mu Std                1.3106791
Policy mu Max                3.3186007
Policy mu Min                -3.0356035
Policy log std Mean          -0.88898355
Policy log std Std           0.44631666
Policy log std Max           0.09269261
Policy log std Min           -3.1626976
Z mean eval                  3.6803055
Z variance eval              0.0014467121
total_rewards                [10353.65129985 10436.92783025 10591.48875135 10590.5592898
 10630.98185943 10473.26235981 10449.52637446 10484.21124519
 10527.85183633 10578.58270654]
total_rewards_mean           10511.70435530071
total_rewards_std            82.59315044561397
total_rewards_max            10630.981859426995
total_rewards_min            10353.651299848923
Number of train steps total  544000
Number of env steps total    682000
Number of rollouts total     0
Train Time (s)               133.62753750709817
(Previous) Eval Time (s)     28.377666444983333
Sample Time (s)              22.681342816911638
Epoch Time (s)               184.68654676899314
Total Train Time (s)         24511.0988665428
Epoch                        135
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:36:14.933925 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #135 | Epoch Duration: 185.02866506576538
2020-01-13 11:36:14.934247 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #135 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6819205
Z variance train             0.0014485866
KL Divergence                51.864574
KL Loss                      5.1864576
QF Loss                      433.28278
VF Loss                      256.8193
Policy Loss                  -3848.205
Q Predictions Mean           3847.807
Q Predictions Std            655.89703
Q Predictions Max            4733.3755
Q Predictions Min            4.625661
V Predictions Mean           3839.7783
V Predictions Std            651.0347
V Predictions Max            4708.035
V Predictions Min            1.04614
Log Pis Mean                 5.455331
Log Pis Std                  3.891383
Log Pis Max                  14.831242
Log Pis Min                  -3.5160918
Policy mu Mean               -0.16183071
Policy mu Std                1.3961431
Policy mu Max                3.873818
Policy mu Min                -3.1648455
Policy log std Mean          -0.8801773
Policy log std Std           0.46357933
Policy log std Max           -0.13365233
Policy log std Min           -3.2658565
Z mean eval                  3.6828568
Z variance eval              0.0017565197
total_rewards                [10447.0703559  10538.27268316 10607.36518557  8761.97562038
 10519.20845456 10483.15274934 10739.74772649 10666.72988355
 10640.3614981  10544.02168936]
total_rewards_mean           10394.790584639888
total_rewards_std            550.7632923706766
total_rewards_max            10739.747726489359
total_rewards_min            8761.975620375024
Number of train steps total  548000
Number of env steps total    687000
Number of rollouts total     0
Train Time (s)               129.8908640719019
(Previous) Eval Time (s)     28.719412684906274
Sample Time (s)              21.154524938203394
Epoch Time (s)               179.76480169501156
Total Train Time (s)         24690.389380773064
Epoch                        136
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:39:14.227156 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #136 | Epoch Duration: 179.29271960258484
2020-01-13 11:39:14.227427 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #136 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6872826
Z variance train             0.0017497673
KL Divergence                51.30224
KL Loss                      5.1302238
QF Loss                      560.1452
VF Loss                      632.62756
Policy Loss                  -3805.4663
Q Predictions Mean           3808.5388
Q Predictions Std            772.23724
Q Predictions Max            4702.7295
Q Predictions Min            -4.2702227
V Predictions Mean           3783.3035
V Predictions Std            764.1214
V Predictions Max            4655.322
V Predictions Min            0.6547515
Log Pis Mean                 4.735177
Log Pis Std                  3.7029235
Log Pis Max                  17.685656
Log Pis Min                  -3.9785037
Policy mu Mean               -0.223291
Policy mu Std                1.3035539
Policy mu Max                3.7173715
Policy mu Min                -3.4439256
Policy log std Mean          -0.89297444
Policy log std Std           0.45913956
Policy log std Max           -0.058267415
Policy log std Min           -3.1590438
Z mean eval                  3.6529725
Z variance eval              0.007695978
total_rewards                [10432.71981522 10537.88008489 10608.66435739 10413.35921957
 10564.22875012 10532.65722846 10604.89622521 10483.53219679
 10561.4905366  10485.3381844 ]
total_rewards_mean           10522.476659865768
total_rewards_std            63.7858742639738
total_rewards_max            10608.664357392066
total_rewards_min            10413.35921956681
Number of train steps total  552000
Number of env steps total    692000
Number of rollouts total     0
Train Time (s)               127.86264576017857
(Previous) Eval Time (s)     28.246917746961117
Sample Time (s)              21.837552790064365
Epoch Time (s)               177.94711629720405
Total Train Time (s)         24867.589064446278
Epoch                        137
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:42:11.428656 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #137 | Epoch Duration: 177.20106196403503
2020-01-13 11:42:11.428844 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #137 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6533437
Z variance train             0.0077094757
KL Divergence                49.862625
KL Loss                      4.986263
QF Loss                      432.0794
VF Loss                      202.0195
Policy Loss                  -3834.6208
Q Predictions Mean           3836.0996
Q Predictions Std            779.9092
Q Predictions Max            4790.231
Q Predictions Min            -15.915215
V Predictions Mean           3831.1274
V Predictions Std            776.619
V Predictions Max            4780.7256
V Predictions Min            0.656621
Log Pis Mean                 5.6344004
Log Pis Std                  3.8074663
Log Pis Max                  16.765442
Log Pis Min                  -4.929572
Policy mu Mean               -0.17085968
Policy mu Std                1.399727
Policy mu Max                2.8444579
Policy mu Min                -3.0396848
Policy log std Mean          -0.86812717
Policy log std Std           0.4719866
Policy log std Max           0.009148717
Policy log std Min           -3.3457236
Z mean eval                  3.6485023
Z variance eval              0.018462628
total_rewards                [10534.48169078 10518.59563105 10596.7443996  10780.31608985
 10676.56420835 10724.26266413  4005.02157556 10367.59559574
 10638.74311435 10620.7236158 ]
total_rewards_mean           9946.304858522224
total_rewards_std            1983.4630433212653
total_rewards_max            10780.316089853597
total_rewards_min            4005.021575560001
Number of train steps total  556000
Number of env steps total    697000
Number of rollouts total     0
Train Time (s)               128.78258376009762
(Previous) Eval Time (s)     27.500549885910004
Sample Time (s)              21.28416236070916
Epoch Time (s)               177.5672960067168
Total Train Time (s)         25046.023332400247
Epoch                        138
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:45:09.866596 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #138 | Epoch Duration: 178.43759727478027
2020-01-13 11:45:09.866889 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #138 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6489098
Z variance train             0.018418876
KL Divergence                47.249336
KL Loss                      4.7249336
QF Loss                      565.99396
VF Loss                      179.72249
Policy Loss                  -3866.6172
Q Predictions Mean           3863.437
Q Predictions Std            750.0068
Q Predictions Max            4767.7197
Q Predictions Min            -3.563533
V Predictions Mean           3866.967
V Predictions Std            748.3193
V Predictions Max            4748.5244
V Predictions Min            0.65889126
Log Pis Mean                 5.304464
Log Pis Std                  3.678974
Log Pis Max                  15.266615
Log Pis Min                  -3.733355
Policy mu Mean               -0.090088785
Policy mu Std                1.4003755
Policy mu Max                2.9566562
Policy mu Min                -3.1558177
Policy log std Mean          -0.8644802
Policy log std Std           0.44941366
Policy log std Max           -0.04281175
Policy log std Min           -3.4120522
Z mean eval                  3.6796448
Z variance eval              0.0050260653
total_rewards                [10400.68485166 10292.50981411 10389.68332288 10470.36526105
 10479.18359651 10426.05786213 10364.58168774 10265.81445877
 10428.12288034 10404.8379711 ]
total_rewards_mean           10392.18417063011
total_rewards_std            65.59345531473019
total_rewards_max            10479.183596510436
total_rewards_min            10265.814458772287
Number of train steps total  560000
Number of env steps total    702000
Number of rollouts total     0
Train Time (s)               136.39476605784148
(Previous) Eval Time (s)     28.3705060868524
Sample Time (s)              21.080569720827043
Epoch Time (s)               185.84584186552092
Total Train Time (s)         25232.490187210497
Epoch                        139
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:48:16.335262 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #139 | Epoch Duration: 186.46812534332275
2020-01-13 11:48:16.335458 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #139 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6797976
Z variance train             0.005033323
KL Divergence                47.297585
KL Loss                      4.7297587
QF Loss                      451.66983
VF Loss                      151.88248
Policy Loss                  -3884.5571
Q Predictions Mean           3882.4128
Q Predictions Std            773.37427
Q Predictions Max            4747.9683
Q Predictions Min            -25.508759
V Predictions Mean           3881.4346
V Predictions Std            770.73724
V Predictions Max            4694.461
V Predictions Min            4.0063453
Log Pis Mean                 5.3082952
Log Pis Std                  4.1040277
Log Pis Max                  15.752396
Log Pis Min                  -7.928732
Policy mu Mean               -0.17961657
Policy mu Std                1.3739685
Policy mu Max                3.0278668
Policy mu Min                -3.2700155
Policy log std Mean          -0.8885629
Policy log std Std           0.4893024
Policy log std Max           -0.047089756
Policy log std Min           -3.4342484
Z mean eval                  3.6838672
Z variance eval              0.00520881
total_rewards                [ 9959.73856831  9780.07624683 10095.06792095  9928.18263636
 10025.35623367  9883.17146426  9933.20571366  9971.88369716
  9940.85842252  9909.65682787]
total_rewards_mean           9942.71977315775
total_rewards_std            79.10518503558725
total_rewards_max            10095.067920948979
total_rewards_min            9780.076246828014
Number of train steps total  564000
Number of env steps total    707000
Number of rollouts total     0
Train Time (s)               135.6157327410765
(Previous) Eval Time (s)     28.992463981267065
Sample Time (s)              22.481285843998194
Epoch Time (s)               187.08948256634176
Total Train Time (s)         25419.232363101095
Epoch                        140
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:51:23.079723 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #140 | Epoch Duration: 186.74412488937378
2020-01-13 11:51:23.079911 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #140 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.68647
Z variance train             0.0051917857
KL Divergence                46.679024
KL Loss                      4.6679025
QF Loss                      595.1618
VF Loss                      205.30516
Policy Loss                  -3910.835
Q Predictions Mean           3918.0232
Q Predictions Std            735.2192
Q Predictions Max            4796.6177
Q Predictions Min            -6.589731
V Predictions Mean           3911.501
V Predictions Std            728.8932
V Predictions Max            4778.026
V Predictions Min            2.4539292
Log Pis Mean                 5.264282
Log Pis Std                  4.2004886
Log Pis Max                  17.018736
Log Pis Min                  -10.392864
Policy mu Mean               -0.16772087
Policy mu Std                1.3718004
Policy mu Max                3.3479543
Policy mu Min                -2.7965574
Policy log std Mean          -0.89517623
Policy log std Std           0.48417556
Policy log std Max           0.08814871
Policy log std Min           -3.183539
Z mean eval                  3.6636555
Z variance eval              0.005824762
total_rewards                [10316.28477321 10495.8480616  10770.45487131 10561.43837793
 10393.99860579 10460.36125353 10371.53241399 10448.83617707
 10775.91496572 10575.1507888 ]
total_rewards_mean           10516.982028895563
total_rewards_std            148.83246769007022
total_rewards_max            10775.91496571775
total_rewards_min            10316.284773211175
Number of train steps total  568000
Number of env steps total    712000
Number of rollouts total     0
Train Time (s)               134.84724918799475
(Previous) Eval Time (s)     28.64676657691598
Sample Time (s)              22.591051113326102
Epoch Time (s)               186.08506687823683
Total Train Time (s)         25604.96168521326
Epoch                        141
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:54:28.812637 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #141 | Epoch Duration: 185.73254680633545
2020-01-13 11:54:28.812984 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #141 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6655629
Z variance train             0.005823686
KL Divergence                45.776573
KL Loss                      4.577657
QF Loss                      345.2226
VF Loss                      341.832
Policy Loss                  -3842.4092
Q Predictions Mean           3840.5188
Q Predictions Std            624.7239
Q Predictions Max            4749.162
Q Predictions Min            -16.683987
V Predictions Mean           3835.6013
V Predictions Std            620.1101
V Predictions Max            4760.073
V Predictions Min            0.6648696
Log Pis Mean                 5.4185867
Log Pis Std                  3.7889879
Log Pis Max                  16.627195
Log Pis Min                  -3.8032546
Policy mu Mean               -0.15783113
Policy mu Std                1.388839
Policy mu Max                3.6510723
Policy mu Min                -2.9478703
Policy log std Mean          -0.8966121
Policy log std Std           0.45972654
Policy log std Max           0.11949015
Policy log std Min           -3.1946177
Z mean eval                  3.6715775
Z variance eval              0.01220824
total_rewards                [10690.33541265 10680.28485155  8837.76789145 10824.27633896
 10717.54477186 10814.61595304 10644.27781195 10688.04125498
 10872.7615724  10623.18804502]
total_rewards_mean           10539.309390385539
total_rewards_std            572.5434177895003
total_rewards_max            10872.761572397503
total_rewards_min            8837.767891450996
Number of train steps total  572000
Number of env steps total    717000
Number of rollouts total     0
Train Time (s)               134.54794588685036
(Previous) Eval Time (s)     28.293876271229237
Sample Time (s)              23.88186610583216
Epoch Time (s)               186.72368826391175
Total Train Time (s)         25792.296348426957
Epoch                        142
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:57:36.152613 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #142 | Epoch Duration: 187.3394181728363
2020-01-13 11:57:36.153016 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #142 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6716816
Z variance train             0.01223633
KL Divergence                44.31911
KL Loss                      4.431911
QF Loss                      488.88663
VF Loss                      157.54417
Policy Loss                  -3897.8809
Q Predictions Mean           3895.2793
Q Predictions Std            622.2749
Q Predictions Max            4776.975
Q Predictions Min            2.9734066
V Predictions Mean           3893.7808
V Predictions Std            610.8922
V Predictions Max            4767.4585
V Predictions Min            8.324123
Log Pis Mean                 5.9370003
Log Pis Std                  3.7763386
Log Pis Max                  23.865543
Log Pis Min                  -4.8314595
Policy mu Mean               -0.18095861
Policy mu Std                1.4221009
Policy mu Max                3.6692567
Policy mu Min                -3.6290123
Policy log std Mean          -0.8837282
Policy log std Std           0.46405432
Policy log std Max           0.01167953
Policy log std Min           -3.2318501
Z mean eval                  3.6607838
Z variance eval              0.0142524075
total_rewards                [10269.74781992 10636.70124567 10454.34093354 10448.13942049
 10474.8466632  10227.56202334 10684.21824085 10458.68597865
 10555.9546689  10389.16075088]
total_rewards_mean           10459.935774543108
total_rewards_std            136.50668835649137
total_rewards_max            10684.218240846532
total_rewards_min            10227.562023336883
Number of train steps total  576000
Number of env steps total    722000
Number of rollouts total     0
Train Time (s)               129.50145043991506
(Previous) Eval Time (s)     28.909165534190834
Sample Time (s)              22.7731721252203
Epoch Time (s)               181.1837880993262
Total Train Time (s)         25972.63630629843
Epoch                        143
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:00:36.492898 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #143 | Epoch Duration: 180.3396189212799
2020-01-13 12:00:36.493208 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #143 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.661801
Z variance train             0.014282365
KL Divergence                44.145576
KL Loss                      4.414558
QF Loss                      490.48737
VF Loss                      849.8627
Policy Loss                  -3814.942
Q Predictions Mean           3813.4038
Q Predictions Std            662.68164
Q Predictions Max            4715.6978
Q Predictions Min            9.210124
V Predictions Mean           3795.1313
V Predictions Std            655.6429
V Predictions Max            4700.5215
V Predictions Min            4.854921
Log Pis Mean                 5.3979692
Log Pis Std                  4.468587
Log Pis Max                  30.794788
Log Pis Min                  -6.448827
Policy mu Mean               -0.09670343
Policy mu Std                1.408845
Policy mu Max                4.644295
Policy mu Min                -4.73896
Policy log std Mean          -0.89096946
Policy log std Std           0.44904655
Policy log std Max           0.025142431
Policy log std Min           -3.0636678
Z mean eval                  3.658072
Z variance eval              0.012036691
total_rewards                [10365.20761585 10731.20441699 10234.91829939 10494.16473988
 10728.951435   10648.59784847 10679.61803468 10647.94777169
 10540.16461885 10702.69242675]
total_rewards_mean           10577.346720753594
total_rewards_std            159.20124168994707
total_rewards_max            10731.204416988663
total_rewards_min            10234.91829939348
Number of train steps total  580000
Number of env steps total    727000
Number of rollouts total     0
Train Time (s)               127.58893885510042
(Previous) Eval Time (s)     28.06463574571535
Sample Time (s)              21.936970790382475
Epoch Time (s)               177.59054539119825
Total Train Time (s)         26148.878153123427
Epoch                        144
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:03:32.736611 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #144 | Epoch Duration: 176.24318981170654
2020-01-13 12:03:32.736802 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #144 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6607068
Z variance train             0.012083517
KL Divergence                43.433758
KL Loss                      4.3433757
QF Loss                      581.17804
VF Loss                      236.30284
Policy Loss                  -3946.8677
Q Predictions Mean           3949.9097
Q Predictions Std            664.2261
Q Predictions Max            4837.9033
Q Predictions Min            8.305777
V Predictions Mean           3941.1187
V Predictions Std            654.6379
V Predictions Max            4803.173
V Predictions Min            1.371416
Log Pis Mean                 5.431632
Log Pis Std                  3.7775319
Log Pis Max                  14.9472885
Log Pis Min                  -3.8925068
Policy mu Mean               -0.18324555
Policy mu Std                1.358679
Policy mu Max                3.1176183
Policy mu Min                -3.15588
Policy log std Mean          -0.883424
Policy log std Std           0.45222563
Policy log std Max           -0.06543052
Policy log std Min           -3.3267193
Z mean eval                  3.6441796
Z variance eval              0.023505524
total_rewards                [10376.55314459 10461.38440921  8326.74854048 10562.20502991
 10618.1973326  10643.63137852  4899.47463872 10778.56341239
 10514.11965237 10641.07716693]
total_rewards_mean           9782.195470572715
total_rewards_std            1763.21787786833
total_rewards_max            10778.563412392994
total_rewards_min            4899.4746387198
Number of train steps total  584000
Number of env steps total    732000
Number of rollouts total     0
Train Time (s)               130.8596547106281
(Previous) Eval Time (s)     26.716999953147024
Sample Time (s)              22.09369710786268
Epoch Time (s)               179.6703517716378
Total Train Time (s)         26330.584065156523
Epoch                        145
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:06:34.444681 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #145 | Epoch Duration: 181.70773720741272
2020-01-13 12:06:34.444872 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #145 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6449592
Z variance train             0.023516307
KL Divergence                41.64554
KL Loss                      4.164554
QF Loss                      423.65442
VF Loss                      257.66052
Policy Loss                  -3914.9204
Q Predictions Mean           3917.7212
Q Predictions Std            600.5266
Q Predictions Max            4704.905
Q Predictions Min            -4.2327557
V Predictions Mean           3925.5098
V Predictions Std            597.88165
V Predictions Max            4699.0757
V Predictions Min            0.89975935
Log Pis Mean                 5.1360846
Log Pis Std                  3.695374
Log Pis Max                  14.961201
Log Pis Min                  -4.233493
Policy mu Mean               -0.21583645
Policy mu Std                1.3460199
Policy mu Max                2.6870127
Policy mu Min                -2.91968
Policy log std Mean          -0.8861981
Policy log std Std           0.4582933
Policy log std Max           -0.04280162
Policy log std Min           -3.209268
Z mean eval                  3.6677406
Z variance eval              0.016328132
total_rewards                [10505.02587635 10354.32120796 10511.35882932 10754.76361353
 10716.83650097 10485.78502984 10828.8638132  10798.28588979
 10679.66190709 10730.46492008]
total_rewards_mean           10636.536758814507
total_rewards_std            151.524493086537
total_rewards_max            10828.863813202868
total_rewards_min            10354.321207964536
Number of train steps total  588000
Number of env steps total    737000
Number of rollouts total     0
Train Time (s)               136.4745147936046
(Previous) Eval Time (s)     28.754039861261845
Sample Time (s)              22.818145434372127
Epoch Time (s)               188.04670008923858
Total Train Time (s)         26517.012423522305
Epoch                        146
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:09:40.875411 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #146 | Epoch Duration: 186.43039846420288
2020-01-13 12:09:40.875601 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #146 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6685078
Z variance train             0.01620378
KL Divergence                43.166397
KL Loss                      4.31664
QF Loss                      608.8887
VF Loss                      172.57071
Policy Loss                  -3946.419
Q Predictions Mean           3952.7925
Q Predictions Std            654.0816
Q Predictions Max            4743.4556
Q Predictions Min            19.305847
V Predictions Mean           3945.9565
V Predictions Std            651.53625
V Predictions Max            4719.2964
V Predictions Min            0.6773453
Log Pis Mean                 5.3327265
Log Pis Std                  3.6760566
Log Pis Max                  16.283615
Log Pis Min                  -2.3069801
Policy mu Mean               -0.16533168
Policy mu Std                1.3796403
Policy mu Max                2.8024902
Policy mu Min                -3.12192
Policy log std Mean          -0.8855643
Policy log std Std           0.44225788
Policy log std Max           0.018773794
Policy log std Min           -3.1177673
Z mean eval                  3.6492143
Z variance eval              0.017731631
total_rewards                [10455.51386194 10771.71974929  9984.07658948 10774.59974189
 10777.49062988 10591.62707777 10649.96357673 10671.36268862
 10598.97053721 10597.52880182]
total_rewards_mean           10587.285325463023
total_rewards_std            223.1060718271018
total_rewards_max            10777.490629880773
total_rewards_min            9984.076589480497
Number of train steps total  592000
Number of env steps total    742000
Number of rollouts total     0
Train Time (s)               136.12170601915568
(Previous) Eval Time (s)     27.137289092876017
Sample Time (s)              22.049510543700308
Epoch Time (s)               185.308505655732
Total Train Time (s)         26702.283263215795
Epoch                        147
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:12:46.150300 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #147 | Epoch Duration: 185.2745325565338
2020-01-13 12:12:46.150613 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #147 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6487212
Z variance train             0.017744133
KL Divergence                42.825665
KL Loss                      4.2825665
QF Loss                      653.4945
VF Loss                      272.636
Policy Loss                  -3900.5557
Q Predictions Mean           3899.8022
Q Predictions Std            783.1733
Q Predictions Max            4853.789
Q Predictions Min            8.278775
V Predictions Mean           3905.0886
V Predictions Std            783.11993
V Predictions Max            4847.24
V Predictions Min            3.0186992
Log Pis Mean                 5.53718
Log Pis Std                  4.1830225
Log Pis Max                  14.787542
Log Pis Min                  -5.317417
Policy mu Mean               -0.15272032
Policy mu Std                1.4080901
Policy mu Max                2.993558
Policy mu Min                -3.0371468
Policy log std Mean          -0.8919091
Policy log std Std           0.49417973
Policy log std Max           0.15778661
Policy log std Min           -3.342311
Z mean eval                  3.6632857
Z variance eval              0.0070468127
total_rewards                [10446.70303447 10650.8016095  10604.59023767 10646.75811678
 10401.07753521 10556.89362603 10318.15340808 10644.13691957
 10472.12079759 10602.62001313]
total_rewards_mean           10534.385529802925
total_rewards_std            111.53896106110902
total_rewards_max            10650.801609501383
total_rewards_min            10318.153408077178
Number of train steps total  596000
Number of env steps total    747000
Number of rollouts total     0
Train Time (s)               135.5716213178821
(Previous) Eval Time (s)     27.102903032209724
Sample Time (s)              21.670174649450928
Epoch Time (s)               184.34469899954274
Total Train Time (s)         26887.61054643942
Epoch                        148
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:15:51.479349 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #148 | Epoch Duration: 185.32854533195496
2020-01-13 12:15:51.479665 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #148 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6610122
Z variance train             0.0070425607
KL Divergence                45.84121
KL Loss                      4.584121
QF Loss                      519.0857
VF Loss                      149.57529
Policy Loss                  -3911.4653
Q Predictions Mean           3915.5083
Q Predictions Std            672.8277
Q Predictions Max            4743.8193
Q Predictions Min            0.98441005
V Predictions Mean           3914.9722
V Predictions Std            670.8322
V Predictions Max            4719.0366
V Predictions Min            1.1766135
Log Pis Mean                 5.428936
Log Pis Std                  3.8269923
Log Pis Max                  14.966433
Log Pis Min                  -4.972481
Policy mu Mean               -0.16511315
Policy mu Std                1.3999077
Policy mu Max                3.029141
Policy mu Min                -4.7251153
Policy log std Mean          -0.8924007
Policy log std Std           0.46220142
Policy log std Max           0.07448459
Policy log std Min           -3.4810967
Z mean eval                  3.6776938
Z variance eval              0.013423798
total_rewards                [10439.71323712 10649.418833   10607.11551985 10609.43496339
 10261.98674656 10549.90839665 10643.98906479 10485.30634495
 10733.63116497 10453.07297699]
total_rewards_mean           10543.357724826417
total_rewards_std            129.41672306887457
total_rewards_max            10733.631164972374
total_rewards_min            10261.986746559875
Number of train steps total  600000
Number of env steps total    752000
Number of rollouts total     0
Train Time (s)               134.0590242310427
(Previous) Eval Time (s)     28.086373732890934
Sample Time (s)              20.157695970498025
Epoch Time (s)               182.30309393443167
Total Train Time (s)         27070.987521463074
Epoch                        149
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:18:54.858233 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #149 | Epoch Duration: 183.37839078903198
2020-01-13 12:18:54.858426 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #149 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6763797
Z variance train             0.013410926
KL Divergence                45.477
KL Loss                      4.5477004
QF Loss                      791.8314
VF Loss                      265.87335
Policy Loss                  -3987.284
Q Predictions Mean           3990.884
Q Predictions Std            621.28925
Q Predictions Max            4792.639
Q Predictions Min            14.519992
V Predictions Mean           3998.6963
V Predictions Std            617.65967
V Predictions Max            4793.786
V Predictions Min            7.203893
Log Pis Mean                 5.7321305
Log Pis Std                  3.785638
Log Pis Max                  16.208086
Log Pis Min                  -2.7542686
Policy mu Mean               -0.108720206
Policy mu Std                1.4029317
Policy mu Max                2.9085763
Policy mu Min                -2.783386
Policy log std Mean          -0.882459
Policy log std Std           0.47960573
Policy log std Max           0.1604706
Policy log std Min           -3.310248
Z mean eval                  3.65415
Z variance eval              0.011936234
total_rewards                [10504.75929997 10632.47036193 10551.6502664  10717.69674761
 10633.773417   10600.46541552 10437.79410135 10429.34288576
 10554.17181595 10588.75843963]
total_rewards_mean           10565.088275111932
total_rewards_std            85.39854259560099
total_rewards_max            10717.696747611772
total_rewards_min            10429.342885759093
Number of train steps total  604000
Number of env steps total    757000
Number of rollouts total     0
Train Time (s)               128.38797142496333
(Previous) Eval Time (s)     29.16135272802785
Sample Time (s)              23.328725907951593
Epoch Time (s)               180.87805006094277
Total Train Time (s)         27250.04318032693
Epoch                        150
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:21:53.916716 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #150 | Epoch Duration: 179.05814480781555
2020-01-13 12:21:53.916926 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #150 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.656915
Z variance train             0.011930448
KL Divergence                45.09022
KL Loss                      4.509022
QF Loss                      581.89087
VF Loss                      126.04622
Policy Loss                  -3902.5728
Q Predictions Mean           3905.9624
Q Predictions Std            791.4915
Q Predictions Max            4872.404
Q Predictions Min            -1.4834181
V Predictions Mean           3901.2854
V Predictions Std            784.9827
V Predictions Max            4854.317
V Predictions Min            6.529177
Log Pis Mean                 4.823183
Log Pis Std                  3.8321981
Log Pis Max                  14.763799
Log Pis Min                  -5.4598722
Policy mu Mean               -0.18233979
Policy mu Std                1.3496904
Policy mu Max                3.1644866
Policy mu Min                -2.934999
Policy log std Mean          -0.884779
Policy log std Std           0.4507609
Policy log std Max           -0.009675145
Policy log std Min           -3.3408198
Z mean eval                  3.646886
Z variance eval              0.00496574
total_rewards                [10641.38447364 10908.90120941 10656.62460268 10768.66390843
 10648.81981127 10094.51083189 10679.78241381  6734.73612145
 10741.63176623 10907.54964173]
total_rewards_mean           10278.260478053657
total_rewards_std            1200.5333143417638
total_rewards_max            10908.90120940511
total_rewards_min            6734.736121445723
Number of train steps total  608000
Number of env steps total    762000
Number of rollouts total     0
Train Time (s)               128.08289430104196
(Previous) Eval Time (s)     27.34105284465477
Sample Time (s)              21.89229332143441
Epoch Time (s)               177.31624046713114
Total Train Time (s)         27427.978892229497
Epoch                        151
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:24:51.854278 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #151 | Epoch Duration: 177.93720841407776
2020-01-13 12:24:51.854463 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #151 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.648597
Z variance train             0.0049558906
KL Divergence                46.36361
KL Loss                      4.636361
QF Loss                      677.49084
VF Loss                      326.44653
Policy Loss                  -3911.7703
Q Predictions Mean           3908.1626
Q Predictions Std            768.8941
Q Predictions Max            4911.8247
Q Predictions Min            8.078924
V Predictions Mean           3898.269
V Predictions Std            763.27496
V Predictions Max            4883.3594
V Predictions Min            6.9254494
Log Pis Mean                 5.1674776
Log Pis Std                  4.2003913
Log Pis Max                  19.510328
Log Pis Min                  -5.146639
Policy mu Mean               -0.087082714
Policy mu Std                1.3706518
Policy mu Max                4.1575246
Policy mu Min                -3.8350785
Policy log std Mean          -0.8770252
Policy log std Std           0.4416258
Policy log std Max           -0.027753472
Policy log std Min           -3.3839283
Z mean eval                  3.6297615
Z variance eval              0.01060865
total_rewards                [10732.64386303 10725.52472851 10851.79598315 10951.42380349
 10949.19252071 10770.900803   10528.74424242 10893.06708404
 10788.17198501 10700.02168179]
total_rewards_mean           10789.148669513803
total_rewards_std            122.47440522610951
total_rewards_max            10951.423803485997
total_rewards_min            10528.744242417884
Number of train steps total  612000
Number of env steps total    767000
Number of rollouts total     0
Train Time (s)               130.60092774499208
(Previous) Eval Time (s)     27.961699937004596
Sample Time (s)              21.717693641781807
Epoch Time (s)               180.28032132377848
Total Train Time (s)         27608.870082451962
Epoch                        152
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:27:52.747560 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #152 | Epoch Duration: 180.89296674728394
2020-01-13 12:27:52.747734 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #152 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.629193
Z variance train             0.010617684
KL Divergence                46.371315
KL Loss                      4.6371317
QF Loss                      569.86383
VF Loss                      216.3614
Policy Loss                  -3907.4404
Q Predictions Mean           3914.984
Q Predictions Std            665.3691
Q Predictions Max            4841.0493
Q Predictions Min            18.34501
V Predictions Mean           3915.442
V Predictions Std            664.05334
V Predictions Max            4834.3594
V Predictions Min            11.014871
Log Pis Mean                 5.1981077
Log Pis Std                  3.7329068
Log Pis Max                  16.04581
Log Pis Min                  -4.579486
Policy mu Mean               -0.17835599
Policy mu Std                1.3619963
Policy mu Max                3.2841136
Policy mu Min                -3.230912
Policy log std Mean          -0.9010183
Policy log std Std           0.46844852
Policy log std Max           0.09290326
Policy log std Min           -3.3149302
Z mean eval                  3.6587899
Z variance eval              0.0031380255
total_rewards                [10529.80933163 10466.28870028 10587.06541777 10257.92410785
 10399.53623693 10449.65792992 10204.17548811 10308.98181625
 10373.35946811 10471.14826132]
total_rewards_mean           10404.794675815674
total_rewards_std            114.48286430426691
total_rewards_max            10587.065417767608
total_rewards_min            10204.175488106875
Number of train steps total  616000
Number of env steps total    772000
Number of rollouts total     0
Train Time (s)               137.52854673098773
(Previous) Eval Time (s)     28.57399261696264
Sample Time (s)              22.164751586969942
Epoch Time (s)               188.2672909349203
Total Train Time (s)         27796.929239398334
Epoch                        153
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:31:00.810442 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #153 | Epoch Duration: 188.0625455379486
2020-01-13 12:31:00.810747 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #153 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6564934
Z variance train             0.0031446791
KL Divergence                48.58307
KL Loss                      4.858307
QF Loss                      719.0442
VF Loss                      244.2054
Policy Loss                  -4061.193
Q Predictions Mean           4069.3667
Q Predictions Std            621.0736
Q Predictions Max            4852.381
Q Predictions Min            -0.4432959
V Predictions Mean           4071.3066
V Predictions Std            615.5919
V Predictions Max            4858.033
V Predictions Min            6.4658694
Log Pis Mean                 5.5620265
Log Pis Std                  3.516111
Log Pis Max                  14.710883
Log Pis Min                  -3.8218338
Policy mu Mean               -0.1422366
Policy mu Std                1.4128752
Policy mu Max                3.0360794
Policy mu Min                -2.9859319
Policy log std Mean          -0.8911393
Policy log std Std           0.4397777
Policy log std Max           -0.014258027
Policy log std Min           -3.0126023
Z mean eval                  3.6331844
Z variance eval              0.0029227561
total_rewards                [10395.39579291 10948.89228412  5093.58472342 11060.74668137
 10252.91618422 10794.43252585 10723.12420824 10785.97913135
 10212.40270374 10884.32615687]
total_rewards_mean           10115.180039209084
total_rewards_std            1696.6164411561124
total_rewards_max            11060.746681370869
total_rewards_min            5093.58472341945
Number of train steps total  620000
Number of env steps total    777000
Number of rollouts total     0
Train Time (s)               135.7831708341837
(Previous) Eval Time (s)     28.36880421033129
Sample Time (s)              22.586500524543226
Epoch Time (s)               186.7384755690582
Total Train Time (s)         27981.95357262157
Epoch                        154
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:34:05.836440 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #154 | Epoch Duration: 185.0255105495453
2020-01-13 12:34:05.836640 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #154 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6328552
Z variance train             0.002914553
KL Divergence                47.936333
KL Loss                      4.7936335
QF Loss                      435.2403
VF Loss                      324.50815
Policy Loss                  -4086.3074
Q Predictions Mean           4087.9836
Q Predictions Std            617.1957
Q Predictions Max            4853.689
Q Predictions Min            -8.05782
V Predictions Mean           4091.4482
V Predictions Std            609.946
V Predictions Max            4839.064
V Predictions Min            10.61514
Log Pis Mean                 5.983956
Log Pis Std                  3.8236942
Log Pis Max                  15.040997
Log Pis Min                  -4.1124606
Policy mu Mean               -0.080508605
Policy mu Std                1.4338902
Policy mu Max                3.7814565
Policy mu Min                -3.5849857
Policy log std Mean          -0.9093649
Policy log std Std           0.50699663
Policy log std Max           0.054230392
Policy log std Min           -3.3869946
Z mean eval                  3.6367402
Z variance eval              0.006939194
total_rewards                [ 7932.0665716   5607.40457915 10594.86817149 10881.73885388
 10659.85327597 10371.63953818  3582.66540213 10840.94837283
 10576.36146665  6765.07113325]
total_rewards_mean           8781.261736512122
total_rewards_std            2512.1544997623455
total_rewards_max            10881.73885388282
total_rewards_min            3582.6654021284244
Number of train steps total  624000
Number of env steps total    782000
Number of rollouts total     0
Train Time (s)               135.42157290689647
(Previous) Eval Time (s)     26.65552082285285
Sample Time (s)              21.145627141930163
Epoch Time (s)               183.22272087167948
Total Train Time (s)         28166.9136342532
Epoch                        155
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:37:10.798891 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #155 | Epoch Duration: 184.96210980415344
2020-01-13 12:37:10.799077 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #155 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6375313
Z variance train             0.006928765
KL Divergence                48.35195
KL Loss                      4.835195
QF Loss                      501.1524
VF Loss                      242.5532
Policy Loss                  -3984.1812
Q Predictions Mean           3980.514
Q Predictions Std            621.44244
Q Predictions Max            4851.0376
Q Predictions Min            1.4469135
V Predictions Mean           3981.4546
V Predictions Std            613.3041
V Predictions Max            4838.4844
V Predictions Min            7.9339595
Log Pis Mean                 5.5945654
Log Pis Std                  3.5927367
Log Pis Max                  15.389729
Log Pis Min                  -3.7766867
Policy mu Mean               -0.12550549
Policy mu Std                1.3958337
Policy mu Max                4.044029
Policy mu Min                -3.5200918
Policy log std Mean          -0.9038608
Policy log std Std           0.46285465
Policy log std Max           0.009615183
Policy log std Min           -3.1156306
Z mean eval                  3.6358085
Z variance eval              0.0047810264
total_rewards                [10397.85447366 10446.29938861 10796.56059797 10554.81839904
 10775.79633054 10599.98802983 10551.52157822 10663.04895206
 10704.99489238 10697.86904306]
total_rewards_mean           10618.87516853657
total_rewards_std            126.26692850854432
total_rewards_max            10796.56059796503
total_rewards_min            10397.854473661522
Number of train steps total  628000
Number of env steps total    787000
Number of rollouts total     0
Train Time (s)               134.95490450505167
(Previous) Eval Time (s)     28.394552187994123
Sample Time (s)              21.498818713705987
Epoch Time (s)               184.84827540675178
Total Train Time (s)         28352.703894325532
Epoch                        156
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:40:16.592097 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #156 | Epoch Duration: 185.79284954071045
2020-01-13 12:40:16.592451 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #156 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6370456
Z variance train             0.004812883
KL Divergence                48.564064
KL Loss                      4.8564067
QF Loss                      471.79663
VF Loss                      187.10915
Policy Loss                  -4031.1392
Q Predictions Mean           4031.2534
Q Predictions Std            551.9235
Q Predictions Max            4901.317
Q Predictions Min            14.538551
V Predictions Mean           4031.1365
V Predictions Std            546.3861
V Predictions Max            4894.4937
V Predictions Min            10.963923
Log Pis Mean                 5.51615
Log Pis Std                  3.9504664
Log Pis Max                  15.120858
Log Pis Min                  -5.9485784
Policy mu Mean               -0.13121091
Policy mu Std                1.3811532
Policy mu Max                3.1913347
Policy mu Min                -3.3722415
Policy log std Mean          -0.9098087
Policy log std Std           0.4743259
Policy log std Max           -0.011258483
Policy log std Min           -3.2454758
Z mean eval                  3.6248448
Z variance eval              0.014030856
total_rewards                [10678.95244643 10882.45949916 10772.01171766 10794.36207279
 10908.35578322 11099.26494012 10933.71917339 10890.95212263
 10990.63989184 10834.80837134]
total_rewards_mean           10878.552601858028
total_rewards_std            112.05841064900939
total_rewards_max            11099.264940119849
total_rewards_min            10678.952446432162
Number of train steps total  632000
Number of env steps total    792000
Number of rollouts total     0
Train Time (s)               128.2760686748661
(Previous) Eval Time (s)     29.338751851115376
Sample Time (s)              22.425280535127968
Epoch Time (s)               180.04010106110945
Total Train Time (s)         28530.974544602912
Epoch                        157
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:43:14.864624 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #157 | Epoch Duration: 178.27193784713745
2020-01-13 12:43:14.864818 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #157 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6253674
Z variance train             0.013982592
KL Divergence                47.842396
KL Loss                      4.78424
QF Loss                      544.21204
VF Loss                      191.88254
Policy Loss                  -3982.0498
Q Predictions Mean           3979.0735
Q Predictions Std            645.35736
Q Predictions Max            4835.1343
Q Predictions Min            19.008389
V Predictions Mean           3973.795
V Predictions Std            641.7776
V Predictions Max            4819.889
V Predictions Min            6.910025
Log Pis Mean                 5.4499555
Log Pis Std                  3.704388
Log Pis Max                  15.254697
Log Pis Min                  -3.3459284
Policy mu Mean               -0.12262145
Policy mu Std                1.3782353
Policy mu Max                3.562202
Policy mu Min                -3.1942444
Policy log std Mean          -0.8852458
Policy log std Std           0.46199432
Policy log std Max           0.14838266
Policy log std Min           -3.269003
Z mean eval                  3.621257
Z variance eval              0.0064711785
total_rewards                [10537.43405722 10388.73052079 10553.51349143 10324.42711097
 10298.71779248 10406.41580914 10418.64527253 10320.92453524
 10318.95939584 10473.8480211 ]
total_rewards_mean           10404.16160067404
total_rewards_std            87.77272860956379
total_rewards_max            10553.51349143203
total_rewards_min            10298.717792481551
Number of train steps total  636000
Number of env steps total    797000
Number of rollouts total     0
Train Time (s)               128.3775129909627
(Previous) Eval Time (s)     27.570254324004054
Sample Time (s)              20.798952158074826
Epoch Time (s)               176.7467194730416
Total Train Time (s)         28707.81195120234
Epoch                        158
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:46:11.705527 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #158 | Epoch Duration: 176.84055852890015
2020-01-13 12:46:11.705778 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #158 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.622612
Z variance train             0.006437692
KL Divergence                47.521835
KL Loss                      4.7521834
QF Loss                      488.93054
VF Loss                      138.76732
Policy Loss                  -3991.152
Q Predictions Mean           3992.2317
Q Predictions Std            672.48517
Q Predictions Max            4882.2603
Q Predictions Min            -3.9412284
V Predictions Mean           3990.5312
V Predictions Std            668.9634
V Predictions Max            4877.6255
V Predictions Min            4.174698
Log Pis Mean                 5.7669573
Log Pis Std                  4.114114
Log Pis Max                  17.696611
Log Pis Min                  -3.9521945
Policy mu Mean               -0.21365182
Policy mu Std                1.4121882
Policy mu Max                3.4521074
Policy mu Min                -3.00843
Policy log std Mean          -0.9067862
Policy log std Std           0.4991596
Policy log std Max           -0.008650184
Policy log std Min           -3.473124
Z mean eval                  3.6339622
Z variance eval              0.0018611085
total_rewards                [ 9955.87343726 10116.60852919 10033.83472971 10181.47874978
 10088.36920359 10179.96218369  2516.18740391 10362.3587895
 10095.27679842 10118.97303151]
total_rewards_mean           9364.892285655293
total_rewards_std            2285.129942911831
total_rewards_max            10362.358789502998
total_rewards_min            2516.1874039112004
Number of train steps total  640000
Number of env steps total    802000
Number of rollouts total     0
Train Time (s)               131.69298125989735
(Previous) Eval Time (s)     27.66376182017848
Sample Time (s)              21.502203923184425
Epoch Time (s)               180.85894700326025
Total Train Time (s)         28888.08801125735
Epoch                        159
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:49:11.981271 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #159 | Epoch Duration: 180.27532839775085
2020-01-13 12:49:11.981388 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #159 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.629151
Z variance train             0.0018644125
KL Divergence                49.096855
KL Loss                      4.9096856
QF Loss                      605.8274
VF Loss                      443.99658
Policy Loss                  -4073.1785
Q Predictions Mean           4076.545
Q Predictions Std            499.40207
Q Predictions Max            4907.295
Q Predictions Min            2494.801
V Predictions Mean           4087.9363
V Predictions Std            494.65018
V Predictions Max            4923.6294
V Predictions Min            2557.2847
Log Pis Mean                 5.803016
Log Pis Std                  3.8219151
Log Pis Max                  25.561596
Log Pis Min                  -3.5922127
Policy mu Mean               -0.14155243
Policy mu Std                1.4074787
Policy mu Max                4.020322
Policy mu Min                -3.9412632
Policy log std Mean          -0.9223428
Policy log std Std           0.4726471
Policy log std Max           -0.09482777
Policy log std Min           -3.3201113
Z mean eval                  3.6139214
Z variance eval              0.0025795125
total_rewards                [10310.54813134 10861.70231957 10256.78171042 10704.64097675
  5487.35831927  5768.02740603 10197.60703553 10680.50110185
  1473.66291805 10370.59663617]
total_rewards_mean           8611.142655497551
total_rewards_std            3061.4310822755956
total_rewards_max            10861.702319566384
total_rewards_min            1473.6629180515722
Number of train steps total  644000
Number of env steps total    807000
Number of rollouts total     0
Train Time (s)               137.20135413017124
(Previous) Eval Time (s)     27.079808675218374
Sample Time (s)              21.319859819021076
Epoch Time (s)               185.6010226244107
Total Train Time (s)         29075.411799916532
Epoch                        160
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:52:19.308166 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #160 | Epoch Duration: 187.32667589187622
2020-01-13 12:52:19.308345 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #160 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.614469
Z variance train             0.0025810015
KL Divergence                48.38055
KL Loss                      4.838055
QF Loss                      632.2466
VF Loss                      164.7748
Policy Loss                  -4026.2314
Q Predictions Mean           4023.1401
Q Predictions Std            660.57654
Q Predictions Max            4898.735
Q Predictions Min            17.266726
V Predictions Mean           4022.5793
V Predictions Std            659.5954
V Predictions Max            4907.755
V Predictions Min            5.016416
Log Pis Mean                 5.4580436
Log Pis Std                  3.8354108
Log Pis Max                  16.884228
Log Pis Min                  -6.9135714
Policy mu Mean               -0.17945008
Policy mu Std                1.3796687
Policy mu Max                3.0545542
Policy mu Min                -3.0332074
Policy log std Mean          -0.891723
Policy log std Std           0.48178163
Policy log std Max           0.12700844
Policy log std Min           -3.4227333
Z mean eval                  3.6132095
Z variance eval              0.010357961
total_rewards                [10616.4721351   3041.61294643 10987.22429105 10730.60437211
 10793.97006771 10805.18911944 10770.16796905 10706.39728862
  2093.37693504 10549.72162932]
total_rewards_mean           9109.473675388424
total_rewards_std            3279.7098569736736
total_rewards_max            10987.224291053604
total_rewards_min            2093.3769350396133
Number of train steps total  648000
Number of env steps total    812000
Number of rollouts total     0
Train Time (s)               136.3675134619698
(Previous) Eval Time (s)     28.805099457968026
Sample Time (s)              23.01540480554104
Epoch Time (s)               188.18801772547886
Total Train Time (s)         29262.602466407232
Epoch                        161
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:55:26.502807 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #161 | Epoch Duration: 187.19430565834045
2020-01-13 12:55:26.503053 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #161 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.612901
Z variance train             0.010357169
KL Divergence                44.71931
KL Loss                      4.471931
QF Loss                      488.36194
VF Loss                      186.90614
Policy Loss                  -4048.0117
Q Predictions Mean           4051.2017
Q Predictions Std            699.07697
Q Predictions Max            4942.6167
Q Predictions Min            -1.6926131
V Predictions Mean           4053.1975
V Predictions Std            695.7858
V Predictions Max            4917.392
V Predictions Min            0.7096748
Log Pis Mean                 5.5214663
Log Pis Std                  3.7689798
Log Pis Max                  15.080165
Log Pis Min                  -4.742352
Policy mu Mean               -0.1865014
Policy mu Std                1.3906958
Policy mu Max                3.344186
Policy mu Min                -3.4387789
Policy log std Mean          -0.8946824
Policy log std Std           0.47745734
Policy log std Max           0.0013639331
Policy log std Min           -3.272697
Z mean eval                  3.6206288
Z variance eval              0.010582621
total_rewards                [10801.58658919 10502.09269332 10804.63869053 10900.37860088
 11147.8133441  11001.41475545 10815.85561816 10712.4417356
 10856.14828972  1294.54060741]
total_rewards_mean           9883.691092437333
total_rewards_std            2867.5599259944784
total_rewards_max            11147.813344103362
total_rewards_min            1294.5406074141351
Number of train steps total  652000
Number of env steps total    817000
Number of rollouts total     0
Train Time (s)               136.9852709081024
(Previous) Eval Time (s)     27.810974234715104
Sample Time (s)              22.457438178826123
Epoch Time (s)               187.25368332164362
Total Train Time (s)         29450.137696073856
Epoch                        162
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:58:34.039083 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #162 | Epoch Duration: 187.53586530685425
2020-01-13 12:58:34.039327 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #162 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6224911
Z variance train             0.010553477
KL Divergence                44.721344
KL Loss                      4.4721346
QF Loss                      764.10974
VF Loss                      297.7876
Policy Loss                  -3960.6658
Q Predictions Mean           3964.919
Q Predictions Std            750.50415
Q Predictions Max            4798.927
Q Predictions Min            21.010729
V Predictions Mean           3950.6882
V Predictions Std            748.2889
V Predictions Max            4776.713
V Predictions Min            3.974095
Log Pis Mean                 4.9166365
Log Pis Std                  3.7640574
Log Pis Max                  17.513208
Log Pis Min                  -5.9867415
Policy mu Mean               -0.17715673
Policy mu Std                1.3353378
Policy mu Max                3.0034928
Policy mu Min                -3.2259572
Policy log std Mean          -0.88950044
Policy log std Std           0.4532879
Policy log std Max           0.11448562
Policy log std Min           -3.2853456
Z mean eval                  3.6407864
Z variance eval              0.005386369
total_rewards                [10645.2730285  10418.21037494 10752.23663259 10741.32419346
 10521.99397959 10675.58834589 10579.15506648 10752.62123283
 10553.97563352 10905.59567704]
total_rewards_mean           10654.59741648413
total_rewards_std            133.96645301575833
total_rewards_max            10905.595677035322
total_rewards_min            10418.210374935436
Number of train steps total  656000
Number of env steps total    822000
Number of rollouts total     0
Train Time (s)               134.6788395899348
(Previous) Eval Time (s)     28.092741591855884
Sample Time (s)              22.99180008750409
Epoch Time (s)               185.76338126929477
Total Train Time (s)         29637.00221631769
Epoch                        163
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:01:40.906527 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #163 | Epoch Duration: 186.8670482635498
2020-01-13 13:01:40.906748 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #163 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6404014
Z variance train             0.0053728465
KL Divergence                46.774666
KL Loss                      4.677467
QF Loss                      490.39
VF Loss                      342.16287
Policy Loss                  -4069.1685
Q Predictions Mean           4059.1895
Q Predictions Std            681.0302
Q Predictions Max            4962.9424
Q Predictions Min            6.8046193
V Predictions Mean           4060.5278
V Predictions Std            674.95044
V Predictions Max            4950.825
V Predictions Min            4.427427
Log Pis Mean                 5.7847996
Log Pis Std                  3.8022108
Log Pis Max                  15.543452
Log Pis Min                  -4.7685175
Policy mu Mean               -0.14067605
Policy mu Std                1.4242039
Policy mu Max                3.3222566
Policy mu Min                -2.9897914
Policy log std Mean          -0.889966
Policy log std Std           0.45191073
Policy log std Max           -0.006431043
Policy log std Min           -3.3578532
Z mean eval                  3.6208332
Z variance eval              0.008298981
total_rewards                [10654.64838851  7966.42728694 10851.62790897 10643.23115269
 10859.40036149 10814.18025494 10814.32526581 10777.69103186
 10978.43406963 10839.83201743]
total_rewards_mean           10519.979773826826
total_rewards_std            856.2270578335036
total_rewards_max            10978.434069631734
total_rewards_min            7966.427286940743
Number of train steps total  660000
Number of env steps total    827000
Number of rollouts total     0
Train Time (s)               128.72708006203175
(Previous) Eval Time (s)     29.195954829920083
Sample Time (s)              22.35360196651891
Epoch Time (s)               180.27663685847074
Total Train Time (s)         29815.140437252354
Epoch                        164
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:04:39.046820 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #164 | Epoch Duration: 178.13991808891296
2020-01-13 13:04:39.047018 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #164 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6201909
Z variance train             0.008305978
KL Divergence                46.0451
KL Loss                      4.6045103
QF Loss                      406.91943
VF Loss                      129.26749
Policy Loss                  -4130.092
Q Predictions Mean           4134.034
Q Predictions Std            640.22833
Q Predictions Max            5000.775
Q Predictions Min            11.68281
V Predictions Mean           4133.8086
V Predictions Std            636.60986
V Predictions Max            5001.8906
V Predictions Min            9.498966
Log Pis Mean                 5.6403027
Log Pis Std                  3.892224
Log Pis Max                  17.05233
Log Pis Min                  -3.6006196
Policy mu Mean               -0.18429495
Policy mu Std                1.4053143
Policy mu Max                2.9755933
Policy mu Min                -3.1423388
Policy log std Mean          -0.88973504
Policy log std Std           0.46095172
Policy log std Max           0.0038787127
Policy log std Min           -3.4789133
Z mean eval                  3.6273656
Z variance eval              0.015630707
total_rewards                [ 2620.29319717 10586.72761218 10601.98437897 10540.17806156
 10670.98998589 10733.98200263 10615.9762862  10555.27459856
 10598.60721004 10078.46186403]
total_rewards_mean           9760.24751972412
total_rewards_std            2385.8936996780276
total_rewards_max            10733.98200263043
total_rewards_min            2620.293197174987
Number of train steps total  664000
Number of env steps total    832000
Number of rollouts total     0
Train Time (s)               127.93199000088498
(Previous) Eval Time (s)     27.058868796098977
Sample Time (s)              21.110891962889582
Epoch Time (s)               176.10175075987354
Total Train Time (s)         29992.04197081644
Epoch                        165
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:07:35.950837 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #165 | Epoch Duration: 176.90367197990417
2020-01-13 13:07:35.951052 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #165 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6285267
Z variance train             0.015548078
KL Divergence                44.82714
KL Loss                      4.482714
QF Loss                      886.1301
VF Loss                      114.861725
Policy Loss                  -4091.4702
Q Predictions Mean           4093.4316
Q Predictions Std            554.9079
Q Predictions Max            4904.11
Q Predictions Min            -5.6264133
V Predictions Mean           4093.5042
V Predictions Std            549.53033
V Predictions Max            4902.956
V Predictions Min            4.671461
Log Pis Mean                 5.5765886
Log Pis Std                  3.5269983
Log Pis Max                  15.431337
Log Pis Min                  -2.5845103
Policy mu Mean               -0.16100226
Policy mu Std                1.3712305
Policy mu Max                3.4717999
Policy mu Min                -2.8218887
Policy log std Mean          -0.9223198
Policy log std Std           0.47213086
Policy log std Max           -0.12644571
Policy log std Min           -3.284225
Z mean eval                  3.6008122
Z variance eval              0.0074758483
total_rewards                [ 9647.29052892 10239.95181097 10334.39458012  9662.36349898
  8919.22913411 10249.7840685   4508.61567956 10165.69918742
  9265.61430973  9253.33723718]
total_rewards_mean           9224.62800354704
total_rewards_std            1640.299515337478
total_rewards_max            10334.394580122485
total_rewards_min            4508.615679559432
Number of train steps total  668000
Number of env steps total    837000
Number of rollouts total     0
Train Time (s)               132.83575577894226
(Previous) Eval Time (s)     27.860473058652133
Sample Time (s)              20.643506661057472
Epoch Time (s)               181.33973549865186
Total Train Time (s)         30174.12235953426
Epoch                        166
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:10:38.033669 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #166 | Epoch Duration: 182.0824716091156
2020-01-13 13:10:38.033861 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #166 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6027985
Z variance train             0.007484813
KL Divergence                45.51967
KL Loss                      4.551967
QF Loss                      606.9617
VF Loss                      218.2495
Policy Loss                  -4020.6558
Q Predictions Mean           4017.5884
Q Predictions Std            566.15173
Q Predictions Max            4917.4683
Q Predictions Min            1.8589263
V Predictions Mean           4011.2651
V Predictions Std            559.49786
V Predictions Max            4896.435
V Predictions Min            1.1618879
Log Pis Mean                 5.1024504
Log Pis Std                  4.1418614
Log Pis Max                  28.56237
Log Pis Min                  -5.506085
Policy mu Mean               -0.1354708
Policy mu Std                1.3699937
Policy mu Max                4.38707
Policy mu Min                -5.9586773
Policy log std Mean          -0.90388495
Policy log std Std           0.44644237
Policy log std Max           0.026498556
Policy log std Min           -3.3224964
Z mean eval                  3.6510563
Z variance eval              0.0048047206
total_rewards                [10464.7449219  10947.00495073 11030.35916655 10919.08057634
 10865.847877   10813.57332944 11034.29022206 10922.34925275
 10647.6350986  10746.6661272 ]
total_rewards_mean           10839.155152258028
total_rewards_std            169.22224554416715
total_rewards_max            11034.290222060867
total_rewards_min            10464.74492189685
Number of train steps total  672000
Number of env steps total    842000
Number of rollouts total     0
Train Time (s)               137.01415312523022
(Previous) Eval Time (s)     28.602889626752585
Sample Time (s)              21.64756083022803
Epoch Time (s)               187.26460358221084
Total Train Time (s)         30360.953626035247
Epoch                        167
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:13:44.867255 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #167 | Epoch Duration: 186.83321595191956
2020-01-13 13:13:44.867445 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #167 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6501
Z variance train             0.0047727367
KL Divergence                48.21852
KL Loss                      4.821852
QF Loss                      474.5724
VF Loss                      256.1011
Policy Loss                  -4095.3862
Q Predictions Mean           4101.6797
Q Predictions Std            810.35767
Q Predictions Max            4946.7354
Q Predictions Min            -1.8222048
V Predictions Mean           4084.3318
V Predictions Std            801.93726
V Predictions Max            4926.109
V Predictions Min            0.7236649
Log Pis Mean                 5.427411
Log Pis Std                  4.069481
Log Pis Max                  17.441454
Log Pis Min                  -5.2927036
Policy mu Mean               -0.15927845
Policy mu Std                1.3929533
Policy mu Max                2.9617429
Policy mu Min                -3.2170308
Policy log std Mean          -0.893058
Policy log std Std           0.48231927
Policy log std Max           0.36757612
Policy log std Min           -3.3655462
Z mean eval                  3.6177857
Z variance eval              0.0040009296
total_rewards                [10507.43609281 10361.40896617  2716.18691217 10513.11943298
  4044.60225896  6597.51250451 10442.49410382 10418.09804864
  2975.16231286 10510.09352141]
total_rewards_mean           7908.6114154346
total_rewards_std            3270.9188420977785
total_rewards_max            10513.119432981235
total_rewards_min            2716.186912170402
Number of train steps total  676000
Number of env steps total    847000
Number of rollouts total     0
Train Time (s)               136.26873284904286
(Previous) Eval Time (s)     28.17110052332282
Sample Time (s)              21.889171075541526
Epoch Time (s)               186.3290044479072
Total Train Time (s)         30547.04959542351
Epoch                        168
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:16:50.965238 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #168 | Epoch Duration: 186.0976619720459
2020-01-13 13:16:50.965403 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #168 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6170967
Z variance train             0.003993859
KL Divergence                48.191925
KL Loss                      4.8191924
QF Loss                      746.2278
VF Loss                      146.45502
Policy Loss                  -4095.4277
Q Predictions Mean           4099.624
Q Predictions Std            754.11176
Q Predictions Max            4916.3184
Q Predictions Min            1.6703107
V Predictions Mean           4097.918
V Predictions Std            749.35913
V Predictions Max            4905.473
V Predictions Min            1.5926718
Log Pis Mean                 5.3741646
Log Pis Std                  3.7908638
Log Pis Max                  19.018955
Log Pis Min                  -5.3747187
Policy mu Mean               -0.120751895
Policy mu Std                1.3890902
Policy mu Max                3.1107268
Policy mu Min                -2.9360905
Policy log std Mean          -0.8934376
Policy log std Std           0.47264326
Policy log std Max           0.00014650822
Policy log std Min           -3.3479483
Z mean eval                  3.6019702
Z variance eval              0.005033179
total_rewards                [10434.32618    10569.68400748  1585.47697667 10690.78852341
 10625.08248887 10586.82837906 10673.86514183 10540.30511652
  7114.57188062 10798.93491216]
total_rewards_mean           9361.986360660869
total_rewards_std            2795.8730924728447
total_rewards_max            10798.934912159044
total_rewards_min            1585.4769766656948
Number of train steps total  680000
Number of env steps total    852000
Number of rollouts total     0
Train Time (s)               137.85309276916087
(Previous) Eval Time (s)     27.939423356205225
Sample Time (s)              22.947597263380885
Epoch Time (s)               188.74011338874698
Total Train Time (s)         30736.27515970776
Epoch                        169
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:20:00.192810 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #169 | Epoch Duration: 189.22728896141052
2020-01-13 13:20:00.192984 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #169 | Started Training: True
