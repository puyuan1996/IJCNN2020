---------------------------  --------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0025329944
Z variance train             0.006951236
KL Divergence                9.939492
KL Loss                      0.99394923
QF Loss                      44.933277
VF Loss                      4.2028666
Policy Loss                  -2.0157986
Q Predictions Mean           -0.0014829484
Q Predictions Std            0.0012278939
Q Predictions Max            0.0012259898
Q Predictions Min            -0.0046781963
V Predictions Mean           0.0021283808
V Predictions Std            0.00053024193
V Predictions Max            0.0040037325
V Predictions Min            0.00075049314
Log Pis Mean                 -2.001243
Log Pis Std                  0.384739
Log Pis Max                  -0.9692137
Log Pis Min                  -2.7174616
Policy mu Mean               0.0016940795
Policy mu Std                0.00089419755
Policy mu Max                0.0037046832
Policy mu Min                7.128809e-05
Policy log std Mean          -0.0005464296
Policy log std Std           0.0013865294
Policy log std Max           0.001534427
Policy log std Min           -0.0032306274
Z mean eval                  0.0030639805
Z variance eval              0.006929914
total_rewards                [38.27959207 38.50242521 39.98521037 37.13770511 40.31017018 37.08773883
 40.07255092 39.90090533 38.44317094 38.16511761]
total_rewards_mean           38.78845865713798
total_rewards_std            1.1445621154422052
total_rewards_max            40.31017017931398
total_rewards_min            37.0877388297043
Number of train steps total  4000
Number of env steps total    7145
Number of rollouts total     0
Train Time (s)               125.45487120421603
(Previous) Eval Time (s)     0
Sample Time (s)              6.543073508888483
Epoch Time (s)               131.99794471310452
Total Train Time (s)         132.48175792908296
Epoch                        0
---------------------------  --------------------------------------------------------------------------------------------------------------------------
2020-01-04 08:32:58.501852 UTC | [2020_01_04_08_30_45] Iteration #0 | Epoch Duration: 132.4854679107666
2020-01-04 08:32:58.502097 UTC | [2020_01_04_08_30_45] Iteration #0 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------
Z mean train                 0.0030618599
Z variance train             0.006928841
KL Divergence                9.947817
KL Loss                      0.9947817
QF Loss                      1413.5459
VF Loss                      198.90645
Policy Loss                  -245.38979
Q Predictions Mean           244.11032
Q Predictions Std            111.53585
Q Predictions Max            485.23834
Q Predictions Min            -4.117668
V Predictions Mean           251.40787
V Predictions Std            103.199875
V Predictions Max            477.1452
V Predictions Min            0.04434264
Log Pis Mean                 2.3030396
Log Pis Std                  2.179302
Log Pis Max                  9.797412
Log Pis Min                  -5.227657
Policy mu Mean               1.2272191
Policy mu Std                0.82520235
Policy mu Max                2.732096
Policy mu Min                -1.4122589
Policy log std Mean          -0.46933356
Policy log std Std           0.19508167
Policy log std Max           0.16956139
Policy log std Min           -0.8411695
Z mean eval                  0.016537333
Z variance eval              0.006054222
total_rewards                [9.0196931  9.15881779 8.75332045 9.28337937 9.27428976 9.02787033
 8.88401176 8.90210225 8.73420631 9.06121009]
total_rewards_mean           9.009890121097019
total_rewards_std            0.18418177592287385
total_rewards_max            9.283379373943387
total_rewards_min            8.734206307307025
Number of train steps total  8000
Number of env steps total    12257
Number of rollouts total     0
Train Time (s)               127.09448166191578
(Previous) Eval Time (s)     0.4871338768862188
Sample Time (s)              4.1456115185283124
Epoch Time (s)               131.7272270573303
Total Train Time (s)         264.3453832506202
Epoch                        1
---------------------------  ----------------------------------------------------------------------------------------------------------------
2020-01-04 08:35:10.365084 UTC | [2020_01_04_08_30_45] Iteration #1 | Epoch Duration: 131.86287093162537
2020-01-04 08:35:10.365203 UTC | [2020_01_04_08_30_45] Iteration #1 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------
Z mean train                 0.016551718
Z variance train             0.006053843
KL Divergence                10.2849865
KL Loss                      1.0284986
QF Loss                      37339.45
VF Loss                      19649.547
Policy Loss                  -562.8916
Q Predictions Mean           597.1515
Q Predictions Std            139.77647
Q Predictions Max            781.045
Q Predictions Min            -5.5925426
V Predictions Mean           624.60876
V Predictions Std            88.43658
V Predictions Max            771.8933
V Predictions Min            59.15683
Log Pis Mean                 3.8059378
Log Pis Std                  3.0202448
Log Pis Max                  16.226171
Log Pis Min                  -4.283923
Policy mu Mean               0.43768716
Policy mu Std                1.6724453
Policy mu Max                4.035545
Policy mu Min                -3.0425537
Policy log std Mean          -0.7489686
Policy log std Std           0.25145832
Policy log std Max           -0.06005192
Policy log std Min           -1.9144306
Z mean eval                  0.01813079
Z variance eval              0.0055305865
total_rewards                [7.28831703 7.4297073  7.35002677 7.5407983  7.42692322 7.58195484
 7.28187628 7.35281558 7.45775872 7.34294185]
total_rewards_mean           7.405311987789434
total_rewards_std            0.09591591645023274
total_rewards_max            7.581954839363923
total_rewards_min            7.281876282435492
Number of train steps total  12000
Number of env steps total    17324
Number of rollouts total     0
Train Time (s)               123.40068397298455
(Previous) Eval Time (s)     0.6225853278301656
Sample Time (s)              4.274484917521477
Epoch Time (s)               128.2977542183362
Total Train Time (s)         392.39632783737034
Epoch                        2
---------------------------  ----------------------------------------------------------------------------------------------------------------
2020-01-04 08:37:18.420100 UTC | [2020_01_04_08_30_45] Iteration #2 | Epoch Duration: 128.05474281311035
2020-01-04 08:37:18.420261 UTC | [2020_01_04_08_30_45] Iteration #2 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018147504
Z variance train             0.005530362
KL Divergence                10.509562
KL Loss                      1.0509561
QF Loss                      78617.03
VF Loss                      21168.836
Policy Loss                  -884.5574
Q Predictions Mean           884.6505
Q Predictions Std            280.4538
Q Predictions Max            1269.8735
Q Predictions Min            -0.79055196
V Predictions Mean           961.9404
V Predictions Std            245.02051
V Predictions Max            1333.7538
V Predictions Min            2.6069305
Log Pis Mean                 6.4037256
Log Pis Std                  2.9241416
Log Pis Max                  16.32772
Log Pis Min                  -0.051041722
Policy mu Mean               0.48535267
Policy mu Std                2.0658686
Policy mu Max                3.6256704
Policy mu Min                -3.4153023
Policy log std Mean          -0.76005775
Policy log std Std           0.2377778
Policy log std Max           -0.19562402
Policy log std Min           -2.3564632
Z mean eval                  0.01852807
Z variance eval              0.0051489165
total_rewards                [291.2431042  287.23057599 289.09644395 278.22591991 288.54250099
 282.87938783 284.14525932 291.72916269 299.5736834  286.18734289]
total_rewards_mean           287.8853381165647
total_rewards_std            5.479321355773043
total_rewards_max            299.5736833976651
total_rewards_min            278.2259199131301
Number of train steps total  16000
Number of env steps total    22374
Number of rollouts total     0
Train Time (s)               124.22806076472625
(Previous) Eval Time (s)     0.3792846747674048
Sample Time (s)              4.364053412806243
Epoch Time (s)               128.9713988522999
Total Train Time (s)         523.4708284279332
Epoch                        3
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 08:39:29.494421 UTC | [2020_01_04_08_30_45] Iteration #3 | Epoch Duration: 131.0740213394165
2020-01-04 08:39:29.494638 UTC | [2020_01_04_08_30_45] Iteration #3 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018514538
Z variance train             0.005149115
KL Divergence                10.686667
KL Loss                      1.0686668
QF Loss                      61874.785
VF Loss                      5974.3696
Policy Loss                  -1578.2968
Q Predictions Mean           1508.1521
Q Predictions Std            645.93646
Q Predictions Max            2578.541
Q Predictions Min            -41.206474
V Predictions Mean           1614.5234
V Predictions Std            545.2769
V Predictions Max            2526.3494
V Predictions Min            0.07556768
Log Pis Mean                 4.766613
Log Pis Std                  3.881454
Log Pis Max                  17.71436
Log Pis Min                  -3.4738064
Policy mu Mean               0.5266488
Policy mu Std                1.8051425
Policy mu Max                4.1977677
Policy mu Min                -3.4416804
Policy log std Mean          -0.91082096
Policy log std Std           0.39422685
Policy log std Max           -0.21318129
Policy log std Min           -3.009953
Z mean eval                  0.016491184
Z variance eval              0.0047690338
total_rewards                [  44.74862725   46.65597751   44.40877371 1036.46394279  440.22648899
   44.85516728  362.4554827  1036.05574021 1034.23879277 1036.44883334]
total_rewards_mean           512.6557826539026
total_rewards_std            446.84697994599725
total_rewards_max            1036.4639427880818
total_rewards_min            44.40877370937429
Number of train steps total  20000
Number of env steps total    28138
Number of rollouts total     0
Train Time (s)               123.32603767514229
(Previous) Eval Time (s)     2.4816839480772614
Sample Time (s)              4.2481232061982155
Epoch Time (s)               130.05584482941777
Total Train Time (s)         658.80516571505
Epoch                        4
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 08:41:44.829872 UTC | [2020_01_04_08_30_45] Iteration #4 | Epoch Duration: 135.33508276939392
2020-01-04 08:41:44.830025 UTC | [2020_01_04_08_30_45] Iteration #4 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016472202
Z variance train             0.0047689797
KL Divergence                10.877136
KL Loss                      1.0877136
QF Loss                      32288.922
VF Loss                      7145.6465
Policy Loss                  -2283.713
Q Predictions Mean           2142.4248
Q Predictions Std            857.26776
Q Predictions Max            3444.9788
Q Predictions Min            -7.7950068
V Predictions Mean           2339.4592
V Predictions Std            720.8946
V Predictions Max            3638.5364
V Predictions Min            3.8204691
Log Pis Mean                 6.290758
Log Pis Std                  3.9683366
Log Pis Max                  17.875221
Log Pis Min                  -3.7908711
Policy mu Mean               0.014471885
Policy mu Std                2.0614388
Policy mu Max                4.3785295
Policy mu Min                -3.6728044
Policy log std Mean          -1.0993266
Policy log std Std           0.5435687
Policy log std Max           -0.19950174
Policy log std Min           -2.7573366
Z mean eval                  0.016479712
Z variance eval              0.004441605
total_rewards                [342.93675566 350.156446   344.68028157 460.85831682 330.55568984
 330.93388215 518.4468266  306.50034821 501.47655778 547.71679011]
total_rewards_mean           403.4261894749711
total_rewards_std            87.67521330768216
total_rewards_max            547.7167901109996
total_rewards_min            306.5003482061713
Number of train steps total  24000
Number of env steps total    33929
Number of rollouts total     0
Train Time (s)               125.8848784849979
(Previous) Eval Time (s)     7.76073833508417
Sample Time (s)              4.73040281701833
Epoch Time (s)               138.3760196371004
Total Train Time (s)         793.5612284853123
Epoch                        5
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 08:43:59.589737 UTC | [2020_01_04_08_30_45] Iteration #5 | Epoch Duration: 134.75954842567444
2020-01-04 08:43:59.590042 UTC | [2020_01_04_08_30_45] Iteration #5 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016468307
Z variance train             0.0044415668
KL Divergence                11.054239
KL Loss                      1.1054239
QF Loss                      24607.96
VF Loss                      4351.934
Policy Loss                  -2671.668
Q Predictions Mean           2529.231
Q Predictions Std            926.1192
Q Predictions Max            3783.1194
Q Predictions Min            -87.734535
V Predictions Mean           2690.981
V Predictions Std            767.7408
V Predictions Max            3851.5852
V Predictions Min            0.09409363
Log Pis Mean                 6.2235537
Log Pis Std                  4.1430063
Log Pis Max                  19.074928
Log Pis Min                  -2.5115902
Policy mu Mean               -0.06073628
Policy mu Std                2.054779
Policy mu Max                5.8472633
Policy mu Min                -3.7610626
Policy log std Mean          -1.1128932
Policy log std Std           0.60607696
Policy log std Max           0.105217144
Policy log std Min           -3.4121943
Z mean eval                  0.013608465
Z variance eval              0.0041607255
total_rewards                [160.47688319 190.99953041 259.17224858 258.23862377 296.24267328
 332.57067993 270.50395399 240.36892154 180.69382646 142.74063683]
total_rewards_mean           233.2007977972168
total_rewards_std            58.82406435421175
total_rewards_max            332.57067993206687
total_rewards_min            142.74063682964535
Number of train steps total  28000
Number of env steps total    39846
Number of rollouts total     0
Train Time (s)               125.34922211105004
(Previous) Eval Time (s)     4.144045192282647
Sample Time (s)              4.606328206602484
Epoch Time (s)               134.09959550993517
Total Train Time (s)         926.6475834073499
Epoch                        6
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 08:46:12.674509 UTC | [2020_01_04_08_30_45] Iteration #6 | Epoch Duration: 133.0842740535736
2020-01-04 08:46:12.674623 UTC | [2020_01_04_08_30_45] Iteration #6 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013599085
Z variance train             0.0041606403
KL Divergence                11.216784
KL Loss                      1.1216784
QF Loss                      159080.45
VF Loss                      5396.806
Policy Loss                  -2855.093
Q Predictions Mean           2720.8696
Q Predictions Std            935.9342
Q Predictions Max            4846.3857
Q Predictions Min            -44.854774
V Predictions Mean           2827.0527
V Predictions Std            792.128
V Predictions Max            4832.8926
V Predictions Min            0.09844068
Log Pis Mean                 5.9900723
Log Pis Std                  3.573848
Log Pis Max                  18.539047
Log Pis Min                  -1.7956243
Policy mu Mean               0.17064351
Policy mu Std                2.0384324
Policy mu Max                4.585644
Policy mu Min                -4.1611023
Policy log std Mean          -1.1047777
Policy log std Std           0.57275814
Policy log std Max           0.2086118
Policy log std Min           -3.236217
Z mean eval                  0.010098422
Z variance eval              0.0039121443
total_rewards                [15.79898062 18.27016657 21.24705637 16.96814038 18.57633229 24.14906522
 24.06397062 18.40049091 17.90095824 18.65635819]
total_rewards_mean           19.403151940549847
total_rewards_std            2.6898539358584994
total_rewards_max            24.149065224452535
total_rewards_min            15.798980617608832
Number of train steps total  32000
Number of env steps total    45357
Number of rollouts total     0
Train Time (s)               124.89325641840696
(Previous) Eval Time (s)     3.1285566398873925
Sample Time (s)              4.642287567257881
Epoch Time (s)               132.66410062555224
Total Train Time (s)         1057.1333423717879
Epoch                        7
---------------------------  --------------------------------------------------------------------------------------------------------------------------
2020-01-04 08:48:23.161738 UTC | [2020_01_04_08_30_45] Iteration #7 | Epoch Duration: 130.48701119422913
2020-01-04 08:48:23.161905 UTC | [2020_01_04_08_30_45] Iteration #7 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010092113
Z variance train             0.0039121667
KL Divergence                11.36977
KL Loss                      1.1369771
QF Loss                      50426.344
VF Loss                      8273.847
Policy Loss                  -2883.2957
Q Predictions Mean           2773.8843
Q Predictions Std            862.4216
Q Predictions Max            3595.4775
Q Predictions Min            -30.278051
V Predictions Mean           2862.843
V Predictions Std            717.04895
V Predictions Max            3678.112
V Predictions Min            0.10640054
Log Pis Mean                 4.8766975
Log Pis Std                  3.9549558
Log Pis Max                  19.720938
Log Pis Min                  -2.688651
Policy mu Mean               0.21281745
Policy mu Std                1.6620592
Policy mu Max                5.6699004
Policy mu Min                -3.7239888
Policy log std Mean          -1.4526826
Policy log std Std           0.7316615
Policy log std Max           0.49268436
Policy log std Min           -3.7937894
Z mean eval                  0.0073657758
Z variance eval              0.0036495153
total_rewards                [370.48069709 370.7816633  323.92701232 326.39483519 392.96767463
 389.62428977 316.98514469 347.0006221  301.1031915  388.51930212]
total_rewards_mean           352.7784432716676
total_rewards_std            32.25067497479747
total_rewards_max            392.9676746265089
total_rewards_min            301.10319150415523
Number of train steps total  36000
Number of env steps total    50857
Number of rollouts total     0
Train Time (s)               123.71607083966956
(Previous) Eval Time (s)     0.9512554872781038
Sample Time (s)              4.286442965269089
Epoch Time (s)               128.95376929221675
Total Train Time (s)         1189.0838551404886
Epoch                        8
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 08:50:35.120064 UTC | [2020_01_04_08_30_45] Iteration #8 | Epoch Duration: 131.9579734802246
2020-01-04 08:50:35.120376 UTC | [2020_01_04_08_30_45] Iteration #8 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0073356167
Z variance train             0.0036494867
KL Divergence                11.542551
KL Loss                      1.1542552
QF Loss                      22902.805
VF Loss                      7697.4233
Policy Loss                  -2735.9502
Q Predictions Mean           2653.0405
Q Predictions Std            829.68994
Q Predictions Max            3410.8093
Q Predictions Min            -53.15991
V Predictions Mean           2795.6108
V Predictions Std            735.75555
V Predictions Max            3484.5676
V Predictions Min            0.15232116
Log Pis Mean                 4.7250767
Log Pis Std                  3.5478427
Log Pis Max                  16.169939
Log Pis Min                  -1.9696949
Policy mu Mean               0.24901192
Policy mu Std                1.6704705
Policy mu Max                5.1624303
Policy mu Min                -3.7610574
Policy log std Mean          -1.2862438
Policy log std Std           0.68533176
Policy log std Max           0.14295208
Policy log std Min           -2.8633542
Z mean eval                  0.005704402
Z variance eval              0.0034377459
total_rewards                [ 22.56830232  18.69909114  35.1421334  683.93750999  32.79253379
  32.41372948  34.59129858  33.68219888  34.13939529  34.44047481]
total_rewards_mean           96.24066676856835
total_rewards_std            195.9720656628617
total_rewards_max            683.937509994281
total_rewards_min            18.699091138817156
Number of train steps total  40000
Number of env steps total    57132
Number of rollouts total     0
Train Time (s)               124.4300374481827
(Previous) Eval Time (s)     3.9552348060533404
Sample Time (s)              5.2743709166534245
Epoch Time (s)               133.65964317088947
Total Train Time (s)         1320.8930318835191
Epoch                        9
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 08:52:46.924972 UTC | [2020_01_04_08_30_45] Iteration #9 | Epoch Duration: 131.80436849594116
2020-01-04 08:52:46.925183 UTC | [2020_01_04_08_30_45] Iteration #9 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.005738574
Z variance train             0.003437711
KL Divergence                11.69133
KL Loss                      1.1691331
QF Loss                      55669.363
VF Loss                      2703.2537
Policy Loss                  -2446.7642
Q Predictions Mean           2336.7964
Q Predictions Std            842.84735
Q Predictions Max            3201.4214
Q Predictions Min            -60.785072
V Predictions Mean           2463.4192
V Predictions Std            723.4741
V Predictions Max            3150.4478
V Predictions Min            0.3414265
Log Pis Mean                 4.30751
Log Pis Std                  3.3285227
Log Pis Max                  15.529538
Log Pis Min                  -4.826289
Policy mu Mean               0.009643693
Policy mu Std                1.6418055
Policy mu Max                5.0161433
Policy mu Min                -3.9666061
Policy log std Mean          -1.190662
Policy log std Std           0.5848095
Policy log std Max           0.0015103519
Policy log std Min           -2.635429
Z mean eval                  0.0035640865
Z variance eval              0.0032238602
total_rewards                [553.71293885 508.97899585 275.34796292 510.42159394 677.91711518
 412.60115237 625.84500836  95.67128535 702.59959984 302.14531207]
total_rewards_mean           466.52409647351385
total_rewards_std            184.70010769627498
total_rewards_max            702.5995998372288
total_rewards_min            95.67128535312202
Number of train steps total  44000
Number of env steps total    62511
Number of rollouts total     0
Train Time (s)               125.59439796116203
(Previous) Eval Time (s)     2.0997311151586473
Sample Time (s)              4.074165480211377
Epoch Time (s)               131.76829455653206
Total Train Time (s)         1456.494256277103
Epoch                        10
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 08:55:02.527457 UTC | [2020_01_04_08_30_45] Iteration #10 | Epoch Duration: 135.60206127166748
2020-01-04 08:55:02.527711 UTC | [2020_01_04_08_30_45] Iteration #10 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0035699054
Z variance train             0.0032237782
KL Divergence                11.851755
KL Loss                      1.1851755
QF Loss                      4355.899
VF Loss                      5175.113
Policy Loss                  -2296.397
Q Predictions Mean           2244.1265
Q Predictions Std            705.46014
Q Predictions Max            2853.2537
Q Predictions Min            -12.070782
V Predictions Mean           2300.817
V Predictions Std            635.3434
V Predictions Max            2881.132
V Predictions Min            0.9318406
Log Pis Mean                 3.5871491
Log Pis Std                  3.0580845
Log Pis Max                  15.898079
Log Pis Min                  -4.7896953
Policy mu Mean               0.18699749
Policy mu Std                1.5061148
Policy mu Max                5.7768326
Policy mu Min                -3.515519
Policy log std Mean          -1.173492
Policy log std Std           0.59116364
Policy log std Max           0.48819345
Policy log std Min           -2.6193352
Z mean eval                  0.0030887125
Z variance eval              0.0030491736
total_rewards                [93.72739022 90.58283441 85.46924049 86.39502953 80.81170251 84.53900417
 85.43134742 83.53777009 86.21647615 86.61007755]
total_rewards_mean           86.3320872542489
total_rewards_std            3.4045235128619633
total_rewards_max            93.72739021673777
total_rewards_min            80.81170250653132
Number of train steps total  48000
Number of env steps total    68631
Number of rollouts total     0
Train Time (s)               121.33648311113939
(Previous) Eval Time (s)     5.933293158188462
Sample Time (s)              4.372073489706963
Epoch Time (s)               131.6418497590348
Total Train Time (s)         1583.3517562183551
Epoch                        11
---------------------------  --------------------------------------------------------------------------------------------------------------------------
2020-01-04 08:57:09.385114 UTC | [2020_01_04_08_30_45] Iteration #11 | Epoch Duration: 126.8572609424591
2020-01-04 08:57:09.385252 UTC | [2020_01_04_08_30_45] Iteration #11 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0030729074
Z variance train             0.003049092
KL Divergence                11.990591
KL Loss                      1.1990591
QF Loss                      45560.15
VF Loss                      1875.6296
Policy Loss                  -2000.7666
Q Predictions Mean           1934.3472
Q Predictions Std            638.172
Q Predictions Max            2506.982
Q Predictions Min            -5.2159643
V Predictions Mean           1976.7249
V Predictions Std            580.4645
V Predictions Max            2508.8853
V Predictions Min            1.7125334
Log Pis Mean                 3.88352
Log Pis Std                  2.961706
Log Pis Max                  18.964125
Log Pis Min                  -3.750878
Policy mu Mean               0.3965613
Policy mu Std                1.5789149
Policy mu Max                4.8127885
Policy mu Min                -4.6340714
Policy log std Mean          -1.0170778
Policy log std Std           0.49150833
Policy log std Max           0.8692964
Policy log std Min           -3.489021
Z mean eval                  0.0021101437
Z variance eval              0.0028952104
total_rewards                [428.81801898 457.84180606 320.9359959  505.55839715 303.49538486
 298.99381444 478.58649351 559.69537551 471.4227647  638.56376877]
total_rewards_mean           446.3911819868853
total_rewards_std            106.42187289672732
total_rewards_max            638.5637687675551
total_rewards_min            298.99381443765606
Number of train steps total  52000
Number of env steps total    73976
Number of rollouts total     0
Train Time (s)               126.05856838123873
(Previous) Eval Time (s)     1.1485057757236063
Sample Time (s)              3.8277587918564677
Epoch Time (s)               131.0348329488188
Total Train Time (s)         1718.7412752606906
Epoch                        12
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 08:59:24.777916 UTC | [2020_01_04_08_30_45] Iteration #12 | Epoch Duration: 135.39251375198364
2020-01-04 08:59:24.778192 UTC | [2020_01_04_08_30_45] Iteration #12 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0021351657
Z variance train             0.002895183
KL Divergence                12.119957
KL Loss                      1.2119957
QF Loss                      7068.1294
VF Loss                      2724.27
Policy Loss                  -1743.3016
Q Predictions Mean           1679.7296
Q Predictions Std            729.9833
Q Predictions Max            2319.9832
Q Predictions Min            -190.65504
V Predictions Mean           1723.029
V Predictions Std            663.28937
V Predictions Max            2267.7087
V Predictions Min            -0.6696614
Log Pis Mean                 3.2572975
Log Pis Std                  2.886992
Log Pis Max                  13.4372835
Log Pis Min                  -4.4361625
Policy mu Mean               0.27537856
Policy mu Std                1.4705876
Policy mu Max                4.8648243
Policy mu Min                -3.5903451
Policy log std Mean          -1.06624
Policy log std Std           0.5122637
Policy log std Max           0.14341184
Policy log std Min           -2.905666
Z mean eval                  0.0016496361
Z variance eval              0.0027315153
total_rewards                [253.2309974  255.93324635 274.4787763  261.13359855 275.00005708
 264.13615435 280.56583515 267.91520066 267.03682142 261.53704137]
total_rewards_mean           266.09677286101174
total_rewards_std            8.253267903264877
total_rewards_max            280.56583514960823
total_rewards_min            253.23099739723548
Number of train steps total  56000
Number of env steps total    79382
Number of rollouts total     0
Train Time (s)               125.25842351373285
(Previous) Eval Time (s)     5.505959032103419
Sample Time (s)              3.986894739791751
Epoch Time (s)               134.75127728562802
Total Train Time (s)         1850.2471270472743
Epoch                        13
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 09:01:36.283832 UTC | [2020_01_04_08_30_45] Iteration #13 | Epoch Duration: 131.50544214248657
2020-01-04 09:01:36.284039 UTC | [2020_01_04_08_30_45] Iteration #13 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0016510099
Z variance train             0.0027315344
KL Divergence                12.265307
KL Loss                      1.2265308
QF Loss                      22995.637
VF Loss                      2992.301
Policy Loss                  -1596.3612
Q Predictions Mean           1559.853
Q Predictions Std            610.5531
Q Predictions Max            2106.1614
Q Predictions Min            -17.919718
V Predictions Mean           1624.0991
V Predictions Std            577.8343
V Predictions Max            2131.0469
V Predictions Min            2.9821029
Log Pis Mean                 3.063521
Log Pis Std                  2.7596824
Log Pis Max                  18.86026
Log Pis Min                  -3.7306254
Policy mu Mean               0.44944683
Policy mu Std                1.3974609
Policy mu Max                4.6214
Policy mu Min                -3.56893
Policy log std Mean          -0.9892192
Policy log std Std           0.46101537
Policy log std Max           -0.03674391
Policy log std Min           -3.3562062
Z mean eval                  0.00055346073
Z variance eval              0.0025840574
total_rewards                [306.37163102 282.26678674 219.27445833 316.12274553 317.076001
 221.92535964 299.22608373 305.84866349 290.7076576  292.22105573]
total_rewards_mean           285.10404428061
total_rewards_std            33.884554384666615
total_rewards_max            317.07600100443267
total_rewards_min            219.27445832517438
Number of train steps total  60000
Number of env steps total    84893
Number of rollouts total     0
Train Time (s)               123.11004665726796
(Previous) Eval Time (s)     2.2599050062708557
Sample Time (s)              4.331192245241255
Epoch Time (s)               129.70114390878007
Total Train Time (s)         1979.7520843441598
Epoch                        14
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------
2020-01-04 09:03:45.789339 UTC | [2020_01_04_08_30_45] Iteration #14 | Epoch Duration: 129.50515151023865
2020-01-04 09:03:45.789497 UTC | [2020_01_04_08_30_45] Iteration #14 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0005456858
Z variance train             0.0025839298
KL Divergence                12.403625
KL Loss                      1.2403625
QF Loss                      44503.273
VF Loss                      695.974
Policy Loss                  -1381.8041
Q Predictions Mean           1326.5732
Q Predictions Std            583.33167
Q Predictions Max            1871.7776
Q Predictions Min            -29.950565
V Predictions Mean           1371.7162
V Predictions Std            543.768
V Predictions Max            1900.8662
V Predictions Min            1.6730244
Log Pis Mean                 2.8559875
Log Pis Std                  2.8885953
Log Pis Max                  15.526649
Log Pis Min                  -5.5667953
Policy mu Mean               0.4696784
Policy mu Std                1.4049621
Policy mu Max                4.2730618
Policy mu Min                -3.7103
Policy log std Mean          -0.87538356
Policy log std Std           0.45360672
Policy log std Max           0.05969718
Policy log std Min           -3.0254664
Z mean eval                  0.0010543443
Z variance eval              0.002450275
total_rewards                [ 46.87741841  11.0228345  520.56307572  34.80795303 341.96867143
 317.11361754  11.04153876 340.51831524 344.60244358 361.89774507]
total_rewards_mean           233.0413613289073
total_rewards_std            177.40710893607098
total_rewards_max            520.5630757193721
total_rewards_min            11.02283450349568
Number of train steps total  64000
Number of env steps total    90565
Number of rollouts total     0
Train Time (s)               125.029150061775
(Previous) Eval Time (s)     2.063702616840601
Sample Time (s)              4.207111947704107
Epoch Time (s)               131.2999646263197
Total Train Time (s)         2111.339127332438
Epoch                        15
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 09:05:57.377778 UTC | [2020_01_04_08_30_45] Iteration #15 | Epoch Duration: 131.58814096450806
2020-01-04 09:05:57.377942 UTC | [2020_01_04_08_30_45] Iteration #15 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0010598169
Z variance train             0.0024502731
KL Divergence                12.535895
KL Loss                      1.2535895
QF Loss                      14069.2705
VF Loss                      683.6216
Policy Loss                  -1183.6707
Q Predictions Mean           1140.8765
Q Predictions Std            527.28357
Q Predictions Max            1776.7913
Q Predictions Min            -9.447035
V Predictions Mean           1170.4521
V Predictions Std            489.9034
V Predictions Max            1798.4094
V Predictions Min            4.830059
Log Pis Mean                 2.5292726
Log Pis Std                  3.1529603
Log Pis Max                  19.503693
Log Pis Min                  -7.124587
Policy mu Mean               -0.2038093
Policy mu Std                1.3905314
Policy mu Max                4.9239044
Policy mu Min                -4.20249
Policy log std Mean          -0.8207224
Policy log std Std           0.40192425
Policy log std Max           0.27108145
Policy log std Min           -2.9614165
Z mean eval                  0.0021033054
Z variance eval              0.0023335542
total_rewards                [ 980.55427707  977.83954059 1001.73532918  990.37197706 1002.31285793
 1000.60348406  987.27871968  990.57896672  988.295875   1000.91873548]
total_rewards_mean           992.0489762764886
total_rewards_std            8.525699239351244
total_rewards_max            1002.3128579343442
total_rewards_min            977.8395405898501
Number of train steps total  68000
Number of env steps total    96353
Number of rollouts total     0
Train Time (s)               124.86029096506536
(Previous) Eval Time (s)     2.3516593552194536
Sample Time (s)              4.484815959353
Epoch Time (s)               131.6967662796378
Total Train Time (s)         2256.406467700377
Epoch                        16
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 09:08:22.446194 UTC | [2020_01_04_08_30_45] Iteration #16 | Epoch Duration: 145.06809663772583
2020-01-04 09:08:22.446364 UTC | [2020_01_04_08_30_45] Iteration #16 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0021487377
Z variance train             0.0023335177
KL Divergence                12.65802
KL Loss                      1.265802
QF Loss                      2307.6338
VF Loss                      1706.7205
Policy Loss                  -1054.6443
Q Predictions Mean           1015.7329
Q Predictions Std            446.35724
Q Predictions Max            1687.0776
Q Predictions Min            -31.91665
V Predictions Mean           1051.9952
V Predictions Std            427.9797
V Predictions Max            1671.9385
V Predictions Min            4.405781
Log Pis Mean                 2.3929336
Log Pis Std                  2.9809868
Log Pis Max                  23.771173
Log Pis Min                  -4.1289644
Policy mu Mean               -0.44595695
Policy mu Std                1.3429687
Policy mu Max                6.6335406
Policy mu Min                -2.9459982
Policy log std Mean          -0.82740813
Policy log std Std           0.38284296
Policy log std Max           0.23034737
Policy log std Min           -2.2450309
Z mean eval                  0.0021509584
Z variance eval              0.0022217757
total_rewards                [1012.34436904 1011.03145907  304.61427578  302.28785158  808.36925745
  394.40892974  238.36968978  412.81731057  259.07409514  501.0829741 ]
total_rewards_mean           524.4400212250534
total_rewards_std            289.0123200187514
total_rewards_max            1012.3443690400998
total_rewards_min            238.36968978061995
Number of train steps total  72000
Number of env steps total    101420
Number of rollouts total     0
Train Time (s)               123.55578915588558
(Previous) Eval Time (s)     15.722760988865048
Sample Time (s)              3.6726636569947004
Epoch Time (s)               142.95121380174533
Total Train Time (s)         2390.5883094207384
Epoch                        17
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 09:10:36.628882 UTC | [2020_01_04_08_30_45] Iteration #17 | Epoch Duration: 134.18238496780396
2020-01-04 09:10:36.629054 UTC | [2020_01_04_08_30_45] Iteration #17 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.002158061
Z variance train             0.0022217028
KL Divergence                12.780469
KL Loss                      1.278047
QF Loss                      1784.8246
VF Loss                      1279.8534
Policy Loss                  -979.397
Q Predictions Mean           953.10815
Q Predictions Std            382.18158
Q Predictions Max            1389.7458
Q Predictions Min            5.6320677
V Predictions Mean           982.73596
V Predictions Std            368.51517
V Predictions Max            1418.9421
V Predictions Min            3.0974126
Log Pis Mean                 2.5016658
Log Pis Std                  2.685815
Log Pis Max                  13.405378
Log Pis Min                  -3.5945036
Policy mu Mean               -0.28289303
Policy mu Std                1.3554944
Policy mu Max                3.718643
Policy mu Min                -3.572097
Policy log std Mean          -0.8511152
Policy log std Std           0.34013823
Policy log std Max           0.058306128
Policy log std Min           -2.5071719
Z mean eval                  0.0013089676
Z variance eval              0.0021082168
total_rewards                [560.70790284 598.58356224 701.34378383 716.81100608 673.51995619
 693.87023776 651.2761106  657.37086223 660.3933922  634.21826335]
total_rewards_mean           654.8095077322469
total_rewards_std            45.13993763378421
total_rewards_max            716.8110060824446
total_rewards_min            560.7079028382302
Number of train steps total  76000
Number of env steps total    106964
Number of rollouts total     0
Train Time (s)               123.48120588669553
(Previous) Eval Time (s)     6.953724362887442
Sample Time (s)              3.74102773796767
Epoch Time (s)               134.17595798755065
Total Train Time (s)         2525.305172539316
Epoch                        18
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 09:12:51.350024 UTC | [2020_01_04_08_30_45] Iteration #18 | Epoch Duration: 134.7208013534546
2020-01-04 09:12:51.350298 UTC | [2020_01_04_08_30_45] Iteration #18 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0013078444
Z variance train             0.0021081506
KL Divergence                12.911438
KL Loss                      1.2911438
QF Loss                      1301.7477
VF Loss                      418.09875
Policy Loss                  -963.1364
Q Predictions Mean           953.2696
Q Predictions Std            320.6794
Q Predictions Max            1319.8566
Q Predictions Min            17.249453
V Predictions Mean           952.6177
V Predictions Std            315.83792
V Predictions Max            1304.9503
V Predictions Min            6.6320133
Log Pis Mean                 1.6715597
Log Pis Std                  2.5423527
Log Pis Max                  13.729466
Log Pis Min                  -4.277885
Policy mu Mean               0.05231446
Policy mu Std                1.2078284
Policy mu Max                4.374146
Policy mu Min                -3.2073283
Policy log std Mean          -0.82954144
Policy log std Std           0.3498152
Policy log std Max           0.031069756
Policy log std Min           -2.1431093
Z mean eval                  0.001452899
Z variance eval              0.001994125
total_rewards                [ 361.00037819  177.79925657 1042.55010016 1195.52780678  917.69183368
  954.42109632  998.9487626   984.88826082  690.16172611  832.84351377]
total_rewards_mean           815.5832735011753
total_rewards_std            302.87018846719064
total_rewards_max            1195.5278067845172
total_rewards_min            177.79925656909253
Number of train steps total  80000
Number of env steps total    111964
Number of rollouts total     0
Train Time (s)               125.18450678000227
(Previous) Eval Time (s)     7.498408250045031
Sample Time (s)              4.190522416494787
Epoch Time (s)               136.87343744654208
Total Train Time (s)         2666.8538681962527
Epoch                        19
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 09:15:12.897818 UTC | [2020_01_04_08_30_45] Iteration #19 | Epoch Duration: 141.54731488227844
2020-01-04 09:15:12.897990 UTC | [2020_01_04_08_30_45] Iteration #19 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0014580234
Z variance train             0.0019941493
KL Divergence                13.05035
KL Loss                      1.305035
QF Loss                      7323.784
VF Loss                      594.4994
Policy Loss                  -895.0988
Q Predictions Mean           866.0314
Q Predictions Std            261.36386
Q Predictions Max            1132.1976
Q Predictions Min            -43.34187
V Predictions Mean           903.58093
V Predictions Std            226.48708
V Predictions Max            1152.4003
V Predictions Min            6.6511827
Log Pis Mean                 1.2544353
Log Pis Std                  2.4856641
Log Pis Max                  13.171473
Log Pis Min                  -4.6107583
Policy mu Mean               -0.10737916
Policy mu Std                1.1683278
Policy mu Max                4.059859
Policy mu Min                -3.1246524
Policy log std Mean          -0.7298034
Policy log std Std           0.32237834
Policy log std Max           0.25228605
Policy log std Min           -2.04671
Z mean eval                  0.0010298416
Z variance eval              0.0019016385
total_rewards                [ 32.04534215  62.76321397  39.35533542 741.32112306  19.51489755
 161.12586587  74.11704873 651.53562141  43.89224741 826.42072013]
total_rewards_mean           265.20914156900983
total_rewards_std            315.2689648514566
total_rewards_max            826.4207201333688
total_rewards_min            19.51489755441036
Number of train steps total  84000
Number of env steps total    117146
Number of rollouts total     0
Train Time (s)               125.96778770070523
(Previous) Eval Time (s)     12.172103984747082
Sample Time (s)              3.930040853098035
Epoch Time (s)               142.06993253855035
Total Train Time (s)         2800.179953509476
Epoch                        20
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 09:17:26.225301 UTC | [2020_01_04_08_30_45] Iteration #20 | Epoch Duration: 133.3271725177765
2020-01-04 09:17:26.225478 UTC | [2020_01_04_08_30_45] Iteration #20 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0010253845
Z variance train             0.0019016039
KL Divergence                13.168987
KL Loss                      1.3168987
QF Loss                      961.5791
VF Loss                      2450.4233
Policy Loss                  -818.9369
Q Predictions Mean           797.34314
Q Predictions Std            259.31265
Q Predictions Max            1044.9789
Q Predictions Min            -16.2826
V Predictions Mean           814.4999
V Predictions Std            243.6978
V Predictions Max            1056.3442
V Predictions Min            10.9842005
Log Pis Mean                 1.3861146
Log Pis Std                  3.174839
Log Pis Max                  21.87545
Log Pis Min                  -4.099514
Policy mu Mean               -0.033383623
Policy mu Std                1.2405019
Policy mu Max                5.1017
Policy mu Min                -4.558476
Policy log std Mean          -0.6699633
Policy log std Std           0.31352586
Policy log std Max           0.3205755
Policy log std Min           -3.1058342
Z mean eval                  0.0010050619
Z variance eval              0.001802916
total_rewards                [583.61276933 596.5485862   43.96717483  51.7701791   65.85380399
 348.19820756 340.62956638  69.2774219   50.40003351 447.97741101]
total_rewards_mean           259.8235153819444
total_rewards_std            218.09063592018282
total_rewards_max            596.5485862042725
total_rewards_min            43.96717483429757
Number of train steps total  88000
Number of env steps total    122585
Number of rollouts total     0
Train Time (s)               124.81045165704563
(Previous) Eval Time (s)     3.4291108902543783
Sample Time (s)              3.5129468329250813
Epoch Time (s)               131.7525093802251
Total Train Time (s)         2930.6263435501605
Epoch                        21
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 09:19:36.672769 UTC | [2020_01_04_08_30_45] Iteration #21 | Epoch Duration: 130.44714975357056
2020-01-04 09:19:36.672940 UTC | [2020_01_04_08_30_45] Iteration #21 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0010203931
Z variance train             0.0018028847
KL Divergence                13.302615
KL Loss                      1.3302616
QF Loss                      405.53702
VF Loss                      86.515976
Policy Loss                  -769.35925
Q Predictions Mean           760.2682
Q Predictions Std            196.73416
Q Predictions Max            979.03516
Q Predictions Min            10.321938
V Predictions Mean           766.4467
V Predictions Std            187.74434
V Predictions Max            970.9392
V Predictions Min            14.556612
Log Pis Mean                 0.66831124
Log Pis Std                  1.9745784
Log Pis Max                  7.0032387
Log Pis Min                  -4.4495597
Policy mu Mean               0.11327342
Policy mu Std                1.0256177
Policy mu Max                2.9966617
Policy mu Min                -2.5281165
Policy log std Mean          -0.61880064
Policy log std Std           0.28065747
Policy log std Max           0.25987768
Policy log std Min           -1.8255941
Z mean eval                  0.0011384755
Z variance eval              0.001715298
total_rewards                [326.09521246 315.19048108 325.12442311 300.84243739 320.72782461
 305.55617759 320.40295244 288.78518081 298.33291901 308.58786302]
total_rewards_mean           310.96454715137264
total_rewards_std            11.918646038291708
total_rewards_max            326.09521245526383
total_rewards_min            288.7851808111429
Number of train steps total  92000
Number of env steps total    128592
Number of rollouts total     0
Train Time (s)               125.20179948071018
(Previous) Eval Time (s)     2.12351417215541
Sample Time (s)              3.9854369494132698
Epoch Time (s)               131.31075060227886
Total Train Time (s)         3062.23070773622
Epoch                        22
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 09:21:48.281047 UTC | [2020_01_04_08_30_45] Iteration #22 | Epoch Duration: 131.6079285144806
2020-01-04 09:21:48.281332 UTC | [2020_01_04_08_30_45] Iteration #22 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0010945288
Z variance train             0.0017151579
KL Divergence                13.42638
KL Loss                      1.342638
QF Loss                      3153.1611
VF Loss                      449.84665
Policy Loss                  -722.5815
Q Predictions Mean           721.6962
Q Predictions Std            193.31343
Q Predictions Max            926.33075
Q Predictions Min            23.263103
V Predictions Mean           724.44946
V Predictions Std            184.37706
V Predictions Max            905.39856
V Predictions Min            13.073448
Log Pis Mean                 1.0335974
Log Pis Std                  2.5185215
Log Pis Max                  11.688834
Log Pis Min                  -5.398848
Policy mu Mean               0.48054025
Policy mu Std                1.0589304
Policy mu Max                4.1793365
Policy mu Min                -2.988218
Policy log std Mean          -0.5880129
Policy log std Std           0.27632043
Policy log std Max           0.15569058
Policy log std Min           -3.037282
Z mean eval                  0.0017682895
Z variance eval              0.001650931
total_rewards                [296.5811664  287.39951805 300.4721007  295.87545725 299.62842362
 304.49581502 314.5886623  314.99350129 326.48565207 300.27224515]
total_rewards_mean           304.07925418534074
total_rewards_std            10.866649008943707
total_rewards_max            326.48565207075404
total_rewards_min            287.3995180466511
Number of train steps total  96000
Number of env steps total    134319
Number of rollouts total     0
Train Time (s)               124.97130332700908
(Previous) Eval Time (s)     2.4204529002308846
Sample Time (s)              4.72719942452386
Epoch Time (s)               132.11895565176383
Total Train Time (s)         3194.0844172276556
Epoch                        23
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 09:24:00.137262 UTC | [2020_01_04_08_30_45] Iteration #23 | Epoch Duration: 131.85556721687317
2020-01-04 09:24:00.137665 UTC | [2020_01_04_08_30_45] Iteration #23 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0017671965
Z variance train             0.0016508873
KL Divergence                13.522315
KL Loss                      1.3522315
QF Loss                      392.05298
VF Loss                      636.02875
Policy Loss                  -709.6793
Q Predictions Mean           697.8655
Q Predictions Std            210.48071
Q Predictions Max            921.3895
Q Predictions Min            12.271138
V Predictions Mean           702.963
V Predictions Std            198.7378
V Predictions Max            914.1103
V Predictions Min            2.9247046
Log Pis Mean                 0.7586498
Log Pis Std                  2.4570081
Log Pis Max                  10.670312
Log Pis Min                  -6.9526234
Policy mu Mean               0.46953884
Policy mu Std                1.0052738
Policy mu Max                3.4728837
Policy mu Min                -2.775351
Policy log std Mean          -0.58343863
Policy log std Std           0.24534477
Policy log std Max           0.2842143
Policy log std Min           -2.699304
Z mean eval                  0.0011230627
Z variance eval              0.0015863914
total_rewards                [340.00003056 350.5637778  345.74615444 352.60646174 345.00489226
 339.92804798 341.55453022 326.28093227 340.28243724 353.63805382]
total_rewards_mean           343.56053183345585
total_rewards_std            7.606053448181796
total_rewards_max            353.6380538192272
total_rewards_min            326.28093226607535
Number of train steps total  100000
Number of env steps total    139927
Number of rollouts total     0
Train Time (s)               156.4712329893373
(Previous) Eval Time (s)     2.1567328716628253
Sample Time (s)              4.574416005052626
Epoch Time (s)               163.20238186605275
Total Train Time (s)         3357.7667992771603
Epoch                        24
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 09:26:43.821378 UTC | [2020_01_04_08_30_45] Iteration #24 | Epoch Duration: 163.6834592819214
2020-01-04 09:26:43.821657 UTC | [2020_01_04_08_30_45] Iteration #24 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0011136889
Z variance train             0.0015864007
KL Divergence                13.621315
KL Loss                      1.3621315
QF Loss                      643.11304
VF Loss                      332.99124
Policy Loss                  -705.0649
Q Predictions Mean           701.61584
Q Predictions Std            188.23158
Q Predictions Max            897.72876
Q Predictions Min            -25.441769
V Predictions Mean           715.00024
V Predictions Std            173.98903
V Predictions Max            891.7959
V Predictions Min            7.2257175
Log Pis Mean                 0.88107824
Log Pis Std                  2.3111708
Log Pis Max                  11.380245
Log Pis Min                  -4.9950156
Policy mu Mean               0.4716108
Policy mu Std                1.0431736
Policy mu Max                3.604539
Policy mu Min                -2.804491
Policy log std Mean          -0.54275185
Policy log std Std           0.2257851
Policy log std Max           0.29513565
Policy log std Min           -2.2566664
Z mean eval                  0.0017421305
Z variance eval              0.00150837
total_rewards                [292.79707951 313.22602824 325.79184151 318.20723793 328.99734308
 321.37781222 329.2237982  340.11677136 325.61023717 325.22093794]
total_rewards_mean           322.0569087160601
total_rewards_std            11.881425469069129
total_rewards_max            340.11677136060797
total_rewards_min            292.7970795145573
Number of train steps total  104000
Number of env steps total    145472
Number of rollouts total     0
Train Time (s)               135.7343685189262
(Previous) Eval Time (s)     2.6375884041190147
Sample Time (s)              4.572129511274397
Epoch Time (s)               142.94408643431962
Total Train Time (s)         3501.58871762082
Epoch                        25
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 09:29:07.644968 UTC | [2020_01_04_08_30_45] Iteration #25 | Epoch Duration: 143.82309293746948
2020-01-04 09:29:07.645132 UTC | [2020_01_04_08_30_45] Iteration #25 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0016919866
Z variance train             0.0015083596
KL Divergence                13.746922
KL Loss                      1.3746922
QF Loss                      1245.9734
VF Loss                      223.38394
Policy Loss                  -671.4027
Q Predictions Mean           656.8286
Q Predictions Std            224.16953
Q Predictions Max            873.4986
Q Predictions Min            -56.09969
V Predictions Mean           678.5512
V Predictions Std            200.06549
V Predictions Max            855.70386
V Predictions Min            3.5761356
Log Pis Mean                 0.92073673
Log Pis Std                  2.4640052
Log Pis Max                  10.6838255
Log Pis Min                  -5.356468
Policy mu Mean               0.3396862
Policy mu Std                1.0983589
Policy mu Max                4.4153786
Policy mu Min                -3.108445
Policy log std Mean          -0.5475695
Policy log std Std           0.2580985
Policy log std Max           0.21156973
Policy log std Min           -2.8811438
Z mean eval                  0.0022245264
Z variance eval              0.0014465958
total_rewards                [320.63516347 304.94810984 313.58325885 308.16812927 326.14450077
 297.06712205 329.32156488 317.74407275 311.96845808 317.1871262 ]
total_rewards_mean           314.6767506157831
total_rewards_std            9.234886068871921
total_rewards_max            329.32156488298193
total_rewards_min            297.0671220465824
Number of train steps total  108000
Number of env steps total    151338
Number of rollouts total     0
Train Time (s)               139.12797356490046
(Previous) Eval Time (s)     3.5163966179825366
Sample Time (s)              5.076637709047645
Epoch Time (s)               147.72100789193064
Total Train Time (s)         3649.428762635216
Epoch                        26
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 09:31:35.486056 UTC | [2020_01_04_08_30_45] Iteration #26 | Epoch Duration: 147.8407063484192
2020-01-04 09:31:35.486343 UTC | [2020_01_04_08_30_45] Iteration #26 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0021699711
Z variance train             0.001446593
KL Divergence                13.851377
KL Loss                      1.3851377
QF Loss                      2147.4282
VF Loss                      370.28827
Policy Loss                  -684.9827
Q Predictions Mean           672.4835
Q Predictions Std            176.1221
Q Predictions Max            837.30066
Q Predictions Min            -0.10411003
V Predictions Mean           694.4428
V Predictions Std            149.563
V Predictions Max            843.66907
V Predictions Min            6.000273
Log Pis Mean                 0.25182366
Log Pis Std                  2.3603218
Log Pis Max                  11.222664
Log Pis Min                  -5.071434
Policy mu Mean               0.2550141
Policy mu Std                0.9773412
Policy mu Max                4.089944
Policy mu Min                -3.7059107
Policy log std Mean          -0.5521651
Policy log std Std           0.2696055
Policy log std Max           0.2803655
Policy log std Min           -2.5226157
Z mean eval                  0.0020030327
Z variance eval              0.0013868369
total_rewards                [327.33831477 324.87890486 313.34770807 309.31246776 329.86782949
 309.01558386 323.01748865 339.67679613 326.03046759 326.21185678]
total_rewards_mean           322.86974179566323
total_rewards_std            9.181739673033697
total_rewards_max            339.6767961303193
total_rewards_min            309.0155838628918
Number of train steps total  112000
Number of env steps total    157008
Number of rollouts total     0
Train Time (s)               138.16324582183734
(Previous) Eval Time (s)     3.635840941220522
Sample Time (s)              5.161633392330259
Epoch Time (s)               146.96072015538812
Total Train Time (s)         3796.0884150597267
Epoch                        27
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 09:34:02.148444 UTC | [2020_01_04_08_30_45] Iteration #27 | Epoch Duration: 146.6619167327881
2020-01-04 09:34:02.148607 UTC | [2020_01_04_08_30_45] Iteration #27 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.002007008
Z variance train             0.0013868315
KL Divergence                13.956459
KL Loss                      1.395646
QF Loss                      296.2116
VF Loss                      241.46497
Policy Loss                  -642.6379
Q Predictions Mean           633.1719
Q Predictions Std            190.54301
Q Predictions Max            822.3351
Q Predictions Min            10.743927
V Predictions Mean           637.03186
V Predictions Std            180.53732
V Predictions Max            825.3541
V Predictions Min            -1.5583982
Log Pis Mean                 0.32899493
Log Pis Std                  2.3559809
Log Pis Max                  13.142532
Log Pis Min                  -5.6369786
Policy mu Mean               0.21848404
Policy mu Std                1.0311698
Policy mu Max                3.7425692
Policy mu Min                -3.2856646
Policy log std Mean          -0.5168871
Policy log std Std           0.24524555
Policy log std Max           0.13265169
Policy log std Min           -2.5661044
Z mean eval                  0.00071296754
Z variance eval              0.0013429818
total_rewards                [315.19418112 336.90991536 324.66492778 335.14175408 326.93530937
 304.7670416  323.18434049 327.70848856 317.38687801 306.83100864]
total_rewards_mean           321.87238449939343
total_rewards_std            10.271174523635512
total_rewards_max            336.909915356641
total_rewards_min            304.76704160063616
Number of train steps total  116000
Number of env steps total    162808
Number of rollouts total     0
Train Time (s)               136.84846768295392
(Previous) Eval Time (s)     3.3368454203009605
Sample Time (s)              5.763359492644668
Epoch Time (s)               145.94867259589955
Total Train Time (s)         3942.149362572469
Epoch                        28
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 09:36:28.209293 UTC | [2020_01_04_08_30_45] Iteration #28 | Epoch Duration: 146.06055521965027
2020-01-04 09:36:28.209467 UTC | [2020_01_04_08_30_45] Iteration #28 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.00076902297
Z variance train             0.001343058
KL Divergence                14.036883
KL Loss                      1.4036883
QF Loss                      199.38272
VF Loss                      217.02791
Policy Loss                  -647.8022
Q Predictions Mean           632.6533
Q Predictions Std            184.29488
Q Predictions Max            786.484
Q Predictions Min            -6.0439677
V Predictions Mean           643.9678
V Predictions Std            165.91791
V Predictions Max            791.87823
V Predictions Min            10.625779
Log Pis Mean                 0.051267546
Log Pis Std                  2.0473745
Log Pis Max                  9.872009
Log Pis Min                  -4.966882
Policy mu Mean               0.34472537
Policy mu Std                0.90928614
Policy mu Max                3.5779583
Policy mu Min                -2.967704
Policy log std Mean          -0.5454946
Policy log std Std           0.25290355
Policy log std Max           0.19476959
Policy log std Min           -1.8854666
Z mean eval                  0.0015002757
Z variance eval              0.0012844645
total_rewards                [305.82221076 309.67231657 324.32540515 311.82376126 326.54737105
 316.91239621 384.77818955 332.50020897 321.62603102 402.83959123]
total_rewards_mean           333.6847481766428
total_rewards_std            31.289646399743745
total_rewards_max            402.8395912257266
total_rewards_min            305.8222107559805
Number of train steps total  120000
Number of env steps total    168513
Number of rollouts total     0
Train Time (s)               134.4249226427637
(Previous) Eval Time (s)     3.4484973098151386
Sample Time (s)              5.848919101059437
Epoch Time (s)               143.72233905363828
Total Train Time (s)         4085.947174373083
Epoch                        29
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 09:38:52.008095 UTC | [2020_01_04_08_30_45] Iteration #29 | Epoch Duration: 143.79849433898926
2020-01-04 09:38:52.008261 UTC | [2020_01_04_08_30_45] Iteration #29 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0014982466
Z variance train             0.0012845068
KL Divergence                14.148363
KL Loss                      1.4148363
QF Loss                      256.31653
VF Loss                      286.23596
Policy Loss                  -628.63153
Q Predictions Mean           621.2423
Q Predictions Std            182.9585
Q Predictions Max            788.6785
Q Predictions Min            -20.52194
V Predictions Mean           626.412
V Predictions Std            171.50911
V Predictions Max            772.653
V Predictions Min            -0.45366216
Log Pis Mean                 0.25321072
Log Pis Std                  2.221564
Log Pis Max                  15.195499
Log Pis Min                  -6.918034
Policy mu Mean               0.4311339
Policy mu Std                0.89277565
Policy mu Max                3.9177222
Policy mu Min                -3.7036207
Policy log std Mean          -0.5172615
Policy log std Std           0.24001455
Policy log std Max           0.1635058
Policy log std Min           -1.726698
Z mean eval                  0.0012741274
Z variance eval              0.0012325264
total_rewards                [318.12253127 343.14501332 338.90767419 411.87922312 369.24765917
 332.33672002 348.13098526 313.75427175 367.90748291 282.78410022]
total_rewards_mean           342.6215661231156
total_rewards_std            33.62914500739891
total_rewards_max            411.8792231176957
total_rewards_min            282.7841002172148
Number of train steps total  124000
Number of env steps total    174401
Number of rollouts total     0
Train Time (s)               135.52471390506253
(Previous) Eval Time (s)     3.524431973695755
Sample Time (s)              5.816408897284418
Epoch Time (s)               144.8655547760427
Total Train Time (s)         4230.921500736382
Epoch                        30
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 09:41:16.984654 UTC | [2020_01_04_08_30_45] Iteration #30 | Epoch Duration: 144.97624921798706
2020-01-04 09:41:16.984841 UTC | [2020_01_04_08_30_45] Iteration #30 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0012992816
Z variance train             0.0012324741
KL Divergence                14.252061
KL Loss                      1.4252061
QF Loss                      380.47263
VF Loss                      81.74159
Policy Loss                  -606.3504
Q Predictions Mean           589.6793
Q Predictions Std            199.96515
Q Predictions Max            771.3964
Q Predictions Min            -15.410613
V Predictions Mean           607.9441
V Predictions Std            187.84482
V Predictions Max            781.31903
V Predictions Min            -1.3769164
Log Pis Mean                 -0.24512246
Log Pis Std                  2.1073086
Log Pis Max                  10.448075
Log Pis Min                  -5.689063
Policy mu Mean               0.27811792
Policy mu Std                0.8323229
Policy mu Max                3.5199907
Policy mu Min                -2.9613934
Policy log std Mean          -0.5023182
Policy log std Std           0.23169513
Policy log std Max           0.20287907
Policy log std Min           -1.8764051
Z mean eval                  0.0009688411
Z variance eval              0.0011817805
total_rewards                [277.73082754 515.20513965 502.1186057  273.60543696 303.75375043
 403.06593475 306.89465122 306.49763666 281.50288039 426.32952462]
total_rewards_mean           359.670438790801
total_rewards_std            89.31958604625468
total_rewards_max            515.2051396461001
total_rewards_min            273.60543695834025
Number of train steps total  128000
Number of env steps total    179921
Number of rollouts total     0
Train Time (s)               137.73260108334944
(Previous) Eval Time (s)     3.634928216226399
Sample Time (s)              5.504146000370383
Epoch Time (s)               146.87167529994622
Total Train Time (s)         4377.747898691334
Epoch                        31
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 09:43:43.812088 UTC | [2020_01_04_08_30_45] Iteration #31 | Epoch Duration: 146.82708859443665
2020-01-04 09:43:43.812281 UTC | [2020_01_04_08_30_45] Iteration #31 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.000965339
Z variance train             0.0011817899
KL Divergence                14.35705
KL Loss                      1.4357051
QF Loss                      377.36163
VF Loss                      67.52704
Policy Loss                  -623.4219
Q Predictions Mean           613.6829
Q Predictions Std            183.03531
Q Predictions Max            766.31494
Q Predictions Min            9.40666
V Predictions Mean           619.3898
V Predictions Std            178.05759
V Predictions Max            761.4482
V Predictions Min            1.1746222
Log Pis Mean                 0.20737168
Log Pis Std                  2.1196475
Log Pis Max                  12.27792
Log Pis Min                  -4.5945835
Policy mu Mean               0.30203494
Policy mu Std                0.9280814
Policy mu Max                3.8668234
Policy mu Min                -2.8728151
Policy log std Mean          -0.4869074
Policy log std Std           0.23514763
Policy log std Max           0.23828658
Policy log std Min           -1.5932974
Z mean eval                  0.00063786394
Z variance eval              0.0011383826
total_rewards                [478.79799241 472.19735083 445.5232556  392.12380752 384.02264555
 414.64492755 490.70648652 448.71459536 463.26506068 488.85699842]
total_rewards_mean           447.88531204429
total_rewards_std            36.87073841790863
total_rewards_max            490.70648652308756
total_rewards_min            384.0226455453984
Number of train steps total  132000
Number of env steps total    185804
Number of rollouts total     0
Train Time (s)               136.48034015810117
(Previous) Eval Time (s)     3.5901039531454444
Sample Time (s)              5.960316502023488
Epoch Time (s)               146.0307606132701
Total Train Time (s)         4524.193664854392
Epoch                        32
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 09:46:10.260598 UTC | [2020_01_04_08_30_45] Iteration #32 | Epoch Duration: 146.44816851615906
2020-01-04 09:46:10.260757 UTC | [2020_01_04_08_30_45] Iteration #32 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0006368801
Z variance train             0.0011383832
KL Divergence                14.450414
KL Loss                      1.4450414
QF Loss                      121.5045
VF Loss                      226.90704
Policy Loss                  -626.5398
Q Predictions Mean           622.33264
Q Predictions Std            160.8579
Q Predictions Max            769.765
Q Predictions Min            2.4901848
V Predictions Mean           623.8723
V Predictions Std            151.48665
V Predictions Max            766.19745
V Predictions Min            0.25496215
Log Pis Mean                 0.061400194
Log Pis Std                  1.96139
Log Pis Max                  8.851289
Log Pis Min                  -5.181514
Policy mu Mean               0.22690694
Policy mu Std                0.9207982
Policy mu Max                3.8553536
Policy mu Min                -3.3477948
Policy log std Mean          -0.50293416
Policy log std Std           0.23067501
Policy log std Max           0.15107548
Policy log std Min           -1.9992495
Z mean eval                  0.0014849885
Z variance eval              0.0010941286
total_rewards                [324.63618585 455.78445433 571.80373456 485.65818871 526.02791508
 480.91303668 510.40459782 461.56172542 548.36028133 455.42827832]
total_rewards_mean           482.0578398103727
total_rewards_std            64.65493858946512
total_rewards_max            571.8037345570896
total_rewards_min            324.63618585387974
Number of train steps total  136000
Number of env steps total    191798
Number of rollouts total     0
Train Time (s)               139.34913107194006
(Previous) Eval Time (s)     4.007322644349188
Sample Time (s)              5.9157292898744345
Epoch Time (s)               149.2721830061637
Total Train Time (s)         4673.64281134028
Epoch                        33
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 09:48:39.710407 UTC | [2020_01_04_08_30_45] Iteration #33 | Epoch Duration: 149.4495198726654
2020-01-04 09:48:39.710581 UTC | [2020_01_04_08_30_45] Iteration #33 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0014804943
Z variance train             0.0010941217
KL Divergence                14.548713
KL Loss                      1.4548713
QF Loss                      132.82297
VF Loss                      208.48634
Policy Loss                  -613.9178
Q Predictions Mean           613.65656
Q Predictions Std            169.56372
Q Predictions Max            756.80927
Q Predictions Min            18.89602
V Predictions Mean           612.1621
V Predictions Std            171.04153
V Predictions Max            753.2982
V Predictions Min            1.2669519
Log Pis Mean                 0.0008114502
Log Pis Std                  2.2157886
Log Pis Max                  12.5375
Log Pis Min                  -5.6785293
Policy mu Mean               0.28797492
Policy mu Std                0.93231285
Policy mu Max                4.1977267
Policy mu Min                -3.4789348
Policy log std Mean          -0.5211692
Policy log std Std           0.21522568
Policy log std Max           0.18717304
Policy log std Min           -1.6812457
Z mean eval                  0.0016042627
Z variance eval              0.0010582531
total_rewards                [430.93918483 314.24075908 525.41878142 499.67520183 497.03118169
 538.35051451 558.76005505 503.24270954 567.00422204 491.51107087]
total_rewards_mean           492.6173680856262
total_rewards_std            69.91533590865754
total_rewards_max            567.004222044539
total_rewards_min            314.24075907739973
Number of train steps total  140000
Number of env steps total    198008
Number of rollouts total     0
Train Time (s)               136.17751912074164
(Previous) Eval Time (s)     4.184450353030115
Sample Time (s)              5.413245444186032
Epoch Time (s)               145.77521491795778
Total Train Time (s)         4819.436792336404
Epoch                        34
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 09:51:05.507259 UTC | [2020_01_04_08_30_45] Iteration #34 | Epoch Duration: 145.7965214252472
2020-01-04 09:51:05.507487 UTC | [2020_01_04_08_30_45] Iteration #34 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0016133117
Z variance train             0.0010582164
KL Divergence                14.632326
KL Loss                      1.4632326
QF Loss                      604.3694
VF Loss                      94.02086
Policy Loss                  -638.0864
Q Predictions Mean           629.2302
Q Predictions Std            175.47751
Q Predictions Max            777.0586
Q Predictions Min            -19.34313
V Predictions Mean           638.51886
V Predictions Std            162.22092
V Predictions Max            780.1609
V Predictions Min            -2.746985
Log Pis Mean                 -0.011083659
Log Pis Std                  2.0854075
Log Pis Max                  8.900236
Log Pis Min                  -5.649732
Policy mu Mean               0.2669337
Policy mu Std                0.8949895
Policy mu Max                3.318031
Policy mu Min                -2.3534043
Policy log std Mean          -0.4973472
Policy log std Std           0.2313804
Policy log std Max           0.16441298
Policy log std Min           -1.7128644
Z mean eval                  0.0018625908
Z variance eval              0.0010236577
total_rewards                [479.58073333 361.70389309 272.28160521 351.67711678 435.76458868
 498.43503078 498.62721473 494.56833318 463.38062883 459.99912474]
total_rewards_mean           431.6018269351701
total_rewards_std            73.29125252723017
total_rewards_max            498.62721473337876
total_rewards_min            272.2816052091465
Number of train steps total  144000
Number of env steps total    204370
Number of rollouts total     0
Train Time (s)               136.3225672179833
(Previous) Eval Time (s)     4.205544182099402
Sample Time (s)              5.444646405056119
Epoch Time (s)               145.97275780513883
Total Train Time (s)         4965.327754682396
Epoch                        35
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 09:53:31.401648 UTC | [2020_01_04_08_30_45] Iteration #35 | Epoch Duration: 145.89385771751404
2020-01-04 09:53:31.402040 UTC | [2020_01_04_08_30_45] Iteration #35 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0018598111
Z variance train             0.001023641
KL Divergence                14.715146
KL Loss                      1.4715146
QF Loss                      235.99666
VF Loss                      78.013245
Policy Loss                  -623.95184
Q Predictions Mean           627.9217
Q Predictions Std            189.67705
Q Predictions Max            775.5374
Q Predictions Min            1.5244002
V Predictions Mean           620.3982
V Predictions Std            185.00899
V Predictions Max            759.30963
V Predictions Min            0.27531534
Log Pis Mean                 0.21041496
Log Pis Std                  2.2390928
Log Pis Max                  14.105211
Log Pis Min                  -5.44747
Policy mu Mean               0.3495369
Policy mu Std                0.9164533
Policy mu Max                3.6284256
Policy mu Min                -3.4879198
Policy log std Mean          -0.4857321
Policy log std Std           0.23445083
Policy log std Max           0.226713
Policy log std Min           -1.1833752
Z mean eval                  0.0023914902
Z variance eval              0.0009893008
total_rewards                [321.24006408 627.98211645 561.79427967 484.70117023 565.18688197
 635.96036411 676.54522266 527.89756285 527.74862138 441.67060744]
total_rewards_mean           537.0726890834562
total_rewards_std            98.74037934366042
total_rewards_max            676.5452226633845
total_rewards_min            321.2400640752008
Number of train steps total  148000
Number of env steps total    210457
Number of rollouts total     0
Train Time (s)               135.78205729322508
(Previous) Eval Time (s)     4.126444438006729
Sample Time (s)              5.059848248958588
Epoch Time (s)               144.9683499801904
Total Train Time (s)         5110.687295282725
Epoch                        36
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 09:55:56.760284 UTC | [2020_01_04_08_30_45] Iteration #36 | Epoch Duration: 145.35803246498108
2020-01-04 09:55:56.760431 UTC | [2020_01_04_08_30_45] Iteration #36 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0023716392
Z variance train             0.0009892901
KL Divergence                14.79998
KL Loss                      1.479998
QF Loss                      385.11264
VF Loss                      166.73862
Policy Loss                  -634.2405
Q Predictions Mean           630.2333
Q Predictions Std            181.93977
Q Predictions Max            785.34564
Q Predictions Min            -98.19072
V Predictions Mean           637.48816
V Predictions Std            175.6609
V Predictions Max            783.02637
V Predictions Min            -62.46957
Log Pis Mean                 0.29124796
Log Pis Std                  2.2003546
Log Pis Max                  9.675011
Log Pis Min                  -7.0206723
Policy mu Mean               0.39137563
Policy mu Std                0.92764115
Policy mu Max                3.2043853
Policy mu Min                -2.6909595
Policy log std Mean          -0.52973384
Policy log std Std           0.23979808
Policy log std Max           0.31223255
Policy log std Min           -1.8947225
Z mean eval                  0.0020087515
Z variance eval              0.0009503742
total_rewards                [192.87183259 345.77442249 699.05438186 526.88835352 710.11048894
 452.20905391 169.4582169  367.24496536 181.38505696 743.00464812]
total_rewards_mean           438.8001420651496
total_rewards_std            213.27999132020446
total_rewards_max            743.0046481194375
total_rewards_min            169.45821690017704
Number of train steps total  152000
Number of env steps total    216791
Number of rollouts total     0
Train Time (s)               138.41786924237385
(Previous) Eval Time (s)     4.515976014081389
Sample Time (s)              6.121761211659759
Epoch Time (s)               149.055606468115
Total Train Time (s)         5259.200639680494
Epoch                        37
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 09:58:25.275601 UTC | [2020_01_04_08_30_45] Iteration #37 | Epoch Duration: 148.5150384902954
2020-01-04 09:58:25.275801 UTC | [2020_01_04_08_30_45] Iteration #37 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0020166882
Z variance train             0.0009503954
KL Divergence                14.899753
KL Loss                      1.4899753
QF Loss                      98.798416
VF Loss                      71.19174
Policy Loss                  -665.98016
Q Predictions Mean           655.2655
Q Predictions Std            180.2158
Q Predictions Max            853.9882
Q Predictions Min            4.6218104
V Predictions Mean           664.94104
V Predictions Std            157.59633
V Predictions Max            829.90924
V Predictions Min            0.7842291
Log Pis Mean                 0.069188625
Log Pis Std                  2.1958988
Log Pis Max                  9.151672
Log Pis Min                  -5.3872237
Policy mu Mean               0.2596334
Policy mu Std                0.968543
Policy mu Max                3.237075
Policy mu Min                -2.749542
Policy log std Mean          -0.46580234
Policy log std Std           0.21830814
Policy log std Max           0.3437022
Policy log std Min           -2.0213633
Z mean eval                  0.0017207989
Z variance eval              0.0009184281
total_rewards                [ 508.96410227  530.06456137  612.07626088  547.9073579   622.04721484
 1030.98147909  693.53167488  573.07834406  684.59874127  584.73891486]
total_rewards_mean           638.7988651414018
total_rewards_std            142.85600191638918
total_rewards_max            1030.9814790886755
total_rewards_min            508.9641022664979
Number of train steps total  156000
Number of env steps total    222773
Number of rollouts total     0
Train Time (s)               138.19209937844425
(Previous) Eval Time (s)     3.975167474709451
Sample Time (s)              4.976373846177012
Epoch Time (s)               147.14364069933072
Total Train Time (s)         5407.582332023885
Epoch                        38
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 10:00:53.659791 UTC | [2020_01_04_08_30_45] Iteration #38 | Epoch Duration: 148.38374018669128
2020-01-04 10:00:53.660125 UTC | [2020_01_04_08_30_45] Iteration #38 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0017272802
Z variance train             0.00091847905
KL Divergence                14.98522
KL Loss                      1.498522
QF Loss                      1194.8143
VF Loss                      67.4383
Policy Loss                  -690.09174
Q Predictions Mean           681.0019
Q Predictions Std            173.05814
Q Predictions Max            874.3061
Q Predictions Min            -10.095401
V Predictions Mean           687.5429
V Predictions Std            160.26912
V Predictions Max            868.32465
V Predictions Min            -0.33630854
Log Pis Mean                 0.15154386
Log Pis Std                  2.2179563
Log Pis Max                  10.448373
Log Pis Min                  -9.313967
Policy mu Mean               0.295715
Policy mu Std                0.9412526
Policy mu Max                3.4930947
Policy mu Min                -2.4975657
Policy log std Mean          -0.5034997
Policy log std Std           0.2172249
Policy log std Max           0.3403902
Policy log std Min           -1.9309958
Z mean eval                  0.0014556716
Z variance eval              0.0008784691
total_rewards                [798.09700523 431.75689792 620.20958649 610.02269213 655.02480468
 599.42346906 569.43556146 655.92113032 524.79422349 552.50299433]
total_rewards_mean           601.7188365105185
total_rewards_std            91.12013840879541
total_rewards_max            798.0970052252646
total_rewards_min            431.75689792218253
Number of train steps total  160000
Number of env steps total    229053
Number of rollouts total     0
Train Time (s)               136.83776648296043
(Previous) Eval Time (s)     5.215075490064919
Sample Time (s)              5.188633285928518
Epoch Time (s)               147.24147525895387
Total Train Time (s)         5554.532780076843
Epoch                        39
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 10:03:20.609508 UTC | [2020_01_04_08_30_45] Iteration #39 | Epoch Duration: 146.94921040534973
2020-01-04 10:03:20.609633 UTC | [2020_01_04_08_30_45] Iteration #39 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0014886478
Z variance train             0.0008784888
KL Divergence                15.09567
KL Loss                      1.509567
QF Loss                      158.5426
VF Loss                      45.99846
Policy Loss                  -691.8932
Q Predictions Mean           684.3964
Q Predictions Std            188.1585
Q Predictions Max            985.2442
Q Predictions Min            -9.217572
V Predictions Mean           692.49133
V Predictions Std            174.96762
V Predictions Max            969.0012
V Predictions Min            10.440262
Log Pis Mean                 0.29537013
Log Pis Std                  2.0296066
Log Pis Max                  10.525116
Log Pis Min                  -5.9487386
Policy mu Mean               0.32019907
Policy mu Std                0.9867445
Policy mu Max                3.5919743
Policy mu Min                -2.8411822
Policy log std Mean          -0.51490855
Policy log std Std           0.22297873
Policy log std Max           0.1978342
Policy log std Min           -1.5034877
Z mean eval                  0.0015567091
Z variance eval              0.0008526721
total_rewards                [ 484.6180337   659.59937536  652.55226524 2279.38426317  607.76338244
  640.16809187 1575.68581986 1971.01315948  460.75185079  708.17880557]
total_rewards_mean           1003.971504749152
total_rewards_std            638.1563217950232
total_rewards_max            2279.384263173147
total_rewards_min            460.7518507928485
Number of train steps total  164000
Number of env steps total    235457
Number of rollouts total     0
Train Time (s)               138.22326884185895
(Previous) Eval Time (s)     4.922646830324084
Sample Time (s)              5.504866669420153
Epoch Time (s)               148.6507823416032
Total Train Time (s)         5707.470473943744
Epoch                        40
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 10:05:53.551043 UTC | [2020_01_04_08_30_45] Iteration #40 | Epoch Duration: 152.9411609172821
2020-01-04 10:05:53.551469 UTC | [2020_01_04_08_30_45] Iteration #40 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0015753489
Z variance train             0.00085265003
KL Divergence                15.170607
KL Loss                      1.5170606
QF Loss                      218.81139
VF Loss                      70.86569
Policy Loss                  -719.38434
Q Predictions Mean           713.36145
Q Predictions Std            199.05669
Q Predictions Max            995.89056
Q Predictions Min            3.7275426
V Predictions Mean           721.1527
V Predictions Std            183.58452
V Predictions Max            967.2516
V Predictions Min            -1.7155284
Log Pis Mean                 0.40725285
Log Pis Std                  2.2834725
Log Pis Max                  12.133104
Log Pis Min                  -5.026899
Policy mu Mean               0.30592436
Policy mu Std                1.0040021
Policy mu Max                3.6655238
Policy mu Min                -3.4221091
Policy log std Mean          -0.5182126
Policy log std Std           0.20820579
Policy log std Max           0.32476962
Policy log std Min           -1.6964535
Z mean eval                  0.0019948226
Z variance eval              0.00082406605
total_rewards                [ 802.72401992  681.49271276  766.97679456  817.62299275  589.1536219
 1774.51971701  733.01156319  966.18824446 2666.90909138  566.41271676]
total_rewards_mean           1036.501147469
total_rewards_std            634.2151057395785
total_rewards_max            2666.909091384041
total_rewards_min            566.4127167598152
Number of train steps total  168000
Number of env steps total    240858
Number of rollouts total     0
Train Time (s)               138.27545277914032
(Previous) Eval Time (s)     9.21280161337927
Sample Time (s)              5.231956980191171
Epoch Time (s)               152.72021137271076
Total Train Time (s)         5859.377090479713
Epoch                        41
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 10:08:25.458841 UTC | [2020_01_04_08_30_45] Iteration #41 | Epoch Duration: 151.90712809562683
2020-01-04 10:08:25.459050 UTC | [2020_01_04_08_30_45] Iteration #41 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0019707996
Z variance train             0.00082406343
KL Divergence                15.25577
KL Loss                      1.525577
QF Loss                      224.26225
VF Loss                      62.926918
Policy Loss                  -733.506
Q Predictions Mean           732.3784
Q Predictions Std            214.29317
Q Predictions Max            1036.2622
Q Predictions Min            -21.223526
V Predictions Mean           732.2
V Predictions Std            210.95995
V Predictions Max            1032.0264
V Predictions Min            -27.615519
Log Pis Mean                 0.41438076
Log Pis Std                  2.1532652
Log Pis Max                  11.637996
Log Pis Min                  -5.1641307
Policy mu Mean               0.3086621
Policy mu Std                1.0110509
Policy mu Max                3.0112004
Policy mu Min                -3.17658
Policy log std Mean          -0.55079067
Policy log std Std           0.23038465
Policy log std Max           0.14285612
Policy log std Min           -1.2430061
Z mean eval                  0.0013401357
Z variance eval              0.00079511234
total_rewards                [ 910.42843826  817.94823414  949.97017814 2526.21272724 2104.30213279
  605.69976418 1003.23247882 2484.42207152 2498.34010461 1409.12236724]
total_rewards_mean           1530.9678496963356
total_rewards_std            744.6210445687578
total_rewards_max            2526.212727238028
total_rewards_min            605.69976418398
Number of train steps total  172000
Number of env steps total    246023
Number of rollouts total     0
Train Time (s)               139.0142543190159
(Previous) Eval Time (s)     8.399559427052736
Sample Time (s)              5.156830343417823
Epoch Time (s)               152.57064408948645
Total Train Time (s)         6017.19124023756
Epoch                        42
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 10:11:03.276934 UTC | [2020_01_04_08_30_45] Iteration #42 | Epoch Duration: 157.8177399635315
2020-01-04 10:11:03.277059 UTC | [2020_01_04_08_30_45] Iteration #42 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0012913181
Z variance train             0.0007950656
KL Divergence                15.345163
KL Loss                      1.5345163
QF Loss                      1175.801
VF Loss                      127.569954
Policy Loss                  -761.1783
Q Predictions Mean           748.8334
Q Predictions Std            220.7539
Q Predictions Max            1115.3527
Q Predictions Min            -9.149825
V Predictions Mean           758.4611
V Predictions Std            209.37602
V Predictions Max            1105.0698
V Predictions Min            -33.996716
Log Pis Mean                 0.51294506
Log Pis Std                  2.1838112
Log Pis Max                  10.174341
Log Pis Min                  -4.0092616
Policy mu Mean               0.27074024
Policy mu Std                0.99794096
Policy mu Max                3.9283097
Policy mu Min                -2.8142874
Policy log std Mean          -0.5395569
Policy log std Std           0.20375632
Policy log std Max           0.18831289
Policy log std Min           -1.2935011
Z mean eval                  0.001685683
Z variance eval              0.00077016826
total_rewards                [1034.27573568  718.78577988  665.80475647  619.66368197  500.81793926
 2431.2618581  1675.78399172  905.40054702  750.7869888  1219.39510658]
total_rewards_mean           1052.1976385465164
total_rewards_std            564.1737443816893
total_rewards_max            2431.2618580984235
total_rewards_min            500.8179392615695
Number of train steps total  176000
Number of env steps total    251661
Number of rollouts total     0
Train Time (s)               137.13203980401158
(Previous) Eval Time (s)     13.646422893274575
Sample Time (s)              4.813928318675607
Epoch Time (s)               155.59239101596177
Total Train Time (s)         6169.108144360594
Epoch                        43
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 10:13:35.193531 UTC | [2020_01_04_08_30_45] Iteration #43 | Epoch Duration: 151.9163680076599
2020-01-04 10:13:35.193703 UTC | [2020_01_04_08_30_45] Iteration #43 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0016972339
Z variance train             0.0007701599
KL Divergence                15.425072
KL Loss                      1.5425072
QF Loss                      1036.5674
VF Loss                      251.05792
Policy Loss                  -764.91907
Q Predictions Mean           750.96136
Q Predictions Std            250.07318
Q Predictions Max            1079.4633
Q Predictions Min            -56.936375
V Predictions Mean           771.8599
V Predictions Std            234.83942
V Predictions Max            1116.39
V Predictions Min            2.2025383
Log Pis Mean                 0.67352563
Log Pis Std                  2.6151633
Log Pis Max                  21.723518
Log Pis Min                  -5.1252594
Policy mu Mean               0.24056284
Policy mu Std                1.0785235
Policy mu Max                4.2350693
Policy mu Min                -6.1533084
Policy log std Mean          -0.5827431
Policy log std Std           0.20451057
Policy log std Max           0.24973342
Policy log std Min           -1.8857963
Z mean eval                  0.0019739047
Z variance eval              0.0007405962
total_rewards                [1163.88188567  928.7407451   698.37732008  673.10641134 1570.49890864
  911.17097702  619.87397743  724.85428068  847.39060248  796.99658902]
total_rewards_mean           893.48916974566
total_rewards_std            270.99553809111904
total_rewards_max            1570.4989086409314
total_rewards_min            619.8739774292577
Number of train steps total  180000
Number of env steps total    257015
Number of rollouts total     0
Train Time (s)               139.44022043794394
(Previous) Eval Time (s)     9.970192935783416
Sample Time (s)              5.347559427842498
Epoch Time (s)               154.75797280156985
Total Train Time (s)         6320.729326735251
Epoch                        44
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 10:16:06.815787 UTC | [2020_01_04_08_30_45] Iteration #44 | Epoch Duration: 151.62194800376892
2020-01-04 10:16:06.815945 UTC | [2020_01_04_08_30_45] Iteration #44 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0019513726
Z variance train             0.00074060075
KL Divergence                15.523075
KL Loss                      1.5523075
QF Loss                      1208.9738
VF Loss                      401.22525
Policy Loss                  -776.1869
Q Predictions Mean           774.829
Q Predictions Std            240.95146
Q Predictions Max            1098.905
Q Predictions Min            11.389591
V Predictions Mean           782.3876
V Predictions Std            225.79372
V Predictions Max            1072.3062
V Predictions Min            -0.72830325
Log Pis Mean                 0.870937
Log Pis Std                  2.8986673
Log Pis Max                  17.671656
Log Pis Min                  -6.0889378
Policy mu Mean               0.43481973
Policy mu Std                1.0851055
Policy mu Max                4.1648536
Policy mu Min                -3.5783002
Policy log std Mean          -0.5570051
Policy log std Std           0.21283522
Policy log std Max           0.10174
Policy log std Min           -1.5645218
Z mean eval                  0.002177674
Z variance eval              0.00072511646
total_rewards                [ 703.86998083  982.57669071 1177.0037478  1066.24528105  645.99856482
 1411.32496375 1310.26744924  827.63756278  862.27828004  864.94823733]
total_rewards_mean           985.2150758351115
total_rewards_std            240.6689794325966
total_rewards_max            1411.3249637452186
total_rewards_min            645.9985648173413
Number of train steps total  184000
Number of env steps total    262282
Number of rollouts total     0
Train Time (s)               140.19300393387675
(Previous) Eval Time (s)     6.833948206156492
Sample Time (s)              5.277177333831787
Epoch Time (s)               152.30412947386503
Total Train Time (s)         6474.527891118545
Epoch                        45
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 10:18:40.620005 UTC | [2020_01_04_08_30_45] Iteration #45 | Epoch Duration: 153.80370569229126
2020-01-04 10:18:40.620615 UTC | [2020_01_04_08_30_45] Iteration #45 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0022001409
Z variance train             0.0007251053
KL Divergence                15.576065
KL Loss                      1.5576066
QF Loss                      346.03003
VF Loss                      211.93991
Policy Loss                  -798.13257
Q Predictions Mean           790.26447
Q Predictions Std            248.63918
Q Predictions Max            1156.3154
Q Predictions Min            19.729622
V Predictions Mean           791.1845
V Predictions Std            236.82918
V Predictions Max            1123.6289
V Predictions Min            18.498863
Log Pis Mean                 0.78138655
Log Pis Std                  2.2386932
Log Pis Max                  12.258385
Log Pis Min                  -4.160186
Policy mu Mean               0.26168966
Policy mu Std                1.087786
Policy mu Max                3.571488
Policy mu Min                -2.592678
Policy log std Mean          -0.53676856
Policy log std Std           0.20283245
Policy log std Max           0.049912274
Policy log std Min           -1.2490332
Z mean eval                  0.0011188424
Z variance eval              0.00070458336
total_rewards                [ 816.11094487  852.016051   1288.17469447  728.61165027 1639.29074652
 1868.98227318 2274.90729038  900.01164275  969.78708198  716.32947794]
total_rewards_mean           1205.422185336293
total_rewards_std            516.8190097318188
total_rewards_max            2274.907290377456
total_rewards_min            716.3294779433274
Number of train steps total  188000
Number of env steps total    267282
Number of rollouts total     0
Train Time (s)               139.76360027398914
(Previous) Eval Time (s)     8.333276039920747
Sample Time (s)              4.397825265768915
Epoch Time (s)               152.4947015796788
Total Train Time (s)         6628.206311093643
Epoch                        46
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 10:21:14.296376 UTC | [2020_01_04_08_30_45] Iteration #46 | Epoch Duration: 153.67553162574768
2020-01-04 10:21:14.296513 UTC | [2020_01_04_08_30_45] Iteration #46 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0011356511
Z variance train             0.000704595
KL Divergence                15.647358
KL Loss                      1.5647358
QF Loss                      304.914
VF Loss                      307.00854
Policy Loss                  -814.5834
Q Predictions Mean           809.2209
Q Predictions Std            243.9549
Q Predictions Max            1155.8839
Q Predictions Min            -35.9424
V Predictions Mean           805.4625
V Predictions Std            239.14734
V Predictions Max            1130.0474
V Predictions Min            -51.994465
Log Pis Mean                 0.51083
Log Pis Std                  2.2256274
Log Pis Max                  9.081221
Log Pis Min                  -6.025952
Policy mu Mean               0.24976397
Policy mu Std                1.0273156
Policy mu Max                3.7476819
Policy mu Min                -2.6128495
Policy log std Mean          -0.55301285
Policy log std Std           0.20244922
Policy log std Max           0.14656109
Policy log std Min           -1.2197049
Z mean eval                  0.00077779597
Z variance eval              0.00068487064
total_rewards                [ 569.47757675 1870.37539169 1458.18971537 1007.76769977 1777.57091984
 1211.86582102 2357.08442894 1523.59844174  832.64344214  749.37653415]
total_rewards_mean           1335.7949971403752
total_rewards_std            536.7937878560228
total_rewards_max            2357.084428935704
total_rewards_min            569.4775767520695
Number of train steps total  192000
Number of env steps total    272334
Number of rollouts total     0
Train Time (s)               138.64808660931885
(Previous) Eval Time (s)     9.513907771091908
Sample Time (s)              4.980389500502497
Epoch Time (s)               153.14238388091326
Total Train Time (s)         6782.7559681730345
Epoch                        47
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 10:23:48.848251 UTC | [2020_01_04_08_30_45] Iteration #47 | Epoch Duration: 154.5516164302826
2020-01-04 10:23:48.848449 UTC | [2020_01_04_08_30_45] Iteration #47 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0008121675
Z variance train             0.0006848596
KL Divergence                15.7186
KL Loss                      1.5718601
QF Loss                      394.35556
VF Loss                      84.7224
Policy Loss                  -850.2071
Q Predictions Mean           835.92114
Q Predictions Std            236.69595
Q Predictions Max            1159.4294
Q Predictions Min            9.601116
V Predictions Mean           848.9678
V Predictions Std            224.57736
V Predictions Max            1166.5862
V Predictions Min            -5.472828
Log Pis Mean                 0.21268673
Log Pis Std                  2.1882534
Log Pis Max                  9.106542
Log Pis Min                  -5.5502863
Policy mu Mean               0.20751713
Policy mu Std                1.0062305
Policy mu Max                3.057602
Policy mu Min                -2.9741073
Policy log std Mean          -0.5501061
Policy log std Std           0.20022245
Policy log std Max           -0.0073004365
Policy log std Min           -1.9674228
Z mean eval                  0.0011643212
Z variance eval              0.000660798
total_rewards                [1077.56591532 2593.66990571  468.87041962  793.91510861 1300.0841105
 1356.94228848  639.31854659 1550.01482474  686.26693693 1004.44375296]
total_rewards_mean           1147.1091809454988
total_rewards_std            583.3071757442777
total_rewards_max            2593.669905706136
total_rewards_min            468.87041962410575
Number of train steps total  196000
Number of env steps total    277721
Number of rollouts total     0
Train Time (s)               136.24147518817335
(Previous) Eval Time (s)     10.922952253371477
Sample Time (s)              4.892808037344366
Epoch Time (s)               152.0572354788892
Total Train Time (s)         6932.493252604734
Epoch                        48
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 10:26:18.588600 UTC | [2020_01_04_08_30_45] Iteration #48 | Epoch Duration: 149.7399959564209
2020-01-04 10:26:18.588759 UTC | [2020_01_04_08_30_45] Iteration #48 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0011602633
Z variance train             0.00066079345
KL Divergence                15.80743
KL Loss                      1.5807431
QF Loss                      970.67224
VF Loss                      277.94836
Policy Loss                  -837.6607
Q Predictions Mean           822.97675
Q Predictions Std            256.73087
Q Predictions Max            1167.0963
Q Predictions Min            -43.420464
V Predictions Mean           833.3164
V Predictions Std            241.86964
V Predictions Max            1145.3181
V Predictions Min            1.612925
Log Pis Mean                 0.5867454
Log Pis Std                  2.4016528
Log Pis Max                  17.238785
Log Pis Min                  -5.400589
Policy mu Mean               0.17632355
Policy mu Std                1.0708468
Policy mu Max                4.609273
Policy mu Min                -3.795734
Policy log std Mean          -0.5444096
Policy log std Std           0.19477668
Policy log std Max           0.060382664
Policy log std Min           -1.272436
Z mean eval                  0.0014036918
Z variance eval              0.0006448414
total_rewards                [ 615.49645263  771.4893538  1441.04891107 1122.76147287 1142.07001856
  594.75004022 1551.44896581  952.01513236  746.44667904 1015.4085835 ]
total_rewards_mean           995.2935609866265
total_rewards_std            310.60742897667865
total_rewards_max            1551.4489658061113
total_rewards_min            594.750040222595
Number of train steps total  200000
Number of env steps total    282802
Number of rollouts total     0
Train Time (s)               136.8959599621594
(Previous) Eval Time (s)     8.605535774026066
Sample Time (s)              5.023197299800813
Epoch Time (s)               150.52469303598627
Total Train Time (s)         7082.427057937253
Epoch                        49
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 10:28:48.522451 UTC | [2020_01_04_08_30_45] Iteration #49 | Epoch Duration: 149.93355703353882
2020-01-04 10:28:48.522617 UTC | [2020_01_04_08_30_45] Iteration #49 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0013791013
Z variance train             0.0006448339
KL Divergence                15.869117
KL Loss                      1.5869117
QF Loss                      496.14725
VF Loss                      85.17498
Policy Loss                  -864.39215
Q Predictions Mean           856.7003
Q Predictions Std            252.28127
Q Predictions Max            1171.8854
Q Predictions Min            -34.803402
V Predictions Mean           867.01794
V Predictions Std            241.95032
V Predictions Max            1181.5397
V Predictions Min            -3.226679
Log Pis Mean                 0.4370889
Log Pis Std                  2.3142648
Log Pis Max                  11.014598
Log Pis Min                  -4.322321
Policy mu Mean               0.3289535
Policy mu Std                0.993847
Policy mu Max                3.5431173
Policy mu Min                -2.655472
Policy log std Mean          -0.53777635
Policy log std Std           0.20702541
Policy log std Max           0.0965001
Policy log std Min           -1.8684342
Z mean eval                  0.0011621565
Z variance eval              0.00062257925
total_rewards                [ 981.97182009 1486.25142927 1429.19947715 1067.99492654  999.18084982
  939.17274232  837.13122042  802.72210726  808.65287916  834.28481266]
total_rewards_mean           1018.6562264711995
total_rewards_std            235.65676261753907
total_rewards_max            1486.251429270615
total_rewards_min            802.7221072647221
Number of train steps total  204000
Number of env steps total    287802
Number of rollouts total     0
Train Time (s)               137.50189267890528
(Previous) Eval Time (s)     8.01415238995105
Sample Time (s)              5.07366971950978
Epoch Time (s)               150.5897147883661
Total Train Time (s)         7232.675226513296
Epoch                        50
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 10:31:18.772276 UTC | [2020_01_04_08_30_45] Iteration #50 | Epoch Duration: 150.24952220916748
2020-01-04 10:31:18.772468 UTC | [2020_01_04_08_30_45] Iteration #50 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0011840273
Z variance train             0.00062258117
KL Divergence                15.957412
KL Loss                      1.5957412
QF Loss                      166.43216
VF Loss                      46.219326
Policy Loss                  -857.3919
Q Predictions Mean           859.4846
Q Predictions Std            252.61983
Q Predictions Max            1180.0793
Q Predictions Min            -6.0672035
V Predictions Mean           859.0364
V Predictions Std            243.10057
V Predictions Max            1173.5503
V Predictions Min            2.9842343
Log Pis Mean                 0.4279511
Log Pis Std                  2.378762
Log Pis Max                  16.5696
Log Pis Min                  -5.5210357
Policy mu Mean               0.22388844
Policy mu Std                1.041203
Policy mu Max                4.4387507
Policy mu Min                -3.721686
Policy log std Mean          -0.523267
Policy log std Std           0.20236221
Policy log std Max           0.22769362
Policy log std Min           -2.0979874
Z mean eval                  0.0020454978
Z variance eval              0.00060942094
total_rewards                [665.48893435 538.19808801 541.92627898 700.18366963 609.78446725
 513.75825856 465.03353066 562.2895218  567.24396607 458.94340263]
total_rewards_mean           562.2850117932716
total_rewards_std            74.45449712984636
total_rewards_max            700.1836696329717
total_rewards_min            458.943402626449
Number of train steps total  208000
Number of env steps total    292802
Number of rollouts total     0
Train Time (s)               135.49340388085693
(Previous) Eval Time (s)     7.67375017888844
Sample Time (s)              4.722675608471036
Epoch Time (s)               147.8898296682164
Total Train Time (s)         7377.536656823475
Epoch                        51
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 10:33:43.635735 UTC | [2020_01_04_08_30_45] Iteration #51 | Epoch Duration: 144.86310386657715
2020-01-04 10:33:43.636076 UTC | [2020_01_04_08_30_45] Iteration #51 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0020270203
Z variance train             0.0006093903
KL Divergence                16.011173
KL Loss                      1.6011174
QF Loss                      751.5308
VF Loss                      166.85646
Policy Loss                  -861.57666
Q Predictions Mean           851.9938
Q Predictions Std            251.862
Q Predictions Max            1224.0382
Q Predictions Min            -19.969673
V Predictions Mean           852.8321
V Predictions Std            242.0085
V Predictions Max            1216.6881
V Predictions Min            -24.89677
Log Pis Mean                 0.7762592
Log Pis Std                  2.2667584
Log Pis Max                  10.863048
Log Pis Min                  -4.7181196
Policy mu Mean               0.091280036
Policy mu Std                1.1033825
Policy mu Max                3.872057
Policy mu Min                -2.7410731
Policy log std Mean          -0.56410843
Policy log std Std           0.20223726
Policy log std Max           0.051971376
Policy log std Min           -2.2304702
Z mean eval                  0.001143072
Z variance eval              0.00059585174
total_rewards                [1207.91382383 1341.01090392  758.31034865  837.68494078  839.0962927
 1144.94701606  826.40904347  535.15617429 1882.26575511  924.30341398]
total_rewards_mean           1029.7097712790255
total_rewards_std            362.31009293056275
total_rewards_max            1882.2657551061209
total_rewards_min            535.1561742912862
Number of train steps total  212000
Number of env steps total    298641
Number of rollouts total     0
Train Time (s)               136.1078337850049
(Previous) Eval Time (s)     4.646798508707434
Sample Time (s)              5.734062766190618
Epoch Time (s)               146.48869505990297
Total Train Time (s)         7527.2953826733865
Epoch                        52
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 10:36:13.395656 UTC | [2020_01_04_08_30_45] Iteration #52 | Epoch Duration: 149.75938415527344
2020-01-04 10:36:13.395842 UTC | [2020_01_04_08_30_45] Iteration #52 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.001144592
Z variance train             0.0005958488
KL Divergence                16.067204
KL Loss                      1.6067203
QF Loss                      288.68353
VF Loss                      156.1934
Policy Loss                  -882.6568
Q Predictions Mean           883.68896
Q Predictions Std            213.54196
Q Predictions Max            1253.3162
Q Predictions Min            -23.476677
V Predictions Mean           878.51794
V Predictions Std            208.63524
V Predictions Max            1237.4912
V Predictions Min            -23.6019
Log Pis Mean                 0.96829396
Log Pis Std                  2.4660065
Log Pis Max                  11.9134445
Log Pis Min                  -5.220407
Policy mu Mean               0.17216156
Policy mu Std                1.1732132
Policy mu Max                3.3628323
Policy mu Min                -3.62925
Policy log std Mean          -0.54611534
Policy log std Std           0.18840475
Policy log std Max           0.025327206
Policy log std Min           -1.7254338
Z mean eval                  0.002361909
Z variance eval              0.00058430684
total_rewards                [1327.99197228  569.65791647 2142.874111   1637.48442766  775.12889355
  924.00609658 1272.50947603 1592.75014453 2269.3445345   782.30542728]
total_rewards_mean           1329.4052999877326
total_rewards_std            553.2472201213313
total_rewards_max            2269.3445344950524
total_rewards_min            569.6579164688869
Number of train steps total  216000
Number of env steps total    303847
Number of rollouts total     0
Train Time (s)               137.72960833413526
(Previous) Eval Time (s)     7.917276164982468
Sample Time (s)              4.74213186185807
Epoch Time (s)               150.3890163609758
Total Train Time (s)         7680.987266472075
Epoch                        53
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 10:38:47.092108 UTC | [2020_01_04_08_30_45] Iteration #53 | Epoch Duration: 153.696106672287
2020-01-04 10:38:47.092290 UTC | [2020_01_04_08_30_45] Iteration #53 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0023407012
Z variance train             0.00058430294
KL Divergence                16.115791
KL Loss                      1.6115792
QF Loss                      3855.2988
VF Loss                      90.72963
Policy Loss                  -901.4243
Q Predictions Mean           905.5915
Q Predictions Std            213.37674
Q Predictions Max            1205.6987
Q Predictions Min            29.461039
V Predictions Mean           905.5002
V Predictions Std            207.78716
V Predictions Max            1191.5231
V Predictions Min            33.67533
Log Pis Mean                 0.13028294
Log Pis Std                  2.151434
Log Pis Max                  11.121381
Log Pis Min                  -5.259063
Policy mu Mean               0.22578688
Policy mu Std                0.9703043
Policy mu Max                3.4189975
Policy mu Min                -2.683035
Policy log std Mean          -0.54115695
Policy log std Std           0.19960538
Policy log std Max           0.012627542
Policy log std Min           -1.7601594
Z mean eval                  0.0019616233
Z variance eval              0.0005687693
total_rewards                [1439.54405144 1376.44217258  822.87086883 2867.18209857  939.89203354
 1462.35454063  762.01472348 1266.11971948 1035.66844586 2805.68035689]
total_rewards_mean           1477.7769011300697
total_rewards_std            719.4816817227992
total_rewards_max            2867.1820985670747
total_rewards_min            762.0147234789245
Number of train steps total  220000
Number of env steps total    308993
Number of rollouts total     0
Train Time (s)               136.6564841531217
(Previous) Eval Time (s)     11.224136183038354
Sample Time (s)              4.49338565999642
Epoch Time (s)               152.37400599615648
Total Train Time (s)         7834.07104963623
Epoch                        54
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 10:41:20.174868 UTC | [2020_01_04_08_30_45] Iteration #54 | Epoch Duration: 153.08243989944458
2020-01-04 10:41:20.175025 UTC | [2020_01_04_08_30_45] Iteration #54 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0019660098
Z variance train             0.00056876795
KL Divergence                16.183123
KL Loss                      1.6183122
QF Loss                      215.78964
VF Loss                      326.47577
Policy Loss                  -884.5584
Q Predictions Mean           871.37537
Q Predictions Std            261.2599
Q Predictions Max            1198.6417
Q Predictions Min            8.494102
V Predictions Mean           884.4464
V Predictions Std            243.19229
V Predictions Max            1200.4717
V Predictions Min            11.879829
Log Pis Mean                 0.25592366
Log Pis Std                  2.331299
Log Pis Max                  12.667089
Log Pis Min                  -5.698225
Policy mu Mean               0.21095343
Policy mu Std                1.0150524
Policy mu Max                4.1986575
Policy mu Min                -2.5789871
Policy log std Mean          -0.55109644
Policy log std Std           0.21254322
Policy log std Max           -0.024296641
Policy log std Min           -2.1230748
Z mean eval                  0.001491712
Z variance eval              0.00055948866
total_rewards                [ 783.42821155  658.89639974 2042.54682643  737.70561863 1139.61849401
 1155.96346174  818.96515007  836.38554405 1119.28530306 1198.92828385]
total_rewards_mean           1049.1723293114458
total_rewards_std            381.04340064448496
total_rewards_max            2042.5468264267931
total_rewards_min            658.8963997359518
Number of train steps total  224000
Number of env steps total    314189
Number of rollouts total     0
Train Time (s)               137.73127033514902
(Previous) Eval Time (s)     11.932387447915971
Sample Time (s)              4.272005954757333
Epoch Time (s)               153.93566373782232
Total Train Time (s)         7984.200177891646
Epoch                        55
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 10:43:50.308363 UTC | [2020_01_04_08_30_45] Iteration #55 | Epoch Duration: 150.13313817977905
2020-01-04 10:43:50.308660 UTC | [2020_01_04_08_30_45] Iteration #55 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.001480496
Z variance train             0.00055946945
KL Divergence                16.22489
KL Loss                      1.622489
QF Loss                      347.43634
VF Loss                      893.2952
Policy Loss                  -890.6201
Q Predictions Mean           882.4866
Q Predictions Std            253.0811
Q Predictions Max            1204.9883
Q Predictions Min            5.021069
V Predictions Mean           893.0282
V Predictions Std            242.3023
V Predictions Max            1219.8389
V Predictions Min            -12.802198
Log Pis Mean                 0.3607418
Log Pis Std                  2.5084445
Log Pis Max                  14.272945
Log Pis Min                  -5.4463882
Policy mu Mean               0.2102469
Policy mu Std                1.0252666
Policy mu Max                3.6176853
Policy mu Min                -2.8872964
Policy log std Mean          -0.54799676
Policy log std Std           0.21392678
Policy log std Max           0.035315096
Policy log std Min           -2.16009
Z mean eval                  0.0021916286
Z variance eval              0.0005492573
total_rewards                [ 996.73828764 1402.44106647 1016.75139024 1106.6923792   719.24822922
 1226.56775444 1471.31751634 1053.00159458  530.44857004  831.17865627]
total_rewards_mean           1035.4385444429697
total_rewards_std            276.61480169097035
total_rewards_max            1471.3175163426595
total_rewards_min            530.4485700369596
Number of train steps total  228000
Number of env steps total    319708
Number of rollouts total     0
Train Time (s)               136.1476895119995
(Previous) Eval Time (s)     8.129650740884244
Sample Time (s)              5.720244570635259
Epoch Time (s)               149.997584823519
Total Train Time (s)         8134.694909734186
Epoch                        56
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 10:46:20.803456 UTC | [2020_01_04_08_30_45] Iteration #56 | Epoch Duration: 150.4945731163025
2020-01-04 10:46:20.803645 UTC | [2020_01_04_08_30_45] Iteration #56 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0022208928
Z variance train             0.00054924504
KL Divergence                16.271427
KL Loss                      1.6271428
QF Loss                      512.6611
VF Loss                      393.53632
Policy Loss                  -905.2106
Q Predictions Mean           895.79626
Q Predictions Std            264.83463
Q Predictions Max            1283.4897
Q Predictions Min            -24.647495
V Predictions Mean           894.7637
V Predictions Std            241.93091
V Predictions Max            1271.2147
V Predictions Min            20.282436
Log Pis Mean                 0.55583423
Log Pis Std                  2.5457323
Log Pis Max                  13.333043
Log Pis Min                  -6.6314263
Policy mu Mean               0.2116599
Policy mu Std                1.0399089
Policy mu Max                3.7434673
Policy mu Min                -3.2846806
Policy log std Mean          -0.550847
Policy log std Std           0.20647874
Policy log std Max           0.20804691
Policy log std Min           -2.2202747
Z mean eval                  0.0014785
Z variance eval              0.00053539535
total_rewards                [1402.9462828   686.9128809   816.53861551  844.94339146  864.96154746
  592.59003281  662.66194732  578.18605459  989.23702023 1068.76880651]
total_rewards_mean           850.7746579584194
total_rewards_std            240.04063764154392
total_rewards_max            1402.9462828046924
total_rewards_min            578.1860545855502
Number of train steps total  232000
Number of env steps total    324734
Number of rollouts total     0
Train Time (s)               137.1563270590268
(Previous) Eval Time (s)     8.62644283566624
Sample Time (s)              4.783661914523691
Epoch Time (s)               150.56643180921674
Total Train Time (s)         8283.455668950453
Epoch                        57
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 10:48:49.565632 UTC | [2020_01_04_08_30_45] Iteration #57 | Epoch Duration: 148.76183319091797
2020-01-04 10:48:49.565814 UTC | [2020_01_04_08_30_45] Iteration #57 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.001462599
Z variance train             0.0005353826
KL Divergence                16.33453
KL Loss                      1.633453
QF Loss                      391.18335
VF Loss                      63.971756
Policy Loss                  -921.33307
Q Predictions Mean           907.7102
Q Predictions Std            259.74127
Q Predictions Max            1270.3262
Q Predictions Min            1.7086279
V Predictions Mean           920.1413
V Predictions Std            239.7725
V Predictions Max            1261.8334
V Predictions Min            8.725574
Log Pis Mean                 0.3354001
Log Pis Std                  2.373872
Log Pis Max                  14.288149
Log Pis Min                  -4.7665243
Policy mu Mean               0.17709674
Policy mu Std                1.0155891
Policy mu Max                3.943227
Policy mu Min                -4.226045
Policy log std Mean          -0.535156
Policy log std Std           0.21920213
Policy log std Max           0.10869342
Policy log std Min           -3.513432
Z mean eval                  0.0008036078
Z variance eval              0.00052756205
total_rewards                [1144.16595385 1132.67041052 1198.06036942  912.93614582 1398.66943495
 1001.45885967 1323.72108099 1041.90565183 1822.28285663 1074.3677237 ]
total_rewards_mean           1205.0238487374543
total_rewards_std            247.38957585265894
total_rewards_max            1822.2828566299313
total_rewards_min            912.936145817893
Number of train steps total  236000
Number of env steps total    330235
Number of rollouts total     0
Train Time (s)               137.9790904233232
(Previous) Eval Time (s)     6.821638904046267
Sample Time (s)              5.48137569334358
Epoch Time (s)               150.28210502071306
Total Train Time (s)         8436.242484392133
Epoch                        58
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 10:51:22.356100 UTC | [2020_01_04_08_30_45] Iteration #58 | Epoch Duration: 152.79002022743225
2020-01-04 10:51:22.356272 UTC | [2020_01_04_08_30_45] Iteration #58 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0008075285
Z variance train             0.00052752596
KL Divergence                16.37137
KL Loss                      1.637137
QF Loss                      451.73578
VF Loss                      368.69254
Policy Loss                  -901.53827
Q Predictions Mean           899.0232
Q Predictions Std            240.0408
Q Predictions Max            1241.4696
Q Predictions Min            30.194458
V Predictions Mean           903.1157
V Predictions Std            238.41386
V Predictions Max            1240.9366
V Predictions Min            12.670773
Log Pis Mean                 0.66355497
Log Pis Std                  2.2941844
Log Pis Max                  8.791575
Log Pis Min                  -6.272568
Policy mu Mean               0.22355385
Policy mu Std                1.0717562
Policy mu Max                3.55938
Policy mu Min                -2.462794
Policy log std Mean          -0.5673414
Policy log std Std           0.18628089
Policy log std Max           0.10676587
Policy log std Min           -1.208354
Z mean eval                  0.0014902313
Z variance eval              0.000521497
total_rewards                [ 793.53450852 1634.75184084 2882.78372581 2813.58015409 1905.95037271
 1060.315716   1421.43107883 1688.43860295 2819.94703758  999.56554089]
total_rewards_mean           1802.02985782451
total_rewards_std            750.6736867460877
total_rewards_max            2882.7837258124728
total_rewards_min            793.534508523507
Number of train steps total  240000
Number of env steps total    335414
Number of rollouts total     0
Train Time (s)               136.65490521397442
(Previous) Eval Time (s)     9.329356758855283
Sample Time (s)              4.458055859897286
Epoch Time (s)               150.44231783272699
Total Train Time (s)         8591.078890046105
Epoch                        59
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 10:53:57.191828 UTC | [2020_01_04_08_30_45] Iteration #59 | Epoch Duration: 154.83543014526367
2020-01-04 10:53:57.192007 UTC | [2020_01_04_08_30_45] Iteration #59 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0013789267
Z variance train             0.0005215246
KL Divergence                16.39957
KL Loss                      1.6399571
QF Loss                      212.4985
VF Loss                      96.4013
Policy Loss                  -944.38617
Q Predictions Mean           938.8036
Q Predictions Std            218.53456
Q Predictions Max            1244.4027
Q Predictions Min            11.950105
V Predictions Mean           944.7706
V Predictions Std            210.3268
V Predictions Max            1239.7623
V Predictions Min            7.96681
Log Pis Mean                 0.44353524
Log Pis Std                  2.1103263
Log Pis Max                  15.786731
Log Pis Min                  -6.1941175
Policy mu Mean               0.18812084
Policy mu Std                0.9666665
Policy mu Max                3.6746275
Policy mu Min                -2.8865085
Policy log std Mean          -0.56151044
Policy log std Std           0.19132188
Policy log std Max           0.08289415
Policy log std Min           -1.3251293
Z mean eval                  0.00087051577
Z variance eval              0.0005049673
total_rewards                [1186.25781538  799.48994829 1343.96450765  996.45575252  832.50261497
 1033.95197709 1243.25620689  973.56829709  974.42105777 1051.94472099]
total_rewards_mean           1043.581289864101
total_rewards_std            163.2972672000034
total_rewards_max            1343.9645076484207
total_rewards_min            799.4899482928768
Number of train steps total  244000
Number of env steps total    340582
Number of rollouts total     0
Train Time (s)               139.4289320600219
(Previous) Eval Time (s)     13.722272140905261
Sample Time (s)              5.1890362380072474
Epoch Time (s)               158.34024043893442
Total Train Time (s)         8746.88055656664
Epoch                        60
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 10:56:32.998046 UTC | [2020_01_04_08_30_45] Iteration #60 | Epoch Duration: 155.80587148666382
2020-01-04 10:56:32.998316 UTC | [2020_01_04_08_30_45] Iteration #60 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.000889545
Z variance train             0.0005049604
KL Divergence                16.480473
KL Loss                      1.6480473
QF Loss                      486.1983
VF Loss                      248.36401
Policy Loss                  -932.4863
Q Predictions Mean           927.0376
Q Predictions Std            262.4918
Q Predictions Max            1246.3657
Q Predictions Min            9.435431
V Predictions Mean           927.0387
V Predictions Std            256.03467
V Predictions Max            1247.0917
V Predictions Min            9.39841
Log Pis Mean                 0.341445
Log Pis Std                  2.313845
Log Pis Max                  16.95737
Log Pis Min                  -3.9916124
Policy mu Mean               0.12529881
Policy mu Std                1.0285091
Policy mu Max                3.8976781
Policy mu Min                -2.987001
Policy log std Mean          -0.5628707
Policy log std Std           0.1917688
Policy log std Max           0.2940179
Policy log std Min           -1.4937251
Z mean eval                  0.0016810171
Z variance eval              0.0004973437
total_rewards                [ 862.12902122 1074.15246289  844.46823081 1898.48231853  809.82714844
  877.64346186 1063.38032926 1004.31681981  854.47203969 1000.98301597]
total_rewards_mean           1028.9854848484388
total_rewards_std            303.96017990674994
total_rewards_max            1898.4823185348928
total_rewards_min            809.8271484391215
Number of train steps total  248000
Number of env steps total    345582
Number of rollouts total     0
Train Time (s)               139.55980325303972
(Previous) Eval Time (s)     11.187655694317073
Sample Time (s)              5.517048347741365
Epoch Time (s)               156.26450729509816
Total Train Time (s)         8900.350449232385
Epoch                        61
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 10:59:06.469426 UTC | [2020_01_04_08_30_45] Iteration #61 | Epoch Duration: 153.4708514213562
2020-01-04 10:59:06.469700 UTC | [2020_01_04_08_30_45] Iteration #61 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0016279265
Z variance train             0.0004973229
KL Divergence                16.518705
KL Loss                      1.6518706
QF Loss                      427.9597
VF Loss                      303.31848
Policy Loss                  -910.89325
Q Predictions Mean           904.61914
Q Predictions Std            263.42953
Q Predictions Max            1221.2122
Q Predictions Min            -5.100699
V Predictions Mean           918.4094
V Predictions Std            251.93634
V Predictions Max            1220.9128
V Predictions Min            3.1591325
Log Pis Mean                 0.34872103
Log Pis Std                  2.1312377
Log Pis Max                  6.6877394
Log Pis Min                  -6.202606
Policy mu Mean               0.3832755
Policy mu Std                0.95391786
Policy mu Max                3.362735
Policy mu Min                -2.3233206
Policy log std Mean          -0.5608123
Policy log std Std           0.20386462
Policy log std Max           0.30759895
Policy log std Min           -1.5302846
Z mean eval                  0.0014441513
Z variance eval              0.00048530038
total_rewards                [ 947.04179825  987.07461886 2021.10557244 1395.08366203 1232.50278162
 2687.37743174  943.71922481 2803.59205497 1428.38401462 1063.38291292]
total_rewards_mean           1550.9264072246901
total_rewards_std            671.6742134060374
total_rewards_max            2803.5920549702687
total_rewards_min            943.7192248090987
Number of train steps total  252000
Number of env steps total    350768
Number of rollouts total     0
Train Time (s)               141.43464246205986
(Previous) Eval Time (s)     8.393779419828206
Sample Time (s)              4.941057685762644
Epoch Time (s)               154.7694795676507
Total Train Time (s)         9060.998784132302
Epoch                        62
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 11:01:47.117553 UTC | [2020_01_04_08_30_45] Iteration #62 | Epoch Duration: 160.6477062702179
2020-01-04 11:01:47.117678 UTC | [2020_01_04_08_30_45] Iteration #62 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0014335065
Z variance train             0.00048528225
KL Divergence                16.579521
KL Loss                      1.6579522
QF Loss                      211.67459
VF Loss                      87.31574
Policy Loss                  -934.729
Q Predictions Mean           918.3246
Q Predictions Std            269.57245
Q Predictions Max            1237.7277
Q Predictions Min            2.1292815
V Predictions Mean           929.2831
V Predictions Std            249.87225
V Predictions Max            1221.4044
V Predictions Min            2.8526142
Log Pis Mean                 0.24043325
Log Pis Std                  2.172768
Log Pis Max                  9.956482
Log Pis Min                  -4.2668257
Policy mu Mean               0.1555291
Policy mu Std                0.9928633
Policy mu Max                3.378723
Policy mu Min                -3.0203304
Policy log std Mean          -0.5516877
Policy log std Std           0.23051022
Policy log std Max           0.25289673
Policy log std Min           -2.489209
Z mean eval                  0.00095658563
Z variance eval              0.00047399715
total_rewards                [ 950.69502503 1184.79878378 1065.40144627 1122.35794788 2801.25697342
  835.70983761 2788.6737181  1380.4409836  1295.00781668 1048.1217531 ]
total_rewards_mean           1447.2464285468218
total_rewards_std            689.9629684085965
total_rewards_max            2801.256973415809
total_rewards_min            835.7098376057712
Number of train steps total  256000
Number of env steps total    356123
Number of rollouts total     0
Train Time (s)               135.23985247220844
(Previous) Eval Time (s)     14.271814920008183
Sample Time (s)              5.387502093333751
Epoch Time (s)               154.89916948555037
Total Train Time (s)         9213.687169261742
Epoch                        63
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 11:04:19.809926 UTC | [2020_01_04_08_30_45] Iteration #63 | Epoch Duration: 152.69211673736572
2020-01-04 11:04:19.810190 UTC | [2020_01_04_08_30_45] Iteration #63 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0009242746
Z variance train             0.000474012
KL Divergence                16.637947
KL Loss                      1.6637948
QF Loss                      281.70056
VF Loss                      161.90628
Policy Loss                  -938.6532
Q Predictions Mean           935.57776
Q Predictions Std            259.40323
Q Predictions Max            1250.3524
Q Predictions Min            8.830956
V Predictions Mean           937.1535
V Predictions Std            250.3433
V Predictions Max            1253.3645
V Predictions Min            21.56417
Log Pis Mean                 -0.016865388
Log Pis Std                  1.9236835
Log Pis Max                  9.381135
Log Pis Min                  -5.377479
Policy mu Mean               0.14795242
Policy mu Std                0.95718443
Policy mu Max                2.484755
Policy mu Min                -3.7593212
Policy log std Mean          -0.5552419
Policy log std Std           0.18079059
Policy log std Max           0.027236402
Policy log std Min           -2.0732684
Z mean eval                  0.0011920838
Z variance eval              0.00046410077
total_rewards                [ 709.24002282  989.52147557  582.00951267 2675.85924695  819.24591497
  795.77357437  741.05418518 1766.12494887 2221.77841511 1000.32057573]
total_rewards_mean           1230.0927872249413
total_rewards_std            689.8962213587323
total_rewards_max            2675.8592469514524
total_rewards_min            582.0095126744961
Number of train steps total  260000
Number of env steps total    361123
Number of rollouts total     0
Train Time (s)               134.71018189797178
(Previous) Eval Time (s)     12.064516570884734
Sample Time (s)              4.646238344255835
Epoch Time (s)               151.42093681311235
Total Train Time (s)         9361.966804957017
Epoch                        64
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 11:06:48.090413 UTC | [2020_01_04_08_30_45] Iteration #64 | Epoch Duration: 148.2800362110138
2020-01-04 11:06:48.090574 UTC | [2020_01_04_08_30_45] Iteration #64 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0011925276
Z variance train             0.0004640962
KL Divergence                16.690907
KL Loss                      1.6690906
QF Loss                      427.19003
VF Loss                      111.91584
Policy Loss                  -934.0714
Q Predictions Mean           923.7035
Q Predictions Std            261.9536
Q Predictions Max            1255.8547
Q Predictions Min            8.436133
V Predictions Mean           931.5596
V Predictions Std            250.22168
V Predictions Max            1237.751
V Predictions Min            9.609953
Log Pis Mean                 0.22333576
Log Pis Std                  2.12369
Log Pis Max                  8.887573
Log Pis Min                  -5.828393
Policy mu Mean               0.2043808
Policy mu Std                0.96945745
Policy mu Max                3.7822633
Policy mu Min                -2.6557925
Policy log std Mean          -0.5571739
Policy log std Std           0.19462882
Policy log std Max           0.17169821
Policy log std Min           -1.7850252
Z mean eval                  0.0008171241
Z variance eval              0.00045396914
total_rewards                [ 765.55857029 1043.2918326  2202.77517818 2602.88844996 2777.79401232
 2390.93862122 2456.98422276  909.19652837 1060.34535554 2392.4339546 ]
total_rewards_mean           1860.2206725837746
total_rewards_std            764.315667608856
total_rewards_max            2777.7940123150433
total_rewards_min            765.5585702911494
Number of train steps total  264000
Number of env steps total    366245
Number of rollouts total     0
Train Time (s)               138.86739581031725
(Previous) Eval Time (s)     8.923359906766564
Sample Time (s)              4.292800105642527
Epoch Time (s)               152.08355582272634
Total Train Time (s)         9519.520373918582
Epoch                        65
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 11:09:25.645485 UTC | [2020_01_04_08_30_45] Iteration #65 | Epoch Duration: 157.55477571487427
2020-01-04 11:09:25.645646 UTC | [2020_01_04_08_30_45] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.000813987
Z variance train             0.0004539707
KL Divergence                16.746052
KL Loss                      1.6746053
QF Loss                      1470.5498
VF Loss                      112.234436
Policy Loss                  -941.6375
Q Predictions Mean           936.25946
Q Predictions Std            253.50072
Q Predictions Max            1249.2096
Q Predictions Min            57.10912
V Predictions Mean           942.0866
V Predictions Std            246.07384
V Predictions Max            1253.9438
V Predictions Min            61.21201
Log Pis Mean                 0.26764044
Log Pis Std                  2.3340044
Log Pis Max                  15.904167
Log Pis Min                  -4.4159746
Policy mu Mean               0.15398313
Policy mu Std                1.0054346
Policy mu Max                4.2557364
Policy mu Min                -3.3346977
Policy log std Mean          -0.5588233
Policy log std Std           0.18905321
Policy log std Max           0.22416085
Policy log std Min           -1.2103784
Z mean eval                  0.0016019339
Z variance eval              0.00044623096
total_rewards                [1696.79990253 1183.35396309  800.20366106  807.61671438  850.11665587
 2916.16428646  925.36798499 2853.44512011 2952.02097279 1193.95154163]
total_rewards_mean           1617.9040802897987
total_rewards_std            880.9657530441896
total_rewards_max            2952.020972787891
total_rewards_min            800.2036610560044
Number of train steps total  268000
Number of env steps total    371245
Number of rollouts total     0
Train Time (s)               138.99080485804006
(Previous) Eval Time (s)     14.394411189947277
Sample Time (s)              4.688245511148125
Epoch Time (s)               158.07346155913547
Total Train Time (s)         9676.778329301625
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 11:12:02.906753 UTC | [2020_01_04_08_30_45] Iteration #66 | Epoch Duration: 157.2609531879425
2020-01-04 11:12:02.907022 UTC | [2020_01_04_08_30_45] Iteration #66 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0016042966
Z variance train             0.00044624275
KL Divergence                16.788658
KL Loss                      1.6788658
QF Loss                      396.14148
VF Loss                      155.78157
Policy Loss                  -973.4345
Q Predictions Mean           964.1571
Q Predictions Std            237.3535
Q Predictions Max            1260.0253
Q Predictions Min            -32.250404
V Predictions Mean           975.12897
V Predictions Std            222.95047
V Predictions Max            1264.0375
V Predictions Min            -11.430027
Log Pis Mean                 0.4952449
Log Pis Std                  2.193033
Log Pis Max                  12.459291
Log Pis Min                  -6.1949186
Policy mu Mean               0.23144738
Policy mu Std                1.0431637
Policy mu Max                3.840313
Policy mu Min                -4.1265006
Policy log std Mean          -0.5628198
Policy log std Std           0.19720894
Policy log std Max           0.13424212
Policy log std Min           -2.1775317
Z mean eval                  0.0016307065
Z variance eval              0.00043873824
total_rewards                [2372.793095   1867.35278539 2703.93576023 2696.11091767 1009.66674418
 1928.1340686  2715.3256485  2733.17885863 2058.82459914 2154.20187536]
total_rewards_mean           2223.95243526891
total_rewards_std            519.3769585249131
total_rewards_max            2733.178858626237
total_rewards_min            1009.6667441818083
Number of train steps total  272000
Number of env steps total    376750
Number of rollouts total     0
Train Time (s)               138.28737747110426
(Previous) Eval Time (s)     13.581644361838698
Sample Time (s)              5.460140833631158
Epoch Time (s)               157.32916266657412
Total Train Time (s)         9840.258451744914
Epoch                        67
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 11:14:46.393514 UTC | [2020_01_04_08_30_45] Iteration #67 | Epoch Duration: 163.48626923561096
2020-01-04 11:14:46.393820 UTC | [2020_01_04_08_30_45] Iteration #67 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0016366327
Z variance train             0.00043873448
KL Divergence                16.832138
KL Loss                      1.6832138
QF Loss                      443.53082
VF Loss                      81.95377
Policy Loss                  -998.7032
Q Predictions Mean           993.995
Q Predictions Std            203.03166
Q Predictions Max            1261.2511
Q Predictions Min            20.460361
V Predictions Mean           994.84845
V Predictions Std            190.8091
V Predictions Max            1250.4536
V Predictions Min            144.5403
Log Pis Mean                 -0.07053362
Log Pis Std                  2.1587682
Log Pis Max                  14.557957
Log Pis Min                  -5.424066
Policy mu Mean               0.107815094
Policy mu Std                0.9394501
Policy mu Max                4.168562
Policy mu Min                -3.231241
Policy log std Mean          -0.5489047
Policy log std Std           0.18477003
Policy log std Max           0.060334563
Policy log std Min           -1.1768067
Z mean eval                  0.0006709714
Z variance eval              0.00043037796
total_rewards                [ 695.95227047 1021.63802135  920.79171908 1565.03600512 1070.80344557
 1047.23308749 1123.25484621 1090.85209788  881.33244608  911.50243744]
total_rewards_mean           1032.839637669624
total_rewards_std            214.5395550533003
total_rewards_max            1565.0360051228342
total_rewards_min            695.9522704686976
Number of train steps total  276000
Number of env steps total    381857
Number of rollouts total     0
Train Time (s)               132.26438750931993
(Previous) Eval Time (s)     19.738503348082304
Sample Time (s)              4.524515209253877
Epoch Time (s)               156.5274060666561
Total Train Time (s)         9984.892457481008
Epoch                        68
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 11:17:11.027209 UTC | [2020_01_04_08_30_45] Iteration #68 | Epoch Duration: 144.63318514823914
2020-01-04 11:17:11.027365 UTC | [2020_01_04_08_30_45] Iteration #68 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0006623222
Z variance train             0.00043037604
KL Divergence                16.88062
KL Loss                      1.688062
QF Loss                      503.74927
VF Loss                      86.82465
Policy Loss                  -954.1877
Q Predictions Mean           948.9109
Q Predictions Std            269.8088
Q Predictions Max            1258.9197
Q Predictions Min            -28.908775
V Predictions Mean           957.86633
V Predictions Std            262.7157
V Predictions Max            1263.269
V Predictions Min            -16.050428
Log Pis Mean                 0.09059515
Log Pis Std                  2.0631201
Log Pis Max                  7.417339
Log Pis Min                  -4.964622
Policy mu Mean               0.36866176
Policy mu Std                0.91964084
Policy mu Max                3.3457086
Policy mu Min                -2.3632903
Policy log std Mean          -0.5373781
Policy log std Std           0.2123426
Policy log std Max           0.041992426
Policy log std Min           -1.5419327
Z mean eval                  0.0008437262
Z variance eval              0.0004225703
total_rewards                [ 877.34424826 1065.13253863 1087.47300846  833.01337853  857.12930994
  834.31000894 1256.20428697 1042.09199439 1116.89450686  923.41293684]
total_rewards_mean           989.3006217812926
total_rewards_std            137.29000578697173
total_rewards_max            1256.2042869715785
total_rewards_min            833.01337852786
Number of train steps total  280000
Number of env steps total    386857
Number of rollouts total     0
Train Time (s)               135.83810076722875
(Previous) Eval Time (s)     7.844135193154216
Sample Time (s)              4.924851282034069
Epoch Time (s)               148.60708724241704
Total Train Time (s)         10135.469353595283
Epoch                        69
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 11:19:41.606472 UTC | [2020_01_04_08_30_45] Iteration #69 | Epoch Duration: 150.5789875984192
2020-01-04 11:19:41.606625 UTC | [2020_01_04_08_30_45] Iteration #69 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.00087338174
Z variance train             0.00042256247
KL Divergence                16.926723
KL Loss                      1.6926724
QF Loss                      228.89697
VF Loss                      221.54355
Policy Loss                  -966.59894
Q Predictions Mean           961.3447
Q Predictions Std            277.2288
Q Predictions Max            1271.1484
Q Predictions Min            22.377419
V Predictions Mean           970.3068
V Predictions Std            267.32397
V Predictions Max            1268.6879
V Predictions Min            9.089074
Log Pis Mean                 0.4351572
Log Pis Std                  2.2970083
Log Pis Max                  13.914379
Log Pis Min                  -6.331574
Policy mu Mean               0.24771242
Policy mu Std                0.9970712
Policy mu Max                3.676243
Policy mu Min                -2.6940107
Policy log std Mean          -0.54629225
Policy log std Std           0.18939841
Policy log std Max           0.00055378675
Policy log std Min           -2.4456854
Z mean eval                  0.0015252995
Z variance eval              0.00040995702
total_rewards                [2410.48883072 2059.95353292 1521.40723717 2677.21401125 2678.09527051
  799.72672469  782.24146238 2431.61496199 1033.83372806 2653.4618665 ]
total_rewards_mean           1904.8037626201353
total_rewards_std            754.9389550462824
total_rewards_max            2678.0952705081563
total_rewards_min            782.2414623839627
Number of train steps total  284000
Number of env steps total    391857
Number of rollouts total     0
Train Time (s)               140.88984806509688
(Previous) Eval Time (s)     9.815834277775139
Sample Time (s)              5.374349009245634
Epoch Time (s)               156.08003135211766
Total Train Time (s)         10301.864938803017
Epoch                        70
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 11:22:28.004618 UTC | [2020_01_04_08_30_45] Iteration #70 | Epoch Duration: 166.39785981178284
2020-01-04 11:22:28.004809 UTC | [2020_01_04_08_30_45] Iteration #70 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0015341423
Z variance train             0.00040995018
KL Divergence                17.002495
KL Loss                      1.7002496
QF Loss                      394.0473
VF Loss                      117.17349
Policy Loss                  -962.7202
Q Predictions Mean           957.6319
Q Predictions Std            282.13904
Q Predictions Max            1264.272
Q Predictions Min            8.520277
V Predictions Mean           967.7744
V Predictions Std            273.30896
V Predictions Max            1272.4646
V Predictions Min            6.3365555
Log Pis Mean                 0.4510061
Log Pis Std                  2.6061497
Log Pis Max                  18.507915
Log Pis Min                  -4.5551057
Policy mu Mean               0.09667709
Policy mu Std                1.0543419
Policy mu Max                4.129495
Policy mu Min                -3.3767667
Policy log std Mean          -0.5622185
Policy log std Std           0.21299122
Policy log std Max           0.15208167
Policy log std Min           -2.0532262
Z mean eval                  0.00069631747
Z variance eval              0.00039599588
total_rewards                [1000.47847118 1836.51817394 1820.10038359 1809.67652247 2498.20154541
 2851.95881955 1104.93617725 2934.17708596  813.49123245 2367.39956915]
total_rewards_mean           1903.6937980949056
total_rewards_std            720.5732322624285
total_rewards_max            2934.1770859584917
total_rewards_min            813.4912324521681
Number of train steps total  288000
Number of env steps total    396857
Number of rollouts total     0
Train Time (s)               142.04244434414431
(Previous) Eval Time (s)     20.133412869181484
Sample Time (s)              5.782429662998766
Epoch Time (s)               167.95828687632456
Total Train Time (s)         10467.402516192291
Epoch                        71
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 11:25:13.545069 UTC | [2020_01_04_08_30_45] Iteration #71 | Epoch Duration: 165.54009103775024
2020-01-04 11:25:13.545314 UTC | [2020_01_04_08_30_45] Iteration #71 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0007243352
Z variance train             0.00039599434
KL Divergence                17.08984
KL Loss                      1.708984
QF Loss                      126.592
VF Loss                      240.00607
Policy Loss                  -974.09283
Q Predictions Mean           964.09424
Q Predictions Std            262.41232
Q Predictions Max            1273.0702
Q Predictions Min            -5.678009
V Predictions Mean           975.8311
V Predictions Std            250.09126
V Predictions Max            1272.6804
V Predictions Min            21.521494
Log Pis Mean                 0.64715946
Log Pis Std                  2.287777
Log Pis Max                  11.707894
Log Pis Min                  -6.623822
Policy mu Mean               0.41808558
Policy mu Std                0.97744477
Policy mu Max                3.873822
Policy mu Min                -2.7847977
Policy log std Mean          -0.5615528
Policy log std Std           0.18351227
Policy log std Max           0.1513806
Policy log std Min           -1.4109738
Z mean eval                  0.0017870916
Z variance eval              0.0003838099
total_rewards                [1117.95818876 1042.05610522  928.21073963 1125.78902099  810.23395345
 1444.0817738  2815.05173782 1262.83120926  871.18865114 1037.24353036]
total_rewards_mean           1245.4644910422085
total_rewards_std            552.1615285639373
total_rewards_max            2815.0517378165505
total_rewards_min            810.2339534517064
Number of train steps total  292000
Number of env steps total    401857
Number of rollouts total     0
Train Time (s)               143.50268933782354
(Previous) Eval Time (s)     17.71498951781541
Sample Time (s)              5.845725305844098
Epoch Time (s)               167.06340416148305
Total Train Time (s)         10628.347990909126
Epoch                        72
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 11:27:54.490753 UTC | [2020_01_04_08_30_45] Iteration #72 | Epoch Duration: 160.94526600837708
2020-01-04 11:27:54.490903 UTC | [2020_01_04_08_30_45] Iteration #72 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0017636152
Z variance train             0.00038381168
KL Divergence                17.167515
KL Loss                      1.7167515
QF Loss                      360.71298
VF Loss                      327.1922
Policy Loss                  -971.55945
Q Predictions Mean           972.3353
Q Predictions Std            272.9638
Q Predictions Max            1294.321
Q Predictions Min            23.85712
V Predictions Mean           965.47864
V Predictions Std            267.4355
V Predictions Max            1267.7554
V Predictions Min            22.789118
Log Pis Mean                 0.2006298
Log Pis Std                  2.1940067
Log Pis Max                  6.878154
Log Pis Min                  -5.3391485
Policy mu Mean               0.29099932
Policy mu Std                0.9624904
Policy mu Max                2.6127262
Policy mu Min                -2.818984
Policy log std Mean          -0.5445317
Policy log std Std           0.19344576
Policy log std Max           0.04781443
Policy log std Min           -1.4650223
Z mean eval                  0.0010817656
Z variance eval              0.00037699862
total_rewards                [ 810.48322492 1295.33783566  841.12661655 2712.69035973 1908.90242541
  772.37528543 1555.12794524 2718.90229503 1095.9271567  1184.58212075]
total_rewards_mean           1489.5455265424962
total_rewards_std            697.7910277197241
total_rewards_max            2718.9022950298363
total_rewards_min            772.3752854329941
Number of train steps total  296000
Number of env steps total    406857
Number of rollouts total     0
Train Time (s)               144.97780950833112
(Previous) Eval Time (s)     11.596636669244617
Sample Time (s)              5.138132068794221
Epoch Time (s)               161.71257824636996
Total Train Time (s)         10794.464004123118
Epoch                        73
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 11:30:40.607658 UTC | [2020_01_04_08_30_45] Iteration #73 | Epoch Duration: 166.11665177345276
2020-01-04 11:30:40.607790 UTC | [2020_01_04_08_30_45] Iteration #73 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0010838769
Z variance train             0.0003769848
KL Divergence                17.214172
KL Loss                      1.7214173
QF Loss                      286.9437
VF Loss                      72.30626
Policy Loss                  -1013.30963
Q Predictions Mean           1008.52765
Q Predictions Std            214.8049
Q Predictions Max            1274.1877
Q Predictions Min            14.921907
V Predictions Mean           1017.20166
V Predictions Std            206.74918
V Predictions Max            1276.6877
V Predictions Min            6.4368587
Log Pis Mean                 0.112629116
Log Pis Std                  2.0889828
Log Pis Max                  7.0217752
Log Pis Min                  -5.1097775
Policy mu Mean               0.14729883
Policy mu Std                0.9614766
Policy mu Max                2.8720596
Policy mu Min                -2.5557601
Policy log std Mean          -0.54020363
Policy log std Std           0.17899345
Policy log std Max           0.1997456
Policy log std Min           -1.2473806
Z mean eval                  0.0017589286
Z variance eval              0.00037182536
total_rewards                [ 839.00318608 1007.88549759 1135.91385238 1976.36998363 1231.44476053
 1012.71592924 2747.43263314 2165.71490689 2856.22878724 2801.16783857]
total_rewards_mean           1777.3877375278848
total_rewards_std            781.6883936438711
total_rewards_max            2856.2287872350216
total_rewards_min            839.0031860841445
Number of train steps total  300000
Number of env steps total    411910
Number of rollouts total     0
Train Time (s)               143.95838361093774
(Previous) Eval Time (s)     16.000498216599226
Sample Time (s)              5.883223586715758
Epoch Time (s)               165.84210541425273
Total Train Time (s)         10961.719091203064
Epoch                        74
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 11:33:27.864153 UTC | [2020_01_04_08_30_45] Iteration #74 | Epoch Duration: 167.25626134872437
2020-01-04 11:33:27.864321 UTC | [2020_01_04_08_30_45] Iteration #74 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0017294495
Z variance train             0.00037183016
KL Divergence                17.247547
KL Loss                      1.7247547
QF Loss                      431.30768
VF Loss                      84.381226
Policy Loss                  -996.7602
Q Predictions Mean           983.7674
Q Predictions Std            256.22165
Q Predictions Max            1279.7372
Q Predictions Min            -14.748382
V Predictions Mean           995.8378
V Predictions Std            234.71283
V Predictions Max            1278.4368
V Predictions Min            36.096085
Log Pis Mean                 0.32623583
Log Pis Std                  2.2536654
Log Pis Max                  12.721237
Log Pis Min                  -4.8953757
Policy mu Mean               0.21551955
Policy mu Std                0.99404603
Policy mu Max                3.8266854
Policy mu Min                -3.7352805
Policy log std Mean          -0.5591909
Policy log std Std           0.19178216
Policy log std Max           0.16104305
Policy log std Min           -1.1740139
Z mean eval                  0.0013373777
Z variance eval              0.00036447746
total_rewards                [1019.34593969  721.55905765  851.73499325 2821.33483446  898.13860152
 2831.7114033  1389.13839927 2795.71044138 2844.00271004 2806.0973465 ]
total_rewards_mean           1897.8773727073901
total_rewards_std            935.905425950533
total_rewards_max            2844.0027100443444
total_rewards_min            721.5590576533741
Number of train steps total  304000
Number of env steps total    416910
Number of rollouts total     0
Train Time (s)               144.19167506787926
(Previous) Eval Time (s)     17.41443946491927
Sample Time (s)              5.524696356151253
Epoch Time (s)               167.13081088894978
Total Train Time (s)         11129.61179880239
Epoch                        75
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 11:36:15.760492 UTC | [2020_01_04_08_30_45] Iteration #75 | Epoch Duration: 167.89601397514343
2020-01-04 11:36:15.760666 UTC | [2020_01_04_08_30_45] Iteration #75 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0013398055
Z variance train             0.00036447583
KL Divergence                17.297203
KL Loss                      1.7297204
QF Loss                      301.50937
VF Loss                      73.2598
Policy Loss                  -993.45135
Q Predictions Mean           990.2461
Q Predictions Std            269.21088
Q Predictions Max            1275.223
Q Predictions Min            4.2362466
V Predictions Mean           995.4171
V Predictions Std            262.7715
V Predictions Max            1261.5615
V Predictions Min            12.321775
Log Pis Mean                 0.33560514
Log Pis Std                  2.267545
Log Pis Max                  18.04045
Log Pis Min                  -5.692488
Policy mu Mean               0.25010917
Policy mu Std                0.9746511
Policy mu Max                4.364185
Policy mu Min                -4.058841
Policy log std Mean          -0.52837485
Policy log std Std           0.20824715
Policy log std Max           0.3377561
Policy log std Min           -1.1469519
Z mean eval                  0.00065320986
Z variance eval              0.00036079306
total_rewards                [3034.98985264  876.68411398 2751.22327605 1378.81684748  950.25699909
  915.30245689  523.7715773  2758.74757137 2751.32194712 2769.40483099]
total_rewards_mean           1871.0519472927597
total_rewards_std            964.723655485852
total_rewards_max            3034.9898526395855
total_rewards_min            523.7715773040458
Number of train steps total  308000
Number of env steps total    421910
Number of rollouts total     0
Train Time (s)               142.80006418703124
(Previous) Eval Time (s)     18.17938183993101
Sample Time (s)              5.7676141182892025
Epoch Time (s)               166.74706014525145
Total Train Time (s)         11297.424586024135
Epoch                        76
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 11:39:03.575358 UTC | [2020_01_04_08_30_45] Iteration #76 | Epoch Duration: 167.81455945968628
2020-01-04 11:39:03.575584 UTC | [2020_01_04_08_30_45] Iteration #76 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.00069832616
Z variance train             0.00036077687
KL Divergence                17.322197
KL Loss                      1.7322197
QF Loss                      211.85599
VF Loss                      165.55003
Policy Loss                  -986.3498
Q Predictions Mean           984.7491
Q Predictions Std            268.48355
Q Predictions Max            1293.3645
Q Predictions Min            6.937531
V Predictions Mean           984.0786
V Predictions Std            262.4513
V Predictions Max            1294.9766
V Predictions Min            45.828373
Log Pis Mean                 0.071212366
Log Pis Std                  2.040704
Log Pis Max                  7.437356
Log Pis Min                  -4.677065
Policy mu Mean               0.12887579
Policy mu Std                0.97553086
Policy mu Max                2.6508024
Policy mu Min                -3.1398177
Policy log std Mean          -0.54017276
Policy log std Std           0.18969786
Policy log std Max           0.20030224
Policy log std Min           -1.3914343
Z mean eval                  0.00054687075
Z variance eval              0.00035357857
total_rewards                [1431.41935311 1718.41206957  995.96923629 1191.4663071  1266.09358304
 1827.54714989  515.41857812 1220.03499209 2731.33965607 2728.50167264]
total_rewards_mean           1562.6202597925526
total_rewards_std            678.0581284730353
total_rewards_max            2731.339656073378
total_rewards_min            515.418578119604
Number of train steps total  312000
Number of env steps total    427109
Number of rollouts total     0
Train Time (s)               142.31539337802678
(Previous) Eval Time (s)     19.246629843022674
Sample Time (s)              6.189980156719685
Epoch Time (s)               167.75200337776914
Total Train Time (s)         11461.352365430444
Epoch                        77
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 11:41:47.504695 UTC | [2020_01_04_08_30_45] Iteration #77 | Epoch Duration: 163.92894434928894
2020-01-04 11:41:47.504886 UTC | [2020_01_04_08_30_45] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0005490294
Z variance train             0.00035358605
KL Divergence                17.372574
KL Loss                      1.7372574
QF Loss                      6157.619
VF Loss                      35.535988
Policy Loss                  -1019.5346
Q Predictions Mean           1015.78564
Q Predictions Std            259.02237
Q Predictions Max            1285.0076
Q Predictions Min            4.2142324
V Predictions Mean           1019.9857
V Predictions Std            257.92786
V Predictions Max            1285.4045
V Predictions Min            26.4059
Log Pis Mean                 0.25433835
Log Pis Std                  1.837516
Log Pis Max                  5.977317
Log Pis Min                  -4.5235806
Policy mu Mean               0.120366774
Policy mu Std                0.9275361
Policy mu Max                2.549792
Policy mu Min                -2.403254
Policy log std Mean          -0.53407246
Policy log std Std           0.19014928
Policy log std Max           0.16682959
Policy log std Min           -1.7102284
Z mean eval                  0.00124904
Z variance eval              0.0003454793
total_rewards                [2855.18172742 1227.90262692 2688.34392475  826.68130501 2687.08091711
  835.07456676 2655.27832723 2654.92256002 2672.31104383 1160.68203807]
total_rewards_mean           2026.3459037125606
total_rewards_std            837.5514713171623
total_rewards_max            2855.1817274188757
total_rewards_min            826.6813050111289
Number of train steps total  316000
Number of env steps total    432109
Number of rollouts total     0
Train Time (s)               143.41535545419902
(Previous) Eval Time (s)     15.423325991723686
Sample Time (s)              5.8257922497577965
Epoch Time (s)               164.6644736956805
Total Train Time (s)         11630.360933387652
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 11:44:36.517035 UTC | [2020_01_04_08_30_45] Iteration #78 | Epoch Duration: 169.01200699806213
2020-01-04 11:44:36.517196 UTC | [2020_01_04_08_30_45] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0012380492
Z variance train             0.00034547635
KL Divergence                17.430756
KL Loss                      1.7430756
QF Loss                      119.30931
VF Loss                      84.08074
Policy Loss                  -1007.3652
Q Predictions Mean           1006.7363
Q Predictions Std            254.83023
Q Predictions Max            1289.1199
Q Predictions Min            24.038
V Predictions Mean           1004.9225
V Predictions Std            252.41576
V Predictions Max            1276.4913
V Predictions Min            22.121565
Log Pis Mean                 0.27305427
Log Pis Std                  2.0748415
Log Pis Max                  7.27603
Log Pis Min                  -5.380044
Policy mu Mean               0.23567344
Policy mu Std                0.9301991
Policy mu Max                2.3645122
Policy mu Min                -2.735461
Policy log std Mean          -0.55591947
Policy log std Std           0.18566786
Policy log std Max           0.06866008
Policy log std Min           -1.3488519
Z mean eval                  0.0009771895
Z variance eval              0.00034254446
total_rewards                [ 826.65698198 1140.67443848  825.81805047 2637.028288   1326.82545476
 2786.35879352 1328.95507242 2836.03833513  965.22660894  825.54470788]
total_rewards_mean           1549.912673157843
total_rewards_std            808.9983466148223
total_rewards_max            2836.038335126927
total_rewards_min            825.5447078763937
Number of train steps total  320000
Number of env steps total    437109
Number of rollouts total     0
Train Time (s)               142.91102106310427
(Previous) Eval Time (s)     19.770638291724026
Sample Time (s)              5.788081586360931
Epoch Time (s)               168.46974094118923
Total Train Time (s)         11795.286695589311
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 11:47:21.446618 UTC | [2020_01_04_08_30_45] Iteration #79 | Epoch Duration: 164.9292550086975
2020-01-04 11:47:21.446930 UTC | [2020_01_04_08_30_45] Iteration #79 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0010115879
Z variance train             0.00034253433
KL Divergence                17.453485
KL Loss                      1.7453486
QF Loss                      425.94434
VF Loss                      133.02493
Policy Loss                  -1011.57874
Q Predictions Mean           1004.0208
Q Predictions Std            263.36307
Q Predictions Max            1308.6675
Q Predictions Min            19.732712
V Predictions Mean           1005.78784
V Predictions Std            252.79486
V Predictions Max            1288.8684
V Predictions Min            12.492264
Log Pis Mean                 -0.06057448
Log Pis Std                  2.2226658
Log Pis Max                  9.217901
Log Pis Min                  -8.259881
Policy mu Mean               0.18914784
Policy mu Std                0.9303903
Policy mu Max                3.4468646
Policy mu Min                -2.537116
Policy log std Mean          -0.5481816
Policy log std Std           0.20805247
Policy log std Max           0.0714497
Policy log std Min           -2.5277762
Z mean eval                  0.00082335836
Z variance eval              0.00033620835
total_rewards                [ 816.16287799  855.64315705 2672.07393804 1908.09042066 1248.30970761
 2685.19348543  822.74901337 2712.21638671 2690.3146865  2699.73088208]
total_rewards_mean           1911.0484555436437
total_rewards_std            835.8162501842459
total_rewards_max            2712.21638670749
total_rewards_min            816.1628779908715
Number of train steps total  324000
Number of env steps total    442109
Number of rollouts total     0
Train Time (s)               140.5725557547994
(Previous) Eval Time (s)     16.229893502779305
Sample Time (s)              5.606750085949898
Epoch Time (s)               162.4091993435286
Total Train Time (s)         11961.594643869903
Epoch                        80
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 11:50:07.755056 UTC | [2020_01_04_08_30_45] Iteration #80 | Epoch Duration: 166.30790781974792
2020-01-04 11:50:07.755243 UTC | [2020_01_04_08_30_45] Iteration #80 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.00087429665
Z variance train             0.00033619738
KL Divergence                17.501385
KL Loss                      1.7501385
QF Loss                      203.45084
VF Loss                      122.374176
Policy Loss                  -1013.53674
Q Predictions Mean           1006.29254
Q Predictions Std            278.7029
Q Predictions Max            1307.2275
Q Predictions Min            11.928315
V Predictions Mean           1010.9858
V Predictions Std            262.73227
V Predictions Max            1300.5464
V Predictions Min            8.266026
Log Pis Mean                 0.31684512
Log Pis Std                  2.1958983
Log Pis Max                  12.518534
Log Pis Min                  -5.477021
Policy mu Mean               0.18546319
Policy mu Std                1.0036782
Policy mu Max                3.6073763
Policy mu Min                -2.75642
Policy log std Mean          -0.5414341
Policy log std Std           0.1866374
Policy log std Max           0.028958917
Policy log std Min           -1.6822939
Z mean eval                  0.0014560511
Z variance eval              0.00032892794
total_rewards                [ 964.62664576  928.59161743 1338.61643481 1050.18856012 2749.92098267
  929.77376143 1427.08955276 1907.63522418  912.14036175 1291.16245932]
total_rewards_mean           1349.9745600245783
total_rewards_std            553.5851999754045
total_rewards_max            2749.920982670217
total_rewards_min            912.1403617530108
Number of train steps total  328000
Number of env steps total    447158
Number of rollouts total     0
Train Time (s)               143.9001753339544
(Previous) Eval Time (s)     20.128380396869034
Sample Time (s)              5.861384973395616
Epoch Time (s)               169.88994070421904
Total Train Time (s)         12123.1408595643
Epoch                        81
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 11:52:49.303097 UTC | [2020_01_04_08_30_45] Iteration #81 | Epoch Duration: 161.54770612716675
2020-01-04 11:52:49.303277 UTC | [2020_01_04_08_30_45] Iteration #81 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.001472498
Z variance train             0.00032893737
KL Divergence                17.553997
KL Loss                      1.7553997
QF Loss                      216.3876
VF Loss                      86.026115
Policy Loss                  -1030.1268
Q Predictions Mean           1024.9119
Q Predictions Std            284.2167
Q Predictions Max            1313.1742
Q Predictions Min            -11.072212
V Predictions Mean           1028.7273
V Predictions Std            270.61447
V Predictions Max            1310.4589
V Predictions Min            -22.040903
Log Pis Mean                 0.26827332
Log Pis Std                  2.45736
Log Pis Max                  13.013216
Log Pis Min                  -4.78799
Policy mu Mean               0.17708956
Policy mu Std                0.9921791
Policy mu Max                4.1991415
Policy mu Min                -2.9710622
Policy log std Mean          -0.51459295
Policy log std Std           0.21889287
Policy log std Max           0.16325015
Policy log std Min           -2.7785192
Z mean eval                  0.0015444966
Z variance eval              0.00032520533
total_rewards                [2792.28330792  534.22059241 2771.05786599 2738.26571913 1225.62115511
 2757.2649918   872.63235901 2717.33719438 2739.35912089 1850.65731596]
total_rewards_mean           2099.869962259768
total_rewards_std            856.9508143053878
total_rewards_max            2792.2833079200886
total_rewards_min            534.2205924088428
Number of train steps total  332000
Number of env steps total    452323
Number of rollouts total     0
Train Time (s)               142.42007545381784
(Previous) Eval Time (s)     11.78592593409121
Sample Time (s)              6.002817573957145
Epoch Time (s)               160.2088189618662
Total Train Time (s)         12292.243236778304
Epoch                        82
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 11:55:38.406830 UTC | [2020_01_04_08_30_45] Iteration #82 | Epoch Duration: 169.1034119129181
2020-01-04 11:55:38.407007 UTC | [2020_01_04_08_30_45] Iteration #82 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0015408655
Z variance train             0.00032520315
KL Divergence                17.581688
KL Loss                      1.7581688
QF Loss                      119.937546
VF Loss                      57.003487
Policy Loss                  -1006.7281
Q Predictions Mean           1004.3689
Q Predictions Std            265.73743
Q Predictions Max            1303.2909
Q Predictions Min            9.625187
V Predictions Mean           1009.2969
V Predictions Std            264.75244
V Predictions Max            1313.289
V Predictions Min            6.713929
Log Pis Mean                 -0.05135904
Log Pis Std                  1.9895177
Log Pis Max                  7.20706
Log Pis Min                  -5.865515
Policy mu Mean               0.098391175
Policy mu Std                0.9219876
Policy mu Max                2.6226964
Policy mu Min                -2.8815007
Policy log std Mean          -0.5289528
Policy log std Std           0.18561481
Policy log std Max           0.16151941
Policy log std Min           -1.2209303
Z mean eval                  0.0013540179
Z variance eval              0.00031683705
total_rewards                [ 366.1426777   373.54089871  816.20778306 2699.18444002 1287.73985458
 1879.57228455  848.795213   2698.19200996 2711.43212124 2709.62902936]
total_rewards_mean           1639.043631215996
total_rewards_std            961.5850334964548
total_rewards_max            2711.4321212364457
total_rewards_min            366.14267769670073
Number of train steps total  336000
Number of env steps total    457671
Number of rollouts total     0
Train Time (s)               144.07226534979418
(Previous) Eval Time (s)     20.68030083924532
Sample Time (s)              6.083074208814651
Epoch Time (s)               170.83564039785415
Total Train Time (s)         12459.385857916437
Epoch                        83
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 11:58:25.552383 UTC | [2020_01_04_08_30_45] Iteration #83 | Epoch Duration: 167.14524006843567
2020-01-04 11:58:25.552572 UTC | [2020_01_04_08_30_45] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0013682198
Z variance train             0.00031683996
KL Divergence                17.646923
KL Loss                      1.7646923
QF Loss                      597.07434
VF Loss                      342.74976
Policy Loss                  -1031.0405
Q Predictions Mean           1021.7524
Q Predictions Std            284.51242
Q Predictions Max            1316.1012
Q Predictions Min            -117.218506
V Predictions Mean           1030.1453
V Predictions Std            265.14026
V Predictions Max            1318.8296
V Predictions Min            38.0704
Log Pis Mean                 0.35528314
Log Pis Std                  2.6631434
Log Pis Max                  17.409914
Log Pis Min                  -4.633604
Policy mu Mean               0.14798214
Policy mu Std                1.0555692
Policy mu Max                4.054256
Policy mu Min                -3.2785008
Policy log std Mean          -0.5430143
Policy log std Std           0.21039668
Policy log std Max           0.6734043
Policy log std Min           -1.7357713
Z mean eval                  0.0013711026
Z variance eval              0.00031572988
total_rewards                [ 384.46540363 1355.07877705  813.01597266 1000.84860889 2744.35241064
 2732.56453329 2448.74184651 2750.63045876 2766.35666465 2750.93274491]
total_rewards_mean           1974.6987420975806
total_rewards_std            918.3374992255569
total_rewards_max            2766.356664651288
total_rewards_min            384.46540362560415
Number of train steps total  340000
Number of env steps total    462923
Number of rollouts total     0
Train Time (s)               141.84989810967818
(Previous) Eval Time (s)     16.98965373309329
Sample Time (s)              5.850593306589872
Epoch Time (s)               164.69014514936134
Total Train Time (s)         12626.919176330324
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 12:01:13.085734 UTC | [2020_01_04_08_30_45] Iteration #84 | Epoch Duration: 167.53303575515747
2020-01-04 12:01:13.085861 UTC | [2020_01_04_08_30_45] Iteration #84 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0015039038
Z variance train             0.00031573168
KL Divergence                17.655596
KL Loss                      1.7655596
QF Loss                      486.34436
VF Loss                      580.8138
Policy Loss                  -1047.7842
Q Predictions Mean           1037.5006
Q Predictions Std            243.46124
Q Predictions Max            1305.5801
Q Predictions Min            12.708854
V Predictions Mean           1039.6414
V Predictions Std            229.37057
V Predictions Max            1308.3933
V Predictions Min            16.121616
Log Pis Mean                 0.23703259
Log Pis Std                  2.2719607
Log Pis Max                  12.764331
Log Pis Min                  -7.894565
Policy mu Mean               0.19644064
Policy mu Std                1.0044338
Policy mu Max                3.4648097
Policy mu Min                -3.2690022
Policy log std Mean          -0.52153957
Policy log std Std           0.1940566
Policy log std Max           0.33088905
Policy log std Min           -1.5678022
Z mean eval                  0.0014013367
Z variance eval              0.00031055516
total_rewards                [1970.40222987 2869.84034057 2751.34259336 2180.34175095 2809.97002525
 2830.763098   2792.34177898 2418.7566497  2784.28876133 1783.96289547]
total_rewards_mean           2519.20101234708
total_rewards_std            383.40611086068856
total_rewards_max            2869.8403405676536
total_rewards_min            1783.9628954690395
Number of train steps total  344000
Number of env steps total    467924
Number of rollouts total     0
Train Time (s)               142.9281269358471
(Previous) Eval Time (s)     19.832315512001514
Sample Time (s)              5.548588449135423
Epoch Time (s)               168.30903089698404
Total Train Time (s)         12797.795120112132
Epoch                        85
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 12:04:03.964887 UTC | [2020_01_04_08_30_45] Iteration #85 | Epoch Duration: 170.87890791893005
2020-01-04 12:04:03.965091 UTC | [2020_01_04_08_30_45] Iteration #85 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0013919134
Z variance train             0.00031054375
KL Divergence                17.697102
KL Loss                      1.7697102
QF Loss                      120.08747
VF Loss                      80.24079
Policy Loss                  -1059.4036
Q Predictions Mean           1054.0007
Q Predictions Std            225.11829
Q Predictions Max            1306.5428
Q Predictions Min            9.702604
V Predictions Mean           1061.3628
V Predictions Std            213.24582
V Predictions Max            1305.2623
V Predictions Min            88.01715
Log Pis Mean                 -0.0509012
Log Pis Std                  2.1010919
Log Pis Max                  15.301235
Log Pis Min                  -5.213189
Policy mu Mean               0.14309476
Policy mu Std                0.8995544
Policy mu Max                4.211746
Policy mu Min                -3.3751569
Policy log std Mean          -0.5587788
Policy log std Std           0.1927546
Policy log std Max           0.11109787
Policy log std Min           -1.3459697
Z mean eval                  0.001076423
Z variance eval              0.0003039567
total_rewards                [2800.38286199  847.05788508 1817.69245077  475.08429658 2758.7904863
 2746.69739246 2798.04127704 2764.19117732 1312.27835701 2183.02059376]
total_rewards_mean           2050.323677831634
total_rewards_std            846.3925268449959
total_rewards_max            2800.382861986948
total_rewards_min            475.08429658123976
Number of train steps total  348000
Number of env steps total    472924
Number of rollouts total     0
Train Time (s)               142.16931514721364
(Previous) Eval Time (s)     22.401958954054862
Sample Time (s)              5.840884248260409
Epoch Time (s)               170.4121583495289
Total Train Time (s)         12965.9392084321
Epoch                        86
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 12:06:52.110758 UTC | [2020_01_04_08_30_45] Iteration #86 | Epoch Duration: 168.14544296264648
2020-01-04 12:06:52.111038 UTC | [2020_01_04_08_30_45] Iteration #86 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0010882348
Z variance train             0.00030394134
KL Divergence                17.751236
KL Loss                      1.7751236
QF Loss                      4555.5366
VF Loss                      268.04776
Policy Loss                  -1035.8784
Q Predictions Mean           1017.1125
Q Predictions Std            272.81015
Q Predictions Max            1302.2765
Q Predictions Min            1.8425095
V Predictions Mean           1033.2347
V Predictions Std            245.83328
V Predictions Max            1296.2719
V Predictions Min            42.7226
Log Pis Mean                 -0.035179034
Log Pis Std                  1.9279797
Log Pis Max                  7.826725
Log Pis Min                  -6.0615335
Policy mu Mean               0.2122188
Policy mu Std                0.88174456
Policy mu Max                3.2486167
Policy mu Min                -2.3347065
Policy log std Mean          -0.55930185
Policy log std Std           0.20998861
Policy log std Max           0.16575044
Policy log std Min           -1.4869822
Z mean eval                  0.0007331812
Z variance eval              0.00029828303
total_rewards                [2694.99173969 2663.08464923 2146.52683239 2833.79242331 2926.30646311
 2823.38819409 1366.50123477 2890.75731462 1127.47548062 2833.60288757]
total_rewards_mean           2430.642721941317
total_rewards_std            630.2235333924255
total_rewards_max            2926.3064631143566
total_rewards_min            1127.4754806208207
Number of train steps total  352000
Number of env steps total    478780
Number of rollouts total     0
Train Time (s)               142.6200146889314
(Previous) Eval Time (s)     20.135007645003498
Sample Time (s)              5.768604643642902
Epoch Time (s)               168.5236269775778
Total Train Time (s)         13138.477302398533
Epoch                        87
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 12:09:44.652093 UTC | [2020_01_04_08_30_45] Iteration #87 | Epoch Duration: 172.54079294204712
2020-01-04 12:09:44.652339 UTC | [2020_01_04_08_30_45] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0007197005
Z variance train             0.00029827954
KL Divergence                17.797642
KL Loss                      1.7797642
QF Loss                      214.36813
VF Loss                      41.638813
Policy Loss                  -1020.7069
Q Predictions Mean           1016.7773
Q Predictions Std            272.9781
Q Predictions Max            1319.4993
Q Predictions Min            26.110294
V Predictions Mean           1023.72034
V Predictions Std            269.3808
V Predictions Max            1333.8633
V Predictions Min            20.876299
Log Pis Mean                 0.2663143
Log Pis Std                  2.0335767
Log Pis Max                  13.89772
Log Pis Min                  -4.1964006
Policy mu Mean               0.26474932
Policy mu Std                0.95547503
Policy mu Max                3.772204
Policy mu Min                -3.3443482
Policy log std Mean          -0.5297782
Policy log std Std           0.1835336
Policy log std Max           -0.022224903
Policy log std Min           -1.300133
Z mean eval                  0.0014807184
Z variance eval              0.00028928023
total_rewards                [ 993.18638963  881.99443829 2465.98765161 2678.48229629 1668.32710229
 2782.52488488 1037.79792138 2737.9212815  2026.46521748 2665.76567668]
total_rewards_mean           1993.8452860017273
total_rewards_std            746.8179900836892
total_rewards_max            2782.5248848797173
total_rewards_min            881.9944382940892
Number of train steps total  356000
Number of env steps total    483780
Number of rollouts total     0
Train Time (s)               138.8745851679705
(Previous) Eval Time (s)     24.151940348558128
Sample Time (s)              5.88114548753947
Epoch Time (s)               168.9076710040681
Total Train Time (s)         13297.70263657812
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 12:12:23.878318 UTC | [2020_01_04_08_30_45] Iteration #88 | Epoch Duration: 159.22576022148132
2020-01-04 12:12:23.878584 UTC | [2020_01_04_08_30_45] Iteration #88 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0014915597
Z variance train             0.00028927912
KL Divergence                17.874184
KL Loss                      1.7874184
QF Loss                      147.78465
VF Loss                      118.06427
Policy Loss                  -1042.0071
Q Predictions Mean           1037.2924
Q Predictions Std            262.6377
Q Predictions Max            1321.0887
Q Predictions Min            7.457464
V Predictions Mean           1040.186
V Predictions Std            258.01483
V Predictions Max            1315.5466
V Predictions Min            4.279898
Log Pis Mean                 0.19236854
Log Pis Std                  1.9596921
Log Pis Max                  9.024381
Log Pis Min                  -4.7130213
Policy mu Mean               0.17447557
Policy mu Std                0.97099656
Policy mu Max                3.044445
Policy mu Min                -2.5153956
Policy log std Mean          -0.5056472
Policy log std Std           0.18111204
Policy log std Max           0.3630262
Policy log std Min           -1.1510608
Z mean eval                  0.0016185396
Z variance eval              0.0002841968
total_rewards                [ 914.19335628 1185.45967611 1141.45997107 2998.06598009 1069.79293246
 1351.72820592 1067.20406858  919.62235003 1650.49321947  896.01547718]
total_rewards_mean           1319.403523718985
total_rewards_std            600.6134774890803
total_rewards_max            2998.0659800901835
total_rewards_min            896.0154771788374
Number of train steps total  360000
Number of env steps total    488780
Number of rollouts total     0
Train Time (s)               138.3611327363178
(Previous) Eval Time (s)     14.469786061905324
Sample Time (s)              5.022391628939658
Epoch Time (s)               157.8533104271628
Total Train Time (s)         13450.663896491751
Epoch                        89
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 12:14:56.841184 UTC | [2020_01_04_08_30_45] Iteration #89 | Epoch Duration: 152.9624433517456
2020-01-04 12:14:56.841378 UTC | [2020_01_04_08_30_45] Iteration #89 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0014949774
Z variance train             0.00028418336
KL Divergence                17.918774
KL Loss                      1.7918774
QF Loss                      158.27316
VF Loss                      97.55017
Policy Loss                  -1056.982
Q Predictions Mean           1053.7908
Q Predictions Std            243.31996
Q Predictions Max            1325.2521
Q Predictions Min            4.2465744
V Predictions Mean           1057.7698
V Predictions Std            241.49065
V Predictions Max            1320.6013
V Predictions Min            -10.919106
Log Pis Mean                 -0.100759216
Log Pis Std                  1.9778566
Log Pis Max                  6.4647303
Log Pis Min                  -5.425212
Policy mu Mean               0.31668898
Policy mu Std                0.8612625
Policy mu Max                2.7300558
Policy mu Min                -2.4702656
Policy log std Mean          -0.48996186
Policy log std Std           0.19744553
Policy log std Max           0.15636563
Policy log std Min           -1.2051277
Z mean eval                  0.0013868475
Z variance eval              0.00027750753
total_rewards                [1533.23404535 2666.68983491 2853.53249947 2819.88640047 1946.76131936
 2856.51542249 2786.94047804 2744.70016309 2807.4899018  2059.6671481 ]
total_rewards_mean           2507.5417213074315
total_rewards_std            453.10021254451664
total_rewards_max            2856.51542248931
total_rewards_min            1533.2340453451081
Number of train steps total  364000
Number of env steps total    493780
Number of rollouts total     0
Train Time (s)               139.31067313812673
(Previous) Eval Time (s)     9.578701910097152
Sample Time (s)              5.062771702185273
Epoch Time (s)               153.95214675040916
Total Train Time (s)         13614.06302038161
Epoch                        90
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 12:17:40.243718 UTC | [2020_01_04_08_30_45] Iteration #90 | Epoch Duration: 163.40217518806458
2020-01-04 12:17:40.243960 UTC | [2020_01_04_08_30_45] Iteration #90 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0014156227
Z variance train             0.00027750916
KL Divergence                17.977383
KL Loss                      1.7977383
QF Loss                      4810.036
VF Loss                      131.5443
Policy Loss                  -1050.816
Q Predictions Mean           1041.3855
Q Predictions Std            254.17566
Q Predictions Max            1305.0669
Q Predictions Min            43.02314
V Predictions Mean           1055.449
V Predictions Std            245.59207
V Predictions Max            1311.967
V Predictions Min            4.351765
Log Pis Mean                 -0.074663125
Log Pis Std                  1.9822562
Log Pis Max                  6.497861
Log Pis Min                  -4.6667495
Policy mu Mean               0.14644301
Policy mu Std                0.89200354
Policy mu Max                2.739559
Policy mu Min                -2.5963066
Policy log std Mean          -0.52471775
Policy log std Std           0.18385832
Policy log std Max           0.01179415
Policy log std Min           -1.3306954
Z mean eval                  0.0021786813
Z variance eval              0.00026965496
total_rewards                [2091.37396092 1722.77686069 2881.16372117 1034.55341255 2839.00487722
 2469.07656584 2866.90187062 2837.93403155 2877.34307171 2868.89164368]
total_rewards_mean           2448.902001594473
total_rewards_std            606.7063765224331
total_rewards_max            2881.163721173439
total_rewards_min            1034.5534125454196
Number of train steps total  368000
Number of env steps total    499069
Number of rollouts total     0
Train Time (s)               136.97851611627266
(Previous) Eval Time (s)     19.02849475480616
Sample Time (s)              5.31415666686371
Epoch Time (s)               161.32116753794253
Total Train Time (s)         13775.17713397881
Epoch                        91
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 12:20:21.359841 UTC | [2020_01_04_08_30_45] Iteration #91 | Epoch Duration: 161.11569142341614
2020-01-04 12:20:21.360003 UTC | [2020_01_04_08_30_45] Iteration #91 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0021806222
Z variance train             0.00026966058
KL Divergence                18.04835
KL Loss                      1.804835
QF Loss                      196.39473
VF Loss                      78.9364
Policy Loss                  -1031.932
Q Predictions Mean           1026.2776
Q Predictions Std            280.7948
Q Predictions Max            1316.5352
Q Predictions Min            -35.585255
V Predictions Mean           1032.4075
V Predictions Std            266.82147
V Predictions Max            1310.9121
V Predictions Min            -11.447706
Log Pis Mean                 0.08580369
Log Pis Std                  2.273394
Log Pis Max                  13.559597
Log Pis Min                  -6.2383857
Policy mu Mean               0.08048215
Policy mu Std                0.978899
Policy mu Max                3.5841765
Policy mu Min                -3.3896935
Policy log std Mean          -0.52796245
Policy log std Std           0.22495195
Policy log std Max           0.17860156
Policy log std Min           -1.935035
Z mean eval                  0.0022475817
Z variance eval              0.00026596594
total_rewards                [2135.45080401 1670.66177446 2437.09017077  918.98524742  841.20666293
  829.33900289 2747.79119246  931.5453915  2869.89436297 2842.94098307]
total_rewards_mean           1822.4905592477558
total_rewards_std            839.8009927378657
total_rewards_max            2869.8943629746473
total_rewards_min            829.3390028894033
Number of train steps total  372000
Number of env steps total    504166
Number of rollouts total     0
Train Time (s)               137.84418175416067
(Previous) Eval Time (s)     18.822831552941352
Sample Time (s)              5.124299761839211
Epoch Time (s)               161.79131306894124
Total Train Time (s)         13932.75580426678
Epoch                        92
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 12:22:58.939878 UTC | [2020_01_04_08_30_45] Iteration #92 | Epoch Duration: 157.5796434879303
2020-01-04 12:22:58.940382 UTC | [2020_01_04_08_30_45] Iteration #92 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0022610605
Z variance train             0.00026596725
KL Divergence                18.08331
KL Loss                      1.8083309
QF Loss                      2670.017
VF Loss                      118.22847
Policy Loss                  -1068.9169
Q Predictions Mean           1069.4164
Q Predictions Std            239.33395
Q Predictions Max            1320.8237
Q Predictions Min            22.110237
V Predictions Mean           1076.779
V Predictions Std            224.98409
V Predictions Max            1315.1384
V Predictions Min            71.48729
Log Pis Mean                 -0.053030316
Log Pis Std                  2.0570486
Log Pis Max                  10.260279
Log Pis Min                  -4.6759324
Policy mu Mean               0.11343212
Policy mu Std                0.89780587
Policy mu Max                3.3778892
Policy mu Min                -2.4843626
Policy log std Mean          -0.50815064
Policy log std Std           0.19319291
Policy log std Max           0.028329074
Policy log std Min           -1.8019273
Z mean eval                  0.0014402879
Z variance eval              0.0002620898
total_rewards                [ 491.26525501  314.66580641 2852.74641689 2806.28771646 2800.97693889
 2758.99190036 1291.02903162 2785.1623475  2833.13289658 2794.52474063]
total_rewards_mean           2172.8783050339084
total_rewards_std            992.8328972567341
total_rewards_max            2852.7464168927413
total_rewards_min            314.6658064130608
Number of train steps total  376000
Number of env steps total    509166
Number of rollouts total     0
Train Time (s)               137.92011694097891
(Previous) Eval Time (s)     14.610913787968457
Sample Time (s)              4.427847026381642
Epoch Time (s)               156.958877755329
Total Train Time (s)         14094.164241043385
Epoch                        93
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 12:25:40.350189 UTC | [2020_01_04_08_30_45] Iteration #93 | Epoch Duration: 161.4096143245697
2020-01-04 12:25:40.350404 UTC | [2020_01_04_08_30_45] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0014278647
Z variance train             0.00026210438
KL Divergence                18.119371
KL Loss                      1.8119372
QF Loss                      362.03714
VF Loss                      99.241325
Policy Loss                  -1087.173
Q Predictions Mean           1082.9707
Q Predictions Std            217.66162
Q Predictions Max            1329.0316
Q Predictions Min            -35.367493
V Predictions Mean           1086.5935
V Predictions Std            214.38858
V Predictions Max            1329.0294
V Predictions Min            43.6804
Log Pis Mean                 0.14726314
Log Pis Std                  2.1985943
Log Pis Max                  8.24278
Log Pis Min                  -4.8394666
Policy mu Mean               0.049369723
Policy mu Std                0.9868761
Policy mu Max                2.8227236
Policy mu Min                -2.803875
Policy log std Mean          -0.5442511
Policy log std Std           0.20059155
Policy log std Max           0.13680464
Policy log std Min           -1.336451
Z mean eval                  0.0013152066
Z variance eval              0.000258209
total_rewards                [ 441.34564484  497.31133558 2798.61864035 2745.08196829 2811.66767038
 2787.32122416 1269.21640146 2737.20890189 2756.21882767 2797.32359561]
total_rewards_mean           2164.1314210223213
total_rewards_std            957.852642165746
total_rewards_max            2811.667670382387
total_rewards_min            441.34564484466017
Number of train steps total  380000
Number of env steps total    514166
Number of rollouts total     0
Train Time (s)               136.46703714085743
(Previous) Eval Time (s)     19.061442126054317
Sample Time (s)              5.169420554302633
Epoch Time (s)               160.69789982121438
Total Train Time (s)         14255.142422433477
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 12:28:21.330639 UTC | [2020_01_04_08_30_45] Iteration #94 | Epoch Duration: 160.98000931739807
2020-01-04 12:28:21.330931 UTC | [2020_01_04_08_30_45] Iteration #94 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0013200226
Z variance train             0.00025820872
KL Divergence                18.156961
KL Loss                      1.8156961
QF Loss                      171.63577
VF Loss                      62.662834
Policy Loss                  -1097.5962
Q Predictions Mean           1098.0015
Q Predictions Std            219.09332
Q Predictions Max            1338.7102
Q Predictions Min            24.459112
V Predictions Mean           1099.9673
V Predictions Std            216.2452
V Predictions Max            1331.8888
V Predictions Min            88.47401
Log Pis Mean                 0.0011547245
Log Pis Std                  2.1314662
Log Pis Max                  10.475911
Log Pis Min                  -6.212002
Policy mu Mean               0.06921328
Policy mu Std                0.92384046
Policy mu Max                3.6741874
Policy mu Min                -3.2053428
Policy log std Mean          -0.54006666
Policy log std Std           0.18957825
Policy log std Max           -0.028165758
Policy log std Min           -1.2447007
Z mean eval                  0.00088738947
Z variance eval              0.0002523584
total_rewards                [ 912.25172305 1067.9521006   954.09928028 2811.80472807  931.1309067
 1289.70092433 1059.66566319 2823.92878344 2832.41984211 1175.36833569]
total_rewards_mean           1585.8322287466042
total_rewards_std            816.8554830151411
total_rewards_max            2832.4198421084348
total_rewards_min            912.2517230546803
Number of train steps total  384000
Number of env steps total    519166
Number of rollouts total     0
Train Time (s)               135.32918245112523
(Previous) Eval Time (s)     19.34332328988239
Sample Time (s)              4.535420977044851
Epoch Time (s)               159.20792671805248
Total Train Time (s)         14407.063830988947
Epoch                        95
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 12:30:53.256117 UTC | [2020_01_04_08_30_45] Iteration #95 | Epoch Duration: 151.92498660087585
2020-01-04 12:30:53.256322 UTC | [2020_01_04_08_30_45] Iteration #95 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0008871358
Z variance train             0.00025235792
KL Divergence                18.213907
KL Loss                      1.8213907
QF Loss                      845.526
VF Loss                      80.054214
Policy Loss                  -1057.624
Q Predictions Mean           1055.9285
Q Predictions Std            247.82362
Q Predictions Max            1326.9224
Q Predictions Min            26.93326
V Predictions Mean           1061.7921
V Predictions Std            243.49469
V Predictions Max            1332.0669
V Predictions Min            30.479124
Log Pis Mean                 0.012379065
Log Pis Std                  2.09707
Log Pis Max                  9.90114
Log Pis Min                  -5.2035236
Policy mu Mean               0.24768673
Policy mu Std                0.8873232
Policy mu Max                3.9008572
Policy mu Min                -3.150633
Policy log std Mean          -0.5111913
Policy log std Std           0.20341757
Policy log std Max           0.15068197
Policy log std Min           -1.8049372
Z mean eval                  0.0019961149
Z variance eval              0.00024975993
total_rewards                [ 742.2241509   941.54129303 2604.57037697 1064.80867807 1219.41565458
 1375.9692531  1109.18279698 1170.8740889  1048.04621163 2896.68605811]
total_rewards_mean           1417.3318562274894
total_rewards_std            688.2873436020343
total_rewards_max            2896.6860581084184
total_rewards_min            742.2241509018575
Number of train steps total  388000
Number of env steps total    524166
Number of rollouts total     0
Train Time (s)               135.2852566037327
(Previous) Eval Time (s)     12.0600880025886
Sample Time (s)              4.779157242272049
Epoch Time (s)               152.12450184859335
Total Train Time (s)         14559.038107557688
Epoch                        96
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 12:33:25.232781 UTC | [2020_01_04_08_30_45] Iteration #96 | Epoch Duration: 151.97629022598267
2020-01-04 12:33:25.233023 UTC | [2020_01_04_08_30_45] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0020088644
Z variance train             0.00024974436
KL Divergence                18.240349
KL Loss                      1.8240349
QF Loss                      7766.8994
VF Loss                      147.97046
Policy Loss                  -1071.853
Q Predictions Mean           1070.0197
Q Predictions Std            251.37846
Q Predictions Max            1326.7483
Q Predictions Min            16.261961
V Predictions Mean           1082.189
V Predictions Std            247.76186
V Predictions Max            1339.0728
V Predictions Min            20.046507
Log Pis Mean                 -0.0010295212
Log Pis Std                  2.19119
Log Pis Max                  10.752495
Log Pis Min                  -6.2597437
Policy mu Mean               0.29387096
Policy mu Std                0.8728088
Policy mu Max                3.3951337
Policy mu Min                -3.356649
Policy log std Mean          -0.51751894
Policy log std Std           0.21250355
Policy log std Max           0.042175412
Policy log std Min           -2.3645382
Z mean eval                  0.0013507175
Z variance eval              0.00024658378
total_rewards                [ 903.31668017 1107.26851733 2850.44224408 1100.79749017 2734.55688581
 2838.39197649 2825.35667302  798.66525596 2763.93182017 2853.32926395]
total_rewards_mean           2077.605680714135
total_rewards_std            902.7696793657207
total_rewards_max            2853.3292639454357
total_rewards_min            798.6652559596373
Number of train steps total  392000
Number of env steps total    529166
Number of rollouts total     0
Train Time (s)               135.46120470296592
(Previous) Eval Time (s)     11.911588141694665
Sample Time (s)              5.061908694449812
Epoch Time (s)               152.4347015391104
Total Train Time (s)         14716.093435193878
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 12:36:02.288770 UTC | [2020_01_04_08_30_45] Iteration #97 | Epoch Duration: 157.0555739402771
2020-01-04 12:36:02.288927 UTC | [2020_01_04_08_30_45] Iteration #97 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0013244377
Z variance train             0.00024659184
KL Divergence                18.272776
KL Loss                      1.8272775
QF Loss                      375.59073
VF Loss                      99.92035
Policy Loss                  -1084.032
Q Predictions Mean           1069.3762
Q Predictions Std            277.20023
Q Predictions Max            1332.4934
Q Predictions Min            -2.9138484
V Predictions Mean           1085.9609
V Predictions Std            252.42035
V Predictions Max            1340.1548
V Predictions Min            -0.9587761
Log Pis Mean                 0.2099721
Log Pis Std                  2.3489952
Log Pis Max                  13.7155905
Log Pis Min                  -4.321169
Policy mu Mean               0.22271551
Policy mu Std                0.9755237
Policy mu Max                4.266554
Policy mu Min                -3.5269592
Policy log std Mean          -0.5523653
Policy log std Std           0.19951504
Policy log std Max           0.031055868
Policy log std Min           -1.4056563
Z mean eval                  0.002303456
Z variance eval              0.00024381457
total_rewards                [2693.85990018 2277.45079166  835.52969083 2799.52682229 2789.70562679
 2825.59492462  965.70786533 2792.61930078 2835.27763113 2788.11728517]
total_rewards_mean           2360.3389838789963
total_rewards_std            746.8117580039254
total_rewards_max            2835.2776311284933
total_rewards_min            835.5296908349062
Number of train steps total  396000
Number of env steps total    534166
Number of rollouts total     0
Train Time (s)               135.35310190590099
(Previous) Eval Time (s)     16.53228867519647
Sample Time (s)              4.069363979622722
Epoch Time (s)               155.95475456072018
Total Train Time (s)         14873.584324851632
Epoch                        98
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 12:38:39.782181 UTC | [2020_01_04_08_30_45] Iteration #98 | Epoch Duration: 157.49311637878418
2020-01-04 12:38:39.782346 UTC | [2020_01_04_08_30_45] Iteration #98 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0023263756
Z variance train             0.0002438152
KL Divergence                18.300747
KL Loss                      1.8300747
QF Loss                      145.90366
VF Loss                      128.78687
Policy Loss                  -1055.5625
Q Predictions Mean           1051.7258
Q Predictions Std            296.41647
Q Predictions Max            1341.6382
Q Predictions Min            1.808816
V Predictions Mean           1054.1625
V Predictions Std            291.37814
V Predictions Max            1336.4772
V Predictions Min            28.605968
Log Pis Mean                 0.26857
Log Pis Std                  2.5465245
Log Pis Max                  14.737574
Log Pis Min                  -7.9454274
Policy mu Mean               0.19793777
Policy mu Std                0.99117243
Policy mu Max                3.899375
Policy mu Min                -3.2758265
Policy log std Mean          -0.5172524
Policy log std Std           0.22346607
Policy log std Max           0.36216807
Policy log std Min           -1.4345193
Z mean eval                  0.0012219707
Z variance eval              0.00023891912
total_rewards                [2715.60574396 2715.13398096 2652.44326619 2688.3098992  1547.75182814
  829.40194738 1072.91672076 2656.67333061 2676.88859255 2674.40068649]
total_rewards_mean           2222.9525996249004
total_rewards_std            721.4158467809688
total_rewards_max            2715.6057439639253
total_rewards_min            829.4019473795414
Number of train steps total  400000
Number of env steps total    539202
Number of rollouts total     0
Train Time (s)               137.06430291384459
(Previous) Eval Time (s)     18.070443673059344
Sample Time (s)              4.786676542367786
Epoch Time (s)               159.92142312927172
Total Train Time (s)         15032.761858540587
Epoch                        99
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 12:41:18.963398 UTC | [2020_01_04_08_30_45] Iteration #99 | Epoch Duration: 159.18091917037964
2020-01-04 12:41:18.963596 UTC | [2020_01_04_08_30_45] Iteration #99 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0012209828
Z variance train             0.000238918
KL Divergence                18.351528
KL Loss                      1.8351529
QF Loss                      130.26192
VF Loss                      75.01299
Policy Loss                  -1082.5671
Q Predictions Mean           1081.9473
Q Predictions Std            260.9354
Q Predictions Max            1342.3577
Q Predictions Min            11.337742
V Predictions Mean           1086.8577
V Predictions Std            256.48553
V Predictions Max            1340.3658
V Predictions Min            15.796333
Log Pis Mean                 -0.018110543
Log Pis Std                  2.1379113
Log Pis Max                  8.448057
Log Pis Min                  -6.0508547
Policy mu Mean               0.010316326
Policy mu Std                0.94342476
Policy mu Max                2.7002149
Policy mu Min                -3.1787605
Policy log std Mean          -0.4993126
Policy log std Std           0.20552549
Policy log std Max           0.068592906
Policy log std Min           -1.9764692
Z mean eval                  0.0018245972
Z variance eval              0.00023037338
total_rewards                [2978.16860079 1060.02497514 2846.948044    848.07387534 2801.61782916
 2830.72757902 1873.16315096 2804.71989248 2803.28890708 2795.59581111]
total_rewards_mean           2364.232866506477
total_rewards_std            763.7128219108624
total_rewards_max            2978.1686007856015
total_rewards_min            848.073875336243
Number of train steps total  404000
Number of env steps total    544202
Number of rollouts total     0
Train Time (s)               138.38210870930925
(Previous) Eval Time (s)     17.32974483910948
Sample Time (s)              4.220173596870154
Epoch Time (s)               159.93202714528888
Total Train Time (s)         15196.617246909998
Epoch                        100
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 12:44:02.820761 UTC | [2020_01_04_08_30_45] Iteration #100 | Epoch Duration: 163.85703301429749
2020-01-04 12:44:02.820890 UTC | [2020_01_04_08_30_45] Iteration #100 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0018450555
Z variance train             0.00023036767
KL Divergence                18.442238
KL Loss                      1.8442239
QF Loss                      314.14832
VF Loss                      56.641846
Policy Loss                  -1106.1101
Q Predictions Mean           1098.947
Q Predictions Std            234.81642
Q Predictions Max            1332.5789
Q Predictions Min            14.519414
V Predictions Mean           1106.2126
V Predictions Std            231.40347
V Predictions Max            1342.2211
V Predictions Min            29.684294
Log Pis Mean                 -0.051257275
Log Pis Std                  1.9444883
Log Pis Max                  4.7902694
Log Pis Min                  -6.0345936
Policy mu Mean               0.20010822
Policy mu Std                0.9232469
Policy mu Max                2.2351246
Policy mu Min                -2.4178102
Policy log std Mean          -0.5392228
Policy log std Std           0.18903567
Policy log std Max           0.05826497
Policy log std Min           -1.4010377
Z mean eval                  0.0016476006
Z variance eval              0.00022912324
total_rewards                [1039.56843537  794.36298013 2780.67165492 2723.16399202 1306.12937127
 2818.83615677 2736.72163765 2790.43118576 2825.02304585 2791.38026744]
total_rewards_mean           2260.6288727188403
total_rewards_std            803.4652947670376
total_rewards_max            2825.023045852999
total_rewards_min            794.3629801300469
Number of train steps total  408000
Number of env steps total    549242
Number of rollouts total     0
Train Time (s)               143.32823469722643
(Previous) Eval Time (s)     21.25455336505547
Sample Time (s)              5.4460286451503634
Epoch Time (s)               170.02881670743227
Total Train Time (s)         15368.548083480448
Epoch                        101
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 12:46:54.753808 UTC | [2020_01_04_08_30_45] Iteration #101 | Epoch Duration: 171.9327347278595
2020-01-04 12:46:54.754073 UTC | [2020_01_04_08_30_45] Iteration #101 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0016382368
Z variance train             0.0002291271
KL Divergence                18.456537
KL Loss                      1.8456538
QF Loss                      603.3725
VF Loss                      61.98336
Policy Loss                  -1109.7964
Q Predictions Mean           1105.9342
Q Predictions Std            227.61864
Q Predictions Max            1343.4325
Q Predictions Min            59.338356
V Predictions Mean           1104.7173
V Predictions Std            223.66702
V Predictions Max            1343.8014
V Predictions Min            136.86844
Log Pis Mean                 0.1340089
Log Pis Std                  2.0329165
Log Pis Max                  8.344553
Log Pis Min                  -4.1961236
Policy mu Mean               0.12103859
Policy mu Std                0.964249
Policy mu Max                2.8230252
Policy mu Min                -3.0166025
Policy log std Mean          -0.523743
Policy log std Std           0.19704221
Policy log std Max           0.16311151
Policy log std Min           -1.589927
Z mean eval                  0.0016292268
Z variance eval              0.00022616998
total_rewards                [2900.01506421 1013.97237352 2813.20785583 2831.33900776 2812.76628496
 2852.75135592 2852.81673617 2813.02411867 1876.79455909 2884.55132231]
total_rewards_mean           2565.1238678431823
total_rewards_std            592.8531380547506
total_rewards_max            2900.0150642120357
total_rewards_min            1013.9723735199527
Number of train steps total  412000
Number of env steps total    554508
Number of rollouts total     0
Train Time (s)               141.55877321586013
(Previous) Eval Time (s)     23.15829777577892
Sample Time (s)              5.660333085805178
Epoch Time (s)               170.37740407744423
Total Train Time (s)         15536.302997154184
Epoch                        102
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 12:49:42.509527 UTC | [2020_01_04_08_30_45] Iteration #102 | Epoch Duration: 167.75530767440796
2020-01-04 12:49:42.509678 UTC | [2020_01_04_08_30_45] Iteration #102 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0016336355
Z variance train             0.00022616691
KL Divergence                18.48981
KL Loss                      1.8489811
QF Loss                      94.41637
VF Loss                      26.027388
Policy Loss                  -1086.4948
Q Predictions Mean           1082.2096
Q Predictions Std            259.64215
Q Predictions Max            1343.4766
Q Predictions Min            4.906876
V Predictions Mean           1084.5824
V Predictions Std            254.37811
V Predictions Max            1341.4058
V Predictions Min            13.55899
Log Pis Mean                 -0.044450343
Log Pis Std                  1.9902253
Log Pis Max                  7.9195857
Log Pis Min                  -4.4615207
Policy mu Mean               0.058894772
Policy mu Std                0.92513126
Policy mu Max                2.9344985
Policy mu Min                -2.5957344
Policy log std Mean          -0.50055754
Policy log std Std           0.22047597
Policy log std Max           0.34987247
Policy log std Min           -1.2422909
Z mean eval                  0.0017205207
Z variance eval              0.00022419174
total_rewards                [1547.67492449 1105.94988663 2865.8752612  2843.68296693 2880.75312356
 2863.43147509 2863.35434058 2846.5693255  2870.0942074  2821.39026838]
total_rewards_mean           2550.877577976639
total_rewards_std            620.1491479059139
total_rewards_max            2880.753123561966
total_rewards_min            1105.949886632778
Number of train steps total  416000
Number of env steps total    559508
Number of rollouts total     0
Train Time (s)               138.81998378783464
(Previous) Eval Time (s)     20.53599025402218
Sample Time (s)              4.423536983784288
Epoch Time (s)               163.7795110256411
Total Train Time (s)         15699.095847760793
Epoch                        103
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 12:52:25.304949 UTC | [2020_01_04_08_30_45] Iteration #103 | Epoch Duration: 162.7951419353485
2020-01-04 12:52:25.305147 UTC | [2020_01_04_08_30_45] Iteration #103 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0016941752
Z variance train             0.00022417649
KL Divergence                18.511845
KL Loss                      1.8511845
QF Loss                      401.90405
VF Loss                      47.84966
Policy Loss                  -1099.774
Q Predictions Mean           1090.6667
Q Predictions Std            253.70085
Q Predictions Max            1349.4965
Q Predictions Min            -0.061957955
V Predictions Mean           1098.1575
V Predictions Std            249.0147
V Predictions Max            1352.7135
V Predictions Min            11.819416
Log Pis Mean                 0.034712315
Log Pis Std                  2.1821015
Log Pis Max                  9.679669
Log Pis Min                  -7.088689
Policy mu Mean               0.19578595
Policy mu Std                0.9108538
Policy mu Max                2.725126
Policy mu Min                -2.6290898
Policy log std Mean          -0.51730293
Policy log std Std           0.18933114
Policy log std Max           0.07160175
Policy log std Min           -1.1963723
Z mean eval                  0.001348352
Z variance eval              0.000220825
total_rewards                [ 445.51195404  621.05202333 2897.41477429 2884.01343595 2935.77921726
  809.83284115  840.40367777  547.46994097 2938.2296093  2927.47088926]
total_rewards_mean           1784.7178363326955
total_rewards_std            1137.034054110881
total_rewards_max            2938.2296093010987
total_rewards_min            445.51195404449146
Number of train steps total  420000
Number of env steps total    564508
Number of rollouts total     0
Train Time (s)               137.1250532148406
(Previous) Eval Time (s)     19.55140705872327
Sample Time (s)              4.150163569953293
Epoch Time (s)               160.82662384351715
Total Train Time (s)         15856.041838398669
Epoch                        104
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 12:55:02.253129 UTC | [2020_01_04_08_30_45] Iteration #104 | Epoch Duration: 156.94777011871338
2020-01-04 12:55:02.253395 UTC | [2020_01_04_08_30_45] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0013376724
Z variance train             0.00022083626
KL Divergence                18.54941
KL Loss                      1.854941
QF Loss                      487.59402
VF Loss                      351.34555
Policy Loss                  -1087.2141
Q Predictions Mean           1091.0914
Q Predictions Std            216.42241
Q Predictions Max            1355.3671
Q Predictions Min            15.275866
V Predictions Mean           1088.6941
V Predictions Std            206.48802
V Predictions Max            1348.0612
V Predictions Min            24.687103
Log Pis Mean                 0.18734896
Log Pis Std                  2.248983
Log Pis Max                  9.192984
Log Pis Min                  -6.2862134
Policy mu Mean               0.19187659
Policy mu Std                0.98189443
Policy mu Max                3.2451482
Policy mu Min                -3.2219694
Policy log std Mean          -0.53432673
Policy log std Std           0.2191035
Policy log std Max           0.32705373
Policy log std Min           -2.7998688
Z mean eval                  0.0019191537
Z variance eval              0.00021713258
total_rewards                [2968.95593521 2654.66514306 2827.20326666 2172.42482957 2945.43341539
 2604.7256195  1083.83643461 2954.4135993   714.65351046 2909.16302134]
total_rewards_mean           2383.5474775086013
total_rewards_std            780.9521340988068
total_rewards_max            2968.955935206665
total_rewards_min            714.6535104552155
Number of train steps total  424000
Number of env steps total    569664
Number of rollouts total     0
Train Time (s)               136.7146791438572
(Previous) Eval Time (s)     15.672346663661301
Sample Time (s)              4.644848942756653
Epoch Time (s)               157.03187475027516
Total Train Time (s)         16016.994453663006
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 12:57:43.207064 UTC | [2020_01_04_08_30_45] Iteration #105 | Epoch Duration: 160.95344758033752
2020-01-04 12:57:43.207249 UTC | [2020_01_04_08_30_45] Iteration #105 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0019497782
Z variance train             0.0002171383
KL Divergence                18.590977
KL Loss                      1.8590977
QF Loss                      175.26794
VF Loss                      129.52106
Policy Loss                  -1104.5238
Q Predictions Mean           1097.5303
Q Predictions Std            246.95049
Q Predictions Max            1361.1963
Q Predictions Min            6.5771637
V Predictions Mean           1097.5126
V Predictions Std            245.22028
V Predictions Max            1358.3718
V Predictions Min            1.9097162
Log Pis Mean                 0.24115421
Log Pis Std                  1.9900147
Log Pis Max                  6.7812347
Log Pis Min                  -5.1170774
Policy mu Mean               0.024318023
Policy mu Std                0.9942289
Policy mu Max                2.9897137
Policy mu Min                -2.8631198
Policy log std Mean          -0.5248619
Policy log std Std           0.21316396
Policy log std Max           0.08428264
Policy log std Min           -1.4403665
Z mean eval                  0.00062168326
Z variance eval              0.00021428426
total_rewards                [2666.51908102 1029.4096893   848.57198501 2864.98864768 2858.51170727
 2808.90642941 2893.22376195 2836.68443936 2877.46379169 2919.28683597]
total_rewards_mean           2460.356636866792
total_rewards_std            764.5453050940455
total_rewards_max            2919.286835973918
total_rewards_min            848.57198500883
Number of train steps total  428000
Number of env steps total    574699
Number of rollouts total     0
Train Time (s)               135.34356189193204
(Previous) Eval Time (s)     19.59371395688504
Sample Time (s)              4.248685789760202
Epoch Time (s)               159.18596163857728
Total Train Time (s)         16175.205917345826
Epoch                        106
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 13:00:21.420167 UTC | [2020_01_04_08_30_45] Iteration #106 | Epoch Duration: 158.21277332305908
2020-01-04 13:00:21.420340 UTC | [2020_01_04_08_30_45] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0006111651
Z variance train             0.0002142844
KL Divergence                18.624306
KL Loss                      1.8624306
QF Loss                      1337.8564
VF Loss                      164.72644
Policy Loss                  -1106.0931
Q Predictions Mean           1100.2311
Q Predictions Std            254.63979
Q Predictions Max            1378.167
Q Predictions Min            23.450884
V Predictions Mean           1108.9315
V Predictions Std            231.45895
V Predictions Max            1366.7981
V Predictions Min            62.659233
Log Pis Mean                 0.20185278
Log Pis Std                  2.4579363
Log Pis Max                  19.03309
Log Pis Min                  -4.4476495
Policy mu Mean               0.20460474
Policy mu Std                0.9529381
Policy mu Max                4.669349
Policy mu Min                -5.231544
Policy log std Mean          -0.5612566
Policy log std Std           0.22932063
Policy log std Max           0.063144684
Policy log std Min           -3.6158233
Z mean eval                  0.0021034416
Z variance eval              0.00021209226
total_rewards                [2956.82435457  912.41492294 2978.67620194 2966.39726824 2935.27711513
 1085.87213467 2971.24221711 2896.0270043  2948.36102271 2899.758337  ]
total_rewards_mean           2555.0850578606914
total_rewards_std            779.3839417413234
total_rewards_max            2978.6762019383436
total_rewards_min            912.4149229389565
Number of train steps total  432000
Number of env steps total    579829
Number of rollouts total     0
Train Time (s)               138.69055775739253
(Previous) Eval Time (s)     18.620330726727843
Sample Time (s)              4.972936579491943
Epoch Time (s)               162.2838250636123
Total Train Time (s)         16337.65448937891
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 13:03:03.874017 UTC | [2020_01_04_08_30_45] Iteration #107 | Epoch Duration: 162.45353889465332
2020-01-04 13:03:03.874188 UTC | [2020_01_04_08_30_45] Iteration #107 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0020886813
Z variance train             0.00021209657
KL Divergence                18.650364
KL Loss                      1.8650364
QF Loss                      5932.0713
VF Loss                      66.36839
Policy Loss                  -1119.911
Q Predictions Mean           1116.4814
Q Predictions Std            225.53491
Q Predictions Max            1361.0249
Q Predictions Min            2.7395005
V Predictions Mean           1117.1575
V Predictions Std            222.44444
V Predictions Max            1353.7039
V Predictions Min            -1.1155113
Log Pis Mean                 -0.11535585
Log Pis Std                  2.1590748
Log Pis Max                  13.342648
Log Pis Min                  -5.581436
Policy mu Mean               0.35544375
Policy mu Std                0.877447
Policy mu Max                3.3731554
Policy mu Min                -2.5630038
Policy log std Mean          -0.5113823
Policy log std Std           0.19163094
Policy log std Max           0.17975342
Policy log std Min           -1.1730639
Z mean eval                  0.0005280463
Z variance eval              0.00021188548
total_rewards                [ 857.03947739 2877.43049697 2039.34340938  917.84639561 1309.48599926
  921.65117091 1725.87652767  938.17343408 1151.22083387 2994.176478  ]
total_rewards_mean           1573.224422312704
total_rewards_std            773.2109338589986
total_rewards_max            2994.176478001505
total_rewards_min            857.0394773863944
Number of train steps total  436000
Number of env steps total    584829
Number of rollouts total     0
Train Time (s)               138.14725556597114
(Previous) Eval Time (s)     18.789814615622163
Sample Time (s)              4.959808707702905
Epoch Time (s)               161.8968788892962
Total Train Time (s)         16496.61284661852
Epoch                        108
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 13:05:42.832130 UTC | [2020_01_04_08_30_45] Iteration #108 | Epoch Duration: 158.9578013420105
2020-01-04 13:05:42.832330 UTC | [2020_01_04_08_30_45] Iteration #108 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0005265103
Z variance train             0.00021187837
KL Divergence                18.651663
KL Loss                      1.8651663
QF Loss                      185.95175
VF Loss                      48.298046
Policy Loss                  -1105.1143
Q Predictions Mean           1098.8811
Q Predictions Std            263.67874
Q Predictions Max            1381.0818
Q Predictions Min            45.8942
V Predictions Mean           1104.6543
V Predictions Std            256.11438
V Predictions Max            1372.3064
V Predictions Min            39.871765
Log Pis Mean                 -0.074050315
Log Pis Std                  1.8336104
Log Pis Max                  6.721472
Log Pis Min                  -4.586231
Policy mu Mean               0.23707189
Policy mu Std                0.883277
Policy mu Max                2.7798018
Policy mu Min                -2.4779756
Policy log std Mean          -0.5181629
Policy log std Std           0.20758598
Policy log std Max           0.13331252
Policy log std Min           -1.2584944
Z mean eval                  0.0017775062
Z variance eval              0.00020783495
total_rewards                [ 875.20738186  878.27384434 1724.38719754 2812.08655314 2772.69964066
 2782.76534332 2801.5818101   857.71552177 2809.71521219 2857.95502248]
total_rewards_mean           2117.238752740075
total_rewards_std            875.8016229525373
total_rewards_max            2857.9550224807567
total_rewards_min            857.7155217706448
Number of train steps total  440000
Number of env steps total    589829
Number of rollouts total     0
Train Time (s)               142.38109800219536
(Previous) Eval Time (s)     15.850535403005779
Sample Time (s)              6.064481562934816
Epoch Time (s)               164.29611496813595
Total Train Time (s)         16668.122860136442
Epoch                        109
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 13:08:34.343862 UTC | [2020_01_04_08_30_45] Iteration #109 | Epoch Duration: 171.51137804985046
2020-01-04 13:08:34.344058 UTC | [2020_01_04_08_30_45] Iteration #109 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0017644798
Z variance train             0.00020784214
KL Divergence                18.700718
KL Loss                      1.8700718
QF Loss                      273.89255
VF Loss                      60.382057
Policy Loss                  -1136.8876
Q Predictions Mean           1132.28
Q Predictions Std            208.35063
Q Predictions Max            1366.2153
Q Predictions Min            95.27991
V Predictions Mean           1134.45
V Predictions Std            205.25029
V Predictions Max            1366.2448
V Predictions Min            97.000084
Log Pis Mean                 0.06827189
Log Pis Std                  2.0571983
Log Pis Max                  5.5839987
Log Pis Min                  -5.9744444
Policy mu Mean               0.18907994
Policy mu Std                0.9243993
Policy mu Max                2.4321246
Policy mu Min                -2.6897025
Policy log std Mean          -0.526329
Policy log std Std           0.20172673
Policy log std Max           0.10678291
Policy log std Min           -1.1705018
Z mean eval                  0.0015333908
Z variance eval              0.00020565814
total_rewards                [ 660.95643095  687.43949789  989.38852699 1666.32783341 2893.17893671
 2874.5289126  1074.0861314   914.52782591 1725.18091368 1626.35869808]
total_rewards_mean           1511.1973707637892
total_rewards_std            779.2633976778008
total_rewards_max            2893.1789367097913
total_rewards_min            660.9564309461344
Number of train steps total  444000
Number of env steps total    594829
Number of rollouts total     0
Train Time (s)               143.89347871718928
(Previous) Eval Time (s)     23.065566264092922
Sample Time (s)              5.837573197670281
Epoch Time (s)               172.79661817895249
Total Train Time (s)         16833.733329853043
Epoch                        110
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 13:11:19.957625 UTC | [2020_01_04_08_30_45] Iteration #110 | Epoch Duration: 165.61339902877808
2020-01-04 13:11:19.957845 UTC | [2020_01_04_08_30_45] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0015135651
Z variance train             0.00020566012
KL Divergence                18.728502
KL Loss                      1.8728503
QF Loss                      1116.7477
VF Loss                      59.88489
Policy Loss                  -1129.6926
Q Predictions Mean           1130.6719
Q Predictions Std            224.68098
Q Predictions Max            1369.7347
Q Predictions Min            36.994747
V Predictions Mean           1132.8435
V Predictions Std            223.06372
V Predictions Max            1367.7269
V Predictions Min            59.21896
Log Pis Mean                 -0.20461097
Log Pis Std                  1.8639816
Log Pis Max                  6.52021
Log Pis Min                  -5.026688
Policy mu Mean               0.09138647
Policy mu Std                0.9018097
Policy mu Max                2.9651263
Policy mu Min                -4.5268126
Policy log std Mean          -0.51025075
Policy log std Std           0.19801255
Policy log std Max           0.16633695
Policy log std Min           -1.5975212
Z mean eval                  0.0015839633
Z variance eval              0.000203995
total_rewards                [1074.5072547   866.04491718 2842.42820725 1970.73277154 2900.33190813
 2830.45273446 2142.96089154 2848.80928964 1401.13851198 2777.71657494]
total_rewards_mean           2165.5123061342483
total_rewards_std            760.5019421475338
total_rewards_max            2900.331908126021
total_rewards_min            866.0449171782341
Number of train steps total  448000
Number of env steps total    600189
Number of rollouts total     0
Train Time (s)               142.967980787158
(Previous) Eval Time (s)     15.8821094436571
Sample Time (s)              5.818821420893073
Epoch Time (s)               164.66891165170819
Total Train Time (s)         17003.29098909488
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 13:14:09.516451 UTC | [2020_01_04_08_30_45] Iteration #111 | Epoch Duration: 169.55844616889954
2020-01-04 13:14:09.516626 UTC | [2020_01_04_08_30_45] Iteration #111 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0015883092
Z variance train             0.00020399613
KL Divergence                18.74952
KL Loss                      1.874952
QF Loss                      395.0801
VF Loss                      415.6686
Policy Loss                  -1119.479
Q Predictions Mean           1115.9756
Q Predictions Std            245.71045
Q Predictions Max            1361.6686
Q Predictions Min            51.01284
V Predictions Mean           1119.275
V Predictions Std            235.33432
V Predictions Max            1363.3259
V Predictions Min            43.81476
Log Pis Mean                 -0.13763238
Log Pis Std                  2.0791993
Log Pis Max                  9.54431
Log Pis Min                  -5.479353
Policy mu Mean               0.17002703
Policy mu Std                0.88166773
Policy mu Max                3.0087154
Policy mu Min                -2.6023853
Policy log std Mean          -0.5039858
Policy log std Std           0.21173398
Policy log std Max           0.16062146
Policy log std Min           -1.2488399
Z mean eval                  0.0017770488
Z variance eval              0.00020348099
total_rewards                [2723.85225299  992.90496717 2823.99662875 2863.85291796 2882.40111953
 2866.73028022 2940.35625017 2862.98622895 2903.50229223 2881.1976079 ]
total_rewards_mean           2674.17805458744
total_rewards_std            563.0229252642139
total_rewards_max            2940.356250173321
total_rewards_min            992.9049671686861
Number of train steps total  452000
Number of env steps total    605368
Number of rollouts total     0
Train Time (s)               143.6209256639704
(Previous) Eval Time (s)     20.7714073760435
Sample Time (s)              5.992844561114907
Epoch Time (s)               170.38517760112882
Total Train Time (s)         17180.204314838164
Epoch                        112
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 13:17:06.431643 UTC | [2020_01_04_08_30_45] Iteration #112 | Epoch Duration: 176.91488456726074
2020-01-04 13:17:06.431821 UTC | [2020_01_04_08_30_45] Iteration #112 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.001772571
Z variance train             0.00020348138
KL Divergence                18.753132
KL Loss                      1.8753132
QF Loss                      85.62505
VF Loss                      30.123592
Policy Loss                  -1127.3861
Q Predictions Mean           1127.9558
Q Predictions Std            238.02846
Q Predictions Max            1369.7854
Q Predictions Min            1.0107361
V Predictions Mean           1128.1759
V Predictions Std            235.01984
V Predictions Max            1363.8939
V Predictions Min            -8.543754
Log Pis Mean                 -0.07893817
Log Pis Std                  2.2009075
Log Pis Max                  14.807009
Log Pis Min                  -10.08074
Policy mu Mean               0.12574619
Policy mu Std                0.9143116
Policy mu Max                3.7389147
Policy mu Min                -3.134315
Policy log std Mean          -0.51764107
Policy log std Std           0.1849532
Policy log std Max           0.14854908
Policy log std Min           -1.1689342
Z mean eval                  0.0014644114
Z variance eval              0.0002010838
total_rewards                [ 881.28076795 2768.51202168 2784.66809109  863.17000519 2817.46151719
 2819.18720304 2807.30306322 2820.80444695 2789.58149431 2731.14168124]
total_rewards_mean           2408.311029184618
total_rewards_std            768.4938001243661
total_rewards_max            2820.80444694558
total_rewards_min            863.1700051851918
Number of train steps total  456000
Number of env steps total    610559
Number of rollouts total     0
Train Time (s)               145.63880994403735
(Previous) Eval Time (s)     27.30088720843196
Sample Time (s)              5.616879849694669
Epoch Time (s)               178.55657700216398
Total Train Time (s)         17354.792392022908
Epoch                        113
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 13:20:01.023265 UTC | [2020_01_04_08_30_45] Iteration #113 | Epoch Duration: 174.59129357337952
2020-01-04 13:20:01.023491 UTC | [2020_01_04_08_30_45] Iteration #113 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0014926376
Z variance train             0.00020107352
KL Divergence                18.783651
KL Loss                      1.8783652
QF Loss                      123.279076
VF Loss                      96.56117
Policy Loss                  -1099.6543
Q Predictions Mean           1096.4287
Q Predictions Std            269.72714
Q Predictions Max            1359.7872
Q Predictions Min            8.01612
V Predictions Mean           1098.2968
V Predictions Std            264.27194
V Predictions Max            1357.6213
V Predictions Min            -31.15848
Log Pis Mean                 -0.08492637
Log Pis Std                  2.126958
Log Pis Max                  16.148567
Log Pis Min                  -5.1562567
Policy mu Mean               0.2783737
Policy mu Std                0.90071416
Policy mu Max                4.003076
Policy mu Min                -3.0202954
Policy log std Mean          -0.50172424
Policy log std Std           0.19087501
Policy log std Max           0.07900518
Policy log std Min           -1.2997155
Z mean eval                  0.0006726809
Z variance eval              0.0001990144
total_rewards                [ 903.35520047 2049.07066039 2910.54371336 2909.00105095 1232.39690672
 2862.94956464 2861.17523864 2865.21662951 2906.96360023 2834.01041413]
total_rewards_mean           2433.468297905948
total_rewards_std            729.6395184156095
total_rewards_max            2910.543713363906
total_rewards_min            903.3552004673977
Number of train steps total  460000
Number of env steps total    615559
Number of rollouts total     0
Train Time (s)               142.04841520776972
(Previous) Eval Time (s)     23.335363960824907
Sample Time (s)              5.708840224891901
Epoch Time (s)               171.09261939348653
Total Train Time (s)         17525.754567851778
Epoch                        114
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 13:22:51.987138 UTC | [2020_01_04_08_30_45] Iteration #114 | Epoch Duration: 170.96344709396362
2020-01-04 13:22:51.987330 UTC | [2020_01_04_08_30_45] Iteration #114 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0006586361
Z variance train             0.00019901544
KL Divergence                18.809511
KL Loss                      1.8809512
QF Loss                      125.25208
VF Loss                      148.10812
Policy Loss                  -1118.2201
Q Predictions Mean           1114.3284
Q Predictions Std            265.02768
Q Predictions Max            1369.3877
Q Predictions Min            8.188556
V Predictions Mean           1118.0068
V Predictions Std            254.09218
V Predictions Max            1370.5585
V Predictions Min            54.285492
Log Pis Mean                 0.04794956
Log Pis Std                  2.5149536
Log Pis Max                  16.671478
Log Pis Min                  -5.8055315
Policy mu Mean               0.28028604
Policy mu Std                0.94547653
Policy mu Max                4.3126388
Policy mu Min                -2.9769895
Policy log std Mean          -0.48964453
Policy log std Std           0.20848122
Policy log std Max           0.11849451
Policy log std Min           -1.3770992
Z mean eval                  0.00085800345
Z variance eval              0.00019709145
total_rewards                [ 646.02364597  814.78673759 1140.80550441 2836.43583122 2748.87746276
 1100.79573043 2805.33363881 2757.74244229 2816.49228097 2833.81123953]
total_rewards_mean           2050.110451398471
total_rewards_std            927.6170778726695
total_rewards_max            2836.4358312225227
total_rewards_min            646.023645974607
Number of train steps total  464000
Number of env steps total    620600
Number of rollouts total     0
Train Time (s)               143.037441031076
(Previous) Eval Time (s)     23.205993263050914
Sample Time (s)              5.538686080370098
Epoch Time (s)               171.78212037449703
Total Train Time (s)         17694.31407626439
Epoch                        115
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 13:25:40.550953 UTC | [2020_01_04_08_30_45] Iteration #115 | Epoch Duration: 168.56348848342896
2020-01-04 13:25:40.551179 UTC | [2020_01_04_08_30_45] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.00085704366
Z variance train             0.00019709351
KL Divergence                18.834927
KL Loss                      1.8834927
QF Loss                      131.78381
VF Loss                      85.00609
Policy Loss                  -1136.8235
Q Predictions Mean           1130.1072
Q Predictions Std            259.3271
Q Predictions Max            1366.6663
Q Predictions Min            -12.346472
V Predictions Mean           1132.422
V Predictions Std            256.7201
V Predictions Max            1376.4984
V Predictions Min            -13.029852
Log Pis Mean                 -0.05004829
Log Pis Std                  1.995366
Log Pis Max                  7.481244
Log Pis Min                  -4.988627
Policy mu Mean               0.16412657
Policy mu Std                0.911565
Policy mu Max                3.2695026
Policy mu Min                -2.7520242
Policy log std Mean          -0.52425236
Policy log std Std           0.19879115
Policy log std Max           0.13213801
Policy log std Min           -1.3181524
Z mean eval                  0.0008649705
Z variance eval              0.00019473964
total_rewards                [ 855.30496115  843.12457689 1277.27221927  838.56935841  823.51090143
 2843.87205473  834.00658647  906.19447672 1723.22684434 2846.6074697 ]
total_rewards_mean           1379.1689449099788
total_rewards_std            781.7402037508249
total_rewards_max            2846.607469700421
total_rewards_min            823.5109014294546
Number of train steps total  468000
Number of env steps total    625790
Number of rollouts total     0
Train Time (s)               144.6986011317931
(Previous) Eval Time (s)     19.987147294916213
Sample Time (s)              5.363815751392394
Epoch Time (s)               170.04956417810172
Total Train Time (s)         17857.991678727325
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 13:28:24.229915 UTC | [2020_01_04_08_30_45] Iteration #116 | Epoch Duration: 163.67857146263123
2020-01-04 13:28:24.230067 UTC | [2020_01_04_08_30_45] Iteration #116 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0008361916
Z variance train             0.00019473446
KL Divergence                18.86422
KL Loss                      1.886422
QF Loss                      672.2466
VF Loss                      113.792625
Policy Loss                  -1108.6085
Q Predictions Mean           1100.801
Q Predictions Std            280.08038
Q Predictions Max            1368.6946
Q Predictions Min            -13.093055
V Predictions Mean           1114.042
V Predictions Std            270.99265
V Predictions Max            1377.0353
V Predictions Min            1.4681803
Log Pis Mean                 -0.14518057
Log Pis Std                  2.0385754
Log Pis Max                  8.448206
Log Pis Min                  -4.7862325
Policy mu Mean               0.16867127
Policy mu Std                0.9220426
Policy mu Max                3.5738118
Policy mu Min                -3.6341462
Policy log std Mean          -0.49217382
Policy log std Std           0.19486271
Policy log std Max           0.06745154
Policy log std Min           -1.4365385
Z mean eval                  0.0016529222
Z variance eval              0.00019202154
total_rewards                [1404.5048838  2831.49799249 1051.71925308 2850.89662045 2812.54044473
 2833.21141421 2825.00206879 2870.3889437  1059.42075732 2814.84015746]
total_rewards_mean           2335.402253602559
total_rewards_std            767.1792761313125
total_rewards_max            2870.388943698666
total_rewards_min            1051.7192530815166
Number of train steps total  472000
Number of env steps total    630790
Number of rollouts total     0
Train Time (s)               147.10426142672077
(Previous) Eval Time (s)     13.615918373223394
Sample Time (s)              5.192436806391925
Epoch Time (s)               165.9126166063361
Total Train Time (s)         18033.025351713877
Epoch                        117
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 13:31:19.266388 UTC | [2020_01_04_08_30_45] Iteration #117 | Epoch Duration: 175.03619694709778
2020-01-04 13:31:19.266577 UTC | [2020_01_04_08_30_45] Iteration #117 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.001657947
Z variance train             0.00019201661
KL Divergence                18.897018
KL Loss                      1.8897018
QF Loss                      153.09802
VF Loss                      1129.7816
Policy Loss                  -1136.5331
Q Predictions Mean           1128.1311
Q Predictions Std            240.14299
Q Predictions Max            1374.833
Q Predictions Min            -16.592657
V Predictions Mean           1133.0435
V Predictions Std            221.55122
V Predictions Max            1363.7987
V Predictions Min            23.867
Log Pis Mean                 0.17794016
Log Pis Std                  2.4247215
Log Pis Max                  18.285082
Log Pis Min                  -4.101431
Policy mu Mean               0.2920246
Policy mu Std                0.9658287
Policy mu Max                4.368454
Policy mu Min                -4.2373943
Policy log std Mean          -0.522445
Policy log std Std           0.20804308
Policy log std Max           0.2347042
Policy log std Min           -1.2978797
Z mean eval                  0.0010634976
Z variance eval              0.00019003444
total_rewards                [ 847.68364684  852.64271462 2949.67406842 2538.34913803 2954.2765609
 2944.78441765 2897.84095405 2947.76774608 2909.1681844  2940.13847909]
total_rewards_mean           2478.232591007576
total_rewards_std            822.6170928756069
total_rewards_max            2954.2765608997593
total_rewards_min            847.6836468359966
Number of train steps total  476000
Number of env steps total    635790
Number of rollouts total     0
Train Time (s)               144.3075319896452
(Previous) Eval Time (s)     22.739261392038316
Sample Time (s)              5.59130590967834
Epoch Time (s)               172.63809929136187
Total Train Time (s)         18205.05343344435
Epoch                        118
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 13:34:11.296905 UTC | [2020_01_04_08_30_45] Iteration #118 | Epoch Duration: 172.03017735481262
2020-01-04 13:34:11.297093 UTC | [2020_01_04_08_30_45] Iteration #118 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0010667301
Z variance train             0.00019003516
KL Divergence                18.923504
KL Loss                      1.8923504
QF Loss                      256.47736
VF Loss                      257.62338
Policy Loss                  -1145.4222
Q Predictions Mean           1143.6206
Q Predictions Std            258.87976
Q Predictions Max            1395.1815
Q Predictions Min            4.441766
V Predictions Mean           1142.9851
V Predictions Std            250.12079
V Predictions Max            1382.549
V Predictions Min            90.86573
Log Pis Mean                 0.3129559
Log Pis Std                  2.3740358
Log Pis Max                  18.93723
Log Pis Min                  -6.391162
Policy mu Mean               0.28613296
Policy mu Std                0.9602435
Policy mu Max                4.108993
Policy mu Min                -3.6984148
Policy log std Mean          -0.5211645
Policy log std Std           0.22406244
Policy log std Max           0.057145238
Policy log std Min           -2.2480893
Z mean eval                  0.0023546738
Z variance eval              0.00019013551
total_rewards                [2591.44035964 1665.09807236 2926.92448557 2856.44794331 2875.14821137
  868.39710003 2845.4125099   883.30984364 2843.80780624 2865.72331743]
total_rewards_mean           2322.1709649495847
total_rewards_std            805.3774881177862
total_rewards_max            2926.9244855687416
total_rewards_min            868.3971000289802
Number of train steps total  480000
Number of env steps total    640790
Number of rollouts total     0
Train Time (s)               143.82408761093393
(Previous) Eval Time (s)     22.131114698015153
Sample Time (s)              5.526077292393893
Epoch Time (s)               171.48127960134298
Total Train Time (s)         18376.69047317421
Epoch                        119
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 13:37:02.937644 UTC | [2020_01_04_08_30_45] Iteration #119 | Epoch Duration: 171.64034008979797
2020-01-04 13:37:02.937936 UTC | [2020_01_04_08_30_45] Iteration #119 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0023573986
Z variance train             0.00019013452
KL Divergence                18.922209
KL Loss                      1.8922209
QF Loss                      173.74438
VF Loss                      50.576344
Policy Loss                  -1179.313
Q Predictions Mean           1174.6106
Q Predictions Std            201.16472
Q Predictions Max            1376.1808
Q Predictions Min            -10.654584
V Predictions Mean           1176.1234
V Predictions Std            185.29562
V Predictions Max            1370.7283
V Predictions Min            72.850204
Log Pis Mean                 -0.2730676
Log Pis Std                  1.9676526
Log Pis Max                  11.064342
Log Pis Min                  -5.632942
Policy mu Mean               0.17440058
Policy mu Std                0.8519277
Policy mu Max                3.2377307
Policy mu Min                -2.5975628
Policy log std Mean          -0.5224958
Policy log std Std           0.18614909
Policy log std Max           0.2516389
Policy log std Min           -1.2217832
Z mean eval                  0.00181889
Z variance eval              0.00018951793
total_rewards                [ 901.15199953 1154.37560134 2826.4862624  1687.44814342 1093.33244534
 2863.73442254 2814.56470872 2834.93314232 2857.42544924 2841.80017225]
total_rewards_mean           2187.5252347102974
total_rewards_std            820.0107789177729
total_rewards_max            2863.7344225435104
total_rewards_min            901.151999528568
Number of train steps total  484000
Number of env steps total    645790
Number of rollouts total     0
Train Time (s)               144.93588787084445
(Previous) Eval Time (s)     22.28991770884022
Sample Time (s)              5.835136760957539
Epoch Time (s)               173.0609423406422
Total Train Time (s)         18546.776791433338
Epoch                        120
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 13:39:53.027673 UTC | [2020_01_04_08_30_45] Iteration #120 | Epoch Duration: 170.08951807022095
2020-01-04 13:39:53.027930 UTC | [2020_01_04_08_30_45] Iteration #120 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0018450643
Z variance train             0.00018951487
KL Divergence                18.929316
KL Loss                      1.8929316
QF Loss                      12421.137
VF Loss                      77.519165
Policy Loss                  -1130.8339
Q Predictions Mean           1132.4176
Q Predictions Std            239.66745
Q Predictions Max            1385.7336
Q Predictions Min            19.0932
V Predictions Mean           1137.5565
V Predictions Std            238.9492
V Predictions Max            1395.1771
V Predictions Min            17.513899
Log Pis Mean                 -0.13728984
Log Pis Std                  1.9132667
Log Pis Max                  5.8121705
Log Pis Min                  -5.3810477
Policy mu Mean               0.17826195
Policy mu Std                0.86999166
Policy mu Max                3.2614245
Policy mu Min                -2.6206815
Policy log std Mean          -0.5188584
Policy log std Std           0.19909345
Policy log std Max           0.13731807
Policy log std Min           -1.3802154
Z mean eval                  0.0022279818
Z variance eval              0.00018773376
total_rewards                [3047.77213019 1315.87215274 2944.85150236 2912.92902274 2898.18880765
 2898.08860063 2882.75686848 2898.8206496  2887.29787589 2853.60154238]
total_rewards_mean           2754.0179152670125
total_rewards_std            481.97391799992573
total_rewards_max            3047.7721301913834
total_rewards_min            1315.8721527433097
Number of train steps total  488000
Number of env steps total    650951
Number of rollouts total     0
Train Time (s)               142.05700774211437
(Previous) Eval Time (s)     19.318295198027045
Sample Time (s)              5.998816267121583
Epoch Time (s)               167.374119207263
Total Train Time (s)         18721.842225614935
Epoch                        121
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 13:42:48.173281 UTC | [2020_01_04_08_30_45] Iteration #121 | Epoch Duration: 175.14509510993958
2020-01-04 13:42:48.173587 UTC | [2020_01_04_08_30_45] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.002257259
Z variance train             0.00018773216
KL Divergence                18.953056
KL Loss                      1.8953056
QF Loss                      734.30664
VF Loss                      75.65216
Policy Loss                  -1149.2776
Q Predictions Mean           1149.6775
Q Predictions Std            250.98654
Q Predictions Max            1382.724
Q Predictions Min            18.016768
V Predictions Mean           1152.3215
V Predictions Std            247.30693
V Predictions Max            1382.7711
V Predictions Min            32.584084
Log Pis Mean                 0.07550544
Log Pis Std                  2.0963037
Log Pis Max                  12.40336
Log Pis Min                  -4.960532
Policy mu Mean               0.14625847
Policy mu Std                0.94269913
Policy mu Max                3.57409
Policy mu Min                -2.803834
Policy log std Mean          -0.49854314
Policy log std Std           0.19434413
Policy log std Max           0.035632133
Policy log std Min           -2.0163255
Z mean eval                  0.00059052976
Z variance eval              0.00018658012
total_rewards                [ 923.27782391  882.0391331  2918.5062767  1120.35892721  884.72486284
 2979.80083715 3004.42552738 2953.55871183 2962.52410945 3029.9215795 ]
total_rewards_mean           2165.9137789072493
total_rewards_std            993.000494036223
total_rewards_max            3029.921579497891
total_rewards_min            882.0391330987733
Number of train steps total  492000
Number of env steps total    655951
Number of rollouts total     0
Train Time (s)               144.13409058796242
(Previous) Eval Time (s)     27.08905518380925
Sample Time (s)              6.0089893084950745
Epoch Time (s)               177.23213508026674
Total Train Time (s)         18892.357556884177
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 13:45:38.613094 UTC | [2020_01_04_08_30_45] Iteration #122 | Epoch Duration: 170.43928956985474
2020-01-04 13:45:38.613342 UTC | [2020_01_04_08_30_45] Iteration #122 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0006948912
Z variance train             0.00018657921
KL Divergence                18.968323
KL Loss                      1.8968323
QF Loss                      790.1318
VF Loss                      197.14598
Policy Loss                  -1152.032
Q Predictions Mean           1149.6843
Q Predictions Std            234.92346
Q Predictions Max            1389.9933
Q Predictions Min            33.160892
V Predictions Mean           1150.6711
V Predictions Std            234.35396
V Predictions Max            1398.2489
V Predictions Min            12.319848
Log Pis Mean                 -0.17387392
Log Pis Std                  1.8413901
Log Pis Max                  5.7046967
Log Pis Min                  -5.407399
Policy mu Mean               0.21028705
Policy mu Std                0.87313896
Policy mu Max                2.7048512
Policy mu Min                -2.5470893
Policy log std Mean          -0.5204188
Policy log std Std           0.19079922
Policy log std Max           0.12315172
Policy log std Min           -1.290308
Z mean eval                  0.001686009
Z variance eval              0.00018553883
total_rewards                [ 953.47017895  694.47320672 2843.37003687 2686.92993143 2883.4757557
 1543.93727274 2885.07047497 2847.9449572  2855.16367299 2873.7772835 ]
total_rewards_mean           2306.761277107208
total_rewards_std            838.2971119925481
total_rewards_max            2885.0704749711203
total_rewards_min            694.4732067170817
Number of train steps total  496000
Number of env steps total    661146
Number of rollouts total     0
Train Time (s)               145.33919877931476
(Previous) Eval Time (s)     20.295971618965268
Sample Time (s)              6.121329751331359
Epoch Time (s)               171.75650014961138
Total Train Time (s)         19065.36103034625
Epoch                        123
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 13:48:31.619176 UTC | [2020_01_04_08_30_45] Iteration #123 | Epoch Duration: 173.00561785697937
2020-01-04 13:48:31.619415 UTC | [2020_01_04_08_30_45] Iteration #123 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0017297228
Z variance train             0.00018552523
KL Divergence                18.982948
KL Loss                      1.8982948
QF Loss                      528.53015
VF Loss                      296.71994
Policy Loss                  -1154.7183
Q Predictions Mean           1146.4857
Q Predictions Std            254.25555
Q Predictions Max            1393.5157
Q Predictions Min            -0.7280619
V Predictions Mean           1146.6699
V Predictions Std            236.7198
V Predictions Max            1382.2152
V Predictions Min            8.692491
Log Pis Mean                 -0.12090892
Log Pis Std                  2.6258938
Log Pis Max                  16.511005
Log Pis Min                  -5.9062934
Policy mu Mean               0.27852187
Policy mu Std                0.9173469
Policy mu Max                3.9240034
Policy mu Min                -3.784249
Policy log std Mean          -0.4934223
Policy log std Std           0.19931497
Policy log std Max           0.114631236
Policy log std Min           -2.45635
Z mean eval                  0.0019056934
Z variance eval              0.0001840848
total_rewards                [2826.9816274   855.39045669  885.92542737 2827.85024708 2817.6168696
 2878.18838619 2854.33629642 2861.54676804 2864.43236575 2907.97529768]
total_rewards_mean           2458.0243742198154
total_rewards_std            794.1153892221761
total_rewards_max            2907.9752976768673
total_rewards_min            855.390456690761
Number of train steps total  500000
Number of env steps total    666306
Number of rollouts total     0
Train Time (s)               144.13095609517768
(Previous) Eval Time (s)     21.54486705502495
Sample Time (s)              4.711942453403026
Epoch Time (s)               170.38776560360566
Total Train Time (s)         19237.659223230556
Epoch                        124
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 13:51:23.921121 UTC | [2020_01_04_08_30_45] Iteration #124 | Epoch Duration: 172.30150246620178
2020-01-04 13:51:23.921406 UTC | [2020_01_04_08_30_45] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0018705539
Z variance train             0.00018408365
KL Divergence                19.002312
KL Loss                      1.9002312
QF Loss                      107.67136
VF Loss                      95.09665
Policy Loss                  -1172.4713
Q Predictions Mean           1170.6213
Q Predictions Std            224.11688
Q Predictions Max            1393.191
Q Predictions Min            30.23348
V Predictions Mean           1166.7197
V Predictions Std            220.02858
V Predictions Max            1386.769
V Predictions Min            13.715734
Log Pis Mean                 -0.17359833
Log Pis Std                  1.7964778
Log Pis Max                  6.1460495
Log Pis Min                  -7.8803635
Policy mu Mean               0.13283134
Policy mu Std                0.8902769
Policy mu Max                2.6016622
Policy mu Min                -2.9964302
Policy log std Mean          -0.50288016
Policy log std Std           0.19572785
Policy log std Max           0.26319635
Policy log std Min           -1.2933993
Z mean eval                  0.0031507935
Z variance eval              0.00018219618
total_rewards                [2947.20944862 2816.78260877 2527.81351709 1115.12005598 2795.12817076
 1521.5311204  2815.42735467 2905.94625292 2822.42561988 2849.73712989]
total_rewards_mean           2511.712127897687
total_rewards_std            612.5932521709116
total_rewards_max            2947.2094486175492
total_rewards_min            1115.1200559830297
Number of train steps total  504000
Number of env steps total    671671
Number of rollouts total     0
Train Time (s)               141.80004542320967
(Previous) Eval Time (s)     23.458379555959255
Sample Time (s)              5.211958820465952
Epoch Time (s)               170.47038379963487
Total Train Time (s)         19407.623547216877
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 13:54:13.886476 UTC | [2020_01_04_08_30_45] Iteration #125 | Epoch Duration: 169.96486496925354
2020-01-04 13:54:13.886647 UTC | [2020_01_04_08_30_45] Iteration #125 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0031379417
Z variance train             0.00018219817
KL Divergence                19.029037
KL Loss                      1.9029038
QF Loss                      204.88025
VF Loss                      101.83984
Policy Loss                  -1150.17
Q Predictions Mean           1151.387
Q Predictions Std            243.30936
Q Predictions Max            1384.4183
Q Predictions Min            -11.083759
V Predictions Mean           1154.9541
V Predictions Std            239.2643
V Predictions Max            1388.1351
V Predictions Min            28.24198
Log Pis Mean                 -0.040707067
Log Pis Std                  2.0320125
Log Pis Max                  8.600474
Log Pis Min                  -6.633428
Policy mu Mean               0.14202604
Policy mu Std                0.87455267
Policy mu Max                3.5256286
Policy mu Min                -2.9154205
Policy log std Mean          -0.52787495
Policy log std Std           0.20582929
Policy log std Max           0.09892434
Policy log std Min           -1.2751973
Z mean eval                  0.0016955606
Z variance eval              0.00017840075
total_rewards                [ 964.55222882  957.17857695 2834.22149114 2832.03596161 2825.56849094
 2840.74435181 2859.80213562 2862.30051051 2811.40593228 2792.19756512]
total_rewards_mean           2458.000724479988
total_rewards_std            748.8246896937818
total_rewards_max            2862.3005105075654
total_rewards_min            957.1785769526367
Number of train steps total  508000
Number of env steps total    676671
Number of rollouts total     0
Train Time (s)               142.09806275600567
(Previous) Eval Time (s)     22.952655888162553
Sample Time (s)              5.57765137264505
Epoch Time (s)               170.62837001681328
Total Train Time (s)         19579.513425927144
Epoch                        126
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 13:57:05.780177 UTC | [2020_01_04_08_30_45] Iteration #126 | Epoch Duration: 171.8933756351471
2020-01-04 13:57:05.780403 UTC | [2020_01_04_08_30_45] Iteration #126 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.001699954
Z variance train             0.00017839645
KL Divergence                19.081615
KL Loss                      1.9081615
QF Loss                      109.96252
VF Loss                      183.5789
Policy Loss                  -1142.445
Q Predictions Mean           1137.2092
Q Predictions Std            250.71742
Q Predictions Max            1394.3065
Q Predictions Min            8.835217
V Predictions Mean           1146.5449
V Predictions Std            240.43373
V Predictions Max            1389.9067
V Predictions Min            19.484394
Log Pis Mean                 -0.091174744
Log Pis Std                  2.0218742
Log Pis Max                  14.626021
Log Pis Min                  -4.342116
Policy mu Mean               0.21708839
Policy mu Std                0.9010433
Policy mu Max                4.1204467
Policy mu Min                -3.2863705
Policy log std Mean          -0.51806444
Policy log std Std           0.20723829
Policy log std Max           0.049579978
Policy log std Min           -1.3126167
Z mean eval                  0.0008898171
Z variance eval              0.00017710845
total_rewards                [2244.02821628 1125.50616854 2975.85494575 2929.15607883 2081.77090874
 2819.87396547 2931.21477578 2904.92101738 2923.86989362 2865.84251761]
total_rewards_mean           2580.20384879864
total_rewards_std            569.3583859642285
total_rewards_max            2975.854945749306
total_rewards_min            1125.5061685377177
Number of train steps total  512000
Number of env steps total    681671
Number of rollouts total     0
Train Time (s)               143.39544550795108
(Previous) Eval Time (s)     24.21743228426203
Sample Time (s)              5.850354395806789
Epoch Time (s)               173.4632321880199
Total Train Time (s)         19753.48541784892
Epoch                        127
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 13:59:59.753455 UTC | [2020_01_04_08_30_45] Iteration #127 | Epoch Duration: 173.9728865623474
2020-01-04 13:59:59.753610 UTC | [2020_01_04_08_30_45] Iteration #127 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.00089669693
Z variance train             0.00017710663
KL Divergence                19.099918
KL Loss                      1.9099919
QF Loss                      339.6293
VF Loss                      61.275112
Policy Loss                  -1164.9761
Q Predictions Mean           1156.6769
Q Predictions Std            263.85822
Q Predictions Max            1394.0004
Q Predictions Min            19.825512
V Predictions Mean           1165.9956
V Predictions Std            234.41708
V Predictions Max            1397.6611
V Predictions Min            137.71713
Log Pis Mean                 -0.10718298
Log Pis Std                  2.2445338
Log Pis Max                  15.074043
Log Pis Min                  -5.008948
Policy mu Mean               0.15145165
Policy mu Std                0.94880486
Policy mu Max                4.15859
Policy mu Min                -3.3034682
Policy log std Mean          -0.49549794
Policy log std Std           0.2071518
Policy log std Max           0.09671742
Policy log std Min           -1.3396944
Z mean eval                  0.0015185884
Z variance eval              0.0001766485
total_rewards                [2925.49161249 2887.27900967 2817.01840384 2873.52021599 2855.21658209
 2882.35792334 2857.68622353 2824.5374506  2820.6084989  2829.17630742]
total_rewards_mean           2857.289222788365
total_rewards_std            33.58201984937858
total_rewards_max            2925.491612494529
total_rewards_min            2817.018403835363
Number of train steps total  516000
Number of env steps total    686671
Number of rollouts total     0
Train Time (s)               142.7185873328708
(Previous) Eval Time (s)     24.726882779970765
Sample Time (s)              5.493992884177715
Epoch Time (s)               172.9394629970193
Total Train Time (s)         19926.76010234328
Epoch                        128
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 14:02:53.030338 UTC | [2020_01_04_08_30_45] Iteration #128 | Epoch Duration: 173.2765974998474
2020-01-04 14:02:53.030517 UTC | [2020_01_04_08_30_45] Iteration #128 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0015181301
Z variance train             0.0001766513
KL Divergence                19.106407
KL Loss                      1.9106407
QF Loss                      161.37643
VF Loss                      55.433952
Policy Loss                  -1141.2302
Q Predictions Mean           1136.1299
Q Predictions Std            262.33383
Q Predictions Max            1399.7719
Q Predictions Min            47.978756
V Predictions Mean           1141.6644
V Predictions Std            250.59995
V Predictions Max            1397.097
V Predictions Min            50.12083
Log Pis Mean                 0.004598204
Log Pis Std                  2.1219208
Log Pis Max                  13.765554
Log Pis Min                  -4.479416
Policy mu Mean               0.20637114
Policy mu Std                0.9327474
Policy mu Max                3.710677
Policy mu Min                -2.8152494
Policy log std Mean          -0.49455252
Policy log std Std           0.20494755
Policy log std Max           0.19870019
Policy log std Min           -1.2554933
Z mean eval                  0.001533032
Z variance eval              0.0001766584
total_rewards                [1049.42298027 2358.92084367 2800.84923733 1250.68332483 1288.60103666
 1047.83437405 1122.64689037 2848.97682971 2800.61158198 2831.04414097]
total_rewards_mean           1939.9591239839506
total_rewards_std            802.1245554910946
total_rewards_max            2848.976829705686
total_rewards_min            1047.834374054945
Number of train steps total  520000
Number of env steps total    691671
Number of rollouts total     0
Train Time (s)               148.94321822421625
(Previous) Eval Time (s)     25.06378165492788
Sample Time (s)              4.877612526994199
Epoch Time (s)               178.88461240613833
Total Train Time (s)         20098.0019572936
Epoch                        129
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 14:05:44.276791 UTC | [2020_01_04_08_30_45] Iteration #129 | Epoch Duration: 171.24610781669617
2020-01-04 14:05:44.277076 UTC | [2020_01_04_08_30_45] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0015213087
Z variance train             0.00017665743
KL Divergence                19.1049
KL Loss                      1.91049
QF Loss                      3817.0938
VF Loss                      114.989815
Policy Loss                  -1142.6315
Q Predictions Mean           1139.886
Q Predictions Std            254.0568
Q Predictions Max            1410.7788
Q Predictions Min            23.731422
V Predictions Mean           1150.4481
V Predictions Std            246.95673
V Predictions Max            1417.0199
V Predictions Min            21.143242
Log Pis Mean                 -0.015868776
Log Pis Std                  2.0846248
Log Pis Max                  8.034643
Log Pis Min                  -4.4907413
Policy mu Mean               0.13329618
Policy mu Std                0.929045
Policy mu Max                3.272297
Policy mu Min                -2.6319213
Policy log std Mean          -0.5247985
Policy log std Std           0.18863434
Policy log std Max           0.14978212
Policy log std Min           -1.4780779
Z mean eval                  0.0016349362
Z variance eval              0.00017257356
total_rewards                [ 645.69797486  641.54891152 2924.46447307 2969.1867809  1596.68361046
 2909.33035943 1329.08411718 2927.65977761 2977.66191307 1078.1987574 ]
total_rewards_mean           1999.9516675493178
total_rewards_std            978.7363196784403
total_rewards_max            2977.6619130716217
total_rewards_min            641.5489115151131
Number of train steps total  524000
Number of env steps total    696671
Number of rollouts total     0
Train Time (s)               152.6475350749679
(Previous) Eval Time (s)     17.425032859668136
Sample Time (s)              5.704393737949431
Epoch Time (s)               175.77696167258546
Total Train Time (s)         20274.515771498904
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 14:08:40.790735 UTC | [2020_01_04_08_30_45] Iteration #130 | Epoch Duration: 176.51348280906677
2020-01-04 14:08:40.790867 UTC | [2020_01_04_08_30_45] Iteration #130 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0016477226
Z variance train             0.00017257058
KL Divergence                19.163715
KL Loss                      1.9163716
QF Loss                      106.58487
VF Loss                      57.830048
Policy Loss                  -1172.507
Q Predictions Mean           1174.0889
Q Predictions Std            254.3577
Q Predictions Max            1426.2662
Q Predictions Min            21.789488
V Predictions Mean           1170.7317
V Predictions Std            252.01114
V Predictions Max            1412.2225
V Predictions Min            62.406013
Log Pis Mean                 -0.57442033
Log Pis Std                  1.9235712
Log Pis Max                  10.465813
Log Pis Min                  -5.637407
Policy mu Mean               0.15865384
Policy mu Std                0.8369058
Policy mu Max                3.7100785
Policy mu Min                -2.9846334
Policy log std Mean          -0.48292932
Policy log std Std           0.19982518
Policy log std Max           0.13063186
Policy log std Min           -1.1938992
Z mean eval                  0.0014682388
Z variance eval              0.00017237067
total_rewards                [2825.77552066  376.41626112 2864.09557443 2898.72085565 2926.27847934
 2910.57111734 2898.17490035 2900.84012871 2838.02522623 2843.653411  ]
total_rewards_mean           2628.255147482828
total_rewards_std            751.308487257005
total_rewards_max            2926.278479336489
total_rewards_min            376.4162611196
Number of train steps total  528000
Number of env steps total    701671
Number of rollouts total     0
Train Time (s)               154.03407314885408
(Previous) Eval Time (s)     18.161400891374797
Sample Time (s)              4.900636177044362
Epoch Time (s)               177.09611021727324
Total Train Time (s)         20457.90084120212
Epoch                        131
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 14:11:44.179045 UTC | [2020_01_04_08_30_45] Iteration #131 | Epoch Duration: 183.38806295394897
2020-01-04 14:11:44.179275 UTC | [2020_01_04_08_30_45] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0014944443
Z variance train             0.00017237617
KL Divergence                19.166912
KL Loss                      1.9166912
QF Loss                      122.24223
VF Loss                      50.594284
Policy Loss                  -1184.9121
Q Predictions Mean           1185.0956
Q Predictions Std            213.15492
Q Predictions Max            1408.868
Q Predictions Min            14.502855
V Predictions Mean           1184.311
V Predictions Std            209.68903
V Predictions Max            1394.636
V Predictions Min            26.23018
Log Pis Mean                 -0.03969312
Log Pis Std                  2.1082313
Log Pis Max                  13.068773
Log Pis Min                  -4.674821
Policy mu Mean               0.20023029
Policy mu Std                0.9337264
Policy mu Max                3.680244
Policy mu Min                -3.0652483
Policy log std Mean          -0.49794862
Policy log std Std           0.2055094
Policy log std Max           0.09621656
Policy log std Min           -3.0890255
Z mean eval                  0.0017127559
Z variance eval              0.00016974966
total_rewards                [2870.15794227 2858.88564763 2850.56628534 2870.67412867 2878.16841031
 2856.88699657 2814.41132252 2869.2627867  2887.0548231  2868.66803285]
total_rewards_mean           2862.4736375961015
total_rewards_std            18.860476240798683
total_rewards_max            2887.054823100295
total_rewards_min            2814.411322515573
Number of train steps total  532000
Number of env steps total    706671
Number of rollouts total     0
Train Time (s)               153.77440419467166
(Previous) Eval Time (s)     24.453174400143325
Sample Time (s)              4.398404217325151
Epoch Time (s)               182.62598281214014
Total Train Time (s)         20640.930667412
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 14:14:47.210616 UTC | [2020_01_04_08_30_45] Iteration #132 | Epoch Duration: 183.0311815738678
2020-01-04 14:14:47.210815 UTC | [2020_01_04_08_30_45] Iteration #132 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0018146647
Z variance train             0.00016975298
KL Divergence                19.204935
KL Loss                      1.9204935
QF Loss                      141.55664
VF Loss                      229.67038
Policy Loss                  -1156.031
Q Predictions Mean           1157.6033
Q Predictions Std            268.1402
Q Predictions Max            1409.7097
Q Predictions Min            -0.95677495
V Predictions Mean           1155.0289
V Predictions Std            260.54712
V Predictions Max            1408.8242
V Predictions Min            16.189995
Log Pis Mean                 -0.26660445
Log Pis Std                  1.9655471
Log Pis Max                  14.80934
Log Pis Min                  -4.872409
Policy mu Mean               0.26554748
Policy mu Std                0.8505673
Policy mu Max                3.9584289
Policy mu Min                -3.6633484
Policy log std Mean          -0.48523793
Policy log std Std           0.20320356
Policy log std Max           0.19085717
Policy log std Min           -1.4860358
Z mean eval                  0.0011684748
Z variance eval              0.00016871752
total_rewards                [2591.97066342 2643.0206734  2751.52241105 2795.90432607 2791.87029563
 2761.50103554 2810.04476769 2795.93709602 2762.68249079 2119.33753329]
total_rewards_mean           2682.379129288918
total_rewards_std            199.57417913079738
total_rewards_max            2810.044767690022
total_rewards_min            2119.337533287169
Number of train steps total  536000
Number of env steps total    711671
Number of rollouts total     0
Train Time (s)               152.56250410806388
(Previous) Eval Time (s)     24.858201566152275
Sample Time (s)              4.9930121740326285
Epoch Time (s)               182.41371784824878
Total Train Time (s)         20823.308863362297
Epoch                        133
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 14:17:49.591168 UTC | [2020_01_04_08_30_45] Iteration #133 | Epoch Duration: 182.38014888763428
2020-01-04 14:17:49.591454 UTC | [2020_01_04_08_30_45] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0011543287
Z variance train             0.00016871879
KL Divergence                19.220417
KL Loss                      1.9220418
QF Loss                      99.49487
VF Loss                      147.91293
Policy Loss                  -1167.2598
Q Predictions Mean           1159.5092
Q Predictions Std            272.03973
Q Predictions Max            1419.3481
Q Predictions Min            3.9382582
V Predictions Mean           1164.5961
V Predictions Std            263.8824
V Predictions Max            1412.2788
V Predictions Min            -42.2283
Log Pis Mean                 0.12883607
Log Pis Std                  2.1516607
Log Pis Max                  12.235437
Log Pis Min                  -4.7756906
Policy mu Mean               0.17750703
Policy mu Std                0.9636993
Policy mu Max                3.8342068
Policy mu Min                -2.8902373
Policy log std Mean          -0.5046541
Policy log std Std           0.20789187
Policy log std Max           0.261948
Policy log std Min           -2.5179844
Z mean eval                  0.0025323513
Z variance eval              0.0001692253
total_rewards                [2159.9997646  1819.77078477 2748.35839683 2633.81340506 2527.39938693
 2889.02263523 2819.53239326 2525.10757916 2933.62767748 2794.3625001 ]
total_rewards_mean           2585.099452341469
total_rewards_std            333.9137044559493
total_rewards_max            2933.6276774846538
total_rewards_min            1819.7707847681852
Number of train steps total  540000
Number of env steps total    716671
Number of rollouts total     0
Train Time (s)               154.11098730005324
(Previous) Eval Time (s)     24.824443073943257
Sample Time (s)              4.892630521673709
Epoch Time (s)               183.8280608956702
Total Train Time (s)         21006.375196051784
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 14:20:52.659048 UTC | [2020_01_04_08_30_45] Iteration #134 | Epoch Duration: 183.06743931770325
2020-01-04 14:20:52.659220 UTC | [2020_01_04_08_30_45] Iteration #134 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0025458373
Z variance train             0.00016922771
KL Divergence                19.21211
KL Loss                      1.9212111
QF Loss                      313.08548
VF Loss                      40.550537
Policy Loss                  -1173.4271
Q Predictions Mean           1165.4331
Q Predictions Std            229.5221
Q Predictions Max            1403.2297
Q Predictions Min            89.74163
V Predictions Mean           1175.2621
V Predictions Std            220.8144
V Predictions Max            1405.5596
V Predictions Min            86.50663
Log Pis Mean                 -0.22716998
Log Pis Std                  2.1235304
Log Pis Max                  10.054956
Log Pis Min                  -4.8796825
Policy mu Mean               0.16481738
Policy mu Std                0.90363187
Policy mu Max                2.5350149
Policy mu Min                -2.7064793
Policy log std Mean          -0.477536
Policy log std Std           0.20982878
Policy log std Max           0.09695703
Policy log std Min           -1.260128
Z mean eval                  0.0010167126
Z variance eval              0.00016823651
total_rewards                [1255.54202426 3031.95035467 2933.13192535 2922.02968692 2847.97743604
 2931.70551807 2865.3105381  2851.73290706 2896.07668361 2926.29643189]
total_rewards_mean           2746.1753505972883
total_rewards_std            499.4564332171098
total_rewards_max            3031.9503546661913
total_rewards_min            1255.542024260827
Number of train steps total  544000
Number of env steps total    721671
Number of rollouts total     0
Train Time (s)               149.26672942517325
(Previous) Eval Time (s)     24.063656657002866
Sample Time (s)              4.143432615324855
Epoch Time (s)               177.47381869750097
Total Train Time (s)         21183.63600405911
Epoch                        135
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 14:23:49.927746 UTC | [2020_01_04_08_30_45] Iteration #135 | Epoch Duration: 177.26831912994385
2020-01-04 14:23:49.928056 UTC | [2020_01_04_08_30_45] Iteration #135 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.00093953696
Z variance train             0.00016823711
KL Divergence                19.227085
KL Loss                      1.9227085
QF Loss                      124.53926
VF Loss                      80.780045
Policy Loss                  -1199.7087
Q Predictions Mean           1196.6235
Q Predictions Std            213.96637
Q Predictions Max            1412.9854
Q Predictions Min            74.83154
V Predictions Mean           1193.0609
V Predictions Std            211.00058
V Predictions Max            1413.2953
V Predictions Min            93.75448
Log Pis Mean                 -0.14428449
Log Pis Std                  1.9013488
Log Pis Max                  5.833802
Log Pis Min                  -6.1368084
Policy mu Mean               0.1842597
Policy mu Std                0.8427656
Policy mu Max                2.6835768
Policy mu Min                -2.5547323
Policy log std Mean          -0.48498538
Policy log std Std           0.21868886
Policy log std Max           0.25237864
Policy log std Min           -1.2661761
Z mean eval                  0.0018246978
Z variance eval              0.00016650019
total_rewards                [3062.33707308 3015.17871101 2907.76733286 2955.18457085 2906.3335396
 2897.19868235 2908.39855777 2913.77959336 2912.74674611 2911.03417828]
total_rewards_mean           2938.9958985273397
total_rewards_std            53.019746096705525
total_rewards_max            3062.3370730755573
total_rewards_min            2897.198682354544
Number of train steps total  548000
Number of env steps total    726671
Number of rollouts total     0
Train Time (s)               146.7246108967811
(Previous) Eval Time (s)     23.85798559617251
Sample Time (s)              5.063143280334771
Epoch Time (s)               175.64573977328837
Total Train Time (s)         21360.697029207833
Epoch                        136
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 14:26:46.985734 UTC | [2020_01_04_08_30_45] Iteration #136 | Epoch Duration: 177.05749607086182
2020-01-04 14:26:46.985951 UTC | [2020_01_04_08_30_45] Iteration #136 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0018525945
Z variance train             0.00016650224
KL Divergence                19.252842
KL Loss                      1.9252843
QF Loss                      181.42926
VF Loss                      574.1964
Policy Loss                  -1173.1185
Q Predictions Mean           1167.2628
Q Predictions Std            240.69766
Q Predictions Max            1403.6635
Q Predictions Min            -1.0140845
V Predictions Mean           1175.2374
V Predictions Std            223.15196
V Predictions Max            1415.0264
V Predictions Min            24.66008
Log Pis Mean                 -0.09527741
Log Pis Std                  2.0636806
Log Pis Max                  12.549885
Log Pis Min                  -5.313237
Policy mu Mean               0.13474706
Policy mu Std                0.90187454
Policy mu Max                3.7789514
Policy mu Min                -2.749735
Policy log std Mean          -0.5022181
Policy log std Std           0.20814295
Policy log std Max           0.18765849
Policy log std Min           -1.8628888
Z mean eval                  0.0018878151
Z variance eval              0.00016606579
total_rewards                [3016.28144646 3071.09127858 2885.81661636 1396.76989502 2773.91876484
 2937.40692008 2879.74204223 1549.31281526 2908.51663758 2315.75789496]
total_rewards_mean           2573.4614311367304
total_rewards_std            584.7986430851116
total_rewards_max            3071.0912785833693
total_rewards_min            1396.7698950241297
Number of train steps total  552000
Number of env steps total    731710
Number of rollouts total     0
Train Time (s)               153.5710917687975
(Previous) Eval Time (s)     25.26954251015559
Sample Time (s)              5.642777252942324
Epoch Time (s)               184.4834115318954
Total Train Time (s)         21541.856696680188
Epoch                        137
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 14:29:48.147682 UTC | [2020_01_04_08_30_45] Iteration #137 | Epoch Duration: 181.1614978313446
2020-01-04 14:29:48.147991 UTC | [2020_01_04_08_30_45] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0018681422
Z variance train             0.0001660636
KL Divergence                19.259945
KL Loss                      1.9259945
QF Loss                      113.903656
VF Loss                      42.710175
Policy Loss                  -1181.1896
Q Predictions Mean           1179.0923
Q Predictions Std            242.04446
Q Predictions Max            1416.2311
Q Predictions Min            9.314272
V Predictions Mean           1179.4618
V Predictions Std            237.69336
V Predictions Max            1408.2457
V Predictions Min            21.432467
Log Pis Mean                 -0.23640186
Log Pis Std                  2.0724854
Log Pis Max                  8.667679
Log Pis Min                  -5.765785
Policy mu Mean               0.17499311
Policy mu Std                0.88195485
Policy mu Max                2.567654
Policy mu Min                -2.6924586
Policy log std Mean          -0.5134445
Policy log std Std           0.20175861
Policy log std Max           0.108594656
Policy log std Min           -1.62028
Z mean eval                  0.0029943348
Z variance eval              0.00016504464
total_rewards                [2124.61479341 2929.79655879 2914.64793132 2934.75105152 2967.02868233
 2863.56194655 2862.48595507 2882.64459084 2923.93554953 2916.79025855]
total_rewards_mean           2832.025731791861
total_rewards_std            237.8468315337726
total_rewards_max            2967.028682327581
total_rewards_min            2124.614793408909
Number of train steps total  556000
Number of env steps total    736747
Number of rollouts total     0
Train Time (s)               154.36634426983073
(Previous) Eval Time (s)     21.94738888507709
Sample Time (s)              5.679347855038941
Epoch Time (s)               181.99308100994676
Total Train Time (s)         21725.323032733984
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 14:32:51.615354 UTC | [2020_01_04_08_30_45] Iteration #138 | Epoch Duration: 183.46718668937683
2020-01-04 14:32:51.615540 UTC | [2020_01_04_08_30_45] Iteration #138 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0029542942
Z variance train             0.00016504127
KL Divergence                19.276852
KL Loss                      1.9276851
QF Loss                      170.30905
VF Loss                      178.75575
Policy Loss                  -1198.9362
Q Predictions Mean           1185.6416
Q Predictions Std            236.28731
Q Predictions Max            1418.9269
Q Predictions Min            -26.644
V Predictions Mean           1193.4885
V Predictions Std            205.60501
V Predictions Max            1417.1451
V Predictions Min            56.25971
Log Pis Mean                 -0.28809696
Log Pis Std                  2.2648857
Log Pis Max                  14.28668
Log Pis Min                  -5.7245812
Policy mu Mean               0.3154025
Policy mu Std                0.8320093
Policy mu Max                3.854742
Policy mu Min                -2.613129
Policy log std Mean          -0.48403335
Policy log std Std           0.2212231
Policy log std Max           0.10042226
Policy log std Min           -2.0253453
Z mean eval                  0.0015187259
Z variance eval              0.00016295367
total_rewards                [2806.48433253 2737.56460341 2844.7865586  1893.01187434 2945.70779123
 2875.52172178 1831.93905439 2840.60851634 1242.63960482  929.75809586]
total_rewards_mean           2294.8022153300276
total_rewards_std            718.695138584651
total_rewards_max            2945.7077912266795
total_rewards_min            929.7580958578139
Number of train steps total  560000
Number of env steps total    741747
Number of rollouts total     0
Train Time (s)               152.1424825200811
(Previous) Eval Time (s)     23.421333295293152
Sample Time (s)              5.459871707018465
Epoch Time (s)               181.02368752239272
Total Train Time (s)         21902.401030680165
Epoch                        139
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 14:35:48.694185 UTC | [2020_01_04_08_30_45] Iteration #139 | Epoch Duration: 177.07851004600525
2020-01-04 14:35:48.694322 UTC | [2020_01_04_08_30_45] Iteration #139 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0015151023
Z variance train             0.00016295825
KL Divergence                19.308437
KL Loss                      1.9308437
QF Loss                      98.39341
VF Loss                      30.07391
Policy Loss                  -1198.1156
Q Predictions Mean           1196.539
Q Predictions Std            240.17673
Q Predictions Max            1418.8195
Q Predictions Min            15.193616
V Predictions Mean           1199.9604
V Predictions Std            232.57141
V Predictions Max            1412.3928
V Predictions Min            18.737282
Log Pis Mean                 -0.24077311
Log Pis Std                  1.9868293
Log Pis Max                  11.957987
Log Pis Min                  -4.5785937
Policy mu Mean               0.09424943
Policy mu Std                0.88264966
Policy mu Max                2.6676733
Policy mu Min                -3.2613804
Policy log std Mean          -0.5080157
Policy log std Std           0.1990264
Policy log std Max           0.2513857
Policy log std Min           -1.2667108
Z mean eval                  0.00095531915
Z variance eval              0.00016218588
total_rewards                [3009.59026906 2101.8637141  2894.79732953 2932.67294871 2919.61789083
 2894.09919939 2913.23464787 2907.66212249 2911.991615   2901.67023478]
total_rewards_mean           2838.719997175309
total_rewards_std            247.66386362797306
total_rewards_max            3009.5902690628186
total_rewards_min            2101.863714097541
Number of train steps total  564000
Number of env steps total    746747
Number of rollouts total     0
Train Time (s)               153.52043987391517
(Previous) Eval Time (s)     19.475952338892967
Sample Time (s)              5.62030596844852
Epoch Time (s)               178.61669818125665
Total Train Time (s)         22086.281754483934
Epoch                        140
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 14:38:52.579540 UTC | [2020_01_04_08_30_45] Iteration #140 | Epoch Duration: 183.8850336074829
2020-01-04 14:38:52.579827 UTC | [2020_01_04_08_30_45] Iteration #140 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0009147256
Z variance train             0.00016219597
KL Divergence                19.321712
KL Loss                      1.9321712
QF Loss                      119.00745
VF Loss                      72.52888
Policy Loss                  -1176.3323
Q Predictions Mean           1178.7957
Q Predictions Std            277.64127
Q Predictions Max            1423.7391
Q Predictions Min            10.519129
V Predictions Mean           1179.668
V Predictions Std            274.84448
V Predictions Max            1422.65
V Predictions Min            -16.255753
Log Pis Mean                 -0.17238966
Log Pis Std                  2.0470088
Log Pis Max                  12.400544
Log Pis Min                  -4.42645
Policy mu Mean               0.25669605
Policy mu Std                0.83349335
Policy mu Max                3.6979806
Policy mu Min                -2.6040905
Policy log std Mean          -0.5080685
Policy log std Std           0.20388898
Policy log std Max           0.060527623
Policy log std Min           -1.549088
Z mean eval                  0.0018511597
Z variance eval              0.00016053978
total_rewards                [2924.28397814 2980.39050861 2968.03193452 2939.0163584  2923.379955
 2932.16021438 2938.640526   2929.58121057 2939.56977691 2918.12950985]
total_rewards_mean           2939.318397237156
total_rewards_std            18.9396106543193
total_rewards_max            2980.3905086058903
total_rewards_min            2918.1295098507458
Number of train steps total  568000
Number of env steps total    751747
Number of rollouts total     0
Train Time (s)               153.07473785197362
(Previous) Eval Time (s)     24.744084922596812
Sample Time (s)              5.044644533190876
Epoch Time (s)               182.8634673077613
Total Train Time (s)         22271.232796157245
Epoch                        141
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 14:41:57.532369 UTC | [2020_01_04_08_30_45] Iteration #141 | Epoch Duration: 184.95238947868347
2020-01-04 14:41:57.532532 UTC | [2020_01_04_08_30_45] Iteration #141 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0018666051
Z variance train             0.00016054124
KL Divergence                19.348034
KL Loss                      1.9348034
QF Loss                      170.53932
VF Loss                      47.911633
Policy Loss                  -1177.8884
Q Predictions Mean           1172.9253
Q Predictions Std            261.44864
Q Predictions Max            1431.6078
Q Predictions Min            -3.6956315
V Predictions Mean           1177.1923
V Predictions Std            253.48882
V Predictions Max            1434.2699
V Predictions Min            31.08514
Log Pis Mean                 -0.1204204
Log Pis Std                  2.2058015
Log Pis Max                  15.252213
Log Pis Min                  -6.3267574
Policy mu Mean               0.17246437
Policy mu Std                0.899681
Policy mu Max                4.521783
Policy mu Min                -2.8337116
Policy log std Mean          -0.50193125
Policy log std Std           0.21704589
Policy log std Max           0.21973038
Policy log std Min           -1.476479
Z mean eval                  0.0015875071
Z variance eval              0.00016011819
total_rewards                [ 200.10388706  189.30580399 2927.32564348 2931.89941805 2877.0945035
 2920.66682158 2932.54443671 1310.14261675 2982.9034453  2941.30186915]
total_rewards_mean           2221.328844557197
total_rewards_std            1121.2206375510186
total_rewards_max            2982.9034453005324
total_rewards_min            189.30580398789084
Number of train steps total  572000
Number of env steps total    756747
Number of rollouts total     0
Train Time (s)               151.61166125210002
(Previous) Eval Time (s)     26.832840260118246
Sample Time (s)              4.871524273883551
Epoch Time (s)               183.31602578610182
Total Train Time (s)         22446.99505562475
Epoch                        142
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 14:44:53.296704 UTC | [2020_01_04_08_30_45] Iteration #142 | Epoch Duration: 175.76403832435608
2020-01-04 14:44:53.296883 UTC | [2020_01_04_08_30_45] Iteration #142 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0015667292
Z variance train             0.00016011577
KL Divergence                19.353928
KL Loss                      1.9353927
QF Loss                      164.2079
VF Loss                      111.78882
Policy Loss                  -1199.7057
Q Predictions Mean           1189.0182
Q Predictions Std            247.20697
Q Predictions Max            1418.9725
Q Predictions Min            -11.63814
V Predictions Mean           1191.9714
V Predictions Std            221.34572
V Predictions Max            1410.5784
V Predictions Min            -8.465655
Log Pis Mean                 -0.2515122
Log Pis Std                  2.265207
Log Pis Max                  15.010092
Log Pis Min                  -5.8602066
Policy mu Mean               0.15957701
Policy mu Std                0.88167554
Policy mu Max                3.1130667
Policy mu Min                -3.408573
Policy log std Mean          -0.5029953
Policy log std Std           0.22361581
Policy log std Max           0.13968933
Policy log std Min           -1.3190398
Z mean eval                  0.0017630961
Z variance eval              0.00015753254
total_rewards                [2949.09164168 2947.07995727 2927.67565227 2887.45383483 2888.16784254
 2946.02197663 2919.763403   2896.23637664 2921.75825258 2879.68878573]
total_rewards_mean           2916.293772318063
total_rewards_std            25.38451438971427
total_rewards_max            2949.091641677874
total_rewards_min            2879.688785731296
Number of train steps total  576000
Number of env steps total    761747
Number of rollouts total     0
Train Time (s)               153.40965085383505
(Previous) Eval Time (s)     19.280675807967782
Sample Time (s)              4.974579273723066
Epoch Time (s)               177.6649059355259
Total Train Time (s)         22631.235322773922
Epoch                        143
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 14:47:57.539445 UTC | [2020_01_04_08_30_45] Iteration #143 | Epoch Duration: 184.24235796928406
2020-01-04 14:47:57.539715 UTC | [2020_01_04_08_30_45] Iteration #143 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0017707308
Z variance train             0.00015753284
KL Divergence                19.393269
KL Loss                      1.9393269
QF Loss                      925.4924
VF Loss                      113.34689
Policy Loss                  -1179.5549
Q Predictions Mean           1172.6575
Q Predictions Std            247.13692
Q Predictions Max            1424.4435
Q Predictions Min            -26.341215
V Predictions Mean           1178.4077
V Predictions Std            240.38957
V Predictions Max            1426.0208
V Predictions Min            18.216345
Log Pis Mean                 -0.054544173
Log Pis Std                  1.8511391
Log Pis Max                  11.411186
Log Pis Min                  -3.671969
Policy mu Mean               0.28991637
Policy mu Std                0.8707933
Policy mu Max                3.8479366
Policy mu Min                -2.936149
Policy log std Mean          -0.49481782
Policy log std Std           0.2155254
Policy log std Max           0.14518195
Policy log std Min           -1.6736606
Z mean eval                  0.0017325159
Z variance eval              0.00015820948
total_rewards                [1861.41370112 1350.96152011 1411.41137062 2911.48308891 2920.89656337
 2929.03656203  877.44834825 2916.16725986 2973.28613187 2928.04278236]
total_rewards_mean           2308.0147328495614
total_rewards_std            792.979049115838
total_rewards_max            2973.286131873983
total_rewards_min            877.4483482535464
Number of train steps total  580000
Number of env steps total    766747
Number of rollouts total     0
Train Time (s)               143.41091209230945
(Previous) Eval Time (s)     25.857938607223332
Sample Time (s)              4.829556436277926
Epoch Time (s)               174.0984071358107
Total Train Time (s)         22798.81272425782
Epoch                        144
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 14:50:45.120778 UTC | [2020_01_04_08_30_45] Iteration #144 | Epoch Duration: 167.58091235160828
2020-01-04 14:50:45.120934 UTC | [2020_01_04_08_30_45] Iteration #144 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0017352419
Z variance train             0.00015819875
KL Divergence                19.38343
KL Loss                      1.938343
QF Loss                      133.62396
VF Loss                      43.3387
Policy Loss                  -1195.3033
Q Predictions Mean           1190.9688
Q Predictions Std            251.86523
Q Predictions Max            1416.7098
Q Predictions Min            -22.174736
V Predictions Mean           1193.9658
V Predictions Std            244.95192
V Predictions Max            1414.1823
V Predictions Min            -15.800172
Log Pis Mean                 0.011070892
Log Pis Std                  1.9856508
Log Pis Max                  9.485855
Log Pis Min                  -4.932852
Policy mu Mean               0.16692238
Policy mu Std                0.8987278
Policy mu Max                3.6465986
Policy mu Min                -2.6297934
Policy log std Mean          -0.51884675
Policy log std Std           0.18981592
Policy log std Max           0.113318145
Policy log std Min           -1.358381
Z mean eval                  0.0017761557
Z variance eval              0.0001567519
total_rewards                [1170.8221436  2913.84655651 2986.38494028 1317.97260902 2866.6960153
 2903.08804649 1653.75225674 2923.35501853 2946.40808916 2920.89293638]
total_rewards_mean           2460.3218612000833
total_rewards_std            715.8728912291303
total_rewards_max            2986.3849402771034
total_rewards_min            1170.822143602151
Number of train steps total  584000
Number of env steps total    771747
Number of rollouts total     0
Train Time (s)               143.83821740932763
(Previous) Eval Time (s)     19.340217957273126
Sample Time (s)              5.249952369369566
Epoch Time (s)               168.42838773597032
Total Train Time (s)         22968.67850778997
Epoch                        145
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 14:53:34.990066 UTC | [2020_01_04_08_30_45] Iteration #145 | Epoch Duration: 169.86898064613342
2020-01-04 14:53:34.990318 UTC | [2020_01_04_08_30_45] Iteration #145 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0018065411
Z variance train             0.00015674967
KL Divergence                19.406647
KL Loss                      1.9406646
QF Loss                      170.14307
VF Loss                      47.95905
Policy Loss                  -1224.0078
Q Predictions Mean           1220.4744
Q Predictions Std            222.51619
Q Predictions Max            1435.7428
Q Predictions Min            9.589529
V Predictions Mean           1224.9006
V Predictions Std            221.17624
V Predictions Max            1436.1628
V Predictions Min            -16.727598
Log Pis Mean                 -0.27171877
Log Pis Std                  1.732951
Log Pis Max                  5.9795017
Log Pis Min                  -5.845373
Policy mu Mean               0.22096257
Policy mu Std                0.8231233
Policy mu Max                2.4646323
Policy mu Min                -2.3759768
Policy log std Mean          -0.48569098
Policy log std Std           0.19848725
Policy log std Max           0.45470256
Policy log std Min           -1.12659
Z mean eval                  0.0012611188
Z variance eval              0.00015752634
total_rewards                [1438.62186639  804.03313953 2856.7659504  2829.04158264 2834.93217127
 2878.36146839 2859.52984994 2873.38556363 2865.49451819 2774.03560762]
total_rewards_mean           2501.420171799441
total_rewards_std            705.0570530962423
total_rewards_max            2878.361468385117
total_rewards_min            804.0331395331058
Number of train steps total  588000
Number of env steps total    776747
Number of rollouts total     0
Train Time (s)               142.354743657168
(Previous) Eval Time (s)     20.78059711586684
Sample Time (s)              5.024981333408505
Epoch Time (s)               168.16032210644335
Total Train Time (s)         23141.42600461468
Epoch                        146
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 14:56:27.741720 UTC | [2020_01_04_08_30_45] Iteration #146 | Epoch Duration: 172.75110578536987
2020-01-04 14:56:27.742089 UTC | [2020_01_04_08_30_45] Iteration #146 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.001367265
Z variance train             0.00015751849
KL Divergence                19.394464
KL Loss                      1.9394464
QF Loss                      524.4486
VF Loss                      862.48895
Policy Loss                  -1187.8118
Q Predictions Mean           1181.98
Q Predictions Std            263.53955
Q Predictions Max            1434.865
Q Predictions Min            32.297054
V Predictions Mean           1189.9949
V Predictions Std            242.02666
V Predictions Max            1433.932
V Predictions Min            53.306538
Log Pis Mean                 -0.11527634
Log Pis Std                  2.1959581
Log Pis Max                  17.222515
Log Pis Min                  -5.977985
Policy mu Mean               0.073369324
Policy mu Std                0.8988105
Policy mu Max                2.0729523
Policy mu Min                -3.8542337
Policy log std Mean          -0.5233746
Policy log std Std           0.19972943
Policy log std Max           0.0974372
Policy log std Min           -1.2828903
Z mean eval                  0.0015177239
Z variance eval              0.00015600637
total_rewards                [2849.63035208 1547.83510732 2955.53197154 2933.40587657 2962.62804581
 2916.83902952 2933.65410189 2967.03508857 2888.00594554 2009.56205736]
total_rewards_mean           2696.412757621003
total_rewards_std            471.5362989233516
total_rewards_max            2967.0350885674497
total_rewards_min            1547.8351073206568
Number of train steps total  592000
Number of env steps total    781831
Number of rollouts total     0
Train Time (s)               142.84835854079574
(Previous) Eval Time (s)     25.37117020599544
Sample Time (s)              5.458277043886483
Epoch Time (s)               173.67780579067767
Total Train Time (s)         23314.827616964
Epoch                        147
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 14:59:21.144562 UTC | [2020_01_04_08_30_45] Iteration #147 | Epoch Duration: 173.40226221084595
2020-01-04 14:59:21.144740 UTC | [2020_01_04_08_30_45] Iteration #147 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0015189259
Z variance train             0.00015601129
KL Divergence                19.417442
KL Loss                      1.9417442
QF Loss                      162.33105
VF Loss                      182.80115
Policy Loss                  -1162.5323
Q Predictions Mean           1167.5359
Q Predictions Std            296.71518
Q Predictions Max            1441.5875
Q Predictions Min            -28.650042
V Predictions Mean           1173.0854
V Predictions Std            284.60977
V Predictions Max            1433.1411
V Predictions Min            -9.956082
Log Pis Mean                 -0.1626153
Log Pis Std                  1.7912319
Log Pis Max                  6.1105366
Log Pis Min                  -4.502233
Policy mu Mean               0.15084536
Policy mu Std                0.86093765
Policy mu Max                2.8496852
Policy mu Min                -2.6629467
Policy log std Mean          -0.5088952
Policy log std Std           0.19463983
Policy log std Max           0.15284818
Policy log std Min           -1.1532025
Z mean eval                  0.0017126206
Z variance eval              0.00015332285
total_rewards                [2914.13849454 1575.71142308 2197.17214046 2970.60780778 2668.84829269
 2869.35035031 1682.74610216 2924.17862361 2902.99859094 2945.69085689]
total_rewards_mean           2565.1442682459033
total_rewards_std            516.7560159477501
total_rewards_max            2970.6078077826105
total_rewards_min            1575.7114230801228
Number of train steps total  596000
Number of env steps total    786831
Number of rollouts total     0
Train Time (s)               141.61644619097933
(Previous) Eval Time (s)     25.095417436677963
Sample Time (s)              5.489760040771216
Epoch Time (s)               172.2016236684285
Total Train Time (s)         23486.546930774115
Epoch                        148
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 15:02:12.865809 UTC | [2020_01_04_08_30_45] Iteration #148 | Epoch Duration: 171.72093105316162
2020-01-04 15:02:12.865984 UTC | [2020_01_04_08_30_45] Iteration #148 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.001710776
Z variance train             0.00015332343
KL Divergence                19.460808
KL Loss                      1.9460808
QF Loss                      2818.4312
VF Loss                      52.519745
Policy Loss                  -1213.5209
Q Predictions Mean           1213.367
Q Predictions Std            230.21661
Q Predictions Max            1424.4087
Q Predictions Min            -0.3831749
V Predictions Mean           1216.6708
V Predictions Std            219.48114
V Predictions Max            1426.5691
V Predictions Min            -5.982397
Log Pis Mean                 -0.06563921
Log Pis Std                  2.1315403
Log Pis Max                  16.989025
Log Pis Min                  -5.1320944
Policy mu Mean               0.21952792
Policy mu Std                0.86087424
Policy mu Max                3.9997854
Policy mu Min                -3.4590344
Policy log std Mean          -0.51207894
Policy log std Std           0.22302367
Policy log std Max           0.2500205
Policy log std Min           -2.663712
Z mean eval                  0.0012752266
Z variance eval              0.00015407326
total_rewards                [2760.86235781 1289.48826146  822.64152749 2899.80110105 1486.84719378
 2902.31672924 2897.84787782 2016.00605131 1787.58118176 1559.9202659 ]
total_rewards_mean           2042.3312547625592
total_rewards_std            733.7788710215926
total_rewards_max            2902.3167292445883
total_rewards_min            822.6415274925703
Number of train steps total  600000
Number of env steps total    792030
Number of rollouts total     0
Train Time (s)               142.79194933595136
(Previous) Eval Time (s)     24.614514754153788
Sample Time (s)              5.747993552591652
Epoch Time (s)               173.1544576426968
Total Train Time (s)         23652.886991642416
Epoch                        149
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 15:04:59.210823 UTC | [2020_01_04_08_30_45] Iteration #149 | Epoch Duration: 166.34469890594482
2020-01-04 15:04:59.210991 UTC | [2020_01_04_08_30_45] Iteration #149 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.001272972
Z variance train             0.00015407571
KL Divergence                19.448658
KL Loss                      1.9448658
QF Loss                      328.99722
VF Loss                      28.88868
Policy Loss                  -1203.042
Q Predictions Mean           1199.3176
Q Predictions Std            261.56897
Q Predictions Max            1441.5463
Q Predictions Min            -3.4001155
V Predictions Mean           1204.5212
V Predictions Std            253.31653
V Predictions Max            1434.7388
V Predictions Min            -5.0249214
Log Pis Mean                 -0.3112542
Log Pis Std                  2.2820275
Log Pis Max                  12.927272
Log Pis Min                  -7.8689847
Policy mu Mean               0.15035453
Policy mu Std                0.888976
Policy mu Max                4.7952437
Policy mu Min                -2.7402184
Policy log std Mean          -0.4924914
Policy log std Std           0.19724253
Policy log std Max           0.10753143
Policy log std Min           -1.1566195
Z mean eval                  0.0009918703
Z variance eval              0.0001523726
total_rewards                [2957.87369356 2900.26622316 2893.10494641 2911.56117097 2910.85266274
 2899.96028717  577.64659019 2853.60093676 2657.83503147 1253.80010933]
total_rewards_mean           2481.650165175253
total_rewards_std            801.0979192192783
total_rewards_max            2957.873693560333
total_rewards_min            577.6465901884603
Number of train steps total  604000
Number of env steps total    797121
Number of rollouts total     0
Train Time (s)               141.87374654319137
(Previous) Eval Time (s)     17.804553139954805
Sample Time (s)              5.127880258485675
Epoch Time (s)               164.80617994163185
Total Train Time (s)         23822.71185573144
Epoch                        150
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 15:07:49.040683 UTC | [2020_01_04_08_30_45] Iteration #150 | Epoch Duration: 169.82950973510742
2020-01-04 15:07:49.041045 UTC | [2020_01_04_08_30_45] Iteration #150 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0010205966
Z variance train             0.00015237743
KL Divergence                19.476616
KL Loss                      1.9476616
QF Loss                      121.54611
VF Loss                      38.618313
Policy Loss                  -1215.983
Q Predictions Mean           1215.6699
Q Predictions Std            223.28358
Q Predictions Max            1444.9325
Q Predictions Min            42.87263
V Predictions Mean           1216.6713
V Predictions Std            220.111
V Predictions Max            1438.1543
V Predictions Min            47.576946
Log Pis Mean                 -0.19895317
Log Pis Std                  1.9750795
Log Pis Max                  12.858656
Log Pis Min                  -4.412015
Policy mu Mean               0.18730406
Policy mu Std                0.8600487
Policy mu Max                3.721666
Policy mu Min                -2.8174522
Policy log std Mean          -0.49987498
Policy log std Std           0.20289044
Policy log std Max           0.30656463
Policy log std Min           -1.3226151
Z mean eval                  0.0012528541
Z variance eval              0.00015196574
total_rewards                [1314.71354834 1691.20615945 2884.9109182  2902.66593277 2902.0625277
 2878.95099004 2861.92856583 2911.3478393  2907.38215554 2905.64077313]
total_rewards_mean           2616.080941031698
total_rewards_std            563.0774357792485
total_rewards_max            2911.347839299827
total_rewards_min            1314.713548343686
Number of train steps total  608000
Number of env steps total    802616
Number of rollouts total     0
Train Time (s)               141.6582638430409
(Previous) Eval Time (s)     22.827648932114244
Sample Time (s)              5.6574626872316
Epoch Time (s)               170.14337546238676
Total Train Time (s)         23992.929785904475
Epoch                        151
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 15:10:39.261441 UTC | [2020_01_04_08_30_45] Iteration #151 | Epoch Duration: 170.22013640403748
2020-01-04 15:10:39.261717 UTC | [2020_01_04_08_30_45] Iteration #151 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.001256296
Z variance train             0.00015196436
KL Divergence                19.483597
KL Loss                      1.9483597
QF Loss                      1767.0046
VF Loss                      38.9341
Policy Loss                  -1228.1497
Q Predictions Mean           1221.3414
Q Predictions Std            261.56717
Q Predictions Max            1442.5886
Q Predictions Min            46.99528
V Predictions Mean           1228.5176
V Predictions Std            246.70836
V Predictions Max            1442.3994
V Predictions Min            118.28339
Log Pis Mean                 -0.375872
Log Pis Std                  2.0123188
Log Pis Max                  12.925398
Log Pis Min                  -6.6423345
Policy mu Mean               0.19245355
Policy mu Std                0.82994384
Policy mu Max                3.4107044
Policy mu Min                -4.278903
Policy log std Mean          -0.5278187
Policy log std Std           0.22005005
Policy log std Max           0.13075572
Policy log std Min           -3.0891016
Z mean eval                  0.0016478322
Z variance eval              0.00015218787
total_rewards                [1495.06741201 2788.42504714 2852.67143544 2888.05169597 2823.42864432
 2895.47212368 1771.09059294 2435.01726065 2852.56210754 2785.52131028]
total_rewards_mean           2558.7307629982656
total_rewards_std            483.3120292418445
total_rewards_max            2895.4721236826117
total_rewards_min            1495.0674120137485
Number of train steps total  612000
Number of env steps total    807616
Number of rollouts total     0
Train Time (s)               141.70379207795486
(Previous) Eval Time (s)     22.90419486258179
Sample Time (s)              5.581562403589487
Epoch Time (s)               170.18954934412614
Total Train Time (s)         24165.433705310803
Epoch                        152
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 15:13:31.769579 UTC | [2020_01_04_08_30_45] Iteration #152 | Epoch Duration: 172.5076322555542
2020-01-04 15:13:31.769911 UTC | [2020_01_04_08_30_45] Iteration #152 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0016621094
Z variance train             0.00015219243
KL Divergence                19.479498
KL Loss                      1.9479498
QF Loss                      165.63669
VF Loss                      822.81616
Policy Loss                  -1177.7471
Q Predictions Mean           1172.3303
Q Predictions Std            273.28687
Q Predictions Max            1443.1757
Q Predictions Min            -1.490995
V Predictions Mean           1179.8611
V Predictions Std            257.8887
V Predictions Max            1439.3914
V Predictions Min            10.066169
Log Pis Mean                 -0.042090394
Log Pis Std                  2.4660275
Log Pis Max                  15.257223
Log Pis Min                  -5.864293
Policy mu Mean               0.21172054
Policy mu Std                0.9295891
Policy mu Max                4.347868
Policy mu Min                -3.2482216
Policy log std Mean          -0.5004845
Policy log std Std           0.18257599
Policy log std Max           0.055206835
Policy log std Min           -1.1975495
Z mean eval                  0.0027171778
Z variance eval              0.00015389198
total_rewards                [1254.46252439 2881.71065112 2787.02908155 2803.50442171 2800.75757978
 2862.18701107 2767.35462609  963.95108642 1230.84551634 2888.00474836]
total_rewards_mean           2323.980724683827
total_rewards_std            773.0200192146413
total_rewards_max            2888.0047483624357
total_rewards_min            963.9510864225355
Number of train steps total  616000
Number of env steps total    812790
Number of rollouts total     0
Train Time (s)               142.7417096681893
(Previous) Eval Time (s)     25.222014124970883
Sample Time (s)              6.093816879671067
Epoch Time (s)               174.05754067283124
Total Train Time (s)         24337.109117643908
Epoch                        153
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 15:16:23.444961 UTC | [2020_01_04_08_30_45] Iteration #153 | Epoch Duration: 171.67479872703552
2020-01-04 15:16:23.445187 UTC | [2020_01_04_08_30_45] Iteration #153 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.002684994
Z variance train             0.00015389782
KL Divergence                19.451653
KL Loss                      1.9451653
QF Loss                      778.8872
VF Loss                      129.66861
Policy Loss                  -1201.2373
Q Predictions Mean           1195.0002
Q Predictions Std            259.88635
Q Predictions Max            1423.6404
Q Predictions Min            -14.301984
V Predictions Mean           1197.0173
V Predictions Std            251.72295
V Predictions Max            1425.8998
V Predictions Min            -9.706744
Log Pis Mean                 -0.23923382
Log Pis Std                  2.1955395
Log Pis Max                  15.978377
Log Pis Min                  -4.5169315
Policy mu Mean               0.19102307
Policy mu Std                0.8340278
Policy mu Max                3.891504
Policy mu Min                -3.2701042
Policy log std Mean          -0.50886804
Policy log std Std           0.18538997
Policy log std Max           0.07188475
Policy log std Min           -1.1690209
Z mean eval                  0.0022760285
Z variance eval              0.00015362613
total_rewards                [2881.91527647 2831.64695458 2999.67297543 2952.87430267 3004.85147646
 2991.79638648 3001.16788242 2964.13356215 2896.8671961  2994.60033373]
total_rewards_mean           2951.952634648049
total_rewards_std            57.85008902546564
total_rewards_max            3004.8514764570227
total_rewards_min            2831.6469545819878
Number of train steps total  620000
Number of env steps total    818029
Number of rollouts total     0
Train Time (s)               143.33176838699728
(Previous) Eval Time (s)     22.839057875797153
Sample Time (s)              5.538869285490364
Epoch Time (s)               171.7096955482848
Total Train Time (s)         24511.4953846056
Epoch                        154
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 15:19:17.832819 UTC | [2020_01_04_08_30_45] Iteration #154 | Epoch Duration: 174.38745546340942
2020-01-04 15:19:17.833000 UTC | [2020_01_04_08_30_45] Iteration #154 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0022870183
Z variance train             0.00015362471
KL Divergence                19.455849
KL Loss                      1.9455849
QF Loss                      204.42743
VF Loss                      157.09517
Policy Loss                  -1218.9928
Q Predictions Mean           1213.5449
Q Predictions Std            265.36508
Q Predictions Max            1442.7119
Q Predictions Min            -17.877775
V Predictions Mean           1216.4851
V Predictions Std            252.31383
V Predictions Max            1445.5153
V Predictions Min            -16.667578
Log Pis Mean                 -0.23524494
Log Pis Std                  2.0865684
Log Pis Max                  10.564985
Log Pis Min                  -5.4411263
Policy mu Mean               0.16629873
Policy mu Std                0.8670677
Policy mu Max                3.8429976
Policy mu Min                -2.5487444
Policy log std Mean          -0.47914752
Policy log std Std           0.1920031
Policy log std Max           0.0026330352
Policy log std Min           -1.24197
Z mean eval                  0.001737712
Z variance eval              0.00015268529
total_rewards                [2990.87315218 3003.50179751 2938.51386247 3021.51521138 2992.57711285
 2900.40475217 2962.75729225 3013.06958699 2946.24387633 3007.87714081]
total_rewards_mean           2977.7333784940047
total_rewards_std            37.235605595260864
total_rewards_max            3021.5152113753684
total_rewards_min            2900.404752170494
Number of train steps total  624000
Number of env steps total    823029
Number of rollouts total     0
Train Time (s)               143.9704513521865
(Previous) Eval Time (s)     25.516620807815343
Sample Time (s)              5.257726335898042
Epoch Time (s)               174.7447984958999
Total Train Time (s)         24686.472008732148
Epoch                        155
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 15:22:12.811927 UTC | [2020_01_04_08_30_45] Iteration #155 | Epoch Duration: 174.97876834869385
2020-01-04 15:22:12.812446 UTC | [2020_01_04_08_30_45] Iteration #155 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0017112202
Z variance train             0.0001526868
KL Divergence                19.470865
KL Loss                      1.9470866
QF Loss                      406.57935
VF Loss                      221.9291
Policy Loss                  -1212.8362
Q Predictions Mean           1208.843
Q Predictions Std            261.18274
Q Predictions Max            1452.824
Q Predictions Min            3.3582523
V Predictions Mean           1213.6632
V Predictions Std            252.13968
V Predictions Max            1449.2847
V Predictions Min            -20.478628
Log Pis Mean                 -0.116175435
Log Pis Std                  2.0017977
Log Pis Max                  13.255503
Log Pis Min                  -4.6304502
Policy mu Mean               0.22949655
Policy mu Std                0.87700635
Policy mu Max                3.3595502
Policy mu Min                -2.5560555
Policy log std Mean          -0.51475054
Policy log std Std           0.19711857
Policy log std Max           0.101907015
Policy log std Min           -1.2644287
Z mean eval                  0.001208604
Z variance eval              0.00015285012
total_rewards                [2926.34582322  848.34478494 2915.31779618 2876.57069137 2899.20417456
 2979.85829804 2914.62335121 2980.34975816 1279.62790344 2925.38884641]
total_rewards_mean           2554.5631427537373
total_rewards_std            752.116932383559
total_rewards_max            2980.349758162589
total_rewards_min            848.344784944106
Number of train steps total  628000
Number of env steps total    828318
Number of rollouts total     0
Train Time (s)               143.4538499400951
(Previous) Eval Time (s)     25.750366664025933
Sample Time (s)              6.035271668806672
Epoch Time (s)               175.2394882729277
Total Train Time (s)         24860.613584860694
Epoch                        156
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 15:25:06.957974 UTC | [2020_01_04_08_30_45] Iteration #156 | Epoch Duration: 174.14526748657227
2020-01-04 15:25:06.958219 UTC | [2020_01_04_08_30_45] Iteration #156 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0012028909
Z variance train             0.00015284763
KL Divergence                19.46812
KL Loss                      1.946812
QF Loss                      94.87583
VF Loss                      30.736145
Policy Loss                  -1210.2987
Q Predictions Mean           1206.4211
Q Predictions Std            253.96169
Q Predictions Max            1447.0089
Q Predictions Min            8.254971
V Predictions Mean           1211.7363
V Predictions Std            247.93246
V Predictions Max            1445.5669
V Predictions Min            1.9793805
Log Pis Mean                 -0.5871038
Log Pis Std                  1.820968
Log Pis Max                  7.163847
Log Pis Min                  -4.682172
Policy mu Mean               0.17138171
Policy mu Std                0.7569632
Policy mu Max                2.7936225
Policy mu Min                -2.519442
Policy log std Mean          -0.5011079
Policy log std Std           0.20444493
Policy log std Max           0.10337746
Policy log std Min           -1.6143179
Z mean eval                  0.0021078554
Z variance eval              0.00015284857
total_rewards                [ 652.68312349  819.36482427 2913.93757572 2976.17387814 1882.10916425
 2952.19231292 2953.49674156 2919.08541749 2922.24574156 2947.64665756]
total_rewards_mean           2393.893543694218
total_rewards_std            887.0655085778014
total_rewards_max            2976.1738781367244
total_rewards_min            652.6831234887376
Number of train steps total  632000
Number of env steps total    833318
Number of rollouts total     0
Train Time (s)               141.45907931169495
(Previous) Eval Time (s)     24.655929127242416
Sample Time (s)              5.6527953669428825
Epoch Time (s)               171.76780380588025
Total Train Time (s)         25030.916293366812
Epoch                        157
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 15:27:57.264173 UTC | [2020_01_04_08_30_45] Iteration #157 | Epoch Duration: 170.3057405948639
2020-01-04 15:27:57.264488 UTC | [2020_01_04_08_30_45] Iteration #157 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0021214862
Z variance train             0.00015284806
KL Divergence                19.46913
KL Loss                      1.946913
QF Loss                      2098.197
VF Loss                      702.6818
Policy Loss                  -1187.7229
Q Predictions Mean           1185.2771
Q Predictions Std            274.9438
Q Predictions Max            1454.4286
Q Predictions Min            -22.123077
V Predictions Mean           1189.1847
V Predictions Std            255.94005
V Predictions Max            1450.3925
V Predictions Min            51.42668
Log Pis Mean                 -0.0118929595
Log Pis Std                  2.3178334
Log Pis Max                  14.707241
Log Pis Min                  -4.814958
Policy mu Mean               0.30415794
Policy mu Std                0.9124908
Policy mu Max                4.5591335
Policy mu Min                -3.7053628
Policy log std Mean          -0.48068956
Policy log std Std           0.18456873
Policy log std Max           0.28925323
Policy log std Min           -1.249656
Z mean eval                  0.001673466
Z variance eval              0.00015310223
total_rewards                [2192.05535965 2972.21900769 2921.71600263 2942.99972491 2934.9569693
 2866.35399959 1246.69947612 2926.19489435 2995.55505533 2939.79751416]
total_rewards_mean           2693.8548003731426
total_rewards_std            532.063978787922
total_rewards_max            2995.5550553338257
total_rewards_min            1246.6994761172386
Number of train steps total  636000
Number of env steps total    838785
Number of rollouts total     0
Train Time (s)               140.41941407509148
(Previous) Eval Time (s)     23.19365918682888
Sample Time (s)              6.734349708072841
Epoch Time (s)               170.3474229699932
Total Train Time (s)         25203.033850416075
Epoch                        158
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 15:30:49.383230 UTC | [2020_01_04_08_30_45] Iteration #158 | Epoch Duration: 172.11861276626587
2020-01-04 15:30:49.383408 UTC | [2020_01_04_08_30_45] Iteration #158 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0017635772
Z variance train             0.00015309772
KL Divergence                19.465088
KL Loss                      1.9465088
QF Loss                      336.66388
VF Loss                      588.0779
Policy Loss                  -1224.8196
Q Predictions Mean           1222.4264
Q Predictions Std            225.00829
Q Predictions Max            1455.6772
Q Predictions Min            85.31453
V Predictions Mean           1226.6123
V Predictions Std            218.5851
V Predictions Max            1452.8683
V Predictions Min            77.8919
Log Pis Mean                 -0.3469564
Log Pis Std                  2.0690563
Log Pis Max                  15.322326
Log Pis Min                  -6.2637677
Policy mu Mean               0.21343844
Policy mu Std                0.83530205
Policy mu Max                3.7544463
Policy mu Min                -3.839463
Policy log std Mean          -0.507742
Policy log std Std           0.18101083
Policy log std Max           0.030433655
Policy log std Min           -1.200788
Z mean eval                  0.0022090366
Z variance eval              0.00015221295
total_rewards                [2402.98606538 3042.62663491  831.27373205 1075.92322829 2872.80062344
 2908.92164744 1108.9527891  2834.23740705 2915.44845174 2902.36805991]
total_rewards_mean           2289.5538639306387
total_rewards_std            857.9652261666043
total_rewards_max            3042.6266349122393
total_rewards_min            831.2737320465365
Number of train steps total  640000
Number of env steps total    843785
Number of rollouts total     0
Train Time (s)               143.77293059788644
(Previous) Eval Time (s)     24.964630196336657
Sample Time (s)              5.186105124652386
Epoch Time (s)               173.92366591887549
Total Train Time (s)         25372.164032333065
Epoch                        159
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 15:33:38.515777 UTC | [2020_01_04_08_30_45] Iteration #159 | Epoch Duration: 169.13223433494568
2020-01-04 15:33:38.515960 UTC | [2020_01_04_08_30_45] Iteration #159 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0022062412
Z variance train             0.00015221542
KL Divergence                19.480698
KL Loss                      1.9480698
QF Loss                      701.50104
VF Loss                      51.705227
Policy Loss                  -1196.2123
Q Predictions Mean           1192.5762
Q Predictions Std            280.42688
Q Predictions Max            1448.3029
Q Predictions Min            34.105858
V Predictions Mean           1198.2664
V Predictions Std            274.6125
V Predictions Max            1451.2822
V Predictions Min            31.031626
Log Pis Mean                 -0.30473483
Log Pis Std                  1.845484
Log Pis Max                  8.522449
Log Pis Min                  -4.3899975
Policy mu Mean               0.068773665
Policy mu Std                0.8430932
Policy mu Max                2.8691676
Policy mu Min                -3.2914627
Policy log std Mean          -0.5018255
Policy log std Std           0.19322442
Policy log std Max           0.038793743
Policy log std Min           -1.4143567
Z mean eval                  0.0015293114
Z variance eval              0.00014894012
total_rewards                [3033.15317104 3052.57890663 2848.94334578 2324.09851437 1372.48949075
 2322.63438235 2668.23650613 2891.2278674  2934.22118133 2914.94582532]
total_rewards_mean           2636.2529191106873
total_rewards_std            490.04890701570446
total_rewards_max            3052.578906627485
total_rewards_min            1372.4894907535095
Number of train steps total  644000
Number of env steps total    848813
Number of rollouts total     0
Train Time (s)               143.4751544878818
(Previous) Eval Time (s)     20.173027396202087
Sample Time (s)              4.781791161280125
Epoch Time (s)               168.42997304536402
Total Train Time (s)         25541.091858026106
Epoch                        160
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 15:36:27.447314 UTC | [2020_01_04_08_30_45] Iteration #160 | Epoch Duration: 168.9312014579773
2020-01-04 15:36:27.447510 UTC | [2020_01_04_08_30_45] Iteration #160 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0015117608
Z variance train             0.0001489341
KL Divergence                19.53611
KL Loss                      1.953611
QF Loss                      104.68349
VF Loss                      182.47084
Policy Loss                  -1235.9897
Q Predictions Mean           1231.9456
Q Predictions Std            249.65807
Q Predictions Max            1446.0713
Q Predictions Min            -4.4457016
V Predictions Mean           1235.6692
V Predictions Std            238.78055
V Predictions Max            1443.6375
V Predictions Min            12.325075
Log Pis Mean                 -0.4143292
Log Pis Std                  2.094748
Log Pis Max                  11.96233
Log Pis Min                  -5.9217367
Policy mu Mean               0.08429142
Policy mu Std                0.8538097
Policy mu Max                3.6806624
Policy mu Min                -2.73879
Policy log std Mean          -0.4938973
Policy log std Std           0.19521584
Policy log std Max           0.13608438
Policy log std Min           -1.2015927
Z mean eval                  0.0027366192
Z variance eval              0.00014935975
total_rewards                [2701.66601025 2924.11930707 1025.43009651 2650.75876588 2973.6130476
  837.20470816 2237.31545409 3046.63087844 3015.80395196 2925.31686908]
total_rewards_mean           2433.7859089062763
total_rewards_std            785.9861359349084
total_rewards_max            3046.630878443879
total_rewards_min            837.2047081609845
Number of train steps total  648000
Number of env steps total    853849
Number of rollouts total     0
Train Time (s)               144.92240869486704
(Previous) Eval Time (s)     20.674072144087404
Sample Time (s)              6.142169195227325
Epoch Time (s)               171.73865003418177
Total Train Time (s)         25711.676967026666
Epoch                        161
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 15:39:18.035019 UTC | [2020_01_04_08_30_45] Iteration #161 | Epoch Duration: 170.58736753463745
2020-01-04 15:39:18.035193 UTC | [2020_01_04_08_30_45] Iteration #161 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.002720144
Z variance train             0.0001493444
KL Divergence                19.529871
KL Loss                      1.9529871
QF Loss                      93.44329
VF Loss                      117.65326
Policy Loss                  -1244.993
Q Predictions Mean           1243.6105
Q Predictions Std            203.35477
Q Predictions Max            1459.7324
Q Predictions Min            101.19003
V Predictions Mean           1245.1064
V Predictions Std            200.78711
V Predictions Max            1456.925
V Predictions Min            99.64579
Log Pis Mean                 -0.48361427
Log Pis Std                  1.7219121
Log Pis Max                  4.8320217
Log Pis Min                  -4.9515038
Policy mu Mean               0.14421286
Policy mu Std                0.7776058
Policy mu Max                2.5531306
Policy mu Min                -2.6894493
Policy log std Mean          -0.50115615
Policy log std Std           0.176237
Policy log std Max           0.14077216
Policy log std Min           -1.2404596
Z mean eval                  0.001523392
Z variance eval              0.00014923415
total_rewards                [3009.49572223 2918.28493777 2915.3149407  3004.81305059 2978.13976749
 2962.77257557 3026.90526182 3017.10766434 3017.68146635 2976.93285119]
total_rewards_mean           2982.744823806656
total_rewards_std            38.353458254389295
total_rewards_max            3026.905261820842
total_rewards_min            2915.314940697372
Number of train steps total  652000
Number of env steps total    858849
Number of rollouts total     0
Train Time (s)               142.29091069102287
(Previous) Eval Time (s)     19.522557886317372
Sample Time (s)              5.87904154881835
Epoch Time (s)               167.6925101261586
Total Train Time (s)         25886.575548316352
Epoch                        162
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 15:42:12.938056 UTC | [2020_01_04_08_30_45] Iteration #162 | Epoch Duration: 174.9026472568512
2020-01-04 15:42:12.938368 UTC | [2020_01_04_08_30_45] Iteration #162 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0015210202
Z variance train             0.00014923267
KL Divergence                19.53147
KL Loss                      1.9531469
QF Loss                      53.639618
VF Loss                      25.757307
Policy Loss                  -1233.7253
Q Predictions Mean           1231.5154
Q Predictions Std            231.39384
Q Predictions Max            1467.6265
Q Predictions Min            0.86883664
V Predictions Mean           1233.3772
V Predictions Std            224.82204
V Predictions Max            1464.2931
V Predictions Min            45.044376
Log Pis Mean                 -0.49809575
Log Pis Std                  1.8450458
Log Pis Max                  9.311693
Log Pis Min                  -5.508158
Policy mu Mean               0.07953369
Policy mu Std                0.8231879
Policy mu Max                3.166037
Policy mu Min                -3.2593064
Policy log std Mean          -0.48263207
Policy log std Std           0.19103067
Policy log std Max           -0.0058683753
Policy log std Min           -1.8339535
Z mean eval                  0.0016839138
Z variance eval              0.00014840589
total_rewards                [ 880.28458604  900.51476186 2931.90297934 2954.72500744 2896.08634921
 2895.61596182 2964.09959845 3000.70170907 1307.5822027  2935.27096748]
total_rewards_mean           2366.6784123412062
total_rewards_std            882.5082237735352
total_rewards_max            3000.701709070891
total_rewards_min            880.2845860445532
Number of train steps total  656000
Number of env steps total    863849
Number of rollouts total     0
Train Time (s)               143.55638875020668
(Previous) Eval Time (s)     26.732464108150452
Sample Time (s)              5.306125055067241
Epoch Time (s)               175.59497791342437
Total Train Time (s)         26058.339793410618
Epoch                        163
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 15:45:04.703915 UTC | [2020_01_04_08_30_45] Iteration #163 | Epoch Duration: 171.76536774635315
2020-01-04 15:45:04.704144 UTC | [2020_01_04_08_30_45] Iteration #163 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0016800838
Z variance train             0.00014840924
KL Divergence                19.546675
KL Loss                      1.9546674
QF Loss                      204.9656
VF Loss                      66.50752
Policy Loss                  -1232.618
Q Predictions Mean           1231.7351
Q Predictions Std            226.96478
Q Predictions Max            1466.3038
Q Predictions Min            23.633713
V Predictions Mean           1227.1128
V Predictions Std            220.92229
V Predictions Max            1452.1072
V Predictions Min            1.1285311
Log Pis Mean                 -0.39968643
Log Pis Std                  1.5296973
Log Pis Max                  4.7487574
Log Pis Min                  -5.0025005
Policy mu Mean               0.17860644
Policy mu Std                0.79859984
Policy mu Max                2.348431
Policy mu Min                -2.4792101
Policy log std Mean          -0.49693897
Policy log std Std           0.18346067
Policy log std Max           0.08663362
Policy log std Min           -1.2359821
Z mean eval                  0.0022853885
Z variance eval              0.00014814959
total_rewards                [3124.62612685  838.90900409 3027.14003811 2967.8170386  2497.15426727
 2990.26344686 2374.65758345 3000.52579004 2947.7931765  2970.64370792]
total_rewards_mean           2673.95301796922
total_rewards_std            653.6161973172246
total_rewards_max            3124.626126848485
total_rewards_min            838.9090040866315
Number of train steps total  660000
Number of env steps total    868849
Number of rollouts total     0
Train Time (s)               144.14168670587242
(Previous) Eval Time (s)     22.90265298401937
Sample Time (s)              6.093084592372179
Epoch Time (s)               173.13742428226396
Total Train Time (s)         26233.882383247837
Epoch                        164
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 15:48:00.251147 UTC | [2020_01_04_08_30_45] Iteration #164 | Epoch Duration: 175.54676175117493
2020-01-04 15:48:00.251512 UTC | [2020_01_04_08_30_45] Iteration #164 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0022817403
Z variance train             0.00014814634
KL Divergence                19.552423
KL Loss                      1.9552424
QF Loss                      403.23914
VF Loss                      347.40073
Policy Loss                  -1229.8696
Q Predictions Mean           1226.4133
Q Predictions Std            227.9016
Q Predictions Max            1447.4807
Q Predictions Min            130.2796
V Predictions Mean           1236.7385
V Predictions Std            219.10289
V Predictions Max            1458.325
V Predictions Min            138.9269
Log Pis Mean                 -0.10226457
Log Pis Std                  2.1601932
Log Pis Max                  14.996927
Log Pis Min                  -4.4353004
Policy mu Mean               0.19785064
Policy mu Std                0.8715241
Policy mu Max                3.7901425
Policy mu Min                -5.3934245
Policy log std Mean          -0.48936042
Policy log std Std           0.23848137
Policy log std Max           0.18069315
Policy log std Min           -3.6826718
Z mean eval                  0.0012253055
Z variance eval              0.00014605939
total_rewards                [2943.82701015 2963.19748239 3021.35006487 2989.43438471 2986.80819827
 2953.82249531 2935.21116707 2996.94261925 3003.1664698  2929.449946  ]
total_rewards_mean           2972.3209837825216
total_rewards_std            29.86079515428766
total_rewards_max            3021.35006487044
total_rewards_min            2929.449945996078
Number of train steps total  664000
Number of env steps total    873849
Number of rollouts total     0
Train Time (s)               140.90584208117798
(Previous) Eval Time (s)     25.311748709063977
Sample Time (s)              6.225186888128519
Epoch Time (s)               172.44277767837048
Total Train Time (s)         26410.775549862068
Epoch                        165
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 15:50:57.146686 UTC | [2020_01_04_08_30_45] Iteration #165 | Epoch Duration: 176.89497089385986
2020-01-04 15:50:57.146890 UTC | [2020_01_04_08_30_45] Iteration #165 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0011999703
Z variance train             0.00014605516
KL Divergence                19.58654
KL Loss                      1.958654
QF Loss                      137.8858
VF Loss                      45.28091
Policy Loss                  -1242.0984
Q Predictions Mean           1234.0664
Q Predictions Std            267.29666
Q Predictions Max            1467.5844
Q Predictions Min            -86.658485
V Predictions Mean           1241.1606
V Predictions Std            243.91043
V Predictions Max            1461.004
V Predictions Min            -18.485107
Log Pis Mean                 -0.45034456
Log Pis Std                  1.9555357
Log Pis Max                  8.891499
Log Pis Min                  -5.56035
Policy mu Mean               0.16331376
Policy mu Std                0.82642215
Policy mu Max                2.624148
Policy mu Min                -2.6251924
Policy log std Mean          -0.4678601
Policy log std Std           0.19042793
Policy log std Max           0.123725355
Policy log std Min           -1.2824411
Z mean eval                  0.0016797583
Z variance eval              0.00014507707
total_rewards                [3115.1516563  3102.45179467 2975.12373068 2935.74427086 3029.15434545
 1232.52204469 2954.87245149 2983.6139031  2937.98531721 1738.40642376]
total_rewards_mean           2700.502593820031
total_rewards_std            620.8151423128401
total_rewards_max            3115.1516563014225
total_rewards_min            1232.5220446948138
Number of train steps total  668000
Number of env steps total    878849
Number of rollouts total     0
Train Time (s)               140.86430496023968
(Previous) Eval Time (s)     29.76370436279103
Sample Time (s)              5.952454347163439
Epoch Time (s)               176.58046367019415
Total Train Time (s)         26582.80564215826
Epoch                        166
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 15:53:49.178294 UTC | [2020_01_04_08_30_45] Iteration #166 | Epoch Duration: 172.0312478542328
2020-01-04 15:53:49.178475 UTC | [2020_01_04_08_30_45] Iteration #166 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0016832665
Z variance train             0.00014507625
KL Divergence                19.602509
KL Loss                      1.9602509
QF Loss                      74.29616
VF Loss                      101.609
Policy Loss                  -1233.844
Q Predictions Mean           1233.5625
Q Predictions Std            230.6177
Q Predictions Max            1451.2852
Q Predictions Min            7.012137
V Predictions Mean           1236.7944
V Predictions Std            227.5621
V Predictions Max            1446.7422
V Predictions Min            -9.061941
Log Pis Mean                 -0.30127797
Log Pis Std                  2.0310285
Log Pis Max                  17.34884
Log Pis Min                  -4.991987
Policy mu Mean               0.12642284
Policy mu Std                0.8526414
Policy mu Max                4.3779836
Policy mu Min                -5.231284
Policy log std Mean          -0.45762515
Policy log std Std           0.19690712
Policy log std Max           0.18232834
Policy log std Min           -1.1183296
Z mean eval                  0.0017346855
Z variance eval              0.0001430283
total_rewards                [3017.01772611 2965.89614564 2969.29482525 2986.04015189 3026.90500957
 2990.87628221 2979.38091526 3010.45965972 2919.9546973  2972.48031168]
total_rewards_mean           2983.8305724633337
total_rewards_std            29.12406867845846
total_rewards_max            3026.9050095698485
total_rewards_min            2919.954697301441
Number of train steps total  672000
Number of env steps total    883886
Number of rollouts total     0
Train Time (s)               144.32390533108264
(Previous) Eval Time (s)     25.21420889813453
Sample Time (s)              5.133089443203062
Epoch Time (s)               174.67120367242023
Total Train Time (s)         26757.765419627074
Epoch                        167
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 15:56:44.140242 UTC | [2020_01_04_08_30_45] Iteration #167 | Epoch Duration: 174.96163702011108
2020-01-04 15:56:44.140426 UTC | [2020_01_04_08_30_45] Iteration #167 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0017356075
Z variance train             0.00014303144
KL Divergence                19.638765
KL Loss                      1.9638766
QF Loss                      146.6355
VF Loss                      3634.573
Policy Loss                  -1239.0486
Q Predictions Mean           1236.0247
Q Predictions Std            214.0568
Q Predictions Max            1457.6534
Q Predictions Min            -26.867157
V Predictions Mean           1243.1785
V Predictions Std            196.94879
V Predictions Max            1455.4263
V Predictions Min            38.50326
Log Pis Mean                 -0.29758048
Log Pis Std                  2.174169
Log Pis Max                  14.720283
Log Pis Min                  -6.2461233
Policy mu Mean               0.1350226
Policy mu Std                0.8435955
Policy mu Max                4.763001
Policy mu Min                -2.9977415
Policy log std Mean          -0.49737263
Policy log std Std           0.19612643
Policy log std Max           0.07883865
Policy log std Min           -1.7583395
Z mean eval                  0.001692708
Z variance eval              0.00014209146
total_rewards                [ 192.07039697  193.89419785 3026.51934144 1261.96314309 1319.87788682
 3020.35078569 2998.25997743 3036.77629847 2881.83734677 1198.31149819]
total_rewards_mean           1912.9860872719214
total_rewards_std            1142.3136705333973
total_rewards_max            3036.77629847008
total_rewards_min            192.0703969726743
Number of train steps total  676000
Number of env steps total    888922
Number of rollouts total     0
Train Time (s)               140.26988730300218
(Previous) Eval Time (s)     25.504407220054418
Sample Time (s)              5.722924517001957
Epoch Time (s)               171.49721904005855
Total Train Time (s)         26921.20894672582
Epoch                        168
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 15:59:27.586334 UTC | [2020_01_04_08_30_45] Iteration #168 | Epoch Duration: 163.44576954841614
2020-01-04 15:59:27.586530 UTC | [2020_01_04_08_30_45] Iteration #168 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0016947448
Z variance train             0.00014209303
KL Divergence                19.658005
KL Loss                      1.9658005
QF Loss                      69.766716
VF Loss                      39.86766
Policy Loss                  -1233.1779
Q Predictions Mean           1235.1279
Q Predictions Std            209.3008
Q Predictions Max            1458.5032
Q Predictions Min            140.44931
V Predictions Mean           1237.7144
V Predictions Std            207.22664
V Predictions Max            1459.1877
V Predictions Min            142.87648
Log Pis Mean                 -0.3180228
Log Pis Std                  1.8078243
Log Pis Max                  7.013877
Log Pis Min                  -4.5725822
Policy mu Mean               0.16269481
Policy mu Std                0.8448567
Policy mu Max                3.0003843
Policy mu Min                -2.6029232
Policy log std Mean          -0.5185756
Policy log std Std           0.18860002
Policy log std Max           0.22628886
Policy log std Min           -1.2340715
Z mean eval                  0.0014380546
Z variance eval              0.00014156828
total_rewards                [2593.8984818  1079.93808823 3038.84483683 1372.36282047 2936.66314547
 3018.49060372 2902.70580135 1432.06532678 2967.64287041 1343.65690154]
total_rewards_mean           2268.6268876605654
total_rewards_std            798.1202795872905
total_rewards_max            3038.844836830527
total_rewards_min            1079.938088230531
Number of train steps total  680000
Number of env steps total    894064
Number of rollouts total     0
Train Time (s)               143.86546267708763
(Previous) Eval Time (s)     17.452723313122988
Sample Time (s)              6.1190761853940785
Epoch Time (s)               167.4372621756047
Total Train Time (s)         27092.46382967988
Epoch                        169
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 16:02:18.843940 UTC | [2020_01_04_08_30_45] Iteration #169 | Epoch Duration: 171.25726652145386
2020-01-04 16:02:18.844164 UTC | [2020_01_04_08_30_45] Iteration #169 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0014368424
Z variance train             0.00014156857
KL Divergence                19.666403
KL Loss                      1.9666404
QF Loss                      98.15771
VF Loss                      65.30406
Policy Loss                  -1240.666
Q Predictions Mean           1242.9496
Q Predictions Std            216.65639
Q Predictions Max            1461.7118
Q Predictions Min            145.16365
V Predictions Mean           1244.3612
V Predictions Std            213.91135
V Predictions Max            1464.7522
V Predictions Min            129.37885
Log Pis Mean                 -0.20345151
Log Pis Std                  1.8467325
Log Pis Max                  8.653623
Log Pis Min                  -4.4938035
Policy mu Mean               0.0902085
Policy mu Std                0.89447707
Policy mu Max                2.733406
Policy mu Min                -2.8550391
Policy log std Mean          -0.50539494
Policy log std Std           0.20712893
Policy log std Max           0.004072547
Policy log std Min           -2.2405534
Z mean eval                  0.0028922968
Z variance eval              0.00013987238
total_rewards                [ 879.11176363 2902.65945405 2997.79345528 2950.76006035 2947.22961942
 2919.41955237 2896.98956202 2948.25220225 2919.53741248 2955.70632221]
total_rewards_mean           2731.745940405937
total_rewards_std            618.1805717647115
total_rewards_max            2997.7934552754014
total_rewards_min            879.1117636269221
Number of train steps total  684000
Number of env steps total    899391
Number of rollouts total     0
Train Time (s)               140.4359983028844
(Previous) Eval Time (s)     21.27245016489178
Sample Time (s)              6.421858521178365
Epoch Time (s)               168.13030698895454
Total Train Time (s)         27265.84386729542
Epoch                        170
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 16:05:12.226165 UTC | [2020_01_04_08_30_45] Iteration #170 | Epoch Duration: 173.38185715675354
2020-01-04 16:05:12.226350 UTC | [2020_01_04_08_30_45] Iteration #170 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.002898385
Z variance train             0.0001398703
KL Divergence                19.693853
KL Loss                      1.9693854
QF Loss                      160.63126
VF Loss                      42.70412
Policy Loss                  -1254.0962
Q Predictions Mean           1249.5354
Q Predictions Std            225.06815
Q Predictions Max            1478.2135
Q Predictions Min            -3.0305486
V Predictions Mean           1253.1755
V Predictions Std            220.18108
V Predictions Max            1476.5151
V Predictions Min            68.29948
Log Pis Mean                 -0.31309032
Log Pis Std                  1.8556386
Log Pis Max                  5.3561525
Log Pis Min                  -5.2757707
Policy mu Mean               0.12381697
Policy mu Std                0.86384684
Policy mu Max                2.6379437
Policy mu Min                -2.7927465
Policy log std Mean          -0.48012534
Policy log std Std           0.19183324
Policy log std Max           -0.035877347
Policy log std Min           -1.3796628
Z mean eval                  0.0012288827
Z variance eval              0.00013884983
total_rewards                [2914.72897738 1453.39823113 3014.82481117 3035.81206059 2991.55806347
 2967.7526324  2971.89302939 2997.24246199 1258.48005227 3020.47851423]
total_rewards_mean           2662.6168834024966
total_rewards_std            655.5681998491466
total_rewards_max            3035.8120605898253
total_rewards_min            1258.4800522677479
Number of train steps total  688000
Number of env steps total    904391
Number of rollouts total     0
Train Time (s)               140.402170361951
(Previous) Eval Time (s)     26.52370838401839
Sample Time (s)              5.843333138152957
Epoch Time (s)               172.76921188412234
Total Train Time (s)         27438.576611264143
Epoch                        171
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 16:08:04.961312 UTC | [2020_01_04_08_30_45] Iteration #171 | Epoch Duration: 172.73482942581177
2020-01-04 16:08:04.961499 UTC | [2020_01_04_08_30_45] Iteration #171 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.001238595
Z variance train             0.00013885024
KL Divergence                19.711761
KL Loss                      1.9711761
QF Loss                      5387.618
VF Loss                      2083.7925
Policy Loss                  -1210.2396
Q Predictions Mean           1203.2722
Q Predictions Std            260.06662
Q Predictions Max            1460.7776
Q Predictions Min            -55.489082
V Predictions Mean           1212.5244
V Predictions Std            239.2722
V Predictions Max            1453.9521
V Predictions Min            74.13622
Log Pis Mean                 -0.08018638
Log Pis Std                  2.087876
Log Pis Max                  11.912152
Log Pis Min                  -5.9658394
Policy mu Mean               0.22934254
Policy mu Std                0.89446574
Policy mu Max                3.5634377
Policy mu Min                -2.8018095
Policy log std Mean          -0.50252485
Policy log std Std           0.19703226
Policy log std Max           0.332641
Policy log std Min           -1.3695138
Z mean eval                  0.0021998733
Z variance eval              0.00013921375
total_rewards                [2952.37408447 2832.45714139 2950.76392199 2958.68885064 2888.05681207
 2949.45783681 2938.75515585 2952.54707552 2867.58097275 2906.80404223]
total_rewards_mean           2919.7485893710696
total_rewards_std            41.68397119671668
total_rewards_max            2958.6888506358046
total_rewards_min            2832.4571413865783
Number of train steps total  692000
Number of env steps total    909419
Number of rollouts total     0
Train Time (s)               139.7588016479276
(Previous) Eval Time (s)     26.48909500008449
Sample Time (s)              6.122770437039435
Epoch Time (s)               172.37066708505154
Total Train Time (s)         27612.86852496583
Epoch                        172
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 16:10:59.257819 UTC | [2020_01_04_08_30_45] Iteration #172 | Epoch Duration: 174.29618000984192
2020-01-04 16:10:59.258013 UTC | [2020_01_04_08_30_45] Iteration #172 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0022226388
Z variance train             0.00013920947
KL Divergence                19.705515
KL Loss                      1.9705515
QF Loss                      151.39041
VF Loss                      225.38419
Policy Loss                  -1243.9098
Q Predictions Mean           1239.1125
Q Predictions Std            248.05412
Q Predictions Max            1471.2896
Q Predictions Min            54.113136
V Predictions Mean           1248.3479
V Predictions Std            232.39285
V Predictions Max            1474.7118
V Predictions Min            94.919235
Log Pis Mean                 -0.29241773
Log Pis Std                  2.3676662
Log Pis Max                  15.206358
Log Pis Min                  -5.9069824
Policy mu Mean               0.15984882
Policy mu Std                0.87689
Policy mu Max                4.6627526
Policy mu Min                -4.102168
Policy log std Mean          -0.52007467
Policy log std Std           0.18710355
Policy log std Max           0.0069737434
Policy log std Min           -1.3994036
Z mean eval                  0.00090724963
Z variance eval              0.0001390146
total_rewards                [2902.12024407 2928.18226808 2983.58366506 2994.20983693 3023.09700601
 2977.56000465 2972.35443988 2937.90710519 2990.79077952 2970.00885742]
total_rewards_mean           2967.981420679065
total_rewards_std            33.808976761560764
total_rewards_max            3023.0970060065765
total_rewards_min            2902.12024407373
Number of train steps total  696000
Number of env steps total    914419
Number of rollouts total     0
Train Time (s)               139.0555135961622
(Previous) Eval Time (s)     28.414364656899124
Sample Time (s)              5.813692125957459
Epoch Time (s)               173.28357037901878
Total Train Time (s)         27787.36626596842
Epoch                        173
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 16:13:53.758018 UTC | [2020_01_04_08_30_45] Iteration #173 | Epoch Duration: 174.49985790252686
2020-01-04 16:13:53.758215 UTC | [2020_01_04_08_30_45] Iteration #173 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.00094542594
Z variance train             0.00013901296
KL Divergence                19.707638
KL Loss                      1.9707638
QF Loss                      118.91461
VF Loss                      33.323837
Policy Loss                  -1233.5157
Q Predictions Mean           1225.7725
Q Predictions Std            238.85207
Q Predictions Max            1469.3763
Q Predictions Min            -16.954933
V Predictions Mean           1231.6902
V Predictions Std            223.21767
V Predictions Max            1466.5406
V Predictions Min            23.504477
Log Pis Mean                 -0.13427635
Log Pis Std                  1.9584336
Log Pis Max                  6.5147333
Log Pis Min                  -4.648443
Policy mu Mean               0.16319156
Policy mu Std                0.8864254
Policy mu Max                2.43192
Policy mu Min                -2.7718854
Policy log std Mean          -0.54322535
Policy log std Std           0.21114524
Policy log std Max           0.070917964
Policy log std Min           -1.3938375
Z mean eval                  0.0010790632
Z variance eval              0.00013880551
total_rewards                [2799.30219263 1304.17674185 2934.33739322 2907.49203052 2922.0708121
 2933.05159999 2908.027138   2929.70242681 2936.2821054  2920.22158564]
total_rewards_mean           2749.4664026159066
total_rewards_std            483.28821309276606
total_rewards_max            2936.282105404962
total_rewards_min            1304.1767418526645
Number of train steps total  700000
Number of env steps total    919544
Number of rollouts total     0
Train Time (s)               136.57494254689664
(Previous) Eval Time (s)     29.63041270710528
Sample Time (s)              6.254017436411232
Epoch Time (s)               172.45937269041315
Total Train Time (s)         27958.040930300485
Epoch                        174
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 16:16:44.437571 UTC | [2020_01_04_08_30_45] Iteration #174 | Epoch Duration: 170.6792094707489
2020-01-04 16:16:44.437767 UTC | [2020_01_04_08_30_45] Iteration #174 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0010819236
Z variance train             0.00013880465
KL Divergence                19.71115
KL Loss                      1.971115
QF Loss                      128.37286
VF Loss                      37.25299
Policy Loss                  -1199.0687
Q Predictions Mean           1197.5245
Q Predictions Std            304.58762
Q Predictions Max            1470.7363
Q Predictions Min            -23.103394
V Predictions Mean           1199.2174
V Predictions Std            302.81656
V Predictions Max            1469.5704
V Predictions Min            -22.907497
Log Pis Mean                 0.0033844337
Log Pis Std                  2.073409
Log Pis Max                  7.7717485
Log Pis Min                  -4.474106
Policy mu Mean               0.18961982
Policy mu Std                0.8989333
Policy mu Max                2.6251738
Policy mu Min                -2.711606
Policy log std Mean          -0.49735498
Policy log std Std           0.19938935
Policy log std Max           0.22034007
Policy log std Min           -1.5447676
Z mean eval                  0.0019252086
Z variance eval              0.00013865114
total_rewards                [ 803.75117583 1304.47871409 3015.06181015 3039.12738066  864.89083546
 2959.64349947 3069.13291015 2991.66660907  865.31875364 2968.08599628]
total_rewards_mean           2188.1157684797317
total_rewards_std            1011.5112559066602
total_rewards_max            3069.132910148095
total_rewards_min            803.751175827334
Number of train steps total  704000
Number of env steps total    924544
Number of rollouts total     0
Train Time (s)               140.55048105912283
(Previous) Eval Time (s)     27.850014192983508
Sample Time (s)              4.738675929605961
Epoch Time (s)               173.1391711817123
Total Train Time (s)         28124.42019940121
Epoch                        175
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 16:19:30.819296 UTC | [2020_01_04_08_30_45] Iteration #175 | Epoch Duration: 166.38140273094177
2020-01-04 16:19:30.819461 UTC | [2020_01_04_08_30_45] Iteration #175 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0019265534
Z variance train             0.00013865298
KL Divergence                19.713913
KL Loss                      1.9713913
QF Loss                      111.94737
VF Loss                      36.382545
Policy Loss                  -1219.4602
Q Predictions Mean           1218.9668
Q Predictions Std            286.59906
Q Predictions Max            1471.4044
Q Predictions Min            28.203602
V Predictions Mean           1218.2878
V Predictions Std            281.0708
V Predictions Max            1473.6132
V Predictions Min            35.133266
Log Pis Mean                 -0.06998138
Log Pis Std                  2.001317
Log Pis Max                  9.7774515
Log Pis Min                  -4.644891
Policy mu Mean               0.20335788
Policy mu Std                0.8977195
Policy mu Max                3.883626
Policy mu Min                -3.1975086
Policy log std Mean          -0.52700645
Policy log std Std           0.19672406
Policy log std Max           0.020724416
Policy log std Min           -1.2647356
Z mean eval                  0.0011646021
Z variance eval              0.00013869844
total_rewards                [2982.83188521  721.96930172 3023.62250166 1108.09382042 3031.81963106
 2996.74719129 2998.33590052 3037.05037309 2975.85298998 2978.93746618]
total_rewards_mean           2585.5261061128167
total_rewards_std            839.9479038452799
total_rewards_max            3037.050373088703
total_rewards_min            721.9693017176987
Number of train steps total  708000
Number of env steps total    929906
Number of rollouts total     0
Train Time (s)               137.29729314520955
(Previous) Eval Time (s)     21.091991048771888
Sample Time (s)              6.267092197202146
Epoch Time (s)               164.65637639118358
Total Train Time (s)         28293.639576525427
Epoch                        176
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 16:22:20.041349 UTC | [2020_01_04_08_30_45] Iteration #176 | Epoch Duration: 169.22176718711853
2020-01-04 16:22:20.041516 UTC | [2020_01_04_08_30_45] Iteration #176 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0011586768
Z variance train             0.00013870044
KL Divergence                19.7146
KL Loss                      1.97146
QF Loss                      409.70453
VF Loss                      76.5281
Policy Loss                  -1232.9478
Q Predictions Mean           1229.6509
Q Predictions Std            250.68134
Q Predictions Max            1474.4381
Q Predictions Min            145.16872
V Predictions Mean           1233.7395
V Predictions Std            247.42664
V Predictions Max            1481.8146
V Predictions Min            138.65083
Log Pis Mean                 -0.27278268
Log Pis Std                  1.8145732
Log Pis Max                  6.4064193
Log Pis Min                  -5.1317997
Policy mu Mean               0.15684532
Policy mu Std                0.8205991
Policy mu Max                2.8617003
Policy mu Min                -2.6691592
Policy log std Mean          -0.51832575
Policy log std Std           0.21275549
Policy log std Max           0.09168041
Policy log std Min           -2.5166333
Z mean eval                  0.0012970503
Z variance eval              0.00013845344
total_rewards                [ 231.27523791  841.30334695 3006.73204803 2945.66074054 2995.81302896
 2948.4683454  2946.3357336  3013.27552213 2980.26173886 2985.55719438]
total_rewards_mean           2489.468293675576
total_rewards_std            986.3420918115058
total_rewards_max            3013.275522128517
total_rewards_min            231.2752379115569
Number of train steps total  712000
Number of env steps total    935031
Number of rollouts total     0
Train Time (s)               137.3662616489455
(Previous) Eval Time (s)     25.657109645660967
Sample Time (s)              5.632955240551382
Epoch Time (s)               168.65632653515786
Total Train Time (s)         28462.330969287083
Epoch                        177
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 16:25:08.735378 UTC | [2020_01_04_08_30_45] Iteration #177 | Epoch Duration: 168.69372749328613
2020-01-04 16:25:08.735576 UTC | [2020_01_04_08_30_45] Iteration #177 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0012934825
Z variance train             0.00013845519
KL Divergence                19.718739
KL Loss                      1.9718739
QF Loss                      95.50426
VF Loss                      48.23354
Policy Loss                  -1255.8903
Q Predictions Mean           1252.1145
Q Predictions Std            231.38715
Q Predictions Max            1469.2706
Q Predictions Min            50.59196
V Predictions Mean           1251.8572
V Predictions Std            216.54143
V Predictions Max            1465.9829
V Predictions Min            73.70196
Log Pis Mean                 -0.032691874
Log Pis Std                  1.9579844
Log Pis Max                  12.523825
Log Pis Min                  -5.039057
Policy mu Mean               0.21051557
Policy mu Std                0.87208086
Policy mu Max                3.9691916
Policy mu Min                -2.6116061
Policy log std Mean          -0.5430077
Policy log std Std           0.18918382
Policy log std Max           0.001997292
Policy log std Min           -1.2881573
Z mean eval                  0.0027581067
Z variance eval              0.00013818649
total_rewards                [2936.02428312 2857.71504908 2977.38298468 3005.99291724 3057.03381698
 3035.01712875 3043.031974   2970.88533713 3031.88008023 3027.38281351]
total_rewards_mean           2994.2346384721477
total_rewards_std            57.87709224488077
total_rewards_max            3057.033816977948
total_rewards_min            2857.715049084536
Number of train steps total  716000
Number of env steps total    940031
Number of rollouts total     0
Train Time (s)               133.22174214106053
(Previous) Eval Time (s)     25.69424979807809
Sample Time (s)              5.899267426226288
Epoch Time (s)               164.8152593653649
Total Train Time (s)         28629.67944990471
Epoch                        178
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 16:27:56.085859 UTC | [2020_01_04_08_30_45] Iteration #178 | Epoch Duration: 167.35015177726746
2020-01-04 16:27:56.086033 UTC | [2020_01_04_08_30_45] Iteration #178 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.002803234
Z variance train             0.00013818865
KL Divergence                19.723196
KL Loss                      1.9723196
QF Loss                      119.80424
VF Loss                      28.015612
Policy Loss                  -1252.5001
Q Predictions Mean           1247.9583
Q Predictions Std            247.73926
Q Predictions Max            1470.5579
Q Predictions Min            27.78518
V Predictions Mean           1251.4431
V Predictions Std            242.63174
V Predictions Max            1471.3364
V Predictions Min            16.73294
Log Pis Mean                 -0.496197
Log Pis Std                  1.8161725
Log Pis Max                  9.632231
Log Pis Min                  -6.3458424
Policy mu Mean               0.122917265
Policy mu Std                0.82122624
Policy mu Max                2.4165716
Policy mu Min                -2.722794
Policy log std Mean          -0.50168204
Policy log std Std           0.19273557
Policy log std Max           0.08744609
Policy log std Min           -1.2455633
Z mean eval                  0.0012206504
Z variance eval              0.00013833624
total_rewards                [3008.84864745 3044.70263211 3048.17717805 3031.83919741 2980.37719663
 3031.15913753 1046.30566729 2965.10038189 3046.78945463 2965.47815948]
total_rewards_mean           2816.877765247806
total_rewards_std            591.0118743347574
total_rewards_max            3048.1771780481067
total_rewards_min            1046.3056672930559
Number of train steps total  720000
Number of env steps total    945134
Number of rollouts total     0
Train Time (s)               138.0464140693657
(Previous) Eval Time (s)     28.22883654339239
Sample Time (s)              6.46033117827028
Epoch Time (s)               172.73558179102838
Total Train Time (s)         28801.21585570369
Epoch                        179
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 16:30:47.624979 UTC | [2020_01_04_08_30_45] Iteration #179 | Epoch Duration: 171.53881549835205
2020-01-04 16:30:47.625158 UTC | [2020_01_04_08_30_45] Iteration #179 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0011906226
Z variance train             0.00013833719
KL Divergence                19.721718
KL Loss                      1.9721718
QF Loss                      172.60666
VF Loss                      46.04343
Policy Loss                  -1261.9979
Q Predictions Mean           1258.9729
Q Predictions Std            226.14497
Q Predictions Max            1476.301
Q Predictions Min            14.743228
V Predictions Mean           1261.817
V Predictions Std            214.35077
V Predictions Max            1475.2716
V Predictions Min            44.314537
Log Pis Mean                 -0.42533565
Log Pis Std                  1.7733319
Log Pis Max                  6.6798162
Log Pis Min                  -4.089594
Policy mu Mean               0.09624418
Policy mu Std                0.7816907
Policy mu Max                1.8892028
Policy mu Min                -2.5992079
Policy log std Mean          -0.4830128
Policy log std Std           0.17813945
Policy log std Max           0.0707652
Policy log std Min           -1.118895
Z mean eval                  0.0020393848
Z variance eval              0.0001397545
total_rewards                [3038.17882601 2996.86786072 2988.09469558 2990.03708759 2950.21698251
 2977.85346847 2943.67514454 2949.66044784 2959.00401662 2905.60853611]
total_rewards_mean           2969.9197065992735
total_rewards_std            34.534019589049045
total_rewards_max            3038.178826007615
total_rewards_min            2905.608536113952
Number of train steps total  724000
Number of env steps total    950157
Number of rollouts total     0
Train Time (s)               140.2148881466128
(Previous) Eval Time (s)     27.031822793651372
Sample Time (s)              5.993418030440807
Epoch Time (s)               173.24012897070497
Total Train Time (s)         28975.79953532433
Epoch                        180
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 16:33:42.210965 UTC | [2020_01_04_08_30_45] Iteration #180 | Epoch Duration: 174.5856614112854
2020-01-04 16:33:42.211161 UTC | [2020_01_04_08_30_45] Iteration #180 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0020492638
Z variance train             0.00013975827
KL Divergence                19.696556
KL Loss                      1.9696556
QF Loss                      215.37045
VF Loss                      50.738758
Policy Loss                  -1229.4557
Q Predictions Mean           1234.0195
Q Predictions Std            257.07437
Q Predictions Max            1482.5995
Q Predictions Min            23.99247
V Predictions Mean           1229.9811
V Predictions Std            253.54211
V Predictions Max            1475.3182
V Predictions Min            29.01784
Log Pis Mean                 -0.28404975
Log Pis Std                  1.783807
Log Pis Max                  4.694434
Log Pis Min                  -6.494401
Policy mu Mean               0.20096534
Policy mu Std                0.8384211
Policy mu Max                2.544805
Policy mu Min                -2.8607948
Policy log std Mean          -0.49670252
Policy log std Std           0.19440697
Policy log std Max           0.23427963
Policy log std Min           -1.8866439
Z mean eval                  0.0023467173
Z variance eval              0.0001386145
total_rewards                [1196.07904963  876.71052896 3029.68046817 2953.05180998 3016.57862866
 3014.3463474  3036.1113139  2282.96672257 3046.32667937 3061.08364957]
total_rewards_mean           2551.2935198226874
total_rewards_std            792.085713304293
total_rewards_max            3061.0836495727413
total_rewards_min            876.7105289605148
Number of train steps total  728000
Number of env steps total    955157
Number of rollouts total     0
Train Time (s)               136.94119826285169
(Previous) Eval Time (s)     28.377091540023685
Sample Time (s)              5.834312664344907
Epoch Time (s)               171.15260246722028
Total Train Time (s)         29144.92009405
Epoch                        181
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 16:36:31.333864 UTC | [2020_01_04_08_30_45] Iteration #181 | Epoch Duration: 169.12255764007568
2020-01-04 16:36:31.334058 UTC | [2020_01_04_08_30_45] Iteration #181 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0023650234
Z variance train             0.00013861239
KL Divergence                19.7154
KL Loss                      1.9715401
QF Loss                      484.3302
VF Loss                      193.34496
Policy Loss                  -1237.7405
Q Predictions Mean           1233.7397
Q Predictions Std            287.3272
Q Predictions Max            1480.7831
Q Predictions Min            17.081396
V Predictions Mean           1239.3853
V Predictions Std            271.42932
V Predictions Max            1480.0116
V Predictions Min            43.716007
Log Pis Mean                 -0.2835639
Log Pis Std                  2.0360756
Log Pis Max                  8.884893
Log Pis Min                  -4.1109056
Policy mu Mean               0.044840556
Policy mu Std                0.8539087
Policy mu Max                3.277306
Policy mu Min                -3.4485743
Policy log std Mean          -0.47267154
Policy log std Std           0.21171753
Policy log std Max           0.21589613
Policy log std Min           -1.8457783
Z mean eval                  0.0013612616
Z variance eval              0.000139401
total_rewards                [2287.1994282  3086.11418054 2992.3770196  3001.14353755 3001.23693311
 3054.08846932 2968.02330153 3024.05899098 2997.23893391 2986.39809434]
total_rewards_mean           2939.7878889079075
total_rewards_std            220.00586666318097
total_rewards_max            3086.1141805417537
total_rewards_min            2287.1994282034375
Number of train steps total  732000
Number of env steps total    960157
Number of rollouts total     0
Train Time (s)               137.88773512793705
(Previous) Eval Time (s)     26.34680864820257
Sample Time (s)              6.047517731785774
Epoch Time (s)               170.2820615079254
Total Train Time (s)         29317.595105013344
Epoch                        182
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 16:39:24.011306 UTC | [2020_01_04_08_30_45] Iteration #182 | Epoch Duration: 172.67710328102112
2020-01-04 16:39:24.011507 UTC | [2020_01_04_08_30_45] Iteration #182 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.001336213
Z variance train             0.00013940429
KL Divergence                19.70012
KL Loss                      1.9700121
QF Loss                      97.81638
VF Loss                      45.36702
Policy Loss                  -1253.6339
Q Predictions Mean           1251.3094
Q Predictions Std            239.3438
Q Predictions Max            1475.979
Q Predictions Min            -14.186077
V Predictions Mean           1253.7908
V Predictions Std            238.3076
V Predictions Max            1473.3298
V Predictions Min            -23.968267
Log Pis Mean                 -0.017563865
Log Pis Std                  2.1055012
Log Pis Max                  9.772785
Log Pis Min                  -7.019489
Policy mu Mean               0.23270218
Policy mu Std                0.89587045
Policy mu Max                5.3613114
Policy mu Min                -2.5326517
Policy log std Mean          -0.51849896
Policy log std Std           0.17892706
Policy log std Max           0.021730304
Policy log std Min           -1.4730339
Z mean eval                  0.0016889864
Z variance eval              0.00013975942
total_rewards                [1004.45773399  676.65060108 2950.7054335  2980.71048711 2929.34460877
 2974.08387076 2934.15167841 2977.07762061 2954.23677714 2961.80997125]
total_rewards_mean           2534.32287826211
total_rewards_std            850.2040699300936
total_rewards_max            2980.7104871059273
total_rewards_min            676.6506010781011
Number of train steps total  736000
Number of env steps total    965285
Number of rollouts total     0
Train Time (s)               134.06209114799276
(Previous) Eval Time (s)     28.741596513893455
Sample Time (s)              6.1358777498826385
Epoch Time (s)               168.93956541176885
Total Train Time (s)         29482.766261896584
Epoch                        183
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 16:42:09.185525 UTC | [2020_01_04_08_30_45] Iteration #183 | Epoch Duration: 165.17385959625244
2020-01-04 16:42:09.185751 UTC | [2020_01_04_08_30_45] Iteration #183 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0016514256
Z variance train             0.00013975787
KL Divergence                19.693356
KL Loss                      1.9693356
QF Loss                      109.928116
VF Loss                      85.44953
Policy Loss                  -1249.8167
Q Predictions Mean           1246.6305
Q Predictions Std            248.55533
Q Predictions Max            1478.1033
Q Predictions Min            27.928925
V Predictions Mean           1244.3118
V Predictions Std            246.91934
V Predictions Max            1475.4584
V Predictions Min            39.11825
Log Pis Mean                 -0.2541691
Log Pis Std                  1.7375644
Log Pis Max                  5.0991893
Log Pis Min                  -4.1035967
Policy mu Mean               0.2055279
Policy mu Std                0.8312702
Policy mu Max                2.1160302
Policy mu Min                -2.5581787
Policy log std Mean          -0.5063067
Policy log std Std           0.19769204
Policy log std Max           0.2764408
Policy log std Min           -1.3617058
Z mean eval                  0.0016778257
Z variance eval              0.00013842573
total_rewards                [ 758.71370918  795.05818879 3004.31378279 3041.6242299  3035.54611288
 3053.89092245 3061.41065164 3038.23382377 2982.96293981 2973.54013454]
total_rewards_mean           2574.52944957566
total_rewards_std            899.2787753343995
total_rewards_max            3061.4106516412535
total_rewards_min            758.7137091826836
Number of train steps total  740000
Number of env steps total    970298
Number of rollouts total     0
Train Time (s)               134.47346278093755
(Previous) Eval Time (s)     24.97565214894712
Sample Time (s)              6.094838379882276
Epoch Time (s)               165.54395330976695
Total Train Time (s)         29648.22175881872
Epoch                        184
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 16:44:54.644440 UTC | [2020_01_04_08_30_45] Iteration #184 | Epoch Duration: 165.45853185653687
2020-01-04 16:44:54.644641 UTC | [2020_01_04_08_30_45] Iteration #184 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.001644261
Z variance train             0.00013842137
KL Divergence                19.71573
KL Loss                      1.9715731
QF Loss                      89.10504
VF Loss                      52.35421
Policy Loss                  -1256.2529
Q Predictions Mean           1256.7112
Q Predictions Std            239.41354
Q Predictions Max            1482.1788
Q Predictions Min            24.697975
V Predictions Mean           1259.1084
V Predictions Std            238.68896
V Predictions Max            1485.6147
V Predictions Min            14.228299
Log Pis Mean                 -0.39771044
Log Pis Std                  1.7160659
Log Pis Max                  4.5857143
Log Pis Min                  -4.3895187
Policy mu Mean               0.08056449
Policy mu Std                0.815553
Policy mu Max                2.3416958
Policy mu Min                -2.4935908
Policy log std Mean          -0.49119088
Policy log std Std           0.18600231
Policy log std Max           0.1638332
Policy log std Min           -1.344888
Z mean eval                  0.0021343299
Z variance eval              0.00013790414
total_rewards                [2854.19752798 2799.70416919 2905.08057447 2915.67449593 2905.7930718
 2925.66456082 2912.42610017 2916.41284643 2904.83317338 2874.89089762]
total_rewards_mean           2891.467741780167
total_rewards_std            36.702143426622534
total_rewards_max            2925.6645608213635
total_rewards_min            2799.7041691912646
Number of train steps total  744000
Number of env steps total    975506
Number of rollouts total     0
Train Time (s)               140.26863958593458
(Previous) Eval Time (s)     24.889997821766883
Sample Time (s)              5.832992658484727
Epoch Time (s)               170.9916300661862
Total Train Time (s)         29822.102379802614
Epoch                        185
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 16:47:48.529115 UTC | [2020_01_04_08_30_45] Iteration #185 | Epoch Duration: 173.88432574272156
2020-01-04 16:47:48.529294 UTC | [2020_01_04_08_30_45] Iteration #185 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0021528397
Z variance train             0.00013790808
KL Divergence                19.72545
KL Loss                      1.972545
QF Loss                      116.64365
VF Loss                      48.223415
Policy Loss                  -1257.1643
Q Predictions Mean           1259.0677
Q Predictions Std            227.36821
Q Predictions Max            1480.1787
Q Predictions Min            11.279249
V Predictions Mean           1259.9912
V Predictions Std            225.95729
V Predictions Max            1481.8413
V Predictions Min            -5.6417136
Log Pis Mean                 -0.41502303
Log Pis Std                  1.6572115
Log Pis Max                  8.322203
Log Pis Min                  -3.425373
Policy mu Mean               0.13657638
Policy mu Std                0.79427487
Policy mu Max                2.0350764
Policy mu Min                -3.0767086
Policy log std Mean          -0.5173399
Policy log std Std           0.19627863
Policy log std Max           0.0838896
Policy log std Min           -1.4097414
Z mean eval                  0.0015453307
Z variance eval              0.00013629
total_rewards                [2892.83401956 2888.85804925 2947.05800878 2907.25584243 2920.80819684
 2895.12179431 2921.61717453 2952.36959199 2929.23295008 2907.17245421]
total_rewards_mean           2916.2328081981127
total_rewards_std            20.928977466509625
total_rewards_max            2952.3695919896013
total_rewards_min            2888.8580492519964
Number of train steps total  748000
Number of env steps total    980506
Number of rollouts total     0
Train Time (s)               140.89138589566574
(Previous) Eval Time (s)     27.782469718251377
Sample Time (s)              5.833876374177635
Epoch Time (s)               174.50773198809475
Total Train Time (s)         29997.375273683574
Epoch                        186
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 16:50:43.803749 UTC | [2020_01_04_08_30_45] Iteration #186 | Epoch Duration: 175.27431440353394
2020-01-04 16:50:43.803940 UTC | [2020_01_04_08_30_45] Iteration #186 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0015657919
Z variance train             0.00013628631
KL Divergence                19.754215
KL Loss                      1.9754215
QF Loss                      175.24702
VF Loss                      95.5333
Policy Loss                  -1279.4255
Q Predictions Mean           1269.4088
Q Predictions Std            211.81009
Q Predictions Max            1471.7289
Q Predictions Min            85.42827
V Predictions Mean           1279.3162
V Predictions Std            187.1895
V Predictions Max            1474.0276
V Predictions Min            57.80125
Log Pis Mean                 -0.27288902
Log Pis Std                  1.8161304
Log Pis Max                  9.173192
Log Pis Min                  -3.9272017
Policy mu Mean               0.24164332
Policy mu Std                0.78932005
Policy mu Max                3.372823
Policy mu Min                -2.8057926
Policy log std Mean          -0.5190213
Policy log std Std           0.18112594
Policy log std Max           0.12435061
Policy log std Min           -1.3392236
Z mean eval                  0.0018630816
Z variance eval              0.00013801044
total_rewards                [1245.4869472  2875.12446644 2910.88450076 2970.17412076 2996.37924873
 1365.38174139 2189.60653816 3016.39537772 2963.86089128 2927.23414155]
total_rewards_mean           2546.052797400284
total_rewards_std            661.6387017896986
total_rewards_max            3016.3953777195734
total_rewards_min            1245.4869472014439
Number of train steps total  752000
Number of env steps total    985506
Number of rollouts total     0
Train Time (s)               137.63456288911402
(Previous) Eval Time (s)     28.548810980282724
Sample Time (s)              5.64915864309296
Epoch Time (s)               171.8325325124897
Total Train Time (s)         30165.587233353406
Epoch                        187
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 16:53:32.019427 UTC | [2020_01_04_08_30_45] Iteration #187 | Epoch Duration: 168.21529865264893
2020-01-04 16:53:32.019697 UTC | [2020_01_04_08_30_45] Iteration #187 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0019281262
Z variance train             0.00013801268
KL Divergence                19.723726
KL Loss                      1.9723727
QF Loss                      103.28635
VF Loss                      138.08745
Policy Loss                  -1264.4543
Q Predictions Mean           1262.5098
Q Predictions Std            248.12885
Q Predictions Max            1481.0298
Q Predictions Min            0.20115352
V Predictions Mean           1269.8682
V Predictions Std            246.77234
V Predictions Max            1480.6978
V Predictions Min            16.43514
Log Pis Mean                 -0.4278979
Log Pis Std                  2.2353082
Log Pis Max                  18.895203
Log Pis Min                  -4.981867
Policy mu Mean               0.035432603
Policy mu Std                0.8598343
Policy mu Max                3.978117
Policy mu Min                -4.2298174
Policy log std Mean          -0.49790406
Policy log std Std           0.20338283
Policy log std Max           0.16231054
Policy log std Min           -1.4232502
Z mean eval                  0.0018184002
Z variance eval              0.00013837917
total_rewards                [1389.3102141  3037.21832715 1331.98219861 2985.51125436 1294.54747843
 3047.51262144 2992.332451   3001.18971992 3019.19555145 3040.7602822 ]
total_rewards_mean           2513.956009864486
total_rewards_std            769.9823585891045
total_rewards_max            3047.5126214416127
total_rewards_min            1294.5474784295789
Number of train steps total  756000
Number of env steps total    990665
Number of rollouts total     0
Train Time (s)               133.49055919982493
(Previous) Eval Time (s)     24.93132390221581
Sample Time (s)              6.161975974217057
Epoch Time (s)               164.5838590762578
Total Train Time (s)         30329.965586995706
Epoch                        188
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 16:56:16.399444 UTC | [2020_01_04_08_30_45] Iteration #188 | Epoch Duration: 164.37955522537231
2020-01-04 16:56:16.399656 UTC | [2020_01_04_08_30_45] Iteration #188 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0017973732
Z variance train             0.00013837694
KL Divergence                19.716774
KL Loss                      1.9716774
QF Loss                      324.52765
VF Loss                      68.57836
Policy Loss                  -1280.9955
Q Predictions Mean           1281.0548
Q Predictions Std            232.3256
Q Predictions Max            1490.255
Q Predictions Min            29.730106
V Predictions Mean           1275.5627
V Predictions Std            230.6129
V Predictions Max            1481.7355
V Predictions Min            24.809298
Log Pis Mean                 -0.20664005
Log Pis Std                  2.2055883
Log Pis Max                  12.085751
Log Pis Min                  -4.797906
Policy mu Mean               0.119254254
Policy mu Std                0.86342984
Policy mu Max                3.831991
Policy mu Min                -2.7646916
Policy log std Mean          -0.49734363
Policy log std Std           0.18524122
Policy log std Max           0.072372794
Policy log std Min           -1.3542893
Z mean eval                  0.0015930498
Z variance eval              0.00013917875
total_rewards                [2987.80622384 2953.09330497 3042.19745872 3003.73176505 3026.99240179
 2999.56004488 2987.0583053  2401.41286011 3031.50938648 2993.0805675 ]
total_rewards_mean           2942.644231864223
total_rewards_std            182.06872087743193
total_rewards_max            3042.1974587165923
total_rewards_min            2401.4128601143493
Number of train steps total  760000
Number of env steps total    995665
Number of rollouts total     0
Train Time (s)               137.87255135411397
(Previous) Eval Time (s)     24.726766895037144
Sample Time (s)              6.018690936733037
Epoch Time (s)               168.61800918588415
Total Train Time (s)         30502.210431891493
Epoch                        189
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 16:59:08.647522 UTC | [2020_01_04_08_30_45] Iteration #189 | Epoch Duration: 172.24771881103516
2020-01-04 16:59:08.647708 UTC | [2020_01_04_08_30_45] Iteration #189 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0015833933
Z variance train             0.0001391743
KL Divergence                19.703955
KL Loss                      1.9703954
QF Loss                      218.36472
VF Loss                      43.851364
Policy Loss                  -1262.32
Q Predictions Mean           1261.8999
Q Predictions Std            221.6151
Q Predictions Max            1479.6475
Q Predictions Min            -10.761132
V Predictions Mean           1266.1191
V Predictions Std            219.22922
V Predictions Max            1484.1432
V Predictions Min            39.605972
Log Pis Mean                 -0.09247895
Log Pis Std                  1.9168509
Log Pis Max                  7.5824146
Log Pis Min                  -4.8054705
Policy mu Mean               0.12142376
Policy mu Std                0.8641403
Policy mu Max                2.248765
Policy mu Min                -2.7420413
Policy log std Mean          -0.5065809
Policy log std Std           0.20107192
Policy log std Max           0.18974054
Policy log std Min           -1.35304
Z mean eval                  0.0016120527
Z variance eval              0.00013805539
total_rewards                [2923.42680502 3001.32210664 2946.76613144 2961.98840386 2978.53624064
 2932.92538589 2946.17917685 2946.86834127 2942.2230718  2948.84876694]
total_rewards_mean           2952.908443034673
total_rewards_std            21.451699344106448
total_rewards_max            3001.322106637458
total_rewards_min            2923.426805024528
Number of train steps total  764000
Number of env steps total    1000665
Number of rollouts total     0
Train Time (s)               141.36648532096297
(Previous) Eval Time (s)     28.35622669896111
Sample Time (s)              5.858105032239109
Epoch Time (s)               175.58081705216318
Total Train Time (s)         30678.323000618257
Epoch                        190
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 17:02:04.762630 UTC | [2020_01_04_08_30_45] Iteration #190 | Epoch Duration: 176.1147849559784
2020-01-04 17:02:04.762801 UTC | [2020_01_04_08_30_45] Iteration #190 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0015997611
Z variance train             0.00013805737
KL Divergence                19.724617
KL Loss                      1.9724617
QF Loss                      292.4067
VF Loss                      236.5393
Policy Loss                  -1261.3558
Q Predictions Mean           1256.7164
Q Predictions Std            270.17807
Q Predictions Max            1481.6722
Q Predictions Min            -13.984438
V Predictions Mean           1263.1377
V Predictions Std            250.62209
V Predictions Max            1491.7211
V Predictions Min            -16.026772
Log Pis Mean                 -0.059791554
Log Pis Std                  2.9323559
Log Pis Max                  26.759342
Log Pis Min                  -5.0002775
Policy mu Mean               0.13419612
Policy mu Std                0.9835178
Policy mu Max                5.364237
Policy mu Min                -5.364263
Policy log std Mean          -0.49305895
Policy log std Std           0.21497343
Policy log std Max           0.078498125
Policy log std Min           -2.4584067
Z mean eval                  0.001678467
Z variance eval              0.00013737791
total_rewards                [ 387.94218808  622.60108034 2982.07649473 2969.09380747 2991.76366005
 2935.21217489 2997.08470219 2942.21054209 3006.63692725 2923.02552432]
total_rewards_mean           2475.764710141883
total_rewards_std            986.9905890195472
total_rewards_max            3006.6369272471734
total_rewards_min            387.94218808077125
Number of train steps total  768000
Number of env steps total    1005665
Number of rollouts total     0
Train Time (s)               140.43455073609948
(Previous) Eval Time (s)     28.88996342709288
Sample Time (s)              5.781756828073412
Epoch Time (s)               175.10627099126577
Total Train Time (s)         30850.15677972557
Epoch                        191
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 17:04:56.599175 UTC | [2020_01_04_08_30_45] Iteration #191 | Epoch Duration: 171.83622884750366
2020-01-04 17:04:56.599399 UTC | [2020_01_04_08_30_45] Iteration #191 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0016584627
Z variance train             0.000137383
KL Divergence                19.73596
KL Loss                      1.973596
QF Loss                      168.95425
VF Loss                      51.70938
Policy Loss                  -1252.1145
Q Predictions Mean           1254.075
Q Predictions Std            252.8584
Q Predictions Max            1483.4135
Q Predictions Min            -67.213135
V Predictions Mean           1255.5626
V Predictions Std            253.89037
V Predictions Max            1484.5148
V Predictions Min            -87.15554
Log Pis Mean                 -0.4595237
Log Pis Std                  1.8454149
Log Pis Max                  5.2888613
Log Pis Min                  -5.163927
Policy mu Mean               0.21171515
Policy mu Std                0.8042453
Policy mu Max                2.084545
Policy mu Min                -2.8507185
Policy log std Mean          -0.5021042
Policy log std Std           0.20301431
Policy log std Max           0.12423515
Policy log std Min           -1.3576303
Z mean eval                  0.002650865
Z variance eval              0.00013783811
total_rewards                [ 749.28402918  885.19486839 2952.4554545  2953.6477602  1280.20089139
 2982.59818641 2868.17264947 1060.26014561  845.08478605 2909.6980758 ]
total_rewards_mean           1948.6596846999262
total_rewards_std            993.9397628189049
total_rewards_max            2982.5981864060113
total_rewards_min            749.284029178527
Number of train steps total  772000
Number of env steps total    1010665
Number of rollouts total     0
Train Time (s)               136.30452990718186
(Previous) Eval Time (s)     25.619665823876858
Sample Time (s)              5.8256760141812265
Epoch Time (s)               167.74987174523994
Total Train Time (s)         31011.57704336522
Epoch                        192
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 17:07:38.023320 UTC | [2020_01_04_08_30_45] Iteration #192 | Epoch Duration: 161.42377924919128
2020-01-04 17:07:38.023513 UTC | [2020_01_04_08_30_45] Iteration #192 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0026548486
Z variance train             0.00013783637
KL Divergence                19.72771
KL Loss                      1.972771
QF Loss                      96.964035
VF Loss                      85.20413
Policy Loss                  -1271.169
Q Predictions Mean           1267.2349
Q Predictions Std            233.96742
Q Predictions Max            1487.452
Q Predictions Min            -4.5430083
V Predictions Mean           1270.2913
V Predictions Std            224.51083
V Predictions Max            1483.6854
V Predictions Min            -32.342583
Log Pis Mean                 -0.2918964
Log Pis Std                  2.1165743
Log Pis Max                  16.229305
Log Pis Min                  -4.689475
Policy mu Mean               0.1600188
Policy mu Std                0.8373577
Policy mu Max                4.2511
Policy mu Min                -3.7049394
Policy log std Mean          -0.5003041
Policy log std Std           0.19415595
Policy log std Max           -2.2888184e-05
Policy log std Min           -1.6740272
Z mean eval                  0.003610662
Z variance eval              0.00013794766
total_rewards                [ 787.56200146 3052.68003063 3003.0233714  3043.52494182 3030.80462016
 3007.53334735 1407.56881005 2992.78562085 3053.14483205 3047.11888504]
total_rewards_mean           2642.5746460818227
total_rewards_std            785.1096221885049
total_rewards_max            3053.1448320491554
total_rewards_min            787.562001461235
Number of train steps total  776000
Number of env steps total    1015938
Number of rollouts total     0
Train Time (s)               139.14399845572188
(Previous) Eval Time (s)     19.29334419593215
Sample Time (s)              6.219981272704899
Epoch Time (s)               164.65732392435893
Total Train Time (s)         31181.76523769321
Epoch                        193
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 17:10:28.214755 UTC | [2020_01_04_08_30_45] Iteration #193 | Epoch Duration: 170.19108891487122
2020-01-04 17:10:28.214949 UTC | [2020_01_04_08_30_45] Iteration #193 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0036700044
Z variance train             0.00013793814
KL Divergence                19.726656
KL Loss                      1.9726657
QF Loss                      118.4311
VF Loss                      59.42212
Policy Loss                  -1281.6676
Q Predictions Mean           1278.9014
Q Predictions Std            215.98045
Q Predictions Max            1492.6685
Q Predictions Min            42.262184
V Predictions Mean           1287.9792
V Predictions Std            215.71379
V Predictions Max            1498.0262
V Predictions Min            23.731134
Log Pis Mean                 -0.40082884
Log Pis Std                  1.5754932
Log Pis Max                  5.392613
Log Pis Min                  -3.8315945
Policy mu Mean               0.12595908
Policy mu Std                0.8011843
Policy mu Max                2.3661454
Policy mu Min                -2.7752035
Policy log std Mean          -0.46061566
Policy log std Std           0.2060138
Policy log std Max           0.22369605
Policy log std Min           -1.6386507
Z mean eval                  0.0046613766
Z variance eval              0.00013830574
total_rewards                [2688.81362296 2945.96013912 2989.65178887 2953.65740799 2980.00972951
 3014.39818408 2938.18384972 2987.29261621 2983.61256257 2941.49624112]
total_rewards_mean           2942.3076142149316
total_rewards_std            87.75462718288365
total_rewards_max            3014.398184084169
total_rewards_min            2688.813622955573
Number of train steps total  780000
Number of env steps total    1020938
Number of rollouts total     0
Train Time (s)               141.94179629487917
(Previous) Eval Time (s)     24.826869437936693
Sample Time (s)              5.935931737534702
Epoch Time (s)               172.70459747035056
Total Train Time (s)         31356.940257424954
Epoch                        194
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 17:13:23.392630 UTC | [2020_01_04_08_30_45] Iteration #194 | Epoch Duration: 175.1775348186493
2020-01-04 17:13:23.392827 UTC | [2020_01_04_08_30_45] Iteration #194 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0046742847
Z variance train             0.00013830313
KL Divergence                19.7211
KL Loss                      1.97211
QF Loss                      113.08703
VF Loss                      26.611898
Policy Loss                  -1280.2106
Q Predictions Mean           1278.0591
Q Predictions Std            233.43495
Q Predictions Max            1501.1243
Q Predictions Min            -28.426535
V Predictions Mean           1280.6127
V Predictions Std            232.02083
V Predictions Max            1505.1333
V Predictions Min            -34.30476
Log Pis Mean                 -0.46187288
Log Pis Std                  1.795072
Log Pis Max                  6.2268753
Log Pis Min                  -4.947752
Policy mu Mean               0.25322422
Policy mu Std                0.7848519
Policy mu Max                2.2740452
Policy mu Min                -3.0461574
Policy log std Mean          -0.5193493
Policy log std Std           0.19700347
Policy log std Max           0.10968727
Policy log std Min           -1.3569248
Z mean eval                  0.0017865589
Z variance eval              0.00013874033
total_rewards                [2844.84013586 2824.4777384  3019.87671385 3023.49797502 3067.49319011
 3051.45820766 3055.68000057 3032.97152228 3035.03428489 1346.43313041]
total_rewards_mean           2830.1762899047344
total_rewards_std            501.43099387270007
total_rewards_max            3067.4931901067444
total_rewards_min            1346.4331304063949
Number of train steps total  784000
Number of env steps total    1025938
Number of rollouts total     0
Train Time (s)               140.83409075578675
(Previous) Eval Time (s)     27.29955052305013
Sample Time (s)              6.234219836536795
Epoch Time (s)               174.36786111537367
Total Train Time (s)         31529.66858104244
Epoch                        195
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 17:16:16.124893 UTC | [2020_01_04_08_30_45] Iteration #195 | Epoch Duration: 172.73189735412598
2020-01-04 17:16:16.125153 UTC | [2020_01_04_08_30_45] Iteration #195 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0017968838
Z variance train             0.00013873968
KL Divergence                19.713634
KL Loss                      1.9713634
QF Loss                      141.86844
VF Loss                      70.47783
Policy Loss                  -1268.8882
Q Predictions Mean           1271.946
Q Predictions Std            244.92567
Q Predictions Max            1521.1505
Q Predictions Min            23.526546
V Predictions Mean           1266.6847
V Predictions Std            238.6589
V Predictions Max            1506.7614
V Predictions Min            30.133282
Log Pis Mean                 -0.41771904
Log Pis Std                  1.8304409
Log Pis Max                  6.5268626
Log Pis Min                  -7.2871714
Policy mu Mean               0.18165015
Policy mu Std                0.80533427
Policy mu Max                2.687225
Policy mu Min                -2.812304
Policy log std Mean          -0.4606072
Policy log std Std           0.2072355
Policy log std Max           0.25687075
Policy log std Min           -1.4337039
Z mean eval                  0.0024223714
Z variance eval              0.00014020235
total_rewards                [3114.49981933  930.4957922  3062.53022815 3030.19099433 2987.34654843
 3067.8875924  2969.81702541  887.49697042 3045.6670571  2986.58771964]
total_rewards_mean           2608.2519747394645
total_rewards_std            850.6896328094643
total_rewards_max            3114.499819325439
total_rewards_min            887.4969704222107
Number of train steps total  788000
Number of env steps total    1030938
Number of rollouts total     0
Train Time (s)               138.79294293792918
(Previous) Eval Time (s)     25.66332553094253
Sample Time (s)              5.455526674631983
Epoch Time (s)               169.9117951435037
Total Train Time (s)         31698.76784002781
Epoch                        196
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 17:19:05.227762 UTC | [2020_01_04_08_30_45] Iteration #196 | Epoch Duration: 169.10241270065308
2020-01-04 17:19:05.228020 UTC | [2020_01_04_08_30_45] Iteration #196 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0024280858
Z variance train             0.0001402004
KL Divergence                19.687336
KL Loss                      1.9687337
QF Loss                      856.42944
VF Loss                      50.08142
Policy Loss                  -1270.7798
Q Predictions Mean           1270.9552
Q Predictions Std            227.19128
Q Predictions Max            1501.8705
Q Predictions Min            157.44649
V Predictions Mean           1270.9154
V Predictions Std            226.04279
V Predictions Max            1500.7584
V Predictions Min            124.97778
Log Pis Mean                 -0.4265976
Log Pis Std                  1.8653094
Log Pis Max                  8.418106
Log Pis Min                  -5.200207
Policy mu Mean               0.2082413
Policy mu Std                0.8077709
Policy mu Max                2.5433655
Policy mu Min                -2.6821482
Policy log std Mean          -0.5110974
Policy log std Std           0.18114156
Policy log std Max           0.042778194
Policy log std Min           -1.4060241
Z mean eval                  0.0033616903
Z variance eval              0.00013864272
total_rewards                [1407.37331527 2951.92150021 2970.72271661 3035.5616983  3017.07390665
 3013.81791345 2989.16830384 3022.56960199 2893.724657   3034.29097638]
total_rewards_mean           2833.6224589688504
total_rewards_std            477.2481237633978
total_rewards_max            3035.5616983020946
total_rewards_min            1407.373315269948
Number of train steps total  792000
Number of env steps total    1035938
Number of rollouts total     0
Train Time (s)               135.6461718310602
(Previous) Eval Time (s)     24.853683321736753
Sample Time (s)              5.715089287143201
Epoch Time (s)               166.21494443994015
Total Train Time (s)         31866.571411911398
Epoch                        197
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 17:21:53.033860 UTC | [2020_01_04_08_30_45] Iteration #197 | Epoch Duration: 167.80566453933716
2020-01-04 17:21:53.034055 UTC | [2020_01_04_08_30_45] Iteration #197 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0033765908
Z variance train             0.00013864627
KL Divergence                19.716396
KL Loss                      1.9716396
QF Loss                      2727.5771
VF Loss                      18.005274
Policy Loss                  -1297.2273
Q Predictions Mean           1293.9991
Q Predictions Std            246.40279
Q Predictions Max            1508.658
Q Predictions Min            30.101473
V Predictions Mean           1298.2642
V Predictions Std            239.88911
V Predictions Max            1507.6315
V Predictions Min            34.9634
Log Pis Mean                 -0.3218812
Log Pis Std                  1.958251
Log Pis Max                  12.666548
Log Pis Min                  -6.149678
Policy mu Mean               0.06778597
Policy mu Std                0.8255113
Policy mu Max                3.043981
Policy mu Min                -2.7433193
Policy log std Mean          -0.5147576
Policy log std Std           0.19364466
Policy log std Max           0.1288932
Policy log std Min           -1.2560902
Z mean eval                  0.003032346
Z variance eval              0.00013871708
total_rewards                [1378.49276485 1157.54257845 3007.63273185 3012.7917586  3037.61245418
 1782.09214181 1523.46156126 2992.49886846 3083.75438317 3009.5687022 ]
total_rewards_mean           2398.5447944827106
total_rewards_std            779.661204734943
total_rewards_max            3083.7543831684457
total_rewards_min            1157.5425784526064
Number of train steps total  796000
Number of env steps total    1040938
Number of rollouts total     0
Train Time (s)               138.84991706581786
(Previous) Eval Time (s)     26.44416169403121
Sample Time (s)              5.83834005985409
Epoch Time (s)               171.13241881970316
Total Train Time (s)         32031.793736001477
Epoch                        198
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 17:24:38.259212 UTC | [2020_01_04_08_30_45] Iteration #198 | Epoch Duration: 165.22500610351562
2020-01-04 17:24:38.259406 UTC | [2020_01_04_08_30_45] Iteration #198 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.003048018
Z variance train             0.00013871661
KL Divergence                19.71579
KL Loss                      1.971579
QF Loss                      83.32413
VF Loss                      66.1835
Policy Loss                  -1284.058
Q Predictions Mean           1281.216
Q Predictions Std            237.26231
Q Predictions Max            1497.6085
Q Predictions Min            129.57298
V Predictions Mean           1283.1176
V Predictions Std            235.02667
V Predictions Max            1504.7487
V Predictions Min            130.75232
Log Pis Mean                 -0.32722327
Log Pis Std                  1.7529365
Log Pis Max                  6.044227
Log Pis Min                  -5.493121
Policy mu Mean               0.23936863
Policy mu Std                0.79610544
Policy mu Max                2.424478
Policy mu Min                -2.6098425
Policy log std Mean          -0.5011933
Policy log std Std           0.18206498
Policy log std Max           0.07164562
Policy log std Min           -1.4245746
Z mean eval                  0.0021812737
Z variance eval              0.00013757583
total_rewards                [3071.61596926 3042.74030713 3067.76531668 3065.08687595 3053.71623856
 3017.80779235 3064.24262088 3041.22948338 3055.44595137 3004.60049576]
total_rewards_mean           3048.425105132674
total_rewards_std            21.116502734102998
total_rewards_max            3071.615969259026
total_rewards_min            3004.6004957628525
Number of train steps total  800000
Number of env steps total    1045938
Number of rollouts total     0
Train Time (s)               140.2300935778767
(Previous) Eval Time (s)     20.536517350003123
Sample Time (s)              5.694491455331445
Epoch Time (s)               166.46110238321126
Total Train Time (s)         32204.084417472128
Epoch                        199
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 17:27:30.554398 UTC | [2020_01_04_08_30_45] Iteration #199 | Epoch Duration: 172.29485321044922
2020-01-04 17:27:30.554594 UTC | [2020_01_04_08_30_45] Iteration #199 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.002175962
Z variance train             0.0001375761
KL Divergence                19.736261
KL Loss                      1.9736261
QF Loss                      65.101746
VF Loss                      28.228302
Policy Loss                  -1297.4065
Q Predictions Mean           1297.3325
Q Predictions Std            213.77202
Q Predictions Max            1511.1877
Q Predictions Min            75.85698
V Predictions Mean           1298.993
V Predictions Std            211.72713
V Predictions Max            1513.0941
V Predictions Min            79.15298
Log Pis Mean                 -0.3506548
Log Pis Std                  1.9035019
Log Pis Max                  5.63409
Log Pis Min                  -4.9557695
Policy mu Mean               0.19706118
Policy mu Std                0.8152583
Policy mu Max                2.3274262
Policy mu Min                -2.5404608
Policy log std Mean          -0.48573306
Policy log std Std           0.1945149
Policy log std Max           0.30317283
Policy log std Min           -1.1759231
Z mean eval                  0.0017044784
Z variance eval              0.00014034806
total_rewards                [1012.59423248  829.35680683 3038.37181567 3037.23478128 1295.62023042
 2977.23269344 2995.02921894 3016.97184345 3028.3613582  3070.96214467]
total_rewards_mean           2430.1735125378973
total_rewards_std            912.6276139706619
total_rewards_max            3070.9621446656197
total_rewards_min            829.356806831512
Number of train steps total  804000
Number of env steps total    1051089
Number of rollouts total     0
Train Time (s)               140.31103162886575
(Previous) Eval Time (s)     26.370029661804438
Sample Time (s)              5.698942117393017
Epoch Time (s)               172.3800034080632
Total Train Time (s)         32370.832447620574
Epoch                        200
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 17:30:17.306909 UTC | [2020_01_04_08_30_45] Iteration #200 | Epoch Duration: 166.75217127799988
2020-01-04 17:30:17.307116 UTC | [2020_01_04_08_30_45] Iteration #200 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.001708371
Z variance train             0.00014035098
KL Divergence                19.683826
KL Loss                      1.9683827
QF Loss                      78.442444
VF Loss                      96.62957
Policy Loss                  -1298.3787
Q Predictions Mean           1296.1913
Q Predictions Std            233.0914
Q Predictions Max            1499.7872
Q Predictions Min            -69.90156
V Predictions Mean           1295.1316
V Predictions Std            231.43524
V Predictions Max            1501.3961
V Predictions Min            -31.55415
Log Pis Mean                 -0.31426126
Log Pis Std                  1.604625
Log Pis Max                  4.9815803
Log Pis Min                  -4.581173
Policy mu Mean               0.16279282
Policy mu Std                0.7881061
Policy mu Max                2.3378735
Policy mu Min                -2.4981787
Policy log std Mean          -0.48116088
Policy log std Std           0.18742609
Policy log std Max           0.083394885
Policy log std Min           -1.2685083
Z mean eval                  0.002431681
Z variance eval              0.00014155441
total_rewards                [2701.21532244  923.39227918 3072.61302212 3043.10994159 3024.37767349
 3013.50538188 3030.0348948  2988.91424941 3050.53961041 3058.82935517]
total_rewards_mean           2790.6531730503702
total_rewards_std            630.7344043680336
total_rewards_max            3072.613022117332
total_rewards_min            923.3922791827266
Number of train steps total  808000
Number of env steps total    1056089
Number of rollouts total     0
Train Time (s)               139.92157429922372
(Previous) Eval Time (s)     20.741927068214864
Sample Time (s)              5.746429311577231
Epoch Time (s)               166.40993067901582
Total Train Time (s)         32542.289574891794
Epoch                        201
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 17:33:08.768797 UTC | [2020_01_04_08_30_45] Iteration #201 | Epoch Duration: 171.46151494979858
2020-01-04 17:33:08.769051 UTC | [2020_01_04_08_30_45] Iteration #201 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.002449477
Z variance train             0.0001415505
KL Divergence                19.664564
KL Loss                      1.9664564
QF Loss                      110.108864
VF Loss                      69.43942
Policy Loss                  -1296.9785
Q Predictions Mean           1297.3448
Q Predictions Std            205.10634
Q Predictions Max            1505.974
Q Predictions Min            133.803
V Predictions Mean           1299.4935
V Predictions Std            204.58868
V Predictions Max            1512.7831
V Predictions Min            144.63513
Log Pis Mean                 -0.6842191
Log Pis Std                  1.7054403
Log Pis Max                  5.125187
Log Pis Min                  -6.329988
Policy mu Mean               0.18595059
Policy mu Std                0.77279955
Policy mu Max                2.1409335
Policy mu Min                -2.7273746
Policy log std Mean          -0.4559835
Policy log std Std           0.194941
Policy log std Max           0.04298359
Policy log std Min           -1.1568842
Z mean eval                  0.0011710542
Z variance eval              0.00014240172
total_rewards                [2982.57142335 2949.64625862 3063.4520909  3051.27565425 3077.90416234
 3037.70797751 3063.00522226 3064.89017157 3071.88810345 3059.63118756]
total_rewards_mean           3042.1972251809048
total_rewards_std            40.10446035969799
total_rewards_max            3077.904162337178
total_rewards_min            2949.6462586176795
Number of train steps total  812000
Number of env steps total    1061089
Number of rollouts total     0
Train Time (s)               138.6224222779274
(Previous) Eval Time (s)     25.79327187873423
Sample Time (s)              5.076932706870139
Epoch Time (s)               169.49262686353177
Total Train Time (s)         32709.707436500583
Epoch                        202
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 17:35:56.193775 UTC | [2020_01_04_08_30_45] Iteration #202 | Epoch Duration: 167.42442727088928
2020-01-04 17:35:56.194193 UTC | [2020_01_04_08_30_45] Iteration #202 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0011081457
Z variance train             0.00014240126
KL Divergence                19.648266
KL Loss                      1.9648266
QF Loss                      84.889915
VF Loss                      30.702705
Policy Loss                  -1312.1797
Q Predictions Mean           1310.5059
Q Predictions Std            234.83818
Q Predictions Max            1520.4095
Q Predictions Min            -93.141815
V Predictions Mean           1309.9741
V Predictions Std            234.23256
V Predictions Max            1517.1943
V Predictions Min            -108.659195
Log Pis Mean                 -0.30784237
Log Pis Std                  1.7937962
Log Pis Max                  8.2846575
Log Pis Min                  -4.259845
Policy mu Mean               0.08462324
Policy mu Std                0.83327776
Policy mu Max                2.0078924
Policy mu Min                -2.79508
Policy log std Mean          -0.4875957
Policy log std Std           0.19197185
Policy log std Max           0.076973796
Policy log std Min           -1.2375458
Z mean eval                  0.0026069374
Z variance eval              0.00014320966
total_rewards                [3095.50887012 2997.33458022 3059.26550409 3045.67694531 3048.12175453
 3046.40230745 3025.09838494 1364.83857639 3065.79983341 3053.73214041]
total_rewards_mean           2880.177889687806
total_rewards_std            505.689914810156
total_rewards_max            3095.508870121736
total_rewards_min            1364.8385763940914
Number of train steps total  816000
Number of env steps total    1066482
Number of rollouts total     0
Train Time (s)               135.3190341470763
(Previous) Eval Time (s)     23.724796729162335
Sample Time (s)              5.810052186716348
Epoch Time (s)               164.853883062955
Total Train Time (s)         32872.71808033297
Epoch                        203
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 17:38:39.205147 UTC | [2020_01_04_08_30_45] Iteration #203 | Epoch Duration: 163.01071166992188
2020-01-04 17:38:39.205383 UTC | [2020_01_04_08_30_45] Iteration #203 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0026012035
Z variance train             0.00014321008
KL Divergence                19.633509
KL Loss                      1.9633509
QF Loss                      69.32796
VF Loss                      24.350653
Policy Loss                  -1323.546
Q Predictions Mean           1319.8958
Q Predictions Std            216.47263
Q Predictions Max            1519.6895
Q Predictions Min            53.700195
V Predictions Mean           1324.329
V Predictions Std            214.24835
V Predictions Max            1526.3799
V Predictions Min            63.499672
Log Pis Mean                 -0.60285616
Log Pis Std                  1.6740601
Log Pis Max                  5.023571
Log Pis Min                  -5.3883715
Policy mu Mean               0.15995526
Policy mu Std                0.7736998
Policy mu Max                1.8899815
Policy mu Min                -2.6020427
Policy log std Mean          -0.47232112
Policy log std Std           0.20017974
Policy log std Max           0.0935601
Policy log std Min           -1.2652535
Z mean eval                  0.0017593417
Z variance eval              0.00014416946
total_rewards                [2812.94712313 1279.66414324 3077.06405342 3041.94834196 3036.74410149
 3060.08800369 3066.97234386 3041.37260141 3047.59552074 3068.67277531]
total_rewards_mean           2853.306900823875
total_rewards_std            529.64073530142
total_rewards_max            3077.0640534153213
total_rewards_min            1279.6641432366707
Number of train steps total  820000
Number of env steps total    1071872
Number of rollouts total     0
Train Time (s)               135.5750198662281
(Previous) Eval Time (s)     21.881389210000634
Sample Time (s)              5.5460899085737765
Epoch Time (s)               163.00249898480251
Total Train Time (s)         33034.34167200187
Epoch                        204
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 17:41:20.833354 UTC | [2020_01_04_08_30_45] Iteration #204 | Epoch Duration: 161.62771916389465
2020-01-04 17:41:20.833664 UTC | [2020_01_04_08_30_45] Iteration #204 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0017693965
Z variance train             0.00014417086
KL Divergence                19.617424
KL Loss                      1.9617424
QF Loss                      132.78848
VF Loss                      25.964638
Policy Loss                  -1308.6833
Q Predictions Mean           1312.3578
Q Predictions Std            240.49483
Q Predictions Max            1511.4595
Q Predictions Min            121.72989
V Predictions Mean           1307.644
V Predictions Std            239.0083
V Predictions Max            1507.5741
V Predictions Min            119.46073
Log Pis Mean                 -0.45184234
Log Pis Std                  1.8302122
Log Pis Max                  6.6532917
Log Pis Min                  -5.0571322
Policy mu Mean               0.17976038
Policy mu Std                0.78507894
Policy mu Max                2.3700154
Policy mu Min                -2.760389
Policy log std Mean          -0.4970254
Policy log std Std           0.18384394
Policy log std Max           0.1135062
Policy log std Min           -1.2627676
Z mean eval                  0.002121075
Z variance eval              0.00014476596
total_rewards                [3099.29243797 3071.87773206 3077.03293988 3117.09137117 3136.48182824
 3136.28363857 3030.31380932 3120.1148286  3138.50919616 3120.27717233]
total_rewards_mean           3104.7274954284917
total_rewards_std            33.45114484501348
total_rewards_max            3138.509196155621
total_rewards_min            3030.313809316366
Number of train steps total  824000
Number of env steps total    1076872
Number of rollouts total     0
Train Time (s)               138.39379537291825
(Previous) Eval Time (s)     20.50636272178963
Sample Time (s)              4.501612881198525
Epoch Time (s)               163.4017709759064
Total Train Time (s)         33199.08646298805
Epoch                        205
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 17:44:05.581882 UTC | [2020_01_04_08_30_45] Iteration #205 | Epoch Duration: 164.7480444908142
2020-01-04 17:44:05.582090 UTC | [2020_01_04_08_30_45] Iteration #205 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.002110735
Z variance train             0.00014476482
KL Divergence                19.607113
KL Loss                      1.9607114
QF Loss                      119.4155
VF Loss                      24.750257
Policy Loss                  -1330.0039
Q Predictions Mean           1328.8914
Q Predictions Std            194.64635
Q Predictions Max            1529.551
Q Predictions Min            140.66095
V Predictions Mean           1332.3049
V Predictions Std            194.29735
V Predictions Max            1528.7921
V Predictions Min            149.10693
Log Pis Mean                 -0.60873187
Log Pis Std                  1.591726
Log Pis Max                  5.9763174
Log Pis Min                  -4.8192873
Policy mu Mean               0.15560006
Policy mu Std                0.7529508
Policy mu Max                2.3438368
Policy mu Min                -3.027257
Policy log std Mean          -0.48541728
Policy log std Std           0.18179154
Policy log std Max           -0.041783214
Policy log std Min           -1.1049721
Z mean eval                  0.002717439
Z variance eval              0.00014352806
total_rewards                [3095.70473741 3089.98461172 1305.04729181 3049.61923941 1086.5680815
 3014.16200313 2916.55981241 3024.00903698 2981.71101107 3019.08233473]
total_rewards_mean           2658.244816017837
total_rewards_std            734.4574127661185
total_rewards_max            3095.704737411721
total_rewards_min            1086.5680814998177
Number of train steps total  828000
Number of env steps total    1081872
Number of rollouts total     0
Train Time (s)               136.67512503406033
(Previous) Eval Time (s)     21.85242561204359
Sample Time (s)              4.9639906459487975
Epoch Time (s)               163.49154129205272
Total Train Time (s)         33360.42064344091
Epoch                        206
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 17:46:46.918304 UTC | [2020_01_04_08_30_45] Iteration #206 | Epoch Duration: 161.3360664844513
2020-01-04 17:46:46.918465 UTC | [2020_01_04_08_30_45] Iteration #206 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0027110276
Z variance train             0.00014352913
KL Divergence                19.626995
KL Loss                      1.9626995
QF Loss                      347.3825
VF Loss                      48.19449
Policy Loss                  -1329.0636
Q Predictions Mean           1329.5835
Q Predictions Std            206.72014
Q Predictions Max            1519.1688
Q Predictions Min            279.82822
V Predictions Mean           1329.9165
V Predictions Std            205.61305
V Predictions Max            1522.2023
V Predictions Min            278.61584
Log Pis Mean                 -0.4699211
Log Pis Std                  1.5577855
Log Pis Max                  7.02743
Log Pis Min                  -4.8165183
Policy mu Mean               0.21517497
Policy mu Std                0.7334791
Policy mu Max                2.3906913
Policy mu Min                -2.5583463
Policy log std Mean          -0.4955258
Policy log std Std           0.19039957
Policy log std Max           0.09736067
Policy log std Min           -1.2138746
Z mean eval                  0.0016965276
Z variance eval              0.00014373519
total_rewards                [ 274.03756201  893.95914423 3112.42227025 3108.35973644 3115.64559882
 3101.55639768 3116.6806423  3092.62477169 3102.71236972 3089.26568665]
total_rewards_mean           2600.7264179783524
total_rewards_std            1017.8833669229698
total_rewards_max            3116.680642296757
total_rewards_min            274.0375620122244
Number of train steps total  832000
Number of env steps total    1087061
Number of rollouts total     0
Train Time (s)               136.65019326889887
(Previous) Eval Time (s)     19.69673667475581
Sample Time (s)              5.365098635666072
Epoch Time (s)               161.71202857932076
Total Train Time (s)         33522.38120546844
Epoch                        207
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 17:49:28.884337 UTC | [2020_01_04_08_30_45] Iteration #207 | Epoch Duration: 161.96574997901917
2020-01-04 17:49:28.884511 UTC | [2020_01_04_08_30_45] Iteration #207 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0017022301
Z variance train             0.00014373372
KL Divergence                19.62122
KL Loss                      1.962122
QF Loss                      292.0902
VF Loss                      65.00229
Policy Loss                  -1305.6846
Q Predictions Mean           1301.0044
Q Predictions Std            245.79535
Q Predictions Max            1525.9646
Q Predictions Min            -0.7286302
V Predictions Mean           1302.4585
V Predictions Std            245.53874
V Predictions Max            1526.0553
V Predictions Min            1.934642
Log Pis Mean                 -0.46108449
Log Pis Std                  1.8988
Log Pis Max                  5.789719
Log Pis Min                  -5.311096
Policy mu Mean               0.1548209
Policy mu Std                0.8116549
Policy mu Max                3.0492632
Policy mu Min                -2.8819745
Policy log std Mean          -0.4768463
Policy log std Std           0.20408219
Policy log std Max           0.12850738
Policy log std Min           -1.1985224
Z mean eval                  0.0021815738
Z variance eval              0.00014334639
total_rewards                [ 805.83498727 3037.72857275 3028.49705335 2995.1279697  3041.52891513
 3028.88004534 3054.07603076 2942.53192414 3077.39900609 3037.22929793]
total_rewards_mean           2804.883380244948
total_rewards_std            667.23882871052
total_rewards_max            3077.399006093701
total_rewards_min            805.8349872716744
Number of train steps total  836000
Number of env steps total    1092405
Number of rollouts total     0
Train Time (s)               134.78822171874344
(Previous) Eval Time (s)     19.950195422396064
Sample Time (s)              5.4067690023221076
Epoch Time (s)               160.14518614346161
Total Train Time (s)         33683.83122110134
Epoch                        208
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 17:52:10.335106 UTC | [2020_01_04_08_30_45] Iteration #208 | Epoch Duration: 161.4504690170288
2020-01-04 17:52:10.335258 UTC | [2020_01_04_08_30_45] Iteration #208 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0021670572
Z variance train             0.00014334473
KL Divergence                19.628746
KL Loss                      1.9628747
QF Loss                      125.8612
VF Loss                      29.631025
Policy Loss                  -1331.0342
Q Predictions Mean           1329.1787
Q Predictions Std            209.47612
Q Predictions Max            1530.2734
Q Predictions Min            43.256252
V Predictions Mean           1331.1718
V Predictions Std            208.24797
V Predictions Max            1528.3278
V Predictions Min            37.871456
Log Pis Mean                 -0.34409267
Log Pis Std                  1.7468929
Log Pis Max                  5.5893807
Log Pis Min                  -4.4001236
Policy mu Mean               0.19417839
Policy mu Std                0.7827467
Policy mu Max                2.6249757
Policy mu Min                -2.6630094
Policy log std Mean          -0.48621336
Policy log std Std           0.17442365
Policy log std Max           0.26173317
Policy log std Min           -1.191267
Z mean eval                  0.0021427397
Z variance eval              0.00014554759
total_rewards                [1006.2455181   996.39616396 3124.37187735 3056.51975952 3100.55876328
 3094.46770557 3088.4518179  3077.62153346 3080.71210235 3080.54804922]
total_rewards_mean           2670.5893290701424
total_rewards_std            834.8006757467942
total_rewards_max            3124.371877347723
total_rewards_min            996.3961639599848
Number of train steps total  840000
Number of env steps total    1097600
Number of rollouts total     0
Train Time (s)               136.58159498265013
(Previous) Eval Time (s)     21.255239685066044
Sample Time (s)              5.321790485177189
Epoch Time (s)               163.15862515289336
Total Train Time (s)         33846.847278662026
Epoch                        209
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 17:54:53.355487 UTC | [2020_01_04_08_30_45] Iteration #209 | Epoch Duration: 163.02010583877563
2020-01-04 17:54:53.355692 UTC | [2020_01_04_08_30_45] Iteration #209 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0021266888
Z variance train             0.00014554782
KL Divergence                19.590406
KL Loss                      1.9590406
QF Loss                      52.787178
VF Loss                      26.886015
Policy Loss                  -1354.2496
Q Predictions Mean           1354.6821
Q Predictions Std            170.10599
Q Predictions Max            1539.0479
Q Predictions Min            120.06143
V Predictions Mean           1355.4138
V Predictions Std            171.76144
V Predictions Max            1544.5544
V Predictions Min            120.10066
Log Pis Mean                 -0.72885096
Log Pis Std                  1.746811
Log Pis Max                  7.264389
Log Pis Min                  -5.9699492
Policy mu Mean               0.1947817
Policy mu Std                0.73704046
Policy mu Max                2.179973
Policy mu Min                -2.5987313
Policy log std Mean          -0.46142027
Policy log std Std           0.18504648
Policy log std Max           0.005007684
Policy log std Min           -1.2847553
Z mean eval                  0.0009992963
Z variance eval              0.00014481955
total_rewards                [3032.05253211  791.85274872 3037.2496223  3001.58676195 1370.66390727
 3033.5518235  3067.44244511 3026.68073068 3040.98481688 2966.80822265]
total_rewards_mean           2636.8873611163726
total_rewards_std            788.9060423903262
total_rewards_max            3067.442445114577
total_rewards_min            791.8527487158744
Number of train steps total  844000
Number of env steps total    1102720
Number of rollouts total     0
Train Time (s)               137.4776985095814
(Previous) Eval Time (s)     21.116481950040907
Sample Time (s)              5.228184612002224
Epoch Time (s)               163.82236507162452
Total Train Time (s)         34009.25752304215
Epoch                        210
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 17:57:35.768633 UTC | [2020_01_04_08_30_45] Iteration #210 | Epoch Duration: 162.41280007362366
2020-01-04 17:57:35.768813 UTC | [2020_01_04_08_30_45] Iteration #210 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0010026146
Z variance train             0.00014481942
KL Divergence                19.602297
KL Loss                      1.9602298
QF Loss                      88.22684
VF Loss                      39.45336
Policy Loss                  -1330.6724
Q Predictions Mean           1330.0687
Q Predictions Std            204.9721
Q Predictions Max            1534.1494
Q Predictions Min            28.03918
V Predictions Mean           1328.47
V Predictions Std            203.30228
V Predictions Max            1528.6239
V Predictions Min            28.843824
Log Pis Mean                 -0.47293085
Log Pis Std                  1.827716
Log Pis Max                  6.5221195
Log Pis Min                  -4.9908767
Policy mu Mean               0.15078638
Policy mu Std                0.80013204
Policy mu Max                2.9472687
Policy mu Min                -2.7447186
Policy log std Mean          -0.4645542
Policy log std Std           0.20864704
Policy log std Max           0.0513283
Policy log std Min           -1.2982091
Z mean eval                  0.0031712477
Z variance eval              0.00014716104
total_rewards                [2944.29617914 2938.35120871 3100.56646548 3119.76801166 3146.54047865
 3114.86180108 3067.89295952 3131.1525757  3103.90298485 3140.3213688 ]
total_rewards_mean           3080.765403359654
total_rewards_std            72.86610324610781
total_rewards_max            3146.5404786451
total_rewards_min            2938.3512087110603
Number of train steps total  848000
Number of env steps total    1107720
Number of rollouts total     0
Train Time (s)               134.21447175601497
(Previous) Eval Time (s)     19.706685313023627
Sample Time (s)              5.018566621467471
Epoch Time (s)               158.93972369050607
Total Train Time (s)         34170.76830808399
Epoch                        211
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 18:00:17.282009 UTC | [2020_01_04_08_30_45] Iteration #211 | Epoch Duration: 161.5130615234375
2020-01-04 18:00:17.282207 UTC | [2020_01_04_08_30_45] Iteration #211 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0031612564
Z variance train             0.00014716164
KL Divergence                19.562603
KL Loss                      1.9562603
QF Loss                      76.59654
VF Loss                      27.729433
Policy Loss                  -1326.064
Q Predictions Mean           1323.5953
Q Predictions Std            240.80843
Q Predictions Max            1536.7255
Q Predictions Min            120.50121
V Predictions Mean           1326.3513
V Predictions Std            239.26305
V Predictions Max            1535.9379
V Predictions Min            122.77142
Log Pis Mean                 -0.47956687
Log Pis Std                  1.7479671
Log Pis Max                  7.861867
Log Pis Min                  -7.039421
Policy mu Mean               0.13153784
Policy mu Std                0.79510397
Policy mu Max                2.476402
Policy mu Min                -2.9187348
Policy log std Mean          -0.51379687
Policy log std Std           0.18055852
Policy log std Max           0.16513771
Policy log std Min           -1.351261
Z mean eval                  0.0011320392
Z variance eval              0.00014842172
total_rewards                [1163.34977289 3141.69395677 3062.69082262 3000.54222231 3067.57464454
 3047.10290122 2988.2683058  3057.16227663 3052.24314293 3056.59600404]
total_rewards_mean           2863.7224049769356
total_rewards_std            568.12837161823
total_rewards_max            3141.6939567738928
total_rewards_min            1163.349772892753
Number of train steps total  852000
Number of env steps total    1112720
Number of rollouts total     0
Train Time (s)               135.3130091340281
(Previous) Eval Time (s)     22.279776313807815
Sample Time (s)              4.687950731720775
Epoch Time (s)               162.2807361795567
Total Train Time (s)         34332.51495324541
Epoch                        212
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 18:02:59.030277 UTC | [2020_01_04_08_30_45] Iteration #212 | Epoch Duration: 161.747944355011
2020-01-04 18:02:59.030418 UTC | [2020_01_04_08_30_45] Iteration #212 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0011212657
Z variance train             0.00014841939
KL Divergence                19.541845
KL Loss                      1.9541845
QF Loss                      146.0783
VF Loss                      187.88567
Policy Loss                  -1341.6173
Q Predictions Mean           1340.1062
Q Predictions Std            215.5591
Q Predictions Max            1539.8036
Q Predictions Min            -131.559
V Predictions Mean           1337.3942
V Predictions Std            210.03235
V Predictions Max            1530.7325
V Predictions Min            -32.331406
Log Pis Mean                 -0.52729726
Log Pis Std                  1.915991
Log Pis Max                  10.241201
Log Pis Min                  -4.6407175
Policy mu Mean               0.10952804
Policy mu Std                0.7859143
Policy mu Max                4.886955
Policy mu Min                -2.747418
Policy log std Mean          -0.48659793
Policy log std Std           0.19464298
Policy log std Max           0.17763382
Policy log std Min           -1.2348409
Z mean eval                  0.0016650318
Z variance eval              0.00014895307
total_rewards                [2931.90205209 2993.05492438 3108.49384665 3052.33227093 3067.55396571
 3028.03192505 3040.77344989 3067.72839634 3101.50829694 3054.36899317]
total_rewards_mean           3044.5748121150964
total_rewards_std            49.1781109179443
total_rewards_max            3108.4938466484086
total_rewards_min            2931.9020520892586
Number of train steps total  856000
Number of env steps total    1117720
Number of rollouts total     0
Train Time (s)               138.7084081522189
(Previous) Eval Time (s)     21.74675972526893
Sample Time (s)              5.061086689122021
Epoch Time (s)               165.51625456660986
Total Train Time (s)         34498.43466595514
Epoch                        213
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 18:05:44.952679 UTC | [2020_01_04_08_30_45] Iteration #213 | Epoch Duration: 165.92215299606323
2020-01-04 18:05:44.952855 UTC | [2020_01_04_08_30_45] Iteration #213 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0016661588
Z variance train             0.00014895252
KL Divergence                19.532183
KL Loss                      1.9532183
QF Loss                      244.21602
VF Loss                      27.09862
Policy Loss                  -1349.5275
Q Predictions Mean           1346.2175
Q Predictions Std            223.21689
Q Predictions Max            1552.1086
Q Predictions Min            27.954395
V Predictions Mean           1348.3618
V Predictions Std            222.40594
V Predictions Max            1541.7957
V Predictions Min            28.194592
Log Pis Mean                 -0.7580906
Log Pis Std                  1.4892755
Log Pis Max                  5.0874534
Log Pis Min                  -3.8792033
Policy mu Mean               0.10274398
Policy mu Std                0.7456158
Policy mu Max                2.0901792
Policy mu Min                -2.6950111
Policy log std Mean          -0.5017755
Policy log std Std           0.17188396
Policy log std Max           0.0679732
Policy log std Min           -1.1987734
Z mean eval                  0.0022284356
Z variance eval              0.00014932222
total_rewards                [3104.99926673 3078.17831127 2982.07049603 1345.75443087 3034.45501309
 3020.53594001 1430.03235931 3050.79376779 3049.87404496 3032.61696868]
total_rewards_mean           2712.9310598732845
total_rewards_std            663.5088062742101
total_rewards_max            3104.999266730227
total_rewards_min            1345.7544308689642
Number of train steps total  860000
Number of env steps total    1122879
Number of rollouts total     0
Train Time (s)               131.93022897280753
(Previous) Eval Time (s)     22.152431985829026
Sample Time (s)              5.097513556480408
Epoch Time (s)               159.18017451511696
Total Train Time (s)         34655.31442075223
Epoch                        214
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 18:08:21.836133 UTC | [2020_01_04_08_30_45] Iteration #214 | Epoch Duration: 156.88314390182495
2020-01-04 18:08:21.836306 UTC | [2020_01_04_08_30_45] Iteration #214 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0022509187
Z variance train             0.00014932474
KL Divergence                19.525589
KL Loss                      1.9525589
QF Loss                      46.589024
VF Loss                      26.478489
Policy Loss                  -1348.852
Q Predictions Mean           1348.4374
Q Predictions Std            193.60431
Q Predictions Max            1540.3999
Q Predictions Min            36.564945
V Predictions Mean           1350.397
V Predictions Std            194.13718
V Predictions Max            1543.0631
V Predictions Min            25.002056
Log Pis Mean                 -0.5777947
Log Pis Std                  1.6343594
Log Pis Max                  6.5833035
Log Pis Min                  -4.4220104
Policy mu Mean               0.18550165
Policy mu Std                0.7240463
Policy mu Max                2.0929165
Policy mu Min                -2.7117383
Policy log std Mean          -0.4659854
Policy log std Std           0.17206861
Policy log std Max           0.039081037
Policy log std Min           -1.3443834
Z mean eval                  0.002108139
Z variance eval              0.00015081077
total_rewards                [3043.2685468    37.97013519 3089.34670157 3081.12956137 3069.48167888
 3062.49438683 3093.80223617 3113.31118114 3110.49245682 3088.61928603]
total_rewards_mean           2778.991617080495
total_rewards_std            913.8952001736424
total_rewards_max            3113.311181140516
total_rewards_min            37.970135190879176
Number of train steps total  864000
Number of env steps total    1127879
Number of rollouts total     0
Train Time (s)               134.51599990110844
(Previous) Eval Time (s)     19.85519097233191
Sample Time (s)              5.107433712575585
Epoch Time (s)               159.47862458601594
Total Train Time (s)         34815.05254291603
Epoch                        215
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 18:11:01.576856 UTC | [2020_01_04_08_30_45] Iteration #215 | Epoch Duration: 159.74042296409607
2020-01-04 18:11:01.577025 UTC | [2020_01_04_08_30_45] Iteration #215 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0020914436
Z variance train             0.0001508117
KL Divergence                19.501175
KL Loss                      1.9501175
QF Loss                      81.40068
VF Loss                      61.74903
Policy Loss                  -1344.0962
Q Predictions Mean           1343.0845
Q Predictions Std            223.97362
Q Predictions Max            1534.5052
Q Predictions Min            39.385944
V Predictions Mean           1340.0922
V Predictions Std            224.91443
V Predictions Max            1530.9108
V Predictions Min            42.573124
Log Pis Mean                 -0.52217
Log Pis Std                  1.7232916
Log Pis Max                  6.5753527
Log Pis Min                  -4.1559086
Policy mu Mean               0.10737691
Policy mu Std                0.7806763
Policy mu Max                2.9163013
Policy mu Min                -2.671096
Policy log std Mean          -0.47644043
Policy log std Std           0.19840774
Policy log std Max           0.08355588
Policy log std Min           -1.3309418
Z mean eval                  0.001366232
Z variance eval              0.00015099607
total_rewards                [ 876.37890033 1434.19045056 3047.5852412  3118.29093623 3172.20064886
 3121.69721576 3101.73810325 3096.03101595 3117.74391162 3131.45984429]
total_rewards_mean           2721.73162680671
total_rewards_std            793.6391836680523
total_rewards_max            3172.200648864755
total_rewards_min            876.3789003274098
Number of train steps total  868000
Number of env steps total    1132900
Number of rollouts total     0
Train Time (s)               136.11889286711812
(Previous) Eval Time (s)     20.116741836071014
Sample Time (s)              4.314220718108118
Epoch Time (s)               160.54985542129725
Total Train Time (s)         34976.17637549061
Epoch                        216
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 18:13:42.702933 UTC | [2020_01_04_08_30_45] Iteration #216 | Epoch Duration: 161.12578701972961
2020-01-04 18:13:42.703077 UTC | [2020_01_04_08_30_45] Iteration #216 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.00136576
Z variance train             0.00015099645
KL Divergence                19.497942
KL Loss                      1.9497942
QF Loss                      158.88731
VF Loss                      30.343777
Policy Loss                  -1354.5189
Q Predictions Mean           1353.1819
Q Predictions Std            232.1332
Q Predictions Max            1536.3464
Q Predictions Min            77.21921
V Predictions Mean           1353.0098
V Predictions Std            231.51672
V Predictions Max            1553.188
V Predictions Min            73.46153
Log Pis Mean                 -0.5093272
Log Pis Std                  2.056153
Log Pis Max                  7.0992537
Log Pis Min                  -5.8837385
Policy mu Mean               0.049400996
Policy mu Std                0.808177
Policy mu Max                2.090922
Policy mu Min                -2.9522698
Policy log std Mean          -0.49346694
Policy log std Std           0.18636489
Policy log std Max           -0.020993263
Policy log std Min           -1.2192621
Z mean eval                  0.0019282363
Z variance eval              0.000152264
total_rewards                [3135.2783246  3171.74357751 3143.42809813 3144.07528811 3113.28653397
 3108.95714004 3171.62196357 3162.33151298 3116.86847894 3130.37055979]
total_rewards_mean           3139.79614776537
total_rewards_std            22.049036403446063
total_rewards_max            3171.743577510935
total_rewards_min            3108.957140044034
Number of train steps total  872000
Number of env steps total    1137900
Number of rollouts total     0
Train Time (s)               130.8423061678186
(Previous) Eval Time (s)     20.692479111254215
Sample Time (s)              5.117825252003968
Epoch Time (s)               156.6526105310768
Total Train Time (s)         35134.89811495226
Epoch                        217
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 18:16:21.428874 UTC | [2020_01_04_08_30_45] Iteration #217 | Epoch Duration: 158.72566652297974
2020-01-04 18:16:21.429096 UTC | [2020_01_04_08_30_45] Iteration #217 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0019538254
Z variance train             0.00015226522
KL Divergence                19.476507
KL Loss                      1.9476508
QF Loss                      70.6803
VF Loss                      17.448273
Policy Loss                  -1353.6852
Q Predictions Mean           1354.5842
Q Predictions Std            173.68619
Q Predictions Max            1545.3488
Q Predictions Min            463.47684
V Predictions Mean           1354.611
V Predictions Std            173.54225
V Predictions Max            1542.5171
V Predictions Min            457.72467
Log Pis Mean                 -0.50020516
Log Pis Std                  1.7093716
Log Pis Max                  4.2472153
Log Pis Min                  -6.9835114
Policy mu Mean               0.16208778
Policy mu Std                0.75613505
Policy mu Max                2.2829604
Policy mu Min                -2.7164657
Policy log std Mean          -0.452921
Policy log std Std           0.18714131
Policy log std Max           0.04400927
Policy log std Min           -1.163744
Z mean eval                  0.0013337114
Z variance eval              0.00015292011
total_rewards                [3115.26205981 3068.54491104 3147.27816515 3160.67512015 3165.50636601
 3184.48517685 3156.73668379 3172.21778982 3172.81688601 3128.56558704]
total_rewards_mean           3147.20887456873
total_rewards_std            32.91481584008329
total_rewards_max            3184.4851768460876
total_rewards_min            3068.544911040143
Number of train steps total  876000
Number of env steps total    1142900
Number of rollouts total     0
Train Time (s)               133.22218423197046
(Previous) Eval Time (s)     22.765308670233935
Sample Time (s)              5.244018878322095
Epoch Time (s)               161.2315117805265
Total Train Time (s)         35296.50816512015
Epoch                        218
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 18:19:03.041119 UTC | [2020_01_04_08_30_45] Iteration #218 | Epoch Duration: 161.61186361312866
2020-01-04 18:19:03.041293 UTC | [2020_01_04_08_30_45] Iteration #218 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.001332596
Z variance train             0.00015292111
KL Divergence                19.465483
KL Loss                      1.9465483
QF Loss                      71.02759
VF Loss                      18.863995
Policy Loss                  -1370.1973
Q Predictions Mean           1370.1536
Q Predictions Std            131.60112
Q Predictions Max            1549.3297
Q Predictions Min            716.38275
V Predictions Mean           1369.0602
V Predictions Std            130.15096
V Predictions Max            1552.655
V Predictions Min            715.63403
Log Pis Mean                 -0.62366974
Log Pis Std                  1.5830878
Log Pis Max                  4.703472
Log Pis Min                  -5.4959946
Policy mu Mean               0.13582893
Policy mu Std                0.7387435
Policy mu Max                2.5293858
Policy mu Min                -2.7383268
Policy log std Mean          -0.47520804
Policy log std Std           0.19548154
Policy log std Max           0.10716981
Policy log std Min           -1.4029739
Z mean eval                  0.002790701
Z variance eval              0.00015314484
total_rewards                [3029.07645729 3015.56702929 3141.08170479 3192.74338626 3207.2115218
 3193.40146578 3174.72852512 3171.00336515 3158.43314514 3153.33878135]
total_rewards_mean           3143.658538196321
total_rewards_std            63.63243719691836
total_rewards_max            3207.211521799209
total_rewards_min            3015.567029286503
Number of train steps total  880000
Number of env steps total    1147900
Number of rollouts total     0
Train Time (s)               127.67336282506585
(Previous) Eval Time (s)     23.145456230733544
Sample Time (s)              5.4157068422064185
Epoch Time (s)               156.2345258980058
Total Train Time (s)         35452.40623207763
Epoch                        219
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 18:21:38.941960 UTC | [2020_01_04_08_30_45] Iteration #219 | Epoch Duration: 155.90052366256714
2020-01-04 18:21:38.942155 UTC | [2020_01_04_08_30_45] Iteration #219 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0028068912
Z variance train             0.00015313945
KL Divergence                19.462059
KL Loss                      1.946206
QF Loss                      69.12811
VF Loss                      68.783905
Policy Loss                  -1365.5852
Q Predictions Mean           1367.2065
Q Predictions Std            193.61623
Q Predictions Max            1543.3025
Q Predictions Min            218.84912
V Predictions Mean           1370.72
V Predictions Std            193.67497
V Predictions Max            1546.4731
V Predictions Min            218.71112
Log Pis Mean                 -0.66086686
Log Pis Std                  1.589919
Log Pis Max                  7.2028008
Log Pis Min                  -6.010704
Policy mu Mean               0.02518327
Policy mu Std                0.7401418
Policy mu Max                2.0861547
Policy mu Min                -2.6325405
Policy log std Mean          -0.47809473
Policy log std Std           0.18226627
Policy log std Max           -0.0115894675
Policy log std Min           -1.2689576
Z mean eval                  0.0034416218
Z variance eval              0.0001522014
total_rewards                [ 626.34504432  691.2764705  3042.78196397 3120.62195314 3063.98175235
 3089.72623711 3076.79115096 3092.67156638 3148.53898378 3134.07497003]
total_rewards_mean           2608.6810092543265
total_rewards_std            975.5094003014676
total_rewards_max            3148.5389837830785
total_rewards_min            626.3450443212005
Number of train steps total  884000
Number of env steps total    1153097
Number of rollouts total     0
Train Time (s)               133.37365342862904
(Previous) Eval Time (s)     22.81121063325554
Sample Time (s)              5.215327254962176
Epoch Time (s)               161.40019131684676
Total Train Time (s)         35610.5256640506
Epoch                        220
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 18:24:17.066314 UTC | [2020_01_04_08_30_45] Iteration #220 | Epoch Duration: 158.12401795387268
2020-01-04 18:24:17.066516 UTC | [2020_01_04_08_30_45] Iteration #220 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0034338771
Z variance train             0.0001522062
KL Divergence                19.478197
KL Loss                      1.9478197
QF Loss                      49.675613
VF Loss                      35.044697
Policy Loss                  -1357.7598
Q Predictions Mean           1355.9465
Q Predictions Std            204.59938
Q Predictions Max            1539.5054
Q Predictions Min            254.78
V Predictions Mean           1357.1752
V Predictions Std            203.42438
V Predictions Max            1541.059
V Predictions Min            257.26758
Log Pis Mean                 -0.67886674
Log Pis Std                  1.6084677
Log Pis Max                  4.3196077
Log Pis Min                  -5.1981997
Policy mu Mean               0.047994155
Policy mu Std                0.7561345
Policy mu Max                2.5438745
Policy mu Min                -2.9918025
Policy log std Mean          -0.47329307
Policy log std Std           0.17902444
Policy log std Max           0.30500284
Policy log std Min           -1.4472916
Z mean eval                  0.0043425034
Z variance eval              0.00015417345
total_rewards                [2738.24869461 2241.83904542 3067.56443723 3138.32822037 3107.49854023
 3035.60520873 3135.64243915 3077.14649644 3152.04538019 3151.48127792]
total_rewards_mean           2984.539974028892
total_rewards_std            273.4720826846019
total_rewards_max            3152.0453801850304
total_rewards_min            2241.839045416345
Number of train steps total  888000
Number of env steps total    1158233
Number of rollouts total     0
Train Time (s)               136.88557473104447
(Previous) Eval Time (s)     19.53479834785685
Sample Time (s)              5.074918260332197
Epoch Time (s)               161.49529133923352
Total Train Time (s)         35775.85966271488
Epoch                        221
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 18:27:02.404492 UTC | [2020_01_04_08_30_45] Iteration #221 | Epoch Duration: 165.33782482147217
2020-01-04 18:27:02.404716 UTC | [2020_01_04_08_30_45] Iteration #221 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0043457462
Z variance train             0.00015417396
KL Divergence                19.44691
KL Loss                      1.9446911
QF Loss                      35.862686
VF Loss                      24.873783
Policy Loss                  -1390.7722
Q Predictions Mean           1390.8909
Q Predictions Std            161.70341
Q Predictions Max            1550.6101
Q Predictions Min            241.54259
V Predictions Mean           1393.2874
V Predictions Std            161.36665
V Predictions Max            1552.9729
V Predictions Min            232.46007
Log Pis Mean                 -0.823088
Log Pis Std                  1.6021475
Log Pis Max                  4.974719
Log Pis Min                  -5.9848785
Policy mu Mean               0.1693175
Policy mu Std                0.6930196
Policy mu Max                2.3004098
Policy mu Min                -2.56449
Policy log std Mean          -0.44709754
Policy log std Std           0.17476407
Policy log std Max           0.07009354
Policy log std Min           -1.1663771
Z mean eval                  0.0018467002
Z variance eval              0.00015585544
total_rewards                [3025.37366058 2955.17395816 3059.13646371 3056.97220453 3008.27355087
 3063.47427813 3108.10272877 3024.31260408 3058.04234208 3047.66264794]
total_rewards_mean           3040.6524438827387
total_rewards_std            38.581495517519386
total_rewards_max            3108.102728767056
total_rewards_min            2955.173958161248
Number of train steps total  892000
Number of env steps total    1163310
Number of rollouts total     0
Train Time (s)               132.74388600979
(Previous) Eval Time (s)     23.37707437109202
Sample Time (s)              5.2788734161295
Epoch Time (s)               161.39983379701152
Total Train Time (s)         35936.90244025644
Epoch                        222
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 18:29:43.449483 UTC | [2020_01_04_08_30_45] Iteration #222 | Epoch Duration: 161.04459428787231
2020-01-04 18:29:43.449655 UTC | [2020_01_04_08_30_45] Iteration #222 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0018382728
Z variance train             0.00015585736
KL Divergence                19.42125
KL Loss                      1.942125
QF Loss                      39.388786
VF Loss                      13.931926
Policy Loss                  -1367.2043
Q Predictions Mean           1365.8099
Q Predictions Std            197.50807
Q Predictions Max            1550.3074
Q Predictions Min            298.25925
V Predictions Mean           1366.6962
V Predictions Std            196.64229
V Predictions Max            1552.8722
V Predictions Min            290.6826
Log Pis Mean                 -0.7758339
Log Pis Std                  1.8083677
Log Pis Max                  12.593044
Log Pis Min                  -5.037695
Policy mu Mean               0.07299054
Policy mu Std                0.7380528
Policy mu Max                3.267476
Policy mu Min                -2.745028
Policy log std Mean          -0.44515648
Policy log std Std           0.17790094
Policy log std Max           0.22315156
Policy log std Min           -1.0795095
Z mean eval                  0.0023238051
Z variance eval              0.00015622922
total_rewards                [2823.88450868 2770.39916537 3089.14217104 3077.29958715 3097.98486194
 3097.3034095  3121.6734476  3091.49171591 3075.44193457 3029.7309314 ]
total_rewards_mean           3027.4351733172416
total_rewards_std            117.87596761116502
total_rewards_max            3121.6734476034603
total_rewards_min            2770.399165371031
Number of train steps total  896000
Number of env steps total    1168310
Number of rollouts total     0
Train Time (s)               132.2894427939318
(Previous) Eval Time (s)     23.021615478675812
Sample Time (s)              5.121858986094594
Epoch Time (s)               160.43291725870222
Total Train Time (s)         36097.693331697024
Epoch                        223
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 18:32:24.243224 UTC | [2020_01_04_08_30_45] Iteration #223 | Epoch Duration: 160.79343509674072
2020-01-04 18:32:24.243409 UTC | [2020_01_04_08_30_45] Iteration #223 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0023219397
Z variance train             0.00015622898
KL Divergence                19.414392
KL Loss                      1.9414393
QF Loss                      77.40517
VF Loss                      25.588545
Policy Loss                  -1381.6399
Q Predictions Mean           1381.8903
Q Predictions Std            168.59491
Q Predictions Max            1546.1051
Q Predictions Min            301.36838
V Predictions Mean           1383.1123
V Predictions Std            167.93375
V Predictions Max            1546.3977
V Predictions Min            295.60724
Log Pis Mean                 -0.7414433
Log Pis Std                  1.7912085
Log Pis Max                  9.476178
Log Pis Min                  -4.9332533
Policy mu Mean               0.06410829
Policy mu Std                0.75923294
Policy mu Max                3.0737195
Policy mu Min                -2.9773216
Policy log std Mean          -0.44863972
Policy log std Std           0.18299453
Policy log std Max           0.06406194
Policy log std Min           -1.1983266
Z mean eval                  0.0027125005
Z variance eval              0.00015594244
total_rewards                [3047.13269401 3122.56810666 3108.90423288 3146.66893644 3118.30404415
 3131.12740934 3080.807853   3093.53484835 3136.82454466 3131.23400385]
total_rewards_mean           3111.710667335126
total_rewards_std            28.698169978213524
total_rewards_max            3146.668936441207
total_rewards_min            3047.13269400946
Number of train steps total  900000
Number of env steps total    1173856
Number of rollouts total     0
Train Time (s)               130.78791318181902
(Previous) Eval Time (s)     23.38190915901214
Sample Time (s)              6.045864501036704
Epoch Time (s)               160.21568684186786
Total Train Time (s)         36257.187265264336
Epoch                        224
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 18:35:03.743892 UTC | [2020_01_04_08_30_45] Iteration #224 | Epoch Duration: 159.50028324127197
2020-01-04 18:35:03.744304 UTC | [2020_01_04_08_30_45] Iteration #224 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0027173911
Z variance train             0.00015594024
KL Divergence                19.418587
KL Loss                      1.9418586
QF Loss                      110.692215
VF Loss                      18.759336
Policy Loss                  -1384.9755
Q Predictions Mean           1385.675
Q Predictions Std            138.41394
Q Predictions Max            1561.4548
Q Predictions Min            619.84766
V Predictions Mean           1384.666
V Predictions Std            138.1594
V Predictions Max            1559.2648
V Predictions Min            602.20154
Log Pis Mean                 -0.6813942
Log Pis Std                  1.7899418
Log Pis Max                  10.132684
Log Pis Min                  -5.324277
Policy mu Mean               0.107904196
Policy mu Std                0.74160236
Policy mu Max                2.1838808
Policy mu Min                -3.7532012
Policy log std Mean          -0.45298052
Policy log std Std           0.19833265
Policy log std Max           0.039089084
Policy log std Min           -1.4131609
Z mean eval                  0.0031200233
Z variance eval              0.00015620666
total_rewards                [3096.46215729 3098.01297502 3127.22993067 3137.56171042 3125.59503365
 3109.63737021 3088.12284408 3106.27171524 3126.21596167 3101.4601227 ]
total_rewards_mean           3111.6569820952764
total_rewards_std            15.581264388696507
total_rewards_max            3137.561710424482
total_rewards_min            3088.1228440772893
Number of train steps total  904000
Number of env steps total    1178934
Number of rollouts total     0
Train Time (s)               131.37002235092223
(Previous) Eval Time (s)     22.666231864131987
Sample Time (s)              5.032702757976949
Epoch Time (s)               159.06895697303116
Total Train Time (s)         36416.10304739885
Epoch                        225
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 18:37:42.662729 UTC | [2020_01_04_08_30_45] Iteration #225 | Epoch Duration: 158.9182744026184
2020-01-04 18:37:42.662933 UTC | [2020_01_04_08_30_45] Iteration #225 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0031294376
Z variance train             0.00015620627
KL Divergence                19.415163
KL Loss                      1.9415163
QF Loss                      96.29148
VF Loss                      81.50149
Policy Loss                  -1362.1096
Q Predictions Mean           1363.8562
Q Predictions Std            213.00569
Q Predictions Max            1553.8385
Q Predictions Min            324.42453
V Predictions Mean           1369.0038
V Predictions Std            212.50487
V Predictions Max            1561.2675
V Predictions Min            311.53754
Log Pis Mean                 -0.7024332
Log Pis Std                  1.5816981
Log Pis Max                  5.1037
Log Pis Min                  -5.4701395
Policy mu Mean               0.17234425
Policy mu Std                0.7197797
Policy mu Max                2.5845652
Policy mu Min                -2.8071232
Policy log std Mean          -0.4577354
Policy log std Std           0.18412942
Policy log std Max           0.05404967
Policy log std Min           -1.2487624
Z mean eval                  0.00253533
Z variance eval              0.00015638804
total_rewards                [3104.12577418 3076.47947352 3078.72334513 2978.21012481 3090.15630468
 3082.73121665 3021.51360323 3061.70989416 1639.20171243 3086.20224635]
total_rewards_mean           2921.9053695127727
total_rewards_std            429.04802804736374
total_rewards_max            3104.1257741838804
total_rewards_min            1639.2017124286363
Number of train steps total  908000
Number of env steps total    1183934
Number of rollouts total     0
Train Time (s)               135.8736879490316
(Previous) Eval Time (s)     22.515301092993468
Sample Time (s)              5.4636205695569515
Epoch Time (s)               163.852609611582
Total Train Time (s)         36579.445404440165
Epoch                        226
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 18:40:26.015884 UTC | [2020_01_04_08_30_45] Iteration #226 | Epoch Duration: 163.35275888442993
2020-01-04 18:40:26.016264 UTC | [2020_01_04_08_30_45] Iteration #226 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0025355201
Z variance train             0.00015638751
KL Divergence                19.41309
KL Loss                      1.941309
QF Loss                      152.06337
VF Loss                      24.043802
Policy Loss                  -1390.5098
Q Predictions Mean           1389.6594
Q Predictions Std            170.27252
Q Predictions Max            1553.7175
Q Predictions Min            125.1911
V Predictions Mean           1390.6062
V Predictions Std            168.9521
V Predictions Max            1554.1497
V Predictions Min            140.54353
Log Pis Mean                 -0.7872323
Log Pis Std                  1.7856896
Log Pis Max                  9.476221
Log Pis Min                  -4.8586226
Policy mu Mean               0.13662626
Policy mu Std                0.69558054
Policy mu Max                3.442184
Policy mu Min                -2.6447837
Policy log std Mean          -0.46417567
Policy log std Std           0.18963186
Policy log std Max           0.10240945
Policy log std Min           -1.4091296
Z mean eval                  0.0025374081
Z variance eval              0.00015861039
total_rewards                [3050.99245697 2988.70172629 3103.55489182 3085.17425195 3075.3620487
 3020.15770304 3055.23025942 3040.63715127 3094.97407523 3092.21314962]
total_rewards_mean           3060.6997714297495
total_rewards_std            34.888965130609336
total_rewards_max            3103.5548918191525
total_rewards_min            2988.7017262854674
Number of train steps total  912000
Number of env steps total    1188934
Number of rollouts total     0
Train Time (s)               131.0924853561446
(Previous) Eval Time (s)     22.01521095726639
Sample Time (s)              5.207028217613697
Epoch Time (s)               158.3147245310247
Total Train Time (s)         36739.02010399569
Epoch                        227
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 18:43:05.594831 UTC | [2020_01_04_08_30_45] Iteration #227 | Epoch Duration: 159.57836174964905
2020-01-04 18:43:05.595026 UTC | [2020_01_04_08_30_45] Iteration #227 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0025458457
Z variance train             0.00015861048
KL Divergence                19.377022
KL Loss                      1.9377022
QF Loss                      286.89044
VF Loss                      56.886284
Policy Loss                  -1389.0634
Q Predictions Mean           1385.5706
Q Predictions Std            197.03207
Q Predictions Max            1568.1754
Q Predictions Min            113.98552
V Predictions Mean           1387.593
V Predictions Std            182.81497
V Predictions Max            1571.4856
V Predictions Min            235.27486
Log Pis Mean                 -0.7336173
Log Pis Std                  1.7202638
Log Pis Max                  11.727226
Log Pis Min                  -4.4630847
Policy mu Mean               0.13171957
Policy mu Std                0.7694605
Policy mu Max                3.816793
Policy mu Min                -5.6819286
Policy log std Mean          -0.46678567
Policy log std Std           0.17358239
Policy log std Max           0.026499808
Policy log std Min           -1.2729505
Z mean eval                  0.0030482276
Z variance eval              0.0001589982
total_rewards                [ 200.69733922  797.80638007 3159.2599038  3160.05044837 3195.2274642
 3117.91584147 3207.17366282 3139.4213326  3126.79240752 3188.38116459]
total_rewards_mean           2629.2725944647473
total_rewards_std            1073.6985060027757
total_rewards_max            3207.173662818252
total_rewards_min            200.6973392151942
Number of train steps total  916000
Number of env steps total    1193934
Number of rollouts total     0
Train Time (s)               129.1028802585788
(Previous) Eval Time (s)     23.278617169708014
Sample Time (s)              5.046669422183186
Epoch Time (s)               157.42816685047
Total Train Time (s)         36894.34491557581
Epoch                        228
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 18:45:40.923357 UTC | [2020_01_04_08_30_45] Iteration #228 | Epoch Duration: 155.3281798362732
2020-01-04 18:45:40.923568 UTC | [2020_01_04_08_30_45] Iteration #228 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.003074854
Z variance train             0.00015900133
KL Divergence                19.37125
KL Loss                      1.9371251
QF Loss                      406.58612
VF Loss                      227.95085
Policy Loss                  -1365.2645
Q Predictions Mean           1363.3479
Q Predictions Std            218.33737
Q Predictions Max            1571.0947
Q Predictions Min            60.25852
V Predictions Mean           1362.8398
V Predictions Std            218.40799
V Predictions Max            1571.8756
V Predictions Min            26.583212
Log Pis Mean                 -0.48592505
Log Pis Std                  1.7720578
Log Pis Max                  8.978416
Log Pis Min                  -5.139492
Policy mu Mean               0.17270982
Policy mu Std                0.76818967
Policy mu Max                3.6714797
Policy mu Min                -2.537942
Policy log std Mean          -0.44746098
Policy log std Std           0.19281976
Policy log std Max           0.046254426
Policy log std Min           -1.7124249
Z mean eval                  0.0010602106
Z variance eval              0.00016088317
total_rewards                [2949.16908049 2929.2938542  3144.16075433  914.92440345 3076.63060284
 3189.35836303 3134.72286279 3179.29481583 3155.36780681 3150.11452657]
total_rewards_mean           2882.3037070337023
total_rewards_std            661.5195220261293
total_rewards_max            3189.3583630272988
total_rewards_min            914.9244034535386
Number of train steps total  920000
Number of env steps total    1198934
Number of rollouts total     0
Train Time (s)               129.90795381600037
(Previous) Eval Time (s)     21.178396997973323
Sample Time (s)              5.082078332081437
Epoch Time (s)               156.16842914605513
Total Train Time (s)         37051.10218411824
Epoch                        229
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 18:48:17.683362 UTC | [2020_01_04_08_30_45] Iteration #229 | Epoch Duration: 156.7596411705017
2020-01-04 18:48:17.683555 UTC | [2020_01_04_08_30_45] Iteration #229 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.00093203364
Z variance train             0.00016089014
KL Divergence                19.342081
KL Loss                      1.9342082
QF Loss                      57.94907
VF Loss                      28.688463
Policy Loss                  -1382.7314
Q Predictions Mean           1380.3964
Q Predictions Std            172.44681
Q Predictions Max            1551.9976
Q Predictions Min            283.147
V Predictions Mean           1380.2021
V Predictions Std            172.10071
V Predictions Max            1552.7228
V Predictions Min            286.24283
Log Pis Mean                 -0.67143214
Log Pis Std                  1.6293615
Log Pis Max                  5.257514
Log Pis Min                  -4.7944283
Policy mu Mean               0.13069116
Policy mu Std                0.7495777
Policy mu Max                2.4146383
Policy mu Min                -2.6797822
Policy log std Mean          -0.44980025
Policy log std Std           0.1889092
Policy log std Max           -0.040201902
Policy log std Min           -1.2566175
Z mean eval                  0.0015611916
Z variance eval              0.00016241876
total_rewards                [2733.20150092 2739.45737849 3139.14283276 3102.10249276 3149.86125595
 3116.27516874 3084.02035896 3111.00516226 3131.11383449 3132.10530856]
total_rewards_mean           3043.8285293894273
total_rewards_std            154.80396364363844
total_rewards_max            3149.861255950721
total_rewards_min            2733.2015009203196
Number of train steps total  924000
Number of env steps total    1204375
Number of rollouts total     0
Train Time (s)               130.48174876440316
(Previous) Eval Time (s)     21.769360154867172
Sample Time (s)              5.559905458241701
Epoch Time (s)               157.81101437751204
Total Train Time (s)         37208.91039184434
Epoch                        230
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 18:50:55.494618 UTC | [2020_01_04_08_30_45] Iteration #230 | Epoch Duration: 157.81091403961182
2020-01-04 18:50:55.494815 UTC | [2020_01_04_08_30_45] Iteration #230 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0015538775
Z variance train             0.0001624192
KL Divergence                19.317347
KL Loss                      1.9317347
QF Loss                      91.33923
VF Loss                      29.393114
Policy Loss                  -1408.6521
Q Predictions Mean           1409.145
Q Predictions Std            128.90556
Q Predictions Max            1566.9598
Q Predictions Min            714.92944
V Predictions Mean           1410.9832
V Predictions Std            128.35977
V Predictions Max            1564.2382
V Predictions Min            731.3966
Log Pis Mean                 -0.67943037
Log Pis Std                  1.6522382
Log Pis Max                  5.620633
Log Pis Min                  -4.9132094
Policy mu Mean               0.10898816
Policy mu Std                0.7176662
Policy mu Max                2.3769908
Policy mu Min                -2.8156602
Policy log std Mean          -0.43100825
Policy log std Std           0.18059933
Policy log std Max           -0.024388611
Policy log std Min           -1.234553
Z mean eval                  0.0029100215
Z variance eval              0.00016402508
total_rewards                [1184.87206249  953.39041134 1133.85557974 1133.75618084 3092.15884983
 3091.45745279 3064.82314779 3081.12272349 3115.55262215 3137.91337225]
total_rewards_mean           2298.8902402697795
total_rewards_std            979.4450182964042
total_rewards_max            3137.9133722516
total_rewards_min            953.3904113393809
Number of train steps total  928000
Number of env steps total    1209753
Number of rollouts total     0
Train Time (s)               134.30564625468105
(Previous) Eval Time (s)     21.769030326977372
Sample Time (s)              5.42336045904085
Epoch Time (s)               161.49803704069927
Total Train Time (s)         37365.11942530051
Epoch                        231
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 18:53:31.706710 UTC | [2020_01_04_08_30_45] Iteration #231 | Epoch Duration: 156.21175265312195
2020-01-04 18:53:31.706896 UTC | [2020_01_04_08_30_45] Iteration #231 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0029109607
Z variance train             0.00016402213
KL Divergence                19.29592
KL Loss                      1.929592
QF Loss                      42.889145
VF Loss                      20.424322
Policy Loss                  -1399.9253
Q Predictions Mean           1402.3359
Q Predictions Std            146.62746
Q Predictions Max            1583.6923
Q Predictions Min            482.74573
V Predictions Mean           1401.6643
V Predictions Std            146.62692
V Predictions Max            1575.9667
V Predictions Min            452.66083
Log Pis Mean                 -0.8053819
Log Pis Std                  1.5165938
Log Pis Max                  8.029866
Log Pis Min                  -5.1783867
Policy mu Mean               0.18077813
Policy mu Std                0.6680798
Policy mu Max                2.347357
Policy mu Min                -3.2007005
Policy log std Mean          -0.44821444
Policy log std Std           0.17695732
Policy log std Max           -0.009093046
Policy log std Min           -1.1093749
Z mean eval                  0.0039101345
Z variance eval              0.00016480443
total_rewards                [3105.62780744 3082.09802137 3087.1483221  3126.11626469 3131.91779954
 3114.29719396 3075.83193196 3097.84728386 3126.53780872 3087.40392652]
total_rewards_mean           3103.4826360152956
total_rewards_std            19.37238283177947
total_rewards_max            3131.917799536013
total_rewards_min            3075.8319319612356
Number of train steps total  932000
Number of env steps total    1215248
Number of rollouts total     0
Train Time (s)               130.45307806925848
(Previous) Eval Time (s)     16.482530751731247
Sample Time (s)              5.519545685965568
Epoch Time (s)               152.4551545069553
Total Train Time (s)         37524.52739443164
Epoch                        232
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-04 18:56:11.116604 UTC | [2020_01_04_08_30_45] Iteration #232 | Epoch Duration: 159.4095799922943
2020-01-04 18:56:11.116749 UTC | [2020_01_04_08_30_45] Iteration #232 | Started Training: True
