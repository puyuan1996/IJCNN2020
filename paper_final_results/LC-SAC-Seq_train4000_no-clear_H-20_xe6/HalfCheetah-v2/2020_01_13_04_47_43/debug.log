---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0019530611
Z variance train             0.69260883
KL Divergence                0.14976072
KL Loss                      0.014976072
QF Loss                      30.072021
VF Loss                      16.352331
Policy Loss                  -4.0086412
Q Predictions Mean           -0.006684159
Q Predictions Std            0.0022229382
Q Predictions Max            -0.0018604228
Q Predictions Min            -0.012359737
V Predictions Mean           0.0002574473
V Predictions Std            0.0015592332
V Predictions Max            0.0041628233
V Predictions Min            -0.0041609993
Log Pis Mean                 -4.035728
Log Pis Std                  0.53440696
Log Pis Max                  -2.344994
Log Pis Min                  -5.7029934
Policy mu Mean               0.00053918344
Policy mu Std                0.0013700707
Policy mu Max                0.0043439977
Policy mu Min                -0.002454193
Policy log std Mean          -0.0006518511
Policy log std Std           0.0012498002
Policy log std Max           0.0031305198
Policy log std Min           -0.003774563
Z mean eval                  0.41251212
Z variance eval              0.029696528
total_rewards                [-263.57235197 -313.19398235 -253.22628164 -273.35500782 -283.03149898
 -279.75429145 -279.4459174  -264.21310072 -256.9009236  -268.0589264 ]
total_rewards_mean           -273.4752282347443
total_rewards_std            16.253952313645584
total_rewards_max            -253.22628163849856
total_rewards_min            -313.1939823519828
Number of train steps total  4000
Number of env steps total    7000
Number of rollouts total     0
Train Time (s)               128.64814642211422
(Previous) Eval Time (s)     0
Sample Time (s)              29.706222897861153
Epoch Time (s)               158.35436931997538
Total Train Time (s)         186.90178753435612
Epoch                        0
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:50:50.502535 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #0 | Epoch Duration: 186.90386962890625
2020-01-13 04:50:50.502655 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #0 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.4168915
Z variance train             0.029556906
KL Divergence                7.12335
KL Loss                      0.71233505
QF Loss                      73.067245
VF Loss                      13.690603
Policy Loss                  -68.97317
Q Predictions Mean           64.9538
Q Predictions Std            19.291653
Q Predictions Max            122.526566
Q Predictions Min            9.026272
V Predictions Mean           69.222305
V Predictions Std            18.603779
V Predictions Max            125.88093
V Predictions Min            21.3865
Log Pis Mean                 -2.1012383
Log Pis Std                  1.8905243
Log Pis Max                  3.6459236
Log Pis Min                  -6.7317634
Policy mu Mean               0.010876273
Policy mu Std                0.69954926
Policy mu Max                1.8733157
Policy mu Min                -1.9749867
Policy log std Mean          -0.2430314
Policy log std Std           0.109738626
Policy log std Max           -0.020024715
Policy log std Min           -0.61912674
Z mean eval                  0.8459414
Z variance eval              0.022192145
total_rewards                [ -53.13113265  -52.11204489  -85.51223372    3.07012314   35.12486895
  -21.32466606   -5.35043451 -118.42374128  -85.99649534  -18.50876853]
total_rewards_mean           -40.21645248982065
total_rewards_std            44.90656846885862
total_rewards_max            35.12486895008706
total_rewards_min            -118.4237412835663
Number of train steps total  8000
Number of env steps total    12000
Number of rollouts total     0
Train Time (s)               129.17045164760202
(Previous) Eval Time (s)     28.54906950192526
Sample Time (s)              23.07123115239665
Epoch Time (s)               180.79075230192393
Total Train Time (s)         368.0781780765392
Epoch                        1
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:53:51.681013 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #1 | Epoch Duration: 181.17825198173523
2020-01-13 04:53:51.681206 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #1 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8447755
Z variance train             0.022183126
KL Divergence                9.90311
KL Loss                      0.99031097
QF Loss                      91.25952
VF Loss                      32.377754
Policy Loss                  -123.001915
Q Predictions Mean           119.57558
Q Predictions Std            32.308617
Q Predictions Max            219.00769
Q Predictions Min            50.593933
V Predictions Mean           126.21886
V Predictions Std            33.239532
V Predictions Max            220.56844
V Predictions Min            57.21777
Log Pis Mean                 -1.9645396
Log Pis Std                  2.0900936
Log Pis Max                  4.771961
Log Pis Min                  -6.9988966
Policy mu Mean               -0.11662211
Policy mu Std                0.6912752
Policy mu Max                3.0196316
Policy mu Min                -2.22548
Policy log std Mean          -0.28233495
Policy log std Std           0.14612423
Policy log std Max           0.08432025
Policy log std Min           -0.74318475
Z mean eval                  1.0454212
Z variance eval              0.013096554
total_rewards                [360.71050293 658.38997218 934.20530035 732.25145273 993.0732366
 776.31762251 727.80537594 306.35057557 847.81230195 755.00019089]
total_rewards_mean           709.19165316359
total_rewards_std            210.76502999327943
total_rewards_max            993.0732365957152
total_rewards_min            306.3505755699643
Number of train steps total  12000
Number of env steps total    17000
Number of rollouts total     0
Train Time (s)               125.08997519593686
(Previous) Eval Time (s)     28.936210989952087
Sample Time (s)              21.127477985341102
Epoch Time (s)               175.15366417123005
Total Train Time (s)         541.3898109733127
Epoch                        2
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:56:44.993389 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #2 | Epoch Duration: 173.3120460510254
2020-01-13 04:56:44.993575 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #2 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0446813
Z variance train             0.013067638
KL Divergence                12.702362
KL Loss                      1.2702363
QF Loss                      60.92475
VF Loss                      16.649487
Policy Loss                  -187.25542
Q Predictions Mean           182.58957
Q Predictions Std            57.630684
Q Predictions Max            302.25827
Q Predictions Min            103.68844
V Predictions Mean           186.50906
V Predictions Std            57.039124
V Predictions Max            302.3349
V Predictions Min            107.32439
Log Pis Mean                 -2.2650628
Log Pis Std                  1.7857271
Log Pis Max                  2.8376656
Log Pis Min                  -6.960513
Policy mu Mean               -0.037323747
Policy mu Std                0.61639565
Policy mu Max                2.4663985
Policy mu Min                -1.8832737
Policy log std Mean          -0.341673
Policy log std Std           0.17324038
Policy log std Max           0.13234699
Policy log std Min           -1.0033957
Z mean eval                  1.1524985
Z variance eval              0.01714981
total_rewards                [2021.00537098 1353.67650591  692.58216712  926.76370928  446.34530332
  328.01957074  397.68463296  297.18196824  426.59368523  255.50406242]
total_rewards_mean           714.5356976182226
total_rewards_std            543.176476647035
total_rewards_max            2021.0053709819517
total_rewards_min            255.50406242001105
Number of train steps total  16000
Number of env steps total    22000
Number of rollouts total     0
Train Time (s)               122.63736859569326
(Previous) Eval Time (s)     27.0942023107782
Sample Time (s)              20.82736107846722
Epoch Time (s)               170.55893198493868
Total Train Time (s)         712.4034570464864
Epoch                        3
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:59:36.008783 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #3 | Epoch Duration: 171.01507425308228
2020-01-13 04:59:36.008977 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #3 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1531117
Z variance train             0.017161602
KL Divergence                12.808952
KL Loss                      1.2808952
QF Loss                      106.311035
VF Loss                      22.107367
Policy Loss                  -256.68375
Q Predictions Mean           254.36862
Q Predictions Std            90.49488
Q Predictions Max            447.87985
Q Predictions Min            125.10891
V Predictions Mean           258.5239
V Predictions Std            88.964516
V Predictions Max            441.9377
V Predictions Min            130.85806
Log Pis Mean                 -1.2606807
Log Pis Std                  2.2323582
Log Pis Max                  4.6179934
Log Pis Min                  -7.2981896
Policy mu Mean               0.027960977
Policy mu Std                0.75242317
Policy mu Max                2.3881683
Policy mu Min                -1.9909483
Policy log std Mean          -0.39661703
Policy log std Std           0.21069807
Policy log std Max           0.18281797
Policy log std Min           -1.1988239
Z mean eval                  1.3873724
Z variance eval              0.015330422
total_rewards                [2161.45089817 2140.389563   2219.23947071 2220.63960063 2370.01047189
 2295.95518411  385.82150584 2210.30720653 2155.05275174 2213.41993892]
total_rewards_mean           2037.228659154814
total_rewards_std            554.3060209624529
total_rewards_max            2370.0104718852185
total_rewards_min            385.82150584380923
Number of train steps total  20000
Number of env steps total    27000
Number of rollouts total     0
Train Time (s)               123.0724608679302
(Previous) Eval Time (s)     27.550037991721183
Sample Time (s)              21.85994529351592
Epoch Time (s)               172.4824441531673
Total Train Time (s)         885.7268639518879
Epoch                        4
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:02:29.333225 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #4 | Epoch Duration: 173.3241012096405
2020-01-13 05:02:29.333502 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #4 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3888525
Z variance train             0.015359682
KL Divergence                15.3641205
KL Loss                      1.5364121
QF Loss                      136.03438
VF Loss                      28.846882
Policy Loss                  -358.59708
Q Predictions Mean           355.17712
Q Predictions Std            131.96811
Q Predictions Max            597.04645
Q Predictions Min            149.2025
V Predictions Mean           356.79733
V Predictions Std            128.99985
V Predictions Max            573.87695
V Predictions Min            151.9281
Log Pis Mean                 -0.19758832
Log Pis Std                  3.0011601
Log Pis Max                  8.792863
Log Pis Min                  -5.8803906
Policy mu Mean               0.004874474
Policy mu Std                0.9105834
Policy mu Max                2.5368156
Policy mu Min                -2.2518578
Policy log std Mean          -0.45925698
Policy log std Std           0.22502053
Policy log std Max           0.068648666
Policy log std Min           -1.3470342
Z mean eval                  1.6123501
Z variance eval              0.00846571
total_rewards                [2692.83795408 2515.03315049 2552.26804566 2677.40507992 2494.75423274
 2739.1760681  2641.26731724 2605.60410794 2657.66574805 2679.83119861]
total_rewards_mean           2625.5842902828963
total_rewards_std            77.09862756687049
total_rewards_max            2739.1760680999023
total_rewards_min            2494.754232743648
Number of train steps total  24000
Number of env steps total    32000
Number of rollouts total     0
Train Time (s)               129.74283995199949
(Previous) Eval Time (s)     28.39135857997462
Sample Time (s)              21.994118144270033
Epoch Time (s)               180.12831667624414
Total Train Time (s)         1065.3359134476632
Epoch                        5
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:05:28.943101 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #5 | Epoch Duration: 179.60942101478577
2020-01-13 05:05:28.943333 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #5 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6117465
Z variance train             0.00849103
KL Divergence                18.669346
KL Loss                      1.8669347
QF Loss                      116.89687
VF Loss                      42.621017
Policy Loss                  -462.16455
Q Predictions Mean           455.185
Q Predictions Std            165.67967
Q Predictions Max            730.5332
Q Predictions Min            167.9455
V Predictions Mean           459.74316
V Predictions Std            164.10025
V Predictions Max            722.6899
V Predictions Min            173.9784
Log Pis Mean                 -0.42441562
Log Pis Std                  2.5088913
Log Pis Max                  7.5955787
Log Pis Min                  -5.1910496
Policy mu Mean               0.018225195
Policy mu Std                0.8645351
Policy mu Max                2.3146482
Policy mu Min                -2.087457
Policy log std Mean          -0.4890952
Policy log std Std           0.2144586
Policy log std Max           -0.014461324
Policy log std Min           -1.3625927
Z mean eval                  1.7243465
Z variance eval              0.0065839575
total_rewards                [2828.15949946 3003.46162819 2618.42025184 2849.37148156 2886.86075529
 2801.19709226 2885.85563237 2877.08196868 2941.6142615  2729.42906276]
total_rewards_mean           2842.1451633918978
total_rewards_std            102.82513861192376
total_rewards_max            3003.4616281862714
total_rewards_min            2618.4202518373545
Number of train steps total  28000
Number of env steps total    37000
Number of rollouts total     0
Train Time (s)               128.22781651793048
(Previous) Eval Time (s)     27.87213307712227
Sample Time (s)              23.790333015378565
Epoch Time (s)               179.8902826104313
Total Train Time (s)         1246.89247624157
Epoch                        6
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:08:30.501710 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #6 | Epoch Duration: 181.55820393562317
2020-01-13 05:08:30.502067 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #6 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7251089
Z variance train             0.0065787444
KL Divergence                20.391747
KL Loss                      2.0391748
QF Loss                      134.31175
VF Loss                      40.960236
Policy Loss                  -580.0475
Q Predictions Mean           579.718
Q Predictions Std            206.4138
Q Predictions Max            870.69086
Q Predictions Min            195.83714
V Predictions Mean           580.6615
V Predictions Std            203.8655
V Predictions Max            868.5578
V Predictions Min            199.73068
Log Pis Mean                 -0.10618477
Log Pis Std                  3.0337222
Log Pis Max                  7.239845
Log Pis Min                  -11.61224
Policy mu Mean               0.044077694
Policy mu Std                0.88678974
Policy mu Max                2.2588856
Policy mu Min                -2.1539214
Policy log std Mean          -0.5460806
Policy log std Std           0.22719783
Policy log std Max           -0.021850228
Policy log std Min           -1.3467463
Z mean eval                  1.8142908
Z variance eval              0.009204874
total_rewards                [3347.80944526 3372.50182389 3363.35057416 3554.07241599 3298.20620523
 3482.82224545 3395.70623033 3244.49874631 3546.72529796 3565.81554856]
total_rewards_mean           3417.1508533155807
total_rewards_std            107.73284658862255
total_rewards_max            3565.8155485602647
total_rewards_min            3244.498746308841
Number of train steps total  32000
Number of env steps total    42000
Number of rollouts total     0
Train Time (s)               128.20434849569574
(Previous) Eval Time (s)     29.539598107803613
Sample Time (s)              23.35998937813565
Epoch Time (s)               181.103935981635
Total Train Time (s)         1426.6319704223424
Epoch                        7
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:11:30.242388 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #7 | Epoch Duration: 179.74012517929077
2020-01-13 05:11:30.242592 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #7 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8144636
Z variance train             0.0092092585
KL Divergence                20.36407
KL Loss                      2.0364072
QF Loss                      162.71606
VF Loss                      47.666504
Policy Loss                  -661.4111
Q Predictions Mean           656.20465
Q Predictions Std            229.68564
Q Predictions Max            1039.9319
Q Predictions Min            206.13573
V Predictions Mean           661.4815
V Predictions Std            228.50308
V Predictions Max            1015.10895
V Predictions Min            210.74792
Log Pis Mean                 0.37200865
Log Pis Std                  3.0531464
Log Pis Max                  8.052788
Log Pis Min                  -6.4546986
Policy mu Mean               -0.05631427
Policy mu Std                0.93361336
Policy mu Max                2.65058
Policy mu Min                -2.106049
Policy log std Mean          -0.5996502
Policy log std Std           0.2529432
Policy log std Max           -0.08380608
Policy log std Min           -1.5444207
Z mean eval                  1.8094561
Z variance eval              0.016029088
total_rewards                [1696.25278236 3266.1503735  3469.77596612 3760.59448379 2421.45311777
 3612.62973335 3673.69008255 3708.72939744 3450.22057745 3648.23049407]
total_rewards_mean           3270.7727008384772
total_rewards_std            642.3158423852061
total_rewards_max            3760.5944837888283
total_rewards_min            1696.2527823554542
Number of train steps total  36000
Number of env steps total    47000
Number of rollouts total     0
Train Time (s)               129.65291046677157
(Previous) Eval Time (s)     28.175388231873512
Sample Time (s)              23.530622941441834
Epoch Time (s)               181.35892164008692
Total Train Time (s)         1607.578623380512
Epoch                        8
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:14:31.190045 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #8 | Epoch Duration: 180.94730138778687
2020-01-13 05:14:31.190237 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #8 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8093636
Z variance train             0.016028073
KL Divergence                18.622683
KL Loss                      1.8622683
QF Loss                      187.48602
VF Loss                      95.89601
Policy Loss                  -762.35724
Q Predictions Mean           762.6053
Q Predictions Std            278.57016
Q Predictions Max            1122.8439
Q Predictions Min            204.99916
V Predictions Mean           767.28094
V Predictions Std            278.54306
V Predictions Max            1123.581
V Predictions Min            203.67255
Log Pis Mean                 0.64439094
Log Pis Std                  3.2203631
Log Pis Max                  10.009582
Log Pis Min                  -11.538987
Policy mu Mean               -0.08419856
Policy mu Std                0.9791118
Policy mu Max                2.5454803
Policy mu Min                -2.656161
Policy log std Mean          -0.5911507
Policy log std Std           0.26712713
Policy log std Max           -0.014669597
Policy log std Min           -1.7054617
Z mean eval                  1.897831
Z variance eval              0.008491794
total_rewards                [4317.83454654 4110.1667456  4271.29119976 4034.56462958 4067.58577139
 4208.73634556 3933.93500836 4078.414103   3855.50575947 1369.87768186]
total_rewards_mean           3824.791179112427
total_rewards_std            829.3396094120194
total_rewards_max            4317.834546536084
total_rewards_min            1369.8776818553506
Number of train steps total  40000
Number of env steps total    52000
Number of rollouts total     0
Train Time (s)               127.45694114081562
(Previous) Eval Time (s)     27.763393457978964
Sample Time (s)              22.461656449362636
Epoch Time (s)               177.68199104815722
Total Train Time (s)         1784.161436028313
Epoch                        9
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:17:27.773891 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #9 | Epoch Duration: 176.5835211277008
2020-01-13 05:17:27.774075 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #9 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8956875
Z variance train             0.008445034
KL Divergence                21.439865
KL Loss                      2.1439865
QF Loss                      136.04855
VF Loss                      131.9807
Policy Loss                  -862.9387
Q Predictions Mean           862.7285
Q Predictions Std            304.90073
Q Predictions Max            1271.9165
Q Predictions Min            220.9783
V Predictions Mean           869.53784
V Predictions Std            305.00006
V Predictions Max            1278.8065
V Predictions Min            221.02731
Log Pis Mean                 1.1002226
Log Pis Std                  3.3312573
Log Pis Max                  11.755883
Log Pis Min                  -8.076817
Policy mu Mean               -0.12638126
Policy mu Std                1.0221453
Policy mu Max                2.6664343
Policy mu Min                -2.6290972
Policy log std Mean          -0.60542154
Policy log std Std           0.2676194
Policy log std Max           0.019006029
Policy log std Min           -1.8004013
Z mean eval                  1.9335282
Z variance eval              0.013410993
total_rewards                [4348.89696951 4047.47515992 4158.50573746 4411.96623812 4242.5369209
 4224.41158034 4208.84563058 4261.04679558 4345.19868463 4116.13574685]
total_rewards_mean           4236.501946389965
total_rewards_std            106.34275513343165
total_rewards_max            4411.966238122231
total_rewards_min            4047.4751599205033
Number of train steps total  44000
Number of env steps total    57000
Number of rollouts total     0
Train Time (s)               122.70811059232801
(Previous) Eval Time (s)     26.664538546931
Sample Time (s)              21.260485434904695
Epoch Time (s)               170.6331345741637
Total Train Time (s)         1955.7479200907983
Epoch                        10
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:20:19.361485 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #10 | Epoch Duration: 171.58727025985718
2020-01-13 05:20:19.361660 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #10 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9330829
Z variance train             0.013407258
KL Divergence                21.686853
KL Loss                      2.1686854
QF Loss                      242.14912
VF Loss                      84.31851
Policy Loss                  -1011.228
Q Predictions Mean           1009.56006
Q Predictions Std            280.9735
Q Predictions Max            1401.9012
Q Predictions Min            228.86476
V Predictions Mean           1014.52386
V Predictions Std            277.50854
V Predictions Max            1400.5823
V Predictions Min            230.50734
Log Pis Mean                 1.4761403
Log Pis Std                  3.234308
Log Pis Max                  11.345076
Log Pis Min                  -6.1701055
Policy mu Mean               -0.16003454
Policy mu Std                1.0491173
Policy mu Max                2.5130434
Policy mu Min                -2.6139758
Policy log std Mean          -0.6539487
Policy log std Std           0.27059346
Policy log std Max           -0.029707983
Policy log std Min           -1.8897686
Z mean eval                  1.9739945
Z variance eval              0.012944192
total_rewards                [1100.10430158 4480.01292414 4337.52276954 2270.29407369 4342.90642105
 4266.59998371 4447.56000187 2313.91177171  909.12664821 4434.77606332]
total_rewards_mean           3290.2814958810436
total_rewards_std            1402.961163592106
total_rewards_max            4480.012924139078
total_rewards_min            909.1266482089594
Number of train steps total  48000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               122.78400045400485
(Previous) Eval Time (s)     27.61835214914754
Sample Time (s)              22.328372603282332
Epoch Time (s)               172.73072520643473
Total Train Time (s)         2128.1301995650865
Epoch                        11
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:23:11.747737 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #11 | Epoch Duration: 172.38592910766602
2020-01-13 05:23:11.747942 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #11 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9733126
Z variance train             0.012898557
KL Divergence                22.61325
KL Loss                      2.2613251
QF Loss                      300.03424
VF Loss                      75.33944
Policy Loss                  -1054.1493
Q Predictions Mean           1044.8965
Q Predictions Std            343.54358
Q Predictions Max            1510.7007
Q Predictions Min            235.12935
V Predictions Mean           1054.6638
V Predictions Std            341.78918
V Predictions Max            1524.8688
V Predictions Min            234.97946
Log Pis Mean                 1.7826343
Log Pis Std                  3.2466025
Log Pis Max                  9.2254505
Log Pis Min                  -5.375907
Policy mu Mean               -0.070112854
Policy mu Std                1.0907068
Policy mu Max                2.5802805
Policy mu Min                -2.5417898
Policy log std Mean          -0.666735
Policy log std Std           0.27321073
Policy log std Max           -0.06354383
Policy log std Min           -1.9690183
Z mean eval                  2.012433
Z variance eval              0.028847065
total_rewards                [4826.53730344 4670.58501924 4793.06726701 4708.82188529 4580.67974327
 4805.46318906 4921.04487718 4877.35102189 5010.58336924 4830.09819252]
total_rewards_mean           4802.423186812981
total_rewards_std            118.22553856256233
total_rewards_max            5010.583369238006
total_rewards_min            4580.679743266746
Number of train steps total  52000
Number of env steps total    67000
Number of rollouts total     0
Train Time (s)               129.57221927819774
(Previous) Eval Time (s)     27.273227415047586
Sample Time (s)              22.463956688065082
Epoch Time (s)               179.3094033813104
Total Train Time (s)         2309.2906246990897
Epoch                        12
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:26:12.907028 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #12 | Epoch Duration: 181.15891361236572
2020-01-13 05:26:12.907339 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #12 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0124767
Z variance train             0.028822288
KL Divergence                19.948526
KL Loss                      1.9948527
QF Loss                      300.45972
VF Loss                      75.663635
Policy Loss                  -1158.6844
Q Predictions Mean           1156.8402
Q Predictions Std            355.24152
Q Predictions Max            1595.5333
Q Predictions Min            237.08743
V Predictions Mean           1160.1675
V Predictions Std            352.96494
V Predictions Max            1600.5157
V Predictions Min            238.53593
Log Pis Mean                 2.0812213
Log Pis Std                  3.5720465
Log Pis Max                  10.83307
Log Pis Min                  -7.1530313
Policy mu Mean               -0.09093547
Policy mu Std                1.1156846
Policy mu Max                2.9271843
Policy mu Min                -2.662121
Policy log std Mean          -0.689069
Policy log std Std           0.28843305
Policy log std Max           0.067103595
Policy log std Min           -2.1973782
Z mean eval                  3.6567218
Z variance eval              0.49369374
total_rewards                [ -36.8091144  -156.1985081  -174.6814037  -128.81790582 -154.86527045
 -197.63797299 -127.66125361   89.27293924  158.03670667 -213.91174586]
total_rewards_mean           -94.3273529019358
total_rewards_std            119.13393505753616
total_rewards_max            158.03670666722545
total_rewards_min            -213.91174585927416
Number of train steps total  56000
Number of env steps total    72000
Number of rollouts total     0
Train Time (s)               130.1818589628674
(Previous) Eval Time (s)     29.122396487742662
Sample Time (s)              21.434017781168222
Epoch Time (s)               180.7382732317783
Total Train Time (s)         2490.0648383456282
Epoch                        13
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:29:13.682733 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #13 | Epoch Duration: 180.7751545906067
2020-01-13 05:29:13.683045 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #13 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6372764
Z variance train             0.4981719
KL Divergence                34.176537
KL Loss                      3.4176538
QF Loss                      126.903725
VF Loss                      39.71082
Policy Loss                  -126.471565
Q Predictions Mean           125.07967
Q Predictions Std            83.78963
Q Predictions Max            286.08456
Q Predictions Min            -5.269777
V Predictions Mean           126.79259
V Predictions Std            81.80393
V Predictions Max            284.20685
V Predictions Min            5.2241635
Log Pis Mean                 -1.0013871
Log Pis Std                  2.427872
Log Pis Max                  5.6562815
Log Pis Min                  -7.979854
Policy mu Mean               0.031507198
Policy mu Std                0.79861003
Policy mu Max                2.0504718
Policy mu Min                -2.1677756
Policy log std Mean          -0.42148766
Policy log std Std           0.14036319
Policy log std Max           -0.008866459
Policy log std Min           -0.95062184
Z mean eval                  3.3755288
Z variance eval              0.1052945
total_rewards                [3295.73236044 2180.79173795 1144.69896815 2952.72799889  796.64186604
  748.15212671 1644.70985189 3092.68897045 2419.83583234 1108.08118181]
total_rewards_mean           1938.406089466124
total_rewards_std            928.4436372484946
total_rewards_max            3295.7323604354574
total_rewards_min            748.1521267073686
Number of train steps total  60000
Number of env steps total    77000
Number of rollouts total     0
Train Time (s)               128.93980638682842
(Previous) Eval Time (s)     29.158937103115022
Sample Time (s)              22.863312010187656
Epoch Time (s)               180.9620555001311
Total Train Time (s)         2669.323775230907
Epoch                        14
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:32:12.942591 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #14 | Epoch Duration: 179.2593710422516
2020-01-13 05:32:12.942777 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #14 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3997025
Z variance train             0.102890216
KL Divergence                32.982258
KL Loss                      3.2982259
QF Loss                      307.0948
VF Loss                      86.77702
Policy Loss                  -315.21948
Q Predictions Mean           314.04953
Q Predictions Std            170.81084
Q Predictions Max            695.43976
Q Predictions Min            32.024178
V Predictions Mean           319.6922
V Predictions Std            167.2148
V Predictions Max            679.3502
V Predictions Min            42.6675
Log Pis Mean                 1.4561081
Log Pis Std                  3.2725234
Log Pis Max                  11.223267
Log Pis Min                  -7.195695
Policy mu Mean               -0.24651778
Policy mu Std                1.0413717
Policy mu Max                2.525249
Policy mu Min                -2.667503
Policy log std Mean          -0.5262465
Policy log std Std           0.23187946
Policy log std Max           -0.021392733
Policy log std Min           -1.9235295
Z mean eval                  3.1349173
Z variance eval              0.04281784
total_rewards                [4234.56314653 4264.00896932 4260.53749549 4385.13189164 4228.74799611
 4319.0442779  4369.6858946  4322.21367329 4302.15962112 4284.55897609]
total_rewards_mean           4297.0651942081295
total_rewards_std            50.327056756764094
total_rewards_max            4385.13189164424
total_rewards_min            4228.747996108382
Number of train steps total  64000
Number of env steps total    82000
Number of rollouts total     0
Train Time (s)               131.34337706072256
(Previous) Eval Time (s)     27.455909217707813
Sample Time (s)              21.889320896472782
Epoch Time (s)               180.68860717490315
Total Train Time (s)         2850.9766789362766
Epoch                        15
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:35:14.596884 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #15 | Epoch Duration: 181.65394949913025
2020-01-13 05:35:14.597115 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #15 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1758802
Z variance train             0.046649802
KL Divergence                31.605791
KL Loss                      3.1605792
QF Loss                      257.94617
VF Loss                      152.63263
Policy Loss                  -514.93146
Q Predictions Mean           513.5797
Q Predictions Std            237.39479
Q Predictions Max            913.9772
Q Predictions Min            76.94611
V Predictions Mean           520.4238
V Predictions Std            232.5832
V Predictions Max            907.5188
V Predictions Min            83.43394
Log Pis Mean                 2.2776074
Log Pis Std                  3.6150987
Log Pis Max                  10.84625
Log Pis Min                  -7.027669
Policy mu Mean               -0.078368105
Policy mu Std                1.1698179
Policy mu Max                3.0654695
Policy mu Min                -3.3193562
Policy log std Mean          -0.57341456
Policy log std Std           0.28467968
Policy log std Max           0.045040518
Policy log std Min           -2.0528831
Z mean eval                  3.3715692
Z variance eval              0.07636393
total_rewards                [5060.17853444 4900.46065305 5195.35539736 5141.54338901 4854.80626351
 4988.26022568 5019.56588247  806.61992041 5206.96528536 5013.65166856]
total_rewards_mean           4618.740721985028
total_rewards_std            1275.429370275107
total_rewards_max            5206.965285361491
total_rewards_min            806.6199204090998
Number of train steps total  68000
Number of env steps total    87000
Number of rollouts total     0
Train Time (s)               129.2152941408567
(Previous) Eval Time (s)     28.420892297755927
Sample Time (s)              22.666839251760393
Epoch Time (s)               180.30302569037303
Total Train Time (s)         3029.9026152384467
Epoch                        16
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:38:13.524586 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #16 | Epoch Duration: 178.9273064136505
2020-01-13 05:38:13.524849 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #16 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3687186
Z variance train             0.07645639
KL Divergence                33.66046
KL Loss                      3.3660462
QF Loss                      237.19162
VF Loss                      369.51147
Policy Loss                  -707.0577
Q Predictions Mean           703.8412
Q Predictions Std            274.73364
Q Predictions Max            1142.3159
Q Predictions Min            111.46911
V Predictions Mean           720.35065
V Predictions Std            272.94214
V Predictions Max            1137.61
V Predictions Min            117.03512
Log Pis Mean                 1.7108302
Log Pis Std                  3.4725194
Log Pis Max                  10.953691
Log Pis Min                  -6.251592
Policy mu Mean               -0.044311758
Policy mu Std                1.1341559
Policy mu Max                2.626416
Policy mu Min                -2.6953824
Policy log std Mean          -0.6024892
Policy log std Std           0.30754912
Policy log std Max           0.19851574
Policy log std Min           -2.1112213
Z mean eval                  3.6421828
Z variance eval              0.06564971
total_rewards                [5100.37908094 5426.29536096 5414.56345856 5334.96555087 5251.70967878
 5410.08125922 5302.84874723 5329.47500375 5202.39073643 5209.62421043]
total_rewards_mean           5298.2333087168245
total_rewards_std            101.5565236546283
total_rewards_max            5426.295360962948
total_rewards_min            5100.379080936579
Number of train steps total  72000
Number of env steps total    92000
Number of rollouts total     0
Train Time (s)               123.16809961525723
(Previous) Eval Time (s)     27.044835323933512
Sample Time (s)              22.352531130425632
Epoch Time (s)               172.56546606961638
Total Train Time (s)         3200.117924714461
Epoch                        17
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:41:03.740636 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #17 | Epoch Duration: 170.21561741828918
2020-01-13 05:41:03.740820 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #17 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6449714
Z variance train             0.06561594
KL Divergence                39.27327
KL Loss                      3.927327
QF Loss                      363.82822
VF Loss                      160.76335
Policy Loss                  -995.2493
Q Predictions Mean           993.6718
Q Predictions Std            292.72653
Q Predictions Max            1423.2843
Q Predictions Min            161.0471
V Predictions Mean           987.3785
V Predictions Std            285.86142
V Predictions Max            1393.9546
V Predictions Min            159.66449
Log Pis Mean                 1.8569582
Log Pis Std                  3.3206835
Log Pis Max                  11.496464
Log Pis Min                  -6.363332
Policy mu Mean               -0.11534414
Policy mu Std                1.0850831
Policy mu Max                2.6259472
Policy mu Min                -2.533559
Policy log std Mean          -0.6613539
Policy log std Std           0.32039866
Policy log std Max           0.16139877
Policy log std Min           -2.2334356
Z mean eval                  3.7705321
Z variance eval              0.07586223
total_rewards                [5804.5543989  5677.39840781 5740.51428601 5729.73457723 5728.1389424
 5805.91113306 5675.50516567 5831.91568631 5775.27409792 5769.91253117]
total_rewards_mean           5753.885922648181
total_rewards_std            50.49331181306233
total_rewards_max            5831.91568631039
total_rewards_min            5675.505165665409
Number of train steps total  76000
Number of env steps total    97000
Number of rollouts total     0
Train Time (s)               123.52586705423892
(Previous) Eval Time (s)     24.694634588900954
Sample Time (s)              21.79766699159518
Epoch Time (s)               170.01816863473505
Total Train Time (s)         3373.6552481832914
Epoch                        18
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:43:57.280102 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #18 | Epoch Duration: 173.53914546966553
2020-01-13 05:43:57.280290 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #18 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7682464
Z variance train             0.075497925
KL Divergence                41.249226
KL Loss                      4.1249228
QF Loss                      300.16595
VF Loss                      136.98318
Policy Loss                  -1150.2463
Q Predictions Mean           1142.3959
Q Predictions Std            338.14542
Q Predictions Max            1605.4017
Q Predictions Min            188.82161
V Predictions Mean           1155.4961
V Predictions Std            335.60846
V Predictions Max            1599.3436
V Predictions Min            186.57741
Log Pis Mean                 2.4569607
Log Pis Std                  3.4554188
Log Pis Max                  11.9238205
Log Pis Min                  -5.389331
Policy mu Mean               -0.071816504
Policy mu Std                1.1479833
Policy mu Max                2.898211
Policy mu Min                -3.1957533
Policy log std Mean          -0.6823408
Policy log std Std           0.32499877
Policy log std Max           0.012519717
Policy log std Min           -2.4453304
Z mean eval                  3.1633363
Z variance eval              0.04837089
total_rewards                [5900.72564731 5680.03199623 5735.05006899 5739.75548267 5544.28907136
 4424.9149741  5558.81733279 2579.11898236 5798.69777445 5919.16863554]
total_rewards_mean           5288.056996580424
total_rewards_std            990.6675961979083
total_rewards_max            5919.16863553579
total_rewards_min            2579.1189823609384
Number of train steps total  80000
Number of env steps total    102000
Number of rollouts total     0
Train Time (s)               129.22394039388746
(Previous) Eval Time (s)     28.215255594812334
Sample Time (s)              22.336782671511173
Epoch Time (s)               179.77597866021097
Total Train Time (s)         3552.1223400854506
Epoch                        19
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:46:55.747397 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #19 | Epoch Duration: 178.46697330474854
2020-01-13 05:46:55.747574 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #19 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1631436
Z variance train             0.048215784
KL Divergence                30.778343
KL Loss                      3.0778344
QF Loss                      319.99094
VF Loss                      123.188354
Policy Loss                  -1183.7705
Q Predictions Mean           1179.4932
Q Predictions Std            367.69342
Q Predictions Max            1649.735
Q Predictions Min            140.87694
V Predictions Mean           1182.5483
V Predictions Std            362.66364
V Predictions Max            1645.4651
V Predictions Min            140.99182
Log Pis Mean                 2.6175241
Log Pis Std                  3.6392217
Log Pis Max                  14.787273
Log Pis Min                  -6.9086266
Policy mu Mean               -0.07920305
Policy mu Std                1.20897
Policy mu Max                2.7068806
Policy mu Min                -2.7520669
Policy log std Mean          -0.66368383
Policy log std Std           0.31987143
Policy log std Max           0.059047997
Policy log std Min           -2.5051956
Z mean eval                  3.3186173
Z variance eval              0.036925163
total_rewards                [6134.95951347 5943.31704412 5901.98211124 2865.08261409 6060.52561289
 5912.80791059 6297.59360798 5961.1806568  5886.05327594 6102.51571282]
total_rewards_mean           5706.601805992893
total_rewards_std            955.1305974972731
total_rewards_max            6297.593607980664
total_rewards_min            2865.0826140942327
Number of train steps total  84000
Number of env steps total    107000
Number of rollouts total     0
Train Time (s)               130.8296263399534
(Previous) Eval Time (s)     26.905895155854523
Sample Time (s)              23.317497067153454
Epoch Time (s)               181.05301856296137
Total Train Time (s)         3735.1258157845587
Epoch                        20
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:49:58.751738 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #20 | Epoch Duration: 183.0040476322174
2020-01-13 05:49:58.751860 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #20 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3154252
Z variance train             0.03694842
KL Divergence                33.74419
KL Loss                      3.374419
QF Loss                      305.75467
VF Loss                      272.01028
Policy Loss                  -1361.9922
Q Predictions Mean           1365.5519
Q Predictions Std            408.49115
Q Predictions Max            1918.805
Q Predictions Min            184.03975
V Predictions Mean           1373.8362
V Predictions Std            404.64392
V Predictions Max            1918.8484
V Predictions Min            193.62068
Log Pis Mean                 2.5569022
Log Pis Std                  3.5145495
Log Pis Max                  11.4427185
Log Pis Min                  -7.5079527
Policy mu Mean               -0.15488313
Policy mu Std                1.1716411
Policy mu Max                2.7621584
Policy mu Min                -3.3829222
Policy log std Mean          -0.6833522
Policy log std Std           0.31158516
Policy log std Max           -0.0071877837
Policy log std Min           -2.4105546
Z mean eval                  3.014462
Z variance eval              0.015547341
total_rewards                [6215.96184663 6009.27284372 6039.24191201 6383.7608607  6162.07084103
 6449.81955384 6205.79210816 6302.5590537  6111.97093298 6249.61023152]
total_rewards_mean           6213.006018428192
total_rewards_std            133.8513767658066
total_rewards_max            6449.819553837399
total_rewards_min            6009.2728437196165
Number of train steps total  88000
Number of env steps total    112000
Number of rollouts total     0
Train Time (s)               129.4730632849969
(Previous) Eval Time (s)     28.85653845826164
Sample Time (s)              22.905380211304873
Epoch Time (s)               181.2349819545634
Total Train Time (s)         3915.6751098893583
Epoch                        21
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:52:59.302881 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #21 | Epoch Duration: 180.55091547966003
2020-01-13 05:52:59.303078 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #21 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0140688
Z variance train             0.015512285
KL Divergence                31.418806
KL Loss                      3.1418808
QF Loss                      441.72858
VF Loss                      130.98154
Policy Loss                  -1398.5823
Q Predictions Mean           1387.2682
Q Predictions Std            447.0148
Q Predictions Max            1937.486
Q Predictions Min            141.20197
V Predictions Mean           1398.7803
V Predictions Std            439.5104
V Predictions Max            1944.1055
V Predictions Min            169.8765
Log Pis Mean                 2.8534946
Log Pis Std                  3.7383325
Log Pis Max                  14.879341
Log Pis Min                  -7.782638
Policy mu Mean               -0.20583676
Policy mu Std                1.200687
Policy mu Max                2.8253536
Policy mu Min                -3.233415
Policy log std Mean          -0.6688176
Policy log std Std           0.32994142
Policy log std Max           -0.013836741
Policy log std Min           -2.481128
Z mean eval                  3.191815
Z variance eval              0.022232845
total_rewards                [6199.72661119 6444.25730971 6392.39381991 6379.86881536 6087.57578696
 6257.83963798 6191.44067251 6302.61832722 6445.36946509 6089.82633546]
total_rewards_mean           6279.091678138143
total_rewards_std            128.61095077236965
total_rewards_max            6445.369465094959
total_rewards_min            6087.575786955633
Number of train steps total  92000
Number of env steps total    117000
Number of rollouts total     0
Train Time (s)               131.9691874613054
(Previous) Eval Time (s)     28.172040863893926
Sample Time (s)              22.722415299154818
Epoch Time (s)               182.86364362435415
Total Train Time (s)         4098.744801192079
Epoch                        22
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:56:02.374064 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #22 | Epoch Duration: 183.07084488868713
2020-01-13 05:56:02.374255 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #22 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1919568
Z variance train             0.022225413
KL Divergence                34.592155
KL Loss                      3.4592156
QF Loss                      488.9791
VF Loss                      126.824455
Policy Loss                  -1581.8475
Q Predictions Mean           1582.3805
Q Predictions Std            460.6288
Q Predictions Max            2130.2314
Q Predictions Min            157.48376
V Predictions Mean           1584.9608
V Predictions Std            454.4133
V Predictions Max            2112.9177
V Predictions Min            202.4124
Log Pis Mean                 2.9491231
Log Pis Std                  3.6250567
Log Pis Max                  16.33096
Log Pis Min                  -7.3068986
Policy mu Mean               -0.16622105
Policy mu Std                1.2103369
Policy mu Max                3.1126993
Policy mu Min                -2.9261339
Policy log std Mean          -0.6901393
Policy log std Std           0.31965294
Policy log std Max           0.046164215
Policy log std Min           -2.4398572
Z mean eval                  3.0484207
Z variance eval              0.005374048
total_rewards                [6285.28100117 6448.44017453 6460.18274573 6531.74776013 6423.82712875
 6340.75804291 6300.91029289 6325.68889468 6403.57601156 6413.08522562]
total_rewards_mean           6393.349727797934
total_rewards_std            74.5964718613045
total_rewards_max            6531.747760128963
total_rewards_min            6285.281001172277
Number of train steps total  96000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               130.93837029207498
(Previous) Eval Time (s)     28.378850155044347
Sample Time (s)              22.857169268652797
Epoch Time (s)               182.17438971577212
Total Train Time (s)         4280.332204652019
Epoch                        23
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:59:03.962929 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #23 | Epoch Duration: 181.58852195739746
2020-01-13 05:59:03.963228 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #23 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0520778
Z variance train             0.0053817253
KL Divergence                35.592052
KL Loss                      3.5592053
QF Loss                      237.66092
VF Loss                      549.8726
Policy Loss                  -1674.9352
Q Predictions Mean           1663.0486
Q Predictions Std            461.66718
Q Predictions Max            2198.0571
Q Predictions Min            177.30984
V Predictions Mean           1655.0222
V Predictions Std            454.30902
V Predictions Max            2179.1755
V Predictions Min            183.76224
Log Pis Mean                 2.7996504
Log Pis Std                  3.4347994
Log Pis Max                  12.336286
Log Pis Min                  -5.319101
Policy mu Mean               -0.121140935
Policy mu Std                1.1818665
Policy mu Max                2.9963696
Policy mu Min                -2.5996115
Policy log std Mean          -0.7100165
Policy log std Std           0.35074544
Policy log std Max           0.07099396
Policy log std Min           -2.466443
Z mean eval                  2.9871888
Z variance eval              0.012042919
total_rewards                [1594.42680131 6417.9397775  6568.55467735 6604.43979352 6543.88342012
 6515.1274927  6470.28228793 6560.58037607 6536.13591469 6494.69219029]
total_rewards_mean           6030.606273148825
total_rewards_std            1479.5853030887333
total_rewards_max            6604.439793520932
total_rewards_min            1594.4268013091976
Number of train steps total  100000
Number of env steps total    127000
Number of rollouts total     0
Train Time (s)               123.67821048386395
(Previous) Eval Time (s)     27.79266486596316
Sample Time (s)              21.284809654578567
Epoch Time (s)               172.75568500440568
Total Train Time (s)         4452.0807642238215
Epoch                        24
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:01:55.712884 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #24 | Epoch Duration: 171.74947834014893
2020-01-13 06:01:55.713134 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #24 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.9814115
Z variance train             0.01214691
KL Divergence                33.56402
KL Loss                      3.356402
QF Loss                      414.94223
VF Loss                      156.36028
Policy Loss                  -1708.2306
Q Predictions Mean           1695.4175
Q Predictions Std            510.81042
Q Predictions Max            2268.0173
Q Predictions Min            132.98538
V Predictions Mean           1710.2576
V Predictions Std            507.53253
V Predictions Max            2283.7993
V Predictions Min            114.58119
Log Pis Mean                 3.1766524
Log Pis Std                  3.7197855
Log Pis Max                  14.154161
Log Pis Min                  -5.966485
Policy mu Mean               -0.19161926
Policy mu Std                1.208029
Policy mu Max                2.7934895
Policy mu Min                -2.9292579
Policy log std Mean          -0.6942255
Policy log std Std           0.34347638
Policy log std Max           0.12611717
Policy log std Min           -2.491851
Z mean eval                  9.477341
Z variance eval              0.002764418
total_rewards                [6306.62993922 6660.55980334 6501.94735716 6586.42007741 6579.02267331
 6502.22277983 6634.27119599 6585.31519917 6587.05770547 5801.11891017]
total_rewards_mean           6474.456564107585
total_rewards_std            243.24673983422852
total_rewards_max            6660.559803344428
total_rewards_min            5801.118910170033
Number of train steps total  104000
Number of env steps total    132000
Number of rollouts total     0
Train Time (s)               123.96559700090438
(Previous) Eval Time (s)     26.786147165112197
Sample Time (s)              20.660265852697194
Epoch Time (s)               171.41201001871377
Total Train Time (s)         4623.670172691811
Epoch                        25
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:04:47.303335 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #25 | Epoch Duration: 171.59004092216492
2020-01-13 06:04:47.303514 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #25 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2101562
Z variance train             0.013140964
KL Divergence                36.363773
KL Loss                      3.6363773
QF Loss                      8564.728
VF Loss                      4372.785
Policy Loss                  -1904.6907
Q Predictions Mean           1865.479
Q Predictions Std            532.69855
Q Predictions Max            2463.7375
Q Predictions Min            177.88124
V Predictions Mean           1843.4552
V Predictions Std            512.55035
V Predictions Max            2418.921
V Predictions Min            209.83717
Log Pis Mean                 3.3248105
Log Pis Std                  3.8009684
Log Pis Max                  14.595114
Log Pis Min                  -8.16495
Policy mu Mean               -0.1663709
Policy mu Std                1.2217265
Policy mu Max                2.891216
Policy mu Min                -2.8842776
Policy log std Mean          -0.71254236
Policy log std Std           0.352639
Policy log std Max           0.028416514
Policy log std Min           -2.4217834
Z mean eval                  3.363985
Z variance eval              0.00442891
total_rewards                [6697.67107497 6665.57472359 6611.69822326 6752.29447785 6626.67684108
 6776.37790482 6921.27372518 6767.35397044 6839.03303231 6835.24044818]
total_rewards_mean           6749.319442169623
total_rewards_std            94.72434620816757
total_rewards_max            6921.2737251814415
total_rewards_min            6611.698223257581
Number of train steps total  108000
Number of env steps total    137000
Number of rollouts total     0
Train Time (s)               128.87589364731684
(Previous) Eval Time (s)     26.963851255830377
Sample Time (s)              21.942118760198355
Epoch Time (s)               177.78186366334558
Total Train Time (s)         4803.0697855656035
Epoch                        26
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:07:46.704190 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #26 | Epoch Duration: 179.40053987503052
2020-01-13 06:07:46.704367 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #26 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.364259
Z variance train             0.0044291676
KL Divergence                40.76333
KL Loss                      4.076333
QF Loss                      324.02594
VF Loss                      134.93645
Policy Loss                  -2020.1102
Q Predictions Mean           2018.3379
Q Predictions Std            554.0734
Q Predictions Max            2623.944
Q Predictions Min            274.7603
V Predictions Mean           2020.5652
V Predictions Std            552.72217
V Predictions Max            2625.1394
V Predictions Min            267.43265
Log Pis Mean                 3.6147532
Log Pis Std                  4.1372495
Log Pis Max                  15.715808
Log Pis Min                  -5.683863
Policy mu Mean               -0.17974214
Policy mu Std                1.2549546
Policy mu Max                2.970281
Policy mu Min                -3.0822823
Policy log std Mean          -0.7199883
Policy log std Std           0.35645357
Policy log std Max           0.0359928
Policy log std Min           -2.6361003
Z mean eval                  3.356264
Z variance eval              0.0022607388
total_rewards                [6416.79489534 6372.5523814  6405.74086524 6492.62109844 6448.65998807
 6468.97455898 6523.98373537 6540.10499206 6328.97775426 6419.70765679]
total_rewards_mean           6441.811792595114
total_rewards_std            63.026991420651754
total_rewards_max            6540.104992064311
total_rewards_min            6328.977754256333
Number of train steps total  112000
Number of env steps total    142000
Number of rollouts total     0
Train Time (s)               130.24461879162118
(Previous) Eval Time (s)     28.58218658901751
Sample Time (s)              21.65817698603496
Epoch Time (s)               180.48498236667365
Total Train Time (s)         4983.560703010298
Epoch                        27
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:10:47.196576 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #27 | Epoch Duration: 180.49207091331482
2020-01-13 06:10:47.196775 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #27 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3540566
Z variance train             0.002264163
KL Divergence                42.00614
KL Loss                      4.2006145
QF Loss                      449.69196
VF Loss                      127.19615
Policy Loss                  -2106.7776
Q Predictions Mean           2097.3752
Q Predictions Std            508.61044
Q Predictions Max            2660.1777
Q Predictions Min            255.56567
V Predictions Mean           2107.7368
V Predictions Std            503.51538
V Predictions Max            2643.1108
V Predictions Min            263.97794
Log Pis Mean                 3.054508
Log Pis Std                  3.7534738
Log Pis Max                  19.287638
Log Pis Min                  -6.237936
Policy mu Mean               -0.12243194
Policy mu Std                1.2241416
Policy mu Max                3.3089013
Policy mu Min                -2.9619744
Policy log std Mean          -0.7442003
Policy log std Std           0.35709494
Policy log std Max           0.031048
Policy log std Min           -2.6519399
Z mean eval                  3.3839574
Z variance eval              0.0018778114
total_rewards                [6921.73107686 7040.73250632 6868.88238975 6901.54474338 6816.96750326
 7058.40852783 6730.48924246 6843.82644776 7052.387959   7137.74885931]
total_rewards_mean           6937.271925594064
total_rewards_std            122.87401588977333
total_rewards_max            7137.748859310405
total_rewards_min            6730.489242464658
Number of train steps total  116000
Number of env steps total    147000
Number of rollouts total     0
Train Time (s)               130.59882841305807
(Previous) Eval Time (s)     28.588906107936054
Sample Time (s)              22.64557435316965
Epoch Time (s)               181.83330887416378
Total Train Time (s)         5163.869703121018
Epoch                        28
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:13:47.507353 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #28 | Epoch Duration: 180.31040501594543
2020-01-13 06:13:47.507719 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #28 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3848312
Z variance train             0.0018795282
KL Divergence                43.644745
KL Loss                      4.364475
QF Loss                      360.82114
VF Loss                      178.77127
Policy Loss                  -2152.8962
Q Predictions Mean           2150.8745
Q Predictions Std            535.33636
Q Predictions Max            2753.7183
Q Predictions Min            239.64326
V Predictions Mean           2158.2087
V Predictions Std            531.1472
V Predictions Max            2724.2712
V Predictions Min            250.45001
Log Pis Mean                 3.555103
Log Pis Std                  3.891474
Log Pis Max                  12.9723835
Log Pis Min                  -6.598531
Policy mu Mean               -0.18763006
Policy mu Std                1.264201
Policy mu Max                2.8253288
Policy mu Min                -2.9070144
Policy log std Mean          -0.7354279
Policy log std Std           0.37099883
Policy log std Max           0.088061154
Policy log std Min           -2.5716176
Z mean eval                  3.368135
Z variance eval              0.01702785
total_rewards                [6920.44113527 7066.86259714 6897.65810578 7022.18359356 6854.99637406
 7027.72569622 6900.64631461 7078.46042743 7221.07026113 7128.98953236]
total_rewards_mean           7011.903403756875
total_rewards_std            111.21223126679905
total_rewards_max            7221.070261131195
total_rewards_min            6854.996374064471
Number of train steps total  120000
Number of env steps total    152000
Number of rollouts total     0
Train Time (s)               131.88447309238836
(Previous) Eval Time (s)     27.065633257851005
Sample Time (s)              22.365810960531235
Epoch Time (s)               181.3159173107706
Total Train Time (s)         5346.034134052694
Epoch                        29
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:16:49.672857 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #29 | Epoch Duration: 182.16489100456238
2020-01-13 06:16:49.673046 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #29 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3679378
Z variance train             0.01704571
KL Divergence                40.32138
KL Loss                      4.0321383
QF Loss                      313.42676
VF Loss                      142.77972
Policy Loss                  -2158.2234
Q Predictions Mean           2154.0327
Q Predictions Std            535.416
Q Predictions Max            2745.9343
Q Predictions Min            221.1774
V Predictions Mean           2160.1472
V Predictions Std            526.2562
V Predictions Max            2721.8105
V Predictions Min            236.2797
Log Pis Mean                 3.5804894
Log Pis Std                  3.7363822
Log Pis Max                  16.892467
Log Pis Min                  -5.189193
Policy mu Mean               -0.17499824
Policy mu Std                1.253051
Policy mu Max                2.8261294
Policy mu Min                -2.754617
Policy log std Mean          -0.73798424
Policy log std Std           0.35006654
Policy log std Max           -0.06612271
Policy log std Min           -2.7007744
Z mean eval                  3.368475
Z variance eval              0.021518553
total_rewards                [7163.8042281  7056.53720762 7159.85593267 7194.66096308 7102.25325951
 7082.15223487 7121.75020434 7033.68951604 7010.36461299 7269.90113668]
total_rewards_mean           7119.496929589644
total_rewards_std            75.36364656601455
total_rewards_max            7269.901136679905
total_rewards_min            7010.364612986954
Number of train steps total  124000
Number of env steps total    157000
Number of rollouts total     0
Train Time (s)               130.60673607327044
(Previous) Eval Time (s)     27.91426402889192
Sample Time (s)              22.62748222472146
Epoch Time (s)               181.14848232688382
Total Train Time (s)         5526.663192850538
Epoch                        30
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:19:50.303132 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #30 | Epoch Duration: 180.6299479007721
2020-01-13 06:19:50.303382 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #30 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.369891
Z variance train             0.021530043
KL Divergence                38.198654
KL Loss                      3.8198655
QF Loss                      263.0645
VF Loss                      295.64322
Policy Loss                  -2162.6565
Q Predictions Mean           2154.368
Q Predictions Std            562.03955
Q Predictions Max            2727.499
Q Predictions Min            217.64743
V Predictions Mean           2149.3108
V Predictions Std            558.32587
V Predictions Max            2718.0288
V Predictions Min            209.06416
Log Pis Mean                 3.3862288
Log Pis Std                  3.620476
Log Pis Max                  13.890592
Log Pis Min                  -5.745482
Policy mu Mean               -0.10334504
Policy mu Std                1.2282255
Policy mu Max                2.908636
Policy mu Min                -3.664404
Policy log std Mean          -0.73917836
Policy log std Std           0.38054654
Policy log std Max           -0.0107058585
Policy log std Min           -2.775342
Z mean eval                  3.392859
Z variance eval              0.023717308
total_rewards                [7076.0030021  6946.92322854 6803.33423468 6734.21322237 6830.48559058
 7199.43087604 7265.80388501 1051.86046697 6901.04815702 2721.26764457]
total_rewards_mean           5953.037030788399
total_rewards_std            2073.48654447131
total_rewards_max            7265.803885005732
total_rewards_min            1051.860466968329
Number of train steps total  128000
Number of env steps total    162000
Number of rollouts total     0
Train Time (s)               124.3733270871453
(Previous) Eval Time (s)     27.395411149132997
Sample Time (s)              21.152085807174444
Epoch Time (s)               172.92082404345274
Total Train Time (s)         5699.098671669606
Epoch                        31
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:22:42.740147 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #31 | Epoch Duration: 172.43662405014038
2020-01-13 06:22:42.740339 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #31 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3926091
Z variance train             0.023670942
KL Divergence                38.39347
KL Loss                      3.8393471
QF Loss                      384.14142
VF Loss                      127.45589
Policy Loss                  -2327.983
Q Predictions Mean           2319.4482
Q Predictions Std            542.7313
Q Predictions Max            2944.1096
Q Predictions Min            225.09384
V Predictions Mean           2322.6406
V Predictions Std            537.61487
V Predictions Max            2938.5366
V Predictions Min            236.86671
Log Pis Mean                 3.5351095
Log Pis Std                  4.29892
Log Pis Max                  20.472887
Log Pis Min                  -9.235671
Policy mu Mean               -0.16896981
Policy mu Std                1.2432203
Policy mu Max                3.3368623
Policy mu Min                -3.007094
Policy log std Mean          -0.74196553
Policy log std Std           0.36051998
Policy log std Max           0.0043044686
Policy log std Min           -2.6688557
Z mean eval                  3.415507
Z variance eval              0.006382107
total_rewards                [7391.39757778 7391.11496515 7584.22095997 7366.41607186 7508.39413887
 7226.20245224 7245.20584877 7369.73124807 7596.850535   7662.05897335]
total_rewards_mean           7434.159277104578
total_rewards_std            140.6438650998211
total_rewards_max            7662.058973352278
total_rewards_min            7226.202452235691
Number of train steps total  132000
Number of env steps total    167000
Number of rollouts total     0
Train Time (s)               124.21886191377416
(Previous) Eval Time (s)     26.910898922011256
Sample Time (s)              22.150590432807803
Epoch Time (s)               173.28035126859322
Total Train Time (s)         5871.903611478861
Epoch                        32
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:25:35.545185 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #32 | Epoch Duration: 172.80472469329834
2020-01-13 06:25:35.545306 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #32 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.415795
Z variance train             0.00637673
KL Divergence                41.399868
KL Loss                      4.139987
QF Loss                      343.3113
VF Loss                      121.057175
Policy Loss                  -2391.5566
Q Predictions Mean           2391.8481
Q Predictions Std            561.4024
Q Predictions Max            2961.9128
Q Predictions Min            230.6759
V Predictions Mean           2389.1333
V Predictions Std            553.5094
V Predictions Max            2925.8203
V Predictions Min            242.88972
Log Pis Mean                 3.9520717
Log Pis Std                  3.7068655
Log Pis Max                  11.90935
Log Pis Min                  -5.810215
Policy mu Mean               -0.16803765
Policy mu Std                1.2945057
Policy mu Max                2.9174583
Policy mu Min                -2.7500472
Policy log std Mean          -0.7534251
Policy log std Std           0.36012858
Policy log std Max           -0.029353082
Policy log std Min           -2.8747842
Z mean eval                  3.3946183
Z variance eval              0.015025425
total_rewards                [4772.92320262 7066.79274801 6799.97276844 6975.5475733  6967.72121032
 6764.83662654 6988.16189612 6911.46571808 6808.60985494 6840.71252176]
total_rewards_mean           6689.674412013311
total_rewards_std            645.619572360354
total_rewards_max            7066.792748014703
total_rewards_min            4772.923202624776
Number of train steps total  136000
Number of env steps total    172000
Number of rollouts total     0
Train Time (s)               127.82706660265103
(Previous) Eval Time (s)     26.43495371611789
Sample Time (s)              21.531948121264577
Epoch Time (s)               175.7939684400335
Total Train Time (s)         6049.802428117488
Epoch                        33
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:28:33.446462 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #33 | Epoch Duration: 177.90104126930237
2020-01-13 06:28:33.446651 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #33 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3958008
Z variance train             0.014995404
KL Divergence                39.124454
KL Loss                      3.9124455
QF Loss                      278.10175
VF Loss                      275.4385
Policy Loss                  -2406.154
Q Predictions Mean           2404.661
Q Predictions Std            517.94354
Q Predictions Max            2963.874
Q Predictions Min            227.84941
V Predictions Mean           2407.6348
V Predictions Std            507.6895
V Predictions Max            2960.4585
V Predictions Min            212.2672
Log Pis Mean                 3.6348429
Log Pis Std                  3.3478744
Log Pis Max                  14.952033
Log Pis Min                  -4.0045137
Policy mu Mean               -0.15339136
Policy mu Std                1.2603524
Policy mu Max                3.081188
Policy mu Min                -3.1712935
Policy log std Mean          -0.74263173
Policy log std Std           0.36738974
Policy log std Max           0.032737613
Policy log std Min           -2.8910902
Z mean eval                  3.410253
Z variance eval              0.017239574
total_rewards                [7364.78578203 7680.06804702 7542.42246319 7613.85510542 7468.79627806
 7695.7554621  7574.99713862 7585.1682485  7531.1072544  7618.73743178]
total_rewards_mean           7567.569321112298
total_rewards_std            93.3017784919783
total_rewards_max            7695.75546210005
total_rewards_min            7364.785782030168
Number of train steps total  140000
Number of env steps total    177000
Number of rollouts total     0
Train Time (s)               131.33876786893234
(Previous) Eval Time (s)     28.54165337001905
Sample Time (s)              22.60622285399586
Epoch Time (s)               182.48664409294724
Total Train Time (s)         6232.187437824439
Epoch                        34
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:31:35.833035 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #34 | Epoch Duration: 182.38624382019043
2020-01-13 06:31:35.833238 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #34 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.410155
Z variance train             0.01722094
KL Divergence                39.911186
KL Loss                      3.9911187
QF Loss                      505.76843
VF Loss                      167.14012
Policy Loss                  -2395.6917
Q Predictions Mean           2398.0562
Q Predictions Std            546.89514
Q Predictions Max            2985.2983
Q Predictions Min            199.58653
V Predictions Mean           2400.9512
V Predictions Std            545.8722
V Predictions Max            2963.514
V Predictions Min            186.07184
Log Pis Mean                 3.7800748
Log Pis Std                  3.8016832
Log Pis Max                  14.067865
Log Pis Min                  -8.1299305
Policy mu Mean               -0.16407019
Policy mu Std                1.264267
Policy mu Max                3.5213206
Policy mu Min                -3.9881349
Policy log std Mean          -0.7676994
Policy log std Std           0.38152665
Policy log std Max           0.1456837
Policy log std Min           -2.7185261
Z mean eval                  3.418686
Z variance eval              0.004933527
total_rewards                [7357.44014433 7531.16507138 7661.02347492 7708.65023159 7592.85100747
 7730.66508159 7406.34914696 7429.18571631 7505.47912845 7768.88225712]
total_rewards_mean           7569.16912601049
total_rewards_std            138.15024297969043
total_rewards_max            7768.882257118361
total_rewards_min            7357.4401443304505
Number of train steps total  144000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               130.86598667968065
(Previous) Eval Time (s)     28.440871933009475
Sample Time (s)              22.931124384514987
Epoch Time (s)               182.2379829972051
Total Train Time (s)         6411.745204178616
Epoch                        35
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:34:35.392643 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #35 | Epoch Duration: 179.55925750732422
2020-01-13 06:34:35.392843 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #35 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.4185174
Z variance train             0.004946901
KL Divergence                41.80832
KL Loss                      4.180832
QF Loss                      384.024
VF Loss                      167.93312
Policy Loss                  -2388.0576
Q Predictions Mean           2392.252
Q Predictions Std            605.82153
Q Predictions Max            3010.9783
Q Predictions Min            203.85043
V Predictions Mean           2393.4004
V Predictions Std            602.55493
V Predictions Max            2995.9248
V Predictions Min            202.51698
Log Pis Mean                 4.0495825
Log Pis Std                  4.015967
Log Pis Max                  14.71815
Log Pis Min                  -5.208635
Policy mu Mean               -0.21080653
Policy mu Std                1.2606459
Policy mu Max                2.9202344
Policy mu Min                -2.8052158
Policy log std Mean          -0.76762843
Policy log std Std           0.38451442
Policy log std Max           -0.06486833
Policy log std Min           -2.8510044
Z mean eval                  3.3967462
Z variance eval              0.009118256
total_rewards                [7325.98793747 7710.24803546 7390.92139749 7461.44166392 7630.91357368
 7286.01879593 7426.81495377 7374.0746163  7383.56259071 7418.17745104]
total_rewards_mean           7440.816101576378
total_rewards_std            125.39304419423871
total_rewards_max            7710.2480354593
total_rewards_min            7286.018795926657
Number of train steps total  148000
Number of env steps total    187000
Number of rollouts total     0
Train Time (s)               131.52333965478465
(Previous) Eval Time (s)     25.761528888717294
Sample Time (s)              21.12066461984068
Epoch Time (s)               178.40553316334262
Total Train Time (s)         6593.68142091576
Epoch                        36
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:37:37.330271 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #36 | Epoch Duration: 181.93728160858154
2020-01-13 06:37:37.330472 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #36 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3985229
Z variance train             0.00911618
KL Divergence                40.174393
KL Loss                      4.0174394
QF Loss                      303.7586
VF Loss                      358.1023
Policy Loss                  -2458.1055
Q Predictions Mean           2454.3914
Q Predictions Std            559.61475
Q Predictions Max            3020.643
Q Predictions Min            213.38478
V Predictions Mean           2441.8145
V Predictions Std            554.6061
V Predictions Max            2988.5947
V Predictions Min            196.81848
Log Pis Mean                 3.886384
Log Pis Std                  3.412249
Log Pis Max                  14.009374
Log Pis Min                  -6.8719893
Policy mu Mean               -0.19674887
Policy mu Std                1.2505951
Policy mu Max                2.9575226
Policy mu Min                -3.1030357
Policy log std Mean          -0.7693289
Policy log std Std           0.38266784
Policy log std Max           0.029661119
Policy log std Min           -2.8090234
Z mean eval                  3.3917117
Z variance eval              0.0059808707
total_rewards                [7743.72059154 7900.54613814 7796.02597706 7570.63560244 7780.3673192
 7464.42584969 7733.82255555 7618.28797302 7598.81193103 7826.09923954]
total_rewards_mean           7703.27431772023
total_rewards_std            128.021138149459
total_rewards_max            7900.546138141448
total_rewards_min            7464.4258496868215
Number of train steps total  152000
Number of env steps total    192000
Number of rollouts total     0
Train Time (s)               130.36791248898953
(Previous) Eval Time (s)     29.292922229971737
Sample Time (s)              22.704581846948713
Epoch Time (s)               182.36541656590998
Total Train Time (s)         6775.943894474767
Epoch                        37
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:40:39.594003 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #37 | Epoch Duration: 182.26338911056519
2020-01-13 06:40:39.594186 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #37 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.391723
Z variance train             0.0059894114
KL Divergence                39.69423
KL Loss                      3.969423
QF Loss                      314.1435
VF Loss                      117.77113
Policy Loss                  -2411.3508
Q Predictions Mean           2413.044
Q Predictions Std            638.0413
Q Predictions Max            3141.971
Q Predictions Min            200.99226
V Predictions Mean           2412.7578
V Predictions Std            634.0952
V Predictions Max            3121.505
V Predictions Min            189.0161
Log Pis Mean                 3.5530791
Log Pis Std                  3.9879923
Log Pis Max                  18.64146
Log Pis Min                  -5.52571
Policy mu Mean               -0.15933558
Policy mu Std                1.2628475
Policy mu Max                3.1929355
Policy mu Min                -3.613269
Policy log std Mean          -0.7486895
Policy log std Std           0.3834308
Policy log std Max           0.07609749
Policy log std Min           -2.8316727
Z mean eval                  7.8169646
Z variance eval              0.0007744687
total_rewards                [4446.17939381 5027.98079373 4766.06583762 4459.24040771 4721.62308153
 2651.48531155 4937.10508287 4631.30974823 4749.87281979 5011.0660355 ]
total_rewards_mean           4540.192851234188
total_rewards_std            658.4838239067251
total_rewards_max            5027.980793731976
total_rewards_min            2651.485311545611
Number of train steps total  156000
Number of env steps total    197000
Number of rollouts total     0
Train Time (s)               124.34976431494579
(Previous) Eval Time (s)     29.19048273609951
Sample Time (s)              22.49545202497393
Epoch Time (s)               176.03569907601923
Total Train Time (s)         6950.346490285825
Epoch                        38
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:43:33.997997 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #38 | Epoch Duration: 174.40367722511292
2020-01-13 06:43:33.998176 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #38 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.356248
Z variance train             0.0014850373
KL Divergence                61.565628
KL Loss                      6.156563
QF Loss                      1007.4302
VF Loss                      822.5626
Policy Loss                  -2887.7136
Q Predictions Mean           2880.8662
Q Predictions Std            730.55
Q Predictions Max            3616.023
Q Predictions Min            415.80075
V Predictions Mean           2893.511
V Predictions Std            724.7676
V Predictions Max            3598.0002
V Predictions Min            356.52258
Log Pis Mean                 6.5633764
Log Pis Std                  3.5425432
Log Pis Max                  17.562056
Log Pis Min                  -1.6971936
Policy mu Mean               -0.38044238
Policy mu Std                1.5865487
Policy mu Max                4.05868
Policy mu Min                -3.4371777
Policy log std Mean          -0.6185374
Policy log std Std           0.263035
Policy log std Max           0.15739709
Policy log std Min           -2.352823
Z mean eval                  7.53898
Z variance eval              0.008837871
total_rewards                [7387.51227714 7131.16941271 7076.4180615  7434.53309309 7395.43584218
 6148.79678045 6935.33755671 6941.53552717 6812.17428016 7236.02614423]
total_rewards_mean           7049.8938975348265
total_rewards_std            362.8551354138219
total_rewards_max            7434.533093093278
total_rewards_min            6148.7967804544605
Number of train steps total  160000
Number of env steps total    202000
Number of rollouts total     0
Train Time (s)               123.93092840211466
(Previous) Eval Time (s)     27.55806744005531
Sample Time (s)              22.390155404806137
Epoch Time (s)               173.8791512469761
Total Train Time (s)         7124.8775896169245
Epoch                        39
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:46:28.530821 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #39 | Epoch Duration: 174.5325014591217
2020-01-13 06:46:28.531024 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #39 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 7.540281
Z variance train             0.00880448
KL Divergence                158.28616
KL Loss                      15.828616
QF Loss                      440.76166
VF Loss                      371.85687
Policy Loss                  -4210.1973
Q Predictions Mean           4205.6724
Q Predictions Std            439.56882
Q Predictions Max            4787.033
Q Predictions Min            2627.316
V Predictions Mean           4197.7124
V Predictions Std            430.52396
V Predictions Max            4775.9136
V Predictions Min            2646.406
Log Pis Mean                 4.247784
Log Pis Std                  3.969136
Log Pis Max                  13.03201
Log Pis Min                  -5.510717
Policy mu Mean               -0.18736033
Policy mu Std                1.3571726
Policy mu Max                3.1965795
Policy mu Min                -2.9096346
Policy log std Mean          -0.719217
Policy log std Std           0.34845948
Policy log std Max           -0.10737461
Policy log std Min           -2.59317
Z mean eval                  7.122419
Z variance eval              0.0024085948
total_rewards                [7391.46859105 7336.68244265 7298.36075348 7252.39857829 7101.69394447
 7308.33169017 7428.92241526 7553.52152855 7414.32864329 7562.75229799]
total_rewards_mean           7364.846088518901
total_rewards_std            131.27421961357905
total_rewards_max            7562.752297987683
total_rewards_min            7101.693944466147
Number of train steps total  164000
Number of env steps total    207000
Number of rollouts total     0
Train Time (s)               127.10390446800739
(Previous) Eval Time (s)     28.211067607160658
Sample Time (s)              21.827735122293234
Epoch Time (s)               177.14270719746128
Total Train Time (s)         7302.783194030635
Epoch                        40
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:49:26.437858 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #40 | Epoch Duration: 177.90668439865112
2020-01-13 06:49:26.438058 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #40 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 7.0635223
Z variance train             0.0024416
KL Divergence                141.17947
KL Loss                      14.117948
QF Loss                      492.424
VF Loss                      217.04385
Policy Loss                  -3719.1963
Q Predictions Mean           3726.165
Q Predictions Std            455.58917
Q Predictions Max            4326.4126
Q Predictions Min            2122.094
V Predictions Mean           3724.0374
V Predictions Std            449.4443
V Predictions Max            4290.7197
V Predictions Min            2110.593
Log Pis Mean                 4.476159
Log Pis Std                  3.717535
Log Pis Max                  15.208763
Log Pis Min                  -5.536269
Policy mu Mean               -0.1344362
Policy mu Std                1.3509029
Policy mu Max                3.412309
Policy mu Min                -3.372918
Policy log std Mean          -0.7486086
Policy log std Std           0.3737554
Policy log std Max           0.040775955
Policy log std Min           -2.742665
Z mean eval                  6.469229
Z variance eval              0.00051688607
total_rewards                [7607.67659517 7708.83864596 7360.79758703 7685.51807401 7537.10400054
 7819.73667212 7397.02741359 7344.84078812 7880.055385   7586.05368929]
total_rewards_mean           7592.764885083258
total_rewards_std            176.94128171734766
total_rewards_max            7880.055384995133
total_rewards_min            7344.840788122569
Number of train steps total  168000
Number of env steps total    212000
Number of rollouts total     0
Train Time (s)               132.99273821897805
(Previous) Eval Time (s)     28.974702620878816
Sample Time (s)              23.1246376093477
Epoch Time (s)               185.09207844920456
Total Train Time (s)         7487.0971093191765
Epoch                        41
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:52:30.756392 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #41 | Epoch Duration: 184.31819701194763
2020-01-13 06:52:30.756577 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #41 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 6.4435143
Z variance train             0.0005231936
KL Divergence                122.53022
KL Loss                      12.253022
QF Loss                      480.09
VF Loss                      144.85696
Policy Loss                  -3334.437
Q Predictions Mean           3327.6113
Q Predictions Std            449.6911
Q Predictions Max            3930.2617
Q Predictions Min            1640.3894
V Predictions Mean           3328.0815
V Predictions Std            441.59085
V Predictions Max            3917.6636
V Predictions Min            1668.5714
Log Pis Mean                 4.049115
Log Pis Std                  3.5930111
Log Pis Max                  14.160757
Log Pis Min                  -3.3161836
Policy mu Mean               -0.19513953
Policy mu Std                1.3023746
Policy mu Max                2.9269068
Policy mu Min                -2.9805179
Policy log std Mean          -0.7454252
Policy log std Std           0.3586232
Policy log std Max           0.08292717
Policy log std Min           -2.8626118
Z mean eval                  5.9100075
Z variance eval              0.0011522796
total_rewards                [ 303.86780121 7575.20935409 7192.20424461 7404.23337393 7173.64188988
 7700.98690918 7376.69037718 7482.8584416  7592.11607787  637.04663489]
total_rewards_mean           6043.885510444057
total_rewards_std            2792.1713627473114
total_rewards_max            7700.986909180761
total_rewards_min            303.8678012057293
Number of train steps total  172000
Number of env steps total    217000
Number of rollouts total     0
Train Time (s)               131.34181896736845
(Previous) Eval Time (s)     28.200401954352856
Sample Time (s)              22.40496197482571
Epoch Time (s)               181.94718289654702
Total Train Time (s)         7668.916126232594
Epoch                        42
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:55:32.573687 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #42 | Epoch Duration: 181.816969871521
2020-01-13 06:55:32.573874 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #42 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 5.961417
Z variance train             0.0014101805
KL Divergence                105.23638
KL Loss                      10.523639
QF Loss                      506.94095
VF Loss                      323.92108
Policy Loss                  -3066.1062
Q Predictions Mean           3060.3022
Q Predictions Std            461.94983
Q Predictions Max            3624.1926
Q Predictions Min            1346.7979
V Predictions Mean           3075.8147
V Predictions Std            455.77115
V Predictions Max            3637.096
V Predictions Min            1360.6877
Log Pis Mean                 3.819763
Log Pis Std                  3.565827
Log Pis Max                  18.071178
Log Pis Min                  -4.194158
Policy mu Mean               -0.24173456
Policy mu Std                1.2627019
Policy mu Max                3.5205917
Policy mu Min                -2.9567776
Policy log std Mean          -0.76247907
Policy log std Std           0.38714254
Policy log std Max           -0.110877454
Policy log std Min           -2.85556
Z mean eval                  5.7620134
Z variance eval              0.000961837
total_rewards                [7588.94864524 7495.86311347 7753.48702539 7797.29315137 7809.13240659
 7645.38842009 7737.11246513 7551.52032391 7700.79648668 7730.48289614]
total_rewards_mean           7681.002493401099
total_rewards_std            100.97907501707135
total_rewards_max            7809.132406592099
total_rewards_min            7495.863113471708
Number of train steps total  176000
Number of env steps total    222000
Number of rollouts total     0
Train Time (s)               131.3628118862398
(Previous) Eval Time (s)     28.069844174198806
Sample Time (s)              21.86061109509319
Epoch Time (s)               181.2932671555318
Total Train Time (s)         7851.501659675967
Epoch                        43
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:58:35.160785 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #43 | Epoch Duration: 182.58677077293396
2020-01-13 06:58:35.160974 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #43 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 5.7267466
Z variance train             0.0011891719
KL Divergence                99.159
KL Loss                      9.9159
QF Loss                      385.4707
VF Loss                      199.87318
Policy Loss                  -2927.0635
Q Predictions Mean           2929.0203
Q Predictions Std            487.89417
Q Predictions Max            3495.9185
Q Predictions Min            1159.437
V Predictions Mean           2920.5796
V Predictions Std            482.7934
V Predictions Max            3486.8613
V Predictions Min            1182.4769
Log Pis Mean                 3.418363
Log Pis Std                  3.4434237
Log Pis Max                  15.692614
Log Pis Min                  -5.0192823
Policy mu Mean               -0.1548476
Policy mu Std                1.2567714
Policy mu Max                3.2762864
Policy mu Min                -3.8904636
Policy log std Mean          -0.7644818
Policy log std Std           0.3714174
Policy log std Max           -0.09060651
Policy log std Min           -2.7254562
Z mean eval                  5.670408
Z variance eval              0.0043845614
total_rewards                [7435.57393826 7976.89346622 7489.68298868 7599.03284966 7810.07800415
 7799.1117261  7838.12702529 7921.81882125 7819.35450466 7673.53337717]
total_rewards_mean           7736.320670143975
total_rewards_std            171.17119483079435
total_rewards_max            7976.893466223064
total_rewards_min            7435.573938256636
Number of train steps total  180000
Number of env steps total    227000
Number of rollouts total     0
Train Time (s)               130.46092393202707
(Previous) Eval Time (s)     29.363004392012954
Sample Time (s)              22.927199005614966
Epoch Time (s)               182.751127329655
Total Train Time (s)         8032.681008758955
Epoch                        44
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:01:36.342346 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #44 | Epoch Duration: 181.1811945438385
2020-01-13 07:01:36.342723 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #44 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 5.623129
Z variance train             0.0032165602
KL Divergence                93.77828
KL Loss                      9.377829
QF Loss                      356.27252
VF Loss                      183.03604
Policy Loss                  -2910.9128
Q Predictions Mean           2905.997
Q Predictions Std            391.77246
Q Predictions Max            3420.2063
Q Predictions Min            1064.3763
V Predictions Mean           2915.5107
V Predictions Std            382.81158
V Predictions Max            3429.0825
V Predictions Min            1086.5221
Log Pis Mean                 4.0505066
Log Pis Std                  3.6240976
Log Pis Max                  13.73336
Log Pis Min                  -3.9885378
Policy mu Mean               -0.2021703
Policy mu Std                1.3056633
Policy mu Max                3.081521
Policy mu Min                -3.0423486
Policy log std Mean          -0.7717147
Policy log std Std           0.3654263
Policy log std Max           -0.09651458
Policy log std Min           -2.6813548
Z mean eval                  5.493882
Z variance eval              0.0013881263
total_rewards                [7425.89420742 6601.90333347 6823.63240453 2328.53725662 7136.72252934
 6447.3264748  7478.35497462 7242.3369918  7008.54875915 7145.79714161]
total_rewards_mean           6563.905407335997
total_rewards_std            1446.539776448769
total_rewards_max            7478.354974623319
total_rewards_min            2328.5372566162414
Number of train steps total  184000
Number of env steps total    232000
Number of rollouts total     0
Train Time (s)               123.8461787449196
(Previous) Eval Time (s)     27.79269085265696
Sample Time (s)              23.266112086828798
Epoch Time (s)               174.90498168440536
Total Train Time (s)         8207.166106893215
Epoch                        45
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:04:30.828289 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #45 | Epoch Duration: 174.4853127002716
2020-01-13 07:04:30.828466 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #45 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 5.5591545
Z variance train             0.0032828175
KL Divergence                93.4801
KL Loss                      9.34801
QF Loss                      464.04825
VF Loss                      297.89996
Policy Loss                  -2814.1897
Q Predictions Mean           2815.7659
Q Predictions Std            508.49158
Q Predictions Max            3449.9985
Q Predictions Min            974.53595
V Predictions Mean           2802.8408
V Predictions Std            503.35428
V Predictions Max            3411.425
V Predictions Min            974.0304
Log Pis Mean                 3.8504326
Log Pis Std                  3.3352702
Log Pis Max                  12.849827
Log Pis Min                  -5.471044
Policy mu Mean               -0.21714121
Policy mu Std                1.2590709
Policy mu Max                3.2108207
Policy mu Min                -2.8092034
Policy log std Mean          -0.7666324
Policy log std Std           0.386784
Policy log std Max           0.08706123
Policy log std Min           -2.8592772
Z mean eval                  5.430449
Z variance eval              0.0045804763
total_rewards                [7740.15169112 7990.33451193 7492.50346408 7765.7067554  7532.11611504
 7738.33417302 7720.74687952 7745.67888926 7624.4789795  7838.87990636]
total_rewards_mean           7718.893136520824
total_rewards_std            136.70096037612794
total_rewards_max            7990.334511931624
total_rewards_min            7492.503464081124
Number of train steps total  188000
Number of env steps total    237000
Number of rollouts total     0
Train Time (s)               124.28909775894135
(Previous) Eval Time (s)     27.37271016696468
Sample Time (s)              22.2019661096856
Epoch Time (s)               173.86377403559163
Total Train Time (s)         8380.403791649733
Epoch                        46
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:07:24.067549 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #46 | Epoch Duration: 173.23894929885864
2020-01-13 07:07:24.067739 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #46 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 5.4443455
Z variance train             0.0027354502
KL Divergence                90.87773
KL Loss                      9.087773
QF Loss                      450.27203
VF Loss                      189.2945
Policy Loss                  -2726.2747
Q Predictions Mean           2723.1904
Q Predictions Std            544.6779
Q Predictions Max            3369.3965
Q Predictions Min            853.70294
V Predictions Mean           2722.2148
V Predictions Std            541.69385
V Predictions Max            3347.4858
V Predictions Min            836.4533
Log Pis Mean                 3.8039794
Log Pis Std                  3.6829245
Log Pis Max                  14.317963
Log Pis Min                  -4.3727436
Policy mu Mean               -0.2005703
Policy mu Std                1.2751745
Policy mu Max                3.5703764
Policy mu Min                -2.9876456
Policy log std Mean          -0.74464846
Policy log std Std           0.374902
Policy log std Max           0.06195891
Policy log std Min           -2.8269613
Z mean eval                  5.3222575
Z variance eval              0.0015945116
total_rewards                [8195.99791556 7622.13295536 7927.82841862 7981.72126705 7846.85104192
 8061.74803373 8204.2647792  8381.62024647 8220.41359884 7974.00893407]
total_rewards_mean           8041.658719082438
total_rewards_std            208.15145266018123
total_rewards_max            8381.620246471495
total_rewards_min            7622.132955356568
Number of train steps total  192000
Number of env steps total    242000
Number of rollouts total     0
Train Time (s)               126.60221681231633
(Previous) Eval Time (s)     26.747544733807445
Sample Time (s)              21.14319601561874
Epoch Time (s)               174.49295756174251
Total Train Time (s)         8555.038663551211
Epoch                        47
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:10:18.703685 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #47 | Epoch Duration: 174.63580513000488
2020-01-13 07:10:18.703872 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #47 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 5.3508396
Z variance train             0.001257532
KL Divergence                88.34534
KL Loss                      8.834534
QF Loss                      300.31873
VF Loss                      114.656456
Policy Loss                  -2770.933
Q Predictions Mean           2767.4893
Q Predictions Std            507.77872
Q Predictions Max            3383.1443
Q Predictions Min            787.3309
V Predictions Mean           2770.516
V Predictions Std            499.44485
V Predictions Max            3379.9631
V Predictions Min            799.0975
Log Pis Mean                 3.5820646
Log Pis Std                  3.5358806
Log Pis Max                  17.728653
Log Pis Min                  -8.306018
Policy mu Mean               -0.2621764
Policy mu Std                1.2376082
Policy mu Max                3.5008852
Policy mu Min                -3.2709427
Policy log std Mean          -0.7714205
Policy log std Std           0.37045628
Policy log std Max           0.30115557
Policy log std Min           -2.879496
Z mean eval                  4.8801894
Z variance eval              0.0021537587
total_rewards                [7393.02312551 7329.97577017 7337.2829375  7279.78059458 7198.03417921
 7144.19790399 7399.854236   7286.97141655 7316.14421288 7461.96726311]
total_rewards_mean           7314.723163949115
total_rewards_std            89.71562794986966
total_rewards_max            7461.967263108873
total_rewards_min            7144.197903994131
Number of train steps total  196000
Number of env steps total    247000
Number of rollouts total     0
Train Time (s)               133.00923406006768
(Previous) Eval Time (s)     26.890074975788593
Sample Time (s)              21.658544899430126
Epoch Time (s)               181.5578539352864
Total Train Time (s)         8738.388100989163
Epoch                        48
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:13:22.054680 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #48 | Epoch Duration: 183.3506715297699
2020-01-13 07:13:22.054866 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #48 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 5.11819
Z variance train             0.002176383
KL Divergence                79.558655
KL Loss                      7.9558654
QF Loss                      296.49542
VF Loss                      221.02493
Policy Loss                  -2749.544
Q Predictions Mean           2751.7014
Q Predictions Std            474.5765
Q Predictions Max            3341.9788
Q Predictions Min            710.0936
V Predictions Mean           2740.6763
V Predictions Std            469.19342
V Predictions Max            3335.582
V Predictions Min            699.71234
Log Pis Mean                 3.9802594
Log Pis Std                  3.49751
Log Pis Max                  13.489878
Log Pis Min                  -4.1543527
Policy mu Mean               -0.22827792
Policy mu Std                1.2733775
Policy mu Max                2.8813465
Policy mu Min                -2.8365357
Policy log std Mean          -0.7861069
Policy log std Std           0.39420313
Policy log std Max           -0.06695843
Policy log std Min           -2.8935401
Z mean eval                  4.6691136
Z variance eval              0.004302767
total_rewards                [7827.55861431 7637.97246117 7550.13260597 7727.49831447 7586.90716651
 7876.53463253 7616.41622934 7761.60644399 7494.25089445 7510.82622939]
total_rewards_mean           7658.970359215069
total_rewards_std            126.23635394595091
total_rewards_max            7876.534632534817
total_rewards_min            7494.250894445095
Number of train steps total  200000
Number of env steps total    252000
Number of rollouts total     0
Train Time (s)               131.5939783398062
(Previous) Eval Time (s)     28.68253478780389
Sample Time (s)              22.35519685409963
Epoch Time (s)               182.63170998170972
Total Train Time (s)         8920.775985493325
Epoch                        49
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:16:24.444097 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #49 | Epoch Duration: 182.38909196853638
2020-01-13 07:16:24.444280 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #49 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.7067394
Z variance train             0.003955703
KL Divergence                69.30983
KL Loss                      6.930983
QF Loss                      326.04016
VF Loss                      121.64311
Policy Loss                  -2616.804
Q Predictions Mean           2615.397
Q Predictions Std            464.40408
Q Predictions Max            3277.6162
Q Predictions Min            628.86694
V Predictions Mean           2616.1445
V Predictions Std            460.17175
V Predictions Max            3261.529
V Predictions Min            623.23584
Log Pis Mean                 3.9920146
Log Pis Std                  3.6384716
Log Pis Max                  14.235765
Log Pis Min                  -7.084605
Policy mu Mean               -0.21443896
Policy mu Std                1.2852045
Policy mu Max                3.0693839
Policy mu Min                -3.2101567
Policy log std Mean          -0.7633578
Policy log std Std           0.37905386
Policy log std Max           0.22964925
Policy log std Min           -2.7972345
Z mean eval                  4.719513
Z variance eval              0.013344797
total_rewards                [7542.54550499 7720.87749394 7676.30441367 7688.45206476 7707.09290159
 7733.52337924 7541.04181153 7660.34732614 7613.40437093 7602.01523987]
total_rewards_mean           7648.560450665575
total_rewards_std            66.76551028943156
total_rewards_max            7733.523379237498
total_rewards_min            7541.041811527895
Number of train steps total  204000
Number of env steps total    257000
Number of rollouts total     0
Train Time (s)               130.97803143179044
(Previous) Eval Time (s)     28.43958068219945
Sample Time (s)              22.114906116388738
Epoch Time (s)               181.53251823037863
Total Train Time (s)         9103.378563253209
Epoch                        50
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:19:27.048252 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #50 | Epoch Duration: 182.6038315296173
2020-01-13 07:19:27.048448 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #50 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.831874
Z variance train             0.012733774
KL Divergence                72.61289
KL Loss                      7.261289
QF Loss                      694.4816
VF Loss                      501.3216
Policy Loss                  -2650.1665
Q Predictions Mean           2640.797
Q Predictions Std            623.74615
Q Predictions Max            3274.4795
Q Predictions Min            597.46844
V Predictions Mean           2650.5327
V Predictions Std            617.4161
V Predictions Max            3259.2273
V Predictions Min            613.54767
Log Pis Mean                 4.2329335
Log Pis Std                  3.8957267
Log Pis Max                  14.583266
Log Pis Min                  -4.9672318
Policy mu Mean               -0.24238475
Policy mu Std                1.2968491
Policy mu Max                2.8609474
Policy mu Min                -2.95461
Policy log std Mean          -0.74605244
Policy log std Std           0.39322323
Policy log std Max           0.0800544
Policy log std Min           -2.956986
Z mean eval                  4.6091413
Z variance eval              0.008766644
total_rewards                [7903.89717408 7992.91388602 7680.14465047 8088.73617996 8178.03914432
 7917.96855039 7897.20944694 7870.97183736 7943.02555429 8005.18913383]
total_rewards_mean           7947.809555767021
total_rewards_std            126.94225871909559
total_rewards_max            8178.039144321089
total_rewards_min            7680.1446504703545
Number of train steps total  208000
Number of env steps total    262000
Number of rollouts total     0
Train Time (s)               130.43664111662656
(Previous) Eval Time (s)     29.51051245769486
Sample Time (s)              23.545325379818678
Epoch Time (s)               183.4924789541401
Total Train Time (s)         9286.093431876507
Epoch                        51
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:22:29.765248 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #51 | Epoch Duration: 182.71664762496948
2020-01-13 07:22:29.765441 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #51 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.6129737
Z variance train             0.008899837
KL Divergence                66.30618
KL Loss                      6.6306186
QF Loss                      1246.6649
VF Loss                      295.1234
Policy Loss                  -2706.33
Q Predictions Mean           2701.1768
Q Predictions Std            526.52386
Q Predictions Max            3284.4558
Q Predictions Min            531.60077
V Predictions Mean           2697.0825
V Predictions Std            514.4078
V Predictions Max            3275.7214
V Predictions Min            569.1726
Log Pis Mean                 4.1159744
Log Pis Std                  3.7089832
Log Pis Max                  15.591346
Log Pis Min                  -4.8883476
Policy mu Mean               -0.23694785
Policy mu Std                1.3204699
Policy mu Max                4.358325
Policy mu Min                -3.4334202
Policy log std Mean          -0.74839765
Policy log std Std           0.36917824
Policy log std Max           -0.07504159
Policy log std Min           -2.8136508
Z mean eval                  4.574062
Z variance eval              0.00591669
total_rewards                [7790.58320413 7866.11400919 7934.71360414 7736.49661466 8080.27279736
 8042.14211445 8201.42794577 7855.24102121 8008.51119869 7830.34256108]
total_rewards_mean           7934.584507067087
total_rewards_std            138.3074399700581
total_rewards_max            8201.427945769823
total_rewards_min            7736.496614662217
Number of train steps total  212000
Number of env steps total    267000
Number of rollouts total     0
Train Time (s)               125.6267337189056
(Previous) Eval Time (s)     28.73419920168817
Sample Time (s)              23.209635026287287
Epoch Time (s)               177.57056794688106
Total Train Time (s)         9462.81576545583
Epoch                        52
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:25:26.488741 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #52 | Epoch Duration: 176.72316217422485
2020-01-13 07:25:26.488925 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #52 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.574677
Z variance train             0.0059210444
KL Divergence                65.73551
KL Loss                      6.573551
QF Loss                      476.87927
VF Loss                      141.32498
Policy Loss                  -2679.4902
Q Predictions Mean           2677.4836
Q Predictions Std            539.3348
Q Predictions Max            3283.9404
Q Predictions Min            498.21783
V Predictions Mean           2676.0786
V Predictions Std            531.4512
V Predictions Max            3287.9558
V Predictions Min            503.8214
Log Pis Mean                 4.111562
Log Pis Std                  3.7182226
Log Pis Max                  14.325725
Log Pis Min                  -4.1821365
Policy mu Mean               -0.19313832
Policy mu Std                1.3073052
Policy mu Max                3.6136494
Policy mu Min                -3.1813486
Policy log std Mean          -0.77486867
Policy log std Std           0.41555092
Policy log std Max           0.044783473
Policy log std Min           -3.021843
Z mean eval                  4.5509434
Z variance eval              0.012688577
total_rewards                [8024.04967854 8033.49670506 7922.30413436 8030.31425395 8018.74697666
 8187.99678218 8244.22643012 8026.94662022 8164.27099571 8089.54439449]
total_rewards_mean           8074.189697129262
total_rewards_std            92.02443892125419
total_rewards_max            8244.22643011736
total_rewards_min            7922.304134355288
Number of train steps total  216000
Number of env steps total    272000
Number of rollouts total     0
Train Time (s)               124.27852843794972
(Previous) Eval Time (s)     27.886442764196545
Sample Time (s)              22.186740580014884
Epoch Time (s)               174.35171178216115
Total Train Time (s)         9637.482929336373
Epoch                        53
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:28:21.157386 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #53 | Epoch Duration: 174.66830897331238
2020-01-13 07:28:21.157584 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #53 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.5518093
Z variance train             0.012682167
KL Divergence                63.841972
KL Loss                      6.384197
QF Loss                      312.54572
VF Loss                      124.68711
Policy Loss                  -2726.1404
Q Predictions Mean           2724.3906
Q Predictions Std            535.17914
Q Predictions Max            3253.3306
Q Predictions Min            488.987
V Predictions Mean           2728.8223
V Predictions Std            529.2452
V Predictions Max            3248.6348
V Predictions Min            450.76382
Log Pis Mean                 4.251011
Log Pis Std                  3.6546917
Log Pis Max                  15.73107
Log Pis Min                  -5.4752955
Policy mu Mean               -0.25586656
Policy mu Std                1.3018329
Policy mu Max                4.0280795
Policy mu Min                -2.9480474
Policy log std Mean          -0.760626
Policy log std Std           0.3876312
Policy log std Max           -0.0708316
Policy log std Min           -2.9977393
Z mean eval                  4.5344515
Z variance eval              0.00262758
total_rewards                [8015.56856535 7956.54161877 8298.49600743 8235.74284108 8109.46419038
 8010.83806713 8169.1622099  7991.17591683 8057.95676981 8064.81617826]
total_rewards_mean           8090.976236494031
total_rewards_std            106.01533999499135
total_rewards_max            8298.496007433087
total_rewards_min            7956.541618774164
Number of train steps total  220000
Number of env steps total    277000
Number of rollouts total     0
Train Time (s)               126.81078449776396
(Previous) Eval Time (s)     28.2026887931861
Sample Time (s)              21.413192899432033
Epoch Time (s)               176.4266661903821
Total Train Time (s)         9813.47123510763
Epoch                        54
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:31:17.148667 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #54 | Epoch Duration: 175.99092078208923
2020-01-13 07:31:17.148973 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #54 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.5349092
Z variance train             0.0026320368
KL Divergence                65.02669
KL Loss                      6.502669
QF Loss                      890.21094
VF Loss                      140.24919
Policy Loss                  -2776.118
Q Predictions Mean           2774.9087
Q Predictions Std            501.82367
Q Predictions Max            3365.1958
Q Predictions Min            459.97623
V Predictions Mean           2777.8105
V Predictions Std            494.4401
V Predictions Max            3372.7944
V Predictions Min            471.2885
Log Pis Mean                 4.4853077
Log Pis Std                  4.1273856
Log Pis Max                  18.671728
Log Pis Min                  -7.703239
Policy mu Mean               -0.21836627
Policy mu Std                1.3114694
Policy mu Max                3.058072
Policy mu Min                -3.730681
Policy log std Mean          -0.7830098
Policy log std Std           0.4112998
Policy log std Max           0.23645622
Policy log std Min           -2.9528756
Z mean eval                  4.5442505
Z variance eval              0.002575981
total_rewards                [7997.56220298 8298.6578522  8236.87263571 6065.26629655 8434.01158772
 8089.15970851 8043.59433726 8114.09381592 8466.10001577 8173.55546991]
total_rewards_mean           7991.887392253515
total_rewards_std            659.2762367246754
total_rewards_max            8466.100015771994
total_rewards_min            6065.266296553797
Number of train steps total  224000
Number of env steps total    282000
Number of rollouts total     0
Train Time (s)               133.78882164973766
(Previous) Eval Time (s)     27.766575323883444
Sample Time (s)              22.80811979761347
Epoch Time (s)               184.36351677123457
Total Train Time (s)         9997.992075181566
Epoch                        55
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:34:21.670210 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #55 | Epoch Duration: 184.52104353904724
2020-01-13 07:34:21.670417 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #55 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.5416155
Z variance train             0.0025799114
KL Divergence                64.94575
KL Loss                      6.494575
QF Loss                      838.8258
VF Loss                      178.12497
Policy Loss                  -2809.3967
Q Predictions Mean           2799.4536
Q Predictions Std            576.3462
Q Predictions Max            3439.5942
Q Predictions Min            436.38202
V Predictions Mean           2808.3933
V Predictions Std            571.0926
V Predictions Max            3435.7483
V Predictions Min            456.12225
Log Pis Mean                 4.4960775
Log Pis Std                  3.7553554
Log Pis Max                  19.476492
Log Pis Min                  -3.5072556
Policy mu Mean               -0.27057076
Policy mu Std                1.3378793
Policy mu Max                4.34295
Policy mu Min                -3.1769655
Policy log std Mean          -0.7828698
Policy log std Std           0.41663247
Policy log std Max           0.16481483
Policy log std Min           -3.0790558
Z mean eval                  4.715295
Z variance eval              0.0037367516
total_rewards                [8049.3777458  7745.94532902 7798.33060779 8099.68046717 7873.51451576
 8121.75842875 7987.03968757 8190.66469436 8038.24923769 7785.1870414 ]
total_rewards_mean           7968.974775530184
total_rewards_std            149.30349320139177
total_rewards_max            8190.664694360967
total_rewards_min            7745.945329017936
Number of train steps total  228000
Number of env steps total    287000
Number of rollouts total     0
Train Time (s)               131.50941702071577
(Previous) Eval Time (s)     27.923735563177615
Sample Time (s)              21.530928615015
Epoch Time (s)               180.9640811989084
Total Train Time (s)         10179.985387261026
Epoch                        56
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:37:23.665319 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #56 | Epoch Duration: 181.99473690986633
2020-01-13 07:37:23.665562 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #56 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.8549323
Z variance train             0.0033642836
KL Divergence                72.05112
KL Loss                      7.205112
QF Loss                      349.38937
VF Loss                      220.54715
Policy Loss                  -2937.3125
Q Predictions Mean           2937.3633
Q Predictions Std            589.39325
Q Predictions Max            3553.245
Q Predictions Min            468.6817
V Predictions Mean           2945.8462
V Predictions Std            582.2389
V Predictions Max            3568.128
V Predictions Min            487.04367
Log Pis Mean                 4.3473535
Log Pis Std                  3.6187038
Log Pis Max                  12.781433
Log Pis Min                  -7.2430353
Policy mu Mean               -0.19281645
Policy mu Std                1.3195086
Policy mu Max                2.9843397
Policy mu Min                -2.7627556
Policy log std Mean          -0.77594346
Policy log std Std           0.39965075
Policy log std Max           -0.058538973
Policy log std Min           -2.9148946
Z mean eval                  4.698317
Z variance eval              0.0059100226
total_rewards                [8343.49838277 8498.8251554  8158.49228641 8198.55353516 8425.14645754
 8367.36593972 8460.7223577  8241.61467012 8319.32810463 8336.79311849]
total_rewards_mean           8335.034000792752
total_rewards_std            105.18231587115453
total_rewards_max            8498.825155396831
total_rewards_min            8158.492286406892
Number of train steps total  232000
Number of env steps total    292000
Number of rollouts total     0
Train Time (s)               131.21592629002407
(Previous) Eval Time (s)     28.953989091329277
Sample Time (s)              22.706174031831324
Epoch Time (s)               182.87608941318467
Total Train Time (s)         10362.259973902721
Epoch                        57
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:40:25.942784 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #57 | Epoch Duration: 182.27703166007996
2020-01-13 07:40:25.943169 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #57 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.6973677
Z variance train             0.0059734443
KL Divergence                68.362724
KL Loss                      6.8362727
QF Loss                      458.02362
VF Loss                      234.83226
Policy Loss                  -2960.9048
Q Predictions Mean           2958.226
Q Predictions Std            472.1582
Q Predictions Max            3502.9507
Q Predictions Min            464.2772
V Predictions Mean           2954.812
V Predictions Std            466.51505
V Predictions Max            3469.8875
V Predictions Min            462.5132
Log Pis Mean                 4.0563674
Log Pis Std                  3.7873363
Log Pis Max                  14.7896595
Log Pis Min                  -5.8254414
Policy mu Mean               -0.20743501
Policy mu Std                1.3271854
Policy mu Max                2.8729346
Policy mu Min                -3.5241907
Policy log std Mean          -0.76318836
Policy log std Std           0.37930366
Policy log std Max           -0.10924691
Policy log std Min           -2.9367054
Z mean eval                  4.710659
Z variance eval              0.0051563764
total_rewards                [8405.25590409 8507.51642598 8591.44006959 8557.59995755 8326.79993359
 8374.15130329 8675.07908649 8640.68367634 8309.03748713 8291.72650186]
total_rewards_mean           8467.929034590261
total_rewards_std            136.5839616184966
total_rewards_max            8675.079086489846
total_rewards_min            8291.726501857862
Number of train steps total  236000
Number of env steps total    297000
Number of rollouts total     0
Train Time (s)               131.2583814440295
(Previous) Eval Time (s)     28.354531548917294
Sample Time (s)              23.831338742747903
Epoch Time (s)               183.4442517356947
Total Train Time (s)         10546.018132793251
Epoch                        58
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:43:29.701403 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #58 | Epoch Duration: 183.75795340538025
2020-01-13 07:43:29.701613 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #58 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.706686
Z variance train             0.005223279
KL Divergence                69.08265
KL Loss                      6.908265
QF Loss                      402.12677
VF Loss                      228.85547
Policy Loss                  -2915.3108
Q Predictions Mean           2911.8125
Q Predictions Std            572.66296
Q Predictions Max            3564.2192
Q Predictions Min            424.30087
V Predictions Mean           2911.4355
V Predictions Std            566.1912
V Predictions Max            3565.124
V Predictions Min            452.69348
Log Pis Mean                 4.4786873
Log Pis Std                  3.7735772
Log Pis Max                  22.389915
Log Pis Min                  -5.1472006
Policy mu Mean               -0.22493614
Policy mu Std                1.323865
Policy mu Max                4.510534
Policy mu Min                -4.816546
Policy log std Mean          -0.7837855
Policy log std Std           0.41088498
Policy log std Max           0.04565817
Policy log std Min           -3.0831487
Z mean eval                  4.547004
Z variance eval              0.023663232
total_rewards                [8183.9336598  8240.75825557 8004.3613867  8417.28399576 8018.08186028
 8022.35251991 7965.6333007  8157.12753182 8167.24566318 7870.67163907]
total_rewards_mean           8104.744981280337
total_rewards_std            150.870682870578
total_rewards_max            8417.283995761807
total_rewards_min            7870.671639073405
Number of train steps total  240000
Number of env steps total    302000
Number of rollouts total     0
Train Time (s)               126.61669434094802
(Previous) Eval Time (s)     28.667854321654886
Sample Time (s)              23.397623443976045
Epoch Time (s)               178.68217210657895
Total Train Time (s)         10722.836440061219
Epoch                        59
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:46:26.521212 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #59 | Epoch Duration: 176.81945419311523
2020-01-13 07:46:26.521402 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #59 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.5474205
Z variance train             0.023577705
KL Divergence                63.906754
KL Loss                      6.3906755
QF Loss                      473.03946
VF Loss                      214.9246
Policy Loss                  -2853.4382
Q Predictions Mean           2846.8394
Q Predictions Std            504.88998
Q Predictions Max            3412.1917
Q Predictions Min            402.96848
V Predictions Mean           2847.6357
V Predictions Std            497.1201
V Predictions Max            3395.836
V Predictions Min            421.82544
Log Pis Mean                 4.0035915
Log Pis Std                  3.684828
Log Pis Max                  12.412982
Log Pis Min                  -5.4041085
Policy mu Mean               -0.20074236
Policy mu Std                1.2992398
Policy mu Max                2.7506773
Policy mu Min                -2.8800025
Policy log std Mean          -0.77121335
Policy log std Std           0.41093597
Policy log std Max           0.098380685
Policy log std Min           -3.0169005
Z mean eval                  4.6439567
Z variance eval              0.005315568
total_rewards                [8548.87305661 8444.15595123 8229.94722755  734.67417054 8514.81232446
 8316.15923592 8364.86428247 8566.19665824 8492.47047157 8336.77793877]
total_rewards_mean           7654.893131736998
total_rewards_std            2309.1128883064885
total_rewards_max            8566.196658241484
total_rewards_min            734.6741705415711
Number of train steps total  244000
Number of env steps total    307000
Number of rollouts total     0
Train Time (s)               125.24847406195477
(Previous) Eval Time (s)     26.80474398797378
Sample Time (s)              21.73873801296577
Epoch Time (s)               173.79195606289431
Total Train Time (s)         10897.803137970623
Epoch                        60
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:49:21.490237 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #60 | Epoch Duration: 174.9686689376831
2020-01-13 07:49:21.490559 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #60 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.550454
Z variance train             0.014725186
KL Divergence                62.113113
KL Loss                      6.2113113
QF Loss                      338.1706
VF Loss                      218.94194
Policy Loss                  -2886.2454
Q Predictions Mean           2886.9375
Q Predictions Std            544.65295
Q Predictions Max            3527.7583
Q Predictions Min            405.88803
V Predictions Mean           2894.556
V Predictions Std            541.34485
V Predictions Max            3537.2732
V Predictions Min            410.65002
Log Pis Mean                 4.015834
Log Pis Std                  3.8238883
Log Pis Max                  14.339666
Log Pis Min                  -5.729001
Policy mu Mean               -0.21732694
Policy mu Std                1.282814
Policy mu Max                2.8550706
Policy mu Min                -2.6617014
Policy log std Mean          -0.7907942
Policy log std Std           0.40502998
Policy log std Max           0.08093727
Policy log std Min           -3.0574312
Z mean eval                  4.645438
Z variance eval              0.0044473284
total_rewards                [8697.84288334 8458.99000657 8604.87010547 8671.45826249 8791.99553015
 8529.11705946 8505.76162751 8318.80624584 8675.76369761 8907.91123195]
total_rewards_mean           8616.251665038759
total_rewards_std            161.96691662933765
total_rewards_max            8907.911231947084
total_rewards_min            8318.806245843783
Number of train steps total  248000
Number of env steps total    312000
Number of rollouts total     0
Train Time (s)               126.11553329974413
(Previous) Eval Time (s)     27.981112139765173
Sample Time (s)              21.194306084420532
Epoch Time (s)               175.29095152392983
Total Train Time (s)         11073.506379215047
Epoch                        61
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:52:17.194624 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #61 | Epoch Duration: 175.7038402557373
2020-01-13 07:52:17.194820 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #61 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.555279
Z variance train             0.0071027502
KL Divergence                63.783978
KL Loss                      6.378398
QF Loss                      313.32718
VF Loss                      87.55612
Policy Loss                  -2935.9277
Q Predictions Mean           2939.3203
Q Predictions Std            556.81604
Q Predictions Max            3573.9644
Q Predictions Min            391.6268
V Predictions Mean           2938.6162
V Predictions Std            547.6314
V Predictions Max            3565.1292
V Predictions Min            410.96634
Log Pis Mean                 4.0511446
Log Pis Std                  3.705382
Log Pis Max                  18.582909
Log Pis Min                  -6.747936
Policy mu Mean               -0.2350455
Policy mu Std                1.2804716
Policy mu Max                3.4010372
Policy mu Min                -2.8123143
Policy log std Mean          -0.7809406
Policy log std Std           0.39496478
Policy log std Max           0.004609108
Policy log std Min           -3.048041
Z mean eval                  4.6434054
Z variance eval              0.0030791447
total_rewards                [8987.03231697 8628.57613681 8782.6629787  8514.07432827 8788.4766697
 8393.6595719  8440.38080168 8726.08852157 8330.91296497 8397.76987371]
total_rewards_mean           8598.963416427123
total_rewards_std            205.94420050102065
total_rewards_max            8987.032316965156
total_rewards_min            8330.912964966852
Number of train steps total  252000
Number of env steps total    317000
Number of rollouts total     0
Train Time (s)               133.53332139691338
(Previous) Eval Time (s)     28.39367841789499
Sample Time (s)              22.478477237280458
Epoch Time (s)               184.40547705208883
Total Train Time (s)         11257.915684292559
Epoch                        62
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:55:21.605491 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #62 | Epoch Duration: 184.41052222251892
2020-01-13 07:55:21.605718 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #62 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.622979
Z variance train             0.0034333665
KL Divergence                67.26976
KL Loss                      6.726976
QF Loss                      337.7072
VF Loss                      234.66699
Policy Loss                  -2930.2078
Q Predictions Mean           2935.5308
Q Predictions Std            643.6263
Q Predictions Max            3631.3206
Q Predictions Min            384.08514
V Predictions Mean           2941.209
V Predictions Std            642.5195
V Predictions Max            3640.3303
V Predictions Min            387.6131
Log Pis Mean                 4.576394
Log Pis Std                  4.117794
Log Pis Max                  14.017086
Log Pis Min                  -6.8794365
Policy mu Mean               -0.18846053
Policy mu Std                1.3534186
Policy mu Max                3.0361557
Policy mu Min                -2.9096653
Policy log std Mean          -0.7716894
Policy log std Std           0.40146664
Policy log std Max           0.004668534
Policy log std Min           -3.09507
Z mean eval                  5.171567
Z variance eval              0.010342627
total_rewards                [8242.67958779 8353.61799057 8386.00770163 8544.97583028 8580.27861271
 8051.65151104 8498.54836095 8518.698605   8430.88397847 4578.9902491 ]
total_rewards_mean           8018.633242754309
total_rewards_std            1156.39207305286
total_rewards_max            8580.278612711321
total_rewards_min            4578.990249099893
Number of train steps total  256000
Number of env steps total    322000
Number of rollouts total     0
Train Time (s)               131.72530746972188
(Previous) Eval Time (s)     28.39835686609149
Sample Time (s)              23.070007730275393
Epoch Time (s)               183.19367206608877
Total Train Time (s)         11441.269616983831
Epoch                        63
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:58:24.961314 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #63 | Epoch Duration: 183.3554368019104
2020-01-13 07:58:24.961558 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #63 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 5.0929475
Z variance train             0.015936267
KL Divergence                75.83998
KL Loss                      7.583998
QF Loss                      578.9237
VF Loss                      120.07394
Policy Loss                  -3279.4568
Q Predictions Mean           3275.016
Q Predictions Std            379.95743
Q Predictions Max            3835.488
Q Predictions Min            474.02957
V Predictions Mean           3277.1875
V Predictions Std            373.88358
V Predictions Max            3820.5486
V Predictions Min            529.7462
Log Pis Mean                 4.763856
Log Pis Std                  3.5551302
Log Pis Max                  15.297841
Log Pis Min                  -3.8929582
Policy mu Mean               -0.29606637
Policy mu Std                1.359971
Policy mu Max                2.919155
Policy mu Min                -2.7663417
Policy log std Mean          -0.7496996
Policy log std Std           0.38420305
Policy log std Max           -0.055962384
Policy log std Min           -2.8449283
Z mean eval                  5.0645685
Z variance eval              0.008438756
total_rewards                [8164.35636154 8270.48755679 7994.7852803  8162.77561544 8242.55329796
 8358.49230624 8155.60452507 8163.16819731 8156.90929501 8241.35257194]
total_rewards_mean           8191.048500760025
total_rewards_std            90.97328480231825
total_rewards_max            8358.492306237216
total_rewards_min            7994.785280300405
Number of train steps total  260000
Number of env steps total    327000
Number of rollouts total     0
Train Time (s)               130.90277990698814
(Previous) Eval Time (s)     28.559675393160433
Sample Time (s)              21.9006875785999
Epoch Time (s)               181.36314287874848
Total Train Time (s)         11623.090091811027
Epoch                        64
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:01:26.784297 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #64 | Epoch Duration: 181.82254433631897
2020-01-13 08:01:26.784652 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #64 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 5.0647078
Z variance train             0.008460633
KL Divergence                77.76866
KL Loss                      7.7768664
QF Loss                      295.18915
VF Loss                      117.7565
Policy Loss                  -3089.5383
Q Predictions Mean           3089.9836
Q Predictions Std            688.6021
Q Predictions Max            3783.388
Q Predictions Min            491.55112
V Predictions Mean           3091.8499
V Predictions Std            687.07874
V Predictions Max            3777.5962
V Predictions Min            488.34174
Log Pis Mean                 4.4303794
Log Pis Std                  3.561003
Log Pis Max                  15.965987
Log Pis Min                  -2.9004164
Policy mu Mean               -0.2656146
Policy mu Std                1.325396
Policy mu Max                3.1183438
Policy mu Min                -2.959721
Policy log std Mean          -0.76815104
Policy log std Std           0.40580377
Policy log std Max           0.100411296
Policy log std Min           -3.081511
Z mean eval                  4.738929
Z variance eval              0.0030588196
total_rewards                [8050.1313215  8171.20588596 8237.29829234 8263.35609903 8220.15021323
 8083.07564885 8542.97812676 8498.52465843 8207.21099297 7984.27472174]
total_rewards_mean           8225.82059608118
total_rewards_std            170.13099191093096
total_rewards_max            8542.978126763657
total_rewards_min            7984.2747217391125
Number of train steps total  264000
Number of env steps total    332000
Number of rollouts total     0
Train Time (s)               131.58324314793572
(Previous) Eval Time (s)     29.01871086517349
Sample Time (s)              22.09740902343765
Epoch Time (s)               182.69936303654686
Total Train Time (s)         11804.532922822516
Epoch                        65
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:04:28.227088 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #65 | Epoch Duration: 181.4421980381012
2020-01-13 08:04:28.227245 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.73771
Z variance train             0.0030104103
KL Divergence                69.71306
KL Loss                      6.971306
QF Loss                      303.948
VF Loss                      140.87256
Policy Loss                  -3007.176
Q Predictions Mean           3001.2432
Q Predictions Std            537.36487
Q Predictions Max            3690.7566
Q Predictions Min            413.39725
V Predictions Mean           3009.8853
V Predictions Std            527.09644
V Predictions Max            3708.2952
V Predictions Min            416.44217
Log Pis Mean                 4.155425
Log Pis Std                  3.535913
Log Pis Max                  15.421663
Log Pis Min                  -5.0046606
Policy mu Mean               -0.24363594
Policy mu Std                1.2945492
Policy mu Max                3.009164
Policy mu Min                -2.6228065
Policy log std Mean          -0.7749901
Policy log std Std           0.3697338
Policy log std Max           -0.068703234
Policy log std Min           -2.7345724
Z mean eval                  4.827036
Z variance eval              0.0042243577
total_rewards                [8846.17967999 8500.18667409 8663.1232452  8726.96658192 8749.28257814
 8557.44366468 8631.31255892 8534.07381496 8425.99679483 8598.13218919]
total_rewards_mean           8623.269778193106
total_rewards_std            120.39976672130797
total_rewards_max            8846.17967998535
total_rewards_min            8425.996794829616
Number of train steps total  268000
Number of env steps total    337000
Number of rollouts total     0
Train Time (s)               127.9292626506649
(Previous) Eval Time (s)     27.761176724918187
Sample Time (s)              23.177788485307246
Epoch Time (s)               178.86822786089033
Total Train Time (s)         11983.23627223121
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:07:26.932547 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #66 | Epoch Duration: 178.70517706871033
2020-01-13 08:07:26.932752 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #66 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.8615546
Z variance train             0.0016565906
KL Divergence                74.06086
KL Loss                      7.406086
QF Loss                      315.52966
VF Loss                      223.81673
Policy Loss                  -3051.4963
Q Predictions Mean           3043.034
Q Predictions Std            536.48254
Q Predictions Max            3723.0625
Q Predictions Min            421.60968
V Predictions Mean           3039.7354
V Predictions Std            528.0461
V Predictions Max            3697.3098
V Predictions Min            415.2433
Log Pis Mean                 4.5434227
Log Pis Std                  3.966586
Log Pis Max                  28.513037
Log Pis Min                  -5.5849824
Policy mu Mean               -0.22270137
Policy mu Std                1.3152044
Policy mu Max                5.0367503
Policy mu Min                -3.988746
Policy log std Mean          -0.80430657
Policy log std Std           0.4099555
Policy log std Max           0.1507237
Policy log std Min           -3.2132363
Z mean eval                  4.976413
Z variance eval              0.0018253202
total_rewards                [8612.18039934 8636.69440015 8764.85992041 8877.10347475 8723.37498024
 8678.97165902 8636.91125984 8964.84529271 4978.13821037 8474.98850771]
total_rewards_mean           8334.806810454891
total_rewards_std            1126.5712949544015
total_rewards_max            8964.845292714184
total_rewards_min            4978.13821037383
Number of train steps total  272000
Number of env steps total    342000
Number of rollouts total     0
Train Time (s)               125.06877675186843
(Previous) Eval Time (s)     27.59768818411976
Sample Time (s)              22.425265073776245
Epoch Time (s)               175.09173000976443
Total Train Time (s)         12158.727290404495
Epoch                        67
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:10:22.425627 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #67 | Epoch Duration: 175.49273037910461
2020-01-13 08:10:22.425803 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #67 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.924299
Z variance train             0.0026507992
KL Divergence                74.62145
KL Loss                      7.4621453
QF Loss                      739.5469
VF Loss                      876.24194
Policy Loss                  -3099.9094
Q Predictions Mean           3106.9756
Q Predictions Std            585.32184
Q Predictions Max            3726.853
Q Predictions Min            394.30975
V Predictions Mean           3115.7742
V Predictions Std            578.38043
V Predictions Max            3721.7158
V Predictions Min            425.56485
Log Pis Mean                 4.979582
Log Pis Std                  3.6203728
Log Pis Max                  17.315815
Log Pis Min                  -3.2321448
Policy mu Mean               -0.22603501
Policy mu Std                1.3635781
Policy mu Max                2.8867717
Policy mu Min                -3.3878434
Policy log std Mean          -0.80504274
Policy log std Std           0.4174822
Policy log std Max           0.1298601
Policy log std Min           -2.9519327
Z mean eval                  4.9562488
Z variance eval              0.0011314498
total_rewards                [8720.78686297 8499.72834727 8850.81365007 8614.98664679 8485.07066588
 8770.15412052 8518.59269313 8802.804095   8705.38987237 8781.67287809]
total_rewards_mean           8674.999983210892
total_rewards_std            128.6685157294781
total_rewards_max            8850.813650070662
total_rewards_min            8485.070665884527
Number of train steps total  276000
Number of env steps total    347000
Number of rollouts total     0
Train Time (s)               126.55808382900432
(Previous) Eval Time (s)     27.998335810843855
Sample Time (s)              21.386825560126454
Epoch Time (s)               175.94324519997463
Total Train Time (s)         12335.056958278175
Epoch                        68
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:13:18.755173 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #68 | Epoch Duration: 176.32925415039062
2020-01-13 08:13:18.755331 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #68 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.9565234
Z variance train             0.0011335359
KL Divergence                77.65419
KL Loss                      7.765419
QF Loss                      397.41803
VF Loss                      210.41989
Policy Loss                  -3126.7144
Q Predictions Mean           3127.3735
Q Predictions Std            570.65845
Q Predictions Max            3768.065
Q Predictions Min            400.00684
V Predictions Mean           3133.3596
V Predictions Std            562.6983
V Predictions Max            3766.3342
V Predictions Min            409.95743
Log Pis Mean                 4.279785
Log Pis Std                  3.7596533
Log Pis Max                  17.128819
Log Pis Min                  -5.039361
Policy mu Mean               -0.16507305
Policy mu Std                1.2903209
Policy mu Max                2.8771946
Policy mu Min                -3.1333356
Policy log std Mean          -0.7998689
Policy log std Std           0.38814384
Policy log std Max           0.04670787
Policy log std Min           -2.9172359
Z mean eval                  4.655746
Z variance eval              0.0075351237
total_rewards                [8819.9859555  8965.93543132 8847.70916286 8327.64657348 8622.72016103
 8808.00661938 8234.56419552 8588.25843054 6157.33162558 8793.52821863]
total_rewards_mean           8416.568637382468
total_rewards_std            785.0423071892651
total_rewards_max            8965.935431320708
total_rewards_min            6157.3316255786485
Number of train steps total  280000
Number of env steps total    352000
Number of rollouts total     0
Train Time (s)               133.4200849318877
(Previous) Eval Time (s)     28.38402446685359
Sample Time (s)              22.60063308198005
Epoch Time (s)               184.40474248072132
Total Train Time (s)         12520.337171851192
Epoch                        69
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:16:24.038434 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #69 | Epoch Duration: 185.28298377990723
2020-01-13 08:16:24.038676 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #69 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.65573
Z variance train             0.007505073
KL Divergence                67.714874
KL Loss                      6.7714877
QF Loss                      254.34314
VF Loss                      143.41982
Policy Loss                  -3035.4219
Q Predictions Mean           3036.603
Q Predictions Std            523.4931
Q Predictions Max            3690.1497
Q Predictions Min            355.76608
V Predictions Mean           3030.331
V Predictions Std            516.31696
V Predictions Max            3673.4226
V Predictions Min            349.5423
Log Pis Mean                 4.4087343
Log Pis Std                  3.68077
Log Pis Max                  14.664467
Log Pis Min                  -6.0758123
Policy mu Mean               -0.17890292
Policy mu Std                1.3284725
Policy mu Max                2.8276508
Policy mu Min                -3.0519664
Policy log std Mean          -0.7887003
Policy log std Std           0.4130273
Policy log std Max           -0.000105023384
Policy log std Min           -2.9983225
Z mean eval                  4.5676394
Z variance eval              0.010230911
total_rewards                [8483.55476962 8296.66936636 8262.65820736 8443.83981968 8856.80489264
 8899.69988403 8529.29981192 8614.7255678  8260.26129293 8429.68224318]
total_rewards_mean           8507.71958555216
total_rewards_std            215.4094618935636
total_rewards_max            8899.699884026808
total_rewards_min            8260.261292928179
Number of train steps total  284000
Number of env steps total    357000
Number of rollouts total     0
Train Time (s)               132.26086341682822
(Previous) Eval Time (s)     29.261817943304777
Sample Time (s)              22.87351594120264
Epoch Time (s)               184.39619730133563
Total Train Time (s)         12702.982449773233
Epoch                        70
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:19:26.685847 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #70 | Epoch Duration: 182.64699053764343
2020-01-13 08:19:26.686168 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #70 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.531625
Z variance train             0.015105613
KL Divergence                62.468872
KL Loss                      6.246887
QF Loss                      379.82013
VF Loss                      178.22691
Policy Loss                  -2947.744
Q Predictions Mean           2951.178
Q Predictions Std            606.30695
Q Predictions Max            3729.4324
Q Predictions Min            342.69452
V Predictions Mean           2947.0571
V Predictions Std            604.1956
V Predictions Max            3727.8882
V Predictions Min            332.91168
Log Pis Mean                 4.280775
Log Pis Std                  4.0695033
Log Pis Max                  16.803745
Log Pis Min                  -6.945936
Policy mu Mean               -0.18161422
Policy mu Std                1.3031939
Policy mu Max                2.9954686
Policy mu Min                -3.0419002
Policy log std Mean          -0.795269
Policy log std Std           0.41091698
Policy log std Max           0.19705504
Policy log std Min           -3.1186957
Z mean eval                  4.696352
Z variance eval              0.0012935159
total_rewards                [8582.75918136 8606.34664749 8957.06411555 8993.09243827 8306.69015555
 8977.43302417 8657.72328733 8649.17092442 8799.14678702 8676.4244866 ]
total_rewards_mean           8720.585104775451
total_rewards_std            204.12803670443358
total_rewards_max            8993.092438270325
total_rewards_min            8306.69015554874
Number of train steps total  288000
Number of env steps total    362000
Number of rollouts total     0
Train Time (s)               131.88673154218122
(Previous) Eval Time (s)     27.512242319993675
Sample Time (s)              22.559390482958406
Epoch Time (s)               181.9583643451333
Total Train Time (s)         12886.20628886437
Epoch                        71
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:22:29.911018 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #71 | Epoch Duration: 183.2246720790863
2020-01-13 08:22:29.911259 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #71 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.6184974
Z variance train             0.0029173265
KL Divergence                67.748245
KL Loss                      6.7748246
QF Loss                      343.70886
VF Loss                      208.74295
Policy Loss                  -3040.2676
Q Predictions Mean           3034.8638
Q Predictions Std            609.2816
Q Predictions Max            3743.897
Q Predictions Min            313.23755
V Predictions Mean           3033.107
V Predictions Std            607.26056
V Predictions Max            3753.5508
V Predictions Min            304.5158
Log Pis Mean                 4.1587095
Log Pis Std                  3.802006
Log Pis Max                  16.298756
Log Pis Min                  -7.277996
Policy mu Mean               -0.20753324
Policy mu Std                1.2981234
Policy mu Max                4.2304068
Policy mu Min                -2.6737318
Policy log std Mean          -0.786683
Policy log std Std           0.41285002
Policy log std Max           0.16211224
Policy log std Min           -3.054181
Z mean eval                  4.607639
Z variance eval              0.0043062344
total_rewards                [8874.50656585 8787.64007763 8815.02143949 8977.43322987 8772.78852036
 8868.05040468 8984.42444493 8772.41844031 8281.68543101 8459.78097343]
total_rewards_mean           8759.37495275591
total_rewards_std            211.05725884261034
total_rewards_max            8984.424444930086
total_rewards_min            8281.68543100703
Number of train steps total  292000
Number of env steps total    367000
Number of rollouts total     0
Train Time (s)               132.90216265898198
(Previous) Eval Time (s)     28.77821715408936
Sample Time (s)              23.471243362873793
Epoch Time (s)               185.15162317594513
Total Train Time (s)         13071.038168592378
Epoch                        72
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:25:34.743012 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #72 | Epoch Duration: 184.83163142204285
2020-01-13 08:25:34.743129 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #72 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.627799
Z variance train             0.0031263027
KL Divergence                70.983604
KL Loss                      7.0983605
QF Loss                      383.84778
VF Loss                      125.43919
Policy Loss                  -3139.1396
Q Predictions Mean           3137.6008
Q Predictions Std            511.17123
Q Predictions Max            3798.2405
Q Predictions Min            318.2698
V Predictions Mean           3139.372
V Predictions Std            504.1115
V Predictions Max            3794.9924
V Predictions Min            326.11984
Log Pis Mean                 4.80915
Log Pis Std                  3.6060238
Log Pis Max                  14.707764
Log Pis Min                  -2.8070116
Policy mu Mean               -0.2248108
Policy mu Std                1.3458599
Policy mu Max                2.8533478
Policy mu Min                -2.792532
Policy log std Mean          -0.8045972
Policy log std Std           0.42445427
Policy log std Max           0.061629534
Policy log std Min           -3.0906606
Z mean eval                  4.6127024
Z variance eval              0.0028747623
total_rewards                [8940.2309631  9221.29603641 9015.55079948 9394.69704568 8917.7153002
 9171.62354716 8634.76623244 8783.68479929 9020.48261751 8863.36715289]
total_rewards_mean           8996.341449416472
total_rewards_std            210.69871051650713
total_rewards_max            9394.69704568181
total_rewards_min            8634.766232436345
Number of train steps total  296000
Number of env steps total    372000
Number of rollouts total     0
Train Time (s)               127.62952772015706
(Previous) Eval Time (s)     28.457918826956302
Sample Time (s)              23.45896413223818
Epoch Time (s)               179.54641067935154
Total Train Time (s)         13250.356568559539
Epoch                        73
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:28:34.064143 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #73 | Epoch Duration: 179.32090497016907
2020-01-13 08:28:34.064324 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #73 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.6135736
Z variance train             0.002896437
KL Divergence                68.51015
KL Loss                      6.8510146
QF Loss                      333.8465
VF Loss                      142.21646
Policy Loss                  -3127.1414
Q Predictions Mean           3129.2737
Q Predictions Std            555.9776
Q Predictions Max            3731.2288
Q Predictions Min            317.1713
V Predictions Mean           3126.1606
V Predictions Std            553.45917
V Predictions Max            3724.5923
V Predictions Min            298.615
Log Pis Mean                 4.981517
Log Pis Std                  3.7809837
Log Pis Max                  14.2521
Log Pis Min                  -6.4354467
Policy mu Mean               -0.18670858
Policy mu Std                1.3666313
Policy mu Max                2.8340065
Policy mu Min                -3.0836504
Policy log std Mean          -0.78808004
Policy log std Std           0.39919823
Policy log std Max           -0.0044201612
Policy log std Min           -3.0479116
Z mean eval                  4.5412436
Z variance eval              0.0018751379
total_rewards                [8818.54693805 8788.60101963 8971.8992529  8829.46902056 9316.91456353
 8892.66078128 7193.72239958 8809.26444112 9173.24498891 8967.9974618 ]
total_rewards_mean           8776.232086735432
total_rewards_std            552.1573851487803
total_rewards_max            9316.914563526258
total_rewards_min            7193.722399581276
Number of train steps total  300000
Number of env steps total    377000
Number of rollouts total     0
Train Time (s)               125.66642750008032
(Previous) Eval Time (s)     28.232032511848956
Sample Time (s)              22.182379654143006
Epoch Time (s)               176.08083966607228
Total Train Time (s)         13424.868036698084
Epoch                        74
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:31:28.576038 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #74 | Epoch Duration: 174.5115978717804
2020-01-13 08:31:28.576158 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #74 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.544152
Z variance train             0.0018741839
KL Divergence                67.16718
KL Loss                      6.716718
QF Loss                      320.04175
VF Loss                      260.8922
Policy Loss                  -3067.7974
Q Predictions Mean           3065.7258
Q Predictions Std            651.90234
Q Predictions Max            3781.8474
Q Predictions Min            287.7528
V Predictions Mean           3057.1504
V Predictions Std            645.06195
V Predictions Max            3776.5427
V Predictions Min            274.5775
Log Pis Mean                 4.1582623
Log Pis Std                  3.7666352
Log Pis Max                  16.999905
Log Pis Min                  -5.4947844
Policy mu Mean               -0.25501764
Policy mu Std                1.2968422
Policy mu Max                3.3299274
Policy mu Min                -4.6079845
Policy log std Mean          -0.79963017
Policy log std Std           0.40044785
Policy log std Max           0.16728342
Policy log std Min           -2.9809594
Z mean eval                  4.5320625
Z variance eval              0.004011242
total_rewards                [8079.39542819 8672.40598485 8820.19788597 8681.85371005 8481.64972311
 7843.97122592 9022.4072441  8641.25588773 8402.10334399 8492.26584969]
total_rewards_mean           8513.750628358519
total_rewards_std            327.6515377046815
total_rewards_max            9022.407244100274
total_rewards_min            7843.971225917825
Number of train steps total  304000
Number of env steps total    382000
Number of rollouts total     0
Train Time (s)               126.83097609691322
(Previous) Eval Time (s)     26.662404865957797
Sample Time (s)              21.1673315721564
Epoch Time (s)               174.66071253502741
Total Train Time (s)         13601.25746855652
Epoch                        75
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:34:24.968843 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #75 | Epoch Duration: 176.39253950119019
2020-01-13 08:34:24.969207 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #75 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.528167
Z variance train             0.004014621
KL Divergence                64.48695
KL Loss                      6.4486957
QF Loss                      439.34158
VF Loss                      197.44888
Policy Loss                  -3103.5413
Q Predictions Mean           3107.2646
Q Predictions Std            573.7078
Q Predictions Max            3803.658
Q Predictions Min            260.78992
V Predictions Mean           3111.4026
V Predictions Std            566.2822
V Predictions Max            3787.415
V Predictions Min            260.5708
Log Pis Mean                 4.349223
Log Pis Std                  3.9016194
Log Pis Max                  15.294027
Log Pis Min                  -4.341483
Policy mu Mean               -0.2346478
Policy mu Std                1.308714
Policy mu Max                3.2260828
Policy mu Min                -2.9572687
Policy log std Mean          -0.7950814
Policy log std Std           0.40319526
Policy log std Max           0.09663439
Policy log std Min           -3.053862
Z mean eval                  4.534758
Z variance eval              0.0045419945
total_rewards                [8936.99288667 9002.01433325 8815.68999189 8638.91916869 8859.45164154
 8989.29059663 9143.32139982 8912.19467403 9058.26002953 8834.88079944]
total_rewards_mean           8919.101552146603
total_rewards_std            134.779755077205
total_rewards_max            9143.321399816934
total_rewards_min            8638.919168685048
Number of train steps total  308000
Number of env steps total    387000
Number of rollouts total     0
Train Time (s)               133.80378579720855
(Previous) Eval Time (s)     28.39385389816016
Sample Time (s)              22.871452586259693
Epoch Time (s)               185.0690922816284
Total Train Time (s)         13785.549550652038
Epoch                        76
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:37:29.261939 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #76 | Epoch Duration: 184.29250264167786
2020-01-13 08:37:29.262143 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #76 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.335687
Z variance train             0.004864622
KL Divergence                60.845703
KL Loss                      6.0845704
QF Loss                      329.0802
VF Loss                      195.60011
Policy Loss                  -3088.0212
Q Predictions Mean           3084.2158
Q Predictions Std            630.9181
Q Predictions Max            3805.0017
Q Predictions Min            264.17743
V Predictions Mean           3082.7793
V Predictions Std            625.86774
V Predictions Max            3805.6863
V Predictions Min            266.15237
Log Pis Mean                 4.6358194
Log Pis Std                  3.7151704
Log Pis Max                  16.392267
Log Pis Min                  -9.603733
Policy mu Mean               -0.19558962
Policy mu Std                1.3572478
Policy mu Max                3.702754
Policy mu Min                -2.9542434
Policy log std Mean          -0.7879862
Policy log std Std           0.4209628
Policy log std Max           0.06887245
Policy log std Min           -3.1273448
Z mean eval                  4.3930025
Z variance eval              0.002388372
total_rewards                [8269.06196553 8555.07599405 8436.05193032 8507.42609322 8699.21556843
 8309.30463368 8827.41325192 8459.37785819 8649.69646118 8874.64460531]
total_rewards_mean           8558.726836184778
total_rewards_std            193.31078672302917
total_rewards_max            8874.644605311722
total_rewards_min            8269.06196553361
Number of train steps total  312000
Number of env steps total    392000
Number of rollouts total     0
Train Time (s)               132.35175290331244
(Previous) Eval Time (s)     27.616905617062002
Sample Time (s)              22.424512377474457
Epoch Time (s)               182.3931708978489
Total Train Time (s)         13968.946128548123
Epoch                        77
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:40:32.658831 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #77 | Epoch Duration: 183.39656591415405
2020-01-13 08:40:32.658946 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.392553
Z variance train             0.0023864233
KL Divergence                63.35706
KL Loss                      6.335706
QF Loss                      360.73767
VF Loss                      231.10927
Policy Loss                  -3232.055
Q Predictions Mean           3236.0542
Q Predictions Std            476.8605
Q Predictions Max            3899.7478
Q Predictions Min            262.02448
V Predictions Mean           3239.1104
V Predictions Std            471.42914
V Predictions Max            3869.349
V Predictions Min            297.3832
Log Pis Mean                 4.8838043
Log Pis Std                  3.2941108
Log Pis Max                  13.600811
Log Pis Min                  -2.7962441
Policy mu Mean               -0.14693712
Policy mu Std                1.3361763
Policy mu Max                3.0775626
Policy mu Min                -2.683378
Policy log std Mean          -0.79850197
Policy log std Std           0.40129575
Policy log std Max           0.104843855
Policy log std Min           -3.1371593
Z mean eval                  4.40778
Z variance eval              0.0014199972
total_rewards                [8783.32251249 8980.69890754 8971.3039254  8824.62526547 8811.59965071
 8658.21254462 8871.45608121 8933.67683415 8754.9668233  8656.10673683]
total_rewards_mean           8824.59692817304
total_rewards_std            110.80547987334806
total_rewards_max            8980.698907542792
total_rewards_min            8656.106736832486
Number of train steps total  316000
Number of env steps total    397000
Number of rollouts total     0
Train Time (s)               132.1341349799186
(Previous) Eval Time (s)     28.619925318751484
Sample Time (s)              22.684521184302866
Epoch Time (s)               183.43858148297295
Total Train Time (s)         14152.249249810353
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:43:35.964801 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #78 | Epoch Duration: 183.30575037002563
2020-01-13 08:43:35.964992 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.4082747
Z variance train             0.0014216725
KL Divergence                63.86139
KL Loss                      6.386139
QF Loss                      531.5808
VF Loss                      134.6705
Policy Loss                  -3184.993
Q Predictions Mean           3190.7017
Q Predictions Std            579.1824
Q Predictions Max            3873.7554
Q Predictions Min            261.88123
V Predictions Mean           3190.739
V Predictions Std            573.8764
V Predictions Max            3866.5225
V Predictions Min            281.42337
Log Pis Mean                 4.932661
Log Pis Std                  3.417538
Log Pis Max                  13.224075
Log Pis Min                  -6.740942
Policy mu Mean               -0.2320258
Policy mu Std                1.3635553
Policy mu Max                3.0576317
Policy mu Min                -2.7698781
Policy log std Mean          -0.7908614
Policy log std Std           0.4176402
Policy log std Max           -0.08990902
Policy log std Min           -2.8986633
Z mean eval                  4.386775
Z variance eval              0.0020131683
total_rewards                [9033.98468053 9252.90076641 9321.48477132 9087.67971092 9190.10028908
 9131.9304017  8918.18605567 8796.18533397 9083.54716943 9245.12696242]
total_rewards_mean           9106.112614144546
total_rewards_std            152.4467529526222
total_rewards_max            9321.4847713229
total_rewards_min            8796.185333966205
Number of train steps total  320000
Number of env steps total    402000
Number of rollouts total     0
Train Time (s)               131.87925387592986
(Previous) Eval Time (s)     28.48671645205468
Sample Time (s)              21.96107752621174
Epoch Time (s)               182.32704785419628
Total Train Time (s)         14334.056756286882
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:46:37.774506 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #79 | Epoch Duration: 181.8093400001526
2020-01-13 08:46:37.774830 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #79 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.385272
Z variance train             0.0020322115
KL Divergence                64.01684
KL Loss                      6.401684
QF Loss                      301.22388
VF Loss                      376.60535
Policy Loss                  -3164.545
Q Predictions Mean           3165.2554
Q Predictions Std            647.56177
Q Predictions Max            3845.7737
Q Predictions Min            248.99721
V Predictions Mean           3151.9043
V Predictions Std            640.40295
V Predictions Max            3821.5933
V Predictions Min            246.16675
Log Pis Mean                 4.338442
Log Pis Std                  3.7407913
Log Pis Max                  13.098749
Log Pis Min                  -5.47559
Policy mu Mean               -0.21995707
Policy mu Std                1.2832711
Policy mu Max                3.0695682
Policy mu Min                -2.813689
Policy log std Mean          -0.8304782
Policy log std Std           0.4191825
Policy log std Max           -0.06693232
Policy log std Min           -2.9567246
Z mean eval                  4.377904
Z variance eval              0.0013186485
total_rewards                [8902.51730837 8747.58952727 8697.9729437  8691.02050869 8690.10567447
 8600.07084636 8840.61271643 8534.11898379 8740.45929386 8605.06475336]
total_rewards_mean           8704.95325562934
total_rewards_std            105.42260317528196
total_rewards_max            8902.517308367957
total_rewards_min            8534.118983793443
Number of train steps total  324000
Number of env steps total    407000
Number of rollouts total     0
Train Time (s)               128.0479786200449
(Previous) Eval Time (s)     27.968616320751607
Sample Time (s)              22.928351339884102
Epoch Time (s)               178.9449462806806
Total Train Time (s)         14513.123747770209
Epoch                        80
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:49:36.846735 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #80 | Epoch Duration: 179.07168245315552
2020-01-13 08:49:36.847141 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #80 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.350086
Z variance train             0.0012017217
KL Divergence                63.595062
KL Loss                      6.359506
QF Loss                      484.88818
VF Loss                      213.22083
Policy Loss                  -3179.1736
Q Predictions Mean           3178.1519
Q Predictions Std            620.12494
Q Predictions Max            3848.9233
Q Predictions Min            238.3488
V Predictions Mean           3173.8008
V Predictions Std            614.3065
V Predictions Max            3845.0586
V Predictions Min            228.574
Log Pis Mean                 4.8629513
Log Pis Std                  3.735241
Log Pis Max                  14.30586
Log Pis Min                  -3.228425
Policy mu Mean               -0.25050297
Policy mu Std                1.3221279
Policy mu Max                2.7047415
Policy mu Min                -3.0008118
Policy log std Mean          -0.8042283
Policy log std Std           0.40367535
Policy log std Max           0.0070618987
Policy log std Min           -3.045741
Z mean eval                  4.3378367
Z variance eval              0.00096159463
total_rewards                [8967.3677356  9114.96536901 9292.66874828 9091.76591405 9170.87095133
 9241.45546888 9375.47992655 9235.19760314 9191.74929621 9111.43770388]
total_rewards_mean           9179.295871693012
total_rewards_std            109.4872830771152
total_rewards_max            9375.479926548694
total_rewards_min            8967.367735601603
Number of train steps total  328000
Number of env steps total    412000
Number of rollouts total     0
Train Time (s)               124.89635625807568
(Previous) Eval Time (s)     28.09492342406884
Sample Time (s)              22.50604216940701
Epoch Time (s)               175.49732185155153
Total Train Time (s)         14688.818035913631
Epoch                        81
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:52:32.539249 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #81 | Epoch Duration: 175.6917746067047
2020-01-13 08:52:32.539444 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #81 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.3265924
Z variance train             0.0010693287
KL Divergence                63.251297
KL Loss                      6.32513
QF Loss                      506.22308
VF Loss                      223.36899
Policy Loss                  -3143.422
Q Predictions Mean           3148.0583
Q Predictions Std            674.6445
Q Predictions Max            3919.8062
Q Predictions Min            228.64468
V Predictions Mean           3145.9736
V Predictions Std            671.3218
V Predictions Max            3885.597
V Predictions Min            235.97478
Log Pis Mean                 4.7353516
Log Pis Std                  3.6070747
Log Pis Max                  18.544365
Log Pis Min                  -3.4464192
Policy mu Mean               -0.20434916
Policy mu Std                1.3469135
Policy mu Max                3.3939855
Policy mu Min                -3.1321104
Policy log std Mean          -0.7994773
Policy log std Std           0.41965517
Policy log std Max           0.22043931
Policy log std Min           -3.0972083
Z mean eval                  4.1182194
Z variance eval              0.0010611529
total_rewards                [9105.17290488 3698.95314551 8756.4788248  8824.93845308 8832.21437989
 8901.53700419 8981.46655363 9238.30357935 9056.63739398 9436.2154822 ]
total_rewards_mean           8483.191772151064
total_rewards_std            1606.8500726388713
total_rewards_max            9436.215482200943
total_rewards_min            3698.953145511315
Number of train steps total  332000
Number of env steps total    417000
Number of rollouts total     0
Train Time (s)               127.40553108463064
(Previous) Eval Time (s)     28.288983006961644
Sample Time (s)              22.2095674299635
Epoch Time (s)               177.90408152155578
Total Train Time (s)         14866.681584910955
Epoch                        82
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:55:30.404628 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #82 | Epoch Duration: 177.86504340171814
2020-01-13 08:55:30.404819 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #82 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.114473
Z variance train             0.0010945383
KL Divergence                58.142067
KL Loss                      5.8142066
QF Loss                      435.30774
VF Loss                      190.64308
Policy Loss                  -3151.3665
Q Predictions Mean           3153.1016
Q Predictions Std            603.6979
Q Predictions Max            3845.4336
Q Predictions Min            193.14853
V Predictions Mean           3160.3145
V Predictions Std            602.37805
V Predictions Max            3848.8076
V Predictions Min            207.51016
Log Pis Mean                 4.5712633
Log Pis Std                  3.9914396
Log Pis Max                  16.385029
Log Pis Min                  -4.9357977
Policy mu Mean               -0.22355843
Policy mu Std                1.3110437
Policy mu Max                2.6962771
Policy mu Min                -2.7735636
Policy log std Mean          -0.7955262
Policy log std Std           0.40823117
Policy log std Max           0.20150936
Policy log std Min           -2.9328804
Z mean eval                  4.1947036
Z variance eval              0.00059469824
total_rewards                [9277.58549512 9297.5803467  9132.36415338 8829.16231794 9169.96558633
 9365.16793888 9190.11382752 9326.02346334 9202.50858981 9223.77659311]
total_rewards_mean           9201.424831213177
total_rewards_std            142.24981863391085
total_rewards_max            9365.167938878689
total_rewards_min            8829.162317944483
Number of train steps total  336000
Number of env steps total    422000
Number of rollouts total     0
Train Time (s)               133.43195722158998
(Previous) Eval Time (s)     28.249599159229547
Sample Time (s)              22.60166082298383
Epoch Time (s)               184.28321720380336
Total Train Time (s)         15052.27593638841
Epoch                        83
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:58:36.000791 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #83 | Epoch Duration: 185.5958333015442
2020-01-13 08:58:36.000981 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1991987
Z variance train             0.0005688486
KL Divergence                61.0489
KL Loss                      6.1048903
QF Loss                      291.8236
VF Loss                      118.982376
Policy Loss                  -3127.1106
Q Predictions Mean           3123.538
Q Predictions Std            679.76733
Q Predictions Max            3864.5195
Q Predictions Min            185.22824
V Predictions Mean           3131.6738
V Predictions Std            674.77216
V Predictions Max            3859.2488
V Predictions Min            214.3381
Log Pis Mean                 4.6480293
Log Pis Std                  3.8294358
Log Pis Max                  14.126593
Log Pis Min                  -3.7111635
Policy mu Mean               -0.2391743
Policy mu Std                1.3275514
Policy mu Max                3.3286848
Policy mu Min                -3.0615883
Policy log std Mean          -0.8037259
Policy log std Std           0.40066075
Policy log std Max           -0.10190362
Policy log std Min           -3.0237706
Z mean eval                  4.2582445
Z variance eval              0.0013670253
total_rewards                [9336.37399358 9397.92685548 9324.29504415 9293.90046916 9211.03466239
 9208.07107219 9376.95354663 9526.34963729 9148.31000796 9412.63902404]
total_rewards_mean           9323.585431287453
total_rewards_std            107.32969454721166
total_rewards_max            9526.349637287954
total_rewards_min            9148.310007960588
Number of train steps total  340000
Number of env steps total    427000
Number of rollouts total     0
Train Time (s)               131.87652385793626
(Previous) Eval Time (s)     29.561870905105025
Sample Time (s)              21.290298308245838
Epoch Time (s)               182.72869307128713
Total Train Time (s)         15232.549700662028
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:01:36.277283 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #84 | Epoch Duration: 180.2761332988739
2020-01-13 09:01:36.277598 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #84 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2466836
Z variance train             0.0016184527
KL Divergence                60.437386
KL Loss                      6.043739
QF Loss                      266.11227
VF Loss                      181.92657
Policy Loss                  -3243.748
Q Predictions Mean           3244.6238
Q Predictions Std            664.94
Q Predictions Max            3915.0537
Q Predictions Min            205.17787
V Predictions Mean           3251.188
V Predictions Std            661.8764
V Predictions Max            3903.2805
V Predictions Min            209.71362
Log Pis Mean                 4.893407
Log Pis Std                  3.8599324
Log Pis Max                  22.914513
Log Pis Min                  -5.5387177
Policy mu Mean               -0.18215342
Policy mu Std                1.3914977
Policy mu Max                3.4065938
Policy mu Min                -5.225232
Policy log std Mean          -0.796693
Policy log std Std           0.42353746
Policy log std Max           0.016124845
Policy log std Min           -3.144209
Z mean eval                  4.2431135
Z variance eval              0.0039134165
total_rewards                [9238.77907375 9589.26750858 9509.44427545 9568.77081357 9506.89980506
 9566.85047496 9326.27393713 9709.51622562 9433.90060751 9512.04850952]
total_rewards_mean           9496.175123114224
total_rewards_std            128.05704432236084
total_rewards_max            9709.516225620608
total_rewards_min            9238.779073747493
Number of train steps total  344000
Number of env steps total    432000
Number of rollouts total     0
Train Time (s)               131.2120385277085
(Previous) Eval Time (s)     27.108961118850857
Sample Time (s)              22.155757036525756
Epoch Time (s)               180.4767566830851
Total Train Time (s)         15415.105972137768
Epoch                        85
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:04:38.833643 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #85 | Epoch Duration: 182.5558865070343
2020-01-13 09:04:38.833770 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #85 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2373624
Z variance train             0.0040450366
KL Divergence                58.917496
KL Loss                      5.89175
QF Loss                      417.39157
VF Loss                      232.5984
Policy Loss                  -3151.0686
Q Predictions Mean           3150.636
Q Predictions Std            753.4452
Q Predictions Max            4024.265
Q Predictions Min            194.67506
V Predictions Mean           3159.1003
V Predictions Std            748.4291
V Predictions Max            3996.5857
V Predictions Min            204.89682
Log Pis Mean                 4.471898
Log Pis Std                  3.925524
Log Pis Max                  15.333836
Log Pis Min                  -5.990817
Policy mu Mean               -0.20062809
Policy mu Std                1.288779
Policy mu Max                3.4062524
Policy mu Min                -3.4609458
Policy log std Mean          -0.8277302
Policy log std Std           0.43371928
Policy log std Max           0.13979888
Policy log std Min           -3.1608133
Z mean eval                  4.3328934
Z variance eval              0.0011760422
total_rewards                [9174.93425826 9535.36904436 9305.42663432 9371.10686903 9183.2178926
 9374.93852908 9064.21082439 9352.10260251 9427.8489569  9237.77769329]
total_rewards_mean           9302.69333047239
total_rewards_std            131.84655975702543
total_rewards_max            9535.369044358065
total_rewards_min            9064.210824393915
Number of train steps total  348000
Number of env steps total    437000
Number of rollouts total     0
Train Time (s)               132.82809175690636
(Previous) Eval Time (s)     29.1877611130476
Sample Time (s)              22.48569788923487
Epoch Time (s)               184.50155075918883
Total Train Time (s)         15599.36365357181
Epoch                        86
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:07:43.093859 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #86 | Epoch Duration: 184.25999069213867
2020-01-13 09:07:43.094039 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #86 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.3248224
Z variance train             0.0011616686
KL Divergence                62.58232
KL Loss                      6.258232
QF Loss                      347.28735
VF Loss                      224.76749
Policy Loss                  -3361.6829
Q Predictions Mean           3362.5898
Q Predictions Std            501.43588
Q Predictions Max            4011.2073
Q Predictions Min            203.76631
V Predictions Mean           3370.12
V Predictions Std            495.99484
V Predictions Max            4023.4243
V Predictions Min            225.44656
Log Pis Mean                 4.800463
Log Pis Std                  3.577114
Log Pis Max                  14.491385
Log Pis Min                  -5.190125
Policy mu Mean               -0.16939759
Policy mu Std                1.3530377
Policy mu Max                2.813226
Policy mu Min                -2.736352
Policy log std Mean          -0.8297243
Policy log std Std           0.43234307
Policy log std Max           -0.22359163
Policy log std Min           -3.18752
Z mean eval                  4.2164006
Z variance eval              0.0019751408
total_rewards                [8725.97561538 9072.64426484 9568.06626884 9205.55301116 8506.22897769
 9006.43676086 9387.11751593 8941.06328327 9586.95814832 9678.73614387]
total_rewards_mean           9167.87799901616
total_rewards_std            369.5774663323586
total_rewards_max            9678.736143872708
total_rewards_min            8506.228977685345
Number of train steps total  352000
Number of env steps total    442000
Number of rollouts total     0
Train Time (s)               129.6162635772489
(Previous) Eval Time (s)     28.945874540135264
Sample Time (s)              23.111089711543173
Epoch Time (s)               181.67322782892734
Total Train Time (s)         15777.331223567482
Epoch                        87
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:10:41.063363 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #87 | Epoch Duration: 177.96918487548828
2020-01-13 09:10:41.063563 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2186522
Z variance train             0.001960031
KL Divergence                59.17098
KL Loss                      5.917098
QF Loss                      333.05267
VF Loss                      134.17642
Policy Loss                  -3282.7747
Q Predictions Mean           3284.5586
Q Predictions Std            646.0852
Q Predictions Max            4065.5642
Q Predictions Min            210.63321
V Predictions Mean           3280.423
V Predictions Std            642.7227
V Predictions Max            4058.5237
V Predictions Min            209.82555
Log Pis Mean                 4.9470596
Log Pis Std                  3.648111
Log Pis Max                  14.835518
Log Pis Min                  -4.736827
Policy mu Mean               -0.21017577
Policy mu Std                1.3413514
Policy mu Max                3.0281606
Policy mu Min                -2.8936877
Policy log std Mean          -0.81051844
Policy log std Std           0.40958467
Policy log std Max           -0.0085353255
Policy log std Min           -3.1330514
Z mean eval                  4.2301
Z variance eval              0.0016906597
total_rewards                [9413.00778074 9417.70548735 9381.03762811 9434.46309    9577.97822396
 9425.29169912 9437.99110056 9504.93167991 9330.72320002 9235.6384035 ]
total_rewards_mean           9415.876829327377
total_rewards_std            87.23137881856847
total_rewards_max            9577.978223960181
total_rewards_min            9235.638403496223
Number of train steps total  356000
Number of env steps total    447000
Number of rollouts total     0
Train Time (s)               125.57788266520947
(Previous) Eval Time (s)     25.241514859721065
Sample Time (s)              22.216113133355975
Epoch Time (s)               173.0355106582865
Total Train Time (s)         15952.933321595658
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:13:36.667612 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #88 | Epoch Duration: 175.6038920879364
2020-01-13 09:13:36.667893 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #88 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2134247
Z variance train             0.0023809536
KL Divergence                59.898964
KL Loss                      5.9898963
QF Loss                      754.2267
VF Loss                      205.64088
Policy Loss                  -3251.668
Q Predictions Mean           3262.3489
Q Predictions Std            729.41046
Q Predictions Max            4044.4136
Q Predictions Min            196.7179
V Predictions Mean           3256.4314
V Predictions Std            723.4112
V Predictions Max            4047.3228
V Predictions Min            218.85909
Log Pis Mean                 4.5860934
Log Pis Std                  3.8416367
Log Pis Max                  16.957983
Log Pis Min                  -6.7019277
Policy mu Mean               -0.19979824
Policy mu Std                1.3116693
Policy mu Max                3.0264761
Policy mu Min                -3.274552
Policy log std Mean          -0.81402475
Policy log std Std           0.40580913
Policy log std Max           0.034369826
Policy log std Min           -3.0454104
Z mean eval                  4.1425686
Z variance eval              0.0053036776
total_rewards                [9655.16336648 9722.75973291 9828.5253173  8054.5201933  9831.92211646
 9793.57009585 9619.24576051 9528.45910797 9608.41580722 9735.86851857]
total_rewards_mean           9537.845001656655
total_rewards_std            503.5363932414392
total_rewards_max            9831.922116460262
total_rewards_min            8054.520193301192
Number of train steps total  360000
Number of env steps total    452000
Number of rollouts total     0
Train Time (s)               125.80993436696008
(Previous) Eval Time (s)     27.809551286976784
Sample Time (s)              22.03291506320238
Epoch Time (s)               175.65240071713924
Total Train Time (s)         16129.059781727381
Epoch                        89
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:16:32.795718 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #89 | Epoch Duration: 176.1276617050171
2020-01-13 09:16:32.795904 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #89 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1436043
Z variance train             0.0055097146
KL Divergence                57.08989
KL Loss                      5.708989
QF Loss                      763.57007
VF Loss                      401.49554
Policy Loss                  -3298.822
Q Predictions Mean           3297.0225
Q Predictions Std            579.30975
Q Predictions Max            4066.0535
Q Predictions Min            212.0442
V Predictions Mean           3282.7021
V Predictions Std            568.6651
V Predictions Max            4042.6277
V Predictions Min            212.93808
Log Pis Mean                 4.845907
Log Pis Std                  3.9084766
Log Pis Max                  15.429817
Log Pis Min                  -7.5633802
Policy mu Mean               -0.21787243
Policy mu Std                1.3520814
Policy mu Max                2.8270938
Policy mu Min                -4.0021453
Policy log std Mean          -0.834419
Policy log std Std           0.40972254
Policy log std Max           -0.087714076
Policy log std Min           -3.0897694
Z mean eval                  4.245582
Z variance eval              0.0043912064
total_rewards                [9504.77829842 9757.77370429 9798.00736144 9754.64630164 9738.14273995
 9751.06239889 9355.26199447 9809.65323344 9602.88727576 9749.19059738]
total_rewards_mean           9682.140390568971
total_rewards_std            140.58174692819958
total_rewards_max            9809.653233439612
total_rewards_min            9355.261994474875
Number of train steps total  364000
Number of env steps total    457000
Number of rollouts total     0
Train Time (s)               131.76995726302266
(Previous) Eval Time (s)     28.284503024071455
Sample Time (s)              22.9178291647695
Epoch Time (s)               182.97228945186362
Total Train Time (s)         16311.882927137893
Epoch                        90
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:19:35.621063 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #90 | Epoch Duration: 182.82499384880066
2020-01-13 09:19:35.621337 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #90 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2436647
Z variance train             0.0043637888
KL Divergence                59.63336
KL Loss                      5.9633365
QF Loss                      514.6864
VF Loss                      165.38696
Policy Loss                  -3340.948
Q Predictions Mean           3344.1958
Q Predictions Std            660.64215
Q Predictions Max            4117.06
Q Predictions Min            192.40031
V Predictions Mean           3344.731
V Predictions Std            654.38605
V Predictions Max            4116.005
V Predictions Min            207.55789
Log Pis Mean                 4.742959
Log Pis Std                  3.8629758
Log Pis Max                  15.80952
Log Pis Min                  -5.7628036
Policy mu Mean               -0.1992373
Policy mu Std                1.3529391
Policy mu Max                3.3413992
Policy mu Min                -2.9627879
Policy log std Mean          -0.82022256
Policy log std Std           0.42740443
Policy log std Max           -0.03831935
Policy log std Min           -3.0195088
Z mean eval                  4.216512
Z variance eval              0.0029717032
total_rewards                [9366.65591075 8794.84906451 9277.07520708 9173.21024812 9163.48366514
 9438.12008545 9535.27135703 8892.04616149 9435.04607295 9448.70907645]
total_rewards_mean           9252.446684896597
total_rewards_std            235.2558463282671
total_rewards_max            9535.271357026892
total_rewards_min            8794.849064511598
Number of train steps total  368000
Number of env steps total    462000
Number of rollouts total     0
Train Time (s)               131.9591387170367
(Previous) Eval Time (s)     28.13682090025395
Sample Time (s)              22.096608455758542
Epoch Time (s)               182.1925680730492
Total Train Time (s)         16494.666092271917
Epoch                        91
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:22:38.405415 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #91 | Epoch Duration: 182.78391981124878
2020-01-13 09:22:38.405684 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #91 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1963534
Z variance train             0.0030793636
KL Divergence                58.096428
KL Loss                      5.809643
QF Loss                      392.8606
VF Loss                      137.34369
Policy Loss                  -3382.6497
Q Predictions Mean           3387.4822
Q Predictions Std            637.52856
Q Predictions Max            4095.707
Q Predictions Min            185.20189
V Predictions Mean           3389.5767
V Predictions Std            634.4478
V Predictions Max            4095.3582
V Predictions Min            188.22447
Log Pis Mean                 4.7140555
Log Pis Std                  3.8514273
Log Pis Max                  15.908123
Log Pis Min                  -5.7288136
Policy mu Mean               -0.22430582
Policy mu Std                1.3531857
Policy mu Max                2.8278375
Policy mu Min                -2.8666487
Policy log std Mean          -0.81817913
Policy log std Std           0.424647
Policy log std Max           0.012949705
Policy log std Min           -3.055278
Z mean eval                  4.046065
Z variance eval              0.0015833369
total_rewards                [9535.27563593 9766.06680732 9409.19027245 9628.37894701 9703.88394219
 9717.23206363 9646.976206   9893.54509993 9571.55169686 9638.0710511 ]
total_rewards_mean           9651.017172242431
total_rewards_std            125.74699066588379
total_rewards_max            9893.545099928699
total_rewards_min            9409.19027245213
Number of train steps total  372000
Number of env steps total    467000
Number of rollouts total     0
Train Time (s)               132.25348411407322
(Previous) Eval Time (s)     28.727822793181986
Sample Time (s)              23.50584598677233
Epoch Time (s)               184.48715289402753
Total Train Time (s)         16679.563241257332
Epoch                        92
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:25:43.304426 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #92 | Epoch Duration: 184.89854669570923
2020-01-13 09:25:43.304651 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #92 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.0463862
Z variance train             0.001584419
KL Divergence                55.358192
KL Loss                      5.5358195
QF Loss                      325.6584
VF Loss                      135.61577
Policy Loss                  -3360.5696
Q Predictions Mean           3358.8303
Q Predictions Std            450.9842
Q Predictions Max            4125.282
Q Predictions Min            186.24396
V Predictions Mean           3356.0386
V Predictions Std            445.62833
V Predictions Max            4123.4097
V Predictions Min            183.19798
Log Pis Mean                 4.7816825
Log Pis Std                  3.4874513
Log Pis Max                  14.410654
Log Pis Min                  -4.5326843
Policy mu Mean               -0.26128408
Policy mu Std                1.3287342
Policy mu Max                2.9734757
Policy mu Min                -3.2132049
Policy log std Mean          -0.85179067
Policy log std Std           0.44357368
Policy log std Max           0.031066656
Policy log std Min           -3.1135664
Z mean eval                  4.143338
Z variance eval              0.0011620997
total_rewards                [ 9503.40380187  9839.76312677  9724.51073878 10073.4149183
  9826.21403865  9683.7545336   9725.98103806  9732.02595314
  9859.99677939  9776.37918932]
total_rewards_mean           9774.544411787663
total_rewards_std            138.55753522464508
total_rewards_max            10073.414918296387
total_rewards_min            9503.403801874407
Number of train steps total  376000
Number of env steps total    472000
Number of rollouts total     0
Train Time (s)               133.7442728341557
(Previous) Eval Time (s)     29.138829801697284
Sample Time (s)              23.32200347352773
Epoch Time (s)               186.20510610938072
Total Train Time (s)         16864.903140531387
Epoch                        93
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:28:48.646681 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #93 | Epoch Duration: 185.34185433387756
2020-01-13 09:28:48.647079 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.142495
Z variance train             0.0011650186
KL Divergence                58.103832
KL Loss                      5.8103833
QF Loss                      358.6636
VF Loss                      97.31552
Policy Loss                  -3410.1313
Q Predictions Mean           3411.1504
Q Predictions Std            659.6175
Q Predictions Max            4139.4688
Q Predictions Min            146.2346
V Predictions Mean           3412.9194
V Predictions Std            654.1855
V Predictions Max            4137.1465
V Predictions Min            165.6151
Log Pis Mean                 4.387864
Log Pis Std                  3.5955963
Log Pis Max                  14.893922
Log Pis Min                  -5.9563293
Policy mu Mean               -0.16320539
Policy mu Std                1.283684
Policy mu Max                2.761848
Policy mu Min                -2.6941803
Policy log std Mean          -0.8334039
Policy log std Std           0.4229458
Policy log std Max           0.07874358
Policy log std Min           -3.0537596
Z mean eval                  4.1362495
Z variance eval              0.0005998602
total_rewards                [9438.0777931  9553.16477947 9362.86339981 9589.39839706 9161.34593989
 9495.3604583  9603.16355392 9309.86663634 9169.06144138 9307.39917092]
total_rewards_mean           9398.970157020052
total_rewards_std            154.75981513782622
total_rewards_max            9603.163553917204
total_rewards_min            9161.345939894618
Number of train steps total  380000
Number of env steps total    477000
Number of rollouts total     0
Train Time (s)               129.93450400792062
(Previous) Eval Time (s)     28.275117261800915
Sample Time (s)              22.441273720469326
Epoch Time (s)               180.65089499019086
Total Train Time (s)         17043.836589789484
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:31:47.582002 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #94 | Epoch Duration: 178.93451833724976
2020-01-13 09:31:47.582191 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #94 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.212447
Z variance train             0.00058175804
KL Divergence                61.345192
KL Loss                      6.134519
QF Loss                      439.86594
VF Loss                      287.55606
Policy Loss                  -3413.6023
Q Predictions Mean           3414.3198
Q Predictions Std            679.29224
Q Predictions Max            4219.821
Q Predictions Min            157.40073
V Predictions Mean           3420.2998
V Predictions Std            682.28815
V Predictions Max            4212.1714
V Predictions Min            138.88687
Log Pis Mean                 4.725069
Log Pis Std                  3.8689244
Log Pis Max                  13.932928
Log Pis Min                  -5.1991067
Policy mu Mean               -0.1766551
Policy mu Std                1.3660367
Policy mu Max                3.2944534
Policy mu Min                -3.077553
Policy log std Mean          -0.8113515
Policy log std Std           0.41326627
Policy log std Max           0.3026898
Policy log std Min           -2.869808
Z mean eval                  4.0796056
Z variance eval              0.00084440224
total_rewards                [9366.09094302 9430.54949744 9458.15545298 9124.07144323 9347.0344463
 9337.67541153 9433.79659709 9309.08702579 9266.53963492 9259.83645052]
total_rewards_mean           9333.283690282165
total_rewards_std            95.20800070299268
total_rewards_max            9458.155452981115
total_rewards_min            9124.071443230638
Number of train steps total  384000
Number of env steps total    482000
Number of rollouts total     0
Train Time (s)               125.91709931194782
(Previous) Eval Time (s)     26.5583404218778
Sample Time (s)              22.04434875352308
Epoch Time (s)               174.5197884873487
Total Train Time (s)         17220.036493122112
Epoch                        95
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:34:43.783946 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #95 | Epoch Duration: 176.20161318778992
2020-01-13 09:34:43.784154 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #95 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1113176
Z variance train             0.0010414086
KL Divergence                60.2818
KL Loss                      6.02818
QF Loss                      491.5495
VF Loss                      235.71161
Policy Loss                  -3422.6506
Q Predictions Mean           3417.666
Q Predictions Std            634.36993
Q Predictions Max            4167.073
Q Predictions Min            150.55171
V Predictions Mean           3415.717
V Predictions Std            629.8995
V Predictions Max            4152.6387
V Predictions Min            152.0306
Log Pis Mean                 5.3187046
Log Pis Std                  3.7057438
Log Pis Max                  16.458855
Log Pis Min                  -4.499894
Policy mu Mean               -0.24951835
Policy mu Std                1.3964951
Policy mu Max                3.360164
Policy mu Min                -2.9495683
Policy log std Mean          -0.8505227
Policy log std Std           0.45155427
Policy log std Max           0.12682354
Policy log std Min           -3.1193342
Z mean eval                  4.215837
Z variance eval              0.0006169983
total_rewards                [ 9939.17672498 10001.11080701 10008.39966596  9939.20247792
  9926.19333153 10016.70151964  9861.28490968  9761.36050326
 10009.28341349 10040.27398071]
total_rewards_mean           9950.298733417583
total_rewards_std            81.48046686344091
total_rewards_max            10040.273980713731
total_rewards_min            9761.360503258107
Number of train steps total  388000
Number of env steps total    487000
Number of rollouts total     0
Train Time (s)               126.58553216094151
(Previous) Eval Time (s)     28.23986380500719
Sample Time (s)              20.612416121643037
Epoch Time (s)               175.43781208759174
Total Train Time (s)         17395.410007324535
Epoch                        96
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:37:39.159448 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #96 | Epoch Duration: 175.37514352798462
2020-01-13 09:37:39.159670 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.189868
Z variance train             0.00059991784
KL Divergence                62.060368
KL Loss                      6.206037
QF Loss                      849.5805
VF Loss                      268.00708
Policy Loss                  -3466.5862
Q Predictions Mean           3465.6099
Q Predictions Std            606.571
Q Predictions Max            4288.8374
Q Predictions Min            127.0925
V Predictions Mean           3475.3167
V Predictions Std            598.7902
V Predictions Max            4289.2627
V Predictions Min            131.71857
Log Pis Mean                 5.144658
Log Pis Std                  3.745441
Log Pis Max                  14.866226
Log Pis Min                  -5.9348435
Policy mu Mean               -0.16835444
Policy mu Std                1.3817351
Policy mu Max                3.4856842
Policy mu Min                -2.8809314
Policy log std Mean          -0.83864427
Policy log std Std           0.4362507
Policy log std Max           0.19962144
Policy log std Min           -3.1677728
Z mean eval                  4.2437716
Z variance eval              0.0007448328
total_rewards                [8940.3423036  9194.1850687  9197.6656807  9042.66793255 9004.17482379
 9025.04556691 9420.11678243 9141.82227508 8896.36211607 9139.10273214]
total_rewards_mean           9100.14852819709
total_rewards_std            144.6404637992881
total_rewards_max            9420.116782434938
total_rewards_min            8896.36211607174
Number of train steps total  392000
Number of env steps total    492000
Number of rollouts total     0
Train Time (s)               132.7130275531672
(Previous) Eval Time (s)     28.176869826857
Sample Time (s)              22.69130978686735
Epoch Time (s)               183.58120716689155
Total Train Time (s)         17579.24264140753
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:40:42.994220 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #97 | Epoch Duration: 183.83439254760742
2020-01-13 09:40:42.994496 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #97 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.238675
Z variance train             0.00071035966
KL Divergence                62.589447
KL Loss                      6.258945
QF Loss                      443.2702
VF Loss                      198.75668
Policy Loss                  -3515.1755
Q Predictions Mean           3515.9941
Q Predictions Std            628.9685
Q Predictions Max            4333.261
Q Predictions Min            140.93678
V Predictions Mean           3518.913
V Predictions Std            623.1512
V Predictions Max            4341.1787
V Predictions Min            154.9601
Log Pis Mean                 4.676612
Log Pis Std                  3.7678318
Log Pis Max                  15.833999
Log Pis Min                  -4.518657
Policy mu Mean               -0.20043136
Policy mu Std                1.32847
Policy mu Max                3.3296766
Policy mu Min                -2.7093558
Policy log std Mean          -0.8301015
Policy log std Std           0.43234786
Policy log std Max           0.00038135052
Policy log std Min           -3.098933
Z mean eval                  4.2246194
Z variance eval              0.0064742276
total_rewards                [9647.64398191 9645.1912485  9359.08467799 9249.30521577 9474.19247487
 9371.9482709  9446.46595319 9489.57580194 9586.66579535 9511.69601958]
total_rewards_mean           9478.17694400074
total_rewards_std            121.86360319331754
total_rewards_max            9647.64398190533
total_rewards_min            9249.30521576721
Number of train steps total  396000
Number of env steps total    497000
Number of rollouts total     0
Train Time (s)               132.53984078532085
(Previous) Eval Time (s)     28.429637335706502
Sample Time (s)              23.52311647636816
Epoch Time (s)               184.4925945973955
Total Train Time (s)         17764.209511563648
Epoch                        98
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:43:47.963149 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #98 | Epoch Duration: 184.96849060058594
2020-01-13 09:43:47.963382 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #98 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.203927
Z variance train             0.0049817273
KL Divergence                59.5402
KL Loss                      5.95402
QF Loss                      339.67624
VF Loss                      207.09546
Policy Loss                  -3555.1206
Q Predictions Mean           3558.787
Q Predictions Std            553.5646
Q Predictions Max            4328.0127
Q Predictions Min            144.19147
V Predictions Mean           3558.6174
V Predictions Std            550.2383
V Predictions Max            4319.38
V Predictions Min            161.15636
Log Pis Mean                 4.8891253
Log Pis Std                  3.975299
Log Pis Max                  15.220361
Log Pis Min                  -6.9182878
Policy mu Mean               -0.17808765
Policy mu Std                1.3479283
Policy mu Max                2.8056965
Policy mu Min                -2.996431
Policy log std Mean          -0.85237724
Policy log std Std           0.43307486
Policy log std Max           -0.008065462
Policy log std Min           -3.1000037
Z mean eval                  4.234784
Z variance eval              0.0011795232
total_rewards                [9546.28723761 9721.65630398 9752.69205538 9446.57145196 9837.5855663
 9693.37562432 9627.84332816 9561.80057713 9464.80959093 9506.5143464 ]
total_rewards_mean           9615.913608217536
total_rewards_std            125.06975673651964
total_rewards_max            9837.585566296566
total_rewards_min            9446.571451956373
Number of train steps total  400000
Number of env steps total    502000
Number of rollouts total     0
Train Time (s)               132.2540004849434
(Previous) Eval Time (s)     28.905225599650294
Sample Time (s)              22.74491461366415
Epoch Time (s)               183.90414069825783
Total Train Time (s)         17947.635411181487
Epoch                        99
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:46:51.391721 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #99 | Epoch Duration: 183.42817068099976
2020-01-13 09:46:51.392048 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #99 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1875734
Z variance train             0.0014983667
KL Divergence                59.626297
KL Loss                      5.96263
QF Loss                      374.40552
VF Loss                      163.17352
Policy Loss                  -3507.5735
Q Predictions Mean           3510.437
Q Predictions Std            594.692
Q Predictions Max            4332.4946
Q Predictions Min            124.76495
V Predictions Mean           3511.8916
V Predictions Std            588.90735
V Predictions Max            4325.024
V Predictions Min            139.23953
Log Pis Mean                 4.6702766
Log Pis Std                  3.7471123
Log Pis Max                  13.564155
Log Pis Min                  -6.438959
Policy mu Mean               -0.17368996
Policy mu Std                1.3362014
Policy mu Max                3.8251958
Policy mu Min                -2.8975344
Policy log std Mean          -0.8393777
Policy log std Std           0.43093306
Policy log std Max           -0.01896143
Policy log std Min           -3.080351
Z mean eval                  4.186348
Z variance eval              0.0013020219
total_rewards                [ 9654.89390483  9897.20475424 10099.7397804  10202.04941787
 10103.5307342   9999.22632481  9650.56526796  9937.28340248
  9848.14269281 10143.39143718]
total_rewards_mean           9953.602771678608
total_rewards_std            184.1979922895253
total_rewards_max            10202.049417867804
total_rewards_min            9650.56526795707
Number of train steps total  404000
Number of env steps total    507000
Number of rollouts total     0
Train Time (s)               134.21979535697028
(Previous) Eval Time (s)     28.428820088040084
Sample Time (s)              23.477197002619505
Epoch Time (s)               186.12581244762987
Total Train Time (s)         18133.08343358198
Epoch                        100
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:49:56.842270 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #100 | Epoch Duration: 185.45002269744873
2020-01-13 09:49:56.842568 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #100 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.077981
Z variance train             0.0014351183
KL Divergence                57.1352
KL Loss                      5.71352
QF Loss                      488.47607
VF Loss                      143.12752
Policy Loss                  -3473.7012
Q Predictions Mean           3465.3237
Q Predictions Std            545.5958
Q Predictions Max            4240.5513
Q Predictions Min            125.92985
V Predictions Mean           3477.1753
V Predictions Std            536.0514
V Predictions Max            4229.185
V Predictions Min            126.25458
Log Pis Mean                 5.1818476
Log Pis Std                  3.8648345
Log Pis Max                  20.800652
Log Pis Min                  -5.372179
Policy mu Mean               -0.19297433
Policy mu Std                1.389198
Policy mu Max                4.513483
Policy mu Min                -3.2552714
Policy log std Mean          -0.8561546
Policy log std Std           0.44835255
Policy log std Max           0.0022770166
Policy log std Min           -3.2995822
Z mean eval                  4.1636276
Z variance eval              0.0030235418
total_rewards                [10105.6421495   9797.86973446 10060.84926209  9801.70835074
  9771.6416944   9728.05029196  9955.29195544  9745.73757273
  9859.97250235 10188.49547278]
total_rewards_mean           9901.525898645317
total_rewards_std            156.83055392793636
total_rewards_max            10188.49547278461
total_rewards_min            9728.05029195833
Number of train steps total  408000
Number of env steps total    512000
Number of rollouts total     0
Train Time (s)               130.13644758611917
(Previous) Eval Time (s)     27.752603566739708
Sample Time (s)              22.618199357762933
Epoch Time (s)               180.50725051062182
Total Train Time (s)         18312.722502973396
Epoch                        101
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:52:56.482622 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #101 | Epoch Duration: 179.63989090919495
2020-01-13 09:52:56.482826 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #101 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1713233
Z variance train             0.0031184885
KL Divergence                58.204304
KL Loss                      5.8204303
QF Loss                      507.70197
VF Loss                      156.36745
Policy Loss                  -3491.1658
Q Predictions Mean           3493.1907
Q Predictions Std            690.74695
Q Predictions Max            4287.843
Q Predictions Min            124.42046
V Predictions Mean           3492.5781
V Predictions Std            688.874
V Predictions Max            4273.3984
V Predictions Min            114.38542
Log Pis Mean                 4.78537
Log Pis Std                  3.7048957
Log Pis Max                  14.457867
Log Pis Min                  -5.8430777
Policy mu Mean               -0.14174531
Policy mu Std                1.3360156
Policy mu Max                3.202446
Policy mu Min                -3.0791588
Policy log std Mean          -0.8482669
Policy log std Std           0.42690185
Policy log std Max           0.049307466
Policy log std Min           -3.2794812
Z mean eval                  4.1431093
Z variance eval              0.0026784497
total_rewards                [ 9788.98878152  9747.27168144 10034.53527233 10124.93720025
  9973.12823994 10111.80006821 10025.09860858  9987.07366641
 10054.85070895  9822.60744455]
total_rewards_mean           9967.029167216273
total_rewards_std            127.60237623945866
total_rewards_max            10124.937200245775
total_rewards_min            9747.271681437653
Number of train steps total  412000
Number of env steps total    517000
Number of rollouts total     0
Train Time (s)               126.60996990278363
(Previous) Eval Time (s)     26.884922807104886
Sample Time (s)              22.286880671046674
Epoch Time (s)               175.7817733809352
Total Train Time (s)         18489.014066384174
Epoch                        102
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:55:52.776102 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #102 | Epoch Duration: 176.2931170463562
2020-01-13 09:55:52.776316 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #102 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.115442
Z variance train             0.003019175
KL Divergence                57.92279
KL Loss                      5.7922792
QF Loss                      404.2864
VF Loss                      352.7924
Policy Loss                  -3482.2305
Q Predictions Mean           3482.0623
Q Predictions Std            655.8032
Q Predictions Max            4320.3057
Q Predictions Min            126.47497
V Predictions Mean           3495.806
V Predictions Std            649.51434
V Predictions Max            4296.954
V Predictions Min            143.99202
Log Pis Mean                 5.101115
Log Pis Std                  3.6332586
Log Pis Max                  15.327793
Log Pis Min                  -6.799707
Policy mu Mean               -0.20129459
Policy mu Std                1.3519852
Policy mu Max                2.7551117
Policy mu Min                -3.6185086
Policy log std Mean          -0.8569724
Policy log std Std           0.428317
Policy log std Max           -0.043427706
Policy log std Min           -3.2153113
Z mean eval                  4.130889
Z variance eval              0.0031534042
total_rewards                [9452.65581617 9960.90444518 9633.59759152 9724.69072073 9084.32966606
 8962.41602646 9369.66658962 8817.99988741 9526.04725979 8746.83926589]
total_rewards_mean           9327.914726881982
total_rewards_std            387.1297019394173
total_rewards_max            9960.90444517617
total_rewards_min            8746.839265890605
Number of train steps total  416000
Number of env steps total    522000
Number of rollouts total     0
Train Time (s)               127.32333960011601
(Previous) Eval Time (s)     27.395910979714245
Sample Time (s)              21.25514837540686
Epoch Time (s)               175.97439895523712
Total Train Time (s)         18665.06683918368
Epoch                        103
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:58:48.831178 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #103 | Epoch Duration: 176.05470442771912
2020-01-13 09:58:48.831402 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #103 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.132844
Z variance train             0.0031373403
KL Divergence                57.658493
KL Loss                      5.7658496
QF Loss                      533.59247
VF Loss                      178.26414
Policy Loss                  -3540.8809
Q Predictions Mean           3539.9263
Q Predictions Std            656.9074
Q Predictions Max            4340.3853
Q Predictions Min            115.850136
V Predictions Mean           3540.9648
V Predictions Std            652.89166
V Predictions Max            4330.4414
V Predictions Min            121.42484
Log Pis Mean                 4.609371
Log Pis Std                  3.8985581
Log Pis Max                  14.726259
Log Pis Min                  -6.26457
Policy mu Mean               -0.105119705
Policy mu Std                1.3683072
Policy mu Max                2.8663497
Policy mu Min                -3.3090136
Policy log std Mean          -0.8311663
Policy log std Std           0.42756656
Policy log std Max           0.021351695
Policy log std Min           -3.1842585
Z mean eval                  4.1681604
Z variance eval              0.010943787
total_rewards                [9592.93369916 9703.98876796 9680.52512056 9762.29412549 9632.13444184
 9713.51514132 9685.00684301 9518.14129384 9693.23642741 9648.34532116]
total_rewards_mean           9663.01211817515
total_rewards_std            65.46573651867685
total_rewards_max            9762.294125493863
total_rewards_min            9518.141293839317
Number of train steps total  420000
Number of env steps total    527000
Number of rollouts total     0
Train Time (s)               134.26926898630336
(Previous) Eval Time (s)     27.47586070559919
Sample Time (s)              21.720078841783106
Epoch Time (s)               183.46520853368565
Total Train Time (s)         18849.61027243035
Epoch                        104
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:01:53.376404 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #104 | Epoch Duration: 184.54485774040222
2020-01-13 10:01:53.376586 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.019462
Z variance train             0.016493745
KL Divergence                53.14279
KL Loss                      5.314279
QF Loss                      754.21185
VF Loss                      196.25763
Policy Loss                  -3550.2964
Q Predictions Mean           3554.4712
Q Predictions Std            594.9418
Q Predictions Max            4333.58
Q Predictions Min            121.19352
V Predictions Mean           3547.625
V Predictions Std            592.63495
V Predictions Max            4331.1367
V Predictions Min            117.50138
Log Pis Mean                 5.1086864
Log Pis Std                  3.8722215
Log Pis Max                  14.698073
Log Pis Min                  -5.4959664
Policy mu Mean               -0.23060127
Policy mu Std                1.3464444
Policy mu Max                3.1165864
Policy mu Min                -2.8257244
Policy log std Mean          -0.8605104
Policy log std Std           0.44976562
Policy log std Max           0.013916731
Policy log std Min           -3.1736283
Z mean eval                  4.1127825
Z variance eval              0.010174734
total_rewards                [9457.38857628 9670.5956895  9701.93760914 9737.92434163 9445.26494535
 9564.2322661  9520.2782271  9561.12380818 9561.73205419 9498.25442609]
total_rewards_mean           9571.873194356102
total_rewards_std            95.77618834559497
total_rewards_max            9737.9243416259
total_rewards_min            9445.264945349563
Number of train steps total  424000
Number of env steps total    532000
Number of rollouts total     0
Train Time (s)               133.38536123000085
(Previous) Eval Time (s)     28.555181351024657
Sample Time (s)              23.358277328312397
Epoch Time (s)               185.2988199093379
Total Train Time (s)         19035.600542239845
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:04:59.372800 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #105 | Epoch Duration: 185.99603843688965
2020-01-13 10:04:59.373066 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #105 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1513634
Z variance train             0.009897578
KL Divergence                57.332184
KL Loss                      5.7332187
QF Loss                      403.1955
VF Loss                      271.14166
Policy Loss                  -3525.9097
Q Predictions Mean           3527.9019
Q Predictions Std            548.6944
Q Predictions Max            4306.489
Q Predictions Min            114.32874
V Predictions Mean           3515.5325
V Predictions Std            542.7485
V Predictions Max            4265.9995
V Predictions Min            139.60571
Log Pis Mean                 5.083396
Log Pis Std                  4.2358947
Log Pis Max                  21.814663
Log Pis Min                  -3.682997
Policy mu Mean               -0.16202463
Policy mu Std                1.3931605
Policy mu Max                3.7970867
Policy mu Min                -4.389512
Policy log std Mean          -0.8458147
Policy log std Std           0.41943422
Policy log std Max           0.2443403
Policy log std Min           -3.0771751
Z mean eval                  4.104113
Z variance eval              0.0029443312
total_rewards                [ 9508.03588592  9767.75216442  9577.89810703 10002.80462051
  9949.67543656  9743.95794457 10111.89073515 10023.93254897
  9713.46119788  9770.22736742]
total_rewards_mean           9816.963600842328
total_rewards_std            188.46875964111535
total_rewards_max            10111.890735146299
total_rewards_min            9508.035885918212
Number of train steps total  428000
Number of env steps total    537000
Number of rollouts total     0
Train Time (s)               132.58355807792395
(Previous) Eval Time (s)     29.251997352112085
Sample Time (s)              23.166900928132236
Epoch Time (s)               185.00245635816827
Total Train Time (s)         19220.31965712551
Epoch                        106
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:08:04.089636 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #106 | Epoch Duration: 184.71639680862427
2020-01-13 10:08:04.089893 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #106 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1037035
Z variance train             0.002936383
KL Divergence                56.348732
KL Loss                      5.6348734
QF Loss                      525.56085
VF Loss                      119.4398
Policy Loss                  -3527.736
Q Predictions Mean           3527.8997
Q Predictions Std            559.7401
Q Predictions Max            4332.281
Q Predictions Min            108.86336
V Predictions Mean           3527.1694
V Predictions Std            553.67163
V Predictions Max            4335.615
V Predictions Min            115.01583
Log Pis Mean                 5.076823
Log Pis Std                  3.7442098
Log Pis Max                  14.854084
Log Pis Min                  -4.4790916
Policy mu Mean               -0.15676606
Policy mu Std                1.3783944
Policy mu Max                3.06009
Policy mu Min                -3.3052092
Policy log std Mean          -0.858233
Policy log std Std           0.44715023
Policy log std Max           0.06773114
Policy log std Min           -3.26502
Z mean eval                  3.9262862
Z variance eval              0.0031607382
total_rewards                [10093.43190275  9693.16522913 10383.35449414  9785.81377944
 10004.61273014 10385.78676745 10130.82933822  9695.07609021
  9607.83257173  9881.51907542]
total_rewards_mean           9966.142197863679
total_rewards_std            266.65157596949945
total_rewards_max            10385.78676744592
total_rewards_min            9607.832571731642
Number of train steps total  432000
Number of env steps total    542000
Number of rollouts total     0
Train Time (s)               134.2566686468199
(Previous) Eval Time (s)     28.965502437669784
Sample Time (s)              21.848107914440334
Epoch Time (s)               185.07027899893
Total Train Time (s)         19403.123883164953
Epoch                        107
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:11:06.897028 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #107 | Epoch Duration: 182.8069202899933
2020-01-13 10:11:06.897388 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #107 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9238372
Z variance train             0.0031645435
KL Divergence                52.55062
KL Loss                      5.255062
QF Loss                      404.8935
VF Loss                      374.339
Policy Loss                  -3496.3516
Q Predictions Mean           3502.809
Q Predictions Std            588.7744
Q Predictions Max            4325.1333
Q Predictions Min            99.55968
V Predictions Mean           3511.4004
V Predictions Std            586.68
V Predictions Max            4352.4746
V Predictions Min            103.84236
Log Pis Mean                 5.400411
Log Pis Std                  3.701072
Log Pis Max                  16.235222
Log Pis Min                  -4.076196
Policy mu Mean               -0.20711982
Policy mu Std                1.3812007
Policy mu Max                3.1840737
Policy mu Min                -3.8598046
Policy log std Mean          -0.84227324
Policy log std Std           0.44294694
Policy log std Max           0.12451708
Policy log std Min           -3.1737118
Z mean eval                  3.941481
Z variance eval              0.0025952044
total_rewards                [ 9968.31845094 10202.92071118 10230.37866308 10232.88052085
 10208.42927023 10388.25864852 10210.09493443 10021.75721004
 10118.04157447 10031.3604854 ]
total_rewards_mean           10161.244046912661
total_rewards_std            119.67032387757618
total_rewards_max            10388.258648519128
total_rewards_min            9968.31845093585
Number of train steps total  436000
Number of env steps total    547000
Number of rollouts total     0
Train Time (s)               130.95973612414673
(Previous) Eval Time (s)     26.701504923868924
Sample Time (s)              23.37297834455967
Epoch Time (s)               181.03421939257532
Total Train Time (s)         19585.851901967544
Epoch                        108
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:14:09.626371 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #108 | Epoch Duration: 182.72879242897034
2020-01-13 10:14:09.626561 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #108 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9400704
Z variance train             0.0025996873
KL Divergence                53.4517
KL Loss                      5.34517
QF Loss                      541.19946
VF Loss                      462.68198
Policy Loss                  -3584.7817
Q Predictions Mean           3589.7124
Q Predictions Std            526.5024
Q Predictions Max            4326.203
Q Predictions Min            131.11441
V Predictions Mean           3601.2017
V Predictions Std            518.77527
V Predictions Max            4346.2217
V Predictions Min            125.6353
Log Pis Mean                 5.3853693
Log Pis Std                  3.9874616
Log Pis Max                  19.947828
Log Pis Min                  -6.6139774
Policy mu Mean               -0.18852532
Policy mu Std                1.409359
Policy mu Max                4.266905
Policy mu Min                -3.51699
Policy log std Mean          -0.85340375
Policy log std Std           0.43554938
Policy log std Max           -0.14741698
Policy log std Min           -3.2362552
Z mean eval                  3.9282117
Z variance eval              0.0016620759
total_rewards                [ 9886.77617206  9689.40445112 10090.0922531  10004.82465701
  9820.24715162  9347.94894625 10009.82521439  9848.07498696
  9843.36979905  9971.40591331]
total_rewards_mean           9851.196954485556
total_rewards_std            200.5032935666494
total_rewards_max            10090.092253097115
total_rewards_min            9347.948946246
Number of train steps total  440000
Number of env steps total    552000
Number of rollouts total     0
Train Time (s)               126.2443143450655
(Previous) Eval Time (s)     28.39567580865696
Sample Time (s)              22.264645640272647
Epoch Time (s)               176.9046357939951
Total Train Time (s)         19761.427901913412
Epoch                        109
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:17:05.204308 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #109 | Epoch Duration: 175.57761025428772
2020-01-13 10:17:05.204491 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #109 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9272988
Z variance train             0.0016634471
KL Divergence                53.77393
KL Loss                      5.3773932
QF Loss                      433.56888
VF Loss                      157.04802
Policy Loss                  -3599.4858
Q Predictions Mean           3598.668
Q Predictions Std            505.59326
Q Predictions Max            4391.283
Q Predictions Min            190.59554
V Predictions Mean           3600.003
V Predictions Std            498.05725
V Predictions Max            4404.624
V Predictions Min            200.6599
Log Pis Mean                 5.213046
Log Pis Std                  3.8243475
Log Pis Max                  19.025768
Log Pis Min                  -3.717221
Policy mu Mean               -0.14901341
Policy mu Std                1.3730416
Policy mu Max                2.8420396
Policy mu Min                -3.0444894
Policy log std Mean          -0.8605943
Policy log std Std           0.4219555
Policy log std Max           -0.13029668
Policy log std Min           -3.1234684
Z mean eval                  3.9868188
Z variance eval              0.0015226982
total_rewards                [ 9682.50781123 10153.01633095 10103.70048651  9564.6570642
  9701.65967468  9988.22896843  9779.34532645 10001.11905877
  9882.26594899  9617.74225571]
total_rewards_mean           9847.424292592925
total_rewards_std            197.36175394217565
total_rewards_max            10153.016330945742
total_rewards_min            9564.657064203739
Number of train steps total  444000
Number of env steps total    557000
Number of rollouts total     0
Train Time (s)               127.24277216382325
(Previous) Eval Time (s)     27.0682628932409
Sample Time (s)              22.094168033450842
Epoch Time (s)               176.405203090515
Total Train Time (s)         19939.174020526465
Epoch                        110
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:20:02.952816 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #110 | Epoch Duration: 177.74817490577698
2020-01-13 10:20:02.953032 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #110 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9860115
Z variance train             0.0015053233
KL Divergence                54.88092
KL Loss                      5.488092
QF Loss                      703.41144
VF Loss                      464.87433
Policy Loss                  -3534.0735
Q Predictions Mean           3534.9614
Q Predictions Std            680.3877
Q Predictions Max            4401.4946
Q Predictions Min            117.562065
V Predictions Mean           3549.1743
V Predictions Std            677.4895
V Predictions Max            4432.8364
V Predictions Min            124.05634
Log Pis Mean                 5.1443214
Log Pis Std                  3.420136
Log Pis Max                  15.929393
Log Pis Min                  -5.184099
Policy mu Mean               -0.19578487
Policy mu Std                1.369478
Policy mu Max                3.0019753
Policy mu Min                -3.1130922
Policy log std Mean          -0.8511564
Policy log std Std           0.41295946
Policy log std Max           0.26300526
Policy log std Min           -2.934394
Z mean eval                  3.9731307
Z variance eval              0.006694986
total_rewards                [10096.27654876  9961.82990256 10127.71483626 10261.32207579
 10042.89032501 10193.21570165 10175.68552713 10158.36858053
  2223.09039438  9924.54779884]
total_rewards_mean           9316.494169092311
total_rewards_std            2366.5303331201267
total_rewards_max            10261.322075793621
total_rewards_min            2223.0903943789594
Number of train steps total  448000
Number of env steps total    562000
Number of rollouts total     0
Train Time (s)               134.3895362308249
(Previous) Eval Time (s)     28.410904198884964
Sample Time (s)              22.329187664669007
Epoch Time (s)               185.12962809437886
Total Train Time (s)         20124.849924476817
Epoch                        111
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:23:08.630603 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #111 | Epoch Duration: 185.67741298675537
2020-01-13 10:23:08.630802 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #111 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9709353
Z variance train             0.006709397
KL Divergence                54.473038
KL Loss                      5.447304
QF Loss                      423.38983
VF Loss                      162.49876
Policy Loss                  -3603.6091
Q Predictions Mean           3599.7131
Q Predictions Std            642.2436
Q Predictions Max            4474.8164
Q Predictions Min            115.397606
V Predictions Mean           3608.6777
V Predictions Std            638.05896
V Predictions Max            4486.9053
V Predictions Min            132.37057
Log Pis Mean                 5.058613
Log Pis Std                  3.5131617
Log Pis Max                  14.23855
Log Pis Min                  -5.1096554
Policy mu Mean               -0.1591969
Policy mu Std                1.3594048
Policy mu Max                2.8540092
Policy mu Min                -3.1559913
Policy log std Mean          -0.85716087
Policy log std Std           0.4533721
Policy log std Max           -0.02319169
Policy log std Min           -3.2109244
Z mean eval                  3.9558105
Z variance eval              0.0015268422
total_rewards                [10270.31648438 10139.59072562  8154.90184646 10268.93954737
 10254.10043112 10317.28013791 10196.47837188 10429.49060696
 10239.949333   10201.59023797]
total_rewards_mean           10047.263772266455
total_rewards_std            635.0942891091779
total_rewards_max            10429.490606955022
total_rewards_min            8154.901846460883
Number of train steps total  452000
Number of env steps total    567000
Number of rollouts total     0
Train Time (s)               133.44742369325832
(Previous) Eval Time (s)     28.958332371897995
Sample Time (s)              23.41054787673056
Epoch Time (s)               185.81630394188687
Total Train Time (s)         20310.5046437392
Epoch                        112
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:26:14.287472 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #112 | Epoch Duration: 185.65652418136597
2020-01-13 10:26:14.287689 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #112 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9582343
Z variance train             0.0015242776
KL Divergence                55.472153
KL Loss                      5.5472155
QF Loss                      513.4134
VF Loss                      125.80414
Policy Loss                  -3623.4788
Q Predictions Mean           3624.294
Q Predictions Std            697.5033
Q Predictions Max            4524.61
Q Predictions Min            132.83997
V Predictions Mean           3620.981
V Predictions Std            693.37683
V Predictions Max            4495.676
V Predictions Min            127.32433
Log Pis Mean                 5.178778
Log Pis Std                  3.8155694
Log Pis Max                  15.034607
Log Pis Min                  -4.1262445
Policy mu Mean               -0.19851506
Policy mu Std                1.3746853
Policy mu Max                2.852719
Policy mu Min                -3.1421022
Policy log std Mean          -0.8543856
Policy log std Std           0.45905522
Policy log std Max           0.21631467
Policy log std Min           -3.2863975
Z mean eval                  3.945734
Z variance eval              0.0046657715
total_rewards                [8769.55314778 9072.07686582 9159.08740113 9100.69735097 9246.96039308
 9153.83451397 9263.2144053  9169.82766874 9443.81560592 9146.69446636]
total_rewards_mean           9152.57618190732
total_rewards_std            161.93331445582547
total_rewards_max            9443.815605919064
total_rewards_min            8769.553147780167
Number of train steps total  456000
Number of env steps total    572000
Number of rollouts total     0
Train Time (s)               132.72025835700333
(Previous) Eval Time (s)     28.798125398810953
Sample Time (s)              22.55975513206795
Epoch Time (s)               184.07813888788223
Total Train Time (s)         20494.168766328134
Epoch                        113
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:29:17.954469 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #113 | Epoch Duration: 183.66662883758545
2020-01-13 10:29:17.954713 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #113 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9428735
Z variance train             0.00466703
KL Divergence                54.28098
KL Loss                      5.428098
QF Loss                      452.48438
VF Loss                      255.53871
Policy Loss                  -3584.7476
Q Predictions Mean           3588.5688
Q Predictions Std            707.1795
Q Predictions Max            4523.419
Q Predictions Min            109.8078
V Predictions Mean           3593.8257
V Predictions Std            693.40985
V Predictions Max            4515.1245
V Predictions Min            138.54797
Log Pis Mean                 5.1443543
Log Pis Std                  3.9891336
Log Pis Max                  24.481428
Log Pis Min                  -5.684178
Policy mu Mean               -0.19834451
Policy mu Std                1.3611063
Policy mu Max                3.507192
Policy mu Min                -4.5783353
Policy log std Mean          -0.85585785
Policy log std Std           0.43556842
Policy log std Max           0.010107636
Policy log std Min           -3.1758392
Z mean eval                  3.778214
Z variance eval              0.0073921815
total_rewards                [ 9384.50235988 10073.4132987   9988.78520262  9935.66645292
 10134.7346958   9920.38072299  8269.29268371 10024.94286854
  9764.17260584  5295.02932588]
total_rewards_mean           9279.0920216894
total_rewards_std            1428.433916408581
total_rewards_max            10134.734695795596
total_rewards_min            5295.029325882087
Number of train steps total  460000
Number of env steps total    577000
Number of rollouts total     0
Train Time (s)               134.16592431999743
(Previous) Eval Time (s)     28.386231007054448
Sample Time (s)              23.149614667054266
Epoch Time (s)               185.70176999410614
Total Train Time (s)         20679.902706727386
Epoch                        114
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:32:23.691003 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #114 | Epoch Duration: 185.73610615730286
2020-01-13 10:32:23.691349 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #114 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7761161
Z variance train             0.0073638475
KL Divergence                49.343002
KL Loss                      4.9343004
QF Loss                      541.70447
VF Loss                      181.77979
Policy Loss                  -3633.961
Q Predictions Mean           3635.7432
Q Predictions Std            633.736
Q Predictions Max            4418.172
Q Predictions Min            114.41016
V Predictions Mean           3641.7632
V Predictions Std            630.3402
V Predictions Max            4412.0903
V Predictions Min            113.91119
Log Pis Mean                 5.1725574
Log Pis Std                  3.7789009
Log Pis Max                  14.846628
Log Pis Min                  -7.259469
Policy mu Mean               -0.19325264
Policy mu Std                1.3740426
Policy mu Max                2.8430057
Policy mu Min                -2.933311
Policy log std Mean          -0.87882775
Policy log std Std           0.47015908
Policy log std Max           0.022040129
Policy log std Min           -3.2465918
Z mean eval                  3.810643
Z variance eval              0.0025586423
total_rewards                [1957.43114084 9135.14706275 9904.16473485 9686.02232608 9619.04267076
 9700.27643362 9940.15318453 9615.54506607 9834.03246847 9747.41511876]
total_rewards_mean           8913.92302067246
total_rewards_std            2328.5341541213843
total_rewards_max            9940.153184527464
total_rewards_min            1957.431140844164
Number of train steps total  464000
Number of env steps total    582000
Number of rollouts total     0
Train Time (s)               130.80517798662186
(Previous) Eval Time (s)     28.420138728339225
Sample Time (s)              21.94676245516166
Epoch Time (s)               181.17207917012274
Total Train Time (s)         20859.79803963285
Epoch                        115
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:35:23.587949 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #115 | Epoch Duration: 179.89635062217712
2020-01-13 10:35:23.588143 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #115 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.8107057
Z variance train             0.0025722939
KL Divergence                50.562195
KL Loss                      5.0562196
QF Loss                      361.46164
VF Loss                      132.73099
Policy Loss                  -3597.0588
Q Predictions Mean           3592.4216
Q Predictions Std            698.7403
Q Predictions Max            4490.8457
Q Predictions Min            118.29474
V Predictions Mean           3594.9097
V Predictions Std            691.9035
V Predictions Max            4493.149
V Predictions Min            116.70571
Log Pis Mean                 5.491509
Log Pis Std                  4.1669455
Log Pis Max                  26.990969
Log Pis Min                  -5.8869743
Policy mu Mean               -0.17480713
Policy mu Std                1.4037472
Policy mu Max                4.3260713
Policy mu Min                -3.326886
Policy log std Mean          -0.8547023
Policy log std Std           0.4265619
Policy log std Max           0.06863278
Policy log std Min           -3.2495883
Z mean eval                  3.7816627
Z variance eval              0.009077453
total_rewards                [10144.88848442  9178.2060882  10446.65439028 10194.58168823
 10437.93847258 10283.41120105 10260.86287143 10324.96111489
 10052.92718037 10193.03240218]
total_rewards_mean           10151.746389361826
total_rewards_std            344.85567858732367
total_rewards_max            10446.654390281297
total_rewards_min            9178.206088195257
Number of train steps total  468000
Number of env steps total    587000
Number of rollouts total     0
Train Time (s)               127.25287741236389
(Previous) Eval Time (s)     27.14407953293994
Sample Time (s)              22.201232238207012
Epoch Time (s)               176.59818918351084
Total Train Time (s)         21037.448758827057
Epoch                        116
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:38:21.240243 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #116 | Epoch Duration: 177.6519238948822
2020-01-13 10:38:21.240567 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #116 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7793174
Z variance train             0.009141325
KL Divergence                48.29167
KL Loss                      4.8291674
QF Loss                      436.49762
VF Loss                      227.07005
Policy Loss                  -3592.417
Q Predictions Mean           3590.7744
Q Predictions Std            708.98004
Q Predictions Max            4507.0923
Q Predictions Min            114.59108
V Predictions Mean           3597.3232
V Predictions Std            705.08624
V Predictions Max            4498.0063
V Predictions Min            120.47054
Log Pis Mean                 5.2792683
Log Pis Std                  3.779743
Log Pis Max                  14.346617
Log Pis Min                  -5.076584
Policy mu Mean               -0.12693746
Policy mu Std                1.3867947
Policy mu Max                3.1032653
Policy mu Min                -2.9479082
Policy log std Mean          -0.8716912
Policy log std Std           0.4580582
Policy log std Max           0.13325894
Policy log std Min           -3.1905022
Z mean eval                  3.8468184
Z variance eval              0.008686625
total_rewards                [ 9886.99862247 10238.12135107 10198.72453566 10156.78601675
 10475.16218553 10142.28703329  8913.84766062 10089.11322494
 10489.99018712  5440.76125411]
total_rewards_mean           9603.179207154975
total_rewards_std            1449.80405807165
total_rewards_max            10489.990187118092
total_rewards_min            5440.76125411345
Number of train steps total  472000
Number of env steps total    592000
Number of rollouts total     0
Train Time (s)               127.45756244286895
(Previous) Eval Time (s)     28.19748226366937
Sample Time (s)              21.91870435094461
Epoch Time (s)               177.57374905748293
Total Train Time (s)         21214.565452727955
Epoch                        117
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:41:18.357702 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #117 | Epoch Duration: 177.11693596839905
2020-01-13 10:41:18.357822 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #117 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7888904
Z variance train             0.009683805
KL Divergence                47.78974
KL Loss                      4.778974
QF Loss                      999.50134
VF Loss                      302.34436
Policy Loss                  -3719.2358
Q Predictions Mean           3716.3286
Q Predictions Std            498.9877
Q Predictions Max            4501.723
Q Predictions Min            132.59424
V Predictions Mean           3708.647
V Predictions Std            495.01028
V Predictions Max            4492.3647
V Predictions Min            110.44777
Log Pis Mean                 5.4607882
Log Pis Std                  3.6391294
Log Pis Max                  15.661228
Log Pis Min                  -3.9239264
Policy mu Mean               -0.15206511
Policy mu Std                1.3865205
Policy mu Max                2.7808251
Policy mu Min                -2.877512
Policy log std Mean          -0.864126
Policy log std Std           0.43022582
Policy log std Max           -0.17037678
Policy log std Min           -3.1277988
Z mean eval                  3.8165486
Z variance eval              0.0033297564
total_rewards                [9489.76966292 9725.91408449 9476.58653751 9580.58059182 9604.18042662
 4767.51605109 9521.31559371 9639.11256266 9512.99442779 9692.77126975]
total_rewards_mean           9101.074120834917
total_rewards_std            1446.7604794806743
total_rewards_max            9725.914084485154
total_rewards_min            4767.516051092267
Number of train steps total  476000
Number of env steps total    597000
Number of rollouts total     0
Train Time (s)               134.3401231369935
(Previous) Eval Time (s)     27.74035754892975
Sample Time (s)              21.78125383378938
Epoch Time (s)               183.86173451971263
Total Train Time (s)         21400.04573975969
Epoch                        118
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:44:23.841085 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #118 | Epoch Duration: 185.48316097259521
2020-01-13 10:44:23.841509 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #118 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.8417149
Z variance train             0.0030156628
KL Divergence                50.45858
KL Loss                      5.045858
QF Loss                      465.19623
VF Loss                      142.74266
Policy Loss                  -3687.3726
Q Predictions Mean           3682.2249
Q Predictions Std            711.7055
Q Predictions Max            4542.221
Q Predictions Min            102.73226
V Predictions Mean           3681.3833
V Predictions Std            704.07263
V Predictions Max            4543.025
V Predictions Min            118.51032
Log Pis Mean                 5.1006937
Log Pis Std                  3.8756456
Log Pis Max                  16.208221
Log Pis Min                  -4.141711
Policy mu Mean               -0.15841384
Policy mu Std                1.3829333
Policy mu Max                2.8547318
Policy mu Min                -3.3402226
Policy log std Mean          -0.8666911
Policy log std Std           0.45062584
Policy log std Max           1.000373
Policy log std Min           -3.3126125
Z mean eval                  3.8801568
Z variance eval              0.0031973743
total_rewards                [10097.393594   10347.96601687  8401.20769963 10232.1824632
 10215.31396624 10367.92200431 10403.73040945 10296.42820967
 10522.40093798 10116.03282319]
total_rewards_mean           10100.057812454144
total_rewards_std            579.6082044814666
total_rewards_max            10522.400937978167
total_rewards_min            8401.207699633016
Number of train steps total  480000
Number of env steps total    602000
Number of rollouts total     0
Train Time (s)               132.84829054074362
(Previous) Eval Time (s)     29.361401072703302
Sample Time (s)              23.1753563368693
Epoch Time (s)               185.38504795031622
Total Train Time (s)         21585.36837689206
Epoch                        119
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:47:29.166183 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #119 | Epoch Duration: 185.32451033592224
2020-01-13 10:47:29.166467 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #119 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.8661747
Z variance train             0.0032788385
KL Divergence                50.576504
KL Loss                      5.0576506
QF Loss                      514.6913
VF Loss                      264.63348
Policy Loss                  -3687.0837
Q Predictions Mean           3689.4387
Q Predictions Std            621.9247
Q Predictions Max            4535.0093
Q Predictions Min            98.218994
V Predictions Mean           3694.6582
V Predictions Std            617.7839
V Predictions Max            4525.104
V Predictions Min            111.98873
Log Pis Mean                 5.0751886
Log Pis Std                  3.6686454
Log Pis Max                  16.45525
Log Pis Min                  -3.461298
Policy mu Mean               -0.15739138
Policy mu Std                1.370658
Policy mu Max                3.3749087
Policy mu Min                -2.8204908
Policy log std Mean          -0.84899616
Policy log std Std           0.4169531
Policy log std Max           0.048369884
Policy log std Min           -3.1640816
Z mean eval                  3.8359787
Z variance eval              0.00582751
total_rewards                [10243.51406387  9976.0117529  10030.45677322 10154.98299273
 10271.28456119  9969.00517777 10378.17780292 10183.89655422
  6770.81591378  9895.6169439 ]
total_rewards_mean           9787.376253651102
total_rewards_std            1016.0044967300411
total_rewards_max            10378.177802916636
total_rewards_min            6770.81591378244
Number of train steps total  484000
Number of env steps total    607000
Number of rollouts total     0
Train Time (s)               132.86862050462514
(Previous) Eval Time (s)     29.300471667200327
Sample Time (s)              22.948136522900313
Epoch Time (s)               185.11722869472578
Total Train Time (s)         21769.778197424952
Epoch                        120
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:50:33.577794 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #120 | Epoch Duration: 184.4111647605896
2020-01-13 10:50:33.577977 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #120 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7903717
Z variance train             0.006533752
KL Divergence                47.89654
KL Loss                      4.7896543
QF Loss                      624.27545
VF Loss                      262.76593
Policy Loss                  -3705.4084
Q Predictions Mean           3704.0342
Q Predictions Std            631.1593
Q Predictions Max            4467.5386
Q Predictions Min            113.54145
V Predictions Mean           3708.711
V Predictions Std            628.7777
V Predictions Max            4444.424
V Predictions Min            110.23787
Log Pis Mean                 5.1698313
Log Pis Std                  3.5772495
Log Pis Max                  14.843591
Log Pis Min                  -4.2568064
Policy mu Mean               -0.18617086
Policy mu Std                1.3572984
Policy mu Max                3.1648574
Policy mu Min                -3.0510888
Policy log std Mean          -0.87940854
Policy log std Std           0.4504313
Policy log std Max           0.008494258
Policy log std Min           -3.180536
Z mean eval                  3.758358
Z variance eval              0.0160913
total_rewards                [10298.19211162 10289.65607574 10286.70631462 10517.47832334
  9484.86116055 10563.73742131 10248.32442349 10305.56494935
 10490.60256163 10295.46401012]
total_rewards_mean           10278.058735177216
total_rewards_std            285.62731276259467
total_rewards_max            10563.737421310849
total_rewards_min            9484.861160546245
Number of train steps total  488000
Number of env steps total    612000
Number of rollouts total     0
Train Time (s)               134.5337265310809
(Previous) Eval Time (s)     28.594026838894933
Sample Time (s)              23.099091161042452
Epoch Time (s)               186.2268445310183
Total Train Time (s)         21956.086879869923
Epoch                        121
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:53:39.889803 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #121 | Epoch Duration: 186.31164813041687
2020-01-13 10:53:39.890206 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #121 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7584393
Z variance train             0.016120277
KL Divergence                45.322144
KL Loss                      4.5322146
QF Loss                      512.21106
VF Loss                      165.91997
Policy Loss                  -3686.0293
Q Predictions Mean           3687.799
Q Predictions Std            659.08435
Q Predictions Max            4575.3486
Q Predictions Min            125.33646
V Predictions Mean           3684.9407
V Predictions Std            654.35486
V Predictions Max            4563.871
V Predictions Min            110.8804
Log Pis Mean                 5.652858
Log Pis Std                  4.0737042
Log Pis Max                  16.1928
Log Pis Min                  -5.6468267
Policy mu Mean               -0.21447508
Policy mu Std                1.3998061
Policy mu Max                3.8285768
Policy mu Min                -3.276926
Policy log std Mean          -0.8634145
Policy log std Std           0.4684224
Policy log std Max           -0.1542294
Policy log std Min           -3.215527
Z mean eval                  3.694804
Z variance eval              0.007511724
total_rewards                [10328.92466968  3333.91380822 10149.3536958   9637.99354843
 10408.36850729  3613.57360698  3955.29821636 10415.30422764
 10236.64763817 10206.79890977]
total_rewards_mean           8228.617682834996
total_rewards_std            3017.998851487835
total_rewards_max            10415.304227642984
total_rewards_min            3333.9138082236504
Number of train steps total  492000
Number of env steps total    617000
Number of rollouts total     0
Train Time (s)               130.6301235742867
(Previous) Eval Time (s)     28.678442707285285
Sample Time (s)              23.084256908856332
Epoch Time (s)               182.39282319042832
Total Train Time (s)         22137.871247783303
Epoch                        122
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:56:41.675424 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #122 | Epoch Duration: 181.7849407196045
2020-01-13 10:56:41.675621 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #122 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6766517
Z variance train             0.007832304
KL Divergence                45.418858
KL Loss                      4.541886
QF Loss                      647.5845
VF Loss                      215.7023
Policy Loss                  -3675.247
Q Predictions Mean           3674.004
Q Predictions Std            565.8366
Q Predictions Max            4448.4663
Q Predictions Min            110.77151
V Predictions Mean           3685.8364
V Predictions Std            561.847
V Predictions Max            4451.1772
V Predictions Min            131.94765
Log Pis Mean                 5.3766527
Log Pis Std                  3.932691
Log Pis Max                  16.301487
Log Pis Min                  -5.0916576
Policy mu Mean               -0.19860995
Policy mu Std                1.3659537
Policy mu Max                2.9542952
Policy mu Min                -2.7827704
Policy log std Mean          -0.88321996
Policy log std Std           0.44761312
Policy log std Max           0.47951567
Policy log std Min           -3.1870756
Z mean eval                  3.6510491
Z variance eval              0.018250015
total_rewards                [ 9768.12706695 10327.22130601 10123.38339756 10151.17045924
 10187.82420136 10270.36857244  9934.73549896 10162.50744603
  9711.8755332   3979.21628979]
total_rewards_mean           9461.64297715276
total_rewards_std            1837.7303769713126
total_rewards_max            10327.221306007328
total_rewards_min            3979.2162897898993
Number of train steps total  496000
Number of env steps total    622000
Number of rollouts total     0
Train Time (s)               127.36883275723085
(Previous) Eval Time (s)     28.070221239235252
Sample Time (s)              21.970930335577577
Epoch Time (s)               177.40998433204368
Total Train Time (s)         22315.531334175263
Epoch                        123
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:59:39.336534 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #123 | Epoch Duration: 177.66078329086304
2020-01-13 10:59:39.336658 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #123 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7174957
Z variance train             0.015550931
KL Divergence                44.390053
KL Loss                      4.4390054
QF Loss                      634.17786
VF Loss                      320.89963
Policy Loss                  -3746.6838
Q Predictions Mean           3752.164
Q Predictions Std            626.9962
Q Predictions Max            4628.42
Q Predictions Min            98.946335
V Predictions Mean           3758.4048
V Predictions Std            623.3378
V Predictions Max            4624.668
V Predictions Min            113.16422
Log Pis Mean                 5.3608556
Log Pis Std                  3.6116102
Log Pis Max                  17.020687
Log Pis Min                  -6.438633
Policy mu Mean               -0.17278488
Policy mu Std                1.3941579
Policy mu Max                3.0513337
Policy mu Min                -3.1385815
Policy log std Mean          -0.8904591
Policy log std Std           0.46367684
Policy log std Max           0.15754777
Policy log std Min           -3.219965
Z mean eval                  3.724237
Z variance eval              0.0056765927
total_rewards                [10291.32469736 10529.94732484 10588.28537245 10502.74663828
 10434.34782403 10345.58275289 10478.11721772 10517.47102765
 10470.13544337 10445.51172765]
total_rewards_mean           10460.34700262285
total_rewards_std            83.25882784806599
total_rewards_max            10588.285372451111
total_rewards_min            10291.324697360897
Number of train steps total  500000
Number of env steps total    627000
Number of rollouts total     0
Train Time (s)               127.53810244007036
(Previous) Eval Time (s)     28.32070450205356
Sample Time (s)              21.091114210430533
Epoch Time (s)               176.94992115255445
Total Train Time (s)         22491.09045035811
Epoch                        124
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:02:34.899518 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #124 | Epoch Duration: 175.5627408027649
2020-01-13 11:02:34.899775 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #124 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.732966
Z variance train             0.005403927
KL Divergence                47.12993
KL Loss                      4.712993
QF Loss                      469.9269
VF Loss                      151.62474
Policy Loss                  -3748.8447
Q Predictions Mean           3748.0752
Q Predictions Std            569.6287
Q Predictions Max            4631.812
Q Predictions Min            98.28988
V Predictions Mean           3751.3813
V Predictions Std            567.0406
V Predictions Max            4651.954
V Predictions Min            88.75472
Log Pis Mean                 5.1421733
Log Pis Std                  3.519014
Log Pis Max                  15.468786
Log Pis Min                  -4.7493057
Policy mu Mean               -0.20625162
Policy mu Std                1.3515512
Policy mu Max                2.8814926
Policy mu Min                -3.0167258
Policy log std Mean          -0.8893252
Policy log std Std           0.45175695
Policy log std Max           0.059093
Policy log std Min           -3.240084
Z mean eval                  3.7085178
Z variance eval              0.009797065
total_rewards                [10080.55824452 10320.33997348 10122.55061895 10171.91439313
 10107.78243881 10156.26852208 10183.61065694 10256.27969499
 10207.29905986 10026.26589336]
total_rewards_mean           10163.286949610974
total_rewards_std            81.33026551918205
total_rewards_max            10320.339973484171
total_rewards_min            10026.265893355894
Number of train steps total  504000
Number of env steps total    632000
Number of rollouts total     0
Train Time (s)               135.82365114893764
(Previous) Eval Time (s)     26.93318514805287
Sample Time (s)              21.938651223666966
Epoch Time (s)               184.69548752065748
Total Train Time (s)         22678.07592544239
Epoch                        125
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:05:41.887427 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #125 | Epoch Duration: 186.98745369911194
2020-01-13 11:05:41.887764 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #125 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6751618
Z variance train             0.009949646
KL Divergence                45.885185
KL Loss                      4.5885186
QF Loss                      432.97815
VF Loss                      152.61378
Policy Loss                  -3764.062
Q Predictions Mean           3770.3928
Q Predictions Std            656.4294
Q Predictions Max            4659.3203
Q Predictions Min            77.65591
V Predictions Mean           3766.4482
V Predictions Std            655.3862
V Predictions Max            4652.127
V Predictions Min            84.18514
Log Pis Mean                 5.499713
Log Pis Std                  3.9639757
Log Pis Max                  19.380007
Log Pis Min                  -6.2480116
Policy mu Mean               -0.18010135
Policy mu Std                1.4016353
Policy mu Max                3.3133981
Policy mu Min                -2.9357016
Policy log std Mean          -0.86987275
Policy log std Std           0.45007503
Policy log std Max           -0.030405521
Policy log std Min           -3.04031
Z mean eval                  3.7223067
Z variance eval              0.007077203
total_rewards                [10230.88859872 10210.39058316  7992.39621803 10180.25775106
 10046.33999753  9786.90277791 10164.66094844  9920.81896883
 10473.85483398 10218.06741743]
total_rewards_mean           9922.457809509313
total_rewards_std            667.3413009041572
total_rewards_max            10473.85483397963
total_rewards_min            7992.396218033584
Number of train steps total  508000
Number of env steps total    637000
Number of rollouts total     0
Train Time (s)               133.6156832240522
(Previous) Eval Time (s)     29.224757002666593
Sample Time (s)              22.62706335214898
Epoch Time (s)               185.46750357886776
Total Train Time (s)         22863.201219165698
Epoch                        126
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:08:47.015773 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #126 | Epoch Duration: 185.12778329849243
2020-01-13 11:08:47.016121 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #126 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.719164
Z variance train             0.0070721703
KL Divergence                47.75181
KL Loss                      4.775181
QF Loss                      493.8089
VF Loss                      464.43027
Policy Loss                  -3747.747
Q Predictions Mean           3750.315
Q Predictions Std            573.27625
Q Predictions Max            4589.436
Q Predictions Min            47.991352
V Predictions Mean           3764.3503
V Predictions Std            566.7216
V Predictions Max            4596.9473
V Predictions Min            70.54614
Log Pis Mean                 5.5354486
Log Pis Std                  3.6626782
Log Pis Max                  16.056078
Log Pis Min                  -8.371956
Policy mu Mean               -0.12998696
Policy mu Std                1.3895427
Policy mu Max                3.2099817
Policy mu Min                -2.739328
Policy log std Mean          -0.87407225
Policy log std Std           0.41468626
Policy log std Max           0.013068914
Policy log std Min           -3.214371
Z mean eval                  3.7238514
Z variance eval              0.0045744395
total_rewards                [ 9860.15260524  9767.66094137  9923.92042284 10039.68105288
  9889.5818958  10006.53528206  9984.44852009  9821.74462469
  9827.28987465  9791.71014916]
total_rewards_mean           9891.272536878998
total_rewards_std            89.52650556963174
total_rewards_max            10039.681052875976
total_rewards_min            9767.660941370403
Number of train steps total  512000
Number of env steps total    642000
Number of rollouts total     0
Train Time (s)               133.2440248238854
(Previous) Eval Time (s)     28.884619650430977
Sample Time (s)              22.614310306496918
Epoch Time (s)               184.7429547808133
Total Train Time (s)         23047.58335255226
Epoch                        127
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:11:51.400792 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #127 | Epoch Duration: 184.384375333786
2020-01-13 11:11:51.401236 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #127 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7240167
Z variance train             0.004572462
KL Divergence                48.53683
KL Loss                      4.853683
QF Loss                      475.87677
VF Loss                      316.53302
Policy Loss                  -3766.585
Q Predictions Mean           3769.9507
Q Predictions Std            634.4499
Q Predictions Max            4607.6616
Q Predictions Min            60.055626
V Predictions Mean           3778.5513
V Predictions Std            631.25757
V Predictions Max            4629.641
V Predictions Min            58.924755
Log Pis Mean                 5.4082565
Log Pis Std                  3.7302787
Log Pis Max                  14.712792
Log Pis Min                  -2.9215007
Policy mu Mean               -0.20265508
Policy mu Std                1.3986028
Policy mu Max                3.036539
Policy mu Min                -3.3207638
Policy log std Mean          -0.8781142
Policy log std Std           0.46597847
Policy log std Max           0.23203278
Policy log std Min           -3.404939
Z mean eval                  3.7260985
Z variance eval              0.0006460681
total_rewards                [ 9982.07881699 10529.26879222 10356.01214401 10344.69342202
 10367.59090568 10088.37992049 10359.46096291 10389.35801499
 10299.06375786 10549.82497319]
total_rewards_mean           10326.573171035854
total_rewards_std            165.83034374706799
total_rewards_max            10549.824973189814
total_rewards_min            9982.078816985957
Number of train steps total  516000
Number of env steps total    647000
Number of rollouts total     0
Train Time (s)               133.88283569784835
(Previous) Eval Time (s)     28.525680297985673
Sample Time (s)              23.377098966389894
Epoch Time (s)               185.78561496222392
Total Train Time (s)         23233.933479648083
Epoch                        128
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:14:57.752153 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #128 | Epoch Duration: 186.35061645507812
2020-01-13 11:14:57.752502 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #128 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7266183
Z variance train             0.0006467265
KL Divergence                52.4542
KL Loss                      5.24542
QF Loss                      486.1215
VF Loss                      169.8411
Policy Loss                  -3854.06
Q Predictions Mean           3854.3005
Q Predictions Std            666.1274
Q Predictions Max            4633.564
Q Predictions Min            55.296196
V Predictions Mean           3852.2983
V Predictions Std            666.07776
V Predictions Max            4634.997
V Predictions Min            47.793762
Log Pis Mean                 5.268845
Log Pis Std                  4.2003126
Log Pis Max                  20.01983
Log Pis Min                  -5.3277454
Policy mu Mean               -0.2542655
Policy mu Std                1.3769295
Policy mu Max                2.8665557
Policy mu Min                -3.7812796
Policy log std Mean          -0.88432217
Policy log std Std           0.46801072
Policy log std Max           -0.0989759
Policy log std Min           -3.2617388
Z mean eval                  3.7150092
Z variance eval              0.0018052539
total_rewards                [10162.19593268 10197.56732775 10254.93490524  9939.93010773
  9675.88403447  9674.53232761 10477.50613401 10218.62383303
  3611.20981435 10133.83836943]
total_rewards_mean           9434.62227862869
total_rewards_std            1955.9847261121863
total_rewards_max            10477.50613401093
total_rewards_min            3611.2098143518424
Number of train steps total  520000
Number of env steps total    652000
Number of rollouts total     0
Train Time (s)               129.69783131033182
(Previous) Eval Time (s)     29.09028129791841
Sample Time (s)              22.00566910300404
Epoch Time (s)               180.79378171125427
Total Train Time (s)         23413.906033306383
Epoch                        129
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:17:57.726718 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #129 | Epoch Duration: 179.9739954471588
2020-01-13 11:17:57.726928 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #129 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7142684
Z variance train             0.0017854093
KL Divergence                51.880276
KL Loss                      5.188028
QF Loss                      370.19092
VF Loss                      195.24687
Policy Loss                  -3785.5312
Q Predictions Mean           3785.8687
Q Predictions Std            713.1662
Q Predictions Max            4611.824
Q Predictions Min            39.540035
V Predictions Mean           3792.5059
V Predictions Std            712.5899
V Predictions Max            4615.487
V Predictions Min            27.169197
Log Pis Mean                 5.125399
Log Pis Std                  3.8993652
Log Pis Max                  14.231577
Log Pis Min                  -3.8823276
Policy mu Mean               -0.18868642
Policy mu Std                1.3427827
Policy mu Max                3.2366796
Policy mu Min                -2.8084931
Policy log std Mean          -0.887801
Policy log std Std           0.46774638
Policy log std Max           -0.0059306026
Policy log std Min           -3.1951914
Z mean eval                  3.6961007
Z variance eval              0.008768398
total_rewards                [10069.05563519 10321.46117102 10406.61654614 10454.76339002
 10464.80049689 10345.69620501 10160.10641554 10324.72906143
 10133.03526793 10244.86403697]
total_rewards_mean           10292.512822612478
total_rewards_std            129.96167996778962
total_rewards_max            10464.800496885964
total_rewards_min            10069.055635192724
Number of train steps total  524000
Number of env steps total    657000
Number of rollouts total     0
Train Time (s)               127.74901134800166
(Previous) Eval Time (s)     28.270156115759164
Sample Time (s)              21.786563403438777
Epoch Time (s)               177.8057308671996
Total Train Time (s)         23591.805509653874
Epoch                        130
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:20:55.628167 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #130 | Epoch Duration: 177.90110087394714
2020-01-13 11:20:55.628347 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #130 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6619873
Z variance train             0.0091309
KL Divergence                48.1762
KL Loss                      4.8176203
QF Loss                      608.0592
VF Loss                      184.21085
Policy Loss                  -3759.4321
Q Predictions Mean           3759.7427
Q Predictions Std            670.5095
Q Predictions Max            4597.831
Q Predictions Min            5.9585037
V Predictions Mean           3752.3193
V Predictions Std            665.432
V Predictions Max            4578.0596
V Predictions Min            11.336635
Log Pis Mean                 5.335786
Log Pis Std                  4.0775385
Log Pis Max                  18.875221
Log Pis Min                  -6.480069
Policy mu Mean               -0.21176545
Policy mu Std                1.3819836
Policy mu Max                3.611637
Policy mu Min                -3.5176508
Policy log std Mean          -0.90971994
Policy log std Std           0.477963
Policy log std Max           0.19906259
Policy log std Min           -3.3747792
Z mean eval                  3.7125545
Z variance eval              0.0018056212
total_rewards                [ 9829.25787231  9840.86384259  9811.37726915  9977.58594521
  9767.19427495 10003.8943194   9961.2686131   9831.27741193
  9799.21932767  9848.06427759]
total_rewards_mean           9867.00031538879
total_rewards_std            78.26071790266208
total_rewards_max            10003.894319401554
total_rewards_min            9767.194274947227
Number of train steps total  528000
Number of env steps total    662000
Number of rollouts total     0
Train Time (s)               129.27174861123785
(Previous) Eval Time (s)     28.365213186014444
Sample Time (s)              21.809026898816228
Epoch Time (s)               179.44598869606853
Total Train Time (s)         23771.406402693596
Epoch                        131
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:23:55.231639 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #131 | Epoch Duration: 179.6031301021576
2020-01-13 11:23:55.231931 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #131 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6769643
Z variance train             0.0019305827
KL Divergence                51.279495
KL Loss                      5.1279497
QF Loss                      579.9872
VF Loss                      468.76892
Policy Loss                  -3785.6309
Q Predictions Mean           3781.521
Q Predictions Std            624.1742
Q Predictions Max            4648.3057
Q Predictions Min            -7.387533
V Predictions Mean           3770.6084
V Predictions Std            614.9255
V Predictions Max            4620.852
V Predictions Min            10.590668
Log Pis Mean                 5.4057236
Log Pis Std                  4.2037787
Log Pis Max                  19.22245
Log Pis Min                  -5.100568
Policy mu Mean               -0.22717507
Policy mu Std                1.3796407
Policy mu Max                3.1562302
Policy mu Min                -3.2082975
Policy log std Mean          -0.87718886
Policy log std Std           0.4433725
Policy log std Max           0.23794353
Policy log std Min           -3.3224015
Z mean eval                  3.708271
Z variance eval              0.0005767093
total_rewards                [10458.89484312 10558.48355002  9869.89587493 10602.12130231
 10558.04962695 10518.87605598 10359.390748   10597.10359502
 10350.06859239 10542.1782362 ]
total_rewards_mean           10441.506242492052
total_rewards_std            208.69578262937554
total_rewards_max            10602.12130231028
total_rewards_min            9869.895874932066
Number of train steps total  532000
Number of env steps total    667000
Number of rollouts total     0
Train Time (s)               136.4221535101533
(Previous) Eval Time (s)     28.522011290304363
Sample Time (s)              20.993925400078297
Epoch Time (s)               185.93809020053595
Total Train Time (s)         23957.629383116495
Epoch                        132
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:27:01.456771 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #132 | Epoch Duration: 186.2246720790863
2020-01-13 11:27:01.456978 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #132 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.710917
Z variance train             0.00057659775
KL Divergence                52.839294
KL Loss                      5.2839293
QF Loss                      759.283
VF Loss                      228.50203
Policy Loss                  -3838.781
Q Predictions Mean           3836.2002
Q Predictions Std            737.43024
Q Predictions Max            4709.1284
Q Predictions Min            -8.6767235
V Predictions Mean           3828.0764
V Predictions Std            731.0546
V Predictions Max            4703.3164
V Predictions Min            1.2365763
Log Pis Mean                 5.3391776
Log Pis Std                  3.873743
Log Pis Max                  16.582737
Log Pis Min                  -4.7486944
Policy mu Mean               -0.21114223
Policy mu Std                1.3953866
Policy mu Max                2.96196
Policy mu Min                -2.8723075
Policy log std Mean          -0.8937581
Policy log std Std           0.46897602
Policy log std Max           0.09574276
Policy log std Min           -3.274331
Z mean eval                  3.7036128
Z variance eval              0.0011741011
total_rewards                [10360.47787913 10286.57149248  9944.89122293 10066.09281358
 10264.38657461 10206.10686292 10508.73413472  2793.00732424
  9976.16026558 10298.43264627]
total_rewards_mean           9470.486121645903
total_rewards_std            2231.976429324037
total_rewards_max            10508.734134715693
total_rewards_min            2793.0073242426915
Number of train steps total  536000
Number of env steps total    672000
Number of rollouts total     0
Train Time (s)               134.48672204790637
(Previous) Eval Time (s)     28.808222969062626
Sample Time (s)              21.292879166081548
Epoch Time (s)               184.58782418305054
Total Train Time (s)         24141.927901800256
Epoch                        133
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:30:05.757922 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #133 | Epoch Duration: 184.30077934265137
2020-01-13 11:30:05.758220 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #133 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7018929
Z variance train             0.0011722024
KL Divergence                51.6166
KL Loss                      5.16166
QF Loss                      426.92633
VF Loss                      261.6759
Policy Loss                  -3835.8413
Q Predictions Mean           3838.4045
Q Predictions Std            692.5305
Q Predictions Max            4716.782
Q Predictions Min            33.522522
V Predictions Mean           3848.937
V Predictions Std            691.9285
V Predictions Max            4733.3237
V Predictions Min            8.299043
Log Pis Mean                 5.612073
Log Pis Std                  3.7497196
Log Pis Max                  15.554518
Log Pis Min                  -7.1565084
Policy mu Mean               -0.1391507
Policy mu Std                1.4025109
Policy mu Max                3.1299593
Policy mu Min                -2.878912
Policy log std Mean          -0.87137896
Policy log std Std           0.4531173
Policy log std Max           -0.04542041
Policy log std Min           -3.0614836
Z mean eval                  3.6833405
Z variance eval              0.0007395594
total_rewards                [10472.21575869 10589.62866749 10709.61939356 10535.99484306
  5668.70376266 10498.70998654  9852.64517593 10775.08407481
  6023.14015021 10711.02847382]
total_rewards_mean           9583.677028678165
total_rewards_std            1886.280333040356
total_rewards_max            10775.084074810646
total_rewards_min            5668.703762664031
Number of train steps total  540000
Number of env steps total    677000
Number of rollouts total     0
Train Time (s)               134.20733813103288
(Previous) Eval Time (s)     28.520822381135076
Sample Time (s)              21.560944257304072
Epoch Time (s)               184.28910476947203
Total Train Time (s)         24326.070459160488
Epoch                        134
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:33:09.904735 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #134 | Epoch Duration: 184.14631843566895
2020-01-13 11:33:09.905062 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #134 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6822228
Z variance train             0.00073719857
KL Divergence                53.391018
KL Loss                      5.339102
QF Loss                      597.584
VF Loss                      140.09476
Policy Loss                  -3772.3057
Q Predictions Mean           3769.5317
Q Predictions Std            745.9135
Q Predictions Max            4665.6484
Q Predictions Min            -3.8582513
V Predictions Mean           3772.3215
V Predictions Std            742.85614
V Predictions Max            4672.687
V Predictions Min            1.1657789
Log Pis Mean                 4.7448797
Log Pis Std                  3.887059
Log Pis Max                  17.308165
Log Pis Min                  -4.668476
Policy mu Mean               -0.17236882
Policy mu Std                1.3106791
Policy mu Max                3.3186007
Policy mu Min                -3.0356035
Policy log std Mean          -0.88898355
Policy log std Std           0.44631666
Policy log std Max           0.09269261
Policy log std Min           -3.1626976
Z mean eval                  3.6803055
Z variance eval              0.0014467121
total_rewards                [10353.65129985 10436.92783025 10591.48875135 10590.5592898
 10630.98185943 10473.26235981 10449.52637446 10484.21124519
 10527.85183633 10578.58270654]
total_rewards_mean           10511.70435530071
total_rewards_std            82.59315044561397
total_rewards_max            10630.981859426995
total_rewards_min            10353.651299848923
Number of train steps total  544000
Number of env steps total    682000
Number of rollouts total     0
Train Time (s)               133.62753750709817
(Previous) Eval Time (s)     28.377666444983333
Sample Time (s)              22.681342816911638
Epoch Time (s)               184.68654676899314
Total Train Time (s)         24511.0988665428
Epoch                        135
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:36:14.933925 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #135 | Epoch Duration: 185.02866506576538
2020-01-13 11:36:14.934247 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #135 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6819205
Z variance train             0.0014485866
KL Divergence                51.864574
KL Loss                      5.1864576
QF Loss                      433.28278
VF Loss                      256.8193
Policy Loss                  -3848.205
Q Predictions Mean           3847.807
Q Predictions Std            655.89703
Q Predictions Max            4733.3755
Q Predictions Min            4.625661
V Predictions Mean           3839.7783
V Predictions Std            651.0347
V Predictions Max            4708.035
V Predictions Min            1.04614
Log Pis Mean                 5.455331
Log Pis Std                  3.891383
Log Pis Max                  14.831242
Log Pis Min                  -3.5160918
Policy mu Mean               -0.16183071
Policy mu Std                1.3961431
Policy mu Max                3.873818
Policy mu Min                -3.1648455
Policy log std Mean          -0.8801773
Policy log std Std           0.46357933
Policy log std Max           -0.13365233
Policy log std Min           -3.2658565
Z mean eval                  3.6828568
Z variance eval              0.0017565197
total_rewards                [10447.0703559  10538.27268316 10607.36518557  8761.97562038
 10519.20845456 10483.15274934 10739.74772649 10666.72988355
 10640.3614981  10544.02168936]
total_rewards_mean           10394.790584639888
total_rewards_std            550.7632923706766
total_rewards_max            10739.747726489359
total_rewards_min            8761.975620375024
Number of train steps total  548000
Number of env steps total    687000
Number of rollouts total     0
Train Time (s)               129.8908640719019
(Previous) Eval Time (s)     28.719412684906274
Sample Time (s)              21.154524938203394
Epoch Time (s)               179.76480169501156
Total Train Time (s)         24690.389380773064
Epoch                        136
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:39:14.227156 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #136 | Epoch Duration: 179.29271960258484
2020-01-13 11:39:14.227427 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #136 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6872826
Z variance train             0.0017497673
KL Divergence                51.30224
KL Loss                      5.1302238
QF Loss                      560.1452
VF Loss                      632.62756
Policy Loss                  -3805.4663
Q Predictions Mean           3808.5388
Q Predictions Std            772.23724
Q Predictions Max            4702.7295
Q Predictions Min            -4.2702227
V Predictions Mean           3783.3035
V Predictions Std            764.1214
V Predictions Max            4655.322
V Predictions Min            0.6547515
Log Pis Mean                 4.735177
Log Pis Std                  3.7029235
Log Pis Max                  17.685656
Log Pis Min                  -3.9785037
Policy mu Mean               -0.223291
Policy mu Std                1.3035539
Policy mu Max                3.7173715
Policy mu Min                -3.4439256
Policy log std Mean          -0.89297444
Policy log std Std           0.45913956
Policy log std Max           -0.058267415
Policy log std Min           -3.1590438
Z mean eval                  3.6529725
Z variance eval              0.007695978
total_rewards                [10432.71981522 10537.88008489 10608.66435739 10413.35921957
 10564.22875012 10532.65722846 10604.89622521 10483.53219679
 10561.4905366  10485.3381844 ]
total_rewards_mean           10522.476659865768
total_rewards_std            63.7858742639738
total_rewards_max            10608.664357392066
total_rewards_min            10413.35921956681
Number of train steps total  552000
Number of env steps total    692000
Number of rollouts total     0
Train Time (s)               127.86264576017857
(Previous) Eval Time (s)     28.246917746961117
Sample Time (s)              21.837552790064365
Epoch Time (s)               177.94711629720405
Total Train Time (s)         24867.589064446278
Epoch                        137
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:42:11.428656 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #137 | Epoch Duration: 177.20106196403503
2020-01-13 11:42:11.428844 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #137 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6533437
Z variance train             0.0077094757
KL Divergence                49.862625
KL Loss                      4.986263
QF Loss                      432.0794
VF Loss                      202.0195
Policy Loss                  -3834.6208
Q Predictions Mean           3836.0996
Q Predictions Std            779.9092
Q Predictions Max            4790.231
Q Predictions Min            -15.915215
V Predictions Mean           3831.1274
V Predictions Std            776.619
V Predictions Max            4780.7256
V Predictions Min            0.656621
Log Pis Mean                 5.6344004
Log Pis Std                  3.8074663
Log Pis Max                  16.765442
Log Pis Min                  -4.929572
Policy mu Mean               -0.17085968
Policy mu Std                1.399727
Policy mu Max                2.8444579
Policy mu Min                -3.0396848
Policy log std Mean          -0.86812717
Policy log std Std           0.4719866
Policy log std Max           0.009148717
Policy log std Min           -3.3457236
Z mean eval                  3.6485023
Z variance eval              0.018462628
total_rewards                [10534.48169078 10518.59563105 10596.7443996  10780.31608985
 10676.56420835 10724.26266413  4005.02157556 10367.59559574
 10638.74311435 10620.7236158 ]
total_rewards_mean           9946.304858522224
total_rewards_std            1983.4630433212653
total_rewards_max            10780.316089853597
total_rewards_min            4005.021575560001
Number of train steps total  556000
Number of env steps total    697000
Number of rollouts total     0
Train Time (s)               128.78258376009762
(Previous) Eval Time (s)     27.500549885910004
Sample Time (s)              21.28416236070916
Epoch Time (s)               177.5672960067168
Total Train Time (s)         25046.023332400247
Epoch                        138
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:45:09.866596 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #138 | Epoch Duration: 178.43759727478027
2020-01-13 11:45:09.866889 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #138 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6489098
Z variance train             0.018418876
KL Divergence                47.249336
KL Loss                      4.7249336
QF Loss                      565.99396
VF Loss                      179.72249
Policy Loss                  -3866.6172
Q Predictions Mean           3863.437
Q Predictions Std            750.0068
Q Predictions Max            4767.7197
Q Predictions Min            -3.563533
V Predictions Mean           3866.967
V Predictions Std            748.3193
V Predictions Max            4748.5244
V Predictions Min            0.65889126
Log Pis Mean                 5.304464
Log Pis Std                  3.678974
Log Pis Max                  15.266615
Log Pis Min                  -3.733355
Policy mu Mean               -0.090088785
Policy mu Std                1.4003755
Policy mu Max                2.9566562
Policy mu Min                -3.1558177
Policy log std Mean          -0.8644802
Policy log std Std           0.44941366
Policy log std Max           -0.04281175
Policy log std Min           -3.4120522
Z mean eval                  3.6796448
Z variance eval              0.0050260653
total_rewards                [10400.68485166 10292.50981411 10389.68332288 10470.36526105
 10479.18359651 10426.05786213 10364.58168774 10265.81445877
 10428.12288034 10404.8379711 ]
total_rewards_mean           10392.18417063011
total_rewards_std            65.59345531473019
total_rewards_max            10479.183596510436
total_rewards_min            10265.814458772287
Number of train steps total  560000
Number of env steps total    702000
Number of rollouts total     0
Train Time (s)               136.39476605784148
(Previous) Eval Time (s)     28.3705060868524
Sample Time (s)              21.080569720827043
Epoch Time (s)               185.84584186552092
Total Train Time (s)         25232.490187210497
Epoch                        139
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:48:16.335262 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #139 | Epoch Duration: 186.46812534332275
2020-01-13 11:48:16.335458 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #139 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6797976
Z variance train             0.005033323
KL Divergence                47.297585
KL Loss                      4.7297587
QF Loss                      451.66983
VF Loss                      151.88248
Policy Loss                  -3884.5571
Q Predictions Mean           3882.4128
Q Predictions Std            773.37427
Q Predictions Max            4747.9683
Q Predictions Min            -25.508759
V Predictions Mean           3881.4346
V Predictions Std            770.73724
V Predictions Max            4694.461
V Predictions Min            4.0063453
Log Pis Mean                 5.3082952
Log Pis Std                  4.1040277
Log Pis Max                  15.752396
Log Pis Min                  -7.928732
Policy mu Mean               -0.17961657
Policy mu Std                1.3739685
Policy mu Max                3.0278668
Policy mu Min                -3.2700155
Policy log std Mean          -0.8885629
Policy log std Std           0.4893024
Policy log std Max           -0.047089756
Policy log std Min           -3.4342484
Z mean eval                  3.6838672
Z variance eval              0.00520881
total_rewards                [ 9959.73856831  9780.07624683 10095.06792095  9928.18263636
 10025.35623367  9883.17146426  9933.20571366  9971.88369716
  9940.85842252  9909.65682787]
total_rewards_mean           9942.71977315775
total_rewards_std            79.10518503558725
total_rewards_max            10095.067920948979
total_rewards_min            9780.076246828014
Number of train steps total  564000
Number of env steps total    707000
Number of rollouts total     0
Train Time (s)               135.6157327410765
(Previous) Eval Time (s)     28.992463981267065
Sample Time (s)              22.481285843998194
Epoch Time (s)               187.08948256634176
Total Train Time (s)         25419.232363101095
Epoch                        140
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:51:23.079723 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #140 | Epoch Duration: 186.74412488937378
2020-01-13 11:51:23.079911 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #140 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.68647
Z variance train             0.0051917857
KL Divergence                46.679024
KL Loss                      4.6679025
QF Loss                      595.1618
VF Loss                      205.30516
Policy Loss                  -3910.835
Q Predictions Mean           3918.0232
Q Predictions Std            735.2192
Q Predictions Max            4796.6177
Q Predictions Min            -6.589731
V Predictions Mean           3911.501
V Predictions Std            728.8932
V Predictions Max            4778.026
V Predictions Min            2.4539292
Log Pis Mean                 5.264282
Log Pis Std                  4.2004886
Log Pis Max                  17.018736
Log Pis Min                  -10.392864
Policy mu Mean               -0.16772087
Policy mu Std                1.3718004
Policy mu Max                3.3479543
Policy mu Min                -2.7965574
Policy log std Mean          -0.89517623
Policy log std Std           0.48417556
Policy log std Max           0.08814871
Policy log std Min           -3.183539
Z mean eval                  3.6636555
Z variance eval              0.005824762
total_rewards                [10316.28477321 10495.8480616  10770.45487131 10561.43837793
 10393.99860579 10460.36125353 10371.53241399 10448.83617707
 10775.91496572 10575.1507888 ]
total_rewards_mean           10516.982028895563
total_rewards_std            148.83246769007022
total_rewards_max            10775.91496571775
total_rewards_min            10316.284773211175
Number of train steps total  568000
Number of env steps total    712000
Number of rollouts total     0
Train Time (s)               134.84724918799475
(Previous) Eval Time (s)     28.64676657691598
Sample Time (s)              22.591051113326102
Epoch Time (s)               186.08506687823683
Total Train Time (s)         25604.96168521326
Epoch                        141
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:54:28.812637 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #141 | Epoch Duration: 185.73254680633545
2020-01-13 11:54:28.812984 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #141 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6655629
Z variance train             0.005823686
KL Divergence                45.776573
KL Loss                      4.577657
QF Loss                      345.2226
VF Loss                      341.832
Policy Loss                  -3842.4092
Q Predictions Mean           3840.5188
Q Predictions Std            624.7239
Q Predictions Max            4749.162
Q Predictions Min            -16.683987
V Predictions Mean           3835.6013
V Predictions Std            620.1101
V Predictions Max            4760.073
V Predictions Min            0.6648696
Log Pis Mean                 5.4185867
Log Pis Std                  3.7889879
Log Pis Max                  16.627195
Log Pis Min                  -3.8032546
Policy mu Mean               -0.15783113
Policy mu Std                1.388839
Policy mu Max                3.6510723
Policy mu Min                -2.9478703
Policy log std Mean          -0.8966121
Policy log std Std           0.45972654
Policy log std Max           0.11949015
Policy log std Min           -3.1946177
Z mean eval                  3.6715775
Z variance eval              0.01220824
total_rewards                [10690.33541265 10680.28485155  8837.76789145 10824.27633896
 10717.54477186 10814.61595304 10644.27781195 10688.04125498
 10872.7615724  10623.18804502]
total_rewards_mean           10539.309390385539
total_rewards_std            572.5434177895003
total_rewards_max            10872.761572397503
total_rewards_min            8837.767891450996
Number of train steps total  572000
Number of env steps total    717000
Number of rollouts total     0
Train Time (s)               134.54794588685036
(Previous) Eval Time (s)     28.293876271229237
Sample Time (s)              23.88186610583216
Epoch Time (s)               186.72368826391175
Total Train Time (s)         25792.296348426957
Epoch                        142
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:57:36.152613 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #142 | Epoch Duration: 187.3394181728363
2020-01-13 11:57:36.153016 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #142 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6716816
Z variance train             0.01223633
KL Divergence                44.31911
KL Loss                      4.431911
QF Loss                      488.88663
VF Loss                      157.54417
Policy Loss                  -3897.8809
Q Predictions Mean           3895.2793
Q Predictions Std            622.2749
Q Predictions Max            4776.975
Q Predictions Min            2.9734066
V Predictions Mean           3893.7808
V Predictions Std            610.8922
V Predictions Max            4767.4585
V Predictions Min            8.324123
Log Pis Mean                 5.9370003
Log Pis Std                  3.7763386
Log Pis Max                  23.865543
Log Pis Min                  -4.8314595
Policy mu Mean               -0.18095861
Policy mu Std                1.4221009
Policy mu Max                3.6692567
Policy mu Min                -3.6290123
Policy log std Mean          -0.8837282
Policy log std Std           0.46405432
Policy log std Max           0.01167953
Policy log std Min           -3.2318501
Z mean eval                  3.6607838
Z variance eval              0.0142524075
total_rewards                [10269.74781992 10636.70124567 10454.34093354 10448.13942049
 10474.8466632  10227.56202334 10684.21824085 10458.68597865
 10555.9546689  10389.16075088]
total_rewards_mean           10459.935774543108
total_rewards_std            136.50668835649137
total_rewards_max            10684.218240846532
total_rewards_min            10227.562023336883
Number of train steps total  576000
Number of env steps total    722000
Number of rollouts total     0
Train Time (s)               129.50145043991506
(Previous) Eval Time (s)     28.909165534190834
Sample Time (s)              22.7731721252203
Epoch Time (s)               181.1837880993262
Total Train Time (s)         25972.63630629843
Epoch                        143
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:00:36.492898 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #143 | Epoch Duration: 180.3396189212799
2020-01-13 12:00:36.493208 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #143 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.661801
Z variance train             0.014282365
KL Divergence                44.145576
KL Loss                      4.414558
QF Loss                      490.48737
VF Loss                      849.8627
Policy Loss                  -3814.942
Q Predictions Mean           3813.4038
Q Predictions Std            662.68164
Q Predictions Max            4715.6978
Q Predictions Min            9.210124
V Predictions Mean           3795.1313
V Predictions Std            655.6429
V Predictions Max            4700.5215
V Predictions Min            4.854921
Log Pis Mean                 5.3979692
Log Pis Std                  4.468587
Log Pis Max                  30.794788
Log Pis Min                  -6.448827
Policy mu Mean               -0.09670343
Policy mu Std                1.408845
Policy mu Max                4.644295
Policy mu Min                -4.73896
Policy log std Mean          -0.89096946
Policy log std Std           0.44904655
Policy log std Max           0.025142431
Policy log std Min           -3.0636678
Z mean eval                  3.658072
Z variance eval              0.012036691
total_rewards                [10365.20761585 10731.20441699 10234.91829939 10494.16473988
 10728.951435   10648.59784847 10679.61803468 10647.94777169
 10540.16461885 10702.69242675]
total_rewards_mean           10577.346720753594
total_rewards_std            159.20124168994707
total_rewards_max            10731.204416988663
total_rewards_min            10234.91829939348
Number of train steps total  580000
Number of env steps total    727000
Number of rollouts total     0
Train Time (s)               127.58893885510042
(Previous) Eval Time (s)     28.06463574571535
Sample Time (s)              21.936970790382475
Epoch Time (s)               177.59054539119825
Total Train Time (s)         26148.878153123427
Epoch                        144
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:03:32.736611 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #144 | Epoch Duration: 176.24318981170654
2020-01-13 12:03:32.736802 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #144 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6607068
Z variance train             0.012083517
KL Divergence                43.433758
KL Loss                      4.3433757
QF Loss                      581.17804
VF Loss                      236.30284
Policy Loss                  -3946.8677
Q Predictions Mean           3949.9097
Q Predictions Std            664.2261
Q Predictions Max            4837.9033
Q Predictions Min            8.305777
V Predictions Mean           3941.1187
V Predictions Std            654.6379
V Predictions Max            4803.173
V Predictions Min            1.371416
Log Pis Mean                 5.431632
Log Pis Std                  3.7775319
Log Pis Max                  14.9472885
Log Pis Min                  -3.8925068
Policy mu Mean               -0.18324555
Policy mu Std                1.358679
Policy mu Max                3.1176183
Policy mu Min                -3.15588
Policy log std Mean          -0.883424
Policy log std Std           0.45222563
Policy log std Max           -0.06543052
Policy log std Min           -3.3267193
Z mean eval                  3.6441796
Z variance eval              0.023505524
total_rewards                [10376.55314459 10461.38440921  8326.74854048 10562.20502991
 10618.1973326  10643.63137852  4899.47463872 10778.56341239
 10514.11965237 10641.07716693]
total_rewards_mean           9782.195470572715
total_rewards_std            1763.21787786833
total_rewards_max            10778.563412392994
total_rewards_min            4899.4746387198
Number of train steps total  584000
Number of env steps total    732000
Number of rollouts total     0
Train Time (s)               130.8596547106281
(Previous) Eval Time (s)     26.716999953147024
Sample Time (s)              22.09369710786268
Epoch Time (s)               179.6703517716378
Total Train Time (s)         26330.584065156523
Epoch                        145
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:06:34.444681 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #145 | Epoch Duration: 181.70773720741272
2020-01-13 12:06:34.444872 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #145 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6449592
Z variance train             0.023516307
KL Divergence                41.64554
KL Loss                      4.164554
QF Loss                      423.65442
VF Loss                      257.66052
Policy Loss                  -3914.9204
Q Predictions Mean           3917.7212
Q Predictions Std            600.5266
Q Predictions Max            4704.905
Q Predictions Min            -4.2327557
V Predictions Mean           3925.5098
V Predictions Std            597.88165
V Predictions Max            4699.0757
V Predictions Min            0.89975935
Log Pis Mean                 5.1360846
Log Pis Std                  3.695374
Log Pis Max                  14.961201
Log Pis Min                  -4.233493
Policy mu Mean               -0.21583645
Policy mu Std                1.3460199
Policy mu Max                2.6870127
Policy mu Min                -2.91968
Policy log std Mean          -0.8861981
Policy log std Std           0.4582933
Policy log std Max           -0.04280162
Policy log std Min           -3.209268
Z mean eval                  3.6677406
Z variance eval              0.016328132
total_rewards                [10505.02587635 10354.32120796 10511.35882932 10754.76361353
 10716.83650097 10485.78502984 10828.8638132  10798.28588979
 10679.66190709 10730.46492008]
total_rewards_mean           10636.536758814507
total_rewards_std            151.524493086537
total_rewards_max            10828.863813202868
total_rewards_min            10354.321207964536
Number of train steps total  588000
Number of env steps total    737000
Number of rollouts total     0
Train Time (s)               136.4745147936046
(Previous) Eval Time (s)     28.754039861261845
Sample Time (s)              22.818145434372127
Epoch Time (s)               188.04670008923858
Total Train Time (s)         26517.012423522305
Epoch                        146
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:09:40.875411 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #146 | Epoch Duration: 186.43039846420288
2020-01-13 12:09:40.875601 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #146 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6685078
Z variance train             0.01620378
KL Divergence                43.166397
KL Loss                      4.31664
QF Loss                      608.8887
VF Loss                      172.57071
Policy Loss                  -3946.419
Q Predictions Mean           3952.7925
Q Predictions Std            654.0816
Q Predictions Max            4743.4556
Q Predictions Min            19.305847
V Predictions Mean           3945.9565
V Predictions Std            651.53625
V Predictions Max            4719.2964
V Predictions Min            0.6773453
Log Pis Mean                 5.3327265
Log Pis Std                  3.6760566
Log Pis Max                  16.283615
Log Pis Min                  -2.3069801
Policy mu Mean               -0.16533168
Policy mu Std                1.3796403
Policy mu Max                2.8024902
Policy mu Min                -3.12192
Policy log std Mean          -0.8855643
Policy log std Std           0.44225788
Policy log std Max           0.018773794
Policy log std Min           -3.1177673
Z mean eval                  3.6492143
Z variance eval              0.017731631
total_rewards                [10455.51386194 10771.71974929  9984.07658948 10774.59974189
 10777.49062988 10591.62707777 10649.96357673 10671.36268862
 10598.97053721 10597.52880182]
total_rewards_mean           10587.285325463023
total_rewards_std            223.1060718271018
total_rewards_max            10777.490629880773
total_rewards_min            9984.076589480497
Number of train steps total  592000
Number of env steps total    742000
Number of rollouts total     0
Train Time (s)               136.12170601915568
(Previous) Eval Time (s)     27.137289092876017
Sample Time (s)              22.049510543700308
Epoch Time (s)               185.308505655732
Total Train Time (s)         26702.283263215795
Epoch                        147
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:12:46.150300 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #147 | Epoch Duration: 185.2745325565338
2020-01-13 12:12:46.150613 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #147 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6487212
Z variance train             0.017744133
KL Divergence                42.825665
KL Loss                      4.2825665
QF Loss                      653.4945
VF Loss                      272.636
Policy Loss                  -3900.5557
Q Predictions Mean           3899.8022
Q Predictions Std            783.1733
Q Predictions Max            4853.789
Q Predictions Min            8.278775
V Predictions Mean           3905.0886
V Predictions Std            783.11993
V Predictions Max            4847.24
V Predictions Min            3.0186992
Log Pis Mean                 5.53718
Log Pis Std                  4.1830225
Log Pis Max                  14.787542
Log Pis Min                  -5.317417
Policy mu Mean               -0.15272032
Policy mu Std                1.4080901
Policy mu Max                2.993558
Policy mu Min                -3.0371468
Policy log std Mean          -0.8919091
Policy log std Std           0.49417973
Policy log std Max           0.15778661
Policy log std Min           -3.342311
Z mean eval                  3.6632857
Z variance eval              0.0070468127
total_rewards                [10446.70303447 10650.8016095  10604.59023767 10646.75811678
 10401.07753521 10556.89362603 10318.15340808 10644.13691957
 10472.12079759 10602.62001313]
total_rewards_mean           10534.385529802925
total_rewards_std            111.53896106110902
total_rewards_max            10650.801609501383
total_rewards_min            10318.153408077178
Number of train steps total  596000
Number of env steps total    747000
Number of rollouts total     0
Train Time (s)               135.5716213178821
(Previous) Eval Time (s)     27.102903032209724
Sample Time (s)              21.670174649450928
Epoch Time (s)               184.34469899954274
Total Train Time (s)         26887.61054643942
Epoch                        148
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:15:51.479349 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #148 | Epoch Duration: 185.32854533195496
2020-01-13 12:15:51.479665 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #148 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6610122
Z variance train             0.0070425607
KL Divergence                45.84121
KL Loss                      4.584121
QF Loss                      519.0857
VF Loss                      149.57529
Policy Loss                  -3911.4653
Q Predictions Mean           3915.5083
Q Predictions Std            672.8277
Q Predictions Max            4743.8193
Q Predictions Min            0.98441005
V Predictions Mean           3914.9722
V Predictions Std            670.8322
V Predictions Max            4719.0366
V Predictions Min            1.1766135
Log Pis Mean                 5.428936
Log Pis Std                  3.8269923
Log Pis Max                  14.966433
Log Pis Min                  -4.972481
Policy mu Mean               -0.16511315
Policy mu Std                1.3999077
Policy mu Max                3.029141
Policy mu Min                -4.7251153
Policy log std Mean          -0.8924007
Policy log std Std           0.46220142
Policy log std Max           0.07448459
Policy log std Min           -3.4810967
Z mean eval                  3.6776938
Z variance eval              0.013423798
total_rewards                [10439.71323712 10649.418833   10607.11551985 10609.43496339
 10261.98674656 10549.90839665 10643.98906479 10485.30634495
 10733.63116497 10453.07297699]
total_rewards_mean           10543.357724826417
total_rewards_std            129.41672306887457
total_rewards_max            10733.631164972374
total_rewards_min            10261.986746559875
Number of train steps total  600000
Number of env steps total    752000
Number of rollouts total     0
Train Time (s)               134.0590242310427
(Previous) Eval Time (s)     28.086373732890934
Sample Time (s)              20.157695970498025
Epoch Time (s)               182.30309393443167
Total Train Time (s)         27070.987521463074
Epoch                        149
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:18:54.858233 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #149 | Epoch Duration: 183.37839078903198
2020-01-13 12:18:54.858426 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #149 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6763797
Z variance train             0.013410926
KL Divergence                45.477
KL Loss                      4.5477004
QF Loss                      791.8314
VF Loss                      265.87335
Policy Loss                  -3987.284
Q Predictions Mean           3990.884
Q Predictions Std            621.28925
Q Predictions Max            4792.639
Q Predictions Min            14.519992
V Predictions Mean           3998.6963
V Predictions Std            617.65967
V Predictions Max            4793.786
V Predictions Min            7.203893
Log Pis Mean                 5.7321305
Log Pis Std                  3.785638
Log Pis Max                  16.208086
Log Pis Min                  -2.7542686
Policy mu Mean               -0.108720206
Policy mu Std                1.4029317
Policy mu Max                2.9085763
Policy mu Min                -2.783386
Policy log std Mean          -0.882459
Policy log std Std           0.47960573
Policy log std Max           0.1604706
Policy log std Min           -3.310248
Z mean eval                  3.65415
Z variance eval              0.011936234
total_rewards                [10504.75929997 10632.47036193 10551.6502664  10717.69674761
 10633.773417   10600.46541552 10437.79410135 10429.34288576
 10554.17181595 10588.75843963]
total_rewards_mean           10565.088275111932
total_rewards_std            85.39854259560099
total_rewards_max            10717.696747611772
total_rewards_min            10429.342885759093
Number of train steps total  604000
Number of env steps total    757000
Number of rollouts total     0
Train Time (s)               128.38797142496333
(Previous) Eval Time (s)     29.16135272802785
Sample Time (s)              23.328725907951593
Epoch Time (s)               180.87805006094277
Total Train Time (s)         27250.04318032693
Epoch                        150
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:21:53.916716 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #150 | Epoch Duration: 179.05814480781555
2020-01-13 12:21:53.916926 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #150 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.656915
Z variance train             0.011930448
KL Divergence                45.09022
KL Loss                      4.509022
QF Loss                      581.89087
VF Loss                      126.04622
Policy Loss                  -3902.5728
Q Predictions Mean           3905.9624
Q Predictions Std            791.4915
Q Predictions Max            4872.404
Q Predictions Min            -1.4834181
V Predictions Mean           3901.2854
V Predictions Std            784.9827
V Predictions Max            4854.317
V Predictions Min            6.529177
Log Pis Mean                 4.823183
Log Pis Std                  3.8321981
Log Pis Max                  14.763799
Log Pis Min                  -5.4598722
Policy mu Mean               -0.18233979
Policy mu Std                1.3496904
Policy mu Max                3.1644866
Policy mu Min                -2.934999
Policy log std Mean          -0.884779
Policy log std Std           0.4507609
Policy log std Max           -0.009675145
Policy log std Min           -3.3408198
Z mean eval                  3.646886
Z variance eval              0.00496574
total_rewards                [10641.38447364 10908.90120941 10656.62460268 10768.66390843
 10648.81981127 10094.51083189 10679.78241381  6734.73612145
 10741.63176623 10907.54964173]
total_rewards_mean           10278.260478053657
total_rewards_std            1200.5333143417638
total_rewards_max            10908.90120940511
total_rewards_min            6734.736121445723
Number of train steps total  608000
Number of env steps total    762000
Number of rollouts total     0
Train Time (s)               128.08289430104196
(Previous) Eval Time (s)     27.34105284465477
Sample Time (s)              21.89229332143441
Epoch Time (s)               177.31624046713114
Total Train Time (s)         27427.978892229497
Epoch                        151
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:24:51.854278 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #151 | Epoch Duration: 177.93720841407776
2020-01-13 12:24:51.854463 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #151 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.648597
Z variance train             0.0049558906
KL Divergence                46.36361
KL Loss                      4.636361
QF Loss                      677.49084
VF Loss                      326.44653
Policy Loss                  -3911.7703
Q Predictions Mean           3908.1626
Q Predictions Std            768.8941
Q Predictions Max            4911.8247
Q Predictions Min            8.078924
V Predictions Mean           3898.269
V Predictions Std            763.27496
V Predictions Max            4883.3594
V Predictions Min            6.9254494
Log Pis Mean                 5.1674776
Log Pis Std                  4.2003913
Log Pis Max                  19.510328
Log Pis Min                  -5.146639
Policy mu Mean               -0.087082714
Policy mu Std                1.3706518
Policy mu Max                4.1575246
Policy mu Min                -3.8350785
Policy log std Mean          -0.8770252
Policy log std Std           0.4416258
Policy log std Max           -0.027753472
Policy log std Min           -3.3839283
Z mean eval                  3.6297615
Z variance eval              0.01060865
total_rewards                [10732.64386303 10725.52472851 10851.79598315 10951.42380349
 10949.19252071 10770.900803   10528.74424242 10893.06708404
 10788.17198501 10700.02168179]
total_rewards_mean           10789.148669513803
total_rewards_std            122.47440522610951
total_rewards_max            10951.423803485997
total_rewards_min            10528.744242417884
Number of train steps total  612000
Number of env steps total    767000
Number of rollouts total     0
Train Time (s)               130.60092774499208
(Previous) Eval Time (s)     27.961699937004596
Sample Time (s)              21.717693641781807
Epoch Time (s)               180.28032132377848
Total Train Time (s)         27608.870082451962
Epoch                        152
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:27:52.747560 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #152 | Epoch Duration: 180.89296674728394
2020-01-13 12:27:52.747734 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #152 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.629193
Z variance train             0.010617684
KL Divergence                46.371315
KL Loss                      4.6371317
QF Loss                      569.86383
VF Loss                      216.3614
Policy Loss                  -3907.4404
Q Predictions Mean           3914.984
Q Predictions Std            665.3691
Q Predictions Max            4841.0493
Q Predictions Min            18.34501
V Predictions Mean           3915.442
V Predictions Std            664.05334
V Predictions Max            4834.3594
V Predictions Min            11.014871
Log Pis Mean                 5.1981077
Log Pis Std                  3.7329068
Log Pis Max                  16.04581
Log Pis Min                  -4.579486
Policy mu Mean               -0.17835599
Policy mu Std                1.3619963
Policy mu Max                3.2841136
Policy mu Min                -3.230912
Policy log std Mean          -0.9010183
Policy log std Std           0.46844852
Policy log std Max           0.09290326
Policy log std Min           -3.3149302
Z mean eval                  3.6587899
Z variance eval              0.0031380255
total_rewards                [10529.80933163 10466.28870028 10587.06541777 10257.92410785
 10399.53623693 10449.65792992 10204.17548811 10308.98181625
 10373.35946811 10471.14826132]
total_rewards_mean           10404.794675815674
total_rewards_std            114.48286430426691
total_rewards_max            10587.065417767608
total_rewards_min            10204.175488106875
Number of train steps total  616000
Number of env steps total    772000
Number of rollouts total     0
Train Time (s)               137.52854673098773
(Previous) Eval Time (s)     28.57399261696264
Sample Time (s)              22.164751586969942
Epoch Time (s)               188.2672909349203
Total Train Time (s)         27796.929239398334
Epoch                        153
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:31:00.810442 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #153 | Epoch Duration: 188.0625455379486
2020-01-13 12:31:00.810747 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #153 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6564934
Z variance train             0.0031446791
KL Divergence                48.58307
KL Loss                      4.858307
QF Loss                      719.0442
VF Loss                      244.2054
Policy Loss                  -4061.193
Q Predictions Mean           4069.3667
Q Predictions Std            621.0736
Q Predictions Max            4852.381
Q Predictions Min            -0.4432959
V Predictions Mean           4071.3066
V Predictions Std            615.5919
V Predictions Max            4858.033
V Predictions Min            6.4658694
Log Pis Mean                 5.5620265
Log Pis Std                  3.516111
Log Pis Max                  14.710883
Log Pis Min                  -3.8218338
Policy mu Mean               -0.1422366
Policy mu Std                1.4128752
Policy mu Max                3.0360794
Policy mu Min                -2.9859319
Policy log std Mean          -0.8911393
Policy log std Std           0.4397777
Policy log std Max           -0.014258027
Policy log std Min           -3.0126023
Z mean eval                  3.6331844
Z variance eval              0.0029227561
total_rewards                [10395.39579291 10948.89228412  5093.58472342 11060.74668137
 10252.91618422 10794.43252585 10723.12420824 10785.97913135
 10212.40270374 10884.32615687]
total_rewards_mean           10115.180039209084
total_rewards_std            1696.6164411561124
total_rewards_max            11060.746681370869
total_rewards_min            5093.58472341945
Number of train steps total  620000
Number of env steps total    777000
Number of rollouts total     0
Train Time (s)               135.7831708341837
(Previous) Eval Time (s)     28.36880421033129
Sample Time (s)              22.586500524543226
Epoch Time (s)               186.7384755690582
Total Train Time (s)         27981.95357262157
Epoch                        154
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:34:05.836440 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #154 | Epoch Duration: 185.0255105495453
2020-01-13 12:34:05.836640 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #154 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6328552
Z variance train             0.002914553
KL Divergence                47.936333
KL Loss                      4.7936335
QF Loss                      435.2403
VF Loss                      324.50815
Policy Loss                  -4086.3074
Q Predictions Mean           4087.9836
Q Predictions Std            617.1957
Q Predictions Max            4853.689
Q Predictions Min            -8.05782
V Predictions Mean           4091.4482
V Predictions Std            609.946
V Predictions Max            4839.064
V Predictions Min            10.61514
Log Pis Mean                 5.983956
Log Pis Std                  3.8236942
Log Pis Max                  15.040997
Log Pis Min                  -4.1124606
Policy mu Mean               -0.080508605
Policy mu Std                1.4338902
Policy mu Max                3.7814565
Policy mu Min                -3.5849857
Policy log std Mean          -0.9093649
Policy log std Std           0.50699663
Policy log std Max           0.054230392
Policy log std Min           -3.3869946
Z mean eval                  3.6367402
Z variance eval              0.006939194
total_rewards                [ 7932.0665716   5607.40457915 10594.86817149 10881.73885388
 10659.85327597 10371.63953818  3582.66540213 10840.94837283
 10576.36146665  6765.07113325]
total_rewards_mean           8781.261736512122
total_rewards_std            2512.1544997623455
total_rewards_max            10881.73885388282
total_rewards_min            3582.6654021284244
Number of train steps total  624000
Number of env steps total    782000
Number of rollouts total     0
Train Time (s)               135.42157290689647
(Previous) Eval Time (s)     26.65552082285285
Sample Time (s)              21.145627141930163
Epoch Time (s)               183.22272087167948
Total Train Time (s)         28166.9136342532
Epoch                        155
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:37:10.798891 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #155 | Epoch Duration: 184.96210980415344
2020-01-13 12:37:10.799077 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #155 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6375313
Z variance train             0.006928765
KL Divergence                48.35195
KL Loss                      4.835195
QF Loss                      501.1524
VF Loss                      242.5532
Policy Loss                  -3984.1812
Q Predictions Mean           3980.514
Q Predictions Std            621.44244
Q Predictions Max            4851.0376
Q Predictions Min            1.4469135
V Predictions Mean           3981.4546
V Predictions Std            613.3041
V Predictions Max            4838.4844
V Predictions Min            7.9339595
Log Pis Mean                 5.5945654
Log Pis Std                  3.5927367
Log Pis Max                  15.389729
Log Pis Min                  -3.7766867
Policy mu Mean               -0.12550549
Policy mu Std                1.3958337
Policy mu Max                4.044029
Policy mu Min                -3.5200918
Policy log std Mean          -0.9038608
Policy log std Std           0.46285465
Policy log std Max           0.009615183
Policy log std Min           -3.1156306
Z mean eval                  3.6358085
Z variance eval              0.0047810264
total_rewards                [10397.85447366 10446.29938861 10796.56059797 10554.81839904
 10775.79633054 10599.98802983 10551.52157822 10663.04895206
 10704.99489238 10697.86904306]
total_rewards_mean           10618.87516853657
total_rewards_std            126.26692850854432
total_rewards_max            10796.56059796503
total_rewards_min            10397.854473661522
Number of train steps total  628000
Number of env steps total    787000
Number of rollouts total     0
Train Time (s)               134.95490450505167
(Previous) Eval Time (s)     28.394552187994123
Sample Time (s)              21.498818713705987
Epoch Time (s)               184.84827540675178
Total Train Time (s)         28352.703894325532
Epoch                        156
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:40:16.592097 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #156 | Epoch Duration: 185.79284954071045
2020-01-13 12:40:16.592451 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #156 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6370456
Z variance train             0.004812883
KL Divergence                48.564064
KL Loss                      4.8564067
QF Loss                      471.79663
VF Loss                      187.10915
Policy Loss                  -4031.1392
Q Predictions Mean           4031.2534
Q Predictions Std            551.9235
Q Predictions Max            4901.317
Q Predictions Min            14.538551
V Predictions Mean           4031.1365
V Predictions Std            546.3861
V Predictions Max            4894.4937
V Predictions Min            10.963923
Log Pis Mean                 5.51615
Log Pis Std                  3.9504664
Log Pis Max                  15.120858
Log Pis Min                  -5.9485784
Policy mu Mean               -0.13121091
Policy mu Std                1.3811532
Policy mu Max                3.1913347
Policy mu Min                -3.3722415
Policy log std Mean          -0.9098087
Policy log std Std           0.4743259
Policy log std Max           -0.011258483
Policy log std Min           -3.2454758
Z mean eval                  3.6248448
Z variance eval              0.014030856
total_rewards                [10678.95244643 10882.45949916 10772.01171766 10794.36207279
 10908.35578322 11099.26494012 10933.71917339 10890.95212263
 10990.63989184 10834.80837134]
total_rewards_mean           10878.552601858028
total_rewards_std            112.05841064900939
total_rewards_max            11099.264940119849
total_rewards_min            10678.952446432162
Number of train steps total  632000
Number of env steps total    792000
Number of rollouts total     0
Train Time (s)               128.2760686748661
(Previous) Eval Time (s)     29.338751851115376
Sample Time (s)              22.425280535127968
Epoch Time (s)               180.04010106110945
Total Train Time (s)         28530.974544602912
Epoch                        157
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:43:14.864624 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #157 | Epoch Duration: 178.27193784713745
2020-01-13 12:43:14.864818 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #157 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6253674
Z variance train             0.013982592
KL Divergence                47.842396
KL Loss                      4.78424
QF Loss                      544.21204
VF Loss                      191.88254
Policy Loss                  -3982.0498
Q Predictions Mean           3979.0735
Q Predictions Std            645.35736
Q Predictions Max            4835.1343
Q Predictions Min            19.008389
V Predictions Mean           3973.795
V Predictions Std            641.7776
V Predictions Max            4819.889
V Predictions Min            6.910025
Log Pis Mean                 5.4499555
Log Pis Std                  3.704388
Log Pis Max                  15.254697
Log Pis Min                  -3.3459284
Policy mu Mean               -0.12262145
Policy mu Std                1.3782353
Policy mu Max                3.562202
Policy mu Min                -3.1942444
Policy log std Mean          -0.8852458
Policy log std Std           0.46199432
Policy log std Max           0.14838266
Policy log std Min           -3.269003
Z mean eval                  3.621257
Z variance eval              0.0064711785
total_rewards                [10537.43405722 10388.73052079 10553.51349143 10324.42711097
 10298.71779248 10406.41580914 10418.64527253 10320.92453524
 10318.95939584 10473.8480211 ]
total_rewards_mean           10404.16160067404
total_rewards_std            87.77272860956379
total_rewards_max            10553.51349143203
total_rewards_min            10298.717792481551
Number of train steps total  636000
Number of env steps total    797000
Number of rollouts total     0
Train Time (s)               128.3775129909627
(Previous) Eval Time (s)     27.570254324004054
Sample Time (s)              20.798952158074826
Epoch Time (s)               176.7467194730416
Total Train Time (s)         28707.81195120234
Epoch                        158
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:46:11.705527 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #158 | Epoch Duration: 176.84055852890015
2020-01-13 12:46:11.705778 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #158 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.622612
Z variance train             0.006437692
KL Divergence                47.521835
KL Loss                      4.7521834
QF Loss                      488.93054
VF Loss                      138.76732
Policy Loss                  -3991.152
Q Predictions Mean           3992.2317
Q Predictions Std            672.48517
Q Predictions Max            4882.2603
Q Predictions Min            -3.9412284
V Predictions Mean           3990.5312
V Predictions Std            668.9634
V Predictions Max            4877.6255
V Predictions Min            4.174698
Log Pis Mean                 5.7669573
Log Pis Std                  4.114114
Log Pis Max                  17.696611
Log Pis Min                  -3.9521945
Policy mu Mean               -0.21365182
Policy mu Std                1.4121882
Policy mu Max                3.4521074
Policy mu Min                -3.00843
Policy log std Mean          -0.9067862
Policy log std Std           0.4991596
Policy log std Max           -0.008650184
Policy log std Min           -3.473124
Z mean eval                  3.6339622
Z variance eval              0.0018611085
total_rewards                [ 9955.87343726 10116.60852919 10033.83472971 10181.47874978
 10088.36920359 10179.96218369  2516.18740391 10362.3587895
 10095.27679842 10118.97303151]
total_rewards_mean           9364.892285655293
total_rewards_std            2285.129942911831
total_rewards_max            10362.358789502998
total_rewards_min            2516.1874039112004
Number of train steps total  640000
Number of env steps total    802000
Number of rollouts total     0
Train Time (s)               131.69298125989735
(Previous) Eval Time (s)     27.66376182017848
Sample Time (s)              21.502203923184425
Epoch Time (s)               180.85894700326025
Total Train Time (s)         28888.08801125735
Epoch                        159
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:49:11.981271 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #159 | Epoch Duration: 180.27532839775085
2020-01-13 12:49:11.981388 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #159 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.629151
Z variance train             0.0018644125
KL Divergence                49.096855
KL Loss                      4.9096856
QF Loss                      605.8274
VF Loss                      443.99658
Policy Loss                  -4073.1785
Q Predictions Mean           4076.545
Q Predictions Std            499.40207
Q Predictions Max            4907.295
Q Predictions Min            2494.801
V Predictions Mean           4087.9363
V Predictions Std            494.65018
V Predictions Max            4923.6294
V Predictions Min            2557.2847
Log Pis Mean                 5.803016
Log Pis Std                  3.8219151
Log Pis Max                  25.561596
Log Pis Min                  -3.5922127
Policy mu Mean               -0.14155243
Policy mu Std                1.4074787
Policy mu Max                4.020322
Policy mu Min                -3.9412632
Policy log std Mean          -0.9223428
Policy log std Std           0.4726471
Policy log std Max           -0.09482777
Policy log std Min           -3.3201113
Z mean eval                  3.6139214
Z variance eval              0.0025795125
total_rewards                [10310.54813134 10861.70231957 10256.78171042 10704.64097675
  5487.35831927  5768.02740603 10197.60703553 10680.50110185
  1473.66291805 10370.59663617]
total_rewards_mean           8611.142655497551
total_rewards_std            3061.4310822755956
total_rewards_max            10861.702319566384
total_rewards_min            1473.6629180515722
Number of train steps total  644000
Number of env steps total    807000
Number of rollouts total     0
Train Time (s)               137.20135413017124
(Previous) Eval Time (s)     27.079808675218374
Sample Time (s)              21.319859819021076
Epoch Time (s)               185.6010226244107
Total Train Time (s)         29075.411799916532
Epoch                        160
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:52:19.308166 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #160 | Epoch Duration: 187.32667589187622
2020-01-13 12:52:19.308345 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #160 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.614469
Z variance train             0.0025810015
KL Divergence                48.38055
KL Loss                      4.838055
QF Loss                      632.2466
VF Loss                      164.7748
Policy Loss                  -4026.2314
Q Predictions Mean           4023.1401
Q Predictions Std            660.57654
Q Predictions Max            4898.735
Q Predictions Min            17.266726
V Predictions Mean           4022.5793
V Predictions Std            659.5954
V Predictions Max            4907.755
V Predictions Min            5.016416
Log Pis Mean                 5.4580436
Log Pis Std                  3.8354108
Log Pis Max                  16.884228
Log Pis Min                  -6.9135714
Policy mu Mean               -0.17945008
Policy mu Std                1.3796687
Policy mu Max                3.0545542
Policy mu Min                -3.0332074
Policy log std Mean          -0.891723
Policy log std Std           0.48178163
Policy log std Max           0.12700844
Policy log std Min           -3.4227333
Z mean eval                  3.6132095
Z variance eval              0.010357961
total_rewards                [10616.4721351   3041.61294643 10987.22429105 10730.60437211
 10793.97006771 10805.18911944 10770.16796905 10706.39728862
  2093.37693504 10549.72162932]
total_rewards_mean           9109.473675388424
total_rewards_std            3279.7098569736736
total_rewards_max            10987.224291053604
total_rewards_min            2093.3769350396133
Number of train steps total  648000
Number of env steps total    812000
Number of rollouts total     0
Train Time (s)               136.3675134619698
(Previous) Eval Time (s)     28.805099457968026
Sample Time (s)              23.01540480554104
Epoch Time (s)               188.18801772547886
Total Train Time (s)         29262.602466407232
Epoch                        161
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:55:26.502807 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #161 | Epoch Duration: 187.19430565834045
2020-01-13 12:55:26.503053 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #161 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.612901
Z variance train             0.010357169
KL Divergence                44.71931
KL Loss                      4.471931
QF Loss                      488.36194
VF Loss                      186.90614
Policy Loss                  -4048.0117
Q Predictions Mean           4051.2017
Q Predictions Std            699.07697
Q Predictions Max            4942.6167
Q Predictions Min            -1.6926131
V Predictions Mean           4053.1975
V Predictions Std            695.7858
V Predictions Max            4917.392
V Predictions Min            0.7096748
Log Pis Mean                 5.5214663
Log Pis Std                  3.7689798
Log Pis Max                  15.080165
Log Pis Min                  -4.742352
Policy mu Mean               -0.1865014
Policy mu Std                1.3906958
Policy mu Max                3.344186
Policy mu Min                -3.4387789
Policy log std Mean          -0.8946824
Policy log std Std           0.47745734
Policy log std Max           0.0013639331
Policy log std Min           -3.272697
Z mean eval                  3.6206288
Z variance eval              0.010582621
total_rewards                [10801.58658919 10502.09269332 10804.63869053 10900.37860088
 11147.8133441  11001.41475545 10815.85561816 10712.4417356
 10856.14828972  1294.54060741]
total_rewards_mean           9883.691092437333
total_rewards_std            2867.5599259944784
total_rewards_max            11147.813344103362
total_rewards_min            1294.5406074141351
Number of train steps total  652000
Number of env steps total    817000
Number of rollouts total     0
Train Time (s)               136.9852709081024
(Previous) Eval Time (s)     27.810974234715104
Sample Time (s)              22.457438178826123
Epoch Time (s)               187.25368332164362
Total Train Time (s)         29450.137696073856
Epoch                        162
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:58:34.039083 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #162 | Epoch Duration: 187.53586530685425
2020-01-13 12:58:34.039327 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #162 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6224911
Z variance train             0.010553477
KL Divergence                44.721344
KL Loss                      4.4721346
QF Loss                      764.10974
VF Loss                      297.7876
Policy Loss                  -3960.6658
Q Predictions Mean           3964.919
Q Predictions Std            750.50415
Q Predictions Max            4798.927
Q Predictions Min            21.010729
V Predictions Mean           3950.6882
V Predictions Std            748.2889
V Predictions Max            4776.713
V Predictions Min            3.974095
Log Pis Mean                 4.9166365
Log Pis Std                  3.7640574
Log Pis Max                  17.513208
Log Pis Min                  -5.9867415
Policy mu Mean               -0.17715673
Policy mu Std                1.3353378
Policy mu Max                3.0034928
Policy mu Min                -3.2259572
Policy log std Mean          -0.88950044
Policy log std Std           0.4532879
Policy log std Max           0.11448562
Policy log std Min           -3.2853456
Z mean eval                  3.6407864
Z variance eval              0.005386369
total_rewards                [10645.2730285  10418.21037494 10752.23663259 10741.32419346
 10521.99397959 10675.58834589 10579.15506648 10752.62123283
 10553.97563352 10905.59567704]
total_rewards_mean           10654.59741648413
total_rewards_std            133.96645301575833
total_rewards_max            10905.595677035322
total_rewards_min            10418.210374935436
Number of train steps total  656000
Number of env steps total    822000
Number of rollouts total     0
Train Time (s)               134.6788395899348
(Previous) Eval Time (s)     28.092741591855884
Sample Time (s)              22.99180008750409
Epoch Time (s)               185.76338126929477
Total Train Time (s)         29637.00221631769
Epoch                        163
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:01:40.906527 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #163 | Epoch Duration: 186.8670482635498
2020-01-13 13:01:40.906748 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #163 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6404014
Z variance train             0.0053728465
KL Divergence                46.774666
KL Loss                      4.677467
QF Loss                      490.39
VF Loss                      342.16287
Policy Loss                  -4069.1685
Q Predictions Mean           4059.1895
Q Predictions Std            681.0302
Q Predictions Max            4962.9424
Q Predictions Min            6.8046193
V Predictions Mean           4060.5278
V Predictions Std            674.95044
V Predictions Max            4950.825
V Predictions Min            4.427427
Log Pis Mean                 5.7847996
Log Pis Std                  3.8022108
Log Pis Max                  15.543452
Log Pis Min                  -4.7685175
Policy mu Mean               -0.14067605
Policy mu Std                1.4242039
Policy mu Max                3.3222566
Policy mu Min                -2.9897914
Policy log std Mean          -0.889966
Policy log std Std           0.45191073
Policy log std Max           -0.006431043
Policy log std Min           -3.3578532
Z mean eval                  3.6208332
Z variance eval              0.008298981
total_rewards                [10654.64838851  7966.42728694 10851.62790897 10643.23115269
 10859.40036149 10814.18025494 10814.32526581 10777.69103186
 10978.43406963 10839.83201743]
total_rewards_mean           10519.979773826826
total_rewards_std            856.2270578335036
total_rewards_max            10978.434069631734
total_rewards_min            7966.427286940743
Number of train steps total  660000
Number of env steps total    827000
Number of rollouts total     0
Train Time (s)               128.72708006203175
(Previous) Eval Time (s)     29.195954829920083
Sample Time (s)              22.35360196651891
Epoch Time (s)               180.27663685847074
Total Train Time (s)         29815.140437252354
Epoch                        164
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:04:39.046820 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #164 | Epoch Duration: 178.13991808891296
2020-01-13 13:04:39.047018 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #164 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6201909
Z variance train             0.008305978
KL Divergence                46.0451
KL Loss                      4.6045103
QF Loss                      406.91943
VF Loss                      129.26749
Policy Loss                  -4130.092
Q Predictions Mean           4134.034
Q Predictions Std            640.22833
Q Predictions Max            5000.775
Q Predictions Min            11.68281
V Predictions Mean           4133.8086
V Predictions Std            636.60986
V Predictions Max            5001.8906
V Predictions Min            9.498966
Log Pis Mean                 5.6403027
Log Pis Std                  3.892224
Log Pis Max                  17.05233
Log Pis Min                  -3.6006196
Policy mu Mean               -0.18429495
Policy mu Std                1.4053143
Policy mu Max                2.9755933
Policy mu Min                -3.1423388
Policy log std Mean          -0.88973504
Policy log std Std           0.46095172
Policy log std Max           0.0038787127
Policy log std Min           -3.4789133
Z mean eval                  3.6273656
Z variance eval              0.015630707
total_rewards                [ 2620.29319717 10586.72761218 10601.98437897 10540.17806156
 10670.98998589 10733.98200263 10615.9762862  10555.27459856
 10598.60721004 10078.46186403]
total_rewards_mean           9760.24751972412
total_rewards_std            2385.8936996780276
total_rewards_max            10733.98200263043
total_rewards_min            2620.293197174987
Number of train steps total  664000
Number of env steps total    832000
Number of rollouts total     0
Train Time (s)               127.93199000088498
(Previous) Eval Time (s)     27.058868796098977
Sample Time (s)              21.110891962889582
Epoch Time (s)               176.10175075987354
Total Train Time (s)         29992.04197081644
Epoch                        165
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:07:35.950837 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #165 | Epoch Duration: 176.90367197990417
2020-01-13 13:07:35.951052 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #165 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6285267
Z variance train             0.015548078
KL Divergence                44.82714
KL Loss                      4.482714
QF Loss                      886.1301
VF Loss                      114.861725
Policy Loss                  -4091.4702
Q Predictions Mean           4093.4316
Q Predictions Std            554.9079
Q Predictions Max            4904.11
Q Predictions Min            -5.6264133
V Predictions Mean           4093.5042
V Predictions Std            549.53033
V Predictions Max            4902.956
V Predictions Min            4.671461
Log Pis Mean                 5.5765886
Log Pis Std                  3.5269983
Log Pis Max                  15.431337
Log Pis Min                  -2.5845103
Policy mu Mean               -0.16100226
Policy mu Std                1.3712305
Policy mu Max                3.4717999
Policy mu Min                -2.8218887
Policy log std Mean          -0.9223198
Policy log std Std           0.47213086
Policy log std Max           -0.12644571
Policy log std Min           -3.284225
Z mean eval                  3.6008122
Z variance eval              0.0074758483
total_rewards                [ 9647.29052892 10239.95181097 10334.39458012  9662.36349898
  8919.22913411 10249.7840685   4508.61567956 10165.69918742
  9265.61430973  9253.33723718]
total_rewards_mean           9224.62800354704
total_rewards_std            1640.299515337478
total_rewards_max            10334.394580122485
total_rewards_min            4508.615679559432
Number of train steps total  668000
Number of env steps total    837000
Number of rollouts total     0
Train Time (s)               132.83575577894226
(Previous) Eval Time (s)     27.860473058652133
Sample Time (s)              20.643506661057472
Epoch Time (s)               181.33973549865186
Total Train Time (s)         30174.12235953426
Epoch                        166
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:10:38.033669 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #166 | Epoch Duration: 182.0824716091156
2020-01-13 13:10:38.033861 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #166 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6027985
Z variance train             0.007484813
KL Divergence                45.51967
KL Loss                      4.551967
QF Loss                      606.9617
VF Loss                      218.2495
Policy Loss                  -4020.6558
Q Predictions Mean           4017.5884
Q Predictions Std            566.15173
Q Predictions Max            4917.4683
Q Predictions Min            1.8589263
V Predictions Mean           4011.2651
V Predictions Std            559.49786
V Predictions Max            4896.435
V Predictions Min            1.1618879
Log Pis Mean                 5.1024504
Log Pis Std                  4.1418614
Log Pis Max                  28.56237
Log Pis Min                  -5.506085
Policy mu Mean               -0.1354708
Policy mu Std                1.3699937
Policy mu Max                4.38707
Policy mu Min                -5.9586773
Policy log std Mean          -0.90388495
Policy log std Std           0.44644237
Policy log std Max           0.026498556
Policy log std Min           -3.3224964
Z mean eval                  3.6510563
Z variance eval              0.0048047206
total_rewards                [10464.7449219  10947.00495073 11030.35916655 10919.08057634
 10865.847877   10813.57332944 11034.29022206 10922.34925275
 10647.6350986  10746.6661272 ]
total_rewards_mean           10839.155152258028
total_rewards_std            169.22224554416715
total_rewards_max            11034.290222060867
total_rewards_min            10464.74492189685
Number of train steps total  672000
Number of env steps total    842000
Number of rollouts total     0
Train Time (s)               137.01415312523022
(Previous) Eval Time (s)     28.602889626752585
Sample Time (s)              21.64756083022803
Epoch Time (s)               187.26460358221084
Total Train Time (s)         30360.953626035247
Epoch                        167
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:13:44.867255 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #167 | Epoch Duration: 186.83321595191956
2020-01-13 13:13:44.867445 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #167 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6501
Z variance train             0.0047727367
KL Divergence                48.21852
KL Loss                      4.821852
QF Loss                      474.5724
VF Loss                      256.1011
Policy Loss                  -4095.3862
Q Predictions Mean           4101.6797
Q Predictions Std            810.35767
Q Predictions Max            4946.7354
Q Predictions Min            -1.8222048
V Predictions Mean           4084.3318
V Predictions Std            801.93726
V Predictions Max            4926.109
V Predictions Min            0.7236649
Log Pis Mean                 5.427411
Log Pis Std                  4.069481
Log Pis Max                  17.441454
Log Pis Min                  -5.2927036
Policy mu Mean               -0.15927845
Policy mu Std                1.3929533
Policy mu Max                2.9617429
Policy mu Min                -3.2170308
Policy log std Mean          -0.893058
Policy log std Std           0.48231927
Policy log std Max           0.36757612
Policy log std Min           -3.3655462
Z mean eval                  3.6177857
Z variance eval              0.0040009296
total_rewards                [10507.43609281 10361.40896617  2716.18691217 10513.11943298
  4044.60225896  6597.51250451 10442.49410382 10418.09804864
  2975.16231286 10510.09352141]
total_rewards_mean           7908.6114154346
total_rewards_std            3270.9188420977785
total_rewards_max            10513.119432981235
total_rewards_min            2716.186912170402
Number of train steps total  676000
Number of env steps total    847000
Number of rollouts total     0
Train Time (s)               136.26873284904286
(Previous) Eval Time (s)     28.17110052332282
Sample Time (s)              21.889171075541526
Epoch Time (s)               186.3290044479072
Total Train Time (s)         30547.04959542351
Epoch                        168
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:16:50.965238 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #168 | Epoch Duration: 186.0976619720459
2020-01-13 13:16:50.965403 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #168 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6170967
Z variance train             0.003993859
KL Divergence                48.191925
KL Loss                      4.8191924
QF Loss                      746.2278
VF Loss                      146.45502
Policy Loss                  -4095.4277
Q Predictions Mean           4099.624
Q Predictions Std            754.11176
Q Predictions Max            4916.3184
Q Predictions Min            1.6703107
V Predictions Mean           4097.918
V Predictions Std            749.35913
V Predictions Max            4905.473
V Predictions Min            1.5926718
Log Pis Mean                 5.3741646
Log Pis Std                  3.7908638
Log Pis Max                  19.018955
Log Pis Min                  -5.3747187
Policy mu Mean               -0.120751895
Policy mu Std                1.3890902
Policy mu Max                3.1107268
Policy mu Min                -2.9360905
Policy log std Mean          -0.8934376
Policy log std Std           0.47264326
Policy log std Max           0.00014650822
Policy log std Min           -3.3479483
Z mean eval                  3.6019702
Z variance eval              0.005033179
total_rewards                [10434.32618    10569.68400748  1585.47697667 10690.78852341
 10625.08248887 10586.82837906 10673.86514183 10540.30511652
  7114.57188062 10798.93491216]
total_rewards_mean           9361.986360660869
total_rewards_std            2795.8730924728447
total_rewards_max            10798.934912159044
total_rewards_min            1585.4769766656948
Number of train steps total  680000
Number of env steps total    852000
Number of rollouts total     0
Train Time (s)               137.85309276916087
(Previous) Eval Time (s)     27.939423356205225
Sample Time (s)              22.947597263380885
Epoch Time (s)               188.74011338874698
Total Train Time (s)         30736.27515970776
Epoch                        169
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:20:00.192810 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #169 | Epoch Duration: 189.22728896141052
2020-01-13 13:20:00.192984 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #169 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6002069
Z variance train             0.0050311014
KL Divergence                47.42507
KL Loss                      4.7425075
QF Loss                      608.7002
VF Loss                      202.9538
Policy Loss                  -4096.964
Q Predictions Mean           4101.342
Q Predictions Std            640.7127
Q Predictions Max            4898.0366
Q Predictions Min            14.011171
V Predictions Mean           4101.4014
V Predictions Std            636.47876
V Predictions Max            4906.3384
V Predictions Min            4.338639
Log Pis Mean                 5.5019317
Log Pis Std                  3.9225805
Log Pis Max                  15.6566105
Log Pis Min                  -4.0370655
Policy mu Mean               -0.18451495
Policy mu Std                1.3626795
Policy mu Max                3.2421453
Policy mu Min                -2.9000301
Policy log std Mean          -0.89587545
Policy log std Std           0.45508075
Policy log std Max           0.11667454
Policy log std Min           -3.3959432
Z mean eval                  3.597261
Z variance eval              0.0037754842
total_rewards                [ 9736.67140318  9911.51393184 10012.82506903 10184.64097099
  9804.08793714  9749.66677696 10018.38165424  9965.77204667
 10017.13298428 10077.85266692]
total_rewards_mean           9947.854544124977
total_rewards_std            138.97816118608137
total_rewards_max            10184.640970986242
total_rewards_min            9736.671403183189
Number of train steps total  684000
Number of env steps total    857000
Number of rollouts total     0
Train Time (s)               136.54829334979877
(Previous) Eval Time (s)     28.426126221660525
Sample Time (s)              22.732348900754005
Epoch Time (s)               187.7067684722133
Total Train Time (s)         30923.317668259144
Epoch                        170
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:23:07.237522 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #170 | Epoch Duration: 187.044429063797
2020-01-13 13:23:07.237641 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #170 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5969806
Z variance train             0.003770608
KL Divergence                49.05171
KL Loss                      4.905171
QF Loss                      952.0099
VF Loss                      712.39795
Policy Loss                  -4043.9502
Q Predictions Mean           4046.0825
Q Predictions Std            758.44037
Q Predictions Max            4951.4614
Q Predictions Min            -17.436283
V Predictions Mean           4030.3804
V Predictions Std            746.10944
V Predictions Max            4949.4976
V Predictions Min            4.8255043
Log Pis Mean                 5.3758054
Log Pis Std                  3.8564343
Log Pis Max                  22.579079
Log Pis Min                  -5.417824
Policy mu Mean               -0.17596364
Policy mu Std                1.3816408
Policy mu Max                3.5508716
Policy mu Min                -3.7196221
Policy log std Mean          -0.8958557
Policy log std Std           0.4429673
Policy log std Max           0.08607048
Policy log std Min           -3.2988038
Z mean eval                  3.6430626
Z variance eval              0.0032638162
total_rewards                [10504.69866488 10736.63612539 10694.03944826 10641.04231986
 10691.94032462 10642.4855945  10525.13293847 10735.6203801
 10654.50304508 10639.53271929]
total_rewards_mean           10646.563156044267
total_rewards_std            74.42299464878974
total_rewards_max            10736.636125385783
total_rewards_min            10504.698664882539
Number of train steps total  688000
Number of env steps total    862000
Number of rollouts total     0
Train Time (s)               129.13921272102743
(Previous) Eval Time (s)     27.76341400714591
Sample Time (s)              21.601557181682438
Epoch Time (s)               178.50418390985578
Total Train Time (s)         31101.618248275947
Epoch                        171
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:26:05.541558 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #171 | Epoch Duration: 178.3038113117218
2020-01-13 13:26:05.541755 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #171 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6417
Z variance train             0.0032622106
KL Divergence                49.692444
KL Loss                      4.9692445
QF Loss                      609.26843
VF Loss                      269.34308
Policy Loss                  -4151.322
Q Predictions Mean           4146.866
Q Predictions Std            691.6722
Q Predictions Max            4933.5957
Q Predictions Min            -10.681515
V Predictions Mean           4144.7407
V Predictions Std            682.8116
V Predictions Max            4930.7593
V Predictions Min            1.4865177
Log Pis Mean                 5.7582464
Log Pis Std                  3.8943532
Log Pis Max                  19.178179
Log Pis Min                  -8.050216
Policy mu Mean               -0.16375297
Policy mu Std                1.4065992
Policy mu Max                4.022321
Policy mu Min                -3.504029
Policy log std Mean          -0.9135699
Policy log std Std           0.48390964
Policy log std Max           -0.17254078
Policy log std Min           -3.4231124
Z mean eval                  3.6047878
Z variance eval              0.0024185835
total_rewards                [11020.77129318 10989.57021128 10942.79473927 10862.77802054
 10743.62064734 10903.12333741 10930.84573581 11110.05101515
  4724.62347785 11116.56303959]
total_rewards_mean           10334.474151743521
total_rewards_std            1872.9480085935897
total_rewards_max            11116.56303958926
total_rewards_min            4724.623477854556
Number of train steps total  692000
Number of env steps total    867000
Number of rollouts total     0
Train Time (s)               128.60290408413857
(Previous) Eval Time (s)     27.562696598935872
Sample Time (s)              22.22720882948488
Epoch Time (s)               178.39280951255932
Total Train Time (s)         31280.639885406476
Epoch                        172
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:29:04.565688 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #172 | Epoch Duration: 179.02379417419434
2020-01-13 13:29:04.565867 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #172 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6066222
Z variance train             0.0024295435
KL Divergence                50.082417
KL Loss                      5.0082417
QF Loss                      1238.8308
VF Loss                      279.91818
Policy Loss                  -4073.604
Q Predictions Mean           4075.2847
Q Predictions Std            711.37396
Q Predictions Max            5022.7407
Q Predictions Min            2.3791103
V Predictions Mean           4070.1313
V Predictions Std            703.51556
V Predictions Max            4988.8643
V Predictions Min            5.2223268
Log Pis Mean                 5.399538
Log Pis Std                  4.033671
Log Pis Max                  17.906502
Log Pis Min                  -7.3167515
Policy mu Mean               -0.16246164
Policy mu Std                1.3841532
Policy mu Max                3.2654326
Policy mu Min                -4.1279984
Policy log std Mean          -0.8895014
Policy log std Std           0.4559907
Policy log std Max           -0.01706028
Policy log std Min           -3.1853676
Z mean eval                  3.5984864
Z variance eval              0.0025924244
total_rewards                [10711.95303221 10545.13579272 10580.118653   10713.44371305
 10856.04397054 10742.94653963 10216.36212916  8998.4813833
 10247.51147304 10147.76435677]
total_rewards_mean           10375.976104342217
total_rewards_std            515.1445050331644
total_rewards_max            10856.043970543977
total_rewards_min            8998.48138330116
Number of train steps total  696000
Number of env steps total    872000
Number of rollouts total     0
Train Time (s)               134.0581917189993
(Previous) Eval Time (s)     28.193381146062165
Sample Time (s)              21.969919196795672
Epoch Time (s)               184.22149206185713
Total Train Time (s)         31465.345255672466
Epoch                        173
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:32:09.273285 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #173 | Epoch Duration: 184.70728373527527
2020-01-13 13:32:09.273466 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #173 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5973773
Z variance train             0.0025933308
KL Divergence                48.68577
KL Loss                      4.868577
QF Loss                      365.60748
VF Loss                      354.44882
Policy Loss                  -4122.6113
Q Predictions Mean           4129.2437
Q Predictions Std            692.6678
Q Predictions Max            4958.6816
Q Predictions Min            5.5799003
V Predictions Mean           4135.596
V Predictions Std            691.70245
V Predictions Max            4969.763
V Predictions Min            6.5290256
Log Pis Mean                 5.5018706
Log Pis Std                  3.568109
Log Pis Max                  14.565523
Log Pis Min                  -4.4877625
Policy mu Mean               -0.15749383
Policy mu Std                1.4121141
Policy mu Max                3.2881422
Policy mu Min                -3.3581522
Policy log std Mean          -0.8872507
Policy log std Std           0.47293878
Policy log std Max           0.34025407
Policy log std Min           -3.352078
Z mean eval                  3.6102738
Z variance eval              0.0015217648
total_rewards                [10467.57038913 10797.16786959 10800.91947295 10831.60349105
 10783.49436579 10587.11711498 10667.58062738 10691.47912706
 10532.62492715 10912.02506526]
total_rewards_mean           10707.158245035043
total_rewards_std            135.743674696901
total_rewards_max            10912.025065257803
total_rewards_min            10467.57038913254
Number of train steps total  700000
Number of env steps total    877000
Number of rollouts total     0
Train Time (s)               136.84644838888198
(Previous) Eval Time (s)     28.6788364010863
Sample Time (s)              23.217199254315346
Epoch Time (s)               188.74248404428363
Total Train Time (s)         31653.741039591376
Epoch                        174
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:35:17.671858 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #174 | Epoch Duration: 188.3982424736023
2020-01-13 13:35:17.672065 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #174 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6074958
Z variance train             0.0015211673
KL Divergence                48.98057
KL Loss                      4.8980575
QF Loss                      1011.70056
VF Loss                      254.37628
Policy Loss                  -4049.2231
Q Predictions Mean           4055.7742
Q Predictions Std            628.96515
Q Predictions Max            4955.698
Q Predictions Min            13.327889
V Predictions Mean           4060.5508
V Predictions Std            629.87225
V Predictions Max            4967.1826
V Predictions Min            3.552493
Log Pis Mean                 5.092046
Log Pis Std                  3.594891
Log Pis Max                  14.2249
Log Pis Min                  -4.5210485
Policy mu Mean               -0.1523932
Policy mu Std                1.3590561
Policy mu Max                2.934689
Policy mu Min                -3.1071177
Policy log std Mean          -0.90553045
Policy log std Std           0.45178822
Policy log std Max           0.004120946
Policy log std Min           -3.2475777
Z mean eval                  3.6188538
Z variance eval              0.014369033
total_rewards                [ 5065.58463442 10307.8017702  10737.75243762 10872.41503169
 10540.35477714  2015.97144176  2977.71643563 10799.99549379
 10800.90613844 10769.27425039]
total_rewards_mean           8488.777241108146
total_rewards_std            3437.0485794360957
total_rewards_max            10872.415031690112
total_rewards_min            2015.9714417627615
Number of train steps total  704000
Number of env steps total    882000
Number of rollouts total     0
Train Time (s)               135.57329250313342
(Previous) Eval Time (s)     28.334163043648005
Sample Time (s)              23.208297081291676
Epoch Time (s)               187.1157526280731
Total Train Time (s)         31840.60572696291
Epoch                        175
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:38:24.538946 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #175 | Epoch Duration: 186.86672806739807
2020-01-13 13:38:24.539166 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #175 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6171927
Z variance train             0.014388757
KL Divergence                47.118042
KL Loss                      4.7118044
QF Loss                      1061.072
VF Loss                      694.1688
Policy Loss                  -4050.346
Q Predictions Mean           4055.352
Q Predictions Std            762.5584
Q Predictions Max            4884.205
Q Predictions Min            13.080774
V Predictions Mean           4056.9463
V Predictions Std            761.3932
V Predictions Max            4916.2744
V Predictions Min            5.5798707
Log Pis Mean                 4.927121
Log Pis Std                  4.1170673
Log Pis Max                  15.576634
Log Pis Min                  -7.738615
Policy mu Mean               -0.20916367
Policy mu Std                1.3529502
Policy mu Max                2.7839499
Policy mu Min                -2.9407132
Policy log std Mean          -0.8998377
Policy log std Std           0.4738113
Policy log std Max           0.015475631
Policy log std Min           -3.3425293
Z mean eval                  3.6053722
Z variance eval              0.004503577
total_rewards                [5060.05830542 9339.79302189 9592.43909836 5391.99282404 4150.96503551
 9835.63103395 5025.19955703 9150.24072246 6396.49593033 1400.92632154]
total_rewards_mean           6534.374185053561
total_rewards_std            2697.6170500548264
total_rewards_max            9835.63103394975
total_rewards_min            1400.9263215445444
Number of train steps total  708000
Number of env steps total    887000
Number of rollouts total     0
Train Time (s)               137.4723671390675
(Previous) Eval Time (s)     28.084770946297795
Sample Time (s)              21.769990550354123
Epoch Time (s)               187.32712863571942
Total Train Time (s)         32028.237312952522
Epoch                        176
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:41:32.174504 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #176 | Epoch Duration: 187.63511276245117
2020-01-13 13:41:32.174850 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #176 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6055417
Z variance train             0.0045081466
KL Divergence                48.740803
KL Loss                      4.87408
QF Loss                      1472.2375
VF Loss                      355.85425
Policy Loss                  -4023.7393
Q Predictions Mean           4019.233
Q Predictions Std            653.47205
Q Predictions Max            4910.041
Q Predictions Min            10.79341
V Predictions Mean           4021.165
V Predictions Std            635.2731
V Predictions Max            4901.6763
V Predictions Min            0.7476124
Log Pis Mean                 5.514326
Log Pis Std                  3.9228494
Log Pis Max                  14.867942
Log Pis Min                  -4.685071
Policy mu Mean               -0.11798238
Policy mu Std                1.3963329
Policy mu Max                3.218434
Policy mu Min                -2.9569867
Policy log std Mean          -0.8917168
Policy log std Std           0.44215626
Policy log std Max           0.04251516
Policy log std Min           -3.317485
Z mean eval                  3.6033173
Z variance eval              0.0052264053
total_rewards                [10445.75016662 10850.76005566 10666.48889116 10845.66891537
 10838.47755538 10926.67561633 10779.06264065 10695.43945645
 10742.28205918 10607.84341224]
total_rewards_mean           10739.844876904637
total_rewards_std            134.51692629757656
total_rewards_max            10926.67561633227
total_rewards_min            10445.7501666202
Number of train steps total  712000
Number of env steps total    892000
Number of rollouts total     0
Train Time (s)               135.84398803394288
(Previous) Eval Time (s)     28.392407704144716
Sample Time (s)              22.474883205257356
Epoch Time (s)               186.71127894334495
Total Train Time (s)         32214.816961816046
Epoch                        177
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:44:38.755448 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #177 | Epoch Duration: 186.58035039901733
2020-01-13 13:44:38.755640 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #177 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.603798
Z variance train             0.0052040303
KL Divergence                48.90648
KL Loss                      4.890648
QF Loss                      601.85913
VF Loss                      439.2209
Policy Loss                  -4116.123
Q Predictions Mean           4116.636
Q Predictions Std            587.3104
Q Predictions Max            4981.8647
Q Predictions Min            1.327039
V Predictions Mean           4115.7793
V Predictions Std            582.6693
V Predictions Max            4968.2227
V Predictions Min            7.971446
Log Pis Mean                 6.1977987
Log Pis Std                  3.7896426
Log Pis Max                  17.431782
Log Pis Min                  -4.855034
Policy mu Mean               -0.11099771
Policy mu Std                1.4440322
Policy mu Max                3.7418807
Policy mu Min                -3.3897796
Policy log std Mean          -0.91916245
Policy log std Std           0.4761984
Policy log std Max           -0.22763216
Policy log std Min           -3.4097726
Z mean eval                  3.5734582
Z variance eval              0.0062260153
total_rewards                [10746.75902757 10681.51937622  3334.17969255 10834.8269908
 10831.81417778 10863.5919542  10650.16670989 10973.99614511
 10809.72925519 10925.87416695]
total_rewards_mean           10065.245749625825
total_rewards_std            2245.698993041936
total_rewards_max            10973.99614510604
total_rewards_min            3334.1796925533718
Number of train steps total  716000
Number of env steps total    897000
Number of rollouts total     0
Train Time (s)               128.55937860207632
(Previous) Eval Time (s)     28.261131669860333
Sample Time (s)              22.10273491917178
Epoch Time (s)               178.92324519110844
Total Train Time (s)         32391.915784774814
Epoch                        178
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:47:35.856994 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #178 | Epoch Duration: 177.10121488571167
2020-01-13 13:47:35.857186 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #178 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5754218
Z variance train             0.006224714
KL Divergence                48.49153
KL Loss                      4.849153
QF Loss                      511.6883
VF Loss                      529.76666
Policy Loss                  -4062.069
Q Predictions Mean           4058.707
Q Predictions Std            602.9069
Q Predictions Max            4916.627
Q Predictions Min            6.487366
V Predictions Mean           4051.7441
V Predictions Std            599.30365
V Predictions Max            4913.0293
V Predictions Min            0.8037122
Log Pis Mean                 5.609695
Log Pis Std                  3.898615
Log Pis Max                  16.76754
Log Pis Min                  -3.2532473
Policy mu Mean               -0.15334107
Policy mu Std                1.4237528
Policy mu Max                3.1419768
Policy mu Min                -3.7747862
Policy log std Mean          -0.9103634
Policy log std Std           0.46837556
Policy log std Max           -0.14124346
Policy log std Min           -3.3169794
Z mean eval                  3.5728142
Z variance eval              0.009553483
total_rewards                [10488.1149462  10683.78247521 10729.15742306 10650.46294162
 10755.24863838 10823.2623526  10837.92373683 11013.4794594
 10700.4824007  10643.04834956]
total_rewards_mean           10732.49627235735
total_rewards_std            132.9226669507165
total_rewards_max            11013.47945940294
total_rewards_min            10488.11494620397
Number of train steps total  720000
Number of env steps total    902000
Number of rollouts total     0
Train Time (s)               129.47494485788047
(Previous) Eval Time (s)     26.438724750187248
Sample Time (s)              21.622239777818322
Epoch Time (s)               177.53590938588604
Total Train Time (s)         32570.17886951333
Epoch                        179
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:50:34.122897 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #179 | Epoch Duration: 178.26556992530823
2020-01-13 13:50:34.123092 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #179 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5751262
Z variance train             0.00954704
KL Divergence                46.36511
KL Loss                      4.636511
QF Loss                      549.69415
VF Loss                      378.713
Policy Loss                  -4041.512
Q Predictions Mean           4039.2412
Q Predictions Std            631.43445
Q Predictions Max            4974.8047
Q Predictions Min            -7.619474
V Predictions Mean           4028.6353
V Predictions Std            626.289
V Predictions Max            4968.219
V Predictions Min            2.1290689
Log Pis Mean                 5.68696
Log Pis Std                  3.7681732
Log Pis Max                  15.731498
Log Pis Min                  -4.4346914
Policy mu Mean               -0.15196122
Policy mu Std                1.4064374
Policy mu Max                3.4788618
Policy mu Min                -3.233706
Policy log std Mean          -0.9052698
Policy log std Std           0.4652497
Policy log std Max           -0.11396229
Policy log std Min           -3.2433443
Z mean eval                  3.6338127
Z variance eval              0.041302077
total_rewards                [10592.90108371 10961.86260867 10802.10266759 11029.95008557
 10838.53455306 10914.67432344 10970.09881817  5246.55583545
 11055.81000851 10510.35514785]
total_rewards_mean           10292.284513201183
total_rewards_std            1690.4988755597346
total_rewards_max            11055.810008507051
total_rewards_min            5246.555835451412
Number of train steps total  724000
Number of env steps total    907000
Number of rollouts total     0
Train Time (s)               134.8260184233077
(Previous) Eval Time (s)     27.16803149925545
Sample Time (s)              21.750585867092013
Epoch Time (s)               183.74463578965515
Total Train Time (s)         32755.289927814156
Epoch                        180
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:53:39.236814 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #180 | Epoch Duration: 185.1135048866272
2020-01-13 13:53:39.237218 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #180 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.634189
Z variance train             0.041347004
KL Divergence                44.918404
KL Loss                      4.4918404
QF Loss                      601.94135
VF Loss                      224.31406
Policy Loss                  -4167.4814
Q Predictions Mean           4167.785
Q Predictions Std            617.7165
Q Predictions Max            4984.698
Q Predictions Min            -26.836802
V Predictions Mean           4164.415
V Predictions Std            615.71954
V Predictions Max            4968.664
V Predictions Min            0.9909984
Log Pis Mean                 5.675243
Log Pis Std                  3.7350178
Log Pis Max                  15.778105
Log Pis Min                  -3.334166
Policy mu Mean               -0.07487645
Policy mu Std                1.4181905
Policy mu Max                2.9530935
Policy mu Min                -3.0718553
Policy log std Mean          -0.8861038
Policy log std Std           0.4782098
Policy log std Max           -0.06249714
Policy log std Min           -3.3134327
Z mean eval                  3.5840602
Z variance eval              0.009148291
total_rewards                [10866.30318166 11192.59609875 10810.93613668 11049.10649871
 11064.4340058  10799.02096807 11011.34939668 10996.43775003
 10921.12689902 10562.60312167]
total_rewards_mean           10927.3914057061
total_rewards_std            168.11526269300944
total_rewards_max            11192.596098749653
total_rewards_min            10562.603121671033
Number of train steps total  728000
Number of env steps total    912000
Number of rollouts total     0
Train Time (s)               136.36745501309633
(Previous) Eval Time (s)     28.53657247312367
Sample Time (s)              23.427560195792466
Epoch Time (s)               188.33158768201247
Total Train Time (s)         32942.1485359543
Epoch                        181
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:56:46.097557 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #181 | Epoch Duration: 186.86009550094604
2020-01-13 13:56:46.097758 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #181 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5823789
Z variance train             0.00912161
KL Divergence                46.027714
KL Loss                      4.6027713
QF Loss                      845.2031
VF Loss                      488.11893
Policy Loss                  -4060.7612
Q Predictions Mean           4068.0957
Q Predictions Std            697.18713
Q Predictions Max            4926.954
Q Predictions Min            0.3751365
V Predictions Mean           4071.831
V Predictions Std            696.8885
V Predictions Max            4938.5303
V Predictions Min            0.75324917
Log Pis Mean                 5.1803207
Log Pis Std                  3.851996
Log Pis Max                  15.341751
Log Pis Min                  -4.5850744
Policy mu Mean               -0.12888132
Policy mu Std                1.376716
Policy mu Max                3.0585535
Policy mu Min                -3.3792658
Policy log std Mean          -0.8812601
Policy log std Std           0.44638845
Policy log std Max           0.058250427
Policy log std Min           -3.295414
Z mean eval                  3.6058273
Z variance eval              0.029937956
total_rewards                [10740.17630249 10973.74635761 11050.20178705 11046.25712726
 11079.55114236 10890.26157946 10803.30901136 11118.87430672
 10997.11545545 11020.91705994]
total_rewards_mean           10972.041012970953
total_rewards_std            116.90838045683282
total_rewards_max            11118.874306717986
total_rewards_min            10740.176302491847
Number of train steps total  732000
Number of env steps total    917000
Number of rollouts total     0
Train Time (s)               135.91168608423322
(Previous) Eval Time (s)     27.064604085870087
Sample Time (s)              23.325288642197847
Epoch Time (s)               186.30157881230116
Total Train Time (s)         33129.51917714812
Epoch                        182
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:59:53.471081 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #182 | Epoch Duration: 187.3731813430786
2020-01-13 13:59:53.471366 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #182 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.605718
Z variance train             0.029965993
KL Divergence                43.77157
KL Loss                      4.3771567
QF Loss                      1047.0618
VF Loss                      231.55077
Policy Loss                  -4132.7666
Q Predictions Mean           4122.994
Q Predictions Std            622.1847
Q Predictions Max            5034.3506
Q Predictions Min            10.862898
V Predictions Mean           4125.286
V Predictions Std            607.84436
V Predictions Max            5035.1655
V Predictions Min            3.8897486
Log Pis Mean                 5.5823016
Log Pis Std                  3.6636636
Log Pis Max                  20.016472
Log Pis Min                  -5.7998924
Policy mu Mean               -0.14161505
Policy mu Std                1.4245865
Policy mu Max                3.3306284
Policy mu Min                -3.5389895
Policy log std Mean          -0.88897085
Policy log std Std           0.4662232
Policy log std Max           0.39301336
Policy log std Min           -3.2533875
Z mean eval                  3.577243
Z variance eval              0.093800634
total_rewards                [10648.21858107 10768.30085901 10616.29037178 10693.7698287
 10692.84598807 10577.79767292 10649.49543885 10748.2716657
 10618.40125425 10755.62294001]
total_rewards_mean           10676.901460035504
total_rewards_std            62.18901341496919
total_rewards_max            10768.300859013398
total_rewards_min            10577.79767291974
Number of train steps total  736000
Number of env steps total    922000
Number of rollouts total     0
Train Time (s)               137.63195631233975
(Previous) Eval Time (s)     28.13573566172272
Sample Time (s)              22.35296925297007
Epoch Time (s)               188.12066122703254
Total Train Time (s)         33316.924791662954
Epoch                        183
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:03:00.879103 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #183 | Epoch Duration: 187.40759468078613
2020-01-13 14:03:00.879298 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #183 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5771046
Z variance train             0.093687095
KL Divergence                40.98171
KL Loss                      4.0981708
QF Loss                      1031.1982
VF Loss                      307.66724
Policy Loss                  -4119.382
Q Predictions Mean           4127.8223
Q Predictions Std            790.1995
Q Predictions Max            5044.169
Q Predictions Min            40.34864
V Predictions Mean           4120.626
V Predictions Std            790.6711
V Predictions Max            5031.6377
V Predictions Min            0.7587557
Log Pis Mean                 5.788397
Log Pis Std                  4.1409435
Log Pis Max                  16.168266
Log Pis Min                  -4.3661976
Policy mu Mean               -0.13178708
Policy mu Std                1.4300216
Policy mu Max                3.2217054
Policy mu Min                -2.8227584
Policy log std Mean          -0.88933825
Policy log std Std           0.4978689
Policy log std Max           0.02475059
Policy log std Min           -3.3798738
Z mean eval                  3.5686812
Z variance eval              0.07736938
total_rewards                [10233.7179192   9886.47466924  1181.06466745 10270.11607236
  9854.90923315 10154.0720885   9777.53881784  9685.84281628
 10131.96355268 10117.18541858]
total_rewards_mean           9129.288525527658
total_rewards_std            2656.2535740241783
total_rewards_max            10270.116072356177
total_rewards_min            1181.064667454182
Number of train steps total  740000
Number of env steps total    927000
Number of rollouts total     0
Train Time (s)               136.34521890431643
(Previous) Eval Time (s)     27.422308324370533
Sample Time (s)              22.285600499249995
Epoch Time (s)               186.05312772793695
Total Train Time (s)         33503.60327483993
Epoch                        184
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:06:07.560617 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #184 | Epoch Duration: 186.68116760253906
2020-01-13 14:06:07.560819 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #184 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5675888
Z variance train             0.077345245
KL Divergence                39.07743
KL Loss                      3.9077432
QF Loss                      704.6041
VF Loss                      195.21092
Policy Loss                  -4132.512
Q Predictions Mean           4132.241
Q Predictions Std            529.42004
Q Predictions Max            4885.119
Q Predictions Min            2427.7214
V Predictions Mean           4127.5024
V Predictions Std            523.3554
V Predictions Max            4870.268
V Predictions Min            2491.9302
Log Pis Mean                 5.7856026
Log Pis Std                  3.859057
Log Pis Max                  22.10342
Log Pis Min                  -7.464442
Policy mu Mean               -0.08462944
Policy mu Std                1.4329058
Policy mu Max                3.5914564
Policy mu Min                -4.429126
Policy log std Mean          -0.87892014
Policy log std Std           0.44098437
Policy log std Max           0.015060425
Policy log std Min           -3.2855406
Z mean eval                  3.6169715
Z variance eval              0.033115074
total_rewards                [10721.99746118 11060.37112618 11111.89190391 10858.68728543
 10578.98111376 10706.65814032 10766.15028537 11040.81166398
 11021.41433173 11192.19610742]
total_rewards_mean           10905.915941927984
total_rewards_std            195.43710332654297
total_rewards_max            11192.196107421361
total_rewards_min            10578.981113759386
Number of train steps total  744000
Number of env steps total    932000
Number of rollouts total     0
Train Time (s)               129.2439555246383
(Previous) Eval Time (s)     28.049974557943642
Sample Time (s)              20.762318626511842
Epoch Time (s)               178.05624870909378
Total Train Time (s)         33680.28671012493
Epoch                        185
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:09:04.246211 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #185 | Epoch Duration: 176.6852512359619
2020-01-13 14:09:04.246394 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #185 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6194072
Z variance train             0.03306122
KL Divergence                42.56309
KL Loss                      4.256309
QF Loss                      492.34473
VF Loss                      270.7075
Policy Loss                  -4213.377
Q Predictions Mean           4211.3447
Q Predictions Std            638.9857
Q Predictions Max            4991.8984
Q Predictions Min            7.346774
V Predictions Mean           4202.206
V Predictions Std            634.3011
V Predictions Max            4989.148
V Predictions Min            5.8185487
Log Pis Mean                 5.6015034
Log Pis Std                  3.8701928
Log Pis Max                  15.654605
Log Pis Min                  -5.148537
Policy mu Mean               -0.13859151
Policy mu Std                1.414544
Policy mu Max                2.9715066
Policy mu Min                -2.9971857
Policy log std Mean          -0.9019017
Policy log std Std           0.483393
Policy log std Max           -0.1585617
Policy log std Min           -3.3233545
Z mean eval                  3.62054
Z variance eval              0.022704583
total_rewards                [11090.09780001 11088.07476032 10550.19982436 11014.37665784
 10973.1378901  10779.83217864 11156.41945741 11216.25354648
 11034.45597044 11264.08793676]
total_rewards_mean           11016.693602235082
total_rewards_std            201.7356283581375
total_rewards_max            11264.087936762011
total_rewards_min            10550.199824356396
Number of train steps total  748000
Number of env steps total    937000
Number of rollouts total     0
Train Time (s)               129.65456017199904
(Previous) Eval Time (s)     26.678682778961957
Sample Time (s)              21.036195542197675
Epoch Time (s)               177.36943849315867
Total Train Time (s)         33858.50833495846
Epoch                        186
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:12:02.470389 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #186 | Epoch Duration: 178.22383975982666
2020-01-13 14:12:02.470579 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #186 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6213577
Z variance train             0.022755638
KL Divergence                43.667763
KL Loss                      4.3667765
QF Loss                      3303.8687
VF Loss                      709.12994
Policy Loss                  -4112.786
Q Predictions Mean           4114.2783
Q Predictions Std            788.7441
Q Predictions Max            5043.529
Q Predictions Min            8.811286
V Predictions Mean           4119.2656
V Predictions Std            787.31726
V Predictions Max            5042.6553
V Predictions Min            0.7698604
Log Pis Mean                 5.4769974
Log Pis Std                  3.9577668
Log Pis Max                  17.726604
Log Pis Min                  -3.6152928
Policy mu Mean               -0.1868399
Policy mu Std                1.3999157
Policy mu Max                3.063753
Policy mu Min                -4.2045035
Policy log std Mean          -0.8849221
Policy log std Std           0.46626985
Policy log std Max           0.45937896
Policy log std Min           -3.3728228
Z mean eval                  3.5927517
Z variance eval              0.038935702
total_rewards                [10613.76506332 10726.09180651 10648.81208187 10802.32922204
 10687.69578116 10794.47529288 10732.82021473 10826.10183904
 10881.3861139  10780.83208913]
total_rewards_mean           10749.430950456634
total_rewards_std            78.90823449186226
total_rewards_max            10881.386113895585
total_rewards_min            10613.765063315997
Number of train steps total  752000
Number of env steps total    942000
Number of rollouts total     0
Train Time (s)               136.2771794698201
(Previous) Eval Time (s)     27.532764630857855
Sample Time (s)              22.641039677895606
Epoch Time (s)               186.45098377857357
Total Train Time (s)         34046.54135604249
Epoch                        187
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:15:10.506976 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #187 | Epoch Duration: 188.03623509407043
2020-01-13 14:15:10.507258 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #187 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.590823
Z variance train             0.038896132
KL Divergence                41.391846
KL Loss                      4.1391845
QF Loss                      626.087
VF Loss                      273.08453
Policy Loss                  -4075.8794
Q Predictions Mean           4077.0554
Q Predictions Std            691.44446
Q Predictions Max            4921.764
Q Predictions Min            -9.104068
V Predictions Mean           4084.3606
V Predictions Std            690.79236
V Predictions Max            4924.3203
V Predictions Min            0.77251524
Log Pis Mean                 5.8311086
Log Pis Std                  4.010864
Log Pis Max                  18.20725
Log Pis Min                  -4.883663
Policy mu Mean               -0.19655402
Policy mu Std                1.4069704
Policy mu Max                3.1883588
Policy mu Min                -3.095046
Policy log std Mean          -0.88885164
Policy log std Std           0.47488388
Policy log std Max           -0.10054505
Policy log std Min           -3.3578446
Z mean eval                  3.5642478
Z variance eval              0.05125781
total_rewards                [10595.94708947 10681.31923218 10473.82631643 10578.1531686
 10462.62414561 10777.9130545  10894.05365533 10808.31580344
 10771.35985067 10689.78961751]
total_rewards_mean           10673.330193373155
total_rewards_std            136.77270700404253
total_rewards_max            10894.053655327902
total_rewards_min            10462.624145607913
Number of train steps total  756000
Number of env steps total    947000
Number of rollouts total     0
Train Time (s)               136.63318582624197
(Previous) Eval Time (s)     29.117647394072264
Sample Time (s)              22.84237406309694
Epoch Time (s)               188.59320728341118
Total Train Time (s)         34234.510857986286
Epoch                        188
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:18:18.478022 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #188 | Epoch Duration: 187.9706346988678
2020-01-13 14:18:18.478182 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #188 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5641322
Z variance train             0.051265877
KL Divergence                40.699066
KL Loss                      4.0699067
QF Loss                      418.14594
VF Loss                      212.1849
Policy Loss                  -4083.8247
Q Predictions Mean           4086.9604
Q Predictions Std            622.50366
Q Predictions Max            4923.206
Q Predictions Min            13.530439
V Predictions Mean           4093.5698
V Predictions Std            619.93994
V Predictions Max            4920.4966
V Predictions Min            15.510723
Log Pis Mean                 5.8631487
Log Pis Std                  3.5620866
Log Pis Max                  17.158125
Log Pis Min                  -4.529169
Policy mu Mean               -0.1311635
Policy mu Std                1.4195195
Policy mu Max                3.2169309
Policy mu Min                -3.062467
Policy log std Mean          -0.8864046
Policy log std Std           0.4801752
Policy log std Max           0.459499
Policy log std Min           -3.264087
Z mean eval                  3.6242042
Z variance eval              0.03164079
total_rewards                [ 9228.13977462 10914.82114331 10064.08095488 10726.57338555
 10573.87364541 10255.21216865 11031.44948202 10743.4693719
 10485.95070935 11013.26313671]
total_rewards_mean           10503.683377239837
total_rewards_std            519.7750445170568
total_rewards_max            11031.449482023358
total_rewards_min            9228.13977461976
Number of train steps total  760000
Number of env steps total    952000
Number of rollouts total     0
Train Time (s)               134.82174008572474
(Previous) Eval Time (s)     28.494671925902367
Sample Time (s)              22.977829607203603
Epoch Time (s)               186.2942416188307
Total Train Time (s)         34421.28597613983
Epoch                        189
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:21:25.256329 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #189 | Epoch Duration: 186.77801752090454
2020-01-13 14:21:25.256519 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #189 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6261718
Z variance train             0.031677593
KL Divergence                43.164566
KL Loss                      4.316457
QF Loss                      520.9352
VF Loss                      263.23538
Policy Loss                  -4032.1086
Q Predictions Mean           4035.7812
Q Predictions Std            816.6762
Q Predictions Max            4971.6587
Q Predictions Min            -4.135416
V Predictions Mean           4029.6025
V Predictions Std            811.843
V Predictions Max            4946.9116
V Predictions Min            0.78016883
Log Pis Mean                 5.536769
Log Pis Std                  4.1492715
Log Pis Max                  16.974346
Log Pis Min                  -9.492164
Policy mu Mean               -0.11384342
Policy mu Std                1.4171482
Policy mu Max                4.169646
Policy mu Min                -3.1696403
Policy log std Mean          -0.876348
Policy log std Std           0.44556716
Policy log std Max           0.11213732
Policy log std Min           -3.4158237
Z mean eval                  3.6014075
Z variance eval              0.019452592
total_rewards                [10362.90104229 10124.12199175  8689.89583883  9316.15345512
 10555.26342872 10355.42346741 10535.64074272  9807.20656122
 10307.61496081 11015.09852904]
total_rewards_mean           10106.932001791492
total_rewards_std            640.3556460930072
total_rewards_max            11015.098529036803
total_rewards_min            8689.895838834233
Number of train steps total  764000
Number of env steps total    957000
Number of rollouts total     0
Train Time (s)               137.43295772466809
(Previous) Eval Time (s)     28.978090024087578
Sample Time (s)              23.136614047456533
Epoch Time (s)               189.5476617962122
Total Train Time (s)         34609.90454558516
Epoch                        190
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:24:33.877437 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #190 | Epoch Duration: 188.6207730770111
2020-01-13 14:24:33.877649 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #190 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6031609
Z variance train             0.01942295
KL Divergence                44.15918
KL Loss                      4.415918
QF Loss                      1089.7893
VF Loss                      266.14386
Policy Loss                  -4121.881
Q Predictions Mean           4125.7
Q Predictions Std            762.0565
Q Predictions Max            4990.229
Q Predictions Min            0.33915383
V Predictions Mean           4122.9326
V Predictions Std            755.82465
V Predictions Max            4973.367
V Predictions Min            6.333415
Log Pis Mean                 6.0311184
Log Pis Std                  4.003265
Log Pis Max                  15.957247
Log Pis Min                  -6.715914
Policy mu Mean               -0.13494952
Policy mu Std                1.4755268
Policy mu Max                3.2373958
Policy mu Min                -3.0406046
Policy log std Mean          -0.8680226
Policy log std Std           0.4532431
Policy log std Max           -0.09580529
Policy log std Min           -3.2935643
Z mean eval                  3.6231797
Z variance eval              0.014206546
total_rewards                [10061.57424031  4518.98133298 10320.9373883  10110.34835259
 10435.37540791 10429.52168499 10479.56261293 10425.23187
 10566.79238167 10569.04493643]
total_rewards_mean           9791.737020811937
total_rewards_std            1765.126304453707
total_rewards_max            10569.044936431119
total_rewards_min            4518.981332976206
Number of train steps total  768000
Number of env steps total    962000
Number of rollouts total     0
Train Time (s)               134.58924678573385
(Previous) Eval Time (s)     28.050808729138225
Sample Time (s)              22.658241368364543
Epoch Time (s)               185.29829688323662
Total Train Time (s)         34794.11638968671
Epoch                        191
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:27:38.092143 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #191 | Epoch Duration: 184.21434140205383
2020-01-13 14:27:38.092375 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #191 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6240966
Z variance train             0.014227596
KL Divergence                45.968117
KL Loss                      4.596812
QF Loss                      723.9273
VF Loss                      265.05353
Policy Loss                  -4140.799
Q Predictions Mean           4143.061
Q Predictions Std            761.2727
Q Predictions Max            5071.896
Q Predictions Min            6.4258485
V Predictions Mean           4148.5303
V Predictions Std            759.11615
V Predictions Max            5080.5884
V Predictions Min            1.885748
Log Pis Mean                 5.5811224
Log Pis Std                  3.8738935
Log Pis Max                  16.546371
Log Pis Min                  -4.3175144
Policy mu Mean               -0.09381967
Policy mu Std                1.4393493
Policy mu Max                2.818176
Policy mu Min                -3.1938908
Policy log std Mean          -0.8730256
Policy log std Std           0.47302607
Policy log std Max           -0.059413075
Policy log std Min           -3.299006
Z mean eval                  3.6332428
Z variance eval              0.020730194
total_rewards                [10452.59062083 10551.10274293 10945.28138707 11192.59265573
 11115.81064319 10833.33129802 10879.3717968  10776.70030246
 11078.00282417 10854.1663395 ]
total_rewards_mean           10867.895061071398
total_rewards_std            223.53770628137235
total_rewards_max            11192.592655732238
total_rewards_min            10452.590620828803
Number of train steps total  772000
Number of env steps total    967000
Number of rollouts total     0
Train Time (s)               129.42843680502847
(Previous) Eval Time (s)     26.96645786985755
Sample Time (s)              22.340637303423136
Epoch Time (s)               178.73553197830915
Total Train Time (s)         34973.3990881592
Epoch                        192
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:30:37.377143 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #192 | Epoch Duration: 179.28462100028992
2020-01-13 14:30:37.377327 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #192 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6345859
Z variance train             0.020710208
KL Divergence                45.449112
KL Loss                      4.5449114
QF Loss                      970.95105
VF Loss                      240.0422
Policy Loss                  -4177.9424
Q Predictions Mean           4189.6313
Q Predictions Std            693.0379
Q Predictions Max            5052.386
Q Predictions Min            11.8505125
V Predictions Mean           4176.7188
V Predictions Std            690.2669
V Predictions Max            5033.1733
V Predictions Min            3.993109
Log Pis Mean                 5.3711977
Log Pis Std                  3.87719
Log Pis Max                  15.861305
Log Pis Min                  -4.923664
Policy mu Mean               -0.1419841
Policy mu Std                1.3993623
Policy mu Max                3.10052
Policy mu Min                -3.1231205
Policy log std Mean          -0.88613516
Policy log std Std           0.4559681
Policy log std Max           -0.012049913
Policy log std Min           -3.3898406
Z mean eval                  3.641306
Z variance eval              0.010782579
total_rewards                [10704.7775652  10983.54680882 10753.8896943  10923.52162458
 11081.52113617 10926.0311883  10899.8213328  11014.15117989
 10899.61793372  7421.03977335]
total_rewards_mean           10560.791823711757
total_rewards_std            1051.9597882999433
total_rewards_max            11081.5211361704
total_rewards_min            7421.039773346991
Number of train steps total  776000
Number of env steps total    972000
Number of rollouts total     0
Train Time (s)               129.1223618858494
(Previous) Eval Time (s)     27.515190178062767
Sample Time (s)              22.420849224552512
Epoch Time (s)               179.05840128846467
Total Train Time (s)         35153.25987499533
Epoch                        193
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:33:37.240613 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #193 | Epoch Duration: 179.86314845085144
2020-01-13 14:33:37.240800 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #193 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6392655
Z variance train             0.010798391
KL Divergence                48.05327
KL Loss                      4.805327
QF Loss                      2130.4827
VF Loss                      149.93137
Policy Loss                  -4210.5566
Q Predictions Mean           4206.1743
Q Predictions Std            598.94336
Q Predictions Max            5004.63
Q Predictions Min            32.30813
V Predictions Mean           4209.4736
V Predictions Std            593.7567
V Predictions Max            5004.4595
V Predictions Min            3.7629056
Log Pis Mean                 5.5830517
Log Pis Std                  4.181064
Log Pis Max                  25.174398
Log Pis Min                  -5.9629517
Policy mu Mean               -0.11000273
Policy mu Std                1.4092412
Policy mu Max                5.173825
Policy mu Min                -3.025811
Policy log std Mean          -0.9087689
Policy log std Std           0.44546622
Policy log std Max           0.028715253
Policy log std Min           -3.2543588
Z mean eval                  3.5948224
Z variance eval              0.0041597094
total_rewards                [ 9955.70142032 10253.93492445 10204.1381021  10413.3079115
 10220.4723759  10338.84199696 10156.19495752 10225.25159039
 10217.5454207  10279.01418709]
total_rewards_mean           10226.440288693344
total_rewards_std            113.98293681634411
total_rewards_max            10413.307911496024
total_rewards_min            9955.701420319547
Number of train steps total  780000
Number of env steps total    977000
Number of rollouts total     0
Train Time (s)               136.446411752142
(Previous) Eval Time (s)     28.319547780789435
Sample Time (s)              22.67353258188814
Epoch Time (s)               187.4394921148196
Total Train Time (s)         35341.44355876325
Epoch                        194
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:36:45.425209 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #194 | Epoch Duration: 188.1842906475067
2020-01-13 14:36:45.425335 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #194 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5920956
Z variance train             0.0041463627
KL Divergence                48.337467
KL Loss                      4.833747
QF Loss                      832.19617
VF Loss                      694.6014
Policy Loss                  -4156.2207
Q Predictions Mean           4159.573
Q Predictions Std            698.20123
Q Predictions Max            4973.871
Q Predictions Min            -7.362093
V Predictions Mean           4162.8413
V Predictions Std            687.0903
V Predictions Max            4995.9097
V Predictions Min            7.086966
Log Pis Mean                 5.905572
Log Pis Std                  3.9665613
Log Pis Max                  19.596992
Log Pis Min                  -4.840666
Policy mu Mean               -0.14687191
Policy mu Std                1.4226859
Policy mu Max                3.7550492
Policy mu Min                -5.556506
Policy log std Mean          -0.9089039
Policy log std Std           0.48112676
Policy log std Max           0.38767987
Policy log std Min           -3.2509623
Z mean eval                  3.6271045
Z variance eval              0.003776346
total_rewards                [10807.4360937  11119.00525894 11087.63112256 11001.41537905
 10995.62151305 11110.56391137 10947.0386187  11033.47603488
 10816.83030368 10873.73069586]
total_rewards_mean           10979.27489317914
total_rewards_std            109.67825826425577
total_rewards_max            11119.005258939971
total_rewards_min            10807.436093699152
Number of train steps total  784000
Number of env steps total    982000
Number of rollouts total     0
Train Time (s)               136.27198734134436
(Previous) Eval Time (s)     29.064030166249722
Sample Time (s)              23.032639988232404
Epoch Time (s)               188.36865749582648
Total Train Time (s)         35529.95823736023
Epoch                        195
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:39:53.943491 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #195 | Epoch Duration: 188.51804900169373
2020-01-13 14:39:53.943687 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #195 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6234956
Z variance train             0.0037693754
KL Divergence                48.98872
KL Loss                      4.898872
QF Loss                      589.49115
VF Loss                      197.27318
Policy Loss                  -4224.1587
Q Predictions Mean           4227.4053
Q Predictions Std            520.15204
Q Predictions Max            4968.673
Q Predictions Min            2713.415
V Predictions Mean           4223.7646
V Predictions Std            517.411
V Predictions Max            4974.4517
V Predictions Min            2739.1812
Log Pis Mean                 6.149664
Log Pis Std                  3.969654
Log Pis Max                  17.611609
Log Pis Min                  -3.5621068
Policy mu Mean               -0.19156301
Policy mu Std                1.4359212
Policy mu Max                3.582055
Policy mu Min                -2.9915915
Policy log std Mean          -0.9339269
Policy log std Std           0.47847134
Policy log std Max           -0.20920366
Policy log std Min           -3.5024486
Z mean eval                  3.5941024
Z variance eval              0.020362195
total_rewards                [10753.3994834  11077.10891058 11136.0867927  10937.41098675
 11164.68520943 10753.93373745 11112.67295391 11050.91212014
 10823.71633686 11092.2351211 ]
total_rewards_mean           10990.216165231202
total_rewards_std            151.9136840854354
total_rewards_max            11164.685209425854
total_rewards_min            10753.399483398925
Number of train steps total  788000
Number of env steps total    987000
Number of rollouts total     0
Train Time (s)               136.13049694895744
(Previous) Eval Time (s)     29.21307608904317
Sample Time (s)              21.200120845343918
Epoch Time (s)               186.54369388334453
Total Train Time (s)         35715.99318938842
Epoch                        196
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:42:59.981393 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #196 | Epoch Duration: 186.03755688667297
2020-01-13 14:42:59.981595 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #196 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5947547
Z variance train             0.020363184
KL Divergence                47.164284
KL Loss                      4.7164283
QF Loss                      506.55032
VF Loss                      167.25218
Policy Loss                  -4141.1865
Q Predictions Mean           4143.8813
Q Predictions Std            610.80853
Q Predictions Max            4910.2354
Q Predictions Min            1.1205728
V Predictions Mean           4136.4497
V Predictions Std            608.4227
V Predictions Max            4891.5215
V Predictions Min            2.5355482
Log Pis Mean                 5.915697
Log Pis Std                  3.6838055
Log Pis Max                  15.77658
Log Pis Min                  -5.535192
Policy mu Mean               -0.12306642
Policy mu Std                1.4283541
Policy mu Max                3.8523214
Policy mu Min                -3.4950235
Policy log std Mean          -0.89704657
Policy log std Std           0.4475342
Policy log std Max           -0.063143015
Policy log std Min           -3.371685
Z mean eval                  3.6437492
Z variance eval              0.03008762
total_rewards                [10075.68788427 10542.6765973  10427.81809254 10676.62028205
 10701.67329932 10735.93524401 10820.45141316  6077.15311585
 10863.90360281 11258.31623314]
total_rewards_mean           10218.023576446772
total_rewards_std            1410.3627388128073
total_rewards_max            11258.316233144595
total_rewards_min            6077.153115854718
Number of train steps total  792000
Number of env steps total    992000
Number of rollouts total     0
Train Time (s)               137.0126507137902
(Previous) Eval Time (s)     28.706542535685003
Sample Time (s)              23.360524442512542
Epoch Time (s)               189.07971769198775
Total Train Time (s)         35905.1357934922
Epoch                        197
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:46:09.126803 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #197 | Epoch Duration: 189.1450674533844
2020-01-13 14:46:09.126993 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #197 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.642737
Z variance train             0.030142713
KL Divergence                49.137352
KL Loss                      4.9137354
QF Loss                      462.67755
VF Loss                      148.5039
Policy Loss                  -4170.923
Q Predictions Mean           4176.1826
Q Predictions Std            703.6014
Q Predictions Max            5004.208
Q Predictions Min            1.2956872
V Predictions Mean           4170.8926
V Predictions Std            697.64996
V Predictions Max            4984.922
V Predictions Min            10.649875
Log Pis Mean                 5.555055
Log Pis Std                  3.7254474
Log Pis Max                  15.463769
Log Pis Min                  -7.034691
Policy mu Mean               -0.19615729
Policy mu Std                1.3992621
Policy mu Max                3.0370357
Policy mu Min                -2.9562128
Policy log std Mean          -0.8852113
Policy log std Std           0.47147423
Policy log std Max           -0.13796282
Policy log std Min           -3.2759795
Z mean eval                  3.6164494
Z variance eval              0.013200715
total_rewards                [10545.72608702 10781.18472932 10734.17147457 11145.17378776
 10795.14381376 10753.58428174 10876.10023924 10971.21874982
 11132.78700229 10717.91756727]
total_rewards_mean           10845.30077327766
total_rewards_std            179.6484895476979
total_rewards_max            11145.173787763502
total_rewards_min            10545.726087015193
Number of train steps total  796000
Number of env steps total    997000
Number of rollouts total     0
Train Time (s)               133.62928264401853
(Previous) Eval Time (s)     28.771559969056398
Sample Time (s)              23.098582750651985
Epoch Time (s)               185.4994253637269
Total Train Time (s)         36088.6301676617
Epoch                        198
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:49:12.623928 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #198 | Epoch Duration: 183.4967918395996
2020-01-13 14:49:12.624121 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #198 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.616243
Z variance train             0.013176136
KL Divergence                49.26072
KL Loss                      4.926072
QF Loss                      670.5993
VF Loss                      210.47868
Policy Loss                  -4235.419
Q Predictions Mean           4233.0293
Q Predictions Std            581.1137
Q Predictions Max            4992.3145
Q Predictions Min            224.16592
V Predictions Mean           4239.796
V Predictions Std            571.1221
V Predictions Max            5002.7007
V Predictions Min            530.9553
Log Pis Mean                 6.0402822
Log Pis Std                  3.9380374
Log Pis Max                  26.77763
Log Pis Min                  -3.5732806
Policy mu Mean               -0.14147289
Policy mu Std                1.4279372
Policy mu Max                4.1701627
Policy mu Min                -3.6062906
Policy log std Mean          -0.90176195
Policy log std Std           0.47160596
Policy log std Max           -0.022663593
Policy log std Min           -3.4507513
Z mean eval                  3.6248753
Z variance eval              0.0030873404
total_rewards                [10835.07853681 11063.66870018 10964.86578866  9121.12419383
 11052.4969126  11180.53295311 11111.63077965  1989.5443608
 11275.44327915 11292.71308736]
total_rewards_mean           9988.709859215805
total_rewards_std            2733.7383615330905
total_rewards_max            11292.713087360422
total_rewards_min            1989.5443608025198
Number of train steps total  800000
Number of env steps total    1002000
Number of rollouts total     0
Train Time (s)               129.80456646811217
(Previous) Eval Time (s)     26.768549663946033
Sample Time (s)              21.723409896716475
Epoch Time (s)               178.29652602877468
Total Train Time (s)         36268.37156268861
Epoch                        199
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:52:12.368629 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #199 | Epoch Duration: 179.74436378479004
2020-01-13 14:52:12.368878 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #199 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6225593
Z variance train             0.00309817
KL Divergence                52.903374
KL Loss                      5.2903376
QF Loss                      1253.5538
VF Loss                      537.95636
Policy Loss                  -4237.521
Q Predictions Mean           4240.8154
Q Predictions Std            711.4757
Q Predictions Max            5034.827
Q Predictions Min            2.919817
V Predictions Mean           4243.663
V Predictions Std            709.7552
V Predictions Max            5032.271
V Predictions Min            2.6832511
Log Pis Mean                 5.8833613
Log Pis Std                  4.1470385
Log Pis Max                  17.269207
Log Pis Min                  -7.021146
Policy mu Mean               -0.1425898
Policy mu Std                1.4647162
Policy mu Max                3.7849014
Policy mu Min                -3.2961762
Policy log std Mean          -0.88948995
Policy log std Std           0.47075865
Policy log std Max           -0.05977142
Policy log std Min           -3.3696308
Z mean eval                  3.6236758
Z variance eval              0.0012093384
total_rewards                [10604.85656479 10888.7302123  10583.75591568 10756.94987832
 10998.21805664 10926.85718421 10817.38036358 10792.62933628
 10724.39323338 10939.09204256]
total_rewards_mean           10803.28627877277
total_rewards_std            132.38706807227632
total_rewards_max            10998.218056636737
total_rewards_min            10583.75591567658
Number of train steps total  804000
Number of env steps total    1007000
Number of rollouts total     0
Train Time (s)               130.8269584099762
(Previous) Eval Time (s)     28.216067458037287
Sample Time (s)              22.10817104857415
Epoch Time (s)               181.15119691658765
Total Train Time (s)         36448.61299950071
Epoch                        200
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:55:12.611963 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #200 | Epoch Duration: 180.24288725852966
2020-01-13 14:55:12.612152 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #200 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.622333
Z variance train             0.0012078909
KL Divergence                53.727158
KL Loss                      5.372716
QF Loss                      521.2688
VF Loss                      5243.284
Policy Loss                  -4215.7334
Q Predictions Mean           4215.0396
Q Predictions Std            649.4686
Q Predictions Max            5061.481
Q Predictions Min            2.9520855
V Predictions Mean           4216.9
V Predictions Std            662.2461
V Predictions Max            5063.6743
V Predictions Min            0.8043993
Log Pis Mean                 5.886705
Log Pis Std                  4.0429263
Log Pis Max                  15.453345
Log Pis Min                  -9.72523
Policy mu Mean               -0.14938183
Policy mu Std                1.4286277
Policy mu Max                3.2164817
Policy mu Min                -3.0643036
Policy log std Mean          -0.89553595
Policy log std Std           0.47474548
Policy log std Max           0.12556028
Policy log std Min           -3.213743
Z mean eval                  3.6306465
Z variance eval              0.001844593
total_rewards                [10107.13513563 10560.87601626 10852.0248006  10611.1807543
 10608.96897151 10560.2695455  10504.81385574 10553.78135538
 10650.10932947 10530.95361856]
total_rewards_mean           10554.01133829584
total_rewards_std            175.23477517166893
total_rewards_max            10852.024800604766
total_rewards_min            10107.13513562669
Number of train steps total  808000
Number of env steps total    1012000
Number of rollouts total     0
Train Time (s)               137.64074445096776
(Previous) Eval Time (s)     27.307427505031228
Sample Time (s)              22.754646698012948
Epoch Time (s)               187.70281865401193
Total Train Time (s)         36637.64375966042
Epoch                        201
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:58:21.646047 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #201 | Epoch Duration: 189.0337314605713
2020-01-13 14:58:21.646351 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #201 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6283746
Z variance train             0.0018375637
KL Divergence                53.62357
KL Loss                      5.362357
QF Loss                      695.48474
VF Loss                      308.7864
Policy Loss                  -4315.549
Q Predictions Mean           4316.08
Q Predictions Std            508.9251
Q Predictions Max            5065.779
Q Predictions Min            2800.2083
V Predictions Mean           4326.388
V Predictions Std            505.4086
V Predictions Max            5071.214
V Predictions Min            2796.2708
Log Pis Mean                 5.874866
Log Pis Std                  3.8168495
Log Pis Max                  18.785728
Log Pis Min                  -6.4351096
Policy mu Mean               -0.1449151
Policy mu Std                1.4288979
Policy mu Max                4.188097
Policy mu Min                -3.5646644
Policy log std Mean          -0.92508405
Policy log std Std           0.49286145
Policy log std Max           -0.17414248
Policy log std Min           -3.4043212
Z mean eval                  3.5869172
Z variance eval              0.006705726
total_rewards                [10939.244525   11003.39458665 10879.61539307 11019.81663095
 10720.23468452 11093.41389994 11059.05143853 11339.82512254
 10950.77084878 11329.73046635]
total_rewards_mean           11033.50975963237
total_rewards_std            180.12982207995032
total_rewards_max            11339.825122541593
total_rewards_min            10720.234684517862
Number of train steps total  812000
Number of env steps total    1017000
Number of rollouts total     0
Train Time (s)               137.24007817171514
(Previous) Eval Time (s)     28.637849412858486
Sample Time (s)              22.506399044767022
Epoch Time (s)               188.38432662934065
Total Train Time (s)         36825.66230343236
Epoch                        202
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:01:29.667027 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #202 | Epoch Duration: 188.02049851417542
2020-01-13 15:01:29.667447 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #202 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5864997
Z variance train             0.0067254365
KL Divergence                51.845573
KL Loss                      5.1845574
QF Loss                      558.7657
VF Loss                      196.31288
Policy Loss                  -4235.45
Q Predictions Mean           4229.779
Q Predictions Std            520.99774
Q Predictions Max            5035.7886
Q Predictions Min            2741.1025
V Predictions Mean           4228.95
V Predictions Std            515.2656
V Predictions Max            5032.374
V Predictions Min            2760.529
Log Pis Mean                 5.9692926
Log Pis Std                  3.7324724
Log Pis Max                  17.304276
Log Pis Min                  -4.0841966
Policy mu Mean               -0.16387783
Policy mu Std                1.4167295
Policy mu Max                3.2750914
Policy mu Min                -2.7856655
Policy log std Mean          -0.8978265
Policy log std Std           0.4705782
Policy log std Max           -0.22056776
Policy log std Min           -3.281931
Z mean eval                  3.5586543
Z variance eval              0.006515612
total_rewards                [ 6250.93941083 10011.00836633 10850.2426948  10650.0280642
 10699.36326312  5649.47928914 10824.49959246 10656.33396358
 10051.02916949 10359.84681063]
total_rewards_mean           9600.277062458288
total_rewards_std            1851.0010352283903
total_rewards_max            10850.242694804214
total_rewards_min            5649.479289136179
Number of train steps total  816000
Number of env steps total    1022000
Number of rollouts total     0
Train Time (s)               136.7896168618463
(Previous) Eval Time (s)     28.273695659823716
Sample Time (s)              22.698531876318157
Epoch Time (s)               187.76184439798817
Total Train Time (s)         37014.09523250954
Epoch                        203
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:04:38.103429 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #203 | Epoch Duration: 188.43572783470154
2020-01-13 15:04:38.103652 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #203 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5569057
Z variance train             0.0065077646
KL Divergence                52.62332
KL Loss                      5.2623324
QF Loss                      456.5076
VF Loss                      327.5951
Policy Loss                  -4269.1987
Q Predictions Mean           4269.8535
Q Predictions Std            511.46344
Q Predictions Max            5030.147
Q Predictions Min            2681.647
V Predictions Mean           4269.848
V Predictions Std            507.88428
V Predictions Max            5007.265
V Predictions Min            2654.694
Log Pis Mean                 6.1291018
Log Pis Std                  3.8115044
Log Pis Max                  15.929844
Log Pis Min                  -2.8598423
Policy mu Mean               -0.09856387
Policy mu Std                1.454678
Policy mu Max                3.154681
Policy mu Min                -3.3147614
Policy log std Mean          -0.90810937
Policy log std Std           0.4619179
Policy log std Max           -0.2302323
Policy log std Min           -3.2878547
Z mean eval                  3.611826
Z variance eval              0.0032009291
total_rewards                [10179.72200536 10724.96368178 10175.97380677 10497.16423787
 10349.31779782 10495.62548915  9824.71623878 10259.70413905
 10622.50242514  9966.73454524]
total_rewards_mean           10309.642436696135
total_rewards_std            270.49603677566375
total_rewards_max            10724.963681784331
total_rewards_min            9824.716238781642
Number of train steps total  820000
Number of env steps total    1027000
Number of rollouts total     0
Train Time (s)               136.81680606212467
(Previous) Eval Time (s)     28.94717195397243
Sample Time (s)              22.142939328681678
Epoch Time (s)               187.90691734477878
Total Train Time (s)         37201.88353241701
Epoch                        204
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:07:45.895689 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #204 | Epoch Duration: 187.79185938835144
2020-01-13 15:07:45.895996 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #204 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6096044
Z variance train             0.0032073874
KL Divergence                52.142796
KL Loss                      5.2142797
QF Loss                      730.4198
VF Loss                      113.89589
Policy Loss                  -4315.0415
Q Predictions Mean           4315.866
Q Predictions Std            495.84866
Q Predictions Max            5061.8745
Q Predictions Min            3042.0847
V Predictions Mean           4316.586
V Predictions Std            495.23145
V Predictions Max            5055.765
V Predictions Min            3037.9336
Log Pis Mean                 6.071946
Log Pis Std                  3.687732
Log Pis Max                  14.711219
Log Pis Min                  -5.1260295
Policy mu Mean               -0.14512044
Policy mu Std                1.4171572
Policy mu Max                2.893053
Policy mu Min                -2.7609937
Policy log std Mean          -0.9185087
Policy log std Std           0.4789245
Policy log std Max           -0.085006
Policy log std Min           -3.3554745
Z mean eval                  3.5806375
Z variance eval              0.006570683
total_rewards                [11055.04867331 11073.14359616 11024.41621706 11214.99804158
 11172.34149938 11138.02076062 11084.2300947  11187.28689897
 11010.67006757 10885.89483453]
total_rewards_mean           11084.60506838841
total_rewards_std            93.63585260954854
total_rewards_max            11214.99804158222
total_rewards_min            10885.894834532264
Number of train steps total  824000
Number of env steps total    1032000
Number of rollouts total     0
Train Time (s)               130.3241790360771
(Previous) Eval Time (s)     28.831772793084383
Sample Time (s)              22.156414325814694
Epoch Time (s)               181.3123661549762
Total Train Time (s)         37381.34875171119
Epoch                        205
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:10:45.363653 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #205 | Epoch Duration: 179.46748971939087
2020-01-13 15:10:45.363842 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #205 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5793357
Z variance train             0.0065752543
KL Divergence                53.773354
KL Loss                      5.3773355
QF Loss                      673.8931
VF Loss                      231.05588
Policy Loss                  -4276.9243
Q Predictions Mean           4278.4663
Q Predictions Std            491.58127
Q Predictions Max            5051.44
Q Predictions Min            2630.9656
V Predictions Mean           4284.1343
V Predictions Std            487.4138
V Predictions Max            5054.3784
V Predictions Min            2730.0935
Log Pis Mean                 5.625099
Log Pis Std                  3.4747226
Log Pis Max                  18.370203
Log Pis Min                  -3.4574485
Policy mu Mean               -0.11500963
Policy mu Std                1.4184694
Policy mu Max                3.4012907
Policy mu Min                -2.7734401
Policy log std Mean          -0.91064924
Policy log std Std           0.47446474
Policy log std Max           -0.19209063
Policy log std Min           -3.3642807
Z mean eval                  3.622198
Z variance eval              0.004454762
total_rewards                [10443.66715921 10736.39700292 10867.57151713 10292.5069823
 10689.75643605 10766.24439627 10603.51324508 10949.39121811
 10811.2301269  10636.39020672]
total_rewards_mean           10679.666829069767
total_rewards_std            186.9344624816052
total_rewards_max            10949.391218109778
total_rewards_min            10292.506982298133
Number of train steps total  828000
Number of env steps total    1037000
Number of rollouts total     0
Train Time (s)               129.60390848992392
(Previous) Eval Time (s)     26.98652372090146
Sample Time (s)              19.907559122890234
Epoch Time (s)               176.49799133371562
Total Train Time (s)         37557.29257367365
Epoch                        206
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:13:41.311911 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #206 | Epoch Duration: 175.94791746139526
2020-01-13 15:13:41.312143 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #206 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6235764
Z variance train             0.004446184
KL Divergence                54.0104
KL Loss                      5.40104
QF Loss                      587.83264
VF Loss                      160.81247
Policy Loss                  -4354.9077
Q Predictions Mean           4358.647
Q Predictions Std            493.06125
Q Predictions Max            5070.0605
Q Predictions Min            3064.943
V Predictions Mean           4347.584
V Predictions Std            489.24387
V Predictions Max            5067.2207
V Predictions Min            3061.1892
Log Pis Mean                 5.6516805
Log Pis Std                  4.0507183
Log Pis Max                  17.32388
Log Pis Min                  -4.7639604
Policy mu Mean               -0.19922404
Policy mu Std                1.4155728
Policy mu Max                2.9324996
Policy mu Min                -3.031421
Policy log std Mean          -0.9053629
Policy log std Std           0.45888227
Policy log std Max           -0.1761117
Policy log std Min           -3.3156822
Z mean eval                  3.6057866
Z variance eval              0.022180017
total_rewards                [10959.19354979 11115.7038096  10927.59400929 11124.94637858
 11147.98338426 11069.55882881 10761.17862313 10899.44052827
 10981.84234976 10939.61261528]
total_rewards_mean           10992.705407677102
total_rewards_std            115.42805497761299
total_rewards_max            11147.983384264402
total_rewards_min            10761.178623127495
Number of train steps total  832000
Number of env steps total    1042000
Number of rollouts total     0
Train Time (s)               131.91510368976742
(Previous) Eval Time (s)     26.43617363506928
Sample Time (s)              22.398251358419657
Epoch Time (s)               180.74952868325636
Total Train Time (s)         37739.19709712081
Epoch                        207
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:16:43.218008 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #207 | Epoch Duration: 181.90568208694458
2020-01-13 15:16:43.218336 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #207 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6103332
Z variance train             0.022194725
KL Divergence                51.409885
KL Loss                      5.140989
QF Loss                      587.2665
VF Loss                      152.4962
Policy Loss                  -4303.49
Q Predictions Mean           4304.261
Q Predictions Std            557.2394
Q Predictions Max            5021.7363
Q Predictions Min            55.485703
V Predictions Mean           4297.5137
V Predictions Std            557.67993
V Predictions Max            5003.3257
V Predictions Min            0.8135509
Log Pis Mean                 5.405445
Log Pis Std                  4.1469245
Log Pis Max                  15.782852
Log Pis Min                  -4.0959435
Policy mu Mean               -0.14848787
Policy mu Std                1.4392647
Policy mu Max                3.5011294
Policy mu Min                -3.6106136
Policy log std Mean          -0.8793855
Policy log std Std           0.44379544
Policy log std Max           -0.09294093
Policy log std Min           -3.5167675
Z mean eval                  3.5768592
Z variance eval              0.047798157
total_rewards                [10716.92904786 10980.72143342 11046.77655472 11030.01737546
 10973.23078701 11103.27957094 10904.71557864 11061.61385741
 11185.55858816 11312.27269846]
total_rewards_mean           11031.511549207265
total_rewards_std            151.61299924476805
total_rewards_max            11312.272698463688
total_rewards_min            10716.92904786004
Number of train steps total  836000
Number of env steps total    1047000
Number of rollouts total     0
Train Time (s)               138.6386496173218
(Previous) Eval Time (s)     27.591951807029545
Sample Time (s)              22.709492499940097
Epoch Time (s)               188.94009392429143
Total Train Time (s)         37929.1826451174
Epoch                        208
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:19:53.205960 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #208 | Epoch Duration: 189.98743724822998
2020-01-13 15:19:53.206192 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #208 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5761344
Z variance train             0.048085827
KL Divergence                48.487053
KL Loss                      4.8487053
QF Loss                      521.7321
VF Loss                      189.009
Policy Loss                  -4294.758
Q Predictions Mean           4296.0254
Q Predictions Std            473.50644
Q Predictions Max            5071.924
Q Predictions Min            3034.935
V Predictions Mean           4298.412
V Predictions Std            472.4253
V Predictions Max            5082.9233
V Predictions Min            3032.2097
Log Pis Mean                 5.680643
Log Pis Std                  3.6799963
Log Pis Max                  15.698085
Log Pis Min                  -2.7339606
Policy mu Mean               -0.12285627
Policy mu Std                1.4110446
Policy mu Max                3.0796633
Policy mu Min                -3.3610938
Policy log std Mean          -0.89429
Policy log std Std           0.45066318
Policy log std Max           -0.13667405
Policy log std Min           -3.3881555
Z mean eval                  3.580173
Z variance eval              0.075811185
total_rewards                [ 9252.97984202 10143.00408921 10141.91704861 10466.8775941
 10571.14286697  9920.86230506 10803.41183404 10381.29298259
 10430.18125356 10677.5539161 ]
total_rewards_mean           10278.922373226602
total_rewards_std            424.9805410469574
total_rewards_max            10803.411834040342
total_rewards_min            9252.979842022825
Number of train steps total  840000
Number of env steps total    1052000
Number of rollouts total     0
Train Time (s)               137.38468663906679
(Previous) Eval Time (s)     28.63895590696484
Sample Time (s)              20.894549124408513
Epoch Time (s)               186.91819167044014
Total Train Time (s)         38116.112797758076
Epoch                        209
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:23:00.138948 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #209 | Epoch Duration: 186.9326045513153
2020-01-13 15:23:00.139156 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #209 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5787368
Z variance train             0.075799525
KL Divergence                44.880203
KL Loss                      4.4880204
QF Loss                      547.73865
VF Loss                      192.98878
Policy Loss                  -4401.82
Q Predictions Mean           4406.6064
Q Predictions Std            481.09277
Q Predictions Max            5181.1904
Q Predictions Min            3137.9026
V Predictions Mean           4407.6387
V Predictions Std            479.6596
V Predictions Max            5173.066
V Predictions Min            3142.7878
Log Pis Mean                 6.089955
Log Pis Std                  3.5794482
Log Pis Max                  16.377024
Log Pis Min                  -3.1430159
Policy mu Mean               -0.08390274
Policy mu Std                1.4340112
Policy mu Max                3.0948124
Policy mu Min                -2.6022732
Policy log std Mean          -0.8820109
Policy log std Std           0.46434385
Policy log std Max           -0.21959874
Policy log std Min           -3.4045668
Z mean eval                  3.6115375
Z variance eval              0.031404607
total_rewards                [3848.56563407 1005.86537952  444.23161818 4465.77556679 1559.67667928
 2504.14301159 1913.68849545   12.66911592  817.0828801   -44.11378353]
total_rewards_mean           1652.758459735262
total_rewards_std            1472.5103962961748
total_rewards_max            4465.775566785225
total_rewards_min            -44.113783526606014
Number of train steps total  844000
Number of env steps total    1057000
Number of rollouts total     0
Train Time (s)               137.09601745475084
(Previous) Eval Time (s)     28.653012939263135
Sample Time (s)              22.738997031003237
Epoch Time (s)               188.4880274250172
Total Train Time (s)         38304.347638216335
Epoch                        210
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:26:08.376698 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #210 | Epoch Duration: 188.2373719215393
2020-01-13 15:26:08.376886 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #210 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6109378
Z variance train             0.03143564
KL Divergence                45.855843
KL Loss                      4.585584
QF Loss                      564.7501
VF Loss                      341.1989
Policy Loss                  -4416.615
Q Predictions Mean           4416.217
Q Predictions Std            598.2374
Q Predictions Max            5241.9497
Q Predictions Min            -1.7044202
V Predictions Mean           4423.883
V Predictions Std            595.87976
V Predictions Max            5238.379
V Predictions Min            0.8592065
Log Pis Mean                 6.447002
Log Pis Std                  4.121978
Log Pis Max                  16.438416
Log Pis Min                  -4.68719
Policy mu Mean               -0.08289617
Policy mu Std                1.5134822
Policy mu Max                4.6060963
Policy mu Min                -3.253941
Policy log std Mean          -0.8475111
Policy log std Std           0.42137912
Policy log std Max           0.06011641
Policy log std Min           -3.1860964
Z mean eval                  3.581493
Z variance eval              0.062181104
total_rewards                [11169.44618661 10943.61133626 11147.13735752 11086.37382933
 11185.04792263 11204.70940653 11114.1570162  11150.23757601
 10880.24604808 11037.05461305]
total_rewards_mean           11091.80212922361
total_rewards_std            102.0740438898446
total_rewards_max            11204.709406530661
total_rewards_min            10880.246048083342
Number of train steps total  848000
Number of env steps total    1062000
Number of rollouts total     0
Train Time (s)               136.95140840439126
(Previous) Eval Time (s)     28.401945133227855
Sample Time (s)              22.086020343005657
Epoch Time (s)               187.43937388062477
Total Train Time (s)         38492.5600118693
Epoch                        211
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:29:16.591740 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #211 | Epoch Duration: 188.21471214294434
2020-01-13 15:29:16.591959 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #211 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.579654
Z variance train             0.062100045
KL Divergence                43.820267
KL Loss                      4.3820267
QF Loss                      2410.5918
VF Loss                      421.03796
Policy Loss                  -4346.327
Q Predictions Mean           4355.9053
Q Predictions Std            638.0267
Q Predictions Max            5147.4
Q Predictions Min            -51.78722
V Predictions Mean           4357.1387
V Predictions Std            634.1513
V Predictions Max            5144.2163
V Predictions Min            0.8242394
Log Pis Mean                 6.344507
Log Pis Std                  4.11005
Log Pis Max                  20.86213
Log Pis Min                  -4.66499
Policy mu Mean               -0.15822463
Policy mu Std                1.4541351
Policy mu Max                3.1558275
Policy mu Min                -3.5218313
Policy log std Mean          -0.912659
Policy log std Std           0.51216596
Policy log std Max           0.002645135
Policy log std Min           -3.3637352
Z mean eval                  3.524517
Z variance eval              0.0811952
total_rewards                [10385.79891245 10560.02782767 10219.92143633 10614.70378087
 10302.68583348 10455.32586791 10317.23494969 10433.32176833
 10448.77456754 10582.64563447]
total_rewards_mean           10432.044057874566
total_rewards_std            122.5961424230016
total_rewards_max            10614.70378086784
total_rewards_min            10219.921436334811
Number of train steps total  852000
Number of env steps total    1067000
Number of rollouts total     0
Train Time (s)               130.00008958484977
(Previous) Eval Time (s)     29.17688501579687
Sample Time (s)              23.469041800592095
Epoch Time (s)               182.64601640123874
Total Train Time (s)         38671.95661688782
Epoch                        212
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:32:15.993114 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #212 | Epoch Duration: 179.40100383758545
2020-01-13 15:32:15.993412 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #212 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5253386
Z variance train             0.0811844
KL Divergence                42.42661
KL Loss                      4.242661
QF Loss                      647.2427
VF Loss                      214.39554
Policy Loss                  -4449.603
Q Predictions Mean           4459.5977
Q Predictions Std            478.78036
Q Predictions Max            5192.3955
Q Predictions Min            3129.3809
V Predictions Mean           4456.3286
V Predictions Std            477.1614
V Predictions Max            5189.1816
V Predictions Min            3129.031
Log Pis Mean                 6.4772253
Log Pis Std                  3.755929
Log Pis Max                  15.54339
Log Pis Min                  -5.315324
Policy mu Mean               -0.22573195
Policy mu Std                1.4862883
Policy mu Max                2.7835436
Policy mu Min                -2.8864477
Policy log std Mean          -0.8634115
Policy log std Std           0.48019013
Policy log std Max           -0.16901708
Policy log std Min           -3.3521824
Z mean eval                  3.5573437
Z variance eval              0.041021343
total_rewards                [10784.62920849 11081.28335682 11040.99355656 11104.09510564
 10991.4585572  10826.69313916 10945.80652604 11069.83935868
 10976.77854192 11087.30592128]
total_rewards_mean           10990.888327178476
total_rewards_std            105.24345666979832
total_rewards_max            11104.095105636035
total_rewards_min            10784.629208490076
Number of train steps total  856000
Number of env steps total    1072000
Number of rollouts total     0
Train Time (s)               129.60713057080284
(Previous) Eval Time (s)     25.93150304397568
Sample Time (s)              22.31021828111261
Epoch Time (s)               177.84885189589113
Total Train Time (s)         38850.78324561287
Epoch                        213
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:35:14.820545 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #213 | Epoch Duration: 178.8269121646881
2020-01-13 15:35:14.820719 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #213 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.558993
Z variance train             0.041036792
KL Divergence                45.059097
KL Loss                      4.50591
QF Loss                      605.7603
VF Loss                      171.52634
Policy Loss                  -4396.59
Q Predictions Mean           4395.02
Q Predictions Std            496.08728
Q Predictions Max            5143.914
Q Predictions Min            3034.563
V Predictions Mean           4397.8457
V Predictions Std            495.4095
V Predictions Max            5138.326
V Predictions Min            3038.545
Log Pis Mean                 6.277545
Log Pis Std                  3.9894555
Log Pis Max                  18.160757
Log Pis Min                  -3.7606103
Policy mu Mean               -0.16946815
Policy mu Std                1.4889376
Policy mu Max                2.905841
Policy mu Min                -3.2006621
Policy log std Mean          -0.88373184
Policy log std Std           0.48061946
Policy log std Max           -0.023346305
Policy log std Min           -3.3337002
Z mean eval                  3.6077743
Z variance eval              0.034778483
total_rewards                [10837.81405845 11127.01448628 10981.82952531 11314.2942354
 11149.85380281 11239.48664943 10975.995865   11316.23509059
 11141.37684552 10877.77303845]
total_rewards_mean           11096.167359723519
total_rewards_std            162.59891519484677
total_rewards_max            11316.235090589136
total_rewards_min            10837.814058445241
Number of train steps total  860000
Number of env steps total    1077000
Number of rollouts total     0
Train Time (s)               132.54694412183017
(Previous) Eval Time (s)     26.909220580011606
Sample Time (s)              22.083447883371264
Epoch Time (s)               181.53961258521304
Total Train Time (s)         39033.72053007269
Epoch                        214
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:38:17.760694 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #214 | Epoch Duration: 182.9398431777954
2020-01-13 15:38:17.760881 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #214 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6090386
Z variance train             0.035024572
KL Divergence                46.49683
KL Loss                      4.649683
QF Loss                      2910.3572
VF Loss                      285.39392
Policy Loss                  -4378.511
Q Predictions Mean           4382.7324
Q Predictions Std            531.3473
Q Predictions Max            5076.756
Q Predictions Min            380.2965
V Predictions Mean           4370.299
V Predictions Std            524.62476
V Predictions Max            5063.6636
V Predictions Min            558.99445
Log Pis Mean                 6.1137977
Log Pis Std                  3.984111
Log Pis Max                  15.418016
Log Pis Min                  -8.458747
Policy mu Mean               -0.12756091
Policy mu Std                1.469397
Policy mu Max                3.3575678
Policy mu Min                -3.87155
Policy log std Mean          -0.9002476
Policy log std Std           0.48564473
Policy log std Max           -0.16190684
Policy log std Min           -3.5308607
Z mean eval                  3.5817933
Z variance eval              0.043240555
total_rewards                [10686.12440431 10785.89298274 10977.97017174 10857.23302014
 11190.49361265 11151.50441009 10869.79463627 10915.02235974
 11053.3476608  10926.36834418]
total_rewards_mean           10941.37516026726
total_rewards_std            149.17853143802185
total_rewards_max            11190.493612651828
total_rewards_min            10686.124404311222
Number of train steps total  864000
Number of env steps total    1082000
Number of rollouts total     0
Train Time (s)               138.76214533811435
(Previous) Eval Time (s)     28.30909461900592
Sample Time (s)              22.396439037285745
Epoch Time (s)               189.46767899440601
Total Train Time (s)         39223.02596553601
Epoch                        215
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:41:27.068929 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #215 | Epoch Duration: 189.30790972709656
2020-01-13 15:41:27.069117 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #215 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.580941
Z variance train             0.0431438
KL Divergence                45.382534
KL Loss                      4.5382533
QF Loss                      509.9422
VF Loss                      118.275986
Policy Loss                  -4332.5103
Q Predictions Mean           4334.1943
Q Predictions Std            594.3521
Q Predictions Max            5117.223
Q Predictions Min            -33.2898
V Predictions Mean           4338.7227
V Predictions Std            593.1583
V Predictions Max            5123.345
V Predictions Min            0.8370663
Log Pis Mean                 5.854273
Log Pis Std                  3.697366
Log Pis Max                  15.49676
Log Pis Min                  -3.5493226
Policy mu Mean               -0.16527553
Policy mu Std                1.4171187
Policy mu Max                3.2618427
Policy mu Min                -2.7889717
Policy log std Mean          -0.91018814
Policy log std Std           0.52088594
Policy log std Max           0.019385815
Policy log std Min           -3.6185298
Z mean eval                  3.60027
Z variance eval              0.041923203
total_rewards                [10941.85803397 10327.30959551 11021.36786753 10737.76787194
 10602.46803189 10393.95174177 10694.41664221 10890.21199553
 11060.28144994 11049.55657331]
total_rewards_mean           10771.918980360779
total_rewards_std            253.32905215974347
total_rewards_max            11060.281449941629
total_rewards_min            10327.309595507313
Number of train steps total  868000
Number of env steps total    1087000
Number of rollouts total     0
Train Time (s)               137.77508210623637
(Previous) Eval Time (s)     28.14894214598462
Sample Time (s)              22.59798462036997
Epoch Time (s)               188.52200887259096
Total Train Time (s)         39411.01506137103
Epoch                        216
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:44:35.060878 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #216 | Epoch Duration: 187.99162101745605
2020-01-13 15:44:35.061065 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #216 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.601263
Z variance train             0.042046648
KL Divergence                45.706036
KL Loss                      4.570604
QF Loss                      547.7782
VF Loss                      424.10498
Policy Loss                  -4373.906
Q Predictions Mean           4378.294
Q Predictions Std            461.37616
Q Predictions Max            5126.0376
Q Predictions Min            3048.4644
V Predictions Mean           4384.702
V Predictions Std            459.69363
V Predictions Max            5129.3877
V Predictions Min            3051.6023
Log Pis Mean                 6.270293
Log Pis Std                  3.8976963
Log Pis Max                  15.291672
Log Pis Min                  -6.1182756
Policy mu Mean               -0.11100072
Policy mu Std                1.4717222
Policy mu Max                2.8164625
Policy mu Min                -3.6683831
Policy log std Mean          -0.9003549
Policy log std Std           0.50671095
Policy log std Max           -0.10474378
Policy log std Min           -3.4082
Z mean eval                  3.5807235
Z variance eval              0.027099777
total_rewards                [10763.7423278  10918.84352386 10921.25201818 11076.35063502
 11235.6522115  11036.51113038 11153.73667354 11042.01560903
 11055.0784921  11211.81355165]
total_rewards_mean           11041.49961730561
total_rewards_std            136.8855242944844
total_rewards_max            11235.652211502296
total_rewards_min            10763.74232779687
Number of train steps total  872000
Number of env steps total    1092000
Number of rollouts total     0
Train Time (s)               138.2944515068084
(Previous) Eval Time (s)     27.61815834697336
Sample Time (s)              22.572139197494835
Epoch Time (s)               188.4847490512766
Total Train Time (s)         39601.03872878291
Epoch                        217
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:47:45.088060 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #217 | Epoch Duration: 190.0268518924713
2020-01-13 15:47:45.088291 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #217 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5820813
Z variance train             0.027021777
KL Divergence                46.885498
KL Loss                      4.68855
QF Loss                      792.6887
VF Loss                      248.70322
Policy Loss                  -4390.704
Q Predictions Mean           4399.526
Q Predictions Std            484.1327
Q Predictions Max            5132.241
Q Predictions Min            3063.034
V Predictions Mean           4391.399
V Predictions Std            482.36224
V Predictions Max            5105.2085
V Predictions Min            3070.2104
Log Pis Mean                 6.3666334
Log Pis Std                  4.2597504
Log Pis Max                  16.50565
Log Pis Min                  -6.226132
Policy mu Mean               -0.17909531
Policy mu Std                1.4811219
Policy mu Max                2.9101615
Policy mu Min                -3.264766
Policy log std Mean          -0.9008124
Policy log std Std           0.49015328
Policy log std Max           -0.12166512
Policy log std Min           -3.320087
Z mean eval                  3.5718288
Z variance eval              0.016908595
total_rewards                [10587.52758953 10753.1195883  10558.46841893 10823.76861354
 10855.98153868 10892.7794073  10850.61098209 10499.63892414
 10819.05900143 10756.28290605]
total_rewards_mean           10739.723697000074
total_rewards_std            132.93120444423508
total_rewards_max            10892.779407298538
total_rewards_min            10499.63892414379
Number of train steps total  876000
Number of env steps total    1097000
Number of rollouts total     0
Train Time (s)               136.95821139402688
(Previous) Eval Time (s)     29.159864003770053
Sample Time (s)              22.663029798772186
Epoch Time (s)               188.78110519656911
Total Train Time (s)         39789.93020190718
Epoch                        218
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:50:53.980812 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #218 | Epoch Duration: 188.8923888206482
2020-01-13 15:50:53.980930 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #218 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5695329
Z variance train             0.016883504
KL Divergence                48.102333
KL Loss                      4.8102336
QF Loss                      712.77423
VF Loss                      135.8842
Policy Loss                  -4322.7207
Q Predictions Mean           4321.9277
Q Predictions Std            535.9292
Q Predictions Max            5178.5835
Q Predictions Min            3007.1523
V Predictions Mean           4324.4023
V Predictions Std            535.8328
V Predictions Max            5166.383
V Predictions Min            3010.2473
Log Pis Mean                 5.478544
Log Pis Std                  3.6553886
Log Pis Max                  15.177506
Log Pis Min                  -3.7653422
Policy mu Mean               -0.16990888
Policy mu Std                1.4064988
Policy mu Max                2.8483326
Policy mu Min                -3.1651266
Policy log std Mean          -0.8869571
Policy log std Std           0.47369888
Policy log std Max           -0.20800471
Policy log std Min           -3.413335
Z mean eval                  3.5685573
Z variance eval              0.012005026
total_rewards                [10703.27137823 10474.67852929 11039.25789906 10603.17295617
 11188.03140378 10772.83241463 10852.08099552 11001.46600744
 10576.20529972 10920.21626585]
total_rewards_mean           10813.121314969527
total_rewards_std            216.4711234027931
total_rewards_max            11188.031403784602
total_rewards_min            10474.67852928603
Number of train steps total  880000
Number of env steps total    1102000
Number of rollouts total     0
Train Time (s)               130.319444286637
(Previous) Eval Time (s)     29.27076427778229
Sample Time (s)              20.53051263326779
Epoch Time (s)               180.1207211976871
Total Train Time (s)         39968.67446049908
Epoch                        219
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:53:52.728690 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #219 | Epoch Duration: 178.74765491485596
2020-01-13 15:53:52.728886 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #219 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5709853
Z variance train             0.0120161865
KL Divergence                48.898323
KL Loss                      4.8898325
QF Loss                      421.6842
VF Loss                      266.12125
Policy Loss                  -4475.8037
Q Predictions Mean           4478.052
Q Predictions Std            488.93878
Q Predictions Max            5227.4526
Q Predictions Min            3100.905
V Predictions Mean           4462.6006
V Predictions Std            486.27243
V Predictions Max            5218.0063
V Predictions Min            3103.2056
Log Pis Mean                 5.6907578
Log Pis Std                  3.8131514
Log Pis Max                  15.338314
Log Pis Min                  -3.56326
Policy mu Mean               -0.1063629
Policy mu Std                1.4355029
Policy mu Max                3.0052817
Policy mu Min                -2.8023956
Policy log std Mean          -0.8647688
Policy log std Std           0.45913827
Policy log std Max           -0.18217188
Policy log std Min           -3.2613184
Z mean eval                  3.5825386
Z variance eval              0.011881558
total_rewards                [10665.34584206 11086.99004853 11017.61048729 11063.2929428
 11293.28533754 11309.01991119 11027.2248407  11178.78411984
 10884.24127778 10929.31880562]
total_rewards_mean           11045.511361335552
total_rewards_std            183.2414857327246
total_rewards_max            11309.019911193765
total_rewards_min            10665.345842056977
Number of train steps total  884000
Number of env steps total    1107000
Number of rollouts total     0
Train Time (s)               130.12688332796097
(Previous) Eval Time (s)     27.89734361693263
Sample Time (s)              21.31749752815813
Epoch Time (s)               179.34172447305173
Total Train Time (s)         40147.6024519098
Epoch                        220
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:56:51.659977 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #220 | Epoch Duration: 178.93092322349548
2020-01-13 15:56:51.660253 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #220 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5829403
Z variance train             0.011886052
KL Divergence                50.402122
KL Loss                      5.040212
QF Loss                      570.16846
VF Loss                      309.8568
Policy Loss                  -4429.5146
Q Predictions Mean           4436.5264
Q Predictions Std            498.3799
Q Predictions Max            5138.3213
Q Predictions Min            3049.7852
V Predictions Mean           4440.496
V Predictions Std            498.2437
V Predictions Max            5133.55
V Predictions Min            3056.6914
Log Pis Mean                 5.7043676
Log Pis Std                  3.703479
Log Pis Max                  14.215156
Log Pis Min                  -4.3967257
Policy mu Mean               -0.0813688
Policy mu Std                1.4180741
Policy mu Max                3.191942
Policy mu Min                -2.7817147
Policy log std Mean          -0.9276219
Policy log std Std           0.49436456
Policy log std Max           -0.15454984
Policy log std Min           -3.4415708
Z mean eval                  3.6210976
Z variance eval              0.011632006
total_rewards                [10973.16827424 10954.47059163 11314.16755852 11133.43207289
 11069.97289805 10918.66616672 11118.48074588 11061.12914626
 10926.45617429 10584.47825004]
total_rewards_mean           11005.442187851428
total_rewards_std            180.65296701258802
total_rewards_max            11314.167558516794
total_rewards_min            10584.478250037457
Number of train steps total  888000
Number of env steps total    1112000
Number of rollouts total     0
Train Time (s)               133.99455569218844
(Previous) Eval Time (s)     27.486159971915185
Sample Time (s)              22.349973177537322
Epoch Time (s)               183.83068884164095
Total Train Time (s)         40330.46825091541
Epoch                        221
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:59:54.528452 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #221 | Epoch Duration: 182.86802506446838
2020-01-13 15:59:54.528639 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #221 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.620233
Z variance train             0.0117072
KL Divergence                52.555206
KL Loss                      5.255521
QF Loss                      576.452
VF Loss                      191.77899
Policy Loss                  -4358.1655
Q Predictions Mean           4361.8496
Q Predictions Std            583.94617
Q Predictions Max            5190.1987
Q Predictions Min            69.82819
V Predictions Mean           4354.3975
V Predictions Std            579.7862
V Predictions Max            5178.951
V Predictions Min            51.187355
Log Pis Mean                 5.908699
Log Pis Std                  3.9062626
Log Pis Max                  17.331772
Log Pis Min                  -8.262556
Policy mu Mean               -0.16375487
Policy mu Std                1.4461294
Policy mu Max                4.6539016
Policy mu Min                -3.2052546
Policy log std Mean          -0.8919999
Policy log std Std           0.46124437
Policy log std Max           0.08667314
Policy log std Min           -3.522737
Z mean eval                  3.62654
Z variance eval              0.0102722375
total_rewards                [10643.87020137 10936.30292853 10816.70192652 10690.76878118
 10447.5717792  10819.4839992  10721.11430591 10588.45796461
 10629.25427067 10645.5665536 ]
total_rewards_mean           10693.909271079216
total_rewards_std            130.83388100555416
total_rewards_max            10936.302928527639
total_rewards_min            10447.571779203749
Number of train steps total  892000
Number of env steps total    1117000
Number of rollouts total     0
Train Time (s)               138.85059087723494
(Previous) Eval Time (s)     26.523141815327108
Sample Time (s)              23.051983588840812
Epoch Time (s)               188.42571628140286
Total Train Time (s)         40520.16151444148
Epoch                        222
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:03:04.224969 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #222 | Epoch Duration: 189.69616842269897
2020-01-13 16:03:04.225282 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #222 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6245823
Z variance train             0.010265864
KL Divergence                51.34535
KL Loss                      5.134535
QF Loss                      1079.7063
VF Loss                      328.17432
Policy Loss                  -4372.1826
Q Predictions Mean           4375.558
Q Predictions Std            517.696
Q Predictions Max            5143.462
Q Predictions Min            3075.2795
V Predictions Mean           4386.3936
V Predictions Std            515.0607
V Predictions Max            5158.2197
V Predictions Min            3079.2473
Log Pis Mean                 5.3486004
Log Pis Std                  3.912198
Log Pis Max                  16.393497
Log Pis Min                  -4.6123896
Policy mu Mean               -0.108570494
Policy mu Std                1.3911586
Policy mu Max                2.839925
Policy mu Min                -2.6107326
Policy log std Mean          -0.915915
Policy log std Std           0.47644016
Policy log std Max           -0.20724127
Policy log std Min           -3.2313752
Z mean eval                  3.629706
Z variance eval              0.021015204
total_rewards                [10330.03467356  9933.95789435 10641.70467917 10828.88647243
 10069.95909105 10116.37102745 10576.89076741 10571.45141253
 10539.98510955  9984.56782386]
total_rewards_mean           10359.380895136503
total_rewards_std            298.36120432913674
total_rewards_max            10828.88647243399
total_rewards_min            9933.957894348023
Number of train steps total  896000
Number of env steps total    1122000
Number of rollouts total     0
Train Time (s)               137.5586471199058
(Previous) Eval Time (s)     27.793178881984204
Sample Time (s)              22.809782201889902
Epoch Time (s)               188.1616082037799
Total Train Time (s)         40709.236604063306
Epoch                        223
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:06:13.303117 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #223 | Epoch Duration: 189.077641248703
2020-01-13 16:06:13.303390 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #223 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.629734
Z variance train             0.021029325
KL Divergence                52.583042
KL Loss                      5.258304
QF Loss                      1811.7018
VF Loss                      240.99501
Policy Loss                  -4410.098
Q Predictions Mean           4409.339
Q Predictions Std            455.51102
Q Predictions Max            5056.1396
Q Predictions Min            3115.6458
V Predictions Mean           4404.782
V Predictions Std            455.58676
V Predictions Max            5051.7603
V Predictions Min            3104.9067
Log Pis Mean                 5.933659
Log Pis Std                  3.9076989
Log Pis Max                  17.303135
Log Pis Min                  -5.6006336
Policy mu Mean               -0.1284235
Policy mu Std                1.4472914
Policy mu Max                3.2305727
Policy mu Min                -3.135687
Policy log std Mean          -0.9052878
Policy log std Std           0.4961636
Policy log std Max           -0.02151215
Policy log std Min           -3.425479
Z mean eval                  3.6270359
Z variance eval              0.02029493
total_rewards                [11041.54408466 11255.99123238 10996.46451609 11190.57313739
 10956.45756378 11146.40442335 10908.16880899 11150.58285271
 11276.07706042 11217.47503842]
total_rewards_mean           11113.97387181826
total_rewards_std            123.14215586879602
total_rewards_max            11276.077060416863
total_rewards_min            10908.168808986718
Number of train steps total  900000
Number of env steps total    1127000
Number of rollouts total     0
Train Time (s)               138.96951330685988
(Previous) Eval Time (s)     28.708812050055712
Sample Time (s)              22.90996343223378
Epoch Time (s)               190.58828878914937
Total Train Time (s)         40899.19120282354
Epoch                        224
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:09:23.260986 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #224 | Epoch Duration: 189.95735239982605
2020-01-13 16:09:23.261289 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #224 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6285279
Z variance train             0.020308843
KL Divergence                51.33998
KL Loss                      5.1339984
QF Loss                      1984.3745
VF Loss                      388.05658
Policy Loss                  -4408.038
Q Predictions Mean           4414.1396
Q Predictions Std            490.12665
Q Predictions Max            5105.208
Q Predictions Min            3078.7751
V Predictions Mean           4401.0566
V Predictions Std            492.33627
V Predictions Max            5087.6133
V Predictions Min            3064.1716
Log Pis Mean                 6.1843114
Log Pis Std                  4.024492
Log Pis Max                  19.364685
Log Pis Min                  -4.711585
Policy mu Mean               -0.14997439
Policy mu Std                1.4561523
Policy mu Max                3.8225257
Policy mu Min                -3.3308055
Policy log std Mean          -0.8881326
Policy log std Std           0.47780842
Policy log std Max           -0.14296544
Policy log std Min           -3.51209
Z mean eval                  3.6490238
Z variance eval              0.025391016
total_rewards                [10671.06375719 11028.32377334 10915.02583779 11009.75667021
 11206.3157473  11161.16004097 10668.85012334 10972.36689188
 11338.11159858 10956.83647701]
total_rewards_mean           10992.781091762085
total_rewards_std            202.71681754013395
total_rewards_max            11338.111598581245
total_rewards_min            10668.850123342821
Number of train steps total  904000
Number of env steps total    1132000
Number of rollouts total     0
Train Time (s)               138.04796421388164
(Previous) Eval Time (s)     28.077416067011654
Sample Time (s)              22.279752353206277
Epoch Time (s)               188.40513263409957
Total Train Time (s)         41086.862241663504
Epoch                        225
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:12:30.934234 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #225 | Epoch Duration: 187.6727786064148
2020-01-13 16:12:30.934424 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #225 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6519647
Z variance train             0.02532981
KL Divergence                51.76956
KL Loss                      5.176956
QF Loss                      430.10883
VF Loss                      289.6385
Policy Loss                  -4384.4326
Q Predictions Mean           4384.8022
Q Predictions Std            505.57834
Q Predictions Max            5101.3164
Q Predictions Min            3055.1663
V Predictions Mean           4372.964
V Predictions Std            502.88843
V Predictions Max            5085.2256
V Predictions Min            3065.636
Log Pis Mean                 5.5766735
Log Pis Std                  4.2263646
Log Pis Max                  20.753782
Log Pis Min                  -4.9992323
Policy mu Mean               -0.11021749
Policy mu Std                1.4108922
Policy mu Max                3.2203236
Policy mu Min                -3.3306427
Policy log std Mean          -0.9006435
Policy log std Std           0.47532594
Policy log std Max           0.17344904
Policy log std Min           -3.3163497
Z mean eval                  3.5856519
Z variance eval              0.034357116
total_rewards                [10729.2937682   2729.97124306  1665.98962374 10600.83725116
 11105.17796603  8865.79187225 11120.47795788 10705.41642955
 10711.74034672 10755.73967736]
total_rewards_mean           8899.043613595502
total_rewards_std            3412.0304603166533
total_rewards_max            11120.477957875311
total_rewards_min            1665.9896237412527
Number of train steps total  908000
Number of env steps total    1137000
Number of rollouts total     0
Train Time (s)               130.60495500592515
(Previous) Eval Time (s)     27.344701679889113
Sample Time (s)              21.389021542388946
Epoch Time (s)               179.3386782282032
Total Train Time (s)         41266.7082989919
Epoch                        226
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:15:30.783439 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #226 | Epoch Duration: 179.8488790988922
2020-01-13 16:15:30.783633 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #226 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5878167
Z variance train             0.034282785
KL Divergence                47.65331
KL Loss                      4.765331
QF Loss                      601.4172
VF Loss                      321.19913
Policy Loss                  -4375.4053
Q Predictions Mean           4373.1357
Q Predictions Std            493.37924
Q Predictions Max            5144.077
Q Predictions Min            3039.7637
V Predictions Mean           4365.89
V Predictions Std            493.00565
V Predictions Max            5143.0347
V Predictions Min            3027.958
Log Pis Mean                 6.243001
Log Pis Std                  3.835262
Log Pis Max                  15.736511
Log Pis Min                  -3.745812
Policy mu Mean               -0.12630296
Policy mu Std                1.4616497
Policy mu Max                3.0652537
Policy mu Min                -2.6131837
Policy log std Mean          -0.88892484
Policy log std Std           0.49766222
Policy log std Max           -0.08028221
Policy log std Min           -3.4514828
Z mean eval                  3.5776412
Z variance eval              0.03809422
total_rewards                [10654.16966719 11135.36100801 11135.8293559  11078.4865717
 10881.88050713 11111.37033204 11238.34823579 11243.59108788
 10787.12775224 11158.76120472]
total_rewards_mean           11042.492572259654
total_rewards_std            189.07579684275385
total_rewards_max            11243.591087883968
total_rewards_min            10654.169667188742
Number of train steps total  912000
Number of env steps total    1142000
Number of rollouts total     0
Train Time (s)               129.82290361821651
(Previous) Eval Time (s)     27.85460674064234
Sample Time (s)              22.384501268155873
Epoch Time (s)               180.06201162701473
Total Train Time (s)         41447.04109032592
Epoch                        227
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:18:31.119101 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #227 | Epoch Duration: 180.33532404899597
2020-01-13 16:18:31.119338 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #227 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.576323
Z variance train             0.038097706
KL Divergence                47.64115
KL Loss                      4.7641153
QF Loss                      555.3816
VF Loss                      122.59491
Policy Loss                  -4310.6465
Q Predictions Mean           4315.2334
Q Predictions Std            575.7295
Q Predictions Max            5068.8623
Q Predictions Min            57.62854
V Predictions Mean           4313.123
V Predictions Std            576.3082
V Predictions Max            5051.587
V Predictions Min            21.640491
Log Pis Mean                 5.3532524
Log Pis Std                  3.6735113
Log Pis Max                  18.552944
Log Pis Min                  -9.87923
Policy mu Mean               -0.144232
Policy mu Std                1.371274
Policy mu Max                3.7162385
Policy mu Min                -2.8220315
Policy log std Mean          -0.8823667
Policy log std Std           0.45839396
Policy log std Max           -0.14738178
Policy log std Min           -3.2638736
Z mean eval                  3.6890807
Z variance eval              0.01881969
total_rewards                [11071.83880591 11270.94284574 10740.68662416 11354.54628725
 10845.75574003 10809.84214264 11032.26664347 11245.11945853
 11425.9563103  10952.43119033]
total_rewards_mean           11074.938604835725
total_rewards_std            228.0651111094371
total_rewards_max            11425.956310301654
total_rewards_min            10740.686624157144
Number of train steps total  916000
Number of env steps total    1147000
Number of rollouts total     0
Train Time (s)               135.77968807704747
(Previous) Eval Time (s)     28.127548673190176
Sample Time (s)              19.032704637385905
Epoch Time (s)               182.93994138762355
Total Train Time (s)         41629.5256274757
Epoch                        228
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:21:33.606634 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #228 | Epoch Duration: 182.48715019226074
2020-01-13 16:21:33.606827 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #228 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6877143
Z variance train             0.018831737
KL Divergence                51.744946
KL Loss                      5.1744947
QF Loss                      837.8202
VF Loss                      138.03976
Policy Loss                  -4440.797
Q Predictions Mean           4450.2354
Q Predictions Std            557.23785
Q Predictions Max            5096.699
Q Predictions Min            297.35312
V Predictions Mean           4443.2285
V Predictions Std            555.0573
V Predictions Max            5088.8794
V Predictions Min            289.26425
Log Pis Mean                 5.842512
Log Pis Std                  4.107904
Log Pis Max                  15.96909
Log Pis Min                  -3.902244
Policy mu Mean               -0.07778656
Policy mu Std                1.440597
Policy mu Max                3.0740602
Policy mu Min                -2.868659
Policy log std Mean          -0.9047239
Policy log std Std           0.5016331
Policy log std Max           -0.1142796
Policy log std Min           -3.3057337
Z mean eval                  3.6015606
Z variance eval              0.01592974
total_rewards                [10779.27621794 10960.20026199 10872.70709881  3629.3549694
 10924.75597219 10708.66695915 10917.73426929 11007.56809965
 11014.33722296 11095.44906469]
total_rewards_mean           10191.005013605913
total_rewards_std            2189.8598902156928
total_rewards_max            11095.449064694481
total_rewards_min            3629.354969397558
Number of train steps total  920000
Number of env steps total    1152000
Number of rollouts total     0
Train Time (s)               137.2489726548083
(Previous) Eval Time (s)     27.674498667009175
Sample Time (s)              23.166405610740185
Epoch Time (s)               188.08987693255767
Total Train Time (s)         41818.83942152327
Epoch                        229
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:24:42.924256 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #229 | Epoch Duration: 189.31728219985962
2020-01-13 16:24:42.924471 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #229 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.602469
Z variance train             0.015975874
KL Divergence                49.951767
KL Loss                      4.995177
QF Loss                      1127.2067
VF Loss                      215.22026
Policy Loss                  -4349.3237
Q Predictions Mean           4346.4365
Q Predictions Std            508.79092
Q Predictions Max            5095.822
Q Predictions Min            3015.4497
V Predictions Mean           4344.039
V Predictions Std            507.7582
V Predictions Max            5097.638
V Predictions Min            3006.4663
Log Pis Mean                 5.487221
Log Pis Std                  3.7925165
Log Pis Max                  16.104412
Log Pis Min                  -3.5728233
Policy mu Mean               -0.14778362
Policy mu Std                1.3710287
Policy mu Max                2.9363737
Policy mu Min                -2.8688958
Policy log std Mean          -0.91214424
Policy log std Std           0.5010145
Policy log std Max           -0.26844394
Policy log std Min           -3.5916705
Z mean eval                  3.6394532
Z variance eval              0.022601837
total_rewards                [11190.5435963  10841.8644313  11243.84662928 11064.77680134
 11073.93977626 10897.91782412 11130.65545706 11014.15470396
 11029.16005722 10723.74859478]
total_rewards_mean           11021.060787161814
total_rewards_std            151.9406391639563
total_rewards_max            11243.846629276435
total_rewards_min            10723.748594778735
Number of train steps total  924000
Number of env steps total    1157000
Number of rollouts total     0
Train Time (s)               136.72836495004594
(Previous) Eval Time (s)     28.90141213964671
Sample Time (s)              22.77932329196483
Epoch Time (s)               188.40910038165748
Total Train Time (s)         42005.813672385644
Epoch                        230
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:27:49.900963 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #230 | Epoch Duration: 186.97634601593018
2020-01-13 16:27:49.901168 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #230 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6367347
Z variance train             0.02259748
KL Divergence                49.759094
KL Loss                      4.9759097
QF Loss                      985.98535
VF Loss                      345.17648
Policy Loss                  -4461.267
Q Predictions Mean           4461.204
Q Predictions Std            437.2352
Q Predictions Max            5105.4087
Q Predictions Min            2975.0256
V Predictions Mean           4471.7725
V Predictions Std            428.29053
V Predictions Max            5084.2227
V Predictions Min            3159.2205
Log Pis Mean                 6.026985
Log Pis Std                  3.8220503
Log Pis Max                  20.186954
Log Pis Min                  -2.5809803
Policy mu Mean               -0.15817656
Policy mu Std                1.4477918
Policy mu Max                4.124621
Policy mu Min                -3.5133283
Policy log std Mean          -0.90471953
Policy log std Std           0.48291373
Policy log std Max           -0.14568818
Policy log std Min           -3.3833938
Z mean eval                  3.69454
Z variance eval              0.024032751
total_rewards                [10791.12160321 11226.47931357 11088.73884629 10664.52208307
 11037.31996857 11248.90510755 11106.04168783 11381.15816716
 11186.7278011  11269.53087085]
total_rewards_mean           11100.054544921635
total_rewards_std            210.38560852149334
total_rewards_max            11381.15816715771
total_rewards_min            10664.522083068367
Number of train steps total  928000
Number of env steps total    1162000
Number of rollouts total     0
Train Time (s)               138.8558755251579
(Previous) Eval Time (s)     27.468298533931375
Sample Time (s)              22.5575382723473
Epoch Time (s)               188.88171233143657
Total Train Time (s)         42194.360699113924
Epoch                        231
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:30:58.451327 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #231 | Epoch Duration: 188.54998755455017
2020-01-13 16:30:58.451627 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #231 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6924884
Z variance train             0.024102159
KL Divergence                53.757835
KL Loss                      5.3757834
QF Loss                      520.36035
VF Loss                      123.74743
Policy Loss                  -4457.8647
Q Predictions Mean           4461.3145
Q Predictions Std            548.9173
Q Predictions Max            5142.166
Q Predictions Min            -8.311478
V Predictions Mean           4459.6797
V Predictions Std            545.6823
V Predictions Max            5140.6313
V Predictions Min            4.2682724
Log Pis Mean                 5.909874
Log Pis Std                  4.0304685
Log Pis Max                  15.60661
Log Pis Min                  -6.6062155
Policy mu Mean               -0.15849662
Policy mu Std                1.4272493
Policy mu Max                2.9854782
Policy mu Min                -2.9096725
Policy log std Mean          -0.9131114
Policy log std Std           0.50965255
Policy log std Max           -0.07255554
Policy log std Min           -3.4820232
Z mean eval                  3.6906345
Z variance eval              0.018014459
total_rewards                [10943.48653681 11140.97282605 11108.0523189  11058.98510724
 11069.32735511 11157.31874001 11060.60660571 11162.0423649
 11114.41762741 11201.90044311]
total_rewards_mean           11101.71099252688
total_rewards_std            69.3627673116755
total_rewards_max            11201.900443113524
total_rewards_min            10943.486536811133
Number of train steps total  932000
Number of env steps total    1167000
Number of rollouts total     0
Train Time (s)               137.016662531998
(Previous) Eval Time (s)     27.136230852920562
Sample Time (s)              22.38072927389294
Epoch Time (s)               186.5336226588115
Total Train Time (s)         42380.53764404636
Epoch                        232
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:34:04.630686 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #232 | Epoch Duration: 186.17889785766602
2020-01-13 16:34:04.630864 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #232 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6893756
Z variance train             0.017921124
KL Divergence                54.217445
KL Loss                      5.421745
QF Loss                      454.2782
VF Loss                      182.26143
Policy Loss                  -4422.9717
Q Predictions Mean           4425.6675
Q Predictions Std            617.539
Q Predictions Max            5142.267
Q Predictions Min            -3.8242319
V Predictions Mean           4427.4385
V Predictions Std            613.9344
V Predictions Max            5121.896
V Predictions Min            11.850332
Log Pis Mean                 5.1295705
Log Pis Std                  3.7190025
Log Pis Max                  15.393394
Log Pis Min                  -5.1537924
Policy mu Mean               -0.1687488
Policy mu Std                1.3535173
Policy mu Max                2.8751261
Policy mu Min                -2.6654692
Policy log std Mean          -0.90382594
Policy log std Std           0.49276972
Policy log std Max           0.31458807
Policy log std Min           -3.4227018
Z mean eval                  3.648074
Z variance eval              0.035035618
total_rewards                [10614.58161678 10983.27119578 10742.3927104  10860.21068899
 10716.70121318 10740.39219385 10780.73076496 10883.1497976
 10616.34765619 10784.20908766]
total_rewards_mean           10772.19869253898
total_rewards_std            109.05852325961607
total_rewards_max            10983.271195780078
total_rewards_min            10614.581616782527
Number of train steps total  936000
Number of env steps total    1172000
Number of rollouts total     0
Train Time (s)               130.87410176591948
(Previous) Eval Time (s)     26.781212648842484
Sample Time (s)              21.62866120552644
Epoch Time (s)               179.2839756202884
Total Train Time (s)         42560.976895499974
Epoch                        233
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:37:05.073710 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #233 | Epoch Duration: 180.44269013404846
2020-01-13 16:37:05.073974 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #233 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6483643
Z variance train             0.035134453
KL Divergence                52.953823
KL Loss                      5.2953825
QF Loss                      773.7302
VF Loss                      215.78091
Policy Loss                  -4489.018
Q Predictions Mean           4496.3394
Q Predictions Std            450.97327
Q Predictions Max            5160.848
Q Predictions Min            2931.9583
V Predictions Mean           4483.281
V Predictions Std            448.46817
V Predictions Max            5153.4155
V Predictions Min            2986.2966
Log Pis Mean                 5.757285
Log Pis Std                  3.4735224
Log Pis Max                  13.755032
Log Pis Min                  -2.3565848
Policy mu Mean               -0.06852808
Policy mu Std                1.4311547
Policy mu Max                4.562835
Policy mu Min                -3.1782212
Policy log std Mean          -0.9116504
Policy log std Std           0.5136967
Policy log std Max           -0.23045841
Policy log std Min           -3.3131413
Z mean eval                  3.636022
Z variance eval              0.017547524
total_rewards                [10940.19592838 10617.51385685 10872.93553012 11175.55430173
 11201.26412059 11140.75079663 11104.78813004 10982.25340403
 11139.31667016 11361.70549067]
total_rewards_mean           11053.627822919398
total_rewards_std            197.46669556077464
total_rewards_max            11361.705490666836
total_rewards_min            10617.513856845482
Number of train steps total  940000
Number of env steps total    1177000
Number of rollouts total     0
Train Time (s)               130.39951725769788
(Previous) Eval Time (s)     27.93956613028422
Sample Time (s)              22.357870822772384
Epoch Time (s)               180.69695421075448
Total Train Time (s)         42740.59222695092
Epoch                        234
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:40:04.692298 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #234 | Epoch Duration: 179.61814999580383
2020-01-13 16:40:04.692545 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #234 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6383648
Z variance train             0.017561022
KL Divergence                53.222008
KL Loss                      5.322201
QF Loss                      1393.4465
VF Loss                      145.74234
Policy Loss                  -4459.6562
Q Predictions Mean           4460.753
Q Predictions Std            518.2458
Q Predictions Max            5133.699
Q Predictions Min            3030.7556
V Predictions Mean           4454.05
V Predictions Std            515.099
V Predictions Max            5124.939
V Predictions Min            3041.6733
Log Pis Mean                 5.7440877
Log Pis Std                  3.513485
Log Pis Max                  15.548257
Log Pis Min                  -6.8086514
Policy mu Mean               -0.13719366
Policy mu Std                1.412675
Policy mu Max                3.07082
Policy mu Min                -4.4186683
Policy log std Mean          -0.8935733
Policy log std Std           0.48381385
Policy log std Max           0.29736936
Policy log std Min           -3.5422611
Z mean eval                  3.68111
Z variance eval              0.01760913
total_rewards                [11146.668181   11144.78924906 11125.10936051 10730.9758246
 11259.02090747 11265.94660822 10959.8924052  10959.05118536
 11102.36357818 11387.38947466]
total_rewards_mean           11108.120677425783
total_rewards_std            177.55415873882126
total_rewards_max            11387.38947466197
total_rewards_min            10730.97582459918
Number of train steps total  944000
Number of env steps total    1182000
Number of rollouts total     0
Train Time (s)               136.17809143522754
(Previous) Eval Time (s)     26.86039082193747
Sample Time (s)              21.504986776970327
Epoch Time (s)               184.54346903413534
Total Train Time (s)         42926.6967315278
Epoch                        235
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:43:10.799578 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #235 | Epoch Duration: 186.1068720817566
2020-01-13 16:43:10.799771 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #235 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6804192
Z variance train             0.017687585
KL Divergence                54.481976
KL Loss                      5.448198
QF Loss                      941.3017
VF Loss                      152.21951
Policy Loss                  -4447.918
Q Predictions Mean           4453.3965
Q Predictions Std            498.74948
Q Predictions Max            5192.639
Q Predictions Min            3130.555
V Predictions Mean           4453.3516
V Predictions Std            496.37842
V Predictions Max            5185.7427
V Predictions Min            3126.5278
Log Pis Mean                 5.6985326
Log Pis Std                  3.8797176
Log Pis Max                  22.939045
Log Pis Min                  -3.773415
Policy mu Mean               -0.08251228
Policy mu Std                1.4237401
Policy mu Max                2.9643457
Policy mu Min                -3.5062616
Policy log std Mean          -0.89269334
Policy log std Std           0.4932591
Policy log std Max           -0.021921873
Policy log std Min           -3.3295412
Z mean eval                  3.6470191
Z variance eval              0.015725471
total_rewards                [10923.40712457 11182.40138601 11002.09617749 10965.34212904
 10643.74484573 11016.1580934  10921.02507264 10872.54536945
 10489.38405029 11338.67206619]
total_rewards_mean           10935.477631480922
total_rewards_std            228.86653167601148
total_rewards_max            11338.672066194626
total_rewards_min            10489.38405029465
Number of train steps total  948000
Number of env steps total    1187000
Number of rollouts total     0
Train Time (s)               136.96589717874303
(Previous) Eval Time (s)     28.423432962968946
Sample Time (s)              23.54625502694398
Epoch Time (s)               188.93558516865596
Total Train Time (s)         43116.391745234374
Epoch                        236
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:46:20.498461 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #236 | Epoch Duration: 189.69853615760803
2020-01-13 16:46:20.498678 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #236 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6465964
Z variance train             0.015734024
KL Divergence                53.68643
KL Loss                      5.3686433
QF Loss                      417.9817
VF Loss                      96.41085
Policy Loss                  -4432.042
Q Predictions Mean           4439.964
Q Predictions Std            651.7371
Q Predictions Max            5127.2554
Q Predictions Min            24.969341
V Predictions Mean           4437.085
V Predictions Std            651.8523
V Predictions Max            5135.3633
V Predictions Min            0.87964183
Log Pis Mean                 5.338398
Log Pis Std                  3.866175
Log Pis Max                  15.819157
Log Pis Min                  -3.7708564
Policy mu Mean               -0.10120269
Policy mu Std                1.381194
Policy mu Max                2.836358
Policy mu Min                -3.1282988
Policy log std Mean          -0.8884924
Policy log std Std           0.49264973
Policy log std Max           0.050831378
Policy log std Min           -3.3188105
Z mean eval                  3.7113461
Z variance eval              0.023773467
total_rewards                [10406.89463646 10862.09883834 10927.31446655 11049.9719197
 10961.91745501 10809.77439413 10973.1680958  10680.69965531
 11036.24977763 10863.4777072 ]
total_rewards_mean           10857.156694613179
total_rewards_std            182.97269977076533
total_rewards_max            11049.97191969955
total_rewards_min            10406.894636459574
Number of train steps total  952000
Number of env steps total    1192000
Number of rollouts total     0
Train Time (s)               136.57527072681114
(Previous) Eval Time (s)     29.18603467522189
Sample Time (s)              23.46976255439222
Epoch Time (s)               189.23106795642525
Total Train Time (s)         43302.83735563699
Epoch                        237
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:49:26.944385 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #237 | Epoch Duration: 186.4455852508545
2020-01-13 16:49:26.944505 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #237 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7133346
Z variance train             0.023945104
KL Divergence                53.713844
KL Loss                      5.3713846
QF Loss                      550.64746
VF Loss                      145.72855
Policy Loss                  -4547.756
Q Predictions Mean           4554.6494
Q Predictions Std            565.6922
Q Predictions Max            5314.7393
Q Predictions Min            54.259247
V Predictions Mean           4541.634
V Predictions Std            565.5797
V Predictions Max            5290.2163
V Predictions Min            0.88119817
Log Pis Mean                 5.924184
Log Pis Std                  3.6551943
Log Pis Max                  16.935755
Log Pis Min                  -2.1890132
Policy mu Mean               -0.10503858
Policy mu Std                1.3940256
Policy mu Max                2.9573884
Policy mu Min                -3.0060277
Policy log std Mean          -0.91857004
Policy log std Std           0.5291555
Policy log std Max           -0.0361948
Policy log std Min           -3.4955459
Z mean eval                  3.6772773
Z variance eval              0.0033779484
total_rewards                [10434.61746155 10660.24963567 11025.27187825 10653.97471199
 10751.74790041 10622.47499208 10889.74008152 10839.46156469
 10728.60760447 10778.99978147]
total_rewards_mean           10738.51456120929
total_rewards_std            153.7181023685407
total_rewards_max            11025.271878245436
total_rewards_min            10434.617461549677
Number of train steps total  956000
Number of env steps total    1197000
Number of rollouts total     0
Train Time (s)               138.4751966232434
(Previous) Eval Time (s)     26.400205062702298
Sample Time (s)              21.162258518859744
Epoch Time (s)               186.03766020480543
Total Train Time (s)         43491.19669687515
Epoch                        238
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:52:35.308164 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #238 | Epoch Duration: 188.36350989341736
2020-01-13 16:52:35.308570 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #238 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6764953
Z variance train             0.0033818148
KL Divergence                56.70192
KL Loss                      5.6701922
QF Loss                      617.1155
VF Loss                      386.57318
Policy Loss                  -4469.8643
Q Predictions Mean           4473.698
Q Predictions Std            567.638
Q Predictions Max            5183.119
Q Predictions Min            136.54495
V Predictions Mean           4455.2217
V Predictions Std            563.53876
V Predictions Max            5170.255
V Predictions Min            129.22751
Log Pis Mean                 5.843357
Log Pis Std                  3.5844347
Log Pis Max                  23.115326
Log Pis Min                  -2.9362154
Policy mu Mean               -0.1381033
Policy mu Std                1.3832643
Policy mu Max                3.591202
Policy mu Min                -4.363809
Policy log std Mean          -0.9303337
Policy log std Std           0.5252631
Policy log std Max           0.45878816
Policy log std Min           -3.5439005
Z mean eval                  3.679737
Z variance eval              0.0036285329
total_rewards                [10793.17691489 11002.61662267 11217.87637778 10996.8319292
 11336.89501414 11049.80063772 10990.45522205 11087.33117475
 11185.6226082  11165.47463281]
total_rewards_mean           11082.60811342097
total_rewards_std            144.06789427220224
total_rewards_max            11336.895014139001
total_rewards_min            10793.176914894155
Number of train steps total  960000
Number of env steps total    1202000
Number of rollouts total     0
Train Time (s)               135.12282091239467
(Previous) Eval Time (s)     28.72567950002849
Sample Time (s)              23.2630171100609
Epoch Time (s)               187.11151752248406
Total Train Time (s)         43677.40124820871
Epoch                        239
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:55:41.515358 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #239 | Epoch Duration: 186.20652842521667
2020-01-13 16:55:41.515567 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #239 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6812809
Z variance train             0.003630268
KL Divergence                55.788353
KL Loss                      5.5788355
QF Loss                      489.26532
VF Loss                      141.54453
Policy Loss                  -4544.55
Q Predictions Mean           4550.6875
Q Predictions Std            460.2404
Q Predictions Max            5169.312
Q Predictions Min            3103.056
V Predictions Mean           4537.7075
V Predictions Std            457.60205
V Predictions Max            5144.114
V Predictions Min            3087.7117
Log Pis Mean                 5.782467
Log Pis Std                  3.7426927
Log Pis Max                  19.420208
Log Pis Min                  -4.196599
Policy mu Mean               -0.14456868
Policy mu Std                1.4257487
Policy mu Max                3.4315667
Policy mu Min                -3.1477327
Policy log std Mean          -0.90155077
Policy log std Std           0.4983968
Policy log std Max           -0.18425322
Policy log std Min           -3.5349112
Z mean eval                  3.682038
Z variance eval              0.013829132
total_rewards                [10930.75335307 11177.09884817 11161.08488376 11202.0825464
 10919.70562383 10932.31313522 11012.39976501 10954.42909432
 11057.93802923 11123.2568292 ]
total_rewards_mean           11047.106210822722
total_rewards_std            106.09574251033042
total_rewards_max            11202.08254640118
total_rewards_min            10919.705623833495
Number of train steps total  964000
Number of env steps total    1207000
Number of rollouts total     0
Train Time (s)               130.0801305361092
(Previous) Eval Time (s)     27.82032743189484
Sample Time (s)              22.32517433958128
Epoch Time (s)               180.22563230758533
Total Train Time (s)         43857.6693667192
Epoch                        240
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:58:41.786525 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #240 | Epoch Duration: 180.27080965042114
2020-01-13 16:58:41.786732 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #240 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6813939
Z variance train             0.013898322
KL Divergence                52.30549
KL Loss                      5.230549
QF Loss                      600.62665
VF Loss                      168.40553
Policy Loss                  -4462.1406
Q Predictions Mean           4471.162
Q Predictions Std            629.5607
Q Predictions Max            5284.5957
Q Predictions Min            95.93382
V Predictions Mean           4465.8457
V Predictions Std            633.2308
V Predictions Max            5271.6816
V Predictions Min            49.608883
Log Pis Mean                 5.4845304
Log Pis Std                  3.723699
Log Pis Max                  15.092257
Log Pis Min                  -3.373158
Policy mu Mean               -0.12581237
Policy mu Std                1.3872638
Policy mu Max                2.8967512
Policy mu Min                -2.8854609
Policy log std Mean          -0.86838406
Policy log std Std           0.46850652
Policy log std Max           0.16754198
Policy log std Min           -3.4421237
Z mean eval                  3.6963875
Z variance eval              0.018737385
total_rewards                [11122.8614164  11130.1009269   6625.81306998 11131.5855079
 11418.45854974 11033.72414877 11262.27482358 10946.01940256
 11061.39949017 10775.79353385]
total_rewards_mean           10650.803086983735
total_rewards_std            1351.49723210254
total_rewards_max            11418.458549735626
total_rewards_min            6625.813069975053
Number of train steps total  968000
Number of env steps total    1212000
Number of rollouts total     0
Train Time (s)               130.40464049298316
(Previous) Eval Time (s)     27.865169547032565
Sample Time (s)              22.458601453341544
Epoch Time (s)               180.72841149335727
Total Train Time (s)         44038.02465513814
Epoch                        241
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:01:42.144820 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #241 | Epoch Duration: 180.35792684555054
2020-01-13 17:01:42.145010 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #241 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6975067
Z variance train             0.018745193
KL Divergence                52.27033
KL Loss                      5.227033
QF Loss                      644.63586
VF Loss                      105.19613
Policy Loss                  -4474.8296
Q Predictions Mean           4480.6055
Q Predictions Std            508.34656
Q Predictions Max            5172.907
Q Predictions Min            3116.7188
V Predictions Mean           4472.0654
V Predictions Std            505.97937
V Predictions Max            5169.391
V Predictions Min            3120.3645
Log Pis Mean                 5.489582
Log Pis Std                  3.9518886
Log Pis Max                  24.626263
Log Pis Min                  -4.683792
Policy mu Mean               -0.04398657
Policy mu Std                1.4143298
Policy mu Max                3.5039926
Policy mu Min                -3.3683314
Policy log std Mean          -0.9088431
Policy log std Std           0.50542176
Policy log std Max           0.22739768
Policy log std Min           -3.401012
Z mean eval                  3.6972027
Z variance eval              0.04700853
total_rewards                [10789.35831465 10671.30162025 10808.53712835 10696.31727325
 10865.68209574 10920.36329927 10806.24131784 10874.65168577
 10944.10638185 10969.28099402]
total_rewards_mean           10834.584011098961
total_rewards_std            94.53833325482513
total_rewards_max            10969.280994024466
total_rewards_min            10671.301620247623
Number of train steps total  972000
Number of env steps total    1217000
Number of rollouts total     0
Train Time (s)               137.40033036656678
(Previous) Eval Time (s)     27.49435760686174
Sample Time (s)              22.842629064340144
Epoch Time (s)               187.73731703776866
Total Train Time (s)         44228.12635194603
Epoch                        242
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:04:52.249532 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #242 | Epoch Duration: 190.10438537597656
2020-01-13 17:04:52.249709 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #242 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6989605
Z variance train             0.04700429
KL Divergence                50.314587
KL Loss                      5.031459
QF Loss                      522.73486
VF Loss                      311.01364
Policy Loss                  -4446.8643
Q Predictions Mean           4449.206
Q Predictions Std            594.2701
Q Predictions Max            5199.322
Q Predictions Min            62.215984
V Predictions Mean           4435.9844
V Predictions Std            593.3892
V Predictions Max            5197.6514
V Predictions Min            28.472292
Log Pis Mean                 5.8284945
Log Pis Std                  3.656303
Log Pis Max                  14.7391205
Log Pis Min                  -5.524705
Policy mu Mean               -0.10593757
Policy mu Std                1.4079592
Policy mu Max                2.9678462
Policy mu Min                -3.0141163
Policy log std Mean          -0.9177866
Policy log std Std           0.5026244
Policy log std Max           -0.043417215
Policy log std Min           -3.4333205
Z mean eval                  3.7427986
Z variance eval              0.028445533
total_rewards                [11164.48528724 11182.80358131 11171.8951318  11362.30730172
 11241.33992171 11193.09112531 11136.10418786 11374.29901751
 11375.81756789 11180.42360545]
total_rewards_mean           11238.256672781064
total_rewards_std            90.31579137558387
total_rewards_max            11375.817567887176
total_rewards_min            11136.104187859628
Number of train steps total  976000
Number of env steps total    1222000
Number of rollouts total     0
Train Time (s)               136.44756103819236
(Previous) Eval Time (s)     29.861053208820522
Sample Time (s)              22.814872164744884
Epoch Time (s)               189.12348641175777
Total Train Time (s)         44416.79694019817
Epoch                        243
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:08:00.923364 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #243 | Epoch Duration: 188.673508644104
2020-01-13 17:08:00.923619 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #243 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.741824
Z variance train             0.028480673
KL Divergence                50.721893
KL Loss                      5.0721893
QF Loss                      560.2802
VF Loss                      317.8899
Policy Loss                  -4423.3613
Q Predictions Mean           4428.121
Q Predictions Std            702.1962
Q Predictions Max            5194.5615
Q Predictions Min            -3.8695712
V Predictions Mean           4437.3105
V Predictions Std            700.8651
V Predictions Max            5199.8184
V Predictions Min            1.2534521
Log Pis Mean                 5.3709908
Log Pis Std                  3.6551678
Log Pis Max                  15.16636
Log Pis Min                  -6.116602
Policy mu Mean               -0.12461409
Policy mu Std                1.3564769
Policy mu Max                3.0057178
Policy mu Min                -2.7884204
Policy log std Mean          -0.8961777
Policy log std Std           0.48797542
Policy log std Max           0.21583521
Policy log std Min           -3.2891364
Z mean eval                  3.7097836
Z variance eval              0.027521098
total_rewards                [10781.98743612 11030.60932846 10677.97288316  4831.60884328
 10311.78472783 10819.3561824  10770.85876152 11025.54477664
 11096.21625804 10500.83179385]
total_rewards_mean           10184.677099129829
total_rewards_std            1799.209831212166
total_rewards_max            11096.216258039925
total_rewards_min            4831.6088432763
Number of train steps total  980000
Number of env steps total    1227000
Number of rollouts total     0
Train Time (s)               136.3008966818452
(Previous) Eval Time (s)     29.410689061973244
Sample Time (s)              20.089562016073614
Epoch Time (s)               185.80114775989205
Total Train Time (s)         44600.7072034413
Epoch                        244
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:11:04.836581 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #244 | Epoch Duration: 183.91279411315918
2020-01-13 17:11:04.836782 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #244 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7065208
Z variance train             0.027645584
KL Divergence                50.100426
KL Loss                      5.0100427
QF Loss                      4251.5566
VF Loss                      275.08716
Policy Loss                  -4481.1797
Q Predictions Mean           4490.2686
Q Predictions Std            508.20056
Q Predictions Max            5141.9077
Q Predictions Min            3075.0374
V Predictions Mean           4489.0576
V Predictions Std            509.7306
V Predictions Max            5144.723
V Predictions Min            3071.6758
Log Pis Mean                 5.5927024
Log Pis Std                  3.759057
Log Pis Max                  14.252739
Log Pis Min                  -8.894627
Policy mu Mean               -0.07843733
Policy mu Std                1.3955553
Policy mu Max                3.2766175
Policy mu Min                -3.1472368
Policy log std Mean          -0.89755195
Policy log std Std           0.4779091
Policy log std Max           -0.18870276
Policy log std Min           -3.2813125
Z mean eval                  3.72696
Z variance eval              0.027305767
total_rewards                [10063.92265995 10127.71443769 10317.8972691  10280.15045185
 10281.14406759 10195.49108706 10300.06070543 10069.03610261
 10217.18823078 10491.07145331]
total_rewards_mean           10234.367646538101
total_rewards_std            122.89880312672284
total_rewards_max            10491.071453306302
total_rewards_min            10063.922659954105
Number of train steps total  984000
Number of env steps total    1232000
Number of rollouts total     0
Train Time (s)               137.9824005062692
(Previous) Eval Time (s)     27.52199377398938
Sample Time (s)              22.83354407083243
Epoch Time (s)               188.337938351091
Total Train Time (s)         44789.43545504613
Epoch                        245
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:14:13.566875 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #245 | Epoch Duration: 188.72996354103088
2020-01-13 17:14:13.567025 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #245 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7277493
Z variance train             0.027305147
KL Divergence                51.749985
KL Loss                      5.1749988
QF Loss                      600.42163
VF Loss                      213.68752
Policy Loss                  -4487.619
Q Predictions Mean           4493.0303
Q Predictions Std            475.34497
Q Predictions Max            5250.5356
Q Predictions Min            2582.5017
V Predictions Mean           4482.6113
V Predictions Std            467.29126
V Predictions Max            5241.6865
V Predictions Min            3146.3308
Log Pis Mean                 5.0878954
Log Pis Std                  3.903907
Log Pis Max                  14.5417385
Log Pis Min                  -6.427661
Policy mu Mean               -0.1526333
Policy mu Std                1.3650714
Policy mu Max                3.3689282
Policy mu Min                -2.563158
Policy log std Mean          -0.8945611
Policy log std Std           0.49314636
Policy log std Max           0.1508553
Policy log std Min           -3.557431
Z mean eval                  3.726132
Z variance eval              0.023437707
total_rewards                [11123.90808552 11100.97736754 11336.8726     11145.66043267
 10897.81603354 11061.69448141 11357.41725434 11260.47443683
 11389.89344618 11231.48196696]
total_rewards_mean           11190.619610498152
total_rewards_std            145.71684597288268
total_rewards_max            11389.893446184029
total_rewards_min            10897.816033542991
Number of train steps total  988000
Number of env steps total    1237000
Number of rollouts total     0
Train Time (s)               133.67378581734374
(Previous) Eval Time (s)     27.913606220390648
Sample Time (s)              21.859307244885713
Epoch Time (s)               183.4466992826201
Total Train Time (s)         44972.96170698013
Epoch                        246
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:17:17.096658 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #246 | Epoch Duration: 183.5295124053955
2020-01-13 17:17:17.096847 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #246 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7240589
Z variance train             0.0233345
KL Divergence                51.44812
KL Loss                      5.144812
QF Loss                      884.51843
VF Loss                      115.01417
Policy Loss                  -4506.093
Q Predictions Mean           4516.4287
Q Predictions Std            492.20938
Q Predictions Max            5196.742
Q Predictions Min            3081.943
V Predictions Mean           4503.776
V Predictions Std            490.2635
V Predictions Max            5174.3975
V Predictions Min            3077.569
Log Pis Mean                 5.622478
Log Pis Std                  3.6905017
Log Pis Max                  16.314034
Log Pis Min                  -2.7362356
Policy mu Mean               -0.11787038
Policy mu Std                1.3891966
Policy mu Max                2.9137409
Policy mu Min                -2.6751077
Policy log std Mean          -0.9207146
Policy log std Std           0.5043844
Policy log std Max           -0.13589275
Policy log std Min           -3.5030203
Z mean eval                  3.7327266
Z variance eval              0.013955176
total_rewards                [10944.42487349 11003.26435416 11182.30490732 11134.54589723
 11150.69781822 11175.04762463 11163.80228047 11113.71066247
 11078.47112931 10934.02482126]
total_rewards_mean           11088.029436857218
total_rewards_std            89.75987876076296
total_rewards_max            11182.304907322325
total_rewards_min            10934.024821264942
Number of train steps total  992000
Number of env steps total    1242000
Number of rollouts total     0
Train Time (s)               129.58400994492695
(Previous) Eval Time (s)     27.996052764821798
Sample Time (s)              21.80131979426369
Epoch Time (s)               179.38138250401244
Total Train Time (s)         45152.521211258136
Epoch                        247
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:20:16.659087 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #247 | Epoch Duration: 179.56210136413574
2020-01-13 17:20:16.659287 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #247 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7319481
Z variance train             0.013997847
KL Divergence                52.844944
KL Loss                      5.2844944
QF Loss                      776.5429
VF Loss                      280.45132
Policy Loss                  -4418.534
Q Predictions Mean           4423.0156
Q Predictions Std            637.8068
Q Predictions Max            5090.3223
Q Predictions Min            -1.0579464
V Predictions Mean           4425.3794
V Predictions Std            636.4364
V Predictions Max            5095.026
V Predictions Min            0.9035111
Log Pis Mean                 5.009942
Log Pis Std                  3.918017
Log Pis Max                  20.602655
Log Pis Min                  -6.539227
Policy mu Mean               -0.15235955
Policy mu Std                1.3766947
Policy mu Max                3.9050083
Policy mu Min                -4.7543726
Policy log std Mean          -0.89089805
Policy log std Std           0.47875053
Policy log std Max           0.02176559
Policy log std Min           -3.5972953
Z mean eval                  3.798139
Z variance eval              0.011286588
total_rewards                [11074.17778471 11256.39953378  3220.83032313 11314.65572063
 11254.9590423  11358.08878626 11251.48911301 11472.5780006
 11361.11834449 11260.53948471]
total_rewards_mean           10482.483613364042
total_rewards_std            2422.511006348952
total_rewards_max            11472.578000596866
total_rewards_min            3220.8303231348987
Number of train steps total  996000
Number of env steps total    1247000
Number of rollouts total     0
Train Time (s)               131.06631171377376
(Previous) Eval Time (s)     28.176475738640875
Sample Time (s)              20.2801771806553
Epoch Time (s)               179.52296463306993
Total Train Time (s)         45332.548577760346
Epoch                        248
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:23:16.689762 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #248 | Epoch Duration: 180.0303337574005
2020-01-13 17:23:16.689956 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #248 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7987657
Z variance train             0.011296867
KL Divergence                54.440025
KL Loss                      5.4440026
QF Loss                      405.7199
VF Loss                      216.7057
Policy Loss                  -4497.392
Q Predictions Mean           4498.0254
Q Predictions Std            533.2048
Q Predictions Max            5183.6836
Q Predictions Min            2374.117
V Predictions Mean           4497.5205
V Predictions Std            531.1162
V Predictions Max            5192.784
V Predictions Min            2567.6567
Log Pis Mean                 5.5114107
Log Pis Std                  4.096925
Log Pis Max                  13.670624
Log Pis Min                  -7.4992495
Policy mu Mean               -0.16575025
Policy mu Std                1.3817483
Policy mu Max                3.065436
Policy mu Min                -3.357132
Policy log std Mean          -0.89361614
Policy log std Std           0.48487446
Policy log std Max           -0.089292645
Policy log std Min           -3.515708
Z mean eval                  3.8043606
Z variance eval              0.021724176
total_rewards                [11264.30022907 11387.38142241 11380.87533671 11337.35070182
 11268.31695829 11387.385435   11360.22087423 11510.21917226
 11221.53316733 11151.0626642 ]
total_rewards_mean           11326.864596130585
total_rewards_std            97.1734910716291
total_rewards_max            11510.21917225523
total_rewards_min            11151.06266419618
Number of train steps total  1000000
Number of env steps total    1252000
Number of rollouts total     0
Train Time (s)               137.16349330823869
(Previous) Eval Time (s)     28.683499094098806
Sample Time (s)              22.183109980542213
Epoch Time (s)               188.0301023828797
Total Train Time (s)         45519.456106592435
Epoch                        249
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:26:23.601727 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #249 | Epoch Duration: 186.91160416603088
2020-01-13 17:26:23.602049 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #249 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.806617
Z variance train             0.021751225
KL Divergence                53.725067
KL Loss                      5.3725066
QF Loss                      875.23206
VF Loss                      162.76114
Policy Loss                  -4561.167
Q Predictions Mean           4562.1104
Q Predictions Std            553.9199
Q Predictions Max            5175.562
Q Predictions Min            74.46371
V Predictions Mean           4558.0146
V Predictions Std            555.7194
V Predictions Max            5173.525
V Predictions Min            0.9074418
Log Pis Mean                 5.2076902
Log Pis Std                  4.0100656
Log Pis Max                  15.876131
Log Pis Min                  -6.622806
Policy mu Mean               -0.13434923
Policy mu Std                1.3647975
Policy mu Max                2.8817368
Policy mu Min                -3.3862605
Policy log std Mean          -0.88554734
Policy log std Std           0.47643635
Policy log std Max           -0.14175743
Policy log std Min           -3.4418995
Z mean eval                  3.7479033
Z variance eval              0.036370944
total_rewards                [10722.04312862 11309.00806795 11210.23082012 10850.21568311
 11104.48788138 10935.65108844 11049.61447163 10970.92345956
  9370.53655209 11289.15918565]
total_rewards_mean           10881.187033855884
total_rewards_std            534.3540812946236
total_rewards_max            11309.008067952802
total_rewards_min            9370.536552092653
Number of train steps total  1004000
Number of env steps total    1257000
Number of rollouts total     0
Train Time (s)               137.42109025502577
(Previous) Eval Time (s)     27.564597509801388
Sample Time (s)              21.044359469320625
Epoch Time (s)               186.0300472341478
Total Train Time (s)         45705.93021675432
Epoch                        250
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:29:30.079011 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #250 | Epoch Duration: 186.47677731513977
2020-01-13 17:29:30.079297 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #250 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.747607
Z variance train             0.03631591
KL Divergence                50.499077
KL Loss                      5.0499077
QF Loss                      310.64642
VF Loss                      240.5491
Policy Loss                  -4500.1196
Q Predictions Mean           4501.627
Q Predictions Std            546.452
Q Predictions Max            5215.5376
Q Predictions Min            3095.2805
V Predictions Mean           4497.5176
V Predictions Std            545.1936
V Predictions Max            5220.4595
V Predictions Min            3104.5447
Log Pis Mean                 4.750355
Log Pis Std                  3.8261607
Log Pis Max                  15.919039
Log Pis Min                  -4.7187614
Policy mu Mean               -0.10341436
Policy mu Std                1.3283843
Policy mu Max                3.6620817
Policy mu Min                -2.7062526
Policy log std Mean          -0.8918431
Policy log std Std           0.46504775
Policy log std Max           -0.15506124
Policy log std Min           -3.4230986
Z mean eval                  3.7918942
Z variance eval              0.013516324
total_rewards                [ 8376.84855543 11518.29489392 11475.52518697 11501.38452697
 11380.14016195 11488.73763911 11475.54784373 11476.20851847
 11536.42283437 11484.92549507]
total_rewards_mean           11171.403565600733
total_rewards_std            932.3339231688551
total_rewards_max            11536.422834368273
total_rewards_min            8376.848555428114
Number of train steps total  1008000
Number of env steps total    1262000
Number of rollouts total     0
Train Time (s)               136.35253236396238
(Previous) Eval Time (s)     28.011001700069755
Sample Time (s)              21.775091845542192
Epoch Time (s)               186.13862590957433
Total Train Time (s)         45891.49403331801
Epoch                        251
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:32:35.646165 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #251 | Epoch Duration: 185.56666326522827
2020-01-13 17:32:35.646560 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #251 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7935805
Z variance train             0.013504112
KL Divergence                53.596424
KL Loss                      5.3596425
QF Loss                      932.3305
VF Loss                      297.8139
Policy Loss                  -4494.8936
Q Predictions Mean           4495.58
Q Predictions Std            516.762
Q Predictions Max            5170.9595
Q Predictions Min            3139.8054
V Predictions Mean           4481.084
V Predictions Std            515.9973
V Predictions Max            5139.667
V Predictions Min            3127.5366
Log Pis Mean                 5.9471135
Log Pis Std                  4.1245112
Log Pis Max                  16.458693
Log Pis Min                  -4.2648325
Policy mu Mean               -0.11582407
Policy mu Std                1.414436
Policy mu Max                4.1432056
Policy mu Min                -2.9965186
Policy log std Mean          -0.89964396
Policy log std Std           0.5014829
Policy log std Max           0.0965054
Policy log std Min           -3.6314878
Z mean eval                  3.8382866
Z variance eval              0.018236542
total_rewards                [10976.02593066 11199.00332318 11376.98971867 10902.09148082
 11076.09687732 11085.5595487  11258.24665674  1697.44566198
 11296.56991592 11161.45236004]
total_rewards_mean           10202.948147401541
total_rewards_std            2838.490939666661
total_rewards_max            11376.989718665009
total_rewards_min            1697.4456619785626
Number of train steps total  1012000
Number of env steps total    1267000
Number of rollouts total     0
Train Time (s)               136.98652176884934
(Previous) Eval Time (s)     27.43866278976202
Sample Time (s)              22.53195814555511
Epoch Time (s)               186.95714270416647
Total Train Time (s)         46079.844466201495
Epoch                        252
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:35:44.000634 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #252 | Epoch Duration: 188.35382223129272
2020-01-13 17:35:44.000867 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #252 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.8361664
Z variance train             0.018283868
KL Divergence                54.58082
KL Loss                      5.4580817
QF Loss                      384.13382
VF Loss                      126.07477
Policy Loss                  -4567.1426
Q Predictions Mean           4574.044
Q Predictions Std            577.96704
Q Predictions Max            5293.9355
Q Predictions Min            378.2419
V Predictions Mean           4569.1074
V Predictions Std            582.1958
V Predictions Max            5280.465
V Predictions Min            239.80353
Log Pis Mean                 5.208723
Log Pis Std                  3.6295958
Log Pis Max                  15.355408
Log Pis Min                  -3.2693691
Policy mu Mean               -0.1336665
Policy mu Std                1.3688571
Policy mu Max                2.8452785
Policy mu Min                -2.9714918
Policy log std Mean          -0.8987522
Policy log std Std           0.5070133
Policy log std Max           -0.121917605
Policy log std Min           -3.5685313
Z mean eval                  3.783134
Z variance eval              0.02430048
total_rewards                [11302.96271685 11471.56678418 11471.80729783 11334.72887083
 10976.32078906 11376.85210498 11265.46504598 11374.80781811
 11480.54338097 11475.41706303]
total_rewards_mean           11353.04718718331
total_rewards_std            145.89658983486873
total_rewards_max            11480.54338097441
total_rewards_min            10976.320789058775
Number of train steps total  1016000
Number of env steps total    1272000
Number of rollouts total     0
Train Time (s)               131.91525923693553
(Previous) Eval Time (s)     28.834907587151974
Sample Time (s)              23.31869750469923
Epoch Time (s)               184.06886432878673
Total Train Time (s)         46262.05864602374
Epoch                        253
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:38:46.216309 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #253 | Epoch Duration: 182.21528148651123
2020-01-13 17:38:46.216493 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #253 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7818885
Z variance train             0.024308857
KL Divergence                52.7377
KL Loss                      5.2737703
QF Loss                      724.46204
VF Loss                      231.77005
Policy Loss                  -4585.633
Q Predictions Mean           4591.614
Q Predictions Std            498.82837
Q Predictions Max            5226.2583
Q Predictions Min            3155.4194
V Predictions Mean           4592.0625
V Predictions Std            496.73492
V Predictions Max            5245.431
V Predictions Min            3166.7175
Log Pis Mean                 5.4338136
Log Pis Std                  3.662792
Log Pis Max                  15.008303
Log Pis Min                  -4.593777
Policy mu Mean               -0.072697684
Policy mu Std                1.4072157
Policy mu Max                2.9845448
Policy mu Min                -2.7152631
Policy log std Mean          -0.9073281
Policy log std Std           0.53210723
Policy log std Max           -0.22342518
Policy log std Min           -3.3547254
Z mean eval                  3.7785194
Z variance eval              0.029238243
total_rewards                [11182.61408378 11321.88178161 11113.67190558 11299.68284095
 11281.30307147 11325.44530928 11333.59041875 11306.46032364
 11199.82567203 11293.43456604]
total_rewards_mean           11265.790997312299
total_rewards_std            70.36977918526172
total_rewards_max            11333.59041874764
total_rewards_min            11113.671905584251
Number of train steps total  1020000
Number of env steps total    1277000
Number of rollouts total     0
Train Time (s)               130.69915370410308
(Previous) Eval Time (s)     26.9808818991296
Sample Time (s)              21.794593341182917
Epoch Time (s)               179.4746289444156
Total Train Time (s)         46442.02791740885
Epoch                        254
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:41:46.188790 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #254 | Epoch Duration: 179.97215867042542
2020-01-13 17:41:46.188985 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #254 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7777038
Z variance train             0.029146383
KL Divergence                52.997128
KL Loss                      5.2997127
QF Loss                      720.7311
VF Loss                      164.8259
Policy Loss                  -4500.955
Q Predictions Mean           4511.5176
Q Predictions Std            507.50467
Q Predictions Max            5236.889
Q Predictions Min            3154.4563
V Predictions Mean           4506.441
V Predictions Std            507.69437
V Predictions Max            5214.8037
V Predictions Min            3151.637
Log Pis Mean                 5.855061
Log Pis Std                  3.8284078
Log Pis Max                  16.21235
Log Pis Min                  -2.6641812
Policy mu Mean               -0.18368888
Policy mu Std                1.3953618
Policy mu Max                4.232298
Policy mu Min                -3.4653933
Policy log std Mean          -0.89213437
Policy log std Std           0.51449525
Policy log std Max           0.32759833
Policy log std Min           -3.6267238
Z mean eval                  3.7919567
Z variance eval              0.01852255
total_rewards                [11197.66050376 11462.29328441 11363.35388653 11395.96861093
 11520.45780484 11545.01778007 11619.3885635  11354.33433716
 11475.92448771 11214.04973094]
total_rewards_mean           11414.844898984535
total_rewards_std            130.41325420808283
total_rewards_max            11619.388563504395
total_rewards_min            11197.660503757892
Number of train steps total  1024000
Number of env steps total    1282000
Number of rollouts total     0
Train Time (s)               132.37245878204703
(Previous) Eval Time (s)     27.47804042417556
Sample Time (s)              21.810322805307806
Epoch Time (s)               181.6608220115304
Total Train Time (s)         46624.12765465304
Epoch                        255
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:44:48.291933 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #255 | Epoch Duration: 182.10277724266052
2020-01-13 17:44:48.292257 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #255 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.792251
Z variance train             0.018507639
KL Divergence                54.244392
KL Loss                      5.4244394
QF Loss                      631.46204
VF Loss                      298.164
Policy Loss                  -4492.259
Q Predictions Mean           4492.1987
Q Predictions Std            504.03528
Q Predictions Max            5110.2485
Q Predictions Min            3024.0037
V Predictions Mean           4480.3926
V Predictions Std            500.8795
V Predictions Max            5087.066
V Predictions Min            3004.1228
Log Pis Mean                 5.4621477
Log Pis Std                  3.9233356
Log Pis Max                  15.596543
Log Pis Min                  -5.339216
Policy mu Mean               -0.15760016
Policy mu Std                1.3802845
Policy mu Max                2.7633896
Policy mu Min                -2.81496
Policy log std Mean          -0.88459605
Policy log std Std           0.47778994
Policy log std Max           -0.119386345
Policy log std Min           -3.5500846
Z mean eval                  3.816383
Z variance eval              0.020415131
total_rewards                [11529.66727417 11731.84137543 11419.7951544  11711.88119158
 11551.11992366 11490.07607723 11541.05677423 11231.97277044
 11744.72335072 11558.61923787]
total_rewards_mean           11551.075312973926
total_rewards_std            148.1323293341112
total_rewards_max            11744.7233507202
total_rewards_min            11231.972770440243
Number of train steps total  1028000
Number of env steps total    1287000
Number of rollouts total     0
Train Time (s)               139.46870070090517
(Previous) Eval Time (s)     27.919673578813672
Sample Time (s)              22.473884482402354
Epoch Time (s)               189.8622587621212
Total Train Time (s)         46812.95291462075
Epoch                        256
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:47:57.120162 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #256 | Epoch Duration: 188.8276596069336
2020-01-13 17:47:57.120401 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #256 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.819725
Z variance train             0.020352134
KL Divergence                56.026466
KL Loss                      5.602647
QF Loss                      674.67834
VF Loss                      145.16214
Policy Loss                  -4620.787
Q Predictions Mean           4627.087
Q Predictions Std            494.56168
Q Predictions Max            5254.021
Q Predictions Min            3120.6345
V Predictions Mean           4612.7075
V Predictions Std            491.46057
V Predictions Max            5234.681
V Predictions Min            3123.9805
Log Pis Mean                 5.61868
Log Pis Std                  3.7728617
Log Pis Max                  14.959654
Log Pis Min                  -3.7215667
Policy mu Mean               -0.12164366
Policy mu Std                1.3964783
Policy mu Max                2.8873827
Policy mu Min                -2.8210402
Policy log std Mean          -0.90302944
Policy log std Std           0.4878832
Policy log std Max           -0.1928842
Policy log std Min           -3.3282692
Z mean eval                  3.817843
Z variance eval              0.029705543
total_rewards                [11319.007454   11529.10635728 11369.77402943 11535.8183368
 11276.80195033 11179.89503146 11509.21582988 10900.80201575
 11531.10811248 11382.73245336]
total_rewards_mean           11353.426157075879
total_rewards_std            190.56112730019456
total_rewards_max            11535.818336795914
total_rewards_min            10900.802015748332
Number of train steps total  1032000
Number of env steps total    1292000
Number of rollouts total     0
Train Time (s)               138.11138959787786
(Previous) Eval Time (s)     26.8846793230623
Sample Time (s)              22.86740614892915
Epoch Time (s)               187.8634750698693
Total Train Time (s)         47001.49613563297
Epoch                        257
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:51:05.666440 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #257 | Epoch Duration: 188.54588866233826
2020-01-13 17:51:05.666628 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #257 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.8199925
Z variance train             0.029847682
KL Divergence                55.95869
KL Loss                      5.595869
QF Loss                      522.53864
VF Loss                      198.83551
Policy Loss                  -4564.579
Q Predictions Mean           4567.1416
Q Predictions Std            508.70908
Q Predictions Max            5199.3657
Q Predictions Min            3136.2424
V Predictions Mean           4553.8896
V Predictions Std            508.31116
V Predictions Max            5192.2764
V Predictions Min            3131.1047
Log Pis Mean                 5.3139305
Log Pis Std                  3.7661014
Log Pis Max                  14.545447
Log Pis Min                  -6.492144
Policy mu Mean               -0.08610042
Policy mu Std                1.3846536
Policy mu Max                3.0401058
Policy mu Min                -3.381044
Policy log std Mean          -0.89708596
Policy log std Std           0.49208862
Policy log std Max           -0.06734586
Policy log std Min           -3.6462069
Z mean eval                  3.7929993
Z variance eval              0.012144548
total_rewards                [11066.62617237 11536.87950546 11662.53448785 11506.06386129
 11346.54028091 11439.45502916 11527.19867895 11644.87981743
 11548.72074033 11436.71172359]
total_rewards_mean           11471.561029734943
total_rewards_std            162.1308352025455
total_rewards_max            11662.534487847099
total_rewards_min            11066.62617237196
Number of train steps total  1036000
Number of env steps total    1297000
Number of rollouts total     0
Train Time (s)               137.64642941066995
(Previous) Eval Time (s)     27.566639793571085
Sample Time (s)              22.18572237715125
Epoch Time (s)               187.3987915813923
Total Train Time (s)         47190.3864397062
Epoch                        258
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:54:14.560360 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #258 | Epoch Duration: 188.89359283447266
2020-01-13 17:54:14.560566 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #258 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7938132
Z variance train             0.0121368375
KL Divergence                58.372765
KL Loss                      5.8372765
QF Loss                      1092.6108
VF Loss                      311.19296
Policy Loss                  -4590.41
Q Predictions Mean           4595.575
Q Predictions Std            492.30682
Q Predictions Max            5303.801
Q Predictions Min            3130.5632
V Predictions Mean           4596.7124
V Predictions Std            492.96228
V Predictions Max            5293.768
V Predictions Min            3129.1418
Log Pis Mean                 5.633066
Log Pis Std                  3.7479706
Log Pis Max                  16.456514
Log Pis Min                  -3.0665336
Policy mu Mean               -0.13867436
Policy mu Std                1.3956635
Policy mu Max                2.8460548
Policy mu Min                -3.0152075
Policy log std Mean          -0.90364695
Policy log std Std           0.483819
Policy log std Max           0.03970182
Policy log std Min           -3.5710819
Z mean eval                  3.8289475
Z variance eval              0.030649474
total_rewards                [11062.83901904 11198.7309915  11260.72830862 11291.98433231
 11377.57250818 11201.21943131 11209.08285804 11376.58079028
 11274.54438773 11265.51049011]
total_rewards_mean           11251.879311711902
total_rewards_std            87.57534278353577
total_rewards_max            11377.572508179344
total_rewards_min            11062.8390190408
Number of train steps total  1040000
Number of env steps total    1302000
Number of rollouts total     0
Train Time (s)               136.7503994400613
(Previous) Eval Time (s)     29.061105412896723
Sample Time (s)              23.49252747418359
Epoch Time (s)               189.3040323271416
Total Train Time (s)         47379.490590545814
Epoch                        259
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:57:23.666074 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #259 | Epoch Duration: 189.1053764820099
2020-01-13 17:57:23.666199 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #259 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.8310204
Z variance train             0.03064607
KL Divergence                56.557068
KL Loss                      5.655707
QF Loss                      407.65228
VF Loss                      168.64894
Policy Loss                  -4699.588
Q Predictions Mean           4701.3413
Q Predictions Std            450.3536
Q Predictions Max            5261.193
Q Predictions Min            3177.3257
V Predictions Mean           4693.4355
V Predictions Std            450.06586
V Predictions Max            5250.481
V Predictions Min            3174.0347
Log Pis Mean                 5.5019655
Log Pis Std                  3.6073458
Log Pis Max                  14.680612
Log Pis Min                  -4.063956
Policy mu Mean               -0.115779944
Policy mu Std                1.4012226
Policy mu Max                5.780761
Policy mu Min                -3.6615407
Policy log std Mean          -0.9025116
Policy log std Std           0.51383716
Policy log std Max           0.6994952
Policy log std Min           -3.593151
Z mean eval                  3.8498394
Z variance eval              0.018540222
total_rewards                [11104.353785   11333.57892812 11353.19219295 11187.23377507
 11364.02986582 11000.11102763 11162.70605772 10939.33224616
 11342.66110028 11016.65243194]
total_rewards_mean           11180.385141069006
total_rewards_std            153.92964642439767
total_rewards_max            11364.02986582239
total_rewards_min            10939.332246160724
Number of train steps total  1044000
Number of env steps total    1307000
Number of rollouts total     0
Train Time (s)               130.45742977922782
(Previous) Eval Time (s)     28.86207461403683
Sample Time (s)              21.639606985263526
Epoch Time (s)               180.95911137852818
Total Train Time (s)         47558.57882597018
Epoch                        260
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:00:22.758233 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #260 | Epoch Duration: 179.0919280052185
2020-01-13 18:00:22.758423 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #260 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.8504872
Z variance train             0.018553257
KL Divergence                57.140312
KL Loss                      5.714031
QF Loss                      430.7466
VF Loss                      120.520065
Policy Loss                  -4737.824
Q Predictions Mean           4741.12
Q Predictions Std            472.09378
Q Predictions Max            5293.9956
Q Predictions Min            3239.2017
V Predictions Mean           4739.6377
V Predictions Std            472.2733
V Predictions Max            5293.538
V Predictions Min            3232.946
Log Pis Mean                 5.3731785
Log Pis Std                  4.015737
Log Pis Max                  14.473986
Log Pis Min                  -6.4892683
Policy mu Mean               -0.09340569
Policy mu Std                1.3865244
Policy mu Max                3.2170267
Policy mu Min                -2.7156634
Policy log std Mean          -0.8924454
Policy log std Std           0.47996053
Policy log std Max           0.30125082
Policy log std Min           -3.2600794
Z mean eval                  3.8387096
Z variance eval              0.021368245
total_rewards                [10647.5383352  10823.15392199 10812.79294346 10870.82320748
 10763.78360168 11077.04041204 10959.83404706 10922.30389605
 10906.72308818  2361.44731829]
total_rewards_mean           10014.54407714441
total_rewards_std            2553.4032103144064
total_rewards_max            11077.040412036009
total_rewards_min            2361.4473182944166
Number of train steps total  1048000
Number of env steps total    1312000
Number of rollouts total     0
Train Time (s)               129.51711840881035
(Previous) Eval Time (s)     26.9944606423378
Sample Time (s)              22.437756796367466
Epoch Time (s)               178.9493358475156
Total Train Time (s)         47737.81776497187
Epoch                        261
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:03:22.000380 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #261 | Epoch Duration: 179.24181628227234
2020-01-13 18:03:22.000571 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #261 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.8396106
Z variance train             0.021394681
KL Divergence                58.55201
KL Loss                      5.8552012
QF Loss                      1519.502
VF Loss                      142.2981
Policy Loss                  -4739.1675
Q Predictions Mean           4747.88
Q Predictions Std            456.60703
Q Predictions Max            5362.437
Q Predictions Min            3180.3188
V Predictions Mean           4738.334
V Predictions Std            452.60202
V Predictions Max            5334.201
V Predictions Min            3175.0793
Log Pis Mean                 6.0751967
Log Pis Std                  3.536527
Log Pis Max                  15.554502
Log Pis Min                  -2.3714285
Policy mu Mean               -0.14061819
Policy mu Std                1.4270929
Policy mu Max                3.5116777
Policy mu Min                -2.924439
Policy log std Mean          -0.937783
Policy log std Std           0.54450744
Policy log std Max           -0.21063524
Policy log std Min           -3.6333337
Z mean eval                  3.8388608
Z variance eval              0.019983482
total_rewards                [10697.35567294 11411.03405349 11754.62939926 11763.43838251
 11146.89177254 11807.75671051 11394.67215175 11469.19136934
 11732.01168472 11518.76126526]
total_rewards_mean           11469.574246233136
total_rewards_std            325.9993328592784
total_rewards_max            11807.756710510144
total_rewards_min            10697.355672944654
Number of train steps total  1052000
Number of env steps total    1317000
Number of rollouts total     0
Train Time (s)               133.08834937913343
(Previous) Eval Time (s)     27.2866144166328
Sample Time (s)              22.121828091330826
Epoch Time (s)               182.49679188709706
Total Train Time (s)         47921.30728433933
Epoch                        262
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:06:25.493162 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #262 | Epoch Duration: 183.4924454689026
2020-01-13 18:06:25.493384 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #262 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.8379688
Z variance train             0.019952241
KL Divergence                58.242455
KL Loss                      5.8242455
QF Loss                      967.8266
VF Loss                      274.09918
Policy Loss                  -4582.3745
Q Predictions Mean           4590.309
Q Predictions Std            504.456
Q Predictions Max            5247.2876
Q Predictions Min            3190.922
V Predictions Mean           4593.5635
V Predictions Std            504.29517
V Predictions Max            5270.8926
V Predictions Min            3197.4233
Log Pis Mean                 5.1421413
Log Pis Std                  3.9782457
Log Pis Max                  18.315699
Log Pis Min                  -4.865979
Policy mu Mean               -0.15490803
Policy mu Std                1.3773731
Policy mu Max                3.2247531
Policy mu Min                -3.4526994
Policy log std Mean          -0.8889382
Policy log std Std           0.47020906
Policy log std Max           -0.054540634
Policy log std Min           -3.5312643
Z mean eval                  3.8297787
Z variance eval              0.006490746
total_rewards                [11505.58653462 10972.28081195  7532.62982255 11307.69395362
 10954.52730325 11068.31386481 11560.09614982 11276.66350691
 11279.33744764 10858.61442012]
total_rewards_mean           10831.574381529408
total_rewards_std            1121.8310906556696
total_rewards_max            11560.096149817244
total_rewards_min            7532.62982254661
Number of train steps total  1056000
Number of env steps total    1322000
Number of rollouts total     0
Train Time (s)               138.89192064106464
(Previous) Eval Time (s)     28.281976855825633
Sample Time (s)              23.03183849574998
Epoch Time (s)               190.20573599264026
Total Train Time (s)         48111.89600526029
Epoch                        263
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:09:36.084860 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #263 | Epoch Duration: 190.59133410453796
2020-01-13 18:09:36.085036 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #263 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.829373
Z variance train             0.006495616
KL Divergence                58.995453
KL Loss                      5.899545
QF Loss                      822.56885
VF Loss                      172.35901
Policy Loss                  -4644.333
Q Predictions Mean           4648.6636
Q Predictions Std            487.68555
Q Predictions Max            5243.8447
Q Predictions Min            3279.023
V Predictions Mean           4646.502
V Predictions Std            487.01645
V Predictions Max            5233.5903
V Predictions Min            3288.5037
Log Pis Mean                 5.8871803
Log Pis Std                  3.7351816
Log Pis Max                  14.816717
Log Pis Min                  -4.534247
Policy mu Mean               -0.1606827
Policy mu Std                1.4200883
Policy mu Max                2.911776
Policy mu Min                -3.2931967
Policy log std Mean          -0.9106843
Policy log std Std           0.5253047
Policy log std Max           0.047471285
Policy log std Min           -3.4554074
Z mean eval                  3.8140855
Z variance eval              0.013726403
total_rewards                [11283.64554757 11404.05394731 11306.6219919  11402.66671078
 11305.26786151 11369.5275256  11452.42821718 11262.14560379
 11349.02764808 11382.16986792]
total_rewards_mean           11351.755492164211
total_rewards_std            57.94603352006386
total_rewards_max            11452.42821717566
total_rewards_min            11262.145603792867
Number of train steps total  1060000
Number of env steps total    1327000
Number of rollouts total     0
Train Time (s)               137.82017833786085
(Previous) Eval Time (s)     28.667136217933148
Sample Time (s)              22.86614560894668
Epoch Time (s)               189.35346016474068
Total Train Time (s)         48299.32054466242
Epoch                        264
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:12:43.512790 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #264 | Epoch Duration: 187.42758989334106
2020-01-13 18:12:43.513009 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #264 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.813823
Z variance train             0.013740283
KL Divergence                57.47062
KL Loss                      5.747062
QF Loss                      446.72208
VF Loss                      146.68561
Policy Loss                  -4561.6743
Q Predictions Mean           4567.531
Q Predictions Std            482.18015
Q Predictions Max            5188.34
Q Predictions Min            3232.6477
V Predictions Mean           4569.4404
V Predictions Std            481.21118
V Predictions Max            5193.4824
V Predictions Min            3236.9768
Log Pis Mean                 5.224814
Log Pis Std                  3.7313626
Log Pis Max                  13.714129
Log Pis Min                  -5.854206
Policy mu Mean               -0.15614226
Policy mu Std                1.3528903
Policy mu Max                2.8146534
Policy mu Min                -2.7329726
Policy log std Mean          -0.8955657
Policy log std Std           0.50742435
Policy log std Max           -0.117322624
Policy log std Min           -3.3830428
Z mean eval                  3.8549447
Z variance eval              0.00765848
total_rewards                [11313.54047707 11421.77788737 11227.32041036 11341.71645551
 11443.7229419  11327.06787293 11286.53054861 11411.70818848
 11334.47560229 11323.26406834]
total_rewards_mean           11343.112445285706
total_rewards_std            62.63213048564987
total_rewards_max            11443.722941901031
total_rewards_min            11227.320410360668
Number of train steps total  1064000
Number of env steps total    1332000
Number of rollouts total     0
Train Time (s)               138.7868520617485
(Previous) Eval Time (s)     26.74088780488819
Sample Time (s)              21.967987487558275
Epoch Time (s)               187.49572735419497
Total Train Time (s)         48488.72552305972
Epoch                        265
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:15:52.920758 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #265 | Epoch Duration: 189.40760278701782
2020-01-13 18:15:52.920945 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #265 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.8576725
Z variance train             0.007648873
KL Divergence                60.66761
KL Loss                      6.066761
QF Loss                      1435.9827
VF Loss                      116.792145
Policy Loss                  -4660.725
Q Predictions Mean           4671.0244
Q Predictions Std            545.484
Q Predictions Max            5275.884
Q Predictions Min            182.08897
V Predictions Mean           4658.782
V Predictions Std            547.15533
V Predictions Max            5253.528
V Predictions Min            113.529976
Log Pis Mean                 5.62805
Log Pis Std                  3.80872
Log Pis Max                  15.795112
Log Pis Min                  -5.5553575
Policy mu Mean               -0.01793295
Policy mu Std                1.3954238
Policy mu Max                2.7367618
Policy mu Min                -2.7822938
Policy log std Mean          -0.8871889
Policy log std Std           0.5142667
Policy log std Max           -0.07530922
Policy log std Min           -3.509268
Z mean eval                  3.8353534
Z variance eval              0.0044675013
total_rewards                [10993.50128016 11153.29356481 11219.87971275 11071.25730744
 11108.9035526  11238.12245771 11112.73855969 11241.09570828
 10983.8345096  11077.50974951]
total_rewards_mean           11120.013640254156
total_rewards_std            88.6575435121504
total_rewards_max            11241.095708281044
total_rewards_min            10983.834509599485
Number of train steps total  1068000
Number of env steps total    1337000
Number of rollouts total     0
Train Time (s)               137.4373574508354
(Previous) Eval Time (s)     28.652435374911875
Sample Time (s)              22.11875001853332
Epoch Time (s)               188.2085428442806
Total Train Time (s)         48676.8825044767
Epoch                        266
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:19:01.081348 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #266 | Epoch Duration: 188.1602578163147
2020-01-13 18:19:01.081551 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #266 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.8323364
Z variance train             0.0044777836
KL Divergence                60.426422
KL Loss                      6.042642
QF Loss                      694.64886
VF Loss                      466.4518
Policy Loss                  -4614.0527
Q Predictions Mean           4623.0938
Q Predictions Std            490.65643
Q Predictions Max            5237.0728
Q Predictions Min            3141.2344
V Predictions Mean           4627.382
V Predictions Std            492.8502
V Predictions Max            5241.206
V Predictions Min            3135.9753
Log Pis Mean                 5.37121
Log Pis Std                  3.9636385
Log Pis Max                  18.367764
Log Pis Min                  -3.9631033
Policy mu Mean               -0.1411287
Policy mu Std                1.3851237
Policy mu Max                3.1927595
Policy mu Min                -3.0722775
Policy log std Mean          -0.89828825
Policy log std Std           0.5118523
Policy log std Max           0.010393858
Policy log std Min           -3.6413589
Z mean eval                  3.8447661
Z variance eval              0.0035502128
total_rewards                [11350.20128441 11268.63267886 11552.70247054  3826.99230141
 11606.39136951 11614.87057809 11601.77786452 11784.64464716
 11898.7598453  11497.77471488]
total_rewards_mean           10800.274775468051
total_rewards_std            2330.9343906519025
total_rewards_max            11898.759845304925
total_rewards_min            3826.992301410826
Number of train steps total  1072000
Number of env steps total    1342000
Number of rollouts total     0
Train Time (s)               130.16962868487462
(Previous) Eval Time (s)     28.60371476598084
Sample Time (s)              22.506100101862103
Epoch Time (s)               181.27944355271757
Total Train Time (s)         48857.764679620974
Epoch                        267
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:22:01.966599 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #267 | Epoch Duration: 180.88490080833435
2020-01-13 18:22:01.966796 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #267 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.8432567
Z variance train             0.00355023
KL Divergence                59.704243
KL Loss                      5.970424
QF Loss                      617.63403
VF Loss                      163.71173
Policy Loss                  -4584.4316
Q Predictions Mean           4592.654
Q Predictions Std            596.4134
Q Predictions Max            5313.98
Q Predictions Min            438.71808
V Predictions Mean           4588.4346
V Predictions Std            597.427
V Predictions Max            5310.2783
V Predictions Min            414.00522
Log Pis Mean                 5.643763
Log Pis Std                  3.8787007
Log Pis Max                  20.436281
Log Pis Min                  -5.3309765
Policy mu Mean               -0.14639889
Policy mu Std                1.4133621
Policy mu Max                2.7814171
Policy mu Min                -5.141259
Policy log std Mean          -0.8603241
Policy log std Std           0.47432935
Policy log std Max           1.0741403
Policy log std Min           -3.4638994
Z mean eval                  3.8436837
Z variance eval              0.016481666
total_rewards                [11570.0905032  11745.29019877 11831.11219941 11537.5829703
 11541.90918676 11754.6189964  11638.26829729 11395.36095636
 11543.36959339 11496.66728408]
total_rewards_mean           11605.427018594659
total_rewards_std            127.87722994471777
total_rewards_max            11831.11219940777
total_rewards_min            11395.36095635857
Number of train steps total  1076000
Number of env steps total    1347000
Number of rollouts total     0
Train Time (s)               130.26740484684706
(Previous) Eval Time (s)     28.2088337643072
Sample Time (s)              21.93717224523425
Epoch Time (s)               180.4134108563885
Total Train Time (s)         49037.69275132241
Epoch                        268
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:25:01.897680 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #268 | Epoch Duration: 179.93074107170105
2020-01-13 18:25:01.897868 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #268 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.843225
Z variance train             0.016402457
KL Divergence                57.732727
KL Loss                      5.773273
QF Loss                      971.6765
VF Loss                      342.3649
Policy Loss                  -4594.9307
Q Predictions Mean           4598.948
Q Predictions Std            611.6115
Q Predictions Max            5262.8105
Q Predictions Min            332.23495
V Predictions Mean           4587.368
V Predictions Std            613.0483
V Predictions Max            5237.548
V Predictions Min            254.71707
Log Pis Mean                 5.714157
Log Pis Std                  3.9018207
Log Pis Max                  17.265041
Log Pis Min                  -6.4558887
Policy mu Mean               -0.11393542
Policy mu Std                1.4152157
Policy mu Max                2.8453326
Policy mu Min                -2.7949526
Policy log std Mean          -0.87179273
Policy log std Std           0.46190962
Policy log std Max           -0.13267657
Policy log std Min           -3.4106975
Z mean eval                  3.863137
Z variance eval              0.008485192
total_rewards                [11096.83236343 11682.27826268 11749.51199987 11680.63884401
 11662.45779778 11705.44203165 11581.1184719  11698.07636727
 11694.93147242 11807.86519003]
total_rewards_mean           11635.915280103529
total_rewards_std            187.9146553541491
total_rewards_max            11807.865190033921
total_rewards_min            11096.832363427473
Number of train steps total  1080000
Number of env steps total    1352000
Number of rollouts total     0
Train Time (s)               136.25065369484946
(Previous) Eval Time (s)     27.725876888725907
Sample Time (s)              22.22005383251235
Epoch Time (s)               186.19658441608772
Total Train Time (s)         49224.539032555185
Epoch                        269
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:28:08.747313 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #269 | Epoch Duration: 186.84930634498596
2020-01-13 18:28:08.747502 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #269 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.8630695
Z variance train             0.008471338
KL Divergence                57.912716
KL Loss                      5.7912717
QF Loss                      523.11725
VF Loss                      92.3072
Policy Loss                  -4739.2793
Q Predictions Mean           4744.741
Q Predictions Std            489.15283
Q Predictions Max            5315.7476
Q Predictions Min            3192.9832
V Predictions Mean           4741.6006
V Predictions Std            490.5175
V Predictions Max            5288.5703
V Predictions Min            3181.7341
Log Pis Mean                 5.825065
Log Pis Std                  3.4658928
Log Pis Max                  14.781742
Log Pis Min                  -2.9863648
Policy mu Mean               -0.08022683
Policy mu Std                1.3908131
Policy mu Max                3.008906
Policy mu Min                -2.9748068
Policy log std Mean          -0.9212248
Policy log std Std           0.5153932
Policy log std Max           -0.14479661
Policy log std Min           -3.473015
Z mean eval                  3.8501084
Z variance eval              0.029792398
total_rewards                [11173.25775801 11308.83921061 11437.31158387 11560.60309541
 11258.30754344 11344.36132365 11597.43973764 11476.46197561
 11485.36499215 11442.24677997]
total_rewards_mean           11408.419400037214
total_rewards_std            127.77803018064475
total_rewards_max            11597.4397376417
total_rewards_min            11173.257758012105
Number of train steps total  1084000
Number of env steps total    1357000
Number of rollouts total     0
Train Time (s)               138.31009982991964
(Previous) Eval Time (s)     28.378277400974184
Sample Time (s)              23.419886684510857
Epoch Time (s)               190.10826391540468
Total Train Time (s)         49413.8622861607
Epoch                        270
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:31:18.074197 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #270 | Epoch Duration: 189.32652306556702
2020-01-13 18:31:18.074599 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #270 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.852162
Z variance train             0.029442683
KL Divergence                56.15143
KL Loss                      5.615143
QF Loss                      1455.2998
VF Loss                      346.00708
Policy Loss                  -4591.1816
Q Predictions Mean           4596.0596
Q Predictions Std            516.9457
Q Predictions Max            5269.2065
Q Predictions Min            3222.0776
V Predictions Mean           4578.379
V Predictions Std            513.38586
V Predictions Max            5243.527
V Predictions Min            3222.112
Log Pis Mean                 5.164703
Log Pis Std                  3.828588
Log Pis Max                  15.234665
Log Pis Min                  -5.9412503
Policy mu Mean               -0.07292231
Policy mu Std                1.3843447
Policy mu Max                3.0874045
Policy mu Min                -3.0655723
Policy log std Mean          -0.8737363
Policy log std Std           0.47478116
Policy log std Max           -0.08825052
Policy log std Min           -3.6018214
Z mean eval                  3.8706756
Z variance eval              0.021646155
total_rewards                [10632.00264244 11244.08560067 10982.44676648 11083.05510142
 11197.39696058 11084.85185515 11274.5742588  10915.83406089
 10967.15377415 11052.40903506]
total_rewards_mean           11043.381005565101
total_rewards_std            177.72250640903277
total_rewards_max            11274.574258796614
total_rewards_min            10632.002642441887
Number of train steps total  1088000
Number of env steps total    1362000
Number of rollouts total     0
Train Time (s)               137.50279347598553
(Previous) Eval Time (s)     27.59616460185498
Sample Time (s)              21.973282797262073
Epoch Time (s)               187.07224087510258
Total Train Time (s)         49599.965369764715
Epoch                        271
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:34:24.180258 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #271 | Epoch Duration: 186.10539627075195
2020-01-13 18:34:24.180463 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #271 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.8707905
Z variance train             0.021665214
KL Divergence                56.95994
KL Loss                      5.6959944
QF Loss                      450.48013
VF Loss                      131.75983
Policy Loss                  -4702.786
Q Predictions Mean           4705.454
Q Predictions Std            526.0605
Q Predictions Max            5340.467
Q Predictions Min            3198.2202
V Predictions Mean           4706.41
V Predictions Std            526.6745
V Predictions Max            5316.3506
V Predictions Min            3206.355
Log Pis Mean                 5.176529
Log Pis Std                  3.6337392
Log Pis Max                  17.022049
Log Pis Min                  -4.901726
Policy mu Mean               -0.12472012
Policy mu Std                1.3540927
Policy mu Max                3.1849046
Policy mu Min                -3.1795828
Policy log std Mean          -0.8808364
Policy log std Std           0.48849142
Policy log std Max           -0.20754689
Policy log std Min           -3.6366591
Z mean eval                  3.8439164
Z variance eval              0.020838603
total_rewards                [11424.98266366 11553.31945993 11593.60441678 11454.87187455
 11747.63802714 11719.23997356 11560.79752296 11603.66548851
 11447.01727576 11588.15753923]
total_rewards_mean           11569.329424207985
total_rewards_std            102.76952908671143
total_rewards_max            11747.638027143195
total_rewards_min            11424.982663655304
Number of train steps total  1092000
Number of env steps total    1367000
Number of rollouts total     0
Train Time (s)               140.02734925458208
(Previous) Eval Time (s)     26.62893465626985
Sample Time (s)              23.044242021627724
Epoch Time (s)               189.70052593247965
Total Train Time (s)         49791.6950466237
Epoch                        272
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:37:35.914125 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #272 | Epoch Duration: 191.73347401618958
2020-01-13 18:37:35.914440 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #272 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.8478532
Z variance train             0.020756183
KL Divergence                56.330166
KL Loss                      5.6330166
QF Loss                      667.9176
VF Loss                      444.41553
Policy Loss                  -4625.704
Q Predictions Mean           4633.8643
Q Predictions Std            517.478
Q Predictions Max            5243.394
Q Predictions Min            3150.0264
V Predictions Mean           4611.368
V Predictions Std            515.325
V Predictions Max            5247.911
V Predictions Min            3135.0535
Log Pis Mean                 5.2626667
Log Pis Std                  3.809657
Log Pis Max                  13.305508
Log Pis Min                  -5.759739
Policy mu Mean               -0.13545989
Policy mu Std                1.3492035
Policy mu Max                2.787283
Policy mu Min                -3.1497633
Policy log std Mean          -0.8967951
Policy log std Std           0.50160396
Policy log std Max           -0.1531024
Policy log std Min           -3.496428
Z mean eval                  3.881349
Z variance eval              0.01739711
total_rewards                [11250.88946267 11523.58096173 11699.95105733 11529.43101544
 11495.06110798 11391.20106111 11507.33214134   662.59664637
 11826.059918   11552.78678875]
total_rewards_mean           10443.88901607309
total_rewards_std            3263.7414565859895
total_rewards_max            11826.059918002911
total_rewards_min            662.5966463696425
Number of train steps total  1096000
Number of env steps total    1372000
Number of rollouts total     0
Train Time (s)               137.67081414023414
(Previous) Eval Time (s)     28.661501914728433
Sample Time (s)              23.114179318770766
Epoch Time (s)               189.44649537373334
Total Train Time (s)         49980.52900865208
Epoch                        273
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:40:44.750726 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #273 | Epoch Duration: 188.8360619544983
2020-01-13 18:40:44.750932 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #273 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.8802466
Z variance train             0.017413203
KL Divergence                57.29617
KL Loss                      5.729617
QF Loss                      652.8056
VF Loss                      204.42673
Policy Loss                  -4687.1597
Q Predictions Mean           4699.3
Q Predictions Std            511.1101
Q Predictions Max            5382.3345
Q Predictions Min            2894.6611
V Predictions Mean           4693.517
V Predictions Std            514.1486
V Predictions Max            5357.727
V Predictions Min            2811.123
Log Pis Mean                 5.4273663
Log Pis Std                  3.6988492
Log Pis Max                  17.343235
Log Pis Min                  -2.661144
Policy mu Mean               -0.06274364
Policy mu Std                1.3874832
Policy mu Max                2.9428375
Policy mu Min                -3.3951626
Policy log std Mean          -0.88244015
Policy log std Std           0.48102662
Policy log std Max           -0.13657579
Policy log std Min           -3.304782
Z mean eval                  3.8588111
Z variance eval              0.049126618
total_rewards                [11353.00533569 11491.42372624 11750.72916285  6214.45017702
 11780.91576278 11730.36629843 11742.60963618 11700.10568731
 10938.63126141 11866.61472865]
total_rewards_mean           11056.885177654125
total_rewards_std            1635.1911450675266
total_rewards_max            11866.614728647148
total_rewards_min            6214.450177022609
Number of train steps total  1100000
Number of env steps total    1377000
Number of rollouts total     0
Train Time (s)               130.40811571711674
(Previous) Eval Time (s)     28.050685603171587
Sample Time (s)              22.252785864286125
Epoch Time (s)               180.71158718457446
Total Train Time (s)         50160.82259545941
Epoch                        274
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:43:45.047561 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #274 | Epoch Duration: 180.2964859008789
2020-01-13 18:43:45.047768 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #274 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.860506
Z variance train             0.049262017
KL Divergence                53.853905
KL Loss                      5.3853908
QF Loss                      674.0498
VF Loss                      115.10787
Policy Loss                  -4632.6445
Q Predictions Mean           4640.3706
Q Predictions Std            577.83685
Q Predictions Max            5232.9873
Q Predictions Min            578.06305
V Predictions Mean           4630.8687
V Predictions Std            579.40247
V Predictions Max            5230.5176
V Predictions Min            522.3458
Log Pis Mean                 5.5872393
Log Pis Std                  3.8949606
Log Pis Max                  16.993855
Log Pis Min                  -8.152664
Policy mu Mean               -0.09758692
Policy mu Std                1.3980802
Policy mu Max                2.8614366
Policy mu Min                -2.7454739
Policy log std Mean          -0.87955207
Policy log std Std           0.5010561
Policy log std Max           0.0026657581
Policy log std Min           -3.6540303
Z mean eval                  3.901052
Z variance eval              0.019270113
total_rewards                [11492.90485171 11670.37523151 11590.63054221 11502.6298045
 11467.69643208 11583.73177019 11575.81781371 11675.89295432
 11500.79623259 11603.91630899]
total_rewards_mean           11566.439194182185
total_rewards_std            69.7836956726143
total_rewards_max            11675.892954320501
total_rewards_min            11467.696432077479
Number of train steps total  1104000
Number of env steps total    1382000
Number of rollouts total     0
Train Time (s)               130.5584241510369
(Previous) Eval Time (s)     27.635246080812067
Sample Time (s)              20.54926725057885
Epoch Time (s)               178.7429374824278
Total Train Time (s)         50339.67615256971
Epoch                        275
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:46:43.905338 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #275 | Epoch Duration: 178.85739636421204
2020-01-13 18:46:43.905710 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #275 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.900973
Z variance train             0.019111458
KL Divergence                56.558712
KL Loss                      5.6558714
QF Loss                      1046.1716
VF Loss                      106.9686
Policy Loss                  -4621.7617
Q Predictions Mean           4623.543
Q Predictions Std            628.7995
Q Predictions Max            5302.624
Q Predictions Min            367.82935
V Predictions Mean           4618.5713
V Predictions Std            625.1878
V Predictions Max            5302.5454
V Predictions Min            470.25937
Log Pis Mean                 5.321944
Log Pis Std                  3.6441147
Log Pis Max                  17.541647
Log Pis Min                  -3.6719313
Policy mu Mean               -0.1252342
Policy mu Std                1.3872354
Policy mu Max                2.9434662
Policy mu Min                -2.9333353
Policy log std Mean          -0.87637234
Policy log std Std           0.47856745
Policy log std Max           0.03891909
Policy log std Min           -3.3775783
Z mean eval                  3.9260056
Z variance eval              0.012954161
total_rewards                [10900.37672224 11100.11904795 10956.47203441 10784.54151801
 10938.0080715  11066.37104351 10896.72707276 10903.05991067
 11002.70830096 10891.03761807]
total_rewards_mean           10943.942134007619
total_rewards_std            87.76773193689291
total_rewards_max            11100.119047952787
total_rewards_min            10784.541518009102
Number of train steps total  1108000
Number of env steps total    1387000
Number of rollouts total     0
Train Time (s)               137.225879766047
(Previous) Eval Time (s)     27.74935639090836
Sample Time (s)              22.89605737430975
Epoch Time (s)               187.8712935312651
Total Train Time (s)         50528.821676438674
Epoch                        276
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:49:53.053627 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #276 | Epoch Duration: 189.1476628780365
2020-01-13 18:49:53.053831 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #276 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9289832
Z variance train             0.0130825965
KL Divergence                59.257324
KL Loss                      5.9257326
QF Loss                      911.1186
VF Loss                      314.90918
Policy Loss                  -4676.4927
Q Predictions Mean           4685.025
Q Predictions Std            649.4146
Q Predictions Max            5366.916
Q Predictions Min            156.61966
V Predictions Mean           4666.09
V Predictions Std            648.2619
V Predictions Max            5355.818
V Predictions Min            159.01039
Log Pis Mean                 5.299241
Log Pis Std                  4.0159473
Log Pis Max                  17.535671
Log Pis Min                  -5.7702465
Policy mu Mean               -0.04659463
Policy mu Std                1.385579
Policy mu Max                3.9630542
Policy mu Min                -3.2115655
Policy log std Mean          -0.84751266
Policy log std Std           0.4803391
Policy log std Max           0.36965466
Policy log std Min           -3.2827582
Z mean eval                  3.898912
Z variance eval              0.010758254
total_rewards                [ 4438.64859498 11905.74491852 11917.68705099 12044.00312375
 11677.74136689 11742.00455655 11755.49942793 11934.66681024
 11994.37563965 11821.23637002]
total_rewards_mean           11123.160785950848
total_rewards_std            2230.910352611589
total_rewards_max            12044.003123754965
total_rewards_min            4438.648594975738
Number of train steps total  1112000
Number of env steps total    1392000
Number of rollouts total     0
Train Time (s)               137.59315164992586
(Previous) Eval Time (s)     29.025379261933267
Sample Time (s)              23.073161019943655
Epoch Time (s)               189.69169193180278
Total Train Time (s)         50717.56763453875
Epoch                        277
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:53:01.802813 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #277 | Epoch Duration: 188.748841047287
2020-01-13 18:53:01.803002 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #277 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9016395
Z variance train             0.010793047
KL Divergence                58.286392
KL Loss                      5.8286395
QF Loss                      423.80963
VF Loss                      109.71079
Policy Loss                  -4720.7246
Q Predictions Mean           4728.3926
Q Predictions Std            508.69577
Q Predictions Max            5373.735
Q Predictions Min            3264.5967
V Predictions Mean           4723.699
V Predictions Std            507.6602
V Predictions Max            5360.4067
V Predictions Min            3265.386
Log Pis Mean                 5.729004
Log Pis Std                  3.935831
Log Pis Max                  14.79633
Log Pis Min                  -8.753831
Policy mu Mean               -0.039076377
Policy mu Std                1.4023321
Policy mu Max                2.887832
Policy mu Min                -3.361004
Policy log std Mean          -0.91093
Policy log std Std           0.5306401
Policy log std Max           -0.07241517
Policy log std Min           -3.5131679
Z mean eval                  3.8989303
Z variance eval              0.010181477
total_rewards                [10989.81835303 11514.2170837  11224.57259182 10822.58356743
 11366.89706466 10961.58454917 10842.99921899  4989.2422573
 11457.01033872 11201.56812768]
total_rewards_mean           10537.049315250388
total_rewards_std            1863.93761158828
total_rewards_max            11514.217083699756
total_rewards_min            4989.242257299112
Number of train steps total  1116000
Number of env steps total    1397000
Number of rollouts total     0
Train Time (s)               136.7368635321036
(Previous) Eval Time (s)     28.08216059440747
Sample Time (s)              23.241313085891306
Epoch Time (s)               188.06033721240237
Total Train Time (s)         50906.261622911785
Epoch                        278
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:56:10.500702 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #278 | Epoch Duration: 188.69753289222717
2020-01-13 18:56:10.501034 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #278 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.899617
Z variance train             0.010189116
KL Divergence                59.254147
KL Loss                      5.9254146
QF Loss                      375.01172
VF Loss                      132.47153
Policy Loss                  -4790.2085
Q Predictions Mean           4795.7637
Q Predictions Std            461.071
Q Predictions Max            5448.052
Q Predictions Min            3265.639
V Predictions Mean           4796.712
V Predictions Std            461.5551
V Predictions Max            5448.669
V Predictions Min            3272.358
Log Pis Mean                 5.89534
Log Pis Std                  3.6619496
Log Pis Max                  16.41093
Log Pis Min                  -2.9124334
Policy mu Mean               -0.09812098
Policy mu Std                1.4201508
Policy mu Max                3.061474
Policy mu Min                -3.0988357
Policy log std Mean          -0.8848317
Policy log std Std           0.48959845
Policy log std Max           -0.16500801
Policy log std Min           -3.5795016
Z mean eval                  3.9427407
Z variance eval              0.012339681
total_rewards                [11352.3242195  11825.83075426 11726.7643898  11596.87370246
 11625.38745938 11575.41537418 11775.59659075 11417.18836134
 11144.36886496 11464.80241989]
total_rewards_mean           11550.455213653182
total_rewards_std            198.8105251859586
total_rewards_max            11825.830754261931
total_rewards_min            11144.36886496445
Number of train steps total  1120000
Number of env steps total    1402000
Number of rollouts total     0
Train Time (s)               139.1642034011893
(Previous) Eval Time (s)     28.718974564690143
Sample Time (s)              23.48661257699132
Epoch Time (s)               191.36979054287076
Total Train Time (s)         51097.189852413256
Epoch                        279
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:59:21.431513 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #279 | Epoch Duration: 190.9303002357483
2020-01-13 18:59:21.431714 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #279 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9422123
Z variance train             0.012343278
KL Divergence                57.40598
KL Loss                      5.740598
QF Loss                      333.2787
VF Loss                      299.59683
Policy Loss                  -4777.002
Q Predictions Mean           4779.461
Q Predictions Std            489.36182
Q Predictions Max            5317.7305
Q Predictions Min            3228.9922
V Predictions Mean           4768.7744
V Predictions Std            490.1744
V Predictions Max            5303.183
V Predictions Min            3213.1619
Log Pis Mean                 5.7526174
Log Pis Std                  3.7052078
Log Pis Max                  15.590666
Log Pis Min                  -6.891643
Policy mu Mean               -0.117987104
Policy mu Std                1.4161361
Policy mu Max                2.78646
Policy mu Min                -3.704854
Policy log std Mean          -0.8878765
Policy log std Std           0.49658245
Policy log std Max           -0.11513412
Policy log std Min           -3.5147429
Z mean eval                  3.9303348
Z variance eval              0.007665479
total_rewards                [11675.94921738 11883.51500558 11720.70248133 12013.44006696
 11747.59811205 11640.95152319 11689.17593484 11819.41112007
 11659.58364258 11848.89448153]
total_rewards_mean           11769.922158552212
total_rewards_std            113.12378644921306
total_rewards_max            12013.440066955778
total_rewards_min            11640.951523187372
Number of train steps total  1124000
Number of env steps total    1407000
Number of rollouts total     0
Train Time (s)               134.99882081523538
(Previous) Eval Time (s)     28.279102832078934
Sample Time (s)              23.145247850567102
Epoch Time (s)               186.4231714978814
Total Train Time (s)         51282.56130496133
Epoch                        280
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:02:26.806128 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #280 | Epoch Duration: 185.37427711486816
2020-01-13 19:02:26.806316 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #280 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9284787
Z variance train             0.0076553756
KL Divergence                58.347427
KL Loss                      5.834743
QF Loss                      511.9166
VF Loss                      154.88036
Policy Loss                  -4662.6426
Q Predictions Mean           4673.1284
Q Predictions Std            533.9638
Q Predictions Max            5299.95
Q Predictions Min            3223.137
V Predictions Mean           4667.336
V Predictions Std            534.12036
V Predictions Max            5291.6006
V Predictions Min            3218.377
Log Pis Mean                 5.059456
Log Pis Std                  3.6234512
Log Pis Max                  14.320467
Log Pis Min                  -4.4269023
Policy mu Mean               -0.083966315
Policy mu Std                1.3591447
Policy mu Max                3.23438
Policy mu Min                -2.7603853
Policy log std Mean          -0.89687663
Policy log std Std           0.48413417
Policy log std Max           -0.12448275
Policy log std Min           -3.637878
Z mean eval                  3.9488118
Z variance eval              0.016374333
total_rewards                [11038.23884213 11250.73607895 11590.51580322 11312.48932995
 11272.77638219 11159.45528166 11488.83526455 11256.36555605
 11315.88648261 11534.5906651 ]
total_rewards_mean           11321.98896864065
total_rewards_std            162.48320869735716
total_rewards_max            11590.515803215478
total_rewards_min            11038.238842131086
Number of train steps total  1128000
Number of env steps total    1412000
Number of rollouts total     0
Train Time (s)               130.06999147078022
(Previous) Eval Time (s)     27.22986009903252
Sample Time (s)              21.978876944165677
Epoch Time (s)               179.27872851397842
Total Train Time (s)         51462.659774541855
Epoch                        281
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:05:26.908442 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #281 | Epoch Duration: 180.1019856929779
2020-01-13 19:05:26.908654 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #281 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9505188
Z variance train             0.016377084
KL Divergence                58.492325
KL Loss                      5.8492327
QF Loss                      531.5693
VF Loss                      297.01828
Policy Loss                  -4762.895
Q Predictions Mean           4766.479
Q Predictions Std            522.8201
Q Predictions Max            5371.291
Q Predictions Min            3156.3347
V Predictions Mean           4750.999
V Predictions Std            519.2511
V Predictions Max            5359.2896
V Predictions Min            3168.255
Log Pis Mean                 5.5797634
Log Pis Std                  3.4041476
Log Pis Max                  15.179661
Log Pis Min                  -4.7000275
Policy mu Mean               -0.12037596
Policy mu Std                1.3827507
Policy mu Max                2.7880895
Policy mu Min                -2.7044919
Policy log std Mean          -0.89984745
Policy log std Std           0.5196398
Policy log std Max           -0.018128633
Policy log std Min           -3.376043
Z mean eval                  3.9449692
Z variance eval              0.007848542
total_rewards                [11141.67658392 11976.25111857  8318.44821005 11969.89028377
 11707.5984482  11694.25140259 11700.26488564 11556.26550283
 11842.02819732 12013.7246129 ]
total_rewards_mean           11392.039924580113
total_rewards_std            1052.9351599461986
total_rewards_max            12013.724612904432
total_rewards_min            8318.448210052047
Number of train steps total  1132000
Number of env steps total    1417000
Number of rollouts total     0
Train Time (s)               131.4301396193914
(Previous) Eval Time (s)     28.052797716110945
Sample Time (s)              20.394968169741333
Epoch Time (s)               179.8779055052437
Total Train Time (s)         51642.651897887234
Epoch                        282
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:08:26.903859 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #282 | Epoch Duration: 179.99503993988037
2020-01-13 19:08:26.904102 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #282 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9466934
Z variance train             0.007823622
KL Divergence                60.438454
KL Loss                      6.0438457
QF Loss                      519.4598
VF Loss                      87.85463
Policy Loss                  -4732.83
Q Predictions Mean           4740.024
Q Predictions Std            598.546
Q Predictions Max            5459.5693
Q Predictions Min            462.18887
V Predictions Mean           4734.0337
V Predictions Std            597.8729
V Predictions Max            5453.44
V Predictions Min            430.54172
Log Pis Mean                 5.128753
Log Pis Std                  3.7533042
Log Pis Max                  14.712687
Log Pis Min                  -3.7907796
Policy mu Mean               -0.03914674
Policy mu Std                1.3830259
Policy mu Max                4.1428676
Policy mu Min                -3.0266752
Policy log std Mean          -0.8847132
Policy log std Std           0.5056581
Policy log std Max           0.26027715
Policy log std Min           -3.7148924
Z mean eval                  3.9261155
Z variance eval              0.009637147
total_rewards                [11493.06905119 11343.58281093 11670.78474148 11645.28587535
 11543.09276198 11722.27288239  2292.50816649 11557.958375
 11693.11281487 11685.27748378]
total_rewards_mean           10664.694496343862
total_rewards_std            2792.8763758405685
total_rewards_max            11722.272882388048
total_rewards_min            2292.508166487122
Number of train steps total  1136000
Number of env steps total    1422000
Number of rollouts total     0
Train Time (s)               138.61082305479795
(Previous) Eval Time (s)     28.169613013044
Sample Time (s)              21.353129462804645
Epoch Time (s)               188.1335655306466
Total Train Time (s)         51829.96876258217
Epoch                        283
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:11:34.224075 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #283 | Epoch Duration: 187.3198118209839
2020-01-13 19:11:34.224320 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #283 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9260395
Z variance train             0.00959987
KL Divergence                59.279285
KL Loss                      5.9279284
QF Loss                      305.5827
VF Loss                      124.86325
Policy Loss                  -4755.758
Q Predictions Mean           4760.081
Q Predictions Std            478.07144
Q Predictions Max            5471.342
Q Predictions Min            3222.22
V Predictions Mean           4753.1567
V Predictions Std            476.73056
V Predictions Max            5467.7344
V Predictions Min            3216.81
Log Pis Mean                 5.476348
Log Pis Std                  3.8618412
Log Pis Max                  14.693613
Log Pis Min                  -4.1475425
Policy mu Mean               -0.07741922
Policy mu Std                1.3721706
Policy mu Max                2.7650044
Policy mu Min                -2.7019725
Policy log std Mean          -0.9064296
Policy log std Std           0.5373225
Policy log std Max           -0.21541154
Policy log std Min           -3.6379132
Z mean eval                  3.9112668
Z variance eval              0.007326594
total_rewards                [10836.30512453 11482.28129446 11458.35783978 11514.47716153
 11267.54904885 11335.42996713 11151.48920442 10998.34234247
 11130.4808075  11304.99467783]
total_rewards_mean           11247.970746850991
total_rewards_std            208.89458662983782
total_rewards_max            11514.477161530944
total_rewards_min            10836.305124533646
Number of train steps total  1140000
Number of env steps total    1427000
Number of rollouts total     0
Train Time (s)               137.0261391121894
(Previous) Eval Time (s)     27.35553854610771
Sample Time (s)              23.71887073572725
Epoch Time (s)               188.10054839402437
Total Train Time (s)         52019.848951070104
Epoch                        284
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:14:44.107352 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #284 | Epoch Duration: 189.88286757469177
2020-01-13 19:14:44.107538 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #284 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9114366
Z variance train             0.00736137
KL Divergence                58.68814
KL Loss                      5.868814
QF Loss                      597.4595
VF Loss                      122.31403
Policy Loss                  -4688.0493
Q Predictions Mean           4699.0835
Q Predictions Std            533.2253
Q Predictions Max            5450.27
Q Predictions Min            3275.7378
V Predictions Mean           4684.797
V Predictions Std            530.2512
V Predictions Max            5438.275
V Predictions Min            3272.379
Log Pis Mean                 5.324787
Log Pis Std                  3.8013237
Log Pis Max                  15.321453
Log Pis Min                  -4.3137484
Policy mu Mean               -0.100022264
Policy mu Std                1.3647486
Policy mu Max                3.2099724
Policy mu Min                -3.225135
Policy log std Mean          -0.8801324
Policy log std Std           0.50555855
Policy log std Max           0.02315402
Policy log std Min           -3.4740963
Z mean eval                  3.920135
Z variance eval              0.012369507
total_rewards                [10902.14335896 11035.48012526 11196.67826085 10867.31166754
 10910.39016902 11191.73556291 11032.85018557 11021.14422124
 11052.0242106  11222.53851571]
total_rewards_mean           11043.229627766292
total_rewards_std            121.23689880559277
total_rewards_max            11222.53851570556
total_rewards_min            10867.311667540533
Number of train steps total  1144000
Number of env steps total    1432000
Number of rollouts total     0
Train Time (s)               136.67507437663153
(Previous) Eval Time (s)     29.13749526720494
Sample Time (s)              22.270301674026996
Epoch Time (s)               188.08287131786346
Total Train Time (s)         52207.34446601616
Epoch                        285
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:17:51.606176 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #285 | Epoch Duration: 187.4984951019287
2020-01-13 19:17:51.606383 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #285 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9202855
Z variance train             0.012372615
KL Divergence                57.769268
KL Loss                      5.776927
QF Loss                      718.70483
VF Loss                      341.316
Policy Loss                  -4740.5996
Q Predictions Mean           4746.8223
Q Predictions Std            513.6658
Q Predictions Max            5459.2837
Q Predictions Min            3217.2761
V Predictions Mean           4729.3477
V Predictions Std            510.47516
V Predictions Max            5440.44
V Predictions Min            3206.3035
Log Pis Mean                 5.6571317
Log Pis Std                  3.9739163
Log Pis Max                  14.427974
Log Pis Min                  -3.2748446
Policy mu Mean               -0.08445713
Policy mu Std                1.4204851
Policy mu Max                2.8656933
Policy mu Min                -3.2090774
Policy log std Mean          -0.8832144
Policy log std Std           0.48875934
Policy log std Max           -0.16658631
Policy log std Min           -3.4344578
Z mean eval                  3.9587379
Z variance eval              0.005596427
total_rewards                [11289.04118219 11847.47138403 11820.19672872 11854.53561976
 11732.59827776 11804.99360814 11779.63331409 11923.7015019
 11464.97326791 11688.96315982]
total_rewards_mean           11720.610804433458
total_rewards_std            186.69357958543173
total_rewards_max            11923.701501903679
total_rewards_min            11289.04118219383
Number of train steps total  1148000
Number of env steps total    1437000
Number of rollouts total     0
Train Time (s)               137.0441587138921
(Previous) Eval Time (s)     28.55266249505803
Sample Time (s)              23.170888506341726
Epoch Time (s)               188.76770971529186
Total Train Time (s)         52396.521735915914
Epoch                        286
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:21:00.786759 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #286 | Epoch Duration: 189.18023252487183
2020-01-13 19:21:00.786967 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #286 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9581094
Z variance train             0.005603459
KL Divergence                59.22487
KL Loss                      5.922487
QF Loss                      525.50476
VF Loss                      179.20921
Policy Loss                  -4707.1895
Q Predictions Mean           4711.4106
Q Predictions Std            512.86096
Q Predictions Max            5410.776
Q Predictions Min            2842.5493
V Predictions Mean           4706.9316
V Predictions Std            513.588
V Predictions Max            5407.952
V Predictions Min            2865.6653
Log Pis Mean                 5.8748393
Log Pis Std                  3.859432
Log Pis Max                  14.434569
Log Pis Min                  -4.6385603
Policy mu Mean               -0.09074036
Policy mu Std                1.4121761
Policy mu Max                2.9269245
Policy mu Min                -2.6030054
Policy log std Mean          -0.89891034
Policy log std Std           0.5134049
Policy log std Max           -0.16227746
Policy log std Min           -3.4669247
Z mean eval                  3.940359
Z variance eval              0.010617545
total_rewards                [11608.31159342 11935.45936244 11742.1284894  11922.42068153
 11667.4466785  11647.73582265 11764.18797433 11809.99005135
 11986.68792268 11776.83126996]
total_rewards_mean           11786.119984624698
total_rewards_std            122.077559939334
total_rewards_max            11986.687922676316
total_rewards_min            11608.311593418688
Number of train steps total  1152000
Number of env steps total    1442000
Number of rollouts total     0
Train Time (s)               133.0629715132527
(Previous) Eval Time (s)     28.96478792419657
Sample Time (s)              23.26443259511143
Epoch Time (s)               185.2921920325607
Total Train Time (s)         52579.45625214791
Epoch                        287
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:24:03.724550 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #287 | Epoch Duration: 182.93743181228638
2020-01-13 19:24:03.724741 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #287 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9405174
Z variance train             0.010608135
KL Divergence                61.1223
KL Loss                      6.11223
QF Loss                      457.50583
VF Loss                      157.77509
Policy Loss                  -4760.866
Q Predictions Mean           4765.0986
Q Predictions Std            520.1956
Q Predictions Max            5368.4565
Q Predictions Min            2175.581
V Predictions Mean           4764.7354
V Predictions Std            519.8826
V Predictions Max            5365.6494
V Predictions Min            2214.4897
Log Pis Mean                 5.1612325
Log Pis Std                  3.727286
Log Pis Max                  15.470718
Log Pis Min                  -5.3575263
Policy mu Mean               -0.062179685
Policy mu Std                1.3731664
Policy mu Max                3.1749938
Policy mu Min                -2.9356592
Policy log std Mean          -0.8880995
Policy log std Std           0.49970266
Policy log std Max           0.192397
Policy log std Min           -3.3476744
Z mean eval                  3.9218612
Z variance eval              0.0058654076
total_rewards                [11813.09837444 11908.65344557 11650.48775251 12052.54537404
 11636.0570626  11723.10148962 11953.28005696 11719.35514382
 11583.58697851 11849.27516463]
total_rewards_mean           11788.94408427
total_rewards_std            144.54741715031162
total_rewards_max            12052.545374038173
total_rewards_min            11583.586978513318
Number of train steps total  1156000
Number of env steps total    1447000
Number of rollouts total     0
Train Time (s)               131.11751181306317
(Previous) Eval Time (s)     26.609697192441672
Sample Time (s)              22.30063428869471
Epoch Time (s)               180.02784329419956
Total Train Time (s)         52760.885452895425
Epoch                        288
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:27:05.157192 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #288 | Epoch Duration: 181.43229937553406
2020-01-13 19:27:05.157431 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #288 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9211013
Z variance train             0.005872744
KL Divergence                60.11906
KL Loss                      6.011906
QF Loss                      479.7055
VF Loss                      216.66974
Policy Loss                  -4803.541
Q Predictions Mean           4805.039
Q Predictions Std            527.409
Q Predictions Max            5490.842
Q Predictions Min            3194.646
V Predictions Mean           4792.8
V Predictions Std            527.36774
V Predictions Max            5489.027
V Predictions Min            3192.0142
Log Pis Mean                 5.569481
Log Pis Std                  3.6195128
Log Pis Max                  16.69758
Log Pis Min                  -3.483375
Policy mu Mean               -0.06864495
Policy mu Std                1.4026651
Policy mu Max                2.905199
Policy mu Min                -2.857211
Policy log std Mean          -0.8716257
Policy log std Std           0.49133512
Policy log std Max           -0.094285786
Policy log std Min           -3.579368
Z mean eval                  3.9060693
Z variance eval              0.00620571
total_rewards                [11640.84605898 12018.61884502 12050.39932357 11955.93548642
 12080.69651263 11697.83817858 11746.03229048 12174.27640321
 11907.98687885 11714.40609929]
total_rewards_mean           11898.70360770241
total_rewards_std            177.17963857142425
total_rewards_max            12174.276403209547
total_rewards_min            11640.846058983032
Number of train steps total  1160000
Number of env steps total    1452000
Number of rollouts total     0
Train Time (s)               132.12852000026032
(Previous) Eval Time (s)     28.01380279008299
Sample Time (s)              22.016686062328517
Epoch Time (s)               182.15900885267183
Total Train Time (s)         52943.11645244574
Epoch                        289
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:30:07.391423 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #289 | Epoch Duration: 182.2338466644287
2020-01-13 19:30:07.391603 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #289 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9041436
Z variance train             0.006145691
KL Divergence                60.403664
KL Loss                      6.0403666
QF Loss                      480.10257
VF Loss                      163.13292
Policy Loss                  -4708.343
Q Predictions Mean           4714.132
Q Predictions Std            639.9836
Q Predictions Max            5397.763
Q Predictions Min            430.7769
V Predictions Mean           4716.2646
V Predictions Std            635.0427
V Predictions Max            5393.0615
V Predictions Min            489.68735
Log Pis Mean                 5.5177717
Log Pis Std                  4.0581527
Log Pis Max                  16.2303
Log Pis Min                  -6.135999
Policy mu Mean               -0.040098924
Policy mu Std                1.4134928
Policy mu Max                2.9260328
Policy mu Min                -2.7610195
Policy log std Mean          -0.87512016
Policy log std Std           0.4959032
Policy log std Max           0.13652313
Policy log std Min           -3.5526543
Z mean eval                  3.957595
Z variance eval              0.005094882
total_rewards                [11827.29822063 11841.48693751 12008.72925043 11798.51337695
 11509.59937652 11765.08054778 11783.06668233 12070.04207191
 11707.8982182  11902.81117317]
total_rewards_mean           11821.452585542489
total_rewards_std            148.07044210388375
total_rewards_max            12070.042071907983
total_rewards_min            11509.599376520559
Number of train steps total  1164000
Number of env steps total    1457000
Number of rollouts total     0
Train Time (s)               140.29137228103355
(Previous) Eval Time (s)     28.088211162015796
Sample Time (s)              22.803035247605294
Epoch Time (s)               191.18261869065464
Total Train Time (s)         53134.35258025071
Epoch                        290
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:33:18.631863 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #290 | Epoch Duration: 191.2400996685028
2020-01-13 19:33:18.632162 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #290 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9583309
Z variance train             0.005092432
KL Divergence                59.74475
KL Loss                      5.9744754
QF Loss                      1774.7444
VF Loss                      108.18106
Policy Loss                  -4709.114
Q Predictions Mean           4714.3267
Q Predictions Std            570.76984
Q Predictions Max            5393.617
Q Predictions Min            2959.114
V Predictions Mean           4713.505
V Predictions Std            566.642
V Predictions Max            5380.9976
V Predictions Min            3272.5793
Log Pis Mean                 5.115758
Log Pis Std                  3.7993305
Log Pis Max                  18.622597
Log Pis Min                  -5.437851
Policy mu Mean               -0.08350948
Policy mu Std                1.3448266
Policy mu Max                3.5072558
Policy mu Min                -2.6304643
Policy log std Mean          -0.8834055
Policy log std Std           0.48192856
Policy log std Max           -0.18366742
Policy log std Min           -3.5911436
Z mean eval                  3.911818
Z variance eval              0.0069528213
total_rewards                [11675.67544663 11943.02110508 11552.14443875 12051.32619217
 11978.41610505  6885.24210752 11749.86130379 11851.052536
 11716.33034767 11940.8557528 ]
total_rewards_mean           11334.39253354556
total_rewards_std            1490.3437318077806
total_rewards_max            12051.32619216813
total_rewards_min            6885.242107515402
Number of train steps total  1168000
Number of env steps total    1462000
Number of rollouts total     0
Train Time (s)               138.7287429641001
(Previous) Eval Time (s)     28.145275291986763
Sample Time (s)              22.95236434880644
Epoch Time (s)               189.8263826048933
Total Train Time (s)         53324.34017140325
Epoch                        291
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:36:28.622906 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #291 | Epoch Duration: 189.9905767440796
2020-01-13 19:36:28.623099 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #291 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.914151
Z variance train             0.006952877
KL Divergence                60.20585
KL Loss                      6.020585
QF Loss                      653.9192
VF Loss                      441.13535
Policy Loss                  -4721.7676
Q Predictions Mean           4729.67
Q Predictions Std            605.26904
Q Predictions Max            5407.193
Q Predictions Min            433.11905
V Predictions Mean           4706.5347
V Predictions Std            601.395
V Predictions Max            5385.7764
V Predictions Min            427.72968
Log Pis Mean                 5.613126
Log Pis Std                  3.774606
Log Pis Max                  20.219784
Log Pis Min                  -7.3930497
Policy mu Mean               -0.113797665
Policy mu Std                1.384747
Policy mu Max                3.8572764
Policy mu Min                -3.3381004
Policy log std Mean          -0.89506227
Policy log std Std           0.5261324
Policy log std Max           -0.08887094
Policy log std Min           -3.7161832
Z mean eval                  3.9072633
Z variance eval              0.016109997
total_rewards                [11462.89839964 11750.70633585 11751.60027748 11397.48300909
 11700.75345506 11524.0934688  11502.84476788 11510.07961825
 11736.48049096 11708.54524218]
total_rewards_mean           11604.548506518226
total_rewards_std            130.05575861370406
total_rewards_max            11751.600277476591
total_rewards_min            11397.483009094325
Number of train steps total  1172000
Number of env steps total    1467000
Number of rollouts total     0
Train Time (s)               138.45673574740067
(Previous) Eval Time (s)     28.309089051093906
Sample Time (s)              19.634030760265887
Epoch Time (s)               186.39985555876046
Total Train Time (s)         53511.68219159404
Epoch                        292
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:39:35.968485 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #292 | Epoch Duration: 187.34504652023315
2020-01-13 19:39:35.968671 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #292 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.906819
Z variance train             0.016079072
KL Divergence                60.27288
KL Loss                      6.027288
QF Loss                      531.7467
VF Loss                      143.06174
Policy Loss                  -4745.6143
Q Predictions Mean           4747.4375
Q Predictions Std            542.3172
Q Predictions Max            5424.9067
Q Predictions Min            3238.5244
V Predictions Mean           4745.984
V Predictions Std            542.2014
V Predictions Max            5408.7744
V Predictions Min            3239.4314
Log Pis Mean                 5.1632576
Log Pis Std                  3.8200145
Log Pis Max                  15.324512
Log Pis Min                  -3.787013
Policy mu Mean               -0.03663818
Policy mu Std                1.3871305
Policy mu Max                2.8172874
Policy mu Min                -2.9913015
Policy log std Mean          -0.86521506
Policy log std Std           0.47755983
Policy log std Max           0.00059628487
Policy log std Min           -3.7127779
Z mean eval                  3.9705834
Z variance eval              0.017772887
total_rewards                [11498.31193508 11858.84213218 12103.50108391 11775.35959227
 11850.37168368 11693.96195332 11818.611166   11843.10337702
  3804.65868109 11776.4848264 ]
total_rewards_mean           11002.320643094303
total_rewards_std            2403.46200298805
total_rewards_max            12103.501083907
total_rewards_min            3804.6586810889366
Number of train steps total  1176000
Number of env steps total    1472000
Number of rollouts total     0
Train Time (s)               137.17271687602624
(Previous) Eval Time (s)     29.25414831424132
Sample Time (s)              21.730665170121938
Epoch Time (s)               188.1575303603895
Total Train Time (s)         53699.125207248144
Epoch                        293
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:42:43.415116 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #293 | Epoch Duration: 187.4462993144989
2020-01-13 19:42:43.415400 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #293 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9752297
Z variance train             0.01777575
KL Divergence                59.23913
KL Loss                      5.923913
QF Loss                      468.91452
VF Loss                      327.8722
Policy Loss                  -4821.487
Q Predictions Mean           4820.671
Q Predictions Std            527.7221
Q Predictions Max            5468.235
Q Predictions Min            3300.4758
V Predictions Mean           4805.974
V Predictions Std            526.4851
V Predictions Max            5433.2534
V Predictions Min            3289.8916
Log Pis Mean                 5.954878
Log Pis Std                  4.0416374
Log Pis Max                  15.393417
Log Pis Min                  -3.1980972
Policy mu Mean               -0.054262605
Policy mu Std                1.419216
Policy mu Max                2.9850488
Policy mu Min                -2.7804284
Policy log std Mean          -0.8727982
Policy log std Std           0.50513375
Policy log std Max           -0.034783304
Policy log std Min           -3.637429
Z mean eval                  3.9309902
Z variance eval              0.013889426
total_rewards                [11810.72785812 11839.61819579 10944.26330806 11690.45248652
 11613.65884381 11786.36496913 11959.94529787 12000.63382622
  5888.38665286 11960.57906608]
total_rewards_mean           11149.463050446513
total_rewards_std            1777.292625829777
total_rewards_max            12000.633826219953
total_rewards_min            5888.386652861646
Number of train steps total  1180000
Number of env steps total    1477000
Number of rollouts total     0
Train Time (s)               131.2985530057922
(Previous) Eval Time (s)     28.542492337990552
Sample Time (s)              22.61732568172738
Epoch Time (s)               182.45837102551013
Total Train Time (s)         53880.066732751206
Epoch                        294
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:45:44.360002 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #294 | Epoch Duration: 180.94445276260376
2020-01-13 19:45:44.360195 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #294 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9313254
Z variance train             0.013887523
KL Divergence                57.555183
KL Loss                      5.7555184
QF Loss                      423.99567
VF Loss                      133.65172
Policy Loss                  -4777.407
Q Predictions Mean           4779.3022
Q Predictions Std            497.81577
Q Predictions Max            5460.799
Q Predictions Min            3238.3408
V Predictions Mean           4768.949
V Predictions Std            497.0534
V Predictions Max            5453.8413
V Predictions Min            3228.2375
Log Pis Mean                 5.449639
Log Pis Std                  3.9963782
Log Pis Max                  16.780968
Log Pis Min                  -7.807067
Policy mu Mean               -0.08494806
Policy mu Std                1.3844758
Policy mu Max                2.9885955
Policy mu Min                -3.1977825
Policy log std Mean          -0.86829424
Policy log std Std           0.48620155
Policy log std Max           -0.17524415
Policy log std Min           -3.63247
Z mean eval                  3.9748855
Z variance eval              0.031894606
total_rewards                [11713.62740039 11378.58273358 11806.71699575  7982.73300383
 11542.14956401 11624.44594836 11983.78230756 11794.29154245
 11817.54115765 11618.95674233]
total_rewards_mean           11326.282739590108
total_rewards_std            1125.9104625663283
total_rewards_max            11983.782307558648
total_rewards_min            7982.733003833257
Number of train steps total  1184000
Number of env steps total    1482000
Number of rollouts total     0
Train Time (s)               130.5865186699666
(Previous) Eval Time (s)     27.02818257221952
Sample Time (s)              22.464269111398607
Epoch Time (s)               180.07897035358474
Total Train Time (s)         54061.03438686021
Epoch                        295
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:48:45.331371 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #295 | Epoch Duration: 180.97101736068726
2020-01-13 19:48:45.331635 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #295 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9731336
Z variance train             0.031892434
KL Divergence                56.763313
KL Loss                      5.6763315
QF Loss                      406.36993
VF Loss                      216.15805
Policy Loss                  -4658.585
Q Predictions Mean           4667.6387
Q Predictions Std            580.8492
Q Predictions Max            5367.581
Q Predictions Min            573.6849
V Predictions Mean           4666.828
V Predictions Std            578.74286
V Predictions Max            5360.931
V Predictions Min            674.1307
Log Pis Mean                 5.067889
Log Pis Std                  3.815605
Log Pis Max                  14.836706
Log Pis Min                  -5.9235997
Policy mu Mean               -0.11325189
Policy mu Std                1.3611015
Policy mu Max                3.064146
Policy mu Min                -2.5675137
Policy log std Mean          -0.87730426
Policy log std Std           0.48094022
Policy log std Max           -0.19823015
Policy log std Min           -3.678682
Z mean eval                  3.962497
Z variance eval              0.00921149
total_rewards                [10894.097836   11256.94051491 10880.23576293 11090.03755172
 11026.95125552 11506.00874546 11085.26430446 11152.27225905
 10886.9075787  11012.97991074]
total_rewards_mean           11079.169571949084
total_rewards_std            183.62792693423518
total_rewards_max            11506.008745459954
total_rewards_min            10880.235762930814
Number of train steps total  1188000
Number of env steps total    1487000
Number of rollouts total     0
Train Time (s)               134.72355681937188
(Previous) Eval Time (s)     27.919874015264213
Sample Time (s)              21.0992424772121
Epoch Time (s)               183.7426733118482
Total Train Time (s)         54245.36686989991
Epoch                        296
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:51:49.666943 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #296 | Epoch Duration: 184.3351490497589
2020-01-13 19:51:49.667125 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #296 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9602215
Z variance train             0.009187887
KL Divergence                59.528477
KL Loss                      5.952848
QF Loss                      647.962
VF Loss                      706.32947
Policy Loss                  -4835.2246
Q Predictions Mean           4846.696
Q Predictions Std            532.8053
Q Predictions Max            5585.939
Q Predictions Min            3339.9824
V Predictions Mean           4859.3433
V Predictions Std            535.8478
V Predictions Max            5594.9604
V Predictions Min            3348.035
Log Pis Mean                 5.8864965
Log Pis Std                  3.6646256
Log Pis Max                  14.299271
Log Pis Min                  -5.1896486
Policy mu Mean               -0.052120507
Policy mu Std                1.4349285
Policy mu Max                2.8870094
Policy mu Min                -2.913713
Policy log std Mean          -0.8772054
Policy log std Std           0.49318293
Policy log std Max           -0.19792971
Policy log std Min           -3.3993979
Z mean eval                  3.9723816
Z variance eval              0.007911614
total_rewards                [11346.84521857 11854.50855279 11785.50188886 11664.97120209
  6649.40188669 11795.31732007 11565.88488023 11413.24945391
 11681.76634463 11841.98080361]
total_rewards_mean           11159.942755145543
total_rewards_std            1512.5753189348716
total_rewards_max            11854.508552790368
total_rewards_min            6649.401886689984
Number of train steps total  1192000
Number of env steps total    1492000
Number of rollouts total     0
Train Time (s)               139.79319038102403
(Previous) Eval Time (s)     28.51203554496169
Sample Time (s)              21.2509936504066
Epoch Time (s)               189.55621957639232
Total Train Time (s)         54434.39733211743
Epoch                        297
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:54:58.701277 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #297 | Epoch Duration: 189.03394269943237
2020-01-13 19:54:58.701522 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #297 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9716582
Z variance train             0.0079309605
KL Divergence                60.623955
KL Loss                      6.0623956
QF Loss                      549.4878
VF Loss                      258.94235
Policy Loss                  -4760.379
Q Predictions Mean           4765.9087
Q Predictions Std            569.0339
Q Predictions Max            5522.331
Q Predictions Min            1335.871
V Predictions Mean           4765.658
V Predictions Std            565.25055
V Predictions Max            5518.856
V Predictions Min            1496.1053
Log Pis Mean                 5.4678707
Log Pis Std                  4.0098777
Log Pis Max                  15.594856
Log Pis Min                  -5.151748
Policy mu Mean               -0.024415933
Policy mu Std                1.420254
Policy mu Max                3.3031075
Policy mu Min                -3.889675
Policy log std Mean          -0.8763847
Policy log std Std           0.47109678
Policy log std Max           -0.17276493
Policy log std Min           -3.3861117
Z mean eval                  3.958184
Z variance eval              0.007877432
total_rewards                [11650.99552589 11680.8687861  11851.3905298  11910.50971897
 12005.21080888 11778.68914373 11872.00083979 11667.80040175
 11894.30298806 11638.57327686]
total_rewards_mean           11795.034201983903
total_rewards_std            122.95507161319587
total_rewards_max            12005.210808876569
total_rewards_min            11638.573276864034
Number of train steps total  1196000
Number of env steps total    1497000
Number of rollouts total     0
Train Time (s)               137.97143573313951
(Previous) Eval Time (s)     27.989406656939536
Sample Time (s)              22.761966485064477
Epoch Time (s)               188.72280887514353
Total Train Time (s)         54623.2624674174
Epoch                        298
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:58:07.567521 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #298 | Epoch Duration: 188.86587572097778
2020-01-13 19:58:07.567642 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #298 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9589005
Z variance train             0.007873466
KL Divergence                60.16086
KL Loss                      6.016086
QF Loss                      937.23047
VF Loss                      282.47318
Policy Loss                  -4767.616
Q Predictions Mean           4772.4795
Q Predictions Std            532.26733
Q Predictions Max            5441.0664
Q Predictions Min            3228.365
V Predictions Mean           4764.049
V Predictions Std            530.77356
V Predictions Max            5450.009
V Predictions Min            3220.8923
Log Pis Mean                 5.5747547
Log Pis Std                  4.0355644
Log Pis Max                  16.623714
Log Pis Min                  -4.1488514
Policy mu Mean               -0.051822186
Policy mu Std                1.4093775
Policy mu Max                3.062616
Policy mu Min                -2.7181501
Policy log std Mean          -0.88778144
Policy log std Std           0.53723365
Policy log std Max           -0.045831084
Policy log std Min           -3.5006042
Z mean eval                  3.9834342
Z variance eval              0.012965096
total_rewards                [10957.61950326 11288.57424131 11275.18821333 11039.82696555
 11411.7916977  11116.10368904 11017.89386652 11488.5214058
 11217.41701348 11130.76943222]
total_rewards_mean           11194.37060282058
total_rewards_std            164.6156894785024
total_rewards_max            11488.521405797816
total_rewards_min            10957.619503255748
Number of train steps total  1200000
Number of env steps total    1502000
Number of rollouts total     0
Train Time (s)               139.10345608415082
(Previous) Eval Time (s)     28.13213739404455
Sample Time (s)              20.176068580709398
Epoch Time (s)               187.41166205890477
Total Train Time (s)         54811.661616939586
Epoch                        299
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:01:15.970673 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #299 | Epoch Duration: 188.40292644500732
2020-01-13 20:01:15.970858 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #299 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.982263
Z variance train             0.012996016
KL Divergence                58.8817
KL Loss                      5.88817
QF Loss                      410.74316
VF Loss                      185.75008
Policy Loss                  -4864.498
Q Predictions Mean           4872.583
Q Predictions Std            470.3238
Q Predictions Max            5438.8384
Q Predictions Min            3268.6277
V Predictions Mean           4869.325
V Predictions Std            470.11124
V Predictions Max            5445.805
V Predictions Min            3264.4333
Log Pis Mean                 5.8071237
Log Pis Std                  4.080826
Log Pis Max                  17.721266
Log Pis Min                  -6.2269697
Policy mu Mean               -0.072086886
Policy mu Std                1.4176832
Policy mu Max                3.2477496
Policy mu Min                -3.0789907
Policy log std Mean          -0.88384795
Policy log std Std           0.4981892
Policy log std Max           -0.11743379
Policy log std Min           -3.3149576
Z mean eval                  3.973692
Z variance eval              0.01147933
total_rewards                [10196.2472322  11645.81575905 10991.78775067 10503.54796886
  9767.73018956 11467.34065386 10231.04568706  9633.44589446
 10376.35646215 10355.72366058]
total_rewards_mean           10516.904125843143
total_rewards_std            630.5150771769182
total_rewards_max            11645.815759051047
total_rewards_min            9633.445894459128
Number of train steps total  1204000
Number of env steps total    1507000
Number of rollouts total     0
Train Time (s)               137.88676949264482
(Previous) Eval Time (s)     29.123063523322344
Sample Time (s)              22.76961999805644
Epoch Time (s)               189.7794530140236
Total Train Time (s)         55000.267753932625
Epoch                        300
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:04:24.580494 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #300 | Epoch Duration: 188.60949420928955
2020-01-13 20:04:24.580694 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #300 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.979112
Z variance train             0.011359514
KL Divergence                59.364502
KL Loss                      5.9364505
QF Loss                      630.901
VF Loss                      171.63338
Policy Loss                  -4822.215
Q Predictions Mean           4827.5845
Q Predictions Std            516.2805
Q Predictions Max            5479.6885
Q Predictions Min            3310.6492
V Predictions Mean           4820.2607
V Predictions Std            516.7975
V Predictions Max            5484.0737
V Predictions Min            3302.5261
Log Pis Mean                 5.2845125
Log Pis Std                  3.9086554
Log Pis Max                  14.280534
Log Pis Min                  -2.7625823
Policy mu Mean               -0.0019306758
Policy mu Std                1.4035614
Policy mu Max                2.9465194
Policy mu Min                -2.819248
Policy log std Mean          -0.859747
Policy log std Std           0.46100706
Policy log std Max           -0.101157784
Policy log std Min           -3.2783742
Z mean eval                  3.9793694
Z variance eval              0.017270371
total_rewards                [11258.31991469 11133.5299223  11560.38610889 11301.0959583
  2897.80729117  2825.69220516 10808.90477054 11188.42363862
 10213.03176098 10921.09299307]
total_rewards_mean           9410.828456371546
total_rewards_std            3292.3698095730238
total_rewards_max            11560.386108885952
total_rewards_min            2825.6922051583583
Number of train steps total  1208000
Number of env steps total    1512000
Number of rollouts total     0
Train Time (s)               130.8465008130297
(Previous) Eval Time (s)     27.952732350677252
Sample Time (s)              20.169555502012372
Epoch Time (s)               178.96878866571933
Total Train Time (s)         55178.24007326644
Epoch                        301
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:07:22.554251 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #301 | Epoch Duration: 177.9734342098236
2020-01-13 20:07:22.554373 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #301 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9804497
Z variance train             0.017273534
KL Divergence                57.6053
KL Loss                      5.76053
QF Loss                      2362.6924
VF Loss                      1026.8356
Policy Loss                  -4762.6934
Q Predictions Mean           4764.825
Q Predictions Std            662.7563
Q Predictions Max            5459.198
Q Predictions Min            717.2036
V Predictions Mean           4753.8613
V Predictions Std            660.7599
V Predictions Max            5442.7104
V Predictions Min            697.7629
Log Pis Mean                 5.412733
Log Pis Std                  4.231834
Log Pis Max                  30.121996
Log Pis Min                  -3.264111
Policy mu Mean               -0.06691224
Policy mu Std                1.4492918
Policy mu Max                7.3483377
Policy mu Min                -4.6778636
Policy log std Mean          -0.85454243
Policy log std Std           0.4629627
Policy log std Max           0.5331669
Policy log std Min           -3.502215
Z mean eval                  4.0018997
Z variance eval              0.010319748
total_rewards                [11182.14029323 11685.15642971 11055.27032171 11664.42481002
 11333.48332651 11435.98904218 11550.24072138 11454.90431201
 11554.16388719 11632.67441599]
total_rewards_mean           11454.84475599222
total_rewards_std            199.16498806284383
total_rewards_max            11685.15642971048
total_rewards_min            11055.270321712766
Number of train steps total  1212000
Number of env steps total    1517000
Number of rollouts total     0
Train Time (s)               130.61258661095053
(Previous) Eval Time (s)     26.95712548168376
Sample Time (s)              21.875623575411737
Epoch Time (s)               179.44533566804603
Total Train Time (s)         55358.92935345648
Epoch                        302
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:10:23.247696 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #302 | Epoch Duration: 180.6932201385498
2020-01-13 20:10:23.247882 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #302 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.001006
Z variance train             0.010329632
KL Divergence                60.23758
KL Loss                      6.023758
QF Loss                      747.5137
VF Loss                      118.21228
Policy Loss                  -4815.645
Q Predictions Mean           4822.0693
Q Predictions Std            537.5205
Q Predictions Max            5475.773
Q Predictions Min            3341.702
V Predictions Mean           4817.747
V Predictions Std            536.4454
V Predictions Max            5465.368
V Predictions Min            3340.2336
Log Pis Mean                 5.8875027
Log Pis Std                  3.9350717
Log Pis Max                  16.207188
Log Pis Min                  -3.5168185
Policy mu Mean               -0.120147824
Policy mu Std                1.4244112
Policy mu Max                2.7789707
Policy mu Min                -2.6419814
Policy log std Mean          -0.8814854
Policy log std Std           0.5165368
Policy log std Max           -0.18755257
Policy log std Min           -3.5094361
Z mean eval                  4.004996
Z variance eval              0.006911649
total_rewards                [11402.0278382  11351.79035266 11509.53832238 11186.20085616
 11290.25260511 11208.19557407 11372.29874444 11446.50157019
 11493.85144233 11392.30746901]
total_rewards_mean           11365.29647745677
total_rewards_std            104.22288989040577
total_rewards_max            11509.538322381972
total_rewards_min            11186.200856164793
Number of train steps total  1216000
Number of env steps total    1522000
Number of rollouts total     0
Train Time (s)               134.75670744897798
(Previous) Eval Time (s)     28.20467194216326
Sample Time (s)              22.16453023906797
Epoch Time (s)               185.1259096302092
Total Train Time (s)         55544.18331137439
Epoch                        303
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:13:28.505376 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #303 | Epoch Duration: 185.25735926628113
2020-01-13 20:13:28.505555 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #303 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.0112076
Z variance train             0.0071328096
KL Divergence                61.82629
KL Loss                      6.182629
QF Loss                      541.00714
VF Loss                      163.47617
Policy Loss                  -4813.8794
Q Predictions Mean           4815.942
Q Predictions Std            538.1227
Q Predictions Max            5490.6694
Q Predictions Min            3294.6738
V Predictions Mean           4813.353
V Predictions Std            536.88696
V Predictions Max            5463.2725
V Predictions Min            3306.3398
Log Pis Mean                 5.665958
Log Pis Std                  3.6147761
Log Pis Max                  15.632826
Log Pis Min                  -2.9999743
Policy mu Mean               -0.0923498
Policy mu Std                1.4172472
Policy mu Max                2.8838894
Policy mu Min                -2.8577995
Policy log std Mean          -0.8751426
Policy log std Std           0.49409175
Policy log std Max           0.06652892
Policy log std Min           -3.294428
Z mean eval                  3.9682395
Z variance eval              0.0035823844
total_rewards                [11273.48455395 11402.5280225  11199.56635009 11670.90838167
 11354.53499309 11565.95379192 11725.52845005 11060.58505627
 11170.593116    8974.58762993]
total_rewards_mean           11139.827034546586
total_rewards_std            750.9134115049449
total_rewards_max            11725.528450049198
total_rewards_min            8974.587629928807
Number of train steps total  1220000
Number of env steps total    1527000
Number of rollouts total     0
Train Time (s)               139.39867999078706
(Previous) Eval Time (s)     28.335792040918022
Sample Time (s)              22.63897630944848
Epoch Time (s)               190.37344834115356
Total Train Time (s)         55734.842375582084
Epoch                        304
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:16:39.167543 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #304 | Epoch Duration: 190.6618468761444
2020-01-13 20:16:39.167739 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #304 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9667485
Z variance train             0.0035849046
KL Divergence                61.741684
KL Loss                      6.1741686
QF Loss                      757.235
VF Loss                      107.99733
Policy Loss                  -4794.9434
Q Predictions Mean           4797.467
Q Predictions Std            546.7733
Q Predictions Max            5413.319
Q Predictions Min            3267.7273
V Predictions Mean           4795.1465
V Predictions Std            546.32776
V Predictions Max            5400.958
V Predictions Min            3272.284
Log Pis Mean                 5.8723907
Log Pis Std                  3.9579744
Log Pis Max                  17.27801
Log Pis Min                  -6.9495745
Policy mu Mean               -0.026047632
Policy mu Std                1.4378008
Policy mu Max                3.1918204
Policy mu Min                -3.1380053
Policy log std Mean          -0.8603525
Policy log std Std           0.4705736
Policy log std Max           -0.12928969
Policy log std Min           -3.75174
Z mean eval                  3.99692
Z variance eval              0.008523742
total_rewards                [12003.87026412 11584.34821639 12016.87829288 12072.16826555
 12050.28054589 12095.18964157 12022.06920105 12055.80694852
 11834.24331911 12014.27656063]
total_rewards_mean           11974.913125570009
total_rewards_std            146.57788732893678
total_rewards_max            12095.189641566541
total_rewards_min            11584.34821638956
Number of train steps total  1224000
Number of env steps total    1532000
Number of rollouts total     0
Train Time (s)               138.47825846914202
(Previous) Eval Time (s)     28.623835970181972
Sample Time (s)              23.23150997282937
Epoch Time (s)               190.33360441215336
Total Train Time (s)         55922.72126035672
Epoch                        305
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:19:47.049563 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #305 | Epoch Duration: 187.88168668746948
2020-01-13 20:19:47.049750 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #305 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9988906
Z variance train             0.008515368
KL Divergence                62.458393
KL Loss                      6.2458396
QF Loss                      657.26074
VF Loss                      284.96573
Policy Loss                  -4763.486
Q Predictions Mean           4765.9023
Q Predictions Std            552.23004
Q Predictions Max            5464.5586
Q Predictions Min            3224.6516
V Predictions Mean           4755.582
V Predictions Std            553.96106
V Predictions Max            5445.4883
V Predictions Min            3213.8
Log Pis Mean                 5.4836745
Log Pis Std                  3.857845
Log Pis Max                  14.916649
Log Pis Min                  -6.709651
Policy mu Mean               -0.04288855
Policy mu Std                1.4013771
Policy mu Max                2.9551482
Policy mu Min                -3.0143468
Policy log std Mean          -0.87623185
Policy log std Std           0.4875471
Policy log std Max           -0.052004874
Policy log std Min           -3.5027382
Z mean eval                  4.0089583
Z variance eval              0.0081487745
total_rewards                [11919.19461474 11489.94855116 12014.82393545 12071.33910805
 12026.08261668  5770.84584803 12295.05607133 11782.87552107
 12103.69609129 11662.07360409]
total_rewards_mean           11313.593596188148
total_rewards_std            1860.7160853037929
total_rewards_max            12295.056071328076
total_rewards_min            5770.845848030757
Number of train steps total  1228000
Number of env steps total    1537000
Number of rollouts total     0
Train Time (s)               140.0082949111238
(Previous) Eval Time (s)     26.17148756235838
Sample Time (s)              22.943434230983257
Epoch Time (s)               189.12321670446545
Total Train Time (s)         56112.22385432944
Epoch                        306
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:22:56.556036 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #306 | Epoch Duration: 189.50614476203918
2020-01-13 20:22:56.556266 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #306 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.0084534
Z variance train             0.008143556
KL Divergence                62.4833
KL Loss                      6.24833
QF Loss                      511.1527
VF Loss                      127.271
Policy Loss                  -4817.498
Q Predictions Mean           4817.741
Q Predictions Std            604.7222
Q Predictions Max            5507.4834
Q Predictions Min            537.36084
V Predictions Mean           4820.3
V Predictions Std            604.01105
V Predictions Max            5500.404
V Predictions Min            555.80066
Log Pis Mean                 5.412084
Log Pis Std                  4.3153996
Log Pis Max                  32.393246
Log Pis Min                  -5.979575
Policy mu Mean               -0.0441785
Policy mu Std                1.4098039
Policy mu Max                5.283927
Policy mu Min                -5.184264
Policy log std Mean          -0.86136574
Policy log std Std           0.47823593
Policy log std Max           0.30513918
Policy log std Min           -3.548254
Z mean eval                  4.0250845
Z variance eval              0.01360969
total_rewards                [11605.14751442 11891.74678689 11837.57239841 11741.08390127
 11709.51453265 11656.54949464 11724.37559267 11816.68353706
  2538.91274357 11577.8037707 ]
total_rewards_mean           10809.939027226208
total_rewards_std            2758.639734580187
total_rewards_max            11891.746786889205
total_rewards_min            2538.912743565549
Number of train steps total  1232000
Number of env steps total    1542000
Number of rollouts total     0
Train Time (s)               138.96966443117708
(Previous) Eval Time (s)     26.55402649892494
Sample Time (s)              22.764897109940648
Epoch Time (s)               188.28858804004267
Total Train Time (s)         56301.87061612727
Epoch                        307
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:26:06.206293 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #307 | Epoch Duration: 189.6498692035675
2020-01-13 20:26:06.206516 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #307 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.027256
Z variance train             0.013659256
KL Divergence                61.535065
KL Loss                      6.1535068
QF Loss                      364.06354
VF Loss                      168.89047
Policy Loss                  -4806.214
Q Predictions Mean           4806.9434
Q Predictions Std            582.7171
Q Predictions Max            5524.9497
Q Predictions Min            797.70013
V Predictions Mean           4797.8975
V Predictions Std            583.4664
V Predictions Max            5513.276
V Predictions Min            736.4096
Log Pis Mean                 5.651759
Log Pis Std                  3.8122928
Log Pis Max                  15.228725
Log Pis Min                  -4.135307
Policy mu Mean               -0.04050869
Policy mu Std                1.3931307
Policy mu Max                3.9470286
Policy mu Min                -2.8623362
Policy log std Mean          -0.8791129
Policy log std Std           0.49140924
Policy log std Max           0.16559589
Policy log std Min           -3.5097961
Z mean eval                  4.0278773
Z variance eval              0.005486115
total_rewards                [11516.05945833  4039.50043842 11862.9796096  11943.62095531
 11836.20196139 11781.50458884 11916.85376224 11759.7432596
 12057.40350494 11932.87548339]
total_rewards_mean           11064.674302206242
total_rewards_std            2345.7274094785057
total_rewards_max            12057.403504942436
total_rewards_min            4039.5004384172244
Number of train steps total  1236000
Number of env steps total    1547000
Number of rollouts total     0
Train Time (s)               130.91152927698568
(Previous) Eval Time (s)     27.914931051898748
Sample Time (s)              21.68945098714903
Epoch Time (s)               180.51591131603345
Total Train Time (s)         56481.51464326633
Epoch                        308
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:29:05.854175 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #308 | Epoch Duration: 179.64751434326172
2020-01-13 20:29:05.854376 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #308 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.0330477
Z variance train             0.005480716
KL Divergence                62.185623
KL Loss                      6.2185626
QF Loss                      507.76373
VF Loss                      265.08414
Policy Loss                  -4828.629
Q Predictions Mean           4828.996
Q Predictions Std            515.8791
Q Predictions Max            5506.7427
Q Predictions Min            3322.7195
V Predictions Mean           4822.762
V Predictions Std            510.5767
V Predictions Max            5505.612
V Predictions Min            3309.874
Log Pis Mean                 5.436307
Log Pis Std                  3.6968367
Log Pis Max                  16.065598
Log Pis Min                  -4.757351
Policy mu Mean               -0.10086436
Policy mu Std                1.3792094
Policy mu Max                2.8806956
Policy mu Min                -3.0745573
Policy log std Mean          -0.890093
Policy log std Std           0.4923552
Policy log std Max           -0.16037327
Policy log std Min           -3.5558367
Z mean eval                  4.0020456
Z variance eval              0.0065452196
total_rewards                [11733.47791201 11941.01787777 11901.11553668 11954.23852971
 12251.77215771 12099.66469386 12229.33360466 12017.30132397
 11991.50879765 11896.12376964]
total_rewards_mean           12001.555420366718
total_rewards_std            149.47871100894648
total_rewards_max            12251.772157714096
total_rewards_min            11733.477912005379
Number of train steps total  1240000
Number of env steps total    1552000
Number of rollouts total     0
Train Time (s)               131.0103713949211
(Previous) Eval Time (s)     27.046226398088038
Sample Time (s)              21.961147013586015
Epoch Time (s)               180.01774480659515
Total Train Time (s)         56661.8992147618
Epoch                        309
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:32:06.242109 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #309 | Epoch Duration: 180.38758969306946
2020-01-13 20:32:06.242361 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #309 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.001473
Z variance train             0.006547096
KL Divergence                61.20998
KL Loss                      6.120998
QF Loss                      748.5283
VF Loss                      230.26659
Policy Loss                  -4861.866
Q Predictions Mean           4871.5605
Q Predictions Std            509.80386
Q Predictions Max            5500.238
Q Predictions Min            3263.5933
V Predictions Mean           4861.71
V Predictions Std            507.34225
V Predictions Max            5485.7046
V Predictions Min            3263.3955
Log Pis Mean                 5.839771
Log Pis Std                  4.2136693
Log Pis Max                  19.641336
Log Pis Min                  -6.0168
Policy mu Mean               -0.05935855
Policy mu Std                1.4361348
Policy mu Max                3.1652741
Policy mu Min                -3.101008
Policy log std Mean          -0.88717073
Policy log std Std           0.49681363
Policy log std Max           -0.19057223
Policy log std Min           -3.4335098
Z mean eval                  3.979342
Z variance eval              0.00559651
total_rewards                [11551.18950787 11810.64706281 11972.96087412 11861.99990057
 12014.55508223  6999.73819285 12043.70770011 12010.71150625
 11985.34417454 11814.90881687]
total_rewards_mean           11406.576281822434
total_rewards_std            1475.6311216091613
total_rewards_max            12043.707700106825
total_rewards_min            6999.738192853428
Number of train steps total  1244000
Number of env steps total    1557000
Number of rollouts total     0
Train Time (s)               137.43121022265404
(Previous) Eval Time (s)     27.415743614081293
Sample Time (s)              20.558085268829018
Epoch Time (s)               185.40503910556436
Total Train Time (s)         56848.85997514287
Epoch                        310
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:35:13.205958 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #310 | Epoch Duration: 186.96342182159424
2020-01-13 20:35:13.206244 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #310 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9804122
Z variance train             0.0056009656
KL Divergence                61.762505
KL Loss                      6.1762505
QF Loss                      772.3779
VF Loss                      133.18677
Policy Loss                  -4775.6094
Q Predictions Mean           4782.1816
Q Predictions Std            574.9864
Q Predictions Max            5488.584
Q Predictions Min            3257.4578
V Predictions Mean           4775.259
V Predictions Std            573.98553
V Predictions Max            5483.362
V Predictions Min            3248.9094
Log Pis Mean                 5.4642177
Log Pis Std                  3.8910794
Log Pis Max                  15.501919
Log Pis Min                  -4.2852254
Policy mu Mean               -0.047822043
Policy mu Std                1.4130613
Policy mu Max                2.8964448
Policy mu Min                -4.5119677
Policy log std Mean          -0.8757108
Policy log std Std           0.5058278
Policy log std Max           0.137074
Policy log std Min           -3.5267186
Z mean eval                  3.9762626
Z variance eval              0.02244727
total_rewards                [11464.73564684 11921.84006645 11633.91449678 11940.45602613
 12001.63984337 11673.53435927 12183.67243904 11542.99600154
 11833.35026435 11750.76199583]
total_rewards_mean           11794.690113959938
total_rewards_std            211.59440698332355
total_rewards_max            12183.672439044947
total_rewards_min            11464.73564684281
Number of train steps total  1248000
Number of env steps total    1562000
Number of rollouts total     0
Train Time (s)               139.22375296102837
(Previous) Eval Time (s)     28.973816267680377
Sample Time (s)              21.324802750255913
Epoch Time (s)               189.52237197896466
Total Train Time (s)         57036.57422604179
Epoch                        311
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:38:20.924167 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #311 | Epoch Duration: 187.71769976615906
2020-01-13 20:38:20.924378 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #311 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9773414
Z variance train             0.022458617
KL Divergence                60.011707
KL Loss                      6.0011706
QF Loss                      470.9282
VF Loss                      224.35303
Policy Loss                  -4768.2744
Q Predictions Mean           4768.4736
Q Predictions Std            542.0179
Q Predictions Max            5436.0684
Q Predictions Min            3243.6584
V Predictions Mean           4758.0903
V Predictions Std            541.3861
V Predictions Max            5427.7524
V Predictions Min            3234.2776
Log Pis Mean                 5.4907546
Log Pis Std                  3.54752
Log Pis Max                  15.025203
Log Pis Min                  -5.319002
Policy mu Mean               -0.05870567
Policy mu Std                1.392377
Policy mu Max                2.7771034
Policy mu Min                -2.6892798
Policy log std Mean          -0.90339047
Policy log std Std           0.5416043
Policy log std Max           -0.12979537
Policy log std Min           -3.7655787
Z mean eval                  3.9973617
Z variance eval              0.018861767
total_rewards                [11828.47196923 11873.74299025 11953.91257551 12000.51194115
 11954.65272116 11677.95715981 11555.72533559 11735.96238812
 11795.58795738 11933.32038613]
total_rewards_mean           11830.984542433409
total_rewards_std            134.5061412271916
total_rewards_max            12000.51194115238
total_rewards_min            11555.725335592939
Number of train steps total  1252000
Number of env steps total    1567000
Number of rollouts total     0
Train Time (s)               138.02613520808518
(Previous) Eval Time (s)     27.16876552067697
Sample Time (s)              22.375234545674175
Epoch Time (s)               187.57013527443632
Total Train Time (s)         57225.84871025989
Epoch                        312
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:41:30.202254 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #312 | Epoch Duration: 189.27772855758667
2020-01-13 20:41:30.202460 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #312 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9983933
Z variance train             0.018761853
KL Divergence                61.53914
KL Loss                      6.153914
QF Loss                      495.73575
VF Loss                      117.62647
Policy Loss                  -4698.1675
Q Predictions Mean           4706.731
Q Predictions Std            639.60297
Q Predictions Max            5393.0337
Q Predictions Min            844.25507
V Predictions Mean           4694.201
V Predictions Std            637.29205
V Predictions Max            5395.6006
V Predictions Min            856.76825
Log Pis Mean                 4.950375
Log Pis Std                  3.8236005
Log Pis Max                  15.458715
Log Pis Min                  -4.9988356
Policy mu Mean               -0.054830316
Policy mu Std                1.3579609
Policy mu Max                2.8544548
Policy mu Min                -2.8554115
Policy log std Mean          -0.8844666
Policy log std Std           0.49014485
Policy log std Max           -0.014079213
Policy log std Min           -3.630493
Z mean eval                  4.0050707
Z variance eval              0.008530477
total_rewards                [11754.44369869 11844.66108625 11922.26606348 11669.15504136
 11956.02718794 11961.889281   12008.58550514 11603.12778992
 11937.72725303 11722.63246339]
total_rewards_mean           11838.051537020514
total_rewards_std            133.95294796426577
total_rewards_max            12008.585505138552
total_rewards_min            11603.127789916844
Number of train steps total  1256000
Number of env steps total    1572000
Number of rollouts total     0
Train Time (s)               140.35462194494903
(Previous) Eval Time (s)     28.875989139080048
Sample Time (s)              22.80749742826447
Epoch Time (s)               192.03810851229355
Total Train Time (s)         57417.044787458144
Epoch                        313
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:44:41.402355 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #313 | Epoch Duration: 191.19973850250244
2020-01-13 20:44:41.402590 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #313 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.003737
Z variance train             0.008544091
KL Divergence                62.813972
KL Loss                      6.2813973
QF Loss                      717.6952
VF Loss                      127.910255
Policy Loss                  -4788.9165
Q Predictions Mean           4796.046
Q Predictions Std            604.9637
Q Predictions Max            5498.5664
Q Predictions Min            3294.5872
V Predictions Mean           4782.9116
V Predictions Std            600.9962
V Predictions Max            5474.6597
V Predictions Min            3295.4033
Log Pis Mean                 5.244239
Log Pis Std                  3.86364
Log Pis Max                  14.320879
Log Pis Min                  -4.7164984
Policy mu Mean               -0.1251927
Policy mu Std                1.3989903
Policy mu Max                2.9004524
Policy mu Min                -2.9108448
Policy log std Mean          -0.8875213
Policy log std Std           0.4980597
Policy log std Max           -0.085822344
Policy log std Min           -3.548275
Z mean eval                  3.9931827
Z variance eval              0.03920897
total_rewards                [11604.96426622 11749.26187546 11827.65955409  4512.48147698
 11729.87357406 11680.7960124  11624.47386282 11476.77912894
 11926.81593813  4346.51247953]
total_rewards_mean           10247.961816863193
total_rewards_std            2911.804360055522
total_rewards_max            11926.815938125586
total_rewards_min            4346.51247953298
Number of train steps total  1260000
Number of env steps total    1577000
Number of rollouts total     0
Train Time (s)               137.21044871211052
(Previous) Eval Time (s)     28.037229410838336
Sample Time (s)              22.671922295354307
Epoch Time (s)               187.91960041830316
Total Train Time (s)         57603.73910232028
Epoch                        314
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:47:48.105240 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #314 | Epoch Duration: 186.70249557495117
2020-01-13 20:47:48.105644 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #314 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9936645
Z variance train             0.039093643
KL Divergence                60.81671
KL Loss                      6.081671
QF Loss                      352.28864
VF Loss                      260.2847
Policy Loss                  -4818.5645
Q Predictions Mean           4822.4424
Q Predictions Std            537.1403
Q Predictions Max            5480.762
Q Predictions Min            3276.9573
V Predictions Mean           4809.5107
V Predictions Std            536.4967
V Predictions Max            5464.797
V Predictions Min            3265.8845
Log Pis Mean                 5.656967
Log Pis Std                  3.674364
Log Pis Max                  14.453295
Log Pis Min                  -2.9336944
Policy mu Mean               -0.06930846
Policy mu Std                1.387166
Policy mu Max                3.079593
Policy mu Min                -2.6405573
Policy log std Mean          -0.89634687
Policy log std Std           0.4789585
Policy log std Max           -0.28137678
Policy log std Min           -3.72617
Z mean eval                  4.0249634
Z variance eval              0.023819793
total_rewards                [11909.34219109 12189.15372138 12183.34102367 12335.42153835
 12234.89881142 11881.48500984 12402.8190606  12342.57630223
 11933.79663537 12142.07230593]
total_rewards_mean           12155.490659988198
total_rewards_std            179.37626740310225
total_rewards_max            12402.819060595684
total_rewards_min            11881.485009837772
Number of train steps total  1264000
Number of env steps total    1582000
Number of rollouts total     0
Train Time (s)               131.49963350500911
(Previous) Eval Time (s)     26.81975408969447
Sample Time (s)              22.209470342844725
Epoch Time (s)               180.5288579375483
Total Train Time (s)         57785.58106027171
Epoch                        315
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:50:49.945735 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #315 | Epoch Duration: 181.83978605270386
2020-01-13 20:50:49.946023 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #315 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.0259805
Z variance train             0.023785511
KL Divergence                62.460934
KL Loss                      6.2460933
QF Loss                      555.2903
VF Loss                      172.5489
Policy Loss                  -4859.3013
Q Predictions Mean           4863.1934
Q Predictions Std            593.21704
Q Predictions Max            5497.739
Q Predictions Min            875.4638
V Predictions Mean           4857.1206
V Predictions Std            592.32544
V Predictions Max            5490.9863
V Predictions Min            862.8445
Log Pis Mean                 5.8072224
Log Pis Std                  4.120777
Log Pis Max                  27.032742
Log Pis Min                  -3.638299
Policy mu Mean               -0.0984297
Policy mu Std                1.4143689
Policy mu Max                3.0976884
Policy mu Min                -4.7761436
Policy log std Mean          -0.8824807
Policy log std Std           0.5040654
Policy log std Max           0.12166107
Policy log std Min           -3.6584454
Z mean eval                  3.9774513
Z variance eval              0.036326706
total_rewards                [11999.2102946  12075.78658333 12030.23738101 12058.41649246
 12341.61471376 11700.2337154  11981.36283453 11750.21652199
 12166.84984732 11685.05046015]
total_rewards_mean           11978.897884453843
total_rewards_std            200.4868262271071
total_rewards_max            12341.614713755824
total_rewards_min            11685.050460149612
Number of train steps total  1268000
Number of env steps total    1587000
Number of rollouts total     0
Train Time (s)               131.7042046301067
(Previous) Eval Time (s)     28.13037518132478
Sample Time (s)              21.773197293281555
Epoch Time (s)               181.60777710471302
Total Train Time (s)         57967.32531985501
Epoch                        316
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:53:51.693158 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #316 | Epoch Duration: 181.74691605567932
2020-01-13 20:53:51.693331 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #316 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9786186
Z variance train             0.036119524
KL Divergence                58.9627
KL Loss                      5.8962703
QF Loss                      567.3743
VF Loss                      271.98987
Policy Loss                  -4765.0977
Q Predictions Mean           4767.762
Q Predictions Std            529.3735
Q Predictions Max            5480.177
Q Predictions Min            3188.1108
V Predictions Mean           4771.7827
V Predictions Std            526.7533
V Predictions Max            5493.0728
V Predictions Min            3200.7603
Log Pis Mean                 5.755802
Log Pis Std                  4.0024967
Log Pis Max                  25.692291
Log Pis Min                  -3.814079
Policy mu Mean               -0.097731926
Policy mu Std                1.4042917
Policy mu Max                3.7729917
Policy mu Min                -3.614348
Policy log std Mean          -0.9082448
Policy log std Std           0.5244074
Policy log std Max           0.20612621
Policy log std Min           -3.440609
Z mean eval                  4.0322685
Z variance eval              0.016020333
total_rewards                [11881.86388973 12326.19882726 12228.06529167 12209.25271622
 12553.55393171 12243.72175679 12115.47448971 11963.74822368
  7709.30331043 12537.00231962]
total_rewards_mean           11776.818475680333
total_rewards_std            1371.0208873769054
total_rewards_max            12553.553931707653
total_rewards_min            7709.303310430631
Number of train steps total  1272000
Number of env steps total    1592000
Number of rollouts total     0
Train Time (s)               138.11942033609375
(Previous) Eval Time (s)     28.269189585000277
Sample Time (s)              22.428702543023974
Epoch Time (s)               188.817312464118
Total Train Time (s)         58156.8756304821
Epoch                        317
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:57:01.247521 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #317 | Epoch Duration: 189.55405116081238
2020-01-13 20:57:01.247717 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #317 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.0299134
Z variance train             0.015984975
KL Divergence                60.760513
KL Loss                      6.076051
QF Loss                      559.9824
VF Loss                      236.58408
Policy Loss                  -4872.887
Q Predictions Mean           4879.51
Q Predictions Std            604.2636
Q Predictions Max            5592.978
Q Predictions Min            751.26776
V Predictions Mean           4882.616
V Predictions Std            604.2414
V Predictions Max            5616.848
V Predictions Min            738.2418
Log Pis Mean                 6.4239144
Log Pis Std                  3.9152882
Log Pis Max                  17.102692
Log Pis Min                  -4.6369343
Policy mu Mean               -0.034925226
Policy mu Std                1.467401
Policy mu Max                2.8415627
Policy mu Min                -2.9969802
Policy log std Mean          -0.89385796
Policy log std Std           0.51832575
Policy log std Max           0.0038226843
Policy log std Min           -3.573511
Z mean eval                  4.019793
Z variance eval              0.010789681
total_rewards                [10950.67147564 12051.22902984  7073.51239559 12149.34240055
 11643.7623627  11858.98291406 11983.39401685 12049.992154
 12183.48338818 12287.47388346]
total_rewards_mean           11423.184402087036
total_rewards_std            1494.4901849436276
total_rewards_max            12287.473883464447
total_rewards_min            7073.512395587311
Number of train steps total  1276000
Number of env steps total    1597000
Number of rollouts total     0
Train Time (s)               137.95255910186097
(Previous) Eval Time (s)     29.005579545162618
Sample Time (s)              23.549785365816206
Epoch Time (s)               190.5079240128398
Total Train Time (s)         58347.30873830756
Epoch                        318
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:00:11.684136 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #318 | Epoch Duration: 190.43627190589905
2020-01-13 21:00:11.684347 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #318 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.0206165
Z variance train             0.010768931
KL Divergence                61.085358
KL Loss                      6.108536
QF Loss                      1317.6897
VF Loss                      119.90065
Policy Loss                  -4787.5063
Q Predictions Mean           4792.4185
Q Predictions Std            607.2632
Q Predictions Max            5481.17
Q Predictions Min            1016.0222
V Predictions Mean           4783.7793
V Predictions Std            605.5021
V Predictions Max            5459.246
V Predictions Min            1008.38715
Log Pis Mean                 5.8585887
Log Pis Std                  3.8238099
Log Pis Max                  16.577225
Log Pis Min                  -6.1489053
Policy mu Mean               -0.14648418
Policy mu Std                1.4447241
Policy mu Max                3.942614
Policy mu Min                -3.8988595
Policy log std Mean          -0.87863785
Policy log std Std           0.4878485
Policy log std Max           0.18720281
Policy log std Min           -3.5687542
Z mean eval                  4.026427
Z variance eval              0.007932369
total_rewards                [11889.03561061  5805.75006898 11983.86705694 12283.34092748
 12354.13671266 12301.53337786 12172.93458983 12232.68523615
 11685.74007293 12270.0595345 ]
total_rewards_mean           11497.90831879395
total_rewards_std            1908.2112704812791
total_rewards_max            12354.136712659367
total_rewards_min            5805.750068983537
Number of train steps total  1280000
Number of env steps total    1602000
Number of rollouts total     0
Train Time (s)               137.31968075409532
(Previous) Eval Time (s)     28.933564029168338
Sample Time (s)              22.944537178147584
Epoch Time (s)               189.19778196141124
Total Train Time (s)         58535.66320678312
Epoch                        319
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:03:20.042346 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #319 | Epoch Duration: 188.35785579681396
2020-01-13 21:03:20.042544 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #319 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.0264244
Z variance train             0.007924767
KL Divergence                62.87919
KL Loss                      6.287919
QF Loss                      1090.925
VF Loss                      112.15678
Policy Loss                  -4818.364
Q Predictions Mean           4829.5166
Q Predictions Std            667.2819
Q Predictions Max            5559.949
Q Predictions Min            515.52716
V Predictions Mean           4822.4185
V Predictions Std            668.91766
V Predictions Max            5564.1353
V Predictions Min            492.42966
Log Pis Mean                 5.5624704
Log Pis Std                  3.881679
Log Pis Max                  16.688742
Log Pis Min                  -5.9325542
Policy mu Mean               -0.032227833
Policy mu Std                1.4109251
Policy mu Max                3.0122354
Policy mu Min                -2.7171066
Policy log std Mean          -0.8752465
Policy log std Std           0.4782075
Policy log std Max           -0.06355226
Policy log std Min           -3.437727
Z mean eval                  4.0481796
Z variance eval              0.007938707
total_rewards                [11453.88194439  6914.64664595 12093.02546051 11665.0946256
 11626.74930405 12030.94095535 11652.62692674 11651.7028159
 11866.59444093 12275.79477252]
total_rewards_mean           11323.105789194495
total_rewards_std            1489.0981663763644
total_rewards_max            12275.794772520014
total_rewards_min            6914.646645950316
Number of train steps total  1284000
Number of env steps total    1607000
Number of rollouts total     0
Train Time (s)               138.1806518388912
(Previous) Eval Time (s)     28.09320325218141
Sample Time (s)              23.13642737455666
Epoch Time (s)               189.41028246562928
Total Train Time (s)         58724.76681949897
Epoch                        320
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:06:29.150128 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #320 | Epoch Duration: 189.10741257667542
2020-01-13 21:06:29.150466 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #320 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.0464926
Z variance train             0.007975364
KL Divergence                61.37765
KL Loss                      6.1377654
QF Loss                      431.62177
VF Loss                      125.72075
Policy Loss                  -4803.724
Q Predictions Mean           4807.2866
Q Predictions Std            594.7291
Q Predictions Max            5498.0015
Q Predictions Min            733.2857
V Predictions Mean           4803.824
V Predictions Std            593.8995
V Predictions Max            5490.997
V Predictions Min            756.7741
Log Pis Mean                 5.5306153
Log Pis Std                  3.8639166
Log Pis Max                  17.397964
Log Pis Min                  -4.8852654
Policy mu Mean               -0.020711895
Policy mu Std                1.4289132
Policy mu Max                3.7148528
Policy mu Min                -3.9376898
Policy log std Mean          -0.88558984
Policy log std Std           0.49237615
Policy log std Max           0.35957086
Policy log std Min           -3.5325294
Z mean eval                  4.015504
Z variance eval              0.032420628
total_rewards                [ 2638.21269019 11414.27554285 11476.58599029  3551.7674729
  1741.64768641 11705.26079734  1092.79886008 11495.70162461
 11714.52107766 11526.79526006]
total_rewards_mean           7835.756700240481
total_rewards_std            4594.245804499055
total_rewards_max            11714.52107766425
total_rewards_min            1092.7988600840988
Number of train steps total  1288000
Number of env steps total    1612000
Number of rollouts total     0
Train Time (s)               135.0605338588357
(Previous) Eval Time (s)     27.789852156769484
Sample Time (s)              23.431528858374804
Epoch Time (s)               186.28191487397999
Total Train Time (s)         58910.23238610523
Epoch                        321
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:09:34.619384 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #321 | Epoch Duration: 185.4687328338623
2020-01-13 21:09:34.619611 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #321 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.018145
Z variance train             0.032218583
KL Divergence                57.6557
KL Loss                      5.76557
QF Loss                      481.4551
VF Loss                      170.16306
Policy Loss                  -4865.3354
Q Predictions Mean           4867.222
Q Predictions Std            555.534
Q Predictions Max            5537.3213
Q Predictions Min            3230.5269
V Predictions Mean           4856.3413
V Predictions Std            553.6442
V Predictions Max            5532.1963
V Predictions Min            3229.2827
Log Pis Mean                 5.641952
Log Pis Std                  3.7689512
Log Pis Max                  23.030155
Log Pis Min                  -2.8451567
Policy mu Mean               -0.06256778
Policy mu Std                1.4314134
Policy mu Max                3.2714639
Policy mu Min                -2.9562664
Policy log std Mean          -0.88408774
Policy log std Std           0.49311033
Policy log std Max           -0.18609798
Policy log std Min           -3.6013436
Z mean eval                  4.0160155
Z variance eval              0.04996109
total_rewards                [11644.13990632 12091.19859915 11847.60050782 12193.00759731
 12010.4643801  11983.32820366 11993.3141466  12105.20623067
 11776.71955866 12071.78685735]
total_rewards_mean           11971.676598764867
total_rewards_std            159.3477298374412
total_rewards_max            12193.007597307129
total_rewards_min            11644.139906322702
Number of train steps total  1292000
Number of env steps total    1617000
Number of rollouts total     0
Train Time (s)               130.6350483079441
(Previous) Eval Time (s)     26.976304408162832
Sample Time (s)              21.516717525199056
Epoch Time (s)               179.12807024130598
Total Train Time (s)         59088.69098649593
Epoch                        322
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:12:33.081312 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #322 | Epoch Duration: 178.46155285835266
2020-01-13 21:12:33.081509 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #322 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.017617
Z variance train             0.04981665
KL Divergence                57.569714
KL Loss                      5.7569714
QF Loss                      701.63684
VF Loss                      258.029
Policy Loss                  -4846.0977
Q Predictions Mean           4848.4287
Q Predictions Std            518.63306
Q Predictions Max            5446.7163
Q Predictions Min            3147.259
V Predictions Mean           4833.5684
V Predictions Std            517.07635
V Predictions Max            5415.453
V Predictions Min            3148.2505
Log Pis Mean                 6.1192436
Log Pis Std                  4.089452
Log Pis Max                  17.450197
Log Pis Min                  -5.243455
Policy mu Mean               -0.045428514
Policy mu Std                1.4663087
Policy mu Max                3.0672488
Policy mu Min                -2.9183083
Policy log std Mean          -0.91674185
Policy log std Std           0.5331838
Policy log std Max           -0.26413408
Policy log std Min           -3.5860453
Z mean eval                  4.0255675
Z variance eval              0.012617068
total_rewards                [ -259.60934918 11694.63441912 11946.92854785 12172.46447578
 12121.70619314 12187.63565207 12130.76352002  9067.61455473
 12277.3507486  11969.79462627]
total_rewards_mean           10530.92833884116
total_rewards_std            3709.258059048246
total_rewards_max            12277.350748603947
total_rewards_min            -259.60934917576833
Number of train steps total  1296000
Number of env steps total    1622000
Number of rollouts total     0
Train Time (s)               132.11795514496043
(Previous) Eval Time (s)     26.309445356950164
Sample Time (s)              21.72802892513573
Epoch Time (s)               180.15542942704633
Total Train Time (s)         59270.27754801046
Epoch                        323
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:15:34.672082 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #323 | Epoch Duration: 181.59042525291443
2020-01-13 21:15:34.672316 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #323 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.0254173
Z variance train             0.012616721
KL Divergence                59.814827
KL Loss                      5.981483
QF Loss                      825.72394
VF Loss                      128.58058
Policy Loss                  -4832.2344
Q Predictions Mean           4836.364
Q Predictions Std            639.3628
Q Predictions Max            5546.064
Q Predictions Min            461.07553
V Predictions Mean           4831.422
V Predictions Std            639.7604
V Predictions Max            5534.8154
V Predictions Min            459.06512
Log Pis Mean                 5.955917
Log Pis Std                  3.9126494
Log Pis Max                  15.16399
Log Pis Min                  -4.4723644
Policy mu Mean               -0.049316972
Policy mu Std                1.4485836
Policy mu Max                2.9105446
Policy mu Min                -2.887601
Policy log std Mean          -0.88560456
Policy log std Std           0.4901172
Policy log std Max           -0.036290526
Policy log std Min           -3.4001355
Z mean eval                  4.0128098
Z variance eval              0.010436122
total_rewards                [11702.9650528  11932.5656926  11826.09933577 11914.84053663
 11925.49722339 11508.40030198 11843.96376674 11776.03652644
 11674.74148585 11808.29427559]
total_rewards_mean           11791.34041978022
total_rewards_std            126.15647938427061
total_rewards_max            11932.565692601624
total_rewards_min            11508.400301980424
Number of train steps total  1300000
Number of env steps total    1627000
Number of rollouts total     0
Train Time (s)               138.74499158095568
(Previous) Eval Time (s)     27.744131471961737
Sample Time (s)              22.499525223858654
Epoch Time (s)               188.98864827677608
Total Train Time (s)         59459.768848785665
Epoch                        324
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:18:44.167148 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #324 | Epoch Duration: 189.49466466903687
2020-01-13 21:18:44.167390 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #324 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.0142107
Z variance train             0.0104494225
KL Divergence                60.160408
KL Loss                      6.016041
QF Loss                      679.94525
VF Loss                      604.0278
Policy Loss                  -4842.465
Q Predictions Mean           4843.414
Q Predictions Std            534.1829
Q Predictions Max            5502.3643
Q Predictions Min            3289.5327
V Predictions Mean           4822.6343
V Predictions Std            531.7576
V Predictions Max            5480.9
V Predictions Min            3288.609
Log Pis Mean                 5.735908
Log Pis Std                  4.046157
Log Pis Max                  16.3422
Log Pis Min                  -3.5774426
Policy mu Mean               -0.053527847
Policy mu Std                1.4079777
Policy mu Max                3.1671164
Policy mu Min                -2.924259
Policy log std Mean          -0.91698956
Policy log std Std           0.5397652
Policy log std Max           -0.14126128
Policy log std Min           -3.851944
Z mean eval                  4.041284
Z variance eval              0.013952343
total_rewards                [12086.71331525 12031.01206535 12031.6919371  12324.76534292
 11884.09981112 12012.65216512 12125.168939   11992.47924693
 11989.45020003 12132.37506152]
total_rewards_mean           12061.040808434882
total_rewards_std            111.64643407180482
total_rewards_max            12324.765342917453
total_rewards_min            11884.099811117625
Number of train steps total  1304000
Number of env steps total    1632000
Number of rollouts total     0
Train Time (s)               138.38481764076278
(Previous) Eval Time (s)     28.249850053340197
Sample Time (s)              22.638948671519756
Epoch Time (s)               189.27361636562273
Total Train Time (s)         59649.42508281162
Epoch                        325
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:21:53.826938 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #325 | Epoch Duration: 189.65940284729004
2020-01-13 21:21:53.827128 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #325 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.0439615
Z variance train             0.013969434
KL Divergence                60.244415
KL Loss                      6.0244417
QF Loss                      405.5603
VF Loss                      135.15611
Policy Loss                  -4985.2446
Q Predictions Mean           4990.9854
Q Predictions Std            615.9563
Q Predictions Max            5691.9805
Q Predictions Min            1035.7162
V Predictions Mean           4982.471
V Predictions Std            617.93915
V Predictions Max            5676.987
V Predictions Min            960.8164
Log Pis Mean                 5.827555
Log Pis Std                  3.9649575
Log Pis Max                  14.913289
Log Pis Min                  -7.7908616
Policy mu Mean               -0.0642842
Policy mu Std                1.4514496
Policy mu Max                3.208665
Policy mu Min                -2.711021
Policy log std Mean          -0.8511086
Policy log std Std           0.483774
Policy log std Max           -0.11785036
Policy log std Min           -3.7747517
Z mean eval                  4.0527334
Z variance eval              0.014700088
total_rewards                [12060.75628606 12045.53017854 12112.99051661 11997.25584787
 12303.31495101 11927.24961918 11999.01024181 11913.91295545
 12178.64267212 11916.4433523 ]
total_rewards_mean           12045.510662095356
total_rewards_std            118.92264754001523
total_rewards_max            12303.314951012799
total_rewards_min            11913.912955452794
Number of train steps total  1308000
Number of env steps total    1637000
Number of rollouts total     0
Train Time (s)               137.594848907087
(Previous) Eval Time (s)     28.63521724427119
Sample Time (s)              22.6098813675344
Epoch Time (s)               188.8399475188926
Total Train Time (s)         59838.6642457284
Epoch                        326
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:25:03.070645 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #326 | Epoch Duration: 189.24331402778625
2020-01-13 21:25:03.070979 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #326 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.052625
Z variance train             0.014667332
KL Divergence                60.809578
KL Loss                      6.080958
QF Loss                      408.55548
VF Loss                      70.602234
Policy Loss                  -4953.8955
Q Predictions Mean           4956.2373
Q Predictions Std            482.1155
Q Predictions Max            5554.349
Q Predictions Min            3342.6836
V Predictions Mean           4953.3433
V Predictions Std            482.86932
V Predictions Max            5548.0264
V Predictions Min            3313.0117
Log Pis Mean                 5.8252645
Log Pis Std                  3.5108504
Log Pis Max                  15.0526495
Log Pis Min                  -2.4360135
Policy mu Mean               -0.082448095
Policy mu Std                1.418085
Policy mu Max                2.8591502
Policy mu Min                -2.8498256
Policy log std Mean          -0.89944035
Policy log std Std           0.51974803
Policy log std Max           -0.048915505
Policy log std Min           -3.5769324
Z mean eval                  4.0282116
Z variance eval              0.011447405
total_rewards                [11466.29091145 12253.24586046 12134.6805458  12548.28280285
 11996.65914307 12114.23615232 12331.21196122 12227.33613209
 12373.34022195 12220.35528451]
total_rewards_mean           12166.56390157259
total_rewards_std            274.350126309494
total_rewards_max            12548.282802854976
total_rewards_min            11466.29091145065
Number of train steps total  1312000
Number of env steps total    1642000
Number of rollouts total     0
Train Time (s)               138.0075225988403
(Previous) Eval Time (s)     29.03820615913719
Sample Time (s)              23.837134481407702
Epoch Time (s)               190.8828632393852
Total Train Time (s)         60029.33717523981
Epoch                        327
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:28:13.746765 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #327 | Epoch Duration: 190.67560601234436
2020-01-13 21:28:13.746962 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #327 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.02711
Z variance train             0.011398058
KL Divergence                62.235832
KL Loss                      6.223583
QF Loss                      456.85382
VF Loss                      116.3549
Policy Loss                  -4902.251
Q Predictions Mean           4909.4927
Q Predictions Std            585.9344
Q Predictions Max            5554.289
Q Predictions Min            3248.8806
V Predictions Mean           4907.2773
V Predictions Std            587.0457
V Predictions Max            5561.2188
V Predictions Min            3259.3484
Log Pis Mean                 5.518082
Log Pis Std                  4.0589156
Log Pis Max                  16.765192
Log Pis Min                  -4.9022794
Policy mu Mean               -0.12019396
Policy mu Std                1.3956963
Policy mu Max                3.035772
Policy mu Min                -2.8886979
Policy log std Mean          -0.9091088
Policy log std Std           0.54158247
Policy log std Max           -0.14035094
Policy log std Min           -3.8147576
Z mean eval                  3.9824777
Z variance eval              0.0116460705
total_rewards                [12261.88061464 11931.36696337 12020.82881165 12071.55052238
 12302.3620475  12137.87416458 12249.90599112  5486.76176127
 12134.1235677  12193.40666713]
total_rewards_mean           11479.006111133052
total_rewards_std            2000.3762562716731
total_rewards_max            12302.362047498144
total_rewards_min            5486.761761265873
Number of train steps total  1316000
Number of env steps total    1647000
Number of rollouts total     0
Train Time (s)               132.38733605574816
(Previous) Eval Time (s)     28.830550904851407
Sample Time (s)              23.071994218509644
Epoch Time (s)               184.28988117910922
Total Train Time (s)         60212.56142368261
Epoch                        328
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:31:16.975632 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #328 | Epoch Duration: 183.22852110862732
2020-01-13 21:31:16.975831 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #328 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9826527
Z variance train             0.011675792
KL Divergence                61.58581
KL Loss                      6.1585813
QF Loss                      645.02356
VF Loss                      150.3252
Policy Loss                  -4810.8267
Q Predictions Mean           4813.2334
Q Predictions Std            551.9974
Q Predictions Max            5492.15
Q Predictions Min            3270.142
V Predictions Mean           4808.0615
V Predictions Std            554.7044
V Predictions Max            5498.0654
V Predictions Min            3280.0632
Log Pis Mean                 5.9937706
Log Pis Std                  3.8423567
Log Pis Max                  15.0315
Log Pis Min                  -2.321664
Policy mu Mean               -0.08549577
Policy mu Std                1.4090588
Policy mu Max                3.1366978
Policy mu Min                -3.152844
Policy log std Mean          -0.8958953
Policy log std Std           0.489895
Policy log std Max           0.0029746294
Policy log std Min           -3.4749794
Z mean eval                  4.0705895
Z variance eval              0.018176239
total_rewards                [ 3689.2255339  11965.38775348  5021.26265312 12282.41490134
 12324.63675908 12321.92496448 12104.52227919 12278.20048214
 11989.47232786 12073.40023353]
total_rewards_mean           10605.044788811614
total_rewards_std            3141.600651012351
total_rewards_max            12324.636759076293
total_rewards_min            3689.225533901725
Number of train steps total  1320000
Number of env steps total    1652000
Number of rollouts total     0
Train Time (s)               131.02194539504126
(Previous) Eval Time (s)     27.768797177355736
Sample Time (s)              22.255956950597465
Epoch Time (s)               181.04669952299446
Total Train Time (s)         60392.930138298776
Epoch                        329
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:34:17.347696 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #329 | Epoch Duration: 180.3717176914215
2020-01-13 21:34:17.347905 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #329 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.0689077
Z variance train             0.01816076
KL Divergence                64.788055
KL Loss                      6.4788055
QF Loss                      377.14166
VF Loss                      231.52103
Policy Loss                  -4819.3965
Q Predictions Mean           4822.4287
Q Predictions Std            678.6413
Q Predictions Max            5532.5205
Q Predictions Min            280.41895
V Predictions Mean           4825.9277
V Predictions Std            678.6513
V Predictions Max            5530.9106
V Predictions Min            292.34714
Log Pis Mean                 5.2388763
Log Pis Std                  3.9328187
Log Pis Max                  18.919395
Log Pis Min                  -4.1707478
Policy mu Mean               -0.052510034
Policy mu Std                1.3763257
Policy mu Max                2.965846
Policy mu Min                -2.8182833
Policy log std Mean          -0.8907666
Policy log std Std           0.49269623
Policy log std Max           0.28906047
Policy log std Min           -3.4956656
Z mean eval                  3.9863179
Z variance eval              0.008850995
total_rewards                [11863.31355243 12176.68021872 11940.01264501 12279.22227789
 12072.90303082 12028.35644067 12340.30933062 12158.68918991
 12126.30854316 12057.47599642]
total_rewards_mean           12104.327122564395
total_rewards_std            137.47368482946422
total_rewards_max            12340.309330615724
total_rewards_min            11863.31355243109
Number of train steps total  1324000
Number of env steps total    1657000
Number of rollouts total     0
Train Time (s)               133.00749120675027
(Previous) Eval Time (s)     27.093457750976086
Sample Time (s)              20.976631512865424
Epoch Time (s)               181.07758047059178
Total Train Time (s)         60574.60986515414
Epoch                        330
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:37:19.030781 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #330 | Epoch Duration: 181.68272614479065
2020-01-13 21:37:19.030967 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #330 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9844558
Z variance train             0.008824759
KL Divergence                63.18676
KL Loss                      6.318676
QF Loss                      889.27893
VF Loss                      146.26479
Policy Loss                  -4812.69
Q Predictions Mean           4821.0195
Q Predictions Std            669.67676
Q Predictions Max            5599.022
Q Predictions Min            144.96565
V Predictions Mean           4821.4023
V Predictions Std            669.54865
V Predictions Max            5602.6875
V Predictions Min            155.73264
Log Pis Mean                 5.919446
Log Pis Std                  3.7537336
Log Pis Max                  17.454607
Log Pis Min                  -2.9532037
Policy mu Mean               -0.054336
Policy mu Std                1.394558
Policy mu Max                3.1597347
Policy mu Min                -2.6664352
Policy log std Mean          -0.911019
Policy log std Std           0.5372016
Policy log std Max           -0.14249408
Policy log std Min           -3.5764666
Z mean eval                  4.0346622
Z variance eval              0.0073244544
total_rewards                [10850.69086207 12537.37133011 12319.82853272 12362.97878217
 12198.64480927 10763.54548858 12549.70728964 12345.72856519
 12380.93643263 12351.3133557 ]
total_rewards_mean           12066.074544809331
total_rewards_std            637.0701983770851
total_rewards_max            12549.707289641648
total_rewards_min            10763.545488582487
Number of train steps total  1328000
Number of env steps total    1662000
Number of rollouts total     0
Train Time (s)               140.21658743079752
(Previous) Eval Time (s)     27.698265423998237
Sample Time (s)              21.120021454058588
Epoch Time (s)               189.03487430885434
Total Train Time (s)         60764.73057272611
Epoch                        331
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:40:29.155220 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #331 | Epoch Duration: 190.12407898902893
2020-01-13 21:40:29.155418 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #331 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.035712
Z variance train             0.00732066
KL Divergence                63.74721
KL Loss                      6.374721
QF Loss                      690.33655
VF Loss                      274.6175
Policy Loss                  -4904.285
Q Predictions Mean           4911.998
Q Predictions Std            577.8019
Q Predictions Max            5571.686
Q Predictions Min            3320.2317
V Predictions Mean           4908.6436
V Predictions Std            577.1494
V Predictions Max            5574.8877
V Predictions Min            3326.084
Log Pis Mean                 6.011424
Log Pis Std                  3.8929322
Log Pis Max                  17.114471
Log Pis Min                  -3.2994287
Policy mu Mean               -0.0714586
Policy mu Std                1.4452773
Policy mu Max                3.588418
Policy mu Min                -3.3162615
Policy log std Mean          -0.8999639
Policy log std Std           0.51293564
Policy log std Max           -0.15491867
Policy log std Min           -3.6451879
Z mean eval                  4.050668
Z variance eval              0.004938966
total_rewards                [11760.31459436 12272.01217995 12185.07602951  5160.97303705
 12224.89380771 12619.47520541 12330.4294191  11629.74897712
 12328.55010563 12452.07933832]
total_rewards_mean           11496.355269417423
total_rewards_std            2130.594273573178
total_rewards_max            12619.475205411109
total_rewards_min            5160.973037048507
Number of train steps total  1332000
Number of env steps total    1667000
Number of rollouts total     0
Train Time (s)               139.29677132889628
(Previous) Eval Time (s)     28.787103477865458
Sample Time (s)              21.96860863547772
Epoch Time (s)               190.05248344223946
Total Train Time (s)         60954.36345308833
Epoch                        332
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:43:38.794919 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #332 | Epoch Duration: 189.63936018943787
2020-01-13 21:43:38.795115 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #332 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.051024
Z variance train             0.0049253353
KL Divergence                64.48901
KL Loss                      6.4489017
QF Loss                      1083.6086
VF Loss                      96.885506
Policy Loss                  -4937.927
Q Predictions Mean           4941.5967
Q Predictions Std            602.82855
Q Predictions Max            5608.2036
Q Predictions Min            460.6277
V Predictions Mean           4935.7695
V Predictions Std            601.50714
V Predictions Max            5613.383
V Predictions Min            464.32867
Log Pis Mean                 5.616068
Log Pis Std                  4.0395756
Log Pis Max                  15.298797
Log Pis Min                  -7.656333
Policy mu Mean               -0.073552914
Policy mu Std                1.4091293
Policy mu Max                3.0781217
Policy mu Min                -3.29078
Policy log std Mean          -0.8710723
Policy log std Std           0.45693657
Policy log std Max           0.061549902
Policy log std Min           -3.4497926
Z mean eval                  4.0595803
Z variance eval              0.00992661
total_rewards                [11768.03229021 12150.04379479 12167.72057629 12035.81827879
 12193.12319717 12241.76479893 12195.57214943 12239.86674889
 11996.59876144 12040.38588432]
total_rewards_mean           12102.892648028459
total_rewards_std            138.93891736516238
total_rewards_max            12241.764798931248
total_rewards_min            11768.03229021471
Number of train steps total  1336000
Number of env steps total    1672000
Number of rollouts total     0
Train Time (s)               139.13547580409795
(Previous) Eval Time (s)     28.373658345080912
Sample Time (s)              21.562760806642473
Epoch Time (s)               189.07189495582134
Total Train Time (s)         61144.10967943119
Epoch                        333
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:46:48.545189 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #333 | Epoch Duration: 189.74989342689514
2020-01-13 21:46:48.545382 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #333 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.0587893
Z variance train             0.0098875165
KL Divergence                62.843136
KL Loss                      6.2843137
QF Loss                      382.08997
VF Loss                      125.34924
Policy Loss                  -4889.3086
Q Predictions Mean           4892.33
Q Predictions Std            678.1262
Q Predictions Max            5556.638
Q Predictions Min            108.43227
V Predictions Mean           4890.6226
V Predictions Std            678.4016
V Predictions Max            5555.2183
V Predictions Min            119.55636
Log Pis Mean                 5.9791794
Log Pis Std                  3.8150892
Log Pis Max                  14.651027
Log Pis Min                  -4.1272454
Policy mu Mean               -0.05611208
Policy mu Std                1.4267595
Policy mu Max                3.2832055
Policy mu Min                -2.8937304
Policy log std Mean          -0.90235585
Policy log std Std           0.5140597
Policy log std Max           0.11817503
Policy log std Min           -3.615427
Z mean eval                  4.0379114
Z variance eval              0.0059680296
total_rewards                [11431.60910229 12018.55255966 11793.24028597 11760.81482941
 11871.18589893 11891.49612586  1408.51107708 11813.04492716
 11789.21688797 11820.30371913]
total_rewards_mean           10759.797541345952
total_rewards_std            3120.28887110457
total_rewards_max            12018.552559664658
total_rewards_min            1408.5110770778545
Number of train steps total  1340000
Number of env steps total    1677000
Number of rollouts total     0
Train Time (s)               137.4988634181209
(Previous) Eval Time (s)     29.051270899828523
Sample Time (s)              22.849342798814178
Epoch Time (s)               189.3994771167636
Total Train Time (s)         61332.96817691205
Epoch                        334
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:49:57.407487 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #334 | Epoch Duration: 188.86196494102478
2020-01-13 21:49:57.407675 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #334 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.0384603
Z variance train             0.005955513
KL Divergence                64.55172
KL Loss                      6.455172
QF Loss                      769.18555
VF Loss                      167.98268
Policy Loss                  -4877.174
Q Predictions Mean           4888.1416
Q Predictions Std            647.47107
Q Predictions Max            5582.386
Q Predictions Min            3357.0298
V Predictions Mean           4869.6504
V Predictions Std            642.9344
V Predictions Max            5560.0454
V Predictions Min            3358.3716
Log Pis Mean                 5.5319223
Log Pis Std                  4.0289917
Log Pis Max                  15.53726
Log Pis Min                  -5.4558744
Policy mu Mean               -0.05667175
Policy mu Std                1.4192812
Policy mu Max                3.2047954
Policy mu Min                -2.8736377
Policy log std Mean          -0.882668
Policy log std Std           0.50828284
Policy log std Max           -0.17011452
Policy log std Min           -3.5991347
Z mean eval                  3.9972515
Z variance eval              0.0031555668
total_rewards                [12065.913948   12230.32330454 12178.29757392  7814.20709345
 12130.62890755  7901.43390155 12237.85842368 12046.72391195
  4155.7013116  12386.47704915]
total_rewards_mean           10514.756542538978
total_rewards_std            2722.2604325473135
total_rewards_max            12386.477049152754
total_rewards_min            4155.701311597975
Number of train steps total  1344000
Number of env steps total    1682000
Number of rollouts total     0
Train Time (s)               131.09999246010557
(Previous) Eval Time (s)     28.51339078694582
Sample Time (s)              22.57818424794823
Epoch Time (s)               182.19156749499962
Total Train Time (s)         61514.74212043034
Epoch                        335
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:52:59.185128 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #335 | Epoch Duration: 181.77730989456177
2020-01-13 21:52:59.185322 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #335 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9978402
Z variance train             0.003161092
KL Divergence                63.617004
KL Loss                      6.3617005
QF Loss                      848.91113
VF Loss                      334.9821
Policy Loss                  -4873.355
Q Predictions Mean           4878.9106
Q Predictions Std            609.8013
Q Predictions Max            5581.1235
Q Predictions Min            2729.9744
V Predictions Mean           4875.9907
V Predictions Std            608.7906
V Predictions Max            5578.684
V Predictions Min            2951.1426
Log Pis Mean                 5.999816
Log Pis Std                  4.1110964
Log Pis Max                  17.48132
Log Pis Min                  -7.9468813
Policy mu Mean               -0.07486907
Policy mu Std                1.4528043
Policy mu Max                3.4785044
Policy mu Min                -2.7553136
Policy log std Mean          -0.88074464
Policy log std Std           0.48606652
Policy log std Max           -0.14366311
Policy log std Min           -3.4810524
Z mean eval                  4.0062
Z variance eval              0.010480435
total_rewards                [ -314.38488831  9594.30462203 11690.80504126 11693.63966547
 11639.88045895 11990.42529195 11533.41701195 11498.19983459
 11563.82821221 11706.22920082]
total_rewards_mean           10259.634445090487
total_rewards_std            3580.6145969595996
total_rewards_max            11990.425291954713
total_rewards_min            -314.3848883136308
Number of train steps total  1348000
Number of env steps total    1687000
Number of rollouts total     0
Train Time (s)               131.40148619608954
(Previous) Eval Time (s)     28.098804275970906
Sample Time (s)              20.183074506465346
Epoch Time (s)               179.6833649785258
Total Train Time (s)         61693.125760426745
Epoch                        336
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:55:57.572448 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #336 | Epoch Duration: 178.38699007034302
2020-01-13 21:55:57.572629 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #336 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.006523
Z variance train             0.010476317
KL Divergence                63.176834
KL Loss                      6.3176837
QF Loss                      737.85034
VF Loss                      357.69135
Policy Loss                  -4968.2783
Q Predictions Mean           4979.949
Q Predictions Std            549.14813
Q Predictions Max            5626.181
Q Predictions Min            3300.262
V Predictions Mean           4963.9316
V Predictions Std            543.8783
V Predictions Max            5592.775
V Predictions Min            3297.9922
Log Pis Mean                 5.7198186
Log Pis Std                  3.5783718
Log Pis Max                  16.52572
Log Pis Min                  -3.7881236
Policy mu Mean               -0.045059692
Policy mu Std                1.4231527
Policy mu Max                2.9432487
Policy mu Min                -2.7394516
Policy log std Mean          -0.86002785
Policy log std Std           0.4812037
Policy log std Max           -0.042919755
Policy log std Min           -3.4588363
Z mean eval                  4.0383058
Z variance eval              0.0083650295
total_rewards                [11582.29018506 11782.11178256 11740.50972576  8315.06545418
 11287.49784451  6896.48877899 11926.77796391 12102.6980219
 11712.7153193  11707.46819611]
total_rewards_mean           10905.36232722803
total_rewards_std            1691.839827719788
total_rewards_max            12102.69802190252
total_rewards_min            6896.488778987045
Number of train steps total  1352000
Number of env steps total    1692000
Number of rollouts total     0
Train Time (s)               135.22299365885556
(Previous) Eval Time (s)     26.80210904730484
Sample Time (s)              22.2250165338628
Epoch Time (s)               184.2501192400232
Total Train Time (s)         61878.31291994685
Epoch                        337
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:59:02.763575 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #337 | Epoch Duration: 185.19080233573914
2020-01-13 21:59:02.763776 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #337 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.038139
Z variance train             0.00840847
KL Divergence                64.42036
KL Loss                      6.4420357
QF Loss                      381.18698
VF Loss                      100.51747
Policy Loss                  -4832.836
Q Predictions Mean           4836.1865
Q Predictions Std            588.4444
Q Predictions Max            5547.2695
Q Predictions Min            3350.8242
V Predictions Mean           4838.269
V Predictions Std            589.4182
V Predictions Max            5543.688
V Predictions Min            3367.2463
Log Pis Mean                 5.346011
Log Pis Std                  3.6901178
Log Pis Max                  13.42093
Log Pis Min                  -4.4903097
Policy mu Mean               -0.07669333
Policy mu Std                1.3977667
Policy mu Max                3.0393143
Policy mu Min                -2.6932201
Policy log std Mean          -0.85772914
Policy log std Std           0.45981133
Policy log std Max           -0.08112621
Policy log std Min           -3.5531914
Z mean eval                  4.0432334
Z variance eval              0.0032543975
total_rewards                [12230.11392995 12256.83845132 12344.23143657 12490.11172507
 12058.40427987  7532.90233534 12343.94905244 12455.8941688
 12169.12427731 12121.70137184]
total_rewards_mean           11800.327102849498
total_rewards_std            1428.5257376620852
total_rewards_max            12490.111725066814
total_rewards_min            7532.902335342828
Number of train steps total  1356000
Number of env steps total    1697000
Number of rollouts total     0
Train Time (s)               140.23648756509647
(Previous) Eval Time (s)     27.742412705905735
Sample Time (s)              22.946346985176206
Epoch Time (s)               190.9252472561784
Total Train Time (s)         62068.59609513264
Epoch                        338
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:02:13.050674 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #338 | Epoch Duration: 190.28674817085266
2020-01-13 22:02:13.050885 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #338 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.04082
Z variance train             0.0032610311
KL Divergence                67.160866
KL Loss                      6.716087
QF Loss                      470.58063
VF Loss                      127.00163
Policy Loss                  -4946.984
Q Predictions Mean           4956.45
Q Predictions Std            619.7294
Q Predictions Max            5590.8896
Q Predictions Min            542.99445
V Predictions Mean           4950.3423
V Predictions Std            619.375
V Predictions Max            5575.509
V Predictions Min            518.3808
Log Pis Mean                 6.0883446
Log Pis Std                  3.9441867
Log Pis Max                  16.38746
Log Pis Min                  -5.376545
Policy mu Mean               -0.062540025
Policy mu Std                1.4634799
Policy mu Max                3.016724
Policy mu Min                -2.6431677
Policy log std Mean          -0.8802759
Policy log std Std           0.51302475
Policy log std Max           -0.062399387
Policy log std Min           -3.5653234
Z mean eval                  4.074082
Z variance eval              0.00467316
total_rewards                [11731.57939179 12359.49886755 12172.30047274  5674.69011203
 11941.87827088  6129.28842991 12379.1614015  12218.80861246
  9577.44698334  5119.28821916]
total_rewards_mean           9930.394076136143
total_rewards_std            2920.2922057717965
total_rewards_max            12379.161401503408
total_rewards_min            5119.288219157049
Number of train steps total  1360000
Number of env steps total    1702000
Number of rollouts total     0
Train Time (s)               139.02924472419545
(Previous) Eval Time (s)     27.10355553822592
Sample Time (s)              22.800261801108718
Epoch Time (s)               188.9330620635301
Total Train Time (s)         62258.47943994496
Epoch                        339
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:05:22.937955 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #339 | Epoch Duration: 189.88692235946655
2020-01-13 22:05:22.938141 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #339 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.0725303
Z variance train             0.0046675554
KL Divergence                64.26778
KL Loss                      6.426778
QF Loss                      375.773
VF Loss                      117.064125
Policy Loss                  -4896.464
Q Predictions Mean           4905.01
Q Predictions Std            606.91
Q Predictions Max            5604.65
Q Predictions Min            3337.3862
V Predictions Mean           4902.433
V Predictions Std            606.64716
V Predictions Max            5593.4824
V Predictions Min            3332.7227
Log Pis Mean                 5.9164324
Log Pis Std                  4.012793
Log Pis Max                  17.437168
Log Pis Min                  -4.3406715
Policy mu Mean               -0.062983476
Policy mu Std                1.4585626
Policy mu Max                2.927658
Policy mu Min                -3.132162
Policy log std Mean          -0.8674887
Policy log std Std           0.4831416
Policy log std Max           0.051884055
Policy log std Min           -3.5264323
Z mean eval                  4.055346
Z variance eval              0.01775672
total_rewards                [12365.45973907 12273.16025078  7110.86251772 12241.0767111
  2658.06450835  2901.26655562 12578.26012255 12577.88342883
 12253.7736543  12258.98031436]
total_rewards_mean           9921.87878026801
total_rewards_std            3896.6985709089813
total_rewards_max            12578.260122553045
total_rewards_min            2658.0645083519357
Number of train steps total  1364000
Number of env steps total    1707000
Number of rollouts total     0
Train Time (s)               139.52630701102316
(Previous) Eval Time (s)     28.057058850768954
Sample Time (s)              20.73937403736636
Epoch Time (s)               188.32273989915848
Total Train Time (s)         62447.51727297716
Epoch                        340
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:08:31.979730 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #340 | Epoch Duration: 189.04143524169922
2020-01-13 22:08:31.979967 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #340 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.0547547
Z variance train             0.017711774
KL Divergence                62.28132
KL Loss                      6.228132
QF Loss                      903.5823
VF Loss                      126.56634
Policy Loss                  -4984.623
Q Predictions Mean           4991.7114
Q Predictions Std            504.84137
Q Predictions Max            5641.7812
Q Predictions Min            3330.0073
V Predictions Mean           4986.207
V Predictions Std            504.82266
V Predictions Max            5629.776
V Predictions Min            3335.1672
Log Pis Mean                 6.2840385
Log Pis Std                  4.072087
Log Pis Max                  20.330957
Log Pis Min                  -3.3277318
Policy mu Mean               -0.04075463
Policy mu Std                1.4683678
Policy mu Max                3.9771628
Policy mu Min                -2.6912622
Policy log std Mean          -0.9032262
Policy log std Std           0.51623386
Policy log std Max           0.38390493
Policy log std Min           -3.395607
Z mean eval                  4.0035534
Z variance eval              0.027855838
total_rewards                [12158.47991581 12189.25700553 12055.12140767 12310.67263674
 12315.10686191  8472.86993009 12037.23155535 12338.71517858
 12135.66640688 12257.99488171]
total_rewards_mean           11827.11157802712
total_rewards_std            1122.6132748412178
total_rewards_max            12338.715178581875
total_rewards_min            8472.869930087902
Number of train steps total  1368000
Number of env steps total    1712000
Number of rollouts total     0
Train Time (s)               139.63674738490954
(Previous) Eval Time (s)     28.77540439600125
Sample Time (s)              22.044700680300593
Epoch Time (s)               190.45685246121138
Total Train Time (s)         62636.05197306117
Epoch                        341
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:11:40.518037 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #341 | Epoch Duration: 188.53791737556458
2020-01-13 22:11:40.518227 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #341 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.0066743
Z variance train             0.028231304
KL Divergence                60.36663
KL Loss                      6.036663
QF Loss                      486.7312
VF Loss                      286.14236
Policy Loss                  -4890.583
Q Predictions Mean           4896.797
Q Predictions Std            626.87286
Q Predictions Max            5635.89
Q Predictions Min            952.7648
V Predictions Mean           4878.8325
V Predictions Std            624.5888
V Predictions Max            5601.2915
V Predictions Min            990.55896
Log Pis Mean                 5.7761235
Log Pis Std                  4.048787
Log Pis Max                  18.499825
Log Pis Min                  -7.649518
Policy mu Mean               -0.06489416
Policy mu Std                1.4032465
Policy mu Max                3.2810955
Policy mu Min                -2.9168584
Policy log std Mean          -0.88833255
Policy log std Std           0.49420354
Policy log std Max           -0.10975146
Policy log std Min           -3.8586798
Z mean eval                  4.1505113
Z variance eval              0.017883126
total_rewards                [11535.05717458 11595.09533269 11879.25129441 11792.4608199
 12073.99993983 11872.7032602  11877.69494269 11962.28126748
 11841.95362855 11840.18679854]
total_rewards_mean           11827.068445886696
total_rewards_std            150.76463557243244
total_rewards_max            12073.99993983245
total_rewards_min            11535.05717458061
Number of train steps total  1372000
Number of env steps total    1717000
Number of rollouts total     0
Train Time (s)               132.1159359361045
(Previous) Eval Time (s)     26.856057109776884
Sample Time (s)              21.491001658141613
Epoch Time (s)               180.462994704023
Total Train Time (s)         62817.111101560295
Epoch                        342
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:14:41.580770 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #342 | Epoch Duration: 181.062402009964
2020-01-13 22:14:41.580953 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #342 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1514807
Z variance train             0.01788329
KL Divergence                62.92059
KL Loss                      6.292059
QF Loss                      952.02264
VF Loss                      242.9912
Policy Loss                  -4979.842
Q Predictions Mean           4989.536
Q Predictions Std            560.47565
Q Predictions Max            5669.1543
Q Predictions Min            3385.6475
V Predictions Mean           4974.782
V Predictions Std            558.7462
V Predictions Max            5656.391
V Predictions Min            3382.882
Log Pis Mean                 5.7595596
Log Pis Std                  3.7800627
Log Pis Max                  17.103613
Log Pis Min                  -4.2875433
Policy mu Mean               -0.069875754
Policy mu Std                1.4149712
Policy mu Max                3.082488
Policy mu Min                -3.0074704
Policy log std Mean          -0.8787637
Policy log std Std           0.5109801
Policy log std Max           -0.0091362
Policy log std Min           -3.6624389
Z mean eval                  4.043374
Z variance eval              0.016754683
total_rewards                [12185.98600001 11899.3898062  11945.80623294 12243.67206389
 12171.16717129 12173.66424006 12191.02039128 12291.77422028
 12018.69463514 11922.00767991]
total_rewards_mean           12104.318244100625
total_rewards_std            136.27693406146943
total_rewards_max            12291.774220284256
total_rewards_min            11899.389806202615
Number of train steps total  1376000
Number of env steps total    1722000
Number of rollouts total     0
Train Time (s)               131.5380605221726
(Previous) Eval Time (s)     27.45515883434564
Sample Time (s)              22.507971971761435
Epoch Time (s)               181.50119132827967
Total Train Time (s)         62999.18673112104
Epoch                        343
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:17:43.660481 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #343 | Epoch Duration: 182.07937788963318
2020-01-13 22:17:43.660702 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #343 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.044126
Z variance train             0.01676042
KL Divergence                60.076523
KL Loss                      6.0076523
QF Loss                      559.15076
VF Loss                      206.9424
Policy Loss                  -4849.9556
Q Predictions Mean           4856.5728
Q Predictions Std            567.4841
Q Predictions Max            5561.5146
Q Predictions Min            2667.6226
V Predictions Mean           4854.3027
V Predictions Std            563.40393
V Predictions Max            5555.528
V Predictions Min            2806.888
Log Pis Mean                 5.5297804
Log Pis Std                  4.1072497
Log Pis Max                  16.312782
Log Pis Min                  -3.3767996
Policy mu Mean               0.005618123
Policy mu Std                1.4034503
Policy mu Max                3.4834776
Policy mu Min                -3.335766
Policy log std Mean          -0.88254803
Policy log std Std           0.49312752
Policy log std Max           -0.10007548
Policy log std Min           -3.495574
Z mean eval                  4.075232
Z variance eval              0.016696248
total_rewards                [12213.33504052 12388.0646189  12518.04897566 12243.18213372
 12292.40336749 12262.21455715 12465.7602839  12233.42983674
 12325.22777554 12149.69147714]
total_rewards_mean           12309.135806676502
total_rewards_std            110.37562591212517
total_rewards_max            12518.048975655784
total_rewards_min            12149.691477141574
Number of train steps total  1380000
Number of env steps total    1727000
Number of rollouts total     0
Train Time (s)               135.97498690895736
(Previous) Eval Time (s)     28.033007952850312
Sample Time (s)              22.47392880404368
Epoch Time (s)               186.48192366585135
Total Train Time (s)         63185.629119878635
Epoch                        344
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:20:50.106472 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #344 | Epoch Duration: 186.44561386108398
2020-01-13 22:20:50.106658 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #344 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.0753365
Z variance train             0.01668303
KL Divergence                60.958138
KL Loss                      6.0958138
QF Loss                      721.9515
VF Loss                      143.4225
Policy Loss                  -4840.258
Q Predictions Mean           4847.433
Q Predictions Std            553.056
Q Predictions Max            5546.3613
Q Predictions Min            3352.5142
V Predictions Mean           4842.9214
V Predictions Std            552.9775
V Predictions Max            5513.882
V Predictions Min            3361.509
Log Pis Mean                 6.1650324
Log Pis Std                  3.862602
Log Pis Max                  15.0561905
Log Pis Min                  -5.4914923
Policy mu Mean               -0.051145762
Policy mu Std                1.4564611
Policy mu Max                3.032868
Policy mu Min                -2.8570104
Policy log std Mean          -0.88704616
Policy log std Std           0.53488076
Policy log std Max           -0.10877442
Policy log std Min           -3.7254667
Z mean eval                  4.117177
Z variance eval              0.024040705
total_rewards                [12025.30598119 12506.27659037 12372.03672919 12494.77861478
 12322.85316112 12010.46293641 12280.65510113 12308.81801681
 12352.46013653 12330.28287891]
total_rewards_mean           12300.393014645728
total_rewards_std            157.9899900640825
total_rewards_max            12506.276590371432
total_rewards_min            12010.462936410617
Number of train steps total  1384000
Number of env steps total    1732000
Number of rollouts total     0
Train Time (s)               138.9495057882741
(Previous) Eval Time (s)     27.996358254924417
Sample Time (s)              22.062915707938373
Epoch Time (s)               189.0087797511369
Total Train Time (s)         63375.516213502735
Epoch                        345
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:23:59.997111 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #345 | Epoch Duration: 189.89031863212585
2020-01-13 22:23:59.997288 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #345 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1148477
Z variance train             0.023987275
KL Divergence                63.078503
KL Loss                      6.3078504
QF Loss                      651.49756
VF Loss                      322.79037
Policy Loss                  -4924.293
Q Predictions Mean           4931.808
Q Predictions Std            583.09344
Q Predictions Max            5643.549
Q Predictions Min            3289.856
V Predictions Mean           4934.885
V Predictions Std            583.6429
V Predictions Max            5626.7017
V Predictions Min            3292.5386
Log Pis Mean                 5.848178
Log Pis Std                  3.811682
Log Pis Max                  15.01969
Log Pis Min                  -3.2565045
Policy mu Mean               -0.06501063
Policy mu Std                1.4198797
Policy mu Max                2.7729027
Policy mu Min                -2.8549962
Policy log std Mean          -0.9091905
Policy log std Std           0.5179633
Policy log std Max           -0.14011419
Policy log std Min           -3.582364
Z mean eval                  4.104551
Z variance eval              0.029131427
total_rewards                [11716.62515654 11869.16252578 12029.11960714 11751.77951938
 11992.84173123 11759.00708552 11955.09431596 11680.08962228
 11883.37506623 12077.08081643]
total_rewards_mean           11871.417544648491
total_rewards_std            132.8824481095577
total_rewards_max            12077.080816429845
total_rewards_min            11680.089622276628
Number of train steps total  1388000
Number of env steps total    1737000
Number of rollouts total     0
Train Time (s)               138.5117603703402
(Previous) Eval Time (s)     28.877502858173102
Sample Time (s)              22.74585641687736
Epoch Time (s)               190.13511964539066
Total Train Time (s)         63564.74159791786
Epoch                        346
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:27:09.227703 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #346 | Epoch Duration: 189.23026299476624
2020-01-13 22:27:09.227976 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #346 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1052947
Z variance train             0.029061232
KL Divergence                63.75341
KL Loss                      6.375341
QF Loss                      944.91516
VF Loss                      224.89012
Policy Loss                  -4951.3477
Q Predictions Mean           4958.1914
Q Predictions Std            562.25934
Q Predictions Max            5650.975
Q Predictions Min            3338.7078
V Predictions Mean           4943.2256
V Predictions Std            560.56805
V Predictions Max            5621.536
V Predictions Min            3327.0156
Log Pis Mean                 6.311094
Log Pis Std                  3.8516798
Log Pis Max                  15.276478
Log Pis Min                  -2.0044851
Policy mu Mean               -0.08319904
Policy mu Std                1.4655148
Policy mu Max                2.7613502
Policy mu Min                -2.8156707
Policy log std Mean          -0.8765113
Policy log std Std           0.49661404
Policy log std Max           -0.24898165
Policy log std Min           -3.7663023
Z mean eval                  4.1635485
Z variance eval              0.030330509
total_rewards                [11695.9810041  12517.03145229 12321.76958481 12313.48041017
 12109.22277298 12128.95277765 12039.93950242 12071.5878564
 12389.98658825 12271.35614746]
total_rewards_mean           12185.930809654008
total_rewards_std            218.3699067705049
total_rewards_max            12517.031452292169
total_rewards_min            11695.98100410314
Number of train steps total  1392000
Number of env steps total    1742000
Number of rollouts total     0
Train Time (s)               140.52888971194625
(Previous) Eval Time (s)     27.972269916906953
Sample Time (s)              22.17288786591962
Epoch Time (s)               190.67404749477282
Total Train Time (s)         63756.09260212025
Epoch                        347
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:30:20.582149 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #347 | Epoch Duration: 191.3539605140686
2020-01-13 22:30:20.582524 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #347 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.156892
Z variance train             0.030161355
KL Divergence                64.44656
KL Loss                      6.4446564
QF Loss                      697.4663
VF Loss                      1174.32
Policy Loss                  -4983.6953
Q Predictions Mean           4995.005
Q Predictions Std            579.10693
Q Predictions Max            5703.873
Q Predictions Min            3319.802
V Predictions Mean           5012.3726
V Predictions Std            580.19037
V Predictions Max            5701.481
V Predictions Min            3345.2588
Log Pis Mean                 5.600169
Log Pis Std                  3.823913
Log Pis Max                  15.714423
Log Pis Min                  -3.9779568
Policy mu Mean               -0.08398336
Policy mu Std                1.4054549
Policy mu Max                2.8404489
Policy mu Min                -2.787624
Policy log std Mean          -0.89066106
Policy log std Std           0.5100361
Policy log std Max           -0.07916927
Policy log std Min           -3.537508
Z mean eval                  4.0983467
Z variance eval              0.019488236
total_rewards                [11229.19707432 12434.98295595 12138.45367727 11342.3388188
 11222.88186979 12271.99997162 11886.84944605  1385.58909967
 11706.97220688 12053.30292866]
total_rewards_mean           10767.256804901775
total_rewards_std            3154.102122525206
total_rewards_max            12434.982955953325
total_rewards_min            1385.5890996672165
Number of train steps total  1396000
Number of env steps total    1747000
Number of rollouts total     0
Train Time (s)               138.48684438876808
(Previous) Eval Time (s)     28.651833427604288
Sample Time (s)              22.764711338095367
Epoch Time (s)               189.90338915446773
Total Train Time (s)         63945.24561319081
Epoch                        348
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:33:29.738422 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #348 | Epoch Duration: 189.15566229820251
2020-01-13 22:33:29.738621 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #348 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.097469
Z variance train             0.019377409
KL Divergence                64.30832
KL Loss                      6.430832
QF Loss                      659.3699
VF Loss                      327.50262
Policy Loss                  -4867.1406
Q Predictions Mean           4878.8975
Q Predictions Std            619.4493
Q Predictions Max            5635.5015
Q Predictions Min            3345.3525
V Predictions Mean           4876.5645
V Predictions Std            622.97266
V Predictions Max            5620.9307
V Predictions Min            3332.364
Log Pis Mean                 5.7699795
Log Pis Std                  4.0335765
Log Pis Max                  15.407725
Log Pis Min                  -4.308665
Policy mu Mean               -0.111630775
Policy mu Std                1.4266716
Policy mu Max                3.1712863
Policy mu Min                -3.3581607
Policy log std Mean          -0.8636586
Policy log std Std           0.5029555
Policy log std Max           -0.082891226
Policy log std Min           -3.8178911
Z mean eval                  4.049988
Z variance eval              0.01650451
total_rewards                [12136.35157537  4031.3218797  12195.5199571  12567.47877249
 12266.3038306  12196.23865653 12435.34903521 12393.01220909
 12092.26582051 12177.49544488]
total_rewards_mean           11449.133718146875
total_rewards_std            2476.642458595385
total_rewards_max            12567.478772494851
total_rewards_min            4031.3218796970814
Number of train steps total  1400000
Number of env steps total    1752000
Number of rollouts total     0
Train Time (s)               131.27440970670432
(Previous) Eval Time (s)     27.90375630510971
Sample Time (s)              22.163538249675184
Epoch Time (s)               181.3417042614892
Total Train Time (s)         64125.70623216685
Epoch                        349
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:36:30.203320 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #349 | Epoch Duration: 180.4645550251007
2020-01-13 22:36:30.203504 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #349 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.047769
Z variance train             0.016452631
KL Divergence                63.12897
KL Loss                      6.312897
QF Loss                      388.8857
VF Loss                      327.87018
Policy Loss                  -4872.6606
Q Predictions Mean           4879.4424
Q Predictions Std            576.9863
Q Predictions Max            5616.078
Q Predictions Min            3291.483
V Predictions Mean           4886.5547
V Predictions Std            577.66547
V Predictions Max            5614.588
V Predictions Min            3298.1992
Log Pis Mean                 5.944424
Log Pis Std                  3.8766642
Log Pis Max                  16.07951
Log Pis Min                  -5.9780045
Policy mu Mean               -0.022774467
Policy mu Std                1.4316525
Policy mu Max                3.4429436
Policy mu Min                -2.708463
Policy log std Mean          -0.8758555
Policy log std Std           0.47111285
Policy log std Max           -0.18227452
Policy log std Min           -3.5253263
Z mean eval                  4.0769086
Z variance eval              0.05011051
total_rewards                [11346.62468476 11815.4810357  11628.31444926 12100.37466535
 12227.10547497 11509.98080987 12365.50659147 12080.0748185
 11728.16273402 11841.76120001]
total_rewards_mean           11864.338646390705
total_rewards_std            309.1552214683774
total_rewards_max            12365.506591465768
total_rewards_min            11346.624684756203
Number of train steps total  1404000
Number of env steps total    1757000
Number of rollouts total     0
Train Time (s)               131.953080015257
(Previous) Eval Time (s)     27.026308570988476
Sample Time (s)              21.94381763180718
Epoch Time (s)               180.92320621805266
Total Train Time (s)         64306.12414435949
Epoch                        350
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:39:30.624849 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #350 | Epoch Duration: 180.42120385169983
2020-01-13 22:39:30.625040 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #350 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.0760775
Z variance train             0.050151955
KL Divergence                61.47988
KL Loss                      6.1479883
QF Loss                      715.42725
VF Loss                      207.7816
Policy Loss                  -4948.0337
Q Predictions Mean           4956.2266
Q Predictions Std            529.23505
Q Predictions Max            5669.9517
Q Predictions Min            3334.055
V Predictions Mean           4958.594
V Predictions Std            530.485
V Predictions Max            5668.4434
V Predictions Min            3348.7766
Log Pis Mean                 6.093484
Log Pis Std                  3.8511188
Log Pis Max                  18.268005
Log Pis Min                  -9.122805
Policy mu Mean               -0.12333999
Policy mu Std                1.4390211
Policy mu Max                2.9007819
Policy mu Min                -3.332758
Policy log std Mean          -0.8814812
Policy log std Std           0.49471685
Policy log std Max           -0.20687675
Policy log std Min           -3.5942817
Z mean eval                  4.101303
Z variance eval              0.01546506
total_rewards                [11874.05083519 12281.86114333  7148.95847899 12081.47897029
 11837.24646478 12243.62524926 12308.51726237 12258.34349075
 12377.6007722   9535.38013937]
total_rewards_mean           11394.706280653647
total_rewards_std            1625.898100340218
total_rewards_max            12377.60077220293
total_rewards_min            7148.958478985254
Number of train steps total  1408000
Number of env steps total    1762000
Number of rollouts total     0
Train Time (s)               138.49018695624545
(Previous) Eval Time (s)     26.52396539784968
Sample Time (s)              21.69187351036817
Epoch Time (s)               186.7060258644633
Total Train Time (s)         64495.22037683427
Epoch                        351
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:42:39.725364 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #351 | Epoch Duration: 189.1001751422882
2020-01-13 22:42:39.725563 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #351 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1025248
Z variance train             0.015444177
KL Divergence                63.957092
KL Loss                      6.3957095
QF Loss                      1203.541
VF Loss                      165.39856
Policy Loss                  -4899.596
Q Predictions Mean           4900.9844
Q Predictions Std            576.7504
Q Predictions Max            5599.042
Q Predictions Min            3305.1782
V Predictions Mean           4894.271
V Predictions Std            575.05316
V Predictions Max            5584.558
V Predictions Min            3306.812
Log Pis Mean                 5.783594
Log Pis Std                  3.6725206
Log Pis Max                  15.260518
Log Pis Min                  -3.113532
Policy mu Mean               -0.0526132
Policy mu Std                1.42367
Policy mu Max                2.9814787
Policy mu Min                -2.656233
Policy log std Mean          -0.90168375
Policy log std Std           0.5018685
Policy log std Max           -0.14192057
Policy log std Min           -3.4902015
Z mean eval                  4.087036
Z variance eval              0.007887825
total_rewards                [11999.19634097 11951.57918341 12395.27228709 12032.56622479
  3469.07793952 11797.41218344 12090.6098651  12263.51541572
 11771.61132353 12242.45639073]
total_rewards_mean           11201.329715430666
total_rewards_std            2584.3214537493777
total_rewards_max            12395.272287093152
total_rewards_min            3469.077939518848
Number of train steps total  1412000
Number of env steps total    1767000
Number of rollouts total     0
Train Time (s)               138.66077336203307
(Previous) Eval Time (s)     28.9177340217866
Sample Time (s)              22.80232136650011
Epoch Time (s)               190.38082875031978
Total Train Time (s)         64685.86923033744
Epoch                        352
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:45:50.377843 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #352 | Epoch Duration: 190.65213823318481
2020-01-13 22:45:50.378032 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #352 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.086898
Z variance train             0.007901708
KL Divergence                64.70129
KL Loss                      6.4701285
QF Loss                      1083.2344
VF Loss                      120.60452
Policy Loss                  -4962.5234
Q Predictions Mean           4965.8955
Q Predictions Std            673.6826
Q Predictions Max            5679.257
Q Predictions Min            130.15544
V Predictions Mean           4964.2427
V Predictions Std            672.24756
V Predictions Max            5671.4956
V Predictions Min            146.94997
Log Pis Mean                 5.976309
Log Pis Std                  4.2563944
Log Pis Max                  25.841461
Log Pis Min                  -7.6553373
Policy mu Mean               0.004227679
Policy mu Std                1.4608674
Policy mu Max                4.027685
Policy mu Min                -3.5595126
Policy log std Mean          -0.870658
Policy log std Std           0.46784845
Policy log std Max           0.17299175
Policy log std Min           -3.6729004
Z mean eval                  4.094403
Z variance eval              0.009731899
total_rewards                [11988.9827369   1972.30815524 12202.23459425 12148.92800476
 12155.09176905 12297.4086654  12134.91716498 12125.64048804
 12280.06369432 12114.84716371]
total_rewards_mean           11142.042243665592
total_rewards_std            3057.6953325557197
total_rewards_max            12297.408665403256
total_rewards_min            1972.3081552402987
Number of train steps total  1416000
Number of env steps total    1772000
Number of rollouts total     0
Train Time (s)               138.12354052998126
(Previous) Eval Time (s)     29.188689591828734
Sample Time (s)              21.987027993891388
Epoch Time (s)               189.29925811570138
Total Train Time (s)         64875.16166728875
Epoch                        353
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:48:59.674121 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #353 | Epoch Duration: 189.29594588279724
2020-01-13 22:48:59.674326 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #353 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.0918045
Z variance train             0.009708626
KL Divergence                66.073944
KL Loss                      6.6073947
QF Loss                      640.32965
VF Loss                      419.0166
Policy Loss                  -4950.409
Q Predictions Mean           4961.075
Q Predictions Std            589.95013
Q Predictions Max            5702.673
Q Predictions Min            3337.6836
V Predictions Mean           4961.285
V Predictions Std            591.1605
V Predictions Max            5705.541
V Predictions Min            3331.3323
Log Pis Mean                 5.6820235
Log Pis Std                  3.9872599
Log Pis Max                  16.034521
Log Pis Min                  -4.4072337
Policy mu Mean               -0.09007821
Policy mu Std                1.3937579
Policy mu Max                2.8132858
Policy mu Min                -2.7646122
Policy log std Mean          -0.90556186
Policy log std Std           0.50656265
Policy log std Max           -0.22018695
Policy log std Min           -3.8392448
Z mean eval                  4.0938883
Z variance eval              0.014407
total_rewards                [12075.29093819 12593.95956362 12191.77102333 12580.08098504
 12380.18573667 12386.01383457 12365.84705759 12048.46544946
 12310.23841577 12582.27648589]
total_rewards_mean           12351.412949013273
total_rewards_std            190.22375789268872
total_rewards_max            12593.959563621034
total_rewards_min            12048.465449457668
Number of train steps total  1420000
Number of env steps total    1777000
Number of rollouts total     0
Train Time (s)               139.28225095709786
(Previous) Eval Time (s)     29.185008249245584
Sample Time (s)              22.897618116345257
Epoch Time (s)               191.3648773226887
Total Train Time (s)         65065.53121346468
Epoch                        354
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:52:10.047838 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #354 | Epoch Duration: 190.37335562705994
2020-01-13 22:52:10.048070 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #354 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.0958433
Z variance train             0.014506484
KL Divergence                64.5272
KL Loss                      6.45272
QF Loss                      457.3747
VF Loss                      350.94153
Policy Loss                  -4942.1655
Q Predictions Mean           4943.2163
Q Predictions Std            575.0582
Q Predictions Max            5613.433
Q Predictions Min            3272.491
V Predictions Mean           4929.5107
V Predictions Std            572.55414
V Predictions Max            5597.75
V Predictions Min            3270.9026
Log Pis Mean                 5.9792194
Log Pis Std                  3.9111102
Log Pis Max                  16.522324
Log Pis Min                  -3.8635855
Policy mu Mean               -0.0083821
Policy mu Std                1.4542953
Policy mu Max                4.57315
Policy mu Min                -3.258217
Policy log std Mean          -0.88770646
Policy log std Std           0.50593877
Policy log std Max           0.30286705
Policy log std Min           -3.8051662
Z mean eval                  4.139895
Z variance eval              0.009366302
total_rewards                [11816.58535836  2544.23992592 11847.43534401  5496.37174246
 12169.3039464  12378.61638794 12081.09359592 12603.84937916
 11670.16009837 11404.90130494]
total_rewards_mean           10401.255708347975
total_rewards_std            3274.321672531526
total_rewards_max            12603.849379160723
total_rewards_min            2544.239925917869
Number of train steps total  1424000
Number of env steps total    1782000
Number of rollouts total     0
Train Time (s)               135.92633705306798
(Previous) Eval Time (s)     28.193076550029218
Sample Time (s)              22.81561301415786
Epoch Time (s)               186.93502661725506
Total Train Time (s)         65251.06172831124
Epoch                        355
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:55:15.582073 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #355 | Epoch Duration: 185.53385019302368
2020-01-13 22:55:15.582255 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #355 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.139902
Z variance train             0.009365676
KL Divergence                64.565155
KL Loss                      6.456516
QF Loss                      1757.4703
VF Loss                      361.52744
Policy Loss                  -4933.52
Q Predictions Mean           4942.6104
Q Predictions Std            524.45386
Q Predictions Max            5614.109
Q Predictions Min            3340.1147
V Predictions Mean           4934.4873
V Predictions Std            523.8199
V Predictions Max            5592.682
V Predictions Min            3336.3499
Log Pis Mean                 6.332651
Log Pis Std                  3.6814618
Log Pis Max                  14.811477
Log Pis Min                  -4.1851797
Policy mu Mean               -0.09707415
Policy mu Std                1.473933
Policy mu Max                3.1279478
Policy mu Min                -4.3110304
Policy log std Mean          -0.91179675
Policy log std Std           0.5399119
Policy log std Max           0.366616
Policy log std Min           -3.59776
Z mean eval                  4.0759974
Z variance eval              0.007392791
total_rewards                [11551.11913564  6517.2723799   4199.6484345  11384.93216866
 11827.67435226 11834.366855    5234.4129806  12183.98142231
 11680.51991228 12199.73335072]
total_rewards_mean           9861.366099186776
total_rewards_std            3029.094713578383
total_rewards_max            12199.733350719092
total_rewards_min            4199.6484344999935
Number of train steps total  1428000
Number of env steps total    1787000
Number of rollouts total     0
Train Time (s)               130.6948274942115
(Previous) Eval Time (s)     26.791514629963785
Sample Time (s)              21.100751949008554
Epoch Time (s)               178.58709407318383
Total Train Time (s)         65430.85720070079
Epoch                        356
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:58:15.381508 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #356 | Epoch Duration: 179.7991166114807
2020-01-13 22:58:15.381696 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #356 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.0768094
Z variance train             0.007325095
KL Divergence                64.50392
KL Loss                      6.4503922
QF Loss                      708.4977
VF Loss                      222.17422
Policy Loss                  -4968.4746
Q Predictions Mean           4978.1094
Q Predictions Std            529.9366
Q Predictions Max            5635.9985
Q Predictions Min            3336.8865
V Predictions Mean           4977.7905
V Predictions Std            531.0254
V Predictions Max            5630.9067
V Predictions Min            3341.0544
Log Pis Mean                 5.3541555
Log Pis Std                  3.8784795
Log Pis Max                  18.663647
Log Pis Min                  -3.9185252
Policy mu Mean               -0.033922527
Policy mu Std                1.4089098
Policy mu Max                3.0549514
Policy mu Min                -2.8348877
Policy log std Mean          -0.87845325
Policy log std Std           0.47827652
Policy log std Max           -0.19028938
Policy log std Min           -3.5761166
Z mean eval                  4.103018
Z variance eval              0.024271293
total_rewards                [12324.04412268 12062.95713337 12263.31203838 12451.02702351
 12504.78439022 12339.03519536 12146.33621741 12377.01387733
 12492.68059004 12495.1286647 ]
total_rewards_mean           12345.631925298747
total_rewards_std            144.32774392074043
total_rewards_max            12504.784390219611
total_rewards_min            12062.95713336657
Number of train steps total  1432000
Number of env steps total    1792000
Number of rollouts total     0
Train Time (s)               132.3847335758619
(Previous) Eval Time (s)     28.003236568067223
Sample Time (s)              21.98303531249985
Epoch Time (s)               182.37100545642897
Total Train Time (s)         65610.80292767892
Epoch                        357
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:01:15.331040 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #357 | Epoch Duration: 179.94920110702515
2020-01-13 23:01:15.331249 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #357 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1047373
Z variance train             0.02426295
KL Divergence                66.30346
KL Loss                      6.630346
QF Loss                      447.9825
VF Loss                      118.86098
Policy Loss                  -4978.2617
Q Predictions Mean           4984.5396
Q Predictions Std            657.42816
Q Predictions Max            5656.2954
Q Predictions Min            51.3167
V Predictions Mean           4980.0405
V Predictions Std            655.26843
V Predictions Max            5650.7593
V Predictions Min            104.64009
Log Pis Mean                 5.794028
Log Pis Std                  3.8469145
Log Pis Max                  15.422541
Log Pis Min                  -4.5655155
Policy mu Mean               -0.07497083
Policy mu Std                1.4279306
Policy mu Max                3.291987
Policy mu Min                -3.2098947
Policy log std Mean          -0.9185743
Policy log std Std           0.5227034
Policy log std Max           -0.22851914
Policy log std Min           -3.5695596
Z mean eval                  4.1528225
Z variance eval              0.008995088
total_rewards                [12081.42528399 11245.60472709 12149.55035019 11916.99721805
 11731.22255723 12013.09978653 11961.43406237  8014.79692196
 12109.12582183 12163.02388486]
total_rewards_mean           11538.628061410065
total_rewards_std            1202.9374660155868
total_rewards_max            12163.023884857661
total_rewards_min            8014.79692196371
Number of train steps total  1436000
Number of env steps total    1797000
Number of rollouts total     0
Train Time (s)               139.94060034072027
(Previous) Eval Time (s)     25.581116673070937
Sample Time (s)              22.676213514991105
Epoch Time (s)               188.1979305287823
Total Train Time (s)         65802.2490767357
Epoch                        358
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:04:26.781306 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #358 | Epoch Duration: 191.44990229606628
2020-01-13 23:04:26.781523 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #358 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1542206
Z variance train             0.009011609
KL Divergence                66.31845
KL Loss                      6.631845
QF Loss                      479.97388
VF Loss                      110.29573
Policy Loss                  -5024.962
Q Predictions Mean           5028.545
Q Predictions Std            539.5612
Q Predictions Max            5676.5205
Q Predictions Min            3434.693
V Predictions Mean           5023.389
V Predictions Std            539.1728
V Predictions Max            5669.8276
V Predictions Min            3431.1267
Log Pis Mean                 6.252905
Log Pis Std                  4.07417
Log Pis Max                  14.95657
Log Pis Min                  -2.1094267
Policy mu Mean               -0.005235344
Policy mu Std                1.4591852
Policy mu Max                2.9055886
Policy mu Min                -2.8011363
Policy log std Mean          -0.91677016
Policy log std Std           0.5257947
Policy log std Max           -0.18200755
Policy log std Min           -3.5451663
Z mean eval                  4.1495643
Z variance eval              0.004336839
total_rewards                [12351.12875851 12520.31772509 12582.21427422 12599.51390652
 12334.74629853 12220.66890174 12466.36417171 12355.74845595
 12139.21999978 11989.29122831]
total_rewards_mean           12355.92137203628
total_rewards_std            187.0591708161903
total_rewards_max            12599.513906523745
total_rewards_min            11989.291228308553
Number of train steps total  1440000
Number of env steps total    1802000
Number of rollouts total     0
Train Time (s)               138.69488154212013
(Previous) Eval Time (s)     28.83276697807014
Sample Time (s)              22.273375927004963
Epoch Time (s)               189.80102444719523
Total Train Time (s)         65991.44621835882
Epoch                        359
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:07:35.982381 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #359 | Epoch Duration: 189.20070958137512
2020-01-13 23:07:35.982601 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #359 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.149265
Z variance train             0.004346265
KL Divergence                68.18863
KL Loss                      6.818863
QF Loss                      678.4369
VF Loss                      494.65128
Policy Loss                  -4990.794
Q Predictions Mean           4995.3135
Q Predictions Std            644.14014
Q Predictions Max            5707.6924
Q Predictions Min            62.54823
V Predictions Mean           5005.4834
V Predictions Std            645.4785
V Predictions Max            5712.797
V Predictions Min            57.853558
Log Pis Mean                 6.1921787
Log Pis Std                  3.831417
Log Pis Max                  15.60107
Log Pis Min                  -3.5125568
Policy mu Mean               -0.113081396
Policy mu Std                1.4375659
Policy mu Max                3.2896714
Policy mu Min                -2.9915462
Policy log std Mean          -0.8997843
Policy log std Std           0.52072555
Policy log std Max           0.23400629
Policy log std Min           -3.469062
Z mean eval                  4.1404734
Z variance eval              0.007970263
total_rewards                [11793.0750438  12191.95418629 12107.09559542 12092.72386248
 12246.11504002 12337.24473081 12330.33196387 12303.93196965
 12198.82113593 12441.05583879]
total_rewards_mean           12204.234936705167
total_rewards_std            171.0184205242834
total_rewards_max            12441.055838792014
total_rewards_min            11793.0750438008
Number of train steps total  1444000
Number of env steps total    1807000
Number of rollouts total     0
Train Time (s)               137.75300415372476
(Previous) Eval Time (s)     28.232117499690503
Sample Time (s)              21.853364762384444
Epoch Time (s)               187.8384864157997
Total Train Time (s)         66179.84456740133
Epoch                        360
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:10:44.384173 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #360 | Epoch Duration: 188.40142822265625
2020-01-13 23:10:44.384353 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #360 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1418886
Z variance train             0.007950054
KL Divergence                65.46524
KL Loss                      6.546524
QF Loss                      603.1679
VF Loss                      577.39215
Policy Loss                  -4894.539
Q Predictions Mean           4904.0146
Q Predictions Std            743.64014
Q Predictions Max            5687.7417
Q Predictions Min            -6.7665772
V Predictions Mean           4906.9287
V Predictions Std            744.66785
V Predictions Max            5720.323
V Predictions Min            -10.304663
Log Pis Mean                 5.454364
Log Pis Std                  4.0530868
Log Pis Max                  15.201897
Log Pis Min                  -2.819105
Policy mu Mean               -0.039013524
Policy mu Std                1.3967285
Policy mu Max                2.9414148
Policy mu Min                -2.8715823
Policy log std Mean          -0.89407206
Policy log std Std           0.49485347
Policy log std Max           0.24289429
Policy log std Min           -3.4617906
Z mean eval                  4.1518173
Z variance eval              0.0032915468
total_rewards                [11672.39191628 12375.42109776 12222.89228496 12116.28422116
 12160.34196185 12476.52264527 12216.84938846 12469.87826114
 12248.90264534 12212.4532592 ]
total_rewards_mean           12217.193768141766
total_rewards_std            216.19927074441247
total_rewards_max            12476.52264526856
total_rewards_min            11672.391916275916
Number of train steps total  1448000
Number of env steps total    1812000
Number of rollouts total     0
Train Time (s)               138.90707805706188
(Previous) Eval Time (s)     28.794744450133294
Sample Time (s)              23.79256957117468
Epoch Time (s)               191.49439207836986
Total Train Time (s)         66370.96298252046
Epoch                        361
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:13:55.506571 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #361 | Epoch Duration: 191.12208223342896
2020-01-13 23:13:55.506758 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #361 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.151332
Z variance train             0.0032929424
KL Divergence                66.90354
KL Loss                      6.6903543
QF Loss                      530.0043
VF Loss                      147.84055
Policy Loss                  -5006.9517
Q Predictions Mean           5014.4326
Q Predictions Std            693.24347
Q Predictions Max            5687.003
Q Predictions Min            87.32371
V Predictions Mean           5013.4985
V Predictions Std            693.78577
V Predictions Max            5697.764
V Predictions Min            86.46898
Log Pis Mean                 6.1578865
Log Pis Std                  4.036611
Log Pis Max                  27.229425
Log Pis Min                  -5.1023417
Policy mu Mean               -0.14896768
Policy mu Std                1.4516094
Policy mu Max                4.668161
Policy mu Min                -4.9965115
Policy log std Mean          -0.8951165
Policy log std Std           0.49829477
Policy log std Max           -0.13251162
Policy log std Min           -3.547894
Z mean eval                  4.0927916
Z variance eval              0.004245051
total_rewards                [12329.05764257 12325.25816852 11972.50576229 12233.49534755
 12144.0906946  12304.49708017 12240.41175046 12416.6818646
 12340.01166386  3306.97274239]
total_rewards_mean           11361.298271700687
total_rewards_std            2687.3626822735478
total_rewards_max            12416.681864602437
total_rewards_min            3306.972742385742
Number of train steps total  1452000
Number of env steps total    1817000
Number of rollouts total     0
Train Time (s)               133.26626233570278
(Previous) Eval Time (s)     28.422035691794008
Sample Time (s)              23.488684358540922
Epoch Time (s)               185.1769823860377
Total Train Time (s)         66554.58912458224
Epoch                        362
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:16:59.134775 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #362 | Epoch Duration: 183.62789463996887
2020-01-13 23:16:59.134898 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #362 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.091404
Z variance train             0.004240893
KL Divergence                65.6841
KL Loss                      6.56841
QF Loss                      699.3795
VF Loss                      132.07803
Policy Loss                  -4976.365
Q Predictions Mean           4984.4717
Q Predictions Std            555.09564
Q Predictions Max            5692.131
Q Predictions Min            3317.5247
V Predictions Mean           4975.8364
V Predictions Std            551.2323
V Predictions Max            5666.2163
V Predictions Min            3324.8225
Log Pis Mean                 6.37764
Log Pis Std                  4.3365636
Log Pis Max                  22.30473
Log Pis Min                  -6.4126477
Policy mu Mean               -0.058610708
Policy mu Std                1.4791756
Policy mu Max                4.132457
Policy mu Min                -4.2097926
Policy log std Mean          -0.9185138
Policy log std Std           0.53032357
Policy log std Max           -0.11450982
Policy log std Min           -3.518579
Z mean eval                  4.1242423
Z variance eval              0.010060681
total_rewards                [11924.76727679 12382.19255932 12589.26540413 12626.97218495
 12794.24225802 12008.09760293 11939.29885153 12581.1041672
 12398.65930359 12566.94478815]
total_rewards_mean           12381.154439661299
total_rewards_std            298.6436898420552
total_rewards_max            12794.242258016555
total_rewards_min            11924.767276791616
Number of train steps total  1456000
Number of env steps total    1822000
Number of rollouts total     0
Train Time (s)               132.21570700081065
(Previous) Eval Time (s)     26.872415758669376
Sample Time (s)              20.42835858045146
Epoch Time (s)               179.5164813399315
Total Train Time (s)         66733.81614686223
Epoch                        363
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:19:58.366294 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #363 | Epoch Duration: 179.2312831878662
2020-01-13 23:19:58.366485 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #363 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.123955
Z variance train             0.010056393
KL Divergence                65.93659
KL Loss                      6.5936594
QF Loss                      654.16614
VF Loss                      217.20102
Policy Loss                  -4981.4146
Q Predictions Mean           4982.951
Q Predictions Std            536.4974
Q Predictions Max            5702.1963
Q Predictions Min            3415.3928
V Predictions Mean           4983.381
V Predictions Std            536.7241
V Predictions Max            5717.415
V Predictions Min            3416.4592
Log Pis Mean                 6.1633024
Log Pis Std                  3.865744
Log Pis Max                  15.6454315
Log Pis Min                  -6.1531734
Policy mu Mean               -0.029333666
Policy mu Std                1.4518116
Policy mu Max                3.0337899
Policy mu Min                -2.830476
Policy log std Mean          -0.9032909
Policy log std Std           0.4945467
Policy log std Max           -0.017227113
Policy log std Min           -3.487454
Z mean eval                  4.125997
Z variance eval              0.030566882
total_rewards                [11640.3008147  12210.71409731 12002.72643863 12143.05149565
 12097.22137434 11999.99203681 12123.68469408 12229.55113316
 12031.528035   11823.6382508 ]
total_rewards_mean           12030.240837048632
total_rewards_std            171.65404797933414
total_rewards_max            12229.55113315578
total_rewards_min            11640.300814700515
Number of train steps total  1460000
Number of env steps total    1827000
Number of rollouts total     0
Train Time (s)               134.46096474211663
(Previous) Eval Time (s)     26.586923031136394
Sample Time (s)              22.46410240419209
Epoch Time (s)               183.5119901774451
Total Train Time (s)         66919.33657614654
Epoch                        364
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:23:03.890821 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #364 | Epoch Duration: 185.52417945861816
2020-01-13 23:23:03.891053 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #364 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1262403
Z variance train             0.03084768
KL Divergence                66.532745
KL Loss                      6.6532745
QF Loss                      670.14545
VF Loss                      174.7716
Policy Loss                  -4958.067
Q Predictions Mean           4965.8833
Q Predictions Std            560.068
Q Predictions Max            5681.342
Q Predictions Min            3328.0627
V Predictions Mean           4951.0293
V Predictions Std            557.8679
V Predictions Max            5660.9204
V Predictions Min            3340.378
Log Pis Mean                 6.237502
Log Pis Std                  4.178431
Log Pis Max                  16.164263
Log Pis Min                  -5.235409
Policy mu Mean               -0.09584564
Policy mu Std                1.4756416
Policy mu Max                3.3286905
Policy mu Min                -3.0667183
Policy log std Mean          -0.9227864
Policy log std Std           0.5442244
Policy log std Max           -0.12326014
Policy log std Min           -3.562067
Z mean eval                  4.0592256
Z variance eval              0.15863016
total_rewards                [11775.10651019 11435.91330168 12012.21571049 11689.73064275
 11741.10299358 11933.31042249 11453.00542487 11951.68203879
 11928.78091324 11522.61480373]
total_rewards_mean           11744.346276181797
total_rewards_std            204.34787784670385
total_rewards_max            12012.215710491537
total_rewards_min            11435.913301684544
Number of train steps total  1464000
Number of env steps total    1832000
Number of rollouts total     0
Train Time (s)               140.58992241090164
(Previous) Eval Time (s)     28.59879386704415
Sample Time (s)              22.86514945793897
Epoch Time (s)               192.05386573588476
Total Train Time (s)         67111.18066219846
Epoch                        365
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:26:15.738743 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #365 | Epoch Duration: 191.84754276275635
2020-01-13 23:26:15.738944 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #365 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.0614443
Z variance train             0.1595843
KL Divergence                59.96817
KL Loss                      5.996817
QF Loss                      1381.4951
VF Loss                      1156.2087
Policy Loss                  -5142.8354
Q Predictions Mean           5153.918
Q Predictions Std            523.4009
Q Predictions Max            5834.9863
Q Predictions Min            3394.8186
V Predictions Mean           5118.107
V Predictions Std            518.43
V Predictions Max            5766.059
V Predictions Min            3478.4824
Log Pis Mean                 6.426488
Log Pis Std                  4.683485
Log Pis Max                  17.020617
Log Pis Min                  -4.922203
Policy mu Mean               -0.05183244
Policy mu Std                1.497309
Policy mu Max                4.372202
Policy mu Min                -3.0431256
Policy log std Mean          -0.8969667
Policy log std Std           0.51932234
Policy log std Max           -0.020414948
Policy log std Min           -3.4863796
Z mean eval                  4.1044617
Z variance eval              0.030909818
total_rewards                [11959.16689637 12266.4346153  12205.93474876 12020.26661133
 12217.3034821  12292.5094405  11993.3909579  11922.94453821
 12153.0287543   8956.38948973]
total_rewards_mean           11798.73695345049
total_rewards_std            955.8322552332291
total_rewards_max            12292.509440501231
total_rewards_min            8956.389489725503
Number of train steps total  1468000
Number of env steps total    1837000
Number of rollouts total     0
Train Time (s)               139.54003255721182
(Previous) Eval Time (s)     28.39212506171316
Sample Time (s)              21.818499500397593
Epoch Time (s)               189.75065711932257
Total Train Time (s)         67301.03257160774
Epoch                        366
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:29:25.594703 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #366 | Epoch Duration: 189.85561680793762
2020-01-13 23:29:25.594900 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #366 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.103688
Z variance train             0.030905258
KL Divergence                62.333527
KL Loss                      6.2333527
QF Loss                      611.06305
VF Loss                      207.45058
Policy Loss                  -4899.229
Q Predictions Mean           4907.4062
Q Predictions Std            596.6007
Q Predictions Max            5635.0586
Q Predictions Min            3300.7896
V Predictions Mean           4904.616
V Predictions Std            595.9778
V Predictions Max            5629.8203
V Predictions Min            3299.9587
Log Pis Mean                 6.476895
Log Pis Std                  4.174939
Log Pis Max                  23.999918
Log Pis Min                  -4.6739073
Policy mu Mean               -0.114676796
Policy mu Std                1.4784261
Policy mu Max                4.687526
Policy mu Min                -3.9625788
Policy log std Mean          -0.90962726
Policy log std Std           0.5277988
Policy log std Max           0.053224564
Policy log std Min           -3.6406107
Z mean eval                  4.0819945
Z variance eval              0.011970414
total_rewards                [12154.79443303 12263.2420756  12030.63532782 12414.89798954
 12037.72383132 12310.5175912  12072.60752182 11812.46206221
 12468.00373865 12385.45101919]
total_rewards_mean           12195.03355903655
total_rewards_std            197.95005940941118
total_rewards_max            12468.003738651245
total_rewards_min            11812.462062211052
Number of train steps total  1472000
Number of env steps total    1842000
Number of rollouts total     0
Train Time (s)               139.8883690708317
(Previous) Eval Time (s)     28.496772286016494
Sample Time (s)              22.445494208484888
Epoch Time (s)               190.83063556533307
Total Train Time (s)         67491.93994431198
Epoch                        367
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:32:36.506740 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #367 | Epoch Duration: 190.9116792678833
2020-01-13 23:32:36.507028 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #367 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.080518
Z variance train             0.011965756
KL Divergence                63.899025
KL Loss                      6.3899026
QF Loss                      1098.8718
VF Loss                      304.1602
Policy Loss                  -4957.203
Q Predictions Mean           4957.506
Q Predictions Std            572.4759
Q Predictions Max            5627.3213
Q Predictions Min            3318.4253
V Predictions Mean           4964.539
V Predictions Std            575.33655
V Predictions Max            5595.3936
V Predictions Min            3312.941
Log Pis Mean                 5.895712
Log Pis Std                  3.9309583
Log Pis Max                  15.359852
Log Pis Min                  -4.154932
Policy mu Mean               -0.15373857
Policy mu Std                1.4543492
Policy mu Max                2.8674614
Policy mu Min                -3.0714664
Policy log std Mean          -0.89885265
Policy log std Std           0.49342248
Policy log std Max           -0.14939862
Policy log std Min           -3.5340283
Z mean eval                  4.1038365
Z variance eval              0.020293709
total_rewards                [12102.44549739 12478.07497087 12222.55734649 12405.48006943
 12215.28320889 12312.99872742 12429.57292019 12253.23871501
 12235.00463246 12292.27325722]
total_rewards_mean           12294.692934535142
total_rewards_std            108.71338387220581
total_rewards_max            12478.074970868542
total_rewards_min            12102.445497392444
Number of train steps total  1476000
Number of env steps total    1847000
Number of rollouts total     0
Train Time (s)               139.4956168718636
(Previous) Eval Time (s)     28.577481335029006
Sample Time (s)              22.784195132553577
Epoch Time (s)               190.8572933394462
Total Train Time (s)         67683.21282703336
Epoch                        368
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:35:47.783926 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #368 | Epoch Duration: 191.27672028541565
2020-01-13 23:35:47.784160 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #368 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.101889
Z variance train             0.020318659
KL Divergence                63.25498
KL Loss                      6.325498
QF Loss                      502.9161
VF Loss                      150.67812
Policy Loss                  -4987.409
Q Predictions Mean           4991.9375
Q Predictions Std            569.06177
Q Predictions Max            5636.0186
Q Predictions Min            3357.844
V Predictions Mean           4993.243
V Predictions Std            568.7279
V Predictions Max            5634.9624
V Predictions Min            3370.707
Log Pis Mean                 6.525298
Log Pis Std                  3.986472
Log Pis Max                  16.29639
Log Pis Min                  -3.4168727
Policy mu Mean               -0.01173392
Policy mu Std                1.5027516
Policy mu Max                3.215362
Policy mu Min                -3.1368165
Policy log std Mean          -0.90332
Policy log std Std           0.50999105
Policy log std Max           -0.111628056
Policy log std Min           -3.6710455
Z mean eval                  4.069627
Z variance eval              0.023812648
total_rewards                [11752.3646211  12250.0144738  11810.92956707 11418.04472322
 11874.86362265 12170.52684454 12155.51116304 12277.94342859
 11595.72750359 12005.08298684]
total_rewards_mean           11931.100893443738
total_rewards_std            275.7564322030154
total_rewards_max            12277.943428588218
total_rewards_min            11418.044723222736
Number of train steps total  1480000
Number of env steps total    1852000
Number of rollouts total     0
Train Time (s)               132.29251608299091
(Previous) Eval Time (s)     28.99652282660827
Sample Time (s)              21.169783908873796
Epoch Time (s)               182.45882281847298
Total Train Time (s)         67864.6354319239
Epoch                        369
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:38:49.210250 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #369 | Epoch Duration: 181.42593622207642
2020-01-13 23:38:49.210423 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #369 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.0702987
Z variance train             0.023892086
KL Divergence                61.841133
KL Loss                      6.1841135
QF Loss                      601.17346
VF Loss                      294.91754
Policy Loss                  -5027.2153
Q Predictions Mean           5033.6577
Q Predictions Std            589.1365
Q Predictions Max            5764.2793
Q Predictions Min            3400.588
V Predictions Mean           5017.556
V Predictions Std            585.4205
V Predictions Max            5742.3525
V Predictions Min            3391.9995
Log Pis Mean                 6.1238966
Log Pis Std                  4.0183244
Log Pis Max                  15.823329
Log Pis Min                  -4.041654
Policy mu Mean               -0.033513322
Policy mu Std                1.457305
Policy mu Max                3.7095814
Policy mu Min                -3.1718173
Policy log std Mean          -0.8974083
Policy log std Std           0.50397396
Policy log std Max           -0.18737832
Policy log std Min           -3.8915243
Z mean eval                  4.1008406
Z variance eval              0.042588733
total_rewards                [11101.84975352 12425.3976382   2350.4654254  11787.56271647
 11530.26334656 12056.17791629 12174.83691805 11022.2798547
 12274.02827136  8917.65087643]
total_rewards_mean           10564.051271696888
total_rewards_std            2903.671423283931
total_rewards_max            12425.397638195023
total_rewards_min            2350.4654253966883
Number of train steps total  1484000
Number of env steps total    1857000
Number of rollouts total     0
Train Time (s)               132.09073802642524
(Previous) Eval Time (s)     27.9633225556463
Sample Time (s)              22.11984954541549
Epoch Time (s)               182.17391012748703
Total Train Time (s)         68046.8763243556
Epoch                        370
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:41:51.455498 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #370 | Epoch Duration: 182.24493932724
2020-01-13 23:41:51.455692 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #370 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.101149
Z variance train             0.04263758
KL Divergence                61.28483
KL Loss                      6.128483
QF Loss                      613.856
VF Loss                      128.19461
Policy Loss                  -5046.9497
Q Predictions Mean           5056.7305
Q Predictions Std            606.8754
Q Predictions Max            5756.437
Q Predictions Min            3376.718
V Predictions Mean           5050.384
V Predictions Std            607.2927
V Predictions Max            5764.503
V Predictions Min            3381.8867
Log Pis Mean                 6.3999863
Log Pis Std                  4.1531568
Log Pis Max                  16.695713
Log Pis Min                  -5.8166723
Policy mu Mean               -0.055209607
Policy mu Std                1.4859717
Policy mu Max                3.3797243
Policy mu Min                -2.7920191
Policy log std Mean          -0.8888862
Policy log std Std           0.5204057
Policy log std Max           -0.13288814
Policy log std Min           -3.540372
Z mean eval                  4.0773134
Z variance eval              0.012271598
total_rewards                [11996.9283721  12207.31970297  3300.45540832 12032.12589921
 12347.78023541 12183.74908009 12262.90666096 12491.53058994
 12259.25768638 11997.0510335 ]
total_rewards_mean           11307.910466886708
total_rewards_std            2673.366419813874
total_rewards_max            12491.53058993539
total_rewards_min            3300.4554083186417
Number of train steps total  1488000
Number of env steps total    1862000
Number of rollouts total     0
Train Time (s)               136.53962247120216
(Previous) Eval Time (s)     28.033996724989265
Sample Time (s)              21.401633476372808
Epoch Time (s)               185.97525267256424
Total Train Time (s)         68233.75344179198
Epoch                        371
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:44:58.336574 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #371 | Epoch Duration: 186.88073921203613
2020-01-13 23:44:58.336773 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #371 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.0756083
Z variance train             0.012281959
KL Divergence                63.95378
KL Loss                      6.395378
QF Loss                      581.44556
VF Loss                      296.3971
Policy Loss                  -4876.7837
Q Predictions Mean           4883.999
Q Predictions Std            616.19604
Q Predictions Max            5647.031
Q Predictions Min            3317.3923
V Predictions Mean           4884.923
V Predictions Std            616.3832
V Predictions Max            5649.465
V Predictions Min            3325.7437
Log Pis Mean                 6.074688
Log Pis Std                  3.991168
Log Pis Max                  15.983311
Log Pis Min                  -4.7914543
Policy mu Mean               -0.11624917
Policy mu Std                1.4759094
Policy mu Max                3.361587
Policy mu Min                -3.3786755
Policy log std Mean          -0.8850134
Policy log std Std           0.50288725
Policy log std Max           -0.14742449
Policy log std Min           -3.5593157
Z mean eval                  4.0221243
Z variance eval              0.015459339
total_rewards                [11727.58394517 11825.3487523  11066.64427822 11100.24098295
 11438.96194525 11939.93044035 11378.31768478 11348.10680149
 10910.92005628 11695.56126899]
total_rewards_mean           11443.161615578956
total_rewards_std            330.6579278768418
total_rewards_max            11939.930440347627
total_rewards_min            10910.920056281955
Number of train steps total  1492000
Number of env steps total    1867000
Number of rollouts total     0
Train Time (s)               139.5028389627114
(Previous) Eval Time (s)     28.93914887914434
Sample Time (s)              22.318598004989326
Epoch Time (s)               190.76058584684506
Total Train Time (s)         68424.44484881498
Epoch                        372
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:48:09.031267 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #372 | Epoch Duration: 190.69435214996338
2020-01-13 23:48:09.031455 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #372 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.021718
Z variance train             0.015491006
KL Divergence                60.63347
KL Loss                      6.063347
QF Loss                      302.97015
VF Loss                      125.29912
Policy Loss                  -4892.991
Q Predictions Mean           4898.447
Q Predictions Std            634.11755
Q Predictions Max            5652.177
Q Predictions Min            3330.2268
V Predictions Mean           4893.4272
V Predictions Std            633.8159
V Predictions Max            5635.508
V Predictions Min            3332.106
Log Pis Mean                 5.6357155
Log Pis Std                  3.8601432
Log Pis Max                  15.807512
Log Pis Min                  -9.599418
Policy mu Mean               0.0005878086
Policy mu Std                1.4121481
Policy mu Max                2.8990679
Policy mu Min                -2.913558
Policy log std Mean          -0.8827486
Policy log std Std           0.5066374
Policy log std Max           -0.1717611
Policy log std Min           -3.6025996
Z mean eval                  4.002758
Z variance eval              0.06321309
total_rewards                [12252.88282318 12149.16222615 12243.84270084 12096.48807676
 11953.96833901 12043.23446635  6951.5618654  12045.02132849
 12107.79801579 12276.66549066]
total_rewards_mean           11612.062533263772
total_rewards_std            1556.6284200278892
total_rewards_max            12276.665490661588
total_rewards_min            6951.561865404352
Number of train steps total  1496000
Number of env steps total    1872000
Number of rollouts total     0
Train Time (s)               139.66324004810303
(Previous) Eval Time (s)     28.87255811970681
Sample Time (s)              23.163725544232875
Epoch Time (s)               191.69952371204272
Total Train Time (s)         68615.7080964339
Epoch                        373
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:51:20.299295 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #373 | Epoch Duration: 191.2677173614502
2020-01-13 23:51:20.299503 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #373 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.0028477
Z variance train             0.06312069
KL Divergence                57.233345
KL Loss                      5.723335
QF Loss                      1021.7348
VF Loss                      226.25717
Policy Loss                  -4799.504
Q Predictions Mean           4805.6133
Q Predictions Std            550.1244
Q Predictions Max            5451.159
Q Predictions Min            3218.9307
V Predictions Mean           4792.5693
V Predictions Std            547.6979
V Predictions Max            5453.7827
V Predictions Min            3218.9502
Log Pis Mean                 5.857665
Log Pis Std                  3.8120272
Log Pis Max                  15.830649
Log Pis Min                  -3.5191793
Policy mu Mean               -0.049699273
Policy mu Std                1.4145854
Policy mu Max                3.050096
Policy mu Min                -3.3889964
Policy log std Mean          -0.9197027
Policy log std Std           0.49426758
Policy log std Max           -0.24873665
Policy log std Min           -3.449823
Z mean eval                  4.0910826
Z variance eval              0.023689644
total_rewards                [11781.63204223 12038.12377565 11843.91085514 11698.85107964
 12196.51261608 11993.62974741 11925.83290353 11797.4122107
 11949.29553187 10270.32745742]
total_rewards_mean           11749.552821966248
total_rewards_std            511.51666614171654
total_rewards_max            12196.512616083359
total_rewards_min            10270.32745741519
Number of train steps total  1500000
Number of env steps total    1877000
Number of rollouts total     0
Train Time (s)               141.39560309704393
(Previous) Eval Time (s)     28.440360265783966
Sample Time (s)              22.665999229997396
Epoch Time (s)               192.5019625928253
Total Train Time (s)         68807.32253002375
Epoch                        374
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:54:31.917193 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #374 | Epoch Duration: 191.61753249168396
2020-01-13 23:54:31.917392 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #374 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.091648
Z variance train             0.023742463
KL Divergence                60.644737
KL Loss                      6.0644736
QF Loss                      812.3993
VF Loss                      225.34796
Policy Loss                  -4950.1147
Q Predictions Mean           4960.1973
Q Predictions Std            629.60846
Q Predictions Max            5702.429
Q Predictions Min            463.71567
V Predictions Mean           4956.2734
V Predictions Std            625.82935
V Predictions Max            5674.585
V Predictions Min            517.37537
Log Pis Mean                 5.8954945
Log Pis Std                  4.116927
Log Pis Max                  20.761204
Log Pis Min                  -2.9272523
Policy mu Mean               -0.014356486
Policy mu Std                1.4420519
Policy mu Max                3.4765306
Policy mu Min                -3.7162566
Policy log std Mean          -0.9051631
Policy log std Std           0.50028735
Policy log std Max           -0.099072576
Policy log std Min           -3.7973633
Z mean eval                  4.0291514
Z variance eval              0.03579397
total_rewards                [12064.19032331 12374.98859268 12135.64727761 12400.79955109
 12067.30758059 12235.92312346 12233.80718375 12191.95269947
 12344.94925045 11881.00104972]
total_rewards_mean           12193.05666321292
total_rewards_std            153.59718694109645
total_rewards_max            12400.799551092763
total_rewards_min            11881.0010497199
Number of train steps total  1504000
Number of env steps total    1882000
Number of rollouts total     0
Train Time (s)               137.80679528042674
(Previous) Eval Time (s)     27.555532759055495
Sample Time (s)              22.3726142863743
Epoch Time (s)               187.73494232585654
Total Train Time (s)         68994.7137848069
Epoch                        375
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:57:39.312717 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #375 | Epoch Duration: 187.39518308639526
2020-01-13 23:57:39.312914 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #375 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.028461
Z variance train             0.035861462
KL Divergence                59.802
KL Loss                      5.9802
QF Loss                      430.03564
VF Loss                      129.71915
Policy Loss                  -4953.591
Q Predictions Mean           4961.43
Q Predictions Std            618.3554
Q Predictions Max            5729.6406
Q Predictions Min            3371.1606
V Predictions Mean           4954.091
V Predictions Std            617.7261
V Predictions Max            5709.181
V Predictions Min            3372.0637
Log Pis Mean                 5.8967166
Log Pis Std                  4.186856
Log Pis Max                  18.282509
Log Pis Min                  -5.600425
Policy mu Mean               -0.0007968123
Policy mu Std                1.453839
Policy mu Max                3.062347
Policy mu Min                -3.0170376
Policy log std Mean          -0.8787444
Policy log std Std           0.489352
Policy log std Max           -0.09654409
Policy log std Min           -3.5952992
Z mean eval                  4.0463743
Z variance eval              0.01848796
total_rewards                [11893.14377021 12210.77285421 12120.58900804  9186.81123638
 12148.72290378 11919.09844692 11834.34888405 12089.7376788
 12349.46584375 11442.75346566]
total_rewards_mean           11719.544409179862
total_rewards_std            877.1926571106483
total_rewards_max            12349.46584374786
total_rewards_min            9186.81123638273
Number of train steps total  1508000
Number of env steps total    1887000
Number of rollouts total     0
Train Time (s)               132.38729413878173
(Previous) Eval Time (s)     27.215446521062404
Sample Time (s)              22.02183129824698
Epoch Time (s)               181.6245719580911
Total Train Time (s)         69175.60189228039
Epoch                        376
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:00:40.203823 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #376 | Epoch Duration: 180.89076781272888
2020-01-14 00:00:40.204006 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #376 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.048444
Z variance train             0.018443868
KL Divergence                60.829773
KL Loss                      6.0829773
QF Loss                      545.44574
VF Loss                      292.45392
Policy Loss                  -4979.8784
Q Predictions Mean           4983.993
Q Predictions Std            604.2725
Q Predictions Max            5759.7017
Q Predictions Min            3385.6792
V Predictions Mean           4968.6035
V Predictions Std            603.2409
V Predictions Max            5729.5767
V Predictions Min            3375.163
Log Pis Mean                 6.530697
Log Pis Std                  4.160148
Log Pis Max                  17.3216
Log Pis Min                  -3.564955
Policy mu Mean               -0.02932939
Policy mu Std                1.4789294
Policy mu Max                3.1556454
Policy mu Min                -2.752317
Policy log std Mean          -0.89861625
Policy log std Std           0.50498897
Policy log std Max           -0.14574468
Policy log std Min           -3.7253203
Z mean eval                  4.049829
Z variance eval              0.00831378
total_rewards                [12373.59181999 12108.39982727 12178.47413488 12374.74149774
 12124.6480623  12052.80916687 12215.8629551  12390.29001237
 11974.29842285 12388.42032859]
total_rewards_mean           12218.153622794027
total_rewards_std            147.13107268297242
total_rewards_max            12390.290012372521
total_rewards_min            11974.298422849071
Number of train steps total  1512000
Number of env steps total    1892000
Number of rollouts total     0
Train Time (s)               132.2348066479899
(Previous) Eval Time (s)     26.481282794848084
Sample Time (s)              21.568289030343294
Epoch Time (s)               180.28437847318128
Total Train Time (s)         69357.10995909385
Epoch                        377
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:03:41.716365 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #377 | Epoch Duration: 181.5122148990631
2020-01-14 00:03:41.716550 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #377 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.0502396
Z variance train             0.008316683
KL Divergence                64.32736
KL Loss                      6.4327364
QF Loss                      474.17938
VF Loss                      180.45097
Policy Loss                  -4963.3955
Q Predictions Mean           4969.747
Q Predictions Std            664.9029
Q Predictions Max            5656.9463
Q Predictions Min            355.2165
V Predictions Mean           4953.665
V Predictions Std            661.70166
V Predictions Max            5639.8594
V Predictions Min            355.19342
Log Pis Mean                 6.1607714
Log Pis Std                  4.057998
Log Pis Max                  16.240963
Log Pis Min                  -4.502864
Policy mu Mean               -0.046216995
Policy mu Std                1.4510182
Policy mu Max                3.348571
Policy mu Min                -3.1911948
Policy log std Mean          -0.89959353
Policy log std Std           0.5018907
Policy log std Max           -0.13869292
Policy log std Min           -3.4747448
Z mean eval                  4.0476427
Z variance eval              0.0053621167
total_rewards                [12086.18629638 12254.86459951 12530.75905781 12396.79720474
 12098.99175857 12486.91317945 12483.17625314 12499.5462151
 12309.5712082  12228.79386509]
total_rewards_mean           12337.559963798018
total_rewards_std            158.15828785127215
total_rewards_max            12530.759057812942
total_rewards_min            12086.186296384252
Number of train steps total  1516000
Number of env steps total    1897000
Number of rollouts total     0
Train Time (s)               139.8481108942069
(Previous) Eval Time (s)     27.708795357029885
Sample Time (s)              22.329049586784095
Epoch Time (s)               189.8859558380209
Total Train Time (s)         69547.21980543528
Epoch                        378
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:06:51.830780 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #378 | Epoch Duration: 190.11405992507935
2020-01-14 00:06:51.831105 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #378 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.0475087
Z variance train             0.005366723
KL Divergence                67.418274
KL Loss                      6.7418275
QF Loss                      620.53766
VF Loss                      236.7483
Policy Loss                  -5033.2236
Q Predictions Mean           5042.665
Q Predictions Std            525.7935
Q Predictions Max            5636.3013
Q Predictions Min            3317.2124
V Predictions Mean           5041.419
V Predictions Std            528.2389
V Predictions Max            5641.855
V Predictions Min            3316.3816
Log Pis Mean                 6.4636126
Log Pis Std                  3.904737
Log Pis Max                  16.277405
Log Pis Min                  -1.8485216
Policy mu Mean               -0.024427572
Policy mu Std                1.4678531
Policy mu Max                3.515525
Policy mu Min                -2.951813
Policy log std Mean          -0.91669947
Policy log std Std           0.54093224
Policy log std Max           -0.17474878
Policy log std Min           -3.561088
Z mean eval                  4.1118164
Z variance eval              0.023028664
total_rewards                [12110.85013927 12313.12418793 12405.07004993 11926.13063858
 12443.29782095 12558.82894414 12020.91384833 12672.00523096
 12371.83106795 12306.12734643]
total_rewards_mean           12312.817927447582
total_rewards_std            222.28941556244692
total_rewards_max            12672.00523096038
total_rewards_min            11926.130638578745
Number of train steps total  1520000
Number of env steps total    1902000
Number of rollouts total     0
Train Time (s)               139.4366393382661
(Previous) Eval Time (s)     27.936525377910584
Sample Time (s)              22.755791728384793
Epoch Time (s)               190.12895644456148
Total Train Time (s)         69738.3836702318
Epoch                        379
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:10:02.998331 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #379 | Epoch Duration: 191.16704154014587
2020-01-14 00:10:02.998518 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #379 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.114005
Z variance train             0.022907048
KL Divergence                65.32626
KL Loss                      6.5326266
QF Loss                      606.89014
VF Loss                      208.6287
Policy Loss                  -4952.049
Q Predictions Mean           4958.884
Q Predictions Std            577.8481
Q Predictions Max            5650.925
Q Predictions Min            3332.8003
V Predictions Mean           4945.294
V Predictions Std            576.1745
V Predictions Max            5655.9263
V Predictions Min            3324.7866
Log Pis Mean                 6.0171547
Log Pis Std                  4.1056314
Log Pis Max                  16.146461
Log Pis Min                  -3.6731703
Policy mu Mean               -0.09337446
Policy mu Std                1.4233341
Policy mu Max                3.4077055
Policy mu Min                -2.8461096
Policy log std Mean          -0.8988432
Policy log std Std           0.5034022
Policy log std Max           -0.16647822
Policy log std Min           -3.402718
Z mean eval                  4.071622
Z variance eval              0.016464828
total_rewards                [11515.17608954  4527.79431002 12465.76384681 12245.60103023
 12307.04745529 12450.78225303 12239.95656197 12329.72294924
 12613.38656456 12332.76696496]
total_rewards_mean           11502.799802565409
total_rewards_std            2341.47055599915
total_rewards_max            12613.38656456382
total_rewards_min            4527.794310023766
Number of train steps total  1524000
Number of env steps total    1907000
Number of rollouts total     0
Train Time (s)               138.96097818668932
(Previous) Eval Time (s)     28.974225864745677
Sample Time (s)              22.369570763781667
Epoch Time (s)               190.30477481521666
Total Train Time (s)         69928.21026796382
Epoch                        380
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:13:12.828990 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #380 | Epoch Duration: 189.8303337097168
2020-01-14 00:13:12.829180 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #380 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.072385
Z variance train             0.016451508
KL Divergence                63.13258
KL Loss                      6.313258
QF Loss                      900.44836
VF Loss                      142.61104
Policy Loss                  -5043.568
Q Predictions Mean           5050.49
Q Predictions Std            600.2587
Q Predictions Max            5670.1025
Q Predictions Min            3350.0935
V Predictions Mean           5043.4746
V Predictions Std            599.5215
V Predictions Max            5662.019
V Predictions Min            3363.136
Log Pis Mean                 6.737681
Log Pis Std                  4.289998
Log Pis Max                  17.42115
Log Pis Min                  -3.5561776
Policy mu Mean               -0.04687426
Policy mu Std                1.5165943
Policy mu Max                3.0373354
Policy mu Min                -3.1145046
Policy log std Mean          -0.9020398
Policy log std Std           0.53013563
Policy log std Max           0.42229939
Policy log std Min           -3.575049
Z mean eval                  4.093369
Z variance eval              0.035828367
total_rewards                [11709.56041224 11692.72990815 11934.08446339 11927.5638177
 11889.73227245 11927.63101395 11972.00895622 11854.29523623
 11815.73466176 12239.23249143]
total_rewards_mean           11896.257323352404
total_rewards_std            145.3726283741253
total_rewards_max            12239.232491426155
total_rewards_min            11692.729908148864
Number of train steps total  1528000
Number of env steps total    1912000
Number of rollouts total     0
Train Time (s)               140.66700160689652
(Previous) Eval Time (s)     28.499431702774018
Sample Time (s)              23.481554243713617
Epoch Time (s)               192.64798755338416
Total Train Time (s)         70120.7667645244
Epoch                        381
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:16:25.387575 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #381 | Epoch Duration: 192.558274269104
2020-01-14 00:16:25.387694 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #381 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.092569
Z variance train             0.035751734
KL Divergence                62.922546
KL Loss                      6.292255
QF Loss                      454.16187
VF Loss                      153.80228
Policy Loss                  -5015.8027
Q Predictions Mean           5023.4375
Q Predictions Std            637.7705
Q Predictions Max            5715.251
Q Predictions Min            107.05324
V Predictions Mean           5013.8794
V Predictions Std            635.72455
V Predictions Max            5700.713
V Predictions Min            110.37454
Log Pis Mean                 5.981477
Log Pis Std                  4.1305914
Log Pis Max                  16.043829
Log Pis Min                  -4.4221516
Policy mu Mean               -0.07085843
Policy mu Std                1.4302515
Policy mu Max                2.7964733
Policy mu Min                -2.8492904
Policy log std Mean          -0.91295767
Policy log std Std           0.52039945
Policy log std Max           -0.23163834
Policy log std Min           -3.5817194
Z mean eval                  4.109702
Z variance eval              0.028656002
total_rewards                [12109.90035458 12205.30204966 12579.97471137 12037.46967177
 12032.55187264 12120.51551836 12580.92191338 12664.63963995
 12513.85129116 12627.35104059]
total_rewards_mean           12347.247806344772
total_rewards_std            252.70605139544543
total_rewards_max            12664.639639950834
total_rewards_min            12032.551872635455
Number of train steps total  1532000
Number of env steps total    1917000
Number of rollouts total     0
Train Time (s)               136.9183471770957
(Previous) Eval Time (s)     28.40931447315961
Sample Time (s)              22.066815609578043
Epoch Time (s)               187.39447725983337
Total Train Time (s)         70307.31359405024
Epoch                        382
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:19:31.938899 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #382 | Epoch Duration: 186.55110120773315
2020-01-14 00:19:31.939081 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #382 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.112546
Z variance train             0.028668482
KL Divergence                64.5891
KL Loss                      6.4589105
QF Loss                      461.14764
VF Loss                      352.50842
Policy Loss                  -4934.243
Q Predictions Mean           4939.2886
Q Predictions Std            667.132
Q Predictions Max            5690.249
Q Predictions Min            879.5544
V Predictions Mean           4923.6523
V Predictions Std            666.0145
V Predictions Max            5650.1113
V Predictions Min            872.99194
Log Pis Mean                 5.6048336
Log Pis Std                  4.185787
Log Pis Max                  17.441463
Log Pis Min                  -5.039035
Policy mu Mean               -0.06400896
Policy mu Std                1.4138749
Policy mu Max                2.8661897
Policy mu Min                -3.020851
Policy log std Mean          -0.89962155
Policy log std Std           0.49158403
Policy log std Max           -0.21856064
Policy log std Min           -3.4436512
Z mean eval                  4.1174145
Z variance eval              0.019960577
total_rewards                [11394.78692414 11872.12316735 11733.63230923 11743.26571637
 11639.10902614 11959.63940463 11844.41944821 11773.61083615
 11757.27351788 11974.94602792]
total_rewards_mean           11769.280637801154
total_rewards_std            159.39191653918547
total_rewards_max            11974.946027917376
total_rewards_min            11394.786924138903
Number of train steps total  1536000
Number of env steps total    1922000
Number of rollouts total     0
Train Time (s)               132.17001109803095
(Previous) Eval Time (s)     27.565595371183008
Sample Time (s)              21.20587169053033
Epoch Time (s)               180.9414781597443
Total Train Time (s)         70487.6939147925
Epoch                        383
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:22:32.324261 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #383 | Epoch Duration: 180.38500475883484
2020-01-14 00:22:32.324637 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #383 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1163163
Z variance train             0.019919112
KL Divergence                64.7007
KL Loss                      6.47007
QF Loss                      786.9595
VF Loss                      161.47897
Policy Loss                  -5009.583
Q Predictions Mean           5017.8467
Q Predictions Std            582.8808
Q Predictions Max            5714.874
Q Predictions Min            3347.9219
V Predictions Mean           5015.662
V Predictions Std            581.0212
V Predictions Max            5721.1777
V Predictions Min            3351.552
Log Pis Mean                 6.0194
Log Pis Std                  4.1001396
Log Pis Max                  20.34161
Log Pis Min                  -3.7818456
Policy mu Mean               -0.027921095
Policy mu Std                1.4298767
Policy mu Max                2.8153796
Policy mu Min                -3.102078
Policy log std Mean          -0.91248536
Policy log std Std           0.5085531
Policy log std Max           -0.2221945
Policy log std Min           -3.55545
Z mean eval                  4.079585
Z variance eval              0.0104327705
total_rewards                [11804.71907747  9473.86224775 11706.63665736 12245.13306863
 11702.00927529 11763.53617344 12405.80789258 12081.60032033
 12212.52580187 12217.7574765 ]
total_rewards_mean           11761.358799122743
total_rewards_std            800.2999708166168
total_rewards_max            12405.80789258156
total_rewards_min            9473.862247751893
Number of train steps total  1540000
Number of env steps total    1927000
Number of rollouts total     0
Train Time (s)               132.78381852200255
(Previous) Eval Time (s)     27.008790474850684
Sample Time (s)              21.86049846978858
Epoch Time (s)               181.6531074666418
Total Train Time (s)         70670.727439865
Epoch                        384
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:25:35.361174 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #384 | Epoch Duration: 183.03628420829773
2020-01-14 00:25:35.361365 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #384 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.0796394
Z variance train             0.010380195
KL Divergence                65.001976
KL Loss                      6.500198
QF Loss                      1814.5292
VF Loss                      277.49017
Policy Loss                  -4989.3125
Q Predictions Mean           4999.0293
Q Predictions Std            571.8699
Q Predictions Max            5671.351
Q Predictions Min            3279.661
V Predictions Mean           4990.032
V Predictions Std            568.24097
V Predictions Max            5692.946
V Predictions Min            3292.5977
Log Pis Mean                 5.6886625
Log Pis Std                  3.7559705
Log Pis Max                  15.527941
Log Pis Min                  -6.061835
Policy mu Mean               -0.07360424
Policy mu Std                1.4265375
Policy mu Max                3.2350674
Policy mu Min                -3.391812
Policy log std Mean          -0.88805574
Policy log std Std           0.5000723
Policy log std Max           0.3706336
Policy log std Min           -3.451667
Z mean eval                  4.132275
Z variance eval              0.018476222
total_rewards                [12023.58256209 12549.96726191 12321.94044703 12322.23486974
 12585.34547818 12218.83022548 12060.70953614 12267.6640996
 11940.06733015 12390.30814192]
total_rewards_mean           12268.064995223924
total_rewards_std            203.3938930838756
total_rewards_max            12585.345478177735
total_rewards_min            11940.067330152484
Number of train steps total  1544000
Number of env steps total    1932000
Number of rollouts total     0
Train Time (s)               140.28394348174334
(Previous) Eval Time (s)     28.3916317820549
Sample Time (s)              20.50457412749529
Epoch Time (s)               189.18014939129353
Total Train Time (s)         70860.6051360527
Epoch                        385
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:28:45.242939 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #385 | Epoch Duration: 189.8814160823822
2020-01-14 00:28:45.243163 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #385 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1326547
Z variance train             0.01843495
KL Divergence                66.923355
KL Loss                      6.6923356
QF Loss                      422.573
VF Loss                      119.138405
Policy Loss                  -5091.222
Q Predictions Mean           5095.5
Q Predictions Std            580.8888
Q Predictions Max            5810.264
Q Predictions Min            3461.8884
V Predictions Mean           5087.577
V Predictions Std            582.70654
V Predictions Max            5804.718
V Predictions Min            3441.4397
Log Pis Mean                 6.2367287
Log Pis Std                  4.190759
Log Pis Max                  17.362486
Log Pis Min                  -5.720872
Policy mu Mean               -0.042978097
Policy mu Std                1.4614784
Policy mu Max                3.1310449
Policy mu Min                -3.1288238
Policy log std Mean          -0.8963577
Policy log std Std           0.5209884
Policy log std Max           -0.22794145
Policy log std Min           -3.8078942
Z mean eval                  4.128894
Z variance eval              0.012533438
total_rewards                [12350.22528249 12364.82038465 12545.6521403  12118.92817609
 12387.06513718 12152.23037248 12471.57311437 12512.67171421
 12472.03476785 12536.15995937]
total_rewards_mean           12391.136104899368
total_rewards_std            143.61358739360708
total_rewards_max            12545.652140297032
total_rewards_min            12118.928176090945
Number of train steps total  1548000
Number of env steps total    1937000
Number of rollouts total     0
Train Time (s)               139.03399810707197
(Previous) Eval Time (s)     29.092542526777834
Sample Time (s)              22.778289795853198
Epoch Time (s)               190.904830429703
Total Train Time (s)         71050.52455528779
Epoch                        386
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:31:55.166395 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #386 | Epoch Duration: 189.92306876182556
2020-01-14 00:31:55.166626 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #386 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1293316
Z variance train             0.012565525
KL Divergence                67.40615
KL Loss                      6.7406154
QF Loss                      446.6757
VF Loss                      260.3112
Policy Loss                  -5052.923
Q Predictions Mean           5060.3477
Q Predictions Std            624.378
Q Predictions Max            5769.2744
Q Predictions Min            3247.8652
V Predictions Mean           5062.723
V Predictions Std            622.95544
V Predictions Max            5759.7734
V Predictions Min            3261.4597
Log Pis Mean                 6.3148756
Log Pis Std                  3.894553
Log Pis Max                  15.886546
Log Pis Min                  -3.9312723
Policy mu Mean               -0.028800437
Policy mu Std                1.4673088
Policy mu Max                4.156418
Policy mu Min                -3.092013
Policy log std Mean          -0.9120076
Policy log std Std           0.5250537
Policy log std Max           -0.1295228
Policy log std Min           -3.6833022
Z mean eval                  4.082629
Z variance eval              0.014472027
total_rewards                [11687.58468455 11930.06952445 11952.63378914 11876.82311184
 11717.20448449 12076.86501526 11484.44370571 11810.48726052
 11931.18017576 11753.9035959 ]
total_rewards_mean           11822.119534762713
total_rewards_std            160.1217095851926
total_rewards_max            12076.865015261264
total_rewards_min            11484.443705709107
Number of train steps total  1552000
Number of env steps total    1942000
Number of rollouts total     0
Train Time (s)               139.2744691655971
(Previous) Eval Time (s)     28.11042113415897
Sample Time (s)              22.793160426430404
Epoch Time (s)               190.17805072618648
Total Train Time (s)         71240.80847467342
Epoch                        387
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:35:05.454571 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #387 | Epoch Duration: 190.2877905368805
2020-01-14 00:35:05.454761 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #387 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.080674
Z variance train             0.014452477
KL Divergence                66.48552
KL Loss                      6.648552
QF Loss                      578.36414
VF Loss                      222.18022
Policy Loss                  -4945.244
Q Predictions Mean           4953.0034
Q Predictions Std            652.3745
Q Predictions Max            5651.843
Q Predictions Min            2825.9062
V Predictions Mean           4954.0527
V Predictions Std            654.1936
V Predictions Max            5649.912
V Predictions Min            2824.5322
Log Pis Mean                 6.07227
Log Pis Std                  3.9850972
Log Pis Max                  25.093735
Log Pis Min                  -4.0368414
Policy mu Mean               -0.051548336
Policy mu Std                1.442437
Policy mu Max                3.3006139
Policy mu Min                -3.979838
Policy log std Mean          -0.9059501
Policy log std Std           0.5301601
Policy log std Max           -0.17158687
Policy log std Min           -3.6989508
Z mean eval                  4.119159
Z variance eval              0.009503501
total_rewards                [12164.06488919 12356.84480973 11842.19580573 12243.49761871
 12338.27123562  6992.87029988 12413.92713574 12088.52924317
 12192.0482057  12310.94269793]
total_rewards_mean           11694.319194140817
total_rewards_std            1574.882771746973
total_rewards_max            12413.927135744467
total_rewards_min            6992.8702998764065
Number of train steps total  1556000
Number of env steps total    1947000
Number of rollouts total     0
Train Time (s)               139.7646838692017
(Previous) Eval Time (s)     28.21981587493792
Sample Time (s)              23.872464486863464
Epoch Time (s)               191.85696423100308
Total Train Time (s)         71433.78341917275
Epoch                        388
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:38:18.433938 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #388 | Epoch Duration: 192.97902703285217
2020-01-14 00:38:18.434183 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #388 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1178946
Z variance train             0.009465737
KL Divergence                64.28035
KL Loss                      6.4280353
QF Loss                      531.55255
VF Loss                      123.88476
Policy Loss                  -5053.0034
Q Predictions Mean           5060.767
Q Predictions Std            536.373
Q Predictions Max            5694.257
Q Predictions Min            3316.3652
V Predictions Mean           5054.7217
V Predictions Std            536.0566
V Predictions Max            5682.163
V Predictions Min            3315.4482
Log Pis Mean                 6.364714
Log Pis Std                  3.7609038
Log Pis Max                  15.606415
Log Pis Min                  -3.090294
Policy mu Mean               -0.0061668768
Policy mu Std                1.4407861
Policy mu Max                3.0551972
Policy mu Min                -3.1208668
Policy log std Mean          -0.91649723
Policy log std Std           0.51533014
Policy log std Max           -0.20456237
Policy log std Min           -3.6236794
Z mean eval                  4.131205
Z variance eval              0.04597324
total_rewards                [11669.42425904 11749.8427284  11915.58409507 11848.29539807
 12017.06602357 11922.01275702 11973.85749734 11996.94124432
 11672.2851447  11956.09574319]
total_rewards_mean           11872.140489072492
total_rewards_std            124.46261396928
total_rewards_max            12017.06602357072
total_rewards_min            11669.42425904458
Number of train steps total  1560000
Number of env steps total    1952000
Number of rollouts total     0
Train Time (s)               134.72563522774726
(Previous) Eval Time (s)     29.341449113097042
Sample Time (s)              20.840587354265153
Epoch Time (s)               184.90767169510946
Total Train Time (s)         71617.07343410328
Epoch                        389
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:41:21.727849 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #389 | Epoch Duration: 183.29351711273193
2020-01-14 00:41:21.728034 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #389 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.130931
Z variance train             0.04603254
KL Divergence                63.579132
KL Loss                      6.3579135
QF Loss                      603.2525
VF Loss                      194.44315
Policy Loss                  -5134.077
Q Predictions Mean           5144.496
Q Predictions Std            573.0658
Q Predictions Max            5774.5063
Q Predictions Min            3443.6326
V Predictions Mean           5138.835
V Predictions Std            571.64716
V Predictions Max            5780.624
V Predictions Min            3437.6067
Log Pis Mean                 6.1332083
Log Pis Std                  4.000613
Log Pis Max                  16.491657
Log Pis Min                  -4.133095
Policy mu Mean               -0.06598114
Policy mu Std                1.4507405
Policy mu Max                3.0766222
Policy mu Min                -2.6989357
Policy log std Mean          -0.8981357
Policy log std Std           0.5288659
Policy log std Max           0.007231593
Policy log std Min           -3.5206807
Z mean eval                  4.090596
Z variance eval              0.018540468
total_rewards                [11812.58671229 12497.07013948 12549.39815647 12189.92700682
 12638.99464401 12248.79414215 12070.6167713  12470.378948
 12345.58999888 12632.38437585]
total_rewards_mean           12345.574089525133
total_rewards_std            253.31734291426926
total_rewards_max            12638.994644013186
total_rewards_min            11812.586712291764
Number of train steps total  1564000
Number of env steps total    1957000
Number of rollouts total     0
Train Time (s)               132.23588647786528
(Previous) Eval Time (s)     27.726945340633392
Sample Time (s)              22.17039237404242
Epoch Time (s)               182.1332241925411
Total Train Time (s)         71799.71911081579
Epoch                        390
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:44:24.377684 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #390 | Epoch Duration: 182.64950561523438
2020-01-14 00:44:24.377891 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #390 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.091881
Z variance train             0.018544322
KL Divergence                64.89494
KL Loss                      6.4894943
QF Loss                      582.1932
VF Loss                      238.8409
Policy Loss                  -5003.441
Q Predictions Mean           5005.5527
Q Predictions Std            603.6747
Q Predictions Max            5673.9014
Q Predictions Min            3393.757
V Predictions Mean           4991.814
V Predictions Std            604.12085
V Predictions Max            5665.603
V Predictions Min            3381.4365
Log Pis Mean                 6.392327
Log Pis Std                  4.1863375
Log Pis Max                  20.519268
Log Pis Min                  -5.432541
Policy mu Mean               -0.07743375
Policy mu Std                1.4573443
Policy mu Max                3.0995324
Policy mu Min                -3.3786898
Policy log std Mean          -0.9208906
Policy log std Std           0.55302817
Policy log std Max           -0.2775179
Policy log std Min           -3.7677784
Z mean eval                  4.163335
Z variance eval              0.012243124
total_rewards                [12223.45510684 12486.45411142 12552.09202634 12430.23782743
 12636.95103776 12519.65567036 12312.60638955 12370.58729666
 12391.58755471 12551.71720994]
total_rewards_mean           12447.534423101508
total_rewards_std            119.22601000280407
total_rewards_max            12636.951037762385
total_rewards_min            12223.45510683725
Number of train steps total  1568000
Number of env steps total    1962000
Number of rollouts total     0
Train Time (s)               135.4655643608421
(Previous) Eval Time (s)     28.24290247214958
Sample Time (s)              21.96474515926093
Epoch Time (s)               185.67321199225262
Total Train Time (s)         71985.25793392025
Epoch                        391
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:47:29.920758 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #391 | Epoch Duration: 185.54271578788757
2020-01-14 00:47:29.920971 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #391 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1639414
Z variance train             0.012243561
KL Divergence                65.59448
KL Loss                      6.5594482
QF Loss                      491.19995
VF Loss                      299.455
Policy Loss                  -4994.2944
Q Predictions Mean           4997.5645
Q Predictions Std            631.2681
Q Predictions Max            5732.626
Q Predictions Min            3372.5017
V Predictions Mean           4982.47
V Predictions Std            628.56586
V Predictions Max            5707.204
V Predictions Min            3359.242
Log Pis Mean                 6.3857946
Log Pis Std                  3.9895988
Log Pis Max                  16.738796
Log Pis Min                  -4.2353764
Policy mu Mean               -0.050920814
Policy mu Std                1.4564021
Policy mu Max                3.0220828
Policy mu Min                -2.976069
Policy log std Mean          -0.88928014
Policy log std Std           0.4867253
Policy log std Max           0.20672715
Policy log std Min           -3.5220962
Z mean eval                  4.0447817
Z variance eval              0.009933139
total_rewards                [12059.91807368 12237.53852709 12553.64311684 11949.47466158
 11962.3763978  12003.86747478 11993.09590882 11965.2788241
 11411.74355598 12454.3290142 ]
total_rewards_mean           12059.126555486944
total_rewards_std            298.2068005311065
total_rewards_max            12553.643116841735
total_rewards_min            11411.743555975849
Number of train steps total  1572000
Number of env steps total    1967000
Number of rollouts total     0
Train Time (s)               141.97228033281863
(Previous) Eval Time (s)     28.112030006945133
Sample Time (s)              23.047632538713515
Epoch Time (s)               193.13194287847728
Total Train Time (s)         72178.00558949588
Epoch                        392
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:50:42.673497 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #392 | Epoch Duration: 192.75239944458008
2020-01-14 00:50:42.673620 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #392 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.0542955
Z variance train             0.009777528
KL Divergence                65.44239
KL Loss                      6.544239
QF Loss                      1509.7449
VF Loss                      1939.2501
Policy Loss                  -5041.103
Q Predictions Mean           5038.7617
Q Predictions Std            600.3733
Q Predictions Max            5712.7124
Q Predictions Min            277.4999
V Predictions Mean           5003.4805
V Predictions Std            598.25995
V Predictions Max            5690.9556
V Predictions Min            257.67502
Log Pis Mean                 6.424584
Log Pis Std                  4.0194216
Log Pis Max                  17.875923
Log Pis Min                  -3.913035
Policy mu Mean               -0.04418227
Policy mu Std                1.4838696
Policy mu Max                4.3866014
Policy mu Min                -2.7587209
Policy log std Mean          -0.9021662
Policy log std Std           0.49505094
Policy log std Max           -0.09852743
Policy log std Min           -3.5243418
Z mean eval                  4.1182446
Z variance eval              0.0074527552
total_rewards                [11892.43442447 12487.15313437 12109.26446351 12194.06633859
 12358.0211971  11948.18791026 12522.47800841 11254.92526728
 12660.73340463  5691.13503582]
total_rewards_mean           11511.839918442984
total_rewards_std            1977.69601832234
total_rewards_max            12660.73340462767
total_rewards_min            5691.135035823945
Number of train steps total  1576000
Number of env steps total    1972000
Number of rollouts total     0
Train Time (s)               140.70430489303544
(Previous) Eval Time (s)     27.73212909279391
Sample Time (s)              22.660136569291353
Epoch Time (s)               191.0965705551207
Total Train Time (s)         72368.81060511107
Epoch                        393
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:53:53.484881 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #393 | Epoch Duration: 190.8111538887024
2020-01-14 00:53:53.485074 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #393 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1180816
Z variance train             0.0074270098
KL Divergence                67.52632
KL Loss                      6.752632
QF Loss                      716.4949
VF Loss                      143.12311
Policy Loss                  -5074.2207
Q Predictions Mean           5079.9077
Q Predictions Std            565.26025
Q Predictions Max            5726.329
Q Predictions Min            3376.0781
V Predictions Mean           5079.3486
V Predictions Std            565.8834
V Predictions Max            5728.7163
V Predictions Min            3369.0425
Log Pis Mean                 6.1516914
Log Pis Std                  3.8764725
Log Pis Max                  16.208273
Log Pis Min                  -3.0338016
Policy mu Mean               0.006638473
Policy mu Std                1.4608053
Policy mu Max                2.9095352
Policy mu Min                -2.885148
Policy log std Mean          -0.8920946
Policy log std Std           0.5094771
Policy log std Max           -0.10254395
Policy log std Min           -3.7191608
Z mean eval                  4.1245418
Z variance eval              0.025595665
total_rewards                [11159.5266724  12398.90052046 11602.64990997  8203.04474144
 11556.52807625 11194.58267882  7169.77624286 11942.6464779
 11614.50437222 11200.55581031]
total_rewards_mean           10804.27155026177
total_rewards_std            1615.860185303776
total_rewards_max            12398.900520458568
total_rewards_min            7169.776242859817
Number of train steps total  1580000
Number of env steps total    1977000
Number of rollouts total     0
Train Time (s)               140.4429172486998
(Previous) Eval Time (s)     27.44633254595101
Sample Time (s)              21.496794271748513
Epoch Time (s)               189.38604406639934
Total Train Time (s)         72560.28389594192
Epoch                        394
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:57:04.962273 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #394 | Epoch Duration: 191.4770483970642
2020-01-14 00:57:04.962477 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #394 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1254764
Z variance train             0.025604289
KL Divergence                63.576706
KL Loss                      6.357671
QF Loss                      423.33206
VF Loss                      211.02441
Policy Loss                  -5041.5557
Q Predictions Mean           5046.0117
Q Predictions Std            623.5013
Q Predictions Max            5801.18
Q Predictions Min            3391.048
V Predictions Mean           5033.5396
V Predictions Std            621.6157
V Predictions Max            5768.788
V Predictions Min            3394.221
Log Pis Mean                 5.8658257
Log Pis Std                  3.9789364
Log Pis Max                  15.359012
Log Pis Min                  -4.111274
Policy mu Mean               -0.044333737
Policy mu Std                1.4273865
Policy mu Max                3.1799712
Policy mu Min                -2.84332
Policy log std Mean          -0.87803394
Policy log std Std           0.4883042
Policy log std Max           -0.10689354
Policy log std Min           -3.5532084
Z mean eval                  4.105686
Z variance eval              0.04000635
total_rewards                [12235.7740204  12038.72035363 12577.61613229 12493.59550398
 12051.0032111  12461.5462186  12686.06619444 12049.37341008
 12254.0956328  12542.33482789]
total_rewards_mean           12339.01255051993
total_rewards_std            230.76241691171782
total_rewards_max            12686.066194444498
total_rewards_min            12038.72035362562
Number of train steps total  1584000
Number of env steps total    1982000
Number of rollouts total     0
Train Time (s)               140.0450341613032
(Previous) Eval Time (s)     29.537048244848847
Sample Time (s)              22.448916409164667
Epoch Time (s)               192.0309988153167
Total Train Time (s)         72750.43523738114
Epoch                        395
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:00:15.117724 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #395 | Epoch Duration: 190.1551012992859
2020-01-14 01:00:15.117905 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #395 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.107592
Z variance train             0.04000248
KL Divergence                60.918644
KL Loss                      6.0918646
QF Loss                      896.3319
VF Loss                      252.43867
Policy Loss                  -5125.177
Q Predictions Mean           5129.8423
Q Predictions Std            596.1751
Q Predictions Max            5819.862
Q Predictions Min            3365.9485
V Predictions Mean           5122.069
V Predictions Std            593.092
V Predictions Max            5786.81
V Predictions Min            3367.6462
Log Pis Mean                 6.226381
Log Pis Std                  4.087005
Log Pis Max                  19.757462
Log Pis Min                  -7.6333046
Policy mu Mean               -0.06961023
Policy mu Std                1.4881436
Policy mu Max                4.8372984
Policy mu Min                -2.9309616
Policy log std Mean          -0.90133697
Policy log std Std           0.5372095
Policy log std Max           -0.14136046
Policy log std Min           -3.520179
Z mean eval                  4.1147537
Z variance eval              0.047420375
total_rewards                [11868.58610677 12235.37445449 12173.84537959 12326.48318829
 12320.88762174 11869.65860748 12034.94055842 12136.85460224
 12570.79355322 11895.86262801]
total_rewards_mean           12143.328670025112
total_rewards_std            219.22837377839943
total_rewards_max            12570.793553221587
total_rewards_min            11868.58610677092
Number of train steps total  1588000
Number of env steps total    1987000
Number of rollouts total     0
Train Time (s)               132.34499443368986
(Previous) Eval Time (s)     27.660780636128038
Sample Time (s)              20.91471581393853
Epoch Time (s)               180.92049088375643
Total Train Time (s)         72931.80256947968
Epoch                        396
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:03:16.489104 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #396 | Epoch Duration: 181.3710653781891
2020-01-14 01:03:16.489286 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #396 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.114076
Z variance train             0.047324646
KL Divergence                61.19098
KL Loss                      6.119098
QF Loss                      626.7419
VF Loss                      156.15004
Policy Loss                  -5036.0347
Q Predictions Mean           5037.8477
Q Predictions Std            591.09204
Q Predictions Max            5760.1113
Q Predictions Min            3355.6213
V Predictions Mean           5041.5107
V Predictions Std            591.1653
V Predictions Max            5761.728
V Predictions Min            3370.282
Log Pis Mean                 6.4132905
Log Pis Std                  4.0736747
Log Pis Max                  16.29895
Log Pis Min                  -4.077033
Policy mu Mean               -0.09582776
Policy mu Std                1.514458
Policy mu Max                2.9323673
Policy mu Min                -3.0198617
Policy log std Mean          -0.8617086
Policy log std Std           0.47477323
Policy log std Max           -0.19501734
Policy log std Min           -3.3704004
Z mean eval                  4.1250105
Z variance eval              0.028503388
total_rewards                [11440.05448909 11778.39963098 11977.08987042 11718.30710041
 11466.22897037 11528.54790735 11682.21335443 11496.02986339
 11708.56867111 11709.3611037 ]
total_rewards_mean           11650.48009612547
total_rewards_std            158.8823011987502
total_rewards_max            11977.089870417314
total_rewards_min            11440.054489086937
Number of train steps total  1592000
Number of env steps total    1992000
Number of rollouts total     0
Train Time (s)               132.28678663587198
(Previous) Eval Time (s)     28.11105591757223
Sample Time (s)              21.586059667170048
Epoch Time (s)               181.98390222061425
Total Train Time (s)         73112.58676072862
Epoch                        397
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:06:17.277415 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #397 | Epoch Duration: 180.78798389434814
2020-01-14 01:06:17.277600 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #397 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.124713
Z variance train             0.028561652
KL Divergence                62.42279
KL Loss                      6.242279
QF Loss                      612.2554
VF Loss                      258.95306
Policy Loss                  -5008.4995
Q Predictions Mean           5014.71
Q Predictions Std            627.14764
Q Predictions Max            5738.376
Q Predictions Min            3394.4224
V Predictions Mean           5005.667
V Predictions Std            621.34204
V Predictions Max            5704.6636
V Predictions Min            3382.8796
Log Pis Mean                 6.435009
Log Pis Std                  4.513876
Log Pis Max                  16.988281
Log Pis Min                  -4.579132
Policy mu Mean               -0.07850603
Policy mu Std                1.4975294
Policy mu Max                3.4661105
Policy mu Min                -3.550273
Policy log std Mean          -0.89599276
Policy log std Std           0.53148645
Policy log std Max           0.011666775
Policy log std Min           -3.5190964
Z mean eval                  4.1000338
Z variance eval              0.013467997
total_rewards                [12297.67764782 12315.85409602 12360.3326298  12382.11911602
 12378.07356951 12640.68721351 12318.55160982 12418.50091118
 12319.80289322 12480.47018899]
total_rewards_mean           12391.206987590313
total_rewards_std            98.47065900121825
total_rewards_max            12640.68721351071
total_rewards_min            12297.677647823537
Number of train steps total  1596000
Number of env steps total    1997000
Number of rollouts total     0
Train Time (s)               137.61370616592467
(Previous) Eval Time (s)     26.914826394990087
Sample Time (s)              21.818509726785123
Epoch Time (s)               186.34704228769988
Total Train Time (s)         73298.92264733324
Epoch                        398
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:09:23.617672 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #398 | Epoch Duration: 186.33993005752563
2020-01-14 01:09:23.617863 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #398 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.099801
Z variance train             0.013431902
KL Divergence                63.739872
KL Loss                      6.373987
QF Loss                      824.3496
VF Loss                      146.2174
Policy Loss                  -5012.306
Q Predictions Mean           5016.2544
Q Predictions Std            601.93774
Q Predictions Max            5675.554
Q Predictions Min            237.2999
V Predictions Mean           5010.066
V Predictions Std            598.9185
V Predictions Max            5675.4697
V Predictions Min            278.59097
Log Pis Mean                 6.351522
Log Pis Std                  4.0238905
Log Pis Max                  15.878064
Log Pis Min                  -4.423155
Policy mu Mean               -0.06225254
Policy mu Std                1.4675378
Policy mu Max                3.037808
Policy mu Min                -3.0941226
Policy log std Mean          -0.9158637
Policy log std Std           0.52687067
Policy log std Max           -0.068554044
Policy log std Min           -3.5851142
Z mean eval                  4.1287026
Z variance eval              0.042857587
total_rewards                [12128.143061   12326.67600034 12390.6009073  12569.60339828
 12261.80607417 12002.80395321 11824.72559927 12139.87069278
 11922.53130322 12180.62884987]
total_rewards_mean           12174.738983945614
total_rewards_std            212.66904277788996
total_rewards_max            12569.603398284975
total_rewards_min            11824.725599273997
Number of train steps total  1600000
Number of env steps total    2002000
Number of rollouts total     0
Train Time (s)               140.2062857011333
(Previous) Eval Time (s)     26.907332609873265
Sample Time (s)              23.250212325248867
Epoch Time (s)               190.36383063625544
Total Train Time (s)         73490.71165590547
Epoch                        399
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:12:35.411157 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #399 | Epoch Duration: 191.79313945770264
2020-01-14 01:12:35.411391 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #399 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1290407
Z variance train             0.042993423
KL Divergence                63.099915
KL Loss                      6.3099914
QF Loss                      631.2433
VF Loss                      162.41783
Policy Loss                  -5054.707
Q Predictions Mean           5063.608
Q Predictions Std            594.12573
Q Predictions Max            5741.9043
Q Predictions Min            2870.5464
V Predictions Mean           5050.791
V Predictions Std            592.416
V Predictions Max            5720.234
V Predictions Min            2817.9607
Log Pis Mean                 5.8331394
Log Pis Std                  3.822911
Log Pis Max                  16.17242
Log Pis Min                  -4.458031
Policy mu Mean               -0.02058546
Policy mu Std                1.4434915
Policy mu Max                2.9248805
Policy mu Min                -2.6258268
Policy log std Mean          -0.8802913
Policy log std Std           0.46904048
Policy log std Max           -0.04342842
Policy log std Min           -3.227941
Z mean eval                  4.1995335
Z variance eval              0.020530472
total_rewards                [12044.07533609 12646.44693662 12335.20748877 12656.32634825
 12780.89923842 12459.98160321 12587.69693091 12239.65626944
 12347.03168105 12295.75551672]
total_rewards_mean           12439.307734949081
total_rewards_std            215.6765106491512
total_rewards_max            12780.899238418486
total_rewards_min            12044.07533609017
Number of train steps total  1604000
Number of env steps total    2007000
Number of rollouts total     0
Train Time (s)               140.1644831271842
(Previous) Eval Time (s)     28.336220149882138
Sample Time (s)              21.5814499091357
Epoch Time (s)               190.08215318620205
Total Train Time (s)         73680.61282664305
Epoch                        400
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:15:45.317084 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #400 | Epoch Duration: 189.90553545951843
2020-01-14 01:15:45.317299 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #400 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1983356
Z variance train             0.020560417
KL Divergence                64.21775
KL Loss                      6.4217753
QF Loss                      1088.0846
VF Loss                      172.52202
Policy Loss                  -4978.216
Q Predictions Mean           4982.772
Q Predictions Std            715.62177
Q Predictions Max            5747.9272
Q Predictions Min            226.20425
V Predictions Mean           4985.788
V Predictions Std            716.1618
V Predictions Max            5755.3857
V Predictions Min            206.03622
Log Pis Mean                 5.8068123
Log Pis Std                  4.2940927
Log Pis Max                  23.039402
Log Pis Min                  -4.410941
Policy mu Mean               -0.056154262
Policy mu Std                1.4466902
Policy mu Max                3.7306144
Policy mu Min                -3.2380807
Policy log std Mean          -0.8776152
Policy log std Std           0.49282703
Policy log std Max           0.052049875
Policy log std Min           -3.7009542
Z mean eval                  4.116304
Z variance eval              0.015312433
total_rewards                [12434.18335143 11793.29381423 11926.16621369 12259.02980826
 12394.82463533 12609.52880004 12232.31591219 12232.20701198
 12394.11074769 12386.94277439]
total_rewards_mean           12266.260306922884
total_rewards_std            231.34295133813535
total_rewards_max            12609.528800036083
total_rewards_min            11793.29381423246
Number of train steps total  1608000
Number of env steps total    2012000
Number of rollouts total     0
Train Time (s)               142.1349291088991
(Previous) Eval Time (s)     28.159247134812176
Sample Time (s)              22.992809859104455
Epoch Time (s)               193.28698610281572
Total Train Time (s)         73874.49685571855
Epoch                        401
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:18:59.205015 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #401 | Epoch Duration: 193.8875675201416
2020-01-14 01:18:59.205203 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #401 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.113659
Z variance train             0.015346274
KL Divergence                64.34275
KL Loss                      6.434275
QF Loss                      547.79736
VF Loss                      153.31767
Policy Loss                  -5040.006
Q Predictions Mean           5048.0645
Q Predictions Std            560.14526
Q Predictions Max            5677.951
Q Predictions Min            3363.3162
V Predictions Mean           5045.282
V Predictions Std            558.70734
V Predictions Max            5705.1997
V Predictions Min            3369.0825
Log Pis Mean                 6.276453
Log Pis Std                  3.8743668
Log Pis Max                  15.885248
Log Pis Min                  -3.8577414
Policy mu Mean               -0.047823265
Policy mu Std                1.4531488
Policy mu Max                2.9333832
Policy mu Min                -2.7947586
Policy log std Mean          -0.90928555
Policy log std Std           0.5167527
Policy log std Max           -0.22952288
Policy log std Min           -3.6962256
Z mean eval                  4.1263795
Z variance eval              0.02666814
total_rewards                [11704.96375131 12024.40516775 12201.82700068 11706.01448016
 12045.20222554 11859.41168747 12020.16035217 12069.91172335
 12006.70681148 12154.68656697]
total_rewards_mean           11979.328976687226
total_rewards_std            161.7423974355078
total_rewards_max            12201.827000679152
total_rewards_min            11704.963751310055
Number of train steps total  1612000
Number of env steps total    2017000
Number of rollouts total     0
Train Time (s)               139.199527093675
(Previous) Eval Time (s)     28.759379925206304
Sample Time (s)              22.248588825576007
Epoch Time (s)               190.2074958444573
Total Train Time (s)         74062.98712961003
Epoch                        402
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:22:07.700520 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #402 | Epoch Duration: 188.4951708316803
2020-01-14 01:22:07.700748 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #402 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1238527
Z variance train             0.026631573
KL Divergence                62.81048
KL Loss                      6.281048
QF Loss                      525.391
VF Loss                      151.15085
Policy Loss                  -5082.087
Q Predictions Mean           5090.4424
Q Predictions Std            591.67584
Q Predictions Max            5698.564
Q Predictions Min            2669.3972
V Predictions Mean           5085.2534
V Predictions Std            589.9369
V Predictions Max            5694.8433
V Predictions Min            2731.3057
Log Pis Mean                 5.8893056
Log Pis Std                  4.248262
Log Pis Max                  17.019135
Log Pis Min                  -4.190883
Policy mu Mean               -0.0775503
Policy mu Std                1.4347013
Policy mu Max                3.0316997
Policy mu Min                -3.0446687
Policy log std Mean          -0.8848403
Policy log std Std           0.48255154
Policy log std Max           -0.20082176
Policy log std Min           -3.5725374
Z mean eval                  4.1542807
Z variance eval              0.026151815
total_rewards                [11639.56806008 12211.6260366  12151.645965   12264.64537624
 11949.64570168 12292.74243408 12081.93748758 11637.86442887
 11867.59390357 11838.42926436]
total_rewards_mean           11993.569865804904
total_rewards_std            231.74189502555345
total_rewards_max            12292.742434076996
total_rewards_min            11637.864428868135
Number of train steps total  1616000
Number of env steps total    2022000
Number of rollouts total     0
Train Time (s)               133.14599726814777
(Previous) Eval Time (s)     27.046728034038097
Sample Time (s)              20.308006897568703
Epoch Time (s)               180.50073219975457
Total Train Time (s)         74243.98001967464
Epoch                        403
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:25:08.696569 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #403 | Epoch Duration: 180.99565744400024
2020-01-14 01:25:08.696765 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #403 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1503
Z variance train             0.026041627
KL Divergence                63.250748
KL Loss                      6.3250747
QF Loss                      593.01404
VF Loss                      359.87088
Policy Loss                  -5108.52
Q Predictions Mean           5116.267
Q Predictions Std            570.84515
Q Predictions Max            5810.351
Q Predictions Min            3396.7114
V Predictions Mean           5120.0703
V Predictions Std            571.1484
V Predictions Max            5785.772
V Predictions Min            3406.5476
Log Pis Mean                 7.0052834
Log Pis Std                  3.7688875
Log Pis Max                  15.992975
Log Pis Min                  -2.092921
Policy mu Mean               0.014655263
Policy mu Std                1.5379119
Policy mu Max                3.393106
Policy mu Min                -3.4900355
Policy log std Mean          -0.8784618
Policy log std Std           0.50700676
Policy log std Max           -0.14036691
Policy log std Min           -3.5741692
Z mean eval                  4.104887
Z variance eval              0.018505573
total_rewards                [11690.29987805 11833.65526553 11889.70421625 12225.75080012
 11932.79066259 11812.42855168  7776.73561945  9789.74112575
 12193.78979548 11970.31747403]
total_rewards_mean           11311.521338893817
total_rewards_std            1350.7785403830294
total_rewards_max            12225.750800122663
total_rewards_min            7776.735619447445
Number of train steps total  1620000
Number of env steps total    2027000
Number of rollouts total     0
Train Time (s)               132.928551658988
(Previous) Eval Time (s)     27.541332555934787
Sample Time (s)              22.312826779205352
Epoch Time (s)               182.78271099412814
Total Train Time (s)         74427.37765895156
Epoch                        404
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:28:12.098433 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #404 | Epoch Duration: 183.40153002738953
2020-01-14 01:28:12.098616 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #404 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1059723
Z variance train             0.018474357
KL Divergence                63.47793
KL Loss                      6.347793
QF Loss                      969.4141
VF Loss                      315.08334
Policy Loss                  -4918.7544
Q Predictions Mean           4930.011
Q Predictions Std            634.54785
Q Predictions Max            5758.801
Q Predictions Min            3338.9236
V Predictions Mean           4930.162
V Predictions Std            635.1724
V Predictions Max            5748.3506
V Predictions Min            3337.7803
Log Pis Mean                 5.7821617
Log Pis Std                  4.0564666
Log Pis Max                  16.680168
Log Pis Min                  -4.4476004
Policy mu Mean               -0.0777489
Policy mu Std                1.4215772
Policy mu Max                3.053812
Policy mu Min                -2.7198074
Policy log std Mean          -0.9086067
Policy log std Std           0.5145631
Policy log std Max           -0.24868843
Policy log std Min           -3.4617252
Z mean eval                  4.167695
Z variance eval              0.022410376
total_rewards                [12426.2538169  12692.98785062 12555.04284274 12441.04239293
 12665.06457521 12395.45323739 12456.32412732 12516.41616881
 12574.02447712 12624.3493496 ]
total_rewards_mean           12534.695883864651
total_rewards_std            99.220096945794
total_rewards_max            12692.987850622227
total_rewards_min            12395.453237387504
Number of train steps total  1624000
Number of env steps total    2032000
Number of rollouts total     0
Train Time (s)               139.64339677523822
(Previous) Eval Time (s)     28.15979047724977
Sample Time (s)              22.123612673487514
Epoch Time (s)               189.9267999259755
Total Train Time (s)         74618.11918734992
Epoch                        405
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:31:22.844507 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #405 | Epoch Duration: 190.74574637413025
2020-01-14 01:31:22.844704 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #405 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.166112
Z variance train             0.022504518
KL Divergence                64.02969
KL Loss                      6.4029694
QF Loss                      1609.2925
VF Loss                      440.10696
Policy Loss                  -5075.9546
Q Predictions Mean           5084.33
Q Predictions Std            572.395
Q Predictions Max            5757.9683
Q Predictions Min            3330.536
V Predictions Mean           5086.6055
V Predictions Std            569.621
V Predictions Max            5770.027
V Predictions Min            3347.8123
Log Pis Mean                 6.299372
Log Pis Std                  4.072408
Log Pis Max                  16.684109
Log Pis Min                  -3.786703
Policy mu Mean               -0.0977451
Policy mu Std                1.4761399
Policy mu Max                3.2763274
Policy mu Min                -3.5200114
Policy log std Mean          -0.9161007
Policy log std Std           0.53176135
Policy log std Max           -0.044797778
Policy log std Min           -3.6766145
Z mean eval                  4.176921
Z variance eval              0.047878172
total_rewards                [11722.37105729 12353.09864747 12358.08929115 12011.42463451
 12172.41149968 12308.97568171 12280.38006751 12253.21535223
 12236.76065119 12240.44721446]
total_rewards_mean           12193.717409719131
total_rewards_std            183.47854423856026
total_rewards_max            12358.08929114688
total_rewards_min            11722.371057292756
Number of train steps total  1628000
Number of env steps total    2037000
Number of rollouts total     0
Train Time (s)               139.4113688552752
(Previous) Eval Time (s)     28.97839511791244
Sample Time (s)              23.48695902246982
Epoch Time (s)               191.87672299565747
Total Train Time (s)         74807.57154686982
Epoch                        406
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:34:32.301849 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #406 | Epoch Duration: 189.45699739456177
2020-01-14 01:34:32.302070 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #406 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1783137
Z variance train             0.04789978
KL Divergence                63.968407
KL Loss                      6.3968406
QF Loss                      721.7564
VF Loss                      237.0726
Policy Loss                  -4881.6646
Q Predictions Mean           4884.6025
Q Predictions Std            618.5524
Q Predictions Max            5596.582
Q Predictions Min            3210.9692
V Predictions Mean           4873.784
V Predictions Std            615.84534
V Predictions Max            5578.7515
V Predictions Min            3217.468
Log Pis Mean                 6.5660143
Log Pis Std                  4.076506
Log Pis Max                  15.897324
Log Pis Min                  -8.1526165
Policy mu Mean               -0.077872835
Policy mu Std                1.4678041
Policy mu Max                2.8065279
Policy mu Min                -2.7197616
Policy log std Mean          -0.9069443
Policy log std Std           0.49876952
Policy log std Max           -0.17103127
Policy log std Min           -3.4272285
Z mean eval                  4.209077
Z variance eval              0.00947608
total_rewards                [12222.38633122 12293.22778555 12585.85204742 11928.87807241
  1905.43951914 12251.57376257 12520.64051333 12570.02798266
 12389.95868922  6372.54828577]
total_rewards_mean           10704.053298929062
total_rewards_std            3436.1120517891245
total_rewards_max            12585.852047419217
total_rewards_min            1905.439519142818
Number of train steps total  1632000
Number of env steps total    2042000
Number of rollouts total     0
Train Time (s)               139.58920973120257
(Previous) Eval Time (s)     26.558239068835974
Sample Time (s)              23.04726117802784
Epoch Time (s)               189.19470997806638
Total Train Time (s)         74998.82256940054
Epoch                        407
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:37:43.557623 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #407 | Epoch Duration: 191.25535774230957
2020-01-14 01:37:43.558012 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #407 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2105265
Z variance train             0.009471354
KL Divergence                68.00354
KL Loss                      6.800354
QF Loss                      504.50555
VF Loss                      213.63249
Policy Loss                  -5087.2324
Q Predictions Mean           5092.9385
Q Predictions Std            583.963
Q Predictions Max            5774.8354
Q Predictions Min            3395.162
V Predictions Mean           5078.622
V Predictions Std            583.55255
V Predictions Max            5766.436
V Predictions Min            3385.5764
Log Pis Mean                 6.739664
Log Pis Std                  4.2212253
Log Pis Max                  17.617447
Log Pis Min                  -6.5643067
Policy mu Mean               -0.061421096
Policy mu Std                1.5113378
Policy mu Max                4.2145333
Policy mu Min                -3.1514642
Policy log std Mean          -0.9176261
Policy log std Std           0.5373651
Policy log std Max           -0.25270927
Policy log std Min           -3.534235
Z mean eval                  4.212596
Z variance eval              0.01375751
total_rewards                [11729.36539611 12126.50557007 12479.61602666 12637.30449783
 12613.9494225  12522.5699841  12126.72181521 12346.05622276
 12184.67325308 12272.31081519]
total_rewards_mean           12303.907300351297
total_rewards_std            263.80349351349605
total_rewards_max            12637.304497833475
total_rewards_min            11729.365396114517
Number of train steps total  1636000
Number of env steps total    2047000
Number of rollouts total     0
Train Time (s)               140.38310798304155
(Previous) Eval Time (s)     28.61843411391601
Sample Time (s)              23.064068601001054
Epoch Time (s)               192.06561069795862
Total Train Time (s)         75190.98963056738
Epoch                        408
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:40:55.728757 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #408 | Epoch Duration: 192.17049908638
2020-01-14 01:40:55.728972 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #408 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2128973
Z variance train             0.013794254
KL Divergence                67.440796
KL Loss                      6.7440796
QF Loss                      696.30164
VF Loss                      179.56747
Policy Loss                  -5102.609
Q Predictions Mean           5105.248
Q Predictions Std            572.6173
Q Predictions Max            5744.0244
Q Predictions Min            3396.1165
V Predictions Mean           5096.6816
V Predictions Std            570.6956
V Predictions Max            5719.9453
V Predictions Min            3392.5266
Log Pis Mean                 6.1193295
Log Pis Std                  4.2994146
Log Pis Max                  22.363354
Log Pis Min                  -4.8141675
Policy mu Mean               -0.071183644
Policy mu Std                1.4719601
Policy mu Max                3.8201365
Policy mu Min                -4.909684
Policy log std Mean          -0.9134976
Policy log std Std           0.50397384
Policy log std Max           0.3366133
Policy log std Min           -3.5696266
Z mean eval                  4.2073746
Z variance eval              0.023085125
total_rewards                [12119.31850063 12237.92454815 12320.91668352 12550.23598423
 12385.2425246  11839.60569067 12071.43992128 12390.80394445
 12227.70762633 12534.34443444]
total_rewards_mean           12267.753985828791
total_rewards_std            207.12663814940004
total_rewards_max            12550.235984229299
total_rewards_min            11839.605690670023
Number of train steps total  1640000
Number of env steps total    2052000
Number of rollouts total     0
Train Time (s)               137.49648045701906
(Previous) Eval Time (s)     28.72297526896
Sample Time (s)              23.228219359647483
Epoch Time (s)               189.44767508562654
Total Train Time (s)         75379.74579225993
Epoch                        409
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:44:04.489218 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #409 | Epoch Duration: 188.7601022720337
2020-01-14 01:44:04.489406 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #409 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2062955
Z variance train             0.023176275
KL Divergence                66.43121
KL Loss                      6.6431212
QF Loss                      1122.023
VF Loss                      170.20941
Policy Loss                  -5150.9253
Q Predictions Mean           5148.108
Q Predictions Std            540.9868
Q Predictions Max            5749.5923
Q Predictions Min            3416.5625
V Predictions Mean           5144.0947
V Predictions Std            541.9681
V Predictions Max            5738.5557
V Predictions Min            3413.2056
Log Pis Mean                 6.696732
Log Pis Std                  3.9731038
Log Pis Max                  18.092434
Log Pis Min                  -4.4709206
Policy mu Mean               -0.040863704
Policy mu Std                1.5129051
Policy mu Max                3.0032723
Policy mu Min                -3.1365972
Policy log std Mean          -0.93609977
Policy log std Std           0.5743731
Policy log std Max           0.10853052
Policy log std Min           -3.6102827
Z mean eval                  4.159449
Z variance eval              0.020529408
total_rewards                [12151.90513347 12080.14820665 12610.6680142  12555.91262264
 12606.08788629 12533.85674847 12597.45311191 12548.32668071
 12577.00305293 12524.3946567 ]
total_rewards_mean           12478.575611396845
total_rewards_std            184.1160548430312
total_rewards_max            12610.66801420327
total_rewards_min            12080.148206647156
Number of train steps total  1644000
Number of env steps total    2057000
Number of rollouts total     0
Train Time (s)               133.040063417051
(Previous) Eval Time (s)     28.034950385335833
Sample Time (s)              21.261755937244743
Epoch Time (s)               182.33676973963156
Total Train Time (s)         75560.4072096874
Epoch                        410
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:47:05.154617 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #410 | Epoch Duration: 180.66507148742676
2020-01-14 01:47:05.154802 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #410 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.15972
Z variance train             0.020492539
KL Divergence                64.6754
KL Loss                      6.4675403
QF Loss                      1010.6803
VF Loss                      141.78156
Policy Loss                  -5003.71
Q Predictions Mean           5006.5815
Q Predictions Std            630.1076
Q Predictions Max            5786.846
Q Predictions Min            3361.1052
V Predictions Mean           5000.0444
V Predictions Std            628.2429
V Predictions Max            5782.213
V Predictions Min            3372.4312
Log Pis Mean                 6.0343533
Log Pis Std                  3.4358938
Log Pis Max                  15.50214
Log Pis Min                  -3.718289
Policy mu Mean               -0.013608406
Policy mu Std                1.4352847
Policy mu Max                3.0115614
Policy mu Min                -2.6662486
Policy log std Mean          -0.89127904
Policy log std Std           0.51149493
Policy log std Max           -0.1735673
Policy log std Min           -3.6085088
Z mean eval                  4.1170197
Z variance eval              0.048213944
total_rewards                [11932.63346863 11606.13753559 11582.98888422 12541.24526052
 12154.8365317   3741.21600724 12036.39336371 12159.58958906
 12093.46761419 11345.03714749]
total_rewards_mean           11119.354540233773
total_rewards_std            2481.272648714749
total_rewards_max            12541.245260515858
total_rewards_min            3741.2160072411066
Number of train steps total  1648000
Number of env steps total    2062000
Number of rollouts total     0
Train Time (s)               132.21657283091918
(Previous) Eval Time (s)     26.362910283263773
Sample Time (s)              21.68223447119817
Epoch Time (s)               180.26171758538112
Total Train Time (s)         75742.71266463492
Epoch                        411
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:50:07.465680 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #411 | Epoch Duration: 182.3107304573059
2020-01-14 01:50:07.465934 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #411 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.118541
Z variance train             0.04837705
KL Divergence                61.367496
KL Loss                      6.1367497
QF Loss                      856.8046
VF Loss                      381.62054
Policy Loss                  -4828.133
Q Predictions Mean           4830.46
Q Predictions Std            577.6632
Q Predictions Max            5488.4414
Q Predictions Min            3179.9575
V Predictions Mean           4813.1885
V Predictions Std            575.40485
V Predictions Max            5466.128
V Predictions Min            3165.7458
Log Pis Mean                 5.8663344
Log Pis Std                  3.8651102
Log Pis Max                  14.898466
Log Pis Min                  -5.1233625
Policy mu Mean               -0.022671526
Policy mu Std                1.4360148
Policy mu Max                3.1881363
Policy mu Min                -3.046875
Policy log std Mean          -0.89647436
Policy log std Std           0.47931975
Policy log std Max           -0.1149528
Policy log std Min           -3.4141207
Z mean eval                  4.144582
Z variance eval              0.03523182
total_rewards                [12089.27676999 12144.81436586 12690.53583528  9524.52463033
 12275.25162063 11967.83282827 12274.85795628 12316.59168859
 12324.7145656  12383.14760769]
total_rewards_mean           11999.15478685046
total_rewards_std            844.9005537589582
total_rewards_max            12690.535835276887
total_rewards_min            9524.52463032776
Number of train steps total  1652000
Number of env steps total    2067000
Number of rollouts total     0
Train Time (s)               141.07432152377442
(Previous) Eval Time (s)     28.411564941052347
Sample Time (s)              22.038321625441313
Epoch Time (s)               191.52420809026808
Total Train Time (s)         75935.33153951168
Epoch                        412
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:53:20.088317 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #412 | Epoch Duration: 192.62221145629883
2020-01-14 01:53:20.088509 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #412 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.14276
Z variance train             0.035099886
KL Divergence                62.07527
KL Loss                      6.207527
QF Loss                      647.2363
VF Loss                      376.76633
Policy Loss                  -5044.1343
Q Predictions Mean           5048.9614
Q Predictions Std            610.81757
Q Predictions Max            5724.7227
Q Predictions Min            794.344
V Predictions Mean           5056.81
V Predictions Std            616.11084
V Predictions Max            5729.3887
V Predictions Min            637.39575
Log Pis Mean                 6.0508986
Log Pis Std                  4.226307
Log Pis Max                  16.635878
Log Pis Min                  -3.0684912
Policy mu Mean               -0.01444786
Policy mu Std                1.4458817
Policy mu Max                2.855404
Policy mu Min                -4.1612616
Policy log std Mean          -0.91940546
Policy log std Std           0.5381961
Policy log std Max           -0.12125528
Policy log std Min           -3.5012312
Z mean eval                  4.2053013
Z variance eval              0.02741887
total_rewards                [12077.6444294  12198.93610112 12132.63343173 12391.81945641
 12133.2443116  11783.2427459  12393.68335097 12137.60947725
 12131.6445063  12331.51270416]
total_rewards_mean           12171.197051482402
total_rewards_std            170.1545447248078
total_rewards_max            12393.683350967625
total_rewards_min            11783.242745900983
Number of train steps total  1656000
Number of env steps total    2072000
Number of rollouts total     0
Train Time (s)               139.6612547650002
(Previous) Eval Time (s)     29.509275905322284
Sample Time (s)              21.424574266187847
Epoch Time (s)               190.59510493651032
Total Train Time (s)         76124.31158878095
Epoch                        413
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:56:29.073196 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #413 | Epoch Duration: 188.98453283309937
2020-01-14 01:56:29.073456 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #413 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.205701
Z variance train             0.027378818
KL Divergence                64.373535
KL Loss                      6.4373536
QF Loss                      492.6369
VF Loss                      148.81679
Policy Loss                  -5123.221
Q Predictions Mean           5129.4155
Q Predictions Std            557.7216
Q Predictions Max            5759.2095
Q Predictions Min            3345.5269
V Predictions Mean           5123.992
V Predictions Std            557.34216
V Predictions Max            5751.7827
V Predictions Min            3336.7605
Log Pis Mean                 6.230465
Log Pis Std                  3.8052092
Log Pis Max                  16.891207
Log Pis Min                  -4.252203
Policy mu Mean               -0.047905784
Policy mu Std                1.4567322
Policy mu Max                3.3618436
Policy mu Min                -3.1484675
Policy log std Mean          -0.9174939
Policy log std Std           0.5403118
Policy log std Max           -0.17424226
Policy log std Min           -3.509767
Z mean eval                  4.172288
Z variance eval              0.035572674
total_rewards                [ 9047.61630171  8714.61405209  4909.00013498  9822.9796314
  8882.33587288  7407.70178912  8313.11499174  9748.22660852
  8651.94531073 10860.9913714 ]
total_rewards_mean           8635.852606457605
total_rewards_std            1527.632090560214
total_rewards_max            10860.991371402011
total_rewards_min            4909.000134982648
Number of train steps total  1660000
Number of env steps total    2077000
Number of rollouts total     0
Train Time (s)               139.42796562612057
(Previous) Eval Time (s)     27.89832704141736
Sample Time (s)              22.95997282816097
Epoch Time (s)               190.2862654956989
Total Train Time (s)         76313.38067072676
Epoch                        414
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:59:38.146402 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #414 | Epoch Duration: 189.0727825164795
2020-01-14 01:59:38.146610 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #414 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.171672
Z variance train             0.03552986
KL Divergence                62.736645
KL Loss                      6.2736645
QF Loss                      1154.6162
VF Loss                      184.21591
Policy Loss                  -5044.207
Q Predictions Mean           5051.8545
Q Predictions Std            600.2022
Q Predictions Max            5761.362
Q Predictions Min            3360.858
V Predictions Mean           5044.585
V Predictions Std            600.03284
V Predictions Max            5750.5757
V Predictions Min            3366.179
Log Pis Mean                 5.6049395
Log Pis Std                  3.9244945
Log Pis Max                  17.783943
Log Pis Min                  -4.5902967
Policy mu Mean               0.05923444
Policy mu Std                1.421929
Policy mu Max                3.1741567
Policy mu Min                -3.076527
Policy log std Mean          -0.8692789
Policy log std Std           0.45130417
Policy log std Max           -0.16247803
Policy log std Min           -3.2713323
Z mean eval                  4.244355
Z variance eval              0.03738811
total_rewards                [11732.10363687 12177.93196649 12017.88426608 12315.62021591
 11926.00493012 12161.60483452 11480.31097621 12328.3003938
 11846.03773752 11601.5598976 ]
total_rewards_mean           11958.735885512291
total_rewards_std            278.9704390605452
total_rewards_max            12328.30039380193
total_rewards_min            11480.310976205534
Number of train steps total  1664000
Number of env steps total    2082000
Number of rollouts total     0
Train Time (s)               140.07011628104374
(Previous) Eval Time (s)     26.684453810565174
Sample Time (s)              23.337819966487586
Epoch Time (s)               190.0923900580965
Total Train Time (s)         76505.2400014964
Epoch                        415
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:02:50.010608 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #415 | Epoch Duration: 191.8638415336609
2020-01-14 02:02:50.010863 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #415 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.246786
Z variance train             0.03729064
KL Divergence                65.1133
KL Loss                      6.5113297
QF Loss                      904.1951
VF Loss                      212.74629
Policy Loss                  -5013.555
Q Predictions Mean           5021.0664
Q Predictions Std            645.6794
Q Predictions Max            5710.039
Q Predictions Min            815.41394
V Predictions Mean           5009.8696
V Predictions Std            648.5339
V Predictions Max            5691.784
V Predictions Min            702.3717
Log Pis Mean                 6.2911096
Log Pis Std                  4.1480975
Log Pis Max                  18.257252
Log Pis Min                  -5.1614532
Policy mu Mean               -0.03502305
Policy mu Std                1.481979
Policy mu Max                2.9020212
Policy mu Min                -2.9851115
Policy log std Mean          -0.9022484
Policy log std Std           0.51632845
Policy log std Max           0.0815984
Policy log std Min           -3.466707
Z mean eval                  4.2313366
Z variance eval              0.021386018
total_rewards                [11267.69854136 11589.09191889 11881.55798111 11764.81720174
 11682.86804747 11855.64739018 11656.43525923 11887.99662458
 11372.69725042 11566.59227271]
total_rewards_mean           11652.540248769434
total_rewards_std            200.1275560281275
total_rewards_max            11887.996624583053
total_rewards_min            11267.698541362613
Number of train steps total  1668000
Number of env steps total    2087000
Number of rollouts total     0
Train Time (s)               134.86045100307092
(Previous) Eval Time (s)     28.455482865683734
Sample Time (s)              21.78211319539696
Epoch Time (s)               185.09804706415161
Total Train Time (s)         76689.94229275221
Epoch                        416
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:05:54.716297 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #416 | Epoch Duration: 184.70528173446655
2020-01-14 02:05:54.716468 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #416 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2321596
Z variance train             0.021392988
KL Divergence                66.08316
KL Loss                      6.608316
QF Loss                      771.70825
VF Loss                      463.73618
Policy Loss                  -5192.443
Q Predictions Mean           5200.1113
Q Predictions Std            605.0529
Q Predictions Max            5903.1416
Q Predictions Min            3552.377
V Predictions Mean           5178.735
V Predictions Std            602.578
V Predictions Max            5877.752
V Predictions Min            3540.612
Log Pis Mean                 6.729292
Log Pis Std                  4.13974
Log Pis Max                  19.543245
Log Pis Min                  -2.6170146
Policy mu Mean               0.0025699977
Policy mu Std                1.5181756
Policy mu Max                3.4497247
Policy mu Min                -3.42433
Policy log std Mean          -0.8731764
Policy log std Std           0.5062914
Policy log std Max           -0.14508748
Policy log std Min           -3.6382947
Z mean eval                  4.168273
Z variance eval              0.014968336
total_rewards                [11931.40929909 11970.04109129 12030.20271159 12099.45488435
 10952.72783066 12220.74629696 11928.71124681 11875.0246203
 12038.43531444 11989.56183817]
total_rewards_mean           11903.63151336664
total_rewards_std            330.3531339181747
total_rewards_max            12220.746296964917
total_rewards_min            10952.727830657117
Number of train steps total  1672000
Number of env steps total    2092000
Number of rollouts total     0
Train Time (s)               131.9315782887861
(Previous) Eval Time (s)     28.062425196170807
Sample Time (s)              22.195177972316742
Epoch Time (s)               182.18918145727366
Total Train Time (s)         76871.49795502378
Epoch                        417
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:08:56.276663 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #417 | Epoch Duration: 181.56004667282104
2020-01-14 02:08:56.276858 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #417 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1686754
Z variance train             0.014964124
KL Divergence                66.01535
KL Loss                      6.6015353
QF Loss                      833.1505
VF Loss                      193.38861
Policy Loss                  -4982.2876
Q Predictions Mean           4993.2666
Q Predictions Std            632.29364
Q Predictions Max            5778.2285
Q Predictions Min            3382.3574
V Predictions Mean           4982.826
V Predictions Std            633.0949
V Predictions Max            5767.766
V Predictions Min            3375.1067
Log Pis Mean                 6.391619
Log Pis Std                  3.909927
Log Pis Max                  15.014603
Log Pis Min                  -2.8007362
Policy mu Mean               -0.09353552
Policy mu Std                1.4816337
Policy mu Max                3.0342133
Policy mu Min                -2.777516
Policy log std Mean          -0.9158168
Policy log std Std           0.52892435
Policy log std Max           -0.020159245
Policy log std Min           -3.4979877
Z mean eval                  4.2020836
Z variance eval              0.01730798
total_rewards                [12164.16032485 12494.35322847 12280.23543216 12351.1131643
 12385.37567904 12122.45027461 12439.41839473 12227.26396907
 12596.65307057 12553.82863925]
total_rewards_mean           12361.485217706842
total_rewards_std            154.07706559693392
total_rewards_max            12596.653070570408
total_rewards_min            12122.450274614632
Number of train steps total  1676000
Number of env steps total    2097000
Number of rollouts total     0
Train Time (s)               134.84533768706024
(Previous) Eval Time (s)     27.432930367067456
Sample Time (s)              22.147498943377286
Epoch Time (s)               184.42576699750498
Total Train Time (s)         77056.15630784119
Epoch                        418
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:12:00.939135 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #418 | Epoch Duration: 184.66214084625244
2020-01-14 02:12:00.939335 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #418 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.201151
Z variance train             0.017369254
KL Divergence                66.56462
KL Loss                      6.656462
QF Loss                      708.3552
VF Loss                      331.80487
Policy Loss                  -5066.5347
Q Predictions Mean           5074.861
Q Predictions Std            585.04645
Q Predictions Max            5764.112
Q Predictions Min            3462.3562
V Predictions Mean           5081.798
V Predictions Std            585.73456
V Predictions Max            5773.543
V Predictions Min            3451.17
Log Pis Mean                 6.3508596
Log Pis Std                  4.018778
Log Pis Max                  22.08422
Log Pis Min                  -3.5196068
Policy mu Mean               -0.04832456
Policy mu Std                1.4996761
Policy mu Max                4.5475216
Policy mu Min                -2.7661319
Policy log std Mean          -0.8969755
Policy log std Std           0.50947183
Policy log std Max           -0.069087625
Policy log std Min           -3.639523
Z mean eval                  4.2360697
Z variance eval              0.011745538
total_rewards                [12201.25955735 12307.72833419 12394.93130328 12358.99103528
 12681.82804734 12217.09813847 12527.64021733 12539.13352605
 12574.61592134 12632.94438012]
total_rewards_mean           12443.617046074702
total_rewards_std            162.4742718786586
total_rewards_max            12681.828047335675
total_rewards_min            12201.259557354655
Number of train steps total  1680000
Number of env steps total    2102000
Number of rollouts total     0
Train Time (s)               142.21265354612842
(Previous) Eval Time (s)     27.66900525521487
Sample Time (s)              22.892930649220943
Epoch Time (s)               192.77458945056424
Total Train Time (s)         77249.41513134213
Epoch                        419
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:15:14.208452 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #419 | Epoch Duration: 193.26893281936646
2020-01-14 02:15:14.209157 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #419 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.237085
Z variance train             0.011839581
KL Divergence                67.27211
KL Loss                      6.727211
QF Loss                      763.82983
VF Loss                      189.67213
Policy Loss                  -5029.984
Q Predictions Mean           5030.32
Q Predictions Std            689.1792
Q Predictions Max            5755.318
Q Predictions Min            431.62286
V Predictions Mean           5024.9883
V Predictions Std            687.482
V Predictions Max            5790.498
V Predictions Min            454.43814
Log Pis Mean                 6.055258
Log Pis Std                  3.7544835
Log Pis Max                  15.188716
Log Pis Min                  -3.255352
Policy mu Mean               -0.12638818
Policy mu Std                1.4413736
Policy mu Max                3.0369165
Policy mu Min                -2.7853649
Policy log std Mean          -0.90428025
Policy log std Std           0.51414317
Policy log std Max           -0.22994217
Policy log std Min           -3.5898252
Z mean eval                  4.2014756
Z variance eval              0.011833328
total_rewards                [11882.34342322 12068.03955582 11881.55533821 11685.44488991
 11560.06890187 12043.04097647 11905.13058966 12181.97384605
 12014.81696252 11906.402093  ]
total_rewards_mean           11912.881657672777
total_rewards_std            173.79215854158656
total_rewards_max            12181.973846053417
total_rewards_min            11560.068901870498
Number of train steps total  1684000
Number of env steps total    2107000
Number of rollouts total     0
Train Time (s)               140.96626986004412
(Previous) Eval Time (s)     28.162935697939247
Sample Time (s)              22.83743812609464
Epoch Time (s)               191.966643684078
Total Train Time (s)         77440.45545090549
Epoch                        420
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:18:25.247233 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #420 | Epoch Duration: 191.03756046295166
2020-01-14 02:18:25.247432 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #420 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.202339
Z variance train             0.01176591
KL Divergence                67.255554
KL Loss                      6.7255554
QF Loss                      783.4091
VF Loss                      617.67554
Policy Loss                  -4995.368
Q Predictions Mean           5000.874
Q Predictions Std            656.1089
Q Predictions Max            5793.9004
Q Predictions Min            849.08624
V Predictions Mean           4993.9927
V Predictions Std            658.393
V Predictions Max            5787.1943
V Predictions Min            843.6327
Log Pis Mean                 6.9385366
Log Pis Std                  4.3303566
Log Pis Max                  18.604101
Log Pis Min                  -6.5060954
Policy mu Mean               -0.020817656
Policy mu Std                1.5407697
Policy mu Max                3.0519032
Policy mu Min                -2.833645
Policy log std Mean          -0.8861715
Policy log std Std           0.48548982
Policy log std Max           -0.25134945
Policy log std Min           -3.5063744
Z mean eval                  4.2132425
Z variance eval              0.023078868
total_rewards                [12019.97836159 12441.93166795 11881.1142379  12291.32176965
 12406.36424317 12489.85595015 12703.52901984 11721.75026834
 12542.56164679   110.86060098]
total_rewards_mean           11060.926776637436
total_rewards_std            3661.961158701631
total_rewards_max            12703.529019840214
total_rewards_min            110.86060098253913
Number of train steps total  1688000
Number of env steps total    2112000
Number of rollouts total     0
Train Time (s)               140.37208591075614
(Previous) Eval Time (s)     27.23354935599491
Sample Time (s)              22.883808858226985
Epoch Time (s)               190.48944412497804
Total Train Time (s)         77633.17178546963
Epoch                        421
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:21:37.968351 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #421 | Epoch Duration: 192.72076296806335
2020-01-14 02:21:37.968588 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #421 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2141523
Z variance train             0.023088668
KL Divergence                67.94881
KL Loss                      6.794881
QF Loss                      733.67456
VF Loss                      175.2281
Policy Loss                  -4986.6465
Q Predictions Mean           4984.4727
Q Predictions Std            629.4621
Q Predictions Max            5766.2056
Q Predictions Min            3366.0977
V Predictions Mean           4987.5557
V Predictions Std            628.01605
V Predictions Max            5755.5415
V Predictions Min            3377.9736
Log Pis Mean                 6.526889
Log Pis Std                  4.266544
Log Pis Max                  15.852955
Log Pis Min                  -3.0843747
Policy mu Mean               -0.073504776
Policy mu Std                1.4622034
Policy mu Max                3.1257515
Policy mu Min                -2.8075995
Policy log std Mean          -0.9179582
Policy log std Std           0.54676515
Policy log std Max           -0.024487078
Policy log std Min           -3.566616
Z mean eval                  4.212262
Z variance eval              0.017775806
total_rewards                [11986.22707536 12698.24789242 12319.37141895 12755.74907241
 12596.78595826 12192.50982315 12413.42279822   322.10040651
    31.02666129 12598.55556386]
total_rewards_mean           9991.399667044436
total_rewards_std            4912.923813619964
total_rewards_max            12755.749072408351
total_rewards_min            31.02666129115839
Number of train steps total  1692000
Number of env steps total    2117000
Number of rollouts total     0
Train Time (s)               140.00336694763973
(Previous) Eval Time (s)     29.46444776514545
Sample Time (s)              22.945228275377303
Epoch Time (s)               192.4130429881625
Total Train Time (s)         77824.54784602486
Epoch                        422
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:24:49.349069 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #422 | Epoch Duration: 191.38033151626587
2020-01-14 02:24:49.349264 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #422 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2116194
Z variance train             0.017795872
KL Divergence                68.49336
KL Loss                      6.849336
QF Loss                      356.3988
VF Loss                      259.65497
Policy Loss                  -5080.018
Q Predictions Mean           5087.5806
Q Predictions Std            571.71436
Q Predictions Max            5764.7646
Q Predictions Min            3359.496
V Predictions Mean           5089.827
V Predictions Std            569.6968
V Predictions Max            5744.527
V Predictions Min            3387.5542
Log Pis Mean                 6.3062563
Log Pis Std                  4.097199
Log Pis Max                  16.209803
Log Pis Min                  -5.59227
Policy mu Mean               -0.053477768
Policy mu Std                1.4843947
Policy mu Max                3.3837967
Policy mu Min                -2.8908505
Policy log std Mean          -0.90224284
Policy log std Std           0.5159068
Policy log std Max           -0.18291247
Policy log std Min           -3.5100205
Z mean eval                  4.2810082
Z variance eval              0.0059447577
total_rewards                [12021.85949066 12248.63436353 12431.83519768 12295.4805735
 12320.62169679 12032.63946955 12448.0493934  12342.54165455
 12166.06192447 12471.0201489 ]
total_rewards_mean           12277.874391303589
total_rewards_std            153.40427399408065
total_rewards_max            12471.020148903815
total_rewards_min            12021.859490664985
Number of train steps total  1696000
Number of env steps total    2122000
Number of rollouts total     0
Train Time (s)               132.72875217581168
(Previous) Eval Time (s)     28.43131291726604
Sample Time (s)              22.51562131056562
Epoch Time (s)               183.67568640364334
Total Train Time (s)         78007.85625343584
Epoch                        423
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:27:52.661287 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #423 | Epoch Duration: 183.31188416481018
2020-01-14 02:27:52.661467 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #423 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2787666
Z variance train             0.005954336
KL Divergence                72.25996
KL Loss                      7.2259955
QF Loss                      1028.3152
VF Loss                      312.12848
Policy Loss                  -5061.6206
Q Predictions Mean           5071.722
Q Predictions Std            679.6439
Q Predictions Max            5770.7993
Q Predictions Min            414.3297
V Predictions Mean           5068.3716
V Predictions Std            679.7792
V Predictions Max            5769.878
V Predictions Min            354.62857
Log Pis Mean                 5.6595697
Log Pis Std                  3.8259423
Log Pis Max                  14.711401
Log Pis Min                  -5.2412148
Policy mu Mean               -0.050955314
Policy mu Std                1.4529264
Policy mu Max                3.1925468
Policy mu Min                -2.9465137
Policy log std Mean          -0.9025243
Policy log std Std           0.4973738
Policy log std Max           0.12048578
Policy log std Min           -3.3795347
Z mean eval                  4.184558
Z variance eval              0.013858525
total_rewards                [12126.69584927 12161.38302032 12018.82442173 12180.40586758
 12188.14568644 12128.42899819 12269.63192331 12190.80654877
 11697.54768274 12022.70112133]
total_rewards_mean           12098.45711196589
total_rewards_std            152.00427282073875
total_rewards_max            12269.631923305345
total_rewards_min            11697.547682739114
Number of train steps total  1700000
Number of env steps total    2127000
Number of rollouts total     0
Train Time (s)               132.62872829521075
(Previous) Eval Time (s)     28.067200834862888
Sample Time (s)              22.127717564813793
Epoch Time (s)               182.82364669488743
Total Train Time (s)         78190.45512861665
Epoch                        424
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:30:55.265081 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #424 | Epoch Duration: 182.6034722328186
2020-01-14 02:30:55.265295 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #424 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1853266
Z variance train             0.0138506545
KL Divergence                69.867744
KL Loss                      6.9867744
QF Loss                      913.13416
VF Loss                      215.36641
Policy Loss                  -4986.4146
Q Predictions Mean           4991.549
Q Predictions Std            650.7896
Q Predictions Max            5683.1343
Q Predictions Min            2746.45
V Predictions Mean           4979.685
V Predictions Std            648.83484
V Predictions Max            5653.1
V Predictions Min            2742.0212
Log Pis Mean                 6.2542152
Log Pis Std                  3.8266156
Log Pis Max                  17.390656
Log Pis Min                  -2.1470265
Policy mu Mean               -0.018183967
Policy mu Std                1.4488167
Policy mu Max                3.1816583
Policy mu Min                -2.9759269
Policy log std Mean          -0.91560555
Policy log std Std           0.5196697
Policy log std Max           -0.15311873
Policy log std Min           -3.3915534
Z mean eval                  4.2383466
Z variance eval              0.008000338
total_rewards                [12084.29800067 12450.75442671 12220.8523021  12229.31122138
 12162.97446667 12228.31211421 12558.6251097  11879.41826885
 12270.43842655 12137.40577852]
total_rewards_mean           12222.239011537724
total_rewards_std            177.49638168392363
total_rewards_max            12558.62510970491
total_rewards_min            11879.418268853698
Number of train steps total  1704000
Number of env steps total    2132000
Number of rollouts total     0
Train Time (s)               136.2348874239251
(Previous) Eval Time (s)     27.84667632402852
Sample Time (s)              19.86286482727155
Epoch Time (s)               183.94442857522517
Total Train Time (s)         78375.41175658163
Epoch                        425
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:34:00.225732 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #425 | Epoch Duration: 184.9602930545807
2020-01-14 02:34:00.225918 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #425 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.240407
Z variance train             0.007980349
KL Divergence                72.71157
KL Loss                      7.2711573
QF Loss                      723.13696
VF Loss                      229.87718
Policy Loss                  -5040.095
Q Predictions Mean           5044.908
Q Predictions Std            637.80054
Q Predictions Max            5759.2876
Q Predictions Min            2559.5933
V Predictions Mean           5032.9824
V Predictions Std            637.3901
V Predictions Max            5754.396
V Predictions Min            2603.664
Log Pis Mean                 6.254443
Log Pis Std                  4.285141
Log Pis Max                  17.988953
Log Pis Min                  -2.4601517
Policy mu Mean               -0.0021706137
Policy mu Std                1.4714999
Policy mu Max                3.320805
Policy mu Min                -3.1834798
Policy log std Mean          -0.8885458
Policy log std Std           0.4867517
Policy log std Max           0.25301123
Policy log std Min           -3.5124538
Z mean eval                  4.2548113
Z variance eval              0.009386234
total_rewards                [11991.09827054 12058.25514783 12284.94736142 12281.35294283
 12562.18157311  2653.48568455 12251.40682149 12304.22589489
 12283.04183664 12260.96765115]
total_rewards_mean           11293.096318444495
total_rewards_std            2883.471046874756
total_rewards_max            12562.181573111511
total_rewards_min            2653.485684546918
Number of train steps total  1708000
Number of env steps total    2137000
Number of rollouts total     0
Train Time (s)               141.02240814687684
(Previous) Eval Time (s)     28.862222022842616
Sample Time (s)              23.374987273477018
Epoch Time (s)               193.25961744319648
Total Train Time (s)         78568.5949057918
Epoch                        426
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:37:13.414201 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #426 | Epoch Duration: 193.18812251091003
2020-01-14 02:37:13.414495 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #426 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2536254
Z variance train             0.0093765985
KL Divergence                69.27898
KL Loss                      6.927898
QF Loss                      1846.5261
VF Loss                      231.48544
Policy Loss                  -5053.609
Q Predictions Mean           5061.868
Q Predictions Std            615.48663
Q Predictions Max            5726.1826
Q Predictions Min            3357.3665
V Predictions Mean           5062.899
V Predictions Std            614.73975
V Predictions Max            5736.868
V Predictions Min            3376.3992
Log Pis Mean                 6.43734
Log Pis Std                  4.4111814
Log Pis Max                  17.27697
Log Pis Min                  -9.855028
Policy mu Mean               -0.1305406
Policy mu Std                1.4521947
Policy mu Max                2.9993467
Policy mu Min                -2.8887622
Policy log std Mean          -0.92937106
Policy log std Std           0.5444204
Policy log std Max           -0.24083993
Policy log std Min           -3.5702252
Z mean eval                  4.2231617
Z variance eval              0.006520373
total_rewards                [11396.14028668 11660.71048842 11615.80697217 11702.14877663
 11539.19159326 11662.29720247 11173.65258408 11719.58564132
 11671.47641411 11538.16297743]
total_rewards_mean           11567.917293656155
total_rewards_std            160.69222823813928
total_rewards_max            11719.585641316165
total_rewards_min            11173.652584080046
Number of train steps total  1712000
Number of env steps total    2142000
Number of rollouts total     0
Train Time (s)               140.22917164070532
(Previous) Eval Time (s)     28.790373877156526
Sample Time (s)              22.254935398232192
Epoch Time (s)               191.27448091609403
Total Train Time (s)         78759.86282412428
Epoch                        427
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:40:24.686051 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #427 | Epoch Duration: 191.27137660980225
2020-01-14 02:40:24.686239 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #427 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2179503
Z variance train             0.0064640916
KL Divergence                70.35903
KL Loss                      7.0359035
QF Loss                      1561.9355
VF Loss                      2192.5662
Policy Loss                  -5003.485
Q Predictions Mean           5008.734
Q Predictions Std            636.1196
Q Predictions Max            5748.5503
Q Predictions Min            3303.5745
V Predictions Mean           5045.5693
V Predictions Std            634.85236
V Predictions Max            5775.127
V Predictions Min            3353.7153
Log Pis Mean                 6.3638716
Log Pis Std                  4.3740144
Log Pis Max                  18.133574
Log Pis Min                  -6.8436103
Policy mu Mean               -0.029777726
Policy mu Std                1.4899591
Policy mu Max                3.121343
Policy mu Min                -3.2287915
Policy log std Mean          -0.89485407
Policy log std Std           0.49409586
Policy log std Max           -0.053116918
Policy log std Min           -3.3996794
Z mean eval                  4.291304
Z variance eval              0.0061282446
total_rewards                [11882.36910107 12052.78414359 12322.35490183 12156.97660999
 11976.82937255 12027.36061558 11973.35059183 12140.55965099
 12062.92584859 12022.32276507]
total_rewards_mean           12061.783360109466
total_rewards_std            115.41938880270132
total_rewards_max            12322.354901831868
total_rewards_min            11882.36910106798
Number of train steps total  1716000
Number of env steps total    2147000
Number of rollouts total     0
Train Time (s)               142.16154840774834
(Previous) Eval Time (s)     28.786933093331754
Sample Time (s)              22.434989728033543
Epoch Time (s)               193.38347122911364
Total Train Time (s)         78953.09820330376
Epoch                        428
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:43:37.926093 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #428 | Epoch Duration: 193.2397117614746
2020-01-14 02:43:37.926302 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #428 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.289708
Z variance train             0.0061227535
KL Divergence                72.602425
KL Loss                      7.2602425
QF Loss                      579.33
VF Loss                      140.52716
Policy Loss                  -5155.9604
Q Predictions Mean           5160.6865
Q Predictions Std            614.2037
Q Predictions Max            5879.4023
Q Predictions Min            3442.8352
V Predictions Mean           5158.391
V Predictions Std            614.8542
V Predictions Max            5857.8154
V Predictions Min            3456.1357
Log Pis Mean                 5.7810836
Log Pis Std                  3.9405253
Log Pis Max                  15.695238
Log Pis Min                  -4.8751335
Policy mu Mean               -0.058647614
Policy mu Std                1.452646
Policy mu Max                3.1478076
Policy mu Min                -2.8321595
Policy log std Mean          -0.8898484
Policy log std Std           0.5145525
Policy log std Max           -0.026871324
Policy log std Min           -3.516872
Z mean eval                  4.291605
Z variance eval              0.0036437516
total_rewards                [12222.70047217 12581.93706296 12895.91157881 12363.38184902
 12597.05664101 12704.70988311 12758.52595608 12524.82208524
 12572.04391068 12495.15277477]
total_rewards_mean           12571.62422138579
total_rewards_std            182.12925939962852
total_rewards_max            12895.911578808804
total_rewards_min            12222.700472170867
Number of train steps total  1720000
Number of env steps total    2152000
Number of rollouts total     0
Train Time (s)               140.06795615842566
(Previous) Eval Time (s)     28.642833833117038
Sample Time (s)              22.306825106963515
Epoch Time (s)               191.0176150985062
Total Train Time (s)         79142.38483685162
Epoch                        429
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:46:47.217156 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #429 | Epoch Duration: 189.2906939983368
2020-01-14 02:46:47.217341 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #429 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.290778
Z variance train             0.0036403276
KL Divergence                72.79129
KL Loss                      7.279129
QF Loss                      679.4763
VF Loss                      139.86751
Policy Loss                  -5105.606
Q Predictions Mean           5114.503
Q Predictions Std            603.23267
Q Predictions Max            5782.6323
Q Predictions Min            3382.9072
V Predictions Mean           5111.4434
V Predictions Std            602.9592
V Predictions Max            5786.244
V Predictions Min            3402.3972
Log Pis Mean                 6.174357
Log Pis Std                  4.1024165
Log Pis Max                  17.044708
Log Pis Min                  -2.9120562
Policy mu Mean               -0.05175587
Policy mu Std                1.4882289
Policy mu Max                2.831469
Policy mu Min                -2.7998013
Policy log std Mean          -0.86574227
Policy log std Std           0.4755452
Policy log std Max           -0.06586397
Policy log std Min           -3.412858
Z mean eval                  4.2870374
Z variance eval              0.0031262778
total_rewards                [11932.48356424 11934.30126411 12286.81446842 12151.42833881
 11867.90606766 12244.46101325 12166.59596271 12108.44957174
 11452.2082093  12215.42310815]
total_rewards_mean           12036.00715683853
total_rewards_std            237.55235222828728
total_rewards_max            12286.814468416385
total_rewards_min            11452.208209298424
Number of train steps total  1724000
Number of env steps total    2157000
Number of rollouts total     0
Train Time (s)               132.9322324176319
(Previous) Eval Time (s)     26.915585820097476
Sample Time (s)              21.78695361269638
Epoch Time (s)               181.63477185042575
Total Train Time (s)         79324.85224059969
Epoch                        430
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:49:49.692267 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #430 | Epoch Duration: 182.4747793674469
2020-01-14 02:49:49.692463 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #430 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.286469
Z variance train             0.0031320571
KL Divergence                71.8088
KL Loss                      7.18088
QF Loss                      757.80237
VF Loss                      268.12854
Policy Loss                  -5128.83
Q Predictions Mean           5134.9893
Q Predictions Std            575.43146
Q Predictions Max            5785.408
Q Predictions Min            3365.244
V Predictions Mean           5126.499
V Predictions Std            572.0982
V Predictions Max            5752.6772
V Predictions Min            3381.25
Log Pis Mean                 5.688005
Log Pis Std                  4.2432556
Log Pis Max                  17.387949
Log Pis Min                  -6.644639
Policy mu Mean               -0.027073814
Policy mu Std                1.4260049
Policy mu Max                2.7261577
Policy mu Min                -3.007473
Policy log std Mean          -0.9092467
Policy log std Std           0.5071529
Policy log std Max           0.16997385
Policy log std Min           -3.4853823
Z mean eval                  4.2509937
Z variance eval              0.027906459
total_rewards                [12049.14779234 12383.57641323 12527.92129261 12553.11907975
 12739.5234461  12604.76122242 12382.48073521 12514.47237287
 12457.19262255 12504.31994524]
total_rewards_mean           12471.651492230496
total_rewards_std            172.22217529115696
total_rewards_max            12739.523446100822
total_rewards_min            12049.147792335394
Number of train steps total  1728000
Number of env steps total    2162000
Number of rollouts total     0
Train Time (s)               132.33286420209333
(Previous) Eval Time (s)     27.755239963997155
Sample Time (s)              22.326575323473662
Epoch Time (s)               182.41467948956415
Total Train Time (s)         79507.7961815903
Epoch                        431
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:52:52.640593 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #431 | Epoch Duration: 182.94798493385315
2020-01-14 02:52:52.640786 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #431 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2521706
Z variance train             0.027990172
KL Divergence                65.73953
KL Loss                      6.573953
QF Loss                      597.86456
VF Loss                      422.07632
Policy Loss                  -5051.3003
Q Predictions Mean           5056.075
Q Predictions Std            565.9345
Q Predictions Max            5702.6646
Q Predictions Min            3354.4504
V Predictions Mean           5035.4043
V Predictions Std            562.6936
V Predictions Max            5684.781
V Predictions Min            3345.434
Log Pis Mean                 6.531312
Log Pis Std                  3.8518877
Log Pis Max                  16.00428
Log Pis Min                  -5.255648
Policy mu Mean               -0.06993546
Policy mu Std                1.4657754
Policy mu Max                2.9210296
Policy mu Min                -3.0067816
Policy log std Mean          -0.90705127
Policy log std Std           0.512506
Policy log std Max           -0.07794511
Policy log std Min           -3.518073
Z mean eval                  4.281307
Z variance eval              0.011516049
total_rewards                [11949.13953655 12423.19035998 12521.91161925 12579.8770484
 12557.41198191 12431.93191436 12408.49672646 12029.5398034
 11981.81527733 12379.20194787]
total_rewards_mean           12326.25162155003
total_rewards_std            231.31473463341487
total_rewards_max            12579.877048400378
total_rewards_min            11949.139536548806
Number of train steps total  1732000
Number of env steps total    2167000
Number of rollouts total     0
Train Time (s)               140.17792139109224
(Previous) Eval Time (s)     28.2881897832267
Sample Time (s)              22.315945187583566
Epoch Time (s)               190.7820563619025
Total Train Time (s)         79699.18438056111
Epoch                        432
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:56:04.033397 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #432 | Epoch Duration: 191.39247035980225
2020-01-14 02:56:04.033578 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #432 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2805696
Z variance train             0.011522504
KL Divergence                69.69288
KL Loss                      6.969288
QF Loss                      562.05334
VF Loss                      147.34987
Policy Loss                  -5130.0415
Q Predictions Mean           5136.375
Q Predictions Std            631.9477
Q Predictions Max            5784.492
Q Predictions Min            3408.2908
V Predictions Mean           5135.416
V Predictions Std            630.2594
V Predictions Max            5791.6743
V Predictions Min            3429.736
Log Pis Mean                 6.180298
Log Pis Std                  4.0519414
Log Pis Max                  16.833553
Log Pis Min                  -9.543333
Policy mu Mean               -0.038341645
Policy mu Std                1.4622561
Policy mu Max                3.116128
Policy mu Min                -2.8964968
Policy log std Mean          -0.89704067
Policy log std Std           0.50134695
Policy log std Max           -0.113967985
Policy log std Min           -3.5583735
Z mean eval                  4.275661
Z variance eval              0.014476629
total_rewards                [10770.46415743 10635.22519477 10941.01440114  9135.07776752
 10932.81054151  6556.26384525  1658.73879297 10138.15880976
  4200.1136327   9110.58049377]
total_rewards_mean           8407.844763683428
total_rewards_std            3066.5301432418464
total_rewards_max            10941.014401137334
total_rewards_min            1658.7387929715387
Number of train steps total  1736000
Number of env steps total    2172000
Number of rollouts total     0
Train Time (s)               140.39155904203653
(Previous) Eval Time (s)     28.898209602106363
Sample Time (s)              22.964557245839387
Epoch Time (s)               192.25432588998228
Total Train Time (s)         79891.45554967038
Epoch                        433
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:59:16.309464 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #433 | Epoch Duration: 192.27573323249817
2020-01-14 02:59:16.309749 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #433 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2763786
Z variance train             0.014506942
KL Divergence                67.72764
KL Loss                      6.7727637
QF Loss                      889.4779
VF Loss                      137.74905
Policy Loss                  -5051.34
Q Predictions Mean           5056.263
Q Predictions Std            667.9352
Q Predictions Max            5779.099
Q Predictions Min            3379.171
V Predictions Mean           5051.958
V Predictions Std            669.31665
V Predictions Max            5783.32
V Predictions Min            3389.3057
Log Pis Mean                 6.39806
Log Pis Std                  4.3806243
Log Pis Max                  23.507837
Log Pis Min                  -4.2772217
Policy mu Mean               0.02537666
Policy mu Std                1.4943571
Policy mu Max                3.4698308
Policy mu Min                -3.650451
Policy log std Mean          -0.88660985
Policy log std Std           0.4734924
Policy log std Max           -0.16053843
Policy log std Min           -3.4113169
Z mean eval                  4.247489
Z variance eval              0.0075525283
total_rewards                [11688.06157848 11933.98562068 12029.69490094 11992.06186795
 11779.43398927 11948.2189252  11993.97115738 11903.14917699
 11983.16012364 12022.6327347 ]
total_rewards_mean           11927.437007522785
total_rewards_std            105.59227963272372
total_rewards_max            12029.694900943847
total_rewards_min            11688.061578481565
Number of train steps total  1740000
Number of env steps total    2177000
Number of rollouts total     0
Train Time (s)               139.21393154701218
(Previous) Eval Time (s)     28.919231373351067
Sample Time (s)              23.242904000915587
Epoch Time (s)               191.37606692127883
Total Train Time (s)         80082.53873380367
Epoch                        434
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:02:27.396016 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #434 | Epoch Duration: 191.08607983589172
2020-01-14 03:02:27.396139 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #434 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.247142
Z variance train             0.0075590955
KL Divergence                69.57611
KL Loss                      6.957611
QF Loss                      1524.9956
VF Loss                      316.46152
Policy Loss                  -4971.407
Q Predictions Mean           4986.318
Q Predictions Std            660.8362
Q Predictions Max            5725.1167
Q Predictions Min            895.4452
V Predictions Mean           4978.332
V Predictions Std            654.7142
V Predictions Max            5697.6206
V Predictions Min            1038.02
Log Pis Mean                 6.3830276
Log Pis Std                  4.17359
Log Pis Max                  18.74212
Log Pis Min                  -2.6113272
Policy mu Mean               -0.07017299
Policy mu Std                1.487203
Policy mu Max                2.9403136
Policy mu Min                -2.7910416
Policy log std Mean          -0.9145598
Policy log std Std           0.5388029
Policy log std Max           -0.2678012
Policy log std Min           -3.6328356
Z mean eval                  4.2547975
Z variance eval              0.0053482982
total_rewards                [12564.60435805 12578.03757085 12509.30173924 12572.70762609
 12717.69241578 12861.40074876 12489.41970927 12558.10970278
 12292.55704883 12586.70691693]
total_rewards_mean           12573.053783657982
total_rewards_std            139.3943292816521
total_rewards_max            12861.400748763885
total_rewards_min            12292.557048826522
Number of train steps total  1744000
Number of env steps total    2182000
Number of rollouts total     0
Train Time (s)               140.63805846264586
(Previous) Eval Time (s)     28.628870624583215
Sample Time (s)              22.917862278409302
Epoch Time (s)               192.18479136563838
Total Train Time (s)         80273.84076597309
Epoch                        435
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:05:38.703237 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #435 | Epoch Duration: 191.30695295333862
2020-01-14 03:05:38.703444 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #435 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2539945
Z variance train             0.0053532585
KL Divergence                70.54798
KL Loss                      7.054798
QF Loss                      1138.9502
VF Loss                      100.51953
Policy Loss                  -5060.1626
Q Predictions Mean           5068.8726
Q Predictions Std            595.5388
Q Predictions Max            5740.555
Q Predictions Min            3407.0535
V Predictions Mean           5062.8
V Predictions Std            594.4659
V Predictions Max            5738.6143
V Predictions Min            3408.6843
Log Pis Mean                 6.5012293
Log Pis Std                  4.016341
Log Pis Max                  15.314415
Log Pis Min                  -3.651987
Policy mu Mean               -0.022092214
Policy mu Std                1.4780085
Policy mu Max                3.5529537
Policy mu Min                -2.7228587
Policy log std Mean          -0.92010194
Policy log std Std           0.54432
Policy log std Max           0.29906595
Policy log std Min           -3.5200472
Z mean eval                  4.248311
Z variance eval              0.015257482
total_rewards                [11999.76004606 12317.00738357 12466.74928312 12170.63436615
 12236.57860692 12188.35561244 12058.69860893 11985.35020167
 12559.86330679 12446.04565615]
total_rewards_mean           12242.904307179902
total_rewards_std            191.03684500346537
total_rewards_max            12559.86330679492
total_rewards_min            11985.350201670137
Number of train steps total  1748000
Number of env steps total    2187000
Number of rollouts total     0
Train Time (s)               136.9774659788236
(Previous) Eval Time (s)     27.750574226956815
Sample Time (s)              23.31035119527951
Epoch Time (s)               188.03839140105993
Total Train Time (s)         80462.15140124736
Epoch                        436
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:08:47.018304 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #436 | Epoch Duration: 188.31472420692444
2020-01-14 03:08:47.018489 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #436 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.249449
Z variance train             0.015218586
KL Divergence                67.4592
KL Loss                      6.7459197
QF Loss                      682.1
VF Loss                      179.52638
Policy Loss                  -5059.042
Q Predictions Mean           5063.9033
Q Predictions Std            546.7333
Q Predictions Max            5688.3247
Q Predictions Min            3297.9065
V Predictions Mean           5050.0054
V Predictions Std            545.42554
V Predictions Max            5664.9067
V Predictions Min            3309.1777
Log Pis Mean                 5.7869473
Log Pis Std                  3.9420915
Log Pis Max                  20.39093
Log Pis Min                  -4.7405143
Policy mu Mean               -0.018935533
Policy mu Std                1.4342681
Policy mu Max                2.9839458
Policy mu Min                -4.9706397
Policy log std Mean          -0.88757247
Policy log std Std           0.49941713
Policy log std Max           -0.16842479
Policy log std Min           -3.8988583
Z mean eval                  4.1889567
Z variance eval              0.019868392
total_rewards                [11666.36347719 12228.45677162 12477.26392309 11932.7088112
  8022.99314474 11504.92373838 11862.57234057 11570.86049053
 12042.11578912 11830.16589389]
total_rewards_mean           11513.842438034973
total_rewards_std            1196.9825189509836
total_rewards_max            12477.263923092834
total_rewards_min            8022.993144737511
Number of train steps total  1752000
Number of env steps total    2192000
Number of rollouts total     0
Train Time (s)               132.56819239770994
(Previous) Eval Time (s)     28.026522592175752
Sample Time (s)              22.367851827293634
Epoch Time (s)               182.96256681717932
Total Train Time (s)         80644.30990483146
Epoch                        437
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:11:49.182258 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #437 | Epoch Duration: 182.16363382339478
2020-01-14 03:11:49.182454 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #437 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1892576
Z variance train             0.01987258
KL Divergence                67.076965
KL Loss                      6.7076964
QF Loss                      879.5465
VF Loss                      136.44539
Policy Loss                  -4997.928
Q Predictions Mean           4999.2637
Q Predictions Std            624.0298
Q Predictions Max            5767.3745
Q Predictions Min            3299.0981
V Predictions Mean           4994.874
V Predictions Std            623.65717
V Predictions Max            5755.3735
V Predictions Min            3307.2646
Log Pis Mean                 6.789113
Log Pis Std                  4.1297064
Log Pis Max                  17.468964
Log Pis Min                  -1.6316354
Policy mu Mean               -0.061760593
Policy mu Std                1.4877464
Policy mu Max                3.6886966
Policy mu Min                -4.367761
Policy log std Mean          -0.92904073
Policy log std Std           0.52860326
Policy log std Max           -0.038618565
Policy log std Min           -3.5366192
Z mean eval                  4.2022524
Z variance eval              0.018000027
total_rewards                [12270.22989583  6140.54198673 12415.98518108 12162.86458314
 12483.41672382 12482.25021582 12431.64708737 12256.22435766
 12548.58064454 12456.73106705]
total_rewards_mean           11764.84717430326
total_rewards_std            1878.3142323664076
total_rewards_max            12548.580644540754
total_rewards_min            6140.5419867256
Number of train steps total  1756000
Number of env steps total    2197000
Number of rollouts total     0
Train Time (s)               133.39516031788662
(Previous) Eval Time (s)     27.22724232217297
Sample Time (s)              19.632120981812477
Epoch Time (s)               180.25452362187207
Total Train Time (s)         80825.92321967892
Epoch                        438
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:14:50.799406 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #438 | Epoch Duration: 181.6167869567871
2020-01-14 03:14:50.799598 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #438 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2035513
Z variance train             0.017997611
KL Divergence                67.333244
KL Loss                      6.7333245
QF Loss                      720.5183
VF Loss                      137.49806
Policy Loss                  -4998.226
Q Predictions Mean           5005.747
Q Predictions Std            634.8912
Q Predictions Max            5732.3633
Q Predictions Min            3426.5974
V Predictions Mean           4994.4873
V Predictions Std            634.76624
V Predictions Max            5726.671
V Predictions Min            3412.4392
Log Pis Mean                 6.2578583
Log Pis Std                  3.771459
Log Pis Max                  16.232874
Log Pis Min                  -2.1898422
Policy mu Mean               -0.024701351
Policy mu Std                1.4595026
Policy mu Max                2.8716307
Policy mu Min                -2.5595827
Policy log std Mean          -0.9088649
Policy log std Std           0.5365389
Policy log std Max           -0.19587821
Policy log std Min           -3.609028
Z mean eval                  4.267728
Z variance eval              0.054240644
total_rewards                [12312.67711441 12533.53616747 12516.86002202 12505.4166451
 12390.98954923 12303.67492936 12387.47066267 12394.88347212
 12434.0851182  12491.23572986]
total_rewards_mean           12427.082941044526
total_rewards_std            78.68919590456278
total_rewards_max            12533.536167474558
total_rewards_min            12303.674929357247
Number of train steps total  1760000
Number of env steps total    2202000
Number of rollouts total     0
Train Time (s)               141.88548250170425
(Previous) Eval Time (s)     28.589187054894865
Sample Time (s)              21.602516300044954
Epoch Time (s)               192.07718585664406
Total Train Time (s)         81018.14859779598
Epoch                        439
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:18:03.029545 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #439 | Epoch Duration: 192.22980976104736
2020-01-14 03:18:03.029733 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #439 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2685647
Z variance train             0.05433523
KL Divergence                67.20123
KL Loss                      6.7201233
QF Loss                      629.28625
VF Loss                      199.49213
Policy Loss                  -5099.0864
Q Predictions Mean           5108.353
Q Predictions Std            587.3293
Q Predictions Max            5743.9253
Q Predictions Min            3293.512
V Predictions Mean           5092.5884
V Predictions Std            584.4415
V Predictions Max            5714.803
V Predictions Min            3302.9226
Log Pis Mean                 6.666383
Log Pis Std                  3.9310668
Log Pis Max                  15.819648
Log Pis Min                  -2.9127574
Policy mu Mean               -0.023190672
Policy mu Std                1.4833798
Policy mu Max                3.6997397
Policy mu Min                -2.645882
Policy log std Mean          -0.8968852
Policy log std Std           0.51387143
Policy log std Max           0.750283
Policy log std Min           -3.682879
Z mean eval                  4.207483
Z variance eval              0.0242478
total_rewards                [11734.75796876 11854.99048674 12129.08805301 12339.16833664
 12273.20880132 12521.83314975 12311.55192387 11300.17184894
 12036.95945818 12480.6043937 ]
total_rewards_mean           12098.233442090785
total_rewards_std            359.5421256267996
total_rewards_max            12521.833149747446
total_rewards_min            11300.171848936665
Number of train steps total  1764000
Number of env steps total    2207000
Number of rollouts total     0
Train Time (s)               140.2448367010802
(Previous) Eval Time (s)     28.741475980263203
Sample Time (s)              22.107642203569412
Epoch Time (s)               191.09395488491282
Total Train Time (s)         81208.82066907175
Epoch                        440
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:21:13.706116 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #440 | Epoch Duration: 190.6762456893921
2020-01-14 03:21:13.706307 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #440 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2078114
Z variance train             0.024290973
KL Divergence                67.12066
KL Loss                      6.712066
QF Loss                      851.59375
VF Loss                      166.74927
Policy Loss                  -5016.4214
Q Predictions Mean           5023.281
Q Predictions Std            693.54956
Q Predictions Max            5777.667
Q Predictions Min            605.7503
V Predictions Mean           5016.7744
V Predictions Std            693.072
V Predictions Max            5772.3164
V Predictions Min            581.1842
Log Pis Mean                 6.200579
Log Pis Std                  3.7154522
Log Pis Max                  16.031073
Log Pis Min                  -4.989684
Policy mu Mean               -0.0816685
Policy mu Std                1.4338973
Policy mu Max                2.9945507
Policy mu Min                -3.2360282
Policy log std Mean          -0.9083054
Policy log std Std           0.48369977
Policy log std Max           -0.1498096
Policy log std Min           -3.388393
Z mean eval                  4.187067
Z variance eval              0.026456272
total_rewards                [12144.7573232  12389.54489451 12478.24383877 12480.16539859
 12323.55023368 12372.24607081 12526.27316679 12483.63865745
 12512.37370087 12483.53503043]
total_rewards_mean           12419.432831509914
total_rewards_std            110.99167009530383
total_rewards_max            12526.273166792278
total_rewards_min            12144.757323200687
Number of train steps total  1768000
Number of env steps total    2212000
Number of rollouts total     0
Train Time (s)               140.3283087327145
(Previous) Eval Time (s)     28.32342322729528
Sample Time (s)              22.658499052748084
Epoch Time (s)               191.31023101275787
Total Train Time (s)         81400.53540072404
Epoch                        441
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:24:25.426523 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #441 | Epoch Duration: 191.7200493812561
2020-01-14 03:24:25.426866 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #441 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1903524
Z variance train             0.026352707
KL Divergence                66.73557
KL Loss                      6.6735573
QF Loss                      798.57935
VF Loss                      608.01764
Policy Loss                  -4957.7505
Q Predictions Mean           4957.6777
Q Predictions Std            657.22687
Q Predictions Max            5739.4785
Q Predictions Min            3340.3955
V Predictions Mean           4938.6426
V Predictions Std            655.8131
V Predictions Max            5728.1807
V Predictions Min            3330.3616
Log Pis Mean                 6.5184736
Log Pis Std                  4.339007
Log Pis Max                  22.08501
Log Pis Min                  -2.2675896
Policy mu Mean               -0.04124073
Policy mu Std                1.5112103
Policy mu Max                4.736179
Policy mu Min                -4.4331403
Policy log std Mean          -0.92401713
Policy log std Std           0.55520713
Policy log std Max           -0.23635244
Policy log std Min           -3.46615
Z mean eval                  4.2637415
Z variance eval              0.025099132
total_rewards                [12328.11410186 12818.77231935 12945.46781924 12683.76485439
 12941.89795624 12734.98593634 12578.67970113 12773.0238522
 12831.75554208 12935.247028  ]
total_rewards_mean           12757.170911084397
total_rewards_std            182.40869126887733
total_rewards_max            12945.467819242014
total_rewards_min            12328.11410186273
Number of train steps total  1772000
Number of env steps total    2217000
Number of rollouts total     0
Train Time (s)               139.87131848139688
(Previous) Eval Time (s)     28.732813057024032
Sample Time (s)              22.54412402259186
Epoch Time (s)               191.14825556101277
Total Train Time (s)         81590.106890528
Epoch                        442
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:27:34.999802 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #442 | Epoch Duration: 189.5727789402008
2020-01-14 03:27:34.999926 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #442 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.261071
Z variance train             0.025237504
KL Divergence                69.7026
KL Loss                      6.97026
QF Loss                      1006.1958
VF Loss                      510.24936
Policy Loss                  -5115.5835
Q Predictions Mean           5128.497
Q Predictions Std            612.67285
Q Predictions Max            5787.0747
Q Predictions Min            3385.6912
V Predictions Mean           5133.2627
V Predictions Std            611.9914
V Predictions Max            5802.2046
V Predictions Min            3389.1602
Log Pis Mean                 6.897292
Log Pis Std                  4.037311
Log Pis Max                  18.023726
Log Pis Min                  -4.5991874
Policy mu Mean               -0.07921773
Policy mu Std                1.5135592
Policy mu Max                3.6142855
Policy mu Min                -3.2848618
Policy log std Mean          -0.93169385
Policy log std Std           0.53715116
Policy log std Max           -0.22793904
Policy log std Min           -3.7213483
Z mean eval                  4.1687484
Z variance eval              0.031067451
total_rewards                [12134.61087823 12363.82240706 12454.70512085 12408.31930935
 12292.75034987 12446.53845441 12372.26278438 12341.13945021
 12282.02441461 12528.20651449]
total_rewards_mean           12362.437968344562
total_rewards_std            104.37930104558805
total_rewards_max            12528.206514487123
total_rewards_min            12134.61087823125
Number of train steps total  1776000
Number of env steps total    2222000
Number of rollouts total     0
Train Time (s)               134.8178421370685
(Previous) Eval Time (s)     27.156951252836734
Sample Time (s)              23.210807154420763
Epoch Time (s)               185.185600544326
Total Train Time (s)         81776.38592184521
Epoch                        443
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:30:41.284294 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #443 | Epoch Duration: 186.2842493057251
2020-01-14 03:30:41.284531 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #443 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1689253
Z variance train             0.030911246
KL Divergence                68.685844
KL Loss                      6.8685846
QF Loss                      1192.0859
VF Loss                      301.7985
Policy Loss                  -5031.03
Q Predictions Mean           5037.714
Q Predictions Std            645.58685
Q Predictions Max            5795.752
Q Predictions Min            3369.7354
V Predictions Mean           5031.2837
V Predictions Std            643.0209
V Predictions Max            5777.7144
V Predictions Min            3358.2837
Log Pis Mean                 6.002419
Log Pis Std                  4.2512727
Log Pis Max                  20.57242
Log Pis Min                  -7.716007
Policy mu Mean               -0.039154347
Policy mu Std                1.4702035
Policy mu Max                3.0699115
Policy mu Min                -4.265354
Policy log std Mean          -0.8966241
Policy log std Std           0.49642292
Policy log std Max           -0.1955612
Policy log std Min           -3.475988
Z mean eval                  4.19246
Z variance eval              0.026876053
total_rewards                [12336.92427795 12716.83541845 12699.51842709 12531.64804999
 12702.2376752  12617.06096836 12858.31385667 12429.64368607
 12405.72536904 12396.73936734]
total_rewards_mean           12569.464709618336
total_rewards_std            165.42662285427144
total_rewards_max            12858.313856674944
total_rewards_min            12336.924277953392
Number of train steps total  1780000
Number of env steps total    2227000
Number of rollouts total     0
Train Time (s)               133.3130067610182
(Previous) Eval Time (s)     28.255211987998337
Sample Time (s)              21.17647546576336
Epoch Time (s)               182.74469421477988
Total Train Time (s)         81958.67255564826
Epoch                        444
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:33:43.574986 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #444 | Epoch Duration: 182.29030466079712
2020-01-14 03:33:43.575174 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #444 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1903844
Z variance train             0.026859421
KL Divergence                70.09619
KL Loss                      7.009619
QF Loss                      1007.4134
VF Loss                      710.11755
Policy Loss                  -5035.4966
Q Predictions Mean           5042.1543
Q Predictions Std            645.4109
Q Predictions Max            5714.826
Q Predictions Min            679.07715
V Predictions Mean           5058.6963
V Predictions Std            649.08954
V Predictions Max            5738.314
V Predictions Min            634.43286
Log Pis Mean                 6.3862896
Log Pis Std                  3.929512
Log Pis Max                  15.526177
Log Pis Min                  -2.3847017
Policy mu Mean               -0.0427112
Policy mu Std                1.480618
Policy mu Max                3.3353589
Policy mu Min                -3.4030092
Policy log std Mean          -0.90721625
Policy log std Std           0.5278268
Policy log std Max           -0.20991886
Policy log std Min           -3.626048
Z mean eval                  4.1677
Z variance eval              0.024032418
total_rewards                [11829.56791144 12680.23785676  2200.64591561 12480.0624464
 12818.57039817 12433.57443062 12316.04113153 12541.57416511
  8976.81721854 12299.24126248]
total_rewards_mean           11057.63327366542
total_rewards_std            3136.071250997357
total_rewards_max            12818.570398167947
total_rewards_min            2200.6459156087462
Number of train steps total  1784000
Number of env steps total    2232000
Number of rollouts total     0
Train Time (s)               135.4191308710724
(Previous) Eval Time (s)     27.800528461113572
Sample Time (s)              21.700371820945293
Epoch Time (s)               184.92003115313128
Total Train Time (s)         82144.39875586284
Epoch                        445
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:36:49.305752 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #445 | Epoch Duration: 185.73042249679565
2020-01-14 03:36:49.305929 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #445 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1674337
Z variance train             0.02408445
KL Divergence                69.50192
KL Loss                      6.9501925
QF Loss                      763.2215
VF Loss                      377.53827
Policy Loss                  -4993.542
Q Predictions Mean           4996.6074
Q Predictions Std            629.09784
Q Predictions Max            5718.8936
Q Predictions Min            2720.085
V Predictions Mean           4982.0205
V Predictions Std            626.3982
V Predictions Max            5705.528
V Predictions Min            2767.095
Log Pis Mean                 6.2487044
Log Pis Std                  3.7393043
Log Pis Max                  15.558628
Log Pis Min                  -2.9290242
Policy mu Mean               -0.084596254
Policy mu Std                1.4409469
Policy mu Max                2.7780256
Policy mu Min                -3.0767503
Policy log std Mean          -0.9102691
Policy log std Std           0.5020717
Policy log std Max           -0.14144188
Policy log std Min           -3.4200015
Z mean eval                  4.20285
Z variance eval              0.022362884
total_rewards                [12387.223388   12275.17473053 12504.65652129 12377.53203571
 12150.2066458  12231.23881375 12408.9326492  12083.05860558
 11799.39307367 12264.7289109 ]
total_rewards_mean           12248.214537443933
total_rewards_std            191.63761769260486
total_rewards_max            12504.656521293866
total_rewards_min            11799.393073674964
Number of train steps total  1788000
Number of env steps total    2237000
Number of rollouts total     0
Train Time (s)               142.13957002805546
(Previous) Eval Time (s)     28.61057331971824
Sample Time (s)              22.914370376616716
Epoch Time (s)               193.66451372439042
Total Train Time (s)         82337.52404590882
Epoch                        446
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:40:02.435707 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #446 | Epoch Duration: 193.12964272499084
2020-01-14 03:40:02.435898 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #446 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.201135
Z variance train             0.02229676
KL Divergence                69.47499
KL Loss                      6.9474993
QF Loss                      798.1681
VF Loss                      394.32965
Policy Loss                  -5134.27
Q Predictions Mean           5147.536
Q Predictions Std            543.5766
Q Predictions Max            5743.481
Q Predictions Min            3445.197
V Predictions Mean           5144.656
V Predictions Std            544.821
V Predictions Max            5746.632
V Predictions Min            3421.4404
Log Pis Mean                 6.3481016
Log Pis Std                  3.897364
Log Pis Max                  17.69946
Log Pis Min                  -3.437981
Policy mu Mean               -0.049884077
Policy mu Std                1.4688342
Policy mu Max                2.9174404
Policy mu Min                -2.8673494
Policy log std Mean          -0.91791034
Policy log std Std           0.5129202
Policy log std Max           -0.18308449
Policy log std Min           -3.4809165
Z mean eval                  4.119868
Z variance eval              0.015627393
total_rewards                [12183.14060673 12357.52713496 12852.57115608 12546.50944667
 12608.59836748 12648.46907436 12672.82982119 12257.43758795
 12499.6907937  12265.88490054]
total_rewards_mean           12489.265888967002
total_rewards_std            205.7593369457477
total_rewards_max            12852.571156083584
total_rewards_min            12183.140606731282
Number of train steps total  1792000
Number of env steps total    2242000
Number of rollouts total     0
Train Time (s)               141.42533435299993
(Previous) Eval Time (s)     28.075355145148933
Sample Time (s)              22.952858662698418
Epoch Time (s)               192.45354816084728
Total Train Time (s)         82529.43373260088
Epoch                        447
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:43:14.347789 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #447 | Epoch Duration: 191.91177010536194
2020-01-14 03:43:14.347908 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #447 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.118713
Z variance train             0.01564223
KL Divergence                67.496735
KL Loss                      6.7496734
QF Loss                      967.8668
VF Loss                      335.3511
Policy Loss                  -4996.067
Q Predictions Mean           5008.08
Q Predictions Std            699.03
Q Predictions Max            5762.215
Q Predictions Min            261.36258
V Predictions Mean           5004.902
V Predictions Std            696.5805
V Predictions Max            5772.561
V Predictions Min            273.79587
Log Pis Mean                 6.3636193
Log Pis Std                  4.314694
Log Pis Max                  16.623522
Log Pis Min                  -6.9370303
Policy mu Mean               -0.09447455
Policy mu Std                1.4570287
Policy mu Max                3.1398942
Policy mu Min                -2.9720902
Policy log std Mean          -0.917093
Policy log std Std           0.53834844
Policy log std Max           -0.13299322
Policy log std Min           -3.6816216
Z mean eval                  4.192623
Z variance eval              0.043996654
total_rewards                [12403.88318581 12386.93610228 12839.98261441 12415.60301412
 12514.61853764 12538.83737787 12499.31884363 12311.61084422
 12753.58348845 12372.22859979]
total_rewards_mean           12503.660260821316
total_rewards_std            162.00062933688
total_rewards_max            12839.982614414297
total_rewards_min            12311.61084421694
Number of train steps total  1796000
Number of env steps total    2247000
Number of rollouts total     0
Train Time (s)               141.80870753806084
(Previous) Eval Time (s)     27.533170931972563
Sample Time (s)              21.974886517971754
Epoch Time (s)               191.31676498800516
Total Train Time (s)         82722.69594478887
Epoch                        448
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:46:27.615136 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #448 | Epoch Duration: 193.2671229839325
2020-01-14 03:46:27.615419 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #448 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1945477
Z variance train             0.044432588
KL Divergence                67.69701
KL Loss                      6.7697005
QF Loss                      663.4103
VF Loss                      4845.9385
Policy Loss                  -5002.644
Q Predictions Mean           5010.123
Q Predictions Std            645.04095
Q Predictions Max            5697.1
Q Predictions Min            3316.3855
V Predictions Mean           4990.957
V Predictions Std            642.35986
V Predictions Max            5672.803
V Predictions Min            3302.123
Log Pis Mean                 6.078912
Log Pis Std                  4.240477
Log Pis Max                  15.72334
Log Pis Min                  -9.245165
Policy mu Mean               -0.056845903
Policy mu Std                1.4177365
Policy mu Max                3.2349637
Policy mu Min                -2.71055
Policy log std Mean          -0.9166748
Policy log std Std           0.50516003
Policy log std Max           0.085146666
Policy log std Min           -3.6391683
Z mean eval                  4.196986
Z variance eval              0.02115862
total_rewards                [11780.83852527 11680.627214   12234.21743307 12158.64379762
 12076.74384019 11839.17744586 11865.92179296 11827.24339675
 11988.3251052  11869.05817752]
total_rewards_mean           11932.079672844917
total_rewards_std            167.56552898837919
total_rewards_max            12234.217433073143
total_rewards_min            11680.62721399957
Number of train steps total  1800000
Number of env steps total    2252000
Number of rollouts total     0
Train Time (s)               140.7175909038633
(Previous) Eval Time (s)     29.48309895116836
Sample Time (s)              22.816841382533312
Epoch Time (s)               193.01753123756498
Total Train Time (s)         82913.78764106659
Epoch                        449
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:49:38.711284 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #449 | Epoch Duration: 191.09571075439453
2020-01-14 03:49:38.711473 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #449 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1964965
Z variance train             0.021179935
KL Divergence                69.064865
KL Loss                      6.9064865
QF Loss                      975.2059
VF Loss                      167.00754
Policy Loss                  -5128.4077
Q Predictions Mean           5134.406
Q Predictions Std            578.8962
Q Predictions Max            5805.692
Q Predictions Min            3378.8118
V Predictions Mean           5134.385
V Predictions Std            578.91486
V Predictions Max            5795.5015
V Predictions Min            3403.6821
Log Pis Mean                 6.6275043
Log Pis Std                  4.164136
Log Pis Max                  17.31194
Log Pis Min                  -3.869515
Policy mu Mean               -0.10072646
Policy mu Std                1.4699254
Policy mu Max                3.540597
Policy mu Min                -2.9427068
Policy log std Mean          -0.91740227
Policy log std Std           0.51945156
Policy log std Max           -0.071873724
Policy log std Min           -3.4687617
Z mean eval                  4.204661
Z variance eval              0.01484599
total_rewards                [12094.22545791 12345.28557453 12209.2833666  12605.31552451
 12340.46027888 12516.51672644 12425.5407914  12377.22759699
 12147.02537726 12380.7660544 ]
total_rewards_mean           12344.164674891781
total_rewards_std            150.49961701478387
total_rewards_max            12605.315524508984
total_rewards_min            12094.225457909959
Number of train steps total  1804000
Number of env steps total    2257000
Number of rollouts total     0
Train Time (s)               132.88203263375908
(Previous) Eval Time (s)     27.560803304892033
Sample Time (s)              20.937873880378902
Epoch Time (s)               181.38070981903002
Total Train Time (s)         83094.93582860986
Epoch                        450
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:52:39.861805 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #450 | Epoch Duration: 181.15020775794983
2020-01-14 03:52:39.861926 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #450 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.204732
Z variance train             0.0148480665
KL Divergence                70.51034
KL Loss                      7.051034
QF Loss                      423.60074
VF Loss                      104.53907
Policy Loss                  -5094.703
Q Predictions Mean           5101.341
Q Predictions Std            614.70917
Q Predictions Max            5739.6094
Q Predictions Min            3045.6914
V Predictions Mean           5097.7227
V Predictions Std            613.4915
V Predictions Max            5739.0986
V Predictions Min            3064.6018
Log Pis Mean                 5.871642
Log Pis Std                  3.8441114
Log Pis Max                  15.48655
Log Pis Min                  -5.6488614
Policy mu Mean               -0.06528778
Policy mu Std                1.400471
Policy mu Max                2.8016527
Policy mu Min                -2.9482136
Policy log std Mean          -0.92301553
Policy log std Std           0.5106825
Policy log std Max           -0.15739816
Policy log std Min           -3.6069646
Z mean eval                  4.214197
Z variance eval              0.010946734
total_rewards                [12099.0300854  12107.28868502 12478.13428058 12341.4070459
 12027.78459182 12324.32046214 12024.579216   12232.63256583
 12309.30149589 12363.75843798]
total_rewards_mean           12230.823686655738
total_rewards_std            149.11695027653457
total_rewards_max            12478.134280577477
total_rewards_min            12024.579216002929
Number of train steps total  1808000
Number of env steps total    2262000
Number of rollouts total     0
Train Time (s)               132.9243224193342
(Previous) Eval Time (s)     27.329993267077953
Sample Time (s)              21.335749051067978
Epoch Time (s)               181.59006473748013
Total Train Time (s)         83277.28005885845
Epoch                        451
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:55:42.210963 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #451 | Epoch Duration: 182.3489375114441
2020-01-14 03:55:42.211145 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #451 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.214342
Z variance train             0.010909003
KL Divergence                72.23149
KL Loss                      7.2231493
QF Loss                      2619.022
VF Loss                      241.22221
Policy Loss                  -5125.2725
Q Predictions Mean           5137.196
Q Predictions Std            579.27234
Q Predictions Max            5794.038
Q Predictions Min            2657.4092
V Predictions Mean           5128.118
V Predictions Std            568.36566
V Predictions Max            5794.838
V Predictions Min            3399.2136
Log Pis Mean                 6.5100727
Log Pis Std                  4.003089
Log Pis Max                  23.690256
Log Pis Min                  -4.4333167
Policy mu Mean               -0.0048149154
Policy mu Std                1.4860188
Policy mu Max                4.668661
Policy mu Min                -3.1689818
Policy log std Mean          -0.9314689
Policy log std Std           0.52905136
Policy log std Max           -0.254537
Policy log std Min           -3.7492971
Z mean eval                  4.1662498
Z variance eval              0.013287021
total_rewards                [11994.97164461 11947.24569025 12268.70541963 12265.46225156
 12400.39720026 12534.48090007 12365.2022143  12017.57239621
 12579.2793344  12415.48966364]
total_rewards_mean           12278.880671493245
total_rewards_std            213.4484074857727
total_rewards_max            12579.279334401712
total_rewards_min            11947.245690250847
Number of train steps total  1812000
Number of env steps total    2267000
Number of rollouts total     0
Train Time (s)               138.33411681605503
(Previous) Eval Time (s)     28.088527508080006
Sample Time (s)              21.84498554468155
Epoch Time (s)               188.26762986881658
Total Train Time (s)         83466.39731670544
Epoch                        452
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:58:51.333032 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #452 | Epoch Duration: 189.12173128128052
2020-01-14 03:58:51.333237 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #452 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.167472
Z variance train             0.013242489
KL Divergence                70.15013
KL Loss                      7.015013
QF Loss                      1354.6765
VF Loss                      414.97433
Policy Loss                  -5053.626
Q Predictions Mean           5068.073
Q Predictions Std            591.96857
Q Predictions Max            5736.023
Q Predictions Min            3370.2083
V Predictions Mean           5059.8857
V Predictions Std            591.9725
V Predictions Max            5725.6606
V Predictions Min            3356.359
Log Pis Mean                 5.764333
Log Pis Std                  3.773659
Log Pis Max                  20.236517
Log Pis Min                  -4.559885
Policy mu Mean               -0.010994521
Policy mu Std                1.4099386
Policy mu Max                3.0370913
Policy mu Min                -4.0330796
Policy log std Mean          -0.9204631
Policy log std Std           0.4973648
Policy log std Max           -0.20280567
Policy log std Min           -3.4976578
Z mean eval                  4.19604
Z variance eval              0.013333052
total_rewards                [12462.54983041 12775.32316057 12862.87165922 12404.47993763
 12061.98384235 12121.90356958 12739.48673755 12760.08538188
 12517.0782029  12524.70275092]
total_rewards_mean           12523.046507301242
total_rewards_std            259.5012766150795
total_rewards_max            12862.871659218963
total_rewards_min            12061.983842349606
Number of train steps total  1816000
Number of env steps total    2272000
Number of rollouts total     0
Train Time (s)               141.69765106774867
(Previous) Eval Time (s)     28.942310996819288
Sample Time (s)              23.059563991613686
Epoch Time (s)               193.69952605618164
Total Train Time (s)         83659.96796674654
Epoch                        453
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:02:04.908281 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #453 | Epoch Duration: 193.5748839378357
2020-01-14 04:02:04.908509 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #453 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.195959
Z variance train             0.013327589
KL Divergence                69.88078
KL Loss                      6.9880786
QF Loss                      570.45624
VF Loss                      392.81226
Policy Loss                  -5096.1777
Q Predictions Mean           5101.657
Q Predictions Std            674.5569
Q Predictions Max            5853.8364
Q Predictions Min            699.8462
V Predictions Mean           5080.4673
V Predictions Std            672.11707
V Predictions Max            5823.8057
V Predictions Min            701.8046
Log Pis Mean                 6.4300933
Log Pis Std                  4.3002553
Log Pis Max                  16.865116
Log Pis Min                  -4.014175
Policy mu Mean               -0.09716489
Policy mu Std                1.4996779
Policy mu Max                3.0914562
Policy mu Min                -4.4848742
Policy log std Mean          -0.90072984
Policy log std Std           0.52364767
Policy log std Max           0.15776497
Policy log std Min           -3.5126746
Z mean eval                  4.2120886
Z variance eval              0.033828937
total_rewards                [12289.22134407 12365.79260408 12670.87437258 12471.12976967
 12804.8282729  12748.44303456 12707.86600248 12710.16797696
 12634.95267577 12794.30123824]
total_rewards_mean           12619.757729131812
total_rewards_std            172.01749500730114
total_rewards_max            12804.828272897117
total_rewards_min            12289.221344070942
Number of train steps total  1820000
Number of env steps total    2277000
Number of rollouts total     0
Train Time (s)               140.6300948788412
(Previous) Eval Time (s)     28.817360586952418
Sample Time (s)              22.950316103640944
Epoch Time (s)               192.39777156943455
Total Train Time (s)         83850.51161826868
Epoch                        454
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:05:15.456503 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #454 | Epoch Duration: 190.5478482246399
2020-01-14 04:05:15.456695 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #454 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2192245
Z variance train             0.033147935
KL Divergence                68.15545
KL Loss                      6.815545
QF Loss                      1405.8945
VF Loss                      2428.1365
Policy Loss                  -5087.732
Q Predictions Mean           5102.3105
Q Predictions Std            623.75006
Q Predictions Max            5847.098
Q Predictions Min            3419.3665
V Predictions Mean           5112.2974
V Predictions Std            629.9701
V Predictions Max            5919.4785
V Predictions Min            3418.645
Log Pis Mean                 6.2740526
Log Pis Std                  4.1738257
Log Pis Max                  20.812355
Log Pis Min                  -3.986655
Policy mu Mean               -0.07900577
Policy mu Std                1.4746311
Policy mu Max                3.0361695
Policy mu Min                -3.0212505
Policy log std Mean          -0.9223995
Policy log std Std           0.55183554
Policy log std Max           -0.23880634
Policy log std Min           -3.5412965
Z mean eval                  4.1854515
Z variance eval              0.00915721
total_rewards                [12421.02549385 12606.31202658 12676.22203332 12511.02845046
 12348.68926893 12622.62008303 12630.96282682 12699.74205408
 12515.98066113 12569.82101459]
total_rewards_mean           12560.240391277815
total_rewards_std            106.08257718892307
total_rewards_max            12699.74205407542
total_rewards_min            12348.689268932216
Number of train steps total  1824000
Number of env steps total    2282000
Number of rollouts total     0
Train Time (s)               141.63647018186748
(Previous) Eval Time (s)     26.966930385679007
Sample Time (s)              23.040836859494448
Epoch Time (s)               191.64423742704093
Total Train Time (s)         84042.8126540198
Epoch                        455
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:08:27.761837 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #455 | Epoch Duration: 192.30500316619873
2020-01-14 04:08:27.762026 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #455 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.183161
Z variance train             0.009151263
KL Divergence                69.77452
KL Loss                      6.9774523
QF Loss                      921.3427
VF Loss                      500.4504
Policy Loss                  -5051.4624
Q Predictions Mean           5060.99
Q Predictions Std            704.4176
Q Predictions Max            5751.2944
Q Predictions Min            53.358234
V Predictions Mean           5069.0845
V Predictions Std            706.6426
V Predictions Max            5765.0977
V Predictions Min            71.594055
Log Pis Mean                 6.637244
Log Pis Std                  3.977634
Log Pis Max                  15.656559
Log Pis Min                  -6.5772777
Policy mu Mean               -0.031013599
Policy mu Std                1.5017107
Policy mu Max                3.074389
Policy mu Min                -2.5879972
Policy log std Mean          -0.9169419
Policy log std Std           0.5282644
Policy log std Max           0.8052838
Policy log std Min           -3.4771028
Z mean eval                  4.1931562
Z variance eval              0.012752274
total_rewards                [12108.51512585 12856.81366437 12640.32785044 12644.55910419
 12447.64119428 12163.51632269 12518.55312331 12617.94721576
 12258.41173166 12369.71726062]
total_rewards_mean           12462.600259315896
total_rewards_std            226.43656711131803
total_rewards_max            12856.813664367713
total_rewards_min            12108.515125849946
Number of train steps total  1828000
Number of env steps total    2287000
Number of rollouts total     0
Train Time (s)               140.14406304759905
(Previous) Eval Time (s)     27.627353788353503
Sample Time (s)              21.96169902291149
Epoch Time (s)               189.73311585886404
Total Train Time (s)         84233.15781512018
Epoch                        456
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:11:38.112117 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #456 | Epoch Duration: 190.3499550819397
2020-01-14 04:11:38.112316 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #456 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1930213
Z variance train             0.012739631
KL Divergence                71.363914
KL Loss                      7.1363916
QF Loss                      429.386
VF Loss                      134.27014
Policy Loss                  -5052.068
Q Predictions Mean           5061.2666
Q Predictions Std            715.8139
Q Predictions Max            5826.831
Q Predictions Min            202.68248
V Predictions Mean           5055.1416
V Predictions Std            717.69604
V Predictions Max            5804.4673
V Predictions Min            172.11731
Log Pis Mean                 5.930625
Log Pis Std                  3.7703526
Log Pis Max                  16.219439
Log Pis Min                  -5.932685
Policy mu Mean               -0.0349816
Policy mu Std                1.455321
Policy mu Max                3.0650392
Policy mu Min                -2.678182
Policy log std Mean          -0.90216994
Policy log std Std           0.49530515
Policy log std Max           0.048337102
Policy log std Min           -3.4743614
Z mean eval                  4.2389746
Z variance eval              0.011695417
total_rewards                [12489.60054358 12483.01867427 12424.04949366 12712.25850018
 12412.47344038 12570.7249212  12517.19802159 12404.38211765
 12648.35836666 12367.09650987]
total_rewards_mean           12502.916058905235
total_rewards_std            106.25847616618097
total_rewards_max            12712.25850018494
total_rewards_min            12367.096509874258
Number of train steps total  1832000
Number of env steps total    2292000
Number of rollouts total     0
Train Time (s)               133.02209259802476
(Previous) Eval Time (s)     28.2438718508929
Sample Time (s)              20.742359961848706
Epoch Time (s)               182.00832441076636
Total Train Time (s)         84413.68136373395
Epoch                        457
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:14:38.640121 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #457 | Epoch Duration: 180.5276620388031
2020-01-14 04:14:38.640309 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #457 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2360454
Z variance train             0.011692638
KL Divergence                70.88524
KL Loss                      7.088524
QF Loss                      1075.2141
VF Loss                      392.45932
Policy Loss                  -5149.0415
Q Predictions Mean           5158.801
Q Predictions Std            624.3944
Q Predictions Max            5930.6523
Q Predictions Min            3414.1726
V Predictions Mean           5159.795
V Predictions Std            623.41956
V Predictions Max            5924.1675
V Predictions Min            3427.27
Log Pis Mean                 6.4119873
Log Pis Std                  3.8368132
Log Pis Max                  17.805809
Log Pis Min                  -5.163498
Policy mu Mean               -0.10798582
Policy mu Std                1.4953457
Policy mu Max                3.1490326
Policy mu Min                -3.319335
Policy log std Mean          -0.9413611
Policy log std Std           0.57236946
Policy log std Max           -0.07495546
Policy log std Min           -3.8293118
Z mean eval                  4.241808
Z variance eval              0.024038095
total_rewards                [12164.28354822 12218.49194688 12581.6057136  12678.10132948
 12317.98186146 12713.8411431  12261.54276473 12535.46683416
 12665.60980695 12201.52481348]
total_rewards_mean           12433.844976206834
total_rewards_std            209.7759414330055
total_rewards_max            12713.841143101094
total_rewards_min            12164.283548220035
Number of train steps total  1836000
Number of env steps total    2297000
Number of rollouts total     0
Train Time (s)               133.3957247803919
(Previous) Eval Time (s)     26.762869614176452
Sample Time (s)              21.96073190262541
Epoch Time (s)               182.11932629719377
Total Train Time (s)         84597.31695706118
Epoch                        458
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:17:42.280085 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #458 | Epoch Duration: 183.639643907547
2020-01-14 04:17:42.280258 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #458 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2440033
Z variance train             0.023995046
KL Divergence                68.867714
KL Loss                      6.8867717
QF Loss                      1769.9683
VF Loss                      720.14764
Policy Loss                  -5071.637
Q Predictions Mean           5085.506
Q Predictions Std            703.24854
Q Predictions Max            5806.521
Q Predictions Min            1161.3986
V Predictions Mean           5072.1543
V Predictions Std            709.21545
V Predictions Max            5782.4937
V Predictions Min            978.2142
Log Pis Mean                 6.5792875
Log Pis Std                  3.9701993
Log Pis Max                  16.301992
Log Pis Min                  -4.452051
Policy mu Mean               -0.058286116
Policy mu Std                1.5046445
Policy mu Max                3.3333175
Policy mu Min                -3.0612857
Policy log std Mean          -0.9243309
Policy log std Std           0.543962
Policy log std Max           -0.284132
Policy log std Min           -3.4910946
Z mean eval                  4.111974
Z variance eval              0.009766734
total_rewards                [12308.81587222 12272.61538369 12395.10443062 12242.05923814
 12166.31598643 12182.64533016 12170.75840363 12043.19024535
 12445.42028939 12318.11870248]
total_rewards_mean           12254.50438821083
total_rewards_std            113.27163668817545
total_rewards_max            12445.420289387925
total_rewards_min            12043.190245350852
Number of train steps total  1840000
Number of env steps total    2302000
Number of rollouts total     0
Train Time (s)               140.8139254739508
(Previous) Eval Time (s)     28.282870583236217
Sample Time (s)              22.787364362273365
Epoch Time (s)               191.8841604194604
Total Train Time (s)         84790.02536545042
Epoch                        459
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:20:54.994455 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #459 | Epoch Duration: 192.71402764320374
2020-01-14 04:20:54.994820 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #459 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1113997
Z variance train             0.009753792
KL Divergence                67.252914
KL Loss                      6.7252917
QF Loss                      524.8637
VF Loss                      243.9251
Policy Loss                  -5036.493
Q Predictions Mean           5044.0586
Q Predictions Std            611.28827
Q Predictions Max            5746.25
Q Predictions Min            3335.4873
V Predictions Mean           5031.8813
V Predictions Std            610.59973
V Predictions Max            5738.289
V Predictions Min            3318.8027
Log Pis Mean                 6.3542395
Log Pis Std                  3.668072
Log Pis Max                  16.307745
Log Pis Min                  -6.757428
Policy mu Mean               -0.0633812
Policy mu Std                1.4532917
Policy mu Max                3.0611377
Policy mu Min                -2.6032138
Policy log std Mean          -0.91982
Policy log std Std           0.5391755
Policy log std Max           -0.25959775
Policy log std Min           -3.6433809
Z mean eval                  4.179806
Z variance eval              0.012799537
total_rewards                [12408.43278294 12540.11965651 12527.97788165 12200.08344159
 12411.86583242 12215.93543916 12621.09470365  8377.46160546
 12497.96737391 12538.43096405]
total_rewards_mean           12033.936968132866
total_rewards_std            1225.9081314575883
total_rewards_max            12621.094703647539
total_rewards_min            8377.461605456965
Number of train steps total  1844000
Number of env steps total    2307000
Number of rollouts total     0
Train Time (s)               140.2049626642838
(Previous) Eval Time (s)     29.112304477021098
Sample Time (s)              23.33554021222517
Epoch Time (s)               192.65280735353008
Total Train Time (s)         84982.32651411137
Epoch                        460
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:24:07.297881 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #460 | Epoch Duration: 192.3028450012207
2020-01-14 04:24:07.297999 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #460 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.182917
Z variance train             0.012801871
KL Divergence                69.38774
KL Loss                      6.938774
QF Loss                      566.42035
VF Loss                      439.1063
Policy Loss                  -5122.553
Q Predictions Mean           5124.985
Q Predictions Std            621.54254
Q Predictions Max            5783.2705
Q Predictions Min            3318.387
V Predictions Mean           5108.583
V Predictions Std            619.9946
V Predictions Max            5757.746
V Predictions Min            3314.5742
Log Pis Mean                 6.0396633
Log Pis Std                  4.068039
Log Pis Max                  17.23811
Log Pis Min                  -4.4070582
Policy mu Mean               -0.11221244
Policy mu Std                1.4567491
Policy mu Max                3.2674325
Policy mu Min                -3.0445507
Policy log std Mean          -0.9129016
Policy log std Std           0.5193992
Policy log std Max           0.3143047
Policy log std Min           -3.5948305
Z mean eval                  4.194831
Z variance eval              0.0064407266
total_rewards                [12254.00453533 12599.96743782 12640.29961106 12527.06056196
 12686.02966156 12768.63723022 12812.99258978 12812.55810567
 12623.22346011 12627.94693439]
total_rewards_mean           12635.272012789348
total_rewards_std            155.53864598734077
total_rewards_max            12812.99258978351
total_rewards_min            12254.004535329574
Number of train steps total  1848000
Number of env steps total    2312000
Number of rollouts total     0
Train Time (s)               139.58482801215723
(Previous) Eval Time (s)     28.76193183287978
Sample Time (s)              23.193680515512824
Epoch Time (s)               191.54044036054984
Total Train Time (s)         85172.46764293732
Epoch                        461
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:27:17.445695 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #461 | Epoch Duration: 190.14756178855896
2020-01-14 04:27:17.445945 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #461 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.197607
Z variance train             0.0064302413
KL Divergence                70.11998
KL Loss                      7.011998
QF Loss                      930.7842
VF Loss                      275.18347
Policy Loss                  -5099.2427
Q Predictions Mean           5104.3516
Q Predictions Std            663.2069
Q Predictions Max            5777.7437
Q Predictions Min            93.19299
V Predictions Mean           5089.9287
V Predictions Std            663.99786
V Predictions Max            5772.656
V Predictions Min            70.58377
Log Pis Mean                 6.2539225
Log Pis Std                  4.145859
Log Pis Max                  17.904163
Log Pis Min                  -4.114604
Policy mu Mean               0.0008337113
Policy mu Std                1.4802167
Policy mu Max                3.1022038
Policy mu Min                -2.9223359
Policy log std Mean          -0.93785757
Policy log std Std           0.55120045
Policy log std Max           -0.0064053535
Policy log std Min           -3.6105185
Z mean eval                  4.193699
Z variance eval              0.0146237705
total_rewards                [12190.86831293 12465.5273638  12511.03446664 12733.40712673
 12326.54594615 12691.69481225 12567.77524767 12422.1845986
 12125.72919198 12489.02314992]
total_rewards_mean           12452.37902166633
total_rewards_std            186.1061237021626
total_rewards_max            12733.407126733378
total_rewards_min            12125.729191980627
Number of train steps total  1852000
Number of env steps total    2317000
Number of rollouts total     0
Train Time (s)               140.98717965884134
(Previous) Eval Time (s)     27.368586505763233
Sample Time (s)              23.20783944800496
Epoch Time (s)               191.56360561260954
Total Train Time (s)         85365.42832435295
Epoch                        462
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:30:30.410545 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #462 | Epoch Duration: 192.96444845199585
2020-01-14 04:30:30.410757 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #462 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.19489
Z variance train             0.014608602
KL Divergence                69.219406
KL Loss                      6.921941
QF Loss                      969.67126
VF Loss                      631.7239
Policy Loss                  -5098.497
Q Predictions Mean           5106.789
Q Predictions Std            693.9973
Q Predictions Max            5826.487
Q Predictions Min            781.5314
V Predictions Mean           5097.984
V Predictions Std            692.98004
V Predictions Max            5808.7197
V Predictions Min            685.27466
Log Pis Mean                 6.4166265
Log Pis Std                  3.8664231
Log Pis Max                  17.53825
Log Pis Min                  -5.0018616
Policy mu Mean               -0.02183278
Policy mu Std                1.4767934
Policy mu Max                2.9476752
Policy mu Min                -2.8817694
Policy log std Mean          -0.9199558
Policy log std Std           0.5236579
Policy log std Max           -0.18489492
Policy log std Min           -3.4973574
Z mean eval                  4.2442975
Z variance eval              0.017247885
total_rewards                [11394.81822847 10946.46628588 11604.85283899 11800.85878011
 10406.85820539 11432.00345616 11085.92181636 11611.70114728
 12450.40136767 11282.58384436]
total_rewards_mean           11401.646597068313
total_rewards_std            515.3922708419748
total_rewards_max            12450.401367672494
total_rewards_min            10406.858205392098
Number of train steps total  1856000
Number of env steps total    2322000
Number of rollouts total     0
Train Time (s)               136.3519987380132
(Previous) Eval Time (s)     28.76903748093173
Sample Time (s)              22.417992261238396
Epoch Time (s)               187.53902848018333
Total Train Time (s)         85550.61532644369
Epoch                        463
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:33:35.602172 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #463 | Epoch Duration: 185.19127321243286
2020-01-14 04:33:35.602360 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #463 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2460227
Z variance train             0.017286133
KL Divergence                69.19131
KL Loss                      6.919131
QF Loss                      2147.229
VF Loss                      353.56897
Policy Loss                  -5178.0835
Q Predictions Mean           5188.4204
Q Predictions Std            616.4491
Q Predictions Max            5809.9365
Q Predictions Min            3403.9321
V Predictions Mean           5177.8613
V Predictions Std            615.85126
V Predictions Max            5799.4907
V Predictions Min            3398.0266
Log Pis Mean                 6.389064
Log Pis Std                  4.49636
Log Pis Max                  25.761444
Log Pis Min                  -3.3152943
Policy mu Mean               -0.0026109144
Policy mu Std                1.5119648
Policy mu Max                7.6037025
Policy mu Min                -3.282748
Policy log std Mean          -0.8840399
Policy log std Std           0.4718986
Policy log std Max           0.1203959
Policy log std Min           -3.8498416
Z mean eval                  4.210926
Z variance eval              0.11284816
total_rewards                [12612.73419175 12648.90856359 12601.57679908 12625.07531649
 12765.19734623 12574.9981611  12718.46861062 12446.2927645
 12732.37478235 12642.995943  ]
total_rewards_mean           12636.86224786987
total_rewards_std            86.33940413120142
total_rewards_max            12765.197346228912
total_rewards_min            12446.292764495922
Number of train steps total  1860000
Number of env steps total    2327000
Number of rollouts total     0
Train Time (s)               133.83280653040856
(Previous) Eval Time (s)     26.42096149874851
Sample Time (s)              22.11605178238824
Epoch Time (s)               182.3698198115453
Total Train Time (s)         85734.9691090826
Epoch                        464
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:36:39.960882 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #464 | Epoch Duration: 184.35837841033936
2020-01-14 04:36:39.961081 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #464 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2121015
Z variance train             0.11256291
KL Divergence                65.9572
KL Loss                      6.59572
QF Loss                      864.4795
VF Loss                      263.34323
Policy Loss                  -5032.396
Q Predictions Mean           5035.4805
Q Predictions Std            625.61
Q Predictions Max            5714.626
Q Predictions Min            3037.1042
V Predictions Mean           5031.623
V Predictions Std            624.42145
V Predictions Max            5724.823
V Predictions Min            3075.343
Log Pis Mean                 6.2841067
Log Pis Std                  4.131207
Log Pis Max                  20.220732
Log Pis Min                  -3.136959
Policy mu Mean               -0.06325961
Policy mu Std                1.4439939
Policy mu Max                3.5900648
Policy mu Min                -4.4346995
Policy log std Mean          -0.9378635
Policy log std Std           0.5163836
Policy log std Max           -0.036577344
Policy log std Min           -3.5545893
Z mean eval                  4.2387753
Z variance eval              0.023832494
total_rewards                [12577.52828126 12982.699951   12639.09738783 12855.16200296
 12811.20149322 12762.37397538 12796.45864314 12920.7367333
 12550.2406481  12862.57735855]
total_rewards_mean           12775.80764747284
total_rewards_std            137.25140674007687
total_rewards_max            12982.699950995438
total_rewards_min            12550.240648098435
Number of train steps total  1864000
Number of env steps total    2332000
Number of rollouts total     0
Train Time (s)               134.78784166974947
(Previous) Eval Time (s)     28.409189892932773
Sample Time (s)              21.874423793517053
Epoch Time (s)               185.0714553561993
Total Train Time (s)         85919.91011092952
Epoch                        465
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:39:44.906927 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #465 | Epoch Duration: 184.94567346572876
2020-01-14 04:39:44.907262 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #465 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.237887
Z variance train             0.023823489
KL Divergence                67.358215
KL Loss                      6.7358217
QF Loss                      768.15466
VF Loss                      175.11537
Policy Loss                  -5148.011
Q Predictions Mean           5151.957
Q Predictions Std            639.4947
Q Predictions Max            5784.066
Q Predictions Min            3425.9854
V Predictions Mean           5152.411
V Predictions Std            638.3214
V Predictions Max            5784.9146
V Predictions Min            3429.2422
Log Pis Mean                 6.1887856
Log Pis Std                  4.1567445
Log Pis Max                  15.662943
Log Pis Min                  -5.359191
Policy mu Mean               -0.10574754
Policy mu Std                1.4570827
Policy mu Max                2.86329
Policy mu Min                -2.7767322
Policy log std Mean          -0.90316087
Policy log std Std           0.506991
Policy log std Max           -0.14491868
Policy log std Min           -3.5307524
Z mean eval                  4.245197
Z variance eval              0.05619452
total_rewards                [12394.9970169  12564.59760584 12770.1750716  12596.15147616
 12691.55198534 12512.32239131 12470.41315717 12768.2979105
 12340.84402061 12487.62764669]
total_rewards_mean           12559.697828212113
total_rewards_std            140.35195091462776
total_rewards_max            12770.175071600874
total_rewards_min            12340.844020609964
Number of train steps total  1868000
Number of env steps total    2337000
Number of rollouts total     0
Train Time (s)               142.82798557309434
(Previous) Eval Time (s)     28.28308646567166
Sample Time (s)              21.71750879380852
Epoch Time (s)               192.82858083257452
Total Train Time (s)         86113.5028115455
Epoch                        466
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:42:58.503288 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #466 | Epoch Duration: 193.59581661224365
2020-01-14 04:42:58.503468 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #466 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.247126
Z variance train             0.056056492
KL Divergence                65.11361
KL Loss                      6.511361
QF Loss                      413.74017
VF Loss                      188.72264
Policy Loss                  -5090.012
Q Predictions Mean           5096.4683
Q Predictions Std            711.27094
Q Predictions Max            5816.501
Q Predictions Min            844.5621
V Predictions Mean           5084.3496
V Predictions Std            710.5872
V Predictions Max            5797.9585
V Predictions Min            795.6435
Log Pis Mean                 6.637579
Log Pis Std                  4.0167804
Log Pis Max                  17.383032
Log Pis Min                  -4.7262692
Policy mu Mean               -0.045185197
Policy mu Std                1.4747953
Policy mu Max                2.9911392
Policy mu Min                -3.1087813
Policy log std Mean          -0.9371514
Policy log std Std           0.54230016
Policy log std Max           -0.16503298
Policy log std Min           -3.4852939
Z mean eval                  4.232686
Z variance eval              0.03990092
total_rewards                [12268.9409563  12823.89205983 12731.03373905 12626.71525894
 12769.00440138 12585.12491221 12614.20054397 12760.01485355
 12479.23835844  8672.98227433]
total_rewards_mean           12233.114735799074
total_rewards_std            1196.7541550527637
total_rewards_max            12823.892059827765
total_rewards_min            8672.982274328633
Number of train steps total  1872000
Number of env steps total    2342000
Number of rollouts total     0
Train Time (s)               141.43851323518902
(Previous) Eval Time (s)     29.04998243926093
Sample Time (s)              20.549656253308058
Epoch Time (s)               191.038151927758
Total Train Time (s)         86304.18039651308
Epoch                        467
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:46:09.186484 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #467 | Epoch Duration: 190.68287467956543
2020-01-14 04:46:09.186675 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #467 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.230941
Z variance train             0.03943117
KL Divergence                65.164505
KL Loss                      6.5164504
QF Loss                      1658.2045
VF Loss                      638.1654
Policy Loss                  -4993.7197
Q Predictions Mean           4991.206
Q Predictions Std            735.6422
Q Predictions Max            5809.2246
Q Predictions Min            132.96176
V Predictions Mean           4977.368
V Predictions Std            729.71234
V Predictions Max            5765.829
V Predictions Min            132.31136
Log Pis Mean                 6.449799
Log Pis Std                  3.9734452
Log Pis Max                  15.783613
Log Pis Min                  -4.5474653
Policy mu Mean               -0.057585686
Policy mu Std                1.4629446
Policy mu Max                3.189614
Policy mu Min                -3.097926
Policy log std Mean          -0.9190936
Policy log std Std           0.53113425
Policy log std Max           -0.028934002
Policy log std Min           -3.5365791
Z mean eval                  4.2100887
Z variance eval              0.031066054
total_rewards                [12338.95717222 12377.83822059 12916.26468109 12876.38386207
 12818.50727746 12258.35856796    13.04735402 12765.31914859
 12756.28754119 12649.76241563]
total_rewards_mean           11377.072624081924
total_rewards_std            3794.5812767557945
total_rewards_max            12916.264681091729
total_rewards_min            13.047354023792588
Number of train steps total  1876000
Number of env steps total    2347000
Number of rollouts total     0
Train Time (s)               140.84470434114337
(Previous) Eval Time (s)     28.694386747200042
Sample Time (s)              21.762854830361903
Epoch Time (s)               191.30194591870531
Total Train Time (s)         86494.57668703469
Epoch                        468
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:49:19.587650 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #468 | Epoch Duration: 190.40082502365112
2020-01-14 04:49:19.587887 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #468 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.210946
Z variance train             0.031101072
KL Divergence                65.77896
KL Loss                      6.577896
QF Loss                      565.02124
VF Loss                      417.34332
Policy Loss                  -5100.829
Q Predictions Mean           5107.7896
Q Predictions Std            576.6523
Q Predictions Max            5828.61
Q Predictions Min            3371.0784
V Predictions Mean           5092.5195
V Predictions Std            574.891
V Predictions Max            5819.743
V Predictions Min            3372.9917
Log Pis Mean                 6.5919447
Log Pis Std                  4.175384
Log Pis Max                  22.098438
Log Pis Min                  -2.759922
Policy mu Mean               -0.088862516
Policy mu Std                1.4795656
Policy mu Max                3.3963478
Policy mu Min                -3.0366068
Policy log std Mean          -0.92110467
Policy log std Std           0.51734847
Policy log std Max           -0.16588104
Policy log std Min           -3.7918987
Z mean eval                  4.224703
Z variance eval              0.033077843
total_rewards                [10917.05352536 10772.3618228   9439.47803477 11395.7493901
 10211.47249527 10397.4247598  10318.75630222 10520.41934934
 10107.35730155 10762.18856957]
total_rewards_mean           10484.226155079019
total_rewards_std            502.25963760316125
total_rewards_max            11395.749390099825
total_rewards_min            9439.478034770078
Number of train steps total  1880000
Number of env steps total    2352000
Number of rollouts total     0
Train Time (s)               140.0685841939412
(Previous) Eval Time (s)     27.79289982607588
Sample Time (s)              23.941957955714315
Epoch Time (s)               191.8034419757314
Total Train Time (s)         86687.73175298935
Epoch                        469
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:52:32.747502 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #469 | Epoch Duration: 193.15946865081787
2020-01-14 04:52:32.747692 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #469 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2246637
Z variance train             0.03311052
KL Divergence                66.33486
KL Loss                      6.6334863
QF Loss                      919.2013
VF Loss                      229.78748
Policy Loss                  -5121.694
Q Predictions Mean           5127.2153
Q Predictions Std            620.6222
Q Predictions Max            5828.4756
Q Predictions Min            3477.8132
V Predictions Mean           5113.4375
V Predictions Std            618.41956
V Predictions Max            5813.1587
V Predictions Min            3467.1995
Log Pis Mean                 6.1310225
Log Pis Std                  4.080302
Log Pis Max                  32.7404
Log Pis Min                  -6.60624
Policy mu Mean               -0.052933972
Policy mu Std                1.4717274
Policy mu Max                3.6681328
Policy mu Min                -4.3663864
Policy log std Mean          -0.8820283
Policy log std Std           0.45731643
Policy log std Max           -0.30238283
Policy log std Min           -3.46138
Z mean eval                  4.2000513
Z variance eval              0.033088975
total_rewards                [12125.35340344 12296.40835951 12410.50556786 12244.21789822
 12317.68465941 12414.74225924 12340.67140315 12114.65864372
 12352.71228773 12220.72477262]
total_rewards_mean           12283.767925490825
total_rewards_std            100.87116343096865
total_rewards_max            12414.74225924302
total_rewards_min            12114.658643721788
Number of train steps total  1884000
Number of env steps total    2357000
Number of rollouts total     0
Train Time (s)               133.1848694854416
(Previous) Eval Time (s)     29.148514355067164
Sample Time (s)              23.05149162746966
Epoch Time (s)               185.38487546797842
Total Train Time (s)         86871.82637215732
Epoch                        470
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:55:36.846910 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #470 | Epoch Duration: 184.09908270835876
2020-01-14 04:55:36.847098 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #470 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1998553
Z variance train             0.03312952
KL Divergence                65.63857
KL Loss                      6.5638576
QF Loss                      902.1416
VF Loss                      274.74835
Policy Loss                  -5138.4224
Q Predictions Mean           5142.908
Q Predictions Std            643.9163
Q Predictions Max            5836.0566
Q Predictions Min            3390.6472
V Predictions Mean           5139.912
V Predictions Std            642.36115
V Predictions Max            5826.101
V Predictions Min            3386.232
Log Pis Mean                 5.96146
Log Pis Std                  3.869488
Log Pis Max                  16.655128
Log Pis Min                  -2.4593043
Policy mu Mean               -0.018240156
Policy mu Std                1.4306816
Policy mu Max                2.9578846
Policy mu Min                -3.1151125
Policy log std Mean          -0.9326091
Policy log std Std           0.49499568
Policy log std Max           -0.10961044
Policy log std Min           -3.4627295
Z mean eval                  4.2489724
Z variance eval              0.033615667
total_rewards                [12028.33557927 12386.58911014 12299.91915393 12271.08390934
 12662.6926696  12635.74402763 12806.94826566 12273.72651009
 12800.4700835  12068.3174039 ]
total_rewards_mean           12423.382671306026
total_rewards_std            271.2944041717468
total_rewards_max            12806.948265658597
total_rewards_min            12028.335579266704
Number of train steps total  1888000
Number of env steps total    2362000
Number of rollouts total     0
Train Time (s)               132.6041445308365
(Previous) Eval Time (s)     27.86235346039757
Sample Time (s)              22.13616347266361
Epoch Time (s)               182.60266146389768
Total Train Time (s)         87053.02609974006
Epoch                        471
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:58:38.051474 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #471 | Epoch Duration: 181.20420265197754
2020-01-14 04:58:38.051667 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #471 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2462234
Z variance train             0.033616893
KL Divergence                67.260475
KL Loss                      6.7260475
QF Loss                      1098.7446
VF Loss                      254.86252
Policy Loss                  -5127.19
Q Predictions Mean           5131.5674
Q Predictions Std            670.19855
Q Predictions Max            5839.885
Q Predictions Min            427.76706
V Predictions Mean           5136.7217
V Predictions Std            668.8991
V Predictions Max            5845.072
V Predictions Min            493.27032
Log Pis Mean                 6.814868
Log Pis Std                  4.118005
Log Pis Max                  17.082409
Log Pis Min                  -4.0219555
Policy mu Mean               -0.07551674
Policy mu Std                1.5042443
Policy mu Max                3.2820988
Policy mu Min                -2.953818
Policy log std Mean          -0.9073085
Policy log std Std           0.5188357
Policy log std Max           0.24345243
Policy log std Min           -3.429123
Z mean eval                  4.2226624
Z variance eval              0.017148789
total_rewards                [12217.67390195 12858.99986556 12546.05425111 12554.16841049
 12616.7426268  12686.59118127 12621.58809932 12645.01111933
 12606.0659481  12518.33623104]
total_rewards_mean           12587.123163498753
total_rewards_std            152.8341868999593
total_rewards_max            12858.999865559985
total_rewards_min            12217.673901952463
Number of train steps total  1892000
Number of env steps total    2367000
Number of rollouts total     0
Train Time (s)               137.4986975779757
(Previous) Eval Time (s)     26.463594559114426
Sample Time (s)              22.512595089618117
Epoch Time (s)               186.47488722670823
Total Train Time (s)         87241.59583401354
Epoch                        472
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:01:46.626069 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #472 | Epoch Duration: 188.57425379753113
2020-01-14 05:01:46.626294 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #472 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2227488
Z variance train             0.017194677
KL Divergence                68.438354
KL Loss                      6.8438354
QF Loss                      1183.406
VF Loss                      208.7857
Policy Loss                  -5122.7197
Q Predictions Mean           5129.9087
Q Predictions Std            604.81757
Q Predictions Max            5818.3403
Q Predictions Min            3358.464
V Predictions Mean           5120.2725
V Predictions Std            603.38995
V Predictions Max            5815.9204
V Predictions Min            3376.4087
Log Pis Mean                 6.559799
Log Pis Std                  4.0471554
Log Pis Max                  17.152464
Log Pis Min                  -4.365411
Policy mu Mean               -0.07987696
Policy mu Std                1.4853374
Policy mu Max                3.1058917
Policy mu Min                -2.878914
Policy log std Mean          -0.9463572
Policy log std Std           0.5378791
Policy log std Max           -0.21901953
Policy log std Min           -3.8459024
Z mean eval                  4.275006
Z variance eval              0.026079223
total_rewards                [11995.89763951 12026.99323674 12044.98718542 12240.40965731
 12016.61410226 12110.91955483 12242.11390861 12387.95582421
 12264.48270973 12057.17355158]
total_rewards_mean           12138.754737019668
total_rewards_std            127.6578650078759
total_rewards_max            12387.955824211818
total_rewards_min            11995.897639511391
Number of train steps total  1896000
Number of env steps total    2372000
Number of rollouts total     0
Train Time (s)               142.34090366167948
(Previous) Eval Time (s)     28.56257786601782
Sample Time (s)              23.027732045389712
Epoch Time (s)               193.931213573087
Total Train Time (s)         87435.65464525577
Epoch                        473
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:05:00.689360 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #473 | Epoch Duration: 194.06292414665222
2020-01-14 05:05:00.689539 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #473 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.27461
Z variance train             0.02608246
KL Divergence                68.439224
KL Loss                      6.8439226
QF Loss                      811.7993
VF Loss                      321.3178
Policy Loss                  -5118.5015
Q Predictions Mean           5125.9565
Q Predictions Std            644.6855
Q Predictions Max            5901.3325
Q Predictions Min            3054.2373
V Predictions Mean           5125.6274
V Predictions Std            641.3293
V Predictions Max            5915.834
V Predictions Min            3109.6995
Log Pis Mean                 6.4235606
Log Pis Std                  3.9791527
Log Pis Max                  14.778736
Log Pis Min                  -7.937108
Policy mu Mean               -0.10816876
Policy mu Std                1.4639156
Policy mu Max                3.599058
Policy mu Min                -2.8449874
Policy log std Mean          -0.9312115
Policy log std Std           0.531795
Policy log std Max           -0.1950227
Policy log std Min           -3.4630547
Z mean eval                  4.1868258
Z variance eval              0.022501435
total_rewards                [11878.78549959 12437.39766993 12788.57503844 12764.5163966
 12357.77199307 11504.34908198 12605.95845751 12390.96739362
 12469.84430609 12356.91425624]
total_rewards_mean           12355.508009308667
total_rewards_std            372.8725501848206
total_rewards_max            12788.575038436022
total_rewards_min            11504.349081976996
Number of train steps total  1900000
Number of env steps total    2377000
Number of rollouts total     0
Train Time (s)               140.5494563835673
(Previous) Eval Time (s)     28.693925593979657
Sample Time (s)              23.020479577127844
Epoch Time (s)               192.2638615546748
Total Train Time (s)         87627.64457067102
Epoch                        474
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:08:12.686031 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #474 | Epoch Duration: 191.99631714820862
2020-01-14 05:08:12.686377 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #474 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1859713
Z variance train             0.022532603
KL Divergence                66.06043
KL Loss                      6.6060433
QF Loss                      457.2906
VF Loss                      181.55476
Policy Loss                  -5065.8833
Q Predictions Mean           5069.9873
Q Predictions Std            614.2302
Q Predictions Max            5772.7637
Q Predictions Min            3026.0757
V Predictions Mean           5073.829
V Predictions Std            616.01794
V Predictions Max            5787.8286
V Predictions Min            3018.6062
Log Pis Mean                 6.825303
Log Pis Std                  3.8075705
Log Pis Max                  16.642826
Log Pis Min                  -4.3684793
Policy mu Mean               -0.08015444
Policy mu Std                1.5052845
Policy mu Max                4.390304
Policy mu Min                -2.8130035
Policy log std Mean          -0.9325827
Policy log std Std           0.52788275
Policy log std Max           -0.2444892
Policy log std Min           -3.4420824
Z mean eval                  4.2495723
Z variance eval              0.019942772
total_rewards                [12620.54249088 13008.78667915 12917.51593303 13116.19696743
 12797.94438776 12984.55460101 12638.64782041 12848.61599831
 12921.60558245 12713.17218326]
total_rewards_mean           12856.758264369444
total_rewards_std            155.61556504564334
total_rewards_max            13116.196967431591
total_rewards_min            12620.542490883818
Number of train steps total  1904000
Number of env steps total    2382000
Number of rollouts total     0
Train Time (s)               142.73992126015946
(Previous) Eval Time (s)     28.42596430098638
Sample Time (s)              22.62916042096913
Epoch Time (s)               193.79504598211497
Total Train Time (s)         87821.08411440859
Epoch                        475
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:11:26.128542 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #475 | Epoch Duration: 193.44191765785217
2020-01-14 05:11:26.128738 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #475 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.251893
Z variance train             0.019979652
KL Divergence                69.41832
KL Loss                      6.941832
QF Loss                      1386.8406
VF Loss                      531.02515
Policy Loss                  -5164.6147
Q Predictions Mean           5173.127
Q Predictions Std            583.70856
Q Predictions Max            5842.1523
Q Predictions Min            3394.225
V Predictions Mean           5159.7603
V Predictions Std            583.7846
V Predictions Max            5808.292
V Predictions Min            3388.2224
Log Pis Mean                 6.669059
Log Pis Std                  4.0355253
Log Pis Max                  17.378178
Log Pis Min                  -4.1543183
Policy mu Mean               -0.06895235
Policy mu Std                1.4927775
Policy mu Max                3.58657
Policy mu Min                -3.0295784
Policy log std Mean          -0.91842985
Policy log std Std           0.51809424
Policy log std Max           -0.099078655
Policy log std Min           -3.7010126
Z mean eval                  4.2528954
Z variance eval              0.017974753
total_rewards                [12314.22206628 12518.64843752 12577.43514366 12288.53540159
 12673.76506251 12603.09802476 12452.79275374 12456.65908729
 12458.7100906  12443.08642251]
total_rewards_mean           12478.695249046312
total_rewards_std            114.41600805738705
total_rewards_max            12673.76506251474
total_rewards_min            12288.53540158667
Number of train steps total  1908000
Number of env steps total    2387000
Number of rollouts total     0
Train Time (s)               141.08294180314988
(Previous) Eval Time (s)     28.072527120355517
Sample Time (s)              22.16557001695037
Epoch Time (s)               191.32103894045576
Total Train Time (s)         88011.04145782953
Epoch                        476
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:14:36.090572 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #476 | Epoch Duration: 189.96169137954712
2020-01-14 05:14:36.090761 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #476 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2535124
Z variance train             0.017992888
KL Divergence                69.22274
KL Loss                      6.922274
QF Loss                      1025.9143
VF Loss                      499.92603
Policy Loss                  -5125.3325
Q Predictions Mean           5135.087
Q Predictions Std            679.1616
Q Predictions Max            5917.087
Q Predictions Min            3474.7498
V Predictions Mean           5128.1104
V Predictions Std            679.30237
V Predictions Max            5912.069
V Predictions Min            3479.7322
Log Pis Mean                 6.470873
Log Pis Std                  4.2503366
Log Pis Max                  15.79571
Log Pis Min                  -5.1051207
Policy mu Mean               -0.07831012
Policy mu Std                1.476348
Policy mu Max                3.9257271
Policy mu Min                -3.5728514
Policy log std Mean          -0.94895345
Policy log std Std           0.5464216
Policy log std Max           -0.19875276
Policy log std Min           -3.5359144
Z mean eval                  4.2829323
Z variance eval              0.033387247
total_rewards                [12536.13906916 12277.31200194 12465.14525337 12711.88771244
 12618.30790486 12775.58687384 12438.9300634  12798.24792611
   360.58711434 12720.96812322]
total_rewards_mean           11370.311204268213
total_rewards_std            3673.3069276718566
total_rewards_max            12798.247926107579
total_rewards_min            360.58711433932797
Number of train steps total  1912000
Number of env steps total    2392000
Number of rollouts total     0
Train Time (s)               134.00999232986942
(Previous) Eval Time (s)     26.71283148229122
Sample Time (s)              21.92370200669393
Epoch Time (s)               182.64652581885457
Total Train Time (s)         88194.8845910551
Epoch                        477
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:17:39.938760 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #477 | Epoch Duration: 183.84785795211792
2020-01-14 05:17:39.938971 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #477 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2837305
Z variance train             0.03340838
KL Divergence                67.476524
KL Loss                      6.7476525
QF Loss                      858.82416
VF Loss                      181.96797
Policy Loss                  -5194.763
Q Predictions Mean           5200.8296
Q Predictions Std            665.93964
Q Predictions Max            5849.9014
Q Predictions Min            431.26483
V Predictions Mean           5192.676
V Predictions Std            667.6415
V Predictions Max            5836.3545
V Predictions Min            390.18454
Log Pis Mean                 6.815982
Log Pis Std                  3.9206293
Log Pis Max                  16.51307
Log Pis Min                  -3.6318934
Policy mu Mean               -0.07826734
Policy mu Std                1.5023766
Policy mu Max                3.1114883
Policy mu Min                -3.191465
Policy log std Mean          -0.9410326
Policy log std Std           0.57103205
Policy log std Max           -0.032150388
Policy log std Min           -3.796794
Z mean eval                  4.153064
Z variance eval              0.048792887
total_rewards                [12205.42329154 12496.49604714 12471.66847282 12494.0946193
 12637.15940654 12390.47792084 12331.21571296 12416.2874931
 12293.38300697 12326.52408938]
total_rewards_mean           12406.273006057949
total_rewards_std            117.8413981736546
total_rewards_max            12637.159406535313
total_rewards_min            12205.423291542302
Number of train steps total  1916000
Number of env steps total    2397000
Number of rollouts total     0
Train Time (s)               133.83621701830998
(Previous) Eval Time (s)     27.91383753111586
Sample Time (s)              22.169946518726647
Epoch Time (s)               183.9200010681525
Total Train Time (s)         88378.76384104975
Epoch                        478
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:20:43.822519 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #478 | Epoch Duration: 183.88340258598328
2020-01-14 05:20:43.822703 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #478 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.1565156
Z variance train             0.048938647
KL Divergence                64.20601
KL Loss                      6.420601
QF Loss                      756.0742
VF Loss                      178.31996
Policy Loss                  -5075.1333
Q Predictions Mean           5081.492
Q Predictions Std            718.69946
Q Predictions Max            5835.4478
Q Predictions Min            -92.456406
V Predictions Mean           5068.4795
V Predictions Std            718.2065
V Predictions Max            5824.8296
V Predictions Min            -88.71746
Log Pis Mean                 6.810291
Log Pis Std                  4.20832
Log Pis Max                  18.281183
Log Pis Min                  -5.8885098
Policy mu Mean               -0.07640772
Policy mu Std                1.5002301
Policy mu Max                3.3853257
Policy mu Min                -2.6714177
Policy log std Mean          -0.9488599
Policy log std Std           0.56598026
Policy log std Max           0.026634932
Policy log std Min           -3.7307675
Z mean eval                  4.2138004
Z variance eval              0.031624965
total_rewards                [12390.11718901 12776.84787558 12465.26653372 12822.04213238
 12361.67413218 12597.50934145 12531.73590489 12960.36198374
 12759.48714683 12790.32972178]
total_rewards_mean           12645.537196155594
total_rewards_std            193.6577238962651
total_rewards_max            12960.361983740602
total_rewards_min            12361.674132183198
Number of train steps total  1920000
Number of env steps total    2402000
Number of rollouts total     0
Train Time (s)               140.25200994685292
(Previous) Eval Time (s)     27.876957995817065
Sample Time (s)              22.327736055012792
Epoch Time (s)               190.45670399768278
Total Train Time (s)         88569.79295041971
Epoch                        479
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:23:54.856530 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #479 | Epoch Duration: 191.03369164466858
2020-01-14 05:23:54.856710 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #479 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.213987
Z variance train             0.03138793
KL Divergence                67.398285
KL Loss                      6.7398286
QF Loss                      860.36646
VF Loss                      228.19077
Policy Loss                  -5060.861
Q Predictions Mean           5065.465
Q Predictions Std            698.3477
Q Predictions Max            5851.177
Q Predictions Min            3396.45
V Predictions Mean           5063.7393
V Predictions Std            698.48615
V Predictions Max            5859.0884
V Predictions Min            3387.254
Log Pis Mean                 6.24977
Log Pis Std                  3.8090396
Log Pis Max                  15.526095
Log Pis Min                  -2.8193393
Policy mu Mean               -0.0011355294
Policy mu Std                1.4422202
Policy mu Max                3.254151
Policy mu Min                -2.9581614
Policy log std Mean          -0.9049291
Policy log std Std           0.5171645
Policy log std Max           -0.24080443
Policy log std Min           -3.423808
Z mean eval                  4.2498336
Z variance eval              0.03764976
total_rewards                [12277.23111627 12636.99516907 12509.21372561 12729.11165842
 12915.55576787 12656.1876091  12781.91572404 12815.15480842
 12759.96720591 12842.76990366]
total_rewards_mean           12692.410268836918
total_rewards_std            176.55252202020088
total_rewards_max            12915.555767872642
total_rewards_min            12277.231116266004
Number of train steps total  1924000
Number of env steps total    2407000
Number of rollouts total     0
Train Time (s)               140.63044677721336
(Previous) Eval Time (s)     28.45355159090832
Sample Time (s)              23.375975128728896
Epoch Time (s)               192.45997349685058
Total Train Time (s)         88762.69091789052
Epoch                        480
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:27:07.761064 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #480 | Epoch Duration: 192.9041826725006
2020-01-14 05:27:07.761411 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #480 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2486506
Z variance train             0.037779924
KL Divergence                68.06487
KL Loss                      6.8064876
QF Loss                      1312.9067
VF Loss                      439.98105
Policy Loss                  -5107.312
Q Predictions Mean           5117.2837
Q Predictions Std            592.82465
Q Predictions Max            5789.2974
Q Predictions Min            3395.6091
V Predictions Mean           5120.2812
V Predictions Std            592.0664
V Predictions Max            5793.22
V Predictions Min            3393.738
Log Pis Mean                 6.359253
Log Pis Std                  3.835872
Log Pis Max                  17.237127
Log Pis Min                  -2.7466478
Policy mu Mean               -0.023446307
Policy mu Std                1.4569279
Policy mu Max                3.3029573
Policy mu Min                -2.8322828
Policy log std Mean          -0.9183764
Policy log std Std           0.52061623
Policy log std Max           -0.1649788
Policy log std Min           -3.3716846
Z mean eval                  4.289382
Z variance eval              0.013542819
total_rewards                [12406.8606915  12766.09930802 12706.84442254 12897.03486137
 12689.69087699 12843.49790479 12627.82496451 12774.76325017
 12737.09326186 12595.8971507 ]
total_rewards_mean           12704.560669245184
total_rewards_std            131.40448154952713
total_rewards_max            12897.034861373688
total_rewards_min            12406.860691500182
Number of train steps total  1928000
Number of env steps total    2412000
Number of rollouts total     0
Train Time (s)               139.86576449405402
(Previous) Eval Time (s)     28.89732359070331
Sample Time (s)              23.507607387378812
Epoch Time (s)               192.27069547213614
Total Train Time (s)         88953.6672287262
Epoch                        481
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:30:18.741655 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #481 | Epoch Duration: 190.98006796836853
2020-01-14 05:30:18.741837 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #481 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2932878
Z variance train             0.013486
KL Divergence                71.31792
KL Loss                      7.1317916
QF Loss                      1456.2605
VF Loss                      317.1813
Policy Loss                  -5190.726
Q Predictions Mean           5202.475
Q Predictions Std            646.37225
Q Predictions Max            5920.826
Q Predictions Min            2909.3586
V Predictions Mean           5178.919
V Predictions Std            642.4893
V Predictions Max            5888.327
V Predictions Min            2923.0708
Log Pis Mean                 6.579468
Log Pis Std                  4.116402
Log Pis Max                  19.3742
Log Pis Min                  -4.354799
Policy mu Mean               -0.056923386
Policy mu Std                1.5201561
Policy mu Max                3.3521223
Policy mu Min                -2.9039712
Policy log std Mean          -0.92560846
Policy log std Std           0.5437504
Policy log std Max           -0.04442036
Policy log std Min           -3.4669147
Z mean eval                  4.322767
Z variance eval              0.006111015
total_rewards                [12402.80215615 12633.89309712 12942.33908794 12978.24804049
 13056.31412463 12464.61916549 12916.90427616 12872.17007988
 12801.12248148 12798.48172048]
total_rewards_mean           12786.689422981277
total_rewards_std            208.0083233008453
total_rewards_max            13056.314124628532
total_rewards_min            12402.802156151381
Number of train steps total  1932000
Number of env steps total    2417000
Number of rollouts total     0
Train Time (s)               141.70960162067786
(Previous) Eval Time (s)     27.6062955618836
Sample Time (s)              21.58523225924
Epoch Time (s)               190.90112944180146
Total Train Time (s)         89145.51701228507
Epoch                        482
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:33:30.596336 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #482 | Epoch Duration: 191.85435724258423
2020-01-14 05:33:30.596526 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #482 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.322549
Z variance train             0.0060970886
KL Divergence                74.48847
KL Loss                      7.4488473
QF Loss                      528.6218
VF Loss                      161.66742
Policy Loss                  -5150.7134
Q Predictions Mean           5160.0117
Q Predictions Std            704.494
Q Predictions Max            5881.766
Q Predictions Min            99.5215
V Predictions Mean           5156.764
V Predictions Std            706.30475
V Predictions Max            5880.4526
V Predictions Min            102.7055
Log Pis Mean                 6.543786
Log Pis Std                  3.8334255
Log Pis Max                  16.722921
Log Pis Min                  -2.1506672
Policy mu Mean               -0.04152695
Policy mu Std                1.5021591
Policy mu Max                3.1102908
Policy mu Min                -3.1647513
Policy log std Mean          -0.91486245
Policy log std Std           0.52080274
Policy log std Max           -0.04219818
Policy log std Min           -3.5235677
Z mean eval                  4.2695265
Z variance eval              0.00795423
total_rewards                [12399.16681203 12575.67550166 12772.36432225 12770.74265702
 12801.69790794 12887.42295266 12846.12390819 12666.03716935
 12654.35780544 12971.54201981]
total_rewards_mean           12734.51310563489
total_rewards_std            157.50572638600093
total_rewards_max            12971.542019813382
total_rewards_min            12399.1668120304
Number of train steps total  1936000
Number of env steps total    2422000
Number of rollouts total     0
Train Time (s)               137.79022990120575
(Previous) Eval Time (s)     28.559214959852397
Sample Time (s)              20.890664087142795
Epoch Time (s)               187.24010894820094
Total Train Time (s)         89332.00507062394
Epoch                        483
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:36:37.089221 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #483 | Epoch Duration: 186.4925560951233
2020-01-14 05:36:37.089399 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #483 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2689466
Z variance train             0.007899778
KL Divergence                72.439
KL Loss                      7.2439003
QF Loss                      655.51843
VF Loss                      298.5251
Policy Loss                  -5202.6235
Q Predictions Mean           5206.248
Q Predictions Std            551.20154
Q Predictions Max            5797.201
Q Predictions Min            3380.4897
V Predictions Mean           5212.733
V Predictions Std            552.1919
V Predictions Max            5827.9546
V Predictions Min            3388.9905
Log Pis Mean                 6.863338
Log Pis Std                  3.7574298
Log Pis Max                  17.800076
Log Pis Min                  -1.4966794
Policy mu Mean               -0.008420997
Policy mu Std                1.5152436
Policy mu Max                4.0736146
Policy mu Min                -2.9719863
Policy log std Mean          -0.9350632
Policy log std Std           0.5449479
Policy log std Max           0.33286786
Policy log std Min           -3.5745378
Z mean eval                  4.273977
Z variance eval              0.0077558905
total_rewards                [12239.95547661 12574.67970019 12191.97860399 12723.60868148
 12323.70003431 12316.94620409 12661.88910733 12406.04930061
 12406.06790289 12604.49086259]
total_rewards_mean           12444.936587409084
total_rewards_std            175.24988070121154
total_rewards_max            12723.608681483665
total_rewards_min            12191.978603991003
Number of train steps total  1940000
Number of env steps total    2427000
Number of rollouts total     0
Train Time (s)               133.66097513306886
(Previous) Eval Time (s)     27.811332589946687
Sample Time (s)              22.365621275734156
Epoch Time (s)               183.8379289987497
Total Train Time (s)         89515.65791046992
Epoch                        484
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:39:40.747044 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #484 | Epoch Duration: 183.6575005054474
2020-01-14 05:39:40.747294 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #484 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.273487
Z variance train             0.007762459
KL Divergence                71.526344
KL Loss                      7.1526346
QF Loss                      615.35596
VF Loss                      184.69086
Policy Loss                  -5099.4575
Q Predictions Mean           5108.281
Q Predictions Std            645.76904
Q Predictions Max            5837.269
Q Predictions Min            3379.1414
V Predictions Mean           5102.669
V Predictions Std            645.81134
V Predictions Max            5848.61
V Predictions Min            3373.9426
Log Pis Mean                 5.9342647
Log Pis Std                  3.5252578
Log Pis Max                  17.496452
Log Pis Min                  -3.7925942
Policy mu Mean               -0.00075371005
Policy mu Std                1.4240608
Policy mu Max                3.0574515
Policy mu Min                -2.8814085
Policy log std Mean          -0.9553378
Policy log std Std           0.52000725
Policy log std Max           -0.1609056
Policy log std Min           -3.4898446
Z mean eval                  4.3006477
Z variance eval              0.025219385
total_rewards                [12638.90060789 12578.2443585  12886.04707359 12881.92182757
 12634.92821843 12527.66443059 12705.54460093 12525.2259078
 12968.20986176 12498.37885212]
total_rewards_mean           12684.506573919274
total_rewards_std            161.54392676144235
total_rewards_max            12968.209861762802
total_rewards_min            12498.378852122994
Number of train steps total  1944000
Number of env steps total    2432000
Number of rollouts total     0
Train Time (s)               133.8476536506787
(Previous) Eval Time (s)     27.63057366712019
Sample Time (s)              22.376978854183108
Epoch Time (s)               183.855206171982
Total Train Time (s)         89700.37067307532
Epoch                        485
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:42:45.464725 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #485 | Epoch Duration: 184.71727800369263
2020-01-14 05:42:45.464917 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #485 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.299309
Z variance train             0.025161048
KL Divergence                70.39349
KL Loss                      7.0393496
QF Loss                      632.7904
VF Loss                      230.8249
Policy Loss                  -5177.759
Q Predictions Mean           5187.116
Q Predictions Std            681.429
Q Predictions Max            5912.7026
Q Predictions Min            3461.5522
V Predictions Mean           5177.781
V Predictions Std            682.25085
V Predictions Max            5896.519
V Predictions Min            3451.8604
Log Pis Mean                 6.375552
Log Pis Std                  4.42368
Log Pis Max                  20.64159
Log Pis Min                  -3.4550505
Policy mu Mean               -0.055389196
Policy mu Std                1.4746268
Policy mu Max                4.142558
Policy mu Min                -3.1607656
Policy log std Mean          -0.9282389
Policy log std Std           0.5451557
Policy log std Max           -0.08217132
Policy log std Min           -3.6701386
Z mean eval                  4.2948446
Z variance eval              0.01877231
total_rewards                [12194.19706505 12611.6334518  12442.91617736 12364.66802071
 12824.01729916 12385.82254762 12701.21411539 12195.95350456
 12604.66774235 12589.41222181]
total_rewards_mean           12491.450214580862
total_rewards_std            199.17950592655865
total_rewards_max            12824.017299158162
total_rewards_min            12194.197065051227
Number of train steps total  1948000
Number of env steps total    2437000
Number of rollouts total     0
Train Time (s)               141.848916167859
(Previous) Eval Time (s)     28.492275043856353
Sample Time (s)              23.04372782027349
Epoch Time (s)               193.38491903198883
Total Train Time (s)         89894.43845096324
Epoch                        486
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:45:59.537545 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #486 | Epoch Duration: 194.0724847316742
2020-01-14 05:45:59.537756 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #486 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.291932
Z variance train             0.018754084
KL Divergence                72.474144
KL Loss                      7.2474146
QF Loss                      601.8346
VF Loss                      732.3284
Policy Loss                  -5213.0117
Q Predictions Mean           5219.324
Q Predictions Std            618.50653
Q Predictions Max            5870.7993
Q Predictions Min            3468.6719
V Predictions Mean           5234.6377
V Predictions Std            622.3402
V Predictions Max            5909.993
V Predictions Min            3488.583
Log Pis Mean                 6.475545
Log Pis Std                  4.1678047
Log Pis Max                  18.342216
Log Pis Min                  -4.062442
Policy mu Mean               -0.057434473
Policy mu Std                1.4901192
Policy mu Max                4.534337
Policy mu Min                -3.0363605
Policy log std Mean          -0.9196722
Policy log std Std           0.52708215
Policy log std Max           0.266688
Policy log std Min           -3.4650898
Z mean eval                  4.2408056
Z variance eval              0.021387551
total_rewards                [12557.87121663 12757.32923969 12922.14441584 12962.41514691
 13002.10178368 12992.29121281 12843.71822689 12832.19089417
 13070.29108771 12925.05283697]
total_rewards_mean           12886.540606130095
total_rewards_std            140.1129463483599
total_rewards_max            13070.291087707583
total_rewards_min            12557.871216628037
Number of train steps total  1952000
Number of env steps total    2442000
Number of rollouts total     0
Train Time (s)               140.87382971914485
(Previous) Eval Time (s)     29.17954859789461
Sample Time (s)              23.3595575154759
Epoch Time (s)               193.41293583251536
Total Train Time (s)         90088.26809512172
Epoch                        487
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:49:13.372289 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #487 | Epoch Duration: 193.83438539505005
2020-01-14 05:49:13.372483 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #487 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.241319
Z variance train             0.021300875
KL Divergence                72.46329
KL Loss                      7.246329
QF Loss                      693.10645
VF Loss                      100.19914
Policy Loss                  -5065.0146
Q Predictions Mean           5066.4194
Q Predictions Std            690.27515
Q Predictions Max            5800.3013
Q Predictions Min            3361.4136
V Predictions Mean           5062.43
V Predictions Std            689.2069
V Predictions Max            5773.463
V Predictions Min            3362.9937
Log Pis Mean                 6.5800123
Log Pis Std                  4.0718913
Log Pis Max                  17.872612
Log Pis Min                  -6.622495
Policy mu Mean               -0.07853382
Policy mu Std                1.4895892
Policy mu Max                3.2060905
Policy mu Min                -2.9642298
Policy log std Mean          -0.91200274
Policy log std Std           0.5241847
Policy log std Max           0.059603214
Policy log std Min           -3.6658502
Z mean eval                  4.2972064
Z variance eval              0.014493167
total_rewards                [12056.32404705 12501.35283214 12405.95784327 12468.26787125
 12584.68422031 12403.40844502 12568.71402845 12574.55247034
 12410.71124758 12517.2990063 ]
total_rewards_mean           12449.127201170899
total_rewards_std            146.92630504593777
total_rewards_max            12584.684220309315
total_rewards_min            12056.324047048281
Number of train steps total  1956000
Number of env steps total    2447000
Number of rollouts total     0
Train Time (s)               141.18457328900695
(Previous) Eval Time (s)     29.600663017015904
Sample Time (s)              21.48542100097984
Epoch Time (s)               192.2706573070027
Total Train Time (s)         90280.24198195711
Epoch                        488
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:52:25.351117 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #488 | Epoch Duration: 191.97849035263062
2020-01-14 05:52:25.351327 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #488 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.297279
Z variance train             0.014513704
KL Divergence                72.624146
KL Loss                      7.2624145
QF Loss                      791.006
VF Loss                      164.78177
Policy Loss                  -5119.652
Q Predictions Mean           5123.3286
Q Predictions Std            747.6152
Q Predictions Max            5852.066
Q Predictions Min            -11.662923
V Predictions Mean           5116.033
V Predictions Std            742.17725
V Predictions Max            5801.5093
V Predictions Min            -20.899176
Log Pis Mean                 6.4454308
Log Pis Std                  4.214946
Log Pis Max                  20.797337
Log Pis Min                  -3.645928
Policy mu Mean               -0.068088874
Policy mu Std                1.4873352
Policy mu Max                3.4576
Policy mu Min                -3.1524632
Policy log std Mean          -0.9516409
Policy log std Std           0.57961905
Policy log std Max           0.40144873
Policy log std Min           -3.5201027
Z mean eval                  4.282872
Z variance eval              0.013144441
total_rewards                [12170.03166827 12496.52390669 13003.65328151 12558.68270411
 12426.53893583 12092.37670792 12430.291713   12345.82341957
  7542.12563258 12120.69856971]
total_rewards_mean           11918.674653918271
total_rewards_std            1480.242569597544
total_rewards_max            13003.653281505949
total_rewards_min            7542.1256325811055
Number of train steps total  1960000
Number of env steps total    2452000
Number of rollouts total     0
Train Time (s)               141.13255342282355
(Previous) Eval Time (s)     29.30816909810528
Sample Time (s)              23.135682825930417
Epoch Time (s)               193.57640534685925
Total Train Time (s)         90473.91014405666
Epoch                        489
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:55:39.025344 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #489 | Epoch Duration: 193.67384481430054
2020-01-14 05:55:39.025658 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #489 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2789974
Z variance train             0.01317783
KL Divergence                73.58127
KL Loss                      7.358127
QF Loss                      1179.4856
VF Loss                      310.22708
Policy Loss                  -5245.146
Q Predictions Mean           5253.302
Q Predictions Std            621.5379
Q Predictions Max            5939.483
Q Predictions Min            3394.6794
V Predictions Mean           5259.9033
V Predictions Std            620.9836
V Predictions Max            5941.8804
V Predictions Min            3417.0337
Log Pis Mean                 6.4016666
Log Pis Std                  4.231585
Log Pis Max                  17.492928
Log Pis Min                  -3.669289
Policy mu Mean               -0.025416879
Policy mu Std                1.4933256
Policy mu Max                3.3986907
Policy mu Min                -4.407995
Policy log std Mean          -0.9122262
Policy log std Std           0.5113962
Policy log std Max           -0.17946428
Policy log std Min           -3.4197192
Z mean eval                  4.2660294
Z variance eval              0.011378821
total_rewards                [11893.89668991 12361.70620238 12226.72220619 12429.19715304
 12114.5880751  12204.65334746 12203.91323651 12172.418089
 11978.22263364 12560.37820366]
total_rewards_mean           12214.56958368889
total_rewards_std            189.2409552933606
total_rewards_max            12560.378203658493
total_rewards_min            11893.896689909878
Number of train steps total  1964000
Number of env steps total    2457000
Number of rollouts total     0
Train Time (s)               135.86728365533054
(Previous) Eval Time (s)     29.405210464261472
Sample Time (s)              23.473247631452978
Epoch Time (s)               188.745741751045
Total Train Time (s)         90661.64736528834
Epoch                        490
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:58:46.768100 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #490 | Epoch Duration: 187.7422616481781
2020-01-14 05:58:46.768315 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #490 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2607203
Z variance train             0.011353372
KL Divergence                73.920975
KL Loss                      7.3920975
QF Loss                      783.3812
VF Loss                      387.70334
Policy Loss                  -5200.797
Q Predictions Mean           5212.6216
Q Predictions Std            586.0498
Q Predictions Max            5880.612
Q Predictions Min            3427.5498
V Predictions Mean           5215.332
V Predictions Std            584.9931
V Predictions Max            5885.156
V Predictions Min            3438.968
Log Pis Mean                 6.8523736
Log Pis Std                  4.2792406
Log Pis Max                  33.78877
Log Pis Min                  -4.6005974
Policy mu Mean               -0.072369926
Policy mu Std                1.512937
Policy mu Max                3.3365943
Policy mu Min                -6.034922
Policy log std Mean          -0.9324293
Policy log std Std           0.5449957
Policy log std Max           0.081587195
Policy log std Min           -3.6556711
Z mean eval                  4.227214
Z variance eval              0.0145549
total_rewards                [12777.79337417 12895.53420165 12903.85036519 12857.75150061
 12736.53962904 12856.92971238 12665.17038947 12748.5650207
 12601.3547094  12884.2616706 ]
total_rewards_mean           12792.775057319759
total_rewards_std            98.92968540288973
total_rewards_max            12903.850365189859
total_rewards_min            12601.354709396563
Number of train steps total  1968000
Number of env steps total    2462000
Number of rollouts total     0
Train Time (s)               134.16014388063923
(Previous) Eval Time (s)     28.40133660612628
Sample Time (s)              22.45135743683204
Epoch Time (s)               185.01283792359754
Total Train Time (s)         90846.58571384009
Epoch                        491
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:01:51.710835 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #491 | Epoch Duration: 184.94236278533936
2020-01-14 06:01:51.711043 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #491 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2268014
Z variance train             0.014547465
KL Divergence                71.73688
KL Loss                      7.173688
QF Loss                      502.4969
VF Loss                      280.58334
Policy Loss                  -5138.6064
Q Predictions Mean           5148.053
Q Predictions Std            654.8395
Q Predictions Max            5861.427
Q Predictions Min            3420.8184
V Predictions Mean           5150.742
V Predictions Std            654.05035
V Predictions Max            5856.7495
V Predictions Min            3423.6074
Log Pis Mean                 6.5416393
Log Pis Std                  3.8613791
Log Pis Max                  15.810492
Log Pis Min                  -3.085278
Policy mu Mean               -0.0033386846
Policy mu Std                1.5085723
Policy mu Max                2.9205627
Policy mu Min                -2.6356611
Policy log std Mean          -0.9315774
Policy log std Std           0.5376768
Policy log std Max           -0.08961427
Policy log std Min           -3.3616958
Z mean eval                  4.2798204
Z variance eval              0.03205339
total_rewards                [12168.13105779 12806.20129625 12458.09506976 12852.306578
 12411.82649467 12388.97840235 12573.466541   12443.05089917
 12596.52481947 12480.38078151]
total_rewards_mean           12517.896193996512
total_rewards_std            191.05294777628944
total_rewards_max            12852.306578000469
total_rewards_min            12168.13105778825
Number of train steps total  1972000
Number of env steps total    2467000
Number of rollouts total     0
Train Time (s)               136.1898646648042
(Previous) Eval Time (s)     28.330527178011835
Sample Time (s)              22.443289171904325
Epoch Time (s)               186.96368101472035
Total Train Time (s)         91033.35338878306
Epoch                        492
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:04:58.483509 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #492 | Epoch Duration: 186.7723183631897
2020-01-14 06:04:58.483712 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #492 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2795157
Z variance train             0.032067057
KL Divergence                72.32814
KL Loss                      7.2328143
QF Loss                      1218.9807
VF Loss                      460.89365
Policy Loss                  -5156.647
Q Predictions Mean           5165.7847
Q Predictions Std            621.4989
Q Predictions Max            5871.41
Q Predictions Min            3353.0146
V Predictions Mean           5164.652
V Predictions Std            618.5793
V Predictions Max            5851.519
V Predictions Min            3372.3945
Log Pis Mean                 6.732897
Log Pis Std                  4.0243073
Log Pis Max                  21.144209
Log Pis Min                  -4.9342318
Policy mu Mean               -0.028256776
Policy mu Std                1.4996369
Policy mu Max                5.4570875
Policy mu Min                -3.1409519
Policy log std Mean          -0.92015415
Policy log std Std           0.5143357
Policy log std Max           0.28883648
Policy log std Min           -3.4451761
Z mean eval                  4.2954397
Z variance eval              0.01833532
total_rewards                [12327.26917663 12442.33357878 12502.59168396 12888.95177783
 12720.71347618 12271.68387168 12747.1285588  12901.74441135
 12709.57775562 12854.73114037]
total_rewards_mean           12636.67254312029
total_rewards_std            221.52393157333935
total_rewards_max            12901.74441135404
total_rewards_min            12271.683871681242
Number of train steps total  1976000
Number of env steps total    2472000
Number of rollouts total     0
Train Time (s)               143.7533394168131
(Previous) Eval Time (s)     28.138880664948374
Sample Time (s)              23.31791536230594
Epoch Time (s)               195.21013544406742
Total Train Time (s)         91228.73033179296
Epoch                        493
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:08:13.863297 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #493 | Epoch Duration: 195.37945461273193
2020-01-14 06:08:13.863425 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #493 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.29489
Z variance train             0.018419202
KL Divergence                74.966354
KL Loss                      7.4966354
QF Loss                      842.5419
VF Loss                      237.20277
Policy Loss                  -5163.117
Q Predictions Mean           5165.4854
Q Predictions Std            755.8771
Q Predictions Max            5885.456
Q Predictions Min            -56.97526
V Predictions Mean           5151.538
V Predictions Std            755.1904
V Predictions Max            5859.3623
V Predictions Min            -88.23775
Log Pis Mean                 6.354021
Log Pis Std                  4.535988
Log Pis Max                  19.54153
Log Pis Min                  -7.7484856
Policy mu Mean               -0.029676585
Policy mu Std                1.4973087
Policy mu Max                3.3232012
Policy mu Min                -2.7258558
Policy log std Mean          -0.89211994
Policy log std Std           0.50445575
Policy log std Max           0.07887018
Policy log std Min           -3.4429255
Z mean eval                  4.2801476
Z variance eval              0.010909228
total_rewards                [12369.01787548 13026.65100419 12803.99979088 12545.32418422
 12830.45682725 12875.77320937 13058.29848639 12642.97184574
 12909.52098153 12411.00544936]
total_rewards_mean           12747.30196544185
total_rewards_std            231.42557401228797
total_rewards_max            13058.29848638814
total_rewards_min            12369.017875482936
Number of train steps total  1980000
Number of env steps total    2477000
Number of rollouts total     0
Train Time (s)               142.18796060420573
(Previous) Eval Time (s)     28.307846668176353
Sample Time (s)              21.491991199553013
Epoch Time (s)               191.9877984719351
Total Train Time (s)         91421.23004821548
Epoch                        494
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:11:26.368614 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #494 | Epoch Duration: 192.5050768852234
2020-01-14 06:11:26.368827 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #494 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2789598
Z variance train             0.010932261
KL Divergence                75.994675
KL Loss                      7.5994678
QF Loss                      3201.7192
VF Loss                      401.112
Policy Loss                  -5151.1855
Q Predictions Mean           5162.317
Q Predictions Std            649.6222
Q Predictions Max            5865.1885
Q Predictions Min            3400.659
V Predictions Mean           5158.5605
V Predictions Std            650.3998
V Predictions Max            5854.8213
V Predictions Min            3393.9485
Log Pis Mean                 6.175432
Log Pis Std                  4.4337196
Log Pis Max                  35.02522
Log Pis Min                  -10.041274
Policy mu Mean               -0.022360774
Policy mu Std                1.5053868
Policy mu Max                5.863655
Policy mu Min                -8.267489
Policy log std Mean          -0.9277237
Policy log std Std           0.5302552
Policy log std Max           0.76360047
Policy log std Min           -3.947958
Z mean eval                  4.277511
Z variance eval              0.010493387
total_rewards                [12684.21729158 12862.85144053 12682.56154614 13045.84714504
 12933.1995724  12911.43972945 12965.67894178 12825.67505939
 12910.45932509 12608.30559027]
total_rewards_mean           12843.023564168147
total_rewards_std            134.27432614314483
total_rewards_max            13045.847145041873
total_rewards_min            12608.30559026734
Number of train steps total  1984000
Number of env steps total    2482000
Number of rollouts total     0
Train Time (s)               142.25810974929482
(Previous) Eval Time (s)     28.82474306365475
Sample Time (s)              22.602422210853547
Epoch Time (s)               193.68527502380311
Total Train Time (s)         91615.86012637429
Epoch                        495
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:14:41.004050 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #495 | Epoch Duration: 194.63507628440857
2020-01-14 06:14:41.004255 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #495 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.278573
Z variance train             0.0105993925
KL Divergence                78.624695
KL Loss                      7.8624697
QF Loss                      751.62036
VF Loss                      150.33368
Policy Loss                  -5183.684
Q Predictions Mean           5187.923
Q Predictions Std            755.5474
Q Predictions Max            5910.3726
Q Predictions Min            -73.31865
V Predictions Mean           5181.0054
V Predictions Std            756.0998
V Predictions Max            5899.766
V Predictions Min            -86.549385
Log Pis Mean                 6.9547744
Log Pis Std                  3.7391536
Log Pis Max                  16.652588
Log Pis Min                  -6.1647544
Policy mu Mean               -0.024360843
Policy mu Std                1.5550376
Policy mu Max                2.9895706
Policy mu Min                -2.9855895
Policy log std Mean          -0.9110376
Policy log std Std           0.5304755
Policy log std Max           -0.069476366
Policy log std Min           -3.4779139
Z mean eval                  4.2314615
Z variance eval              0.007068701
total_rewards                [11912.45304449 12590.75654015 12443.71988065 12548.99545677
 11787.45454798 11549.25507585 12187.07548573 11870.71319757
 12265.96350511 11768.34651768]
total_rewards_mean           12092.473325197807
total_rewards_std            345.52666132236544
total_rewards_max            12590.756540150105
total_rewards_min            11549.255075849685
Number of train steps total  1988000
Number of env steps total    2487000
Number of rollouts total     0
Train Time (s)               141.37019699485973
(Previous) Eval Time (s)     29.774187277071178
Sample Time (s)              22.94412526860833
Epoch Time (s)               194.08850954053923
Total Train Time (s)         91809.47985143913
Epoch                        496
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:17:54.628382 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #496 | Epoch Duration: 193.62398314476013
2020-01-14 06:17:54.628570 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #496 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2304153
Z variance train             0.007072815
KL Divergence                75.31446
KL Loss                      7.531446
QF Loss                      579.64026
VF Loss                      145.45348
Policy Loss                  -5153.0483
Q Predictions Mean           5159.8867
Q Predictions Std            605.9976
Q Predictions Max            5848.6733
Q Predictions Min            3517.5217
V Predictions Mean           5151.6846
V Predictions Std            605.35364
V Predictions Max            5837.342
V Predictions Min            3489.343
Log Pis Mean                 6.5530376
Log Pis Std                  4.2029953
Log Pis Max                  17.217484
Log Pis Min                  -5.767745
Policy mu Mean               0.0025556546
Policy mu Std                1.534357
Policy mu Max                2.9651177
Policy mu Min                -2.8235316
Policy log std Mean          -0.90490586
Policy log std Std           0.51314276
Policy log std Max           -0.1775279
Policy log std Min           -3.9413025
Z mean eval                  4.2434225
Z variance eval              0.018260773
total_rewards                [12452.09974239 12800.10521441 13030.97738971 13103.90092168
 12617.91322714 13050.09948267 13083.03360203 13035.53659136
 13007.84453843 12926.71794695]
total_rewards_mean           12910.82286567712
total_rewards_std            208.43979695956398
total_rewards_max            13103.900921682072
total_rewards_min            12452.099742389717
Number of train steps total  1992000
Number of env steps total    2492000
Number of rollouts total     0
Train Time (s)               133.70292914425954
(Previous) Eval Time (s)     29.30929114529863
Sample Time (s)              22.135198193602264
Epoch Time (s)               185.14741848316044
Total Train Time (s)         91993.87428697618
Epoch                        497
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:20:59.027831 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #497 | Epoch Duration: 184.39912390708923
2020-01-14 06:20:59.028019 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #497 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2445755
Z variance train             0.018372275
KL Divergence                73.24265
KL Loss                      7.3242655
QF Loss                      843.50964
VF Loss                      281.77722
Policy Loss                  -5133.406
Q Predictions Mean           5136.7305
Q Predictions Std            678.4951
Q Predictions Max            5822.685
Q Predictions Min            708.07745
V Predictions Mean           5120.415
V Predictions Std            676.3052
V Predictions Max            5804.174
V Predictions Min            676.6111
Log Pis Mean                 6.1746244
Log Pis Std                  3.5722656
Log Pis Max                  16.547836
Log Pis Min                  -4.5393424
Policy mu Mean               -0.03150115
Policy mu Std                1.4587014
Policy mu Max                3.1326203
Policy mu Min                -2.9101884
Policy log std Mean          -0.9477956
Policy log std Std           0.5332606
Policy log std Max           -0.09625244
Policy log std Min           -3.7498024
Z mean eval                  4.2811365
Z variance eval              0.013541187
total_rewards                [12314.21764277 12467.75956081 12559.85080318 12527.25856972
 12602.65999463 12407.40296225 12458.07908206 12933.07343788
 12384.22767779 12597.45134481]
total_rewards_mean           12525.198107590133
total_rewards_std            162.74319624255895
total_rewards_max            12933.073437882571
total_rewards_min            12314.217642774593
Number of train steps total  1996000
Number of env steps total    2497000
Number of rollouts total     0
Train Time (s)               133.61011240212247
(Previous) Eval Time (s)     28.560640908312052
Sample Time (s)              22.345881529152393
Epoch Time (s)               184.5166348395869
Total Train Time (s)         92178.26892373059
Epoch                        498
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:24:03.428610 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #498 | Epoch Duration: 184.40043759346008
2020-01-14 06:24:03.428858 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #498 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2801824
Z variance train             0.013545404
KL Divergence                74.99938
KL Loss                      7.4999385
QF Loss                      592.9426
VF Loss                      250.02487
Policy Loss                  -5161.6836
Q Predictions Mean           5170.95
Q Predictions Std            648.7255
Q Predictions Max            5925.178
Q Predictions Min            3425.104
V Predictions Mean           5173.0024
V Predictions Std            649.335
V Predictions Max            5932.5815
V Predictions Min            3429.4602
Log Pis Mean                 6.6180096
Log Pis Std                  4.2472167
Log Pis Max                  33.956215
Log Pis Min                  -4.1009464
Policy mu Mean               -0.053864878
Policy mu Std                1.509355
Policy mu Max                6.7602687
Policy mu Min                -9.5717325
Policy log std Mean          -0.9233591
Policy log std Std           0.5112926
Policy log std Max           1.3200626
Policy log std Min           -3.5219154
Z mean eval                  4.2204585
Z variance eval              0.00895806
total_rewards                [12596.83875747 12630.06127731 12699.58372617 12677.0197196
 12553.51660048 12811.22420333 12628.8424332  12984.17891951
 12752.8108823  12711.2663278 ]
total_rewards_mean           12704.534284717372
total_rewards_std            117.65267649471173
total_rewards_max            12984.178919511141
total_rewards_min            12553.516600478868
Number of train steps total  2000000
Number of env steps total    2502000
Number of rollouts total     0
Train Time (s)               138.8483591452241
(Previous) Eval Time (s)     28.444081495981663
Sample Time (s)              22.18843982834369
Epoch Time (s)               189.48088046954945
Total Train Time (s)         92367.98186051939
Epoch                        499
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:27:13.146181 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #499 | Epoch Duration: 189.7171573638916
2020-01-14 06:27:13.146378 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #499 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.220423
Z variance train             0.008952331
KL Divergence                75.59494
KL Loss                      7.559494
QF Loss                      840.8542
VF Loss                      238.53085
Policy Loss                  -5161.238
Q Predictions Mean           5170.67
Q Predictions Std            613.4431
Q Predictions Max            5864.216
Q Predictions Min            3388.2744
V Predictions Mean           5170.326
V Predictions Std            614.54565
V Predictions Max            5878.363
V Predictions Min            3402.5352
Log Pis Mean                 6.83144
Log Pis Std                  4.207512
Log Pis Max                  17.039145
Log Pis Min                  -10.849296
Policy mu Mean               -0.071769215
Policy mu Std                1.5260392
Policy mu Max                3.007333
Policy mu Min                -2.837709
Policy log std Mean          -0.9451589
Policy log std Std           0.54823154
Policy log std Max           -0.28950298
Policy log std Min           -3.5698345
Z mean eval                  4.207641
Z variance eval              0.017313866
total_rewards                [12426.44102176 12592.28701947 12760.03619828 12605.42527106
 12894.17585466 12691.03948511 12882.81018966 12278.18400324
 12894.19445919 12815.30094527]
total_rewards_mean           12683.989444768886
total_rewards_std            199.138292727821
total_rewards_max            12894.194459186854
total_rewards_min            12278.184003238866
Number of train steps total  2004000
Number of env steps total    2507000
Number of rollouts total     0
Train Time (s)               143.0952707780525
(Previous) Eval Time (s)     28.68003739370033
Sample Time (s)              23.718954638577998
Epoch Time (s)               195.49426281033084
Total Train Time (s)         92563.77832520893
Epoch                        500
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:30:28.947978 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #500 | Epoch Duration: 195.8014371395111
2020-01-14 06:30:28.948263 UTC | [2020_01_11_13_32_55] [2020_01_13_04_47_43] Iteration #500 | Started Training: True
