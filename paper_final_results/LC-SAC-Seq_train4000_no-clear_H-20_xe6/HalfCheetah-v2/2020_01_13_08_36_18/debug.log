---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0012457505
Z variance train             0.69295514
KL Divergence                0.14937219
KL Loss                      0.014937219
QF Loss                      30.614424
VF Loss                      16.36408
Policy Loss                  -4.0074687
Q Predictions Mean           -0.003765408
Q Predictions Std            0.0021504015
Q Predictions Max            0.0019707258
Q Predictions Min            -0.008826294
V Predictions Mean           -0.0035245663
V Predictions Std            0.0012763198
V Predictions Max            -0.00020867772
V Predictions Min            -0.0075911563
Log Pis Mean                 -4.0296206
Log Pis Std                  0.5254945
Log Pis Max                  -2.448501
Log Pis Min                  -5.336877
Policy mu Mean               0.0010540453
Policy mu Std                0.0016826743
Policy mu Max                0.007478892
Policy mu Min                -0.0022162735
Policy log std Mean          0.00048335767
Policy log std Std           0.0009788934
Policy log std Max           0.0032959678
Policy log std Min           -0.0020309421
Z mean eval                  0.628561
Z variance eval              0.027482351
total_rewards                [-282.83767511 -290.29498025 -288.35996893 -299.71675192 -285.40588017
 -278.82270476 -273.90804956 -300.54071864 -281.29473746 -258.75060161]
total_rewards_mean           -283.9932068408397
total_rewards_std            11.645072865733463
total_rewards_max            -258.7506016077926
total_rewards_min            -300.5407186433345
Number of train steps total  4000
Number of env steps total    7000
Number of rollouts total     0
Train Time (s)               110.21506367065012
(Previous) Eval Time (s)     0
Sample Time (s)              22.93132338160649
Epoch Time (s)               133.1463870522566
Total Train Time (s)         156.46919088065624
Epoch                        0
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:38:55.358323 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #0 | Epoch Duration: 156.47420167922974
2020-01-13 08:38:55.358612 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #0 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.61568946
Z variance train             0.028527137
KL Divergence                7.506925
KL Loss                      0.75069255
QF Loss                      178.4768
VF Loss                      91.35954
Policy Loss                  -66.59576
Q Predictions Mean           63.76955
Q Predictions Std            20.55064
Q Predictions Max            113.28124
Q Predictions Min            7.455209
V Predictions Mean           72.24949
V Predictions Std            20.661192
V Predictions Max            115.14223
V Predictions Min            14.871356
Log Pis Mean                 -0.9560207
Log Pis Std                  2.5059512
Log Pis Max                  5.9273434
Log Pis Min                  -6.7857504
Policy mu Mean               -0.12984331
Policy mu Std                0.86047906
Policy mu Max                2.0160275
Policy mu Min                -2.642189
Policy log std Mean          -0.31558552
Policy log std Std           0.1337712
Policy log std Max           -0.059776537
Policy log std Min           -0.76984066
Z mean eval                  0.9986416
Z variance eval              0.027677152
total_rewards                [-302.34043717 -406.83261832 -406.99721955 -438.6178349  -337.54477525
 -346.92335863 -403.27890917 -400.42785756 -350.16679193 -381.32558426]
total_rewards_mean           -377.44553867350487
total_rewards_std            39.494477559200064
total_rewards_max            -302.34043716836163
total_rewards_min            -438.61783490208524
Number of train steps total  8000
Number of env steps total    12000
Number of rollouts total     0
Train Time (s)               112.72498171590269
(Previous) Eval Time (s)     23.327456586062908
Sample Time (s)              16.034958101343364
Epoch Time (s)               152.08739640330896
Total Train Time (s)         307.9255045093596
Epoch                        1
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:41:26.813005 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #1 | Epoch Duration: 151.45419478416443
2020-01-13 08:41:26.813158 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #1 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99792844
Z variance train             0.027689924
KL Divergence                9.329681
KL Loss                      0.93296814
QF Loss                      231.60794
VF Loss                      28.55466
Policy Loss                  -129.86415
Q Predictions Mean           123.91619
Q Predictions Std            20.540236
Q Predictions Max            208.16814
Q Predictions Min            47.61658
V Predictions Mean           128.9472
V Predictions Std            20.453411
V Predictions Max            210.2953
V Predictions Min            64.103386
Log Pis Mean                 -1.7842556
Log Pis Std                  2.047518
Log Pis Max                  4.4983897
Log Pis Min                  -9.7208
Policy mu Mean               -0.079125896
Policy mu Std                0.73489505
Policy mu Max                1.9243048
Policy mu Min                -2.261077
Policy log std Mean          -0.27527812
Policy log std Std           0.12119935
Policy log std Max           0.061163895
Policy log std Min           -0.7404426
Z mean eval                  1.352073
Z variance eval              0.018047396
total_rewards                [  -5.29420221 -156.48259271 -134.03712234   -1.63598733 -108.16507388
   94.23408969  -83.30645074  -20.57297564 -163.94716736 -220.2607476 ]
total_rewards_mean           -79.94682301139532
total_rewards_std            90.50134886623094
total_rewards_max            94.23408969189995
total_rewards_min            -220.2607475972802
Number of train steps total  12000
Number of env steps total    17000
Number of rollouts total     0
Train Time (s)               115.22349850274622
(Previous) Eval Time (s)     22.69395993789658
Sample Time (s)              16.82628980698064
Epoch Time (s)               154.74374824762344
Total Train Time (s)         462.764694434125
Epoch                        2
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:44:01.654066 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #2 | Epoch Duration: 154.84076356887817
2020-01-13 08:44:01.654316 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #2 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3512412
Z variance train             0.018025516
KL Divergence                12.646511
KL Loss                      1.2646512
QF Loss                      65.69432
VF Loss                      13.53095
Policy Loss                  -169.8218
Q Predictions Mean           167.72607
Q Predictions Std            42.624184
Q Predictions Max            315.1617
Q Predictions Min            104.69985
V Predictions Mean           170.32433
V Predictions Std            42.162556
V Predictions Max            314.13495
V Predictions Min            110.571175
Log Pis Mean                 -2.3928812
Log Pis Std                  1.9543785
Log Pis Max                  4.890258
Log Pis Min                  -7.4958344
Policy mu Mean               -0.13078327
Policy mu Std                0.6014988
Policy mu Max                1.8279668
Policy mu Min                -1.6683878
Policy log std Mean          -0.29952264
Policy log std Std           0.14448848
Policy log std Max           0.07742707
Policy log std Min           -0.94793475
Z mean eval                  1.5462358
Z variance eval              0.009479667
total_rewards                [1.04357422e+02 8.29185157e+02 2.04116706e+02 8.85620906e+02
 7.19014577e+02 8.45949757e+02 2.66373840e+02 1.16096788e+03
 7.38484213e+02 3.74814194e-01]
total_rewards_mean           575.4445270754835
total_rewards_std            375.47782128232166
total_rewards_max            1160.967879143385
total_rewards_min            0.37481419360368085
Number of train steps total  16000
Number of env steps total    22000
Number of rollouts total     0
Train Time (s)               110.8962363009341
(Previous) Eval Time (s)     22.79065038310364
Sample Time (s)              15.901511052623391
Epoch Time (s)               149.58839773666114
Total Train Time (s)         612.4083675486036
Epoch                        3
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:46:31.299151 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #3 | Epoch Duration: 149.64465761184692
2020-01-13 08:46:31.299370 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #3 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5487229
Z variance train             0.009477184
KL Divergence                15.452665
KL Loss                      1.5452665
QF Loss                      67.18808
VF Loss                      19.785416
Policy Loss                  -221.34027
Q Predictions Mean           220.15317
Q Predictions Std            79.47603
Q Predictions Max            387.4206
Q Predictions Min            108.2124
V Predictions Mean           219.7443
V Predictions Std            78.42544
V Predictions Max            389.1361
V Predictions Min            109.648636
Log Pis Mean                 -1.9174757
Log Pis Std                  2.1933498
Log Pis Max                  5.835287
Log Pis Min                  -7.962221
Policy mu Mean               -0.042990208
Policy mu Std                0.6651067
Policy mu Max                2.0532029
Policy mu Min                -2.0324678
Policy log std Mean          -0.35423145
Policy log std Std           0.18612057
Policy log std Max           0.09108853
Policy log std Min           -1.0839621
Z mean eval                  1.745553
Z variance eval              0.005873815
total_rewards                [1857.15735346 1714.53801862 1845.66297244 1797.54780839 1919.82797648
 1794.05287376 1698.76153223 1839.35469355 1649.08034692 1799.90481242]
total_rewards_mean           1791.5888388284504
total_rewards_std            78.0533404491577
total_rewards_max            1919.827976480664
total_rewards_min            1649.0803469195046
Number of train steps total  20000
Number of env steps total    27000
Number of rollouts total     0
Train Time (s)               113.8979875901714
(Previous) Eval Time (s)     22.84663489414379
Sample Time (s)              16.03130231006071
Epoch Time (s)               152.7759247943759
Total Train Time (s)         764.5886086737737
Epoch                        4
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:49:03.479198 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #4 | Epoch Duration: 152.17967128753662
2020-01-13 08:49:03.479353 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #4 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7473576
Z variance train             0.0059068655
KL Divergence                18.712698
KL Loss                      1.8712698
QF Loss                      81.29608
VF Loss                      21.226429
Policy Loss                  -282.77008
Q Predictions Mean           281.492
Q Predictions Std            114.028465
Q Predictions Max            489.03992
Q Predictions Min            126.96365
V Predictions Mean           283.18365
V Predictions Std            114.066284
V Predictions Max            493.8458
V Predictions Min            133.20044
Log Pis Mean                 -1.4046888
Log Pis Std                  2.4597247
Log Pis Max                  6.5841284
Log Pis Min                  -8.596814
Policy mu Mean               0.012249689
Policy mu Std                0.7089112
Policy mu Max                2.2666492
Policy mu Min                -2.1316712
Policy log std Mean          -0.3894161
Policy log std Std           0.20671816
Policy log std Max           0.039595738
Policy log std Min           -1.2511321
Z mean eval                  1.9102243
Z variance eval              0.0045891325
total_rewards                [2468.12928414 2380.89856258 2331.94889278 2443.38615637 2509.31682747
 2336.45320217 2371.76987537 2382.90445239 2528.11959371 2244.455962  ]
total_rewards_mean           2399.7382808974744
total_rewards_std            83.18968149680059
total_rewards_max            2528.119593708687
total_rewards_min            2244.455961998926
Number of train steps total  24000
Number of env steps total    32000
Number of rollouts total     0
Train Time (s)               115.1550712082535
(Previous) Eval Time (s)     22.250103851314634
Sample Time (s)              16.224637099541724
Epoch Time (s)               153.62981215910986
Total Train Time (s)         919.1265194048174
Epoch                        5
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:51:38.018136 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #5 | Epoch Duration: 154.53866457939148
2020-01-13 08:51:38.018333 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #5 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9107635
Z variance train             0.004586278
KL Divergence                20.624924
KL Loss                      2.0624924
QF Loss                      123.52498
VF Loss                      31.828794
Policy Loss                  -387.9629
Q Predictions Mean           382.90344
Q Predictions Std            157.96204
Q Predictions Max            626.8578
Q Predictions Min            134.73064
V Predictions Mean           384.8045
V Predictions Std            155.61346
V Predictions Max            622.63904
V Predictions Min            144.9738
Log Pis Mean                 -1.0381448
Log Pis Std                  2.6682339
Log Pis Max                  7.850091
Log Pis Min                  -6.667865
Policy mu Mean               0.009502257
Policy mu Std                0.78162557
Policy mu Max                2.3151317
Policy mu Min                -2.4185295
Policy log std Mean          -0.43612465
Policy log std Std           0.21884194
Policy log std Max           0.031076074
Policy log std Min           -1.3481383
Z mean eval                  2.0359802
Z variance eval              0.01664384
total_rewards                [2719.14271542 2917.2033017  2730.75649807 2820.12631663 2792.9247871
 2969.21335084 2956.01755633 2660.11076111 2942.25774435 2830.0372841 ]
total_rewards_mean           2833.7790315645225
total_rewards_std            103.82543710035941
total_rewards_max            2969.21335084046
total_rewards_min            2660.1107611053326
Number of train steps total  28000
Number of env steps total    37000
Number of rollouts total     0
Train Time (s)               114.91340536810458
(Previous) Eval Time (s)     23.158654887694865
Sample Time (s)              16.04918751725927
Epoch Time (s)               154.1212477730587
Total Train Time (s)         1073.4347090842202
Epoch                        6
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:54:12.327141 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #6 | Epoch Duration: 154.30867218971252
2020-01-13 08:54:12.327338 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #6 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0336952
Z variance train             0.016701246
KL Divergence                19.950933
KL Loss                      1.9950933
QF Loss                      136.25708
VF Loss                      65.81027
Policy Loss                  -453.71738
Q Predictions Mean           446.81158
Q Predictions Std            196.09023
Q Predictions Max            761.3243
Q Predictions Min            135.49709
V Predictions Mean           447.89954
V Predictions Std            193.4754
V Predictions Max            747.9191
V Predictions Min            140.80939
Log Pis Mean                 -0.8918572
Log Pis Std                  2.721726
Log Pis Max                  9.734151
Log Pis Min                  -6.7928967
Policy mu Mean               -0.019431265
Policy mu Std                0.77395827
Policy mu Max                2.3524032
Policy mu Min                -2.117918
Policy log std Mean          -0.4843755
Policy log std Std           0.24199
Policy log std Max           0.13079198
Policy log std Min           -1.6417655
Z mean eval                  2.2100582
Z variance eval              0.0075418567
total_rewards                [3151.57828294 3241.32545481 3382.57761737 3431.30420083 3503.40524302
 3353.73553926 3422.46849557 3353.31014662 3515.93891539 3346.91463218]
total_rewards_mean           3370.2558527997403
total_rewards_std            105.40636554133202
total_rewards_max            3515.938915389279
total_rewards_min            3151.578282944603
Number of train steps total  32000
Number of env steps total    42000
Number of rollouts total     0
Train Time (s)               113.95658383984119
(Previous) Eval Time (s)     23.345778845716268
Sample Time (s)              16.107747976202518
Epoch Time (s)               153.41011066175997
Total Train Time (s)         1226.3589313724078
Epoch                        7
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:56:45.254256 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #7 | Epoch Duration: 152.92677688598633
2020-01-13 08:56:45.254437 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #7 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.21005
Z variance train             0.0075446805
KL Divergence                23.19463
KL Loss                      2.319463
QF Loss                      147.64453
VF Loss                      41.245598
Policy Loss                  -569.87616
Q Predictions Mean           565.13226
Q Predictions Std            251.48866
Q Predictions Max            954.66144
Q Predictions Min            158.21219
V Predictions Mean           568.6189
V Predictions Std            248.75885
V Predictions Max            933.09656
V Predictions Min            155.3033
Log Pis Mean                 -0.5360782
Log Pis Std                  3.091602
Log Pis Max                  12.133513
Log Pis Min                  -8.334568
Policy mu Mean               0.043735627
Policy mu Std                0.8684841
Policy mu Max                2.8035772
Policy mu Min                -2.253933
Policy log std Mean          -0.5132446
Policy log std Std           0.24622673
Policy log std Max           0.015334114
Policy log std Min           -1.5874217
Z mean eval                  2.3629317
Z variance eval              0.006886994
total_rewards                [3594.32537675 3795.15757598 3494.79395019 3931.25831927 3421.38713452
 3751.49006873 3754.47476048 3702.41544822 3752.41916563 3895.32665373]
total_rewards_mean           3709.3048453502793
total_rewards_std            154.62735281834702
total_rewards_max            3931.2583192731086
total_rewards_min            3421.3871345239927
Number of train steps total  36000
Number of env steps total    47000
Number of rollouts total     0
Train Time (s)               113.90841681975871
(Previous) Eval Time (s)     22.862104720901698
Sample Time (s)              16.911021458450705
Epoch Time (s)               153.68154299911112
Total Train Time (s)         1379.6716608200222
Epoch                        8
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:59:18.567652 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #8 | Epoch Duration: 153.31305599212646
2020-01-13 08:59:18.568028 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #8 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3656452
Z variance train             0.0068819523
KL Divergence                25.292015
KL Loss                      2.5292015
QF Loss                      185.92572
VF Loss                      139.9944
Policy Loss                  -702.0062
Q Predictions Mean           692.3939
Q Predictions Std            286.06174
Q Predictions Max            1095.758
Q Predictions Min            181.33258
V Predictions Mean           692.11523
V Predictions Std            282.3599
V Predictions Max            1075.938
V Predictions Min            185.51343
Log Pis Mean                 0.22556522
Log Pis Std                  3.1298044
Log Pis Max                  12.58712
Log Pis Min                  -8.339167
Policy mu Mean               -0.012579516
Policy mu Std                0.93578374
Policy mu Max                2.6190236
Policy mu Min                -2.418634
Policy log std Mean          -0.54409164
Policy log std Std           0.25289547
Policy log std Max           0.16135123
Policy log std Min           -1.750263
Z mean eval                  2.4910617
Z variance eval              0.008008067
total_rewards                [3879.74907573 4015.19282022 3827.8469857  4132.09878097 3876.96494965
 3826.19526649 3893.62884471 4000.07590816 4165.95458462 4024.14263897]
total_rewards_mean           3964.184985522963
total_rewards_std            115.64386314925223
total_rewards_max            4165.954584621495
total_rewards_min            3826.195266487261
Number of train steps total  40000
Number of env steps total    52000
Number of rollouts total     0
Train Time (s)               114.14174756687135
(Previous) Eval Time (s)     22.493319396860898
Sample Time (s)              15.80332974717021
Epoch Time (s)               152.43839671090245
Total Train Time (s)         1532.0933290817775
Epoch                        9
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:01:50.988868 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #9 | Epoch Duration: 152.42055916786194
2020-01-13 09:01:50.989025 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #9 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4893162
Z variance train             0.007983432
KL Divergence                27.931353
KL Loss                      2.7931354
QF Loss                      225.785
VF Loss                      69.90759
Policy Loss                  -822.58685
Q Predictions Mean           818.7708
Q Predictions Std            316.1376
Q Predictions Max            1257.152
Q Predictions Min            215.90018
V Predictions Mean           822.5707
V Predictions Std            314.54172
V Predictions Max            1268.7821
V Predictions Min            217.84149
Log Pis Mean                 0.5887064
Log Pis Std                  3.3710744
Log Pis Max                  11.317989
Log Pis Min                  -6.014797
Policy mu Mean               0.012342806
Policy mu Std                0.958221
Policy mu Max                3.055008
Policy mu Min                -2.4398522
Policy log std Mean          -0.5638519
Policy log std Std           0.2669496
Policy log std Max           0.022259116
Policy log std Min           -1.9485407
Z mean eval                  2.5841775
Z variance eval              0.011292124
total_rewards                [3932.32230598 3961.92927781 4089.09974364 4229.64475362 2899.27099211
 4122.76705071 4014.67121934 1315.43011475 4155.65796014 1297.53756468]
total_rewards_mean           3401.8330982806015
total_rewards_std            1106.7975483375694
total_rewards_max            4229.644753623327
total_rewards_min            1297.5375646821826
Number of train steps total  44000
Number of env steps total    57000
Number of rollouts total     0
Train Time (s)               113.46746774762869
(Previous) Eval Time (s)     22.475203794892877
Sample Time (s)              15.668891204986721
Epoch Time (s)               151.6115627475083
Total Train Time (s)         1683.4392182100564
Epoch                        10
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:04:22.336688 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #10 | Epoch Duration: 151.34753489494324
2020-01-13 09:04:22.336897 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #10 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5851238
Z variance train             0.011323895
KL Divergence                28.692623
KL Loss                      2.8692625
QF Loss                      212.95657
VF Loss                      86.12039
Policy Loss                  -936.6323
Q Predictions Mean           932.6178
Q Predictions Std            315.03595
Q Predictions Max            1366.4398
Q Predictions Min            218.67238
V Predictions Mean           934.64075
V Predictions Std            308.8193
V Predictions Max            1355.3606
V Predictions Min            233.92177
Log Pis Mean                 0.7968751
Log Pis Std                  3.2793646
Log Pis Max                  13.367478
Log Pis Min                  -6.2733054
Policy mu Mean               -0.008932165
Policy mu Std                1.0100248
Policy mu Max                2.6883821
Policy mu Min                -2.512717
Policy log std Mean          -0.58778065
Policy log std Std           0.24613313
Policy log std Max           0.11237344
Policy log std Min           -1.8369529
Z mean eval                  2.6603203
Z variance eval              0.004912203
total_rewards                [4170.56592456 4275.4715483   407.42104741 4423.78773341 4216.10583483
 4160.59748308 4453.3837282  4374.76530422 4382.78023001 4609.66843608]
total_rewards_mean           3947.4547270110606
total_rewards_std            1187.446935785901
total_rewards_max            4609.668436079662
total_rewards_min            407.4210474130184
Number of train steps total  48000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               109.17313935002312
(Previous) Eval Time (s)     22.210897183045745
Sample Time (s)              16.031351238954812
Epoch Time (s)               147.41538777202368
Total Train Time (s)         1832.2681331709027
Epoch                        11
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:06:51.165641 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #11 | Epoch Duration: 148.82859563827515
2020-01-13 09:06:51.165800 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #11 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.6593766
Z variance train             0.00491384
KL Divergence                30.781994
KL Loss                      3.0781994
QF Loss                      207.56815
VF Loss                      78.533424
Policy Loss                  -989.04346
Q Predictions Mean           982.5615
Q Predictions Std            392.63773
Q Predictions Max            1453.6288
Q Predictions Min            244.38855
V Predictions Mean           989.34875
V Predictions Std            389.9482
V Predictions Max            1459.927
V Predictions Min            260.82977
Log Pis Mean                 0.9378776
Log Pis Std                  3.4959834
Log Pis Max                  10.368065
Log Pis Min                  -5.6603527
Policy mu Mean               -0.03301247
Policy mu Std                1.0073929
Policy mu Max                2.5755355
Policy mu Min                -2.3752537
Policy log std Mean          -0.6135469
Policy log std Std           0.27561072
Policy log std Max           0.07370755
Policy log std Min           -2.1513438
Z mean eval                  2.7147038
Z variance eval              0.0016501329
total_rewards                [4521.46664688 4651.37278325 4518.45542763 4540.34341057 4384.72352148
 4702.97861461 4396.67108983 4409.09957424 4438.70551793 4499.38929783]
total_rewards_mean           4506.320588426521
total_rewards_std            101.05906871686011
total_rewards_max            4702.978614612975
total_rewards_min            4384.723521482551
Number of train steps total  52000
Number of env steps total    67000
Number of rollouts total     0
Train Time (s)               113.08734135283157
(Previous) Eval Time (s)     23.623825686983764
Sample Time (s)              16.65791191533208
Epoch Time (s)               153.36907895514742
Total Train Time (s)         1985.2628776109777
Epoch                        12
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:09:24.164278 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #12 | Epoch Duration: 152.99831533432007
2020-01-13 09:09:24.164578 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #12 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.7115176
Z variance train             0.0016508574
KL Divergence                32.58106
KL Loss                      3.258106
QF Loss                      309.4172
VF Loss                      76.3751
Policy Loss                  -1110.5791
Q Predictions Mean           1101.6858
Q Predictions Std            379.7665
Q Predictions Max            1568.3882
Q Predictions Min            251.17603
V Predictions Mean           1112.6033
V Predictions Std            374.62457
V Predictions Max            1571.7175
V Predictions Min            279.4167
Log Pis Mean                 1.6185632
Log Pis Std                  3.6092925
Log Pis Max                  13.179838
Log Pis Min                  -6.642151
Policy mu Mean               -0.03498357
Policy mu Std                1.0610904
Policy mu Max                2.815791
Policy mu Min                -2.8044095
Policy log std Mean          -0.62411326
Policy log std Std           0.2666135
Policy log std Max           0.06598106
Policy log std Min           -2.0132556
Z mean eval                  2.7420263
Z variance eval              0.0067500444
total_rewards                [4829.84128498 4777.30155403 4980.34769529 4911.72796549 4835.58456671
 4790.40215215 4777.06324264 4980.86053923 4727.87854095 4711.68551993]
total_rewards_mean           4832.269306140514
total_rewards_std            91.43141244854081
total_rewards_max            4980.860539225302
total_rewards_min            4711.685519934305
Number of train steps total  56000
Number of env steps total    72000
Number of rollouts total     0
Train Time (s)               114.04235506011173
(Previous) Eval Time (s)     23.252722263801843
Sample Time (s)              16.488664836622775
Epoch Time (s)               153.78374216053635
Total Train Time (s)         2139.5485926074907
Epoch                        13
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:11:58.451311 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #13 | Epoch Duration: 154.2865002155304
2020-01-13 09:11:58.451549 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #13 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.739912
Z variance train             0.0067570573
KL Divergence                32.20735
KL Loss                      3.2207353
QF Loss                      277.75253
VF Loss                      109.95351
Policy Loss                  -1180.1444
Q Predictions Mean           1172.6333
Q Predictions Std            377.4912
Q Predictions Max            1665.2825
Q Predictions Min            263.47418
V Predictions Mean           1182.4663
V Predictions Std            372.4897
V Predictions Max            1669.3057
V Predictions Min            271.10486
Log Pis Mean                 1.6712074
Log Pis Std                  3.5153196
Log Pis Max                  14.243598
Log Pis Min                  -5.511313
Policy mu Mean               -0.0191608
Policy mu Std                1.0503997
Policy mu Max                3.2566047
Policy mu Min                -2.7448692
Policy log std Mean          -0.6630574
Policy log std Std           0.29191297
Policy log std Max           -0.03182903
Policy log std Min           -2.2031786
Z mean eval                  2.797116
Z variance eval              0.0011441263
total_rewards                [4776.07997391 4837.40993692 4790.48368321 4844.30457941 4848.42901444
 4511.63574997 4822.23089606 4850.91222145 4669.70106346 4927.85946321]
total_rewards_mean           4787.904658202808
total_rewards_std            111.56773122386693
total_rewards_max            4927.8594632143795
total_rewards_min            4511.635749968187
Number of train steps total  60000
Number of env steps total    77000
Number of rollouts total     0
Train Time (s)               119.70245715789497
(Previous) Eval Time (s)     23.755166636779904
Sample Time (s)              16.742932680994272
Epoch Time (s)               160.20055647566915
Total Train Time (s)         2299.092315150425
Epoch                        14
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:14:37.994060 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #14 | Epoch Duration: 159.54234147071838
2020-01-13 09:14:37.994242 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #14 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.7966328
Z variance train             0.0011451382
KL Divergence                34.50976
KL Loss                      3.4509761
QF Loss                      319.3932
VF Loss                      108.25875
Policy Loss                  -1284.1654
Q Predictions Mean           1271.8296
Q Predictions Std            406.9619
Q Predictions Max            1763.7352
Q Predictions Min            290.53558
V Predictions Mean           1279.5514
V Predictions Std            398.63605
V Predictions Max            1735.9332
V Predictions Min            303.87286
Log Pis Mean                 1.7169232
Log Pis Std                  3.4634504
Log Pis Max                  10.51613
Log Pis Min                  -6.27448
Policy mu Mean               -0.06740414
Policy mu Std                1.0657493
Policy mu Max                2.9395423
Policy mu Min                -2.4258118
Policy log std Mean          -0.6791744
Policy log std Std           0.29076988
Policy log std Max           -0.06727578
Policy log std Min           -2.2145875
Z mean eval                  2.8211129
Z variance eval              0.0016053161
total_rewards                [5060.64882949 5011.20939317 5190.72917734 5133.87591318 4877.89124733
 5007.98774966 5033.37836722 5219.46539725 4873.95402895 4993.96901193]
total_rewards_mean           5040.310911550746
total_rewards_std            110.46814091657116
total_rewards_max            5219.465397248747
total_rewards_min            4873.954028950604
Number of train steps total  64000
Number of env steps total    82000
Number of rollouts total     0
Train Time (s)               111.22370905894786
(Previous) Eval Time (s)     23.096660749986768
Sample Time (s)              16.351071551907808
Epoch Time (s)               150.67144136084244
Total Train Time (s)         2448.9508382081985
Epoch                        15
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:17:07.854372 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #15 | Epoch Duration: 149.85998702049255
2020-01-13 09:17:07.854576 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #15 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.820313
Z variance train             0.0016056638
KL Divergence                35.075005
KL Loss                      3.5075004
QF Loss                      202.2244
VF Loss                      89.710396
Policy Loss                  -1417.5726
Q Predictions Mean           1418.1172
Q Predictions Std            376.16144
Q Predictions Max            1856.5171
Q Predictions Min            315.29562
V Predictions Mean           1423.6191
V Predictions Std            373.91492
V Predictions Max            1855.6464
V Predictions Min            330.5299
Log Pis Mean                 1.5748811
Log Pis Std                  3.2437508
Log Pis Max                  11.160758
Log Pis Min                  -8.5836735
Policy mu Mean               -0.034556095
Policy mu Std                1.057108
Policy mu Max                2.6295822
Policy mu Min                -2.3100877
Policy log std Mean          -0.6868275
Policy log std Std           0.31457034
Policy log std Max           -0.08496094
Policy log std Min           -2.211728
Z mean eval                  2.8481221
Z variance eval              0.0038331256
total_rewards                [5401.26262185 5325.14903902 5387.00577134 5540.10216867 5045.37190922
 5219.63601419 5212.67487934 5210.33905005 5420.8827668  5352.72651775]
total_rewards_mean           5311.515073821945
total_rewards_std            133.83983173880011
total_rewards_max            5540.102168665793
total_rewards_min            5045.371909219382
Number of train steps total  68000
Number of env steps total    87000
Number of rollouts total     0
Train Time (s)               111.5884022898972
(Previous) Eval Time (s)     22.28490922693163
Sample Time (s)              15.710140312090516
Epoch Time (s)               149.58345182891935
Total Train Time (s)         2599.162675632164
Epoch                        16
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:19:38.069105 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #16 | Epoch Duration: 150.21434235572815
2020-01-13 09:19:38.069395 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #16 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.8469844
Z variance train             0.0038243718
KL Divergence                34.674942
KL Loss                      3.4674942
QF Loss                      297.38394
VF Loss                      215.91458
Policy Loss                  -1458.243
Q Predictions Mean           1455.8086
Q Predictions Std            422.7178
Q Predictions Max            1941.162
Q Predictions Min            324.92392
V Predictions Mean           1464.0363
V Predictions Std            418.83316
V Predictions Max            1949.8694
V Predictions Min            334.8216
Log Pis Mean                 2.446762
Log Pis Std                  3.5659308
Log Pis Max                  12.161009
Log Pis Min                  -4.720646
Policy mu Mean               -0.08471286
Policy mu Std                1.126159
Policy mu Max                2.8908978
Policy mu Min                -2.5600197
Policy log std Mean          -0.6931605
Policy log std Std           0.32368702
Policy log std Max           0.12891808
Policy log std Min           -2.2563326
Z mean eval                  2.8818758
Z variance eval              0.0026495527
total_rewards                [5630.44047328 5710.0333353  5685.39805132 5496.34156822 5457.88471918
 5442.27455103 5263.15888352 5602.00128052 5645.97212858 5684.31994298]
total_rewards_mean           5561.782493394348
total_rewards_std            135.7311236920438
total_rewards_max            5710.033335303184
total_rewards_min            5263.15888352204
Number of train steps total  72000
Number of env steps total    92000
Number of rollouts total     0
Train Time (s)               117.27543929312378
(Previous) Eval Time (s)     22.915520214941353
Sample Time (s)              16.701160674914718
Epoch Time (s)               156.89212018297985
Total Train Time (s)         2755.564176379703
Epoch                        17
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:22:14.470609 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #17 | Epoch Duration: 156.4010009765625
2020-01-13 09:22:14.470810 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #17 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.8797407
Z variance train             0.002636795
KL Divergence                35.40076
KL Loss                      3.540076
QF Loss                      394.84595
VF Loss                      107.99864
Policy Loss                  -1490.662
Q Predictions Mean           1478.1667
Q Predictions Std            446.57587
Q Predictions Max            2000.9332
Q Predictions Min            308.02197
V Predictions Mean           1485.8516
V Predictions Std            439.8023
V Predictions Max            1994.7102
V Predictions Min            320.47308
Log Pis Mean                 2.088828
Log Pis Std                  3.7071812
Log Pis Max                  11.848766
Log Pis Min                  -7.4351015
Policy mu Mean               -0.059160005
Policy mu Std                1.1438326
Policy mu Max                2.8186445
Policy mu Min                -2.516161
Policy log std Mean          -0.69020766
Policy log std Std           0.3306695
Policy log std Max           0.014205158
Policy log std Min           -2.4285939
Z mean eval                  2.917715
Z variance eval              0.0019421529
total_rewards                [5459.22935101 5527.65340491 5618.40329076 5585.80793217 5210.99889393
 5505.54501437 5706.34940788 5469.8108328  5613.82716072 5524.74828755]
total_rewards_mean           5522.237357610262
total_rewards_std            126.2843011103276
total_rewards_max            5706.34940787949
total_rewards_min            5210.9988939322575
Number of train steps total  76000
Number of env steps total    97000
Number of rollouts total     0
Train Time (s)               113.07670788094401
(Previous) Eval Time (s)     22.424121217802167
Sample Time (s)              17.058353883679956
Epoch Time (s)               152.55918298242614
Total Train Time (s)         2908.2026102356613
Epoch                        18
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:24:47.110275 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #18 | Epoch Duration: 152.63929891586304
2020-01-13 09:24:47.110463 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #18 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.9160686
Z variance train             0.0019457698
KL Divergence                36.469597
KL Loss                      3.6469598
QF Loss                      241.86157
VF Loss                      79.32068
Policy Loss                  -1581.4052
Q Predictions Mean           1574.209
Q Predictions Std            457.3825
Q Predictions Max            2105.5989
Q Predictions Min            320.18304
V Predictions Mean           1581.9188
V Predictions Std            452.49344
V Predictions Max            2083.8823
V Predictions Min            338.36664
Log Pis Mean                 2.3831782
Log Pis Std                  4.0377784
Log Pis Max                  13.903695
Log Pis Min                  -7.360607
Policy mu Mean               -0.06594125
Policy mu Std                1.138969
Policy mu Max                2.9808815
Policy mu Min                -2.8465543
Policy log std Mean          -0.68876266
Policy log std Std           0.3248765
Policy log std Max           -0.046847403
Policy log std Min           -2.2528903
Z mean eval                  2.940349
Z variance eval              0.002769644
total_rewards                [6009.40233253 5560.73422756 5694.04482406 5747.59278142 5808.18147802
 5950.90890954 5932.70341041 5642.20144737 5768.15070316 5816.42290386]
total_rewards_mean           5793.034301793239
total_rewards_std            134.6181103970868
total_rewards_max            6009.402332525766
total_rewards_min            5560.734227556114
Number of train steps total  80000
Number of env steps total    102000
Number of rollouts total     0
Train Time (s)               111.17429330013692
(Previous) Eval Time (s)     22.503920347895473
Sample Time (s)              16.30650497134775
Epoch Time (s)               149.98471861938015
Total Train Time (s)         3058.297030130867
Epoch                        19
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:27:17.205439 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #19 | Epoch Duration: 150.09483885765076
2020-01-13 09:27:17.205644 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #19 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.9439838
Z variance train             0.0027667587
KL Divergence                37.455894
KL Loss                      3.7455895
QF Loss                      228.49098
VF Loss                      122.239204
Policy Loss                  -1646.0504
Q Predictions Mean           1641.7869
Q Predictions Std            497.14798
Q Predictions Max            2163.5706
Q Predictions Min            327.13052
V Predictions Mean           1638.9038
V Predictions Std            492.19955
V Predictions Max            2150.087
V Predictions Min            327.13977
Log Pis Mean                 2.4957294
Log Pis Std                  3.6633942
Log Pis Max                  12.3768
Log Pis Min                  -6.0116005
Policy mu Mean               -0.05762024
Policy mu Std                1.1360431
Policy mu Max                3.0090466
Policy mu Min                -2.7219417
Policy log std Mean          -0.7179368
Policy log std Std           0.33895478
Policy log std Max           -0.013176978
Policy log std Min           -2.45106
Z mean eval                  2.9692807
Z variance eval              0.0011275718
total_rewards                [5675.32174667 6157.45527639 6178.41828411 6049.64152087 6076.63221364
 6162.36705137 5983.67659652 6023.80841974 5789.05728174 6173.78497887]
total_rewards_mean           6027.016336992761
total_rewards_std            162.78008829778148
total_rewards_max            6178.41828410955
total_rewards_min            5675.321746668095
Number of train steps total  84000
Number of env steps total    107000
Number of rollouts total     0
Train Time (s)               115.74529556790367
(Previous) Eval Time (s)     22.6137089333497
Sample Time (s)              16.163176532369107
Epoch Time (s)               154.52218103362247
Total Train Time (s)         3213.0762766255066
Epoch                        20
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:29:51.985822 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #20 | Epoch Duration: 154.78002047538757
2020-01-13 09:29:51.986010 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #20 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.969176
Z variance train             0.0011287334
KL Divergence                38.2348
KL Loss                      3.82348
QF Loss                      317.11475
VF Loss                      81.19697
Policy Loss                  -1663.3143
Q Predictions Mean           1658.5007
Q Predictions Std            555.8115
Q Predictions Max            2225.8193
Q Predictions Min            325.46414
V Predictions Mean           1662.9115
V Predictions Std            548.30597
V Predictions Max            2233.9324
V Predictions Min            331.10464
Log Pis Mean                 2.9011493
Log Pis Std                  4.001638
Log Pis Max                  14.142928
Log Pis Min                  -8.72017
Policy mu Mean               -0.11319218
Policy mu Std                1.2046347
Policy mu Max                3.4105055
Policy mu Min                -2.7274957
Policy log std Mean          -0.6980953
Policy log std Std           0.3338756
Policy log std Max           0.026949883
Policy log std Min           -2.4231343
Z mean eval                  2.988315
Z variance eval              0.0027386225
total_rewards                [6224.83859335 6392.45408686 6160.53361561 6153.47824149 6076.30423194
 6337.5455483  6222.04856544 6290.13457468 6281.33686014 6278.56071449]
total_rewards_mean           6241.723503231663
total_rewards_std            89.21107886832847
total_rewards_max            6392.454086862964
total_rewards_min            6076.304231938882
Number of train steps total  88000
Number of env steps total    112000
Number of rollouts total     0
Train Time (s)               109.99875999707729
(Previous) Eval Time (s)     22.871245592366904
Sample Time (s)              16.401175576727837
Epoch Time (s)               149.27118116617203
Total Train Time (s)         3361.9804305890575
Epoch                        21
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:32:20.892771 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #21 | Epoch Duration: 148.90659141540527
2020-01-13 09:32:20.893037 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #21 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.9894419
Z variance train             0.0027386246
KL Divergence                38.362457
KL Loss                      3.8362458
QF Loss                      249.25484
VF Loss                      134.95813
Policy Loss                  -1739.1324
Q Predictions Mean           1733.6099
Q Predictions Std            543.0242
Q Predictions Max            2309.32
Q Predictions Min            342.33463
V Predictions Mean           1733.4324
V Predictions Std            539.1463
V Predictions Max            2295.229
V Predictions Min            352.94913
Log Pis Mean                 2.6848764
Log Pis Std                  3.7291672
Log Pis Max                  18.14968
Log Pis Min                  -7.2351723
Policy mu Mean               -0.07033208
Policy mu Std                1.1679295
Policy mu Max                3.828464
Policy mu Min                -2.8160489
Policy log std Mean          -0.7214196
Policy log std Std           0.36038738
Policy log std Max           0.028285503
Policy log std Min           -2.5503786
Z mean eval                  2.9539514
Z variance eval              0.08424366
total_rewards                [6124.72144014 6166.44681509 6062.84211921 6172.68398601 6063.47621807
 6281.85939884 6061.81344307 6114.69412121 5964.1229179  6124.18249322]
total_rewards_mean           6113.684295274628
total_rewards_std            80.58891470403452
total_rewards_max            6281.859398839102
total_rewards_min            5964.122917896567
Number of train steps total  92000
Number of env steps total    117000
Number of rollouts total     0
Train Time (s)               113.21690152678639
(Previous) Eval Time (s)     22.50635629799217
Sample Time (s)              15.91554286563769
Epoch Time (s)               151.63880069041625
Total Train Time (s)         3513.9074077480473
Epoch                        22
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:34:52.819526 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #22 | Epoch Duration: 151.92630124092102
2020-01-13 09:34:52.819731 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #22 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.9519114
Z variance train             0.08451943
KL Divergence                29.024452
KL Loss                      2.9024453
QF Loss                      322.30908
VF Loss                      141.77266
Policy Loss                  -1793.8896
Q Predictions Mean           1785.5422
Q Predictions Std            505.97632
Q Predictions Max            2311.997
Q Predictions Min            306.95187
V Predictions Mean           1799.751
V Predictions Std            497.20844
V Predictions Max            2317.7751
V Predictions Min            341.41827
Log Pis Mean                 2.6078124
Log Pis Std                  3.570827
Log Pis Max                  15.657003
Log Pis Min                  -4.9596915
Policy mu Mean               -0.14817348
Policy mu Std                1.1791874
Policy mu Max                3.3229613
Policy mu Min                -2.9160545
Policy log std Mean          -0.73899645
Policy log std Std           0.33831137
Policy log std Max           0.079631746
Policy log std Min           -2.2482176
Z mean eval                  3.042209
Z variance eval              0.018703828
total_rewards                [6281.52950396 6572.50585662 6428.85028375 6302.83932931 6479.0937376
 6468.15511002 6408.05078962 6140.46966415 6535.19803049 6615.82094551]
total_rewards_mean           6423.251325103558
total_rewards_std            138.50586968379363
total_rewards_max            6615.820945507521
total_rewards_min            6140.469664151648
Number of train steps total  96000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               103.43383543984964
(Previous) Eval Time (s)     22.793551311362535
Sample Time (s)              16.009874084498733
Epoch Time (s)               142.2372608357109
Total Train Time (s)         3656.1186977513134
Epoch                        23
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:37:15.034601 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #23 | Epoch Duration: 142.21468925476074
2020-01-13 09:37:15.034913 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #23 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0413842
Z variance train             0.018700836
KL Divergence                31.228462
KL Loss                      3.1228464
QF Loss                      328.75262
VF Loss                      282.2074
Policy Loss                  -1845.7037
Q Predictions Mean           1844.1597
Q Predictions Std            490.53848
Q Predictions Max            2357.6265
Q Predictions Min            365.60223
V Predictions Mean           1860.0413
V Predictions Std            486.9452
V Predictions Max            2370.1465
V Predictions Min            381.71353
Log Pis Mean                 3.1822777
Log Pis Std                  3.7566957
Log Pis Max                  15.333656
Log Pis Min                  -5.48773
Policy mu Mean               -0.08381573
Policy mu Std                1.2051256
Policy mu Max                3.4683678
Policy mu Min                -2.933063
Policy log std Mean          -0.7371152
Policy log std Std           0.3377837
Policy log std Max           0.010536134
Policy log std Min           -2.4133408
Z mean eval                  3.0449913
Z variance eval              0.03159382
total_rewards                [6320.79159688 6538.31605925 6621.91666066 6775.00551477 6483.90365186
 6328.21141332 6666.03607571 6638.2549586  6572.27559454 6622.95905594]
total_rewards_mean           6556.767058152896
total_rewards_std            137.34846285592243
total_rewards_max            6775.0055147714465
total_rewards_min            6320.791596883648
Number of train steps total  100000
Number of env steps total    127000
Number of rollouts total     0
Train Time (s)               112.13515253504738
(Previous) Eval Time (s)     22.770693704951555
Sample Time (s)              15.975464770570397
Epoch Time (s)               150.88131101056933
Total Train Time (s)         3807.0504746669903
Epoch                        24
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:39:45.966054 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #24 | Epoch Duration: 150.9309046268463
2020-01-13 09:39:45.966252 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #24 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0450187
Z variance train             0.03152943
KL Divergence                30.33129
KL Loss                      3.033129
QF Loss                      319.3366
VF Loss                      102.69345
Policy Loss                  -1874.3087
Q Predictions Mean           1869.2935
Q Predictions Std            545.30414
Q Predictions Max            2457.0107
Q Predictions Min            369.97144
V Predictions Mean           1875.9172
V Predictions Std            539.393
V Predictions Max            2447.0974
V Predictions Min            383.06656
Log Pis Mean                 3.1827922
Log Pis Std                  3.877088
Log Pis Max                  13.450172
Log Pis Min                  -6.404342
Policy mu Mean               -0.056112263
Policy mu Std                1.2200036
Policy mu Max                3.0835428
Policy mu Min                -2.6336553
Policy log std Mean          -0.7338991
Policy log std Std           0.34896323
Policy log std Max           -0.0017611384
Policy log std Min           -2.4599714
Z mean eval                  3.0978477
Z variance eval              0.010375765
total_rewards                [6514.26922526 6349.57898549 6627.85928174 6775.66759215 6394.09623733
 6602.30954009 6640.13199427 6547.86329115 6654.58739391 6670.24245154]
total_rewards_mean           6577.660599293669
total_rewards_std            123.02418336258613
total_rewards_max            6775.667592146787
total_rewards_min            6349.578985487615
Number of train steps total  104000
Number of env steps total    132000
Number of rollouts total     0
Train Time (s)               109.3278941148892
(Previous) Eval Time (s)     22.820015120320022
Sample Time (s)              16.268717131577432
Epoch Time (s)               148.41662636678666
Total Train Time (s)         3955.6629077317193
Epoch                        25
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:42:14.580355 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #25 | Epoch Duration: 148.6139416694641
2020-01-13 09:42:14.580590 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #25 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0959792
Z variance train             0.010386674
KL Divergence                33.490753
KL Loss                      3.3490753
QF Loss                      313.91376
VF Loss                      117.27118
Policy Loss                  -1967.6648
Q Predictions Mean           1962.053
Q Predictions Std            563.7295
Q Predictions Max            2591.8037
Q Predictions Min            420.00778
V Predictions Mean           1973.2997
V Predictions Std            555.6588
V Predictions Max            2581.79
V Predictions Min            430.21002
Log Pis Mean                 3.5288424
Log Pis Std                  3.5745943
Log Pis Max                  16.510845
Log Pis Min                  -6.253705
Policy mu Mean               -0.13335204
Policy mu Std                1.2451128
Policy mu Max                3.7972045
Policy mu Min                -3.0134785
Policy log std Mean          -0.75542575
Policy log std Std           0.3640507
Policy log std Max           -0.08970368
Policy log std Min           -2.5409417
Z mean eval                  3.1197486
Z variance eval              0.011012407
total_rewards                [6998.95761357 7299.84778709 6974.21290656 7002.05391211 6932.54608741
 7070.2276372  6941.70396779 6789.67594866 7017.44957387 6946.66350944]
total_rewards_mean           6997.3338943697045
total_rewards_std            122.78996200296774
total_rewards_max            7299.847787088058
total_rewards_min            6789.675948664673
Number of train steps total  108000
Number of env steps total    137000
Number of rollouts total     0
Train Time (s)               113.75808065896854
(Previous) Eval Time (s)     23.017017828766257
Sample Time (s)              16.430755404755473
Epoch Time (s)               153.20585389249027
Total Train Time (s)         4109.598257263191
Epoch                        26
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:44:48.516667 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #26 | Epoch Duration: 153.9359142780304
2020-01-13 09:44:48.516837 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #26 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.119968
Z variance train             0.011040112
KL Divergence                34.41523
KL Loss                      3.441523
QF Loss                      298.24823
VF Loss                      120.00716
Policy Loss                  -2094.4985
Q Predictions Mean           2100.7217
Q Predictions Std            508.65637
Q Predictions Max            2677.3867
Q Predictions Min            458.90558
V Predictions Mean           2100.9626
V Predictions Std            506.80188
V Predictions Max            2664.8232
V Predictions Min            452.45297
Log Pis Mean                 3.4195952
Log Pis Std                  3.8282175
Log Pis Max                  15.032516
Log Pis Min                  -7.5870123
Policy mu Mean               -0.09554892
Policy mu Std                1.2330188
Policy mu Max                2.735413
Policy mu Min                -3.0015302
Policy log std Mean          -0.76767236
Policy log std Std           0.38923863
Policy log std Max           0.0569669
Policy log std Min           -2.7215874
Z mean eval                  3.138002
Z variance eval              0.005245619
total_rewards                [7086.4870544  7081.39066741 7161.07525033 7154.2482926  6918.12998156
 7292.37079612 6853.98898416 6969.19030923 7104.99140106 6947.59380023]
total_rewards_mean           7056.946653710748
total_rewards_std            126.34652740656905
total_rewards_max            7292.370796122662
total_rewards_min            6853.98898416198
Number of train steps total  112000
Number of env steps total    142000
Number of rollouts total     0
Train Time (s)               118.68731584306806
(Previous) Eval Time (s)     23.746758680790663
Sample Time (s)              16.230451211333275
Epoch Time (s)               158.664525735192
Total Train Time (s)         4268.079735934269
Epoch                        27
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:47:26.998060 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #27 | Epoch Duration: 158.48108792304993
2020-01-13 09:47:26.998210 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #27 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1368222
Z variance train             0.005248281
KL Divergence                36.296867
KL Loss                      3.6296868
QF Loss                      337.81586
VF Loss                      132.49391
Policy Loss                  -2142.2598
Q Predictions Mean           2134.613
Q Predictions Std            516.9549
Q Predictions Max            2718.0159
Q Predictions Min            449.88455
V Predictions Mean           2137.6316
V Predictions Std            511.67856
V Predictions Max            2708.4187
V Predictions Min            442.40405
Log Pis Mean                 3.7565455
Log Pis Std                  3.7168505
Log Pis Max                  14.932155
Log Pis Min                  -6.8590436
Policy mu Mean               -0.11665151
Policy mu Std                1.2618433
Policy mu Max                2.9458475
Policy mu Min                -2.9971943
Policy log std Mean          -0.767945
Policy log std Std           0.37567616
Policy log std Max           -0.002103746
Policy log std Min           -2.584892
Z mean eval                  3.1650262
Z variance eval              0.0031769506
total_rewards                [7064.47194903 7350.06590917 7182.63375402 6892.11867367 7263.09074259
 7142.57086257 7172.11452588 7059.13766016 7101.76418664 6978.18639507]
total_rewards_mean           7120.61546588001
total_rewards_std            126.376810039707
total_rewards_max            7350.0659091671105
total_rewards_min            6892.11867366846
Number of train steps total  116000
Number of env steps total    147000
Number of rollouts total     0
Train Time (s)               113.61160814296454
(Previous) Eval Time (s)     23.563013947103173
Sample Time (s)              15.597603441681713
Epoch Time (s)               152.77222553174943
Total Train Time (s)         4420.032246865332
Epoch                        28
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:49:58.952745 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #28 | Epoch Duration: 151.95440912246704
2020-01-13 09:49:58.952938 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #28 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1648839
Z variance train             0.0031827814
KL Divergence                37.990612
KL Loss                      3.7990613
QF Loss                      264.81915
VF Loss                      94.37902
Policy Loss                  -2181.8354
Q Predictions Mean           2179.369
Q Predictions Std            540.3334
Q Predictions Max            2786.5535
Q Predictions Min            461.0005
V Predictions Mean           2186.4014
V Predictions Std            536.5416
V Predictions Max            2777.6338
V Predictions Min            465.4641
Log Pis Mean                 3.4995375
Log Pis Std                  3.5485554
Log Pis Max                  12.639671
Log Pis Min                  -3.554503
Policy mu Mean               -0.092625745
Policy mu Std                1.239193
Policy mu Max                3.5280297
Policy mu Min                -2.7334669
Policy log std Mean          -0.7682218
Policy log std Std           0.36670858
Policy log std Max           0.07655299
Policy log std Min           -2.6776989
Z mean eval                  3.171751
Z variance eval              0.0034182905
total_rewards                [6939.00743367 7018.85740678 7048.15924338 7190.41991761 7271.46392484
 6928.4843015  7162.66885805 6928.07413586 7342.57355923 7098.52551281]
total_rewards_mean           7092.823429371788
total_rewards_std            139.28331822932014
total_rewards_max            7342.573559229656
total_rewards_min            6928.07413585968
Number of train steps total  120000
Number of env steps total    152000
Number of rollouts total     0
Train Time (s)               105.83528647013009
(Previous) Eval Time (s)     22.744908796157688
Sample Time (s)              16.23722716839984
Epoch Time (s)               144.81742243468761
Total Train Time (s)         4564.409557573963
Epoch                        29
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:52:23.331545 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #29 | Epoch Duration: 144.37844896316528
2020-01-13 09:52:23.331776 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #29 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1731377
Z variance train             0.0034124055
KL Divergence                37.942543
KL Loss                      3.7942543
QF Loss                      240.16031
VF Loss                      59.312298
Policy Loss                  -2353.39
Q Predictions Mean           2354.2754
Q Predictions Std            468.65674
Q Predictions Max            2873.732
Q Predictions Min            478.0843
V Predictions Mean           2352.862
V Predictions Std            461.843
V Predictions Max            2861.9373
V Predictions Min            480.8297
Log Pis Mean                 3.6735225
Log Pis Std                  3.7696393
Log Pis Max                  13.114738
Log Pis Min                  -5.808177
Policy mu Mean               -0.15164824
Policy mu Std                1.2340255
Policy mu Max                3.2241673
Policy mu Min                -2.8932629
Policy log std Mean          -0.782768
Policy log std Std           0.375822
Policy log std Max           0.046737254
Policy log std Min           -2.4567404
Z mean eval                  3.1851358
Z variance eval              0.0032878376
total_rewards                [6796.59993614 6982.75199807 7137.94517552 7261.28233074 7172.30741878
 7029.62292924 7150.37807389 7459.10554291 7265.87693138 7113.45171165]
total_rewards_mean           7136.932204831208
total_rewards_std            169.99493604470894
total_rewards_max            7459.10554290928
total_rewards_min            6796.599936143459
Number of train steps total  124000
Number of env steps total    157000
Number of rollouts total     0
Train Time (s)               114.98555279709399
(Previous) Eval Time (s)     22.305622912943363
Sample Time (s)              15.738180537708104
Epoch Time (s)               153.02935624774545
Total Train Time (s)         4718.218229218852
Epoch                        30
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:54:57.140258 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #30 | Epoch Duration: 153.80829644203186
2020-01-13 09:54:57.140418 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #30 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1837573
Z variance train             0.0033002086
KL Divergence                38.50068
KL Loss                      3.8500679
QF Loss                      319.10583
VF Loss                      97.690346
Policy Loss                  -2323.2732
Q Predictions Mean           2317.8447
Q Predictions Std            544.64435
Q Predictions Max            2877.9702
Q Predictions Min            469.93683
V Predictions Mean           2320.6501
V Predictions Std            538.3944
V Predictions Max            2873.734
V Predictions Min            486.0086
Log Pis Mean                 3.5044463
Log Pis Std                  3.702463
Log Pis Max                  16.747555
Log Pis Min                  -7.005639
Policy mu Mean               -0.16627897
Policy mu Std                1.2368861
Policy mu Max                3.1910024
Policy mu Min                -2.910042
Policy log std Mean          -0.7732821
Policy log std Std           0.38434404
Policy log std Max           0.0045577884
Policy log std Min           -2.858089
Z mean eval                  3.1917021
Z variance eval              0.0054233223
total_rewards                [7340.29896853 7463.88560241 7446.71894359 7407.25705757 7546.50857505
 7407.51868991 7389.19054118 7383.77415311 7528.92135898 7386.55310704]
total_rewards_mean           7430.0626997379495
total_rewards_std            62.88576967328193
total_rewards_max            7546.508575052863
total_rewards_min            7340.298968531366
Number of train steps total  128000
Number of env steps total    162000
Number of rollouts total     0
Train Time (s)               118.8573523205705
(Previous) Eval Time (s)     23.084302621893585
Sample Time (s)              16.50225146720186
Epoch Time (s)               158.44390640966594
Total Train Time (s)         4876.235287742224
Epoch                        31
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:57:35.161802 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #31 | Epoch Duration: 158.0212185382843
2020-01-13 09:57:35.162094 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #31 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1935148
Z variance train             0.0053993515
KL Divergence                38.13127
KL Loss                      3.8131273
QF Loss                      276.1515
VF Loss                      105.253525
Policy Loss                  -2386.6797
Q Predictions Mean           2380.0527
Q Predictions Std            556.02826
Q Predictions Max            2982.3079
Q Predictions Min            504.03012
V Predictions Mean           2383.1553
V Predictions Std            552.7618
V Predictions Max            2982.5928
V Predictions Min            510.45547
Log Pis Mean                 4.6658983
Log Pis Std                  3.6191392
Log Pis Max                  14.3168125
Log Pis Min                  -3.5530653
Policy mu Mean               -0.130216
Policy mu Std                1.3404944
Policy mu Max                3.1936414
Policy mu Min                -3.302917
Policy log std Mean          -0.7915986
Policy log std Std           0.3858633
Policy log std Max           0.056728423
Policy log std Min           -2.7590108
Z mean eval                  3.2083638
Z variance eval              0.023823222
total_rewards                [7233.45053471 7530.38822644 7264.8425543  7299.21001263 7444.49239554
 7414.23581894 7398.97093193 7304.07329169 7159.08742589 7533.39916996]
total_rewards_mean           7358.2150362032
total_rewards_std            119.55148252229996
total_rewards_max            7533.3991699614635
total_rewards_min            7159.087425885804
Number of train steps total  132000
Number of env steps total    167000
Number of rollouts total     0
Train Time (s)               110.49742769310251
(Previous) Eval Time (s)     22.661297048907727
Sample Time (s)              16.454112232197076
Epoch Time (s)               149.6128369742073
Total Train Time (s)         5026.059207947925
Epoch                        32
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:00:04.986218 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #32 | Epoch Duration: 149.82388639450073
2020-01-13 10:00:04.986462 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #32 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2074342
Z variance train             0.024002941
KL Divergence                36.98029
KL Loss                      3.698029
QF Loss                      269.84805
VF Loss                      99.80007
Policy Loss                  -2383.254
Q Predictions Mean           2380.0378
Q Predictions Std            532.7151
Q Predictions Max            2952.7307
Q Predictions Min            519.86554
V Predictions Mean           2386.915
V Predictions Std            530.6114
V Predictions Max            2957.702
V Predictions Min            518.83185
Log Pis Mean                 3.6713288
Log Pis Std                  3.7784016
Log Pis Max                  12.557894
Log Pis Min                  -6.599111
Policy mu Mean               -0.11337825
Policy mu Std                1.2454667
Policy mu Max                2.8287365
Policy mu Min                -2.7624109
Policy log std Mean          -0.81247115
Policy log std Std           0.39085054
Policy log std Max           0.056197107
Policy log std Min           -2.7375894
Z mean eval                  3.2466874
Z variance eval              0.0039565274
total_rewards                [7119.07493257 7215.75730943 7239.89277708 7325.95222357 7236.71646599
 7340.68625732 7331.26872127 7321.38505567 7380.34054994 7267.28257793]
total_rewards_mean           7277.83568707654
total_rewards_std            73.36538955097811
total_rewards_max            7380.340549938624
total_rewards_min            7119.074932569856
Number of train steps total  136000
Number of env steps total    172000
Number of rollouts total     0
Train Time (s)               108.5492239492014
(Previous) Eval Time (s)     22.872059975750744
Sample Time (s)              15.707033664453775
Epoch Time (s)               147.12831758940592
Total Train Time (s)         5173.021993022412
Epoch                        33
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:02:31.950751 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #33 | Epoch Duration: 146.96407270431519
2020-01-13 10:02:31.951063 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #33 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2458744
Z variance train             0.003942961
KL Divergence                39.39332
KL Loss                      3.9393318
QF Loss                      312.54797
VF Loss                      130.45743
Policy Loss                  -2400.5461
Q Predictions Mean           2404.361
Q Predictions Std            564.9825
Q Predictions Max            3011.356
Q Predictions Min            555.31085
V Predictions Mean           2406.7021
V Predictions Std            556.9794
V Predictions Max            3013.002
V Predictions Min            574.6645
Log Pis Mean                 3.970552
Log Pis Std                  4.115163
Log Pis Max                  14.017586
Log Pis Min                  -5.6731997
Policy mu Mean               -0.08137108
Policy mu Std                1.2971243
Policy mu Max                3.7602806
Policy mu Min                -2.8274157
Policy log std Mean          -0.7920275
Policy log std Std           0.38798356
Policy log std Max           -0.060623407
Policy log std Min           -2.6855347
Z mean eval                  3.2524788
Z variance eval              0.0014559032
total_rewards                [7432.08240691 7347.68414492 7383.47009902 7325.06762953 7379.18002547
 7377.31502861 7356.52482187 5567.21703529 7336.86683767 7224.20167029]
total_rewards_mean           7172.960969957263
total_rewards_std            537.6810886285775
total_rewards_max            7432.082406910196
total_rewards_min            5567.2170352923185
Number of train steps total  140000
Number of env steps total    177000
Number of rollouts total     0
Train Time (s)               111.37160664005205
(Previous) Eval Time (s)     22.70751447370276
Sample Time (s)              16.023662752471864
Epoch Time (s)               150.10278386622667
Total Train Time (s)         5323.654938242398
Epoch                        34
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:05:02.586218 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #34 | Epoch Duration: 150.6348967552185
2020-01-13 10:05:02.586558 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #34 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.252105
Z variance train             0.0014514329
KL Divergence                41.85645
KL Loss                      4.185645
QF Loss                      225.03087
VF Loss                      79.62462
Policy Loss                  -2435.99
Q Predictions Mean           2432.5156
Q Predictions Std            568.7672
Q Predictions Max            3070.2576
Q Predictions Min            562.4124
V Predictions Mean           2432.3354
V Predictions Std            564.71967
V Predictions Max            3051.8987
V Predictions Min            563.5528
Log Pis Mean                 4.26917
Log Pis Std                  3.6459374
Log Pis Max                  12.732267
Log Pis Min                  -4.8419333
Policy mu Mean               -0.16571733
Policy mu Std                1.2632477
Policy mu Max                2.706558
Policy mu Min                -2.8591983
Policy log std Mean          -0.8120008
Policy log std Std           0.39650744
Policy log std Max           -0.01801759
Policy log std Min           -2.8218884
Z mean eval                  3.2722468
Z variance eval              0.0008889494
total_rewards                [7626.87659781 7829.04177391 7786.24353883 7913.84202656 7821.40841684
 7981.11862239 7766.93962981 7669.790862   7974.60256405 7618.60161263]
total_rewards_mean           7798.846564482694
total_rewards_std            125.9572125022765
total_rewards_max            7981.118622386927
total_rewards_min            7618.601612629597
Number of train steps total  144000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               115.82510420214385
(Previous) Eval Time (s)     23.239352982025594
Sample Time (s)              16.61785670556128
Epoch Time (s)               155.68231388973072
Total Train Time (s)         5478.49353460595
Epoch                        35
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:07:37.427424 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #35 | Epoch Duration: 154.84060740470886
2020-01-13 10:07:37.427718 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #35 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2729602
Z variance train             0.0008885636
KL Divergence                43.859993
KL Loss                      4.385999
QF Loss                      275.37384
VF Loss                      92.555244
Policy Loss                  -2522.5645
Q Predictions Mean           2516.771
Q Predictions Std            536.1308
Q Predictions Max            3107.4553
Q Predictions Min            562.6873
V Predictions Mean           2519.8452
V Predictions Std            529.8595
V Predictions Max            3090.1125
V Predictions Min            564.11816
Log Pis Mean                 4.216957
Log Pis Std                  3.598841
Log Pis Max                  13.91431
Log Pis Min                  -5.262604
Policy mu Mean               -0.10188543
Policy mu Std                1.2748665
Policy mu Max                2.8295007
Policy mu Min                -3.1415043
Policy log std Mean          -0.8129587
Policy log std Std           0.39117825
Policy log std Max           -0.10594213
Policy log std Min           -2.7573833
Z mean eval                  3.2628403
Z variance eval              0.0026333944
total_rewards                [7680.17186335 7821.71749621 7951.29767076 7573.14086621 7744.47119744
 7914.96591609 7957.9093202  7791.50093958 7936.62739548 7906.80029575]
total_rewards_mean           7827.860296107389
total_rewards_std            123.61475167670281
total_rewards_max            7957.909320203666
total_rewards_min            7573.140866210304
Number of train steps total  148000
Number of env steps total    187000
Number of rollouts total     0
Train Time (s)               112.08577079931274
(Previous) Eval Time (s)     22.397369297221303
Sample Time (s)              16.63449606159702
Epoch Time (s)               151.11763615813106
Total Train Time (s)         5629.808386695106
Epoch                        36
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:10:08.740472 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #36 | Epoch Duration: 151.31252217292786
2020-01-13 10:10:08.740624 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #36 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2644134
Z variance train             0.0026337346
KL Divergence                41.834892
KL Loss                      4.1834893
QF Loss                      246.87808
VF Loss                      83.2568
Policy Loss                  -2438.8833
Q Predictions Mean           2436.7222
Q Predictions Std            628.5491
Q Predictions Max            3134.4246
Q Predictions Min            562.56854
V Predictions Mean           2437.1099
V Predictions Std            623.6246
V Predictions Max            3126.4302
V Predictions Min            564.8039
Log Pis Mean                 4.2411547
Log Pis Std                  3.5655096
Log Pis Max                  15.121959
Log Pis Min                  -5.3818026
Policy mu Mean               -0.079339184
Policy mu Std                1.2893251
Policy mu Max                2.847384
Policy mu Min                -3.1441557
Policy log std Mean          -0.7875125
Policy log std Std           0.38894248
Policy log std Max           -0.091073245
Policy log std Min           -2.5379133
Z mean eval                  3.2516618
Z variance eval              0.0070478455
total_rewards                [7659.49621673 7838.58038189 7732.98474121 7770.65597086 7780.85475792
 7752.14985215 7689.65945823 7868.35691052 7629.96622407 7766.76790576]
total_rewards_mean           7748.947241933616
total_rewards_std            70.73738137507854
total_rewards_max            7868.356910516362
total_rewards_min            7629.966224069741
Number of train steps total  152000
Number of env steps total    192000
Number of rollouts total     0
Train Time (s)               107.52866009902209
(Previous) Eval Time (s)     22.591964362654835
Sample Time (s)              16.18418791424483
Epoch Time (s)               146.30481237592176
Total Train Time (s)         5775.943606174085
Epoch                        37
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:12:34.881235 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #37 | Epoch Duration: 146.14046382904053
2020-01-13 10:12:34.881492 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #37 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.252689
Z variance train             0.0070269457
KL Divergence                39.359535
KL Loss                      3.9359536
QF Loss                      372.65662
VF Loss                      201.1003
Policy Loss                  -2491.4424
Q Predictions Mean           2490.8
Q Predictions Std            561.065
Q Predictions Max            3083.9011
Q Predictions Min            544.3504
V Predictions Mean           2484.2397
V Predictions Std            554.63135
V Predictions Max            3069.6099
V Predictions Min            548.47784
Log Pis Mean                 3.986986
Log Pis Std                  3.5796604
Log Pis Max                  14.401946
Log Pis Min                  -6.4550753
Policy mu Mean               -0.13467772
Policy mu Std                1.263739
Policy mu Max                2.93953
Policy mu Min                -3.0061865
Policy log std Mean          -0.8261669
Policy log std Std           0.41027817
Policy log std Max           -0.08330649
Policy log std Min           -2.7997646
Z mean eval                  3.2669883
Z variance eval              0.007134106
total_rewards                [7056.93876073 7404.26624995 7252.79043726 7250.79201889 7355.70791967
 7297.68773933 7308.24786282 7090.76103556 7120.29961246 7432.29412812]
total_rewards_mean           7256.978576480889
total_rewards_std            123.62993661721326
total_rewards_max            7432.294128124578
total_rewards_min            7056.938760725487
Number of train steps total  156000
Number of env steps total    197000
Number of rollouts total     0
Train Time (s)               112.74878424592316
(Previous) Eval Time (s)     22.42730404390022
Sample Time (s)              15.79826170252636
Epoch Time (s)               150.97434999234974
Total Train Time (s)         5926.688570137136
Epoch                        38
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:15:05.625866 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #38 | Epoch Duration: 150.74416160583496
2020-01-13 10:15:05.626152 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #38 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2633736
Z variance train             0.0071567283
KL Divergence                40.273506
KL Loss                      4.027351
QF Loss                      297.54376
VF Loss                      127.35591
Policy Loss                  -2530.9988
Q Predictions Mean           2537.3687
Q Predictions Std            621.8495
Q Predictions Max            3164.2102
Q Predictions Min            536.39496
V Predictions Mean           2537.3887
V Predictions Std            617.1577
V Predictions Max            3145.5945
V Predictions Min            533.92615
Log Pis Mean                 4.421155
Log Pis Std                  3.8949006
Log Pis Max                  13.522505
Log Pis Min                  -7.3839407
Policy mu Mean               -0.0388993
Policy mu Std                1.3055217
Policy mu Max                3.195201
Policy mu Min                -3.0798154
Policy log std Mean          -0.83579254
Policy log std Std           0.422939
Policy log std Max           -0.040403724
Policy log std Min           -2.8362622
Z mean eval                  3.2592492
Z variance eval              0.007316211
total_rewards                [7950.34933874 8049.62178836 8122.72752759 7990.84855636 8097.08144685
 7949.85011934 7813.88966469 7831.81837174 8046.53752408 8075.99113574]
total_rewards_mean           7992.871547348566
total_rewards_std            101.17681815701005
total_rewards_max            8122.727527586499
total_rewards_min            7813.889664693732
Number of train steps total  160000
Number of env steps total    202000
Number of rollouts total     0
Train Time (s)               108.99941162765026
(Previous) Eval Time (s)     22.196851865388453
Sample Time (s)              16.033152877818793
Epoch Time (s)               147.2294163708575
Total Train Time (s)         6074.327276316937
Epoch                        39
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:17:33.263933 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #39 | Epoch Duration: 147.63758778572083
2020-01-13 10:17:33.264090 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #39 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2594867
Z variance train             0.007348848
KL Divergence                40.42154
KL Loss                      4.042154
QF Loss                      283.6314
VF Loss                      102.66615
Policy Loss                  -2642.791
Q Predictions Mean           2649.2358
Q Predictions Std            581.96234
Q Predictions Max            3214.6921
Q Predictions Min            577.0834
V Predictions Mean           2643.8372
V Predictions Std            576.69
V Predictions Max            3205.7747
V Predictions Min            572.27783
Log Pis Mean                 4.388714
Log Pis Std                  3.72216
Log Pis Max                  15.572067
Log Pis Min                  -5.507752
Policy mu Mean               -0.12496835
Policy mu Std                1.2933022
Policy mu Max                2.768247
Policy mu Min                -2.9239864
Policy log std Mean          -0.81068754
Policy log std Std           0.40267438
Policy log std Max           -0.03238046
Policy log std Min           -2.961543
Z mean eval                  3.275206
Z variance eval              0.0014054778
total_rewards                [7866.25786102 8071.45765817 8123.40904408 7949.82580103 8217.67088092
 7987.9597229  3721.38103296 8119.77787919 8126.38680678 7964.78297308]
total_rewards_mean           7614.8909660131685
total_rewards_std            1301.6649787306335
total_rewards_max            8217.67088091871
total_rewards_min            3721.381032957035
Number of train steps total  164000
Number of env steps total    207000
Number of rollouts total     0
Train Time (s)               113.82941151410341
(Previous) Eval Time (s)     22.60472722304985
Sample Time (s)              15.426336812786758
Epoch Time (s)               151.86047554994002
Total Train Time (s)         6225.82677037688
Epoch                        40
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:20:04.766208 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #40 | Epoch Duration: 151.50195693969727
2020-01-13 10:20:04.766479 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #40 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2759678
Z variance train             0.001402097
KL Divergence                41.699413
KL Loss                      4.1699414
QF Loss                      262.65265
VF Loss                      81.54721
Policy Loss                  -2624.9194
Q Predictions Mean           2618.9678
Q Predictions Std            578.1961
Q Predictions Max            3271.6545
Q Predictions Min            583.3449
V Predictions Mean           2621.4646
V Predictions Std            569.78076
V Predictions Max            3260.4724
V Predictions Min            605.1135
Log Pis Mean                 4.2593327
Log Pis Std                  3.7599063
Log Pis Max                  14.00721
Log Pis Min                  -5.6853733
Policy mu Mean               -0.11603552
Policy mu Std                1.2788048
Policy mu Max                3.1676202
Policy mu Min                -2.8319674
Policy log std Mean          -0.81739014
Policy log std Std           0.39592898
Policy log std Max           -0.015721738
Policy log std Min           -2.7662537
Z mean eval                  3.2687817
Z variance eval              0.013612034
total_rewards                [8017.40332873 8079.91287116 8113.55274143 8170.82935132 8158.50233879
 8139.34436179 8114.67235711 8144.44754627 8089.43696382 8118.13173076]
total_rewards_mean           8114.623359119156
total_rewards_std            42.295924879723984
total_rewards_max            8170.829351321027
total_rewards_min            8017.403328734833
Number of train steps total  168000
Number of env steps total    212000
Number of rollouts total     0
Train Time (s)               112.48869409179315
(Previous) Eval Time (s)     22.245930220000446
Sample Time (s)              15.57358914334327
Epoch Time (s)               150.30821345513687
Total Train Time (s)         6376.5298605659045
Epoch                        41
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:22:35.469214 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #41 | Epoch Duration: 150.702561378479
2020-01-13 10:22:35.469377 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #41 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2678552
Z variance train             0.013593426
KL Divergence                40.273632
KL Loss                      4.0273633
QF Loss                      297.88522
VF Loss                      100.88108
Policy Loss                  -2637.6648
Q Predictions Mean           2632.3794
Q Predictions Std            543.8698
Q Predictions Max            3273.7314
Q Predictions Min            613.3795
V Predictions Mean           2642.9238
V Predictions Std            538.5504
V Predictions Max            3282.177
V Predictions Min            625.63983
Log Pis Mean                 4.2786226
Log Pis Std                  3.9566438
Log Pis Max                  15.9796505
Log Pis Min                  -5.415206
Policy mu Mean               -0.114359595
Policy mu Std                1.325019
Policy mu Max                3.7539551
Policy mu Min                -2.9495163
Policy log std Mean          -0.8030796
Policy log std Std           0.3873152
Policy log std Max           -0.106573105
Policy log std Min           -2.9461582
Z mean eval                  3.2774024
Z variance eval              0.004323948
total_rewards                [7988.92497893 8044.23840003 7915.97798388 7881.50969931 8062.38442546
 7929.42113672 7927.93240753 7884.28392499 7973.37840178 8045.53300736]
total_rewards_mean           7965.358436598186
total_rewards_std            64.35687077833549
total_rewards_max            8062.384425461413
total_rewards_min            7881.509699310257
Number of train steps total  172000
Number of env steps total    217000
Number of rollouts total     0
Train Time (s)               112.8515988541767
(Previous) Eval Time (s)     22.640018092934042
Sample Time (s)              15.822918137069792
Epoch Time (s)               151.31453508418053
Total Train Time (s)         6527.873559247237
Epoch                        42
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:25:06.814257 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #42 | Epoch Duration: 151.34474349021912
2020-01-13 10:25:06.814476 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #42 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.277998
Z variance train             0.004321971
KL Divergence                40.61319
KL Loss                      4.061319
QF Loss                      247.28549
VF Loss                      95.08162
Policy Loss                  -2675.138
Q Predictions Mean           2674.6877
Q Predictions Std            518.0661
Q Predictions Max            3326.1003
Q Predictions Min            622.59174
V Predictions Mean           2679.1897
V Predictions Std            510.8533
V Predictions Max            3327.1736
V Predictions Min            654.49756
Log Pis Mean                 4.2793775
Log Pis Std                  3.6607244
Log Pis Max                  15.753781
Log Pis Min                  -6.7007074
Policy mu Mean               -0.14734763
Policy mu Std                1.2678721
Policy mu Max                2.8925505
Policy mu Min                -3.006705
Policy log std Mean          -0.83604354
Policy log std Std           0.40918377
Policy log std Max           0.045684397
Policy log std Min           -2.8320613
Z mean eval                  3.2794197
Z variance eval              0.0025780434
total_rewards                [8321.94515978 8203.32296498 8243.98378035 8067.09058542 8158.13552074
 8085.89944263 8326.21252707 8285.47620152 8297.76605781 7451.43309665]
total_rewards_mean           8144.126533696671
total_rewards_std            247.22068538418984
total_rewards_max            8326.2125270703
total_rewards_min            7451.4330966532
Number of train steps total  176000
Number of env steps total    222000
Number of rollouts total     0
Train Time (s)               110.94627068471164
(Previous) Eval Time (s)     22.669916834682226
Sample Time (s)              16.149535922333598
Epoch Time (s)               149.76572344172746
Total Train Time (s)         6677.511515446473
Epoch                        43
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:27:36.453221 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #43 | Epoch Duration: 149.63860535621643
2020-01-13 10:27:36.453467 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #43 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2784653
Z variance train             0.002591059
KL Divergence                41.056927
KL Loss                      4.105693
QF Loss                      428.49786
VF Loss                      188.55945
Policy Loss                  -2703.4553
Q Predictions Mean           2708.681
Q Predictions Std            600.4626
Q Predictions Max            3360.4062
Q Predictions Min            620.23047
V Predictions Mean           2713.6343
V Predictions Std            590.65466
V Predictions Max            3359.5032
V Predictions Min            649.89233
Log Pis Mean                 4.5348387
Log Pis Std                  3.7086837
Log Pis Max                  13.923839
Log Pis Min                  -6.4255023
Policy mu Mean               -0.1217821
Policy mu Std                1.3342977
Policy mu Max                2.9470243
Policy mu Min                -2.8406577
Policy log std Mean          -0.8334504
Policy log std Std           0.40099657
Policy log std Max           -0.09749138
Policy log std Min           -2.924186
Z mean eval                  3.2772796
Z variance eval              0.0034359847
total_rewards                [8221.01385677 8217.58956144 8272.01080103 8336.68148742 8284.55859286
 8340.71811463 8328.1888013  7998.97435307 8286.83764543 8319.17876257]
total_rewards_mean           8260.575197652344
total_rewards_std            96.6770865491259
total_rewards_max            8340.718114630363
total_rewards_min            7998.974353069143
Number of train steps total  180000
Number of env steps total    227000
Number of rollouts total     0
Train Time (s)               113.63978690793738
(Previous) Eval Time (s)     22.542499942239374
Sample Time (s)              16.10921859368682
Epoch Time (s)               152.29150544386357
Total Train Time (s)         6830.2657737648115
Epoch                        44
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:30:09.211658 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #44 | Epoch Duration: 152.75800395011902
2020-01-13 10:30:09.212016 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #44 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2775314
Z variance train             0.0034342103
KL Divergence                39.81651
KL Loss                      3.981651
QF Loss                      226.94037
VF Loss                      103.62396
Policy Loss                  -2752.8713
Q Predictions Mean           2749.134
Q Predictions Std            535.0276
Q Predictions Max            3351.7676
Q Predictions Min            651.8461
V Predictions Mean           2748.1062
V Predictions Std            528.3425
V Predictions Max            3338.487
V Predictions Min            668.83716
Log Pis Mean                 4.1895876
Log Pis Std                  3.642643
Log Pis Max                  15.342759
Log Pis Min                  -5.272438
Policy mu Mean               -0.15206023
Policy mu Std                1.2781668
Policy mu Max                2.9518783
Policy mu Min                -3.0045335
Policy log std Mean          -0.8397839
Policy log std Std           0.41047806
Policy log std Max           0.0008351207
Policy log std Min           -2.8051174
Z mean eval                  3.2644043
Z variance eval              0.010223319
total_rewards                [8110.88352964 8182.68847154 8114.96199384 8185.60600188 8247.39502799
 8178.87920352 8093.90022124 8106.03709018 8044.69921966 8263.36376935]
total_rewards_mean           8152.841452884818
total_rewards_std            66.59779737839847
total_rewards_max            8263.363769346104
total_rewards_min            8044.699219659347
Number of train steps total  184000
Number of env steps total    232000
Number of rollouts total     0
Train Time (s)               117.03577816905454
(Previous) Eval Time (s)     23.008687490131706
Sample Time (s)              16.14441252592951
Epoch Time (s)               156.18887818511575
Total Train Time (s)         6986.818406602833
Epoch                        45
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:32:45.765289 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #45 | Epoch Duration: 156.55302143096924
2020-01-13 10:32:45.765534 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #45 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2656531
Z variance train             0.0102309985
KL Divergence                36.918793
KL Loss                      3.6918793
QF Loss                      310.83057
VF Loss                      236.1654
Policy Loss                  -2754.4517
Q Predictions Mean           2747.4875
Q Predictions Std            606.1836
Q Predictions Max            3390.4956
Q Predictions Min            656.08136
V Predictions Mean           2742.1174
V Predictions Std            600.0941
V Predictions Max            3367.018
V Predictions Min            657.7748
Log Pis Mean                 4.3346806
Log Pis Std                  3.549055
Log Pis Max                  13.777702
Log Pis Min                  -4.982573
Policy mu Mean               -0.13318892
Policy mu Std                1.3068118
Policy mu Max                2.8834462
Policy mu Min                -3.1333675
Policy log std Mean          -0.8195429
Policy log std Std           0.39637005
Policy log std Max           -0.14314122
Policy log std Min           -2.9261463
Z mean eval                  3.2703195
Z variance eval              0.012431434
total_rewards                [8122.44218864 8419.51279079 8168.99827429 8475.24020314 8447.48445715
 8500.92983748 8382.16282512 8490.62190239 8283.31169493 8154.56113978]
total_rewards_mean           8344.526531370087
total_rewards_std            141.59710812370116
total_rewards_max            8500.92983747677
total_rewards_min            8122.442188642577
Number of train steps total  188000
Number of env steps total    237000
Number of rollouts total     0
Train Time (s)               111.91133831301704
(Previous) Eval Time (s)     23.372553561348468
Sample Time (s)              16.167460537981242
Epoch Time (s)               151.45135241234675
Total Train Time (s)         7137.879575183149
Epoch                        46
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:35:16.827372 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #46 | Epoch Duration: 151.06165194511414
2020-01-13 10:35:16.827588 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #46 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2709148
Z variance train             0.012401179
KL Divergence                36.028362
KL Loss                      3.6028364
QF Loss                      182.80072
VF Loss                      84.22084
Policy Loss                  -2716.0713
Q Predictions Mean           2707.1597
Q Predictions Std            698.3343
Q Predictions Max            3444.974
Q Predictions Min            676.39307
V Predictions Mean           2711.6313
V Predictions Std            693.84106
V Predictions Max            3433.3804
V Predictions Min            685.4899
Log Pis Mean                 4.200343
Log Pis Std                  3.6727178
Log Pis Max                  15.96492
Log Pis Min                  -4.5855417
Policy mu Mean               -0.072491236
Policy mu Std                1.3099964
Policy mu Max                2.8813977
Policy mu Min                -2.748857
Policy log std Mean          -0.80670166
Policy log std Std           0.40859404
Policy log std Max           -0.044902682
Policy log std Min           -2.859765
Z mean eval                  3.2772942
Z variance eval              0.013337931
total_rewards                [8264.72903199 8220.11366153 8334.07641756 8399.99174442 8152.46015801
 7898.196795   8286.63585981 8053.4455427  8274.57335204 8175.26907229]
total_rewards_mean           8205.949163535106
total_rewards_std            138.0998410517464
total_rewards_max            8399.991744424715
total_rewards_min            7898.196794998898
Number of train steps total  192000
Number of env steps total    242000
Number of rollouts total     0
Train Time (s)               110.42040917510167
(Previous) Eval Time (s)     22.982543678954244
Sample Time (s)              16.34632107988
Epoch Time (s)               149.7492739339359
Total Train Time (s)         7287.177411741577
Epoch                        47
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:37:46.126121 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #47 | Epoch Duration: 149.29837775230408
2020-01-13 10:37:46.126333 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #47 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.277909
Z variance train             0.013304266
KL Divergence                38.225212
KL Loss                      3.8225212
QF Loss                      272.47015
VF Loss                      140.18935
Policy Loss                  -2871.8406
Q Predictions Mean           2879.474
Q Predictions Std            525.3661
Q Predictions Max            3476.3843
Q Predictions Min            707.2932
V Predictions Mean           2871.6304
V Predictions Std            518.63684
V Predictions Max            3457.1882
V Predictions Min            710.51184
Log Pis Mean                 4.168808
Log Pis Std                  3.643279
Log Pis Max                  14.860039
Log Pis Min                  -7.5414066
Policy mu Mean               -0.0981333
Policy mu Std                1.2886347
Policy mu Max                3.008719
Policy mu Min                -2.9258575
Policy log std Mean          -0.85128456
Policy log std Std           0.41141036
Policy log std Max           -0.13193169
Policy log std Min           -2.991661
Z mean eval                  3.2861743
Z variance eval              0.0057977512
total_rewards                [8233.41554017 8183.38114258 8190.56034212 8304.4902552  8209.04115907
 8309.05041462 8305.0782267  8170.38847475 8219.89464393 8276.09838967]
total_rewards_mean           8240.139858881541
total_rewards_std            51.34860856758966
total_rewards_max            8309.050414623272
total_rewards_min            8170.388474754276
Number of train steps total  196000
Number of env steps total    247000
Number of rollouts total     0
Train Time (s)               115.28401315724477
(Previous) Eval Time (s)     22.531306916847825
Sample Time (s)              16.213625598698854
Epoch Time (s)               154.02894567279145
Total Train Time (s)         7441.670369927306
Epoch                        48
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:40:20.619641 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #48 | Epoch Duration: 154.49316596984863
2020-01-13 10:40:20.619819 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #48 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.286832
Z variance train             0.0058128354
KL Divergence                39.519028
KL Loss                      3.9519029
QF Loss                      247.18552
VF Loss                      155.90321
Policy Loss                  -2799.9138
Q Predictions Mean           2792.6182
Q Predictions Std            621.1474
Q Predictions Max            3436.6406
Q Predictions Min            692.3547
V Predictions Mean           2791.5542
V Predictions Std            614.0352
V Predictions Max            3427.579
V Predictions Min            698.5101
Log Pis Mean                 4.883031
Log Pis Std                  3.6727808
Log Pis Max                  15.246477
Log Pis Min                  -2.899928
Policy mu Mean               -0.12735632
Policy mu Std                1.3325504
Policy mu Max                3.722176
Policy mu Min                -2.8006263
Policy log std Mean          -0.81300783
Policy log std Std           0.4059883
Policy log std Max           -0.12768868
Policy log std Min           -2.8060884
Z mean eval                  3.3054829
Z variance eval              0.004241246
total_rewards                [7956.94539533 7620.84472864 8048.16955473 7936.63580481 7891.58439079
 7737.98480484 8055.95986461 7943.4277514  8053.72751829 7941.81156553]
total_rewards_mean           7918.709137897781
total_rewards_std            133.74456105047457
total_rewards_max            8055.959864606507
total_rewards_min            7620.844728641618
Number of train steps total  200000
Number of env steps total    252000
Number of rollouts total     0
Train Time (s)               116.63774570869282
(Previous) Eval Time (s)     22.995237068273127
Sample Time (s)              16.0194702912122
Epoch Time (s)               155.65245306817815
Total Train Time (s)         7597.853186551016
Epoch                        49
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:42:56.827602 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #49 | Epoch Duration: 156.20759844779968
2020-01-13 10:42:56.827912 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #49 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3040154
Z variance train             0.0042337975
KL Divergence                40.382202
KL Loss                      4.0382204
QF Loss                      243.35544
VF Loss                      115.247665
Policy Loss                  -2871.5916
Q Predictions Mean           2874.646
Q Predictions Std            602.6539
Q Predictions Max            3513.016
Q Predictions Min            706.6306
V Predictions Mean           2876.3257
V Predictions Std            595.8993
V Predictions Max            3510.249
V Predictions Min            720.92615
Log Pis Mean                 4.4287415
Log Pis Std                  3.9092548
Log Pis Max                  16.37917
Log Pis Min                  -8.333274
Policy mu Mean               -0.11799345
Policy mu Std                1.3176612
Policy mu Max                2.9779115
Policy mu Min                -3.6154425
Policy log std Mean          -0.81469274
Policy log std Std           0.41837013
Policy log std Max           0.13096583
Policy log std Min           -2.9740324
Z mean eval                  3.2934868
Z variance eval              0.0061813416
total_rewards                [8428.65194686 8638.10282131 8681.04854435 8371.16278558 8695.51602892
 8386.39403365 8652.71671876 8573.73262414 8580.31361465 8540.12035102]
total_rewards_mean           8554.775946924707
total_rewards_std            114.66827897376372
total_rewards_max            8695.51602892478
total_rewards_min            8371.162785583365
Number of train steps total  204000
Number of env steps total    257000
Number of rollouts total     0
Train Time (s)               111.45005264971405
(Previous) Eval Time (s)     23.55009586084634
Sample Time (s)              15.775772517547011
Epoch Time (s)               150.7759210281074
Total Train Time (s)         7747.5741738923825
Epoch                        50
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:45:26.527542 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #50 | Epoch Duration: 149.69942092895508
2020-01-13 10:45:26.527726 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #50 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2925644
Z variance train             0.006179291
KL Divergence                39.22486
KL Loss                      3.922486
QF Loss                      262.304
VF Loss                      93.485466
Policy Loss                  -2794.5186
Q Predictions Mean           2789.046
Q Predictions Std            643.69965
Q Predictions Max            3541.213
Q Predictions Min            720.4838
V Predictions Mean           2791.7776
V Predictions Std            638.26587
V Predictions Max            3516.6252
V Predictions Min            718.67584
Log Pis Mean                 4.7056227
Log Pis Std                  3.8755386
Log Pis Max                  17.02367
Log Pis Min                  -8.739567
Policy mu Mean               -0.1536703
Policy mu Std                1.306809
Policy mu Max                3.0475452
Policy mu Min                -2.8294468
Policy log std Mean          -0.8255682
Policy log std Std           0.4305131
Policy log std Max           -0.11754185
Policy log std Min           -3.1042013
Z mean eval                  3.3004975
Z variance eval              0.0018510377
total_rewards                [8775.7271657  8668.38073471 8653.64821888 8704.00284271 8537.52248844
 8577.68036329 8568.03593519 8771.25348978 8651.42839866 8650.68849803]
total_rewards_mean           8655.83681353824
total_rewards_std            76.18297429106539
total_rewards_max            8775.727165700218
total_rewards_min            8537.522488437107
Number of train steps total  208000
Number of env steps total    262000
Number of rollouts total     0
Train Time (s)               119.66007532505319
(Previous) Eval Time (s)     22.47333044372499
Sample Time (s)              16.726717200595886
Epoch Time (s)               158.86012296937406
Total Train Time (s)         7906.755397976842
Epoch                        51
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:48:05.714322 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #51 | Epoch Duration: 159.18641328811646
2020-01-13 10:48:05.714592 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #51 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3010948
Z variance train             0.0018508686
KL Divergence                42.215458
KL Loss                      4.2215457
QF Loss                      262.57782
VF Loss                      105.66557
Policy Loss                  -2926.9749
Q Predictions Mean           2922.2583
Q Predictions Std            583.6576
Q Predictions Max            3589.4536
Q Predictions Min            724.18304
V Predictions Mean           2924.5552
V Predictions Std            573.1554
V Predictions Max            3569.089
V Predictions Min            740.33014
Log Pis Mean                 4.770673
Log Pis Std                  3.5255976
Log Pis Max                  14.286886
Log Pis Min                  -3.489866
Policy mu Mean               -0.09186301
Policy mu Std                1.3411119
Policy mu Max                2.9992292
Policy mu Min                -3.3254158
Policy log std Mean          -0.84156424
Policy log std Std           0.45063847
Policy log std Max           -0.023924977
Policy log std Min           -3.0783792
Z mean eval                  3.2995636
Z variance eval              0.0017670349
total_rewards                [8712.49841844 8811.23925656 8984.32995751 8640.61603152 8512.39166649
 8971.52348762 8887.7034795  8841.09150503 8771.02144695 8790.39773087]
total_rewards_mean           8792.281298049202
total_rewards_std            137.48420972340605
total_rewards_max            8984.329957514441
total_rewards_min            8512.391666491145
Number of train steps total  212000
Number of env steps total    267000
Number of rollouts total     0
Train Time (s)               111.85500352922827
(Previous) Eval Time (s)     22.799317946191877
Sample Time (s)              16.010231473017484
Epoch Time (s)               150.66455294843763
Total Train Time (s)         8057.404297064524
Epoch                        52
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:50:36.362780 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #52 | Epoch Duration: 150.64795541763306
2020-01-13 10:50:36.363105 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #52 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2991748
Z variance train             0.0017638548
KL Divergence                42.619484
KL Loss                      4.2619486
QF Loss                      322.59204
VF Loss                      178.09393
Policy Loss                  -2952.212
Q Predictions Mean           2951.1611
Q Predictions Std            544.088
Q Predictions Max            3622.5742
Q Predictions Min            714.35236
V Predictions Mean           2953.0059
V Predictions Std            539.45966
V Predictions Max            3623.936
V Predictions Min            757.2107
Log Pis Mean                 4.3629575
Log Pis Std                  3.743176
Log Pis Max                  14.52302
Log Pis Min                  -6.5653687
Policy mu Mean               -0.14413798
Policy mu Std                1.2898551
Policy mu Max                2.9361708
Policy mu Min                -3.4227812
Policy log std Mean          -0.85307425
Policy log std Std           0.42955777
Policy log std Max           -0.12187305
Policy log std Min           -2.8637013
Z mean eval                  3.3030782
Z variance eval              0.0010563645
total_rewards                [8652.42959559 8731.02928894 8528.7914083  8857.0500556  8754.44725707
 8666.33803522 2576.89453428 8775.43992797 8792.34719427 8787.84289698]
total_rewards_mean           8112.261019419772
total_rewards_std            1847.1947787569716
total_rewards_max            8857.050055598289
total_rewards_min            2576.8945342762395
Number of train steps total  216000
Number of env steps total    272000
Number of rollouts total     0
Train Time (s)               112.4864803547971
(Previous) Eval Time (s)     22.7824142081663
Sample Time (s)              16.267275331541896
Epoch Time (s)               151.5361698945053
Total Train Time (s)         8209.337568723597
Epoch                        53
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:53:08.298526 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #53 | Epoch Duration: 151.9350941181183
2020-01-13 10:53:08.298915 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #53 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3029175
Z variance train             0.0010549191
KL Divergence                44.44686
KL Loss                      4.4446864
QF Loss                      171.20142
VF Loss                      93.851395
Policy Loss                  -2968.5474
Q Predictions Mean           2966.8765
Q Predictions Std            669.4041
Q Predictions Max            3617.6917
Q Predictions Min            747.1031
V Predictions Mean           2966.2493
V Predictions Std            661.98016
V Predictions Max            3609.8901
V Predictions Min            752.80316
Log Pis Mean                 4.373491
Log Pis Std                  3.416782
Log Pis Max                  13.71186
Log Pis Min                  -4.536483
Policy mu Mean               -0.08492031
Policy mu Std                1.28446
Policy mu Max                2.7602987
Policy mu Min                -3.178522
Policy log std Mean          -0.8352596
Policy log std Std           0.431148
Policy log std Max           -0.11076665
Policy log std Min           -2.997023
Z mean eval                  3.2953076
Z variance eval              0.0061735804
total_rewards                [8831.73115198 8915.42197073 9128.1133549  8931.65042491 8747.09243896
 8871.2375512  8839.21935577 8830.17908886 8854.24614008 8565.00106612]
total_rewards_mean           8851.389254352296
total_rewards_std            134.68512440879525
total_rewards_max            9128.11335489836
total_rewards_min            8565.001066122031
Number of train steps total  220000
Number of env steps total    277000
Number of rollouts total     0
Train Time (s)               107.9289987012744
(Previous) Eval Time (s)     23.181073241867125
Sample Time (s)              16.132480083499104
Epoch Time (s)               147.24255202664062
Total Train Time (s)         8356.020891720429
Epoch                        54
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:55:34.983391 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #54 | Epoch Duration: 146.68421006202698
2020-01-13 10:55:34.983665 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #54 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2956624
Z variance train             0.0061907754
KL Divergence                43.691017
KL Loss                      4.369102
QF Loss                      243.6864
VF Loss                      125.926186
Policy Loss                  -3036.1758
Q Predictions Mean           3037.581
Q Predictions Std            592.5401
Q Predictions Max            3644.1067
Q Predictions Min            745.86206
V Predictions Mean           3042.1108
V Predictions Std            584.3582
V Predictions Max            3643.4548
V Predictions Min            753.95685
Log Pis Mean                 4.2103405
Log Pis Std                  4.072939
Log Pis Max                  17.083952
Log Pis Min                  -7.72872
Policy mu Mean               -0.028412826
Policy mu Std                1.2924654
Policy mu Max                3.372621
Policy mu Min                -2.8057556
Policy log std Mean          -0.83210635
Policy log std Std           0.43487749
Policy log std Max           -0.0858168
Policy log std Min           -2.856852
Z mean eval                  3.2950969
Z variance eval              0.0055859257
total_rewards                [8632.40106419 8637.37166701 8596.34246087 8695.87080108 8660.39343958
 8578.14896574 8613.98861731 8612.63119105 8587.19883131 8509.92955096]
total_rewards_mean           8612.427658910732
total_rewards_std            47.8154900027596
total_rewards_max            8695.870801082774
total_rewards_min            8509.929550963729
Number of train steps total  224000
Number of env steps total    282000
Number of rollouts total     0
Train Time (s)               113.19425966404378
(Previous) Eval Time (s)     22.6224127789028
Sample Time (s)              15.956521301995963
Epoch Time (s)               151.77319374494255
Total Train Time (s)         8508.205291005317
Epoch                        55
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:58:07.171280 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #55 | Epoch Duration: 152.18728804588318
2020-01-13 10:58:07.171709 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #55 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.296491
Z variance train             0.0055993525
KL Divergence                43.808315
KL Loss                      4.3808317
QF Loss                      328.92276
VF Loss                      78.9639
Policy Loss                  -3058.0725
Q Predictions Mean           3065.7773
Q Predictions Std            538.38824
Q Predictions Max            3734.6135
Q Predictions Min            776.46155
V Predictions Mean           3059.683
V Predictions Std            532.7477
V Predictions Max            3727.2268
V Predictions Min            778.1008
Log Pis Mean                 4.482578
Log Pis Std                  3.8693144
Log Pis Max                  13.127436
Log Pis Min                  -4.3685136
Policy mu Mean               -0.13442402
Policy mu Std                1.3147271
Policy mu Max                2.8131762
Policy mu Min                -3.468672
Policy log std Mean          -0.86305046
Policy log std Std           0.44892138
Policy log std Max           -0.011871994
Policy log std Min           -3.115674
Z mean eval                  3.3001587
Z variance eval              0.0036424217
total_rewards                [8621.17491491 8701.67392522 8550.0078814  8760.82353811 8586.69127072
 8730.10638546 8532.18474333 8448.8972961  8587.12240073 8627.6288132 ]
total_rewards_mean           8614.631116918183
total_rewards_std            90.8149791928738
total_rewards_max            8760.823538112623
total_rewards_min            8448.8972961
Number of train steps total  228000
Number of env steps total    287000
Number of rollouts total     0
Train Time (s)               112.43516139406711
(Previous) Eval Time (s)     23.036214896012098
Sample Time (s)              16.196566591970623
Epoch Time (s)               151.66794288204983
Total Train Time (s)         8659.18109021755
Epoch                        56
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:00:38.145638 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #56 | Epoch Duration: 150.97366786003113
2020-01-13 11:00:38.145823 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #56 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2976806
Z variance train             0.0036392927
KL Divergence                43.512825
KL Loss                      4.3512826
QF Loss                      273.77838
VF Loss                      310.044
Policy Loss                  -3132.6797
Q Predictions Mean           3136.9453
Q Predictions Std            499.3473
Q Predictions Max            3761.8105
Q Predictions Min            768.53845
V Predictions Mean           3147.918
V Predictions Std            492.94165
V Predictions Max            3771.433
V Predictions Min            773.2354
Log Pis Mean                 4.4279194
Log Pis Std                  3.60419
Log Pis Max                  13.78661
Log Pis Min                  -5.1014543
Policy mu Mean               -0.1143829
Policy mu Std                1.3067088
Policy mu Max                2.989068
Policy mu Min                -2.8075225
Policy log std Mean          -0.8530777
Policy log std Std           0.4323887
Policy log std Max           -0.11687225
Policy log std Min           -3.0801911
Z mean eval                  3.2935417
Z variance eval              0.0026714134
total_rewards                [8911.6382898  8959.46682425 9049.21868894 9104.15602937 9023.36893898
 8818.48432223 8837.67267103 8911.42600703 9132.40768899 9084.73517946]
total_rewards_mean           8983.257464007867
total_rewards_std            105.98111725029119
total_rewards_max            9132.407688989497
total_rewards_min            8818.484322227268
Number of train steps total  232000
Number of env steps total    292000
Number of rollouts total     0
Train Time (s)               110.16400420991704
(Previous) Eval Time (s)     22.34165702899918
Sample Time (s)              16.528492451645434
Epoch Time (s)               149.03415369056165
Total Train Time (s)         8808.444859925192
Epoch                        57
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:03:07.410480 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #57 | Epoch Duration: 149.26451921463013
2020-01-13 11:03:07.410683 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #57 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2967274
Z variance train             0.002691303
KL Divergence                43.678886
KL Loss                      4.367889
QF Loss                      351.53653
VF Loss                      100.61267
Policy Loss                  -3067.9248
Q Predictions Mean           3064.359
Q Predictions Std            561.4143
Q Predictions Max            3742.571
Q Predictions Min            746.7675
V Predictions Mean           3071.542
V Predictions Std            555.6252
V Predictions Max            3730.509
V Predictions Min            772.7465
Log Pis Mean                 4.9498024
Log Pis Std                  3.8128867
Log Pis Max                  17.268024
Log Pis Min                  -4.841809
Policy mu Mean               -0.09042061
Policy mu Std                1.3473277
Policy mu Max                3.231397
Policy mu Min                -3.1304374
Policy log std Mean          -0.8460179
Policy log std Std           0.44221672
Policy log std Max           -0.021169841
Policy log std Min           -2.8927712
Z mean eval                  3.3005824
Z variance eval              0.00095924886
total_rewards                [8952.32699355 8631.98229461 9136.15265659 9051.25953236 8871.63638992
 8981.48048076 9113.79626985 8962.58347643 8876.72303372 8986.70116796]
total_rewards_mean           8956.464229575415
total_rewards_std            136.5522043465544
total_rewards_max            9136.152656594308
total_rewards_min            8631.98229461048
Number of train steps total  236000
Number of env steps total    297000
Number of rollouts total     0
Train Time (s)               109.79193476494402
(Previous) Eval Time (s)     22.571745524182916
Sample Time (s)              15.789851853158325
Epoch Time (s)               148.15353214228526
Total Train Time (s)         8956.872639690991
Epoch                        58
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:05:35.842496 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #58 | Epoch Duration: 148.43163919448853
2020-01-13 11:05:35.842796 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #58 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2981994
Z variance train             0.0009594759
KL Divergence                44.913486
KL Loss                      4.4913487
QF Loss                      320.59332
VF Loss                      152.23444
Policy Loss                  -3129.6646
Q Predictions Mean           3124.713
Q Predictions Std            529.24963
Q Predictions Max            3802.4763
Q Predictions Min            772.73883
V Predictions Mean           3123.742
V Predictions Std            524.6566
V Predictions Max            3793.7556
V Predictions Min            761.49243
Log Pis Mean                 4.6904774
Log Pis Std                  3.7243857
Log Pis Max                  14.270017
Log Pis Min                  -6.044141
Policy mu Mean               -0.12328708
Policy mu Std                1.317857
Policy mu Max                3.7008698
Policy mu Min                -2.7885385
Policy log std Mean          -0.84677744
Policy log std Std           0.4359066
Policy log std Max           -0.056559622
Policy log std Min           -3.2455566
Z mean eval                  3.3098576
Z variance eval              0.0010953962
total_rewards                [9021.14575333 9251.40020731 9195.72834744 9185.65190832 9244.62170417
 9107.20693302 9238.17952315 8877.22686959 8993.52807075 9276.36445164]
total_rewards_mean           9139.105376871052
total_rewards_std            127.46662028214953
total_rewards_max            9276.364451643476
total_rewards_min            8877.22686958965
Number of train steps total  240000
Number of env steps total    302000
Number of rollouts total     0
Train Time (s)               115.67605408607051
(Previous) Eval Time (s)     22.849553643725812
Sample Time (s)              15.954679496586323
Epoch Time (s)               154.48028722638264
Total Train Time (s)         9111.123792756349
Epoch                        59
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:08:10.093189 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #59 | Epoch Duration: 154.2501664161682
2020-01-13 11:08:10.093367 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #59 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3065434
Z variance train             0.001094466
KL Divergence                45.092358
KL Loss                      4.509236
QF Loss                      255.84259
VF Loss                      301.2988
Policy Loss                  -3098.4583
Q Predictions Mean           3098.9634
Q Predictions Std            640.6848
Q Predictions Max            3820.0535
Q Predictions Min            748.24066
V Predictions Mean           3110.1528
V Predictions Std            634.61176
V Predictions Max            3836.278
V Predictions Min            769.4769
Log Pis Mean                 4.650168
Log Pis Std                  3.9634976
Log Pis Max                  14.771341
Log Pis Min                  -5.7687407
Policy mu Mean               -0.10975078
Policy mu Std                1.3083731
Policy mu Max                3.0910177
Policy mu Min                -3.1766853
Policy log std Mean          -0.83588105
Policy log std Std           0.44339317
Policy log std Max           -0.08546817
Policy log std Min           -3.2144237
Z mean eval                  3.2983346
Z variance eval              0.0014567615
total_rewards                [9077.58681523 8970.72038676 9077.72600334 9214.85588796 9289.36108135
 9187.45385628 9112.70108406 9058.20364314 9029.7416324  9204.82647811]
total_rewards_mean           9122.317686864651
total_rewards_std            93.41395052517221
total_rewards_max            9289.361081349913
total_rewards_min            8970.720386764562
Number of train steps total  244000
Number of env steps total    307000
Number of rollouts total     0
Train Time (s)               116.58612247603014
(Previous) Eval Time (s)     22.61914864135906
Sample Time (s)              16.48079398041591
Epoch Time (s)               155.6860650978051
Total Train Time (s)         9266.555288540665
Epoch                        60
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:10:45.527087 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #60 | Epoch Duration: 155.4335560798645
2020-01-13 11:10:45.527317 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #60 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2964127
Z variance train             0.001462295
KL Divergence                44.518555
KL Loss                      4.4518557
QF Loss                      227.60638
VF Loss                      120.51196
Policy Loss                  -3118.8218
Q Predictions Mean           3121.455
Q Predictions Std            632.6186
Q Predictions Max            3837.831
Q Predictions Min            750.8055
V Predictions Mean           3124.7354
V Predictions Std            625.9712
V Predictions Max            3828.5571
V Predictions Min            756.3319
Log Pis Mean                 4.4707003
Log Pis Std                  3.7673151
Log Pis Max                  13.413522
Log Pis Min                  -4.1181326
Policy mu Mean               -0.14961985
Policy mu Std                1.3078014
Policy mu Max                2.956246
Policy mu Min                -2.8610117
Policy log std Mean          -0.8578646
Policy log std Std           0.4385085
Policy log std Max           -0.1472491
Policy log std Min           -2.9513876
Z mean eval                  3.3069663
Z variance eval              0.0025321308
total_rewards                [8843.2964308  9263.61202654 9102.37185016 9401.78954311 9045.7635887
 9104.93472517 9389.14250084 9208.77066724 9421.88270888 9199.51025684]
total_rewards_mean           9198.10742982797
total_rewards_std            173.03428763080694
total_rewards_max            9421.882708882746
total_rewards_min            8843.296430795817
Number of train steps total  248000
Number of env steps total    312000
Number of rollouts total     0
Train Time (s)               109.4252496631816
(Previous) Eval Time (s)     22.36634333897382
Sample Time (s)              15.721190490294248
Epoch Time (s)               147.51278349244967
Total Train Time (s)         9415.30375038879
Epoch                        61
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:13:14.278308 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #61 | Epoch Duration: 148.75077319145203
2020-01-13 11:13:14.278577 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #61 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.306298
Z variance train             0.0025404051
KL Divergence                42.99813
KL Loss                      4.2998133
QF Loss                      379.43683
VF Loss                      174.13097
Policy Loss                  -3214.0325
Q Predictions Mean           3220.222
Q Predictions Std            519.9846
Q Predictions Max            3909.3584
Q Predictions Min            761.55786
V Predictions Mean           3221.5715
V Predictions Std            511.69446
V Predictions Max            3900.0984
V Predictions Min            785.6893
Log Pis Mean                 5.324941
Log Pis Std                  3.6958396
Log Pis Max                  16.102795
Log Pis Min                  -5.2935753
Policy mu Mean               -0.15512848
Policy mu Std                1.3541142
Policy mu Max                3.0482152
Policy mu Min                -3.034178
Policy log std Mean          -0.85904104
Policy log std Std           0.42639837
Policy log std Max           -0.05588731
Policy log std Min           -2.8931308
Z mean eval                  3.2977767
Z variance eval              0.006246851
total_rewards                [8587.4780055  8972.96984266 8772.38003984 8612.27101306 8812.91902437
 9026.91376267 8830.78850115 9047.52971253 8723.34254988 8784.98994818]
total_rewards_mean           8817.15823998379
total_rewards_std            151.03723413170897
total_rewards_max            9047.529712527565
total_rewards_min            8587.478005498444
Number of train steps total  252000
Number of env steps total    317000
Number of rollouts total     0
Train Time (s)               110.56503053894266
(Previous) Eval Time (s)     23.604049650020897
Sample Time (s)              16.378979183733463
Epoch Time (s)               150.54805937269703
Total Train Time (s)         9565.608449595515
Epoch                        62
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:15:44.582579 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #62 | Epoch Duration: 150.30381178855896
2020-01-13 11:15:44.582762 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #62 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2958572
Z variance train             0.0062260553
KL Divergence                43.002438
KL Loss                      4.300244
QF Loss                      313.43024
VF Loss                      149.604
Policy Loss                  -3148.367
Q Predictions Mean           3148.5696
Q Predictions Std            658.89667
Q Predictions Max            3910.6677
Q Predictions Min            788.3013
V Predictions Mean           3154.4495
V Predictions Std            653.38007
V Predictions Max            3909.0774
V Predictions Min            790.50574
Log Pis Mean                 4.57003
Log Pis Std                  3.6484194
Log Pis Max                  13.243933
Log Pis Min                  -4.1322565
Policy mu Mean               -0.13298298
Policy mu Std                1.317695
Policy mu Max                2.8876998
Policy mu Min                -3.06045
Policy log std Mean          -0.8348012
Policy log std Std           0.43175238
Policy log std Max           -0.09414074
Policy log std Min           -3.3058066
Z mean eval                  3.2961166
Z variance eval              0.017829357
total_rewards                [4262.4753569  8856.10814237 8916.50172253 8791.7029399  1245.35877629
 8999.03620233 8604.67412009 8729.58234295 8922.78554077 8808.64753478]
total_rewards_mean           7613.687267891571
total_rewards_std            2523.945757397874
total_rewards_max            8999.036202331767
total_rewards_min            1245.3587762874192
Number of train steps total  256000
Number of env steps total    322000
Number of rollouts total     0
Train Time (s)               112.69677595933899
(Previous) Eval Time (s)     23.359517918899655
Sample Time (s)              16.659180257469416
Epoch Time (s)               152.71547413570806
Total Train Time (s)         9717.94244045997
Epoch                        63
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:18:16.919756 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #63 | Epoch Duration: 152.33683013916016
2020-01-13 11:18:16.920027 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #63 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2955756
Z variance train             0.017936686
KL Divergence                42.184834
KL Loss                      4.2184834
QF Loss                      221.41197
VF Loss                      191.10333
Policy Loss                  -3145.27
Q Predictions Mean           3150.162
Q Predictions Std            635.528
Q Predictions Max            3915.0315
Q Predictions Min            789.9081
V Predictions Mean           3153.9658
V Predictions Std            630.2397
V Predictions Max            3881.7188
V Predictions Min            805.0236
Log Pis Mean                 4.3061676
Log Pis Std                  3.3121684
Log Pis Max                  12.560189
Log Pis Min                  -2.450798
Policy mu Mean               -0.09751441
Policy mu Std                1.289393
Policy mu Max                2.7964532
Policy mu Min                -3.1209407
Policy log std Mean          -0.84839875
Policy log std Std           0.44669792
Policy log std Max           -0.09679508
Policy log std Min           -3.1385214
Z mean eval                  3.3179955
Z variance eval              0.002299289
total_rewards                [8922.87468186 8826.48844846 8937.25026843 8907.52576504 8902.53125003
 8804.80437995 8805.11973051 8935.51820288 8982.5916215  9005.42139844]
total_rewards_mean           8903.012574710077
total_rewards_std            66.74438674874735
total_rewards_max            9005.421398444569
total_rewards_min            8804.804379948897
Number of train steps total  260000
Number of env steps total    327000
Number of rollouts total     0
Train Time (s)               111.35519993212074
(Previous) Eval Time (s)     22.980570496991277
Sample Time (s)              16.356100347824395
Epoch Time (s)               150.6918707769364
Total Train Time (s)         9868.685344751924
Epoch                        64
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:20:47.665525 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #64 | Epoch Duration: 150.74528288841248
2020-01-13 11:20:47.665820 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #64 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3164277
Z variance train             0.002307551
KL Divergence                45.105087
KL Loss                      4.510509
QF Loss                      288.23953
VF Loss                      139.00917
Policy Loss                  -3190.2493
Q Predictions Mean           3187.1294
Q Predictions Std            639.44257
Q Predictions Max            3981.988
Q Predictions Min            788.8052
V Predictions Mean           3190.0518
V Predictions Std            634.4291
V Predictions Max            3968.4836
V Predictions Min            806.6358
Log Pis Mean                 4.8565855
Log Pis Std                  3.7878418
Log Pis Max                  14.6873665
Log Pis Min                  -8.214704
Policy mu Mean               -0.11287707
Policy mu Std                1.3457261
Policy mu Max                3.4205422
Policy mu Min                -3.076737
Policy log std Mean          -0.8480711
Policy log std Std           0.4186219
Policy log std Max           -0.10131031
Policy log std Min           -3.0708046
Z mean eval                  3.318891
Z variance eval              0.0012197641
total_rewards                [9099.97843381 9293.63307184 9261.0531422  8984.50785229 9151.94902665
 8970.09484168 9255.50807441 9259.83289611 9255.11318468 9131.14047603]
total_rewards_mean           9166.281099970114
total_rewards_std            112.77041826570415
total_rewards_max            9293.633071839178
total_rewards_min            8970.094841679156
Number of train steps total  264000
Number of env steps total    332000
Number of rollouts total     0
Train Time (s)               111.39493589941412
(Previous) Eval Time (s)     23.03368124179542
Sample Time (s)              17.06183737842366
Epoch Time (s)               151.4904545196332
Total Train Time (s)         10019.386956893839
Epoch                        65
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:23:18.366499 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #65 | Epoch Duration: 150.70048594474792
2020-01-13 11:23:18.366681 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3190968
Z variance train             0.0012233775
KL Divergence                45.223843
KL Loss                      4.522384
QF Loss                      295.7324
VF Loss                      107.11029
Policy Loss                  -3330.0837
Q Predictions Mean           3329.707
Q Predictions Std            531.14014
Q Predictions Max            4011.2827
Q Predictions Min            823.794
V Predictions Mean           3330.756
V Predictions Std            525.68396
V Predictions Max            3999.4011
V Predictions Min            822.7297
Log Pis Mean                 4.6665497
Log Pis Std                  3.4130533
Log Pis Max                  15.925748
Log Pis Min                  -3.2083552
Policy mu Mean               -0.14230765
Policy mu Std                1.3178576
Policy mu Max                3.2046702
Policy mu Min                -2.813477
Policy log std Mean          -0.85792106
Policy log std Std           0.43253264
Policy log std Max           0.046073854
Policy log std Min           -3.2191927
Z mean eval                  3.316904
Z variance eval              0.00046858285
total_rewards                [8607.19565296 8987.17959219 8694.90465729 8860.59829746 8982.00087094
 9046.74891188 9290.04637475 9317.35129849 9020.16543966 8792.71965418]
total_rewards_mean           8959.891074979241
total_rewards_std            219.45576418642767
total_rewards_max            9317.351298491198
total_rewards_min            8607.195652961269
Number of train steps total  268000
Number of env steps total    337000
Number of rollouts total     0
Train Time (s)               114.6075705033727
(Previous) Eval Time (s)     22.243416647426784
Sample Time (s)              16.275191727560014
Epoch Time (s)               153.1261788783595
Total Train Time (s)         10172.727759841364
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:25:51.708723 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #66 | Epoch Duration: 153.34192419052124
2020-01-13 11:25:51.708926 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #66 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.315791
Z variance train             0.0004681886
KL Divergence                46.00245
KL Loss                      4.600245
QF Loss                      336.49286
VF Loss                      98.91447
Policy Loss                  -3317.289
Q Predictions Mean           3316.2036
Q Predictions Std            534.3876
Q Predictions Max            4005.0254
Q Predictions Min            811.26904
V Predictions Mean           3321.489
V Predictions Std            528.8435
V Predictions Max            4012.6387
V Predictions Min            824.11383
Log Pis Mean                 4.693163
Log Pis Std                  3.5901363
Log Pis Max                  14.726756
Log Pis Min                  -6.1882763
Policy mu Mean               -0.08779479
Policy mu Std                1.3339108
Policy mu Max                3.6185613
Policy mu Min                -2.9852626
Policy log std Mean          -0.87016463
Policy log std Std           0.46188664
Policy log std Max           -0.031747878
Policy log std Min           -3.2491689
Z mean eval                  3.325576
Z variance eval              0.00078253297
total_rewards                [9108.82390489 9309.3647346  8766.65649817 9258.38266864 9196.3451336
 9103.15310307 9275.38965485 9240.75171318 9248.11403667 9499.93536305]
total_rewards_mean           9200.691681071597
total_rewards_std            179.01877891822366
total_rewards_max            9499.935363046216
total_rewards_min            8766.656498168302
Number of train steps total  272000
Number of env steps total    342000
Number of rollouts total     0
Train Time (s)               116.40086278738454
(Previous) Eval Time (s)     22.45888067735359
Sample Time (s)              16.21531151328236
Epoch Time (s)               155.0750549780205
Total Train Time (s)         10328.652030120604
Epoch                        67
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:28:27.636989 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #67 | Epoch Duration: 155.92788887023926
2020-01-13 11:28:27.637282 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #67 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.323478
Z variance train             0.0007820553
KL Divergence                45.64746
KL Loss                      4.5647464
QF Loss                      280.8157
VF Loss                      256.7265
Policy Loss                  -3304.7117
Q Predictions Mean           3313.5647
Q Predictions Std            631.3592
Q Predictions Max            4042.3535
Q Predictions Min            797.38666
V Predictions Mean           3318.9897
V Predictions Std            623.018
V Predictions Max            4030.0205
V Predictions Min            831.2318
Log Pis Mean                 4.7421494
Log Pis Std                  3.7810369
Log Pis Max                  14.644079
Log Pis Min                  -6.5944304
Policy mu Mean               -0.11479815
Policy mu Std                1.3313677
Policy mu Max                3.0132253
Policy mu Min                -3.0526278
Policy log std Mean          -0.86070085
Policy log std Std           0.44723436
Policy log std Max           -0.08642429
Policy log std Min           -3.0954156
Z mean eval                  3.3226724
Z variance eval              0.001502869
total_rewards                [9367.94315507 9395.65864681 9397.05867155 9451.67777825 9477.7561613
 9426.52007695 9373.99722137 9404.27463474 9317.67837456 9516.36535123]
total_rewards_mean           9412.893007183568
total_rewards_std            54.61220886454207
total_rewards_max            9516.36535122914
total_rewards_min            9317.678374563777
Number of train steps total  276000
Number of env steps total    347000
Number of rollouts total     0
Train Time (s)               111.84374458622187
(Previous) Eval Time (s)     23.311384194996208
Sample Time (s)              15.58711874531582
Epoch Time (s)               150.7422475265339
Total Train Time (s)         10479.437369698193
Epoch                        68
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:30:58.423734 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #68 | Epoch Duration: 150.78622698783875
2020-01-13 11:30:58.423999 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #68 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3244033
Z variance train             0.0015098441
KL Divergence                45.97463
KL Loss                      4.597463
QF Loss                      219.42953
VF Loss                      236.29733
Policy Loss                  -3439.111
Q Predictions Mean           3429.72
Q Predictions Std            497.01492
Q Predictions Max            4046.2092
Q Predictions Min            825.9297
V Predictions Mean           3433.773
V Predictions Std            490.83084
V Predictions Max            4033.9944
V Predictions Min            831.31464
Log Pis Mean                 4.9142127
Log Pis Std                  3.6012924
Log Pis Max                  13.4643135
Log Pis Min                  -4.85083
Policy mu Mean               -0.13705584
Policy mu Std                1.318384
Policy mu Max                3.0223444
Policy mu Min                -3.0794437
Policy log std Mean          -0.87325567
Policy log std Std           0.44462982
Policy log std Max           -0.10595429
Policy log std Min           -3.2033923
Z mean eval                  3.3163257
Z variance eval              0.0013040219
total_rewards                [9168.97371421 9278.35648973 9426.63511539 9488.39120388 5121.5127007
 9416.85765461 9072.70971707 9381.84492524 9343.31267712 9267.32938474]
total_rewards_mean           8896.592358268845
total_rewards_std            1263.9818597051437
total_rewards_max            9488.391203876905
total_rewards_min            5121.512700700205
Number of train steps total  280000
Number of env steps total    352000
Number of rollouts total     0
Train Time (s)               111.75836385507137
(Previous) Eval Time (s)     23.355085057206452
Sample Time (s)              15.820680388249457
Epoch Time (s)               150.93412930052727
Total Train Time (s)         10629.906603586394
Epoch                        69
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:33:28.895140 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #69 | Epoch Duration: 150.47093224525452
2020-01-13 11:33:28.895420 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #69 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3176064
Z variance train             0.0013089656
KL Divergence                45.825813
KL Loss                      4.5825815
QF Loss                      392.78067
VF Loss                      112.01821
Policy Loss                  -3296.6262
Q Predictions Mean           3284.592
Q Predictions Std            600.88043
Q Predictions Max            3996.3806
Q Predictions Min            794.2217
V Predictions Mean           3292.1177
V Predictions Std            586.27313
V Predictions Max            4010.9282
V Predictions Min            825.2225
Log Pis Mean                 4.579363
Log Pis Std                  3.6217647
Log Pis Max                  13.658705
Log Pis Min                  -6.45968
Policy mu Mean               -0.09094989
Policy mu Std                1.3136777
Policy mu Max                2.8090897
Policy mu Min                -2.87962
Policy log std Mean          -0.8524588
Policy log std Std           0.44359195
Policy log std Max           -0.11210829
Policy log std Min           -3.261185
Z mean eval                  3.319542
Z variance eval              0.0015363976
total_rewards                [9134.87699216 9288.73808593 9179.40870849 9392.82755324 9362.33361749
 9389.71014178 9429.72292409 9311.45110322 9547.80639108 9180.59040779]
total_rewards_mean           9321.746592526733
total_rewards_std            122.630225543418
total_rewards_max            9547.806391076532
total_rewards_min            9134.876992159285
Number of train steps total  284000
Number of env steps total    357000
Number of rollouts total     0
Train Time (s)               114.34195066569373
(Previous) Eval Time (s)     22.89154753088951
Sample Time (s)              16.07065529609099
Epoch Time (s)               153.30415349267423
Total Train Time (s)         10783.68201718852
Epoch                        70
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:36:02.671956 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #70 | Epoch Duration: 153.7763319015503
2020-01-13 11:36:02.672197 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #70 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3220253
Z variance train             0.0015413465
KL Divergence                44.42192
KL Loss                      4.442192
QF Loss                      244.99023
VF Loss                      131.55742
Policy Loss                  -3380.9785
Q Predictions Mean           3381.511
Q Predictions Std            540.71027
Q Predictions Max            4115.261
Q Predictions Min            822.4748
V Predictions Mean           3373.4834
V Predictions Std            533.76733
V Predictions Max            4106.228
V Predictions Min            816.3761
Log Pis Mean                 4.9485245
Log Pis Std                  3.7651823
Log Pis Max                  14.473335
Log Pis Min                  -4.0577974
Policy mu Mean               -0.15653318
Policy mu Std                1.3473997
Policy mu Max                3.290332
Policy mu Min                -2.9997382
Policy log std Mean          -0.874502
Policy log std Std           0.44857416
Policy log std Max           -0.09768444
Policy log std Min           -3.1086712
Z mean eval                  3.3189073
Z variance eval              0.0031166726
total_rewards                [9146.20184733 9325.17039173 9166.8239104  9395.68663022 9209.56017317
 9189.66930356 9247.5680811  9159.07525195 9211.43641697 9362.37902317]
total_rewards_mean           9241.3571029614
total_rewards_std            84.548858688112
total_rewards_max            9395.686630223776
total_rewards_min            9146.201847326052
Number of train steps total  288000
Number of env steps total    362000
Number of rollouts total     0
Train Time (s)               117.1123698442243
(Previous) Eval Time (s)     23.363405500072986
Sample Time (s)              16.09360772324726
Epoch Time (s)               156.56938306754455
Total Train Time (s)         10939.907448088285
Epoch                        71
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:38:38.898668 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #71 | Epoch Duration: 156.2263162136078
2020-01-13 11:38:38.898854 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #71 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3171113
Z variance train             0.0031174165
KL Divergence                43.850693
KL Loss                      4.3850694
QF Loss                      404.03928
VF Loss                      130.93713
Policy Loss                  -3341.4216
Q Predictions Mean           3339.9749
Q Predictions Std            609.9706
Q Predictions Max            4085.4392
Q Predictions Min            804.75653
V Predictions Mean           3343.7522
V Predictions Std            602.1612
V Predictions Max            4071.4885
V Predictions Min            824.464
Log Pis Mean                 5.42879
Log Pis Std                  3.5873964
Log Pis Max                  14.82877
Log Pis Min                  -1.9944663
Policy mu Mean               -0.06158762
Policy mu Std                1.381677
Policy mu Max                3.4314682
Policy mu Min                -3.1749918
Policy log std Mean          -0.8722825
Policy log std Std           0.44741186
Policy log std Max           -0.09392971
Policy log std Min           -3.1875803
Z mean eval                  3.322583
Z variance eval              0.0011329383
total_rewards                [9262.39329605 9498.3043152  9351.1782447  9463.2391256  9486.606386
 9465.40624119 9509.80392192 9471.88590371 9493.14064301 9600.95445899]
total_rewards_mean           9460.291253637899
total_rewards_std            87.57439259248135
total_rewards_max            9600.95445899415
total_rewards_min            9262.393296045433
Number of train steps total  292000
Number of env steps total    367000
Number of rollouts total     0
Train Time (s)               113.03231612825766
(Previous) Eval Time (s)     23.020063323900104
Sample Time (s)              16.42729680193588
Epoch Time (s)               152.47967625409365
Total Train Time (s)         11092.235586750787
Epoch                        72
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:41:11.230848 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #72 | Epoch Duration: 152.3318178653717
2020-01-13 11:41:11.231170 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #72 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.321069
Z variance train             0.0011344944
KL Divergence                43.97033
KL Loss                      4.397033
QF Loss                      220.06787
VF Loss                      84.472244
Policy Loss                  -3401.9326
Q Predictions Mean           3399.3877
Q Predictions Std            588.72504
Q Predictions Max            4114.062
Q Predictions Min            778.1827
V Predictions Mean           3400.4885
V Predictions Std            584.2053
V Predictions Max            4114.529
V Predictions Min            806.06335
Log Pis Mean                 5.0163016
Log Pis Std                  3.9022124
Log Pis Max                  14.365626
Log Pis Min                  -4.2544994
Policy mu Mean               -0.14421183
Policy mu Std                1.3560472
Policy mu Max                3.3172755
Policy mu Min                -3.0483785
Policy log std Mean          -0.84401935
Policy log std Std           0.43630928
Policy log std Max           -0.067598164
Policy log std Min           -2.987434
Z mean eval                  3.3100052
Z variance eval              0.00801898
total_rewards                [9407.96911079 9462.27485245 9456.46520248 9494.5878405  9441.5146644
 9605.33288809 9523.19279034 9347.56811608 9436.6457285  9443.33713651]
total_rewards_mean           9461.888833014378
total_rewards_std            65.42645586486034
total_rewards_max            9605.332888090808
total_rewards_min            9347.568116079361
Number of train steps total  296000
Number of env steps total    372000
Number of rollouts total     0
Train Time (s)               106.67015752382576
(Previous) Eval Time (s)     22.871861944906414
Sample Time (s)              16.735089662950486
Epoch Time (s)               146.27710913168266
Total Train Time (s)         11239.092819021083
Epoch                        73
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:43:38.087150 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #73 | Epoch Duration: 146.8557550907135
2020-01-13 11:43:38.087317 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #73 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3084683
Z variance train             0.008064324
KL Divergence                41.38846
KL Loss                      4.138846
QF Loss                      374.11212
VF Loss                      82.79316
Policy Loss                  -3354.576
Q Predictions Mean           3354.163
Q Predictions Std            640.1393
Q Predictions Max            4112.8184
Q Predictions Min            779.30963
V Predictions Mean           3355.9866
V Predictions Std            634.17523
V Predictions Max            4102.236
V Predictions Min            799.10974
Log Pis Mean                 4.938592
Log Pis Std                  3.6102996
Log Pis Max                  13.054233
Log Pis Min                  -3.3391762
Policy mu Mean               -0.11041417
Policy mu Std                1.3490908
Policy mu Max                3.0763195
Policy mu Min                -2.9801815
Policy log std Mean          -0.85535383
Policy log std Std           0.4450787
Policy log std Max           -0.03681898
Policy log std Min           -3.100387
Z mean eval                  3.2831047
Z variance eval              0.026139632
total_rewards                [9352.32576644 9433.66265616 9514.37054859 9693.98679253 9330.80114084
 9544.58285216 9383.52528726 9404.32652698 9534.76017697 9631.60452625]
total_rewards_mean           9482.394627417407
total_rewards_std            115.24317653433687
total_rewards_max            9693.986792530599
total_rewards_min            9330.801140844183
Number of train steps total  300000
Number of env steps total    377000
Number of rollouts total     0
Train Time (s)               111.42427693493664
(Previous) Eval Time (s)     23.45020188903436
Sample Time (s)              16.399622633121908
Epoch Time (s)               151.2741014570929
Total Train Time (s)         11389.874198077247
Epoch                        74
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:46:08.872347 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #74 | Epoch Duration: 150.78486919403076
2020-01-13 11:46:08.872624 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #74 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2830734
Z variance train             0.026179457
KL Divergence                37.74807
KL Loss                      3.774807
QF Loss                      268.36023
VF Loss                      125.41214
Policy Loss                  -3358.7056
Q Predictions Mean           3358.8477
Q Predictions Std            719.7687
Q Predictions Max            4157.534
Q Predictions Min            744.65234
V Predictions Mean           3357.1694
V Predictions Std            714.1605
V Predictions Max            4139.473
V Predictions Min            749.3114
Log Pis Mean                 4.600168
Log Pis Std                  3.7252862
Log Pis Max                  14.737322
Log Pis Min                  -4.5945616
Policy mu Mean               -0.10792761
Policy mu Std                1.3308198
Policy mu Max                3.1711626
Policy mu Min                -2.9405
Policy log std Mean          -0.85202533
Policy log std Std           0.46550766
Policy log std Max           -0.015382826
Policy log std Min           -3.0753527
Z mean eval                  3.3243911
Z variance eval              0.008950126
total_rewards                [9566.30907466 9577.46781847 9514.80222159 9695.81894052 9621.83770512
 9516.68305202 9612.92191629 9404.95854287 9534.58731061 9679.08200689]
total_rewards_mean           9572.446858904874
total_rewards_std            81.6397461234057
total_rewards_max            9695.818940518167
total_rewards_min            9404.958542872198
Number of train steps total  304000
Number of env steps total    382000
Number of rollouts total     0
Train Time (s)               118.68912614602596
(Previous) Eval Time (s)     22.96068706922233
Sample Time (s)              17.25345416693017
Epoch Time (s)               158.90326738217846
Total Train Time (s)         11548.773309933953
Epoch                        75
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:48:47.776656 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #75 | Epoch Duration: 158.90379810333252
2020-01-13 11:48:47.776960 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #75 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.323976
Z variance train             0.008956762
KL Divergence                40.139294
KL Loss                      4.0139294
QF Loss                      305.46432
VF Loss                      123.72922
Policy Loss                  -3419.1775
Q Predictions Mean           3418.0635
Q Predictions Std            647.3521
Q Predictions Max            4154.886
Q Predictions Min            754.0562
V Predictions Mean           3416.8704
V Predictions Std            641.54315
V Predictions Max            4150.9346
V Predictions Min            751.0272
Log Pis Mean                 5.1459928
Log Pis Std                  3.6183581
Log Pis Max                  14.800925
Log Pis Min                  -3.306078
Policy mu Mean               -0.046666276
Policy mu Std                1.3422946
Policy mu Max                3.1090372
Policy mu Min                -2.797279
Policy log std Mean          -0.8764377
Policy log std Std           0.45961127
Policy log std Max           -0.13414848
Policy log std Min           -2.9565063
Z mean eval                  3.3337905
Z variance eval              0.015002226
total_rewards                [9483.52211802 9510.55146008 9585.8575778  9684.1684132  9523.29313442
 2346.58337774 9533.66161692 9357.83744262 9623.85544704 9672.24407307]
total_rewards_mean           8832.157466090675
total_rewards_std            2163.788328658941
total_rewards_max            9684.168413198684
total_rewards_min            2346.583377738473
Number of train steps total  308000
Number of env steps total    387000
Number of rollouts total     0
Train Time (s)               115.54089845903218
(Previous) Eval Time (s)     22.96088885003701
Sample Time (s)              17.407338412012905
Epoch Time (s)               155.9091257210821
Total Train Time (s)         11704.505401883274
Epoch                        76
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:51:23.505945 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #76 | Epoch Duration: 155.72878313064575
2020-01-13 11:51:23.506101 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #76 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3315327
Z variance train             0.015106918
KL Divergence                39.159603
KL Loss                      3.9159603
QF Loss                      250.95102
VF Loss                      122.445816
Policy Loss                  -3542.117
Q Predictions Mean           3539.26
Q Predictions Std            544.51337
Q Predictions Max            4197.4683
Q Predictions Min            736.29663
V Predictions Mean           3544.0808
V Predictions Std            539.8858
V Predictions Max            4201.2856
V Predictions Min            744.51733
Log Pis Mean                 5.2141643
Log Pis Std                  3.6153393
Log Pis Max                  15.860195
Log Pis Min                  -3.9964309
Policy mu Mean               -0.07640494
Policy mu Std                1.3688828
Policy mu Max                3.0735488
Policy mu Min                -3.3008935
Policy log std Mean          -0.8653571
Policy log std Std           0.45676863
Policy log std Max           -0.17628098
Policy log std Min           -3.114747
Z mean eval                  3.3510127
Z variance eval              0.0064722397
total_rewards                [9541.77304379 9676.18030688 9597.20606532 9688.63612245 9658.17713133
 9496.53959809 9611.25285913 9322.19458173 9368.77380292 9718.87852265]
total_rewards_mean           9567.96120342979
total_rewards_std            128.75632372956983
total_rewards_max            9718.878522652509
total_rewards_min            9322.194581725085
Number of train steps total  312000
Number of env steps total    392000
Number of rollouts total     0
Train Time (s)               108.81062187207863
(Previous) Eval Time (s)     22.780269108712673
Sample Time (s)              16.38738150615245
Epoch Time (s)               147.97827248694375
Total Train Time (s)         11852.942603080068
Epoch                        77
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:53:51.945269 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #77 | Epoch Duration: 148.4390366077423
2020-01-13 11:53:51.945466 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3522143
Z variance train             0.006470873
KL Divergence                40.52701
KL Loss                      4.0527015
QF Loss                      278.05878
VF Loss                      126.79961
Policy Loss                  -3581.872
Q Predictions Mean           3586.9097
Q Predictions Std            545.07074
Q Predictions Max            4276.1084
Q Predictions Min            729.9324
V Predictions Mean           3587.7656
V Predictions Std            537.4402
V Predictions Max            4278.168
V Predictions Min            747.69037
Log Pis Mean                 4.896769
Log Pis Std                  3.4150124
Log Pis Max                  13.940433
Log Pis Min                  -5.5241575
Policy mu Mean               -0.10203282
Policy mu Std                1.3635345
Policy mu Max                2.764274
Policy mu Min                -3.1646967
Policy log std Mean          -0.87459797
Policy log std Std           0.45585194
Policy log std Max           -0.17388237
Policy log std Min           -3.2037036
Z mean eval                  3.355577
Z variance eval              0.01201407
total_rewards                [9355.72071904 9555.30253564 9466.6251618  9687.30629079 9477.58479722
 9605.5667503  9494.77407951 9426.99011399 9380.35811112 9440.67253281]
total_rewards_mean           9489.090109222965
total_rewards_std            96.80940776033025
total_rewards_max            9687.306290785395
total_rewards_min            9355.720719042767
Number of train steps total  316000
Number of env steps total    397000
Number of rollouts total     0
Train Time (s)               116.03680856293067
(Previous) Eval Time (s)     23.240717665757984
Sample Time (s)              15.892886739224195
Epoch Time (s)               155.17041296791285
Total Train Time (s)         12007.838694123086
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:56:26.842565 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #78 | Epoch Duration: 154.89695763587952
2020-01-13 11:56:26.842728 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3536713
Z variance train             0.0120210005
KL Divergence                40.048172
KL Loss                      4.0048175
QF Loss                      369.44025
VF Loss                      220.17511
Policy Loss                  -3554.9512
Q Predictions Mean           3554.9653
Q Predictions Std            666.4297
Q Predictions Max            4285.933
Q Predictions Min            720.0857
V Predictions Mean           3562.6604
V Predictions Std            664.2349
V Predictions Max            4295.864
V Predictions Min            737.74384
Log Pis Mean                 5.042969
Log Pis Std                  3.820838
Log Pis Max                  15.775566
Log Pis Min                  -5.337655
Policy mu Mean               -0.12651785
Policy mu Std                1.3680366
Policy mu Max                3.096446
Policy mu Min                -2.9188933
Policy log std Mean          -0.87427694
Policy log std Std           0.46720585
Policy log std Max           -0.1349813
Policy log std Min           -3.2269444
Z mean eval                  3.361379
Z variance eval              0.0070340843
total_rewards                [9413.19477801 9415.41313212 9394.35291517 9525.08547977 9508.03524655
 9411.12309599 9522.59397459 9623.2327151  9414.01634178 9473.79107676]
total_rewards_mean           9470.08387558278
total_rewards_std            70.19364911648366
total_rewards_max            9623.232715100674
total_rewards_min            9394.352915165133
Number of train steps total  320000
Number of env steps total    402000
Number of rollouts total     0
Train Time (s)               115.35104324901477
(Previous) Eval Time (s)     22.966977381147444
Sample Time (s)              16.887034901883453
Epoch Time (s)               155.20505553204566
Total Train Time (s)         12162.549758031499
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:59:01.558608 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #79 | Epoch Duration: 154.71572184562683
2020-01-13 11:59:01.558897 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #79 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3610578
Z variance train             0.007044965
KL Divergence                40.574326
KL Loss                      4.0574327
QF Loss                      385.96936
VF Loss                      214.65211
Policy Loss                  -3504.5269
Q Predictions Mean           3511.7778
Q Predictions Std            692.92615
Q Predictions Max            4228.856
Q Predictions Min            707.04675
V Predictions Mean           3516.3252
V Predictions Std            687.6536
V Predictions Max            4224.054
V Predictions Min            713.2465
Log Pis Mean                 5.446905
Log Pis Std                  3.9072902
Log Pis Max                  16.893335
Log Pis Min                  -3.5983481
Policy mu Mean               -0.09538912
Policy mu Std                1.3773279
Policy mu Max                3.2173138
Policy mu Min                -3.1474013
Policy log std Mean          -0.8804173
Policy log std Std           0.46537435
Policy log std Max           -0.09291983
Policy log std Min           -3.0317583
Z mean eval                  3.351792
Z variance eval              0.009166891
total_rewards                [9386.61561258 9468.80553587 9667.76057949 9452.26513607 9581.22895964
 9326.13189222 9530.42902066 9304.71423128 9626.22829501 9592.4608451 ]
total_rewards_mean           9493.664010791712
total_rewards_std            120.09296626608646
total_rewards_max            9667.760579486923
total_rewards_min            9304.714231275226
Number of train steps total  324000
Number of env steps total    407000
Number of rollouts total     0
Train Time (s)               116.29440924106166
(Previous) Eval Time (s)     22.477297235745937
Sample Time (s)              16.00653186859563
Epoch Time (s)               154.77823834540322
Total Train Time (s)         12317.178787097335
Epoch                        80
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:01:36.186080 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #80 | Epoch Duration: 154.62698340415955
2020-01-13 12:01:36.186235 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #80 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3523414
Z variance train             0.009176208
KL Divergence                40.474674
KL Loss                      4.0474677
QF Loss                      249.49335
VF Loss                      93.61436
Policy Loss                  -3575.464
Q Predictions Mean           3578.8071
Q Predictions Std            574.30524
Q Predictions Max            4321.604
Q Predictions Min            653.79407
V Predictions Mean           3570.4443
V Predictions Std            569.3991
V Predictions Max            4298.9766
V Predictions Min            645.53076
Log Pis Mean                 4.953103
Log Pis Std                  3.7931833
Log Pis Max                  17.3562
Log Pis Min                  -4.555927
Policy mu Mean               -0.14332406
Policy mu Std                1.3354207
Policy mu Max                3.6217027
Policy mu Min                -4.1484623
Policy log std Mean          -0.88951874
Policy log std Std           0.47296694
Policy log std Max           0.042911768
Policy log std Min           -3.220768
Z mean eval                  3.3503795
Z variance eval              0.022739481
total_rewards                [9547.70769578 9561.66808621 9588.03864861 9460.5706251  9387.05538346
 9602.17519437 9341.8252008  9603.26780619 9344.84774823 9471.17908372]
total_rewards_mean           9490.83354724744
total_rewards_std            99.15989505670703
total_rewards_max            9603.267806191408
total_rewards_min            9341.825200799298
Number of train steps total  328000
Number of env steps total    412000
Number of rollouts total     0
Train Time (s)               111.7310673580505
(Previous) Eval Time (s)     22.325744600966573
Sample Time (s)              16.39988266583532
Epoch Time (s)               150.4566946248524
Total Train Time (s)         12468.058856944554
Epoch                        81
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:04:07.067748 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #81 | Epoch Duration: 150.8813920021057
2020-01-13 12:04:07.067955 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #81 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3491807
Z variance train             0.022772038
KL Divergence                39.65535
KL Loss                      3.965535
QF Loss                      278.39325
VF Loss                      360.72214
Policy Loss                  -3566.1204
Q Predictions Mean           3568.6018
Q Predictions Std            609.3722
Q Predictions Max            4310.733
Q Predictions Min            711.8893
V Predictions Mean           3581.9624
V Predictions Std            607.9778
V Predictions Max            4311.289
V Predictions Min            706.61945
Log Pis Mean                 4.8388853
Log Pis Std                  3.3891962
Log Pis Max                  12.846286
Log Pis Min                  -4.314707
Policy mu Mean               -0.120226644
Policy mu Std                1.3492732
Policy mu Max                2.865824
Policy mu Min                -3.041879
Policy log std Mean          -0.86772823
Policy log std Std           0.46667835
Policy log std Max           0.24231732
Policy log std Min           -3.1178508
Z mean eval                  3.3578858
Z variance eval              0.015278807
total_rewards                [9779.57927669 9655.95905425 9896.57679891 9713.99052655 9701.0925289
 5990.6529857  9860.40560969 9736.42244387 9709.83946737 9731.88288703]
total_rewards_mean           9377.640157895617
total_rewards_std            1131.1665798905838
total_rewards_max            9896.5767989144
total_rewards_min            5990.652985701545
Number of train steps total  332000
Number of env steps total    417000
Number of rollouts total     0
Train Time (s)               113.86780890682712
(Previous) Eval Time (s)     22.750134625006467
Sample Time (s)              15.63635983504355
Epoch Time (s)               152.25430336687714
Total Train Time (s)         12620.519256254192
Epoch                        82
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:06:39.531239 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #82 | Epoch Duration: 152.46312737464905
2020-01-13 12:06:39.531458 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #82 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3574996
Z variance train             0.015270928
KL Divergence                38.880394
KL Loss                      3.8880394
QF Loss                      268.29272
VF Loss                      242.09096
Policy Loss                  -3487.8765
Q Predictions Mean           3490.5278
Q Predictions Std            751.22864
Q Predictions Max            4313.5996
Q Predictions Min            709.1231
V Predictions Mean           3497.065
V Predictions Std            742.4548
V Predictions Max            4294.9595
V Predictions Min            728.0562
Log Pis Mean                 5.181021
Log Pis Std                  3.8215659
Log Pis Max                  23.184612
Log Pis Min                  -4.297097
Policy mu Mean               -0.10023331
Policy mu Std                1.3439077
Policy mu Max                3.0390282
Policy mu Min                -4.4098196
Policy log std Mean          -0.8866939
Policy log std Std           0.46409386
Policy log std Max           -0.092642784
Policy log std Min           -3.0814652
Z mean eval                  3.3663335
Z variance eval              0.0038273267
total_rewards                [9638.17247901 9487.1406617  9821.62714358 9720.3527865  9777.00870871
 9837.58195345 9797.24886158 9734.7752624  9793.8929124  9767.52684742]
total_rewards_mean           9737.532761673978
total_rewards_std            99.57590343291957
total_rewards_max            9837.581953445071
total_rewards_min            9487.140661699132
Number of train steps total  336000
Number of env steps total    422000
Number of rollouts total     0
Train Time (s)               117.02641464676708
(Previous) Eval Time (s)     22.958644608967006
Sample Time (s)              15.699275881052017
Epoch Time (s)               155.6843351367861
Total Train Time (s)         12776.291505330242
Epoch                        83
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:09:15.305443 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #83 | Epoch Duration: 155.77379369735718
2020-01-13 12:09:15.305707 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3644001
Z variance train             0.0038106642
KL Divergence                42.17828
KL Loss                      4.2178283
QF Loss                      306.9472
VF Loss                      233.5017
Policy Loss                  -3546.0103
Q Predictions Mean           3542.3735
Q Predictions Std            665.2783
Q Predictions Max            4280.721
Q Predictions Min            687.1648
V Predictions Mean           3540.3262
V Predictions Std            649.0328
V Predictions Max            4272.0107
V Predictions Min            712.3601
Log Pis Mean                 5.2520237
Log Pis Std                  3.8036954
Log Pis Max                  13.790169
Log Pis Min                  -5.964398
Policy mu Mean               -0.11098812
Policy mu Std                1.381564
Policy mu Max                2.9382389
Policy mu Min                -3.0891333
Policy log std Mean          -0.8886846
Policy log std Std           0.487915
Policy log std Max           -0.0475443
Policy log std Min           -3.1702454
Z mean eval                  3.3571835
Z variance eval              0.0043074656
total_rewards                [9680.45101814 9742.01639362 9673.12867044 9534.60984797 9930.90553225
 9696.40239256 9688.91155655 9774.08196935 9673.89463969 9826.21709177]
total_rewards_mean           9722.061911234337
total_rewards_std            100.45390731472091
total_rewards_max            9930.905532253508
total_rewards_min            9534.609847974754
Number of train steps total  340000
Number of env steps total    427000
Number of rollouts total     0
Train Time (s)               115.14436462987214
(Previous) Eval Time (s)     23.047829766292125
Sample Time (s)              16.503474716562778
Epoch Time (s)               154.69566911272705
Total Train Time (s)         12931.238565695006
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:11:50.256242 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #84 | Epoch Duration: 154.9503185749054
2020-01-13 12:11:50.256516 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #84 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.357509
Z variance train             0.0043125697
KL Divergence                42.326675
KL Loss                      4.2326674
QF Loss                      282.5667
VF Loss                      109.16291
Policy Loss                  -3525.1147
Q Predictions Mean           3525.5464
Q Predictions Std            666.632
Q Predictions Max            4331.4526
Q Predictions Min            724.1459
V Predictions Mean           3520.6396
V Predictions Std            661.0731
V Predictions Max            4310.185
V Predictions Min            733.8321
Log Pis Mean                 5.532323
Log Pis Std                  3.830499
Log Pis Max                  16.170593
Log Pis Min                  -4.643483
Policy mu Mean               -0.06862482
Policy mu Std                1.4001563
Policy mu Max                3.2954543
Policy mu Min                -3.2793515
Policy log std Mean          -0.8507717
Policy log std Std           0.46842766
Policy log std Max           -0.13099629
Policy log std Min           -3.262535
Z mean eval                  3.3559613
Z variance eval              0.0015112432
total_rewards                [9495.80446474 9803.66166783 9716.88035295 9600.7859691  9754.89261233
 9698.19808714 9713.20693672 9763.06971665 9573.11962031 9675.86213453]
total_rewards_mean           9679.548156231269
total_rewards_std            90.68465940830436
total_rewards_max            9803.661667829467
total_rewards_min            9495.804464740606
Number of train steps total  344000
Number of env steps total    432000
Number of rollouts total     0
Train Time (s)               111.59970424836501
(Previous) Eval Time (s)     23.302171380259097
Sample Time (s)              15.671796306036413
Epoch Time (s)               150.57367193466052
Total Train Time (s)         13081.311917562969
Epoch                        85
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:14:20.329472 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #85 | Epoch Duration: 150.0727574825287
2020-01-13 12:14:20.329669 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #85 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3547282
Z variance train             0.0015122571
KL Divergence                44.538887
KL Loss                      4.453889
QF Loss                      320.93024
VF Loss                      100.58473
Policy Loss                  -3579.5981
Q Predictions Mean           3576.7588
Q Predictions Std            719.01984
Q Predictions Max            4314.1826
Q Predictions Min            745.32544
V Predictions Mean           3578.1406
V Predictions Std            712.4533
V Predictions Max            4297.8374
V Predictions Min            774.2337
Log Pis Mean                 5.2265167
Log Pis Std                  3.5681202
Log Pis Max                  15.324054
Log Pis Min                  -5.8434353
Policy mu Mean               -0.066104606
Policy mu Std                1.382739
Policy mu Max                3.2578146
Policy mu Min                -3.2074013
Policy log std Mean          -0.8769498
Policy log std Std           0.46832567
Policy log std Max           -0.10553193
Policy log std Min           -3.0891302
Z mean eval                  3.3578346
Z variance eval              0.0011229666
total_rewards                [9457.82175414 9693.80198078 9582.69427458 9580.16972251 9611.19333939
 9645.01462453 9736.73196888 9488.62832926 9659.71112245 9511.95980803]
total_rewards_mean           9596.772692453735
total_rewards_std            86.12166931808213
total_rewards_max            9736.731968881137
total_rewards_min            9457.821754143984
Number of train steps total  348000
Number of env steps total    437000
Number of rollouts total     0
Train Time (s)               112.47366007231176
(Previous) Eval Time (s)     22.800985565874726
Sample Time (s)              16.089714402798563
Epoch Time (s)               151.36436004098505
Total Train Time (s)         13232.479831692297
Epoch                        86
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:16:51.501259 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #86 | Epoch Duration: 151.17141008377075
2020-01-13 12:16:51.501547 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #86 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3589387
Z variance train             0.0011205666
KL Divergence                44.91861
KL Loss                      4.491861
QF Loss                      298.3164
VF Loss                      110.68388
Policy Loss                  -3604.7927
Q Predictions Mean           3600.7612
Q Predictions Std            551.31604
Q Predictions Max            4346.9634
Q Predictions Min            749.1649
V Predictions Mean           3605.0122
V Predictions Std            548.6749
V Predictions Max            4350.589
V Predictions Min            755.6525
Log Pis Mean                 5.0448914
Log Pis Std                  3.605228
Log Pis Max                  14.337148
Log Pis Min                  -3.6704545
Policy mu Mean               -0.13241722
Policy mu Std                1.331702
Policy mu Max                3.0101092
Policy mu Min                -2.957913
Policy log std Mean          -0.8950903
Policy log std Std           0.48457843
Policy log std Max           -0.104656726
Policy log std Min           -3.096925
Z mean eval                  3.3398864
Z variance eval              0.0016527504
total_rewards                [1168.26713184 9693.99522681 8451.03594063 9758.31209589 9619.85189347
 5816.09232726 9721.863508   9643.88228319 9672.74928682 9838.18148083]
total_rewards_mean           8338.423117473158
total_rewards_std            2663.259726469007
total_rewards_max            9838.18148082783
total_rewards_min            1168.2671318355096
Number of train steps total  352000
Number of env steps total    442000
Number of rollouts total     0
Train Time (s)               112.51012570410967
(Previous) Eval Time (s)     22.607730793301016
Sample Time (s)              16.76005276106298
Epoch Time (s)               151.87790925847366
Total Train Time (s)         13384.180050386582
Epoch                        87
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:19:23.203707 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #87 | Epoch Duration: 151.7019054889679
2020-01-13 12:19:23.204012 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3415947
Z variance train             0.0016557295
KL Divergence                44.63852
KL Loss                      4.463852
QF Loss                      262.0558
VF Loss                      360.9286
Policy Loss                  -3652.117
Q Predictions Mean           3646.691
Q Predictions Std            512.1003
Q Predictions Max            4312.403
Q Predictions Min            759.2493
V Predictions Mean           3635.9504
V Predictions Std            503.61218
V Predictions Max            4287.11
V Predictions Min            756.1448
Log Pis Mean                 4.8286095
Log Pis Std                  3.561214
Log Pis Max                  13.988458
Log Pis Min                  -6.1367545
Policy mu Mean               -0.14501785
Policy mu Std                1.3168298
Policy mu Max                2.9322243
Policy mu Min                -3.0550973
Policy log std Mean          -0.8772134
Policy log std Std           0.45829841
Policy log std Max           -0.16177309
Policy log std Min           -3.1724315
Z mean eval                  3.3415534
Z variance eval              0.015119024
total_rewards                [9561.8748053  9720.68781411 9851.62573443 9781.08349385 9915.26500517
 9808.4624586  9927.70869576 9948.40271687 9972.59221573 9864.5120866 ]
total_rewards_mean           9835.22150264383
total_rewards_std            118.00505649192618
total_rewards_max            9972.59221573226
total_rewards_min            9561.874805303087
Number of train steps total  356000
Number of env steps total    447000
Number of rollouts total     0
Train Time (s)               113.02076843567193
(Previous) Eval Time (s)     22.431419871747494
Sample Time (s)              16.475363945122808
Epoch Time (s)               151.92755225254223
Total Train Time (s)         13536.34980137879
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:21:55.376326 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #88 | Epoch Duration: 152.17208337783813
2020-01-13 12:21:55.376616 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #88 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3435636
Z variance train             0.01512479
KL Divergence                41.87399
KL Loss                      4.187399
QF Loss                      240.97437
VF Loss                      155.5169
Policy Loss                  -3472.0208
Q Predictions Mean           3464.7114
Q Predictions Std            770.68005
Q Predictions Max            4308.612
Q Predictions Min            698.46716
V Predictions Mean           3466.0645
V Predictions Std            763.65765
V Predictions Max            4300.4814
V Predictions Min            693.7124
Log Pis Mean                 4.652382
Log Pis Std                  3.889395
Log Pis Max                  19.410603
Log Pis Min                  -9.890769
Policy mu Mean               -0.0797892
Policy mu Std                1.3155465
Policy mu Max                2.7644205
Policy mu Min                -3.3335938
Policy log std Mean          -0.8600693
Policy log std Std           0.434207
Policy log std Max           -0.09224039
Policy log std Min           -3.1438217
Z mean eval                  3.3635173
Z variance eval              0.0032380621
total_rewards                [9940.79002609 9627.09137972 9772.60801794 9985.85748347 9753.17307082
 9693.04692398 9755.37989213 9967.98163929 9815.2545887  9665.93096751]
total_rewards_mean           9797.711398965219
total_rewards_std            121.24680828243092
total_rewards_max            9985.857483465277
total_rewards_min            9627.09137971869
Number of train steps total  360000
Number of env steps total    452000
Number of rollouts total     0
Train Time (s)               112.32054239884019
(Previous) Eval Time (s)     22.675629287958145
Sample Time (s)              16.652708143927157
Epoch Time (s)               151.6488798307255
Total Train Time (s)         13688.205241367687
Epoch                        89
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:24:27.233655 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #89 | Epoch Duration: 151.8568058013916
2020-01-13 12:24:27.233912 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #89 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3652146
Z variance train             0.003233082
KL Divergence                43.388687
KL Loss                      4.3388686
QF Loss                      207.33746
VF Loss                      95.06862
Policy Loss                  -3646.0635
Q Predictions Mean           3643.0454
Q Predictions Std            554.60284
Q Predictions Max            4335.326
Q Predictions Min            718.4929
V Predictions Mean           3645.7134
V Predictions Std            548.5218
V Predictions Max            4333.668
V Predictions Min            735.31433
Log Pis Mean                 5.315172
Log Pis Std                  3.6161108
Log Pis Max                  14.684476
Log Pis Min                  -7.261736
Policy mu Mean               -0.13291635
Policy mu Std                1.3564186
Policy mu Max                3.5175517
Policy mu Min                -3.2768688
Policy log std Mean          -0.88779163
Policy log std Std           0.4503658
Policy log std Max           -0.123075485
Policy log std Min           -3.2418356
Z mean eval                  3.3576775
Z variance eval              0.009100052
total_rewards                [9758.03887824 9838.29587297 9632.69001216 9991.34914139 9460.09310479
 9894.30075232 9706.3351104  9647.90789874 9732.21496593 9784.83569659]
total_rewards_mean           9744.606143354722
total_rewards_std            140.8221776134062
total_rewards_max            9991.349141393222
total_rewards_min            9460.093104790287
Number of train steps total  364000
Number of env steps total    457000
Number of rollouts total     0
Train Time (s)               112.60284527391195
(Previous) Eval Time (s)     22.88325067004189
Sample Time (s)              15.829393961001188
Epoch Time (s)               151.31548990495503
Total Train Time (s)         13839.833504680544
Epoch                        90
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:26:58.863094 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #90 | Epoch Duration: 151.6289827823639
2020-01-13 12:26:58.863297 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #90 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3582444
Z variance train             0.00908179
KL Divergence                42.250805
KL Loss                      4.2250805
QF Loss                      272.4172
VF Loss                      62.453815
Policy Loss                  -3655.5762
Q Predictions Mean           3659.0798
Q Predictions Std            613.276
Q Predictions Max            4406.0137
Q Predictions Min            767.6734
V Predictions Mean           3656.4421
V Predictions Std            608.2045
V Predictions Max            4393.149
V Predictions Min            771.32983
Log Pis Mean                 5.336956
Log Pis Std                  4.140762
Log Pis Max                  17.08361
Log Pis Min                  -4.016792
Policy mu Mean               -0.15689111
Policy mu Std                1.3862054
Policy mu Max                3.3549957
Policy mu Min                -3.5505216
Policy log std Mean          -0.8837443
Policy log std Std           0.48350388
Policy log std Max           0.20788074
Policy log std Min           -3.3676608
Z mean eval                  3.3494534
Z variance eval              0.0026914252
total_rewards                [ 9591.11008705  9880.52363236  9809.86246259  9847.89262118
  9804.70044837  9665.22980014  9892.20688629  9901.61101857
  9790.59246086 10111.4811726 ]
total_rewards_mean           9829.521059000152
total_rewards_std            133.3852037598285
total_rewards_max            10111.481172598309
total_rewards_min            9591.11008705372
Number of train steps total  368000
Number of env steps total    462000
Number of rollouts total     0
Train Time (s)               112.5869827712886
(Previous) Eval Time (s)     23.19646980240941
Sample Time (s)              16.54763352451846
Epoch Time (s)               152.33108609821647
Total Train Time (s)         13991.904672625475
Epoch                        91
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:29:30.939756 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #91 | Epoch Duration: 152.07626795768738
2020-01-13 12:29:30.940098 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #91 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.347653
Z variance train             0.0026907003
KL Divergence                42.737648
KL Loss                      4.273765
QF Loss                      327.1728
VF Loss                      88.33396
Policy Loss                  -3609.901
Q Predictions Mean           3612.4346
Q Predictions Std            677.32855
Q Predictions Max            4415.37
Q Predictions Min            763.9064
V Predictions Mean           3612.982
V Predictions Std            669.79803
V Predictions Max            4404.965
V Predictions Min            800.4341
Log Pis Mean                 5.133633
Log Pis Std                  3.7655454
Log Pis Max                  16.261578
Log Pis Min                  -3.7665339
Policy mu Mean               -0.1035796
Policy mu Std                1.3581766
Policy mu Max                2.9082766
Policy mu Min                -3.0668662
Policy log std Mean          -0.88664716
Policy log std Std           0.46706337
Policy log std Max           -0.08105236
Policy log std Min           -3.1476202
Z mean eval                  3.336617
Z variance eval              0.009533231
total_rewards                [9653.56810306 9791.38044699 9679.40115419 9777.98291295 9739.3268813
 9743.81364972 9815.98105958 9761.1446149  9791.14558741 9794.13852477]
total_rewards_mean           9754.788293487249
total_rewards_std            49.82014936826686
total_rewards_max            9815.981059577345
total_rewards_min            9653.568103059513
Number of train steps total  372000
Number of env steps total    467000
Number of rollouts total     0
Train Time (s)               115.56923331692815
(Previous) Eval Time (s)     22.941320194862783
Sample Time (s)              16.982197938952595
Epoch Time (s)               155.49275145074353
Total Train Time (s)         14147.000212475657
Epoch                        92
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:32:06.034730 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #92 | Epoch Duration: 155.094402551651
2020-01-13 12:32:06.034940 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #92 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3352764
Z variance train             0.00951972
KL Divergence                40.117424
KL Loss                      4.0117426
QF Loss                      318.80432
VF Loss                      114.383484
Policy Loss                  -3639.8086
Q Predictions Mean           3640.7485
Q Predictions Std            692.5093
Q Predictions Max            4451.5796
Q Predictions Min            785.1162
V Predictions Mean           3642.7544
V Predictions Std            684.68005
V Predictions Max            4445.18
V Predictions Min            802.21246
Log Pis Mean                 5.135238
Log Pis Std                  3.8750339
Log Pis Max                  14.788235
Log Pis Min                  -5.2965026
Policy mu Mean               -0.11177975
Policy mu Std                1.369794
Policy mu Max                2.991226
Policy mu Min                -2.9857469
Policy log std Mean          -0.86844295
Policy log std Std           0.45878616
Policy log std Max           -0.14371061
Policy log std Min           -3.5006683
Z mean eval                  3.3456109
Z variance eval              0.0055142613
total_rewards                [3469.84362621 9660.3532779  9511.98830968 9463.9613163  9527.09367969
 9355.88115349 9672.97892623 9272.06923717 9445.21342517 9356.62025593]
total_rewards_mean           8873.600320775473
total_rewards_std            1805.356301726844
total_rewards_max            9672.978926226491
total_rewards_min            3469.8436262073355
Number of train steps total  376000
Number of env steps total    472000
Number of rollouts total     0
Train Time (s)               112.03227051906288
(Previous) Eval Time (s)     22.54267140198499
Sample Time (s)              17.386570684146136
Epoch Time (s)               151.961512605194
Total Train Time (s)         14298.679992737249
Epoch                        93
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:34:37.716833 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #93 | Epoch Duration: 151.68172192573547
2020-01-13 12:34:37.717063 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.344942
Z variance train             0.0055232714
KL Divergence                41.26429
KL Loss                      4.126429
QF Loss                      251.90652
VF Loss                      232.90771
Policy Loss                  -3595.5132
Q Predictions Mean           3598.76
Q Predictions Std            637.4217
Q Predictions Max            4417.969
Q Predictions Min            765.82654
V Predictions Mean           3607.3965
V Predictions Std            634.9219
V Predictions Max            4417.9673
V Predictions Min            768.01
Log Pis Mean                 5.0790176
Log Pis Std                  3.9691298
Log Pis Max                  17.786247
Log Pis Min                  -7.6415915
Policy mu Mean               -0.10480874
Policy mu Std                1.3598241
Policy mu Max                3.0352328
Policy mu Min                -3.7418513
Policy log std Mean          -0.86969525
Policy log std Std           0.4472309
Policy log std Max           0.2297771
Policy log std Min           -3.0266967
Z mean eval                  3.3551643
Z variance eval              0.0034437384
total_rewards                [9501.25710804 9489.73620187 9703.30802181 9534.73523435 9403.78270132
 9638.47430639 9595.51591545 9586.67294051 9641.45606411 9795.49589365]
total_rewards_mean           9589.043438750434
total_rewards_std            107.5901047123053
total_rewards_max            9795.495893649893
total_rewards_min            9403.782701323129
Number of train steps total  380000
Number of env steps total    477000
Number of rollouts total     0
Train Time (s)               115.91435174224898
(Previous) Eval Time (s)     22.262528697028756
Sample Time (s)              16.390455985907465
Epoch Time (s)               154.5673364251852
Total Train Time (s)         14454.392885386944
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:37:13.433877 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #94 | Epoch Duration: 155.71659755706787
2020-01-13 12:37:13.434233 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #94 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.355905
Z variance train             0.0034343028
KL Divergence                41.812325
KL Loss                      4.1812325
QF Loss                      315.11346
VF Loss                      145.8973
Policy Loss                  -3641.1665
Q Predictions Mean           3641.7515
Q Predictions Std            670.2589
Q Predictions Max            4430.044
Q Predictions Min            753.0725
V Predictions Mean           3634.587
V Predictions Std            661.8867
V Predictions Max            4433.18
V Predictions Min            779.7892
Log Pis Mean                 5.392857
Log Pis Std                  3.5245674
Log Pis Max                  13.186185
Log Pis Min                  -3.4687514
Policy mu Mean               -0.0989783
Policy mu Std                1.3597871
Policy mu Max                3.0663795
Policy mu Min                -2.6742015
Policy log std Mean          -0.874008
Policy log std Std           0.4653157
Policy log std Max           -0.12964404
Policy log std Min           -3.1045675
Z mean eval                  3.337376
Z variance eval              0.0032917683
total_rewards                [9659.72399063 9807.97743339 9724.27843017 9647.72178998 9542.37172639
 9716.04728811 9682.05911806 9755.26660777 9655.21510373 9903.13426418]
total_rewards_mean           9709.379575240917
total_rewards_std            93.52734875181906
total_rewards_max            9903.134264182972
total_rewards_min            9542.371726386244
Number of train steps total  384000
Number of env steps total    482000
Number of rollouts total     0
Train Time (s)               117.38002979196608
(Previous) Eval Time (s)     23.41147667495534
Sample Time (s)              16.467670751269907
Epoch Time (s)               157.25917721819133
Total Train Time (s)         14610.852178887464
Epoch                        95
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:39:49.895829 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #95 | Epoch Duration: 156.46121406555176
2020-01-13 12:39:49.896308 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #95 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3347614
Z variance train             0.003300768
KL Divergence                42.805084
KL Loss                      4.2805085
QF Loss                      272.49988
VF Loss                      114.34032
Policy Loss                  -3652.111
Q Predictions Mean           3650.4297
Q Predictions Std            707.6548
Q Predictions Max            4403.565
Q Predictions Min            755.8038
V Predictions Mean           3656.92
V Predictions Std            701.6798
V Predictions Max            4412.436
V Predictions Min            766.4913
Log Pis Mean                 4.973942
Log Pis Std                  3.7624547
Log Pis Max                  15.198187
Log Pis Min                  -3.783895
Policy mu Mean               -0.15110521
Policy mu Std                1.353279
Policy mu Max                3.17981
Policy mu Min                -2.9313219
Policy log std Mean          -0.8537145
Policy log std Std           0.44169492
Policy log std Max           0.0916183
Policy log std Min           -3.237782
Z mean eval                  3.328551
Z variance eval              0.008203042
total_rewards                [9472.35876574 9738.26368999 9668.90551835 9801.58829794 9730.52569814
 9727.52157983 9581.83020609 9489.30927294 9572.33729718 9811.68870117]
total_rewards_mean           9659.43290273631
total_rewards_std            117.01746309870869
total_rewards_max            9811.68870116985
total_rewards_min            9472.358765735047
Number of train steps total  388000
Number of env steps total    487000
Number of rollouts total     0
Train Time (s)               114.84330450510606
(Previous) Eval Time (s)     22.613203381653875
Sample Time (s)              16.999887683894485
Epoch Time (s)               154.45639557065442
Total Train Time (s)         14764.856138881296
Epoch                        96
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:42:23.899730 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #96 | Epoch Duration: 154.00314474105835
2020-01-13 12:42:23.899978 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3267944
Z variance train             0.00820539
KL Divergence                41.72706
KL Loss                      4.172706
QF Loss                      450.86285
VF Loss                      88.1252
Policy Loss                  -3733.2002
Q Predictions Mean           3730.5615
Q Predictions Std            504.34256
Q Predictions Max            4455.8926
Q Predictions Min            843.9496
V Predictions Mean           3732.6577
V Predictions Std            500.46436
V Predictions Max            4451.706
V Predictions Min            804.67896
Log Pis Mean                 4.9808073
Log Pis Std                  3.424604
Log Pis Max                  14.826147
Log Pis Min                  -7.278683
Policy mu Mean               -0.08947242
Policy mu Std                1.3296598
Policy mu Max                2.952079
Policy mu Min                -3.1303256
Policy log std Mean          -0.9197097
Policy log std Std           0.46906936
Policy log std Max           -0.04271713
Policy log std Min           -3.1220598
Z mean eval                  3.334041
Z variance eval              0.0070990473
total_rewards                [9704.80542827 9419.29374142 9737.5955851  9690.3167101  9784.47023773
 9661.76880332 9616.78034736 9643.66110622 9717.40662826 9607.13062684]
total_rewards_mean           9658.322921461795
total_rewards_std            95.17386158453597
total_rewards_max            9784.470237727523
total_rewards_min            9419.293741424908
Number of train steps total  392000
Number of env steps total    492000
Number of rollouts total     0
Train Time (s)               110.59187303483486
(Previous) Eval Time (s)     22.159656852018088
Sample Time (s)              15.777489388827235
Epoch Time (s)               148.52901927568018
Total Train Time (s)         14913.86455985671
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:44:52.909619 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #97 | Epoch Duration: 149.00940251350403
2020-01-13 12:44:52.909862 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #97 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3358238
Z variance train             0.007085122
KL Divergence                40.46583
KL Loss                      4.046583
QF Loss                      262.66876
VF Loss                      166.86328
Policy Loss                  -3675.0215
Q Predictions Mean           3669.2407
Q Predictions Std            711.16455
Q Predictions Max            4415.5884
Q Predictions Min            728.54126
V Predictions Mean           3667.228
V Predictions Std            703.44775
V Predictions Max            4421.1196
V Predictions Min            758.3384
Log Pis Mean                 5.1939754
Log Pis Std                  3.694126
Log Pis Max                  18.615011
Log Pis Min                  -3.5037072
Policy mu Mean               -0.06289112
Policy mu Std                1.3634092
Policy mu Max                3.364873
Policy mu Min                -3.4194155
Policy log std Mean          -0.91103834
Policy log std Std           0.483565
Policy log std Max           -0.13496014
Policy log std Min           -3.191496
Z mean eval                  3.3232994
Z variance eval              0.01712574
total_rewards                [9761.94203511 9929.06511437 6304.09056482 9806.86868484 9880.22351994
 9909.33399322 9844.80625641 9938.80987234 9689.52749228 9716.66441359]
total_rewards_mean           9478.13319469243
total_rewards_std            1061.243057837286
total_rewards_max            9938.809872335267
total_rewards_min            6304.090564820858
Number of train steps total  396000
Number of env steps total    497000
Number of rollouts total     0
Train Time (s)               115.59433436114341
(Previous) Eval Time (s)     22.639774876181036
Sample Time (s)              15.524867986794561
Epoch Time (s)               153.758977224119
Total Train Time (s)         15068.313332884107
Epoch                        98
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:47:27.362478 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #98 | Epoch Duration: 154.45244002342224
2020-01-13 12:47:27.362736 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #98 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3229527
Z variance train             0.01701823
KL Divergence                40.191586
KL Loss                      4.019159
QF Loss                      609.3578
VF Loss                      436.95773
Policy Loss                  -3772.5864
Q Predictions Mean           3775.1597
Q Predictions Std            537.7796
Q Predictions Max            4457.2715
Q Predictions Min            742.9057
V Predictions Mean           3786.442
V Predictions Std            529.9068
V Predictions Max            4463.025
V Predictions Min            792.361
Log Pis Mean                 5.246085
Log Pis Std                  3.555423
Log Pis Max                  13.662275
Log Pis Min                  -3.6382997
Policy mu Mean               -0.06376399
Policy mu Std                1.3622047
Policy mu Max                3.1873388
Policy mu Min                -3.0561047
Policy log std Mean          -0.88624173
Policy log std Std           0.4689948
Policy log std Max           -0.17523247
Policy log std Min           -3.376042
Z mean eval                  3.3302703
Z variance eval              0.012841776
total_rewards                [ 9731.14156687 10037.69461731  9825.47496    10048.19980972
  9829.61622259  9811.394373    7073.90674705  9816.02181151
  9840.88185432  9670.89987253]
total_rewards_mean           9568.523183489418
total_rewards_std            838.9793449033158
total_rewards_max            10048.199809717993
total_rewards_min            7073.906747050275
Number of train steps total  400000
Number of env steps total    502000
Number of rollouts total     0
Train Time (s)               117.23518055584282
(Previous) Eval Time (s)     23.332978394813836
Sample Time (s)              16.442298544105142
Epoch Time (s)               157.0104574947618
Total Train Time (s)         15225.060120827984
Epoch                        99
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:50:04.109037 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #99 | Epoch Duration: 156.74611902236938
2020-01-13 12:50:04.109268 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #99 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3280234
Z variance train             0.012826266
KL Divergence                40.349678
KL Loss                      4.034968
QF Loss                      257.60077
VF Loss                      118.10318
Policy Loss                  -3753.8381
Q Predictions Mean           3750.96
Q Predictions Std            624.8125
Q Predictions Max            4521.902
Q Predictions Min            768.8141
V Predictions Mean           3756.6768
V Predictions Std            620.77875
V Predictions Max            4519.7627
V Predictions Min            774.51843
Log Pis Mean                 5.486839
Log Pis Std                  3.6630237
Log Pis Max                  16.223383
Log Pis Min                  -5.9137216
Policy mu Mean               -0.092012234
Policy mu Std                1.428527
Policy mu Max                3.163085
Policy mu Min                -3.4798143
Policy log std Mean          -0.88038415
Policy log std Std           0.4522753
Policy log std Max           -0.1655064
Policy log std Min           -3.208674
Z mean eval                  3.3564591
Z variance eval              0.007719394
total_rewards                [9691.32638377 9772.37906984 9949.94501813 9659.55738659 9704.82055687
 9971.66626815 9802.31021502 9635.31244468 9814.05848776 9769.48635938]
total_rewards_mean           9777.086219018249
total_rewards_std            107.84923667260728
total_rewards_max            9971.66626814562
total_rewards_min            9635.312444682611
Number of train steps total  404000
Number of env steps total    507000
Number of rollouts total     0
Train Time (s)               116.29573408607394
(Previous) Eval Time (s)     23.06834561098367
Sample Time (s)              17.567114875186235
Epoch Time (s)               156.93119457224384
Total Train Time (s)         15381.435492895544
Epoch                        100
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:52:40.488136 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #100 | Epoch Duration: 156.37871980667114
2020-01-13 12:52:40.488345 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #100 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3554077
Z variance train             0.0077121994
KL Divergence                41.66225
KL Loss                      4.166225
QF Loss                      617.8651
VF Loss                      181.22252
Policy Loss                  -3739.0908
Q Predictions Mean           3746.4116
Q Predictions Std            522.66296
Q Predictions Max            4446.3457
Q Predictions Min            759.17596
V Predictions Mean           3748.4548
V Predictions Std            517.31805
V Predictions Max            4436.465
V Predictions Min            765.5386
Log Pis Mean                 5.3152504
Log Pis Std                  3.8615694
Log Pis Max                  17.5168
Log Pis Min                  -5.18486
Policy mu Mean               -0.16351277
Policy mu Std                1.381764
Policy mu Max                2.9365246
Policy mu Min                -3.4645925
Policy log std Mean          -0.8607444
Policy log std Std           0.4734345
Policy log std Max           -0.013636291
Policy log std Min           -3.229783
Z mean eval                  3.3342896
Z variance eval              0.012119653
total_rewards                [ 9662.41981678  9986.32575831 10104.87314948 10028.85379854
 10045.31851011 10049.10655289  9949.44757298  9916.16475618
 10030.63018279 10083.01301444]
total_rewards_mean           9985.615311251384
total_rewards_std            120.74252647605817
total_rewards_max            10104.873149481919
total_rewards_min            9662.419816783979
Number of train steps total  408000
Number of env steps total    512000
Number of rollouts total     0
Train Time (s)               115.81437643896788
(Previous) Eval Time (s)     22.515536647755653
Sample Time (s)              16.347961094696075
Epoch Time (s)               154.6778741814196
Total Train Time (s)         15536.457062427886
Epoch                        101
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:55:15.509460 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #101 | Epoch Duration: 155.0209765434265
2020-01-13 12:55:15.509663 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #101 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.335096
Z variance train             0.012124919
KL Divergence                38.90834
KL Loss                      3.890834
QF Loss                      328.7857
VF Loss                      105.28926
Policy Loss                  -3775.8198
Q Predictions Mean           3779.2441
Q Predictions Std            547.7155
Q Predictions Max            4484.2686
Q Predictions Min            771.8576
V Predictions Mean           3775.2144
V Predictions Std            543.1651
V Predictions Max            4460.911
V Predictions Min            739.81165
Log Pis Mean                 5.504406
Log Pis Std                  3.696885
Log Pis Max                  14.167382
Log Pis Min                  -6.902904
Policy mu Mean               -0.14517201
Policy mu Std                1.3743153
Policy mu Max                3.0647032
Policy mu Min                -2.6638663
Policy log std Mean          -0.885935
Policy log std Std           0.48667103
Policy log std Max           -0.19241518
Policy log std Min           -3.3163855
Z mean eval                  3.3345065
Z variance eval              0.008061295
total_rewards                [ 9444.55637136  9739.73887581 10092.81037042 10232.1556162
 10015.13775747  9789.49390223 10071.98274376  9817.10383488
  9882.55335293  9980.08003506]
total_rewards_mean           9906.561286010601
total_rewards_std            211.85385317634464
total_rewards_max            10232.155616200207
total_rewards_min            9444.556371363098
Number of train steps total  412000
Number of env steps total    517000
Number of rollouts total     0
Train Time (s)               112.48509279405698
(Previous) Eval Time (s)     22.8583269007504
Sample Time (s)              15.966712429188192
Epoch Time (s)               151.31013212399557
Total Train Time (s)         15687.364034221973
Epoch                        102
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:57:46.419821 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #102 | Epoch Duration: 150.90996479988098
2020-01-13 12:57:46.420110 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #102 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3310275
Z variance train             0.008042512
KL Divergence                39.88363
KL Loss                      3.988363
QF Loss                      348.1712
VF Loss                      138.99437
Policy Loss                  -3651.46
Q Predictions Mean           3652.023
Q Predictions Std            729.4982
Q Predictions Max            4482.945
Q Predictions Min            750.81274
V Predictions Mean           3656.4353
V Predictions Std            727.403
V Predictions Max            4491.2603
V Predictions Min            750.47644
Log Pis Mean                 5.053694
Log Pis Std                  3.8377588
Log Pis Max                  14.994763
Log Pis Min                  -4.7098737
Policy mu Mean               -0.07214507
Policy mu Std                1.3616229
Policy mu Max                3.0804014
Policy mu Min                -2.9876308
Policy log std Mean          -0.8815555
Policy log std Std           0.47352913
Policy log std Max           0.040088773
Policy log std Min           -3.0447822
Z mean eval                  3.3281875
Z variance eval              0.010274852
total_rewards                [10192.99346669 10349.76471737 10064.97976675  9965.22375396
 10322.91093449 10063.00982784 10372.20647758 10060.05680673
 10232.46892383 10016.79553967]
total_rewards_mean           10164.041021491388
total_rewards_std            141.64360503322303
total_rewards_max            10372.206477582395
total_rewards_min            9965.22375395624
Number of train steps total  416000
Number of env steps total    522000
Number of rollouts total     0
Train Time (s)               116.40385803300887
(Previous) Eval Time (s)     22.457862661220133
Sample Time (s)              16.164125179871917
Epoch Time (s)               155.02584587410092
Total Train Time (s)         15842.34829659015
Epoch                        103
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:00:21.405900 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #103 | Epoch Duration: 154.9855761528015
2020-01-13 13:00:21.406139 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #103 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3285632
Z variance train             0.010250055
KL Divergence                39.100983
KL Loss                      3.9100983
QF Loss                      833.6776
VF Loss                      138.60574
Policy Loss                  -3870.791
Q Predictions Mean           3869.121
Q Predictions Std            549.75616
Q Predictions Max            4519.575
Q Predictions Min            748.01385
V Predictions Mean           3869.9766
V Predictions Std            545.2956
V Predictions Max            4504.3677
V Predictions Min            749.6933
Log Pis Mean                 5.571663
Log Pis Std                  3.5946717
Log Pis Max                  13.943357
Log Pis Min                  -3.28006
Policy mu Mean               -0.11433494
Policy mu Std                1.3675413
Policy mu Max                3.0282967
Policy mu Min                -3.1949534
Policy log std Mean          -0.8968403
Policy log std Std           0.48207304
Policy log std Max           -0.19636413
Policy log std Min           -3.495482
Z mean eval                  3.320404
Z variance eval              0.008511224
total_rewards                [ 9778.52606861  9720.44846129  6320.24838249  9775.63597593
  9786.52706816  9740.40249548  9676.30193265 10043.36833498
 10070.7164591   9684.8479413 ]
total_rewards_mean           9459.702312000154
total_rewards_std            1054.6487318691584
total_rewards_max            10070.716459103855
total_rewards_min            6320.248382488052
Number of train steps total  420000
Number of env steps total    527000
Number of rollouts total     0
Train Time (s)               114.43702291930094
(Previous) Eval Time (s)     22.417289331089705
Sample Time (s)              16.133253084961325
Epoch Time (s)               152.98756533535197
Total Train Time (s)         15996.09772737138
Epoch                        104
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:02:55.156773 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #104 | Epoch Duration: 153.75044918060303
2020-01-13 13:02:55.156976 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #104 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3223038
Z variance train             0.00853301
KL Divergence                39.92431
KL Loss                      3.992431
QF Loss                      606.5072
VF Loss                      249.17656
Policy Loss                  -3714.5007
Q Predictions Mean           3707.9717
Q Predictions Std            625.43036
Q Predictions Max            4488.521
Q Predictions Min            703.703
V Predictions Mean           3704.0874
V Predictions Std            615.23773
V Predictions Max            4478.979
V Predictions Min            728.7471
Log Pis Mean                 5.349768
Log Pis Std                  3.8179348
Log Pis Max                  17.31957
Log Pis Min                  -2.960412
Policy mu Mean               -0.18070889
Policy mu Std                1.3846654
Policy mu Max                3.4694338
Policy mu Min                -3.7089095
Policy log std Mean          -0.8683683
Policy log std Std           0.45400155
Policy log std Max           -0.060525388
Policy log std Min           -3.2589397
Z mean eval                  3.329185
Z variance eval              0.005434771
total_rewards                [10007.68723168  5295.37366566 10160.6137779  10073.41531898
 10205.15283702 10128.17977263 10125.25751821  9899.84513595
 10019.18749653 10035.96511312]
total_rewards_mean           9595.067786767606
total_rewards_std            1435.6515417610194
total_rewards_max            10205.152837023796
total_rewards_min            5295.373665656139
Number of train steps total  424000
Number of env steps total    532000
Number of rollouts total     0
Train Time (s)               112.391579604242
(Previous) Eval Time (s)     23.17988583492115
Sample Time (s)              16.373615510296077
Epoch Time (s)               151.94508094945922
Total Train Time (s)         16147.398411983624
Epoch                        105
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:05:26.459431 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #105 | Epoch Duration: 151.3022940158844
2020-01-13 13:05:26.459634 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #105 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3299778
Z variance train             0.0054449276
KL Divergence                41.22393
KL Loss                      4.122393
QF Loss                      331.7107
VF Loss                      128.86533
Policy Loss                  -3709.066
Q Predictions Mean           3708.8018
Q Predictions Std            674.4927
Q Predictions Max            4478.5596
Q Predictions Min            719.40674
V Predictions Mean           3704.754
V Predictions Std            672.34595
V Predictions Max            4465.8013
V Predictions Min            695.3062
Log Pis Mean                 5.223263
Log Pis Std                  4.09881
Log Pis Max                  14.864316
Log Pis Min                  -7.4138546
Policy mu Mean               -0.12802663
Policy mu Std                1.3949387
Policy mu Max                3.556646
Policy mu Min                -3.8135042
Policy log std Mean          -0.8719886
Policy log std Std           0.46505663
Policy log std Max           0.065773845
Policy log std Min           -3.2633276
Z mean eval                  3.3233514
Z variance eval              0.00813189
total_rewards                [ 9789.8618524   9945.64359515  9794.75524329  9860.99753091
  9966.43253145  9856.16124305  9849.75836341  9851.98610879
  9905.46789608 10078.3637796 ]
total_rewards_mean           9889.94281441421
total_rewards_std            82.95067228735611
total_rewards_max            10078.363779604391
total_rewards_min            9789.861852403876
Number of train steps total  428000
Number of env steps total    537000
Number of rollouts total     0
Train Time (s)               113.3258579550311
(Previous) Eval Time (s)     22.536805307026953
Sample Time (s)              16.413250906858593
Epoch Time (s)               152.27591416891664
Total Train Time (s)         16299.864230814856
Epoch                        106
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:07:58.926235 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #106 | Epoch Duration: 152.46643352508545
2020-01-13 13:07:58.926424 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3234406
Z variance train             0.008129016
KL Divergence                40.774273
KL Loss                      4.0774274
QF Loss                      596.44714
VF Loss                      412.9638
Policy Loss                  -3808.6575
Q Predictions Mean           3807.476
Q Predictions Std            612.37
Q Predictions Max            4511.1387
Q Predictions Min            688.1211
V Predictions Mean           3822.768
V Predictions Std            608.7267
V Predictions Max            4515.432
V Predictions Min            731.7954
Log Pis Mean                 5.2897916
Log Pis Std                  4.0131426
Log Pis Max                  30.075657
Log Pis Min                  -5.2863593
Policy mu Mean               -0.08932823
Policy mu Std                1.3722932
Policy mu Max                4.2069426
Policy mu Min                -3.8465414
Policy log std Mean          -0.89271814
Policy log std Std           0.49897966
Policy log std Max           -0.09089756
Policy log std Min           -3.2718234
Z mean eval                  3.3404865
Z variance eval              0.008906839
total_rewards                [9536.50076473 9632.111716   9727.92857904 9872.06470926 9918.28084234
 9737.68099684 9974.25234677 9625.63687391 9736.50890633 9726.29492558]
total_rewards_mean           9748.7260660794
total_rewards_std            130.3148973901053
total_rewards_max            9974.25234676705
total_rewards_min            9536.500764734807
Number of train steps total  432000
Number of env steps total    542000
Number of rollouts total     0
Train Time (s)               107.37772839190438
(Previous) Eval Time (s)     22.72702720761299
Sample Time (s)              16.54624795773998
Epoch Time (s)               146.65100355725735
Total Train Time (s)         16446.462459383998
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:10:25.527006 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #107 | Epoch Duration: 146.60042715072632
2020-01-13 13:10:25.527223 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #107 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.340451
Z variance train             0.008905509
KL Divergence                40.524265
KL Loss                      4.052427
QF Loss                      385.1176
VF Loss                      173.7967
Policy Loss                  -3735.3025
Q Predictions Mean           3737.5264
Q Predictions Std            702.09955
Q Predictions Max            4521.009
Q Predictions Min            658.20264
V Predictions Mean           3741.336
V Predictions Std            691.26447
V Predictions Max            4521.012
V Predictions Min            724.3209
Log Pis Mean                 4.7900867
Log Pis Std                  3.6676176
Log Pis Max                  16.17081
Log Pis Min                  -5.729347
Policy mu Mean               -0.091058135
Policy mu Std                1.3244698
Policy mu Max                2.9381597
Policy mu Min                -3.2716544
Policy log std Mean          -0.86490726
Policy log std Std           0.45094278
Policy log std Max           0.0036593676
Policy log std Min           -2.9541366
Z mean eval                  3.3284965
Z variance eval              0.007347662
total_rewards                [9179.24608521 9467.93515322 9270.76414864 9291.41717587 9712.80784167
 9464.01795861 9620.58151329 4144.56253169 9343.31198781 9618.94999414]
total_rewards_mean           8911.359439017036
total_rewards_std            1597.3578965059496
total_rewards_max            9712.807841665202
total_rewards_min            4144.562531694924
Number of train steps total  436000
Number of env steps total    547000
Number of rollouts total     0
Train Time (s)               119.72173029184341
(Previous) Eval Time (s)     22.676154281944036
Sample Time (s)              15.973220578860492
Epoch Time (s)               158.37110515264794
Total Train Time (s)         16604.516063244082
Epoch                        108
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:13:03.582286 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #108 | Epoch Duration: 158.05491256713867
2020-01-13 13:13:03.582492 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #108 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3273113
Z variance train             0.0073529175
KL Divergence                39.783554
KL Loss                      3.9783554
QF Loss                      232.24835
VF Loss                      141.49341
Policy Loss                  -3813.4878
Q Predictions Mean           3811.6064
Q Predictions Std            620.753
Q Predictions Max            4538.1064
Q Predictions Min            670.77374
V Predictions Mean           3807.6895
V Predictions Std            614.3826
V Predictions Max            4540.8193
V Predictions Min            713.252
Log Pis Mean                 4.9236674
Log Pis Std                  3.5569668
Log Pis Max                  14.187565
Log Pis Min                  -5.2728777
Policy mu Mean               -0.048977535
Policy mu Std                1.3484462
Policy mu Max                3.3070543
Policy mu Min                -3.3417118
Policy log std Mean          -0.89099616
Policy log std Std           0.47357774
Policy log std Max           0.011148691
Policy log std Min           -3.0048418
Z mean eval                  3.329387
Z variance eval              0.008348532
total_rewards                [ 9752.64603879  5476.74844436  9994.48030258 10027.19989971
 10092.35413257 10254.77596979 10050.16150785 10037.19086173
 10105.52519449 10106.59048887]
total_rewards_mean           9589.767284073716
total_rewards_std            1376.1790081163938
total_rewards_max            10254.775969790036
total_rewards_min            5476.748444360265
Number of train steps total  440000
Number of env steps total    552000
Number of rollouts total     0
Train Time (s)               116.83984165964648
(Previous) Eval Time (s)     22.359659471083432
Sample Time (s)              15.733919709920883
Epoch Time (s)               154.9334208406508
Total Train Time (s)         16760.050838932395
Epoch                        109
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:15:39.119644 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #109 | Epoch Duration: 155.5369791984558
2020-01-13 13:15:39.119909 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #109 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3283048
Z variance train             0.008341992
KL Divergence                40.070045
KL Loss                      4.0070047
QF Loss                      395.73004
VF Loss                      205.69618
Policy Loss                  -3803.4265
Q Predictions Mean           3807.3276
Q Predictions Std            663.952
Q Predictions Max            4563.8984
Q Predictions Min            730.72046
V Predictions Mean           3811.5261
V Predictions Std            661.67004
V Predictions Max            4559.5503
V Predictions Min            726.842
Log Pis Mean                 5.369186
Log Pis Std                  3.6284995
Log Pis Max                  15.221279
Log Pis Min                  -4.775813
Policy mu Mean               -0.15996285
Policy mu Std                1.3725449
Policy mu Max                3.131214
Policy mu Min                -3.585684
Policy log std Mean          -0.8717033
Policy log std Std           0.46137458
Policy log std Max           -0.15691024
Policy log std Min           -3.1842413
Z mean eval                  3.3275154
Z variance eval              0.00967131
total_rewards                [9703.58529056 9766.67527542 9981.38821903 9968.78516166 9514.98321085
 9853.80188354 9972.79322365 9816.43344486 9815.64108446 9924.32035287]
total_rewards_mean           9831.840714689684
total_rewards_std            138.42510676451866
total_rewards_max            9981.388219033386
total_rewards_min            9514.983210847406
Number of train steps total  444000
Number of env steps total    557000
Number of rollouts total     0
Train Time (s)               103.51821297314018
(Previous) Eval Time (s)     22.962951064575464
Sample Time (s)              16.382879747077823
Epoch Time (s)               142.86404378479347
Total Train Time (s)         16903.016141568776
Epoch                        110
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:18:02.086863 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #110 | Epoch Duration: 142.96669626235962
2020-01-13 13:18:02.087141 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #110 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.33
Z variance train             0.009662611
KL Divergence                39.505417
KL Loss                      3.9505417
QF Loss                      403.24933
VF Loss                      169.73395
Policy Loss                  -3830.2363
Q Predictions Mean           3833.7134
Q Predictions Std            661.5246
Q Predictions Max            4523.534
Q Predictions Min            719.70514
V Predictions Mean           3829.2466
V Predictions Std            654.1765
V Predictions Max            4506.518
V Predictions Min            736.034
Log Pis Mean                 5.6002736
Log Pis Std                  3.7387102
Log Pis Max                  17.25003
Log Pis Min                  -3.8283825
Policy mu Mean               -0.16631518
Policy mu Std                1.371648
Policy mu Max                3.0802333
Policy mu Min                -3.992791
Policy log std Mean          -0.91445655
Policy log std Std           0.47398642
Policy log std Max           -0.067255944
Policy log std Min           -3.3287416
Z mean eval                  3.320956
Z variance eval              0.018143749
total_rewards                [10001.52823167 10249.42736513 10292.37440488 10204.40652054
 10132.74015746  9949.93803824 10328.85925494  9978.7185604
  9971.08973208 10196.34984405]
total_rewards_mean           10130.543210939406
total_rewards_std            136.81461490302655
total_rewards_max            10328.859254940022
total_rewards_min            9949.93803824468
Number of train steps total  448000
Number of env steps total    562000
Number of rollouts total     0
Train Time (s)               114.88564976165071
(Previous) Eval Time (s)     23.065304009709507
Sample Time (s)              16.74885086994618
Epoch Time (s)               154.6998046413064
Total Train Time (s)         17057.74666176224
Epoch                        111
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:20:36.821979 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #111 | Epoch Duration: 154.73464131355286
2020-01-13 13:20:36.822263 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #111 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.321907
Z variance train             0.018106107
KL Divergence                38.85516
KL Loss                      3.885516
QF Loss                      320.20764
VF Loss                      157.89984
Policy Loss                  -3777.717
Q Predictions Mean           3779.5388
Q Predictions Std            732.7649
Q Predictions Max            4531.4204
Q Predictions Min            647.9554
V Predictions Mean           3774.8633
V Predictions Std            722.2889
V Predictions Max            4509.4033
V Predictions Min            693.11383
Log Pis Mean                 4.5775485
Log Pis Std                  3.6737056
Log Pis Max                  15.786523
Log Pis Min                  -4.327284
Policy mu Mean               -0.08129162
Policy mu Std                1.3189696
Policy mu Max                3.3358827
Policy mu Min                -3.2741442
Policy log std Mean          -0.8959496
Policy log std Std           0.49333924
Policy log std Max           0.021704972
Policy log std Min           -3.3058429
Z mean eval                  3.3087258
Z variance eval              0.012698874
total_rewards                [ 9780.25313482 10152.71116149 10075.65094005 10102.32620263
 10158.22010794  9953.42259305  9906.9862831  10030.65630451
 10161.12009235 10091.00547766]
total_rewards_mean           10041.235229760985
total_rewards_std            119.09481827244143
total_rewards_max            10161.120092347197
total_rewards_min            9780.253134823708
Number of train steps total  452000
Number of env steps total    567000
Number of rollouts total     0
Train Time (s)               110.90318542718887
(Previous) Eval Time (s)     23.099841808900237
Sample Time (s)              16.96682189265266
Epoch Time (s)               150.96984912874177
Total Train Time (s)         17208.149364324287
Epoch                        112
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:23:07.224034 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #112 | Epoch Duration: 150.40150547027588
2020-01-13 13:23:07.224289 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #112 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.309801
Z variance train             0.012764534
KL Divergence                38.84904
KL Loss                      3.8849041
QF Loss                      489.5147
VF Loss                      152.80765
Policy Loss                  -3803.5615
Q Predictions Mean           3808.5923
Q Predictions Std            611.4495
Q Predictions Max            4536.154
Q Predictions Min            665.0285
V Predictions Mean           3797.768
V Predictions Std            602.7997
V Predictions Max            4526.67
V Predictions Min            680.06354
Log Pis Mean                 5.128146
Log Pis Std                  3.6596692
Log Pis Max                  14.70449
Log Pis Min                  -4.4242625
Policy mu Mean               -0.0645397
Policy mu Std                1.3585888
Policy mu Max                2.9152849
Policy mu Min                -2.997
Policy log std Mean          -0.8994188
Policy log std Std           0.49147716
Policy log std Max           -0.07173884
Policy log std Min           -3.3499053
Z mean eval                  3.3336728
Z variance eval              0.0033962945
total_rewards                [ 9961.98717377 10231.92030886 10232.73317235 10262.51027881
 10108.78886991 10109.83346758 10164.67268418 10197.31516372
  9990.49711641 10035.77521899]
total_rewards_mean           10129.603345457834
total_rewards_std            100.82512371751545
total_rewards_max            10262.51027880904
total_rewards_min            9961.987173769778
Number of train steps total  456000
Number of env steps total    572000
Number of rollouts total     0
Train Time (s)               115.49028345989063
(Previous) Eval Time (s)     22.531198823824525
Sample Time (s)              15.829513301607221
Epoch Time (s)               153.85099558532238
Total Train Time (s)         17361.98764582444
Epoch                        113
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:25:41.063331 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #113 | Epoch Duration: 153.83884000778198
2020-01-13 13:25:41.063527 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #113 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3333359
Z variance train             0.003396413
KL Divergence                42.26734
KL Loss                      4.226734
QF Loss                      323.40753
VF Loss                      158.45169
Policy Loss                  -3864.3384
Q Predictions Mean           3867.2454
Q Predictions Std            558.4848
Q Predictions Max            4565.3506
Q Predictions Min            669.4712
V Predictions Mean           3868.7734
V Predictions Std            556.10614
V Predictions Max            4547.946
V Predictions Min            667.30194
Log Pis Mean                 4.5932245
Log Pis Std                  4.018907
Log Pis Max                  15.008055
Log Pis Min                  -7.5042253
Policy mu Mean               -0.14670272
Policy mu Std                1.336742
Policy mu Max                2.98918
Policy mu Min                -2.7981415
Policy log std Mean          -0.9089902
Policy log std Std           0.47690102
Policy log std Max           -0.034305096
Policy log std Min           -3.179903
Z mean eval                  3.3322825
Z variance eval              0.0025198981
total_rewards                [9837.34953207 9869.44105764 9955.99419735 9791.69094123 9762.62516046
 9765.44990174 9764.3209226  9782.89876832 9825.84971449 9786.68209143]
total_rewards_mean           9814.230228733815
total_rewards_std            57.96282863667849
total_rewards_max            9955.99419735134
total_rewards_min            9762.625160458703
Number of train steps total  460000
Number of env steps total    577000
Number of rollouts total     0
Train Time (s)               116.2122044339776
(Previous) Eval Time (s)     22.518788802903146
Sample Time (s)              17.41263632895425
Epoch Time (s)               156.143629565835
Total Train Time (s)         17518.366175156552
Epoch                        114
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:28:17.447781 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #114 | Epoch Duration: 156.3840720653534
2020-01-13 13:28:17.448127 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #114 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3337765
Z variance train             0.0025223058
KL Divergence                44.02589
KL Loss                      4.4025893
QF Loss                      346.44394
VF Loss                      124.78629
Policy Loss                  -3887.7563
Q Predictions Mean           3883.8657
Q Predictions Std            607.57776
Q Predictions Max            4636.5933
Q Predictions Min            690.6186
V Predictions Mean           3883.4697
V Predictions Std            601.3097
V Predictions Max            4630.3257
V Predictions Min            703.66156
Log Pis Mean                 5.1400394
Log Pis Std                  3.8338745
Log Pis Max                  14.632948
Log Pis Min                  -5.265847
Policy mu Mean               -0.06918712
Policy mu Std                1.394208
Policy mu Max                2.9787169
Policy mu Min                -2.7960126
Policy log std Mean          -0.9040475
Policy log std Std           0.4791192
Policy log std Max           0.033441782
Policy log std Min           -3.2502706
Z mean eval                  3.3236644
Z variance eval              0.0017910026
total_rewards                [ 9973.66481854 10106.94876417 10287.51360832 10138.94139003
 10309.7181964  10115.97874216 10251.22217404 10273.25722761
 10362.23805462 10216.53427253]
total_rewards_mean           10203.601724841006
total_rewards_std            111.72545080014633
total_rewards_max            10362.238054615142
total_rewards_min            9973.664818537507
Number of train steps total  464000
Number of env steps total    582000
Number of rollouts total     0
Train Time (s)               112.46140686189756
(Previous) Eval Time (s)     22.758892889134586
Sample Time (s)              15.821496752556413
Epoch Time (s)               151.04179650358856
Total Train Time (s)         17669.052356893662
Epoch                        115
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:30:48.133231 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #115 | Epoch Duration: 150.68487691879272
2020-01-13 13:30:48.133431 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #115 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.323969
Z variance train             0.00179468
KL Divergence                44.773304
KL Loss                      4.4773307
QF Loss                      426.29138
VF Loss                      158.50839
Policy Loss                  -3882.185
Q Predictions Mean           3877.529
Q Predictions Std            594.74554
Q Predictions Max            4537.609
Q Predictions Min            696.13165
V Predictions Mean           3875.1313
V Predictions Std            588.62036
V Predictions Max            4539.6816
V Predictions Min            707.6623
Log Pis Mean                 5.069461
Log Pis Std                  3.487305
Log Pis Max                  14.987175
Log Pis Min                  -3.8454823
Policy mu Mean               -0.067092784
Policy mu Std                1.3186944
Policy mu Max                3.0036254
Policy mu Min                -2.6927311
Policy log std Mean          -0.919015
Policy log std Std           0.48022377
Policy log std Max           -0.13343471
Policy log std Min           -3.3427515
Z mean eval                  3.3118186
Z variance eval              0.008361433
total_rewards                [ 9961.413674    9952.2739924  10146.26694544 10212.53519062
 10358.9267542  10031.01038544 10314.6747665  10123.85697754
 10122.80738053 10109.64979999]
total_rewards_mean           10133.341586667102
total_rewards_std            127.97955515581789
total_rewards_max            10358.926754196882
total_rewards_min            9952.273992401762
Number of train steps total  468000
Number of env steps total    587000
Number of rollouts total     0
Train Time (s)               112.05169145017862
(Previous) Eval Time (s)     22.401703401934355
Sample Time (s)              17.052265785634518
Epoch Time (s)               151.5056606377475
Total Train Time (s)         17821.010897914413
Epoch                        116
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:33:20.092768 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #116 | Epoch Duration: 151.9591929912567
2020-01-13 13:33:20.092982 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #116 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.309543
Z variance train             0.008373616
KL Divergence                44.337772
KL Loss                      4.4337773
QF Loss                      273.04767
VF Loss                      240.4438
Policy Loss                  -3799.086
Q Predictions Mean           3801.7761
Q Predictions Std            637.8052
Q Predictions Max            4602.22
Q Predictions Min            677.938
V Predictions Mean           3811.3535
V Predictions Std            631.48615
V Predictions Max            4609.784
V Predictions Min            706.59454
Log Pis Mean                 5.3590555
Log Pis Std                  3.9335816
Log Pis Max                  16.901905
Log Pis Min                  -5.9560566
Policy mu Mean               -0.11662943
Policy mu Std                1.3739723
Policy mu Max                3.1877682
Policy mu Min                -2.7760372
Policy log std Mean          -0.893717
Policy log std Std           0.49012777
Policy log std Max           -0.17050183
Policy log std Min           -3.3148527
Z mean eval                  3.3274174
Z variance eval              0.0034302317
total_rewards                [10202.35791105 10165.62848268 10118.15096312 10282.20945122
 10387.26368892 10187.67971079 10303.66060538 10432.35857669
 10348.39971097 10119.57124452]
total_rewards_mean           10254.728034534957
total_rewards_std            106.36719838466196
total_rewards_max            10432.358576689881
total_rewards_min            10118.15096312442
Number of train steps total  472000
Number of env steps total    592000
Number of rollouts total     0
Train Time (s)               116.59666116908193
(Previous) Eval Time (s)     22.85495133092627
Sample Time (s)              16.69676977302879
Epoch Time (s)               156.148382273037
Total Train Time (s)         17976.94919493934
Epoch                        117
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:35:56.032667 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #117 | Epoch Duration: 155.93956351280212
2020-01-13 13:35:56.032844 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #117 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3281198
Z variance train             0.0034249187
KL Divergence                45.635895
KL Loss                      4.5635896
QF Loss                      358.90808
VF Loss                      118.02127
Policy Loss                  -3850.7334
Q Predictions Mean           3853.5273
Q Predictions Std            609.09686
Q Predictions Max            4594.627
Q Predictions Min            686.11145
V Predictions Mean           3854.3054
V Predictions Std            605.01294
V Predictions Max            4577.707
V Predictions Min            687.7306
Log Pis Mean                 5.274803
Log Pis Std                  3.653084
Log Pis Max                  14.805765
Log Pis Min                  -4.9242764
Policy mu Mean               -0.068798006
Policy mu Std                1.3639343
Policy mu Max                3.097535
Policy mu Min                -3.0639596
Policy log std Mean          -0.917291
Policy log std Std           0.49964422
Policy log std Max           -0.18723655
Policy log std Min           -3.236198
Z mean eval                  3.3119893
Z variance eval              0.003931864
total_rewards                [10339.39380696 10188.57706089 10392.92153468 10517.9389026
 10149.89163075 10183.14125275 10452.5636069  10069.16526456
 10060.56714487  6390.99811741]
total_rewards_mean           9874.51583223681
total_rewards_std            1170.9015150245655
total_rewards_max            10517.938902599582
total_rewards_min            6390.998117408849
Number of train steps total  476000
Number of env steps total    597000
Number of rollouts total     0
Train Time (s)               113.57439290825278
(Previous) Eval Time (s)     22.64585715578869
Sample Time (s)              15.66070842416957
Epoch Time (s)               151.88095848821104
Total Train Time (s)         18129.13194800634
Epoch                        118
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:38:28.216928 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #118 | Epoch Duration: 152.18394470214844
2020-01-13 13:38:28.217112 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #118 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3120239
Z variance train             0.003927121
KL Divergence                44.79121
KL Loss                      4.479121
QF Loss                      477.39355
VF Loss                      113.556366
Policy Loss                  -3873.0913
Q Predictions Mean           3878.8662
Q Predictions Std            543.31555
Q Predictions Max            4638.035
Q Predictions Min            680.4382
V Predictions Mean           3873.8357
V Predictions Std            536.63684
V Predictions Max            4635.42
V Predictions Min            683.5951
Log Pis Mean                 5.720702
Log Pis Std                  3.9960766
Log Pis Max                  17.217373
Log Pis Min                  -5.439848
Policy mu Mean               -0.13069417
Policy mu Std                1.3926103
Policy mu Max                3.1644218
Policy mu Min                -3.2243986
Policy log std Mean          -0.92354316
Policy log std Std           0.4978785
Policy log std Max           -0.14232463
Policy log std Min           -3.346527
Z mean eval                  3.3201096
Z variance eval              0.0017755805
total_rewards                [10172.15390674 10261.94621723 10078.61151018  9988.90284767
 10169.23810265 10050.74870835 10255.93534533 10067.64121638
 10240.32172042 10205.14909729]
total_rewards_mean           10149.064867223311
total_rewards_std            91.37190027552779
total_rewards_max            10261.946217229166
total_rewards_min            9988.902847667825
Number of train steps total  480000
Number of env steps total    602000
Number of rollouts total     0
Train Time (s)               117.49707228830084
(Previous) Eval Time (s)     22.94853104231879
Sample Time (s)              16.269282021094114
Epoch Time (s)               156.71488535171375
Total Train Time (s)         18285.27704121126
Epoch                        119
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:41:04.363531 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #119 | Epoch Duration: 156.14626359939575
2020-01-13 13:41:04.363737 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #119 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3219051
Z variance train             0.0017716943
KL Divergence                45.776955
KL Loss                      4.5776954
QF Loss                      386.58636
VF Loss                      389.1432
Policy Loss                  -3810.6963
Q Predictions Mean           3805.4473
Q Predictions Std            751.84686
Q Predictions Max            4631.3374
Q Predictions Min            707.87964
V Predictions Mean           3799.857
V Predictions Std            736.3931
V Predictions Max            4605.835
V Predictions Min            694.4937
Log Pis Mean                 5.2821655
Log Pis Std                  4.2174797
Log Pis Max                  19.67658
Log Pis Min                  -4.1505375
Policy mu Mean               -0.09255585
Policy mu Std                1.3727419
Policy mu Max                3.4948964
Policy mu Min                -3.1047552
Policy log std Mean          -0.91095567
Policy log std Std           0.48250702
Policy log std Max           -0.12892914
Policy log std Min           -3.3523698
Z mean eval                  3.324407
Z variance eval              0.005046147
total_rewards                [ 9897.58927052 10116.37123354 10536.07352734 10216.38651515
  9925.11744088 10346.16715227 10423.1967744  10337.37659284
 10266.24382257 10313.53519757]
total_rewards_mean           10237.805752707853
total_rewards_std            195.00258340777083
total_rewards_max            10536.073527341452
total_rewards_min            9897.589270515993
Number of train steps total  484000
Number of env steps total    607000
Number of rollouts total     0
Train Time (s)               119.82528701936826
(Previous) Eval Time (s)     22.379598268773407
Sample Time (s)              16.92727693868801
Epoch Time (s)               159.13216222682968
Total Train Time (s)         18444.723022589926
Epoch                        120
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:43:43.819832 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #120 | Epoch Duration: 159.45586729049683
2020-01-13 13:43:43.820173 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #120 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3258376
Z variance train             0.005051693
KL Divergence                46.036976
KL Loss                      4.603698
QF Loss                      543.21655
VF Loss                      113.82115
Policy Loss                  -3884.2307
Q Predictions Mean           3884.69
Q Predictions Std            552.1587
Q Predictions Max            4586.2676
Q Predictions Min            703.07947
V Predictions Mean           3881.1042
V Predictions Std            545.7519
V Predictions Max            4570.236
V Predictions Min            690.0189
Log Pis Mean                 5.639623
Log Pis Std                  3.7825558
Log Pis Max                  19.334538
Log Pis Min                  -4.4157715
Policy mu Mean               -0.106015176
Policy mu Std                1.3958005
Policy mu Max                3.0693774
Policy mu Min                -3.5299141
Policy log std Mean          -0.91793936
Policy log std Std           0.48756844
Policy log std Max           0.052909195
Policy log std Min           -3.1556137
Z mean eval                  3.3051102
Z variance eval              0.0071503506
total_rewards                [10157.64608047 10218.31524923 10545.91733048 10356.39463412
 10553.3237247  10424.91898482 10292.95739169 10353.56487955
 10347.3875759  10419.6879774 ]
total_rewards_mean           10367.011382835453
total_rewards_std            120.39714365755191
total_rewards_max            10553.323724704009
total_rewards_min            10157.646080470162
Number of train steps total  488000
Number of env steps total    612000
Number of rollouts total     0
Train Time (s)               110.18643674859777
(Previous) Eval Time (s)     22.70295973494649
Sample Time (s)              16.391320146154612
Epoch Time (s)               149.28071662969887
Total Train Time (s)         18593.523661014624
Epoch                        121
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:46:12.614495 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #121 | Epoch Duration: 148.79410767555237
2020-01-13 13:46:12.614652 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #121 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3014984
Z variance train             0.0071602985
KL Divergence                44.160282
KL Loss                      4.4160285
QF Loss                      373.44617
VF Loss                      309.73767
Policy Loss                  -3918.9707
Q Predictions Mean           3920.8193
Q Predictions Std            556.2246
Q Predictions Max            4579.1006
Q Predictions Min            681.65405
V Predictions Mean           3931.9722
V Predictions Std            552.0665
V Predictions Max            4601.9087
V Predictions Min            683.04724
Log Pis Mean                 5.497306
Log Pis Std                  3.7298906
Log Pis Max                  18.01663
Log Pis Min                  -3.1034765
Policy mu Mean               -0.12541799
Policy mu Std                1.3679632
Policy mu Max                3.1329858
Policy mu Min                -3.0613768
Policy log std Mean          -0.9000197
Policy log std Std           0.47216988
Policy log std Max           -0.17662525
Policy log std Min           -3.4130764
Z mean eval                  3.3246956
Z variance eval              0.0028117816
total_rewards                [10250.04140339 10041.54851461 10293.35024407 10477.81586792
 10548.37195623 10524.73893255 10534.77217471  2184.34744106
 10476.27962263 10360.13431015]
total_rewards_mean           9569.140046732275
total_rewards_std            2466.27683582745
total_rewards_max            10548.371956225983
total_rewards_min            2184.3474410613912
Number of train steps total  492000
Number of env steps total    617000
Number of rollouts total     0
Train Time (s)               114.76431468920782
(Previous) Eval Time (s)     22.216099104844034
Sample Time (s)              16.089253718499094
Epoch Time (s)               153.06966751255095
Total Train Time (s)         18746.76869274024
Epoch                        122
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:48:45.864654 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #122 | Epoch Duration: 153.24983835220337
2020-01-13 13:48:45.864965 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #122 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3276792
Z variance train             0.0028013359
KL Divergence                45.283245
KL Loss                      4.5283246
QF Loss                      470.14114
VF Loss                      113.72952
Policy Loss                  -3941.2422
Q Predictions Mean           3940.1902
Q Predictions Std            522.9596
Q Predictions Max            4638.7637
Q Predictions Min            699.3474
V Predictions Mean           3935.8774
V Predictions Std            518.5833
V Predictions Max            4629.509
V Predictions Min            712.34247
Log Pis Mean                 5.6340303
Log Pis Std                  4.001508
Log Pis Max                  16.91563
Log Pis Min                  -6.696056
Policy mu Mean               -0.11867679
Policy mu Std                1.3906809
Policy mu Max                3.0305188
Policy mu Min                -3.3481798
Policy log std Mean          -0.8959977
Policy log std Std           0.50065106
Policy log std Max           0.12986124
Policy log std Min           -3.4017138
Z mean eval                  3.3085182
Z variance eval              0.0025769079
total_rewards                [10130.57739812 10425.10124239 10301.49015749 10414.66414073
 10335.87031302 10412.35999922 10367.31949424 10295.56137141
 10291.73814935 10212.84240314]
total_rewards_mean           10318.752466910319
total_rewards_std            89.50734262598573
total_rewards_max            10425.10124239382
total_rewards_min            10130.577398115285
Number of train steps total  496000
Number of env steps total    622000
Number of rollouts total     0
Train Time (s)               120.33589481702074
(Previous) Eval Time (s)     22.395943509880453
Sample Time (s)              15.835790294688195
Epoch Time (s)               158.5676286215894
Total Train Time (s)         18905.287645708304
Epoch                        123
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:51:24.386842 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #123 | Epoch Duration: 158.5216405391693
2020-01-13 13:51:24.387085 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #123 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3064332
Z variance train             0.0025724757
KL Divergence                44.613197
KL Loss                      4.46132
QF Loss                      294.49588
VF Loss                      107.57805
Policy Loss                  -3909.0122
Q Predictions Mean           3908.1558
Q Predictions Std            551.05444
Q Predictions Max            4709.49
Q Predictions Min            703.603
V Predictions Mean           3914.7073
V Predictions Std            547.4554
V Predictions Max            4695.977
V Predictions Min            703.64166
Log Pis Mean                 5.2658114
Log Pis Std                  3.9417484
Log Pis Max                  21.895502
Log Pis Min                  -4.7922525
Policy mu Mean               -0.1252756
Policy mu Std                1.3562995
Policy mu Max                3.7983365
Policy mu Min                -3.1886897
Policy log std Mean          -0.9243107
Policy log std Std           0.4992828
Policy log std Max           0.0757792
Policy log std Min           -3.344761
Z mean eval                  3.305956
Z variance eval              0.0064922916
total_rewards                [10114.89527705 10429.09615019 10053.61089325 10442.44208135
 10032.52623762 10243.80979614 10411.94735977 10433.2083031
 10275.00291763 10395.60832604]
total_rewards_mean           10283.214734212586
total_rewards_std            156.15744731514638
total_rewards_max            10442.442081348438
total_rewards_min            10032.526237624143
Number of train steps total  500000
Number of env steps total    627000
Number of rollouts total     0
Train Time (s)               115.6732176267542
(Previous) Eval Time (s)     22.349656163249165
Sample Time (s)              16.377920418512076
Epoch Time (s)               154.40079420851544
Total Train Time (s)         19059.973531425
Epoch                        124
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:53:59.072673 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #124 | Epoch Duration: 154.68540859222412
2020-01-13 13:53:59.072865 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #124 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3051655
Z variance train             0.0065087704
KL Divergence                43.09576
KL Loss                      4.309576
QF Loss                      627.44214
VF Loss                      184.04697
Policy Loss                  -3925.0872
Q Predictions Mean           3929.0586
Q Predictions Std            668.068
Q Predictions Max            4725.571
Q Predictions Min            679.93567
V Predictions Mean           3932.435
V Predictions Std            662.4526
V Predictions Max            4704.628
V Predictions Min            682.48987
Log Pis Mean                 5.7371445
Log Pis Std                  4.047223
Log Pis Max                  14.024941
Log Pis Min                  -5.0273767
Policy mu Mean               -0.13246012
Policy mu Std                1.4124857
Policy mu Max                3.402436
Policy mu Min                -3.0368
Policy log std Mean          -0.89970034
Policy log std Std           0.4945835
Policy log std Max           -0.16475803
Policy log std Min           -3.1973777
Z mean eval                  3.312418
Z variance eval              0.009888994
total_rewards                [10396.20778131 10487.99571987 10494.04610875 10711.29766062
 10438.72113857 10654.68751275 10636.96737452 10441.99814308
 10539.55710616 10567.4026033 ]
total_rewards_mean           10536.888114893296
total_rewards_std            98.94808008634706
total_rewards_max            10711.297660616689
total_rewards_min            10396.207781312367
Number of train steps total  504000
Number of env steps total    632000
Number of rollouts total     0
Train Time (s)               111.6130211846903
(Previous) Eval Time (s)     22.633959602098912
Sample Time (s)              15.726552024949342
Epoch Time (s)               149.97353281173855
Total Train Time (s)         19209.864800152835
Epoch                        125
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:56:28.965236 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #125 | Epoch Duration: 149.8922257423401
2020-01-13 13:56:28.965436 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #125 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3130264
Z variance train             0.00984603
KL Divergence                42.8116
KL Loss                      4.28116
QF Loss                      534.20044
VF Loss                      129.89449
Policy Loss                  -3899.2197
Q Predictions Mean           3897.494
Q Predictions Std            765.2936
Q Predictions Max            4718.78
Q Predictions Min            683.2942
V Predictions Mean           3898.183
V Predictions Std            759.3661
V Predictions Max            4692.196
V Predictions Min            693.6344
Log Pis Mean                 5.338548
Log Pis Std                  3.840031
Log Pis Max                  16.317318
Log Pis Min                  -3.7338672
Policy mu Mean               -0.09201592
Policy mu Std                1.3629386
Policy mu Max                3.0524507
Policy mu Min                -3.21349
Policy log std Mean          -0.9027052
Policy log std Std           0.49439955
Policy log std Max           -0.05488658
Policy log std Min           -3.2835088
Z mean eval                  3.305359
Z variance eval              0.0049725734
total_rewards                [10393.75726409 10534.68208372 10640.33591315 10522.75422533
 10508.13296622 10636.18590697 10526.18379097 10494.49913197
  9865.51873909 10745.23990833]
total_rewards_mean           10486.728992983299
total_rewards_std            226.49034699457312
total_rewards_max            10745.239908334728
total_rewards_min            9865.518739094896
Number of train steps total  508000
Number of env steps total    637000
Number of rollouts total     0
Train Time (s)               111.38666756497696
(Previous) Eval Time (s)     22.552354118786752
Sample Time (s)              16.452449872158468
Epoch Time (s)               150.39147155592218
Total Train Time (s)         19360.465008099563
Epoch                        126
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:58:59.568933 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #126 | Epoch Duration: 150.6033456325531
2020-01-13 13:58:59.569161 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #126 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3064518
Z variance train             0.004978425
KL Divergence                43.931335
KL Loss                      4.3931336
QF Loss                      319.96735
VF Loss                      118.91899
Policy Loss                  -3987.388
Q Predictions Mean           3987.8242
Q Predictions Std            591.17035
Q Predictions Max            4740.993
Q Predictions Min            722.74585
V Predictions Mean           3989.9827
V Predictions Std            585.6348
V Predictions Max            4746.871
V Predictions Min            750.161
Log Pis Mean                 5.2107596
Log Pis Std                  3.5333643
Log Pis Max                  13.45097
Log Pis Min                  -3.6495044
Policy mu Mean               -0.13441297
Policy mu Std                1.353762
Policy mu Max                3.0245364
Policy mu Min                -2.8851361
Policy log std Mean          -0.92600536
Policy log std Std           0.51372373
Policy log std Max           0.14977127
Policy log std Min           -3.2921693
Z mean eval                  3.2917125
Z variance eval              0.0026576333
total_rewards                [10394.91693509 10332.86761543 10519.70932213 10492.15759862
 10728.0842549  10552.31911574 10456.62881771 10436.15402902
 10661.62543437 10730.59338329]
total_rewards_mean           10530.505650629757
total_rewards_std            130.43499226009598
total_rewards_max            10730.593383285848
total_rewards_min            10332.8676154315
Number of train steps total  512000
Number of env steps total    642000
Number of rollouts total     0
Train Time (s)               117.13503079861403
(Previous) Eval Time (s)     22.763905168976635
Sample Time (s)              16.047925943974406
Epoch Time (s)               155.94686191156507
Total Train Time (s)         19516.3403790202
Epoch                        127
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:01:35.446648 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #127 | Epoch Duration: 155.87729406356812
2020-01-13 14:01:35.446910 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #127 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2932136
Z variance train             0.002660351
KL Divergence                44.69403
KL Loss                      4.4694033
QF Loss                      443.3334
VF Loss                      122.06288
Policy Loss                  -3923.2173
Q Predictions Mean           3924.6086
Q Predictions Std            682.3261
Q Predictions Max            4705.2373
Q Predictions Min            755.83997
V Predictions Mean           3918.1802
V Predictions Std            672.271
V Predictions Max            4692.92
V Predictions Min            752.2358
Log Pis Mean                 5.6225348
Log Pis Std                  4.1030912
Log Pis Max                  15.202166
Log Pis Min                  -3.8219862
Policy mu Mean               -0.074401826
Policy mu Std                1.3876518
Policy mu Max                2.9841406
Policy mu Min                -3.1966777
Policy log std Mean          -0.9111335
Policy log std Std           0.5080853
Policy log std Max           -0.08877087
Policy log std Min           -3.443774
Z mean eval                  3.2986782
Z variance eval              0.0034062634
total_rewards                [10396.07841893 10469.7965166  10431.2587116  10671.80931983
 10641.80193229 10478.36025987 10333.15604433 10540.82702854
 10451.64050512 10390.85629362]
total_rewards_mean           10480.558503072194
total_rewards_std            103.2021521331441
total_rewards_max            10671.809319825401
total_rewards_min            10333.156044326668
Number of train steps total  516000
Number of env steps total    647000
Number of rollouts total     0
Train Time (s)               112.54095396911725
(Previous) Eval Time (s)     22.69401986990124
Sample Time (s)              16.364417048171163
Epoch Time (s)               151.59939088718966
Total Train Time (s)         19667.785103590228
Epoch                        128
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:04:06.891955 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #128 | Epoch Duration: 151.44483542442322
2020-01-13 14:04:06.892173 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #128 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3008945
Z variance train             0.0033975553
KL Divergence                45.58809
KL Loss                      4.558809
QF Loss                      1128.7673
VF Loss                      133.94225
Policy Loss                  -3961.1067
Q Predictions Mean           3959.0183
Q Predictions Std            574.6409
Q Predictions Max            4774.498
Q Predictions Min            736.174
V Predictions Mean           3954.3599
V Predictions Std            561.70325
V Predictions Max            4756.157
V Predictions Min            747.8009
Log Pis Mean                 5.663764
Log Pis Std                  3.9779892
Log Pis Max                  16.027872
Log Pis Min                  -5.7806644
Policy mu Mean               -0.1329899
Policy mu Std                1.4246219
Policy mu Max                3.2491066
Policy mu Min                -2.8791142
Policy log std Mean          -0.88996667
Policy log std Std           0.501951
Policy log std Max           -0.14834502
Policy log std Min           -3.4297955
Z mean eval                  3.3057532
Z variance eval              0.0045648552
total_rewards                [10423.2374265  10526.6332462   4634.98095498  1486.07671248
 10559.08441225 10496.89205075 10894.279317   10769.90732445
 10640.43770425 10726.03169831]
total_rewards_mean           9115.756084718378
total_rewards_std            3111.2243720500146
total_rewards_max            10894.279317003577
total_rewards_min            1486.0767124838962
Number of train steps total  520000
Number of env steps total    652000
Number of rollouts total     0
Train Time (s)               116.53620449779555
(Previous) Eval Time (s)     22.539157301187515
Sample Time (s)              16.107322645839304
Epoch Time (s)               155.18268444482237
Total Train Time (s)         19822.92117417371
Epoch                        129
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:06:42.030701 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #129 | Epoch Duration: 155.13835668563843
2020-01-13 14:06:42.030919 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #129 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3061416
Z variance train             0.0045586047
KL Divergence                43.62382
KL Loss                      4.3623824
QF Loss                      315.90063
VF Loss                      271.5069
Policy Loss                  -3956.425
Q Predictions Mean           3952.7202
Q Predictions Std            590.49255
Q Predictions Max            4689.037
Q Predictions Min            719.8137
V Predictions Mean           3946.0752
V Predictions Std            584.4754
V Predictions Max            4683.2104
V Predictions Min            729.7482
Log Pis Mean                 5.3932486
Log Pis Std                  3.6479461
Log Pis Max                  14.855885
Log Pis Min                  -4.242519
Policy mu Mean               -0.09881699
Policy mu Std                1.349102
Policy mu Max                3.1938064
Policy mu Min                -2.6354153
Policy log std Mean          -0.9189811
Policy log std Std           0.50787073
Policy log std Max           -0.08684969
Policy log std Min           -3.4786935
Z mean eval                  3.3027923
Z variance eval              0.0029948296
total_rewards                [10261.21686869 10336.82727014 10115.72034623 10386.53998508
 10601.81363083 10483.52092944 10412.09388262 10375.82806323
 10347.32178584 10371.03983491]
total_rewards_mean           10369.192259701787
total_rewards_std            121.16319302269812
total_rewards_max            10601.813630826162
total_rewards_min            10115.720346233484
Number of train steps total  524000
Number of env steps total    657000
Number of rollouts total     0
Train Time (s)               110.79270289326087
(Previous) Eval Time (s)     22.494480188004673
Sample Time (s)              16.495720331091434
Epoch Time (s)               149.78290341235697
Total Train Time (s)         19972.476654361002
Epoch                        130
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:09:11.587004 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #130 | Epoch Duration: 149.55592703819275
2020-01-13 14:09:11.587195 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #130 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3022556
Z variance train             0.0029953248
KL Divergence                43.226772
KL Loss                      4.322677
QF Loss                      312.69745
VF Loss                      94.635735
Policy Loss                  -3954.0056
Q Predictions Mean           3955.4028
Q Predictions Std            650.44507
Q Predictions Max            4729.3823
Q Predictions Min            692.74133
V Predictions Mean           3953.7034
V Predictions Std            644.5595
V Predictions Max            4729.7993
V Predictions Min            710.1428
Log Pis Mean                 5.729925
Log Pis Std                  3.7071714
Log Pis Max                  14.899527
Log Pis Min                  -4.8471813
Policy mu Mean               -0.07571294
Policy mu Std                1.4083406
Policy mu Max                3.0603924
Policy mu Min                -3.0493543
Policy log std Mean          -0.91629857
Policy log std Std           0.48893544
Policy log std Max           -0.066927254
Policy log std Min           -3.5704274
Z mean eval                  3.2985015
Z variance eval              0.0040479074
total_rewards                [10702.48280824 10735.37556717 10701.52578586 10647.81831788
 10612.53085779 10710.06394979 10676.81919289  1334.45838076
 10649.91221753 10609.05627946]
total_rewards_mean           9738.004335736694
total_rewards_std            2801.4650653208923
total_rewards_max            10735.375567172137
total_rewards_min            1334.4583807617146
Number of train steps total  528000
Number of env steps total    662000
Number of rollouts total     0
Train Time (s)               117.62640183698386
(Previous) Eval Time (s)     22.267180810216814
Sample Time (s)              15.614197031129152
Epoch Time (s)               155.50777967832983
Total Train Time (s)         20128.75433353847
Epoch                        131
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:11:47.870818 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #131 | Epoch Duration: 156.2834494113922
2020-01-13 14:11:47.871108 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #131 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2941546
Z variance train             0.0040660976
KL Divergence                42.43303
KL Loss                      4.243303
QF Loss                      352.4481
VF Loss                      430.434
Policy Loss                  -3999.7288
Q Predictions Mean           4003.3315
Q Predictions Std            543.94116
Q Predictions Max            4769.985
Q Predictions Min            689.9544
V Predictions Mean           4017.3865
V Predictions Std            542.25665
V Predictions Max            4779.6255
V Predictions Min            705.7108
Log Pis Mean                 5.317831
Log Pis Std                  3.7164133
Log Pis Max                  15.184421
Log Pis Min                  -5.109477
Policy mu Mean               -0.11037461
Policy mu Std                1.3856952
Policy mu Max                3.1575515
Policy mu Min                -3.075405
Policy log std Mean          -0.9127167
Policy log std Std           0.45325363
Policy log std Max           -0.09475899
Policy log std Min           -3.1799972
Z mean eval                  3.2865906
Z variance eval              0.0069152215
total_rewards                [10450.41232441 10643.84069199 10649.60546191 10784.93533233
 10736.3979158  10603.81034028 10898.82956117 10776.96959073
  4432.20791412 10767.58908392]
total_rewards_mean           10074.459821666056
total_rewards_std            1884.357106177261
total_rewards_max            10898.82956116717
total_rewards_min            4432.207914120709
Number of train steps total  532000
Number of env steps total    667000
Number of rollouts total     0
Train Time (s)               115.17181943403557
(Previous) Eval Time (s)     23.042508978396654
Sample Time (s)              16.017642232123762
Epoch Time (s)               154.231970644556
Total Train Time (s)         20282.218198989518
Epoch                        132
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:14:21.333350 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #132 | Epoch Duration: 153.46203660964966
2020-01-13 14:14:21.333550 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #132 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2874665
Z variance train             0.0069472953
KL Divergence                41.29882
KL Loss                      4.1298823
QF Loss                      434.45197
VF Loss                      107.26582
Policy Loss                  -4076.0168
Q Predictions Mean           4074.1797
Q Predictions Std            648.7
Q Predictions Max            4865.5703
Q Predictions Min            673.95166
V Predictions Mean           4071.4292
V Predictions Std            645.1074
V Predictions Max            4859.653
V Predictions Min            684.1738
Log Pis Mean                 5.986261
Log Pis Std                  3.975174
Log Pis Max                  16.450766
Log Pis Min                  -5.279372
Policy mu Mean               -0.09337268
Policy mu Std                1.421862
Policy mu Max                3.153654
Policy mu Min                -3.0412936
Policy log std Mean          -0.9147218
Policy log std Std           0.51052314
Policy log std Max           -0.1603049
Policy log std Min           -3.6553454
Z mean eval                  3.2881234
Z variance eval              0.0053423895
total_rewards                [10525.64313172 10697.25914661 10436.36394062 10544.9586669
 10708.30769665  6178.39524043 10791.66774252 10604.70728685
 10740.7261604  10738.23066414]
total_rewards_mean           10196.625967685923
total_rewards_std            1343.714179136564
total_rewards_max            10791.667742519618
total_rewards_min            6178.3952404263755
Number of train steps total  536000
Number of env steps total    672000
Number of rollouts total     0
Train Time (s)               117.73723709210753
(Previous) Eval Time (s)     22.272312079090625
Sample Time (s)              15.413634791970253
Epoch Time (s)               155.4231839631684
Total Train Time (s)         20437.623189324513
Epoch                        133
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:16:56.740585 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #133 | Epoch Duration: 155.40690207481384
2020-01-13 14:16:56.740756 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #133 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.290319
Z variance train             0.005352042
KL Divergence                41.90699
KL Loss                      4.190699
QF Loss                      631.31934
VF Loss                      93.980896
Policy Loss                  -4006.5664
Q Predictions Mean           4006.3494
Q Predictions Std            678.9828
Q Predictions Max            4841.769
Q Predictions Min            668.9791
V Predictions Mean           4001.7954
V Predictions Std            673.8369
V Predictions Max            4813.978
V Predictions Min            662.63983
Log Pis Mean                 5.547369
Log Pis Std                  3.787494
Log Pis Max                  16.28227
Log Pis Min                  -6.185898
Policy mu Mean               -0.1277398
Policy mu Std                1.3615174
Policy mu Max                3.142048
Policy mu Min                -2.9492037
Policy log std Mean          -0.9177889
Policy log std Std           0.50157124
Policy log std Max           -0.15015316
Policy log std Min           -3.3815928
Z mean eval                  3.2897701
Z variance eval              0.0029585925
total_rewards                [10540.27559148 10999.43020582 10554.22882783 10639.91665404
 10816.30661978 10833.04788766 10778.27812338 10854.90595445
 10802.41638647 10759.50677589]
total_rewards_mean           10757.831302680468
total_rewards_std            134.8953091732526
total_rewards_max            10999.430205821485
total_rewards_min            10540.275591476799
Number of train steps total  540000
Number of env steps total    677000
Number of rollouts total     0
Train Time (s)               113.41438681771979
(Previous) Eval Time (s)     22.255754723213613
Sample Time (s)              16.095219924580306
Epoch Time (s)               151.7653614655137
Total Train Time (s)         20589.45786866313
Epoch                        134
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:19:28.578224 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #134 | Epoch Duration: 151.83730459213257
2020-01-13 14:19:28.578532 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #134 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2884572
Z variance train             0.0029607527
KL Divergence                42.949966
KL Loss                      4.2949967
QF Loss                      452.86615
VF Loss                      92.1072
Policy Loss                  -3951.0713
Q Predictions Mean           3947.2397
Q Predictions Std            670.2442
Q Predictions Max            4725.368
Q Predictions Min            670.30194
V Predictions Mean           3946.625
V Predictions Std            667.9358
V Predictions Max            4715.324
V Predictions Min            646.88086
Log Pis Mean                 5.373046
Log Pis Std                  3.6984293
Log Pis Max                  15.18026
Log Pis Min                  -4.7803535
Policy mu Mean               -0.054569114
Policy mu Std                1.3894122
Policy mu Max                3.232169
Policy mu Min                -3.351838
Policy log std Mean          -0.9169249
Policy log std Std           0.49546027
Policy log std Max           -0.18482465
Policy log std Min           -3.4831777
Z mean eval                  3.288456
Z variance eval              0.010239055
total_rewards                [10684.61015615 10988.72902522 10839.43029909 10915.10892838
 10868.3842394  10873.57389619 10930.43587945 10895.74079573
 11047.7266199  11132.50061831]
total_rewards_mean           10917.624045782479
total_rewards_std            115.57620595880086
total_rewards_max            11132.50061830963
total_rewards_min            10684.610156151484
Number of train steps total  544000
Number of env steps total    682000
Number of rollouts total     0
Train Time (s)               112.57810206711292
(Previous) Eval Time (s)     22.327379574999213
Sample Time (s)              15.566927288193256
Epoch Time (s)               150.4724089303054
Total Train Time (s)         20739.964827813674
Epoch                        135
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:21:59.085593 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #135 | Epoch Duration: 150.50683450698853
2020-01-13 14:21:59.085764 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #135 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2875454
Z variance train             0.010211691
KL Divergence                42.53965
KL Loss                      4.253965
QF Loss                      241.52518
VF Loss                      212.10579
Policy Loss                  -4007.0881
Q Predictions Mean           4005.4697
Q Predictions Std            698.6293
Q Predictions Max            4784.269
Q Predictions Min            697.7596
V Predictions Mean           4017.7568
V Predictions Std            692.2265
V Predictions Max            4783.3037
V Predictions Min            720.2086
Log Pis Mean                 5.3325863
Log Pis Std                  4.026109
Log Pis Max                  15.561798
Log Pis Min                  -5.8946347
Policy mu Mean               -0.121774256
Policy mu Std                1.3761909
Policy mu Max                3.3044076
Policy mu Min                -2.9846554
Policy log std Mean          -0.897803
Policy log std Std           0.5017645
Policy log std Max           -0.14397323
Policy log std Min           -3.467818
Z mean eval                  3.2963061
Z variance eval              0.010265837
total_rewards                [10912.0565216  10863.20431112 10744.92009515 10832.14534545
 10997.94139844 10952.27537545 10854.48327292 10737.39790575
 10763.77902098 10766.44364895]
total_rewards_mean           10842.464689580938
total_rewards_std            86.1859002091486
total_rewards_max            10997.941398436447
total_rewards_min            10737.39790575292
Number of train steps total  548000
Number of env steps total    687000
Number of rollouts total     0
Train Time (s)               115.77217516489327
(Previous) Eval Time (s)     22.36155277490616
Sample Time (s)              15.627089446410537
Epoch Time (s)               153.76081738620996
Total Train Time (s)         20893.909599208273
Epoch                        136
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:24:33.034119 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #136 | Epoch Duration: 153.94821190834045
2020-01-13 14:24:33.034360 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #136 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.296193
Z variance train             0.010290408
KL Divergence                40.5977
KL Loss                      4.05977
QF Loss                      371.82242
VF Loss                      208.32309
Policy Loss                  -3999.1982
Q Predictions Mean           3999.2217
Q Predictions Std            746.55817
Q Predictions Max            4808.8784
Q Predictions Min            747.1512
V Predictions Mean           3992.774
V Predictions Std            746.2183
V Predictions Max            4802.987
V Predictions Min            705.7593
Log Pis Mean                 5.6091595
Log Pis Std                  3.8615677
Log Pis Max                  20.148941
Log Pis Min                  -6.0986395
Policy mu Mean               -0.070777655
Policy mu Std                1.3761989
Policy mu Max                3.8207686
Policy mu Min                -3.9738655
Policy log std Mean          -0.9341362
Policy log std Std           0.5188495
Policy log std Max           -0.053548217
Policy log std Min           -3.3232033
Z mean eval                  3.2904599
Z variance eval              0.0059252777
total_rewards                [10762.33407814 11141.84580505 11043.36293434 11087.37144204
 11107.07118506 10783.83439736 11120.30174322 10754.12972532
 10372.7195403  10732.44830405]
total_rewards_mean           10890.541915488006
total_rewards_std            237.5899631892924
total_rewards_max            11141.845805054092
total_rewards_min            10372.7195403018
Number of train steps total  552000
Number of env steps total    692000
Number of rollouts total     0
Train Time (s)               115.69979331083596
(Previous) Eval Time (s)     22.548650268930942
Sample Time (s)              16.479719989467412
Epoch Time (s)               154.7281635692343
Total Train Time (s)         21048.923912442755
Epoch                        137
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:27:08.050495 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #137 | Epoch Duration: 155.01594185829163
2020-01-13 14:27:08.050746 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #137 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2903748
Z variance train             0.005941858
KL Divergence                41.81258
KL Loss                      4.181258
QF Loss                      335.229
VF Loss                      175.76305
Policy Loss                  -4059.8584
Q Predictions Mean           4061.2812
Q Predictions Std            627.8078
Q Predictions Max            4828.929
Q Predictions Min            721.377
V Predictions Mean           4067.5757
V Predictions Std            619.2168
V Predictions Max            4805.212
V Predictions Min            740.6349
Log Pis Mean                 5.5331154
Log Pis Std                  3.8302338
Log Pis Max                  15.488397
Log Pis Min                  -3.0827475
Policy mu Mean               -0.091122665
Policy mu Std                1.354311
Policy mu Max                3.2802093
Policy mu Min                -3.0340333
Policy log std Mean          -0.925209
Policy log std Std           0.51646125
Policy log std Max           -0.09179127
Policy log std Min           -3.5349422
Z mean eval                  3.3015456
Z variance eval              0.003762215
total_rewards                [10728.3656135  11150.28031671 10790.98976823 10873.05527904
 10915.43407995 10705.60966134 11043.00562327 10728.67533625
 11086.46556132 10887.11876886]
total_rewards_mean           10890.90000084573
total_rewards_std            150.54688415644424
total_rewards_max            11150.280316707454
total_rewards_min            10705.60966133544
Number of train steps total  556000
Number of env steps total    697000
Number of rollouts total     0
Train Time (s)               119.80380858993158
(Previous) Eval Time (s)     22.836101848166436
Sample Time (s)              15.996165001299232
Epoch Time (s)               158.63607543939725
Total Train Time (s)         21207.57232788438
Epoch                        138
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:29:46.702537 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #138 | Epoch Duration: 158.65155267715454
2020-01-13 14:29:46.702872 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #138 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3002052
Z variance train             0.0037515007
KL Divergence                43.357697
KL Loss                      4.3357697
QF Loss                      424.95132
VF Loss                      172.70229
Policy Loss                  -3959.7812
Q Predictions Mean           3962.011
Q Predictions Std            758.7497
Q Predictions Max            4852.2
Q Predictions Min            749.26086
V Predictions Mean           3969.6226
V Predictions Std            751.1862
V Predictions Max            4848.404
V Predictions Min            755.041
Log Pis Mean                 5.2570047
Log Pis Std                  3.8394756
Log Pis Max                  14.939536
Log Pis Min                  -5.7877626
Policy mu Mean               -0.13469249
Policy mu Std                1.3611645
Policy mu Max                2.957244
Policy mu Min                -3.376822
Policy log std Mean          -0.9172533
Policy log std Std           0.5019082
Policy log std Max           0.19562137
Policy log std Min           -3.4564805
Z mean eval                  3.29692
Z variance eval              0.004312787
total_rewards                [10964.40268752 10671.42328689 11069.84686702 10990.75992001
 11032.76007711 10865.80969285   874.07911749 11003.65429081
 11075.01170793 11072.4523499 ]
total_rewards_mean           9962.019999753928
total_rewards_std            3031.574053409649
total_rewards_max            11075.011707927768
total_rewards_min            874.0791174901227
Number of train steps total  560000
Number of env steps total    702000
Number of rollouts total     0
Train Time (s)               116.75066425697878
(Previous) Eval Time (s)     22.851253021042794
Sample Time (s)              16.08747156523168
Epoch Time (s)               155.68938884325325
Total Train Time (s)         21362.495654893573
Epoch                        139
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:32:21.626335 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #139 | Epoch Duration: 154.92321348190308
2020-01-13 14:32:21.626555 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #139 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2976704
Z variance train             0.0043083956
KL Divergence                43.557312
KL Loss                      4.3557315
QF Loss                      288.2365
VF Loss                      114.304054
Policy Loss                  -3999.5405
Q Predictions Mean           3996.699
Q Predictions Std            778.52155
Q Predictions Max            4897.2764
Q Predictions Min            769.6302
V Predictions Mean           3996.397
V Predictions Std            775.5655
V Predictions Max            4894.6465
V Predictions Min            766.2968
Log Pis Mean                 5.2308836
Log Pis Std                  3.5709317
Log Pis Max                  14.556069
Log Pis Min                  -4.439932
Policy mu Mean               -0.067966826
Policy mu Std                1.3694241
Policy mu Max                3.4498417
Policy mu Min                -4.0217085
Policy log std Mean          -0.9167544
Policy log std Std           0.51889724
Policy log std Max           0.45411086
Policy log std Min           -3.5634084
Z mean eval                  3.2789447
Z variance eval              0.0035901063
total_rewards                [ 9969.04533219 10030.39787467 10148.6292307  10132.40086916
  9639.84956662  9410.13604491 10281.47417248  9907.11490091
 10073.58675509 10047.66988308]
total_rewards_mean           9964.030462982146
total_rewards_std            245.30702895411477
total_rewards_max            10281.474172480286
total_rewards_min            9410.136044911602
Number of train steps total  564000
Number of env steps total    707000
Number of rollouts total     0
Train Time (s)               111.9765898459591
(Previous) Eval Time (s)     22.08482237998396
Sample Time (s)              16.081698616966605
Epoch Time (s)               150.14311084290966
Total Train Time (s)         21512.775429893285
Epoch                        140
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:34:51.910504 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #140 | Epoch Duration: 150.28375053405762
2020-01-13 14:34:51.910813 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #140 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2773304
Z variance train             0.003594293
KL Divergence                44.452877
KL Loss                      4.4452877
QF Loss                      356.70724
VF Loss                      125.35749
Policy Loss                  -4093.285
Q Predictions Mean           4091.6729
Q Predictions Std            640.22345
Q Predictions Max            4924.777
Q Predictions Min            776.1957
V Predictions Mean           4097.043
V Predictions Std            639.56744
V Predictions Max            4933.5996
V Predictions Min            776.8624
Log Pis Mean                 5.569092
Log Pis Std                  3.763902
Log Pis Max                  14.930193
Log Pis Min                  -4.0393353
Policy mu Mean               -0.10681874
Policy mu Std                1.3752047
Policy mu Max                3.4665706
Policy mu Min                -2.983088
Policy log std Mean          -0.92072743
Policy log std Std           0.49510574
Policy log std Max           0.019908786
Policy log std Min           -3.4143357
Z mean eval                  3.2938163
Z variance eval              0.0019119913
total_rewards                [10266.90732313 10358.50199706 10258.01064397 10243.53927781
 10302.575008   10451.94085973 10298.9105782  10465.9594988
 10223.64570302 10405.29403839]
total_rewards_mean           10327.528492810277
total_rewards_std            83.33280249625378
total_rewards_max            10465.95949879724
total_rewards_min            10223.645703016507
Number of train steps total  568000
Number of env steps total    712000
Number of rollouts total     0
Train Time (s)               112.86909403884783
(Previous) Eval Time (s)     22.22515151882544
Sample Time (s)              15.476783463731408
Epoch Time (s)               150.57102902140468
Total Train Time (s)         21664.833052635193
Epoch                        141
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:37:23.968799 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #141 | Epoch Duration: 152.05777788162231
2020-01-13 14:37:23.969010 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #141 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2924354
Z variance train             0.0019059246
KL Divergence                45.566948
KL Loss                      4.556695
QF Loss                      339.4531
VF Loss                      363.82944
Policy Loss                  -4145.5137
Q Predictions Mean           4149.1743
Q Predictions Std            608.3131
Q Predictions Max            5014.6704
Q Predictions Min            716.792
V Predictions Mean           4160.681
V Predictions Std            604.0839
V Predictions Max            5050.65
V Predictions Min            747.89496
Log Pis Mean                 5.7820716
Log Pis Std                  4.050958
Log Pis Max                  17.55792
Log Pis Min                  -4.912606
Policy mu Mean               -0.12004927
Policy mu Std                1.4203417
Policy mu Max                3.2738843
Policy mu Min                -3.285962
Policy log std Mean          -0.9182703
Policy log std Std           0.5081142
Policy log std Max           0.31625676
Policy log std Min           -3.396803
Z mean eval                  3.2786572
Z variance eval              0.004616254
total_rewards                [10391.91338167 10545.85188296 10365.76359022 10405.70333732
 10330.25419896 10496.13335323 10337.3008916  10365.55835628
 10485.84903575 10450.68693037]
total_rewards_mean           10417.501495836032
total_rewards_std            69.74419448011842
total_rewards_max            10545.851882962683
total_rewards_min            10330.254198960878
Number of train steps total  572000
Number of env steps total    717000
Number of rollouts total     0
Train Time (s)               115.04661530582234
(Previous) Eval Time (s)     23.711652433965355
Sample Time (s)              15.78197359200567
Epoch Time (s)               154.54024133179337
Total Train Time (s)         21818.52390361624
Epoch                        142
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:39:57.664066 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #142 | Epoch Duration: 153.694890499115
2020-01-13 14:39:57.664394 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #142 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2830188
Z variance train             0.0046220645
KL Divergence                43.755154
KL Loss                      4.3755155
QF Loss                      595.0094
VF Loss                      113.554344
Policy Loss                  -4075.4438
Q Predictions Mean           4075.4614
Q Predictions Std            680.2708
Q Predictions Max            4906.6064
Q Predictions Min            711.0642
V Predictions Mean           4075.1313
V Predictions Std            673.0179
V Predictions Max            4923.1533
V Predictions Min            718.0363
Log Pis Mean                 5.3284445
Log Pis Std                  3.6008823
Log Pis Max                  14.845992
Log Pis Min                  -7.0458965
Policy mu Mean               -0.15355998
Policy mu Std                1.3731741
Policy mu Max                3.150835
Policy mu Min                -3.201796
Policy log std Mean          -0.89971966
Policy log std Std           0.4715873
Policy log std Max           0.50681627
Policy log std Min           -3.2798629
Z mean eval                  3.2581239
Z variance eval              0.015332295
total_rewards                [10910.51829016 10834.51832622 11036.41946221 11018.04303023
 11098.74991245 10943.8577486  10825.00684713 11081.2027782
 11131.97219125 10891.73983044]
total_rewards_mean           10977.20284168786
total_rewards_std            105.40536066207507
total_rewards_max            11131.972191246989
total_rewards_min            10825.006847133756
Number of train steps total  576000
Number of env steps total    722000
Number of rollouts total     0
Train Time (s)               117.15530146006495
(Previous) Eval Time (s)     22.86599281989038
Sample Time (s)              15.803098836448044
Epoch Time (s)               155.82439311640337
Total Train Time (s)         21974.61864513671
Epoch                        143
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:42:33.760084 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #143 | Epoch Duration: 156.09544491767883
2020-01-13 14:42:33.760319 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #143 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2597332
Z variance train             0.015326934
KL Divergence                41.782967
KL Loss                      4.1782966
QF Loss                      322.36682
VF Loss                      114.965485
Policy Loss                  -4127.3506
Q Predictions Mean           4124.6333
Q Predictions Std            586.261
Q Predictions Max            4840.4233
Q Predictions Min            718.5639
V Predictions Mean           4126.1294
V Predictions Std            582.2333
V Predictions Max            4857.655
V Predictions Min            740.064
Log Pis Mean                 5.0941877
Log Pis Std                  3.5321095
Log Pis Max                  14.743471
Log Pis Min                  -3.04217
Policy mu Mean               -0.13985874
Policy mu Std                1.3185359
Policy mu Max                3.3011775
Policy mu Min                -3.0286016
Policy log std Mean          -0.92750835
Policy log std Std           0.48789573
Policy log std Max           0.12832081
Policy log std Min           -3.4058325
Z mean eval                  3.284446
Z variance eval              0.00299245
total_rewards                [10812.85771276  2271.4256717  10914.10714827  4386.04921533
 10896.44798204  3165.27172046 11047.05973683  9626.22144667
 10953.75199705 10679.2782288 ]
total_rewards_mean           8475.247085991728
total_rewards_std            3458.6002303794166
total_rewards_max            11047.05973683423
total_rewards_min            2271.42567169966
Number of train steps total  580000
Number of env steps total    727000
Number of rollouts total     0
Train Time (s)               113.74380103498697
(Previous) Eval Time (s)     23.136765665840358
Sample Time (s)              16.27896679379046
Epoch Time (s)               153.1595334946178
Total Train Time (s)         22127.693329150323
Epoch                        144
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:45:06.835971 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #144 | Epoch Duration: 153.07548332214355
2020-01-13 14:45:06.836186 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #144 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.284216
Z variance train             0.0029960242
KL Divergence                43.549347
KL Loss                      4.3549347
QF Loss                      350.03546
VF Loss                      163.88362
Policy Loss                  -4145.8
Q Predictions Mean           4141.32
Q Predictions Std            723.34656
Q Predictions Max            4970.4062
Q Predictions Min            637.7264
V Predictions Mean           4142.3564
V Predictions Std            717.4211
V Predictions Max            4949.291
V Predictions Min            653.975
Log Pis Mean                 5.34543
Log Pis Std                  3.6997929
Log Pis Max                  16.919456
Log Pis Min                  -4.388348
Policy mu Mean               -0.13710278
Policy mu Std                1.3668352
Policy mu Max                3.1516564
Policy mu Min                -3.1356654
Policy log std Mean          -0.9246008
Policy log std Std           0.49245924
Policy log std Max           -0.13838673
Policy log std Min           -3.4215062
Z mean eval                  3.254394
Z variance eval              0.02270301
total_rewards                [10785.91239038 11149.69687481 10887.45976921 10958.61963248
 11058.92772056 10863.26989505 11089.33145142 11011.47913727
 11064.30225443 10961.76315875]
total_rewards_mean           10983.076228435419
total_rewards_std            107.53253900788629
total_rewards_max            11149.69687481156
total_rewards_min            10785.912390375031
Number of train steps total  584000
Number of env steps total    732000
Number of rollouts total     0
Train Time (s)               114.37955724494532
(Previous) Eval Time (s)     23.052399535197765
Sample Time (s)              15.666582766454667
Epoch Time (s)               153.09853954659775
Total Train Time (s)         22280.829627819825
Epoch                        145
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:47:39.974179 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #145 | Epoch Duration: 153.13784217834473
2020-01-13 14:47:39.974362 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #145 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2555327
Z variance train             0.02291647
KL Divergence                39.079807
KL Loss                      3.9079807
QF Loss                      384.43988
VF Loss                      243.26631
Policy Loss                  -4084.7546
Q Predictions Mean           4079.5725
Q Predictions Std            648.67426
Q Predictions Max            4979.497
Q Predictions Min            635.5774
V Predictions Mean           4074.8513
V Predictions Std            639.2841
V Predictions Max            4979.099
V Predictions Min            658.70276
Log Pis Mean                 5.248394
Log Pis Std                  4.092284
Log Pis Max                  14.945139
Log Pis Min                  -5.6938267
Policy mu Mean               -0.12413993
Policy mu Std                1.3741322
Policy mu Max                3.1782408
Policy mu Min                -3.009881
Policy log std Mean          -0.91468984
Policy log std Std           0.5122608
Policy log std Max           -0.01342988
Policy log std Min           -3.4848561
Z mean eval                  3.2888894
Z variance eval              0.008976534
total_rewards                [10625.96075994 11109.57119454 11106.42745554 11004.21631795
 10804.51949584 10818.3477772  10912.6581522  11020.1235819
 10964.77010635 11103.78291566]
total_rewards_mean           10947.037775711111
total_rewards_std            150.48639867705492
total_rewards_max            11109.571194541933
total_rewards_min            10625.960759935117
Number of train steps total  588000
Number of env steps total    737000
Number of rollouts total     0
Train Time (s)               115.26414272235706
(Previous) Eval Time (s)     23.091391509398818
Sample Time (s)              15.836422109045088
Epoch Time (s)               154.19195634080097
Total Train Time (s)         22435.269785277545
Epoch                        146
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:50:14.420254 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #146 | Epoch Duration: 154.4457242488861
2020-01-13 14:50:14.420540 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #146 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2869365
Z variance train             0.008974528
KL Divergence                41.57866
KL Loss                      4.157866
QF Loss                      598.70795
VF Loss                      107.586395
Policy Loss                  -4139.7715
Q Predictions Mean           4139.001
Q Predictions Std            690.6083
Q Predictions Max            5030.7446
Q Predictions Min            731.4589
V Predictions Mean           4138.6006
V Predictions Std            686.7621
V Predictions Max            5027.0063
V Predictions Min            728.92487
Log Pis Mean                 5.3635874
Log Pis Std                  3.60455
Log Pis Max                  16.336502
Log Pis Min                  -4.012536
Policy mu Mean               -0.10555933
Policy mu Std                1.3821487
Policy mu Max                3.394486
Policy mu Min                -3.4424672
Policy log std Mean          -0.9242955
Policy log std Std           0.49676734
Policy log std Max           -0.08995265
Policy log std Min           -3.170951
Z mean eval                  3.2790928
Z variance eval              0.006584988
total_rewards                [10930.94431196 10584.88079391  2134.3665793  10680.94802649
 10686.25956117 10802.73770542 10663.37068542 10345.80114407
 10882.95495289 10486.30443121]
total_rewards_mean           9819.856819183446
total_rewards_std            2567.2395111850155
total_rewards_max            10930.944311961008
total_rewards_min            2134.366579298879
Number of train steps total  592000
Number of env steps total    742000
Number of rollouts total     0
Train Time (s)               119.93027894198895
(Previous) Eval Time (s)     23.344865014776587
Sample Time (s)              15.685830016154796
Epoch Time (s)               158.96097397292033
Total Train Time (s)         22594.065531579778
Epoch                        147
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:52:53.214665 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #147 | Epoch Duration: 158.79392552375793
2020-01-13 14:52:53.214881 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #147 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2782261
Z variance train             0.0066019585
KL Divergence                42.592056
KL Loss                      4.259206
QF Loss                      312.96332
VF Loss                      153.85013
Policy Loss                  -4122.6855
Q Predictions Mean           4123.5127
Q Predictions Std            569.687
Q Predictions Max            4914.066
Q Predictions Min            730.14624
V Predictions Mean           4128.24
V Predictions Std            564.96936
V Predictions Max            4917.4927
V Predictions Min            742.491
Log Pis Mean                 6.1481028
Log Pis Std                  3.560608
Log Pis Max                  17.08664
Log Pis Min                  -3.2844715
Policy mu Mean               -0.13195989
Policy mu Std                1.4352269
Policy mu Max                3.2133362
Policy mu Min                -3.4730785
Policy log std Mean          -0.92022914
Policy log std Std           0.49410063
Policy log std Max           -0.2094543
Policy log std Min           -3.4360125
Z mean eval                  3.2812665
Z variance eval              0.008711076
total_rewards                [10980.34143665 11146.34383812 11088.18925755 10728.31914143
 11304.40054759 10798.84864959 11252.48770263 10851.16553194
 10638.24086259 11054.79616428]
total_rewards_mean           10984.313313237199
total_rewards_std            213.03184781606683
total_rewards_max            11304.400547588899
total_rewards_min            10638.240862592722
Number of train steps total  596000
Number of env steps total    747000
Number of rollouts total     0
Train Time (s)               118.52224089810625
(Previous) Eval Time (s)     23.177557392977178
Sample Time (s)              16.68154422333464
Epoch Time (s)               158.38134251441807
Total Train Time (s)         22752.423798610456
Epoch                        148
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:55:31.575608 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #148 | Epoch Duration: 158.36058449745178
2020-01-13 14:55:31.575774 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #148 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.281416
Z variance train             0.008709323
KL Divergence                43.02418
KL Loss                      4.302418
QF Loss                      430.99945
VF Loss                      91.08137
Policy Loss                  -4172.8896
Q Predictions Mean           4173.051
Q Predictions Std            551.0933
Q Predictions Max            4949.0347
Q Predictions Min            832.12006
V Predictions Mean           4173.285
V Predictions Std            542.9271
V Predictions Max            4930.6157
V Predictions Min            840.0342
Log Pis Mean                 5.292565
Log Pis Std                  4.024222
Log Pis Max                  15.166802
Log Pis Min                  -6.2343745
Policy mu Mean               -0.17192328
Policy mu Std                1.3500304
Policy mu Max                3.257246
Policy mu Min                -3.3194067
Policy log std Mean          -0.9271362
Policy log std Std           0.5174343
Policy log std Max           -0.013987541
Policy log std Min           -3.5886226
Z mean eval                  3.2716823
Z variance eval              0.006267895
total_rewards                [10827.43014777 11003.22829892 10965.65065586 10978.85362085
 11119.64515301 10839.41944476 10883.54477987 11341.38749599
 10936.01293245 10912.56793138]
total_rewards_mean           10980.774046087947
total_rewards_std            144.79933669724824
total_rewards_max            11341.3874959936
total_rewards_min            10827.430147774781
Number of train steps total  600000
Number of env steps total    752000
Number of rollouts total     0
Train Time (s)               115.36340633872896
(Previous) Eval Time (s)     23.156527733895928
Sample Time (s)              16.43703259062022
Epoch Time (s)               154.9569666632451
Total Train Time (s)         22907.144383279607
Epoch                        149
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:58:06.299233 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #149 | Epoch Duration: 154.7232825756073
2020-01-13 14:58:06.299490 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #149 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.272705
Z variance train             0.006280779
KL Divergence                42.5527
KL Loss                      4.25527
QF Loss                      796.66675
VF Loss                      1105.7109
Policy Loss                  -4164.354
Q Predictions Mean           4172.958
Q Predictions Std            658.01605
Q Predictions Max            5095.1104
Q Predictions Min            885.27167
V Predictions Mean           4187.266
V Predictions Std            655.79694
V Predictions Max            5107.663
V Predictions Min            882.972
Log Pis Mean                 5.1502104
Log Pis Std                  3.6449363
Log Pis Max                  15.939107
Log Pis Min                  -4.489211
Policy mu Mean               -0.09603772
Policy mu Std                1.364827
Policy mu Max                3.1052504
Policy mu Min                -2.8123932
Policy log std Mean          -0.9282415
Policy log std Std           0.5222181
Policy log std Max           -0.02488327
Policy log std Min           -3.6327033
Z mean eval                  3.2798495
Z variance eval              0.0051760003
total_rewards                [10636.9991981  10713.41452941 10657.36537975 10711.68248233
 10715.38066595 10830.28972417 10810.68315141 10819.30107911
 10623.83105734 10892.39647218]
total_rewards_mean           10741.134373973899
total_rewards_std            87.00371806887475
total_rewards_max            10892.39647218294
total_rewards_min            10623.831057339119
Number of train steps total  604000
Number of env steps total    757000
Number of rollouts total     0
Train Time (s)               116.37259568786249
(Previous) Eval Time (s)     22.92255799099803
Sample Time (s)              17.864117331337184
Epoch Time (s)               157.1592710101977
Total Train Time (s)         23063.84840528248
Epoch                        150
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:00:43.004795 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #150 | Epoch Duration: 156.70511078834534
2020-01-13 15:00:43.005009 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #150 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2792454
Z variance train             0.00517758
KL Divergence                43.14012
KL Loss                      4.314012
QF Loss                      232.6279
VF Loss                      69.61768
Policy Loss                  -4148.515
Q Predictions Mean           4150.831
Q Predictions Std            680.24194
Q Predictions Max            5043.6143
Q Predictions Min            962.0287
V Predictions Mean           4146.879
V Predictions Std            675.95966
V Predictions Max            5024.5347
V Predictions Min            967.11395
Log Pis Mean                 5.32435
Log Pis Std                  3.7388775
Log Pis Max                  16.158943
Log Pis Min                  -3.6436725
Policy mu Mean               -0.09555501
Policy mu Std                1.3544273
Policy mu Max                2.915733
Policy mu Min                -2.9819195
Policy log std Mean          -0.9095392
Policy log std Std           0.46544012
Policy log std Max           -0.19663385
Policy log std Min           -3.4840531
Z mean eval                  3.2633247
Z variance eval              0.006601142
total_rewards                [11000.28615288 11073.58669621 10753.658055   10911.68715817
 11058.3701645  11168.27817664 11143.26503622 10644.89423484
  3543.6650152  11010.55036007]
total_rewards_mean           10230.824104973522
total_rewards_std            2234.568757775525
total_rewards_max            11168.278176644038
total_rewards_min            3543.665015201162
Number of train steps total  608000
Number of env steps total    762000
Number of rollouts total     0
Train Time (s)               111.77475723763928
(Previous) Eval Time (s)     22.46805107779801
Sample Time (s)              16.406690667383373
Epoch Time (s)               150.64949898282066
Total Train Time (s)         23214.648265114054
Epoch                        151
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:03:13.808949 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #151 | Epoch Duration: 150.80376434326172
2020-01-13 15:03:13.809227 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #151 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2624717
Z variance train             0.006613114
KL Divergence                43.632793
KL Loss                      4.3632793
QF Loss                      265.32904
VF Loss                      130.28125
Policy Loss                  -4133.67
Q Predictions Mean           4137.795
Q Predictions Std            621.2896
Q Predictions Max            4978.0566
Q Predictions Min            1083.8538
V Predictions Mean           4133.028
V Predictions Std            617.98114
V Predictions Max            4973.4106
V Predictions Min            1088.9993
Log Pis Mean                 5.1704254
Log Pis Std                  3.6554763
Log Pis Max                  15.141316
Log Pis Min                  -3.710681
Policy mu Mean               -0.121809006
Policy mu Std                1.3629559
Policy mu Max                2.978757
Policy mu Min                -3.553729
Policy log std Mean          -0.90685934
Policy log std Std           0.50196135
Policy log std Max           -0.15578127
Policy log std Min           -3.3722143
Z mean eval                  3.2753994
Z variance eval              0.007122473
total_rewards                [10954.24116851 10880.50550899 10785.46377255 11031.63060701
 10630.8343826  11168.2300997  11040.32958317 11011.99863966
 10775.57600856  6164.781654  ]
total_rewards_mean           10444.359142474912
total_rewards_std            1434.297357951266
total_rewards_max            11168.230099703927
total_rewards_min            6164.781654004075
Number of train steps total  612000
Number of env steps total    767000
Number of rollouts total     0
Train Time (s)               115.23192569008097
(Previous) Eval Time (s)     22.622016957961023
Sample Time (s)              16.82836898835376
Epoch Time (s)               154.68231163639575
Total Train Time (s)         23369.846257052384
Epoch                        152
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:05:49.010188 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #152 | Epoch Duration: 155.20074486732483
2020-01-13 15:05:49.010444 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #152 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2732646
Z variance train             0.007126616
KL Divergence                44.310287
KL Loss                      4.431029
QF Loss                      360.47128
VF Loss                      159.69254
Policy Loss                  -4248.7817
Q Predictions Mean           4249.661
Q Predictions Std            517.70935
Q Predictions Max            5018.3135
Q Predictions Min            2926.6936
V Predictions Mean           4257.9165
V Predictions Std            513.3546
V Predictions Max            5013.6006
V Predictions Min            2963.628
Log Pis Mean                 5.4319315
Log Pis Std                  3.9845352
Log Pis Max                  17.03275
Log Pis Min                  -4.4598026
Policy mu Mean               -0.062193792
Policy mu Std                1.3739716
Policy mu Max                2.9367952
Policy mu Min                -2.7968535
Policy log std Mean          -0.9442329
Policy log std Std           0.5187548
Policy log std Max           -0.19439638
Policy log std Min           -3.5593314
Z mean eval                  3.2589874
Z variance eval              0.008761939
total_rewards                [10272.23120642 10604.46493797 10595.08798345 10463.31558571
 10715.13020481 10731.10540273 10495.87257471 10432.49948992
 10363.95468471  2531.35792043]
total_rewards_mean           9720.501999087119
total_rewards_std            2400.396564526597
total_rewards_max            10731.105402733308
total_rewards_min            2531.357920433894
Number of train steps total  616000
Number of env steps total    772000
Number of rollouts total     0
Train Time (s)               115.64055093144998
(Previous) Eval Time (s)     23.140097300056368
Sample Time (s)              17.062731632962823
Epoch Time (s)               155.84337986446917
Total Train Time (s)         23525.24683480803
Epoch                        153
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:08:24.411516 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #153 | Epoch Duration: 155.40087962150574
2020-01-13 15:08:24.411719 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #153 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.257103
Z variance train             0.008748146
KL Divergence                43.707146
KL Loss                      4.3707147
QF Loss                      450.4518
VF Loss                      152.37378
Policy Loss                  -4237.612
Q Predictions Mean           4234.343
Q Predictions Std            671.20416
Q Predictions Max            5050.491
Q Predictions Min            1160.3494
V Predictions Mean           4244.268
V Predictions Std            660.6879
V Predictions Max            5019.536
V Predictions Min            1181.2208
Log Pis Mean                 5.4504633
Log Pis Std                  3.970591
Log Pis Max                  19.849792
Log Pis Min                  -5.2643538
Policy mu Mean               -0.15632023
Policy mu Std                1.363981
Policy mu Max                4.0387754
Policy mu Min                -3.2551956
Policy log std Mean          -0.9121569
Policy log std Std           0.5075308
Policy log std Max           -0.04649043
Policy log std Min           -3.503138
Z mean eval                  3.2727463
Z variance eval              0.0076503493
total_rewards                [10552.86970046  8857.37118958  5818.07201446 11008.72590019
  3287.42044724  1213.12931468 10919.73840588 10802.74295065
 10859.9038871  11158.19738151]
total_rewards_mean           8447.81711917517
total_rewards_std            3490.896585538138
total_rewards_max            11158.197381510397
total_rewards_min            1213.1293146768985
Number of train steps total  620000
Number of env steps total    777000
Number of rollouts total     0
Train Time (s)               116.98105958802626
(Previous) Eval Time (s)     22.697290547192097
Sample Time (s)              15.78644542582333
Epoch Time (s)               155.46479556104168
Total Train Time (s)         23680.651217427105
Epoch                        154
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:10:59.819502 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #154 | Epoch Duration: 155.40759539604187
2020-01-13 15:10:59.819725 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #154 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2740397
Z variance train             0.00765572
KL Divergence                43.20719
KL Loss                      4.3207192
QF Loss                      316.9702
VF Loss                      183.15497
Policy Loss                  -4275.466
Q Predictions Mean           4276.506
Q Predictions Std            551.273
Q Predictions Max            5164.5703
Q Predictions Min            1295.7097
V Predictions Mean           4268.9766
V Predictions Std            547.96875
V Predictions Max            5166.073
V Predictions Min            1292.541
Log Pis Mean                 5.5454035
Log Pis Std                  4.2470884
Log Pis Max                  16.646042
Log Pis Min                  -3.6340208
Policy mu Mean               -0.13336469
Policy mu Std                1.3794252
Policy mu Max                3.1553562
Policy mu Min                -2.9992056
Policy log std Mean          -0.9273284
Policy log std Std           0.4974772
Policy log std Max           -0.2645321
Policy log std Min           -3.4714804
Z mean eval                  3.268613
Z variance eval              0.0068872375
total_rewards                [10604.52283747 11024.27801832 11056.2499873  10834.03263852
 10943.06854075 10963.13833506 11042.07162744 10765.15870857
 10955.46589013 10889.81884782]
total_rewards_mean           10907.780543137404
total_rewards_std            133.5290802755832
total_rewards_max            11056.249987297255
total_rewards_min            10604.522837469727
Number of train steps total  624000
Number of env steps total    782000
Number of rollouts total     0
Train Time (s)               113.76394158322364
(Previous) Eval Time (s)     22.63979107281193
Sample Time (s)              16.63809986691922
Epoch Time (s)               153.0418325229548
Total Train Time (s)         23833.94986646762
Epoch                        155
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:13:33.119054 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #155 | Epoch Duration: 153.29914712905884
2020-01-13 15:13:33.119247 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #155 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2717335
Z variance train             0.006857221
KL Divergence                43.947144
KL Loss                      4.3947144
QF Loss                      372.9012
VF Loss                      275.58154
Policy Loss                  -4257.807
Q Predictions Mean           4255.8623
Q Predictions Std            598.6086
Q Predictions Max            5077.08
Q Predictions Min            1298.8849
V Predictions Mean           4244.3115
V Predictions Std            592.45746
V Predictions Max            5039.1797
V Predictions Min            1339.3229
Log Pis Mean                 5.554684
Log Pis Std                  3.856952
Log Pis Max                  15.094261
Log Pis Min                  -6.9319916
Policy mu Mean               -0.16298015
Policy mu Std                1.3900547
Policy mu Max                2.8728685
Policy mu Min                -2.9089627
Policy log std Mean          -0.9110258
Policy log std Std           0.51098955
Policy log std Max           0.00032246113
Policy log std Min           -3.49681
Z mean eval                  3.2655978
Z variance eval              0.009227721
total_rewards                [11251.30940687 10980.20775653 10886.78361464 11259.25855207
 11305.17001572  6088.9448269  10908.86238177 10776.06696987
 11378.31482146 11146.51148964]
total_rewards_mean           10598.142983548172
total_rewards_std            1515.3653658710227
total_rewards_max            11378.3148214638
total_rewards_min            6088.944826898931
Number of train steps total  628000
Number of env steps total    787000
Number of rollouts total     0
Train Time (s)               121.75563749624416
(Previous) Eval Time (s)     22.896780350711197
Sample Time (s)              16.51204195059836
Epoch Time (s)               161.16445979755372
Total Train Time (s)         23994.899160101544
Epoch                        156
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:16:14.073894 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #156 | Epoch Duration: 160.95446825027466
2020-01-13 15:16:14.074192 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #156 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2597947
Z variance train             0.009173612
KL Divergence                43.35137
KL Loss                      4.3351374
QF Loss                      564.01263
VF Loss                      439.71954
Policy Loss                  -4242.882
Q Predictions Mean           4248.8506
Q Predictions Std            582.5874
Q Predictions Max            5091.7183
Q Predictions Min            1405.3475
V Predictions Mean           4259.4507
V Predictions Std            579.9922
V Predictions Max            5112.381
V Predictions Min            1404.9177
Log Pis Mean                 5.834585
Log Pis Std                  3.8921719
Log Pis Max                  17.108839
Log Pis Min                  -2.8502378
Policy mu Mean               -0.09319651
Policy mu Std                1.4007055
Policy mu Max                3.1775138
Policy mu Min                -3.2575364
Policy log std Mean          -0.9235764
Policy log std Std           0.50841665
Policy log std Max           -0.040084124
Policy log std Min           -3.3465848
Z mean eval                  3.259996
Z variance eval              0.009261835
total_rewards                [10522.19404808 11345.19477327 11183.03661497 11232.54500748
 11274.24680247 11333.02969522 11077.89202121 11107.36747614
 11179.53314013 11086.67893632]
total_rewards_mean           11134.171851529021
total_rewards_std            223.2660071654535
total_rewards_max            11345.194773270725
total_rewards_min            10522.194048078267
Number of train steps total  632000
Number of env steps total    792000
Number of rollouts total     0
Train Time (s)               116.22930979868397
(Previous) Eval Time (s)     22.686479263938963
Sample Time (s)              15.851795709691942
Epoch Time (s)               154.76758477231488
Total Train Time (s)         24149.416178544518
Epoch                        157
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:18:48.592951 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #157 | Epoch Duration: 154.51852345466614
2020-01-13 15:18:48.593224 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #157 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2608922
Z variance train             0.009232624
KL Divergence                43.979263
KL Loss                      4.3979263
QF Loss                      391.38577
VF Loss                      94.219246
Policy Loss                  -4148.2905
Q Predictions Mean           4146.573
Q Predictions Std            708.2477
Q Predictions Max            5125.3633
Q Predictions Min            1386.8087
V Predictions Mean           4151.2637
V Predictions Std            702.1535
V Predictions Max            5111.4287
V Predictions Min            1406.4625
Log Pis Mean                 5.291272
Log Pis Std                  3.72043
Log Pis Max                  15.059006
Log Pis Min                  -6.4444294
Policy mu Mean               -0.10389924
Policy mu Std                1.3621916
Policy mu Max                3.0942822
Policy mu Min                -2.9899702
Policy log std Mean          -0.89871675
Policy log std Std           0.46047723
Policy log std Max           0.21979237
Policy log std Min           -3.347217
Z mean eval                  3.2684917
Z variance eval              0.0047085
total_rewards                [10659.21411422 10809.75495765 10867.30716204 10828.22673153
 10681.13450659 10588.28676985 10827.42363669 10622.330104
 10712.41525987 10919.99610357]
total_rewards_mean           10751.608934600448
total_rewards_std            107.31550301728419
total_rewards_max            10919.996103568335
total_rewards_min            10588.286769847722
Number of train steps total  636000
Number of env steps total    797000
Number of rollouts total     0
Train Time (s)               111.33097095275298
(Previous) Eval Time (s)     22.437155128922313
Sample Time (s)              16.93333921628073
Epoch Time (s)               150.70146529795602
Total Train Time (s)         24300.33058252046
Epoch                        158
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:21:19.511426 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #158 | Epoch Duration: 150.917902469635
2020-01-13 15:21:19.511846 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #158 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2660263
Z variance train             0.004709467
KL Divergence                46.38817
KL Loss                      4.638817
QF Loss                      412.5573
VF Loss                      214.55554
Policy Loss                  -4236.0854
Q Predictions Mean           4235.1484
Q Predictions Std            584.771
Q Predictions Max            5186.8794
Q Predictions Min            1430.3385
V Predictions Mean           4245.679
V Predictions Std            581.60565
V Predictions Max            5182.8906
V Predictions Min            1423.5935
Log Pis Mean                 5.753456
Log Pis Std                  3.478369
Log Pis Max                  14.321072
Log Pis Min                  -5.69203
Policy mu Mean               -0.08886366
Policy mu Std                1.3992081
Policy mu Max                3.0702639
Policy mu Min                -2.9382172
Policy log std Mean          -0.94582766
Policy log std Std           0.51760733
Policy log std Max           -0.24299067
Policy log std Min           -3.3069582
Z mean eval                  3.2762122
Z variance eval              0.003919445
total_rewards                [ 2453.77468691 10918.68815601 11006.09655936 11035.81359179
  4298.52809504 10861.92020233 10901.59580169 11008.2623823
  1079.64114394 10872.50584984]
total_rewards_mean           8443.68264692101
total_rewards_std            3886.729118048919
total_rewards_max            11035.813591787106
total_rewards_min            1079.641143942901
Number of train steps total  640000
Number of env steps total    802000
Number of rollouts total     0
Train Time (s)               117.32397515513003
(Previous) Eval Time (s)     22.653302274644375
Sample Time (s)              16.333302792161703
Epoch Time (s)               156.3105802219361
Total Train Time (s)         24457.62541546719
Epoch                        159
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:23:56.806017 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #159 | Epoch Duration: 157.29393124580383
2020-01-13 15:23:56.806209 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #159 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2754905
Z variance train             0.003916023
KL Divergence                46.752556
KL Loss                      4.675256
QF Loss                      770.209
VF Loss                      142.4737
Policy Loss                  -4205.1016
Q Predictions Mean           4205.9346
Q Predictions Std            682.21265
Q Predictions Max            5126.867
Q Predictions Min            1431.5278
V Predictions Mean           4204.742
V Predictions Std            674.9757
V Predictions Max            5112.838
V Predictions Min            1470.1841
Log Pis Mean                 5.2996807
Log Pis Std                  3.8206537
Log Pis Max                  16.074497
Log Pis Min                  -3.5005789
Policy mu Mean               -0.12153399
Policy mu Std                1.395647
Policy mu Max                3.2624266
Policy mu Min                -3.4918113
Policy log std Mean          -0.9139579
Policy log std Std           0.5038272
Policy log std Max           0.08164477
Policy log std Min           -3.5069785
Z mean eval                  3.265845
Z variance eval              0.008017075
total_rewards                [10601.50216479 10767.79899107 10997.84973901 11037.07410822
  3630.9019793  10729.65988856 11142.07753292 11147.84976167
 11006.81614049 11098.37758402]
total_rewards_mean           10215.990789005493
total_rewards_std            2202.1773797270116
total_rewards_max            11147.849761665857
total_rewards_min            3630.9019793011953
Number of train steps total  644000
Number of env steps total    807000
Number of rollouts total     0
Train Time (s)               111.59238976519555
(Previous) Eval Time (s)     23.636366137769073
Sample Time (s)              16.88968993583694
Epoch Time (s)               152.11844583880156
Total Train Time (s)         24610.349095910788
Epoch                        160
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:26:29.535809 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #160 | Epoch Duration: 152.7293164730072
2020-01-13 15:26:29.536245 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #160 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.265932
Z variance train             0.008022132
KL Divergence                46.34007
KL Loss                      4.634007
QF Loss                      441.92184
VF Loss                      117.23921
Policy Loss                  -4318.5947
Q Predictions Mean           4319.7656
Q Predictions Std            536.3857
Q Predictions Max            5225.2446
Q Predictions Min            1545.6252
V Predictions Mean           4320.0146
V Predictions Std            532.0208
V Predictions Max            5195.387
V Predictions Min            1560.7373
Log Pis Mean                 5.535561
Log Pis Std                  4.023084
Log Pis Max                  19.351961
Log Pis Min                  -2.5768952
Policy mu Mean               -0.10601342
Policy mu Std                1.4049131
Policy mu Max                2.9413657
Policy mu Min                -3.245348
Policy log std Mean          -0.9285767
Policy log std Std           0.48798847
Policy log std Max           -0.23158276
Policy log std Min           -3.4932377
Z mean eval                  3.25891
Z variance eval              0.008993858
total_rewards                [10917.77937268 11273.36541145 11100.79768555 11222.86618373
 10924.72761332 11130.64040726 11267.96535506 11229.63428438
 11067.33327928 11149.09192988]
total_rewards_mean           11128.420152259478
total_rewards_std            122.65129117490739
total_rewards_max            11273.365411445875
total_rewards_min            10917.779372678502
Number of train steps total  648000
Number of env steps total    812000
Number of rollouts total     0
Train Time (s)               115.18128982698545
(Previous) Eval Time (s)     24.24691200396046
Sample Time (s)              16.1227832082659
Epoch Time (s)               155.5509850392118
Total Train Time (s)         24764.72776267305
Epoch                        161
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:29:03.916931 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #161 | Epoch Duration: 154.3804054260254
2020-01-13 15:29:03.917231 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #161 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2590404
Z variance train             0.009000601
KL Divergence                45.900005
KL Loss                      4.5900006
QF Loss                      493.64624
VF Loss                      149.17542
Policy Loss                  -4259.6055
Q Predictions Mean           4255.8853
Q Predictions Std            652.88745
Q Predictions Max            5143.928
Q Predictions Min            1425.391
V Predictions Mean           4252.3315
V Predictions Std            645.8832
V Predictions Max            5118.7812
V Predictions Min            1445.3008
Log Pis Mean                 5.899224
Log Pis Std                  3.514196
Log Pis Max                  15.268175
Log Pis Min                  -2.8883605
Policy mu Mean               -0.09452178
Policy mu Std                1.3930978
Policy mu Max                3.7348464
Policy mu Min                -3.5951116
Policy log std Mean          -0.92485684
Policy log std Std           0.48310313
Policy log std Max           -0.11467767
Policy log std Min           -3.3765135
Z mean eval                  3.25814
Z variance eval              0.016712224
total_rewards                [10969.85854702 11400.3300131  10647.93929657 11211.18912092
 11285.21017139 11296.7261906  11437.10902726 11263.77015958
 11505.45639535 11482.06203545]
total_rewards_mean           11249.965095725465
total_rewards_std            249.55860352744216
total_rewards_max            11505.456395352438
total_rewards_min            10647.939296568913
Number of train steps total  652000
Number of env steps total    817000
Number of rollouts total     0
Train Time (s)               116.18468716461211
(Previous) Eval Time (s)     23.076047881040722
Sample Time (s)              16.336986287031323
Epoch Time (s)               155.59772133268416
Total Train Time (s)         24920.07612286415
Epoch                        162
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:31:39.265842 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #162 | Epoch Duration: 155.34839296340942
2020-01-13 15:31:39.266042 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #162 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2609024
Z variance train             0.016635211
KL Divergence                47.15645
KL Loss                      4.715645
QF Loss                      352.1537
VF Loss                      91.131714
Policy Loss                  -4283.733
Q Predictions Mean           4283.7266
Q Predictions Std            531.3453
Q Predictions Max            5113.4097
Q Predictions Min            1466.7354
V Predictions Mean           4277.8965
V Predictions Std            525.6643
V Predictions Max            5104.767
V Predictions Min            1478.9076
Log Pis Mean                 5.559762
Log Pis Std                  3.8548942
Log Pis Max                  14.298296
Log Pis Min                  -5.836882
Policy mu Mean               -0.11001948
Policy mu Std                1.3814969
Policy mu Max                3.0370045
Policy mu Min                -2.9576166
Policy log std Mean          -0.9212909
Policy log std Std           0.50013787
Policy log std Max           -0.06729174
Policy log std Min           -3.585157
Z mean eval                  3.2711303
Z variance eval              0.010373015
total_rewards                [11298.20603203 11255.71142953 11039.98388752 11213.94264422
 10761.20273277 11449.18952497 10927.68396293 10717.99046557
 11177.72681685 10919.01484989]
total_rewards_mean           11076.065234627331
total_rewards_std            229.2435182688465
total_rewards_max            11449.189524965883
total_rewards_min            10717.990465573075
Number of train steps total  656000
Number of env steps total    822000
Number of rollouts total     0
Train Time (s)               118.04648318793625
(Previous) Eval Time (s)     22.826429925858974
Sample Time (s)              16.206784878857434
Epoch Time (s)               157.07969799265265
Total Train Time (s)         25077.425550783053
Epoch                        163
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:34:16.619935 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #163 | Epoch Duration: 157.35371899604797
2020-01-13 15:34:16.620239 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #163 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2699
Z variance train             0.010423949
KL Divergence                48.463688
KL Loss                      4.846369
QF Loss                      386.08344
VF Loss                      181.94604
Policy Loss                  -4221.053
Q Predictions Mean           4221.9326
Q Predictions Std            687.5862
Q Predictions Max            5136.629
Q Predictions Min            1413.9714
V Predictions Mean           4225.648
V Predictions Std            684.74146
V Predictions Max            5121.612
V Predictions Min            1464.3578
Log Pis Mean                 5.6728516
Log Pis Std                  4.010955
Log Pis Max                  17.236565
Log Pis Min                  -3.6865666
Policy mu Mean               -0.09859619
Policy mu Std                1.3981745
Policy mu Max                3.7196498
Policy mu Min                -3.482776
Policy log std Mean          -0.91286725
Policy log std Std           0.4763109
Policy log std Max           -0.0076247454
Policy log std Min           -3.510333
Z mean eval                  3.2691588
Z variance eval              0.006604825
total_rewards                [11236.00823359 11470.99590029  7919.80965485 11226.56003052
 11394.21102071 11412.30278868 11173.04977855 11434.13415844
 11298.48358547 11433.60362994]
total_rewards_mean           10999.915878104333
total_rewards_std            1031.3756897408907
total_rewards_max            11470.995900291153
total_rewards_min            7919.8096548537405
Number of train steps total  660000
Number of env steps total    827000
Number of rollouts total     0
Train Time (s)               113.63279908010736
(Previous) Eval Time (s)     23.100118340924382
Sample Time (s)              16.53964436566457
Epoch Time (s)               153.27256178669631
Total Train Time (s)         25229.783479944337
Epoch                        164
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:36:48.978431 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #164 | Epoch Duration: 152.357985496521
2020-01-13 15:36:48.978628 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #164 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2705352
Z variance train             0.006588566
KL Divergence                50.116867
KL Loss                      5.011687
QF Loss                      660.15405
VF Loss                      204.6708
Policy Loss                  -4262.716
Q Predictions Mean           4265.727
Q Predictions Std            623.43604
Q Predictions Max            5146.483
Q Predictions Min            1467.207
V Predictions Mean           4268.301
V Predictions Std            620.3267
V Predictions Max            5149.222
V Predictions Min            1495.2723
Log Pis Mean                 5.8534822
Log Pis Std                  3.8313415
Log Pis Max                  17.427757
Log Pis Min                  -3.2435732
Policy mu Mean               -0.116048336
Policy mu Std                1.4117589
Policy mu Max                3.0402899
Policy mu Min                -4.1772766
Policy log std Mean          -0.9067922
Policy log std Std           0.47374165
Policy log std Max           0.12289965
Policy log std Min           -3.3348212
Z mean eval                  3.258574
Z variance eval              0.005789208
total_rewards                [11121.74936954 11403.66574123  5108.6970042  11276.41567895
 11365.01343028 11304.14116167 11629.90102152 11442.75146178
 11398.17287204  2526.35193134]
total_rewards_mean           9857.685967254616
total_rewards_std            3077.2163734993937
total_rewards_max            11629.901021522968
total_rewards_min            2526.3519313354827
Number of train steps total  664000
Number of env steps total    832000
Number of rollouts total     0
Train Time (s)               117.15076082432643
(Previous) Eval Time (s)     22.185254785697907
Sample Time (s)              16.262394259218127
Epoch Time (s)               155.59840986924246
Total Train Time (s)         25386.134024490137
Epoch                        165
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:39:25.331685 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #165 | Epoch Duration: 156.3529326915741
2020-01-13 15:39:25.331900 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #165 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2581172
Z variance train             0.005803452
KL Divergence                48.163208
KL Loss                      4.816321
QF Loss                      406.70953
VF Loss                      128.78305
Policy Loss                  -4322.9434
Q Predictions Mean           4320.5957
Q Predictions Std            590.1965
Q Predictions Max            5239.9585
Q Predictions Min            1526.9362
V Predictions Mean           4322.205
V Predictions Std            583.0286
V Predictions Max            5236.3984
V Predictions Min            1526.0153
Log Pis Mean                 5.9845905
Log Pis Std                  3.9206178
Log Pis Max                  15.174046
Log Pis Min                  -4.6407843
Policy mu Mean               -0.12427936
Policy mu Std                1.4199374
Policy mu Max                3.4041445
Policy mu Min                -3.3807807
Policy log std Mean          -0.9333639
Policy log std Std           0.5090101
Policy log std Max           0.4329338
Policy log std Min           -3.59935
Z mean eval                  3.2715957
Z variance eval              0.009333689
total_rewards                [11259.98670911 10955.78268074 11313.32011859 11450.23722297
 11460.7755688  11396.97575957 11378.65047391 11402.86962489
 11269.86112165 11292.11829922]
total_rewards_mean           11318.057757944009
total_rewards_std            138.7681736802338
total_rewards_max            11460.775568802757
total_rewards_min            10955.78268073772
Number of train steps total  668000
Number of env steps total    837000
Number of rollouts total     0
Train Time (s)               113.3740264037624
(Previous) Eval Time (s)     22.93946545990184
Sample Time (s)              16.185192005708814
Epoch Time (s)               152.49868386937305
Total Train Time (s)         25539.29964512121
Epoch                        166
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:41:58.501437 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #166 | Epoch Duration: 153.16935968399048
2020-01-13 15:41:58.501726 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #166 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2717004
Z variance train             0.009323064
KL Divergence                49.20052
KL Loss                      4.920052
QF Loss                      1673.909
VF Loss                      120.88473
Policy Loss                  -4270.491
Q Predictions Mean           4272.4917
Q Predictions Std            628.0974
Q Predictions Max            5169.3076
Q Predictions Min            1501.7292
V Predictions Mean           4266.4453
V Predictions Std            624.064
V Predictions Max            5157.4585
V Predictions Min            1495.4841
Log Pis Mean                 5.5448933
Log Pis Std                  3.7710307
Log Pis Max                  14.211264
Log Pis Min                  -3.9081326
Policy mu Mean               -0.07840539
Policy mu Std                1.3803402
Policy mu Max                3.223394
Policy mu Min                -2.8722858
Policy log std Mean          -0.8994151
Policy log std Std           0.47986898
Policy log std Max           -0.1625182
Policy log std Min           -3.3630798
Z mean eval                  3.258513
Z variance eval              0.0034924983
total_rewards                [11505.46768207 11459.60017463 11357.16873869 11391.45643132
 11345.01894727 11536.06695457 11296.42630732 11789.49457466
 11345.06078892 11573.86439688]
total_rewards_mean           11459.962499631698
total_rewards_std            140.65771214908037
total_rewards_max            11789.494574659388
total_rewards_min            11296.42630732223
Number of train steps total  672000
Number of env steps total    842000
Number of rollouts total     0
Train Time (s)               114.56694035697728
(Previous) Eval Time (s)     23.60981006640941
Sample Time (s)              16.849354497157037
Epoch Time (s)               155.02610492054373
Total Train Time (s)         25693.237448933534
Epoch                        167
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:44:32.441257 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #167 | Epoch Duration: 153.93932127952576
2020-01-13 15:44:32.441460 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #167 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2584748
Z variance train             0.0035000488
KL Divergence                48.14159
KL Loss                      4.814159
QF Loss                      306.59534
VF Loss                      170.20358
Policy Loss                  -4334.8096
Q Predictions Mean           4330.6855
Q Predictions Std            605.21893
Q Predictions Max            5175.603
Q Predictions Min            1505.3671
V Predictions Mean           4324.55
V Predictions Std            599.0784
V Predictions Max            5164.14
V Predictions Min            1502.0896
Log Pis Mean                 5.8530397
Log Pis Std                  3.8263366
Log Pis Max                  16.357689
Log Pis Min                  -4.447248
Policy mu Mean               -0.11761295
Policy mu Std                1.391743
Policy mu Max                3.2152135
Policy mu Min                -2.7685728
Policy log std Mean          -0.9255345
Policy log std Std           0.50061035
Policy log std Max           -0.011879265
Policy log std Min           -3.5601082
Z mean eval                  3.2415347
Z variance eval              0.023367895
total_rewards                [10595.4945271  10836.04728304 10546.20667056 10591.824583
 10583.72640933 10793.7081729  10639.34944511 10712.04443552
 10720.31748841 10801.40704419]
total_rewards_mean           10682.01260591615
total_rewards_std            99.18145965340096
total_rewards_max            10836.04728303631
total_rewards_min            10546.206670556703
Number of train steps total  676000
Number of env steps total    847000
Number of rollouts total     0
Train Time (s)               121.66146961366758
(Previous) Eval Time (s)     22.52270641596988
Sample Time (s)              16.260321035049856
Epoch Time (s)               160.4444970646873
Total Train Time (s)         25854.230231053196
Epoch                        168
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:47:13.434590 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #168 | Epoch Duration: 160.9929838180542
2020-01-13 15:47:13.434770 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #168 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.24244
Z variance train             0.023359861
KL Divergence                47.63971
KL Loss                      4.763971
QF Loss                      333.86926
VF Loss                      299.7608
Policy Loss                  -4311.342
Q Predictions Mean           4311.3696
Q Predictions Std            560.49585
Q Predictions Max            5145.2124
Q Predictions Min            1598.7473
V Predictions Mean           4297.915
V Predictions Std            552.745
V Predictions Max            5116.0312
V Predictions Min            1604.1715
Log Pis Mean                 5.6898317
Log Pis Std                  4.186742
Log Pis Max                  17.089909
Log Pis Min                  -6.1894274
Policy mu Mean               -0.16617016
Policy mu Std                1.4096274
Policy mu Max                3.0858796
Policy mu Min                -3.227913
Policy log std Mean          -0.9331419
Policy log std Std           0.52433646
Policy log std Max           -0.09993255
Policy log std Min           -3.5083528
Z mean eval                  3.2449398
Z variance eval              0.006759177
total_rewards                [10872.15901556 11444.9179389  11346.87694516 11249.50810643
 11338.39778955 11184.87411002 11499.94270218 11384.56718358
 11369.34115456 11297.1271384 ]
total_rewards_mean           11298.77120843344
total_rewards_std            165.96818957998838
total_rewards_max            11499.942702182176
total_rewards_min            10872.1590155632
Number of train steps total  680000
Number of env steps total    852000
Number of rollouts total     0
Train Time (s)               114.87587296636775
(Previous) Eval Time (s)     23.070881315972656
Sample Time (s)              16.805181313306093
Epoch Time (s)               154.7519355956465
Total Train Time (s)         26008.68465510849
Epoch                        169
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:49:47.895504 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #169 | Epoch Duration: 154.46056580543518
2020-01-13 15:49:47.895848 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #169 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2438571
Z variance train             0.006725952
KL Divergence                48.788124
KL Loss                      4.8788123
QF Loss                      703.657
VF Loss                      215.98239
Policy Loss                  -4264.5303
Q Predictions Mean           4268.384
Q Predictions Std            715.20856
Q Predictions Max            5208.5166
Q Predictions Min            1461.8236
V Predictions Mean           4273.762
V Predictions Std            710.73505
V Predictions Max            5200.5723
V Predictions Min            1453.5022
Log Pis Mean                 6.0535927
Log Pis Std                  4.116967
Log Pis Max                  16.04367
Log Pis Min                  -5.659824
Policy mu Mean               -0.13417937
Policy mu Std                1.4312557
Policy mu Max                3.338177
Policy mu Min                -2.9128165
Policy log std Mean          -0.9130761
Policy log std Std           0.5121442
Policy log std Max           -0.09841868
Policy log std Min           -3.5159345
Z mean eval                  3.233046
Z variance eval              0.00621868
total_rewards                [11031.87348663 10846.51436755 11110.54486305 10960.17945648
 10925.04865752 11130.25609015 11350.24727432 10780.81001789
 11032.65596782 11240.35784879]
total_rewards_mean           11040.848803019737
total_rewards_std            165.47912731513713
total_rewards_max            11350.247274324789
total_rewards_min            10780.810017891607
Number of train steps total  684000
Number of env steps total    857000
Number of rollouts total     0
Train Time (s)               122.83398326206952
(Previous) Eval Time (s)     22.779166102875024
Sample Time (s)              16.747937567532063
Epoch Time (s)               162.3610869324766
Total Train Time (s)         26171.198424629867
Epoch                        170
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:52:30.411311 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #170 | Epoch Duration: 162.5152199268341
2020-01-13 15:52:30.411547 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #170 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2305999
Z variance train             0.006262972
KL Divergence                48.014748
KL Loss                      4.801475
QF Loss                      527.88293
VF Loss                      147.42511
Policy Loss                  -4359.037
Q Predictions Mean           4357.217
Q Predictions Std            625.65216
Q Predictions Max            5272.1685
Q Predictions Min            1366.3883
V Predictions Mean           4367.5063
V Predictions Std            623.07336
V Predictions Max            5275.1074
V Predictions Min            1355.0939
Log Pis Mean                 6.053764
Log Pis Std                  3.7250345
Log Pis Max                  14.534202
Log Pis Min                  -8.011296
Policy mu Mean               -0.1565469
Policy mu Std                1.3865147
Policy mu Max                3.4253578
Policy mu Min                -2.9683323
Policy log std Mean          -0.9411075
Policy log std Std           0.51084495
Policy log std Max           -0.17483884
Policy log std Min           -3.5899715
Z mean eval                  3.20718
Z variance eval              0.0076274946
total_rewards                [11284.02394706 11429.38687711  1444.21116745 11517.71691727
 11230.4679799   1109.71240736  6054.18646913  6950.51584808
 11364.35041683 11331.38141838]
total_rewards_mean           8371.59534485763
total_rewards_std            4021.6156679126275
total_rewards_max            11517.716917267426
total_rewards_min            1109.7124073569462
Number of train steps total  688000
Number of env steps total    862000
Number of rollouts total     0
Train Time (s)               116.65389955602586
(Previous) Eval Time (s)     22.932957854121923
Sample Time (s)              16.731615216936916
Epoch Time (s)               156.3184726270847
Total Train Time (s)         26327.17036340665
Epoch                        171
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:55:06.384715 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #171 | Epoch Duration: 155.9729883670807
2020-01-13 15:55:06.384929 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #171 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2073905
Z variance train             0.0076385313
KL Divergence                47.6398
KL Loss                      4.7639804
QF Loss                      611.5004
VF Loss                      113.402954
Policy Loss                  -4357.5913
Q Predictions Mean           4356.4043
Q Predictions Std            621.21545
Q Predictions Max            5201.2974
Q Predictions Min            1236.0898
V Predictions Mean           4351.6787
V Predictions Std            615.48846
V Predictions Max            5184.099
V Predictions Min            1255.903
Log Pis Mean                 5.1218085
Log Pis Std                  3.674695
Log Pis Max                  14.96501
Log Pis Min                  -3.6975641
Policy mu Mean               -0.07907369
Policy mu Std                1.3261825
Policy mu Max                2.7957516
Policy mu Min                -3.445791
Policy log std Mean          -0.9559862
Policy log std Std           0.5101279
Policy log std Max           0.12091291
Policy log std Min           -3.473628
Z mean eval                  3.2035713
Z variance eval              0.013368654
total_rewards                [10986.48405921 11480.88074476  6306.0264673  11272.72761273
 11533.13824219 10996.69659895 11178.39016376 11100.05605611
 11109.80550155 11002.43810583]
total_rewards_mean           10696.664355241337
total_rewards_std            1475.0327613002255
total_rewards_max            11533.13824219135
total_rewards_min            6306.026467304439
Number of train steps total  692000
Number of env steps total    867000
Number of rollouts total     0
Train Time (s)               117.38416662113741
(Previous) Eval Time (s)     22.587185919750482
Sample Time (s)              15.923926908988506
Epoch Time (s)               155.8952794498764
Total Train Time (s)         26483.86383171333
Epoch                        172
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:57:43.080289 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #172 | Epoch Duration: 156.69518971443176
2020-01-13 15:57:43.080464 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #172 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2024105
Z variance train             0.013372809
KL Divergence                47.02146
KL Loss                      4.702146
QF Loss                      769.4506
VF Loss                      137.11188
Policy Loss                  -4319.8984
Q Predictions Mean           4321.499
Q Predictions Std            666.5359
Q Predictions Max            5125.6284
Q Predictions Min            1095.8081
V Predictions Mean           4319.373
V Predictions Std            659.24713
V Predictions Max            5125.667
V Predictions Min            1113.2272
Log Pis Mean                 5.854642
Log Pis Std                  3.9267538
Log Pis Max                  14.246026
Log Pis Min                  -5.7576942
Policy mu Mean               -0.10149702
Policy mu Std                1.4263484
Policy mu Max                3.2170796
Policy mu Min                -2.9549367
Policy log std Mean          -0.9236703
Policy log std Std           0.5018905
Policy log std Max           -0.08921993
Policy log std Min           -3.3314488
Z mean eval                  3.216415
Z variance eval              0.0071836943
total_rewards                [10512.06904748 11152.76046445 11044.90340534  6856.68917023
  6055.02709114 11021.88112789 11389.72906001 11153.28100523
 10178.26649733 11484.51309695]
total_rewards_mean           10084.911996606239
total_rewards_std            1859.9787991449593
total_rewards_max            11484.513096947128
total_rewards_min            6055.02709114143
Number of train steps total  696000
Number of env steps total    872000
Number of rollouts total     0
Train Time (s)               121.50087925419211
(Previous) Eval Time (s)     23.386779673863202
Sample Time (s)              16.000397165305912
Epoch Time (s)               160.88805609336123
Total Train Time (s)         26644.46048068907
Epoch                        173
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:00:23.681278 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #173 | Epoch Duration: 160.60063934326172
2020-01-13 16:00:23.681571 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #173 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2166886
Z variance train             0.007174001
KL Divergence                46.723618
KL Loss                      4.672362
QF Loss                      289.60446
VF Loss                      150.97893
Policy Loss                  -4316.1025
Q Predictions Mean           4315.1455
Q Predictions Std            697.9296
Q Predictions Max            5285.2427
Q Predictions Min            1028.6086
V Predictions Mean           4312.5625
V Predictions Std            692.03784
V Predictions Max            5277.4727
V Predictions Min            1063.6794
Log Pis Mean                 5.568417
Log Pis Std                  3.7196372
Log Pis Max                  16.223183
Log Pis Min                  -6.0508585
Policy mu Mean               -0.08125761
Policy mu Std                1.3945695
Policy mu Max                3.1101644
Policy mu Min                -2.718306
Policy log std Mean          -0.9173353
Policy log std Std           0.4974889
Policy log std Max           -0.074909985
Policy log std Min           -3.3121006
Z mean eval                  3.1985946
Z variance eval              0.0050301193
total_rewards                [10991.06691213 11388.60544028 11063.78741129 11291.4071687
 10359.07768947 11370.21527174 10992.20572717 10859.75708869
 10515.70328102 11331.89508163]
total_rewards_mean           11016.372107213701
total_rewards_std            339.0675063753042
total_rewards_max            11388.605440282823
total_rewards_min            10359.077689466554
Number of train steps total  700000
Number of env steps total    877000
Number of rollouts total     0
Train Time (s)               121.03773159906268
(Previous) Eval Time (s)     23.09905722923577
Sample Time (s)              17.249043420888484
Epoch Time (s)               161.38583224918693
Total Train Time (s)         26806.00062600244
Epoch                        174
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:03:05.225063 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #174 | Epoch Duration: 161.54325556755066
2020-01-13 16:03:05.225345 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #174 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1986482
Z variance train             0.005028374
KL Divergence                46.920345
KL Loss                      4.6920347
QF Loss                      641.056
VF Loss                      298.1897
Policy Loss                  -4354.962
Q Predictions Mean           4357.7954
Q Predictions Std            675.41705
Q Predictions Max            5272.445
Q Predictions Min            1013.1153
V Predictions Mean           4359.9336
V Predictions Std            671.43176
V Predictions Max            5268.339
V Predictions Min            1026.056
Log Pis Mean                 5.613776
Log Pis Std                  3.741992
Log Pis Max                  15.3137455
Log Pis Min                  -3.66059
Policy mu Mean               -0.08612218
Policy mu Std                1.393478
Policy mu Max                3.178182
Policy mu Min                -2.9571276
Policy log std Mean          -0.8989287
Policy log std Std           0.51776344
Policy log std Max           0.055380106
Policy log std Min           -3.3567638
Z mean eval                  3.1887374
Z variance eval              0.01042983
total_rewards                [11378.01911578 11354.83914826 11216.57361897 11397.81490758
 11195.22795332 11308.15732305 11305.61924877 11226.86184903
 11010.4665606  11553.83001572]
total_rewards_mean           11294.740974107546
total_rewards_std            137.85109228980903
total_rewards_max            11553.830015721169
total_rewards_min            11010.466560595556
Number of train steps total  704000
Number of env steps total    882000
Number of rollouts total     0
Train Time (s)               117.40410280087963
(Previous) Eval Time (s)     23.25614600116387
Sample Time (s)              16.022240836638957
Epoch Time (s)               156.68248963868245
Total Train Time (s)         26962.73243572982
Epoch                        175
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:05:41.961708 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #175 | Epoch Duration: 156.73613572120667
2020-01-13 16:05:41.962001 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #175 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1882439
Z variance train             0.010462841
KL Divergence                45.056217
KL Loss                      4.505622
QF Loss                      444.60333
VF Loss                      254.14418
Policy Loss                  -4420.2383
Q Predictions Mean           4423.336
Q Predictions Std            615.46906
Q Predictions Max            5263.751
Q Predictions Min            935.6284
V Predictions Mean           4427.8955
V Predictions Std            609.496
V Predictions Max            5260.679
V Predictions Min            984.8718
Log Pis Mean                 6.131138
Log Pis Std                  3.7910788
Log Pis Max                  17.339516
Log Pis Min                  -3.1025975
Policy mu Mean               -0.10542714
Policy mu Std                1.4410661
Policy mu Max                3.5287502
Policy mu Min                -3.6835375
Policy log std Mean          -0.9251445
Policy log std Std           0.5194291
Policy log std Max           -0.08515513
Policy log std Min           -3.3225234
Z mean eval                  3.1628072
Z variance eval              0.022377849
total_rewards                [10958.58575784 10846.38527298 10678.65090806 10965.70698247
  2691.92296748 11278.33034822 10651.88948386 11035.56541748
 11169.51744547 11002.57439117]
total_rewards_mean           10127.912897502698
total_rewards_std            2485.5018630747527
total_rewards_max            11278.330348224834
total_rewards_min            2691.922967483599
Number of train steps total  708000
Number of env steps total    887000
Number of rollouts total     0
Train Time (s)               111.28625907516107
(Previous) Eval Time (s)     23.30950049497187
Sample Time (s)              16.71879401151091
Epoch Time (s)               151.31455358164385
Total Train Time (s)         27114.12097729789
Epoch                        176
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:08:13.353155 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #176 | Epoch Duration: 151.3909273147583
2020-01-13 16:08:13.353426 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #176 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1622415
Z variance train             0.022269752
KL Divergence                44.27919
KL Loss                      4.427919
QF Loss                      381.08978
VF Loss                      132.6912
Policy Loss                  -4389.334
Q Predictions Mean           4389.512
Q Predictions Std            685.62524
Q Predictions Max            5303.679
Q Predictions Min            906.8891
V Predictions Mean           4394.1436
V Predictions Std            684.9134
V Predictions Max            5293.7056
V Predictions Min            907.06244
Log Pis Mean                 5.78666
Log Pis Std                  3.794874
Log Pis Max                  20.282408
Log Pis Min                  -5.2950716
Policy mu Mean               -0.06959298
Policy mu Std                1.4320827
Policy mu Max                2.9105754
Policy mu Min                -3.626786
Policy log std Mean          -0.8999157
Policy log std Std           0.49194095
Policy log std Max           -0.045566797
Policy log std Min           -3.497192
Z mean eval                  3.1713052
Z variance eval              0.011545658
total_rewards                [11460.4221828  11366.85592681 11774.68788082 11367.3565464
 11304.20326827 11290.1017049   5386.41715828 11314.12547291
 11320.40728147 11365.31867416]
total_rewards_mean           10794.989609682856
total_rewards_std            1807.9041933087872
total_rewards_max            11774.687880822301
total_rewards_min            5386.417158281706
Number of train steps total  712000
Number of env steps total    892000
Number of rollouts total     0
Train Time (s)               117.4219957049936
(Previous) Eval Time (s)     23.38553613377735
Sample Time (s)              16.66467258008197
Epoch Time (s)               157.47220441885293
Total Train Time (s)         27271.279031828046
Epoch                        177
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:10:50.515058 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #177 | Epoch Duration: 157.16142082214355
2020-01-13 16:10:50.515300 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #177 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.173954
Z variance train             0.011567801
KL Divergence                45.55128
KL Loss                      4.555128
QF Loss                      473.90015
VF Loss                      184.15158
Policy Loss                  -4435.8936
Q Predictions Mean           4431.9287
Q Predictions Std            669.3276
Q Predictions Max            5264.4937
Q Predictions Min            811.6722
V Predictions Mean           4427.177
V Predictions Std            661.17944
V Predictions Max            5245.1567
V Predictions Min            826.46405
Log Pis Mean                 5.7940025
Log Pis Std                  3.5458803
Log Pis Max                  14.326599
Log Pis Min                  -4.641826
Policy mu Mean               -0.1253366
Policy mu Std                1.4001579
Policy mu Max                3.0027788
Policy mu Min                -2.8914309
Policy log std Mean          -0.91969395
Policy log std Std           0.4985632
Policy log std Max           -0.08739233
Policy log std Min           -3.5082397
Z mean eval                  3.1802766
Z variance eval              0.010994281
total_rewards                [11087.6689816  11567.18435045 11455.92644552 11510.94307744
 11671.61471561 10747.39261273 11529.95419307  8528.06646298
  9714.28493761 11365.63904706]
total_rewards_mean           10917.867482409038
total_rewards_std            970.7624321259924
total_rewards_max            11671.614715610356
total_rewards_min            8528.066462984381
Number of train steps total  716000
Number of env steps total    897000
Number of rollouts total     0
Train Time (s)               117.64426954090595
(Previous) Eval Time (s)     23.074451840948313
Sample Time (s)              16.249522671103477
Epoch Time (s)               156.96824405295774
Total Train Time (s)         27427.87475545518
Epoch                        178
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:13:27.112942 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #178 | Epoch Duration: 156.5974464416504
2020-01-13 16:13:27.113213 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #178 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1845062
Z variance train             0.01095903
KL Divergence                47.00475
KL Loss                      4.700475
QF Loss                      538.78723
VF Loss                      469.7113
Policy Loss                  -4453.508
Q Predictions Mean           4451.9707
Q Predictions Std            545.0845
Q Predictions Max            5280.2197
Q Predictions Min            1746.6757
V Predictions Mean           4436.1836
V Predictions Std            536.2551
V Predictions Max            5251.169
V Predictions Min            1936.3367
Log Pis Mean                 5.6007633
Log Pis Std                  3.9369884
Log Pis Max                  14.723846
Log Pis Min                  -4.9327393
Policy mu Mean               -0.15196267
Policy mu Std                1.3887246
Policy mu Max                2.9282014
Policy mu Min                -4.380469
Policy log std Mean          -0.9235942
Policy log std Std           0.50279754
Policy log std Max           0.0110321045
Policy log std Min           -3.4478765
Z mean eval                  3.1774962
Z variance eval              0.010226688
total_rewards                [11283.39776614  6239.1300134  11348.51997772 11690.46354658
 11684.88597247 11692.25099938 11649.36517863 11522.13125975
 11842.44873134 11530.69203413]
total_rewards_mean           11048.328547954134
total_rewards_std            1611.0548485644724
total_rewards_max            11842.448731343284
total_rewards_min            6239.130013396932
Number of train steps total  720000
Number of env steps total    902000
Number of rollouts total     0
Train Time (s)               109.78489566128701
(Previous) Eval Time (s)     22.703337281011045
Sample Time (s)              16.02389559475705
Epoch Time (s)               148.5121285370551
Total Train Time (s)         27576.12654314749
Epoch                        179
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:15:55.365631 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #179 | Epoch Duration: 148.25221824645996
2020-01-13 16:15:55.365808 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #179 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1754544
Z variance train             0.010224929
KL Divergence                47.32345
KL Loss                      4.732345
QF Loss                      356.25684
VF Loss                      147.41325
Policy Loss                  -4331.5557
Q Predictions Mean           4330.2188
Q Predictions Std            702.81396
Q Predictions Max            5154.259
Q Predictions Min            853.20514
V Predictions Mean           4325.6606
V Predictions Std            695.3622
V Predictions Max            5129.8003
V Predictions Min            882.53845
Log Pis Mean                 5.776579
Log Pis Std                  4.0211325
Log Pis Max                  15.185801
Log Pis Min                  -3.818305
Policy mu Mean               -0.08456069
Policy mu Std                1.390256
Policy mu Max                3.1687407
Policy mu Min                -2.7666926
Policy log std Mean          -0.932898
Policy log std Std           0.49771646
Policy log std Max           -0.12675357
Policy log std Min           -3.483896
Z mean eval                  3.1760335
Z variance eval              0.020654459
total_rewards                [11604.5436145  11666.1896962  11523.45743541 11347.64604689
 11409.68255806 11165.62696866 11471.58613295 10747.47584765
 11346.77198775 11498.02964187]
total_rewards_mean           11378.100992994016
total_rewards_std            249.85233635827456
total_rewards_max            11666.189696201533
total_rewards_min            10747.475847650694
Number of train steps total  724000
Number of env steps total    907000
Number of rollouts total     0
Train Time (s)               113.89649751922116
(Previous) Eval Time (s)     22.44314580503851
Sample Time (s)              16.38474827306345
Epoch Time (s)               152.72439159732312
Total Train Time (s)         27729.327977498993
Epoch                        180
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:18:28.569343 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #180 | Epoch Duration: 153.20339584350586
2020-01-13 16:18:28.569525 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #180 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1785133
Z variance train             0.0207146
KL Divergence                46.576656
KL Loss                      4.6576657
QF Loss                      643.2866
VF Loss                      229.23813
Policy Loss                  -4341.9995
Q Predictions Mean           4339.3965
Q Predictions Std            667.83514
Q Predictions Max            5206.6704
Q Predictions Min            846.85364
V Predictions Mean           4332.9087
V Predictions Std            665.1874
V Predictions Max            5187.519
V Predictions Min            858.3834
Log Pis Mean                 5.693399
Log Pis Std                  4.1441584
Log Pis Max                  16.430132
Log Pis Min                  -5.1037893
Policy mu Mean               -0.14210059
Policy mu Std                1.4037044
Policy mu Max                3.0964775
Policy mu Min                -4.110754
Policy log std Mean          -0.9152487
Policy log std Std           0.5096652
Policy log std Max           0.115038395
Policy log std Min           -3.389431
Z mean eval                  3.1919727
Z variance eval              0.015213187
total_rewards                [11103.26086896 11107.31997    11109.47816054 11147.24006688
 10911.23649054 11134.64502112 11078.51948462 11131.51204908
 11013.68079204 11263.58936027]
total_rewards_mean           11100.048226405346
total_rewards_std            86.5358293673091
total_rewards_max            11263.589360266204
total_rewards_min            10911.236490535788
Number of train steps total  728000
Number of env steps total    912000
Number of rollouts total     0
Train Time (s)               115.9906609710306
(Previous) Eval Time (s)     22.9218295160681
Sample Time (s)              16.31216778466478
Epoch Time (s)               155.22465827176347
Total Train Time (s)         27884.27523750905
Epoch                        181
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:21:03.518282 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #181 | Epoch Duration: 154.94864010810852
2020-01-13 16:21:03.518483 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #181 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1908085
Z variance train             0.015142863
KL Divergence                45.85464
KL Loss                      4.585464
QF Loss                      573.74963
VF Loss                      140.78705
Policy Loss                  -4417.9443
Q Predictions Mean           4421.54
Q Predictions Std            690.0396
Q Predictions Max            5218.475
Q Predictions Min            851.34106
V Predictions Mean           4423.52
V Predictions Std            684.7128
V Predictions Max            5186.843
V Predictions Min            861.4088
Log Pis Mean                 6.0016026
Log Pis Std                  4.0540805
Log Pis Max                  16.373058
Log Pis Min                  -3.9155045
Policy mu Mean               -0.09198105
Policy mu Std                1.4427286
Policy mu Max                2.9417107
Policy mu Min                -3.0578604
Policy log std Mean          -0.91391844
Policy log std Std           0.49239707
Policy log std Max           -0.20538092
Policy log std Min           -3.2917318
Z mean eval                  3.1821933
Z variance eval              0.019500902
total_rewards                [11118.65120002 11431.39525768 11333.14925545 11213.70684091
 11439.64759741  3338.54335862 11469.61908866 11381.44772126
 11610.50361246 11378.99101482]
total_rewards_mean           10571.56549472942
total_rewards_std            2414.4332449484823
total_rewards_max            11610.503612459388
total_rewards_min            3338.5433586183403
Number of train steps total  732000
Number of env steps total    917000
Number of rollouts total     0
Train Time (s)               118.96440232405439
(Previous) Eval Time (s)     22.645511059090495
Sample Time (s)              16.710020665545017
Epoch Time (s)               158.3199340486899
Total Train Time (s)         28042.38047753554
Epoch                        182
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:23:41.627306 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #182 | Epoch Duration: 158.10868978500366
2020-01-13 16:23:41.627521 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #182 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1817145
Z variance train             0.019508574
KL Divergence                45.99312
KL Loss                      4.599312
QF Loss                      570.23676
VF Loss                      185.29814
Policy Loss                  -4382.3125
Q Predictions Mean           4384.299
Q Predictions Std            709.0914
Q Predictions Max            5360.7783
Q Predictions Min            866.1463
V Predictions Mean           4384.0586
V Predictions Std            700.3742
V Predictions Max            5356.087
V Predictions Min            930.5625
Log Pis Mean                 5.25935
Log Pis Std                  3.6234944
Log Pis Max                  17.557247
Log Pis Min                  -2.9683862
Policy mu Mean               -0.12476623
Policy mu Std                1.3652295
Policy mu Max                3.6463
Policy mu Min                -2.930416
Policy log std Mean          -0.9177452
Policy log std Std           0.4970365
Policy log std Max           -0.21126828
Policy log std Min           -3.5392141
Z mean eval                  3.1807168
Z variance eval              0.018308958
total_rewards                [11063.11808544 11254.0614681  11244.82378238 11580.19924147
 11259.63110759 11209.65387995 11491.58128772 11582.94295835
 11325.01782227 11269.64742262]
total_rewards_mean           11328.067705588855
total_rewards_std            161.24540484884665
total_rewards_max            11582.942958345639
total_rewards_min            11063.118085438511
Number of train steps total  736000
Number of env steps total    922000
Number of rollouts total     0
Train Time (s)               116.40617081010714
(Previous) Eval Time (s)     22.433932188898325
Sample Time (s)              16.09315449744463
Epoch Time (s)               154.9332574964501
Total Train Time (s)         28197.3869807343
Epoch                        183
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:26:16.634875 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #183 | Epoch Duration: 155.00717067718506
2020-01-13 16:26:16.635071 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #183 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1820097
Z variance train             0.01830472
KL Divergence                46.24626
KL Loss                      4.624626
QF Loss                      505.24112
VF Loss                      182.87308
Policy Loss                  -4417.6177
Q Predictions Mean           4421.2373
Q Predictions Std            664.6816
Q Predictions Max            5336.736
Q Predictions Min            932.7984
V Predictions Mean           4410.3574
V Predictions Std            660.1184
V Predictions Max            5320.6777
V Predictions Min            938.0669
Log Pis Mean                 6.0652456
Log Pis Std                  3.5549042
Log Pis Max                  15.0079365
Log Pis Min                  -4.318616
Policy mu Mean               -0.08670285
Policy mu Std                1.4160587
Policy mu Max                3.1737576
Policy mu Min                -3.624227
Policy log std Mean          -0.91754323
Policy log std Std           0.5128376
Policy log std Max           0.158669
Policy log std Min           -3.5382013
Z mean eval                  3.168342
Z variance eval              0.008757515
total_rewards                [11039.87521414 11491.69542548 11471.74598502 11439.80180312
 11479.98889877 11620.57115721 11306.21061867 11424.68967272
 11308.21622435 11299.95145655]
total_rewards_mean           11388.274645603164
total_rewards_std            150.4475333169299
total_rewards_max            11620.571157214006
total_rewards_min            11039.875214143143
Number of train steps total  740000
Number of env steps total    927000
Number of rollouts total     0
Train Time (s)               110.78742699697614
(Previous) Eval Time (s)     22.507467473391443
Sample Time (s)              16.736437127459794
Epoch Time (s)               150.03133159782737
Total Train Time (s)         28347.512520723045
Epoch                        184
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:28:46.763500 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #184 | Epoch Duration: 150.1282560825348
2020-01-13 16:28:46.763727 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #184 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1687262
Z variance train             0.008759488
KL Divergence                46.705364
KL Loss                      4.6705365
QF Loss                      412.74823
VF Loss                      93.53406
Policy Loss                  -4369.4004
Q Predictions Mean           4369.1035
Q Predictions Std            739.2156
Q Predictions Max            5329.3193
Q Predictions Min            989.9665
V Predictions Mean           4369.413
V Predictions Std            738.4559
V Predictions Max            5307.7197
V Predictions Min            951.9607
Log Pis Mean                 5.739456
Log Pis Std                  3.783529
Log Pis Max                  16.097435
Log Pis Min                  -6.2986045
Policy mu Mean               -0.14154662
Policy mu Std                1.4080194
Policy mu Max                3.3615358
Policy mu Min                -3.1113842
Policy log std Mean          -0.9351902
Policy log std Std           0.52339953
Policy log std Max           -0.1608445
Policy log std Min           -3.3773234
Z mean eval                  3.1670442
Z variance eval              0.008940913
total_rewards                [11134.91293361 11395.37564295 11279.99321199  7718.22467423
 10949.25109609 11420.60920749 11018.70111961 11398.82250386
  3766.36829732 11355.84067653]
total_rewards_mean           10143.809936368994
total_rewards_std            2376.621583485603
total_rewards_max            11420.609207485375
total_rewards_min            3766.3682973213186
Number of train steps total  744000
Number of env steps total    932000
Number of rollouts total     0
Train Time (s)               121.03972903219983
(Previous) Eval Time (s)     22.6040650610812
Sample Time (s)              15.681332082953304
Epoch Time (s)               159.32512617623433
Total Train Time (s)         28506.857502265368
Epoch                        185
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:31:26.109857 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #185 | Epoch Duration: 159.34594440460205
2020-01-13 16:31:26.110039 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #185 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1692605
Z variance train             0.008923225
KL Divergence                46.68792
KL Loss                      4.6687922
QF Loss                      351.84732
VF Loss                      94.523636
Policy Loss                  -4412.5117
Q Predictions Mean           4410.4995
Q Predictions Std            633.6709
Q Predictions Max            5292.129
Q Predictions Min            1008.8653
V Predictions Mean           4415.912
V Predictions Std            630.84265
V Predictions Max            5282.238
V Predictions Min            1031.2799
Log Pis Mean                 5.698475
Log Pis Std                  4.175593
Log Pis Max                  17.262789
Log Pis Min                  -9.4873905
Policy mu Mean               -0.12820329
Policy mu Std                1.4173337
Policy mu Max                3.0991762
Policy mu Min                -2.8781052
Policy log std Mean          -0.9104536
Policy log std Std           0.50309765
Policy log std Max           -0.107734084
Policy log std Min           -3.6398764
Z mean eval                  3.1681123
Z variance eval              0.010713098
total_rewards                [ 5821.33721709 11392.24203384 11245.12036229 11761.79014277
 11507.54935772 11343.23939156 11766.50365138 11226.44563295
 11393.1984217   8918.76405008]
total_rewards_mean           10637.619026139188
total_rewards_std            1783.2549936688629
total_rewards_max            11766.503651380282
total_rewards_min            5821.337217090926
Number of train steps total  748000
Number of env steps total    937000
Number of rollouts total     0
Train Time (s)               117.5520373028703
(Previous) Eval Time (s)     22.62458903901279
Sample Time (s)              16.425251621752977
Epoch Time (s)               156.60187796363607
Total Train Time (s)         28663.634478273336
Epoch                        186
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:34:02.891451 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #186 | Epoch Duration: 156.78126668930054
2020-01-13 16:34:02.891683 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #186 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1673923
Z variance train             0.010714248
KL Divergence                47.35821
KL Loss                      4.7358212
QF Loss                      381.81302
VF Loss                      140.13295
Policy Loss                  -4379.0293
Q Predictions Mean           4381.2217
Q Predictions Std            733.484
Q Predictions Max            5317.861
Q Predictions Min            969.525
V Predictions Mean           4379.8896
V Predictions Std            728.44135
V Predictions Max            5325.7017
V Predictions Min            995.42236
Log Pis Mean                 5.7224236
Log Pis Std                  3.67227
Log Pis Max                  13.675928
Log Pis Min                  -6.2960157
Policy mu Mean               -0.099109985
Policy mu Std                1.4219083
Policy mu Max                4.0221615
Policy mu Min                -2.9075563
Policy log std Mean          -0.9109023
Policy log std Std           0.48130658
Policy log std Max           0.06353319
Policy log std Min           -3.387309
Z mean eval                  3.168116
Z variance eval              0.011085687
total_rewards                [10952.15483814 11397.37673463 10926.68802795 11613.94613339
 11158.90111996 11020.01988757 11113.54856632 11362.13174695
 11322.83703232  4464.62318265]
total_rewards_mean           10533.222726989046
total_rewards_std            2033.439171398224
total_rewards_max            11613.94613338554
total_rewards_min            4464.623182650538
Number of train steps total  752000
Number of env steps total    942000
Number of rollouts total     0
Train Time (s)               112.72644043480977
(Previous) Eval Time (s)     22.80365074891597
Sample Time (s)              15.816493449732661
Epoch Time (s)               151.3465846334584
Total Train Time (s)         28814.543731599115
Epoch                        187
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:36:33.803857 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #187 | Epoch Duration: 150.911954164505
2020-01-13 16:36:33.804124 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #187 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1655943
Z variance train             0.011109196
KL Divergence                46.9079
KL Loss                      4.69079
QF Loss                      411.00436
VF Loss                      127.708626
Policy Loss                  -4432.5234
Q Predictions Mean           4436.9883
Q Predictions Std            518.7975
Q Predictions Max            5312.9907
Q Predictions Min            3014.305
V Predictions Mean           4436.6787
V Predictions Std            513.9231
V Predictions Max            5280.219
V Predictions Min            3066.0652
Log Pis Mean                 6.027546
Log Pis Std                  4.0613794
Log Pis Max                  16.280567
Log Pis Min                  -4.981648
Policy mu Mean               -0.11695597
Policy mu Std                1.4164765
Policy mu Max                2.9986691
Policy mu Min                -2.8259904
Policy log std Mean          -0.9071948
Policy log std Std           0.49495375
Policy log std Max           -0.008841872
Policy log std Min           -3.5009742
Z mean eval                  3.1753993
Z variance eval              0.019065317
total_rewards                [10758.76604872 10803.71564868 10643.21996141 11051.15015327
 11003.89641936 10869.76607388 10926.16928518 10896.87569494
 10988.52412409 10841.64565006]
total_rewards_mean           10878.37290595857
total_rewards_std            117.03317910121488
total_rewards_max            11051.150153272452
total_rewards_min            10643.219961408768
Number of train steps total  756000
Number of env steps total    947000
Number of rollouts total     0
Train Time (s)               121.75062586413696
(Previous) Eval Time (s)     22.368764251004905
Sample Time (s)              16.128708140924573
Epoch Time (s)               160.24809825606644
Total Train Time (s)         28975.741691891104
Epoch                        188
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:39:15.010240 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #188 | Epoch Duration: 161.2058801651001
2020-01-13 16:39:15.010556 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #188 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1766343
Z variance train             0.019028436
KL Divergence                47.13736
KL Loss                      4.713736
QF Loss                      550.5733
VF Loss                      332.38528
Policy Loss                  -4436.494
Q Predictions Mean           4433.7104
Q Predictions Std            653.91125
Q Predictions Max            5352.0444
Q Predictions Min            1076.6676
V Predictions Mean           4421.6094
V Predictions Std            648.26495
V Predictions Max            5334.1523
V Predictions Min            1077.6432
Log Pis Mean                 5.775478
Log Pis Std                  3.9437263
Log Pis Max                  16.848652
Log Pis Min                  -4.4713116
Policy mu Mean               -0.18786366
Policy mu Std                1.3987838
Policy mu Max                3.177418
Policy mu Min                -2.9364314
Policy log std Mean          -0.9126155
Policy log std Std           0.49882317
Policy log std Max           0.110158205
Policy log std Min           -3.317649
Z mean eval                  3.1803775
Z variance eval              0.027257998
total_rewards                [11172.38547989 11020.35488608 11113.94227892 11172.955454
 10942.81392489 11317.80272611 11078.9870918  11139.62171546
 10766.43335939 11244.12609121]
total_rewards_mean           11096.942300775912
total_rewards_std            149.39957773742216
total_rewards_max            11317.802726107699
total_rewards_min            10766.433359394121
Number of train steps total  760000
Number of env steps total    952000
Number of rollouts total     0
Train Time (s)               117.32616489101201
(Previous) Eval Time (s)     23.326253233011812
Sample Time (s)              15.900529826525599
Epoch Time (s)               156.55294795054942
Total Train Time (s)         29131.31935466826
Epoch                        189
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:41:50.583695 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #189 | Epoch Duration: 155.57294392585754
2020-01-13 16:41:50.583860 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #189 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.181008
Z variance train             0.02719758
KL Divergence                46.724403
KL Loss                      4.6724405
QF Loss                      329.3954
VF Loss                      95.84789
Policy Loss                  -4515.9937
Q Predictions Mean           4514.8906
Q Predictions Std            567.71246
Q Predictions Max            5406.475
Q Predictions Min            1133.6967
V Predictions Mean           4513.1025
V Predictions Std            558.5762
V Predictions Max            5389.417
V Predictions Min            1155.2917
Log Pis Mean                 5.86435
Log Pis Std                  3.876647
Log Pis Max                  15.272369
Log Pis Min                  -4.664537
Policy mu Mean               -0.11815646
Policy mu Std                1.4107165
Policy mu Max                3.3410032
Policy mu Min                -2.8005152
Policy log std Mean          -0.9092877
Policy log std Std           0.50826234
Policy log std Max           -0.0027114153
Policy log std Min           -3.444488
Z mean eval                  3.1870184
Z variance eval              0.01599105
total_rewards                [11321.49024151 11578.43180796 11332.33024677 11707.45519231
 11593.93218608 11546.22564547 11228.86855601 11178.69303951
 11154.20413355 11581.10424613]
total_rewards_mean           11422.273529528979
total_rewards_std            190.42510650551853
total_rewards_max            11707.455192307678
total_rewards_min            11154.20413355038
Number of train steps total  764000
Number of env steps total    957000
Number of rollouts total     0
Train Time (s)               116.91476080659777
(Previous) Eval Time (s)     22.345966904889792
Sample Time (s)              16.20331667456776
Epoch Time (s)               155.46404438605532
Total Train Time (s)         29287.399846950546
Epoch                        190
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:44:26.668799 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #190 | Epoch Duration: 156.0847978591919
2020-01-13 16:44:26.669036 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #190 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1871257
Z variance train             0.016008664
KL Divergence                48.430904
KL Loss                      4.8430905
QF Loss                      472.23975
VF Loss                      148.73479
Policy Loss                  -4481.99
Q Predictions Mean           4481.6025
Q Predictions Std            611.7162
Q Predictions Max            5295.3184
Q Predictions Min            1088.9855
V Predictions Mean           4477.3984
V Predictions Std            606.8722
V Predictions Max            5287.101
V Predictions Min            1098.5177
Log Pis Mean                 5.8480415
Log Pis Std                  3.8585858
Log Pis Max                  14.122248
Log Pis Min                  -6.3833447
Policy mu Mean               -0.16207524
Policy mu Std                1.4045246
Policy mu Max                3.0194783
Policy mu Min                -3.4051738
Policy log std Mean          -0.9287424
Policy log std Std           0.49897912
Policy log std Max           0.066197395
Policy log std Min           -3.4533534
Z mean eval                  3.1736882
Z variance eval              0.008391707
total_rewards                [11436.0093148  11541.35591913 11501.58892765 11353.12936982
 11240.08637364 11585.74721292 11562.80703687 11411.02906906
 11381.19064442 11273.35979742]
total_rewards_mean           11428.630366574105
total_rewards_std            113.44251994173045
total_rewards_max            11585.747212922803
total_rewards_min            11240.086373639237
Number of train steps total  768000
Number of env steps total    962000
Number of rollouts total     0
Train Time (s)               119.85179837374017
(Previous) Eval Time (s)     22.96636806288734
Sample Time (s)              17.10402593901381
Epoch Time (s)               159.92219237564132
Total Train Time (s)         29446.70583728561
Epoch                        191
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:47:05.979654 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #191 | Epoch Duration: 159.31041622161865
2020-01-13 16:47:05.979960 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #191 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.172243
Z variance train             0.008407087
KL Divergence                47.73796
KL Loss                      4.773796
QF Loss                      473.11267
VF Loss                      167.086
Policy Loss                  -4390.824
Q Predictions Mean           4394.842
Q Predictions Std            678.369
Q Predictions Max            5381.551
Q Predictions Min            1054.8965
V Predictions Mean           4400.61
V Predictions Std            674.7624
V Predictions Max            5382.7793
V Predictions Min            1071.5973
Log Pis Mean                 5.9586945
Log Pis Std                  3.9975917
Log Pis Max                  18.355968
Log Pis Min                  -5.074238
Policy mu Mean               -0.1114013
Policy mu Std                1.4175398
Policy mu Max                3.1449974
Policy mu Min                -2.7940745
Policy log std Mean          -0.9370714
Policy log std Std           0.51787
Policy log std Max           -0.093660116
Policy log std Min           -3.3593898
Z mean eval                  3.147255
Z variance eval              0.017204927
total_rewards                [11010.72507311 11552.6777991  11609.39365892 11525.14159574
 11355.86994591 11603.90007932 11060.25116238 11365.18176091
 11419.81039278 11258.93930328]
total_rewards_mean           11376.18907714365
total_rewards_std            202.27131784624004
total_rewards_max            11609.393658924771
total_rewards_min            11010.725073108619
Number of train steps total  772000
Number of env steps total    967000
Number of rollouts total     0
Train Time (s)               114.70716324076056
(Previous) Eval Time (s)     22.354300857987255
Sample Time (s)              16.306927009951323
Epoch Time (s)               153.36839110869914
Total Train Time (s)         29601.01220105635
Epoch                        192
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:49:40.287311 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #192 | Epoch Duration: 154.3071563243866
2020-01-13 16:49:40.287529 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #192 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1503751
Z variance train             0.017186156
KL Divergence                46.565086
KL Loss                      4.656509
QF Loss                      283.41876
VF Loss                      217.85718
Policy Loss                  -4404.4336
Q Predictions Mean           4402.512
Q Predictions Std            619.9405
Q Predictions Max            5291.862
Q Predictions Min            1057.5471
V Predictions Mean           4392.713
V Predictions Std            611.6757
V Predictions Max            5292.39
V Predictions Min            1074.6195
Log Pis Mean                 5.631356
Log Pis Std                  3.9733605
Log Pis Max                  15.74666
Log Pis Min                  -2.9989667
Policy mu Mean               -0.11101969
Policy mu Std                1.3786548
Policy mu Max                3.259606
Policy mu Min                -2.8267472
Policy log std Mean          -0.9295499
Policy log std Std           0.50041544
Policy log std Max           -0.23177034
Policy log std Min           -3.2717118
Z mean eval                  3.1675363
Z variance eval              0.0106163705
total_rewards                [11602.26839741 10996.44718755 11334.68801854 11579.87545245
 11658.14106603  6125.10763092 11608.20505128 11618.85357965
 11416.66269086 11882.64367215]
total_rewards_mean           10982.289274682884
total_rewards_std            1634.3549436246144
total_rewards_max            11882.64367215276
total_rewards_min            6125.107630917629
Number of train steps total  776000
Number of env steps total    972000
Number of rollouts total     0
Train Time (s)               117.93905562581494
(Previous) Eval Time (s)     23.292798028793186
Sample Time (s)              16.160203491337597
Epoch Time (s)               157.39205714594573
Total Train Time (s)         29758.11544562131
Epoch                        193
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:52:17.393879 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #193 | Epoch Duration: 157.10621094703674
2020-01-13 16:52:17.394118 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #193 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1658478
Z variance train             0.010611288
KL Divergence                46.895466
KL Loss                      4.6895466
QF Loss                      1236.4526
VF Loss                      140.18677
Policy Loss                  -4429.9385
Q Predictions Mean           4431.9097
Q Predictions Std            601.4034
Q Predictions Max            5348.8623
Q Predictions Min            1096.8088
V Predictions Mean           4432.3857
V Predictions Std            597.6594
V Predictions Max            5333.176
V Predictions Min            1101.2795
Log Pis Mean                 5.2136483
Log Pis Std                  4.115771
Log Pis Max                  15.14553
Log Pis Min                  -4.172674
Policy mu Mean               -0.13283326
Policy mu Std                1.3896121
Policy mu Max                2.98515
Policy mu Min                -3.07111
Policy log std Mean          -0.89346266
Policy log std Std           0.47535014
Policy log std Max           -0.0030292273
Policy log std Min           -3.52341
Z mean eval                  3.1604931
Z variance eval              0.004784058
total_rewards                [10848.10473019 11018.05092723 10942.53520392 10856.87708908
 11010.08729487 10743.59097974 10942.63461453 10834.01214131
 10866.85743216 10868.89225588]
total_rewards_mean           10893.164266889584
total_rewards_std            80.40641796677599
total_rewards_max            11018.050927225437
total_rewards_min            10743.5909797416
Number of train steps total  780000
Number of env steps total    977000
Number of rollouts total     0
Train Time (s)               115.56494493363425
(Previous) Eval Time (s)     23.006632797885686
Sample Time (s)              16.3753045857884
Epoch Time (s)               154.94688231730834
Total Train Time (s)         29912.488397532143
Epoch                        194
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:54:51.768877 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #194 | Epoch Duration: 154.3745698928833
2020-01-13 16:54:51.769071 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #194 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1593294
Z variance train             0.004790873
KL Divergence                48.37654
KL Loss                      4.837654
QF Loss                      515.1717
VF Loss                      197.98639
Policy Loss                  -4477.676
Q Predictions Mean           4478.081
Q Predictions Std            566.8221
Q Predictions Max            5392.338
Q Predictions Min            1161.7241
V Predictions Mean           4488.8213
V Predictions Std            562.869
V Predictions Max            5400.062
V Predictions Min            1169.7944
Log Pis Mean                 5.5842814
Log Pis Std                  3.932538
Log Pis Max                  16.32134
Log Pis Min                  -6.8371515
Policy mu Mean               -0.1486612
Policy mu Std                1.3970664
Policy mu Max                3.0299757
Policy mu Min                -2.997377
Policy log std Mean          -0.93580914
Policy log std Std           0.4993227
Policy log std Max           -0.11962688
Policy log std Min           -3.4284585
Z mean eval                  3.1394792
Z variance eval              0.023257872
total_rewards                [10935.71204065 11298.61552697 11123.14473928 11155.09050625
 11242.12682399 10988.7640536  11077.06075676 11031.61845798
 11053.62218139 11043.87875842]
total_rewards_mean           11094.963384528692
total_rewards_std            106.22233234068072
total_rewards_max            11298.615526974976
total_rewards_min            10935.712040645161
Number of train steps total  784000
Number of env steps total    982000
Number of rollouts total     0
Train Time (s)               116.37355046207085
(Previous) Eval Time (s)     22.434020389802754
Sample Time (s)              15.988050351385027
Epoch Time (s)               154.79562120325863
Total Train Time (s)         30067.66538920719
Epoch                        195
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:57:26.947601 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #195 | Epoch Duration: 155.17837572097778
2020-01-13 16:57:26.947823 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #195 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.142773
Z variance train             0.023307374
KL Divergence                43.781948
KL Loss                      4.378195
QF Loss                      698.36127
VF Loss                      464.29822
Policy Loss                  -4420.633
Q Predictions Mean           4425.4463
Q Predictions Std            605.0045
Q Predictions Max            5338.516
Q Predictions Min            1211.3413
V Predictions Mean           4402.49
V Predictions Std            598.9238
V Predictions Max            5308.7837
V Predictions Min            1138.0175
Log Pis Mean                 5.650112
Log Pis Std                  3.834894
Log Pis Max                  16.473148
Log Pis Min                  -3.385373
Policy mu Mean               -0.10743425
Policy mu Std                1.3777297
Policy mu Max                3.02421
Policy mu Min                -2.9532647
Policy log std Mean          -0.9260643
Policy log std Std           0.47750017
Policy log std Max           0.1113044
Policy log std Min           -3.369782
Z mean eval                  3.1563535
Z variance eval              0.020269081
total_rewards                [10901.23467952 11174.9249145  11134.98278898 11024.50248054
 11190.94118275 11080.97599863 11237.13993469 10990.44494805
 11369.64567163 11112.53694369]
total_rewards_mean           11121.732954298557
total_rewards_std            126.34464729942253
total_rewards_max            11369.64567163263
total_rewards_min            10901.234679520403
Number of train steps total  788000
Number of env steps total    987000
Number of rollouts total     0
Train Time (s)               117.52046356676146
(Previous) Eval Time (s)     22.816492991987616
Sample Time (s)              16.519035113044083
Epoch Time (s)               156.85599167179316
Total Train Time (s)         30225.423190560192
Epoch                        196
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:00:04.708128 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #196 | Epoch Duration: 157.7601387500763
2020-01-13 17:00:04.708297 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #196 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.155864
Z variance train             0.020275837
KL Divergence                42.922005
KL Loss                      4.2922006
QF Loss                      363.72424
VF Loss                      108.86498
Policy Loss                  -4468.287
Q Predictions Mean           4468.341
Q Predictions Std            697.02216
Q Predictions Max            5290.94
Q Predictions Min            1136.2335
V Predictions Mean           4463.1284
V Predictions Std            691.44147
V Predictions Max            5272.009
V Predictions Min            1135.8894
Log Pis Mean                 5.455023
Log Pis Std                  3.8447113
Log Pis Max                  15.48264
Log Pis Min                  -3.7381759
Policy mu Mean               -0.10902115
Policy mu Std                1.375756
Policy mu Max                3.2193506
Policy mu Min                -2.8786256
Policy log std Mean          -0.9082389
Policy log std Std           0.48499417
Policy log std Max           -0.021957755
Policy log std Min           -3.5672107
Z mean eval                  3.1187203
Z variance eval              0.08261137
total_rewards                [10881.15553571 10813.14923053 11180.80232723 10957.45263917
 11149.1430167  11236.31681005 10938.5726484  10908.89931643
 11173.26966177 10894.81629247]
total_rewards_mean           11013.357747846114
total_rewards_std            145.94540011426074
total_rewards_max            11236.316810045277
total_rewards_min            10813.149230531675
Number of train steps total  792000
Number of env steps total    992000
Number of rollouts total     0
Train Time (s)               113.02781183412299
(Previous) Eval Time (s)     23.720283600967377
Sample Time (s)              15.600546925328672
Epoch Time (s)               152.34864236041903
Total Train Time (s)         30376.42015347304
Epoch                        197
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:02:35.708517 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #197 | Epoch Duration: 151.0000720024109
2020-01-13 17:02:35.708756 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #197 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1189606
Z variance train             0.08282625
KL Divergence                39.73463
KL Loss                      3.973463
QF Loss                      331.61438
VF Loss                      151.561
Policy Loss                  -4323.041
Q Predictions Mean           4321.4126
Q Predictions Std            690.65765
Q Predictions Max            5237.315
Q Predictions Min            1095.3176
V Predictions Mean           4315.9707
V Predictions Std            686.47
V Predictions Max            5226.874
V Predictions Min            1098.9869
Log Pis Mean                 5.894794
Log Pis Std                  3.7353086
Log Pis Max                  14.602593
Log Pis Min                  -6.22448
Policy mu Mean               -0.13708137
Policy mu Std                1.4150735
Policy mu Max                3.4935746
Policy mu Min                -3.1222963
Policy log std Mean          -0.9016492
Policy log std Std           0.4722984
Policy log std Max           -0.10653198
Policy log std Min           -3.4479613
Z mean eval                  3.1716979
Z variance eval              0.027419955
total_rewards                [11061.31263808 11283.31862273 11041.99006735 11284.84141172
 11239.50090458 11301.9849905  11083.10059421 11070.02753715
 11210.98177214  2435.66359401]
total_rewards_mean           10301.27221324733
total_rewards_std            2623.6893459972002
total_rewards_max            11301.984990503415
total_rewards_min            2435.663594010408
Number of train steps total  796000
Number of env steps total    997000
Number of rollouts total     0
Train Time (s)               112.71493878820911
(Previous) Eval Time (s)     22.37139496812597
Sample Time (s)              16.054515012539923
Epoch Time (s)               151.140848768875
Total Train Time (s)         30527.67846985953
Epoch                        198
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:05:06.968511 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #198 | Epoch Duration: 151.25958156585693
2020-01-13 17:05:06.968733 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #198 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.172249
Z variance train             0.027442634
KL Divergence                42.693443
KL Loss                      4.2693443
QF Loss                      3762.8794
VF Loss                      156.47385
Policy Loss                  -4652.842
Q Predictions Mean           4658.1987
Q Predictions Std            604.2211
Q Predictions Max            5468.3315
Q Predictions Min            1197.9304
V Predictions Mean           4656.417
V Predictions Std            598.16003
V Predictions Max            5435.5415
V Predictions Min            1190.8423
Log Pis Mean                 5.60933
Log Pis Std                  3.9821887
Log Pis Max                  15.954332
Log Pis Min                  -6.1227484
Policy mu Mean               -0.11428984
Policy mu Std                1.4197574
Policy mu Max                3.1290169
Policy mu Min                -2.858443
Policy log std Mean          -0.9098223
Policy log std Std           0.5021496
Policy log std Max           -0.012917638
Policy log std Min           -3.5306368
Z mean eval                  3.1809292
Z variance eval              0.0119541045
total_rewards                [11064.17693037 11299.6053889  11307.56792681 11528.67531514
 11268.67731169 11143.23887644 11337.07297157 11466.5414716
 11570.79956019 11496.34352034]
total_rewards_mean           11348.269927304296
total_rewards_std            158.4964661313205
total_rewards_max            11570.799560185304
total_rewards_min            11064.176930365971
Number of train steps total  800000
Number of env steps total    1002000
Number of rollouts total     0
Train Time (s)               112.89084595674649
(Previous) Eval Time (s)     22.489828804973513
Sample Time (s)              16.024505896493793
Epoch Time (s)               151.4051806582138
Total Train Time (s)         30679.20439989725
Epoch                        199
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:07:38.496335 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #199 | Epoch Duration: 151.52745389938354
2020-01-13 17:07:38.496518 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #199 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1802704
Z variance train             0.011941535
KL Divergence                44.94932
KL Loss                      4.494932
QF Loss                      437.30035
VF Loss                      104.44167
Policy Loss                  -4598.3364
Q Predictions Mean           4597.95
Q Predictions Std            584.3218
Q Predictions Max            5428.0547
Q Predictions Min            1156.437
V Predictions Mean           4603.385
V Predictions Std            579.6717
V Predictions Max            5427.24
V Predictions Min            1180.266
Log Pis Mean                 6.0632057
Log Pis Std                  3.8176305
Log Pis Max                  14.91358
Log Pis Min                  -3.8964317
Policy mu Mean               -0.12111386
Policy mu Std                1.4516951
Policy mu Max                3.1132393
Policy mu Min                -3.0358167
Policy log std Mean          -0.93383884
Policy log std Std           0.5240847
Policy log std Max           -0.21654332
Policy log std Min           -3.5664024
Z mean eval                  3.216811
Z variance eval              0.008064159
total_rewards                [10508.91173783 10732.44321682 10909.87926682 10693.56338633
 10760.59534086 10796.69067861 11070.07788669 11093.52363214
 11080.48743955 10690.47552665]
total_rewards_mean           10833.664811229515
total_rewards_std            187.80201981351345
total_rewards_max            11093.523632136623
total_rewards_min            10508.911737833145
Number of train steps total  804000
Number of env steps total    1007000
Number of rollouts total     0
Train Time (s)               109.01988426595926
(Previous) Eval Time (s)     22.611842647194862
Sample Time (s)              16.120253294706345
Epoch Time (s)               147.75198020786047
Total Train Time (s)         30826.788102637976
Epoch                        200
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:10:06.081638 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #200 | Epoch Duration: 147.58499360084534
2020-01-13 17:10:06.081794 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #200 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2184982
Z variance train             0.0080496585
KL Divergence                46.80474
KL Loss                      4.6804743
QF Loss                      469.95502
VF Loss                      671.12726
Policy Loss                  -4505.676
Q Predictions Mean           4503.035
Q Predictions Std            623.89185
Q Predictions Max            5430.212
Q Predictions Min            1168.6503
V Predictions Mean           4489.0024
V Predictions Std            616.4378
V Predictions Max            5406.264
V Predictions Min            1219.1622
Log Pis Mean                 5.3719053
Log Pis Std                  3.8545172
Log Pis Max                  17.21276
Log Pis Min                  -7.4803224
Policy mu Mean               -0.05414568
Policy mu Std                1.3760743
Policy mu Max                3.0873919
Policy mu Min                -2.9986057
Policy log std Mean          -0.9185386
Policy log std Std           0.49001244
Policy log std Max           -0.09524655
Policy log std Min           -3.1564498
Z mean eval                  3.1741064
Z variance eval              0.0071941353
total_rewards                [11017.74104015 11015.57503003 11390.81308926 11124.56392145
 11284.87937232 11522.45888943 11425.89285876 11359.18943936
 11374.60581668 11397.09585832]
total_rewards_mean           11291.281531575753
total_rewards_std            168.19483581467824
total_rewards_max            11522.458889430358
total_rewards_min            11015.575030034526
Number of train steps total  808000
Number of env steps total    1012000
Number of rollouts total     0
Train Time (s)               117.11825384292752
(Previous) Eval Time (s)     22.444583744741976
Sample Time (s)              16.642499186098576
Epoch Time (s)               156.20533677376807
Total Train Time (s)         30983.132178343367
Epoch                        201
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:12:42.427470 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #201 | Epoch Duration: 156.3455367088318
2020-01-13 17:12:42.427658 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #201 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1734645
Z variance train             0.007201828
KL Divergence                46.956665
KL Loss                      4.695667
QF Loss                      498.29373
VF Loss                      79.71998
Policy Loss                  -4545.797
Q Predictions Mean           4549.6494
Q Predictions Std            537.69745
Q Predictions Max            5323.983
Q Predictions Min            3109.85
V Predictions Mean           4550.1035
V Predictions Std            536.0977
V Predictions Max            5303.8545
V Predictions Min            3123.8328
Log Pis Mean                 5.8709354
Log Pis Std                  4.0289254
Log Pis Max                  16.809488
Log Pis Min                  -5.53022
Policy mu Mean               -0.09367428
Policy mu Std                1.4219114
Policy mu Max                3.392682
Policy mu Min                -2.8015099
Policy log std Mean          -0.9085274
Policy log std Std           0.48881587
Policy log std Max           -0.11593163
Policy log std Min           -3.4409742
Z mean eval                  3.181045
Z variance eval              0.011410954
total_rewards                [11010.29925672 11251.72296938 10363.44385911  2888.15555543
 11418.72111836 11363.56184468 11155.92296439 11383.52825629
 11234.32048406 11402.29411924]
total_rewards_mean           10347.197042765594
total_rewards_std            2504.0933421770496
total_rewards_max            11418.721118362797
total_rewards_min            2888.1555554303536
Number of train steps total  812000
Number of env steps total    1017000
Number of rollouts total     0
Train Time (s)               116.88486800715327
(Previous) Eval Time (s)     22.584494759794325
Sample Time (s)              16.32916983915493
Epoch Time (s)               155.79853260610253
Total Train Time (s)         31138.80376034975
Epoch                        202
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:15:18.104140 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #202 | Epoch Duration: 155.67630648612976
2020-01-13 17:15:18.104439 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #202 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1824014
Z variance train             0.011393527
KL Divergence                47.238358
KL Loss                      4.723836
QF Loss                      1924.4563
VF Loss                      204.37566
Policy Loss                  -4536.908
Q Predictions Mean           4540.062
Q Predictions Std            568.72144
Q Predictions Max            5326.6235
Q Predictions Min            1274.3662
V Predictions Mean           4529.9814
V Predictions Std            565.83307
V Predictions Max            5331.1387
V Predictions Min            1272.7743
Log Pis Mean                 5.4496403
Log Pis Std                  3.916804
Log Pis Max                  15.517514
Log Pis Min                  -5.9474945
Policy mu Mean               -0.17849292
Policy mu Std                1.3699417
Policy mu Max                3.2994735
Policy mu Min                -2.8392692
Policy log std Mean          -0.9131872
Policy log std Std           0.4941678
Policy log std Max           -0.027971148
Policy log std Min           -3.278367
Z mean eval                  3.1815217
Z variance eval              0.011273326
total_rewards                [11037.35413128 11168.19821146 11459.73816916 11706.07011708
 11589.36092327 10995.51713456 11745.82915666  3093.77198877
 11567.39842819 11254.68701835]
total_rewards_mean           10561.792527879627
total_rewards_std            2502.3628358346878
total_rewards_max            11745.829156662332
total_rewards_min            3093.7719887742583
Number of train steps total  816000
Number of env steps total    1022000
Number of rollouts total     0
Train Time (s)               117.79338932130486
(Previous) Eval Time (s)     22.46194859407842
Sample Time (s)              16.11391468066722
Epoch Time (s)               156.3692525960505
Total Train Time (s)         31295.305422863457
Epoch                        203
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:17:54.610502 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #203 | Epoch Duration: 156.50582003593445
2020-01-13 17:17:54.610789 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #203 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.181127
Z variance train             0.011279456
KL Divergence                46.69125
KL Loss                      4.669125
QF Loss                      322.82776
VF Loss                      50.9381
Policy Loss                  -4452.12
Q Predictions Mean           4456.8457
Q Predictions Std            539.26917
Q Predictions Max            5312.6064
Q Predictions Min            3206.6985
V Predictions Mean           4453.3496
V Predictions Std            535.6078
V Predictions Max            5313.3574
V Predictions Min            3195.369
Log Pis Mean                 5.61588
Log Pis Std                  4.037904
Log Pis Max                  15.759174
Log Pis Min                  -7.371564
Policy mu Mean               -0.09131377
Policy mu Std                1.4003803
Policy mu Max                3.1924107
Policy mu Min                -2.9688644
Policy log std Mean          -0.9332535
Policy log std Std           0.5049446
Policy log std Max           -0.25844967
Policy log std Min           -3.448322
Z mean eval                  3.1667476
Z variance eval              0.019045915
total_rewards                [11146.40783708 11251.24817151 11306.78189276 11394.98430959
 11207.42113382 11358.62140454 11509.71960216 11296.07831985
 11068.71092571 11239.09579958]
total_rewards_mean           11277.906939659382
total_rewards_std            119.73438830477775
total_rewards_max            11509.719602156702
total_rewards_min            11068.710925712125
Number of train steps total  820000
Number of env steps total    1027000
Number of rollouts total     0
Train Time (s)               119.66762737510726
(Previous) Eval Time (s)     22.598211794160306
Sample Time (s)              16.927305943332613
Epoch Time (s)               159.19314511260018
Total Train Time (s)         31454.953706998844
Epoch                        204
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:20:34.261977 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #204 | Epoch Duration: 159.65094923973083
2020-01-13 17:20:34.262274 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #204 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1682687
Z variance train             0.019118512
KL Divergence                45.261425
KL Loss                      4.5261426
QF Loss                      594.125
VF Loss                      251.60358
Policy Loss                  -4506.384
Q Predictions Mean           4509.556
Q Predictions Std            540.11865
Q Predictions Max            5432.676
Q Predictions Min            3238.135
V Predictions Mean           4495.068
V Predictions Std            535.64777
V Predictions Max            5404.7197
V Predictions Min            3226.399
Log Pis Mean                 6.038659
Log Pis Std                  4.0349445
Log Pis Max                  17.836073
Log Pis Min                  -4.8052235
Policy mu Mean               -0.16334172
Policy mu Std                1.4127951
Policy mu Max                3.0785527
Policy mu Min                -3.1125872
Policy log std Mean          -0.9497339
Policy log std Std           0.53010637
Policy log std Max           -0.24965504
Policy log std Min           -3.5872169
Z mean eval                  3.1439388
Z variance eval              0.022057319
total_rewards                [11058.8910636  10784.8054675  11321.70699586 11531.46758475
 11828.34752402 11315.75317273 11733.17573921 11317.50382304
 11426.15042339 11239.58897543]
total_rewards_mean           11355.739076954344
total_rewards_std            288.69520426443154
total_rewards_max            11828.3475240232
total_rewards_min            10784.805467502214
Number of train steps total  824000
Number of env steps total    1032000
Number of rollouts total     0
Train Time (s)               117.55831060186028
(Previous) Eval Time (s)     23.055698415264487
Sample Time (s)              15.701912615913898
Epoch Time (s)               156.31592163303867
Total Train Time (s)         31610.916307527106
Epoch                        205
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:23:10.227304 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #205 | Epoch Duration: 155.96479678153992
2020-01-13 17:23:10.227554 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #205 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1443706
Z variance train             0.02207477
KL Divergence                43.468643
KL Loss                      4.346864
QF Loss                      516.8472
VF Loss                      102.30164
Policy Loss                  -4568.1953
Q Predictions Mean           4569.2266
Q Predictions Std            527.7621
Q Predictions Max            5425.736
Q Predictions Min            3252.5447
V Predictions Mean           4562.4204
V Predictions Std            524.50214
V Predictions Max            5419.9233
V Predictions Min            3243.831
Log Pis Mean                 5.3407354
Log Pis Std                  3.9534688
Log Pis Max                  16.686375
Log Pis Min                  -6.118026
Policy mu Mean               -0.12532322
Policy mu Std                1.3563255
Policy mu Max                2.991022
Policy mu Min                -2.696293
Policy log std Mean          -0.9139556
Policy log std Std           0.5015765
Policy log std Max           -0.21896362
Policy log std Min           -3.3617449
Z mean eval                  3.1332135
Z variance eval              0.023263779
total_rewards                [10520.5327837  11228.31150682 11030.01271546 11088.68809942
 10791.29269709 11082.04058878 11001.63386452 11141.88181279
 10587.35857526 11082.24036001]
total_rewards_mean           10955.399300385307
total_rewards_std            227.6725742597005
total_rewards_max            11228.311506819395
total_rewards_min            10520.532783696437
Number of train steps total  828000
Number of env steps total    1037000
Number of rollouts total     0
Train Time (s)               115.02703526709229
(Previous) Eval Time (s)     22.70429300889373
Sample Time (s)              15.756149404682219
Epoch Time (s)               153.48747768066823
Total Train Time (s)         31763.983463868964
Epoch                        206
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:25:43.298291 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #206 | Epoch Duration: 153.07053232192993
2020-01-13 17:25:43.298542 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #206 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1344543
Z variance train             0.023253063
KL Divergence                42.97911
KL Loss                      4.297911
QF Loss                      557.8142
VF Loss                      134.04375
Policy Loss                  -4622.9116
Q Predictions Mean           4626.327
Q Predictions Std            529.6027
Q Predictions Max            5393.9077
Q Predictions Min            3235.4153
V Predictions Mean           4619.2266
V Predictions Std            526.94147
V Predictions Max            5385.9746
V Predictions Min            3227.097
Log Pis Mean                 6.161979
Log Pis Std                  3.9710186
Log Pis Max                  15.159537
Log Pis Min                  -2.7823696
Policy mu Mean               -0.10478181
Policy mu Std                1.4532878
Policy mu Max                3.3445747
Policy mu Min                -3.983631
Policy log std Mean          -0.91124916
Policy log std Std           0.50275475
Policy log std Max           -0.10311234
Policy log std Min           -3.6170392
Z mean eval                  3.143528
Z variance eval              0.031619303
total_rewards                [11456.68534688 11594.94026356 11456.50624781 11562.36662667
 11437.93068198 11439.71982765 11388.38675239 11383.46948288
 11428.50908966 11715.44601138]
total_rewards_mean           11486.396033085606
total_rewards_std            99.93575347296027
total_rewards_max            11715.446011375212
total_rewards_min            11383.469482877585
Number of train steps total  832000
Number of env steps total    1042000
Number of rollouts total     0
Train Time (s)               113.32784870499745
(Previous) Eval Time (s)     22.28707259800285
Sample Time (s)              15.829520730301738
Epoch Time (s)               151.44444203330204
Total Train Time (s)         31915.904259414878
Epoch                        207
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:28:15.219965 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #207 | Epoch Duration: 151.9212384223938
2020-01-13 17:28:15.220188 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #207 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1435199
Z variance train             0.031585585
KL Divergence                43.05895
KL Loss                      4.305895
QF Loss                      774.00964
VF Loss                      213.53043
Policy Loss                  -4498.8794
Q Predictions Mean           4504.9067
Q Predictions Std            535.1921
Q Predictions Max            5288.7256
Q Predictions Min            1466.1637
V Predictions Mean           4506.404
V Predictions Std            531.66
V Predictions Max            5298.9946
V Predictions Min            1502.9447
Log Pis Mean                 5.8335342
Log Pis Std                  3.8657622
Log Pis Max                  18.024897
Log Pis Min                  -4.158526
Policy mu Mean               -0.162569
Policy mu Std                1.4105529
Policy mu Max                2.9654858
Policy mu Min                -3.0995238
Policy log std Mean          -0.93772525
Policy log std Std           0.5036876
Policy log std Max           -0.25673258
Policy log std Min           -3.6132104
Z mean eval                  3.165266
Z variance eval              0.012826721
total_rewards                [11266.20513882 11708.80412628 11564.5106984  11176.60954518
 11664.48117894 11085.66553356 11331.19655941 11453.82957299
 11327.21997345  9455.90151171]
total_rewards_mean           11203.442383873615
total_rewards_std            613.6027220868419
total_rewards_max            11708.804126282279
total_rewards_min            9455.901511708023
Number of train steps total  836000
Number of env steps total    1047000
Number of rollouts total     0
Train Time (s)               114.88138859393075
(Previous) Eval Time (s)     22.76360093941912
Sample Time (s)              16.33970992732793
Epoch Time (s)               153.9846994606778
Total Train Time (s)         32069.143457066268
Epoch                        208
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:30:48.465327 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #208 | Epoch Duration: 153.24496269226074
2020-01-13 17:30:48.465618 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #208 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1635964
Z variance train             0.012865787
KL Divergence                45.650604
KL Loss                      4.5650606
QF Loss                      1013.1731
VF Loss                      141.61649
Policy Loss                  -4569.5723
Q Predictions Mean           4576.162
Q Predictions Std            548.14984
Q Predictions Max            5349.0586
Q Predictions Min            1658.5708
V Predictions Mean           4570.536
V Predictions Std            547.6032
V Predictions Max            5337.922
V Predictions Min            1555.698
Log Pis Mean                 6.293421
Log Pis Std                  4.0563884
Log Pis Max                  24.081547
Log Pis Min                  -3.6182866
Policy mu Mean               -0.15479174
Policy mu Std                1.4459829
Policy mu Max                3.8310266
Policy mu Min                -4.8316865
Policy log std Mean          -0.9133673
Policy log std Std           0.52387065
Policy log std Max           0.3271103
Policy log std Min           -3.4262195
Z mean eval                  3.1697896
Z variance eval              0.036263816
total_rewards                [11562.22856955 11856.59176395 11674.80082036  7389.75189067
 11835.0300241  11436.65846037 11598.62483626 11695.11713408
 11757.32025218 11798.62323851]
total_rewards_mean           11260.474699003571
total_rewards_std            1296.2039038133273
total_rewards_max            11856.59176394615
total_rewards_min            7389.751890674547
Number of train steps total  840000
Number of env steps total    1052000
Number of rollouts total     0
Train Time (s)               112.01465045334771
(Previous) Eval Time (s)     22.02355029527098
Sample Time (s)              15.811962553299963
Epoch Time (s)               149.85016330191866
Total Train Time (s)         32219.50591789512
Epoch                        209
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:33:18.830648 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #209 | Epoch Duration: 150.36479949951172
2020-01-13 17:33:18.830917 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #209 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1692555
Z variance train             0.036175862
KL Divergence                45.306526
KL Loss                      4.5306525
QF Loss                      438.7851
VF Loss                      200.25247
Policy Loss                  -4604.6875
Q Predictions Mean           4608.02
Q Predictions Std            501.24615
Q Predictions Max            5366.9307
Q Predictions Min            3197.6682
V Predictions Mean           4610.4824
V Predictions Std            502.61105
V Predictions Max            5371.9497
V Predictions Min            3200.171
Log Pis Mean                 5.842252
Log Pis Std                  3.9684362
Log Pis Max                  16.103426
Log Pis Min                  -4.4789886
Policy mu Mean               -0.13813984
Policy mu Std                1.4149622
Policy mu Max                2.9193416
Policy mu Min                -3.436511
Policy log std Mean          -0.9135416
Policy log std Std           0.5216544
Policy log std Max           -0.19744945
Policy log std Min           -3.6370182
Z mean eval                  3.1669831
Z variance eval              0.011637817
total_rewards                [11248.21269549 11353.94321978 11678.33673426 11698.07151003
 11432.65735295 11719.27975808 11675.90571359 11745.59806979
 11751.48642891 11564.45533418]
total_rewards_mean           11586.79468170668
total_rewards_std            170.79589172834054
total_rewards_max            11751.486428910095
total_rewards_min            11248.212695485488
Number of train steps total  844000
Number of env steps total    1057000
Number of rollouts total     0
Train Time (s)               119.33550692815334
(Previous) Eval Time (s)     22.537884407211095
Sample Time (s)              15.825368584133685
Epoch Time (s)               157.69875991949812
Total Train Time (s)         32377.396275466774
Epoch                        210
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:35:56.724421 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #210 | Epoch Duration: 157.89330291748047
2020-01-13 17:35:56.724636 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #210 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1631439
Z variance train             0.011763152
KL Divergence                47.721733
KL Loss                      4.7721734
QF Loss                      654.05206
VF Loss                      314.03195
Policy Loss                  -4539.8174
Q Predictions Mean           4542.7656
Q Predictions Std            524.7944
Q Predictions Max            5253.6885
Q Predictions Min            1507.868
V Predictions Mean           4551.9546
V Predictions Std            527.63074
V Predictions Max            5264.6196
V Predictions Min            1442.6761
Log Pis Mean                 6.0681534
Log Pis Std                  3.806948
Log Pis Max                  17.759008
Log Pis Min                  -3.6091728
Policy mu Mean               -0.13317113
Policy mu Std                1.403818
Policy mu Max                3.346556
Policy mu Min                -2.8712692
Policy log std Mean          -0.938032
Policy log std Std           0.51580137
Policy log std Max           0.13048577
Policy log std Min           -3.471846
Z mean eval                  3.160419
Z variance eval              0.0121107455
total_rewards                [11469.66281358 11779.59194483 11598.58099635 11739.5044789
 11854.58351465 11756.23974095 11868.94610704 11668.09463538
 11789.73761927 11885.63630854]
total_rewards_mean           11741.057815947435
total_rewards_std            123.90014648096918
total_rewards_max            11885.636308540184
total_rewards_min            11469.66281357935
Number of train steps total  848000
Number of env steps total    1062000
Number of rollouts total     0
Train Time (s)               112.48998293699697
(Previous) Eval Time (s)     22.732117069885135
Sample Time (s)              15.902337363455445
Epoch Time (s)               151.12443737033755
Total Train Time (s)         32528.47779634921
Epoch                        211
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:38:27.806126 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #211 | Epoch Duration: 151.08133506774902
2020-01-13 17:38:27.806322 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #211 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1613007
Z variance train             0.0121200625
KL Divergence                48.065147
KL Loss                      4.8065147
QF Loss                      314.67535
VF Loss                      126.49417
Policy Loss                  -4627.241
Q Predictions Mean           4626.299
Q Predictions Std            471.05313
Q Predictions Max            5347.6294
Q Predictions Min            3305.7434
V Predictions Mean           4621.5093
V Predictions Std            468.6509
V Predictions Max            5336.7744
V Predictions Min            3298.5828
Log Pis Mean                 5.441069
Log Pis Std                  3.7874815
Log Pis Max                  16.0913
Log Pis Min                  -2.3590522
Policy mu Mean               -0.14741983
Policy mu Std                1.3687319
Policy mu Max                3.2338533
Policy mu Min                -3.2759495
Policy log std Mean          -0.9362278
Policy log std Std           0.50332946
Policy log std Max           -0.18097079
Policy log std Min           -3.478085
Z mean eval                  3.1613584
Z variance eval              0.018041871
total_rewards                [11433.79364286 11432.02909775 11884.79848468 11624.2627707
 11800.71511555 11465.16447186 11596.18676836 11602.40517023
 11713.90298365 11419.53031793]
total_rewards_mean           11597.278882356633
total_rewards_std            155.4008654830728
total_rewards_max            11884.798484681174
total_rewards_min            11419.530317927032
Number of train steps total  852000
Number of env steps total    1067000
Number of rollouts total     0
Train Time (s)               112.82417709426954
(Previous) Eval Time (s)     22.688729378860444
Sample Time (s)              16.13465756876394
Epoch Time (s)               151.64756404189393
Total Train Time (s)         32680.505130795762
Epoch                        212
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:40:59.836569 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #212 | Epoch Duration: 152.03009033203125
2020-01-13 17:40:59.836747 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #212 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1603832
Z variance train             0.01806767
KL Divergence                47.52774
KL Loss                      4.7527742
QF Loss                      630.74817
VF Loss                      379.79657
Policy Loss                  -4579.066
Q Predictions Mean           4586.818
Q Predictions Std            528.2191
Q Predictions Max            5391.617
Q Predictions Min            3274.2515
V Predictions Mean           4595.363
V Predictions Std            527.8591
V Predictions Max            5398.3564
V Predictions Min            3277.4246
Log Pis Mean                 5.640463
Log Pis Std                  3.6989877
Log Pis Max                  17.40754
Log Pis Min                  -3.9251544
Policy mu Mean               -0.101175405
Policy mu Std                1.4013045
Policy mu Max                3.9798458
Policy mu Min                -3.2444308
Policy log std Mean          -0.90912455
Policy log std Std           0.49658227
Policy log std Max           0.3232386
Policy log std Min           -3.3894186
Z mean eval                  3.1584373
Z variance eval              0.015099947
total_rewards                [11599.01798828 11785.0810875  11889.1437324  11641.77933147
 11767.8050848  11922.49637675 11664.32459525 11795.14033606
 11974.9905418  11733.25217313]
total_rewards_mean           11777.303124742468
total_rewards_std            117.47149240325874
total_rewards_max            11974.990541798727
total_rewards_min            11599.0179882849
Number of train steps total  856000
Number of env steps total    1072000
Number of rollouts total     0
Train Time (s)               111.73501309007406
(Previous) Eval Time (s)     23.070945754647255
Sample Time (s)              15.899124913848937
Epoch Time (s)               150.70508375857025
Total Train Time (s)         32830.72102289973
Epoch                        213
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:43:30.054937 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #213 | Epoch Duration: 150.21802949905396
2020-01-13 17:43:30.055130 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #213 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.158111
Z variance train             0.015170338
KL Divergence                47.569473
KL Loss                      4.7569475
QF Loss                      462.4622
VF Loss                      101.06804
Policy Loss                  -4633.7153
Q Predictions Mean           4640.149
Q Predictions Std            480.6658
Q Predictions Max            5440.809
Q Predictions Min            3322.5767
V Predictions Mean           4637.665
V Predictions Std            478.21844
V Predictions Max            5441.698
V Predictions Min            3319.8542
Log Pis Mean                 6.4336395
Log Pis Std                  4.0051208
Log Pis Max                  15.597699
Log Pis Min                  -2.9122283
Policy mu Mean               -0.12495863
Policy mu Std                1.4709145
Policy mu Max                2.9464028
Policy mu Min                -2.8701682
Policy log std Mean          -0.9235034
Policy log std Std           0.52187747
Policy log std Max           -0.09268719
Policy log std Min           -3.6460204
Z mean eval                  3.156682
Z variance eval              0.027047714
total_rewards                [11341.55715925 11783.60517514 11868.04850356 11552.02743555
 11806.53473611 11393.08908438 11672.57302091 11900.05091187
 11759.04645175 11596.99992981]
total_rewards_mean           11667.353240832355
total_rewards_std            183.1287062438798
total_rewards_max            11900.050911874292
total_rewards_min            11341.557159245182
Number of train steps total  860000
Number of env steps total    1077000
Number of rollouts total     0
Train Time (s)               120.49931278731674
(Previous) Eval Time (s)     22.58358157798648
Sample Time (s)              16.376071359962225
Epoch Time (s)               159.45896572526544
Total Train Time (s)         32990.75636095228
Epoch                        214
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:46:10.091899 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #214 | Epoch Duration: 160.03662705421448
2020-01-13 17:46:10.092137 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #214 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.155241
Z variance train             0.027023654
KL Divergence                48.102757
KL Loss                      4.8102756
QF Loss                      368.42975
VF Loss                      70.14894
Policy Loss                  -4627.084
Q Predictions Mean           4628.8164
Q Predictions Std            470.343
Q Predictions Max            5392.5254
Q Predictions Min            3221.177
V Predictions Mean           4626.9995
V Predictions Std            467.85663
V Predictions Max            5357.4663
V Predictions Min            3231.1975
Log Pis Mean                 5.5997577
Log Pis Std                  3.8818953
Log Pis Max                  15.568979
Log Pis Min                  -5.8286934
Policy mu Mean               -0.09224597
Policy mu Std                1.4216145
Policy mu Max                3.0291524
Policy mu Min                -2.6870434
Policy log std Mean          -0.91109705
Policy log std Std           0.5059297
Policy log std Max           -0.017347693
Policy log std Min           -3.462462
Z mean eval                  3.1636276
Z variance eval              0.016171273
total_rewards                [ 3797.42480232 11975.55263634 11688.89168476 11697.3755664
 11606.06524424 11182.91926182 11738.51656937 11731.75360858
 11542.85709143 11186.04786271]
total_rewards_mean           10814.740432798008
total_rewards_std            2350.6900692872573
total_rewards_max            11975.552636335915
total_rewards_min            3797.4248023238015
Number of train steps total  864000
Number of env steps total    1082000
Number of rollouts total     0
Train Time (s)               117.07682247692719
(Previous) Eval Time (s)     23.160948435310274
Sample Time (s)              15.99404544616118
Epoch Time (s)               156.23181635839865
Total Train Time (s)         33146.66087906854
Epoch                        215
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:48:46.000018 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #215 | Epoch Duration: 155.90771412849426
2020-01-13 17:48:46.000360 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #215 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1641383
Z variance train             0.016109202
KL Divergence                49.17702
KL Loss                      4.917702
QF Loss                      652.1762
VF Loss                      149.61078
Policy Loss                  -4642.1934
Q Predictions Mean           4643.451
Q Predictions Std            506.2098
Q Predictions Max            5401.4385
Q Predictions Min            1985.6316
V Predictions Mean           4634.6133
V Predictions Std            505.79123
V Predictions Max            5377.931
V Predictions Min            1951.2406
Log Pis Mean                 5.8612804
Log Pis Std                  3.7632763
Log Pis Max                  18.543839
Log Pis Min                  -3.4675887
Policy mu Mean               -0.15875499
Policy mu Std                1.4146839
Policy mu Max                3.0231318
Policy mu Min                -2.826624
Policy log std Mean          -0.9171221
Policy log std Std           0.5067031
Policy log std Max           -0.1577748
Policy log std Min           -3.3783774
Z mean eval                  3.1627452
Z variance eval              0.017507775
total_rewards                [11489.17966451 11776.57293069 11701.23733886 11726.26294303
 11795.6762828  11663.8749585  11697.56557829 11511.72826885
 12000.05866722 11514.07540597]
total_rewards_mean           11687.623203871017
total_rewards_std            148.31801955393848
total_rewards_max            12000.05866722326
total_rewards_min            11489.179664514366
Number of train steps total  868000
Number of env steps total    1087000
Number of rollouts total     0
Train Time (s)               117.47212523361668
(Previous) Eval Time (s)     22.836523585021496
Sample Time (s)              15.949040957260877
Epoch Time (s)               156.25768977589905
Total Train Time (s)         33302.42495427281
Epoch                        216
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:51:21.766621 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #216 | Epoch Duration: 155.76605343818665
2020-01-13 17:51:21.766837 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #216 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1618214
Z variance train             0.017436054
KL Divergence                49.942978
KL Loss                      4.994298
QF Loss                      291.042
VF Loss                      127.634315
Policy Loss                  -4677.636
Q Predictions Mean           4682.4756
Q Predictions Std            470.90417
Q Predictions Max            5414.556
Q Predictions Min            3285.162
V Predictions Mean           4685.4062
V Predictions Std            471.0367
V Predictions Max            5421.5874
V Predictions Min            3287.449
Log Pis Mean                 5.688066
Log Pis Std                  3.7742221
Log Pis Max                  16.178661
Log Pis Min                  -3.7470322
Policy mu Mean               -0.16394034
Policy mu Std                1.3983104
Policy mu Max                2.9891577
Policy mu Min                -2.6999142
Policy log std Mean          -0.94078654
Policy log std Std           0.52088886
Policy log std Max           -0.04316342
Policy log std Min           -3.451992
Z mean eval                  3.1727633
Z variance eval              0.025631204
total_rewards                [11613.54930801 11948.22683475 12149.529748   11685.41318186
 11857.32163559 11772.37108336  7681.35413098 11671.8613762
 11697.83293184 11735.44974655]
total_rewards_mean           11381.290997713437
total_rewards_std            1242.4645357530512
total_rewards_max            12149.529748001552
total_rewards_min            7681.354130979586
Number of train steps total  872000
Number of env steps total    1092000
Number of rollouts total     0
Train Time (s)               107.79229742614552
(Previous) Eval Time (s)     22.344586277846247
Sample Time (s)              15.794076221529394
Epoch Time (s)               145.93095992552117
Total Train Time (s)         33448.890108361375
Epoch                        217
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:53:48.234574 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #217 | Epoch Duration: 146.46756958961487
2020-01-13 17:53:48.234782 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #217 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1727135
Z variance train             0.025664818
KL Divergence                50.019997
KL Loss                      5.002
QF Loss                      613.5714
VF Loss                      131.69603
Policy Loss                  -4624.6084
Q Predictions Mean           4630.3057
Q Predictions Std            503.52832
Q Predictions Max            5376.8096
Q Predictions Min            3259.0403
V Predictions Mean           4626.134
V Predictions Std            501.86935
V Predictions Max            5362.1016
V Predictions Min            3260.4524
Log Pis Mean                 6.1004844
Log Pis Std                  3.9190166
Log Pis Max                  17.211048
Log Pis Min                  -8.572052
Policy mu Mean               -0.15980475
Policy mu Std                1.4346468
Policy mu Max                3.0983195
Policy mu Min                -3.0530496
Policy log std Mean          -0.9188359
Policy log std Std           0.49881715
Policy log std Max           -0.19801867
Policy log std Min           -3.5947971
Z mean eval                  3.1459336
Z variance eval              0.021904986
total_rewards                [11685.88441758 11480.26952808 11914.60450185 11855.44344122
 11702.25354524 11887.33577491 11765.27946338 11462.32474207
 11524.53707921 11542.34571991]
total_rewards_mean           11682.027821345537
total_rewards_std            163.38950692448913
total_rewards_max            11914.604501849924
total_rewards_min            11462.32474207255
Number of train steps total  876000
Number of env steps total    1097000
Number of rollouts total     0
Train Time (s)               112.02356919785962
(Previous) Eval Time (s)     22.88092103973031
Sample Time (s)              15.643917633220553
Epoch Time (s)               150.54840787081048
Total Train Time (s)         33599.29834657954
Epoch                        218
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:56:18.644331 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #218 | Epoch Duration: 150.40938210487366
2020-01-13 17:56:18.644503 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #218 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1473563
Z variance train             0.021927869
KL Divergence                49.05535
KL Loss                      4.905535
QF Loss                      411.41995
VF Loss                      102.6545
Policy Loss                  -4673.2666
Q Predictions Mean           4671.852
Q Predictions Std            467.97244
Q Predictions Max            5421.2583
Q Predictions Min            3296.0647
V Predictions Mean           4672.912
V Predictions Std            465.7247
V Predictions Max            5421.257
V Predictions Min            3295.8477
Log Pis Mean                 5.6407976
Log Pis Std                  4.0198665
Log Pis Max                  17.191704
Log Pis Min                  -4.678878
Policy mu Mean               -0.17230971
Policy mu Std                1.3873383
Policy mu Max                2.9422972
Policy mu Min                -2.829379
Policy log std Mean          -0.92931145
Policy log std Std           0.51708585
Policy log std Max           0.25147063
Policy log std Min           -3.6044846
Z mean eval                  3.1372683
Z variance eval              0.021932116
total_rewards                [10865.68495588 10849.32142997  8269.90597082 10830.6082301
 10810.18887142 10456.14992606 10660.19720112 11192.22447624
 10725.88379461 10802.33723843]
total_rewards_mean           10546.250209463977
total_rewards_std            778.6135394744935
total_rewards_max            11192.224476236686
total_rewards_min            8269.905970819405
Number of train steps total  880000
Number of env steps total    1102000
Number of rollouts total     0
Train Time (s)               116.77971959812567
(Previous) Eval Time (s)     22.74159987922758
Sample Time (s)              16.389135526958853
Epoch Time (s)               155.9104550043121
Total Train Time (s)         33754.88521705521
Epoch                        219
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:58:54.237793 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #219 | Epoch Duration: 155.59314441680908
2020-01-13 17:58:54.237990 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #219 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1373365
Z variance train             0.021903396
KL Divergence                48.068176
KL Loss                      4.8068175
QF Loss                      1003.4281
VF Loss                      201.32933
Policy Loss                  -4641.586
Q Predictions Mean           4648.303
Q Predictions Std            496.21884
Q Predictions Max            5481.93
Q Predictions Min            3291.6768
V Predictions Mean           4648.457
V Predictions Std            496.23013
V Predictions Max            5468.9653
V Predictions Min            3285.1416
Log Pis Mean                 5.6024976
Log Pis Std                  3.8245008
Log Pis Max                  14.417736
Log Pis Min                  -5.4513474
Policy mu Mean               -0.08393368
Policy mu Std                1.4021213
Policy mu Max                3.2091448
Policy mu Min                -2.8397355
Policy log std Mean          -0.91209155
Policy log std Std           0.48802167
Policy log std Max           -0.20115805
Policy log std Min           -3.2947836
Z mean eval                  3.1191683
Z variance eval              0.023523057
total_rewards                [10735.51295879 11161.76555058 10503.01133066 11236.52783301
 11133.0924637  11098.6414369  10766.59025672 11013.06088154
 11187.56766819 11096.72656663]
total_rewards_mean           10993.249694671613
total_rewards_std            229.18138363349584
total_rewards_max            11236.527833007074
total_rewards_min            10503.01133065831
Number of train steps total  884000
Number of env steps total    1107000
Number of rollouts total     0
Train Time (s)               114.49016838893294
(Previous) Eval Time (s)     22.423987994901836
Sample Time (s)              15.828447507694364
Epoch Time (s)               152.74260389152914
Total Train Time (s)         33908.35980764544
Epoch                        220
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:01:27.710458 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #220 | Epoch Duration: 153.4723241329193
2020-01-13 18:01:27.710659 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #220 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1210797
Z variance train             0.02349693
KL Divergence                46.837994
KL Loss                      4.6837993
QF Loss                      792.5465
VF Loss                      309.94077
Policy Loss                  -4640.036
Q Predictions Mean           4648.4404
Q Predictions Std            506.28726
Q Predictions Max            5449.0625
Q Predictions Min            3279.4744
V Predictions Mean           4626.1914
V Predictions Std            503.1992
V Predictions Max            5412.96
V Predictions Min            3267.5522
Log Pis Mean                 5.712635
Log Pis Std                  3.5692942
Log Pis Max                  15.8809395
Log Pis Min                  -4.954184
Policy mu Mean               -0.13813992
Policy mu Std                1.3789241
Policy mu Max                2.937909
Policy mu Min                -3.8209417
Policy log std Mean          -0.94044113
Policy log std Std           0.5178984
Policy log std Max           0.44377172
Policy log std Min           -3.2967036
Z mean eval                  3.1036952
Z variance eval              0.0243156
total_rewards                [11312.5237414  11414.26198335 11686.18838847 12011.20771537
 11405.99504918 11816.01754138 11667.16577372 11911.03960885
 12023.0093584  11837.64405238]
total_rewards_mean           11708.505321249684
total_rewards_std            244.31483329169808
total_rewards_max            12023.009358396423
total_rewards_min            11312.523741404708
Number of train steps total  888000
Number of env steps total    1112000
Number of rollouts total     0
Train Time (s)               113.80529344128445
(Previous) Eval Time (s)     23.153372938279063
Sample Time (s)              16.006247312296182
Epoch Time (s)               152.9649136918597
Total Train Time (s)         34061.10719309887
Epoch                        221
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:04:00.466365 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #221 | Epoch Duration: 152.75552535057068
2020-01-13 18:04:00.466688 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #221 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1053708
Z variance train             0.024348939
KL Divergence                46.291794
KL Loss                      4.6291795
QF Loss                      369.549
VF Loss                      464.2419
Policy Loss                  -4618.244
Q Predictions Mean           4616.322
Q Predictions Std            498.07233
Q Predictions Max            5376.496
Q Predictions Min            3182.4314
V Predictions Mean           4598.2744
V Predictions Std            497.2835
V Predictions Max            5350.587
V Predictions Min            3199.6875
Log Pis Mean                 5.122466
Log Pis Std                  3.7699873
Log Pis Max                  16.003597
Log Pis Min                  -6.3666043
Policy mu Mean               -0.13164604
Policy mu Std                1.365158
Policy mu Max                3.0932558
Policy mu Min                -3.328745
Policy log std Mean          -0.90877455
Policy log std Std           0.46309614
Policy log std Max           0.07346606
Policy log std Min           -3.06286
Z mean eval                  3.1192806
Z variance eval              0.009507947
total_rewards                [11102.08535148 11285.61443664 10886.41047002 11174.63636513
 10961.20089866 10773.50287288 11786.31130401 11460.49686189
 11115.03024733 11507.61255097]
total_rewards_mean           11205.290135901687
total_rewards_std            294.61986914501574
total_rewards_max            11786.311304009674
total_rewards_min            10773.502872884603
Number of train steps total  892000
Number of env steps total    1117000
Number of rollouts total     0
Train Time (s)               111.33387523284182
(Previous) Eval Time (s)     22.943682341836393
Sample Time (s)              16.661651438567787
Epoch Time (s)               150.939209013246
Total Train Time (s)         34211.40343920607
Epoch                        222
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:06:30.764586 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #222 | Epoch Duration: 150.2976541519165
2020-01-13 18:06:30.764847 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #222 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1177516
Z variance train             0.009453917
KL Divergence                49.207047
KL Loss                      4.920705
QF Loss                      482.42487
VF Loss                      92.277084
Policy Loss                  -4647.0776
Q Predictions Mean           4644.573
Q Predictions Std            486.00064
Q Predictions Max            5297.1636
Q Predictions Min            3208.5195
V Predictions Mean           4648.2515
V Predictions Std            486.5543
V Predictions Max            5301.942
V Predictions Min            3215.1968
Log Pis Mean                 6.164075
Log Pis Std                  4.0209546
Log Pis Max                  15.589268
Log Pis Min                  -1.9752787
Policy mu Mean               -0.08685699
Policy mu Std                1.4568076
Policy mu Max                3.2135694
Policy mu Min                -3.265665
Policy log std Mean          -0.91276854
Policy log std Std           0.49353638
Policy log std Max           0.098454475
Policy log std Min           -3.2882996
Z mean eval                  3.1293168
Z variance eval              0.008756552
total_rewards                [11637.40268949 11885.48149507 11782.89611919 11977.84235936
 11712.58240306 11776.2977548  11892.30420626 11711.31633392
 11733.68832353 11715.38909017]
total_rewards_mean           11782.520077485751
total_rewards_std            99.37538845245547
total_rewards_max            11977.84235936204
total_rewards_min            11637.402689486296
Number of train steps total  896000
Number of env steps total    1122000
Number of rollouts total     0
Train Time (s)               113.06501041119918
(Previous) Eval Time (s)     22.301809255965054
Sample Time (s)              16.857642652932554
Epoch Time (s)               152.2244623200968
Total Train Time (s)         34364.17646150943
Epoch                        223
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:09:03.540722 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #223 | Epoch Duration: 152.7756724357605
2020-01-13 18:09:03.540958 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #223 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1297889
Z variance train             0.008727571
KL Divergence                49.75786
KL Loss                      4.9757857
QF Loss                      710.9237
VF Loss                      219.47382
Policy Loss                  -4740.2515
Q Predictions Mean           4743.639
Q Predictions Std            499.22617
Q Predictions Max            5477.476
Q Predictions Min            3283.9233
V Predictions Mean           4728.6143
V Predictions Std            495.33725
V Predictions Max            5454.5312
V Predictions Min            3271.258
Log Pis Mean                 5.5729427
Log Pis Std                  3.8016756
Log Pis Max                  14.142683
Log Pis Min                  -3.4565723
Policy mu Mean               -0.114545085
Policy mu Std                1.381223
Policy mu Max                3.221697
Policy mu Min                -3.2254198
Policy log std Mean          -0.92221326
Policy log std Std           0.5158684
Policy log std Max           -0.24486041
Policy log std Min           -3.4338217
Z mean eval                  3.1209342
Z variance eval              0.0049484577
total_rewards                [11827.28393559 11874.90385566 11753.22313393 11698.93273432
 12016.88932108 11665.7439853  11800.60110613 11720.94573749
 11831.12195832 11574.76028542]
total_rewards_mean           11776.440605324166
total_rewards_std            116.71517274683391
total_rewards_max            12016.889321077859
total_rewards_min            11574.76028541816
Number of train steps total  900000
Number of env steps total    1127000
Number of rollouts total     0
Train Time (s)               117.9608977609314
(Previous) Eval Time (s)     22.852726082783192
Sample Time (s)              16.148016607388854
Epoch Time (s)               156.96164045110345
Total Train Time (s)         34520.80639913492
Epoch                        224
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:11:40.175639 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #224 | Epoch Duration: 156.6344814300537
2020-01-13 18:11:40.175949 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #224 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1190596
Z variance train             0.004927549
KL Divergence                52.464844
KL Loss                      5.2464843
QF Loss                      233.5369
VF Loss                      196.85416
Policy Loss                  -4697.9277
Q Predictions Mean           4703.6943
Q Predictions Std            466.70148
Q Predictions Max            5476.4434
Q Predictions Min            3314.7998
V Predictions Mean           4708.628
V Predictions Std            467.06378
V Predictions Max            5481.289
V Predictions Min            3321.5493
Log Pis Mean                 5.654475
Log Pis Std                  4.12465
Log Pis Max                  14.75737
Log Pis Min                  -4.6282578
Policy mu Mean               -0.10020567
Policy mu Std                1.3975382
Policy mu Max                3.1138406
Policy mu Min                -2.9558356
Policy log std Mean          -0.91565657
Policy log std Std           0.5176684
Policy log std Max           -0.24981457
Policy log std Min           -3.5178187
Z mean eval                  3.130408
Z variance eval              0.0033869296
total_rewards                [11473.22845512 11662.19643657 11437.51764368 11451.17386565
 11751.35980233 11841.68921415 11672.13838307 11576.6432453
 11636.92689831 11464.28381723]
total_rewards_mean           11596.715776141598
total_rewards_std            132.37700812965608
total_rewards_max            11841.689214148879
total_rewards_min            11437.517643679248
Number of train steps total  904000
Number of env steps total    1132000
Number of rollouts total     0
Train Time (s)               115.60656741214916
(Previous) Eval Time (s)     22.525275555904955
Sample Time (s)              16.196118493098766
Epoch Time (s)               154.32796146115288
Total Train Time (s)         34675.44222580688
Epoch                        225
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:14:14.814815 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #225 | Epoch Duration: 154.63863611221313
2020-01-13 18:14:14.815090 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #225 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1263635
Z variance train             0.0033919127
KL Divergence                52.614822
KL Loss                      5.2614822
QF Loss                      687.7849
VF Loss                      907.68994
Policy Loss                  -4680.041
Q Predictions Mean           4686.5957
Q Predictions Std            523.0038
Q Predictions Max            5501.4175
Q Predictions Min            3282.8477
V Predictions Mean           4706.995
V Predictions Std            522.03625
V Predictions Max            5545.1646
V Predictions Min            3308.2434
Log Pis Mean                 5.8735404
Log Pis Std                  4.133458
Log Pis Max                  17.800571
Log Pis Min                  -5.861
Policy mu Mean               -0.10471753
Policy mu Std                1.4165531
Policy mu Max                3.0998735
Policy mu Min                -2.8379931
Policy log std Mean          -0.92546505
Policy log std Std           0.501871
Policy log std Max           -0.18570566
Policy log std Min           -3.537303
Z mean eval                  3.1235397
Z variance eval              0.019639015
total_rewards                [11758.92397663 11747.09711019 11807.42796142 11635.03921135
 11620.25745082 11771.94758658 11721.71832298 11515.71500744
 11931.29399824 11796.26959418]
total_rewards_mean           11730.569021981744
total_rewards_std            109.92675493301941
total_rewards_max            11931.293998240568
total_rewards_min            11515.715007444907
Number of train steps total  908000
Number of env steps total    1137000
Number of rollouts total     0
Train Time (s)               116.61165863787755
(Previous) Eval Time (s)     22.83565246220678
Sample Time (s)              17.14305566996336
Epoch Time (s)               156.5903667700477
Total Train Time (s)         34831.89187339321
Epoch                        226
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:16:51.269323 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #226 | Epoch Duration: 156.45401310920715
2020-01-13 18:16:51.269594 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #226 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1259568
Z variance train             0.019609883
KL Divergence                50.84671
KL Loss                      5.084671
QF Loss                      316.97253
VF Loss                      181.42702
Policy Loss                  -4652.007
Q Predictions Mean           4651.7866
Q Predictions Std            499.97382
Q Predictions Max            5499.4546
Q Predictions Min            3338.9434
V Predictions Mean           4646.1187
V Predictions Std            497.64697
V Predictions Max            5493.779
V Predictions Min            3342.103
Log Pis Mean                 5.804238
Log Pis Std                  4.167038
Log Pis Max                  16.909359
Log Pis Min                  -9.1567955
Policy mu Mean               -0.10462486
Policy mu Std                1.4220004
Policy mu Max                3.0697699
Policy mu Min                -2.8781703
Policy log std Mean          -0.92388505
Policy log std Std           0.5198001
Policy log std Max           0.077456355
Policy log std Min           -3.4929886
Z mean eval                  3.1067204
Z variance eval              0.021607686
total_rewards                [11572.62362283 11598.94468331 11873.52115449 11818.42724636
 11688.68695677 11647.4444523  11792.98838548 11770.50591387
 11585.269538   11664.72374094]
total_rewards_mean           11701.313569436337
total_rewards_std            100.73219704340931
total_rewards_max            11873.521154487293
total_rewards_min            11572.623622832118
Number of train steps total  912000
Number of env steps total    1142000
Number of rollouts total     0
Train Time (s)               121.32225683517754
(Previous) Eval Time (s)     22.699023684021086
Sample Time (s)              16.01704948907718
Epoch Time (s)               160.0383300082758
Total Train Time (s)         34992.04204656696
Epoch                        227
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:19:31.423203 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #227 | Epoch Duration: 160.15337562561035
2020-01-13 18:19:31.423527 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #227 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1077814
Z variance train             0.021624833
KL Divergence                48.88832
KL Loss                      4.888832
QF Loss                      361.03476
VF Loss                      106.14557
Policy Loss                  -4691.028
Q Predictions Mean           4696.1904
Q Predictions Std            511.24875
Q Predictions Max            5441.302
Q Predictions Min            3277.8398
V Predictions Mean           4687.9165
V Predictions Std            507.67084
V Predictions Max            5413.117
V Predictions Min            3279.1238
Log Pis Mean                 5.8502626
Log Pis Std                  3.6283166
Log Pis Max                  16.521454
Log Pis Min                  -2.872046
Policy mu Mean               -0.14711447
Policy mu Std                1.4017594
Policy mu Max                3.0238898
Policy mu Min                -2.973657
Policy log std Mean          -0.91831017
Policy log std Std           0.51696825
Policy log std Max           -0.12055442
Policy log std Min           -3.601145
Z mean eval                  3.0902562
Z variance eval              0.012319656
total_rewards                [10795.55398217 10988.36541704 10933.72730407 11167.71819274
 10881.08879505 10997.18597842 11072.62254327 11113.07031971
  6443.77363382 11250.68984274]
total_rewards_mean           10564.379600902696
total_rewards_std            1379.53088042628
total_rewards_max            11250.6898427391
total_rewards_min            6443.773633823452
Number of train steps total  916000
Number of env steps total    1147000
Number of rollouts total     0
Train Time (s)               118.03223413275555
(Previous) Eval Time (s)     22.81372951110825
Sample Time (s)              16.127333697397262
Epoch Time (s)               156.97329734126106
Total Train Time (s)         35148.749685388524
Epoch                        228
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:22:08.131601 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #228 | Epoch Duration: 156.70786547660828
2020-01-13 18:22:08.131829 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #228 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0895095
Z variance train             0.012337049
KL Divergence                50.69448
KL Loss                      5.069448
QF Loss                      747.8435
VF Loss                      170.25034
Policy Loss                  -4714.0693
Q Predictions Mean           4720.1367
Q Predictions Std            528.02325
Q Predictions Max            5473.4717
Q Predictions Min            3269.9128
V Predictions Mean           4717.0225
V Predictions Std            526.4181
V Predictions Max            5482.0947
V Predictions Min            3274.3386
Log Pis Mean                 5.5762672
Log Pis Std                  4.0653205
Log Pis Max                  17.13457
Log Pis Min                  -7.0992455
Policy mu Mean               -0.11174641
Policy mu Std                1.375923
Policy mu Max                3.2198136
Policy mu Min                -3.184254
Policy log std Mean          -0.9227291
Policy log std Std           0.48513907
Policy log std Max           -0.2551857
Policy log std Min           -3.0348866
Z mean eval                  3.0937824
Z variance eval              0.009238703
total_rewards                [ 7656.82638815 10926.36670112  7187.3784244  10815.46786543
 11771.03546449 11588.77222325 11528.54384825  9850.80021127
 11527.05393761 11718.91656536]
total_rewards_mean           10457.116162933491
total_rewards_std            1616.8157748177882
total_rewards_max            11771.035464489265
total_rewards_min            7187.378424404859
Number of train steps total  920000
Number of env steps total    1152000
Number of rollouts total     0
Train Time (s)               113.47171029169112
(Previous) Eval Time (s)     22.548060504253954
Sample Time (s)              16.45133540732786
Epoch Time (s)               152.47110620327294
Total Train Time (s)         35301.20489539299
Epoch                        229
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:24:40.592111 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #229 | Epoch Duration: 152.46010375022888
2020-01-13 18:24:40.592404 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #229 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.09423
Z variance train             0.009242238
KL Divergence                50.256645
KL Loss                      5.025665
QF Loss                      321.32495
VF Loss                      148.52519
Policy Loss                  -4735.9004
Q Predictions Mean           4740.052
Q Predictions Std            529.53296
Q Predictions Max            5573.007
Q Predictions Min            3271.2393
V Predictions Mean           4729.092
V Predictions Std            526.6297
V Predictions Max            5557.1143
V Predictions Min            3271.5332
Log Pis Mean                 5.7111864
Log Pis Std                  3.9116285
Log Pis Max                  14.967974
Log Pis Min                  -6.269712
Policy mu Mean               -0.07155585
Policy mu Std                1.3991103
Policy mu Max                2.9766839
Policy mu Min                -2.9005291
Policy log std Mean          -0.9153616
Policy log std Std           0.5069724
Policy log std Max           -0.1390171
Policy log std Min           -3.465909
Z mean eval                  3.0855937
Z variance eval              0.023345146
total_rewards                [11500.81206133 11876.63738633 11097.07877813 11846.05676156
 11732.37854484 11634.26914123 11630.21461887 11442.05876912
 11754.80742683 11711.20512103]
total_rewards_mean           11622.551860928494
total_rewards_std            218.09242050513288
total_rewards_max            11876.637386329312
total_rewards_min            11097.078778134139
Number of train steps total  924000
Number of env steps total    1157000
Number of rollouts total     0
Train Time (s)               122.27319066505879
(Previous) Eval Time (s)     22.53674123901874
Sample Time (s)              17.208861040417105
Epoch Time (s)               162.01879294449463
Total Train Time (s)         35464.18581700558
Epoch                        230
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:27:23.577216 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #230 | Epoch Duration: 162.98458456993103
2020-01-13 18:27:23.577482 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #230 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.085914
Z variance train             0.023410682
KL Divergence                49.180935
KL Loss                      4.9180937
QF Loss                      1841.8679
VF Loss                      149.62428
Policy Loss                  -4712.0107
Q Predictions Mean           4718.9385
Q Predictions Std            535.3246
Q Predictions Max            5504.549
Q Predictions Min            3328.6243
V Predictions Mean           4705.1704
V Predictions Std            532.00385
V Predictions Max            5484.8926
V Predictions Min            3310.5732
Log Pis Mean                 5.803108
Log Pis Std                  3.9478815
Log Pis Max                  15.539767
Log Pis Min                  -3.4935768
Policy mu Mean               -0.11574002
Policy mu Std                1.3967085
Policy mu Max                2.9894514
Policy mu Min                -2.7370303
Policy log std Mean          -0.915912
Policy log std Std           0.52499986
Policy log std Max           0.031733274
Policy log std Min           -3.6579962
Z mean eval                  3.0709035
Z variance eval              0.020393988
total_rewards                [11423.2708992  12062.63970813 11885.23407106 11651.76104173
 11853.40521076 11719.38480254  3918.95497517 11964.01222184
 10356.04532879 10685.26683263]
total_rewards_mean           10751.997509185268
total_rewards_std            2339.48303275659
total_rewards_max            12062.63970813304
total_rewards_min            3918.9549751727573
Number of train steps total  928000
Number of env steps total    1162000
Number of rollouts total     0
Train Time (s)               116.08066045213491
(Previous) Eval Time (s)     23.502221278846264
Sample Time (s)              15.937283624894917
Epoch Time (s)               155.5201653558761
Total Train Time (s)         35619.271604510024
Epoch                        231
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:29:58.665880 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #231 | Epoch Duration: 155.08820295333862
2020-01-13 18:29:58.666080 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #231 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0727112
Z variance train             0.02040997
KL Divergence                47.624905
KL Loss                      4.7624907
QF Loss                      541.3756
VF Loss                      225.68253
Policy Loss                  -4647.255
Q Predictions Mean           4645.082
Q Predictions Std            527.39996
Q Predictions Max            5369.1445
Q Predictions Min            3259.354
V Predictions Mean           4640.179
V Predictions Std            526.7566
V Predictions Max            5378.9814
V Predictions Min            3269.1936
Log Pis Mean                 5.918812
Log Pis Std                  3.8793921
Log Pis Max                  16.673037
Log Pis Min                  -2.588678
Policy mu Mean               -0.15983795
Policy mu Std                1.4034888
Policy mu Max                4.187507
Policy mu Min                -3.1765978
Policy log std Mean          -0.9163857
Policy log std Std           0.5041656
Policy log std Max           0.13533092
Policy log std Min           -3.322445
Z mean eval                  3.0727458
Z variance eval              0.01445957
total_rewards                [11503.32333087 11877.53740805 11591.43360447 11716.79013112
 11849.42182216 11597.63059419 11498.46931511 11697.38455793
 11737.93030556 11336.15533305]
total_rewards_mean           11640.607640250535
total_rewards_std            159.4505483310451
total_rewards_max            11877.53740804791
total_rewards_min            11336.15533305238
Number of train steps total  932000
Number of env steps total    1167000
Number of rollouts total     0
Train Time (s)               115.94861743412912
(Previous) Eval Time (s)     23.0699669145979
Sample Time (s)              16.475747728720307
Epoch Time (s)               155.49433207744732
Total Train Time (s)         35774.57541073812
Epoch                        232
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:32:33.971058 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #232 | Epoch Duration: 155.30481481552124
2020-01-13 18:32:33.971239 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #232 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.073398
Z variance train             0.014477156
KL Divergence                48.480858
KL Loss                      4.848086
QF Loss                      351.71387
VF Loss                      204.37234
Policy Loss                  -4725.658
Q Predictions Mean           4732.658
Q Predictions Std            534.42444
Q Predictions Max            5505.598
Q Predictions Min            3283.738
V Predictions Mean           4733.986
V Predictions Std            531.9436
V Predictions Max            5500.6533
V Predictions Min            3293.3906
Log Pis Mean                 5.832316
Log Pis Std                  4.030195
Log Pis Max                  16.994625
Log Pis Min                  -4.4222064
Policy mu Mean               -0.124212205
Policy mu Std                1.3891522
Policy mu Max                2.9226727
Policy mu Min                -3.1175568
Policy log std Mean          -0.91624266
Policy log std Std           0.52714115
Policy log std Max           -0.16691378
Policy log std Min           -3.34574
Z mean eval                  3.0444145
Z variance eval              0.052334487
total_rewards                [11540.63973081 11155.49053666 11113.64236089 11794.38807913
 11664.02432201 11476.2057788  11816.27462162 11425.99623271
 11338.09324576 11471.07513433]
total_rewards_mean           11479.583004272774
total_rewards_std            226.30359460065375
total_rewards_max            11816.274621621578
total_rewards_min            11113.642360893478
Number of train steps total  936000
Number of env steps total    1172000
Number of rollouts total     0
Train Time (s)               114.2730819657445
(Previous) Eval Time (s)     22.880133801605552
Sample Time (s)              16.238636980764568
Epoch Time (s)               153.39185274811462
Total Train Time (s)         35929.0883985064
Epoch                        233
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:35:08.488205 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #233 | Epoch Duration: 154.51680994033813
2020-01-13 18:35:08.488421 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #233 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0455613
Z variance train             0.05226896
KL Divergence                44.66185
KL Loss                      4.466185
QF Loss                      478.21274
VF Loss                      102.422455
Policy Loss                  -4791.961
Q Predictions Mean           4795.7764
Q Predictions Std            526.727
Q Predictions Max            5509.7046
Q Predictions Min            3322.4873
V Predictions Mean           4788.789
V Predictions Std            525.6392
V Predictions Max            5497.998
V Predictions Min            3318.336
Log Pis Mean                 5.563214
Log Pis Std                  3.779064
Log Pis Max                  16.73165
Log Pis Min                  -10.370985
Policy mu Mean               -0.089888334
Policy mu Std                1.3929888
Policy mu Max                3.3402455
Policy mu Min                -3.5347095
Policy log std Mean          -0.9035368
Policy log std Std           0.47847062
Policy log std Max           -0.19310424
Policy log std Min           -3.3428314
Z mean eval                  3.0312476
Z variance eval              0.015780037
total_rewards                [10780.88007403 11648.57171669 11668.66426387 11516.37863549
 11729.36095747 11617.03994368 11372.39903072 11415.4781599
 11531.19235642 11165.81198729]
total_rewards_mean           11444.577712555036
total_rewards_std            271.9543994968
total_rewards_max            11729.360957466959
total_rewards_min            10780.88007402984
Number of train steps total  940000
Number of env steps total    1177000
Number of rollouts total     0
Train Time (s)               113.67401166679338
(Previous) Eval Time (s)     24.00477328011766
Sample Time (s)              15.8284454443492
Epoch Time (s)               153.50723039126024
Total Train Time (s)         36081.01776886778
Epoch                        234
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:37:40.418211 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #234 | Epoch Duration: 151.92962789535522
2020-01-13 18:37:40.418411 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #234 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0321975
Z variance train             0.015693475
KL Divergence                47.199028
KL Loss                      4.719903
QF Loss                      325.3986
VF Loss                      187.92606
Policy Loss                  -4681.459
Q Predictions Mean           4685.052
Q Predictions Std            517.33905
Q Predictions Max            5407.6045
Q Predictions Min            3225.5564
V Predictions Mean           4678.174
V Predictions Std            515.90015
V Predictions Max            5399.2256
V Predictions Min            3221.56
Log Pis Mean                 5.352415
Log Pis Std                  3.938966
Log Pis Max                  16.133396
Log Pis Min                  -5.3565855
Policy mu Mean               -0.11423265
Policy mu Std                1.3968508
Policy mu Max                2.8734057
Policy mu Min                -3.1553118
Policy log std Mean          -0.92673606
Policy log std Std           0.52741754
Policy log std Max           0.06506884
Policy log std Min           -3.2541819
Z mean eval                  3.0671139
Z variance eval              0.023642413
total_rewards                [11828.90467531 11514.5712495  11244.76479675 11581.52029369
 11680.0548883  11626.54409911 11761.33494715 11440.54473253
 11677.54919582 11611.21164878]
total_rewards_mean           11596.700052694412
total_rewards_std            158.375495300799
total_rewards_max            11828.904675312106
total_rewards_min            11244.764796749409
Number of train steps total  944000
Number of env steps total    1182000
Number of rollouts total     0
Train Time (s)               113.99536759220064
(Previous) Eval Time (s)     22.42690063500777
Sample Time (s)              16.498285070527345
Epoch Time (s)               152.92055329773575
Total Train Time (s)         36233.74829149153
Epoch                        235
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:40:13.150807 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #235 | Epoch Duration: 152.7322642803192
2020-01-13 18:40:13.150996 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #235 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0652068
Z variance train             0.02361682
KL Divergence                47.329514
KL Loss                      4.7329516
QF Loss                      455.81122
VF Loss                      498.11862
Policy Loss                  -4866.916
Q Predictions Mean           4869.2896
Q Predictions Std            491.96036
Q Predictions Max            5538.2593
Q Predictions Min            3336.5676
V Predictions Mean           4884.5684
V Predictions Std            491.30325
V Predictions Max            5538.007
V Predictions Min            3334.7712
Log Pis Mean                 5.581168
Log Pis Std                  3.7683806
Log Pis Max                  15.6069145
Log Pis Min                  -3.7714782
Policy mu Mean               -0.081575476
Policy mu Std                1.3754102
Policy mu Max                3.2163584
Policy mu Min                -2.6448462
Policy log std Mean          -0.92380184
Policy log std Std           0.5029014
Policy log std Max           -0.11963987
Policy log std Min           -3.5217366
Z mean eval                  3.050937
Z variance eval              0.009617646
total_rewards                [11693.34354836   801.66777089 11547.68326093  1710.71901611
  7845.26325606 11441.42722834 11730.51569821  5333.11058365
 11700.17433561 11655.34699365]
total_rewards_mean           8545.925169181228
total_rewards_std            4178.119259632065
total_rewards_max            11730.515698206988
total_rewards_min            801.6677708855087
Number of train steps total  948000
Number of env steps total    1187000
Number of rollouts total     0
Train Time (s)               119.05569662712514
(Previous) Eval Time (s)     22.238333051092923
Sample Time (s)              15.969278147444129
Epoch Time (s)               157.2633078256622
Total Train Time (s)         36391.10406416841
Epoch                        236
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:42:50.511662 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #236 | Epoch Duration: 157.3604907989502
2020-01-13 18:42:50.511919 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #236 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0480561
Z variance train             0.009598521
KL Divergence                48.48725
KL Loss                      4.8487253
QF Loss                      402.4173
VF Loss                      130.55374
Policy Loss                  -4772.8555
Q Predictions Mean           4776.338
Q Predictions Std            504.88126
Q Predictions Max            5474.9355
Q Predictions Min            3309.0796
V Predictions Mean           4780.7036
V Predictions Std            504.41013
V Predictions Max            5468.1436
V Predictions Min            3309.432
Log Pis Mean                 5.831856
Log Pis Std                  4.227644
Log Pis Max                  16.01088
Log Pis Min                  -4.6872816
Policy mu Mean               -0.1676035
Policy mu Std                1.4240175
Policy mu Max                3.0057456
Policy mu Min                -3.4160807
Policy log std Mean          -0.91227245
Policy log std Std           0.48991585
Policy log std Max           0.19894719
Policy log std Min           -3.5026753
Z mean eval                  3.0306773
Z variance eval              0.015780702
total_rewards                [11295.89274709  3397.00129075 11059.28432319 11539.00683611
 11845.03644954 10374.98172471  1595.65704274  9475.06149705
 11389.18113773 11508.29848694]
total_rewards_mean           9347.940153585088
total_rewards_std            3509.6415084792916
total_rewards_max            11845.036449536834
total_rewards_min            1595.657042743832
Number of train steps total  952000
Number of env steps total    1192000
Number of rollouts total     0
Train Time (s)               120.70205264305696
(Previous) Eval Time (s)     22.33521823491901
Sample Time (s)              15.634510359726846
Epoch Time (s)               158.67178123770282
Total Train Time (s)         36549.76824645884
Epoch                        237
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:45:29.176519 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #237 | Epoch Duration: 158.66438913345337
2020-01-13 18:45:29.176690 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #237 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0298796
Z variance train             0.015803467
KL Divergence                48.48604
KL Loss                      4.8486037
QF Loss                      529.1139
VF Loss                      330.88123
Policy Loss                  -4749.358
Q Predictions Mean           4755.3145
Q Predictions Std            529.5998
Q Predictions Max            5457.099
Q Predictions Min            1380.887
V Predictions Mean           4755.7617
V Predictions Std            523.6186
V Predictions Max            5457.059
V Predictions Min            1621.6122
Log Pis Mean                 5.7261157
Log Pis Std                  3.4705133
Log Pis Max                  15.817501
Log Pis Min                  -2.9315221
Policy mu Mean               -0.135026
Policy mu Std                1.3956926
Policy mu Max                3.12963
Policy mu Min                -3.7879257
Policy log std Mean          -0.89385813
Policy log std Std           0.46467125
Policy log std Max           -0.06805837
Policy log std Min           -3.3685875
Z mean eval                  3.040546
Z variance eval              0.015933173
total_rewards                [11368.67368077 12013.51769993 11906.15919484 11882.63704937
 11680.92363774 12083.3542811  11920.40615492 11942.47057788
 12045.43642428 12056.84304273]
total_rewards_mean           11890.042174354727
total_rewards_std            205.94335389355277
total_rewards_max            12083.354281099875
total_rewards_min            11368.673680765942
Number of train steps total  956000
Number of env steps total    1197000
Number of rollouts total     0
Train Time (s)               113.1718991859816
(Previous) Eval Time (s)     22.32756469817832
Sample Time (s)              16.318123889621347
Epoch Time (s)               151.81758777378127
Total Train Time (s)         36702.06393302651
Epoch                        238
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:48:01.473941 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #238 | Epoch Duration: 152.29711651802063
2020-01-13 18:48:01.474098 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #238 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0412621
Z variance train             0.01594602
KL Divergence                48.897984
KL Loss                      4.8897986
QF Loss                      417.95392
VF Loss                      213.27713
Policy Loss                  -4782.2617
Q Predictions Mean           4787.2324
Q Predictions Std            502.14886
Q Predictions Max            5432.2974
Q Predictions Min            3310.9856
V Predictions Mean           4788.634
V Predictions Std            500.51413
V Predictions Max            5460.5317
V Predictions Min            3311.4614
Log Pis Mean                 5.78442
Log Pis Std                  4.0358567
Log Pis Max                  14.567757
Log Pis Min                  -4.942425
Policy mu Mean               -0.12752962
Policy mu Std                1.3826005
Policy mu Max                2.8226545
Policy mu Min                -2.5980744
Policy log std Mean          -0.95297384
Policy log std Std           0.5307819
Policy log std Max           0.046245933
Policy log std Min           -3.4501724
Z mean eval                  3.0469558
Z variance eval              0.020113228
total_rewards                [11840.74694401 12165.35063068 11616.86829108 11811.26465029
 11971.04741347 12014.79308518 11713.09419442 11556.02955721
 11514.84562018 11683.61213306]
total_rewards_mean           11788.765251959232
total_rewards_std            201.21380551578662
total_rewards_max            12165.350630682893
total_rewards_min            11514.845620179709
Number of train steps total  960000
Number of env steps total    1202000
Number of rollouts total     0
Train Time (s)               115.67272030562162
(Previous) Eval Time (s)     22.806814742274582
Sample Time (s)              16.690464589279145
Epoch Time (s)               155.16999963717535
Total Train Time (s)         36856.54794985941
Epoch                        239
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:50:35.960169 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #239 | Epoch Duration: 154.48595237731934
2020-01-13 18:50:35.960438 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #239 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0457299
Z variance train             0.020050636
KL Divergence                50.101143
KL Loss                      5.010114
QF Loss                      678.64465
VF Loss                      95.28655
Policy Loss                  -4784.802
Q Predictions Mean           4785.1562
Q Predictions Std            487.7155
Q Predictions Max            5552.6143
Q Predictions Min            3320.9414
V Predictions Mean           4789.7686
V Predictions Std            487.2513
V Predictions Max            5546.333
V Predictions Min            3328.987
Log Pis Mean                 5.621744
Log Pis Std                  3.6006374
Log Pis Max                  13.747086
Log Pis Min                  -6.6229067
Policy mu Mean               -0.14258778
Policy mu Std                1.3833138
Policy mu Max                2.7681
Policy mu Min                -2.7299168
Policy log std Mean          -0.912111
Policy log std Std           0.5025045
Policy log std Max           -0.17988682
Policy log std Min           -3.3851984
Z mean eval                  3.036058
Z variance eval              0.016091581
total_rewards                [11732.9941898  10995.9255398  11555.99888242 11511.26451658
 11896.81753208 11627.19767756 11663.9661603  11713.32428971
 11880.36194067 11723.01916278]
total_rewards_mean           11630.086989169775
total_rewards_std            241.42538820263192
total_rewards_max            11896.817532080251
total_rewards_min            10995.925539797643
Number of train steps total  964000
Number of env steps total    1207000
Number of rollouts total     0
Train Time (s)               120.01057429192588
(Previous) Eval Time (s)     22.122470079921186
Sample Time (s)              17.15445404779166
Epoch Time (s)               159.28749841963872
Total Train Time (s)         37016.71568599902
Epoch                        240
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:53:16.132122 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #240 | Epoch Duration: 160.17154169082642
2020-01-13 18:53:16.132323 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #240 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0376012
Z variance train             0.016082395
KL Divergence                49.193424
KL Loss                      4.9193425
QF Loss                      476.88855
VF Loss                      110.567444
Policy Loss                  -4772.3486
Q Predictions Mean           4774.5825
Q Predictions Std            564.8529
Q Predictions Max            5532.0938
Q Predictions Min            836.5806
V Predictions Mean           4768.7344
V Predictions Std            565.0418
V Predictions Max            5514.3438
V Predictions Min            777.57465
Log Pis Mean                 5.685413
Log Pis Std                  3.76398
Log Pis Max                  16.308239
Log Pis Min                  -5.611594
Policy mu Mean               -0.112618364
Policy mu Std                1.3903998
Policy mu Max                3.1027071
Policy mu Min                -2.8737195
Policy log std Mean          -0.92362857
Policy log std Std           0.5165981
Policy log std Max           0.03696227
Policy log std Min           -3.342986
Z mean eval                  3.0746646
Z variance eval              0.014090801
total_rewards                [11690.0693135  12068.34227338 11802.85460041 11539.08663441
 12058.01379997 11668.18703533 11601.18375462 11745.63848566
 11629.86929877 11313.07894589]
total_rewards_mean           11711.632414193275
total_rewards_std            215.99846831066947
total_rewards_max            12068.342273377331
total_rewards_min            11313.078945887706
Number of train steps total  968000
Number of env steps total    1212000
Number of rollouts total     0
Train Time (s)               115.50480903498828
(Previous) Eval Time (s)     23.00620872620493
Sample Time (s)              16.77001488674432
Epoch Time (s)               155.28103264793754
Total Train Time (s)         37171.514088449534
Epoch                        241
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:55:50.933768 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #241 | Epoch Duration: 154.80129551887512
2020-01-13 18:55:50.934035 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #241 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0765224
Z variance train             0.014135967
KL Divergence                50.216038
KL Loss                      5.021604
QF Loss                      399.5394
VF Loss                      179.9732
Policy Loss                  -4717.098
Q Predictions Mean           4719.4756
Q Predictions Std            530.4381
Q Predictions Max            5440.9736
Q Predictions Min            3335.5256
V Predictions Mean           4707.039
V Predictions Std            527.2173
V Predictions Max            5432.109
V Predictions Min            3329.3035
Log Pis Mean                 5.602272
Log Pis Std                  3.9260826
Log Pis Max                  15.436677
Log Pis Min                  -2.66332
Policy mu Mean               -0.14998566
Policy mu Std                1.4219011
Policy mu Max                3.0695167
Policy mu Min                -2.9658897
Policy log std Mean          -0.9183182
Policy log std Std           0.5185125
Policy log std Max           -0.023302913
Policy log std Min           -3.3896127
Z mean eval                  3.0618002
Z variance eval              0.0059153996
total_rewards                [11633.40812406 11984.56676159 12030.29822523 11974.23027182
 11861.84042459 12051.37439586 12092.31580366 11779.39193714
 11980.02530178 11945.96408181]
total_rewards_mean           11933.341532753087
total_rewards_std            131.9138840288366
total_rewards_max            12092.315803658566
total_rewards_min            11633.408124060188
Number of train steps total  972000
Number of env steps total    1217000
Number of rollouts total     0
Train Time (s)               108.62737322691828
(Previous) Eval Time (s)     22.526161645073444
Sample Time (s)              16.648070743773133
Epoch Time (s)               147.80160561576486
Total Train Time (s)         37319.34012883948
Epoch                        242
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:58:18.761176 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #242 | Epoch Duration: 147.8269362449646
2020-01-13 18:58:18.761366 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #242 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0624623
Z variance train             0.0059164613
KL Divergence                51.953117
KL Loss                      5.195312
QF Loss                      375.6846
VF Loss                      206.59778
Policy Loss                  -4762.0117
Q Predictions Mean           4761.516
Q Predictions Std            507.5156
Q Predictions Max            5493.593
Q Predictions Min            3348.0088
V Predictions Mean           4750.168
V Predictions Std            506.04724
V Predictions Max            5496.805
V Predictions Min            3345.3748
Log Pis Mean                 5.7735653
Log Pis Std                  3.9609923
Log Pis Max                  19.754196
Log Pis Min                  -4.626883
Policy mu Mean               -0.12431268
Policy mu Std                1.3894376
Policy mu Max                3.1548786
Policy mu Min                -2.717161
Policy log std Mean          -0.92063636
Policy log std Std           0.48916215
Policy log std Max           0.10157168
Policy log std Min           -3.3885524
Z mean eval                  3.054401
Z variance eval              0.006072153
total_rewards                [11850.63804877 12043.50159524 11859.25609014 11737.551547
 11749.43218728 12004.46204554 12037.91332687 11906.71656544
 12061.41834989 11893.6362168 ]
total_rewards_mean           11914.452597297644
total_rewards_std            113.0197615619339
total_rewards_max            12061.41834989381
total_rewards_min            11737.551547004956
Number of train steps total  976000
Number of env steps total    1222000
Number of rollouts total     0
Train Time (s)               112.75559639977291
(Previous) Eval Time (s)     22.551208367105573
Sample Time (s)              16.1452156486921
Epoch Time (s)               151.4520204155706
Total Train Time (s)         37471.74176831357
Epoch                        243
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:00:51.167285 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #243 | Epoch Duration: 152.40574383735657
2020-01-13 19:00:51.167527 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #243 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0538268
Z variance train             0.006079658
KL Divergence                54.04934
KL Loss                      5.404934
QF Loss                      406.1502
VF Loss                      167.88422
Policy Loss                  -4766.1206
Q Predictions Mean           4771.582
Q Predictions Std            531.4785
Q Predictions Max            5583.4307
Q Predictions Min            3345.4014
V Predictions Mean           4771.0996
V Predictions Std            531.58405
V Predictions Max            5571.6875
V Predictions Min            3356.4226
Log Pis Mean                 6.054264
Log Pis Std                  4.036607
Log Pis Max                  17.373499
Log Pis Min                  -6.342875
Policy mu Mean               -0.14036392
Policy mu Std                1.4109613
Policy mu Max                3.1026711
Policy mu Min                -2.7165065
Policy log std Mean          -0.9210782
Policy log std Std           0.48904914
Policy log std Max           -0.18594658
Policy log std Min           -3.4786613
Z mean eval                  3.0663362
Z variance eval              0.011492045
total_rewards                [11341.14056831 11900.78228144 12160.39409033 11669.14354083
  6326.72303952 11991.60308786 11848.36301912 12042.66956544
 11655.87492084 11907.72644785]
total_rewards_mean           11284.442056154283
total_rewards_std            1667.237037133851
total_rewards_max            12160.394090334474
total_rewards_min            6326.723039524068
Number of train steps total  980000
Number of env steps total    1227000
Number of rollouts total     0
Train Time (s)               117.53511432604864
(Previous) Eval Time (s)     23.504638544283807
Sample Time (s)              16.362622279208153
Epoch Time (s)               157.4023751495406
Total Train Time (s)         37628.16408100352
Epoch                        244
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:03:27.591662 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #244 | Epoch Duration: 156.42395853996277
2020-01-13 19:03:27.591867 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #244 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0660756
Z variance train             0.011547337
KL Divergence                52.785885
KL Loss                      5.278589
QF Loss                      390.3012
VF Loss                      111.6925
Policy Loss                  -4780.998
Q Predictions Mean           4786.998
Q Predictions Std            557.9236
Q Predictions Max            5474.6475
Q Predictions Min            3294.6838
V Predictions Mean           4778.448
V Predictions Std            558.39594
V Predictions Max            5483.358
V Predictions Min            3287.8284
Log Pis Mean                 5.7052693
Log Pis Std                  3.9489346
Log Pis Max                  16.081501
Log Pis Min                  -6.039384
Policy mu Mean               -0.13319753
Policy mu Std                1.3999194
Policy mu Max                3.0032475
Policy mu Min                -2.7766645
Policy log std Mean          -0.9123509
Policy log std Std           0.5061814
Policy log std Max           0.020909905
Policy log std Min           -3.5736275
Z mean eval                  3.0663104
Z variance eval              0.0060977824
total_rewards                [11443.65621029 11740.8986894  12147.7996067  11419.78790207
 12010.23928962 11958.17034116 12173.40827823 12094.57797953
  4285.17757732 12056.35187545]
total_rewards_mean           11133.006774975995
total_rewards_std            2297.4094262315107
total_rewards_max            12173.408278233686
total_rewards_min            4285.177577320908
Number of train steps total  984000
Number of env steps total    1232000
Number of rollouts total     0
Train Time (s)               114.83894817577675
(Previous) Eval Time (s)     22.52593569410965
Sample Time (s)              16.011366485618055
Epoch Time (s)               153.37625035550445
Total Train Time (s)         37782.14042893564
Epoch                        245
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:06:01.569351 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #245 | Epoch Duration: 153.9773452281952
2020-01-13 19:06:01.569507 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #245 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0680962
Z variance train             0.006096906
KL Divergence                55.38627
KL Loss                      5.538627
QF Loss                      505.75452
VF Loss                      105.221794
Policy Loss                  -4807.645
Q Predictions Mean           4811.314
Q Predictions Std            528.8243
Q Predictions Max            5507.2974
Q Predictions Min            3371.1733
V Predictions Mean           4806.691
V Predictions Std            526.9639
V Predictions Max            5486.38
V Predictions Min            3363.4355
Log Pis Mean                 5.53535
Log Pis Std                  3.5460286
Log Pis Max                  13.942234
Log Pis Min                  -5.700391
Policy mu Mean               -0.062288594
Policy mu Std                1.3602102
Policy mu Max                2.8997223
Policy mu Min                -2.5484757
Policy log std Mean          -0.92808837
Policy log std Std           0.5104774
Policy log std Max           -0.021450043
Policy log std Min           -3.4469275
Z mean eval                  3.1066616
Z variance eval              0.008503741
total_rewards                [11565.49153233 12069.48984876 12037.75467866 11928.29190954
 11894.77861706 11817.70630486 12075.30373168 11893.99690237
 11792.95678991 11503.18151342]
total_rewards_mean           11857.895182859578
total_rewards_std            186.8586262080127
total_rewards_max            12075.303731682337
total_rewards_min            11503.181513424233
Number of train steps total  988000
Number of env steps total    1237000
Number of rollouts total     0
Train Time (s)               122.7604043232277
(Previous) Eval Time (s)     23.12675122730434
Sample Time (s)              16.691095490474254
Epoch Time (s)               162.5782510410063
Total Train Time (s)         37944.40527031943
Epoch                        246
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:08:43.838597 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #246 | Epoch Duration: 162.26895356178284
2020-01-13 19:08:43.838803 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #246 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1062808
Z variance train             0.008465679
KL Divergence                54.631058
KL Loss                      5.4631057
QF Loss                      431.08636
VF Loss                      113.728584
Policy Loss                  -4841.3184
Q Predictions Mean           4841.8657
Q Predictions Std            525.98035
Q Predictions Max            5564.731
Q Predictions Min            3320.9712
V Predictions Mean           4837.26
V Predictions Std            525.41034
V Predictions Max            5558.3867
V Predictions Min            3312.8042
Log Pis Mean                 5.6071405
Log Pis Std                  3.8775985
Log Pis Max                  15.712047
Log Pis Min                  -3.317552
Policy mu Mean               -0.09644193
Policy mu Std                1.4053655
Policy mu Max                3.0797298
Policy mu Min                -2.8068755
Policy log std Mean          -0.9078407
Policy log std Std           0.48041666
Policy log std Max           -0.17797482
Policy log std Min           -3.3556929
Z mean eval                  3.0830586
Z variance eval              0.005347893
total_rewards                [11699.66886499 11961.05946489 11829.18390335 11977.55877262
 11784.60720561 11970.49286881 11997.50679942 11968.80714673
 11702.99606393 11786.26080569]
total_rewards_mean           11867.81418960416
total_rewards_std            113.49261510170072
total_rewards_max            11997.506799415669
total_rewards_min            11699.668864991014
Number of train steps total  992000
Number of env steps total    1242000
Number of rollouts total     0
Train Time (s)               118.72216628910974
(Previous) Eval Time (s)     22.81713573122397
Sample Time (s)              16.042744536418468
Epoch Time (s)               157.58204655675218
Total Train Time (s)         38102.1435303553
Epoch                        247
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:11:21.581942 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #247 | Epoch Duration: 157.74291062355042
2020-01-13 19:11:21.582356 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #247 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0837905
Z variance train             0.005330768
KL Divergence                54.994263
KL Loss                      5.4994264
QF Loss                      426.0133
VF Loss                      69.01238
Policy Loss                  -4740.7393
Q Predictions Mean           4748.754
Q Predictions Std            570.1598
Q Predictions Max            5519.1123
Q Predictions Min            3324.7146
V Predictions Mean           4743.9287
V Predictions Std            568.2159
V Predictions Max            5491.0093
V Predictions Min            3324.1594
Log Pis Mean                 6.0373425
Log Pis Std                  3.8856063
Log Pis Max                  15.136109
Log Pis Min                  -4.711576
Policy mu Mean               -0.10840177
Policy mu Std                1.4188439
Policy mu Max                2.8679924
Policy mu Min                -3.4952226
Policy log std Mean          -0.9229347
Policy log std Std           0.5094016
Policy log std Max           -0.17514384
Policy log std Min           -3.6373005
Z mean eval                  3.0697968
Z variance eval              0.0148610445
total_rewards                [11069.25324977 11777.59459187 11897.4738434  11823.7804663
 11893.97691899 11753.61208273 11906.68471156 11716.43593713
 12151.47440991 11225.53002338]
total_rewards_mean           11721.581623504284
total_rewards_std            310.79947773659046
total_rewards_max            12151.474409909239
total_rewards_min            11069.25324976572
Number of train steps total  996000
Number of env steps total    1247000
Number of rollouts total     0
Train Time (s)               113.21531704533845
(Previous) Eval Time (s)     22.97767868405208
Sample Time (s)              17.063007853925228
Epoch Time (s)               153.25600358331576
Total Train Time (s)         38255.49420941202
Epoch                        248
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:13:54.933551 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #248 | Epoch Duration: 153.35094547271729
2020-01-13 19:13:54.933740 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #248 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0703034
Z variance train             0.01488514
KL Divergence                53.6267
KL Loss                      5.3626704
QF Loss                      344.5926
VF Loss                      149.5495
Policy Loss                  -4827.2227
Q Predictions Mean           4828.3037
Q Predictions Std            512.21216
Q Predictions Max            5500.6235
Q Predictions Min            3340.0444
V Predictions Mean           4825.34
V Predictions Std            510.4551
V Predictions Max            5500.8545
V Predictions Min            3352.7534
Log Pis Mean                 5.3933573
Log Pis Std                  3.7562048
Log Pis Max                  19.805067
Log Pis Min                  -6.081753
Policy mu Mean               -0.0744892
Policy mu Std                1.3925071
Policy mu Max                4.755774
Policy mu Min                -3.1319816
Policy log std Mean          -0.8901437
Policy log std Std           0.4783955
Policy log std Max           0.10323429
Policy log std Min           -3.3602743
Z mean eval                  3.0578141
Z variance eval              0.0140110105
total_rewards                [11519.82787807 11668.60374143 12121.84234858 11748.07077546
  5654.10052111 11832.67206157 12029.64166251 12002.21850887
 11736.78973679 11682.94485022]
total_rewards_mean           11199.671208460324
total_rewards_std            1856.9482192296518
total_rewards_max            12121.842348581213
total_rewards_min            5654.100521113263
Number of train steps total  1000000
Number of env steps total    1252000
Number of rollouts total     0
Train Time (s)               114.58529358915985
(Previous) Eval Time (s)     23.072291327174753
Sample Time (s)              16.39482567133382
Epoch Time (s)               154.05241058766842
Total Train Time (s)         38409.14327465417
Epoch                        249
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:16:28.584516 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #249 | Epoch Duration: 153.6506471633911
2020-01-13 19:16:28.584685 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #249 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0574517
Z variance train             0.014021041
KL Divergence                53.893738
KL Loss                      5.389374
QF Loss                      492.3462
VF Loss                      172.01457
Policy Loss                  -4819.576
Q Predictions Mean           4824.9224
Q Predictions Std            482.36783
Q Predictions Max            5505.705
Q Predictions Min            3384.03
V Predictions Mean           4815.588
V Predictions Std            479.59335
V Predictions Max            5489.2656
V Predictions Min            3372.427
Log Pis Mean                 5.9254913
Log Pis Std                  3.8086488
Log Pis Max                  16.110882
Log Pis Min                  -3.5757394
Policy mu Mean               -0.09525309
Policy mu Std                1.4219532
Policy mu Max                3.0229723
Policy mu Min                -3.1934338
Policy log std Mean          -0.9293569
Policy log std Std           0.50997955
Policy log std Max           0.05507171
Policy log std Min           -3.5034275
Z mean eval                  3.0704758
Z variance eval              0.022197539
total_rewards                [11559.27403809 11914.13715675 11554.76000617 11711.70865552
 11539.40185904 11703.25332407 11574.51272017 11487.03418944
 11861.06100314 11927.95295034]
total_rewards_mean           11683.309590272564
total_rewards_std            157.76932657394016
total_rewards_max            11927.95295033777
total_rewards_min            11487.034189435206
Number of train steps total  1004000
Number of env steps total    1257000
Number of rollouts total     0
Train Time (s)               117.48467925610021
(Previous) Eval Time (s)     22.670191324781626
Sample Time (s)              15.609787830151618
Epoch Time (s)               155.76465841103345
Total Train Time (s)         38564.73767022416
Epoch                        250
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:19:04.182126 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #250 | Epoch Duration: 155.5972716808319
2020-01-13 19:19:04.182319 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #250 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.067264
Z variance train             0.022058077
KL Divergence                52.033325
KL Loss                      5.2033324
QF Loss                      1115.763
VF Loss                      386.02762
Policy Loss                  -4836.455
Q Predictions Mean           4843.039
Q Predictions Std            502.34622
Q Predictions Max            5535.3276
Q Predictions Min            3344.1047
V Predictions Mean           4851.42
V Predictions Std            504.61075
V Predictions Max            5540.4243
V Predictions Min            3361.0984
Log Pis Mean                 5.4857726
Log Pis Std                  4.053033
Log Pis Max                  17.343334
Log Pis Min                  -4.8808627
Policy mu Mean               -0.11433443
Policy mu Std                1.3867674
Policy mu Max                3.8623967
Policy mu Min                -4.104882
Policy log std Mean          -0.91457766
Policy log std Std           0.4989911
Policy log std Max           0.1920532
Policy log std Min           -3.2505674
Z mean eval                  3.0855346
Z variance eval              0.019379605
total_rewards                [11543.19839325 11792.32957162 11990.56362523 11935.38159364
 12041.4745857  11787.80200126 12003.64624827 12105.88603207
 11902.68400684 11908.47754333]
total_rewards_mean           11901.144360119957
total_rewards_std            153.02122873712975
total_rewards_max            12105.886032065151
total_rewards_min            11543.198393249937
Number of train steps total  1008000
Number of env steps total    1262000
Number of rollouts total     0
Train Time (s)               114.73672274500132
(Previous) Eval Time (s)     22.50252593215555
Sample Time (s)              16.170200319960713
Epoch Time (s)               153.40944899711758
Total Train Time (s)         38718.21290784655
Epoch                        251
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:21:37.662144 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #251 | Epoch Duration: 153.4796483516693
2020-01-13 19:21:37.662442 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #251 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.08565
Z variance train             0.0193342
KL Divergence                51.87397
KL Loss                      5.187397
QF Loss                      616.1219
VF Loss                      233.60822
Policy Loss                  -4891.1465
Q Predictions Mean           4898.6245
Q Predictions Std            510.3783
Q Predictions Max            5542.9546
Q Predictions Min            3388.5444
V Predictions Mean           4896.6914
V Predictions Std            508.31403
V Predictions Max            5534.12
V Predictions Min            3404.6313
Log Pis Mean                 5.6908727
Log Pis Std                  3.9559004
Log Pis Max                  17.555532
Log Pis Min                  -4.5679436
Policy mu Mean               -0.11796219
Policy mu Std                1.4272314
Policy mu Max                3.1821718
Policy mu Min                -3.0155125
Policy log std Mean          -0.89928144
Policy log std Std           0.4873828
Policy log std Max           -0.13903236
Policy log std Min           -3.3334832
Z mean eval                  3.0897405
Z variance eval              0.016407914
total_rewards                [11842.88335935 11842.26517502 11868.72243697 11998.62542305
 11744.33286963 11235.91047888 11990.08850486  7488.72363201
 11258.84409444  8827.30878769]
total_rewards_mean           11009.770476189622
total_rewards_std            1479.1027446557302
total_rewards_max            11998.62542304645
total_rewards_min            7488.723632013661
Number of train steps total  1012000
Number of env steps total    1267000
Number of rollouts total     0
Train Time (s)               114.55808351701126
(Previous) Eval Time (s)     22.572427108883858
Sample Time (s)              16.589501133188605
Epoch Time (s)               153.72001175908372
Total Train Time (s)         38872.1099084178
Epoch                        252
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:24:11.561881 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #252 | Epoch Duration: 153.8992280960083
2020-01-13 19:24:11.562077 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #252 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0913336
Z variance train             0.016398575
KL Divergence                51.48004
KL Loss                      5.148004
QF Loss                      410.69214
VF Loss                      87.71347
Policy Loss                  -4794.4805
Q Predictions Mean           4801.3813
Q Predictions Std            575.40704
Q Predictions Max            5529.935
Q Predictions Min            3326.3992
V Predictions Mean           4800.3296
V Predictions Std            575.36615
V Predictions Max            5513.408
V Predictions Min            3314.489
Log Pis Mean                 4.9623456
Log Pis Std                  3.8627007
Log Pis Max                  14.222927
Log Pis Min                  -6.7402964
Policy mu Mean               -0.08136642
Policy mu Std                1.3360541
Policy mu Max                3.3015597
Policy mu Min                -2.6185646
Policy log std Mean          -0.92149717
Policy log std Std           0.50987893
Policy log std Max           0.25377834
Policy log std Min           -3.402852
Z mean eval                  3.0609274
Z variance eval              0.024996247
total_rewards                [12160.00344075 12176.66066    12189.10336063 12402.95826228
 12060.33090271 12157.51421624 12297.88361251 12106.73030167
 12104.57369873 11598.26466366]
total_rewards_mean           12125.402311917747
total_rewards_std            199.64759517665033
total_rewards_max            12402.958262275555
total_rewards_min            11598.26466366467
Number of train steps total  1016000
Number of env steps total    1272000
Number of rollouts total     0
Train Time (s)               115.93306898279116
(Previous) Eval Time (s)     22.751333143096417
Sample Time (s)              15.614245811942965
Epoch Time (s)               154.29864793783054
Total Train Time (s)         39026.0783793428
Epoch                        253
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:26:45.534367 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #253 | Epoch Duration: 153.97211980819702
2020-01-13 19:26:45.534633 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #253 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0599918
Z variance train             0.0249147
KL Divergence                50.141777
KL Loss                      5.014178
QF Loss                      361.61053
VF Loss                      213.99759
Policy Loss                  -4915.9106
Q Predictions Mean           4921.8906
Q Predictions Std            500.78015
Q Predictions Max            5625.638
Q Predictions Min            3389.0493
V Predictions Mean           4928.257
V Predictions Std            500.9361
V Predictions Max            5624.5273
V Predictions Min            3396.9788
Log Pis Mean                 5.4124517
Log Pis Std                  3.77399
Log Pis Max                  18.984169
Log Pis Min                  -2.6064925
Policy mu Mean               -0.024935678
Policy mu Std                1.3929538
Policy mu Max                3.2221236
Policy mu Min                -3.159401
Policy log std Mean          -0.9200938
Policy log std Std           0.5124454
Policy log std Max           -0.13225138
Policy log std Min           -3.3051085
Z mean eval                  3.0591636
Z variance eval              0.033606984
total_rewards                [11228.12670756 11593.34250289 10954.99754889 11680.61315188
 11331.14339374 11773.62479383 11488.01931687 11869.80275923
 11021.99376368 11525.38022389]
total_rewards_mean           11446.704416245122
total_rewards_std            292.1108208130001
total_rewards_max            11869.802759229362
total_rewards_min            10954.997548885729
Number of train steps total  1020000
Number of env steps total    1277000
Number of rollouts total     0
Train Time (s)               116.84893860574812
(Previous) Eval Time (s)     22.424519800115377
Sample Time (s)              15.896232089959085
Epoch Time (s)               155.16969049582258
Total Train Time (s)         39182.30726681976
Epoch                        254
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:29:21.766392 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #254 | Epoch Duration: 156.23155856132507
2020-01-13 19:29:21.766641 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #254 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0582118
Z variance train             0.033796825
KL Divergence                48.295364
KL Loss                      4.8295364
QF Loss                      2481.706
VF Loss                      848.6543
Policy Loss                  -4749.5117
Q Predictions Mean           4753.4434
Q Predictions Std            514.74164
Q Predictions Max            5515.083
Q Predictions Min            3303.4807
V Predictions Mean           4740.7715
V Predictions Std            508.89273
V Predictions Max            5520.5635
V Predictions Min            3303.3147
Log Pis Mean                 5.611583
Log Pis Std                  4.0674515
Log Pis Max                  18.947712
Log Pis Min                  -4.808712
Policy mu Mean               -0.14992106
Policy mu Std                1.3994265
Policy mu Max                2.9309068
Policy mu Min                -3.2801394
Policy log std Mean          -0.9085509
Policy log std Std           0.4737848
Policy log std Max           -0.029233456
Policy log std Min           -3.3705168
Z mean eval                  3.0762553
Z variance eval              0.04555248
total_rewards                [11625.48184823 11921.28128077 11953.87482694 12032.85449995
 11922.23139661 11841.00875183 11826.99906514 11781.13929218
 11606.27938388 11965.10214428]
total_rewards_mean           11847.625248980947
total_rewards_std            135.23168064075142
total_rewards_max            12032.854499949335
total_rewards_min            11606.279383879075
Number of train steps total  1024000
Number of env steps total    1282000
Number of rollouts total     0
Train Time (s)               118.06776860868558
(Previous) Eval Time (s)     23.486091528087854
Sample Time (s)              16.07223110459745
Epoch Time (s)               157.6260912413709
Total Train Time (s)         39339.54361595027
Epoch                        255
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:31:59.006828 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #255 | Epoch Duration: 157.24000144004822
2020-01-13 19:31:59.007075 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #255 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0763335
Z variance train             0.045506455
KL Divergence                48.480255
KL Loss                      4.848026
QF Loss                      564.16327
VF Loss                      89.04223
Policy Loss                  -4922.238
Q Predictions Mean           4924.7197
Q Predictions Std            486.43985
Q Predictions Max            5626.9062
Q Predictions Min            3428.9014
V Predictions Mean           4921.7666
V Predictions Std            485.86777
V Predictions Max            5623.19
V Predictions Min            3432.1477
Log Pis Mean                 5.7252655
Log Pis Std                  3.8640754
Log Pis Max                  18.150864
Log Pis Min                  -4.080983
Policy mu Mean               -0.097655
Policy mu Std                1.4003145
Policy mu Max                2.9599164
Policy mu Min                -3.3779056
Policy log std Mean          -0.92308444
Policy log std Std           0.50736797
Policy log std Max           -0.006128311
Policy log std Min           -3.3978634
Z mean eval                  3.0764217
Z variance eval              0.01599789
total_rewards                [11312.70484167 11926.35474747 12057.14051899 11920.41003876
 11808.65257823 11907.57430507 11930.58102404 12008.32581936
 11985.18739363 11857.21165449]
total_rewards_mean           11871.414292171943
total_rewards_std            198.16851401348276
total_rewards_max            12057.140518994322
total_rewards_min            11312.70484166761
Number of train steps total  1028000
Number of env steps total    1287000
Number of rollouts total     0
Train Time (s)               120.00310738198459
(Previous) Eval Time (s)     23.09972214093432
Sample Time (s)              15.806178477127105
Epoch Time (s)               158.90900800004601
Total Train Time (s)         39498.29849474318
Epoch                        256
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:34:37.767877 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #256 | Epoch Duration: 158.76057744026184
2020-01-13 19:34:37.768173 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #256 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0766232
Z variance train             0.015986288
KL Divergence                50.54518
KL Loss                      5.054518
QF Loss                      510.4758
VF Loss                      180.29712
Policy Loss                  -4888.873
Q Predictions Mean           4888.7446
Q Predictions Std            541.89014
Q Predictions Max            5619.9873
Q Predictions Min            3387.9436
V Predictions Mean           4881.488
V Predictions Std            541.60034
V Predictions Max            5592.7646
V Predictions Min            3384.9583
Log Pis Mean                 5.809704
Log Pis Std                  3.9395206
Log Pis Max                  20.937693
Log Pis Min                  -7.9740305
Policy mu Mean               -0.12215114
Policy mu Std                1.4080279
Policy mu Max                2.981742
Policy mu Min                -3.8419738
Policy log std Mean          -0.92529035
Policy log std Std           0.51023597
Policy log std Max           0.04067242
Policy log std Min           -3.385819
Z mean eval                  3.1055179
Z variance eval              0.03284023
total_rewards                [11273.69391425 11551.35629821 11281.33468991 11473.16481697
 11229.28862785 11584.87723346 11454.97430488 11563.03473935
  4550.80067225 11785.37129457]
total_rewards_mean           10774.789659169812
total_rewards_std            2080.9224812606544
total_rewards_max            11785.371294567556
total_rewards_min            4550.800672249285
Number of train steps total  1032000
Number of env steps total    1292000
Number of rollouts total     0
Train Time (s)               118.17016516486183
(Previous) Eval Time (s)     22.950932770967484
Sample Time (s)              16.477225319948047
Epoch Time (s)               157.59832325577736
Total Train Time (s)         39655.340788451955
Epoch                        257
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:37:14.813876 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #257 | Epoch Duration: 157.04547357559204
2020-01-13 19:37:14.814168 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #257 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.105052
Z variance train             0.032873563
KL Divergence                49.75212
KL Loss                      4.975212
QF Loss                      653.8524
VF Loss                      257.24237
Policy Loss                  -4909.082
Q Predictions Mean           4917.866
Q Predictions Std            558.6277
Q Predictions Max            5639.1743
Q Predictions Min            1467.863
V Predictions Mean           4921.0044
V Predictions Std            556.79126
V Predictions Max            5627.406
V Predictions Min            1524.2157
Log Pis Mean                 5.831083
Log Pis Std                  3.961901
Log Pis Max                  15.37154
Log Pis Min                  -3.0247617
Policy mu Mean               -0.095271945
Policy mu Std                1.4230705
Policy mu Max                3.1257808
Policy mu Min                -4.2057395
Policy log std Mean          -0.9153939
Policy log std Std           0.49317566
Policy log std Max           -0.03018272
Policy log std Min           -3.449252
Z mean eval                  3.0911458
Z variance eval              0.03618822
total_rewards                [11890.19654602 11917.37531221 12138.02109584 12031.97379054
 12110.96415432 12195.78744452 12303.57793828 12131.35714543
 12353.90646783 12165.05166503]
total_rewards_mean           12123.821156003843
total_rewards_std            140.7802785623799
total_rewards_max            12353.906467828318
total_rewards_min            11890.196546022968
Number of train steps total  1036000
Number of env steps total    1297000
Number of rollouts total     0
Train Time (s)               110.38638063007966
(Previous) Eval Time (s)     22.397757115773857
Sample Time (s)              16.648507547099143
Epoch Time (s)               149.43264529295266
Total Train Time (s)         39804.536381766666
Epoch                        258
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:39:44.011992 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #258 | Epoch Duration: 149.19759964942932
2020-01-13 19:39:44.012204 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #258 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.092298
Z variance train             0.03620798
KL Divergence                51.16037
KL Loss                      5.116037
QF Loss                      502.59692
VF Loss                      69.88306
Policy Loss                  -4874.8145
Q Predictions Mean           4880.173
Q Predictions Std            537.2987
Q Predictions Max            5587.234
Q Predictions Min            3406.5088
V Predictions Mean           4873.7744
V Predictions Std            535.5822
V Predictions Max            5569.872
V Predictions Min            3418.6255
Log Pis Mean                 5.826498
Log Pis Std                  3.885645
Log Pis Max                  17.069248
Log Pis Min                  -7.7243824
Policy mu Mean               -0.14594561
Policy mu Std                1.402639
Policy mu Max                3.1099613
Policy mu Min                -3.0974493
Policy log std Mean          -0.92050904
Policy log std Std           0.5222019
Policy log std Max           0.05479753
Policy log std Min           -3.4874582
Z mean eval                  3.0902982
Z variance eval              0.036695562
total_rewards                [11764.62059828 12043.32718283 11832.14088888 12281.41981557
 11801.21382625 11560.60178196 12140.43861961 12048.00389937
 11831.76125771 12009.8958483 ]
total_rewards_mean           11931.342371876013
total_rewards_std            200.1329862026112
total_rewards_max            12281.419815574136
total_rewards_min            11560.601781958729
Number of train steps total  1040000
Number of env steps total    1302000
Number of rollouts total     0
Train Time (s)               112.35653224820271
(Previous) Eval Time (s)     22.162425361108035
Sample Time (s)              16.147402399219573
Epoch Time (s)               150.66636000853032
Total Train Time (s)         39956.349287394434
Epoch                        259
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:42:15.826742 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #259 | Epoch Duration: 151.81436347961426
2020-01-13 19:42:15.826951 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #259 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.089614
Z variance train             0.03668721
KL Divergence                50.209778
KL Loss                      5.020978
QF Loss                      771.0788
VF Loss                      72.02754
Policy Loss                  -4816.5635
Q Predictions Mean           4820.9883
Q Predictions Std            556.5851
Q Predictions Max            5564.3833
Q Predictions Min            3319.8928
V Predictions Mean           4818.72
V Predictions Std            556.6609
V Predictions Max            5553.5947
V Predictions Min            3318.8462
Log Pis Mean                 5.859044
Log Pis Std                  3.5847096
Log Pis Max                  13.894138
Log Pis Min                  -3.2085953
Policy mu Mean               -0.096130185
Policy mu Std                1.3965465
Policy mu Max                2.8384283
Policy mu Min                -2.6047583
Policy log std Mean          -0.9347083
Policy log std Std           0.5208221
Policy log std Max           0.043911934
Policy log std Min           -3.3463206
Z mean eval                  3.0826068
Z variance eval              0.047939066
total_rewards                [11627.03712689 11841.01530509 12106.81230609 12419.52289004
 11595.7249688   6671.88443609 11455.1988319  11848.04595405
  8295.40256367 11646.19109983]
total_rewards_mean           10950.683548243916
total_rewards_std            1790.6007543238234
total_rewards_max            12419.522890041715
total_rewards_min            6671.884436091698
Number of train steps total  1044000
Number of env steps total    1307000
Number of rollouts total     0
Train Time (s)               119.43906676443294
(Previous) Eval Time (s)     23.310170450713485
Sample Time (s)              16.460999011062086
Epoch Time (s)               159.2102362262085
Total Train Time (s)         40115.7566888337
Epoch                        260
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:44:55.241313 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #260 | Epoch Duration: 159.41418313980103
2020-01-13 19:44:55.241613 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #260 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.08196
Z variance train             0.047941484
KL Divergence                50.198524
KL Loss                      5.0198526
QF Loss                      518.50476
VF Loss                      88.363266
Policy Loss                  -4896.1543
Q Predictions Mean           4904.7617
Q Predictions Std            492.3065
Q Predictions Max            5597.816
Q Predictions Min            3438.524
V Predictions Mean           4896.8857
V Predictions Std            491.47467
V Predictions Max            5582.659
V Predictions Min            3433.2312
Log Pis Mean                 5.997986
Log Pis Std                  4.1413097
Log Pis Max                  16.790936
Log Pis Min                  -7.28703
Policy mu Mean               -0.0735659
Policy mu Std                1.4349759
Policy mu Max                3.8614926
Policy mu Min                -3.2475839
Policy log std Mean          -0.9092469
Policy log std Std           0.5074982
Policy log std Max           -0.15708745
Policy log std Min           -3.2711306
Z mean eval                  3.0941842
Z variance eval              0.022851925
total_rewards                [11124.55672133 11304.42011879 11759.67888183 11327.72782975
 11715.20226207 11630.82251965 11509.69660546 11619.08790643
 11541.49232125 10852.44369664]
total_rewards_mean           11438.512886321107
total_rewards_std            271.5265353256684
total_rewards_max            11759.678881833257
total_rewards_min            10852.443696642827
Number of train steps total  1048000
Number of env steps total    1312000
Number of rollouts total     0
Train Time (s)               120.6964494343847
(Previous) Eval Time (s)     23.513764011207968
Sample Time (s)              15.97487037954852
Epoch Time (s)               160.1850838251412
Total Train Time (s)         40275.13183670631
Epoch                        261
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:47:34.616711 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #261 | Epoch Duration: 159.3748779296875
2020-01-13 19:47:34.616877 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #261 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0980756
Z variance train             0.0227913
KL Divergence                50.981056
KL Loss                      5.098106
QF Loss                      667.4947
VF Loss                      548.75854
Policy Loss                  -4943.4854
Q Predictions Mean           4947.395
Q Predictions Std            480.31897
Q Predictions Max            5598.799
Q Predictions Min            3457.2368
V Predictions Mean           4953.7295
V Predictions Std            481.526
V Predictions Max            5613.5176
V Predictions Min            3453.389
Log Pis Mean                 5.7806854
Log Pis Std                  3.881124
Log Pis Max                  19.32074
Log Pis Min                  -5.042052
Policy mu Mean               -0.049255144
Policy mu Std                1.4599162
Policy mu Max                3.1605487
Policy mu Min                -2.8669205
Policy log std Mean          -0.8961609
Policy log std Std           0.49953216
Policy log std Max           0.045533538
Policy log std Min           -3.2280998
Z mean eval                  3.117127
Z variance eval              0.025253814
total_rewards                [11433.36175447  9027.61538183 11609.8839732  11930.01730931
  2587.11511656 11879.79026518 11796.31587715  6898.9565567
  9546.58651488 11688.04942869]
total_rewards_mean           9839.769217795929
total_rewards_std            2888.646768241364
total_rewards_max            11930.01730930789
total_rewards_min            2587.1151165605756
Number of train steps total  1052000
Number of env steps total    1317000
Number of rollouts total     0
Train Time (s)               118.26343374885619
(Previous) Eval Time (s)     22.703314364887774
Sample Time (s)              15.896368840243667
Epoch Time (s)               156.86311695398763
Total Train Time (s)         40432.39654525835
Epoch                        262
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:50:11.910179 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #262 | Epoch Duration: 157.29311895370483
2020-01-13 19:50:11.910513 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #262 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1200833
Z variance train             0.025232682
KL Divergence                50.90134
KL Loss                      5.090134
QF Loss                      948.97253
VF Loss                      551.68066
Policy Loss                  -4844.323
Q Predictions Mean           4845.01
Q Predictions Std            617.4442
Q Predictions Max            5521.1167
Q Predictions Min            448.52307
V Predictions Mean           4823.8706
V Predictions Std            616.0791
V Predictions Max            5491.342
V Predictions Min            418.198
Log Pis Mean                 5.686183
Log Pis Std                  3.980666
Log Pis Max                  17.724262
Log Pis Min                  -4.135853
Policy mu Mean               -0.048181098
Policy mu Std                1.4029101
Policy mu Max                3.2771301
Policy mu Min                -2.62297
Policy log std Mean          -0.9120123
Policy log std Std           0.49681792
Policy log std Max           -0.09117746
Policy log std Min           -3.298834
Z mean eval                  3.1235092
Z variance eval              0.0397017
total_rewards                [11753.22442731 11036.79857775 11729.62249738 11631.28329123
 11321.32663265 11752.21667698 12059.26872525 11717.40263839
 11427.01824471 11772.60575724]
total_rewards_mean           11620.076746888893
total_rewards_std            271.9703632077399
total_rewards_max            12059.268725248106
total_rewards_min            11036.798577751908
Number of train steps total  1056000
Number of env steps total    1322000
Number of rollouts total     0
Train Time (s)               109.9470052588731
(Previous) Eval Time (s)     23.133032756391913
Sample Time (s)              16.509501794353127
Epoch Time (s)               149.58953980961815
Total Train Time (s)         40582.151375609916
Epoch                        263
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:52:41.643651 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #263 | Epoch Duration: 149.732901096344
2020-01-13 19:52:41.643876 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #263 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1224568
Z variance train             0.03979526
KL Divergence                51.657017
KL Loss                      5.165702
QF Loss                      290.8481
VF Loss                      122.848434
Policy Loss                  -4899.6323
Q Predictions Mean           4903.873
Q Predictions Std            520.3928
Q Predictions Max            5620.1313
Q Predictions Min            3408.4966
V Predictions Mean           4906.5283
V Predictions Std            521.60815
V Predictions Max            5612.87
V Predictions Min            3411.056
Log Pis Mean                 5.3806086
Log Pis Std                  4.0694504
Log Pis Max                  14.434626
Log Pis Min                  -6.9315624
Policy mu Mean               -0.11845442
Policy mu Std                1.3951529
Policy mu Max                3.025712
Policy mu Min                -2.8887024
Policy log std Mean          -0.91036654
Policy log std Std           0.49825525
Policy log std Max           0.019312263
Policy log std Min           -3.1761374
Z mean eval                  3.109887
Z variance eval              0.0649227
total_rewards                [11420.90195125 11757.25617032 11724.97415728 12071.56812387
 11571.84579388 11243.96131493 11607.2113523  11849.90963432
 11807.06055896 11730.9865148 ]
total_rewards_mean           11678.567557191873
total_rewards_std            219.8105126761128
total_rewards_max            12071.568123870762
total_rewards_min            11243.96131493183
Number of train steps total  1060000
Number of env steps total    1327000
Number of rollouts total     0
Train Time (s)               120.7776193167083
(Previous) Eval Time (s)     23.276087216101587
Sample Time (s)              16.85058738803491
Epoch Time (s)               160.9042939208448
Total Train Time (s)         40743.36368086096
Epoch                        264
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:55:22.859888 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #264 | Epoch Duration: 161.21587324142456
2020-01-13 19:55:22.860071 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #264 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1092694
Z variance train             0.06533026
KL Divergence                48.237133
KL Loss                      4.8237133
QF Loss                      899.9663
VF Loss                      118.30983
Policy Loss                  -4926.685
Q Predictions Mean           4936.254
Q Predictions Std            545.2925
Q Predictions Max            5636.368
Q Predictions Min            3441.3528
V Predictions Mean           4925.4785
V Predictions Std            544.6487
V Predictions Max            5627.4185
V Predictions Min            3429.6184
Log Pis Mean                 5.5044103
Log Pis Std                  3.9821608
Log Pis Max                  15.03542
Log Pis Min                  -6.165517
Policy mu Mean               -0.11895005
Policy mu Std                1.3726019
Policy mu Max                2.8647435
Policy mu Min                -2.6250792
Policy log std Mean          -0.9299052
Policy log std Std           0.50002
Policy log std Max           -0.18324798
Policy log std Min           -3.330134
Z mean eval                  3.0994873
Z variance eval              0.0558277
total_rewards                [11747.87002396  7192.28345751 12006.26168849 11796.97307609
 12109.61353936 11875.6835229   4989.57167698 12037.76434618
 12007.82907127  6556.30028588]
total_rewards_mean           10232.01506886211
total_rewards_std            2660.2666944395596
total_rewards_max            12109.613539358432
total_rewards_min            4989.571676980608
Number of train steps total  1064000
Number of env steps total    1332000
Number of rollouts total     0
Train Time (s)               115.05286303022876
(Previous) Eval Time (s)     23.587311988696456
Sample Time (s)              16.566274849232286
Epoch Time (s)               155.2064498681575
Total Train Time (s)         40898.149333775975
Epoch                        265
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:57:57.649641 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #265 | Epoch Duration: 154.78938817977905
2020-01-13 19:57:57.649933 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #265 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.0979936
Z variance train             0.05607285
KL Divergence                46.838604
KL Loss                      4.6838603
QF Loss                      423.98285
VF Loss                      80.585175
Policy Loss                  -4730.6924
Q Predictions Mean           4739.0356
Q Predictions Std            539.36444
Q Predictions Max            5508.383
Q Predictions Min            3309.6382
V Predictions Mean           4733.4507
V Predictions Std            538.2949
V Predictions Max            5503.5576
V Predictions Min            3304.1694
Log Pis Mean                 5.3444076
Log Pis Std                  3.875596
Log Pis Max                  16.08675
Log Pis Min                  -3.6222188
Policy mu Mean               -0.12052175
Policy mu Std                1.3820075
Policy mu Max                3.0609176
Policy mu Min                -3.3255107
Policy log std Mean          -0.8932913
Policy log std Std           0.4793226
Policy log std Max           0.039058566
Policy log std Min           -3.4949079
Z mean eval                  3.1176958
Z variance eval              0.04401657
total_rewards                [11964.10849622 12243.76926504 11917.9425962  11216.77745937
 11677.59373702 11701.06819103 12085.18167943 11829.39683043
 12063.4626789  11948.57836881]
total_rewards_mean           11864.787930246077
total_rewards_std            270.9979082546389
total_rewards_max            12243.769265043182
total_rewards_min            11216.777459370433
Number of train steps total  1068000
Number of env steps total    1337000
Number of rollouts total     0
Train Time (s)               115.74283751472831
(Previous) Eval Time (s)     23.169921709690243
Sample Time (s)              16.481036238837987
Epoch Time (s)               155.39379546325654
Total Train Time (s)         41053.35950110154
Epoch                        266
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:00:32.865261 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #266 | Epoch Duration: 155.21511363983154
2020-01-13 20:00:32.865482 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #266 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1207337
Z variance train             0.044129305
KL Divergence                48.908924
KL Loss                      4.8908925
QF Loss                      698.85986
VF Loss                      505.00342
Policy Loss                  -4943.831
Q Predictions Mean           4944.8057
Q Predictions Std            547.79974
Q Predictions Max            5642.241
Q Predictions Min            3338.9087
V Predictions Mean           4924.8125
V Predictions Std            545.3726
V Predictions Max            5626.744
V Predictions Min            3329.639
Log Pis Mean                 5.70521
Log Pis Std                  4.39324
Log Pis Max                  30.061539
Log Pis Min                  -5.341399
Policy mu Mean               -0.07567176
Policy mu Std                1.4192399
Policy mu Max                4.5909395
Policy mu Min                -3.381343
Policy log std Mean          -0.8881491
Policy log std Std           0.46472654
Policy log std Max           0.12989044
Policy log std Min           -3.388962
Z mean eval                  3.1300435
Z variance eval              0.07191415
total_rewards                [11880.36200003 11546.53934308 11669.72616061 11942.17618281
  7480.39092156 11440.35056815 11885.28865516 12088.88564342
 11613.81039746  5295.95471783]
total_rewards_mean           10684.348459011355
total_rewards_std            2210.825028387533
total_rewards_max            12088.885643423144
total_rewards_min            5295.954717826163
Number of train steps total  1072000
Number of env steps total    1342000
Number of rollouts total     0
Train Time (s)               121.50862809084356
(Previous) Eval Time (s)     22.990925003774464
Sample Time (s)              16.32123702391982
Epoch Time (s)               160.82079011853784
Total Train Time (s)         41214.27087861812
Epoch                        267
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:03:13.781161 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #267 | Epoch Duration: 160.91548776626587
2020-01-13 20:03:13.781470 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #267 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1311848
Z variance train             0.0719087
KL Divergence                48.65654
KL Loss                      4.865654
QF Loss                      500.96136
VF Loss                      93.41406
Policy Loss                  -4883.039
Q Predictions Mean           4886.2173
Q Predictions Std            541.09033
Q Predictions Max            5645.711
Q Predictions Min            3365.6636
V Predictions Mean           4885.296
V Predictions Std            540.91547
V Predictions Max            5629.783
V Predictions Min            3369.5923
Log Pis Mean                 5.960038
Log Pis Std                  3.7008812
Log Pis Max                  16.447546
Log Pis Min                  -4.084853
Policy mu Mean               -0.13369292
Policy mu Std                1.4062651
Policy mu Max                3.083184
Policy mu Min                -2.9786317
Policy log std Mean          -0.90504265
Policy log std Std           0.48800623
Policy log std Max           -0.05756551
Policy log std Min           -3.1568816
Z mean eval                  3.11216
Z variance eval              0.054516964
total_rewards                [ 3880.69178789 11813.68731007 11763.83359108 11310.18063644
 11491.08818819 11998.95170268 11219.14025269 11618.22998274
  9534.63528521  6882.09450787]
total_rewards_mean           10151.253324485111
total_rewards_std            2561.1779186924564
total_rewards_max            11998.951702682913
total_rewards_min            3880.691787887976
Number of train steps total  1076000
Number of env steps total    1347000
Number of rollouts total     0
Train Time (s)               118.19847072008997
(Previous) Eval Time (s)     23.085285434965044
Sample Time (s)              16.61745080538094
Epoch Time (s)               157.90120696043596
Total Train Time (s)         41371.565576170105
Epoch                        268
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:05:51.074866 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #268 | Epoch Duration: 157.29318690299988
2020-01-13 20:05:51.075065 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #268 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1108785
Z variance train             0.05443312
KL Divergence                49.104797
KL Loss                      4.91048
QF Loss                      473.6328
VF Loss                      182.4147
Policy Loss                  -4814.452
Q Predictions Mean           4818.1157
Q Predictions Std            539.78094
Q Predictions Max            5572.4575
Q Predictions Min            3353.878
V Predictions Mean           4823.402
V Predictions Std            540.02136
V Predictions Max            5586.216
V Predictions Min            3360.7937
Log Pis Mean                 5.2606487
Log Pis Std                  3.9718184
Log Pis Max                  15.873681
Log Pis Min                  -4.823741
Policy mu Mean               -0.120164335
Policy mu Std                1.355904
Policy mu Max                2.8313954
Policy mu Min                -3.4727502
Policy log std Mean          -0.9143793
Policy log std Std           0.4937942
Policy log std Max           -0.15749437
Policy log std Min           -3.3624692
Z mean eval                  3.1443467
Z variance eval              0.06876152
total_rewards                [11573.84757794 11758.96277032 11885.45617886 11835.83793169
 11680.18865759 11914.50575806 11779.59425241 11861.88270476
 11277.9403828  11641.65960693]
total_rewards_mean           11720.987582135776
total_rewards_std            181.19508281931266
total_rewards_max            11914.505758061927
total_rewards_min            11277.940382803623
Number of train steps total  1080000
Number of env steps total    1352000
Number of rollouts total     0
Train Time (s)               117.1171536562033
(Previous) Eval Time (s)     22.47696011699736
Sample Time (s)              16.53390856552869
Epoch Time (s)               156.12802233872935
Total Train Time (s)         41527.68907345878
Epoch                        269
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:08:27.201407 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #269 | Epoch Duration: 156.12622261047363
2020-01-13 20:08:27.201616 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #269 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1461952
Z variance train             0.06874692
KL Divergence                50.42312
KL Loss                      5.042312
QF Loss                      1532.2678
VF Loss                      273.28976
Policy Loss                  -4850.3877
Q Predictions Mean           4853.464
Q Predictions Std            546.76306
Q Predictions Max            5579.95
Q Predictions Min            3436.6611
V Predictions Mean           4847.041
V Predictions Std            544.0813
V Predictions Max            5574.154
V Predictions Min            3437.5854
Log Pis Mean                 5.4734073
Log Pis Std                  3.970375
Log Pis Max                  18.002403
Log Pis Min                  -3.7686744
Policy mu Mean               -0.052202042
Policy mu Std                1.4102374
Policy mu Max                3.2067552
Policy mu Min                -3.7695234
Policy log std Mean          -0.89445037
Policy log std Std           0.4890862
Policy log std Max           -0.04747671
Policy log std Min           -3.3587058
Z mean eval                  3.1490486
Z variance eval              0.043306317
total_rewards                [11303.73532347 11697.325931   11509.2225675  11926.96083658
 11912.54635921 11882.38303834 11881.73117588  6704.45457094
 11780.57830176 11790.39741592]
total_rewards_mean           11238.933552060163
total_rewards_std            1523.1783164656015
total_rewards_max            11926.960836576598
total_rewards_min            6704.4545709429
Number of train steps total  1084000
Number of env steps total    1357000
Number of rollouts total     0
Train Time (s)               120.48041596217081
(Previous) Eval Time (s)     22.47485304111615
Sample Time (s)              16.798804325051606
Epoch Time (s)               159.75407332833856
Total Train Time (s)         41687.69659991842
Epoch                        270
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:11:07.211545 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #270 | Epoch Duration: 160.009779214859
2020-01-13 20:11:07.211744 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #270 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1491015
Z variance train             0.04356207
KL Divergence                52.998596
KL Loss                      5.2998595
QF Loss                      933.94385
VF Loss                      649.24365
Policy Loss                  -4950.744
Q Predictions Mean           4963.307
Q Predictions Std            501.1377
Q Predictions Max            5637.9614
Q Predictions Min            3494.4666
V Predictions Mean           4947.402
V Predictions Std            499.45038
V Predictions Max            5600.351
V Predictions Min            3483.729
Log Pis Mean                 5.8905635
Log Pis Std                  4.1019335
Log Pis Max                  18.61976
Log Pis Min                  -4.2312775
Policy mu Mean               -0.12916453
Policy mu Std                1.4449536
Policy mu Max                3.105073
Policy mu Min                -2.738377
Policy log std Mean          -0.882327
Policy log std Std           0.48082182
Policy log std Max           0.003664136
Policy log std Min           -3.2352247
Z mean eval                  3.1600156
Z variance eval              0.04557201
total_rewards                [11920.68523618 12267.50210803 12140.42375658 11980.58492011
 11764.00568893 11884.328785   12180.34863205 12105.55641869
 12019.77744244 12087.07241538]
total_rewards_mean           12035.028540338466
total_rewards_std            143.66199362098183
total_rewards_max            12267.502108026685
total_rewards_min            11764.005688930365
Number of train steps total  1088000
Number of env steps total    1362000
Number of rollouts total     0
Train Time (s)               122.36756747309119
(Previous) Eval Time (s)     22.73025458306074
Sample Time (s)              16.295943948905915
Epoch Time (s)               161.39376600505784
Total Train Time (s)         41849.61251534568
Epoch                        271
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:13:49.130633 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #271 | Epoch Duration: 161.91873478889465
2020-01-13 20:13:49.130823 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #271 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1571243
Z variance train             0.04568251
KL Divergence                51.73653
KL Loss                      5.173653
QF Loss                      406.456
VF Loss                      336.69843
Policy Loss                  -4861.7183
Q Predictions Mean           4868.1104
Q Predictions Std            501.95587
Q Predictions Max            5635.5605
Q Predictions Min            3393.6926
V Predictions Mean           4875.718
V Predictions Std            502.3481
V Predictions Max            5648.3003
V Predictions Min            3398.5
Log Pis Mean                 5.380512
Log Pis Std                  3.8563766
Log Pis Max                  15.733851
Log Pis Min                  -3.500005
Policy mu Mean               -0.109802246
Policy mu Std                1.3976952
Policy mu Max                2.9857173
Policy mu Min                -3.0433836
Policy log std Mean          -0.9018683
Policy log std Std           0.4870912
Policy log std Max           -0.08432484
Policy log std Min           -3.3779125
Z mean eval                  3.144705
Z variance eval              0.035460185
total_rewards                [12058.65777869 12190.94935773 12245.33172441 11967.36934614
 12033.13032058 11911.51144534 12113.76398967 11884.30492785
 12189.05490459 12150.88069396]
total_rewards_mean           12074.495448896476
total_rewards_std            118.07678264681175
total_rewards_max            12245.331724406262
total_rewards_min            11884.304927848938
Number of train steps total  1092000
Number of env steps total    1367000
Number of rollouts total     0
Train Time (s)               123.39948541717604
(Previous) Eval Time (s)     23.25490525411442
Sample Time (s)              16.54532634280622
Epoch Time (s)               163.19971701409668
Total Train Time (s)         42012.3761477666
Epoch                        272
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:16:31.903647 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #272 | Epoch Duration: 162.77266335487366
2020-01-13 20:16:31.903945 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #272 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1447616
Z variance train             0.035317484
KL Divergence                51.42909
KL Loss                      5.142909
QF Loss                      1027.105
VF Loss                      1268.0585
Policy Loss                  -4925.0186
Q Predictions Mean           4941.4634
Q Predictions Std            495.61307
Q Predictions Max            5563.877
Q Predictions Min            3367.68
V Predictions Mean           4953.735
V Predictions Std            497.6922
V Predictions Max            5593.313
V Predictions Min            3373.4897
Log Pis Mean                 5.8215275
Log Pis Std                  3.9584649
Log Pis Max                  16.799263
Log Pis Min                  -2.9393015
Policy mu Mean               -0.1602514
Policy mu Std                1.409975
Policy mu Max                3.1756852
Policy mu Min                -3.1182685
Policy log std Mean          -0.90039855
Policy log std Std           0.48063415
Policy log std Max           -0.038891673
Policy log std Min           -3.486704
Z mean eval                  3.1433017
Z variance eval              0.03829029
total_rewards                [11374.90198728 11315.60874541 10986.34607531 11493.29784549
 11355.35144202 11627.49803217 11437.83371107 11568.29816748
 11470.10394219 11764.57040042]
total_rewards_mean           11439.381034883998
total_rewards_std            198.34007240398742
total_rewards_max            11764.570400417228
total_rewards_min            10986.346075305002
Number of train steps total  1096000
Number of env steps total    1372000
Number of rollouts total     0
Train Time (s)               117.85254715476185
(Previous) Eval Time (s)     22.82752121426165
Sample Time (s)              16.469324418809265
Epoch Time (s)               157.14939278783277
Total Train Time (s)         42170.16195018543
Epoch                        273
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:19:09.690978 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #273 | Epoch Duration: 157.78681111335754
2020-01-13 20:19:09.691265 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #273 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.142409
Z variance train             0.038332626
KL Divergence                51.592926
KL Loss                      5.1592927
QF Loss                      486.19
VF Loss                      173.38248
Policy Loss                  -4955.464
Q Predictions Mean           4961.1143
Q Predictions Std            538.0712
Q Predictions Max            5630.9917
Q Predictions Min            3402.2556
V Predictions Mean           4956.624
V Predictions Std            536.0037
V Predictions Max            5613.195
V Predictions Min            3399.2869
Log Pis Mean                 5.677248
Log Pis Std                  3.846402
Log Pis Max                  16.474361
Log Pis Min                  -3.3069787
Policy mu Mean               -0.08523867
Policy mu Std                1.4055433
Policy mu Max                3.103896
Policy mu Min                -2.7770464
Policy log std Mean          -0.9105594
Policy log std Std           0.48503682
Policy log std Max           0.022527575
Policy log std Min           -3.1397698
Z mean eval                  3.1208394
Z variance eval              0.038627822
total_rewards                [11750.86568074 11406.9996215  12166.18694262 12224.66728786
 12038.09878668 12341.58991243 11622.50237405 11949.3710324
 11835.49217773 12211.35479038]
total_rewards_mean           11954.71286063975
total_rewards_std            283.9433402877781
total_rewards_max            12341.589912430736
total_rewards_min            11406.999621495592
Number of train steps total  1100000
Number of env steps total    1377000
Number of rollouts total     0
Train Time (s)               118.12203851621598
(Previous) Eval Time (s)     23.464639781042933
Sample Time (s)              15.845397462137043
Epoch Time (s)               157.43207575939596
Total Train Time (s)         42328.54279976431
Epoch                        274
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:21:48.073837 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #274 | Epoch Duration: 158.38235569000244
2020-01-13 20:21:48.074055 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #274 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1177833
Z variance train             0.038495854
KL Divergence                51.79962
KL Loss                      5.179962
QF Loss                      668.3534
VF Loss                      184.0046
Policy Loss                  -4872.8228
Q Predictions Mean           4875.7837
Q Predictions Std            548.7168
Q Predictions Max            5529.3677
Q Predictions Min            2023.4033
V Predictions Mean           4881.5244
V Predictions Std            548.39935
V Predictions Max            5536.0244
V Predictions Min            2070.8384
Log Pis Mean                 5.4461646
Log Pis Std                  4.08037
Log Pis Max                  23.003859
Log Pis Min                  -4.621031
Policy mu Mean               -0.15673515
Policy mu Std                1.383979
Policy mu Max                3.1135323
Policy mu Min                -4.4857707
Policy log std Mean          -0.8846242
Policy log std Std           0.4667065
Policy log std Max           0.76345396
Policy log std Min           -3.4244204
Z mean eval                  3.1544719
Z variance eval              0.045722313
total_rewards                [11724.42178046 11825.27810016 12104.82730327 12133.36942271
 12143.75983129 11785.40182352 12052.11331028 12197.53273536
 11866.35165604 11934.08771389]
total_rewards_mean           11976.714367697461
total_rewards_std            161.39566644566457
total_rewards_max            12197.532735364763
total_rewards_min            11724.421780456154
Number of train steps total  1104000
Number of env steps total    1382000
Number of rollouts total     0
Train Time (s)               115.29481313284487
(Previous) Eval Time (s)     24.414663677103817
Sample Time (s)              16.498968163505197
Epoch Time (s)               156.20844497345388
Total Train Time (s)         42482.832226749975
Epoch                        275
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:24:22.365596 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #275 | Epoch Duration: 154.29138660430908
2020-01-13 20:24:22.365800 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #275 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1557598
Z variance train             0.045989208
KL Divergence                51.238792
KL Loss                      5.1238794
QF Loss                      637.9324
VF Loss                      102.15255
Policy Loss                  -5077.6196
Q Predictions Mean           5084.6733
Q Predictions Std            496.86533
Q Predictions Max            5686.7583
Q Predictions Min            3490.5466
V Predictions Mean           5080.6157
V Predictions Std            497.16577
V Predictions Max            5689.1455
V Predictions Min            3477.7817
Log Pis Mean                 5.616082
Log Pis Std                  3.728249
Log Pis Max                  16.738003
Log Pis Min                  -3.1143205
Policy mu Mean               -0.060299307
Policy mu Std                1.402613
Policy mu Max                3.0781746
Policy mu Min                -2.7768588
Policy log std Mean          -0.90805095
Policy log std Std           0.50435734
Policy log std Max           -0.12030113
Policy log std Min           -3.2497163
Z mean eval                  3.123975
Z variance eval              0.037613
total_rewards                [10007.68460773  3262.95317742  2268.46359909 11467.53597026
 11711.80839482 11509.67924936 10591.67938951  7306.76821119
 11543.69382437 11208.34819463]
total_rewards_mean           9087.861461836857
total_rewards_std            3400.7985257156893
total_rewards_max            11711.808394824298
total_rewards_min            2268.4635990853026
Number of train steps total  1108000
Number of env steps total    1387000
Number of rollouts total     0
Train Time (s)               115.7495876988396
(Previous) Eval Time (s)     22.49731410993263
Sample Time (s)              16.20586446719244
Epoch Time (s)               154.45276627596468
Total Train Time (s)         42637.15976094687
Epoch                        276
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:26:56.695644 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #276 | Epoch Duration: 154.32970690727234
2020-01-13 20:26:56.695850 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #276 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.124269
Z variance train             0.037647743
KL Divergence                50.30887
KL Loss                      5.030887
QF Loss                      472.95084
VF Loss                      231.40071
Policy Loss                  -4876.593
Q Predictions Mean           4876.8936
Q Predictions Std            539.4731
Q Predictions Max            5561.119
Q Predictions Min            3350.2046
V Predictions Mean           4866.7295
V Predictions Std            538.34576
V Predictions Max            5555.6797
V Predictions Min            3350.0874
Log Pis Mean                 5.68555
Log Pis Std                  3.6041007
Log Pis Max                  13.688791
Log Pis Min                  -3.2642708
Policy mu Mean               -0.09433248
Policy mu Std                1.3845576
Policy mu Max                3.3338633
Policy mu Min                -3.4341583
Policy log std Mean          -0.92505306
Policy log std Std           0.50325114
Policy log std Max           -0.12787771
Policy log std Min           -3.2106028
Z mean eval                  3.1387763
Z variance eval              0.041804798
total_rewards                [11691.10474145 11882.6007027  12024.47160561 11972.61078159
 12371.38011542 12028.90204854 12232.13011454 12071.71656876
 11852.2717533  12220.23536676]
total_rewards_mean           12034.742379869364
total_rewards_std            191.4656630929858
total_rewards_max            12371.380115424881
total_rewards_min            11691.104741453533
Number of train steps total  1112000
Number of env steps total    1392000
Number of rollouts total     0
Train Time (s)               117.309815550223
(Previous) Eval Time (s)     22.37395488517359
Sample Time (s)              16.536426207982004
Epoch Time (s)               156.22019664337859
Total Train Time (s)         42793.760100336745
Epoch                        277
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:29:33.302116 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #277 | Epoch Duration: 156.60607957839966
2020-01-13 20:29:33.302432 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #277 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1361136
Z variance train             0.04179484
KL Divergence                51.40226
KL Loss                      5.140226
QF Loss                      290.01025
VF Loss                      180.49365
Policy Loss                  -4873.946
Q Predictions Mean           4878.5415
Q Predictions Std            541.3787
Q Predictions Max            5595.355
Q Predictions Min            3341.4016
V Predictions Mean           4883.81
V Predictions Std            541.66595
V Predictions Max            5616.3525
V Predictions Min            3343.7502
Log Pis Mean                 5.5577097
Log Pis Std                  3.8525581
Log Pis Max                  16.60164
Log Pis Min                  -4.7719655
Policy mu Mean               -0.12600647
Policy mu Std                1.3751131
Policy mu Max                3.217588
Policy mu Min                -2.8809633
Policy log std Mean          -0.90782166
Policy log std Std           0.48743585
Policy log std Max           -0.080215335
Policy log std Min           -3.3515306
Z mean eval                  3.1123989
Z variance eval              0.0586979
total_rewards                [11868.07993232 11820.11274242 12131.94818712 12239.52895406
 12294.71786109 11981.20788917 12007.45010811 12119.56691696
 12082.98547882 12150.97293736]
total_rewards_mean           12069.657100741586
total_rewards_std            143.96825591252383
total_rewards_max            12294.717861089757
total_rewards_min            11820.11274241615
Number of train steps total  1116000
Number of env steps total    1397000
Number of rollouts total     0
Train Time (s)               117.14317112462595
(Previous) Eval Time (s)     22.759543991182
Sample Time (s)              16.17845255509019
Epoch Time (s)               156.08116767089814
Total Train Time (s)         42950.66336070746
Epoch                        278
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:32:10.207629 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #278 | Epoch Duration: 156.90496492385864
2020-01-13 20:32:10.207881 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #278 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1132343
Z variance train             0.058173943
KL Divergence                50.004356
KL Loss                      5.000436
QF Loss                      745.9686
VF Loss                      280.09937
Policy Loss                  -4891.177
Q Predictions Mean           4889.2705
Q Predictions Std            539.9929
Q Predictions Max            5518.0864
Q Predictions Min            3363.4895
V Predictions Mean           4881.685
V Predictions Std            537.9343
V Predictions Max            5500.0845
V Predictions Min            3371.9321
Log Pis Mean                 5.311871
Log Pis Std                  3.64835
Log Pis Max                  14.520755
Log Pis Min                  -4.0904512
Policy mu Mean               -0.10055265
Policy mu Std                1.3692079
Policy mu Max                3.121982
Policy mu Min                -3.0916777
Policy log std Mean          -0.9458279
Policy log std Std           0.49874154
Policy log std Max           0.21420312
Policy log std Min           -3.5174074
Z mean eval                  3.134544
Z variance eval              0.034823988
total_rewards                [11618.55188229 11513.49941848 11862.86044095 11707.8757792
 11658.88045493 11788.95855663 11666.12428294 11744.04196876
  3687.72280895 11794.22393598]
total_rewards_mean           10904.273952910298
total_rewards_std            2407.3711394589136
total_rewards_max            11862.860440953848
total_rewards_min            3687.7228089549603
Number of train steps total  1120000
Number of env steps total    1402000
Number of rollouts total     0
Train Time (s)               115.90650777565315
(Previous) Eval Time (s)     23.583050983026624
Sample Time (s)              16.029427028726786
Epoch Time (s)               155.51898578740656
Total Train Time (s)         43105.313936586026
Epoch                        279
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:34:44.863483 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #279 | Epoch Duration: 154.65541124343872
2020-01-13 20:34:44.863729 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #279 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1358914
Z variance train             0.034908347
KL Divergence                51.867283
KL Loss                      5.1867285
QF Loss                      636.52954
VF Loss                      367.98666
Policy Loss                  -4885.7505
Q Predictions Mean           4892.2744
Q Predictions Std            573.099
Q Predictions Max            5600.703
Q Predictions Min            2264.915
V Predictions Mean           4875.9795
V Predictions Std            565.7067
V Predictions Max            5584.678
V Predictions Min            2339.245
Log Pis Mean                 6.1397114
Log Pis Std                  4.0712724
Log Pis Max                  25.851076
Log Pis Min                  -2.92695
Policy mu Mean               -0.11292703
Policy mu Std                1.4381117
Policy mu Max                5.9263697
Policy mu Min                -3.7285182
Policy log std Mean          -0.92848104
Policy log std Std           0.5126997
Policy log std Max           -0.18344665
Policy log std Min           -3.4909928
Z mean eval                  3.1348624
Z variance eval              0.038018897
total_rewards                [11296.67673027 11799.12372719 12029.06979783 11823.80087715
 12077.20527597 11971.55119951 11905.04530311 11842.53336385
 11584.79090995 11829.67040492]
total_rewards_mean           11815.94675897439
total_rewards_std            216.8278145718189
total_rewards_max            12077.205275970788
total_rewards_min            11296.676730266854
Number of train steps total  1124000
Number of env steps total    1407000
Number of rollouts total     0
Train Time (s)               116.72385094733909
(Previous) Eval Time (s)     22.719200714025646
Sample Time (s)              16.460700339172035
Epoch Time (s)               155.90375200053677
Total Train Time (s)         43261.540058768354
Epoch                        280
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:37:21.091840 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #280 | Epoch Duration: 156.22788667678833
2020-01-13 20:37:21.092056 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #280 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1363177
Z variance train             0.03797552
KL Divergence                50.708706
KL Loss                      5.070871
QF Loss                      516.8758
VF Loss                      73.5866
Policy Loss                  -4842.3223
Q Predictions Mean           4849.503
Q Predictions Std            632.72577
Q Predictions Max            5571.606
Q Predictions Min            -72.33762
V Predictions Mean           4840.997
V Predictions Std            632.5669
V Predictions Max            5550.6924
V Predictions Min            -117.490585
Log Pis Mean                 5.6757927
Log Pis Std                  4.123169
Log Pis Max                  17.525696
Log Pis Min                  -3.2167687
Policy mu Mean               -0.07916689
Policy mu Std                1.4033003
Policy mu Max                3.3969288
Policy mu Min                -3.315954
Policy log std Mean          -0.9031026
Policy log std Std           0.5105339
Policy log std Max           0.040472507
Policy log std Min           -3.5518737
Z mean eval                  3.144721
Z variance eval              0.026854604
total_rewards                [11861.94654763 12080.12029701 11929.64126961 11883.87566809
 12067.7934987  12003.66141585 11673.07526088 11790.84460818
 12148.56035966 12274.27860669]
total_rewards_mean           11971.379753231242
total_rewards_std            169.78106661756289
total_rewards_max            12274.278606692655
total_rewards_min            11673.075260875385
Number of train steps total  1128000
Number of env steps total    1412000
Number of rollouts total     0
Train Time (s)               115.05501582333818
(Previous) Eval Time (s)     23.04303151089698
Sample Time (s)              16.519103260245174
Epoch Time (s)               154.61715059448034
Total Train Time (s)         43416.3327259589
Epoch                        281
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:39:55.888729 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #281 | Epoch Duration: 154.7964949607849
2020-01-13 20:39:55.888921 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #281 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.146077
Z variance train             0.026889969
KL Divergence                52.08378
KL Loss                      5.208378
QF Loss                      652.2985
VF Loss                      130.66861
Policy Loss                  -4902.999
Q Predictions Mean           4907.602
Q Predictions Std            577.51306
Q Predictions Max            5593.24
Q Predictions Min            1793.8281
V Predictions Mean           4895.159
V Predictions Std            574.77686
V Predictions Max            5569.0674
V Predictions Min            1852.3348
Log Pis Mean                 5.7679424
Log Pis Std                  4.038319
Log Pis Max                  26.846663
Log Pis Min                  -4.029482
Policy mu Mean               -0.118207335
Policy mu Std                1.4282193
Policy mu Max                3.6170142
Policy mu Min                -3.4075208
Policy log std Mean          -0.93174475
Policy log std Std           0.5263569
Policy log std Max           -0.08412373
Policy log std Min           -3.7650595
Z mean eval                  3.1520395
Z variance eval              0.035108227
total_rewards                [8653.7502253  8215.8193463  8188.72681871 9035.30710626 6316.57517494
 8906.5819063  8244.96546568 6781.23590413 9248.59871267 8614.43142849]
total_rewards_mean           8220.59920887864
total_rewards_std            907.3331513241941
total_rewards_max            9248.598712670333
total_rewards_min            6316.575174940215
Number of train steps total  1132000
Number of env steps total    1417000
Number of rollouts total     0
Train Time (s)               117.45254212804139
(Previous) Eval Time (s)     23.22207636712119
Sample Time (s)              16.669865793548524
Epoch Time (s)               157.3444842887111
Total Train Time (s)         43573.10229201289
Epoch                        282
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:42:32.662799 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #282 | Epoch Duration: 156.7737147808075
2020-01-13 20:42:32.663046 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #282 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1510777
Z variance train             0.035255894
KL Divergence                52.495316
KL Loss                      5.2495317
QF Loss                      628.4324
VF Loss                      571.0112
Policy Loss                  -4890.125
Q Predictions Mean           4893.961
Q Predictions Std            573.1974
Q Predictions Max            5598.6357
Q Predictions Min            3394.7986
V Predictions Mean           4910.356
V Predictions Std            572.03516
V Predictions Max            5599.895
V Predictions Min            3426.5603
Log Pis Mean                 5.5242844
Log Pis Std                  3.827064
Log Pis Max                  14.339605
Log Pis Min                  -5.8288093
Policy mu Mean               -0.04384822
Policy mu Std                1.4313874
Policy mu Max                2.8128877
Policy mu Min                -2.7725933
Policy log std Mean          -0.8662138
Policy log std Std           0.48987103
Policy log std Max           -0.22172302
Policy log std Min           -3.4540534
Z mean eval                  3.1445558
Z variance eval              0.02836821
total_rewards                [12075.60896847 12085.25332074 12028.61719994 12003.76323808
 12078.48656171 12268.79834893 11956.34154688 11822.26862722
 12042.9576236  11930.5175592 ]
total_rewards_mean           12029.261299476439
total_rewards_std            111.28165868333808
total_rewards_max            12268.798348932503
total_rewards_min            11822.26862722393
Number of train steps total  1136000
Number of env steps total    1422000
Number of rollouts total     0
Train Time (s)               115.60525719029829
(Previous) Eval Time (s)     22.650962103158236
Sample Time (s)              16.29970827139914
Epoch Time (s)               154.55592756485566
Total Train Time (s)         43728.186473958194
Epoch                        283
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:45:07.754451 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #283 | Epoch Duration: 155.091210603714
2020-01-13 20:45:07.754680 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #283 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.144193
Z variance train             0.028294897
KL Divergence                51.018158
KL Loss                      5.1018157
QF Loss                      381.2374
VF Loss                      128.31522
Policy Loss                  -4928.1934
Q Predictions Mean           4936.022
Q Predictions Std            496.98944
Q Predictions Max            5554.505
Q Predictions Min            3293.152
V Predictions Mean           4934.623
V Predictions Std            495.50174
V Predictions Max            5564.5186
V Predictions Min            3297.2686
Log Pis Mean                 5.7335544
Log Pis Std                  4.2343416
Log Pis Max                  15.2742405
Log Pis Min                  -11.387351
Policy mu Mean               -0.13422076
Policy mu Std                1.4177073
Policy mu Max                2.9329515
Policy mu Min                -2.7365475
Policy log std Mean          -0.8956935
Policy log std Std           0.4642122
Policy log std Max           -0.17839152
Policy log std Min           -3.358243
Z mean eval                  3.1286016
Z variance eval              0.027357649
total_rewards                [11828.3831758  12263.58538372 12168.11177436 12118.10981619
 12119.29001278 11922.17280874 12151.34998571 11736.27288288
 12156.78917941 11950.39703029]
total_rewards_mean           12041.44620498811
total_rewards_std            162.40458671039886
total_rewards_max            12263.585383716729
total_rewards_min            11736.272882884765
Number of train steps total  1140000
Number of env steps total    1427000
Number of rollouts total     0
Train Time (s)               116.88140120590106
(Previous) Eval Time (s)     23.1859490419738
Sample Time (s)              15.828047316055745
Epoch Time (s)               155.8953975639306
Total Train Time (s)         43883.46453465568
Epoch                        284
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:47:43.030601 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #284 | Epoch Duration: 155.27574348449707
2020-01-13 20:47:43.030804 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #284 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.128085
Z variance train             0.027414244
KL Divergence                50.884422
KL Loss                      5.0884423
QF Loss                      548.2264
VF Loss                      184.76657
Policy Loss                  -4862.9624
Q Predictions Mean           4867.3525
Q Predictions Std            609.6726
Q Predictions Max            5733.5547
Q Predictions Min            3361.8923
V Predictions Mean           4870.6367
V Predictions Std            608.8546
V Predictions Max            5731.743
V Predictions Min            3366.658
Log Pis Mean                 5.721976
Log Pis Std                  3.6952474
Log Pis Max                  15.744564
Log Pis Min                  -3.297251
Policy mu Mean               -0.10694355
Policy mu Std                1.4012344
Policy mu Max                2.7965686
Policy mu Min                -2.730668
Policy log std Mean          -0.91101605
Policy log std Std           0.50491303
Policy log std Max           0.26845014
Policy log std Min           -3.51556
Z mean eval                  3.148608
Z variance eval              0.022587653
total_rewards                [11364.94474484 11818.98925838 11923.0739624  11828.09157968
  7002.62911911 11533.96565987 11710.40702298 11428.86766924
 11365.11858189 11571.39759294]
total_rewards_mean           11154.748519134746
total_rewards_std            1396.9525376403158
total_rewards_max            11923.073962403443
total_rewards_min            7002.629119108771
Number of train steps total  1144000
Number of env steps total    1432000
Number of rollouts total     0
Train Time (s)               113.04189713159576
(Previous) Eval Time (s)     22.566035558935255
Sample Time (s)              16.090209851507097
Epoch Time (s)               151.6981425420381
Total Train Time (s)         44035.43085049512
Epoch                        285
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:50:14.999241 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #285 | Epoch Duration: 151.96831560134888
2020-01-13 20:50:14.999465 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #285 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.148915
Z variance train             0.022652777
KL Divergence                51.89425
KL Loss                      5.189425
QF Loss                      923.5311
VF Loss                      466.63757
Policy Loss                  -4893.7847
Q Predictions Mean           4902.7734
Q Predictions Std            572.1011
Q Predictions Max            5620.6284
Q Predictions Min            1405.8024
V Predictions Mean           4889.8213
V Predictions Std            575.1675
V Predictions Max            5657.071
V Predictions Min            1339.2366
Log Pis Mean                 5.162629
Log Pis Std                  3.6986065
Log Pis Max                  26.452463
Log Pis Min                  -3.0975883
Policy mu Mean               -0.05864076
Policy mu Std                1.3490078
Policy mu Max                3.1104908
Policy mu Min                -4.817207
Policy log std Mean          -0.9160387
Policy log std Std           0.48444617
Policy log std Max           0.1635592
Policy log std Min           -3.43324
Z mean eval                  3.138874
Z variance eval              0.03182835
total_rewards                [11776.32962201 11991.06895804 11722.64467089 11936.88499785
 12171.92076203 12342.54648073 11898.77827887 12155.22840892
 11838.25202104 12072.25619627]
total_rewards_mean           11990.591039664594
total_rewards_std            185.13570710954144
total_rewards_max            12342.546480728084
total_rewards_min            11722.644670891783
Number of train steps total  1148000
Number of env steps total    1437000
Number of rollouts total     0
Train Time (s)               106.68722777767107
(Previous) Eval Time (s)     22.835922288242728
Sample Time (s)              15.718213501386344
Epoch Time (s)               145.24136356730014
Total Train Time (s)         44180.31943683745
Epoch                        286
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:52:39.892073 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #286 | Epoch Duration: 144.89243245124817
2020-01-13 20:52:39.892311 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #286 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.137861
Z variance train             0.031749878
KL Divergence                51.980618
KL Loss                      5.198062
QF Loss                      448.72968
VF Loss                      146.12898
Policy Loss                  -4828.771
Q Predictions Mean           4834.009
Q Predictions Std            629.9439
Q Predictions Max            5538.506
Q Predictions Min            65.67732
V Predictions Mean           4833.3887
V Predictions Std            626.3921
V Predictions Max            5541.2783
V Predictions Min            194.91867
Log Pis Mean                 5.6736073
Log Pis Std                  3.8901126
Log Pis Max                  16.294205
Log Pis Min                  -2.8937032
Policy mu Mean               -0.12941907
Policy mu Std                1.4024907
Policy mu Max                2.9722836
Policy mu Min                -2.7166421
Policy log std Mean          -0.912271
Policy log std Std           0.49662402
Policy log std Max           -0.035907865
Policy log std Min           -3.2496533
Z mean eval                  3.1250987
Z variance eval              0.04384009
total_rewards                [11492.74290625 12176.03264629 12255.14693581 12091.15549744
 12205.77658479 11715.38492372 12192.2795396  12250.08313766
 11342.09387922 12195.847549  ]
total_rewards_mean           11991.654359978316
total_rewards_std            324.81833476736654
total_rewards_max            12255.14693581492
total_rewards_min            11342.093879224885
Number of train steps total  1152000
Number of env steps total    1442000
Number of rollouts total     0
Train Time (s)               115.6957969982177
(Previous) Eval Time (s)     22.486710470635444
Sample Time (s)              16.619258818216622
Epoch Time (s)               154.80176628706977
Total Train Time (s)         44335.285100500565
Epoch                        287
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:55:14.862341 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #287 | Epoch Duration: 154.96983361244202
2020-01-13 20:55:14.862596 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #287 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.124426
Z variance train             0.04371816
KL Divergence                49.748615
KL Loss                      4.9748616
QF Loss                      410.1624
VF Loss                      103.02037
Policy Loss                  -4904.622
Q Predictions Mean           4909.7573
Q Predictions Std            544.9165
Q Predictions Max            5625.299
Q Predictions Min            3234.8337
V Predictions Mean           4900.7607
V Predictions Std            541.69226
V Predictions Max            5609.116
V Predictions Min            3278.191
Log Pis Mean                 5.1750927
Log Pis Std                  3.7796829
Log Pis Max                  20.159664
Log Pis Min                  -3.44396
Policy mu Mean               -0.07790497
Policy mu Std                1.3753008
Policy mu Max                3.1443808
Policy mu Min                -2.6367772
Policy log std Mean          -0.9352503
Policy log std Std           0.51404065
Policy log std Max           -0.15555286
Policy log std Min           -3.5101352
Z mean eval                  3.1108527
Z variance eval              0.0470632
total_rewards                [10362.26274647  5975.72294428  9908.18503608 10469.07935681
 10517.56219814 10560.43514026 10529.87078794 10924.36526787
 10525.02962011 10556.19530139]
total_rewards_mean           10032.87083993429
total_rewards_std            1372.8030564918754
total_rewards_max            10924.365267869278
total_rewards_min            5975.722944275079
Number of train steps total  1156000
Number of env steps total    1447000
Number of rollouts total     0
Train Time (s)               117.5321874502115
(Previous) Eval Time (s)     22.65445600170642
Sample Time (s)              15.802104036323726
Epoch Time (s)               155.98874748824164
Total Train Time (s)         44491.12466762774
Epoch                        288
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:57:50.703498 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #288 | Epoch Duration: 155.84072542190552
2020-01-13 20:57:50.703656 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #288 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.110659
Z variance train             0.047025803
KL Divergence                47.89239
KL Loss                      4.7892394
QF Loss                      1074.3497
VF Loss                      209.36331
Policy Loss                  -4961.8022
Q Predictions Mean           4964.787
Q Predictions Std            516.30426
Q Predictions Max            5661.549
Q Predictions Min            3037.3198
V Predictions Mean           4961.343
V Predictions Std            514.1619
V Predictions Max            5660.7974
V Predictions Min            3085.998
Log Pis Mean                 5.612966
Log Pis Std                  3.7757888
Log Pis Max                  15.743873
Log Pis Min                  -5.476667
Policy mu Mean               -0.03186412
Policy mu Std                1.4033486
Policy mu Max                2.8706534
Policy mu Min                -3.1101525
Policy log std Mean          -0.9301811
Policy log std Std           0.5108786
Policy log std Max           -0.1867001
Policy log std Min           -3.395862
Z mean eval                  3.0891137
Z variance eval              0.0530095
total_rewards                [11680.78389256 11902.73104085 12007.69007926 12028.36773381
 12182.27555673 12070.22441718 11992.2936595  11974.21479635
 11872.02632984 11888.96706629]
total_rewards_mean           11959.957457235838
total_rewards_std            127.97486916548606
total_rewards_max            12182.275556731232
total_rewards_min            11680.783892556537
Number of train steps total  1160000
Number of env steps total    1452000
Number of rollouts total     0
Train Time (s)               109.54128004005179
(Previous) Eval Time (s)     22.506141541991383
Sample Time (s)              15.790350919123739
Epoch Time (s)               147.8377725011669
Total Train Time (s)         44639.126159193926
Epoch                        289
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:00:18.707244 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #289 | Epoch Duration: 148.00346612930298
2020-01-13 21:00:18.707468 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #289 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.089184
Z variance train             0.05287341
KL Divergence                47.342285
KL Loss                      4.7342286
QF Loss                      399.8279
VF Loss                      79.544525
Policy Loss                  -4769.341
Q Predictions Mean           4777.8545
Q Predictions Std            550.994
Q Predictions Max            5490.1724
Q Predictions Min            3281.6494
V Predictions Mean           4773.1377
V Predictions Std            549.75775
V Predictions Max            5478.3496
V Predictions Min            3282.9038
Log Pis Mean                 5.4546537
Log Pis Std                  3.9613092
Log Pis Max                  15.038456
Log Pis Min                  -5.6365423
Policy mu Mean               -0.16463058
Policy mu Std                1.3728878
Policy mu Max                3.0821018
Policy mu Min                -2.6589587
Policy log std Mean          -0.91373616
Policy log std Std           0.51040304
Policy log std Max           -0.12866437
Policy log std Min           -3.498695
Z mean eval                  3.1316075
Z variance eval              0.026297178
total_rewards                [11598.9453362  11441.28852433 11959.20072635 11703.57748492
 11199.95181016 11464.56943033 11009.03169044 11739.06681035
 12089.87072183 11688.41759864]
total_rewards_mean           11589.392013354412
total_rewards_std            309.6082553995037
total_rewards_max            12089.870721833417
total_rewards_min            11009.031690437827
Number of train steps total  1164000
Number of env steps total    1457000
Number of rollouts total     0
Train Time (s)               110.38949816022068
(Previous) Eval Time (s)     22.67155699711293
Sample Time (s)              15.847611705772579
Epoch Time (s)               148.9086668631062
Total Train Time (s)         44788.149812065065
Epoch                        290
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:02:47.734583 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #290 | Epoch Duration: 149.0269763469696
2020-01-13 21:02:47.734790 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #290 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1306942
Z variance train             0.026222935
KL Divergence                49.567673
KL Loss                      4.9567676
QF Loss                      1344.8081
VF Loss                      335.81973
Policy Loss                  -4961.1113
Q Predictions Mean           4964.4727
Q Predictions Std            584.84973
Q Predictions Max            5648.82
Q Predictions Min            965.8515
V Predictions Mean           4973.4824
V Predictions Std            586.35547
V Predictions Max            5636.3667
V Predictions Min            1005.30524
Log Pis Mean                 5.8831043
Log Pis Std                  4.272234
Log Pis Max                  23.742073
Log Pis Min                  -3.8157983
Policy mu Mean               -0.06600378
Policy mu Std                1.4250784
Policy mu Max                4.007238
Policy mu Min                -5.900251
Policy log std Mean          -0.90696526
Policy log std Std           0.48453233
Policy log std Max           0.011108518
Policy log std Min           -3.3651986
Z mean eval                  3.148328
Z variance eval              0.025760364
total_rewards                [11278.27763624 11880.59879994 11673.82035912 12014.08960407
 11449.17320563 11481.95308736 11734.56874317 11666.76654393
 11700.69672186 11674.66632871]
total_rewards_mean           11655.461103002974
total_rewards_std            200.83985559883976
total_rewards_max            12014.089604068213
total_rewards_min            11278.277636242816
Number of train steps total  1168000
Number of env steps total    1462000
Number of rollouts total     0
Train Time (s)               115.71029090695083
(Previous) Eval Time (s)     22.789557706099004
Sample Time (s)              16.475523697678
Epoch Time (s)               154.97537231072783
Total Train Time (s)         44942.70944299828
Epoch                        291
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:05:22.296415 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #291 | Epoch Duration: 154.56147408485413
2020-01-13 21:05:22.296622 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #291 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1456218
Z variance train             0.025621515
KL Divergence                51.05011
KL Loss                      5.105011
QF Loss                      679.33026
VF Loss                      168.09554
Policy Loss                  -4935.843
Q Predictions Mean           4941.841
Q Predictions Std            611.89746
Q Predictions Max            5631.79
Q Predictions Min            595.3736
V Predictions Mean           4936.1025
V Predictions Std            609.8332
V Predictions Max            5641.238
V Predictions Min            652.83826
Log Pis Mean                 5.6394415
Log Pis Std                  4.179432
Log Pis Max                  19.747284
Log Pis Min                  -5.143014
Policy mu Mean               -0.07965233
Policy mu Std                1.4030156
Policy mu Max                4.212944
Policy mu Min                -3.3731167
Policy log std Mean          -0.9099722
Policy log std Std           0.4691042
Policy log std Max           0.5161575
Policy log std Min           -3.3686185
Z mean eval                  3.1585643
Z variance eval              0.025275543
total_rewards                [11359.20233721 11670.03109632 11851.58338909 11769.26456701
 11627.30089429 11550.42603276 11293.84596208 11562.07818943
 11768.70755249 11695.83353638]
total_rewards_mean           11614.827355705742
total_rewards_std            169.897510303374
total_rewards_max            11851.583389094032
total_rewards_min            11293.845962077372
Number of train steps total  1172000
Number of env steps total    1467000
Number of rollouts total     0
Train Time (s)               114.5099435010925
(Previous) Eval Time (s)     22.375358656980097
Sample Time (s)              15.831965820398182
Epoch Time (s)               152.71726797847077
Total Train Time (s)         45096.87451004656
Epoch                        292
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:07:56.465574 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #292 | Epoch Duration: 154.16881346702576
2020-01-13 21:07:56.465774 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #292 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1604497
Z variance train             0.025312364
KL Divergence                50.963768
KL Loss                      5.096377
QF Loss                      838.8146
VF Loss                      336.5476
Policy Loss                  -4808.7637
Q Predictions Mean           4811.6147
Q Predictions Std            612.15674
Q Predictions Max            5572.4355
Q Predictions Min            3306.0488
V Predictions Mean           4806.6133
V Predictions Std            611.54034
V Predictions Max            5573.2827
V Predictions Min            3300.5557
Log Pis Mean                 5.8593616
Log Pis Std                  3.896272
Log Pis Max                  16.485926
Log Pis Min                  -3.348071
Policy mu Mean               -0.13340306
Policy mu Std                1.4084373
Policy mu Max                3.2338293
Policy mu Min                -3.0631897
Policy log std Mean          -0.92239493
Policy log std Std           0.49852383
Policy log std Max           -0.09147632
Policy log std Min           -3.6221485
Z mean eval                  3.1674054
Z variance eval              0.02408061
total_rewards                [11895.40882627 12150.08886981 12119.5586599  12080.77691379
 12085.19933506 12240.0824384  12264.20920645 12206.43513527
 12211.31831531 11893.18090316]
total_rewards_mean           12114.62586034235
total_rewards_std            125.01220357790794
total_rewards_max            12264.209206447675
total_rewards_min            11893.180903162103
Number of train steps total  1176000
Number of env steps total    1472000
Number of rollouts total     0
Train Time (s)               121.59375593531877
(Previous) Eval Time (s)     23.82660243054852
Sample Time (s)              17.520600205753
Epoch Time (s)               162.94095857162029
Total Train Time (s)         45258.499254557304
Epoch                        293
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:10:38.094577 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #293 | Epoch Duration: 161.6286461353302
2020-01-13 21:10:38.094868 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #293 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1662877
Z variance train             0.02406958
KL Divergence                51.024673
KL Loss                      5.1024675
QF Loss                      1023.461
VF Loss                      103.85992
Policy Loss                  -4969.643
Q Predictions Mean           4978.34
Q Predictions Std            530.48346
Q Predictions Max            5691.3447
Q Predictions Min            3504.083
V Predictions Mean           4976.277
V Predictions Std            529.55145
V Predictions Max            5685.997
V Predictions Min            3498.6636
Log Pis Mean                 5.8529196
Log Pis Std                  3.8868282
Log Pis Max                  16.021112
Log Pis Min                  -4.8415513
Policy mu Mean               -0.16361631
Policy mu Std                1.3985167
Policy mu Max                3.0941136
Policy mu Min                -3.1451385
Policy log std Mean          -0.92303544
Policy log std Std           0.5143384
Policy log std Max           -0.17197457
Policy log std Min           -3.5093918
Z mean eval                  3.1237998
Z variance eval              0.029720072
total_rewards                [12033.62351278 12297.6702898  12194.32623587 12275.64948292
 11647.8065311  12126.92030943 12021.06185253 12086.92353194
 11799.12640187 12008.79818895]
total_rewards_mean           12049.190633718714
total_rewards_std            191.7973404507757
total_rewards_max            12297.67028980119
total_rewards_min            11647.806531095828
Number of train steps total  1180000
Number of env steps total    1477000
Number of rollouts total     0
Train Time (s)               121.91190095618367
(Previous) Eval Time (s)     22.513955373782665
Sample Time (s)              16.08093179948628
Epoch Time (s)               160.50678812945262
Total Train Time (s)         45419.675106602255
Epoch                        294
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:13:19.273433 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #294 | Epoch Duration: 161.17832851409912
2020-01-13 21:13:19.273680 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #294 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1245396
Z variance train             0.029695023
KL Divergence                50.34932
KL Loss                      5.034932
QF Loss                      402.75806
VF Loss                      203.0324
Policy Loss                  -4945.329
Q Predictions Mean           4949.951
Q Predictions Std            541.203
Q Predictions Max            5637.546
Q Predictions Min            3367.8674
V Predictions Mean           4939.675
V Predictions Std            538.6016
V Predictions Max            5632.0225
V Predictions Min            3356.7234
Log Pis Mean                 6.0258656
Log Pis Std                  3.9205189
Log Pis Max                  19.724966
Log Pis Min                  -4.6506963
Policy mu Mean               -0.08507872
Policy mu Std                1.4255906
Policy mu Max                2.9621596
Policy mu Min                -3.0400987
Policy log std Mean          -0.9236808
Policy log std Std           0.48743585
Policy log std Max           0.016563416
Policy log std Min           -3.282222
Z mean eval                  3.1825378
Z variance eval              0.029231023
total_rewards                [11698.74801963 12009.00582038 12182.99795496 12294.12604018
 12176.84520846 11968.10572562 12147.83504165 12026.27237388
 12119.39170681 11778.45624901]
total_rewards_mean           12040.178414056805
total_rewards_std            176.87908662886056
total_rewards_max            12294.126040180481
total_rewards_min            11698.748019630006
Number of train steps total  1184000
Number of env steps total    1482000
Number of rollouts total     0
Train Time (s)               115.87640117993578
(Previous) Eval Time (s)     23.18518116697669
Sample Time (s)              15.755481408443302
Epoch Time (s)               154.81706375535578
Total Train Time (s)         45573.72251721518
Epoch                        295
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:15:53.326933 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #295 | Epoch Duration: 154.05304169654846
2020-01-13 21:15:53.327234 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #295 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1837552
Z variance train             0.02916469
KL Divergence                51.753124
KL Loss                      5.1753125
QF Loss                      868.33875
VF Loss                      134.26471
Policy Loss                  -4940.751
Q Predictions Mean           4946.8706
Q Predictions Std            634.16095
Q Predictions Max            5620.5083
Q Predictions Min            -255.71877
V Predictions Mean           4934.4785
V Predictions Std            632.23584
V Predictions Max            5615.2554
V Predictions Min            -297.32065
Log Pis Mean                 5.8400354
Log Pis Std                  3.8848176
Log Pis Max                  15.929407
Log Pis Min                  -3.964095
Policy mu Mean               -0.11157644
Policy mu Std                1.3905045
Policy mu Max                2.807918
Policy mu Min                -3.3317747
Policy log std Mean          -0.91456795
Policy log std Std           0.48380476
Policy log std Max           0.24430072
Policy log std Min           -3.4300256
Z mean eval                  3.1767962
Z variance eval              0.025594404
total_rewards                [11552.39292062 12158.66307192 12196.94726658 12117.47052528
 12083.01098006 11601.64960714 11911.80939969 12407.75211021
 12009.40193849 12216.27396815]
total_rewards_mean           12025.537178813825
total_rewards_std            256.52839851034963
total_rewards_max            12407.75211020527
total_rewards_min            11552.392920616647
Number of train steps total  1188000
Number of env steps total    1487000
Number of rollouts total     0
Train Time (s)               117.48130629584193
(Previous) Eval Time (s)     22.42082596803084
Sample Time (s)              15.980397251900285
Epoch Time (s)               155.88252951577306
Total Train Time (s)         45729.46688399371
Epoch                        296
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:18:29.075857 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #296 | Epoch Duration: 155.74837017059326
2020-01-13 21:18:29.076143 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #296 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1782525
Z variance train             0.025658447
KL Divergence                53.887398
KL Loss                      5.38874
QF Loss                      580.91266
VF Loss                      130.9967
Policy Loss                  -4970.901
Q Predictions Mean           4975.291
Q Predictions Std            523.4168
Q Predictions Max            5718.49
Q Predictions Min            3484.4712
V Predictions Mean           4971.038
V Predictions Std            524.1639
V Predictions Max            5713.3066
V Predictions Min            3477.463
Log Pis Mean                 5.5607014
Log Pis Std                  3.8688643
Log Pis Max                  16.462036
Log Pis Min                  -4.230394
Policy mu Mean               -0.055511873
Policy mu Std                1.4059045
Policy mu Max                2.9453213
Policy mu Min                -2.7874122
Policy log std Mean          -0.920356
Policy log std Std           0.4895389
Policy log std Max           0.1512965
Policy log std Min           -3.1908746
Z mean eval                  3.202932
Z variance eval              0.023239773
total_rewards                [11899.09179225 12090.46702555 12326.17457228 11880.05662066
 11972.48249449 11762.35194451 12175.97456566 12206.36586161
 11981.5170234  12145.6712485 ]
total_rewards_mean           12044.015314891754
total_rewards_std            164.9602972097194
total_rewards_max            12326.174572284272
total_rewards_min            11762.351944512702
Number of train steps total  1192000
Number of env steps total    1492000
Number of rollouts total     0
Train Time (s)               119.94219002313912
(Previous) Eval Time (s)     22.286337467841804
Sample Time (s)              15.648550274316221
Epoch Time (s)               157.87707776529714
Total Train Time (s)         45887.88115403289
Epoch                        297
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:21:07.492596 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #297 | Epoch Duration: 158.41624450683594
2020-01-13 21:21:07.492824 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #297 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2041764
Z variance train             0.02324859
KL Divergence                54.127678
KL Loss                      5.412768
QF Loss                      668.3925
VF Loss                      234.62471
Policy Loss                  -4961.339
Q Predictions Mean           4966.0366
Q Predictions Std            589.40137
Q Predictions Max            5633.7847
Q Predictions Min            3366.5647
V Predictions Mean           4951.3394
V Predictions Std            587.76
V Predictions Max            5609.659
V Predictions Min            3350.3047
Log Pis Mean                 5.341132
Log Pis Std                  3.7577229
Log Pis Max                  18.234482
Log Pis Min                  -3.1466258
Policy mu Mean               -0.074371
Policy mu Std                1.3628672
Policy mu Max                3.1210976
Policy mu Min                -3.4591343
Policy log std Mean          -0.9403348
Policy log std Std           0.49082553
Policy log std Max           -0.14325392
Policy log std Min           -3.361277
Z mean eval                  3.2178452
Z variance eval              0.038567718
total_rewards                [11887.91239673 12017.77293613 12229.34906702 12509.32767286
 12222.5332495  11870.21658151 12079.25568207 12010.10785275
 11812.97062954 12410.78799317]
total_rewards_mean           12105.023406129463
total_rewards_std            221.60126308840333
total_rewards_max            12509.327672864758
total_rewards_min            11812.97062953937
Number of train steps total  1196000
Number of env steps total    1497000
Number of rollouts total     0
Train Time (s)               112.86414650827646
(Previous) Eval Time (s)     22.82522174390033
Sample Time (s)              15.947594012599438
Epoch Time (s)               151.63696226477623
Total Train Time (s)         46039.751913536806
Epoch                        298
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:23:39.370068 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #298 | Epoch Duration: 151.87708020210266
2020-01-13 21:23:39.370384 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #298 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.218303
Z variance train             0.03838547
KL Divergence                54.9606
KL Loss                      5.4960604
QF Loss                      735.98254
VF Loss                      383.56866
Policy Loss                  -4940.325
Q Predictions Mean           4942.2534
Q Predictions Std            598.0956
Q Predictions Max            5588.9053
Q Predictions Min            1055.1486
V Predictions Mean           4928.6406
V Predictions Std            593.9094
V Predictions Max            5564.6353
V Predictions Min            1063.0269
Log Pis Mean                 5.624538
Log Pis Std                  3.8720887
Log Pis Max                  18.168333
Log Pis Min                  -4.96249
Policy mu Mean               -0.017145654
Policy mu Std                1.4128098
Policy mu Max                4.1088104
Policy mu Min                -3.8484616
Policy log std Mean          -0.9402625
Policy log std Std           0.48620832
Policy log std Max           0.0068142414
Policy log std Min           -3.4775333
Z mean eval                  3.1876013
Z variance eval              0.0509799
total_rewards                [12023.46640615 12426.14238758 11761.46345797 12418.49237782
 12334.57538866 12360.64140391 12339.35156818 12189.37884576
 12197.68706851 11970.27930352]
total_rewards_mean           12202.147820807242
total_rewards_std            209.41260423751459
total_rewards_max            12426.142387577134
total_rewards_min            11761.46345796672
Number of train steps total  1200000
Number of env steps total    1502000
Number of rollouts total     0
Train Time (s)               117.06852861493826
(Previous) Eval Time (s)     23.065001361072063
Sample Time (s)              16.757451170124114
Epoch Time (s)               156.89098114613444
Total Train Time (s)         46196.64347593812
Epoch                        299
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:26:16.265975 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #299 | Epoch Duration: 156.89530444145203
2020-01-13 21:26:16.266264 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #299 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1874213
Z variance train             0.050991815
KL Divergence                53.199406
KL Loss                      5.3199406
QF Loss                      397.04614
VF Loss                      141.07101
Policy Loss                  -5006.369
Q Predictions Mean           5009.549
Q Predictions Std            556.1984
Q Predictions Max            5664.815
Q Predictions Min            3439.0486
V Predictions Mean           5007.919
V Predictions Std            554.6529
V Predictions Max            5678.2544
V Predictions Min            3445.2449
Log Pis Mean                 5.8615513
Log Pis Std                  3.7780247
Log Pis Max                  15.143332
Log Pis Min                  -3.677493
Policy mu Mean               -0.10766345
Policy mu Std                1.3987103
Policy mu Max                3.1612916
Policy mu Min                -3.0313044
Policy log std Mean          -0.92728657
Policy log std Std           0.50496185
Policy log std Max           0.34355783
Policy log std Min           -3.4558544
Z mean eval                  3.1884434
Z variance eval              0.027858919
total_rewards                [12203.79983694 12306.48635601 12054.41578339 12390.61855314
 12257.87779587 11746.77350741 12031.88037483 10856.59746053
 12180.30534389 12276.74483477]
total_rewards_mean           12030.5499846766
total_rewards_std            427.76012392209384
total_rewards_max            12390.618553139984
total_rewards_min            10856.597460530054
Number of train steps total  1204000
Number of env steps total    1507000
Number of rollouts total     0
Train Time (s)               120.02708418900147
(Previous) Eval Time (s)     23.06903068907559
Sample Time (s)              16.455553082749248
Epoch Time (s)               159.5516679608263
Total Train Time (s)         46355.832715538796
Epoch                        300
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:28:55.456680 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #300 | Epoch Duration: 159.19021248817444
2020-01-13 21:28:55.456970 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #300 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.188169
Z variance train             0.027858982
KL Divergence                54.33215
KL Loss                      5.433215
QF Loss                      289.16522
VF Loss                      93.90289
Policy Loss                  -4971.2485
Q Predictions Mean           4977.665
Q Predictions Std            551.69867
Q Predictions Max            5669.827
Q Predictions Min            3393.9092
V Predictions Mean           4975.337
V Predictions Std            551.0268
V Predictions Max            5654.7363
V Predictions Min            3390.5996
Log Pis Mean                 5.521411
Log Pis Std                  3.9482467
Log Pis Max                  19.174755
Log Pis Min                  -3.3729057
Policy mu Mean               -0.124343455
Policy mu Std                1.385667
Policy mu Max                2.8049335
Policy mu Min                -4.5034375
Policy log std Mean          -0.943999
Policy log std Std           0.5115642
Policy log std Max           -0.08890498
Policy log std Min           -3.4288764
Z mean eval                  3.1880546
Z variance eval              0.06319141
total_rewards                [11617.13807359 11743.42437774 12176.89930166 11954.79655306
 11864.2037769  12037.68164231 11829.32183329 12195.60137691
 11731.11776894 11931.75233602]
total_rewards_mean           11908.193704044377
total_rewards_std            180.46437677118143
total_rewards_max            12195.601376910034
total_rewards_min            11617.138073593853
Number of train steps total  1208000
Number of env steps total    1512000
Number of rollouts total     0
Train Time (s)               119.2751663629897
(Previous) Eval Time (s)     22.707285044249147
Sample Time (s)              15.693323217332363
Epoch Time (s)               157.6757746245712
Total Train Time (s)         46513.255668057594
Epoch                        301
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:31:32.882628 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #301 | Epoch Duration: 157.42551565170288
2020-01-13 21:31:32.882828 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #301 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1885781
Z variance train             0.063381955
KL Divergence                53.445206
KL Loss                      5.3445206
QF Loss                      444.15088
VF Loss                      144.04572
Policy Loss                  -4900.58
Q Predictions Mean           4903.996
Q Predictions Std            542.34863
Q Predictions Max            5637.4487
Q Predictions Min            3363.2915
V Predictions Mean           4894.2363
V Predictions Std            540.05206
V Predictions Max            5624.467
V Predictions Min            3361.9521
Log Pis Mean                 5.9950457
Log Pis Std                  3.8683147
Log Pis Max                  17.267748
Log Pis Min                  -3.735928
Policy mu Mean               -0.15790153
Policy mu Std                1.4038976
Policy mu Max                3.0606036
Policy mu Min                -3.0073347
Policy log std Mean          -0.9164222
Policy log std Std           0.4889641
Policy log std Max           0.30541766
Policy log std Min           -3.4034257
Z mean eval                  3.1984787
Z variance eval              0.030039081
total_rewards                [12017.07118064  4266.38065812 12364.26593343 12070.3661866
 11825.23962798 11889.12196936 12166.27017364 12004.43053477
 12371.24829474 12018.12021323]
total_rewards_mean           11299.25147725208
total_rewards_std            2350.4248523084825
total_rewards_max            12371.248294739853
total_rewards_min            4266.380658121275
Number of train steps total  1212000
Number of env steps total    1517000
Number of rollouts total     0
Train Time (s)               121.34447493031621
(Previous) Eval Time (s)     22.456736880820245
Sample Time (s)              17.425004162825644
Epoch Time (s)               161.2262159739621
Total Train Time (s)         46675.0082020713
Epoch                        302
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:34:14.641597 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #302 | Epoch Duration: 161.75861120224
2020-01-13 21:34:14.641891 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #302 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1976752
Z variance train             0.030026164
KL Divergence                52.704758
KL Loss                      5.270476
QF Loss                      792.2026
VF Loss                      176.4067
Policy Loss                  -5002.1816
Q Predictions Mean           5010.1064
Q Predictions Std            527.1359
Q Predictions Max            5702.129
Q Predictions Min            3495.3872
V Predictions Mean           5007.9434
V Predictions Std            527.4682
V Predictions Max            5692.0938
V Predictions Min            3493.5183
Log Pis Mean                 5.8585005
Log Pis Std                  3.7509928
Log Pis Max                  18.290058
Log Pis Min                  -4.7025566
Policy mu Mean               -0.11706022
Policy mu Std                1.4070503
Policy mu Max                2.950232
Policy mu Min                -3.6739004
Policy log std Mean          -0.92743534
Policy log std Std           0.50109226
Policy log std Max           -0.052302957
Policy log std Min           -3.4673963
Z mean eval                  3.171409
Z variance eval              0.053674124
total_rewards                [11719.110811    9119.04898767 12012.76420794 11962.85387052
 12098.82238196 12078.72416101 12307.93882792 11832.73733383
 11959.51429035 12230.65860666]
total_rewards_mean           11732.217347886432
total_rewards_std            886.3889500436192
total_rewards_max            12307.938827916432
total_rewards_min            9119.048987671264
Number of train steps total  1216000
Number of env steps total    1522000
Number of rollouts total     0
Train Time (s)               115.49120211135596
(Previous) Eval Time (s)     22.9887637430802
Sample Time (s)              17.55577606521547
Epoch Time (s)               156.03574191965163
Total Train Time (s)         46831.06265395321
Epoch                        303
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:36:50.696700 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #303 | Epoch Duration: 156.05460476875305
2020-01-13 21:36:50.696897 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #303 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1712508
Z variance train             0.053674795
KL Divergence                49.976425
KL Loss                      4.9976425
QF Loss                      877.3042
VF Loss                      152.65778
Policy Loss                  -4867.708
Q Predictions Mean           4877.7266
Q Predictions Std            639.71356
Q Predictions Max            5609.6875
Q Predictions Min            460.16434
V Predictions Mean           4872.4316
V Predictions Std            637.574
V Predictions Max            5608.3345
V Predictions Min            483.92215
Log Pis Mean                 6.1813097
Log Pis Std                  3.8437145
Log Pis Max                  20.025925
Log Pis Min                  -3.2700782
Policy mu Mean               -0.108115464
Policy mu Std                1.434654
Policy mu Max                3.522223
Policy mu Min                -3.8178067
Policy log std Mean          -0.9126527
Policy log std Std           0.49575418
Policy log std Max           -0.02019918
Policy log std Min           -3.47019
Z mean eval                  3.1797416
Z variance eval              0.017957153
total_rewards                [12201.5433098  11987.09140925 12211.71403918 12499.1671185
 12231.00556735 12279.61898294 12098.11881664 12267.20986698
 11916.81628268 12202.62754439]
total_rewards_mean           12189.4912937733
total_rewards_std            153.70871653855795
total_rewards_max            12499.167118504773
total_rewards_min            11916.816282681799
Number of train steps total  1220000
Number of env steps total    1527000
Number of rollouts total     0
Train Time (s)               117.96884600585327
(Previous) Eval Time (s)     23.007315364200622
Sample Time (s)              15.670324394945055
Epoch Time (s)               156.64648576499894
Total Train Time (s)         46987.615367587656
Epoch                        304
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:39:27.256269 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #304 | Epoch Duration: 156.55921244621277
2020-01-13 21:39:27.256543 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #304 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1790576
Z variance train             0.017942403
KL Divergence                52.451904
KL Loss                      5.2451906
QF Loss                      480.256
VF Loss                      102.173935
Policy Loss                  -4987.1123
Q Predictions Mean           4990.256
Q Predictions Std            547.5535
Q Predictions Max            5611.4854
Q Predictions Min            3427.4207
V Predictions Mean           4991.303
V Predictions Std            546.982
V Predictions Max            5615.3354
V Predictions Min            3448.2256
Log Pis Mean                 5.8432884
Log Pis Std                  4.1990876
Log Pis Max                  16.249626
Log Pis Min                  -6.1087584
Policy mu Mean               -0.11068895
Policy mu Std                1.4128861
Policy mu Max                3.1497295
Policy mu Min                -3.1330562
Policy log std Mean          -0.9310023
Policy log std Std           0.5057557
Policy log std Max           -0.1966089
Policy log std Min           -3.4740124
Z mean eval                  3.257182
Z variance eval              0.023900833
total_rewards                [11759.61939343 12193.11381217 11744.94161924 11961.80498486
 12106.58194403 11964.82297106 11767.72393928 12182.2501078
 12207.86001168 11869.12662951]
total_rewards_mean           11975.784541307752
total_rewards_std            177.71425399758766
total_rewards_max            12207.860011683219
total_rewards_min            11744.941619243027
Number of train steps total  1224000
Number of env steps total    1532000
Number of rollouts total     0
Train Time (s)               119.54358545225114
(Previous) Eval Time (s)     22.919755013659596
Sample Time (s)              16.216339469887316
Epoch Time (s)               158.67967993579805
Total Train Time (s)         47146.86136941053
Epoch                        305
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:42:06.502833 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #305 | Epoch Duration: 159.24609184265137
2020-01-13 21:42:06.503008 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #305 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2584825
Z variance train             0.023899086
KL Divergence                52.30089
KL Loss                      5.230089
QF Loss                      334.6239
VF Loss                      208.70728
Policy Loss                  -4945.792
Q Predictions Mean           4951.7227
Q Predictions Std            552.6086
Q Predictions Max            5647.6074
Q Predictions Min            3359.7468
V Predictions Mean           4942.2036
V Predictions Std            550.8568
V Predictions Max            5631.0
V Predictions Min            3355.0515
Log Pis Mean                 5.4394817
Log Pis Std                  3.6226053
Log Pis Max                  15.961128
Log Pis Min                  -5.1456914
Policy mu Mean               -0.11473521
Policy mu Std                1.3882763
Policy mu Max                3.00578
Policy mu Min                -2.6735983
Policy log std Mean          -0.9026272
Policy log std Std           0.48930526
Policy log std Max           -0.11627877
Policy log std Min           -3.173246
Z mean eval                  3.219605
Z variance eval              0.033668555
total_rewards                [11797.18758503 12307.0296902  12159.35145764 11937.16992837
 12134.97331844 11847.65028066 11997.80119431 12024.62326136
 12114.85412069 11907.2736142 ]
total_rewards_mean           12022.791445090867
total_rewards_std            149.45739750070658
total_rewards_max            12307.029690204034
total_rewards_min            11797.187585031286
Number of train steps total  1228000
Number of env steps total    1537000
Number of rollouts total     0
Train Time (s)               116.9551522010006
(Previous) Eval Time (s)     23.48583769891411
Sample Time (s)              17.183646383695304
Epoch Time (s)               157.62463628361002
Total Train Time (s)         47304.39097913029
Epoch                        306
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:44:44.035749 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #306 | Epoch Duration: 157.5325562953949
2020-01-13 21:44:44.035958 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #306 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.219474
Z variance train             0.033605404
KL Divergence                51.606194
KL Loss                      5.1606193
QF Loss                      571.46606
VF Loss                      177.41351
Policy Loss                  -5067.469
Q Predictions Mean           5071.412
Q Predictions Std            487.5107
Q Predictions Max            5755.777
Q Predictions Min            3520.6753
V Predictions Mean           5065.059
V Predictions Std            485.39215
V Predictions Max            5747.4775
V Predictions Min            3508.01
Log Pis Mean                 6.0133877
Log Pis Std                  4.072412
Log Pis Max                  17.798454
Log Pis Min                  -3.0077517
Policy mu Mean               -0.21294296
Policy mu Std                1.441495
Policy mu Max                3.1503918
Policy mu Min                -3.72822
Policy log std Mean          -0.9048812
Policy log std Std           0.5028256
Policy log std Max           -0.16499555
Policy log std Min           -3.4745142
Z mean eval                  3.237786
Z variance eval              0.015512815
total_rewards                [11900.60764284 12362.8487584  12039.46544986 12198.99426574
 12447.24574541 12421.44964382 12224.07313964 12175.32937958
 12480.1983824  12245.16176354]
total_rewards_mean           12249.537417123205
total_rewards_std            175.86858028057728
total_rewards_max            12480.198382399425
total_rewards_min            11900.607642836047
Number of train steps total  1232000
Number of env steps total    1542000
Number of rollouts total     0
Train Time (s)               115.33027505595237
(Previous) Eval Time (s)     23.393457615748048
Sample Time (s)              15.98145694192499
Epoch Time (s)               154.7051896136254
Total Train Time (s)         47458.35167118721
Epoch                        307
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:47:17.998921 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #307 | Epoch Duration: 153.96280598640442
2020-01-13 21:47:17.999138 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #307 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.238195
Z variance train             0.015491635
KL Divergence                53.670414
KL Loss                      5.3670416
QF Loss                      810.75824
VF Loss                      124.744965
Policy Loss                  -5057.923
Q Predictions Mean           5062.745
Q Predictions Std            520.3415
Q Predictions Max            5717.2085
Q Predictions Min            3427.5444
V Predictions Mean           5056.88
V Predictions Std            518.24615
V Predictions Max            5702.8267
V Predictions Min            3426.3142
Log Pis Mean                 5.8273573
Log Pis Std                  3.9215224
Log Pis Max                  16.205467
Log Pis Min                  -4.4030743
Policy mu Mean               -0.12102562
Policy mu Std                1.4194541
Policy mu Max                2.9341617
Policy mu Min                -2.915581
Policy log std Mean          -0.9235471
Policy log std Std           0.50007045
Policy log std Max           -0.03441465
Policy log std Min           -3.458603
Z mean eval                  3.2376199
Z variance eval              0.008564778
total_rewards                [11846.02886367 12116.24384583 12063.26543956 12040.86966529
 12177.42341019 12135.55412353 11919.00897826 12077.74633312
 12068.98726876 12117.99656551]
total_rewards_mean           12056.312449371544
total_rewards_std            96.08440346115265
total_rewards_max            12177.423410187785
total_rewards_min            11846.028863673397
Number of train steps total  1236000
Number of env steps total    1547000
Number of rollouts total     0
Train Time (s)               114.83311030641198
(Previous) Eval Time (s)     22.65079302014783
Sample Time (s)              16.54533521644771
Epoch Time (s)               154.02923854300752
Total Train Time (s)         47612.17661042418
Epoch                        308
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:49:51.828105 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #308 | Epoch Duration: 153.82880640029907
2020-01-13 21:49:51.828302 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #308 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.238505
Z variance train             0.008562766
KL Divergence                56.28253
KL Loss                      5.6282535
QF Loss                      439.0758
VF Loss                      364.0903
Policy Loss                  -5030.2637
Q Predictions Mean           5037.5815
Q Predictions Std            541.4911
Q Predictions Max            5702.4746
Q Predictions Min            3429.5674
V Predictions Mean           5030.2627
V Predictions Std            541.7717
V Predictions Max            5696.727
V Predictions Min            3415.0352
Log Pis Mean                 5.5426884
Log Pis Std                  3.878558
Log Pis Max                  16.736725
Log Pis Min                  -9.585621
Policy mu Mean               -0.107084595
Policy mu Std                1.3939928
Policy mu Max                3.317225
Policy mu Min                -2.9444408
Policy log std Mean          -0.9150823
Policy log std Std           0.48905563
Policy log std Max           -0.09967816
Policy log std Min           -3.4053254
Z mean eval                  3.2462692
Z variance eval              0.03358599
total_rewards                [11653.45391784 12118.88972584 12076.79101266 12040.26211158
 11976.5477333  11972.96593974 11971.69464014 11921.71831379
 11896.14924156 11789.89388689]
total_rewards_mean           11941.836652334303
total_rewards_std            130.78865582505202
total_rewards_max            12118.889725840112
total_rewards_min            11653.453917835492
Number of train steps total  1240000
Number of env steps total    1552000
Number of rollouts total     0
Train Time (s)               117.82809420209378
(Previous) Eval Time (s)     22.450054723769426
Sample Time (s)              16.50494089955464
Epoch Time (s)               156.78308982541785
Total Train Time (s)         47769.63120045047
Epoch                        309
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:52:29.288031 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #309 | Epoch Duration: 157.459547996521
2020-01-13 21:52:29.288319 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #309 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2452145
Z variance train             0.033573955
KL Divergence                55.951065
KL Loss                      5.5951066
QF Loss                      525.4267
VF Loss                      425.491
Policy Loss                  -5040.533
Q Predictions Mean           5048.1895
Q Predictions Std            537.53754
Q Predictions Max            5757.6533
Q Predictions Min            3470.5293
V Predictions Mean           5056.407
V Predictions Std            535.313
V Predictions Max            5774.9097
V Predictions Min            3479.703
Log Pis Mean                 6.089365
Log Pis Std                  4.280521
Log Pis Max                  22.0635
Log Pis Min                  -2.4430285
Policy mu Mean               -0.138296
Policy mu Std                1.4289882
Policy mu Max                4.205656
Policy mu Min                -4.291854
Policy log std Mean          -0.91163796
Policy log std Std           0.4884386
Policy log std Max           -0.0037002563
Policy log std Min           -3.546148
Z mean eval                  3.2357395
Z variance eval              0.018632544
total_rewards                [11878.2298766  12286.55680774 12259.86873923 12191.27986573
 12230.01307558 12221.10883643 11981.74684844 12084.52722839
 12122.66304408 11915.87936709]
total_rewards_mean           12117.187368931423
total_rewards_std            139.68872071103024
total_rewards_max            12286.556807736559
total_rewards_min            11878.229876597268
Number of train steps total  1244000
Number of env steps total    1557000
Number of rollouts total     0
Train Time (s)               110.26974982768297
(Previous) Eval Time (s)     23.126216514967382
Sample Time (s)              15.830088240094483
Epoch Time (s)               149.22605458274484
Total Train Time (s)         47918.38735965267
Epoch                        310
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:54:58.046519 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #310 | Epoch Duration: 148.75797748565674
2020-01-13 21:54:58.046721 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #310 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2358966
Z variance train             0.018692933
KL Divergence                57.004707
KL Loss                      5.700471
QF Loss                      597.7384
VF Loss                      164.7532
Policy Loss                  -4987.6274
Q Predictions Mean           4993.207
Q Predictions Std            584.5927
Q Predictions Max            5669.522
Q Predictions Min            3449.4663
V Predictions Mean           4983.418
V Predictions Std            583.55914
V Predictions Max            5654.4575
V Predictions Min            3439.581
Log Pis Mean                 5.9887276
Log Pis Std                  4.0261836
Log Pis Max                  18.86877
Log Pis Min                  -4.1863804
Policy mu Mean               -0.111682616
Policy mu Std                1.4423252
Policy mu Max                4.3874598
Policy mu Min                -3.81644
Policy log std Mean          -0.91600233
Policy log std Std           0.49464473
Policy log std Max           -0.15033317
Policy log std Min           -3.3292828
Z mean eval                  3.2571113
Z variance eval              0.0137994485
total_rewards                [12122.48197109 12416.95787763 11918.82542225 11844.02777557
 12340.3100982   4402.78201903 12046.14675894 12355.20285566
 12180.65170381 11999.56172188]
total_rewards_mean           11362.694820403956
total_rewards_std            2327.0723939741524
total_rewards_max            12416.9578776279
total_rewards_min            4402.782019028239
Number of train steps total  1248000
Number of env steps total    1562000
Number of rollouts total     0
Train Time (s)               116.9558341386728
(Previous) Eval Time (s)     22.657890542875975
Sample Time (s)              15.8950440781191
Epoch Time (s)               155.50876875966787
Total Train Time (s)         48073.525288295
Epoch                        311
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:57:33.191868 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #311 | Epoch Duration: 155.14486455917358
2020-01-13 21:57:33.192319 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #311 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.253537
Z variance train             0.0138529595
KL Divergence                56.816925
KL Loss                      5.6816926
QF Loss                      514.473
VF Loss                      548.49756
Policy Loss                  -4963.83
Q Predictions Mean           4971.589
Q Predictions Std            538.1962
Q Predictions Max            5673.094
Q Predictions Min            3384.6294
V Predictions Mean           4984.789
V Predictions Std            539.5047
V Predictions Max            5705.5605
V Predictions Min            3400.6523
Log Pis Mean                 5.8959007
Log Pis Std                  3.8097646
Log Pis Max                  16.579885
Log Pis Min                  -6.4829574
Policy mu Mean               -0.07134547
Policy mu Std                1.4258951
Policy mu Max                3.0981307
Policy mu Min                -2.9900715
Policy log std Mean          -0.90762967
Policy log std Std           0.474865
Policy log std Max           0.12191427
Policy log std Min           -3.2414227
Z mean eval                  3.2780182
Z variance eval              0.005778006
total_rewards                [12127.02926753 12135.24142018 12485.58169244 12156.22523474
 12215.41822541 12456.06267048 12332.487229   11903.09545927
 11924.27878264 12565.20366016]
total_rewards_mean           12230.062364185756
total_rewards_std            215.6063462236235
total_rewards_max            12565.2036601551
total_rewards_min            11903.09545927364
Number of train steps total  1252000
Number of env steps total    1567000
Number of rollouts total     0
Train Time (s)               116.13735214667395
(Previous) Eval Time (s)     22.293684596195817
Sample Time (s)              16.635453779716045
Epoch Time (s)               155.0664905225858
Total Train Time (s)         48229.74114619987
Epoch                        312
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:00:09.408259 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #312 | Epoch Duration: 156.21565699577332
2020-01-13 22:00:09.408433 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #312 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2794445
Z variance train             0.005787827
KL Divergence                59.51414
KL Loss                      5.951414
QF Loss                      4169.545
VF Loss                      177.80629
Policy Loss                  -5006.929
Q Predictions Mean           5012.456
Q Predictions Std            521.4242
Q Predictions Max            5653.379
Q Predictions Min            3339.051
V Predictions Mean           4999.2144
V Predictions Std            519.232
V Predictions Max            5618.465
V Predictions Min            3332.7458
Log Pis Mean                 5.88693
Log Pis Std                  3.9036734
Log Pis Max                  15.098189
Log Pis Min                  -3.454423
Policy mu Mean               -0.12577759
Policy mu Std                1.4046288
Policy mu Max                2.9162126
Policy mu Min                -3.2184544
Policy log std Mean          -0.9423866
Policy log std Std           0.502207
Policy log std Max           -0.09182954
Policy log std Min           -3.5907903
Z mean eval                  3.2317052
Z variance eval              0.017590247
total_rewards                [12316.57402429 11077.52752263 12295.59930355 12174.84794375
 12284.02446301 12397.87746302 12350.72818901 12265.40292121
 12387.8623792  12377.63002329]
total_rewards_mean           12192.807423296326
total_rewards_std            377.20621883668224
total_rewards_max            12397.877463024013
total_rewards_min            11077.527522626726
Number of train steps total  1256000
Number of env steps total    1572000
Number of rollouts total     0
Train Time (s)               114.53377128019929
(Previous) Eval Time (s)     23.44258039398119
Sample Time (s)              16.621951648965478
Epoch Time (s)               154.59830332314596
Total Train Time (s)         48383.29569187341
Epoch                        313
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:02:42.969650 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #313 | Epoch Duration: 153.56098341941833
2020-01-13 22:02:42.970038 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #313 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.230514
Z variance train             0.017500969
KL Divergence                59.04554
KL Loss                      5.904554
QF Loss                      393.8526
VF Loss                      199.64998
Policy Loss                  -5005.62
Q Predictions Mean           5012.232
Q Predictions Std            562.05396
Q Predictions Max            5701.4194
Q Predictions Min            3402.9907
V Predictions Mean           5014.341
V Predictions Std            563.3818
V Predictions Max            5682.4883
V Predictions Min            3414.3003
Log Pis Mean                 5.387948
Log Pis Std                  3.6624062
Log Pis Max                  15.726702
Log Pis Min                  -4.47433
Policy mu Mean               -0.020678995
Policy mu Std                1.3782493
Policy mu Max                2.9095192
Policy mu Min                -3.3454268
Policy log std Mean          -0.93552685
Policy log std Std           0.5061018
Policy log std Max           0.031978965
Policy log std Min           -3.3051624
Z mean eval                  3.2594082
Z variance eval              0.021143107
total_rewards                [12109.04094643 12448.74193947 12370.18358104 12503.97662096
 12589.951665   12604.9795976  12563.34002119 12434.88736263
 12314.78485411 12159.36784844]
total_rewards_mean           12409.925443685366
total_rewards_std            163.98438165208532
total_rewards_max            12604.97959759537
total_rewards_min            12109.04094642763
Number of train steps total  1260000
Number of env steps total    1577000
Number of rollouts total     0
Train Time (s)               115.49753215024248
(Previous) Eval Time (s)     22.40492151817307
Sample Time (s)              17.15661995438859
Epoch Time (s)               155.05907362280414
Total Train Time (s)         48538.967626075726
Epoch                        314
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:05:18.642612 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #314 | Epoch Duration: 155.6723334789276
2020-01-13 22:05:18.642792 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #314 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2591202
Z variance train             0.021163372
KL Divergence                59.18889
KL Loss                      5.918889
QF Loss                      827.5394
VF Loss                      156.94789
Policy Loss                  -4976.6187
Q Predictions Mean           4981.3755
Q Predictions Std            657.65375
Q Predictions Max            5652.767
Q Predictions Min            915.06335
V Predictions Mean           4978.6655
V Predictions Std            651.97076
V Predictions Max            5649.599
V Predictions Min            997.9228
Log Pis Mean                 5.898462
Log Pis Std                  4.1125636
Log Pis Max                  16.37608
Log Pis Min                  -4.68287
Policy mu Mean               -0.124088235
Policy mu Std                1.4251564
Policy mu Max                2.9742448
Policy mu Min                -2.8351147
Policy log std Mean          -0.9143281
Policy log std Std           0.5061164
Policy log std Max           -0.009298563
Policy log std Min           -3.4300141
Z mean eval                  3.2478688
Z variance eval              0.029448142
total_rewards                [11961.92024203 11735.20490464 12277.41054983 11946.40660076
 12051.68488271 11955.63625962 12112.76874747 12199.72115951
 11985.66238679 12059.76282096]
total_rewards_mean           12028.617855433626
total_rewards_std            142.90819502070295
total_rewards_max            12277.410549831666
total_rewards_min            11735.204904641523
Number of train steps total  1264000
Number of env steps total    1582000
Number of rollouts total     0
Train Time (s)               115.44008754380047
(Previous) Eval Time (s)     23.01787421805784
Sample Time (s)              16.705524505581707
Epoch Time (s)               155.16348626744002
Total Train Time (s)         48694.35460250499
Epoch                        315
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:07:54.034915 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #315 | Epoch Duration: 155.39196062088013
2020-01-13 22:07:54.035153 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #315 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2459722
Z variance train             0.029343683
KL Divergence                59.98282
KL Loss                      5.998282
QF Loss                      369.6575
VF Loss                      157.31439
Policy Loss                  -4928.9995
Q Predictions Mean           4935.595
Q Predictions Std            661.55695
Q Predictions Max            5626.923
Q Predictions Min            -77.365234
V Predictions Mean           4929.171
V Predictions Std            656.4324
V Predictions Max            5630.317
V Predictions Min            2.7095122
Log Pis Mean                 5.1981745
Log Pis Std                  3.9199197
Log Pis Max                  17.850657
Log Pis Min                  -6.226442
Policy mu Mean               -0.07618675
Policy mu Std                1.3674812
Policy mu Max                4.9221115
Policy mu Min                -3.7182696
Policy log std Mean          -0.9118588
Policy log std Std           0.49475342
Policy log std Max           0.015322864
Policy log std Min           -3.570991
Z mean eval                  3.239329
Z variance eval              0.02186216
total_rewards                [11861.62841153 11523.01545636 11758.43250056 12338.11791053
 12421.12007135 12338.80391419 12194.60496953 12147.65010471
 11962.51398942 12313.42377627]
total_rewards_mean           12085.931110446701
total_rewards_std            282.30116737540544
total_rewards_max            12421.120071347783
total_rewards_min            11523.01545636473
Number of train steps total  1268000
Number of env steps total    1587000
Number of rollouts total     0
Train Time (s)               112.05258248979226
(Previous) Eval Time (s)     23.245983642991632
Sample Time (s)              15.64489763835445
Epoch Time (s)               150.94346377113834
Total Train Time (s)         48844.90791144408
Epoch                        316
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:10:24.594240 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #316 | Epoch Duration: 150.55884909629822
2020-01-13 22:10:24.594560 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #316 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2395775
Z variance train             0.021917852
KL Divergence                59.83294
KL Loss                      5.983294
QF Loss                      597.91223
VF Loss                      260.3246
Policy Loss                  -4939.0625
Q Predictions Mean           4940.9688
Q Predictions Std            598.5158
Q Predictions Max            5637.9307
Q Predictions Min            3462.7773
V Predictions Mean           4928.0723
V Predictions Std            597.54663
V Predictions Max            5617.136
V Predictions Min            3449.5168
Log Pis Mean                 5.7103662
Log Pis Std                  3.7829094
Log Pis Max                  15.849943
Log Pis Min                  -4.6696186
Policy mu Mean               -0.113185905
Policy mu Std                1.4046676
Policy mu Max                3.1665463
Policy mu Min                -2.8919842
Policy log std Mean          -0.940413
Policy log std Std           0.48774624
Policy log std Max           0.12219399
Policy log std Min           -3.2011757
Z mean eval                  3.2490191
Z variance eval              0.023115985
total_rewards                [11585.36874039 12026.11192121 12029.73010341 12296.59621374
  2212.31632839 11997.16585667 12115.07270573  4408.28027371
 12239.98942701 11760.22968966]
total_rewards_mean           10267.086125992753
total_rewards_std            3518.4207210690865
total_rewards_max            12296.59621374375
total_rewards_min            2212.3163283888284
Number of train steps total  1272000
Number of env steps total    1592000
Number of rollouts total     0
Train Time (s)               118.53763582417741
(Previous) Eval Time (s)     22.861048920080066
Sample Time (s)              16.50024794274941
Epoch Time (s)               157.8989326870069
Total Train Time (s)         49003.0923711136
Epoch                        317
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:13:02.782674 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #317 | Epoch Duration: 158.1878833770752
2020-01-13 22:13:02.782891 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #317 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2487893
Z variance train             0.023092395
KL Divergence                60.15682
KL Loss                      6.0156817
QF Loss                      1313.0621
VF Loss                      128.67029
Policy Loss                  -5009.833
Q Predictions Mean           5018.512
Q Predictions Std            610.02856
Q Predictions Max            5675.3716
Q Predictions Min            216.42288
V Predictions Mean           5012.1494
V Predictions Std            610.86206
V Predictions Max            5657.2974
V Predictions Min            124.73282
Log Pis Mean                 5.7278113
Log Pis Std                  4.0079174
Log Pis Max                  16.255636
Log Pis Min                  -5.034672
Policy mu Mean               -0.056004297
Policy mu Std                1.4320945
Policy mu Max                4.3581986
Policy mu Min                -2.8097086
Policy log std Mean          -0.9292102
Policy log std Std           0.49066362
Policy log std Max           -0.20812064
Policy log std Min           -3.1769023
Z mean eval                  3.2504795
Z variance eval              0.013294971
total_rewards                [12042.56328589 12299.54937597 12463.95632398 12143.48209076
 12293.87939721 12169.03865288 12546.5645008  12401.08617889
 12277.99228922 11992.84193948]
total_rewards_mean           12263.095403506883
total_rewards_std            169.4299627621041
total_rewards_max            12546.564500804361
total_rewards_min            11992.841939475084
Number of train steps total  1276000
Number of env steps total    1597000
Number of rollouts total     0
Train Time (s)               120.88597419392318
(Previous) Eval Time (s)     23.149690884165466
Sample Time (s)              17.250509810633957
Epoch Time (s)               161.2861748887226
Total Train Time (s)         49163.91661987221
Epoch                        318
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:15:43.609240 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #318 | Epoch Duration: 160.8261797428131
2020-01-13 22:15:43.609437 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #318 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2492738
Z variance train             0.013270949
KL Divergence                61.83873
KL Loss                      6.183873
QF Loss                      367.0252
VF Loss                      217.15027
Policy Loss                  -4981.029
Q Predictions Mean           4985.297
Q Predictions Std            606.0362
Q Predictions Max            5680.369
Q Predictions Min            3394.249
V Predictions Mean           4991.1885
V Predictions Std            605.0625
V Predictions Max            5687.602
V Predictions Min            3406.5315
Log Pis Mean                 5.0855265
Log Pis Std                  3.6675086
Log Pis Max                  14.851139
Log Pis Min                  -4.353546
Policy mu Mean               -0.09439895
Policy mu Std                1.3563286
Policy mu Max                3.2351372
Policy mu Min                -3.11661
Policy log std Mean          -0.90113944
Policy log std Std           0.45115238
Policy log std Max           0.015949368
Policy log std Min           -3.4195309
Z mean eval                  3.2431412
Z variance eval              0.0064731524
total_rewards                [12049.0650965  12365.17617422 12181.09569597 12279.24737702
 12032.66048943 12546.28238114 12309.98946312 12234.41845658
 11945.71155656 12384.90296934]
total_rewards_mean           12232.854965987866
total_rewards_std            174.91585896572045
total_rewards_max            12546.282381140789
total_rewards_min            11945.711556556562
Number of train steps total  1280000
Number of env steps total    1602000
Number of rollouts total     0
Train Time (s)               117.20891080889851
(Previous) Eval Time (s)     22.689376327209175
Sample Time (s)              17.300722261425108
Epoch Time (s)               157.1990093975328
Total Train Time (s)         49321.610645579174
Epoch                        319
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:18:21.309483 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #319 | Epoch Duration: 157.69986510276794
2020-01-13 22:18:21.309793 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #319 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2435424
Z variance train             0.006456246
KL Divergence                61.93464
KL Loss                      6.193464
QF Loss                      1313.4607
VF Loss                      369.50143
Policy Loss                  -4982.5757
Q Predictions Mean           4986.8813
Q Predictions Std            595.6122
Q Predictions Max            5669.247
Q Predictions Min            2439.1033
V Predictions Mean           4974.612
V Predictions Std            593.1071
V Predictions Max            5660.0317
V Predictions Min            2506.3591
Log Pis Mean                 6.0367746
Log Pis Std                  3.6438684
Log Pis Max                  19.199059
Log Pis Min                  -2.782796
Policy mu Mean               -0.07005644
Policy mu Std                1.4604399
Policy mu Max                2.9867647
Policy mu Min                -3.83597
Policy log std Mean          -0.93020916
Policy log std Std           0.5151246
Policy log std Max           -0.21720827
Policy log std Min           -3.5500705
Z mean eval                  3.2435138
Z variance eval              0.0055784383
total_rewards                [12159.77032341 12360.99637778 12372.09870243 12108.21650558
 12346.47810175 12064.81132737 12485.35730981 12079.30327395
 11719.31918871 12463.84691601]
total_rewards_mean           12216.019802680341
total_rewards_std            223.47519680283818
total_rewards_max            12485.35730981403
total_rewards_min            11719.319188708005
Number of train steps total  1284000
Number of env steps total    1607000
Number of rollouts total     0
Train Time (s)               118.0249219480902
(Previous) Eval Time (s)     23.189874755684286
Sample Time (s)              16.224265300668776
Epoch Time (s)               157.43906200444326
Total Train Time (s)         49479.11084684683
Epoch                        320
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:20:58.815532 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #320 | Epoch Duration: 157.50548815727234
2020-01-13 22:20:58.815843 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #320 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2435405
Z variance train             0.0055760345
KL Divergence                62.35148
KL Loss                      6.235148
QF Loss                      515.28375
VF Loss                      376.61133
Policy Loss                  -5032.098
Q Predictions Mean           5041.8477
Q Predictions Std            537.6706
Q Predictions Max            5667.1626
Q Predictions Min            3352.6511
V Predictions Mean           5035.5264
V Predictions Std            538.7897
V Predictions Max            5661.254
V Predictions Min            3356.537
Log Pis Mean                 6.4741735
Log Pis Std                  4.1054397
Log Pis Max                  23.315203
Log Pis Min                  -2.8293548
Policy mu Mean               -0.09062145
Policy mu Std                1.4567368
Policy mu Max                4.2750835
Policy mu Min                -3.587851
Policy log std Mean          -0.95422894
Policy log std Std           0.51386636
Policy log std Max           -0.043311417
Policy log std Min           -3.2940812
Z mean eval                  3.2736268
Z variance eval              0.0072592995
total_rewards                [11762.61002182 12041.42297333 11896.6092039  11832.21651675
 11956.34280855 11958.81421302 11018.68882345 10628.89015016
  3891.39640298 11690.28231908]
total_rewards_mean           10867.72734330548
total_rewards_std            2365.7639469700684
total_rewards_max            12041.422973334922
total_rewards_min            3891.3964029842605
Number of train steps total  1288000
Number of env steps total    1612000
Number of rollouts total     0
Train Time (s)               116.78382989391685
(Previous) Eval Time (s)     23.255996903870255
Sample Time (s)              16.031897258479148
Epoch Time (s)               156.07172405626625
Total Train Time (s)         49634.444120267406
Epoch                        321
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:23:34.148689 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #321 | Epoch Duration: 155.33264088630676
2020-01-13 22:23:34.148865 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #321 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.275193
Z variance train             0.007184083
KL Divergence                63.22381
KL Loss                      6.322381
QF Loss                      542.727
VF Loss                      646.18384
Policy Loss                  -5039.888
Q Predictions Mean           5045.099
Q Predictions Std            523.13904
Q Predictions Max            5702.2666
Q Predictions Min            3458.1333
V Predictions Mean           5017.609
V Predictions Std            520.43964
V Predictions Max            5697.0435
V Predictions Min            3434.9048
Log Pis Mean                 6.165454
Log Pis Std                  3.453281
Log Pis Max                  15.54889
Log Pis Min                  -3.4263506
Policy mu Mean               -0.09215965
Policy mu Std                1.4448504
Policy mu Max                3.594688
Policy mu Min                -2.8187094
Policy log std Mean          -0.9308416
Policy log std Std           0.5070803
Policy log std Max           -0.21942183
Policy log std Min           -3.314602
Z mean eval                  3.2486413
Z variance eval              0.017396366
total_rewards                [12274.55483454 12472.51803822 12346.51808843 12497.80538108
 12557.87161748 12104.47887122 12048.85279104 12377.79678011
 12249.16597176 12262.25808092]
total_rewards_mean           12319.182045478728
total_rewards_std            156.80670137157657
total_rewards_max            12557.871617477353
total_rewards_min            12048.85279104411
Number of train steps total  1292000
Number of env steps total    1617000
Number of rollouts total     0
Train Time (s)               112.1125350240618
(Previous) Eval Time (s)     22.516660276800394
Sample Time (s)              15.75749643938616
Epoch Time (s)               150.38669174024835
Total Train Time (s)         49784.62370189279
Epoch                        322
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:26:04.334133 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #322 | Epoch Duration: 150.18510031700134
2020-01-13 22:26:04.334398 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #322 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2436023
Z variance train             0.01745806
KL Divergence                59.650475
KL Loss                      5.9650474
QF Loss                      954.55396
VF Loss                      492.19965
Policy Loss                  -4969.12
Q Predictions Mean           4974.8223
Q Predictions Std            640.9158
Q Predictions Max            5658.1807
Q Predictions Min            950.15155
V Predictions Mean           4986.5205
V Predictions Std            636.2747
V Predictions Max            5691.259
V Predictions Min            1035.7701
Log Pis Mean                 5.7783766
Log Pis Std                  3.688323
Log Pis Max                  15.615171
Log Pis Min                  -2.8865738
Policy mu Mean               -0.06548836
Policy mu Std                1.3960109
Policy mu Max                3.1933956
Policy mu Min                -2.576456
Policy log std Mean          -0.9469393
Policy log std Std           0.5026568
Policy log std Max           -0.1958459
Policy log std Min           -3.181991
Z mean eval                  3.2744145
Z variance eval              0.010198892
total_rewards                [12010.05310219 12414.74014283 12383.87892815 12327.33775632
 12375.76321714 12521.9094898  12156.1541394  12508.76891351
 12477.60324446 12062.95767578]
total_rewards_mean           12323.916660956906
total_rewards_std            175.01126198821123
total_rewards_max            12521.909489799342
total_rewards_min            12010.053102191288
Number of train steps total  1296000
Number of env steps total    1622000
Number of rollouts total     0
Train Time (s)               113.7809611079283
(Previous) Eval Time (s)     22.31479299487546
Sample Time (s)              15.801411977503449
Epoch Time (s)               151.89716608030722
Total Train Time (s)         49937.942950598896
Epoch                        323
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:28:37.655849 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #323 | Epoch Duration: 153.32124948501587
2020-01-13 22:28:37.656051 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #323 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.273161
Z variance train             0.010214066
KL Divergence                60.732525
KL Loss                      6.0732527
QF Loss                      373.76385
VF Loss                      264.8219
Policy Loss                  -4939.0767
Q Predictions Mean           4947.6685
Q Predictions Std            588.87415
Q Predictions Max            5626.2134
Q Predictions Min            3393.81
V Predictions Mean           4951.5103
V Predictions Std            589.9082
V Predictions Max            5640.4067
V Predictions Min            3408.5364
Log Pis Mean                 5.5915847
Log Pis Std                  3.582244
Log Pis Max                  14.957525
Log Pis Min                  -6.2948155
Policy mu Mean               -0.076601505
Policy mu Std                1.3922379
Policy mu Max                2.8903751
Policy mu Min                -3.50939
Policy log std Mean          -0.93576413
Policy log std Std           0.5095445
Policy log std Max           -0.0935241
Policy log std Min           -3.3976526
Z mean eval                  3.282002
Z variance eval              0.016721811
total_rewards                [12033.8645415  12231.85870017 12392.22232239 12503.78706001
 12368.40075022 12431.62142747 12320.15914357 12402.62602701
 12208.94196702 12622.57556985]
total_rewards_mean           12351.605750922081
total_rewards_std            156.25678392667663
total_rewards_max            12622.57556985358
total_rewards_min            12033.864541503384
Number of train steps total  1300000
Number of env steps total    1627000
Number of rollouts total     0
Train Time (s)               115.8877432141453
(Previous) Eval Time (s)     23.738561492878944
Sample Time (s)              15.794976238161325
Epoch Time (s)               155.42128094518557
Total Train Time (s)         50092.05388764618
Epoch                        324
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:31:11.771919 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #324 | Epoch Duration: 154.11571431159973
2020-01-13 22:31:11.772192 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #324 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2803903
Z variance train             0.01672278
KL Divergence                59.03378
KL Loss                      5.903378
QF Loss                      432.5553
VF Loss                      275.18777
Policy Loss                  -5016.2104
Q Predictions Mean           5023.464
Q Predictions Std            573.4933
Q Predictions Max            5720.4937
Q Predictions Min            3362.8074
V Predictions Mean           5029.4473
V Predictions Std            574.4222
V Predictions Max            5728.216
V Predictions Min            3371.6675
Log Pis Mean                 5.6328344
Log Pis Std                  3.6045024
Log Pis Max                  15.496136
Log Pis Min                  -4.2421436
Policy mu Mean               -0.089762904
Policy mu Std                1.3897245
Policy mu Max                2.899096
Policy mu Min                -2.7020729
Policy log std Mean          -0.935833
Policy log std Std           0.5020566
Policy log std Max           -0.2200197
Policy log std Min           -3.3355527
Z mean eval                  3.2536423
Z variance eval              0.014416161
total_rewards                [11951.79369711 11976.75406925 12253.46983802 12327.96903564
 11757.758747   12077.64186957 12160.74883968 12296.82264414
 12300.58317902 12281.40451338]
total_rewards_mean           12138.494643280705
total_rewards_std            181.9502430990644
total_rewards_max            12327.969035636153
total_rewards_min            11757.758747
Number of train steps total  1304000
Number of env steps total    1632000
Number of rollouts total     0
Train Time (s)               117.0412146509625
(Previous) Eval Time (s)     22.43268281687051
Sample Time (s)              15.715343747287989
Epoch Time (s)               155.189241215121
Total Train Time (s)         50247.970040222164
Epoch                        325
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:33:47.694215 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #325 | Epoch Duration: 155.92177534103394
2020-01-13 22:33:47.694554 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #325 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.25
Z variance train             0.014461604
KL Divergence                59.25398
KL Loss                      5.925398
QF Loss                      812.5172
VF Loss                      174.88864
Policy Loss                  -5079.129
Q Predictions Mean           5084.0693
Q Predictions Std            549.418
Q Predictions Max            5732.526
Q Predictions Min            3453.3057
V Predictions Mean           5073.4536
V Predictions Std            547.8602
V Predictions Max            5707.977
V Predictions Min            3459.1653
Log Pis Mean                 6.281824
Log Pis Std                  4.019367
Log Pis Max                  16.364157
Log Pis Min                  -6.8833747
Policy mu Mean               -0.12256201
Policy mu Std                1.4482766
Policy mu Max                2.9715474
Policy mu Min                -2.94667
Policy log std Mean          -0.9463853
Policy log std Std           0.5252413
Policy log std Max           -0.1780867
Policy log std Min           -3.425146
Z mean eval                  3.298658
Z variance eval              0.013228184
total_rewards                [12465.08988231 12140.50128863 12435.20334643 12487.03446157
 11937.13813494 12227.11563912 12215.80090561 12185.63515427
 12431.4114091  12446.99149622]
total_rewards_mean           12297.192171819655
total_rewards_std            173.75345489894332
total_rewards_max            12487.034461570212
total_rewards_min            11937.138134937893
Number of train steps total  1308000
Number of env steps total    1637000
Number of rollouts total     0
Train Time (s)               115.14490087796003
(Previous) Eval Time (s)     23.164916472043842
Sample Time (s)              16.29141290485859
Epoch Time (s)               154.60123025486246
Total Train Time (s)         50401.9177655275
Epoch                        326
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:36:21.642610 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #326 | Epoch Duration: 153.9478223323822
2020-01-13 22:36:21.642788 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #326 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.297224
Z variance train             0.013248803
KL Divergence                61.119682
KL Loss                      6.1119685
QF Loss                      359.82693
VF Loss                      156.46094
Policy Loss                  -5016.3755
Q Predictions Mean           5025.759
Q Predictions Std            562.2599
Q Predictions Max            5697.535
Q Predictions Min            3460.6616
V Predictions Mean           5025.715
V Predictions Std            563.3227
V Predictions Max            5698.6064
V Predictions Min            3463.3577
Log Pis Mean                 5.2695704
Log Pis Std                  3.6918383
Log Pis Max                  16.235031
Log Pis Min                  -4.1905074
Policy mu Mean               -0.10802273
Policy mu Std                1.3509473
Policy mu Max                2.9775891
Policy mu Min                -3.4040046
Policy log std Mean          -0.9399423
Policy log std Std           0.51499474
Policy log std Max           -0.16445512
Policy log std Min           -3.3784907
Z mean eval                  3.2274184
Z variance eval              0.012123724
total_rewards                [11727.99123107 11916.30503297 11812.35945833 11675.02035465
 12219.54324171 11853.72740111 11685.04835424 11810.28004045
 11995.45803547 12070.1623194 ]
total_rewards_mean           11876.589546940071
total_rewards_std            167.10459368252523
total_rewards_max            12219.543241711764
total_rewards_min            11675.020354653348
Number of train steps total  1312000
Number of env steps total    1642000
Number of rollouts total     0
Train Time (s)               115.53789153974503
(Previous) Eval Time (s)     22.511241691187024
Sample Time (s)              15.909153509885073
Epoch Time (s)               153.95828674081713
Total Train Time (s)         50556.08259403985
Epoch                        327
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:38:55.812866 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #327 | Epoch Duration: 154.16989374160767
2020-01-13 22:38:55.813163 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #327 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2281327
Z variance train             0.012169652
KL Divergence                60.176205
KL Loss                      6.0176206
QF Loss                      329.2095
VF Loss                      138.55551
Policy Loss                  -4954.719
Q Predictions Mean           4959.401
Q Predictions Std            604.8578
Q Predictions Max            5671.403
Q Predictions Min            3403.031
V Predictions Mean           4949.9253
V Predictions Std            601.5315
V Predictions Max            5632.242
V Predictions Min            3402.5955
Log Pis Mean                 5.277296
Log Pis Std                  3.5629377
Log Pis Max                  13.248685
Log Pis Min                  -5.3281784
Policy mu Mean               -0.04736777
Policy mu Std                1.3594636
Policy mu Max                3.159608
Policy mu Min                -2.8302298
Policy log std Mean          -0.93592614
Policy log std Std           0.49347004
Policy log std Max           -0.12342048
Policy log std Min           -3.2877603
Z mean eval                  3.265225
Z variance eval              0.0116000725
total_rewards                [12113.28626232 12446.14628368 12118.74808753 12540.44080704
 12280.90560775 12425.36185167 12085.32971985 12377.01799186
 12165.73447713 12416.73830734]
total_rewards_mean           12296.97093961714
total_rewards_std            157.0170036710716
total_rewards_max            12540.44080703563
total_rewards_min            12085.329719854139
Number of train steps total  1316000
Number of env steps total    1647000
Number of rollouts total     0
Train Time (s)               119.73741513397545
(Previous) Eval Time (s)     22.722521116025746
Sample Time (s)              17.267960420809686
Epoch Time (s)               159.72789667081088
Total Train Time (s)         50715.95843488723
Epoch                        328
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:41:35.695427 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #328 | Epoch Duration: 159.88203287124634
2020-01-13 22:41:35.695733 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #328 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2649982
Z variance train             0.011653344
KL Divergence                60.457
KL Loss                      6.0457
QF Loss                      605.0597
VF Loss                      129.38437
Policy Loss                  -5014.2744
Q Predictions Mean           5014.8604
Q Predictions Std            564.6883
Q Predictions Max            5713.9287
Q Predictions Min            3529.2844
V Predictions Mean           5009.428
V Predictions Std            564.16675
V Predictions Max            5713.2764
V Predictions Min            3521.0083
Log Pis Mean                 5.40775
Log Pis Std                  3.749642
Log Pis Max                  15.952283
Log Pis Min                  -2.8160377
Policy mu Mean               -0.10617866
Policy mu Std                1.3679564
Policy mu Max                2.7416787
Policy mu Min                -2.6434915
Policy log std Mean          -0.92266494
Policy log std Std           0.4956739
Policy log std Max           -0.18156826
Policy log std Min           -3.3345387
Z mean eval                  3.2596784
Z variance eval              0.010952143
total_rewards                [12162.95828546 11995.03260372 12302.16911093 12392.54854736
 11742.00167982 12285.42875968 11811.38716921 11721.92274967
 11810.7765718  11376.45159853]
total_rewards_mean           11960.06770761839
total_rewards_std            306.8529474570278
total_rewards_max            12392.5485473648
total_rewards_min            11376.451598533205
Number of train steps total  1320000
Number of env steps total    1652000
Number of rollouts total     0
Train Time (s)               117.327161711175
(Previous) Eval Time (s)     22.87633843300864
Sample Time (s)              16.872090792749077
Epoch Time (s)               157.0755909369327
Total Train Time (s)         50873.36073538056
Epoch                        329
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:44:13.102813 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #329 | Epoch Duration: 157.4067099094391
2020-01-13 22:44:13.103124 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #329 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.263012
Z variance train             0.011031171
KL Divergence                60.203377
KL Loss                      6.0203376
QF Loss                      866.2609
VF Loss                      560.9972
Policy Loss                  -4961.1963
Q Predictions Mean           4961.0537
Q Predictions Std            730.2479
Q Predictions Max            5712.682
Q Predictions Min            321.06506
V Predictions Mean           4945.9736
V Predictions Std            728.4569
V Predictions Max            5687.822
V Predictions Min            303.21484
Log Pis Mean                 5.8804617
Log Pis Std                  3.9081242
Log Pis Max                  15.353691
Log Pis Min                  -1.9465744
Policy mu Mean               -0.018746002
Policy mu Std                1.4211608
Policy mu Max                2.9354906
Policy mu Min                -2.8491023
Policy log std Mean          -0.92380476
Policy log std Std           0.4934378
Policy log std Max           0.090818286
Policy log std Min           -3.413672
Z mean eval                  3.2939334
Z variance eval              0.009546722
total_rewards                [12159.07956278 12532.21233162 12537.34572973 12680.41434787
 12569.01028927 12230.22348747 12400.15294335 12346.98700104
 12428.85425458 12532.07356951]
total_rewards_mean           12441.635351723296
total_rewards_std            153.022458432307
total_rewards_max            12680.41434786923
total_rewards_min            12159.079562781373
Number of train steps total  1324000
Number of env steps total    1657000
Number of rollouts total     0
Train Time (s)               113.8041667449288
(Previous) Eval Time (s)     23.20713708875701
Sample Time (s)              16.51033075619489
Epoch Time (s)               153.5216345898807
Total Train Time (s)         51025.9310319745
Epoch                        330
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:46:45.674459 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #330 | Epoch Duration: 152.57117295265198
2020-01-13 22:46:45.674689 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #330 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2936993
Z variance train             0.009553624
KL Divergence                60.590202
KL Loss                      6.0590205
QF Loss                      418.07062
VF Loss                      67.07391
Policy Loss                  -5067.831
Q Predictions Mean           5075.2207
Q Predictions Std            540.62744
Q Predictions Max            5705.793
Q Predictions Min            3454.3508
V Predictions Mean           5067.6455
V Predictions Std            540.295
V Predictions Max            5717.278
V Predictions Min            3448.8591
Log Pis Mean                 5.621276
Log Pis Std                  3.9765458
Log Pis Max                  19.479994
Log Pis Min                  -3.1265512
Policy mu Mean               -0.124198556
Policy mu Std                1.3981484
Policy mu Max                3.044423
Policy mu Min                -2.8967376
Policy log std Mean          -0.9301706
Policy log std Std           0.50203246
Policy log std Max           0.5674696
Policy log std Min           -3.4247727
Z mean eval                  3.2249267
Z variance eval              0.014861661
total_rewards                [11980.40967872 12310.94186042 12272.48537029 12237.62496004
 11991.11441023 12379.63037059 12201.27816737 12501.1731796
 12237.61000617 12250.33934217]
total_rewards_mean           12236.260734559886
total_rewards_std            149.8683097989471
total_rewards_max            12501.173179603047
total_rewards_min            11980.40967871663
Number of train steps total  1328000
Number of env steps total    1662000
Number of rollouts total     0
Train Time (s)               116.82007104391232
(Previous) Eval Time (s)     22.256383664906025
Sample Time (s)              16.750564884394407
Epoch Time (s)               155.82701959321275
Total Train Time (s)         51183.940507702995
Epoch                        331
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:49:23.687688 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #331 | Epoch Duration: 158.01280307769775
2020-01-13 22:49:23.687981 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #331 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2241108
Z variance train             0.014852883
KL Divergence                58.64963
KL Loss                      5.864963
QF Loss                      397.79132
VF Loss                      78.79274
Policy Loss                  -4901.349
Q Predictions Mean           4907.5576
Q Predictions Std            621.6509
Q Predictions Max            5651.7896
Q Predictions Min            1958.4462
V Predictions Mean           4899.088
V Predictions Std            623.4036
V Predictions Max            5630.777
V Predictions Min            1820.7098
Log Pis Mean                 5.595483
Log Pis Std                  3.751841
Log Pis Max                  15.959847
Log Pis Min                  -4.1168437
Policy mu Mean               -0.073157884
Policy mu Std                1.3901628
Policy mu Max                2.989997
Policy mu Min                -3.5116088
Policy log std Mean          -0.9212189
Policy log std Std           0.47432026
Policy log std Max           -0.15864456
Policy log std Min           -3.3540492
Z mean eval                  3.247066
Z variance eval              0.008612366
total_rewards                [12268.55333825 12281.53784603 12126.02753509 12452.41738034
 12274.16635337 12654.20793898 12446.49325612 12661.71702145
 12194.65780664 12293.29842637]
total_rewards_mean           12365.307690263775
total_rewards_std            173.7090336701916
total_rewards_max            12661.717021451543
total_rewards_min            12126.02753508987
Number of train steps total  1332000
Number of env steps total    1667000
Number of rollouts total     0
Train Time (s)               114.76640207413584
(Previous) Eval Time (s)     24.441849044989794
Sample Time (s)              16.095000537112355
Epoch Time (s)               155.303251656238
Total Train Time (s)         51337.47775944136
Epoch                        332
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:51:57.227459 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #332 | Epoch Duration: 153.5393238067627
2020-01-13 22:51:57.227646 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #332 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2479172
Z variance train             0.008608717
KL Divergence                61.53743
KL Loss                      6.1537433
QF Loss                      448.12595
VF Loss                      194.0026
Policy Loss                  -5027.6895
Q Predictions Mean           5032.992
Q Predictions Std            631.0477
Q Predictions Max            5733.6323
Q Predictions Min            3389.7754
V Predictions Mean           5018.3975
V Predictions Std            630.0179
V Predictions Max            5713.4663
V Predictions Min            3385.5676
Log Pis Mean                 5.78288
Log Pis Std                  3.7879546
Log Pis Max                  16.98603
Log Pis Min                  -3.907193
Policy mu Mean               -0.105855264
Policy mu Std                1.4326065
Policy mu Max                3.0588179
Policy mu Min                -3.097301
Policy log std Mean          -0.91240174
Policy log std Std           0.49718422
Policy log std Max           0.066364646
Policy log std Min           -3.5205984
Z mean eval                  3.29363
Z variance eval              0.0052233962
total_rewards                [12468.38096572 12212.74462496 12677.32720445 12526.34074473
 12354.66848873 12394.1611483  12393.44035307 12514.59465174
 12707.80593533 12547.04477111]
total_rewards_mean           12479.650888813754
total_rewards_std            141.70423881684823
total_rewards_max            12707.805935333277
total_rewards_min            12212.744624958945
Number of train steps total  1336000
Number of env steps total    1672000
Number of rollouts total     0
Train Time (s)               118.51749919494614
(Previous) Eval Time (s)     22.677643324248493
Sample Time (s)              16.473648647777736
Epoch Time (s)               157.66879116697237
Total Train Time (s)         51495.34623541497
Epoch                        333
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:54:35.101607 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #333 | Epoch Duration: 157.8738009929657
2020-01-13 22:54:35.101845 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #333 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.294539
Z variance train             0.0052161263
KL Divergence                63.178925
KL Loss                      6.3178926
QF Loss                      1516.3535
VF Loss                      408.07532
Policy Loss                  -5106.984
Q Predictions Mean           5113.202
Q Predictions Std            560.5984
Q Predictions Max            5739.3022
Q Predictions Min            3453.2805
V Predictions Mean           5100.5195
V Predictions Std            559.9436
V Predictions Max            5731.8613
V Predictions Min            3441.1655
Log Pis Mean                 6.2047596
Log Pis Std                  3.9499862
Log Pis Max                  16.822304
Log Pis Min                  -3.4235594
Policy mu Mean               -0.08863831
Policy mu Std                1.4275887
Policy mu Max                2.901343
Policy mu Min                -3.3131254
Policy log std Mean          -0.94966036
Policy log std Std           0.53264123
Policy log std Max           -0.2582749
Policy log std Min           -3.4093804
Z mean eval                  3.2597165
Z variance eval              0.0049666315
total_rewards                [12232.46490853 12109.30991138 12430.24849542 12338.67605341
 12613.16747459 12448.24776124 12590.33597091 12548.61526552
 12354.9454876  12334.13416433]
total_rewards_mean           12400.01454929305
total_rewards_std            151.55693495378472
total_rewards_max            12613.16747459099
total_rewards_min            12109.309911383052
Number of train steps total  1340000
Number of env steps total    1677000
Number of rollouts total     0
Train Time (s)               120.6363971978426
(Previous) Eval Time (s)     22.882340191863477
Sample Time (s)              16.483243057504296
Epoch Time (s)               160.00198044721037
Total Train Time (s)         51655.13290177286
Epoch                        334
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:57:14.890875 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #334 | Epoch Duration: 159.78884291648865
2020-01-13 22:57:14.891090 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #334 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2605247
Z variance train             0.004966411
KL Divergence                61.80788
KL Loss                      6.180788
QF Loss                      720.0261
VF Loss                      124.7275
Policy Loss                  -4958.288
Q Predictions Mean           4965.3394
Q Predictions Std            600.16534
Q Predictions Max            5721.9355
Q Predictions Min            3426.2239
V Predictions Mean           4957.357
V Predictions Std            599.4902
V Predictions Max            5705.0776
V Predictions Min            3414.1638
Log Pis Mean                 5.7587776
Log Pis Std                  3.832331
Log Pis Max                  16.072828
Log Pis Min                  -4.9542737
Policy mu Mean               -0.0640819
Policy mu Std                1.3940799
Policy mu Max                3.1504269
Policy mu Min                -2.9623377
Policy log std Mean          -0.93083286
Policy log std Std           0.4947842
Policy log std Max           -0.26849532
Policy log std Min           -3.3235655
Z mean eval                  3.3334816
Z variance eval              0.0039942632
total_rewards                [12275.77672274 12366.08621882 12447.54595269 12623.44112874
 12454.98289125 12598.83057393 12454.28949316 12323.82981913
 12347.21033919 12443.99003127]
total_rewards_mean           12433.598317091699
total_rewards_std            106.53989196547919
total_rewards_max            12623.44112873555
total_rewards_min            12275.776722736791
Number of train steps total  1344000
Number of env steps total    1682000
Number of rollouts total     0
Train Time (s)               114.42667374620214
(Previous) Eval Time (s)     22.66883562784642
Sample Time (s)              16.48893955303356
Epoch Time (s)               153.58444892708212
Total Train Time (s)         51808.69066639338
Epoch                        335
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:59:48.455108 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #335 | Epoch Duration: 153.5637514591217
2020-01-13 22:59:48.455518 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #335 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.334823
Z variance train             0.0039921356
KL Divergence                61.710655
KL Loss                      6.171066
QF Loss                      389.31717
VF Loss                      204.74225
Policy Loss                  -5082.9097
Q Predictions Mean           5088.418
Q Predictions Std            551.1986
Q Predictions Max            5754.8037
Q Predictions Min            3451.6265
V Predictions Mean           5072.172
V Predictions Std            548.19006
V Predictions Max            5713.9297
V Predictions Min            3451.6572
Log Pis Mean                 6.085687
Log Pis Std                  4.1249537
Log Pis Max                  18.968155
Log Pis Min                  -3.9005163
Policy mu Mean               -0.09805935
Policy mu Std                1.4308286
Policy mu Max                3.405231
Policy mu Min                -3.1035872
Policy log std Mean          -0.9322384
Policy log std Std           0.5010598
Policy log std Max           0.096452594
Policy log std Min           -3.3802147
Z mean eval                  3.3363655
Z variance eval              0.04953306
total_rewards                [11511.79155491 11872.36413549 11847.61916223 11999.41588693
 11880.45521904 11826.35614131 12271.87589913 11866.04859598
 12194.4560271  11518.47794132]
total_rewards_mean           11878.886056344336
total_rewards_std            231.76541030600305
total_rewards_max            12271.875899126966
total_rewards_min            11511.791554913128
Number of train steps total  1348000
Number of env steps total    1687000
Number of rollouts total     0
Train Time (s)               119.82979082362726
(Previous) Eval Time (s)     22.647840758319944
Sample Time (s)              16.299840628169477
Epoch Time (s)               158.77747221011668
Total Train Time (s)         51968.374235023744
Epoch                        336
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:02:28.142842 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #336 | Epoch Duration: 159.68708157539368
2020-01-13 23:02:28.143108 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #336 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3362174
Z variance train             0.049591966
KL Divergence                58.920525
KL Loss                      5.8920527
QF Loss                      823.578
VF Loss                      143.56956
Policy Loss                  -4922.4717
Q Predictions Mean           4924.18
Q Predictions Std            560.58466
Q Predictions Max            5620.398
Q Predictions Min            3361.4675
V Predictions Mean           4918.8926
V Predictions Std            559.123
V Predictions Max            5608.965
V Predictions Min            3367.1235
Log Pis Mean                 5.768787
Log Pis Std                  3.6660857
Log Pis Max                  14.8364525
Log Pis Min                  -6.050775
Policy mu Mean               -0.11090172
Policy mu Std                1.4040271
Policy mu Max                3.1282318
Policy mu Min                -3.0215173
Policy log std Mean          -0.9164451
Policy log std Std           0.47749066
Policy log std Max           -0.12968671
Policy log std Min           -3.2195659
Z mean eval                  3.2587543
Z variance eval              0.040816832
total_rewards                [11828.56602312 11952.83661271 12111.32957281 12089.50514192
 12088.59036242 12004.78235374 12191.37911963 11867.40475491
 12138.37807925 11896.7130218 ]
total_rewards_mean           12016.948504230695
total_rewards_std            118.76118984715171
total_rewards_max            12191.379119627934
total_rewards_min            11828.566023121559
Number of train steps total  1352000
Number of env steps total    1692000
Number of rollouts total     0
Train Time (s)               116.813985100016
(Previous) Eval Time (s)     23.557142518926412
Sample Time (s)              17.295733460225165
Epoch Time (s)               157.66686107916757
Total Train Time (s)         52126.360539299436
Epoch                        337
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:05:06.133707 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #337 | Epoch Duration: 157.99033522605896
2020-01-13 23:05:06.134016 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #337 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2579799
Z variance train             0.040966857
KL Divergence                57.558834
KL Loss                      5.7558837
QF Loss                      725.3086
VF Loss                      134.80453
Policy Loss                  -4951.602
Q Predictions Mean           4959.2837
Q Predictions Std            641.3002
Q Predictions Max            5668.752
Q Predictions Min            646.8932
V Predictions Mean           4949.3115
V Predictions Std            639.7997
V Predictions Max            5661.508
V Predictions Min            644.9837
Log Pis Mean                 5.8471317
Log Pis Std                  3.9469943
Log Pis Max                  15.573416
Log Pis Min                  -4.300972
Policy mu Mean               -0.15428682
Policy mu Std                1.4036162
Policy mu Max                3.4079225
Policy mu Min                -3.3047469
Policy log std Mean          -0.95382434
Policy log std Std           0.5257662
Policy log std Max           -0.16468024
Policy log std Min           -3.4618306
Z mean eval                  3.264297
Z variance eval              0.041594297
total_rewards                [12056.77187229 12159.88178248 12066.56673021 12177.11793156
 12266.78927967 12382.51042995 12177.1560122  12076.13206882
 12125.45170057 12159.42512476]
total_rewards_mean           12164.78029325038
total_rewards_std            94.28004220202037
total_rewards_max            12382.510429954978
total_rewards_min            12056.77187229107
Number of train steps total  1356000
Number of env steps total    1697000
Number of rollouts total     0
Train Time (s)               120.58910585287958
(Previous) Eval Time (s)     23.8803107640706
Sample Time (s)              16.109265509527177
Epoch Time (s)               160.57868212647736
Total Train Time (s)         52285.27986164624
Epoch                        338
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:07:45.055304 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #338 | Epoch Duration: 158.92111611366272
2020-01-13 23:07:45.055504 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #338 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2642899
Z variance train             0.041658573
KL Divergence                56.67748
KL Loss                      5.667748
QF Loss                      853.4445
VF Loss                      144.99538
Policy Loss                  -5032.5044
Q Predictions Mean           5037.175
Q Predictions Std            630.48645
Q Predictions Max            5754.423
Q Predictions Min            496.47113
V Predictions Mean           5030.7627
V Predictions Std            627.99426
V Predictions Max            5744.5483
V Predictions Min            507.74777
Log Pis Mean                 6.3815117
Log Pis Std                  4.0891867
Log Pis Max                  15.948253
Log Pis Min                  -4.164361
Policy mu Mean               -0.08755181
Policy mu Std                1.4413013
Policy mu Max                3.066887
Policy mu Min                -4.279836
Policy log std Mean          -0.9658473
Policy log std Std           0.5393451
Policy log std Max           0.182073
Policy log std Min           -3.4920692
Z mean eval                  3.2138627
Z variance eval              0.20104317
total_rewards                [11926.88151576 11759.18219121 11945.80772402 12112.12622142
 11764.79060391 12074.69346147 11882.0434464  11417.7333059
 12112.10375527  7066.9726906 ]
total_rewards_mean           11406.233491596691
total_rewards_std            1459.9465219338113
total_rewards_max            12112.126221420167
total_rewards_min            7066.972690601684
Number of train steps total  1360000
Number of env steps total    1702000
Number of rollouts total     0
Train Time (s)               121.43077283585444
(Previous) Eval Time (s)     22.222429875750095
Sample Time (s)              16.393671152181923
Epoch Time (s)               160.04687386378646
Total Train Time (s)         52445.48574156966
Epoch                        339
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:10:25.264913 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #339 | Epoch Duration: 160.20925545692444
2020-01-13 23:10:25.265150 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #339 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2141101
Z variance train             0.20033757
KL Divergence                51.892464
KL Loss                      5.1892467
QF Loss                      541.8416
VF Loss                      321.70422
Policy Loss                  -5106.0894
Q Predictions Mean           5112.3564
Q Predictions Std            547.8036
Q Predictions Max            5753.4614
Q Predictions Min            3452.0996
V Predictions Mean           5118.541
V Predictions Std            550.4167
V Predictions Max            5748.629
V Predictions Min            3469.342
Log Pis Mean                 5.423064
Log Pis Std                  3.9013388
Log Pis Max                  16.071608
Log Pis Min                  -4.929245
Policy mu Mean               -0.044940025
Policy mu Std                1.3726975
Policy mu Max                3.3104892
Policy mu Min                -2.9475946
Policy log std Mean          -0.9423607
Policy log std Std           0.4998919
Policy log std Max           0.17166865
Policy log std Min           -3.3855991
Z mean eval                  3.3140526
Z variance eval              0.057147503
total_rewards                [11780.79746985 11949.05394246 12112.36650667 11919.67331973
 11847.98180255 12100.69410893 12166.22231207 12305.11621995
 12257.5099737  11875.92862593]
total_rewards_mean           12031.534428183657
total_rewards_std            171.8893099730209
total_rewards_max            12305.116219947828
total_rewards_min            11780.797469850026
Number of train steps total  1364000
Number of env steps total    1707000
Number of rollouts total     0
Train Time (s)               117.36044502677396
(Previous) Eval Time (s)     22.384492230135947
Sample Time (s)              15.973726049531251
Epoch Time (s)               155.71866330644116
Total Train Time (s)         52602.18371254299
Epoch                        340
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:13:01.964929 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #340 | Epoch Duration: 156.6996099948883
2020-01-13 23:13:01.965086 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #340 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3132331
Z variance train             0.05708421
KL Divergence                54.510956
KL Loss                      5.4510956
QF Loss                      619.27936
VF Loss                      202.39651
Policy Loss                  -5100.35
Q Predictions Mean           5108.7007
Q Predictions Std            560.3371
Q Predictions Max            5754.437
Q Predictions Min            3405.4753
V Predictions Mean           5104.52
V Predictions Std            558.08185
V Predictions Max            5748.7266
V Predictions Min            3411.7761
Log Pis Mean                 5.902844
Log Pis Std                  4.1133285
Log Pis Max                  17.198471
Log Pis Min                  -4.456775
Policy mu Mean               -0.087628454
Policy mu Std                1.4314038
Policy mu Max                2.9206254
Policy mu Min                -3.0541255
Policy log std Mean          -0.92045516
Policy log std Std           0.50293803
Policy log std Max           -0.09762007
Policy log std Min           -3.6337318
Z mean eval                  3.283664
Z variance eval              0.04720903
total_rewards                [12366.74464727 12403.73941549 12302.81859306 12623.83503478
 12444.08170524 12316.24159314 12361.69465732 12515.40059383
  2644.07431788 12099.41718426]
total_rewards_mean           11407.804774225395
total_rewards_std            2924.180770709001
total_rewards_max            12623.835034783398
total_rewards_min            2644.074317879057
Number of train steps total  1368000
Number of env steps total    1712000
Number of rollouts total     0
Train Time (s)               108.42615993274376
(Previous) Eval Time (s)     23.365167803131044
Sample Time (s)              16.90093599818647
Epoch Time (s)               148.69226373406127
Total Train Time (s)         52750.6132739638
Epoch                        341
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:15:30.397156 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #341 | Epoch Duration: 148.43194723129272
2020-01-13 23:15:30.397386 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #341 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2827897
Z variance train             0.047266833
KL Divergence                53.944077
KL Loss                      5.3944077
QF Loss                      512.34766
VF Loss                      127.32483
Policy Loss                  -5031.159
Q Predictions Mean           5037.307
Q Predictions Std            575.42615
Q Predictions Max            5754.9023
Q Predictions Min            3402.6218
V Predictions Mean           5030.3105
V Predictions Std            574.2697
V Predictions Max            5740.3794
V Predictions Min            3400.8376
Log Pis Mean                 6.056648
Log Pis Std                  3.9955008
Log Pis Max                  16.381813
Log Pis Min                  -6.788099
Policy mu Mean               -0.09597244
Policy mu Std                1.4171915
Policy mu Max                3.0827332
Policy mu Min                -3.002854
Policy log std Mean          -0.9224155
Policy log std Std           0.5225767
Policy log std Max           -0.22401226
Policy log std Min           -3.2391334
Z mean eval                  3.2936845
Z variance eval              0.03787853
total_rewards                [12113.30682852 12269.95607619 12169.47245184 12283.45637454
 12256.25214252 12391.37962715 12428.44027395 12533.48793864
 12336.75021577 12371.72635001]
total_rewards_mean           12315.422827912407
total_rewards_std            117.67002770387911
total_rewards_max            12533.48793863513
total_rewards_min            12113.30682851841
Number of train steps total  1372000
Number of env steps total    1717000
Number of rollouts total     0
Train Time (s)               123.59901885408908
(Previous) Eval Time (s)     23.10445922287181
Sample Time (s)              16.63002344267443
Epoch Time (s)               163.33350151963532
Total Train Time (s)         52913.20958790369
Epoch                        342
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:18:12.997416 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #342 | Epoch Duration: 162.59989023208618
2020-01-13 23:18:12.997601 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #342 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2932334
Z variance train             0.037829917
KL Divergence                55.033684
KL Loss                      5.5033684
QF Loss                      377.76807
VF Loss                      118.66326
Policy Loss                  -4986.749
Q Predictions Mean           4992.083
Q Predictions Std            657.3281
Q Predictions Max            5708.728
Q Predictions Min            1318.9491
V Predictions Mean           4982.0127
V Predictions Std            656.7435
V Predictions Max            5692.7656
V Predictions Min            1332.3921
Log Pis Mean                 5.6632457
Log Pis Std                  3.772699
Log Pis Max                  19.477554
Log Pis Min                  -5.707036
Policy mu Mean               -0.09718286
Policy mu Std                1.418002
Policy mu Max                2.7494848
Policy mu Min                -3.1773398
Policy log std Mean          -0.9169481
Policy log std Std           0.4870042
Policy log std Max           -0.12056309
Policy log std Min           -3.568216
Z mean eval                  3.2571006
Z variance eval              0.03874914
total_rewards                [12144.53256025 12004.45161916 10263.40292119 11722.67954205
  2702.68375822 12099.48036711 12433.33858786 12267.23019049
  1566.03150348 12359.57063344]
total_rewards_mean           9956.340168326115
total_rewards_std            3963.007696544115
total_rewards_max            12433.338587856659
total_rewards_min            1566.0315034806608
Number of train steps total  1376000
Number of env steps total    1722000
Number of rollouts total     0
Train Time (s)               118.7916610990651
(Previous) Eval Time (s)     22.370552971959114
Sample Time (s)              16.306938367895782
Epoch Time (s)               157.46915243892
Total Train Time (s)         53071.260314267594
Epoch                        343
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:20:51.056290 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #343 | Epoch Duration: 158.05852341651917
2020-01-13 23:20:51.056582 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #343 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.256429
Z variance train             0.03869816
KL Divergence                54.057396
KL Loss                      5.40574
QF Loss                      555.0298
VF Loss                      229.21303
Policy Loss                  -5113.181
Q Predictions Mean           5119.9263
Q Predictions Std            588.6083
Q Predictions Max            5843.0864
Q Predictions Min            3301.407
V Predictions Mean           5125.074
V Predictions Std            587.7159
V Predictions Max            5845.9507
V Predictions Min            3341.0693
Log Pis Mean                 6.1419125
Log Pis Std                  3.8071432
Log Pis Max                  16.583042
Log Pis Min                  -2.7755501
Policy mu Mean               -0.0472098
Policy mu Std                1.4344119
Policy mu Max                3.3153615
Policy mu Min                -2.8556705
Policy log std Mean          -0.93566275
Policy log std Std           0.54234105
Policy log std Max           0.07002771
Policy log std Min           -3.596003
Z mean eval                  3.2935956
Z variance eval              0.028174099
total_rewards                [12422.58999758 12624.59606711 12417.69418609 12829.21178852
 12565.02955326 12477.5491468  12500.88624794 12474.93762279
 12757.26299155 12700.91988613]
total_rewards_mean           12577.067748776926
total_rewards_std            137.54693648328262
total_rewards_max            12829.211788516406
total_rewards_min            12417.694186093357
Number of train steps total  1380000
Number of env steps total    1727000
Number of rollouts total     0
Train Time (s)               120.26123332232237
(Previous) Eval Time (s)     22.959602154791355
Sample Time (s)              16.501289314124733
Epoch Time (s)               159.72212479123846
Total Train Time (s)         53230.44729645038
Epoch                        344
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:23:30.243290 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #344 | Epoch Duration: 159.18649697303772
2020-01-13 23:23:30.243511 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #344 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2950034
Z variance train             0.028128857
KL Divergence                55.576336
KL Loss                      5.557634
QF Loss                      489.3287
VF Loss                      83.72168
Policy Loss                  -5117.092
Q Predictions Mean           5124.283
Q Predictions Std            604.5974
Q Predictions Max            5830.063
Q Predictions Min            3516.7551
V Predictions Mean           5113.871
V Predictions Std            602.93866
V Predictions Max            5817.334
V Predictions Min            3527.309
Log Pis Mean                 6.059139
Log Pis Std                  3.9214885
Log Pis Max                  15.948038
Log Pis Min                  -3.9772205
Policy mu Mean               -0.1075694
Policy mu Std                1.400102
Policy mu Max                2.8596575
Policy mu Min                -2.8696628
Policy log std Mean          -0.93772525
Policy log std Std           0.50825137
Policy log std Max           -0.27023405
Policy log std Min           -3.2437477
Z mean eval                  3.3038564
Z variance eval              0.01093549
total_rewards                [12233.45205368 12583.90871941 12285.02334608 12319.75137941
 12522.67566858 12403.09204218 12526.54989543 12540.2205883
 12313.42272586 12602.18466778]
total_rewards_mean           12433.02810867246
total_rewards_std            130.16196910605353
total_rewards_max            12602.18466778132
total_rewards_min            12233.452053683104
Number of train steps total  1384000
Number of env steps total    1732000
Number of rollouts total     0
Train Time (s)               115.01324819307774
(Previous) Eval Time (s)     22.423695397097617
Sample Time (s)              16.034641201607883
Epoch Time (s)               153.47158479178324
Total Train Time (s)         53384.8041647505
Epoch                        345
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:26:04.605537 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #345 | Epoch Duration: 154.361878156662
2020-01-13 23:26:04.605765 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #345 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.303334
Z variance train             0.010852042
KL Divergence                57.86857
KL Loss                      5.786857
QF Loss                      628.5139
VF Loss                      145.80273
Policy Loss                  -5064.202
Q Predictions Mean           5072.964
Q Predictions Std            599.45386
Q Predictions Max            5773.2036
Q Predictions Min            3462.4807
V Predictions Mean           5066.536
V Predictions Std            599.86487
V Predictions Max            5783.0264
V Predictions Min            3477.9485
Log Pis Mean                 5.7242355
Log Pis Std                  3.8192708
Log Pis Max                  16.20283
Log Pis Min                  -4.3193235
Policy mu Mean               -0.095358066
Policy mu Std                1.3903661
Policy mu Max                2.9741292
Policy mu Min                -3.1948361
Policy log std Mean          -0.9432079
Policy log std Std           0.53890276
Policy log std Max           -0.18391949
Policy log std Min           -3.4835181
Z mean eval                  3.3022563
Z variance eval              0.015123832
total_rewards                [12078.4716359  12073.2281316  12085.3038432  11906.6061341
 11983.29729277 12055.81789743 11796.70756344 11917.88980433
 12012.5621419  11782.68946743]
total_rewards_mean           11969.257391211731
total_rewards_std            108.12697576117701
total_rewards_max            12085.30384320249
total_rewards_min            11782.689467434171
Number of train steps total  1388000
Number of env steps total    1737000
Number of rollouts total     0
Train Time (s)               116.98815748374909
(Previous) Eval Time (s)     23.313689175993204
Sample Time (s)              16.654960257466882
Epoch Time (s)               156.95680691720918
Total Train Time (s)         53540.74889627984
Epoch                        346
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:28:40.551490 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #346 | Epoch Duration: 155.94556260108948
2020-01-13 23:28:40.551641 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #346 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3047233
Z variance train             0.01516995
KL Divergence                57.754547
KL Loss                      5.775455
QF Loss                      676.91077
VF Loss                      344.28143
Policy Loss                  -5022.8115
Q Predictions Mean           5026.2207
Q Predictions Std            600.72
Q Predictions Max            5716.6006
Q Predictions Min            3367.6597
V Predictions Mean           5009.3774
V Predictions Std            600.2926
V Predictions Max            5686.873
V Predictions Min            3362.3538
Log Pis Mean                 6.4417167
Log Pis Std                  4.160073
Log Pis Max                  17.483398
Log Pis Min                  -4.640723
Policy mu Mean               -0.14261498
Policy mu Std                1.4430628
Policy mu Max                3.1313477
Policy mu Min                -2.8716044
Policy log std Mean          -0.93618536
Policy log std Std           0.5075234
Policy log std Max           -0.027400613
Policy log std Min           -3.4740238
Z mean eval                  3.3286495
Z variance eval              0.012104601
total_rewards                [12191.69158517 12627.16344943 12632.86831788 12992.83118883
 12606.36409114 12664.55943138 12729.21808208 12556.65271258
 12667.63919401 12386.48923341]
total_rewards_mean           12605.547728591107
total_rewards_std            198.86908780210237
total_rewards_max            12992.8311888265
total_rewards_min            12191.691585166504
Number of train steps total  1392000
Number of env steps total    1742000
Number of rollouts total     0
Train Time (s)               119.404465733096
(Previous) Eval Time (s)     22.302169656846672
Sample Time (s)              16.20885314978659
Epoch Time (s)               157.91548853972927
Total Train Time (s)         53698.90517049283
Epoch                        347
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:31:18.712300 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #347 | Epoch Duration: 158.16053414344788
2020-01-13 23:31:18.712481 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #347 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.328654
Z variance train             0.012121078
KL Divergence                58.88551
KL Loss                      5.888551
QF Loss                      610.90247
VF Loss                      155.93735
Policy Loss                  -5143.1377
Q Predictions Mean           5148.1143
Q Predictions Std            569.3749
Q Predictions Max            5800.5264
Q Predictions Min            2435.7678
V Predictions Mean           5137.2725
V Predictions Std            566.4167
V Predictions Max            5779.3086
V Predictions Min            2445.6794
Log Pis Mean                 6.1822844
Log Pis Std                  3.8062563
Log Pis Max                  17.55453
Log Pis Min                  -3.8074367
Policy mu Mean               -0.06596878
Policy mu Std                1.4343216
Policy mu Max                3.11908
Policy mu Min                -3.4353733
Policy log std Mean          -0.9529063
Policy log std Std           0.51882815
Policy log std Max           -0.26547837
Policy log std Min           -3.508574
Z mean eval                  3.3217628
Z variance eval              0.0156053435
total_rewards                [12050.51302363 12650.52453532 12002.7246661   2692.50231171
 10259.90068256 12307.46442592 12351.5941961  12568.36086098
 12481.87157265 11723.25544414]
total_rewards_mean           11108.871171909603
total_rewards_std            2880.8344071119022
total_rewards_max            12650.524535324463
total_rewards_min            2692.502311706022
Number of train steps total  1396000
Number of env steps total    1747000
Number of rollouts total     0
Train Time (s)               116.34902220219374
(Previous) Eval Time (s)     22.546900692861527
Sample Time (s)              16.02551592187956
Epoch Time (s)               154.92143881693482
Total Train Time (s)         53854.6200304064
Epoch                        348
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:33:54.430407 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #348 | Epoch Duration: 155.71776676177979
2020-01-13 23:33:54.430624 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #348 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3220534
Z variance train             0.01563001
KL Divergence                59.68377
KL Loss                      5.968377
QF Loss                      698.2853
VF Loss                      150.9562
Policy Loss                  -5059.2026
Q Predictions Mean           5061.8823
Q Predictions Std            622.78345
Q Predictions Max            5822.558
Q Predictions Min            3500.388
V Predictions Mean           5064.569
V Predictions Std            622.7327
V Predictions Max            5809.4727
V Predictions Min            3512.9792
Log Pis Mean                 5.937367
Log Pis Std                  3.8079023
Log Pis Max                  15.566647
Log Pis Min                  -2.0028737
Policy mu Mean               -0.11250403
Policy mu Std                1.4263717
Policy mu Max                3.1648455
Policy mu Min                -2.908393
Policy log std Mean          -0.93168753
Policy log std Std           0.48618412
Policy log std Max           -0.25246298
Policy log std Min           -3.3017528
Z mean eval                  3.3309116
Z variance eval              0.017882405
total_rewards                [11319.77604204 11193.53018963 11472.99926983 11401.69401229
 11081.41123167 11227.4457523  11198.14487    11117.41656719
 11690.19694952 11018.59848063]
total_rewards_mean           11272.121336507862
total_rewards_std            192.9823705783847
total_rewards_max            11690.196949518575
total_rewards_min            11018.598480626326
Number of train steps total  1400000
Number of env steps total    1752000
Number of rollouts total     0
Train Time (s)               120.31252392521128
(Previous) Eval Time (s)     23.34288465185091
Sample Time (s)              16.762997908052057
Epoch Time (s)               160.41840648511425
Total Train Time (s)         54014.93362426432
Epoch                        349
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:36:34.748724 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #349 | Epoch Duration: 160.31791877746582
2020-01-13 23:36:34.748935 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #349 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3304563
Z variance train             0.017883688
KL Divergence                59.36409
KL Loss                      5.936409
QF Loss                      365.86896
VF Loss                      167.20605
Policy Loss                  -5152.821
Q Predictions Mean           5157.105
Q Predictions Std            533.6968
Q Predictions Max            5815.856
Q Predictions Min            3529.122
V Predictions Mean           5157.289
V Predictions Std            533.3321
V Predictions Max            5836.91
V Predictions Min            3530.472
Log Pis Mean                 5.558385
Log Pis Std                  3.5027707
Log Pis Max                  15.860119
Log Pis Min                  -2.0806155
Policy mu Mean               -0.12515697
Policy mu Std                1.3905071
Policy mu Max                2.8779254
Policy mu Min                -2.8119218
Policy log std Mean          -0.942632
Policy log std Std           0.53058296
Policy log std Max           -0.07893872
Policy log std Min           -3.5514874
Z mean eval                  3.352951
Z variance eval              0.052037545
total_rewards                [12330.09537361 12098.04006079 12384.02762757 12391.41915506
 12473.57780027  6343.83760861 12618.67023499 12133.91334394
 12500.31975158 12525.11866342]
total_rewards_mean           11779.901961984655
total_rewards_std            1818.7367472530834
total_rewards_max            12618.670234992613
total_rewards_min            6343.8376086054905
Number of train steps total  1404000
Number of env steps total    1757000
Number of rollouts total     0
Train Time (s)               117.52136997086927
(Previous) Eval Time (s)     23.242083930876106
Sample Time (s)              15.488789519295096
Epoch Time (s)               156.25224342104048
Total Train Time (s)         54171.01843660418
Epoch                        350
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:39:10.846081 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #350 | Epoch Duration: 156.09695506095886
2020-01-13 23:39:10.846368 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #350 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.355889
Z variance train             0.051793456
KL Divergence                58.118492
KL Loss                      5.811849
QF Loss                      769.6588
VF Loss                      232.93732
Policy Loss                  -4973.466
Q Predictions Mean           4975.1055
Q Predictions Std            600.1994
Q Predictions Max            5673.0127
Q Predictions Min            1401.1732
V Predictions Mean           4963.223
V Predictions Std            598.1563
V Predictions Max            5635.4517
V Predictions Min            1413.4899
Log Pis Mean                 5.825922
Log Pis Std                  3.9326174
Log Pis Max                  15.619192
Log Pis Min                  -4.9744654
Policy mu Mean               -0.09163829
Policy mu Std                1.4154177
Policy mu Max                3.190586
Policy mu Min                -3.9127066
Policy log std Mean          -0.9432909
Policy log std Std           0.5109769
Policy log std Max           -0.17832315
Policy log std Min           -3.3212652
Z mean eval                  3.4155908
Z variance eval              0.024225214
total_rewards                [12053.12073455 12437.70385176 11969.00379874 12010.13157093
 12359.16255552 12256.9589496  12684.64637247 12216.61346171
 12282.59961032  8397.69276587]
total_rewards_mean           11866.763367147007
total_rewards_std            1174.1004012955812
total_rewards_max            12684.64637247294
total_rewards_min            8397.692765865058
Number of train steps total  1408000
Number of env steps total    1762000
Number of rollouts total     0
Train Time (s)               115.25529076997191
(Previous) Eval Time (s)     23.086513749789447
Sample Time (s)              16.576622215099633
Epoch Time (s)               154.918426734861
Total Train Time (s)         54326.06893139286
Epoch                        351
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:41:45.897856 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #351 | Epoch Duration: 155.05129194259644
2020-01-13 23:41:45.898046 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #351 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.4157596
Z variance train             0.024308886
KL Divergence                57.406036
KL Loss                      5.740604
QF Loss                      715.9451
VF Loss                      139.71179
Policy Loss                  -5057.961
Q Predictions Mean           5066.3267
Q Predictions Std            613.8614
Q Predictions Max            5793.8604
Q Predictions Min            3484.5247
V Predictions Mean           5057.1616
V Predictions Std            614.1672
V Predictions Max            5782.2305
V Predictions Min            3481.6572
Log Pis Mean                 5.319979
Log Pis Std                  3.8905714
Log Pis Max                  16.104862
Log Pis Min                  -2.7627456
Policy mu Mean               -0.07346583
Policy mu Std                1.3929917
Policy mu Max                2.9210026
Policy mu Min                -2.9035645
Policy log std Mean          -0.9393504
Policy log std Std           0.5102703
Policy log std Max           -0.14854974
Policy log std Min           -3.5756092
Z mean eval                  3.3610644
Z variance eval              0.024379764
total_rewards                [12100.38647602 12535.5825596  12467.84189423 12306.64604788
 12327.10491162 12505.7844127  12161.04933699 12463.1473924
 12644.29545811 12395.11282937]
total_rewards_mean           12390.695131892811
total_rewards_std            160.5913369995521
total_rewards_max            12644.295458113997
total_rewards_min            12100.38647602261
Number of train steps total  1412000
Number of env steps total    1767000
Number of rollouts total     0
Train Time (s)               112.84320609597489
(Previous) Eval Time (s)     23.219100362155586
Sample Time (s)              15.630866593681276
Epoch Time (s)               151.69317305181175
Total Train Time (s)         54477.05815236317
Epoch                        352
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:44:16.892132 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #352 | Epoch Duration: 150.99393796920776
2020-01-13 23:44:16.892374 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #352 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3635986
Z variance train             0.024124384
KL Divergence                58.75836
KL Loss                      5.8758364
QF Loss                      995.80176
VF Loss                      339.92548
Policy Loss                  -5151.4966
Q Predictions Mean           5151.497
Q Predictions Std            643.6952
Q Predictions Max            5864.9473
Q Predictions Min            1077.5898
V Predictions Mean           5137.551
V Predictions Std            642.0001
V Predictions Max            5851.554
V Predictions Min            1112.5994
Log Pis Mean                 6.086584
Log Pis Std                  3.9091117
Log Pis Max                  21.464348
Log Pis Min                  -5.2328353
Policy mu Mean               -0.083318956
Policy mu Std                1.4345913
Policy mu Max                4.321592
Policy mu Min                -4.0358477
Policy log std Mean          -0.928482
Policy log std Std           0.49762776
Policy log std Max           0.049860597
Policy log std Min           -3.3349292
Z mean eval                  3.3284087
Z variance eval              0.041003473
total_rewards                [11923.35406496 12059.14064591 12048.46050632 12430.13248674
 12329.65091142 12142.91034005 11697.70978599 11549.3188342
  4436.69163557 12039.14908115]
total_rewards_mean           11265.651829231425
total_rewards_std            2289.821265394233
total_rewards_max            12430.132486743389
total_rewards_min            4436.691635566623
Number of train steps total  1416000
Number of env steps total    1772000
Number of rollouts total     0
Train Time (s)               118.33320856885985
(Previous) Eval Time (s)     22.51957752322778
Sample Time (s)              16.4840208850801
Epoch Time (s)               157.33680697716773
Total Train Time (s)         54634.71420367528
Epoch                        353
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:46:54.552883 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #353 | Epoch Duration: 157.66033124923706
2020-01-13 23:46:54.553094 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #353 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3283646
Z variance train             0.04106163
KL Divergence                55.043793
KL Loss                      5.5043793
QF Loss                      816.7381
VF Loss                      247.58958
Policy Loss                  -5013.0806
Q Predictions Mean           5026.333
Q Predictions Std            679.67126
Q Predictions Max            5773.1562
Q Predictions Min            935.47723
V Predictions Mean           5011.381
V Predictions Std            685.60876
V Predictions Max            5764.781
V Predictions Min            838.0219
Log Pis Mean                 6.119649
Log Pis Std                  3.7037385
Log Pis Max                  16.726446
Log Pis Min                  -4.6178117
Policy mu Mean               -0.11113504
Policy mu Std                1.4466066
Policy mu Max                3.2568567
Policy mu Min                -3.4678712
Policy log std Mean          -0.9098404
Policy log std Std           0.4948886
Policy log std Max           0.03576815
Policy log std Min           -3.4865253
Z mean eval                  3.3547375
Z variance eval              0.022437945
total_rewards                [12441.15413878 12337.82678421  7640.22477662 12369.67584873
 12596.7716522  12506.38818227 12566.00963279 11486.31949614
 12496.62047326 11356.6866063 ]
total_rewards_mean           11779.767759130284
total_rewards_std            1443.0975615002294
total_rewards_max            12596.77165220083
total_rewards_min            7640.22477662198
Number of train steps total  1420000
Number of env steps total    1777000
Number of rollouts total     0
Train Time (s)               113.99287414969876
(Previous) Eval Time (s)     22.84281077515334
Sample Time (s)              16.476424586959183
Epoch Time (s)               153.3121095118113
Total Train Time (s)         54788.40424275957
Epoch                        354
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:49:28.249216 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #354 | Epoch Duration: 153.69591903686523
2020-01-13 23:49:28.249564 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #354 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3550205
Z variance train             0.022426901
KL Divergence                57.557076
KL Loss                      5.7557077
QF Loss                      736.03564
VF Loss                      146.37816
Policy Loss                  -5093.6895
Q Predictions Mean           5103.4663
Q Predictions Std            577.3174
Q Predictions Max            5760.5664
Q Predictions Min            3424.058
V Predictions Mean           5087.8477
V Predictions Std            575.2717
V Predictions Max            5740.2734
V Predictions Min            3429.6902
Log Pis Mean                 5.83356
Log Pis Std                  3.3485985
Log Pis Max                  16.642708
Log Pis Min                  -2.02129
Policy mu Mean               -0.12524162
Policy mu Std                1.4200665
Policy mu Max                3.7286673
Policy mu Min                -3.305754
Policy log std Mean          -0.93646497
Policy log std Std           0.5057756
Policy log std Max           0.2759052
Policy log std Min           -3.5191793
Z mean eval                  3.3147101
Z variance eval              0.025930699
total_rewards                [12360.47772235 12802.19860344 12523.82622451 12372.21275787
 12616.477931   12612.11077761 12549.04758614 12628.38266204
 12446.87258892 12944.79163623]
total_rewards_mean           12585.639849011068
total_rewards_std            173.21423806346226
total_rewards_max            12944.791636233336
total_rewards_min            12360.477722345267
Number of train steps total  1424000
Number of env steps total    1782000
Number of rollouts total     0
Train Time (s)               122.0008754460141
(Previous) Eval Time (s)     23.226273883134127
Sample Time (s)              16.156780175864697
Epoch Time (s)               161.38392950501293
Total Train Time (s)         54949.43473418057
Epoch                        355
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:52:09.282282 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #355 | Epoch Duration: 161.03247499465942
2020-01-13 23:52:09.282494 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #355 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3137245
Z variance train             0.02595064
KL Divergence                56.72145
KL Loss                      5.6721454
QF Loss                      673.5754
VF Loss                      244.28229
Policy Loss                  -5001.0215
Q Predictions Mean           5003.8184
Q Predictions Std            670.1621
Q Predictions Max            5797.4805
Q Predictions Min            820.9618
V Predictions Mean           5012.7725
V Predictions Std            666.60895
V Predictions Max            5795.9004
V Predictions Min            871.3962
Log Pis Mean                 5.687578
Log Pis Std                  3.7994363
Log Pis Max                  14.598481
Log Pis Min                  -6.9693065
Policy mu Mean               -0.08775564
Policy mu Std                1.3964914
Policy mu Max                3.4975417
Policy mu Min                -2.755252
Policy log std Mean          -0.93094254
Policy log std Std           0.47389042
Policy log std Max           -0.23351777
Policy log std Min           -3.4378476
Z mean eval                  3.3522582
Z variance eval              0.010726223
total_rewards                [12354.13420062 12641.90597783 12466.65439521 12591.24003598
 12840.14812465 12440.60221291 12698.80071431 12534.52741771
 12546.86102004 12680.76887535]
total_rewards_mean           12579.56429746177
total_rewards_std            135.04150809481038
total_rewards_max            12840.148124654479
total_rewards_min            12354.134200619274
Number of train steps total  1428000
Number of env steps total    1787000
Number of rollouts total     0
Train Time (s)               118.80422087293118
(Previous) Eval Time (s)     22.874500122852623
Sample Time (s)              15.767756502144039
Epoch Time (s)               157.44647749792784
Total Train Time (s)         55106.85375952255
Epoch                        356
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:54:46.708337 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #356 | Epoch Duration: 157.42566514015198
2020-01-13 23:54:46.708613 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #356 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3533607
Z variance train             0.010700585
KL Divergence                60.390182
KL Loss                      6.039018
QF Loss                      629.891
VF Loss                      512.0135
Policy Loss                  -5075.1743
Q Predictions Mean           5075.5557
Q Predictions Std            652.6676
Q Predictions Max            5818.642
Q Predictions Min            976.6144
V Predictions Mean           5059.6255
V Predictions Std            647.11566
V Predictions Max            5782.658
V Predictions Min            1103.4697
Log Pis Mean                 6.024336
Log Pis Std                  4.0893774
Log Pis Max                  18.269512
Log Pis Min                  -3.944633
Policy mu Mean               -0.0737184
Policy mu Std                1.4393482
Policy mu Max                3.1697545
Policy mu Min                -3.4453065
Policy log std Mean          -0.9621153
Policy log std Std           0.5314212
Policy log std Max           0.010420799
Policy log std Min           -3.5735297
Z mean eval                  3.3237007
Z variance eval              0.0126875695
total_rewards                [12357.13005161 12670.76341902 12490.15820141 12749.32880198
 12198.61261483 12334.60664655 12416.52654228 12611.74029508
 12422.31277524 12514.32615468]
total_rewards_mean           12476.550550268268
total_rewards_std            158.1829591289848
total_rewards_max            12749.328801983498
total_rewards_min            12198.612614832804
Number of train steps total  1432000
Number of env steps total    1792000
Number of rollouts total     0
Train Time (s)               119.12366316793486
(Previous) Eval Time (s)     22.85338987223804
Sample Time (s)              16.746267333626747
Epoch Time (s)               158.72332037379965
Total Train Time (s)         55266.39245797228
Epoch                        357
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:57:26.248113 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #357 | Epoch Duration: 159.53928017616272
2020-01-13 23:57:26.248325 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #357 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.32352
Z variance train             0.0126871895
KL Divergence                58.750885
KL Loss                      5.8750887
QF Loss                      475.6015
VF Loss                      151.78088
Policy Loss                  -5046.7153
Q Predictions Mean           5052.587
Q Predictions Std            570.8602
Q Predictions Max            5728.9253
Q Predictions Min            3440.2979
V Predictions Mean           5053.7974
V Predictions Std            569.7607
V Predictions Max            5738.9746
V Predictions Min            3440.426
Log Pis Mean                 5.621048
Log Pis Std                  3.6670902
Log Pis Max                  18.77889
Log Pis Min                  -2.7198794
Policy mu Mean               -0.10716591
Policy mu Std                1.3984165
Policy mu Max                3.1472356
Policy mu Min                -3.2968166
Policy log std Mean          -0.9438327
Policy log std Std           0.49257916
Policy log std Max           -0.0077064037
Policy log std Min           -3.3971512
Z mean eval                  3.3377743
Z variance eval              0.015055736
total_rewards                [12146.95105265 12512.31636207 12222.53889106 12445.58763267
 12353.04019963 12398.75343979 12275.03287781 12602.29703525
 12273.98886264 12379.71139366]
total_rewards_mean           12361.021774724146
total_rewards_std            130.40877082233035
total_rewards_max            12602.297035254038
total_rewards_min            12146.951052652372
Number of train steps total  1436000
Number of env steps total    1797000
Number of rollouts total     0
Train Time (s)               116.12602123897523
(Previous) Eval Time (s)     23.669070683885366
Sample Time (s)              15.805419206619263
Epoch Time (s)               155.60051112947986
Total Train Time (s)         55420.78692727396
Epoch                        358
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:00:00.645486 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #358 | Epoch Duration: 154.3970227241516
2020-01-14 00:00:00.645714 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #358 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3380141
Z variance train             0.015068062
KL Divergence                59.26586
KL Loss                      5.926586
QF Loss                      1449.7651
VF Loss                      84.950806
Policy Loss                  -5080.6523
Q Predictions Mean           5084.8975
Q Predictions Std            618.11066
Q Predictions Max            5792.909
Q Predictions Min            3453.6377
V Predictions Mean           5080.239
V Predictions Std            616.453
V Predictions Max            5789.7285
V Predictions Min            3452.633
Log Pis Mean                 5.4294796
Log Pis Std                  3.7606208
Log Pis Max                  24.249702
Log Pis Min                  -5.4900203
Policy mu Mean               -0.04707053
Policy mu Std                1.3664958
Policy mu Max                3.6349905
Policy mu Min                -3.2191327
Policy log std Mean          -0.95566225
Policy log std Std           0.50324655
Policy log std Max           -0.18873698
Policy log std Min           -3.4307175
Z mean eval                  3.3181396
Z variance eval              0.025151188
total_rewards                [12010.99368338 12193.45287689 10376.98689031 12462.90509501
  6273.63516525 12259.55472869 12658.23177305 12296.19488226
 12339.51805333 12450.13532768]
total_rewards_mean           11532.160847586003
total_rewards_std            1854.5829856730968
total_rewards_max            12658.231773045693
total_rewards_min            6273.635165249301
Number of train steps total  1440000
Number of env steps total    1802000
Number of rollouts total     0
Train Time (s)               114.95173310907558
(Previous) Eval Time (s)     22.465268526691943
Sample Time (s)              15.742510801181197
Epoch Time (s)               153.15951243694872
Total Train Time (s)         55573.80249543628
Epoch                        359
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:02:33.664818 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #359 | Epoch Duration: 153.01896166801453
2020-01-14 00:02:33.665031 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #359 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3192246
Z variance train             0.025116455
KL Divergence                57.30828
KL Loss                      5.7308283
QF Loss                      2173.2446
VF Loss                      711.42334
Policy Loss                  -5159.886
Q Predictions Mean           5164.49
Q Predictions Std            587.3759
Q Predictions Max            5812.7334
Q Predictions Min            2401.8796
V Predictions Mean           5159.835
V Predictions Std            581.414
V Predictions Max            5806.3223
V Predictions Min            2844.7346
Log Pis Mean                 6.6173787
Log Pis Std                  4.076777
Log Pis Max                  17.073391
Log Pis Min                  -4.871753
Policy mu Mean               -0.043419078
Policy mu Std                1.4809537
Policy mu Max                2.8756402
Policy mu Min                -3.0585163
Policy log std Mean          -0.93953043
Policy log std Std           0.5123103
Policy log std Max           -0.17968047
Policy log std Min           -3.4501333
Z mean eval                  3.3098812
Z variance eval              0.015513438
total_rewards                [11817.07526251 11917.21217421 12240.42650157  5974.66745424
 12021.92552711 12469.07358686 12337.48113735 12168.49307017
 12292.12248114 12138.0550521 ]
total_rewards_mean           11537.653224726879
total_rewards_std            1863.6602694710175
total_rewards_max            12469.073586864393
total_rewards_min            5974.667454242218
Number of train steps total  1444000
Number of env steps total    1807000
Number of rollouts total     0
Train Time (s)               113.81418349593878
(Previous) Eval Time (s)     22.324410079978406
Sample Time (s)              17.034828716889024
Epoch Time (s)               153.1734222928062
Total Train Time (s)         55727.704775820486
Epoch                        360
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:05:07.570883 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #360 | Epoch Duration: 153.90569519996643
2020-01-14 00:05:07.571104 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #360 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.309909
Z variance train             0.015493324
KL Divergence                58.705643
KL Loss                      5.8705645
QF Loss                      1079.7158
VF Loss                      282.4176
Policy Loss                  -5052.098
Q Predictions Mean           5055.9644
Q Predictions Std            702.5485
Q Predictions Max            5799.102
Q Predictions Min            382.0241
V Predictions Mean           5041.7725
V Predictions Std            704.999
V Predictions Max            5771.17
V Predictions Min            329.61966
Log Pis Mean                 6.1718864
Log Pis Std                  3.946969
Log Pis Max                  15.214653
Log Pis Min                  -4.8913283
Policy mu Mean               -0.11911126
Policy mu Std                1.4512439
Policy mu Max                3.3031373
Policy mu Min                -3.3048806
Policy log std Mean          -0.93235093
Policy log std Std           0.48789853
Policy log std Max           -0.104573965
Policy log std Min           -3.227179
Z mean eval                  3.2953422
Z variance eval              0.02035223
total_rewards                [12016.00150908 12653.43930869 12478.49244547 12401.95376419
 12627.23141109 12674.26717905 12410.77658985 12392.35915287
 12493.5945165  12402.9527221 ]
total_rewards_mean           12455.10685988831
total_rewards_std            179.80081049604726
total_rewards_max            12674.267179045053
total_rewards_min            12016.001509080992
Number of train steps total  1448000
Number of env steps total    1812000
Number of rollouts total     0
Train Time (s)               122.89092704467475
(Previous) Eval Time (s)     23.056360811926425
Sample Time (s)              15.96701497072354
Epoch Time (s)               161.91430282732472
Total Train Time (s)         55889.755749380216
Epoch                        361
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:07:49.625836 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #361 | Epoch Duration: 162.0545620918274
2020-01-14 00:07:49.626076 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #361 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2944112
Z variance train             0.020351317
KL Divergence                57.36602
KL Loss                      5.7366023
QF Loss                      389.94882
VF Loss                      302.00696
Policy Loss                  -5084.077
Q Predictions Mean           5091.842
Q Predictions Std            595.9538
Q Predictions Max            5782.1274
Q Predictions Min            3462.0415
V Predictions Mean           5098.16
V Predictions Std            594.8323
V Predictions Max            5785.5786
V Predictions Min            3461.197
Log Pis Mean                 6.054699
Log Pis Std                  3.8875642
Log Pis Max                  16.196274
Log Pis Min                  -2.7848918
Policy mu Mean               -0.10480833
Policy mu Std                1.4271288
Policy mu Max                3.07209
Policy mu Min                -3.0513265
Policy log std Mean          -0.9323535
Policy log std Std           0.49952525
Policy log std Max           -0.039254427
Policy log std Min           -3.3956156
Z mean eval                  3.2966697
Z variance eval              0.052033853
total_rewards                [12030.7462038   5659.24483362 12475.61681891 12528.78046996
 12455.05612076 12377.26749219 12105.93113299 12436.75860087
 12331.92386171 12281.26493336]
total_rewards_mean           11668.259046816598
total_rewards_std            2008.782981793244
total_rewards_max            12528.78046995606
total_rewards_min            5659.244833622681
Number of train steps total  1452000
Number of env steps total    1817000
Number of rollouts total     0
Train Time (s)               122.55616044998169
(Previous) Eval Time (s)     23.19632775289938
Sample Time (s)              15.872235736809671
Epoch Time (s)               161.62472393969074
Total Train Time (s)         56050.882133550476
Epoch                        362
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:10:30.756179 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #362 | Epoch Duration: 161.12991857528687
2020-01-14 00:10:30.756381 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #362 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.2962341
Z variance train             0.052047264
KL Divergence                57.254948
KL Loss                      5.725495
QF Loss                      383.87396
VF Loss                      99.79826
Policy Loss                  -5298.6084
Q Predictions Mean           5307.194
Q Predictions Std            540.29803
Q Predictions Max            5930.3286
Q Predictions Min            3632.266
V Predictions Mean           5303.8174
V Predictions Std            540.15466
V Predictions Max            5917.5884
V Predictions Min            3610.3235
Log Pis Mean                 5.732976
Log Pis Std                  3.9750826
Log Pis Max                  15.390529
Log Pis Min                  -3.1832662
Policy mu Mean               -0.107612275
Policy mu Std                1.4082448
Policy mu Max                2.8931212
Policy mu Min                -2.6086671
Policy log std Mean          -0.94695514
Policy log std Std           0.51170033
Policy log std Max           -0.16064799
Policy log std Min           -3.2890358
Z mean eval                  3.352715
Z variance eval              0.058226902
total_rewards                [ 7765.12036562 12584.07875911 12582.1058987  12666.36435066
 12672.65447919 12456.91295457 12847.31622812 12684.33441884
 12389.80829675 12476.2662325 ]
total_rewards_mean           12112.49619840673
total_rewards_std            1454.5776091100697
total_rewards_max            12847.316228124348
total_rewards_min            7765.120365617622
Number of train steps total  1456000
Number of env steps total    1822000
Number of rollouts total     0
Train Time (s)               113.89087259676307
(Previous) Eval Time (s)     22.701231370214373
Sample Time (s)              15.908782973885536
Epoch Time (s)               152.50088694086298
Total Train Time (s)         56203.36002181331
Epoch                        363
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:13:03.239262 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #363 | Epoch Duration: 152.48271584510803
2020-01-14 00:13:03.239519 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #363 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3517277
Z variance train             0.05806352
KL Divergence                55.411274
KL Loss                      5.5411277
QF Loss                      854.20105
VF Loss                      185.83167
Policy Loss                  -4995.036
Q Predictions Mean           5009.0635
Q Predictions Std            753.3557
Q Predictions Max            5728.13
Q Predictions Min            -103.37991
V Predictions Mean           4999.0737
V Predictions Std            752.58655
V Predictions Max            5713.602
V Predictions Min            -112.608376
Log Pis Mean                 6.079745
Log Pis Std                  3.9524379
Log Pis Max                  16.696735
Log Pis Min                  -2.8560452
Policy mu Mean               -0.019131953
Policy mu Std                1.4103742
Policy mu Max                2.7816014
Policy mu Min                -3.1082542
Policy log std Mean          -0.9469688
Policy log std Std           0.51251894
Policy log std Max           -0.23144215
Policy log std Min           -3.537632
Z mean eval                  3.3160954
Z variance eval              0.032094073
total_rewards                [12278.72400784 12320.41971344 12461.17623903 12464.42871411
 12541.06832718 12551.70491146 12661.10345642 12455.47578582
 12534.98001677 12370.8111765 ]
total_rewards_mean           12463.989234856583
total_rewards_std            110.10317031575484
total_rewards_max            12661.103456421197
total_rewards_min            12278.724007839643
Number of train steps total  1460000
Number of env steps total    1827000
Number of rollouts total     0
Train Time (s)               116.06323394877836
(Previous) Eval Time (s)     22.682771157938987
Sample Time (s)              16.374818756710738
Epoch Time (s)               155.1208238634281
Total Train Time (s)         56358.30131211132
Epoch                        364
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:15:38.182487 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #364 | Epoch Duration: 154.94278645515442
2020-01-14 00:15:38.182675 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #364 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.317494
Z variance train             0.03217126
KL Divergence                57.703056
KL Loss                      5.7703056
QF Loss                      847.7959
VF Loss                      888.60583
Policy Loss                  -5067.068
Q Predictions Mean           5072.7715
Q Predictions Std            660.2945
Q Predictions Max            5750.4746
Q Predictions Min            -97.576744
V Predictions Mean           5045.786
V Predictions Std            654.4081
V Predictions Max            5728.2124
V Predictions Min            -98.3814
Log Pis Mean                 6.656268
Log Pis Std                  4.173978
Log Pis Max                  21.457352
Log Pis Min                  -5.042561
Policy mu Mean               -0.13860857
Policy mu Std                1.4620363
Policy mu Max                3.1631634
Policy mu Min                -3.1406467
Policy log std Mean          -0.96916395
Policy log std Std           0.5482527
Policy log std Max           0.132429
Policy log std Min           -3.3628576
Z mean eval                  3.3409119
Z variance eval              0.038331028
total_rewards                [12498.79377329 12958.41622953 12374.54844858 12671.56947508
 12817.90430917 12601.79921714 12676.12561121 12358.94564577
 12384.72681686 12530.65914167]
total_rewards_mean           12587.348866829681
total_rewards_std            188.57187158674932
total_rewards_max            12958.416229529003
total_rewards_min            12358.94564576514
Number of train steps total  1464000
Number of env steps total    1832000
Number of rollouts total     0
Train Time (s)               115.40738087426871
(Previous) Eval Time (s)     22.504431684035808
Sample Time (s)              15.870825815480202
Epoch Time (s)               153.78263837378472
Total Train Time (s)         56511.747503813356
Epoch                        365
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:18:11.632805 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #365 | Epoch Duration: 153.44999814033508
2020-01-14 00:18:11.633000 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #365 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3396657
Z variance train             0.038298476
KL Divergence                58.367195
KL Loss                      5.8367195
QF Loss                      471.68552
VF Loss                      244.54745
Policy Loss                  -5129.439
Q Predictions Mean           5139.232
Q Predictions Std            583.74646
Q Predictions Max            5781.1274
Q Predictions Min            3488.5315
V Predictions Mean           5141.832
V Predictions Std            582.55676
V Predictions Max            5774.6543
V Predictions Min            3500.841
Log Pis Mean                 6.271271
Log Pis Std                  3.8985417
Log Pis Max                  17.738003
Log Pis Min                  -1.5089979
Policy mu Mean               -0.10332922
Policy mu Std                1.439951
Policy mu Max                3.0777335
Policy mu Min                -2.752232
Policy log std Mean          -0.95358753
Policy log std Std           0.53482413
Policy log std Max           0.16916335
Policy log std Min           -3.458211
Z mean eval                  3.3376126
Z variance eval              0.037019175
total_rewards                [11950.07306928 12045.12164528 12315.1879149  12128.92259075
 12287.97241551 12196.54104062 12344.44688242 12020.1486626
 12331.9575126  12168.530942  ]
total_rewards_mean           12178.890267595174
total_rewards_std            134.04492669320766
total_rewards_max            12344.446882417078
total_rewards_min            11950.073069275943
Number of train steps total  1468000
Number of env steps total    1837000
Number of rollouts total     0
Train Time (s)               118.55517421709374
(Previous) Eval Time (s)     22.17149674287066
Sample Time (s)              16.26278181746602
Epoch Time (s)               156.98945277743042
Total Train Time (s)         56669.34683082346
Epoch                        366
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:20:49.237710 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #366 | Epoch Duration: 157.60453510284424
2020-01-14 00:20:49.237952 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #366 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3387833
Z variance train             0.037026465
KL Divergence                57.426937
KL Loss                      5.742694
QF Loss                      1224.6023
VF Loss                      321.39508
Policy Loss                  -5158.818
Q Predictions Mean           5160.415
Q Predictions Std            634.2019
Q Predictions Max            5820.3496
Q Predictions Min            1373.0951
V Predictions Mean           5154.664
V Predictions Std            630.32635
V Predictions Max            5798.0054
V Predictions Min            1524.06
Log Pis Mean                 6.28201
Log Pis Std                  3.8576536
Log Pis Max                  18.031694
Log Pis Min                  -4.4383917
Policy mu Mean               -0.10208932
Policy mu Std                1.451395
Policy mu Max                3.1301177
Policy mu Min                -3.3404725
Policy log std Mean          -0.91805726
Policy log std Std           0.5089482
Policy log std Max           -0.15784359
Policy log std Min           -3.4966364
Z mean eval                  3.3323033
Z variance eval              0.023811178
total_rewards                [12614.31423012 12651.16832646  7084.05796903 12348.71822009
 12498.26933563 12150.1895048  12422.04747219 12603.00806931
 12577.97566449 12422.32563982]
total_rewards_mean           11937.20744319386
total_rewards_std            1624.0397283646237
total_rewards_max            12651.168326457775
total_rewards_min            7084.0579690326185
Number of train steps total  1472000
Number of env steps total    1842000
Number of rollouts total     0
Train Time (s)               116.52505698194727
(Previous) Eval Time (s)     22.786279728170484
Sample Time (s)              16.55706445639953
Epoch Time (s)               155.8684011665173
Total Train Time (s)         56825.34654650651
Epoch                        367
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:23:25.239682 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #367 | Epoch Duration: 156.0015368461609
2020-01-14 00:23:25.239888 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #367 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3325284
Z variance train             0.023816062
KL Divergence                57.831047
KL Loss                      5.783105
QF Loss                      669.2167
VF Loss                      298.93668
Policy Loss                  -5091.842
Q Predictions Mean           5093.5884
Q Predictions Std            612.6398
Q Predictions Max            5807.027
Q Predictions Min            3455.2446
V Predictions Mean           5077.745
V Predictions Std            607.85376
V Predictions Max            5795.3823
V Predictions Min            3454.7593
Log Pis Mean                 5.494917
Log Pis Std                  3.4324427
Log Pis Max                  16.839813
Log Pis Min                  -3.4283593
Policy mu Mean               -0.12031025
Policy mu Std                1.3586992
Policy mu Max                3.1474493
Policy mu Min                -3.2276313
Policy log std Mean          -0.9556133
Policy log std Std           0.49513242
Policy log std Max           0.03413987
Policy log std Min           -3.6197731
Z mean eval                  3.3412278
Z variance eval              0.028901953
total_rewards                [12036.38502792 12251.90626264 11897.70246184 12594.77118534
 12087.71305863 12253.90074806 12226.54581159 12110.39292852
 12210.03720351 12238.86323782]
total_rewards_mean           12190.821792586696
total_rewards_std            173.6976299638042
total_rewards_max            12594.771185335518
total_rewards_min            11897.70246183933
Number of train steps total  1476000
Number of env steps total    1847000
Number of rollouts total     0
Train Time (s)               118.19688370078802
(Previous) Eval Time (s)     22.919086894020438
Sample Time (s)              16.708770993631333
Epoch Time (s)               157.8247415884398
Total Train Time (s)         56983.17728483118
Epoch                        368
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:26:03.074265 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #368 | Epoch Duration: 157.8342409133911
2020-01-14 00:26:03.074450 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #368 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3415685
Z variance train             0.02887733
KL Divergence                59.23393
KL Loss                      5.923393
QF Loss                      522.4873
VF Loss                      209.15298
Policy Loss                  -5031.781
Q Predictions Mean           5033.463
Q Predictions Std            592.51685
Q Predictions Max            5748.6587
Q Predictions Min            3431.9053
V Predictions Mean           5022.507
V Predictions Std            587.828
V Predictions Max            5739.3623
V Predictions Min            3442.1064
Log Pis Mean                 6.2457476
Log Pis Std                  3.6697712
Log Pis Max                  16.674795
Log Pis Min                  -3.7263408
Policy mu Mean               -0.058263317
Policy mu Std                1.4283915
Policy mu Max                2.8275518
Policy mu Min                -3.0833623
Policy log std Mean          -0.945301
Policy log std Std           0.5116928
Policy log std Max           -0.2657981
Policy log std Min           -3.504611
Z mean eval                  3.330954
Z variance eval              0.02860564
total_rewards                [12110.26137878 12365.06520192 12488.74624341 12226.81520734
  6028.04551715  9524.13552996 11804.97559394 12116.9324548
 11127.12020895 12318.39001255]
total_rewards_mean           11211.048734881213
total_rewards_std            1921.4695282938894
total_rewards_max            12488.746243414724
total_rewards_min            6028.045517147328
Number of train steps total  1480000
Number of env steps total    1852000
Number of rollouts total     0
Train Time (s)               121.30023679323494
(Previous) Eval Time (s)     22.92824618378654
Sample Time (s)              16.419492012355477
Epoch Time (s)               160.64797498937696
Total Train Time (s)         57143.72963532992
Epoch                        369
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:28:43.636150 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #369 | Epoch Duration: 160.56150555610657
2020-01-14 00:28:43.636469 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #369 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3308845
Z variance train             0.028648073
KL Divergence                60.13999
KL Loss                      6.0139995
QF Loss                      525.79065
VF Loss                      140.62488
Policy Loss                  -5139.2607
Q Predictions Mean           5149.715
Q Predictions Std            563.6575
Q Predictions Max            5798.4316
Q Predictions Min            3464.6174
V Predictions Mean           5137.032
V Predictions Std            560.4547
V Predictions Max            5781.821
V Predictions Min            3478.3748
Log Pis Mean                 6.051475
Log Pis Std                  3.6815655
Log Pis Max                  14.536516
Log Pis Min                  -4.315627
Policy mu Mean               -0.068530135
Policy mu Std                1.4154621
Policy mu Max                3.232214
Policy mu Min                -2.8615043
Policy log std Mean          -0.9768967
Policy log std Std           0.52165544
Policy log std Max           -0.14613682
Policy log std Min           -3.474791
Z mean eval                  3.3572667
Z variance eval              0.030519525
total_rewards                [12611.54736813 12727.53846446 12846.46966999  1362.70303943
 12933.95179753 12647.81178638 12314.15181935 12385.07521318
 12952.53718036 12997.43608995]
total_rewards_mean           11577.922242874713
total_rewards_std            3412.206174740384
total_rewards_max            12997.436089947996
total_rewards_min            1362.7030394260678
Number of train steps total  1484000
Number of env steps total    1857000
Number of rollouts total     0
Train Time (s)               119.12966459291056
(Previous) Eval Time (s)     22.841430693864822
Sample Time (s)              16.50455559697002
Epoch Time (s)               158.4756508837454
Total Train Time (s)         57302.282991081476
Epoch                        370
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:31:22.191727 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #370 | Epoch Duration: 158.55502486228943
2020-01-14 00:31:22.191951 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #370 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3569775
Z variance train             0.03043617
KL Divergence                61.070747
KL Loss                      6.1070747
QF Loss                      833.6449
VF Loss                      211.46783
Policy Loss                  -5159.4766
Q Predictions Mean           5161.203
Q Predictions Std            698.5257
Q Predictions Max            5886.564
Q Predictions Min            -725.7602
V Predictions Mean           5149.8467
V Predictions Std            699.28
V Predictions Max            5846.495
V Predictions Min            -857.0719
Log Pis Mean                 6.162408
Log Pis Std                  3.716228
Log Pis Max                  14.329565
Log Pis Min                  -2.0378156
Policy mu Mean               -0.14628248
Policy mu Std                1.4188323
Policy mu Max                3.2932515
Policy mu Min                -3.3411808
Policy log std Mean          -0.96384877
Policy log std Std           0.5117174
Policy log std Max           1.0920202
Policy log std Min           -3.4556088
Z mean eval                  3.374087
Z variance eval              0.013592658
total_rewards                [11816.40948329  6269.69295625 11899.39235501 12067.16512069
 11864.02558851 11876.0489555  12006.99181457 11762.71102497
 12040.29693605 12115.08318664]
total_rewards_mean           11371.781742149098
total_rewards_std            1704.2080676442768
total_rewards_max            12115.083186635846
total_rewards_min            6269.6929562489795
Number of train steps total  1488000
Number of env steps total    1862000
Number of rollouts total     0
Train Time (s)               113.04697959916666
(Previous) Eval Time (s)     22.92048007901758
Sample Time (s)              16.401389731559902
Epoch Time (s)               152.36884940974414
Total Train Time (s)         57454.21458794596
Epoch                        371
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:33:54.129563 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #371 | Epoch Duration: 151.937424659729
2020-01-14 00:33:54.129873 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #371 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3753104
Z variance train             0.0135704335
KL Divergence                63.730194
KL Loss                      6.3730197
QF Loss                      996.7892
VF Loss                      223.27039
Policy Loss                  -5106.9404
Q Predictions Mean           5111.551
Q Predictions Std            582.8237
Q Predictions Max            5843.5005
Q Predictions Min            3435.4805
V Predictions Mean           5096.9385
V Predictions Std            580.2351
V Predictions Max            5807.426
V Predictions Min            3422.7397
Log Pis Mean                 6.788961
Log Pis Std                  3.7610168
Log Pis Max                  15.864803
Log Pis Min                  -1.6106066
Policy mu Mean               -0.18002765
Policy mu Std                1.4895653
Policy mu Max                3.0052862
Policy mu Min                -3.2108352
Policy log std Mean          -0.920201
Policy log std Std           0.51011
Policy log std Max           -0.11067557
Policy log std Min           -3.2357082
Z mean eval                  3.3692925
Z variance eval              0.011701554
total_rewards                [12557.45133627 12822.97546409 12757.69636054 12590.34556543
 12512.99458545 12164.56485466 12606.62271842 12837.32078765
 12587.06730699 12716.00740721]
total_rewards_mean           12615.304638671736
total_rewards_std            184.74608917160805
total_rewards_max            12837.320787646462
total_rewards_min            12164.564854661045
Number of train steps total  1492000
Number of env steps total    1867000
Number of rollouts total     0
Train Time (s)               116.36678851488978
(Previous) Eval Time (s)     22.488720573019236
Sample Time (s)              16.11954049160704
Epoch Time (s)               154.97504957951605
Total Train Time (s)         57609.47866107477
Epoch                        372
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:36:29.400036 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #372 | Epoch Duration: 155.26986169815063
2020-01-14 00:36:29.400418 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #372 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.368164
Z variance train             0.011719262
KL Divergence                64.94787
KL Loss                      6.4947867
QF Loss                      755.484
VF Loss                      229.51706
Policy Loss                  -5185.8667
Q Predictions Mean           5193.127
Q Predictions Std            566.82556
Q Predictions Max            5846.0615
Q Predictions Min            3279.8157
V Predictions Mean           5190.854
V Predictions Std            562.16907
V Predictions Max            5840.751
V Predictions Min            3490.0872
Log Pis Mean                 6.023426
Log Pis Std                  4.0056996
Log Pis Max                  15.424384
Log Pis Min                  -7.560944
Policy mu Mean               -0.12116546
Policy mu Std                1.4394664
Policy mu Max                2.9667108
Policy mu Min                -3.0009334
Policy log std Mean          -0.9450303
Policy log std Std           0.5031733
Policy log std Max           -0.2355113
Policy log std Min           -3.653257
Z mean eval                  3.3715072
Z variance eval              0.011153268
total_rewards                [12006.49002178 12464.59211694 12143.25786299 12317.81685336
 12470.83021851 12627.90668416 12613.44079059 12529.122384
 12229.34875675  7511.42506915]
total_rewards_mean           11891.423075823139
total_rewards_std            1472.8089692818696
total_rewards_max            12627.90668415814
total_rewards_min            7511.425069154874
Number of train steps total  1496000
Number of env steps total    1872000
Number of rollouts total     0
Train Time (s)               120.53894369862974
(Previous) Eval Time (s)     22.78321692487225
Sample Time (s)              17.193629302550107
Epoch Time (s)               160.5157899260521
Total Train Time (s)         57770.416651736945
Epoch                        373
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:39:10.345305 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #373 | Epoch Duration: 160.94462418556213
2020-01-14 00:39:10.345635 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #373 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3727322
Z variance train             0.01115491
KL Divergence                64.24511
KL Loss                      6.424511
QF Loss                      658.2517
VF Loss                      362.73218
Policy Loss                  -5098.775
Q Predictions Mean           5103.1436
Q Predictions Std            665.10114
Q Predictions Max            5822.555
Q Predictions Min            -32.50297
V Predictions Mean           5092.671
V Predictions Std            662.22845
V Predictions Max            5818.535
V Predictions Min            18.711924
Log Pis Mean                 5.5466967
Log Pis Std                  3.8364904
Log Pis Max                  15.94109
Log Pis Min                  -4.508194
Policy mu Mean               -0.07309225
Policy mu Std                1.3890803
Policy mu Max                3.0249007
Policy mu Min                -2.971742
Policy log std Mean          -0.97845393
Policy log std Std           0.5073118
Policy log std Max           -0.084198
Policy log std Min           -3.303348
Z mean eval                  3.3610942
Z variance eval              0.017368888
total_rewards                [12606.03022942 12708.98398325 13014.42924259 12427.70086078
 12731.76007426 12864.9552449  12609.31248115 12822.88522189
 12734.08266991 12983.67193356]
total_rewards_mean           12750.381194170304
total_rewards_std            170.2105418431326
total_rewards_max            13014.429242587366
total_rewards_min            12427.700860775802
Number of train steps total  1500000
Number of env steps total    1877000
Number of rollouts total     0
Train Time (s)               114.07539077010006
(Previous) Eval Time (s)     23.211746267974377
Sample Time (s)              15.904054396320134
Epoch Time (s)               153.19119143439457
Total Train Time (s)         57923.2249048003
Epoch                        374
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:41:43.154507 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #374 | Epoch Duration: 152.8086018562317
2020-01-14 00:41:43.154749 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #374 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3625336
Z variance train             0.017404336
KL Divergence                62.16769
KL Loss                      6.216769
QF Loss                      871.7212
VF Loss                      480.04205
Policy Loss                  -5081.0483
Q Predictions Mean           5085.442
Q Predictions Std            572.204
Q Predictions Max            5726.5693
Q Predictions Min            3384.7742
V Predictions Mean           5062.065
V Predictions Std            567.9305
V Predictions Max            5704.8496
V Predictions Min            3373.5
Log Pis Mean                 6.3299108
Log Pis Std                  3.92075
Log Pis Max                  16.835976
Log Pis Min                  -3.795363
Policy mu Mean               -0.14488904
Policy mu Std                1.4490764
Policy mu Max                3.279447
Policy mu Min                -2.762819
Policy log std Mean          -0.97615767
Policy log std Std           0.5349873
Policy log std Max           -0.24591985
Policy log std Min           -3.7505908
Z mean eval                  3.394083
Z variance eval              0.017784085
total_rewards                [12614.77509507 12590.39510921 12794.33087866 12657.086401
 12605.6930739  12671.20220642 12604.46774966 12541.60909201
 12832.0574064  12687.87481701]
total_rewards_mean           12659.949182932543
total_rewards_std            86.8902221984505
total_rewards_max            12832.057406397054
total_rewards_min            12541.609092011438
Number of train steps total  1504000
Number of env steps total    1882000
Number of rollouts total     0
Train Time (s)               121.26531824236736
(Previous) Eval Time (s)     22.828893792349845
Sample Time (s)              15.92374282842502
Epoch Time (s)               160.01795486314222
Total Train Time (s)         58083.58866165858
Epoch                        375
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:44:23.523249 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #375 | Epoch Duration: 160.3683168888092
2020-01-14 00:44:23.523491 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #375 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3924232
Z variance train             0.01776946
KL Divergence                63.165375
KL Loss                      6.3165374
QF Loss                      660.2647
VF Loss                      401.72656
Policy Loss                  -5138.0703
Q Predictions Mean           5144.723
Q Predictions Std            719.56805
Q Predictions Max            5806.4473
Q Predictions Min            -674.0649
V Predictions Mean           5153.0547
V Predictions Std            715.7747
V Predictions Max            5810.8457
V Predictions Min            -558.7233
Log Pis Mean                 6.204213
Log Pis Std                  3.9328778
Log Pis Max                  19.383831
Log Pis Min                  -4.502493
Policy mu Mean               -0.10284785
Policy mu Std                1.4581063
Policy mu Max                4.3678637
Policy mu Min                -3.0043688
Policy log std Mean          -0.94651157
Policy log std Std           0.52660584
Policy log std Max           0.105958104
Policy log std Min           -3.4227147
Z mean eval                  3.3557887
Z variance eval              0.03391362
total_rewards                [12553.92366337 12361.74165139  9413.2401094  12642.20094241
 12463.12861605 12509.47398017 12706.23592033 12692.82417736
 12888.76121068 12837.18258002]
total_rewards_mean           12306.871285116966
total_rewards_std            976.899938695362
total_rewards_max            12888.76121068254
total_rewards_min            9413.24010939654
Number of train steps total  1508000
Number of env steps total    1887000
Number of rollouts total     0
Train Time (s)               116.74188095610589
(Previous) Eval Time (s)     23.178976934868842
Sample Time (s)              15.679951943922788
Epoch Time (s)               155.60080983489752
Total Train Time (s)         58239.40397075517
Epoch                        376
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:46:59.347322 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #376 | Epoch Duration: 155.82361721992493
2020-01-14 00:46:59.347624 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #376 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3550153
Z variance train             0.033822346
KL Divergence                60.42765
KL Loss                      6.042765
QF Loss                      793.77655
VF Loss                      139.06436
Policy Loss                  -5249.701
Q Predictions Mean           5261.8193
Q Predictions Std            565.2153
Q Predictions Max            5956.2295
Q Predictions Min            3562.8745
V Predictions Mean           5247.16
V Predictions Std            563.9278
V Predictions Max            5935.128
V Predictions Min            3556.1416
Log Pis Mean                 6.6467667
Log Pis Std                  4.0984635
Log Pis Max                  15.05642
Log Pis Min                  -4.5612464
Policy mu Mean               -0.12318131
Policy mu Std                1.4726939
Policy mu Max                3.130744
Policy mu Min                -3.2916288
Policy log std Mean          -0.952848
Policy log std Std           0.53468823
Policy log std Max           -0.021695793
Policy log std Min           -3.528041
Z mean eval                  3.3454857
Z variance eval              0.016298717
total_rewards                [12549.04302635 13012.97923502 12834.54859953 13005.01568105
 13041.20775861 12645.80592362 12950.28709751 12875.45672753
 12756.45375424 12833.20348119]
total_rewards_mean           12850.400128463381
total_rewards_std            154.7250900733108
total_rewards_max            13041.207758606244
total_rewards_min            12549.043026349214
Number of train steps total  1512000
Number of env steps total    1892000
Number of rollouts total     0
Train Time (s)               117.28529880009592
(Previous) Eval Time (s)     23.40147401019931
Sample Time (s)              16.131149565335363
Epoch Time (s)               156.8179223756306
Total Train Time (s)         58395.73115348909
Epoch                        377
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:49:35.677658 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #377 | Epoch Duration: 156.32971501350403
2020-01-14 00:49:35.678045 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #377 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3449512
Z variance train             0.016314916
KL Divergence                62.22174
KL Loss                      6.222174
QF Loss                      666.9307
VF Loss                      269.68753
Policy Loss                  -5150.028
Q Predictions Mean           5162.624
Q Predictions Std            571.55884
Q Predictions Max            5760.927
Q Predictions Min            3457.8394
V Predictions Mean           5154.525
V Predictions Std            571.5341
V Predictions Max            5751.6465
V Predictions Min            3467.869
Log Pis Mean                 6.1492887
Log Pis Std                  3.9789755
Log Pis Max                  16.522171
Log Pis Min                  -4.0665965
Policy mu Mean               -0.12470717
Policy mu Std                1.4499195
Policy mu Max                3.0464957
Policy mu Min                -2.9731119
Policy log std Mean          -0.95432013
Policy log std Std           0.5102629
Policy log std Max           -0.06884503
Policy log std Min           -3.2845006
Z mean eval                  3.3501916
Z variance eval              0.009785172
total_rewards                [12538.38627833 12415.84800629 12834.77430432 12351.24234694
 12269.56711596 12819.45542092 12518.03208692 12789.60327996
 13068.31694188 12762.58576922]
total_rewards_mean           12636.78115507353
total_rewards_std            242.27022584380532
total_rewards_max            13068.316941881943
total_rewards_min            12269.56711596189
Number of train steps total  1516000
Number of env steps total    1897000
Number of rollouts total     0
Train Time (s)               116.9427667572163
(Previous) Eval Time (s)     22.912951522041112
Sample Time (s)              17.216818570625037
Epoch Time (s)               157.07253684988245
Total Train Time (s)         58552.67189756315
Epoch                        378
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:52:12.621457 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #378 | Epoch Duration: 156.94315385818481
2020-01-14 00:52:12.621656 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #378 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3483436
Z variance train             0.00976537
KL Divergence                62.949524
KL Loss                      6.2949524
QF Loss                      530.92395
VF Loss                      109.467865
Policy Loss                  -5092.6763
Q Predictions Mean           5100.0107
Q Predictions Std            647.7553
Q Predictions Max            5826.257
Q Predictions Min            -111.32151
V Predictions Mean           5094.129
V Predictions Std            650.1294
V Predictions Max            5798.3423
V Predictions Min            -191.13997
Log Pis Mean                 6.021244
Log Pis Std                  3.577552
Log Pis Max                  17.227865
Log Pis Min                  -3.8023977
Policy mu Mean               -0.06810706
Policy mu Std                1.4227349
Policy mu Max                3.0475476
Policy mu Min                -3.0399015
Policy log std Mean          -0.9573598
Policy log std Std           0.5185604
Policy log std Max           0.4264903
Policy log std Min           -3.4597588
Z mean eval                  3.4586723
Z variance eval              0.011549028
total_rewards                [12155.06865781 12452.96038147 12710.82530694 12228.82152129
 12231.81485158 12459.60203022 12610.05443534 12206.70510214
 12270.46637692 11906.60074119]
total_rewards_mean           12323.29194049021
total_rewards_std            224.36924055266454
total_rewards_max            12710.825306936496
total_rewards_min            11906.600741189659
Number of train steps total  1520000
Number of env steps total    1902000
Number of rollouts total     0
Train Time (s)               117.57411451498047
(Previous) Eval Time (s)     22.783277094829828
Sample Time (s)              15.91265317844227
Epoch Time (s)               156.27004478825256
Total Train Time (s)         58708.97960917838
Epoch                        379
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:54:48.932122 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #379 | Epoch Duration: 156.310307264328
2020-01-14 00:54:48.932317 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #379 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.4588819
Z variance train             0.011536425
KL Divergence                63.881897
KL Loss                      6.38819
QF Loss                      702.27875
VF Loss                      170.44319
Policy Loss                  -5117.2993
Q Predictions Mean           5127.323
Q Predictions Std            709.01556
Q Predictions Max            5879.827
Q Predictions Min            -87.882355
V Predictions Mean           5118.923
V Predictions Std            704.88525
V Predictions Max            5865.7056
V Predictions Min            2.266849
Log Pis Mean                 5.705124
Log Pis Std                  3.5973475
Log Pis Max                  16.74097
Log Pis Min                  -4.587821
Policy mu Mean               -0.098496854
Policy mu Std                1.408216
Policy mu Max                3.1181462
Policy mu Min                -2.93396
Policy log std Mean          -0.934192
Policy log std Std           0.49110496
Policy log std Max           0.04861498
Policy log std Min           -3.1558735
Z mean eval                  3.4223106
Z variance eval              0.020410974
total_rewards                [12442.31647527 12494.2961873  12717.53490057 12468.26759507
 12754.22852556 12796.53744186 12594.36118328 12621.35984836
 12335.78434423 12560.28062887]
total_rewards_mean           12578.496713035122
total_rewards_std            140.31049161324032
total_rewards_max            12796.537441855118
total_rewards_min            12335.784344228046
Number of train steps total  1524000
Number of env steps total    1907000
Number of rollouts total     0
Train Time (s)               115.93828824814409
(Previous) Eval Time (s)     22.823220467194915
Sample Time (s)              16.39048366388306
Epoch Time (s)               155.15199237922207
Total Train Time (s)         58864.2294293968
Epoch                        380
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:57:24.185231 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #380 | Epoch Duration: 155.25276374816895
2020-01-14 00:57:24.185437 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #380 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.4237797
Z variance train             0.020248938
KL Divergence                63.177547
KL Loss                      6.3177547
QF Loss                      804.52686
VF Loss                      124.53421
Policy Loss                  -5184.7104
Q Predictions Mean           5197.0137
Q Predictions Std            591.5836
Q Predictions Max            5861.087
Q Predictions Min            3467.2349
V Predictions Mean           5178.586
V Predictions Std            588.52856
V Predictions Max            5836.372
V Predictions Min            3473.3025
Log Pis Mean                 6.2763205
Log Pis Std                  3.7101903
Log Pis Max                  17.251884
Log Pis Min                  -3.6258457
Policy mu Mean               -0.06507104
Policy mu Std                1.435016
Policy mu Max                2.677562
Policy mu Min                -2.970446
Policy log std Mean          -0.9557168
Policy log std Std           0.5112424
Policy log std Max           -0.012836099
Policy log std Min           -3.4698253
Z mean eval                  3.350516
Z variance eval              0.023346294
total_rewards                [12408.72632631 11782.26434741 12737.69692809 11625.73021767
 12779.91820579 12412.02651303 12613.69089392 12540.89589479
 12628.60689157 12688.24881071]
total_rewards_mean           12421.780502930325
total_rewards_std            378.9206925471816
total_rewards_max            12779.9182057896
total_rewards_min            11625.730217673612
Number of train steps total  1528000
Number of env steps total    1912000
Number of rollouts total     0
Train Time (s)               115.27843313477933
(Previous) Eval Time (s)     22.923686707857996
Sample Time (s)              15.678715565707535
Epoch Time (s)               153.88083540834486
Total Train Time (s)         59018.10967256315
Epoch                        381
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:59:58.069767 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #381 | Epoch Duration: 153.884122133255
2020-01-14 00:59:58.070094 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #381 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3486533
Z variance train             0.023559982
KL Divergence                60.31507
KL Loss                      6.031507
QF Loss                      506.5277
VF Loss                      1690.6917
Policy Loss                  -5145.128
Q Predictions Mean           5158.0396
Q Predictions Std            590.23944
Q Predictions Max            5790.7485
Q Predictions Min            3441.3042
V Predictions Mean           5184.224
V Predictions Std            592.4596
V Predictions Max            5802.7954
V Predictions Min            3477.6804
Log Pis Mean                 6.0070186
Log Pis Std                  3.8397033
Log Pis Max                  15.625685
Log Pis Min                  -4.987193
Policy mu Mean               -0.12462153
Policy mu Std                1.4363369
Policy mu Max                2.7856026
Policy mu Min                -3.2863762
Policy log std Mean          -0.91961175
Policy log std Std           0.47275406
Policy log std Max           -0.25994658
Policy log std Min           -3.2335649
Z mean eval                  3.4140391
Z variance eval              0.021864401
total_rewards                [12443.81250726 12669.42101842 12678.0171833  12776.1699272
 12765.82148264 12425.92179345 12593.87691053 12498.82594998
 12649.82141347 12646.73568538]
total_rewards_mean           12614.842387163599
total_rewards_std            116.99292051679251
total_rewards_max            12776.169927199264
total_rewards_min            12425.92179345127
Number of train steps total  1532000
Number of env steps total    1917000
Number of rollouts total     0
Train Time (s)               122.22354722395539
(Previous) Eval Time (s)     22.92667292105034
Sample Time (s)              15.879500608891249
Epoch Time (s)               161.02972075389698
Total Train Time (s)         59178.70426405966
Epoch                        382
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:02:38.667536 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #382 | Epoch Duration: 160.59725308418274
2020-01-14 01:02:38.667694 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #382 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.4155338
Z variance train             0.021816421
KL Divergence                61.824455
KL Loss                      6.1824455
QF Loss                      355.19174
VF Loss                      127.36801
Policy Loss                  -5233.0293
Q Predictions Mean           5235.0225
Q Predictions Std            556.9684
Q Predictions Max            5881.925
Q Predictions Min            3534.2598
V Predictions Mean           5226.5405
V Predictions Std            555.82294
V Predictions Max            5871.604
V Predictions Min            3542.6072
Log Pis Mean                 5.774198
Log Pis Std                  3.5353074
Log Pis Max                  17.394722
Log Pis Min                  -2.9420023
Policy mu Mean               -0.11011171
Policy mu Std                1.4212486
Policy mu Max                3.0560408
Policy mu Min                -3.2515402
Policy log std Mean          -0.9249074
Policy log std Std           0.47615385
Policy log std Max           -0.05721438
Policy log std Min           -3.2528262
Z mean eval                  3.406564
Z variance eval              0.018174415
total_rewards                [12673.87768652  1204.90744298 12614.75942604 12938.90897925
 12854.60757082 12958.20634741 12875.82153219 12753.91051147
 12381.7645058  12436.4527868 ]
total_rewards_mean           11569.321678928969
total_rewards_std            3459.9561934315416
total_rewards_max            12958.206347413965
total_rewards_min            1204.9074429825578
Number of train steps total  1536000
Number of env steps total    1922000
Number of rollouts total     0
Train Time (s)               117.68800303479657
(Previous) Eval Time (s)     22.4939559889026
Sample Time (s)              15.835064100567251
Epoch Time (s)               156.01702312426642
Total Train Time (s)         59334.86585590476
Epoch                        383
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:05:14.830774 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #383 | Epoch Duration: 156.16295981407166
2020-01-14 01:05:14.830959 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #383 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.405828
Z variance train             0.018219544
KL Divergence                63.377953
KL Loss                      6.3377953
QF Loss                      609.73035
VF Loss                      118.20018
Policy Loss                  -5160.048
Q Predictions Mean           5164.0234
Q Predictions Std            601.1414
Q Predictions Max            5843.802
Q Predictions Min            3521.891
V Predictions Mean           5163.2007
V Predictions Std            599.9786
V Predictions Max            5832.4863
V Predictions Min            3507.5352
Log Pis Mean                 6.039526
Log Pis Std                  3.5890334
Log Pis Max                  14.940043
Log Pis Min                  -5.8660316
Policy mu Mean               -0.07391354
Policy mu Std                1.4147532
Policy mu Max                3.2985125
Policy mu Min                -2.7650867
Policy log std Mean          -0.95458394
Policy log std Std           0.5020399
Policy log std Max           -0.096789
Policy log std Min           -3.43743
Z mean eval                  3.380352
Z variance eval              0.02791256
total_rewards                [12123.77320154 12127.82758847 12414.34839664 12444.88843382
 12313.39376619 12571.31449809  9386.78522924 12529.74942104
 12462.39109212 12350.98018971]
total_rewards_mean           12072.54518168728
total_rewards_std            906.6298245454427
total_rewards_max            12571.314498087893
total_rewards_min            9386.785229239935
Number of train steps total  1540000
Number of env steps total    1927000
Number of rollouts total     0
Train Time (s)               120.27349308086559
(Previous) Eval Time (s)     22.63957666186616
Sample Time (s)              15.766153200529516
Epoch Time (s)               158.67922294326127
Total Train Time (s)         59493.82563378243
Epoch                        384
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:07:53.796092 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #384 | Epoch Duration: 158.9649977684021
2020-01-14 01:07:53.796342 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #384 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3824189
Z variance train             0.027943378
KL Divergence                62.23462
KL Loss                      6.223462
QF Loss                      927.4341
VF Loss                      871.04297
Policy Loss                  -5140.5767
Q Predictions Mean           5143.755
Q Predictions Std            561.2983
Q Predictions Max            5843.2666
Q Predictions Min            3499.4316
V Predictions Mean           5135.0996
V Predictions Std            557.86523
V Predictions Max            5858.37
V Predictions Min            3511.9043
Log Pis Mean                 5.933649
Log Pis Std                  3.5840447
Log Pis Max                  20.999329
Log Pis Min                  -3.161162
Policy mu Mean               -0.122826464
Policy mu Std                1.4146525
Policy mu Max                3.6709845
Policy mu Min                -3.2397316
Policy log std Mean          -0.96058244
Policy log std Std           0.51870924
Policy log std Max           0.027855873
Policy log std Min           -3.6267219
Z mean eval                  3.367189
Z variance eval              0.028343156
total_rewards                [12518.24763655 12909.81502812 12627.04483756 12685.45927121
 12132.20640832 12592.21918534 12843.3239089  12576.42055986
 12764.005419   12647.67106969]
total_rewards_mean           12629.641332455682
total_rewards_std            202.42075818139125
total_rewards_max            12909.815028115334
total_rewards_min            12132.206408324044
Number of train steps total  1544000
Number of env steps total    1932000
Number of rollouts total     0
Train Time (s)               123.70685951318592
(Previous) Eval Time (s)     22.92504345672205
Sample Time (s)              16.355983486864716
Epoch Time (s)               162.98788645677269
Total Train Time (s)         59656.46122528333
Epoch                        385
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:10:36.436890 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #385 | Epoch Duration: 162.64041686058044
2020-01-14 01:10:36.437057 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #385 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.367199
Z variance train             0.028321385
KL Divergence                62.17801
KL Loss                      6.217801
QF Loss                      779.9889
VF Loss                      132.7537
Policy Loss                  -5055.4146
Q Predictions Mean           5063.333
Q Predictions Std            704.8192
Q Predictions Max            5803.697
Q Predictions Min            61.733807
V Predictions Mean           5059.028
V Predictions Std            707.64087
V Predictions Max            5805.765
V Predictions Min            -21.359755
Log Pis Mean                 6.0905104
Log Pis Std                  4.023085
Log Pis Max                  18.558437
Log Pis Min                  -3.1087728
Policy mu Mean               -0.1224551
Policy mu Std                1.4370809
Policy mu Max                2.9543364
Policy mu Min                -3.998907
Policy log std Mean          -0.9639247
Policy log std Std           0.5225992
Policy log std Max           0.2529298
Policy log std Min           -3.2204475
Z mean eval                  3.4350057
Z variance eval              0.031022709
total_rewards                [12876.85989917 12669.33251275 12965.24108144 12850.0831257
 12879.13098797 12877.10446042 12817.24428082 12788.48228263
 12590.81033391 12839.81986252]
total_rewards_mean           12815.410882733046
total_rewards_std            104.1163722435198
total_rewards_max            12965.241081440105
total_rewards_min            12590.810333908632
Number of train steps total  1548000
Number of env steps total    1937000
Number of rollouts total     0
Train Time (s)               116.04464971413836
(Previous) Eval Time (s)     22.57727820193395
Sample Time (s)              16.561122949700803
Epoch Time (s)               155.1830508657731
Total Train Time (s)         59811.95796098467
Epoch                        386
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:13:11.940247 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #386 | Epoch Duration: 155.50301718711853
2020-01-14 01:13:11.940541 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #386 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.4370093
Z variance train             0.030972054
KL Divergence                64.0714
KL Loss                      6.4071403
QF Loss                      519.77203
VF Loss                      279.56482
Policy Loss                  -5274.234
Q Predictions Mean           5280.392
Q Predictions Std            551.23645
Q Predictions Max            5898.7705
Q Predictions Min            3519.3052
V Predictions Mean           5261.1885
V Predictions Std            548.5312
V Predictions Max            5869.4316
V Predictions Min            3515.122
Log Pis Mean                 6.6618924
Log Pis Std                  4.133652
Log Pis Max                  18.107231
Log Pis Min                  -3.3134263
Policy mu Mean               -0.14633372
Policy mu Std                1.4907663
Policy mu Max                3.112858
Policy mu Min                -3.0324779
Policy log std Mean          -0.970335
Policy log std Std           0.56870186
Policy log std Max           -0.21599543
Policy log std Min           -3.4408054
Z mean eval                  3.4381187
Z variance eval              0.022233624
total_rewards                [12370.9853942  12659.24229019 12431.32667055 12913.78807002
 12837.50304332  9941.37494437 12096.86933991 12519.77911082
 12488.88742936 12661.31872515]
total_rewards_mean           12292.107501790084
total_rewards_std            814.5716544678589
total_rewards_max            12913.788070023704
total_rewards_min            9941.374944372381
Number of train steps total  1552000
Number of env steps total    1942000
Number of rollouts total     0
Train Time (s)               121.14545387681574
(Previous) Eval Time (s)     22.896950867958367
Sample Time (s)              16.725700264330953
Epoch Time (s)               160.76810500910506
Total Train Time (s)         59973.12028040178
Epoch                        387
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:15:53.108340 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #387 | Epoch Duration: 161.16755533218384
2020-01-14 01:15:53.108600 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #387 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.4379704
Z variance train             0.022278477
KL Divergence                63.757225
KL Loss                      6.3757224
QF Loss                      1136.6163
VF Loss                      183.99591
Policy Loss                  -5218.5728
Q Predictions Mean           5225.789
Q Predictions Std            560.0964
Q Predictions Max            5894.6143
Q Predictions Min            3525.5164
V Predictions Mean           5227.4736
V Predictions Std            558.5763
V Predictions Max            5903.904
V Predictions Min            3524.856
Log Pis Mean                 5.9879036
Log Pis Std                  3.9357486
Log Pis Max                  16.391508
Log Pis Min                  -2.8645222
Policy mu Mean               -0.06618064
Policy mu Std                1.4400901
Policy mu Max                2.9582977
Policy mu Min                -2.583993
Policy log std Mean          -0.9378584
Policy log std Std           0.52778757
Policy log std Max           -0.04734409
Policy log std Min           -3.3319185
Z mean eval                  3.3829167
Z variance eval              0.025219629
total_rewards                [12630.43442612 12732.696608   12996.87483748 12560.70656324
 12774.3245351  12815.26094727 12739.56217503 12716.87150102
 12959.86421498 12734.49621351]
total_rewards_mean           12766.109202174503
total_rewards_std            126.14275106788722
total_rewards_max            12996.874837475145
total_rewards_min            12560.706563238073
Number of train steps total  1556000
Number of env steps total    1947000
Number of rollouts total     0
Train Time (s)               115.35668242909014
(Previous) Eval Time (s)     23.29605984687805
Sample Time (s)              16.940955356694758
Epoch Time (s)               155.59369763266295
Total Train Time (s)         60128.63898343453
Epoch                        388
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:18:28.632359 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #388 | Epoch Duration: 155.52355122566223
2020-01-14 01:18:28.632593 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #388 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.3836513
Z variance train             0.025147911
KL Divergence                62.49972
KL Loss                      6.2499723
QF Loss                      765.12726
VF Loss                      333.1775
Policy Loss                  -5198.6084
Q Predictions Mean           5202.755
Q Predictions Std            615.0482
Q Predictions Max            5927.941
Q Predictions Min            3616.9888
V Predictions Mean           5192.1943
V Predictions Std            612.97986
V Predictions Max            5911.369
V Predictions Min            3611.7712
Log Pis Mean                 5.869688
Log Pis Std                  3.767585
Log Pis Max                  15.591307
Log Pis Min                  -3.4001565
Policy mu Mean               -0.07787961
Policy mu Std                1.4279159
Policy mu Max                3.2337582
Policy mu Min                -3.0780745
Policy log std Mean          -0.94907624
Policy log std Std           0.50933665
Policy log std Max           -0.25093377
Policy log std Min           -3.4341602
Z mean eval                  3.448401
Z variance eval              0.03609759
total_rewards                [11821.0175245  12438.2815117   4019.79613961 12103.91003823
 12436.26921931 12372.90631423 12259.56767068 12360.48959401
 12355.92932822 12109.07174261]
total_rewards_mean           11427.723908311511
total_rewards_std            2476.0629538442213
total_rewards_max            12438.281511704654
total_rewards_min            4019.7961396085875
Number of train steps total  1560000
Number of env steps total    1952000
Number of rollouts total     0
Train Time (s)               119.86148268170655
(Previous) Eval Time (s)     23.225583352148533
Sample Time (s)              16.39644659170881
Epoch Time (s)               159.4835126255639
Total Train Time (s)         60287.55886392761
Epoch                        389
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:21:07.553900 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #389 | Epoch Duration: 158.92113614082336
2020-01-14 01:21:07.554096 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #389 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.4476025
Z variance train             0.03618466
KL Divergence                63.14334
KL Loss                      6.3143344
QF Loss                      509.48328
VF Loss                      361.5677
Policy Loss                  -5216.6855
Q Predictions Mean           5222.867
Q Predictions Std            641.1416
Q Predictions Max            5978.4404
Q Predictions Min            3536.9539
V Predictions Mean           5217.8896
V Predictions Std            639.85223
V Predictions Max            5965.983
V Predictions Min            3544.2725
Log Pis Mean                 5.9575987
Log Pis Std                  3.60214
Log Pis Max                  13.550606
Log Pis Min                  -6.559025
Policy mu Mean               -0.10472535
Policy mu Std                1.4571773
Policy mu Max                3.2251499
Policy mu Min                -3.262738
Policy log std Mean          -0.9559407
Policy log std Std           0.5325339
Policy log std Max           -0.13177502
Policy log std Min           -3.618246
Z mean eval                  3.4156876
Z variance eval              0.018391496
total_rewards                [12648.28088358 12352.70656286 10934.29505294 13014.28480131
 12633.83296719  2344.30993314 12795.38092827 12472.43349216
 12435.57147511  7331.12456793]
total_rewards_mean           10896.222066449936
total_rewards_std            3271.145867785201
total_rewards_max            13014.284801311273
total_rewards_min            2344.3099331357885
Number of train steps total  1564000
Number of env steps total    1957000
Number of rollouts total     0
Train Time (s)               114.84162363503128
(Previous) Eval Time (s)     22.6629187008366
Sample Time (s)              16.11805292777717
Epoch Time (s)               153.62259526364505
Total Train Time (s)         60443.166117416695
Epoch                        390
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:23:43.168613 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #390 | Epoch Duration: 155.61435651779175
2020-01-14 01:23:43.168922 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #390 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.4153543
Z variance train             0.018399458
KL Divergence                63.664635
KL Loss                      6.3664637
QF Loss                      875.33777
VF Loss                      115.00916
Policy Loss                  -5155.656
Q Predictions Mean           5164.949
Q Predictions Std            614.3643
Q Predictions Max            5865.3516
Q Predictions Min            2880.5488
V Predictions Mean           5160.08
V Predictions Std            615.09717
V Predictions Max            5865.2754
V Predictions Min            2784.7559
Log Pis Mean                 5.5938826
Log Pis Std                  3.7555864
Log Pis Max                  21.162987
Log Pis Min                  -5.7741065
Policy mu Mean               -0.052685488
Policy mu Std                1.4143133
Policy mu Max                5.1994333
Policy mu Min                -2.815313
Policy log std Mean          -0.9515156
Policy log std Std           0.51672393
Policy log std Max           -0.23362249
Policy log std Min           -3.482514
Z mean eval                  3.4469619
Z variance eval              0.04332452
total_rewards                [12061.40774514  7715.96775614 12721.63580896 12874.2280908
 12855.19282141 12937.40799928 12593.74202957 12790.84409372
 12685.78574547 12285.92799312]
total_rewards_mean           12152.214008361996
total_rewards_std            1501.670887137563
total_rewards_max            12937.407999282708
total_rewards_min            7715.967756143894
Number of train steps total  1568000
Number of env steps total    1962000
Number of rollouts total     0
Train Time (s)               120.30606621969491
(Previous) Eval Time (s)     24.654317868407816
Sample Time (s)              16.938427702058107
Epoch Time (s)               161.89881179016083
Total Train Time (s)         60603.53381462209
Epoch                        391
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:26:23.541878 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #391 | Epoch Duration: 160.3727011680603
2020-01-14 01:26:23.542188 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #391 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.4481578
Z variance train             0.043104786
KL Divergence                63.479202
KL Loss                      6.3479204
QF Loss                      749.2095
VF Loss                      339.5222
Policy Loss                  -5195.672
Q Predictions Mean           5197.8936
Q Predictions Std            639.6018
Q Predictions Max            5827.1084
Q Predictions Min            0.6164031
V Predictions Mean           5180.831
V Predictions Std            637.8876
V Predictions Max            5816.85
V Predictions Min            -62.055298
Log Pis Mean                 6.321539
Log Pis Std                  4.0432496
Log Pis Max                  19.7739
Log Pis Min                  -3.8406203
Policy mu Mean               -0.0138605675
Policy mu Std                1.4543258
Policy mu Max                3.0517044
Policy mu Min                -4.6325116
Policy log std Mean          -0.9506605
Policy log std Std           0.52230686
Policy log std Max           -0.0023514032
Policy log std Min           -3.4662132
Z mean eval                  3.4569657
Z variance eval              0.069666594
total_rewards                [11959.70324554 12556.54242772 12248.35980802 12649.34223717
 12255.98517688 12471.08512447 12645.17341715 12510.75060908
 12233.78901354 11626.53336389]
total_rewards_mean           12315.72644234655
total_rewards_std            309.2828046989441
total_rewards_max            12649.342237172785
total_rewards_min            11626.533363885608
Number of train steps total  1572000
Number of env steps total    1967000
Number of rollouts total     0
Train Time (s)               118.53888072026893
(Previous) Eval Time (s)     23.12790933297947
Sample Time (s)              16.388529133051634
Epoch Time (s)               158.05531918630004
Total Train Time (s)         60761.05314788036
Epoch                        392
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:29:01.063023 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #392 | Epoch Duration: 157.52061414718628
2020-01-14 01:29:01.063266 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #392 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.455792
Z variance train             0.069605306
KL Divergence                61.128998
KL Loss                      6.1129
QF Loss                      817.0149
VF Loss                      98.86404
Policy Loss                  -5161.53
Q Predictions Mean           5166.624
Q Predictions Std            657.61804
Q Predictions Max            5812.0913
Q Predictions Min            -256.21948
V Predictions Mean           5164.2734
V Predictions Std            653.2608
V Predictions Max            5826.1978
V Predictions Min            -93.57221
Log Pis Mean                 6.7195754
Log Pis Std                  3.7549953
Log Pis Max                  17.863525
Log Pis Min                  -6.2559423
Policy mu Mean               -0.037960503
Policy mu Std                1.4770837
Policy mu Max                3.6096268
Policy mu Min                -3.3817806
Policy log std Mean          -0.9685809
Policy log std Std           0.5244612
Policy log std Max           -0.17998213
Policy log std Min           -3.266792
Z mean eval                  3.4463272
Z variance eval              0.04060035
total_rewards                [12324.12329871 12717.94827259 12740.50229761 12796.98213522
 12640.92089192 12699.63050082 12890.91905258 12810.9975678
 12686.91491984 12702.35456135]
total_rewards_mean           12701.12934984371
total_rewards_std            143.20490107999163
total_rewards_max            12890.919052577632
total_rewards_min            12324.123298708806
Number of train steps total  1576000
Number of env steps total    1972000
Number of rollouts total     0
Train Time (s)               121.74116045469418
(Previous) Eval Time (s)     22.592930897139013
Sample Time (s)              15.929744535591453
Epoch Time (s)               160.26383588742465
Total Train Time (s)         60921.464686068706
Epoch                        393
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:31:41.483139 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #393 | Epoch Duration: 160.41970038414001
2020-01-14 01:31:41.483450 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #393 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.4452453
Z variance train             0.040594615
KL Divergence                62.42249
KL Loss                      6.242249
QF Loss                      2317.8982
VF Loss                      203.4832
Policy Loss                  -5141.5063
Q Predictions Mean           5152.6035
Q Predictions Std            617.94324
Q Predictions Max            5876.7837
Q Predictions Min            3488.8472
V Predictions Mean           5152.075
V Predictions Std            618.50366
V Predictions Max            5870.464
V Predictions Min            3486.3933
Log Pis Mean                 6.131962
Log Pis Std                  3.8058
Log Pis Max                  18.58938
Log Pis Min                  -4.6443677
Policy mu Mean               -0.056768462
Policy mu Std                1.4257582
Policy mu Max                3.4616287
Policy mu Min                -3.1884036
Policy log std Mean          -0.9645898
Policy log std Std           0.53804904
Policy log std Max           -0.18611544
Policy log std Min           -3.4590654
Z mean eval                  3.451821
Z variance eval              0.036527846
total_rewards                [11689.05449223 12525.58975353 12926.0000255  12578.77826129
  6902.36980437  5575.46291313 12319.97145333 12081.54742999
 12731.84305822 12408.38179889]
total_rewards_mean           11173.899899048774
total_rewards_std            2506.249993807025
total_rewards_max            12926.000025502375
total_rewards_min            5575.4629131342945
Number of train steps total  1580000
Number of env steps total    1977000
Number of rollouts total     0
Train Time (s)               116.53396120201796
(Previous) Eval Time (s)     22.748492621351033
Sample Time (s)              16.088073308113962
Epoch Time (s)               155.37052713148296
Total Train Time (s)         61077.19338573236
Epoch                        394
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:34:17.213565 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #394 | Epoch Duration: 155.72987937927246
2020-01-14 01:34:17.213768 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #394 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.4521756
Z variance train             0.03642364
KL Divergence                62.876938
KL Loss                      6.287694
QF Loss                      554.40137
VF Loss                      145.96725
Policy Loss                  -5220.0444
Q Predictions Mean           5224.203
Q Predictions Std            562.6356
Q Predictions Max            5893.4663
Q Predictions Min            3551.11
V Predictions Mean           5217.1235
V Predictions Std            563.3478
V Predictions Max            5892.717
V Predictions Min            3547.7214
Log Pis Mean                 6.459633
Log Pis Std                  3.9213967
Log Pis Max                  16.24953
Log Pis Min                  -2.8008795
Policy mu Mean               -0.111857675
Policy mu Std                1.4704454
Policy mu Max                3.0368385
Policy mu Min                -3.2242231
Policy log std Mean          -0.95249504
Policy log std Std           0.5310324
Policy log std Max           -0.19053662
Policy log std Min           -3.4422524
Z mean eval                  3.4054809
Z variance eval              0.015157978
total_rewards                [12667.79667444 12453.83438683 12872.73893261 12946.54726109
 12761.41448176 12573.52328791 12837.87705977 12695.51359037
 12315.08897831 12818.39138298]
total_rewards_mean           12694.272603608568
total_rewards_std            187.85689934521966
total_rewards_max            12946.547261093814
total_rewards_min            12315.088978314307
Number of train steps total  1584000
Number of env steps total    1982000
Number of rollouts total     0
Train Time (s)               117.63642960926518
(Previous) Eval Time (s)     23.107583336997777
Sample Time (s)              15.579076625406742
Epoch Time (s)               156.3230895716697
Total Train Time (s)         61233.07922192896
Epoch                        395
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:36:53.101778 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #395 | Epoch Duration: 155.88786721229553
2020-01-14 01:36:53.101966 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #395 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.4057438
Z variance train             0.015132077
KL Divergence                64.800476
KL Loss                      6.4800477
QF Loss                      912.4866
VF Loss                      205.44644
Policy Loss                  -5179.268
Q Predictions Mean           5186.231
Q Predictions Std            628.1676
Q Predictions Max            5834.694
Q Predictions Min            3445.4084
V Predictions Mean           5188.0977
V Predictions Std            628.9947
V Predictions Max            5837.3213
V Predictions Min            3456.5154
Log Pis Mean                 6.2368307
Log Pis Std                  3.9047177
Log Pis Max                  17.411
Log Pis Min                  -5.2924595
Policy mu Mean               -0.08385166
Policy mu Std                1.4429536
Policy mu Max                3.4280498
Policy mu Min                -2.979483
Policy log std Mean          -0.9458897
Policy log std Std           0.49995184
Policy log std Max           -0.115249395
Policy log std Min           -3.507795
Z mean eval                  3.5033913
Z variance eval              0.014755899
total_rewards                [12485.38575901 12826.44995417 12918.57926195 12777.52608822
 12711.53023758 12645.19562736 12882.62514421 12810.59748502
 12822.61338253 12776.24398138]
total_rewards_mean           12765.67469214233
total_rewards_std            119.27774246387659
total_rewards_max            12918.579261949046
total_rewards_min            12485.385759013283
Number of train steps total  1588000
Number of env steps total    1987000
Number of rollouts total     0
Train Time (s)               123.25168534507975
(Previous) Eval Time (s)     22.672077865339816
Sample Time (s)              15.9029600629583
Epoch Time (s)               161.82672327337787
Total Train Time (s)         61395.20729493257
Epoch                        396
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:39:35.237136 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #396 | Epoch Duration: 162.13499689102173
2020-01-14 01:39:35.237438 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #396 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5015283
Z variance train             0.014718813
KL Divergence                66.28429
KL Loss                      6.628429
QF Loss                      659.2964
VF Loss                      165.78738
Policy Loss                  -5183.339
Q Predictions Mean           5189.877
Q Predictions Std            580.0714
Q Predictions Max            5900.3687
Q Predictions Min            3501.3835
V Predictions Mean           5188.34
V Predictions Std            578.1228
V Predictions Max            5886.0864
V Predictions Min            3522.4817
Log Pis Mean                 5.9106445
Log Pis Std                  4.122408
Log Pis Max                  17.547573
Log Pis Min                  -8.31325
Policy mu Mean               -0.11772173
Policy mu Std                1.3996011
Policy mu Max                3.2906923
Policy mu Min                -3.4942064
Policy log std Mean          -0.9557085
Policy log std Std           0.48995364
Policy log std Max           -0.1672231
Policy log std Min           -3.319437
Z mean eval                  3.4558167
Z variance eval              0.011788504
total_rewards                [12534.6203207  12793.82037564 12539.67018732 12719.3971465
 12542.29597247 12873.23719697 12674.86656006 12497.97075922
 12712.76592461 12688.8660446 ]
total_rewards_mean           12657.751048806767
total_rewards_std            118.74383563463023
total_rewards_max            12873.237196968073
total_rewards_min            12497.970759215108
Number of train steps total  1592000
Number of env steps total    1992000
Number of rollouts total     0
Train Time (s)               112.87867369363084
(Previous) Eval Time (s)     22.980065647047013
Sample Time (s)              17.620580984279513
Epoch Time (s)               153.47932032495737
Total Train Time (s)         61548.42990575265
Epoch                        397
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:42:08.465154 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #397 | Epoch Duration: 153.22748398780823
2020-01-14 01:42:08.465434 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #397 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.454682
Z variance train             0.011844727
KL Divergence                67.60269
KL Loss                      6.760269
QF Loss                      5094.9434
VF Loss                      163.15591
Policy Loss                  -5161.6797
Q Predictions Mean           5163.625
Q Predictions Std            614.6586
Q Predictions Max            5830.972
Q Predictions Min            3467.0378
V Predictions Mean           5168.074
V Predictions Std            613.8051
V Predictions Max            5833.8438
V Predictions Min            3470.307
Log Pis Mean                 6.0556684
Log Pis Std                  3.793742
Log Pis Max                  16.933155
Log Pis Min                  -3.1084795
Policy mu Mean               -0.101198204
Policy mu Std                1.4410884
Policy mu Max                3.2496045
Policy mu Min                -4.0439367
Policy log std Mean          -0.9601614
Policy log std Std           0.5359385
Policy log std Max           0.08377147
Policy log std Min           -3.3612235
Z mean eval                  3.4408226
Z variance eval              0.01247387
total_rewards                [12506.62453279 12214.68000205 10473.9382131   2643.50469943
 12630.19220026  8302.32072986 12975.89764364 12705.48381826
 12507.07213569  7156.8160402 ]
total_rewards_mean           10411.653001527195
total_rewards_std            3227.7046608092346
total_rewards_max            12975.897643644332
total_rewards_min            2643.504699426833
Number of train steps total  1596000
Number of env steps total    1997000
Number of rollouts total     0
Train Time (s)               109.84875729400665
(Previous) Eval Time (s)     22.727933295536786
Sample Time (s)              16.83546676672995
Epoch Time (s)               149.41215735627338
Total Train Time (s)         61697.933850692585
Epoch                        398
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:44:37.974941 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #398 | Epoch Duration: 149.50928664207458
2020-01-14 01:44:37.975212 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #398 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.4393601
Z variance train             0.012479074
KL Divergence                67.44423
KL Loss                      6.744423
QF Loss                      795.619
VF Loss                      339.23816
Policy Loss                  -5146.9556
Q Predictions Mean           5155.208
Q Predictions Std            647.3729
Q Predictions Max            5822.214
Q Predictions Min            1642.2369
V Predictions Mean           5156.251
V Predictions Std            643.7421
V Predictions Max            5826.251
V Predictions Min            1834.561
Log Pis Mean                 5.919714
Log Pis Std                  3.6247897
Log Pis Max                  16.058908
Log Pis Min                  -2.8009448
Policy mu Mean               -0.07116432
Policy mu Std                1.4547418
Policy mu Max                3.3833177
Policy mu Min                -3.3903568
Policy log std Mean          -0.9407439
Policy log std Std           0.50290066
Policy log std Max           -0.07172418
Policy log std Min           -3.302782
Z mean eval                  3.4627786
Z variance eval              0.016337218
total_rewards                [12747.01247604 12936.08029773 12982.83366485 12972.34508837
 12900.24498619 12787.37899214 12818.28602948 12931.2669211
 13031.02989265 13115.98640788]
total_rewards_mean           12922.246475642718
total_rewards_std            107.70814609350913
total_rewards_max            13115.986407878067
total_rewards_min            12747.012476038057
Number of train steps total  1600000
Number of env steps total    2002000
Number of rollouts total     0
Train Time (s)               116.59002503566444
(Previous) Eval Time (s)     22.824716889765114
Sample Time (s)              16.786262267734855
Epoch Time (s)               156.2010041931644
Total Train Time (s)         61853.680939763784
Epoch                        399
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:47:13.724854 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #399 | Epoch Duration: 155.74943256378174
2020-01-14 01:47:13.725074 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #399 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.4649258
Z variance train             0.016255075
KL Divergence                67.5289
KL Loss                      6.75289
QF Loss                      594.80945
VF Loss                      357.80414
Policy Loss                  -5250.565
Q Predictions Mean           5255.0117
Q Predictions Std            590.5555
Q Predictions Max            5953.175
Q Predictions Min            3576.1135
V Predictions Mean           5236.3535
V Predictions Std            590.80756
V Predictions Max            5925.373
V Predictions Min            3548.9607
Log Pis Mean                 6.2773294
Log Pis Std                  3.5942552
Log Pis Max                  16.705427
Log Pis Min                  -1.8043294
Policy mu Mean               -0.022533635
Policy mu Std                1.4556259
Policy mu Max                3.3796873
Policy mu Min                -3.2846303
Policy log std Mean          -0.95036316
Policy log std Std           0.5139959
Policy log std Max           -0.11854303
Policy log std Min           -3.4128695
Z mean eval                  3.433038
Z variance eval              0.03337645
total_rewards                [12609.20918159 12968.62402374 12823.97116245 12910.54214287
 12972.61248308 12774.01314194 13038.55969484 12938.27903027
 13026.40842849 12940.44946832]
total_rewards_mean           12900.266875759573
total_rewards_std            124.33179399273924
total_rewards_max            13038.559694844489
total_rewards_min            12609.209181585718
Number of train steps total  1604000
Number of env steps total    2007000
Number of rollouts total     0
Train Time (s)               112.9228083039634
(Previous) Eval Time (s)     22.372814916074276
Sample Time (s)              16.46481757191941
Epoch Time (s)               151.76044079195708
Total Train Time (s)         62006.391051261686
Epoch                        400
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:49:46.437783 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #400 | Epoch Duration: 152.71254563331604
2020-01-14 01:49:46.437964 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #400 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.433328
Z variance train             0.03332883
KL Divergence                64.48304
KL Loss                      6.448304
QF Loss                      431.9629
VF Loss                      113.87317
Policy Loss                  -5211.054
Q Predictions Mean           5215.8794
Q Predictions Std            596.88855
Q Predictions Max            5839.4565
Q Predictions Min            3481.6914
V Predictions Mean           5212.078
V Predictions Std            594.77496
V Predictions Max            5839.312
V Predictions Min            3491.773
Log Pis Mean                 6.7240305
Log Pis Std                  3.7669933
Log Pis Max                  19.124445
Log Pis Min                  -5.981971
Policy mu Mean               -0.08080518
Policy mu Std                1.4667807
Policy mu Max                3.1111128
Policy mu Min                -3.083704
Policy log std Mean          -0.9924045
Policy log std Std           0.5635425
Policy log std Max           -0.014667869
Policy log std Min           -3.5426779
Z mean eval                  3.4413104
Z variance eval              0.039553225
total_rewards                [12560.23388955 12923.62192987 12702.27820825 12997.07827305
 12843.00757397 13036.96292733 12971.12526271 12803.4524798
 12963.31183206 12918.29711684]
total_rewards_mean           12871.936949344305
total_rewards_std            140.4891933903321
total_rewards_max            13036.962927334165
total_rewards_min            12560.233889553676
Number of train steps total  1608000
Number of env steps total    2012000
Number of rollouts total     0
Train Time (s)               120.95217797718942
(Previous) Eval Time (s)     23.324579934123904
Sample Time (s)              17.14130148012191
Epoch Time (s)               161.41805939143524
Total Train Time (s)         62167.21022655396
Epoch                        401
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:52:27.264660 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #401 | Epoch Duration: 160.8265266418457
2020-01-14 01:52:27.264933 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #401 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.4405682
Z variance train             0.039514963
KL Divergence                62.577538
KL Loss                      6.257754
QF Loss                      550.66956
VF Loss                      214.4519
Policy Loss                  -5237.8203
Q Predictions Mean           5244.101
Q Predictions Std            567.7608
Q Predictions Max            5894.7446
Q Predictions Min            3503.3035
V Predictions Mean           5240.0615
V Predictions Std            566.55646
V Predictions Max            5882.7744
V Predictions Min            3495.7805
Log Pis Mean                 5.7999525
Log Pis Std                  3.6766012
Log Pis Max                  17.465439
Log Pis Min                  -4.5279865
Policy mu Mean               0.010388183
Policy mu Std                1.4160655
Policy mu Max                3.1645799
Policy mu Min                -3.2193987
Policy log std Mean          -0.97401553
Policy log std Std           0.5305937
Policy log std Max           -0.09333408
Policy log std Min           -3.3392906
Z mean eval                  3.4210124
Z variance eval              0.038301084
total_rewards                [12673.96602458 13004.99581934 12289.17812888 13094.96008366
 13184.10240433 13056.93137698 12878.25413071 12847.50708389
 12672.91481476 13242.34685451]
total_rewards_mean           12894.515672165822
total_rewards_std            273.90994259313914
total_rewards_max            13242.346854513331
total_rewards_min            12289.178128884467
Number of train steps total  1612000
Number of env steps total    2017000
Number of rollouts total     0
Train Time (s)               120.40201681433246
(Previous) Eval Time (s)     22.732716429047287
Sample Time (s)              15.910944927949458
Epoch Time (s)               159.0456781713292
Total Train Time (s)         62326.44013962848
Epoch                        402
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:55:06.496728 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #402 | Epoch Duration: 159.23160123825073
2020-01-14 01:55:06.496915 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #402 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.4216106
Z variance train             0.038267523
KL Divergence                62.900696
KL Loss                      6.2900696
QF Loss                      558.171
VF Loss                      221.59229
Policy Loss                  -5190.2485
Q Predictions Mean           5194.3276
Q Predictions Std            693.3682
Q Predictions Max            5877.1777
Q Predictions Min            196.57149
V Predictions Mean           5191.4263
V Predictions Std            692.85876
V Predictions Max            5888.4746
V Predictions Min            136.73553
Log Pis Mean                 6.3056498
Log Pis Std                  3.777494
Log Pis Max                  15.157822
Log Pis Min                  -3.4666867
Policy mu Mean               -0.05874778
Policy mu Std                1.4197328
Policy mu Max                3.282316
Policy mu Min                -2.7743645
Policy log std Mean          -0.96790415
Policy log std Std           0.5142063
Policy log std Max           0.19400549
Policy log std Min           -3.2607327
Z mean eval                  3.417108
Z variance eval              0.032840062
total_rewards                [12463.34632075 12160.43886484 12462.6613182  12489.04534827
 12505.69148496 12616.8911878  12633.17760198 12456.11617381
 12730.85646195 12476.63098324]
total_rewards_mean           12499.485574578775
total_rewards_std            143.3023431612354
total_rewards_max            12730.856461953043
total_rewards_min            12160.438864840891
Number of train steps total  1616000
Number of env steps total    2022000
Number of rollouts total     0
Train Time (s)               119.44934106618166
(Previous) Eval Time (s)     22.918339987751096
Sample Time (s)              16.704399950336665
Epoch Time (s)               159.07208100426942
Total Train Time (s)         62485.82689576037
Epoch                        403
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:57:45.888279 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #403 | Epoch Duration: 159.39122104644775
2020-01-14 01:57:45.888526 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #403 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.41897
Z variance train             0.033080827
KL Divergence                62.35958
KL Loss                      6.235958
QF Loss                      857.59985
VF Loss                      209.00255
Policy Loss                  -5283.2554
Q Predictions Mean           5284.9746
Q Predictions Std            517.96484
Q Predictions Max            5965.333
Q Predictions Min            3619.4275
V Predictions Mean           5281.3477
V Predictions Std            516.11646
V Predictions Max            5908.7197
V Predictions Min            3616.7847
Log Pis Mean                 6.4568815
Log Pis Std                  3.636883
Log Pis Max                  18.238028
Log Pis Min                  -2.5582037
Policy mu Mean               -0.17670976
Policy mu Std                1.467685
Policy mu Max                3.0126815
Policy mu Min                -4.188782
Policy log std Mean          -0.9686036
Policy log std Std           0.513306
Policy log std Max           -0.040642977
Policy log std Min           -3.3347025
Z mean eval                  3.449929
Z variance eval              0.026113257
total_rewards                [12562.14000991 12856.40839263 12980.35223765 12585.96271617
 12442.89249085 12794.71361543 12754.03239999 12582.965642
 12780.70436905 12930.50008972]
total_rewards_mean           12727.067196341126
total_rewards_std            167.056720363511
total_rewards_max            12980.352237654797
total_rewards_min            12442.89249085409
Number of train steps total  1620000
Number of env steps total    2027000
Number of rollouts total     0
Train Time (s)               119.34219124726951
(Previous) Eval Time (s)     23.237184322904795
Sample Time (s)              16.033247645013034
Epoch Time (s)               158.61262321518734
Total Train Time (s)         62644.64398023719
Epoch                        404
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:00:24.710905 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #404 | Epoch Duration: 158.82218384742737
2020-01-14 02:00:24.711175 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #404 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.448975
Z variance train             0.026201
KL Divergence                63.865616
KL Loss                      6.386562
QF Loss                      685.79877
VF Loss                      112.8371
Policy Loss                  -5253.351
Q Predictions Mean           5262.3965
Q Predictions Std            594.438
Q Predictions Max            5927.6265
Q Predictions Min            3565.2295
V Predictions Mean           5256.9653
V Predictions Std            594.13165
V Predictions Max            5924.218
V Predictions Min            3577.5415
Log Pis Mean                 6.7073116
Log Pis Std                  3.5614002
Log Pis Max                  15.764931
Log Pis Min                  -4.515524
Policy mu Mean               -0.040658128
Policy mu Std                1.4786762
Policy mu Max                3.426127
Policy mu Min                -3.1573372
Policy log std Mean          -0.9664615
Policy log std Std           0.5210803
Policy log std Max           -0.2362181
Policy log std Min           -3.2373388
Z mean eval                  3.4681637
Z variance eval              0.020069232
total_rewards                [12959.49099282 12917.39909756 13004.61481085 12868.35436207
 12914.16948415 12937.62181619 13096.42439432 12927.11305427
 12767.88005719 10499.39993693]
total_rewards_mean           12689.246800634854
total_rewards_std            734.3628993397164
total_rewards_max            13096.424394315953
total_rewards_min            10499.399936931066
Number of train steps total  1624000
Number of env steps total    2032000
Number of rollouts total     0
Train Time (s)               116.85883870115504
(Previous) Eval Time (s)     23.446447726804763
Sample Time (s)              15.620514379348606
Epoch Time (s)               155.9258008073084
Total Train Time (s)         62800.5708117201
Epoch                        405
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:03:00.639925 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #405 | Epoch Duration: 155.9285671710968
2020-01-14 02:03:00.640176 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #405 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.469275
Z variance train             0.020035453
KL Divergence                65.33327
KL Loss                      6.5333266
QF Loss                      1043.5184
VF Loss                      192.62285
Policy Loss                  -5205.9893
Q Predictions Mean           5209.6514
Q Predictions Std            590.8739
Q Predictions Max            5964.498
Q Predictions Min            3579.2427
V Predictions Mean           5200.6777
V Predictions Std            589.85516
V Predictions Max            5956.1743
V Predictions Min            3579.0676
Log Pis Mean                 6.209054
Log Pis Std                  3.7183056
Log Pis Max                  16.05717
Log Pis Min                  -7.664164
Policy mu Mean               0.0153862685
Policy mu Std                1.449921
Policy mu Max                3.1494367
Policy mu Min                -3.3989449
Policy log std Mean          -0.9659044
Policy log std Std           0.49015647
Policy log std Max           0.15975285
Policy log std Min           -4.006524
Z mean eval                  3.4415448
Z variance eval              0.020504307
total_rewards                [12862.4763942  12836.89379901 12850.38340121 13239.49986589
 12969.97688443 12901.56390807 12871.11876186 12730.99427419
 12547.14750416 12640.59471504]
total_rewards_mean           12845.064950807782
total_rewards_std            178.61300071327253
total_rewards_max            13239.49986589428
total_rewards_min            12547.147504157416
Number of train steps total  1628000
Number of env steps total    2037000
Number of rollouts total     0
Train Time (s)               117.21881186636165
(Previous) Eval Time (s)     23.44895563693717
Sample Time (s)              16.430081002879888
Epoch Time (s)               157.0978485061787
Total Train Time (s)         62957.79818196455
Epoch                        406
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:05:37.872612 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #406 | Epoch Duration: 157.23227453231812
2020-01-14 02:05:37.872838 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #406 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.4411197
Z variance train             0.020571154
KL Divergence                63.671936
KL Loss                      6.3671937
QF Loss                      922.00696
VF Loss                      325.83307
Policy Loss                  -5283.6543
Q Predictions Mean           5284.7065
Q Predictions Std            609.92505
Q Predictions Max            5925.2354
Q Predictions Min            3564.8813
V Predictions Mean           5295.896
V Predictions Std            611.8278
V Predictions Max            5954.5396
V Predictions Min            3581.0972
Log Pis Mean                 6.239916
Log Pis Std                  3.6784048
Log Pis Max                  15.150554
Log Pis Min                  -8.14712
Policy mu Mean               -0.047975596
Policy mu Std                1.4394002
Policy mu Max                2.939336
Policy mu Min                -3.001147
Policy log std Mean          -0.9723789
Policy log std Std           0.5468414
Policy log std Max           0.018268704
Policy log std Min           -3.6037097
Z mean eval                  3.5271459
Z variance eval              0.016393742
total_rewards                [12136.0067953  12985.1051837  13107.38413521 12435.73402179
 12675.92072943 12566.95687986 12521.52364186 12586.20461996
 12737.55100766 12665.31829185]
total_rewards_mean           12641.770530661819
total_rewards_std            258.2559412034918
total_rewards_max            13107.384135208096
total_rewards_min            12136.006795297193
Number of train steps total  1632000
Number of env steps total    2042000
Number of rollouts total     0
Train Time (s)               117.9932504738681
(Previous) Eval Time (s)     23.583061390090734
Sample Time (s)              15.654505596496165
Epoch Time (s)               157.230817460455
Total Train Time (s)         63114.264747961424
Epoch                        407
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:08:14.351115 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #407 | Epoch Duration: 156.4780716896057
2020-01-14 02:08:14.351451 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #407 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5272622
Z variance train             0.016363088
KL Divergence                65.842545
KL Loss                      6.5842547
QF Loss                      2081.645
VF Loss                      326.8061
Policy Loss                  -5239.271
Q Predictions Mean           5253.9688
Q Predictions Std            623.7321
Q Predictions Max            5920.5396
Q Predictions Min            2542.0417
V Predictions Mean           5235.5386
V Predictions Std            626.41614
V Predictions Max            5910.2495
V Predictions Min            2176.343
Log Pis Mean                 6.278633
Log Pis Std                  3.9500043
Log Pis Max                  24.706055
Log Pis Min                  -3.4446476
Policy mu Mean               -0.021452973
Policy mu Std                1.4670734
Policy mu Max                4.278753
Policy mu Min                -4.864303
Policy log std Mean          -0.942983
Policy log std Std           0.5086067
Policy log std Max           0.04299462
Policy log std Min           -4.0153275
Z mean eval                  3.4901671
Z variance eval              0.026386593
total_rewards                [12656.2885491  12742.48555654 13018.07619998 12676.46159088
 12975.12880914 12986.58573104 11449.56508941 13113.94543077
 12859.56973478 13033.77061863]
total_rewards_mean           12751.187731027032
total_rewards_std            459.22448272413635
total_rewards_max            13113.945430771386
total_rewards_min            11449.565089409441
Number of train steps total  1636000
Number of env steps total    2047000
Number of rollouts total     0
Train Time (s)               119.6858563576825
(Previous) Eval Time (s)     22.829997824970633
Sample Time (s)              16.23641371447593
Epoch Time (s)               158.75226789712906
Total Train Time (s)         63272.52925486723
Epoch                        408
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:10:52.612151 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #408 | Epoch Duration: 158.26047801971436
2020-01-14 02:10:52.612334 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #408 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.4902065
Z variance train             0.026531672
KL Divergence                65.33902
KL Loss                      6.533902
QF Loss                      2051.126
VF Loss                      127.54607
Policy Loss                  -5214.45
Q Predictions Mean           5222.72
Q Predictions Std            576.88666
Q Predictions Max            5869.9717
Q Predictions Min            3457.6792
V Predictions Mean           5209.521
V Predictions Std            573.3313
V Predictions Max            5856.7256
V Predictions Min            3453.2903
Log Pis Mean                 5.9511423
Log Pis Std                  3.5463417
Log Pis Max                  15.450953
Log Pis Min                  -3.939074
Policy mu Mean               -0.10161243
Policy mu Std                1.4028181
Policy mu Max                3.2080898
Policy mu Min                -2.775022
Policy log std Mean          -0.9894404
Policy log std Std           0.5282755
Policy log std Max           -0.30245066
Policy log std Min           -3.5309997
Z mean eval                  3.4820893
Z variance eval              0.014153561
total_rewards                [12400.43923584 12580.46881736 12385.82544876 13027.02665265
  6074.75682515  8778.0484904  12631.25346216 12509.98153597
 12565.4576835  12839.13013462]
total_rewards_mean           11579.238828639312
total_rewards_std            2170.3101876201695
total_rewards_max            13027.026652645862
total_rewards_min            6074.756825150893
Number of train steps total  1640000
Number of env steps total    2052000
Number of rollouts total     0
Train Time (s)               115.66599238524213
(Previous) Eval Time (s)     22.3379401457496
Sample Time (s)              15.994398353621364
Epoch Time (s)               153.9983308846131
Total Train Time (s)         63426.68370604748
Epoch                        409
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:13:26.782282 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #409 | Epoch Duration: 154.1697814464569
2020-01-14 02:13:26.782574 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #409 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.4825325
Z variance train             0.014124264
KL Divergence                68.11005
KL Loss                      6.8110046
QF Loss                      698.8507
VF Loss                      234.93576
Policy Loss                  -5192.6323
Q Predictions Mean           5198.7495
Q Predictions Std            656.16547
Q Predictions Max            5865.002
Q Predictions Min            445.3852
V Predictions Mean           5182.3
V Predictions Std            651.0044
V Predictions Max            5852.8984
V Predictions Min            511.3415
Log Pis Mean                 6.0826454
Log Pis Std                  3.5013518
Log Pis Max                  16.756207
Log Pis Min                  -2.9793453
Policy mu Mean               -0.035883408
Policy mu Std                1.4326895
Policy mu Max                3.3065264
Policy mu Min                -2.9100478
Policy log std Mean          -0.9666078
Policy log std Std           0.52060974
Policy log std Max           -0.16772759
Policy log std Min           -3.6655693
Z mean eval                  3.5065084
Z variance eval              0.010847935
total_rewards                [12679.10662505 12898.64893016 12902.28096887 12817.22485895
 13096.21513967 13067.40120889 12878.25686007 12921.77485205
 12940.04994625 12873.67658111]
total_rewards_mean           12907.463597105023
total_rewards_std            111.74209463438754
total_rewards_max            13096.215139674854
total_rewards_min            12679.106625045624
Number of train steps total  1644000
Number of env steps total    2057000
Number of rollouts total     0
Train Time (s)               114.81707855081186
(Previous) Eval Time (s)     22.509067056234926
Sample Time (s)              16.750842411071062
Epoch Time (s)               154.07698801811785
Total Train Time (s)         63581.4469587137
Epoch                        410
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:16:01.543843 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #410 | Epoch Duration: 154.7610204219818
2020-01-14 02:16:01.544128 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #410 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5087852
Z variance train             0.01087229
KL Divergence                69.88308
KL Loss                      6.988308
QF Loss                      1666.6161
VF Loss                      328.7046
Policy Loss                  -5244.3657
Q Predictions Mean           5248.5596
Q Predictions Std            594.5708
Q Predictions Max            5953.274
Q Predictions Min            3581.7021
V Predictions Mean           5232.5854
V Predictions Std            592.58325
V Predictions Max            5922.442
V Predictions Min            3584.6343
Log Pis Mean                 6.3013053
Log Pis Std                  3.7660298
Log Pis Max                  21.733345
Log Pis Min                  -5.7228756
Policy mu Mean               0.0012365704
Policy mu Std                1.4445295
Policy mu Max                3.995942
Policy mu Min                -3.386517
Policy log std Mean          -0.9552679
Policy log std Std           0.5102732
Policy log std Max           -0.05532956
Policy log std Min           -3.380251
Z mean eval                  3.4856372
Z variance eval              0.0048737163
total_rewards                [12329.14174744  3512.25044747 12695.58272112 12375.11254335
 13036.77300022  2941.87147266  7010.76614249 12545.99278011
 11777.3905101  12320.33826366]
total_rewards_mean           10054.521962861803
total_rewards_std            3786.730099036701
total_rewards_max            13036.773000223724
total_rewards_min            2941.8714726604294
Number of train steps total  1648000
Number of env steps total    2062000
Number of rollouts total     0
Train Time (s)               116.30232325801626
(Previous) Eval Time (s)     23.19280628208071
Sample Time (s)              16.809379982296377
Epoch Time (s)               156.30450952239335
Total Train Time (s)         63737.65189571772
Epoch                        411
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:18:37.754318 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #411 | Epoch Duration: 156.2099847793579
2020-01-14 02:18:37.754558 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #411 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.4856045
Z variance train             0.0048783747
KL Divergence                70.121704
KL Loss                      7.0121703
QF Loss                      884.4547
VF Loss                      210.81311
Policy Loss                  -5178.853
Q Predictions Mean           5188.494
Q Predictions Std            696.2372
Q Predictions Max            5935.823
Q Predictions Min            832.02496
V Predictions Mean           5182.3696
V Predictions Std            691.58826
V Predictions Max            5926.7417
V Predictions Min            877.5394
Log Pis Mean                 6.0722556
Log Pis Std                  3.856407
Log Pis Max                  19.633814
Log Pis Min                  -3.3624778
Policy mu Mean               -0.03464246
Policy mu Std                1.428869
Policy mu Max                5.1553416
Policy mu Min                -2.6308348
Policy log std Mean          -0.97581387
Policy log std Std           0.55923676
Policy log std Max           0.07336211
Policy log std Min           -3.7762473
Z mean eval                  3.5610778
Z variance eval              0.011125959
total_rewards                [12700.33497166 12498.12597411 12885.27088394 12258.61187205
 12764.69155609 12821.33510096 12875.51754565 12682.04813755
 12526.77571016 12788.25967365]
total_rewards_mean           12680.097142581284
total_rewards_std            188.08856532665106
total_rewards_max            12885.270883938985
total_rewards_min            12258.611872051593
Number of train steps total  1652000
Number of env steps total    2067000
Number of rollouts total     0
Train Time (s)               118.29362654406577
(Previous) Eval Time (s)     23.097958466038108
Sample Time (s)              16.2831501099281
Epoch Time (s)               157.67473512003198
Total Train Time (s)         63894.65463097999
Epoch                        412
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:21:14.762657 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #412 | Epoch Duration: 157.00789284706116
2020-01-14 02:21:14.762955 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #412 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.562449
Z variance train             0.011123498
KL Divergence                72.644196
KL Loss                      7.2644196
QF Loss                      8823.4375
VF Loss                      175.55768
Policy Loss                  -5286.3213
Q Predictions Mean           5292.843
Q Predictions Std            629.5161
Q Predictions Max            6016.48
Q Predictions Min            840.1977
V Predictions Mean           5279.632
V Predictions Std            617.4637
V Predictions Max            6003.5947
V Predictions Min            1223.7285
Log Pis Mean                 6.28964
Log Pis Std                  3.9182465
Log Pis Max                  28.006832
Log Pis Min                  -5.3125887
Policy mu Mean               -0.1590256
Policy mu Std                1.4342586
Policy mu Max                5.3341827
Policy mu Min                -2.8583086
Policy log std Mean          -0.9796092
Policy log std Std           0.5198398
Policy log std Max           -0.14366114
Policy log std Min           -3.2616782
Z mean eval                  3.496891
Z variance eval              0.0076231374
total_rewards                [12315.03472537 12696.3657847  13026.93276936 12707.32074479
 12800.30607056 12665.94458008 12793.15700454 12436.73978894
 12628.99332442 12819.10557495]
total_rewards_mean           12688.990036771796
total_rewards_std            190.36051005264872
total_rewards_max            13026.932769359702
total_rewards_min            12315.034725369616
Number of train steps total  1656000
Number of env steps total    2072000
Number of rollouts total     0
Train Time (s)               120.61319647403434
(Previous) Eval Time (s)     22.43080394109711
Sample Time (s)              16.01301470445469
Epoch Time (s)               159.05701511958614
Total Train Time (s)         64054.00647126231
Epoch                        413
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:23:54.121161 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #413 | Epoch Duration: 159.3579604625702
2020-01-14 02:23:54.121424 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #413 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.4978547
Z variance train             0.00763346
KL Divergence                69.93505
KL Loss                      6.993505
QF Loss                      647.63226
VF Loss                      259.06763
Policy Loss                  -5314.685
Q Predictions Mean           5321.4736
Q Predictions Std            536.062
Q Predictions Max            5925.962
Q Predictions Min            3579.7598
V Predictions Mean           5307.366
V Predictions Std            535.16455
V Predictions Max            5902.7812
V Predictions Min            3576.7493
Log Pis Mean                 6.186469
Log Pis Std                  3.5859683
Log Pis Max                  14.953148
Log Pis Min                  -7.0742803
Policy mu Mean               0.010359173
Policy mu Std                1.4249592
Policy mu Max                3.146487
Policy mu Min                -3.087428
Policy log std Mean          -0.9902486
Policy log std Std           0.5101717
Policy log std Max           -0.34620205
Policy log std Min           -3.4186776
Z mean eval                  3.5036225
Z variance eval              0.02604692
total_rewards                [11452.1057818  11104.46953779 11654.03289725 11475.44466993
 11530.14079017 11330.55113081 11379.95684677 11511.93250483
 11363.23730727 11444.47638961]
total_rewards_mean           11424.634785622762
total_rewards_std            138.64673822527647
total_rewards_max            11654.032897251036
total_rewards_min            11104.469537792529
Number of train steps total  1660000
Number of env steps total    2077000
Number of rollouts total     0
Train Time (s)               119.4359370879829
(Previous) Eval Time (s)     22.731444669421762
Sample Time (s)              17.239763718564063
Epoch Time (s)               159.40714547596872
Total Train Time (s)         64213.62407928193
Epoch                        414
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:26:33.741132 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #414 | Epoch Duration: 159.6195194721222
2020-01-14 02:26:33.741342 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #414 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5044627
Z variance train             0.025859699
KL Divergence                67.126656
KL Loss                      6.7126656
QF Loss                      1519.1864
VF Loss                      288.1031
Policy Loss                  -5316.072
Q Predictions Mean           5321.3843
Q Predictions Std            631.4077
Q Predictions Max            5971.394
Q Predictions Min            174.59604
V Predictions Mean           5311.1216
V Predictions Std            629.2399
V Predictions Max            5961.0005
V Predictions Min            182.284
Log Pis Mean                 6.418828
Log Pis Std                  3.8563156
Log Pis Max                  18.44984
Log Pis Min                  -2.89178
Policy mu Mean               -0.053103436
Policy mu Std                1.439429
Policy mu Max                2.946896
Policy mu Min                -3.2020748
Policy log std Mean          -0.9903762
Policy log std Std           0.5117421
Policy log std Max           -0.29222155
Policy log std Min           -3.362913
Z mean eval                  3.5303051
Z variance eval              0.01342004
total_rewards                [12744.56107311 12761.19362642 12919.05192292 12363.41918881
 12860.47508914 12931.90595595 12869.64492203 12733.16786798
 12853.63232775 12776.68404599]
total_rewards_mean           12781.373602008527
total_rewards_std            154.81588233274186
total_rewards_max            12931.905955945525
total_rewards_min            12363.419188805003
Number of train steps total  1664000
Number of env steps total    2082000
Number of rollouts total     0
Train Time (s)               119.63290050067008
(Previous) Eval Time (s)     22.943502518814057
Sample Time (s)              16.970706194639206
Epoch Time (s)               159.54710921412334
Total Train Time (s)         64373.60446903808
Epoch                        415
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:29:13.725950 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #415 | Epoch Duration: 159.98444986343384
2020-01-14 02:29:13.726175 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #415 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.530019
Z variance train             0.01341414
KL Divergence                68.13043
KL Loss                      6.813043
QF Loss                      586.5499
VF Loss                      91.89994
Policy Loss                  -5260.8164
Q Predictions Mean           5267.3735
Q Predictions Std            610.20874
Q Predictions Max            5981.073
Q Predictions Min            3494.9856
V Predictions Mean           5259.3125
V Predictions Std            608.70636
V Predictions Max            5966.566
V Predictions Min            3490.3171
Log Pis Mean                 5.5270586
Log Pis Std                  3.3863783
Log Pis Max                  15.281506
Log Pis Min                  -4.282876
Policy mu Mean               -0.070537
Policy mu Std                1.38625
Policy mu Max                3.0410242
Policy mu Min                -2.6262608
Policy log std Mean          -0.9606338
Policy log std Std           0.49154422
Policy log std Max           -0.26736856
Policy log std Min           -3.2561965
Z mean eval                  3.516082
Z variance eval              0.022577617
total_rewards                [12262.61165629 12858.93834582 12273.57916944 12634.42909844
 12484.51021357 12254.37299572 12421.11652389 12700.68684365
 12739.40811731 12536.82458389]
total_rewards_mean           12516.6477548015
total_rewards_std            204.32785585741823
total_rewards_max            12858.938345816081
total_rewards_min            12254.372995724647
Number of train steps total  1668000
Number of env steps total    2087000
Number of rollouts total     0
Train Time (s)               119.96445099636912
(Previous) Eval Time (s)     23.38054415024817
Sample Time (s)              17.28789425222203
Epoch Time (s)               160.63288939883932
Total Train Time (s)         64534.38010101253
Epoch                        416
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:31:54.504677 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #416 | Epoch Duration: 160.77829718589783
2020-01-14 02:31:54.504862 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #416 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5157065
Z variance train             0.022615861
KL Divergence                66.701805
KL Loss                      6.670181
QF Loss                      1281.3977
VF Loss                      565.4017
Policy Loss                  -5354.4106
Q Predictions Mean           5359.6504
Q Predictions Std            561.21063
Q Predictions Max            5974.801
Q Predictions Min            2644.1584
V Predictions Mean           5351.3086
V Predictions Std            565.53357
V Predictions Max            5972.4316
V Predictions Min            2447.1746
Log Pis Mean                 6.885803
Log Pis Std                  4.0163903
Log Pis Max                  19.402666
Log Pis Min                  -6.517997
Policy mu Mean               -0.10633255
Policy mu Std                1.4869305
Policy mu Max                4.3988857
Policy mu Min                -3.325292
Policy log std Mean          -0.9809081
Policy log std Std           0.5223115
Policy log std Max           -0.23910224
Policy log std Min           -3.3168168
Z mean eval                  3.5235543
Z variance eval              0.01171211
total_rewards                [12640.7263921  12653.29300715  9722.76479934 13146.47490291
 12536.44753498 12686.9943978  13115.29500556 13015.69514208
 12350.31298286 13000.94017622]
total_rewards_mean           12486.894434100246
total_rewards_std            955.33880268006
total_rewards_max            13146.474902908285
total_rewards_min            9722.764799341685
Number of train steps total  1672000
Number of env steps total    2092000
Number of rollouts total     0
Train Time (s)               115.38473068503663
(Previous) Eval Time (s)     23.525673147756606
Sample Time (s)              16.771303568035364
Epoch Time (s)               155.6817074008286
Total Train Time (s)         64688.981168921106
Epoch                        417
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:34:29.115504 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #417 | Epoch Duration: 154.6104621887207
2020-01-14 02:34:29.115817 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #417 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5225549
Z variance train             0.011690666
KL Divergence                69.5353
KL Loss                      6.9535303
QF Loss                      919.2403
VF Loss                      285.0372
Policy Loss                  -5267.034
Q Predictions Mean           5277.4424
Q Predictions Std            618.4234
Q Predictions Max            5968.9116
Q Predictions Min            3581.3152
V Predictions Mean           5278.034
V Predictions Std            620.8287
V Predictions Max            5968.454
V Predictions Min            3577.3818
Log Pis Mean                 6.234125
Log Pis Std                  3.9068096
Log Pis Max                  18.314451
Log Pis Min                  -4.771748
Policy mu Mean               -0.022630379
Policy mu Std                1.4368652
Policy mu Max                3.3078797
Policy mu Min                -3.9948978
Policy log std Mean          -0.9710303
Policy log std Std           0.5246363
Policy log std Max           -0.33305338
Policy log std Min           -3.544324
Z mean eval                  3.549614
Z variance eval              0.055845547
total_rewards                [12080.89431102  2614.8734679   4008.13044599 12549.32163333
  3876.85856608 12315.36591978  8764.75599292 11887.39670208
 11807.12976478  6412.29995299]
total_rewards_mean           8631.70267568652
total_rewards_std            3829.2109492483987
total_rewards_max            12549.321633328173
total_rewards_min            2614.8734678975256
Number of train steps total  1676000
Number of env steps total    2097000
Number of rollouts total     0
Train Time (s)               121.62298687687144
(Previous) Eval Time (s)     22.454097746871412
Sample Time (s)              16.146098311524838
Epoch Time (s)               160.2231829352677
Total Train Time (s)         64849.70208653668
Epoch                        418
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:37:09.837635 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #418 | Epoch Duration: 160.72159576416016
2020-01-14 02:37:09.837840 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #418 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5489304
Z variance train             0.056519527
KL Divergence                67.71939
KL Loss                      6.7719393
QF Loss                      769.58264
VF Loss                      463.34863
Policy Loss                  -5223.3413
Q Predictions Mean           5230.4395
Q Predictions Std            591.9155
Q Predictions Max            5867.905
Q Predictions Min            3527.0718
V Predictions Mean           5242.077
V Predictions Std            591.2195
V Predictions Max            5883.8
V Predictions Min            3550.9111
Log Pis Mean                 5.7863903
Log Pis Std                  3.6173527
Log Pis Max                  16.861113
Log Pis Min                  -2.5711021
Policy mu Mean               -0.09125271
Policy mu Std                1.4037199
Policy mu Max                2.787407
Policy mu Min                -3.2608507
Policy log std Mean          -0.98707515
Policy log std Std           0.524443
Policy log std Max           -0.13569999
Policy log std Min           -3.4314265
Z mean eval                  3.552327
Z variance eval              0.010395137
total_rewards                [12733.42227513 12786.51419112 12924.00655589 13149.3644542
 12883.6740338  12946.88991046 13011.84126161 13057.94582814
  7385.35644222 12863.785903  ]
total_rewards_mean           12374.28008555734
total_rewards_std            1667.096200344582
total_rewards_max            13149.364454198474
total_rewards_min            7385.35644222193
Number of train steps total  1680000
Number of env steps total    2102000
Number of rollouts total     0
Train Time (s)               121.6670412896201
(Previous) Eval Time (s)     22.95220447704196
Sample Time (s)              17.459738871082664
Epoch Time (s)               162.07898463774472
Total Train Time (s)         65012.40673704445
Epoch                        419
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:39:52.546185 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #419 | Epoch Duration: 162.70819401741028
2020-01-14 02:39:52.546374 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #419 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.551942
Z variance train             0.0103871655
KL Divergence                69.86606
KL Loss                      6.986606
QF Loss                      1046.863
VF Loss                      188.29082
Policy Loss                  -5252.928
Q Predictions Mean           5262.7305
Q Predictions Std            679.085
Q Predictions Max            5953.487
Q Predictions Min            1574.257
V Predictions Mean           5261.7637
V Predictions Std            682.6896
V Predictions Max            5962.4463
V Predictions Min            1413.7904
Log Pis Mean                 6.1843715
Log Pis Std                  3.8351297
Log Pis Max                  16.879822
Log Pis Min                  -5.430765
Policy mu Mean               -0.04394583
Policy mu Std                1.4513147
Policy mu Max                3.1748092
Policy mu Min                -3.460173
Policy log std Mean          -0.95381933
Policy log std Std           0.5349005
Policy log std Max           -0.17851615
Policy log std Min           -3.5224888
Z mean eval                  3.615239
Z variance eval              0.00675032
total_rewards                [12588.91940503 12965.16687779 12858.31890183 12854.49768483
 12513.48676986 12929.54514249 12627.1381834  12555.15598777
 12638.71116    12720.91709889]
total_rewards_mean           12725.185721189115
total_rewards_std            155.95005996304343
total_rewards_max            12965.166877793437
total_rewards_min            12513.486769860901
Number of train steps total  1684000
Number of env steps total    2107000
Number of rollouts total     0
Train Time (s)               114.12471227021888
(Previous) Eval Time (s)     23.581077515613288
Sample Time (s)              16.327044969890267
Epoch Time (s)               154.03283475572243
Total Train Time (s)         65166.14378499286
Epoch                        420
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:42:26.289832 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #420 | Epoch Duration: 153.74329233169556
2020-01-14 02:42:26.290076 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #420 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.614659
Z variance train             0.0067483126
KL Divergence                70.97395
KL Loss                      7.0973954
QF Loss                      661.7051
VF Loss                      205.85152
Policy Loss                  -5374.659
Q Predictions Mean           5383.0244
Q Predictions Std            668.4
Q Predictions Max            6007.2217
Q Predictions Min            99.66759
V Predictions Mean           5383.9355
V Predictions Std            666.06616
V Predictions Max            6015.573
V Predictions Min            146.58633
Log Pis Mean                 6.6953025
Log Pis Std                  3.7118015
Log Pis Max                  16.539436
Log Pis Min                  -2.825955
Policy mu Mean               -0.085260786
Policy mu Std                1.4547812
Policy mu Max                3.027667
Policy mu Min                -3.6026125
Policy log std Mean          -1.0013009
Policy log std Std           0.5500416
Policy log std Max           0.06892133
Policy log std Min           -3.6486595
Z mean eval                  3.5486286
Z variance eval              0.018384803
total_rewards                [12641.39225902 12537.93749585 12791.73919758 12835.68974082
 12833.28456571 12615.40901492 12867.20853978 12761.1841752
 12840.49619229 12147.08786736]
total_rewards_mean           12687.142904853403
total_rewards_std            209.03288628569211
total_rewards_max            12867.208539783396
total_rewards_min            12147.087867359
Number of train steps total  1688000
Number of env steps total    2112000
Number of rollouts total     0
Train Time (s)               107.90478499187157
(Previous) Eval Time (s)     23.291218298953027
Sample Time (s)              16.262816323898733
Epoch Time (s)               147.45881961472332
Total Train Time (s)         65313.20508058043
Epoch                        421
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:44:53.352762 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #421 | Epoch Duration: 147.06251430511475
2020-01-14 02:44:53.352929 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #421 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5467162
Z variance train             0.01833994
KL Divergence                69.33325
KL Loss                      6.9333253
QF Loss                      610.84534
VF Loss                      289.20294
Policy Loss                  -5201.641
Q Predictions Mean           5210.1846
Q Predictions Std            842.2695
Q Predictions Max            5981.694
Q Predictions Min            -1090.3386
V Predictions Mean           5215.8516
V Predictions Std            841.0372
V Predictions Max            5995.4023
V Predictions Min            -1087.36
Log Pis Mean                 5.828873
Log Pis Std                  3.933833
Log Pis Max                  17.327063
Log Pis Min                  -5.6626844
Policy mu Mean               -0.022000486
Policy mu Std                1.4002374
Policy mu Max                3.8397646
Policy mu Min                -3.1024017
Policy log std Mean          -0.9755896
Policy log std Std           0.4993612
Policy log std Max           -0.25866163
Policy log std Min           -3.499539
Z mean eval                  3.5644023
Z variance eval              0.03073633
total_rewards                [12254.10766075 12605.71004313 12764.93236387 12382.48102996
 12708.01065253 12822.25153472 12648.15339149 12898.37757986
 12637.9500175  12619.03609756]
total_rewards_mean           12634.101037137634
total_rewards_std            183.51431727383678
total_rewards_max            12898.377579859563
total_rewards_min            12254.107660753347
Number of train steps total  1692000
Number of env steps total    2117000
Number of rollouts total     0
Train Time (s)               124.49709234759212
(Previous) Eval Time (s)     22.894651830662042
Sample Time (s)              16.657539798878133
Epoch Time (s)               164.0492839771323
Total Train Time (s)         65476.78607149748
Epoch                        422
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:47:36.946617 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #422 | Epoch Duration: 163.59352087974548
2020-01-14 02:47:36.946964 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #422 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5659142
Z variance train             0.030689696
KL Divergence                68.87985
KL Loss                      6.887985
QF Loss                      545.8464
VF Loss                      175.15569
Policy Loss                  -5153.9067
Q Predictions Mean           5160.4883
Q Predictions Std            795.6399
Q Predictions Max            5904.505
Q Predictions Min            -1230.416
V Predictions Mean           5146.2964
V Predictions Std            789.9626
V Predictions Max            5875.3237
V Predictions Min            -1192.2804
Log Pis Mean                 5.907369
Log Pis Std                  3.874349
Log Pis Max                  18.648571
Log Pis Min                  -4.0060005
Policy mu Mean               -0.08482295
Policy mu Std                1.4193522
Policy mu Max                3.4195704
Policy mu Min                -2.7210903
Policy log std Mean          -0.96825343
Policy log std Std           0.5163931
Policy log std Max           0.065182805
Policy log std Min           -3.15005
Z mean eval                  3.515897
Z variance eval              0.0265312
total_rewards                [12649.96364488 12617.27222571 12632.28548488 12740.62129509
 12932.83573322 12848.05024406 12663.57438329 12396.67741476
 12879.29385981 12440.02846658]
total_rewards_mean           12680.0602752273
total_rewards_std            167.5712375257595
total_rewards_max            12932.835733220265
total_rewards_min            12396.67741476102
Number of train steps total  1696000
Number of env steps total    2122000
Number of rollouts total     0
Train Time (s)               119.15909676812589
(Previous) Eval Time (s)     22.438520106021315
Sample Time (s)              16.45596019970253
Epoch Time (s)               158.05357707384974
Total Train Time (s)         65634.96674725274
Epoch                        423
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:50:15.125573 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #423 | Epoch Duration: 158.17831563949585
2020-01-14 02:50:15.125842 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #423 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5160148
Z variance train             0.026538532
KL Divergence                68.04357
KL Loss                      6.804357
QF Loss                      1235.113
VF Loss                      167.711
Policy Loss                  -5283.983
Q Predictions Mean           5286.9497
Q Predictions Std            682.4869
Q Predictions Max            6002.383
Q Predictions Min            324.18655
V Predictions Mean           5275.5913
V Predictions Std            680.4955
V Predictions Max            6004.334
V Predictions Min            325.69476
Log Pis Mean                 6.368258
Log Pis Std                  3.8209953
Log Pis Max                  15.791745
Log Pis Min                  -2.8003364
Policy mu Mean               -0.103996314
Policy mu Std                1.472663
Policy mu Max                2.9878078
Policy mu Min                -2.856169
Policy log std Mean          -0.96320957
Policy log std Std           0.5289748
Policy log std Max           -0.0707171
Policy log std Min           -3.4109612
Z mean eval                  3.5540473
Z variance eval              0.026362706
total_rewards                [12056.9806181  11604.9550863  11968.95739435 12293.27138765
 12225.33821494 12098.89776311 12163.17101482 11926.9132664
 11928.23598895 12198.07675595]
total_rewards_mean           12046.479749057024
total_rewards_std            190.15371624854495
total_rewards_max            12293.271387648007
total_rewards_min            11604.955086297317
Number of train steps total  1700000
Number of env steps total    2127000
Number of rollouts total     0
Train Time (s)               115.13941379403695
(Previous) Eval Time (s)     22.562992563005537
Sample Time (s)              16.896865846123546
Epoch Time (s)               154.59927220316604
Total Train Time (s)         65789.94390806695
Epoch                        424
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:52:50.111661 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #424 | Epoch Duration: 154.9855878353119
2020-01-14 02:52:50.111995 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #424 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5535178
Z variance train             0.02630207
KL Divergence                69.472595
KL Loss                      6.9472594
QF Loss                      517.6385
VF Loss                      137.5445
Policy Loss                  -5323.9204
Q Predictions Mean           5331.6533
Q Predictions Std            664.92584
Q Predictions Max            6046.668
Q Predictions Min            205.41765
V Predictions Mean           5325.7324
V Predictions Std            664.3365
V Predictions Max            6034.1772
V Predictions Min            165.7067
Log Pis Mean                 6.285524
Log Pis Std                  3.713795
Log Pis Max                  14.950108
Log Pis Min                  -5.2759123
Policy mu Mean               -0.0002565235
Policy mu Std                1.4420455
Policy mu Max                2.890946
Policy mu Min                -3.3193817
Policy log std Mean          -0.9738125
Policy log std Std           0.5465189
Policy log std Max           -0.28365046
Policy log std Min           -3.3349142
Z mean eval                  3.5708632
Z variance eval              0.039517533
total_rewards                [12002.81650201 12991.27318722 12352.16095707 12994.14380864
 12699.37445288 12633.47304773 12482.36506042 12571.7605887
 12632.29879609 12585.5214856 ]
total_rewards_mean           12594.518788636415
total_rewards_std            274.42302079009454
total_rewards_max            12994.143808644232
total_rewards_min            12002.81650201484
Number of train steps total  1704000
Number of env steps total    2132000
Number of rollouts total     0
Train Time (s)               119.07976361690089
(Previous) Eval Time (s)     22.94895787211135
Sample Time (s)              16.494360288605094
Epoch Time (s)               158.52308177761734
Total Train Time (s)         65947.82771338103
Epoch                        425
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:55:27.995561 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #425 | Epoch Duration: 157.88333439826965
2020-01-14 02:55:27.995776 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #425 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.571246
Z variance train             0.03943281
KL Divergence                67.788216
KL Loss                      6.7788215
QF Loss                      1022.74493
VF Loss                      114.71411
Policy Loss                  -5314.9067
Q Predictions Mean           5321.9365
Q Predictions Std            585.544
Q Predictions Max            5932.762
Q Predictions Min            3404.3267
V Predictions Mean           5312.4854
V Predictions Std            584.38367
V Predictions Max            5908.7837
V Predictions Min            3380.799
Log Pis Mean                 6.3927426
Log Pis Std                  3.6309004
Log Pis Max                  19.106188
Log Pis Min                  -4.2394
Policy mu Mean               -0.06603694
Policy mu Std                1.4397556
Policy mu Max                3.6678603
Policy mu Min                -3.2063656
Policy log std Mean          -0.97964287
Policy log std Std           0.53666174
Policy log std Max           0.06290388
Policy log std Min           -3.426044
Z mean eval                  3.5529506
Z variance eval              0.04250761
total_rewards                [12578.00313059 12907.46945193 12778.76178925 12896.15969448
 12768.62100686 12457.97103517 12436.36498221 12885.04570982
 12560.39696037 12969.45510076]
total_rewards_mean           12723.824886144039
total_rewards_std            188.6954855164679
total_rewards_max            12969.455100758252
total_rewards_min            12436.364982209177
Number of train steps total  1708000
Number of env steps total    2137000
Number of rollouts total     0
Train Time (s)               119.70075143082067
(Previous) Eval Time (s)     22.3088735206984
Sample Time (s)              16.82137027196586
Epoch Time (s)               158.83099522348493
Total Train Time (s)         66106.9688456594
Epoch                        426
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:58:07.142218 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #426 | Epoch Duration: 159.14628982543945
2020-01-14 02:58:07.142436 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #426 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5516365
Z variance train             0.04275953
KL Divergence                68.71199
KL Loss                      6.871199
QF Loss                      715.7362
VF Loss                      159.72964
Policy Loss                  -5181.556
Q Predictions Mean           5186.5493
Q Predictions Std            599.1483
Q Predictions Max            5857.945
Q Predictions Min            3435.2324
V Predictions Mean           5190.0728
V Predictions Std            597.9144
V Predictions Max            5855.402
V Predictions Min            3447.3496
Log Pis Mean                 6.030405
Log Pis Std                  3.5815997
Log Pis Max                  15.971101
Log Pis Min                  -3.593005
Policy mu Mean               -0.07870894
Policy mu Std                1.41319
Policy mu Max                3.193038
Policy mu Min                -2.99967
Policy log std Mean          -0.98433954
Policy log std Std           0.5141895
Policy log std Max           0.15231276
Policy log std Min           -3.3042426
Z mean eval                  3.5226696
Z variance eval              0.08118139
total_rewards                [12604.72443151 12529.24258131 13133.25683901 13151.98092132
 12694.23451414 13114.1891176  13036.24117336 12999.20880832
 12792.11232632 12590.977315  ]
total_rewards_mean           12864.616802786848
total_rewards_std            235.32687570186096
total_rewards_max            13151.980921318425
total_rewards_min            12529.242581312254
Number of train steps total  1712000
Number of env steps total    2142000
Number of rollouts total     0
Train Time (s)               120.88304529059678
(Previous) Eval Time (s)     22.62384805828333
Sample Time (s)              15.96247686073184
Epoch Time (s)               159.46937020961195
Total Train Time (s)         66267.55346717127
Epoch                        427
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:00:47.731699 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #427 | Epoch Duration: 160.58909153938293
2020-01-14 03:00:47.731940 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #427 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5192332
Z variance train             0.08087423
KL Divergence                66.746796
KL Loss                      6.6746798
QF Loss                      798.00116
VF Loss                      138.99075
Policy Loss                  -5303.908
Q Predictions Mean           5313.291
Q Predictions Std            595.7045
Q Predictions Max            5939.361
Q Predictions Min            3667.8967
V Predictions Mean           5307.4365
V Predictions Std            593.15076
V Predictions Max            5927.379
V Predictions Min            3681.6099
Log Pis Mean                 6.354739
Log Pis Std                  3.9671783
Log Pis Max                  16.019938
Log Pis Min                  -5.520926
Policy mu Mean               -0.083735056
Policy mu Std                1.477996
Policy mu Max                2.9292948
Policy mu Min                -2.9383504
Policy log std Mean          -0.9652049
Policy log std Std           0.5056828
Policy log std Max           0.027359664
Policy log std Min           -3.4387026
Z mean eval                  3.5591426
Z variance eval              0.03031749
total_rewards                [11841.12474179 12129.91039009 12175.74310591 12074.75885217
 12497.01431178 12239.24424833 12177.08541792 12115.86337139
 12433.25830281 12273.76602814]
total_rewards_mean           12195.776877032296
total_rewards_std            175.2175574047275
total_rewards_max            12497.014311778465
total_rewards_min            11841.12474178885
Number of train steps total  1716000
Number of env steps total    2147000
Number of rollouts total     0
Train Time (s)               118.95730123808607
(Previous) Eval Time (s)     23.743232768028975
Sample Time (s)              16.399411167018116
Epoch Time (s)               159.09994517313316
Total Train Time (s)         66425.94179211091
Epoch                        428
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:03:26.124677 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #428 | Epoch Duration: 158.39253735542297
2020-01-14 03:03:26.124995 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #428 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5576813
Z variance train             0.030388856
KL Divergence                70.04941
KL Loss                      7.004941
QF Loss                      1835.46
VF Loss                      870.49164
Policy Loss                  -5317.091
Q Predictions Mean           5327.1035
Q Predictions Std            654.4993
Q Predictions Max            5964.6187
Q Predictions Min            268.97525
V Predictions Mean           5333.999
V Predictions Std            663.37225
V Predictions Max            6014.144
V Predictions Min            210.42506
Log Pis Mean                 6.729021
Log Pis Std                  4.02745
Log Pis Max                  31.348654
Log Pis Min                  -3.8982537
Policy mu Mean               -0.2133724
Policy mu Std                1.4684377
Policy mu Max                4.9770813
Policy mu Min                -4.9012403
Policy log std Mean          -0.9757034
Policy log std Std           0.51929337
Policy log std Max           -0.2063179
Policy log std Min           -3.5743592
Z mean eval                  3.5403962
Z variance eval              0.016902685
total_rewards                [12470.9097442  12380.36022702 12496.528544   12774.97265695
 12375.90274694 12691.34298093  3590.97286168 12639.89330414
 12492.35395543 13047.44667206]
total_rewards_mean           11696.06836933583
total_rewards_std            2708.686481242373
total_rewards_max            13047.446672059006
total_rewards_min            3590.97286168233
Number of train steps total  1720000
Number of env steps total    2152000
Number of rollouts total     0
Train Time (s)               115.08562063798308
(Previous) Eval Time (s)     23.03550995280966
Sample Time (s)              16.07591540319845
Epoch Time (s)               154.1970459939912
Total Train Time (s)         66579.76841657748
Epoch                        429
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:05:59.956655 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #429 | Epoch Duration: 153.831401348114
2020-01-14 03:05:59.956969 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #429 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5404162
Z variance train             0.016900904
KL Divergence                71.08331
KL Loss                      7.108331
QF Loss                      823.2734
VF Loss                      185.2467
Policy Loss                  -5281.58
Q Predictions Mean           5287.4463
Q Predictions Std            579.16394
Q Predictions Max            5927.091
Q Predictions Min            3591.9626
V Predictions Mean           5283.417
V Predictions Std            579.4517
V Predictions Max            5920.557
V Predictions Min            3587.0376
Log Pis Mean                 6.487321
Log Pis Std                  3.869834
Log Pis Max                  17.382242
Log Pis Min                  -4.0844603
Policy mu Mean               -0.1522029
Policy mu Std                1.4709699
Policy mu Max                3.1472023
Policy mu Min                -3.351955
Policy log std Mean          -0.9510934
Policy log std Std           0.5188474
Policy log std Max           0.034386754
Policy log std Min           -3.1800742
Z mean eval                  3.5890949
Z variance eval              0.033015445
total_rewards                [12797.81159263 12609.2984199  12667.86060681 12813.82734249
 12584.18010656 12891.48372208 12626.19011056 12003.71567481
 12709.36392609 12626.8627258 ]
total_rewards_mean           12633.059422772078
total_rewards_std            230.8137449965527
total_rewards_max            12891.483722077675
total_rewards_min            12003.715674808907
Number of train steps total  1724000
Number of env steps total    2157000
Number of rollouts total     0
Train Time (s)               118.55984117370099
(Previous) Eval Time (s)     22.669544985052198
Sample Time (s)              16.295010035391897
Epoch Time (s)               157.52439619414508
Total Train Time (s)         66737.55103173945
Epoch                        430
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:08:37.741059 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #430 | Epoch Duration: 157.78386116027832
2020-01-14 03:08:37.741230 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #430 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5892854
Z variance train             0.033023052
KL Divergence                71.15312
KL Loss                      7.115312
QF Loss                      1165.0642
VF Loss                      210.57771
Policy Loss                  -5331.5605
Q Predictions Mean           5340.071
Q Predictions Std            587.4632
Q Predictions Max            5969.7505
Q Predictions Min            3612.663
V Predictions Mean           5321.1416
V Predictions Std            584.74457
V Predictions Max            5937.391
V Predictions Min            3602.38
Log Pis Mean                 6.4360714
Log Pis Std                  3.7816832
Log Pis Max                  25.473526
Log Pis Min                  -2.2343078
Policy mu Mean               -0.1382855
Policy mu Std                1.4541671
Policy mu Max                5.3028994
Policy mu Min                -3.9160974
Policy log std Mean          -0.9508875
Policy log std Std           0.50927746
Policy log std Max           0.7361634
Policy log std Min           -3.3528786
Z mean eval                  3.5449142
Z variance eval              0.034637008
total_rewards                [12634.30323943 12533.86641754 12834.60274584 13006.1755912
 12717.40726953 13116.08247195 12921.46894462 12761.04293543
 12835.50129677 12513.30946981]
total_rewards_mean           12787.37603821141
total_rewards_std            186.23867167018795
total_rewards_max            13116.082471950995
total_rewards_min            12513.30946980615
Number of train steps total  1728000
Number of env steps total    2162000
Number of rollouts total     0
Train Time (s)               115.35372974025086
(Previous) Eval Time (s)     22.928762418217957
Sample Time (s)              16.378505552187562
Epoch Time (s)               154.66099771065637
Total Train Time (s)         66892.15595219517
Epoch                        431
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:11:12.348765 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #431 | Epoch Duration: 154.60740160942078
2020-01-14 03:11:12.348916 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #431 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.545379
Z variance train             0.034554183
KL Divergence                71.432625
KL Loss                      7.1432624
QF Loss                      659.64026
VF Loss                      228.94476
Policy Loss                  -5224.3433
Q Predictions Mean           5227.1543
Q Predictions Std            597.79407
Q Predictions Max            5940.3774
Q Predictions Min            3641.6382
V Predictions Mean           5212.3545
V Predictions Std            596.6915
V Predictions Max            5931.969
V Predictions Min            3632.9595
Log Pis Mean                 6.13855
Log Pis Std                  3.4126759
Log Pis Max                  17.453005
Log Pis Min                  -3.2333775
Policy mu Mean               -0.0834564
Policy mu Std                1.4172823
Policy mu Max                3.1985803
Policy mu Min                -2.9638593
Policy log std Mean          -0.98970336
Policy log std Std           0.5390893
Policy log std Max           -0.22128618
Policy log std Min           -3.615592
Z mean eval                  3.6194363
Z variance eval              0.024727339
total_rewards                [12737.08815087 12901.92650741 12901.86298785 12915.4488282
 12784.65864619 12943.57052156 12858.56549391 12927.69117448
 12983.76470931 12892.46466172]
total_rewards_mean           12884.704168151837
total_rewards_std            70.14658926225572
total_rewards_max            12983.764709313375
total_rewards_min            12737.088150867106
Number of train steps total  1732000
Number of env steps total    2167000
Number of rollouts total     0
Train Time (s)               117.18418783973902
(Previous) Eval Time (s)     22.874813954811543
Sample Time (s)              16.457695345859975
Epoch Time (s)               156.51669714041054
Total Train Time (s)         67048.37908665556
Epoch                        432
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:13:48.575391 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #432 | Epoch Duration: 156.22634601593018
2020-01-14 03:13:48.575570 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #432 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.620954
Z variance train             0.024729555
KL Divergence                71.34436
KL Loss                      7.134436
QF Loss                      633.6604
VF Loss                      536.984
Policy Loss                  -5287.6
Q Predictions Mean           5290.166
Q Predictions Std            608.9335
Q Predictions Max            5919.8984
Q Predictions Min            3548.146
V Predictions Mean           5275.029
V Predictions Std            608.1554
V Predictions Max            5889.9844
V Predictions Min            3547.8735
Log Pis Mean                 6.501918
Log Pis Std                  4.2028995
Log Pis Max                  17.510006
Log Pis Min                  -4.02087
Policy mu Mean               -0.09463989
Policy mu Std                1.4376044
Policy mu Max                3.327935
Policy mu Min                -3.9843335
Policy log std Mean          -1.0043546
Policy log std Std           0.54846346
Policy log std Max           -0.008281469
Policy log std Min           -3.4550695
Z mean eval                  3.5695274
Z variance eval              0.031947196
total_rewards                [12165.41367079 11743.08674002 12082.26087203 12495.47243586
 12199.58760594 12571.78931904 12619.66499975 12556.59072809
 12167.18694377 12670.87193092]
total_rewards_mean           12327.192524621927
total_rewards_std            285.24607270112193
total_rewards_max            12670.871930921328
total_rewards_min            11743.086740024719
Number of train steps total  1736000
Number of env steps total    2172000
Number of rollouts total     0
Train Time (s)               121.70956250000745
(Previous) Eval Time (s)     22.584154442884028
Sample Time (s)              16.57032741745934
Epoch Time (s)               160.86404436035082
Total Train Time (s)         67208.91869786708
Epoch                        433
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:16:29.118133 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #433 | Epoch Duration: 160.54244089126587
2020-01-14 03:16:29.118341 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #433 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5644767
Z variance train             0.03196419
KL Divergence                70.75765
KL Loss                      7.075765
QF Loss                      1176.1006
VF Loss                      414.07013
Policy Loss                  -5305.53
Q Predictions Mean           5317.176
Q Predictions Std            767.9639
Q Predictions Max            5997.2334
Q Predictions Min            -1573.5679
V Predictions Mean           5304.8867
V Predictions Std            769.8367
V Predictions Max            6005.6895
V Predictions Min            -1681.809
Log Pis Mean                 6.101407
Log Pis Std                  3.601692
Log Pis Max                  15.665617
Log Pis Min                  -3.728162
Policy mu Mean               -0.08168845
Policy mu Std                1.4517907
Policy mu Max                3.1873703
Policy mu Min                -3.2108414
Policy log std Mean          -0.96856004
Policy log std Std           0.5153288
Policy log std Max           -0.10976958
Policy log std Min           -3.5527768
Z mean eval                  3.5445015
Z variance eval              0.020104337
total_rewards                [12577.77134861 12646.17193594 12958.5202309  13140.69124908
 13137.252128   12960.19571426 13267.97278952 12744.4588091
 12914.70454353 13005.20577785]
total_rewards_mean           12935.294452680157
total_rewards_std            211.6491228988928
total_rewards_max            13267.972789522983
total_rewards_min            12577.77134861283
Number of train steps total  1740000
Number of env steps total    2177000
Number of rollouts total     0
Train Time (s)               117.59797784034163
(Previous) Eval Time (s)     22.26223326800391
Sample Time (s)              16.20376604516059
Epoch Time (s)               156.06397715350613
Total Train Time (s)         67365.26415453432
Epoch                        434
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:19:05.471430 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #434 | Epoch Duration: 156.35293793678284
2020-01-14 03:19:05.471704 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #434 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5430522
Z variance train             0.020070842
KL Divergence                72.001816
KL Loss                      7.2001815
QF Loss                      439.38608
VF Loss                      82.70112
Policy Loss                  -5222.548
Q Predictions Mean           5231.245
Q Predictions Std            625.62836
Q Predictions Max            5992.355
Q Predictions Min            3556.1
V Predictions Mean           5219.927
V Predictions Std            623.44617
V Predictions Max            5956.8965
V Predictions Min            3549.7588
Log Pis Mean                 5.7428865
Log Pis Std                  3.8585067
Log Pis Max                  17.530853
Log Pis Min                  -4.6442213
Policy mu Mean               -0.047904924
Policy mu Std                1.3931675
Policy mu Max                3.0496998
Policy mu Min                -2.6390162
Policy log std Mean          -0.9649143
Policy log std Std           0.50711024
Policy log std Max           -0.018562078
Policy log std Min           -3.3980951
Z mean eval                  3.5321221
Z variance eval              0.023345
total_rewards                [12536.59694187 13022.98129046 11865.83336698 12995.84916
 12574.02801732 12755.14739107 12406.43596435 12337.56999829
 12470.11403826 12618.80304884]
total_rewards_mean           12558.335921742875
total_rewards_std            317.7384277113186
total_rewards_max            13022.981290458809
total_rewards_min            11865.833366976893
Number of train steps total  1744000
Number of env steps total    2182000
Number of rollouts total     0
Train Time (s)               117.86948770424351
(Previous) Eval Time (s)     22.55086218006909
Sample Time (s)              16.21559065580368
Epoch Time (s)               156.63594054011628
Total Train Time (s)         67522.15617047297
Epoch                        435
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:21:42.369412 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #435 | Epoch Duration: 156.89746499061584
2020-01-14 03:21:42.369715 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #435 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.533071
Z variance train             0.023450678
KL Divergence                71.968414
KL Loss                      7.1968417
QF Loss                      1042.9021
VF Loss                      476.8145
Policy Loss                  -5318.4395
Q Predictions Mean           5319.5107
Q Predictions Std            596.6478
Q Predictions Max            5978.7183
Q Predictions Min            1979.3439
V Predictions Mean           5310.196
V Predictions Std            597.0044
V Predictions Max            5951.7466
V Predictions Min            1835.5187
Log Pis Mean                 6.4259157
Log Pis Std                  3.4602592
Log Pis Max                  16.76643
Log Pis Min                  -5.7973576
Policy mu Mean               -0.041802254
Policy mu Std                1.4272841
Policy mu Max                6.176886
Policy mu Min                -2.696212
Policy log std Mean          -1.0112044
Policy log std Std           0.5594015
Policy log std Max           0.4184959
Policy log std Min           -3.5442886
Z mean eval                  3.580278
Z variance eval              0.02290589
total_rewards                [12583.01498803 12684.22458234 12726.07747273 12634.51991843
 12538.78593197 12778.44417109 12909.15042183 12612.10691678
 12475.98081427 12770.51099725]
total_rewards_mean           12671.281621469429
total_rewards_std            122.23891888003986
total_rewards_max            12909.150421826213
total_rewards_min            12475.980814265824
Number of train steps total  1748000
Number of env steps total    2187000
Number of rollouts total     0
Train Time (s)               121.12554315896705
(Previous) Eval Time (s)     22.812101274728775
Sample Time (s)              15.467586422339082
Epoch Time (s)               159.4052308560349
Total Train Time (s)         67681.21002883883
Epoch                        436
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:24:21.426361 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #436 | Epoch Duration: 159.05643439292908
2020-01-14 03:24:21.426563 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #436 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5802758
Z variance train             0.022919204
KL Divergence                71.56642
KL Loss                      7.1566424
QF Loss                      636.9076
VF Loss                      94.61265
Policy Loss                  -5278.405
Q Predictions Mean           5285.9316
Q Predictions Std            576.32214
Q Predictions Max            5927.9297
Q Predictions Min            3683.0208
V Predictions Mean           5277.5986
V Predictions Std            574.3575
V Predictions Max            5896.282
V Predictions Min            3681.7092
Log Pis Mean                 6.091669
Log Pis Std                  3.678539
Log Pis Max                  17.719406
Log Pis Min                  -5.0402713
Policy mu Mean               -0.046731714
Policy mu Std                1.4357073
Policy mu Max                3.57866
Policy mu Min                -2.7789607
Policy log std Mean          -0.9859803
Policy log std Std           0.53071904
Policy log std Max           0.050429344
Policy log std Min           -3.500011
Z mean eval                  3.5859616
Z variance eval              0.034107823
total_rewards                [13040.82775457 13093.72091593 13297.20669322 12958.91461271
 12915.74329502 13035.3606443  13232.98170566 12953.28099902
 13099.25064752 13048.35180115]
total_rewards_mean           13067.563906909356
total_rewards_std            114.81412083519672
total_rewards_max            13297.206693217382
total_rewards_min            12915.743295020464
Number of train steps total  1752000
Number of env steps total    2192000
Number of rollouts total     0
Train Time (s)               119.80251701408997
(Previous) Eval Time (s)     22.463042036164552
Sample Time (s)              16.75546774175018
Epoch Time (s)               159.0210267920047
Total Train Time (s)         67840.3235974242
Epoch                        437
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:27:00.545107 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #437 | Epoch Duration: 159.1183853149414
2020-01-14 03:27:00.545328 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #437 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5875568
Z variance train             0.03401326
KL Divergence                72.168076
KL Loss                      7.216808
QF Loss                      668.21423
VF Loss                      191.70041
Policy Loss                  -5367.3706
Q Predictions Mean           5378.605
Q Predictions Std            608.58026
Q Predictions Max            6055.9663
Q Predictions Min            3242.7065
V Predictions Mean           5361.384
V Predictions Std            606.2836
V Predictions Max            6036.9014
V Predictions Min            3238.1438
Log Pis Mean                 6.5773315
Log Pis Std                  3.9740386
Log Pis Max                  25.007612
Log Pis Min                  -4.056646
Policy mu Mean               -0.093937
Policy mu Std                1.4699945
Policy mu Max                4.9103837
Policy mu Min                -3.1392326
Policy log std Mean          -0.96453786
Policy log std Std           0.51437587
Policy log std Max           -0.20993072
Policy log std Min           -3.3249583
Z mean eval                  3.5583866
Z variance eval              0.01651724
total_rewards                [12417.88271453 12816.90709439 13124.25738568 12756.66078819
 13039.0611767  12517.82447558 12397.84092412 12834.45031566
 12548.50344812 13025.17741597]
total_rewards_mean           12747.856573895164
total_rewards_std            252.9384596908718
total_rewards_max            13124.2573856827
total_rewards_min            12397.840924117203
Number of train steps total  1756000
Number of env steps total    2197000
Number of rollouts total     0
Train Time (s)               123.84054672485217
(Previous) Eval Time (s)     22.560049961321056
Sample Time (s)              17.05109709315002
Epoch Time (s)               163.45169377932325
Total Train Time (s)         68004.97080808273
Epoch                        438
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:29:45.197334 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #438 | Epoch Duration: 164.65182185173035
2020-01-14 03:29:45.197573 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #438 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5579464
Z variance train             0.01651795
KL Divergence                71.29596
KL Loss                      7.129596
QF Loss                      959.82935
VF Loss                      115.728096
Policy Loss                  -5267.344
Q Predictions Mean           5276.856
Q Predictions Std            604.2081
Q Predictions Max            5977.6904
Q Predictions Min            3589.202
V Predictions Mean           5271.881
V Predictions Std            604.3645
V Predictions Max            5961.3535
V Predictions Min            3588.3467
Log Pis Mean                 5.8744984
Log Pis Std                  3.5523243
Log Pis Max                  14.590935
Log Pis Min                  -4.7164173
Policy mu Mean               -0.010316074
Policy mu Std                1.4000397
Policy mu Max                3.1165667
Policy mu Min                -3.0524044
Policy log std Mean          -0.98823524
Policy log std Std           0.50562036
Policy log std Max           -0.23878205
Policy log std Min           -3.3477705
Z mean eval                  3.5486214
Z variance eval              0.011546268
total_rewards                [12792.40316021 12930.48948731 12828.96146409 13085.75648457
 12837.06067102 12931.59879086 12615.86836076 13057.82329454
 12927.7182131  12825.25500386]
total_rewards_mean           12883.293493030109
total_rewards_std            128.92691626703737
total_rewards_max            13085.756484573441
total_rewards_min            12615.86836075869
Number of train steps total  1760000
Number of env steps total    2202000
Number of rollouts total     0
Train Time (s)               119.1951254978776
(Previous) Eval Time (s)     23.75982416421175
Sample Time (s)              16.2885485496372
Epoch Time (s)               159.24349821172655
Total Train Time (s)         68163.2395910807
Epoch                        439
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:32:23.473461 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #439 | Epoch Duration: 158.27568221092224
2020-01-14 03:32:23.473752 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #439 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5483806
Z variance train             0.011551468
KL Divergence                72.57175
KL Loss                      7.257175
QF Loss                      500.6386
VF Loss                      187.16142
Policy Loss                  -5196.842
Q Predictions Mean           5208.131
Q Predictions Std            800.73737
Q Predictions Max            5960.969
Q Predictions Min            -634.2807
V Predictions Mean           5202.8936
V Predictions Std            796.2077
V Predictions Max            5946.308
V Predictions Min            -584.70593
Log Pis Mean                 6.0748835
Log Pis Std                  3.8577456
Log Pis Max                  18.317146
Log Pis Min                  -2.922443
Policy mu Mean               -0.01903645
Policy mu Std                1.4367645
Policy mu Max                4.40992
Policy mu Min                -3.537232
Policy log std Mean          -0.97238463
Policy log std Std           0.49573314
Policy log std Max           0.07791841
Policy log std Min           -3.368501
Z mean eval                  3.5818439
Z variance eval              0.00621593
total_rewards                [12832.73973143 13097.46023741 12944.75452787 13192.12850044
 12825.10902393 12998.68369014 12884.06340742 13291.22008945
 13117.65141444 13062.36255427]
total_rewards_mean           13024.617317680584
total_rewards_std            147.63121572716133
total_rewards_max            13291.220089450877
total_rewards_min            12825.109023930288
Number of train steps total  1764000
Number of env steps total    2207000
Number of rollouts total     0
Train Time (s)               118.08241865411401
(Previous) Eval Time (s)     22.79171677492559
Sample Time (s)              16.054328388534486
Epoch Time (s)               156.92846381757408
Total Train Time (s)         68320.4102415815
Epoch                        440
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:35:00.653366 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #440 | Epoch Duration: 157.17937755584717
2020-01-14 03:35:00.653650 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #440 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.58349
Z variance train             0.0062286863
KL Divergence                73.59596
KL Loss                      7.3595963
QF Loss                      537.3837
VF Loss                      147.77454
Policy Loss                  -5274.7695
Q Predictions Mean           5283.2383
Q Predictions Std            716.1412
Q Predictions Max            5946.281
Q Predictions Min            -747.2308
V Predictions Mean           5269.284
V Predictions Std            714.78906
V Predictions Max            5921.4805
V Predictions Min            -729.6981
Log Pis Mean                 6.0084987
Log Pis Std                  3.4170253
Log Pis Max                  15.536789
Log Pis Min                  -2.9090872
Policy mu Mean               -0.04058416
Policy mu Std                1.4122059
Policy mu Max                3.0074403
Policy mu Min                -2.5373137
Policy log std Mean          -1.0090503
Policy log std Std           0.5167285
Policy log std Max           -0.33909804
Policy log std Min           -3.277196
Z mean eval                  3.5761597
Z variance eval              0.00799166
total_rewards                [12650.42061203 12842.58607395 13032.65578279 12860.99116173
 12992.12368892 12935.96710824 12813.8212569  12974.13300974
 12859.89179517 12439.0907005 ]
total_rewards_mean           12840.168118996391
total_rewards_std            169.01357117848536
total_rewards_max            13032.655782785794
total_rewards_min            12439.090700497669
Number of train steps total  1768000
Number of env steps total    2212000
Number of rollouts total     0
Train Time (s)               122.43449732288718
(Previous) Eval Time (s)     23.042346300091594
Sample Time (s)              16.153436188586056
Epoch Time (s)               161.63027981156483
Total Train Time (s)         68481.39619853767
Epoch                        441
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:37:41.642900 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #441 | Epoch Duration: 160.98902463912964
2020-01-14 03:37:41.643205 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #441 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.576184
Z variance train             0.007982854
KL Divergence                74.74304
KL Loss                      7.474304
QF Loss                      429.00354
VF Loss                      86.00774
Policy Loss                  -5306.8823
Q Predictions Mean           5311.343
Q Predictions Std            618.27075
Q Predictions Max            5974.74
Q Predictions Min            3598.3613
V Predictions Mean           5309.342
V Predictions Std            618.2676
V Predictions Max            5975.5176
V Predictions Min            3592.8516
Log Pis Mean                 6.1942124
Log Pis Std                  3.3937337
Log Pis Max                  15.30272
Log Pis Min                  -3.993939
Policy mu Mean               -0.043269962
Policy mu Std                1.4043982
Policy mu Max                2.8085685
Policy mu Min                -2.690496
Policy log std Mean          -0.98817015
Policy log std Std           0.52372277
Policy log std Max           -0.17967165
Policy log std Min           -3.4731903
Z mean eval                  3.5760932
Z variance eval              0.019700114
total_rewards                [12880.08240179 13120.2736552  12992.56247952 13204.96873195
 13092.774918   13108.8501897  13001.27606815 13079.05690666
 13095.91071528 12851.82311125]
total_rewards_mean           13042.75791774896
total_rewards_std            105.11589446596214
total_rewards_max            13204.96873195215
total_rewards_min            12851.823111247979
Number of train steps total  1772000
Number of env steps total    2217000
Number of rollouts total     0
Train Time (s)               116.02650198386982
(Previous) Eval Time (s)     22.400792866945267
Sample Time (s)              15.877324343193322
Epoch Time (s)               154.3046191940084
Total Train Time (s)         68636.12270958442
Epoch                        442
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:40:16.376779 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #442 | Epoch Duration: 154.73333263397217
2020-01-14 03:40:16.377085 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #442 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.577105
Z variance train             0.019710036
KL Divergence                74.98459
KL Loss                      7.498459
QF Loss                      749.1189
VF Loss                      232.68602
Policy Loss                  -5316.5425
Q Predictions Mean           5319.0195
Q Predictions Std            575.15906
Q Predictions Max            5970.5356
Q Predictions Min            3614.879
V Predictions Mean           5305.031
V Predictions Std            572.5213
V Predictions Max            5939.842
V Predictions Min            3611.187
Log Pis Mean                 6.540998
Log Pis Std                  3.4849944
Log Pis Max                  15.728546
Log Pis Min                  -3.1968453
Policy mu Mean               -0.03953629
Policy mu Std                1.4304496
Policy mu Max                2.9538157
Policy mu Min                -2.9424505
Policy log std Mean          -0.9942811
Policy log std Std           0.54787344
Policy log std Max           -0.2966756
Policy log std Min           -3.5925717
Z mean eval                  3.6200938
Z variance eval              0.032041226
total_rewards                [12490.03577988 13036.0935158  12687.56578984 12773.79507823
 12747.34990884 12861.69055499 12550.95556533 12895.85747116
 12790.22977169 12568.49352946]
total_rewards_mean           12740.206696520689
total_rewards_std            161.5159339647313
total_rewards_max            13036.093515804423
total_rewards_min            12490.035779876713
Number of train steps total  1776000
Number of env steps total    2222000
Number of rollouts total     0
Train Time (s)               121.09669522987679
(Previous) Eval Time (s)     22.829198013991117
Sample Time (s)              15.7480689259246
Epoch Time (s)               159.6739621697925
Total Train Time (s)         68795.71976137906
Epoch                        443
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:42:55.976304 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #443 | Epoch Duration: 159.59901547431946
2020-01-14 03:42:55.976508 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #443 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.620256
Z variance train             0.032116435
KL Divergence                72.93427
KL Loss                      7.2934275
QF Loss                      934.02673
VF Loss                      182.88197
Policy Loss                  -5349.416
Q Predictions Mean           5355.332
Q Predictions Std            587.87225
Q Predictions Max            5979.874
Q Predictions Min            3277.8677
V Predictions Mean           5350.273
V Predictions Std            583.4037
V Predictions Max            5983.3354
V Predictions Min            3352.2927
Log Pis Mean                 6.5565424
Log Pis Std                  4.165015
Log Pis Max                  20.785353
Log Pis Min                  -6.1232367
Policy mu Mean               -0.12749432
Policy mu Std                1.466706
Policy mu Max                3.9026446
Policy mu Min                -4.1252003
Policy log std Mean          -0.9912171
Policy log std Std           0.5094059
Policy log std Max           0.15145993
Policy log std Min           -3.1675138
Z mean eval                  3.5939014
Z variance eval              0.035886813
total_rewards                [12959.36565889 12984.11064092 10784.41112461 12896.97505517
  9441.91164369 12816.25876549 13087.90268644 12908.21262658
 12838.92560922 12997.59979057]
total_rewards_mean           12371.567360156736
total_rewards_std            1170.8087851712887
total_rewards_max            13087.902686436648
total_rewards_min            9441.911643692072
Number of train steps total  1780000
Number of env steps total    2227000
Number of rollouts total     0
Train Time (s)               118.09593745786697
(Previous) Eval Time (s)     22.753981862217188
Sample Time (s)              16.463959801010787
Epoch Time (s)               157.31387912109494
Total Train Time (s)         68952.71437996766
Epoch                        444
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:45:32.975089 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #444 | Epoch Duration: 156.99843406677246
2020-01-14 03:45:32.975301 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #444 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5943208
Z variance train             0.035870362
KL Divergence                71.95978
KL Loss                      7.1959777
QF Loss                      1235.6177
VF Loss                      302.6531
Policy Loss                  -5383.1035
Q Predictions Mean           5392.256
Q Predictions Std            539.3885
Q Predictions Max            5966.9863
Q Predictions Min            3636.478
V Predictions Mean           5391.2305
V Predictions Std            538.70496
V Predictions Max            5967.628
V Predictions Min            3641.8086
Log Pis Mean                 6.590594
Log Pis Std                  3.9327054
Log Pis Max                  24.003723
Log Pis Min                  -4.2304726
Policy mu Mean               -0.036529068
Policy mu Std                1.4538196
Policy mu Max                3.7443683
Policy mu Min                -4.6131916
Policy log std Mean          -1.0141609
Policy log std Std           0.54699916
Policy log std Max           0.08798301
Policy log std Min           -3.5449488
Z mean eval                  3.5755546
Z variance eval              0.023604235
total_rewards                [12815.76977079 13028.02184576 13353.59282307  5236.03709831
 13056.53495355 12956.34924766 13054.80479729 13077.50664275
 13044.15611837 12802.50395083]
total_rewards_mean           12242.527724836109
total_rewards_std            2340.0063725333775
total_rewards_max            13353.592823065916
total_rewards_min            5236.037098310424
Number of train steps total  1784000
Number of env steps total    2232000
Number of rollouts total     0
Train Time (s)               122.6103584561497
(Previous) Eval Time (s)     22.43825971800834
Sample Time (s)              16.43015875807032
Epoch Time (s)               161.47877693222836
Total Train Time (s)         69115.07109095668
Epoch                        445
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:48:15.340357 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #445 | Epoch Duration: 162.36487770080566
2020-01-14 03:48:15.340644 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #445 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5753846
Z variance train             0.023541955
KL Divergence                72.16617
KL Loss                      7.216617
QF Loss                      484.3443
VF Loss                      164.14832
Policy Loss                  -5314.53
Q Predictions Mean           5322.63
Q Predictions Std            618.71387
Q Predictions Max            6006.8296
Q Predictions Min            3541.3691
V Predictions Mean           5316.8394
V Predictions Std            618.92725
V Predictions Max            5995.4897
V Predictions Min            3539.322
Log Pis Mean                 6.2262893
Log Pis Std                  3.9128854
Log Pis Max                  18.901855
Log Pis Min                  -2.3009439
Policy mu Mean               -0.073982656
Policy mu Std                1.4466747
Policy mu Max                3.078299
Policy mu Min                -3.6754308
Policy log std Mean          -0.96664524
Policy log std Std           0.51184
Policy log std Max           -0.11789274
Policy log std Min           -3.4451454
Z mean eval                  3.5784698
Z variance eval              0.017184157
total_rewards                [12931.40523214 13104.48084909 12989.00205842 13321.84326913
 12929.35747546 13184.34631503 12786.5045015  12682.61496631
 12717.73139653 13184.34953198]
total_rewards_mean           12983.163559560682
total_rewards_std            203.82313642276935
total_rewards_max            13321.843269132572
total_rewards_min            12682.614966312303
Number of train steps total  1788000
Number of env steps total    2237000
Number of rollouts total     0
Train Time (s)               115.07629803568125
(Previous) Eval Time (s)     23.324003076180816
Sample Time (s)              16.733360822312534
Epoch Time (s)               155.1336619341746
Total Train Time (s)         69269.46991432784
Epoch                        446
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:50:49.741976 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #446 | Epoch Duration: 154.40112233161926
2020-01-14 03:50:49.742177 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #446 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5777879
Z variance train             0.01714192
KL Divergence                74.034584
KL Loss                      7.4034586
QF Loss                      554.16626
VF Loss                      148.17966
Policy Loss                  -5256.0103
Q Predictions Mean           5266.717
Q Predictions Std            641.981
Q Predictions Max            6023.6562
Q Predictions Min            2614.6018
V Predictions Mean           5255.0645
V Predictions Std            643.6478
V Predictions Max            5987.538
V Predictions Min            2399.8125
Log Pis Mean                 6.306507
Log Pis Std                  3.7595046
Log Pis Max                  14.487333
Log Pis Min                  -6.0146146
Policy mu Mean               -0.06888478
Policy mu Std                1.4253691
Policy mu Max                3.0030375
Policy mu Min                -3.2614584
Policy log std Mean          -1.0025953
Policy log std Std           0.53711385
Policy log std Max           -0.37717378
Policy log std Min           -3.5453253
Z mean eval                  3.577613
Z variance eval              0.026435692
total_rewards                [12791.99330699 12777.78801158 13064.1662793  13009.17160714
 12913.54569097 12542.52895497 13143.76102985 13133.18678087
 12941.83071018 13310.84099675]
total_rewards_mean           12962.881336859766
total_rewards_std            209.3404592538812
total_rewards_max            13310.840996747125
total_rewards_min            12542.528954967262
Number of train steps total  1792000
Number of env steps total    2242000
Number of rollouts total     0
Train Time (s)               117.41972335008904
(Previous) Eval Time (s)     22.591197405941784
Sample Time (s)              16.43951057596132
Epoch Time (s)               156.45043133199215
Total Train Time (s)         69426.30182582932
Epoch                        447
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:53:26.581260 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #447 | Epoch Duration: 156.83890390396118
2020-01-14 03:53:26.581527 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #447 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5774264
Z variance train             0.026535477
KL Divergence                72.506004
KL Loss                      7.2506003
QF Loss                      617.31775
VF Loss                      372.30142
Policy Loss                  -5244.4595
Q Predictions Mean           5256.6626
Q Predictions Std            801.0522
Q Predictions Max            5975.9976
Q Predictions Min            -764.2959
V Predictions Mean           5257.4453
V Predictions Std            797.5264
V Predictions Max            5981.336
V Predictions Min            -666.44684
Log Pis Mean                 6.380992
Log Pis Std                  3.70235
Log Pis Max                  16.894474
Log Pis Min                  -3.8214905
Policy mu Mean               -0.048824262
Policy mu Std                1.4460009
Policy mu Max                3.435955
Policy mu Min                -3.291512
Policy log std Mean          -0.9919502
Policy log std Std           0.5495642
Policy log std Max           -0.28528154
Policy log std Min           -3.4500287
Z mean eval                  3.5801587
Z variance eval              0.030455422
total_rewards                [12227.08249379  8657.13264325 12356.07641009 11801.72560989
 12231.36181474 12178.96709905 12163.37074057 11841.9100872
 12232.44922018 12300.59095304]
total_rewards_mean           11799.066707180782
total_rewards_std            1061.6175101250772
total_rewards_max            12356.076410090032
total_rewards_min            8657.132643252651
Number of train steps total  1796000
Number of env steps total    2247000
Number of rollouts total     0
Train Time (s)               120.05768525367603
(Previous) Eval Time (s)     22.979378815740347
Sample Time (s)              16.810713160783052
Epoch Time (s)               159.84777723019943
Total Train Time (s)         69585.8382439944
Epoch                        448
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:56:06.121363 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #448 | Epoch Duration: 159.53964591026306
2020-01-14 03:56:06.121553 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #448 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5797486
Z variance train             0.030521918
KL Divergence                72.57163
KL Loss                      7.2571635
QF Loss                      705.2752
VF Loss                      200.27223
Policy Loss                  -5300.2827
Q Predictions Mean           5305.2144
Q Predictions Std            620.0947
Q Predictions Max            5986.1816
Q Predictions Min            3571.1382
V Predictions Mean           5304.22
V Predictions Std            620.8019
V Predictions Max            5993.8105
V Predictions Min            3564.7312
Log Pis Mean                 6.4015646
Log Pis Std                  3.7645628
Log Pis Max                  17.245457
Log Pis Min                  -2.3375874
Policy mu Mean               -0.121651
Policy mu Std                1.4309124
Policy mu Max                2.9692395
Policy mu Min                -2.9586155
Policy log std Mean          -0.99587613
Policy log std Std           0.5055095
Policy log std Max           -0.36002743
Policy log std Min           -3.5748549
Z mean eval                  3.6893802
Z variance eval              0.009960821
total_rewards                [12965.66086085 13075.22818071 12914.89018229 13251.65693679
 12774.81146641  6186.51109569 12876.21354105 13048.01276129
 13143.95891725 12212.32669963]
total_rewards_mean           12244.927064196232
total_rewards_std            2037.38029346926
total_rewards_max            13251.656936789857
total_rewards_min            6186.511095690587
Number of train steps total  1800000
Number of env steps total    2252000
Number of rollouts total     0
Train Time (s)               118.2740539079532
(Previous) Eval Time (s)     22.670942010823637
Sample Time (s)              16.54712683148682
Epoch Time (s)               157.49212275026366
Total Train Time (s)         69743.61168764997
Epoch                        449
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:58:43.899273 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #449 | Epoch Duration: 157.77756571769714
2020-01-14 03:58:43.899490 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #449 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6883845
Z variance train             0.009956798
KL Divergence                74.001686
KL Loss                      7.400169
QF Loss                      1074.4924
VF Loss                      245.93433
Policy Loss                  -5331.816
Q Predictions Mean           5341.158
Q Predictions Std            574.78204
Q Predictions Max            5999.2217
Q Predictions Min            3611.837
V Predictions Mean           5340.5073
V Predictions Std            574.5182
V Predictions Max            5998.4673
V Predictions Min            3600.66
Log Pis Mean                 6.3096333
Log Pis Std                  3.6765025
Log Pis Max                  15.300795
Log Pis Min                  -3.4051864
Policy mu Mean               -0.112961076
Policy mu Std                1.4729997
Policy mu Max                2.9309165
Policy mu Min                -2.9581013
Policy log std Mean          -0.95417005
Policy log std Std           0.49528113
Policy log std Max           0.05378592
Policy log std Min           -3.3659422
Z mean eval                  3.6010468
Z variance eval              0.011958499
total_rewards                [12865.64515973 13110.91900731 12724.53166162 13195.76969311
 13235.44837257 13036.49211929 10048.06257279 13130.83038488
 12727.99621723 13060.62442035]
total_rewards_mean           12713.631960887089
total_rewards_std            904.9848861790947
total_rewards_max            13235.44837256806
total_rewards_min            10048.062572785071
Number of train steps total  1804000
Number of env steps total    2257000
Number of rollouts total     0
Train Time (s)               121.26164411474019
(Previous) Eval Time (s)     22.95606814790517
Sample Time (s)              15.62752729980275
Epoch Time (s)               159.8452395624481
Total Train Time (s)         69903.42222975427
Epoch                        450
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:01:23.714727 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #450 | Epoch Duration: 159.81507563591003
2020-01-14 04:01:23.714920 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #450 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6008766
Z variance train             0.011996798
KL Divergence                74.569565
KL Loss                      7.4569564
QF Loss                      1432.8726
VF Loss                      255.3541
Policy Loss                  -5339.9604
Q Predictions Mean           5349.647
Q Predictions Std            664.69995
Q Predictions Max            6011.1523
Q Predictions Min            246.75824
V Predictions Mean           5341.0054
V Predictions Std            665.17926
V Predictions Max            5994.5103
V Predictions Min            136.95778
Log Pis Mean                 6.4396524
Log Pis Std                  3.8308728
Log Pis Max                  19.00063
Log Pis Min                  -3.4266257
Policy mu Mean               -0.04853469
Policy mu Std                1.4422277
Policy mu Max                4.608569
Policy mu Min                -3.5945117
Policy log std Mean          -0.9990322
Policy log std Std           0.54564005
Policy log std Max           -0.09224033
Policy log std Min           -3.4681745
Z mean eval                  3.58952
Z variance eval              0.010305455
total_rewards                [12780.79530964 12962.03902176 12876.78283161 12933.03586044
 12926.83199927 12985.47014045 13158.27760381 12662.24068521
 12940.47327403 13000.92971631]
total_rewards_mean           12922.687644253265
total_rewards_std            125.55019650750752
total_rewards_max            13158.277603810058
total_rewards_min            12662.240685206969
Number of train steps total  1808000
Number of env steps total    2262000
Number of rollouts total     0
Train Time (s)               122.16235306626186
(Previous) Eval Time (s)     22.925619202200323
Sample Time (s)              15.83830397715792
Epoch Time (s)               160.9262762456201
Total Train Time (s)         70063.95300163282
Epoch                        451
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:04:04.252087 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #451 | Epoch Duration: 160.5369803905487
2020-01-14 04:04:04.252339 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #451 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.589307
Z variance train             0.010314336
KL Divergence                75.10684
KL Loss                      7.5106845
QF Loss                      667.66693
VF Loss                      173.88016
Policy Loss                  -5345.656
Q Predictions Mean           5352.8506
Q Predictions Std            603.75824
Q Predictions Max            5969.723
Q Predictions Min            3527.4272
V Predictions Mean           5340.5137
V Predictions Std            600.01764
V Predictions Max            5949.8755
V Predictions Min            3576.0618
Log Pis Mean                 6.521224
Log Pis Std                  3.777165
Log Pis Max                  20.203747
Log Pis Min                  -3.990555
Policy mu Mean               -0.08560293
Policy mu Std                1.4613096
Policy mu Max                3.7878716
Policy mu Min                -3.0671656
Policy log std Mean          -0.97582334
Policy log std Std           0.5112932
Policy log std Max           -0.22480929
Policy log std Min           -3.2513084
Z mean eval                  3.558242
Z variance eval              0.029954035
total_rewards                [12424.99150963 12798.13110086 13006.33480287 12856.43797963
 12869.74146288 12683.79048714 12945.61031218 12951.06369659
 12812.22656429 12744.60101528]
total_rewards_mean           12809.292893134367
total_rewards_std            158.4740485911041
total_rewards_max            13006.334802867776
total_rewards_min            12424.99150963484
Number of train steps total  1812000
Number of env steps total    2267000
Number of rollouts total     0
Train Time (s)               120.1137278471142
(Previous) Eval Time (s)     22.536041056737304
Sample Time (s)              16.350981649942696
Epoch Time (s)               159.0007505537942
Total Train Time (s)         70223.73011342948
Epoch                        452
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:06:44.037562 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #452 | Epoch Duration: 159.7850158214569
2020-01-14 04:06:44.037845 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #452 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5576377
Z variance train             0.03002877
KL Divergence                72.58924
KL Loss                      7.258924
QF Loss                      657.0257
VF Loss                      1672.3302
Policy Loss                  -5273.7856
Q Predictions Mean           5275.372
Q Predictions Std            619.9742
Q Predictions Max            5943.0015
Q Predictions Min            3551.4133
V Predictions Mean           5238.834
V Predictions Std            617.7343
V Predictions Max            5906.928
V Predictions Min            3429.4463
Log Pis Mean                 6.422716
Log Pis Std                  3.9505641
Log Pis Max                  28.145235
Log Pis Min                  -2.1154656
Policy mu Mean               -0.05698897
Policy mu Std                1.4505585
Policy mu Max                3.9670177
Policy mu Min                -5.224096
Policy log std Mean          -0.9815946
Policy log std Std           0.5285028
Policy log std Max           0.5655409
Policy log std Min           -3.428761
Z mean eval                  3.5735517
Z variance eval              0.018828385
total_rewards                [12612.92969909 10834.13109726 13039.95453485 12878.76922121
 13182.40778786 12505.03714889 13082.92423411 12232.01293803
 12835.28351362 13055.41446506]
total_rewards_mean           12625.886463997127
total_rewards_std            660.502768723833
total_rewards_max            13182.407787859445
total_rewards_min            10834.131097258794
Number of train steps total  1816000
Number of env steps total    2272000
Number of rollouts total     0
Train Time (s)               109.61309119872749
(Previous) Eval Time (s)     23.319987152237445
Sample Time (s)              16.92222179658711
Epoch Time (s)               149.85530014755204
Total Train Time (s)         70373.62689505657
Epoch                        453
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:09:13.941374 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #453 | Epoch Duration: 149.90329217910767
2020-01-14 04:09:13.941685 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #453 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5740762
Z variance train             0.018775849
KL Divergence                73.898544
KL Loss                      7.3898544
QF Loss                      1575.3385
VF Loss                      182.09825
Policy Loss                  -5231.009
Q Predictions Mean           5242.576
Q Predictions Std            632.649
Q Predictions Max            5980.2275
Q Predictions Min            3405.7122
V Predictions Mean           5232.263
V Predictions Std            630.984
V Predictions Max            5964.105
V Predictions Min            3398.8933
Log Pis Mean                 6.614705
Log Pis Std                  3.9509778
Log Pis Max                  21.206137
Log Pis Min                  -4.8339767
Policy mu Mean               -0.061724395
Policy mu Std                1.4723252
Policy mu Max                4.577637
Policy mu Min                -4.487436
Policy log std Mean          -0.9961136
Policy log std Std           0.54448724
Policy log std Max           0.8578764
Policy log std Min           -3.5760903
Z mean eval                  3.5454984
Z variance eval              0.020103479
total_rewards                [12655.47771969 13016.39018787 12747.44778898 12988.83154545
 13029.24985561 12693.2229376  10013.84073263 12628.39360222
 13076.81226139 12774.74525329]
total_rewards_mean           12562.441188471985
total_rewards_std            864.5889478558371
total_rewards_max            13076.812261389194
total_rewards_min            10013.840732631948
Number of train steps total  1820000
Number of env steps total    2277000
Number of rollouts total     0
Train Time (s)               122.94101714389399
(Previous) Eval Time (s)     23.3676495840773
Sample Time (s)              16.613610858097672
Epoch Time (s)               162.92227758606896
Total Train Time (s)         70536.07047340879
Epoch                        454
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:11:56.387304 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #454 | Epoch Duration: 162.4454140663147
2020-01-14 04:11:56.387515 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #454 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5440135
Z variance train             0.020025365
KL Divergence                73.282936
KL Loss                      7.328294
QF Loss                      614.4561
VF Loss                      226.09723
Policy Loss                  -5367.11
Q Predictions Mean           5376.174
Q Predictions Std            588.5753
Q Predictions Max            6003.094
Q Predictions Min            3599.915
V Predictions Mean           5368.255
V Predictions Std            588.68774
V Predictions Max            5974.289
V Predictions Min            3584.2532
Log Pis Mean                 6.5195007
Log Pis Std                  3.4270277
Log Pis Max                  21.566029
Log Pis Min                  -2.9106712
Policy mu Mean               -0.07973438
Policy mu Std                1.4285872
Policy mu Max                3.1265883
Policy mu Min                -3.0125995
Policy log std Mean          -1.0166937
Policy log std Std           0.5531444
Policy log std Max           0.2818203
Policy log std Min           -3.484857
Z mean eval                  3.5462239
Z variance eval              0.011463227
total_rewards                [12640.40272212 12975.1044242  13032.40162838 12762.08607236
 12992.34513429 12962.28091404 12648.41429156 12827.74734752
 12692.52834911 13069.02289285]
total_rewards_mean           12860.233377643719
total_rewards_std            156.94062447482577
total_rewards_max            13069.022892851282
total_rewards_min            12640.402722122033
Number of train steps total  1824000
Number of env steps total    2282000
Number of rollouts total     0
Train Time (s)               121.74037130409852
(Previous) Eval Time (s)     22.89051208505407
Sample Time (s)              16.876782943028957
Epoch Time (s)               161.50766633218154
Total Train Time (s)         70697.34217416402
Epoch                        455
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:14:37.663684 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #455 | Epoch Duration: 161.2760124206543
2020-01-14 04:14:37.664150 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #455 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5459697
Z variance train             0.011468147
KL Divergence                74.89363
KL Loss                      7.489363
QF Loss                      863.0604
VF Loss                      611.7535
Policy Loss                  -5257.5137
Q Predictions Mean           5260.5723
Q Predictions Std            707.6483
Q Predictions Max            5965.3135
Q Predictions Min            619.4813
V Predictions Mean           5246.3716
V Predictions Std            702.5456
V Predictions Max            5957.6304
V Predictions Min            672.55237
Log Pis Mean                 5.9486547
Log Pis Std                  3.7963037
Log Pis Max                  17.914682
Log Pis Min                  -4.022589
Policy mu Mean               -0.015638867
Policy mu Std                1.4355106
Policy mu Max                3.4420776
Policy mu Min                -3.1123857
Policy log std Mean          -0.9775052
Policy log std Std           0.5204762
Policy log std Max           0.21641421
Policy log std Min           -3.31633
Z mean eval                  3.5467503
Z variance eval              0.014595387
total_rewards                [12526.61889388 12544.79731812 12560.64131547 12785.6392795
 12661.72595703 12422.80686639 13063.35581492 12634.43856931
 12804.18456629 12591.24725165]
total_rewards_mean           12659.545583255504
total_rewards_std            173.7372960730442
total_rewards_max            13063.355814916737
total_rewards_min            12422.806866387862
Number of train steps total  1828000
Number of env steps total    2287000
Number of rollouts total     0
Train Time (s)               120.94134496059269
(Previous) Eval Time (s)     22.658509127795696
Sample Time (s)              15.68229199713096
Epoch Time (s)               159.28214608551934
Total Train Time (s)         70856.41876117
Epoch                        456
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:17:16.745336 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #456 | Epoch Duration: 159.0809404850006
2020-01-14 04:17:16.745525 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #456 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5461133
Z variance train             0.014618987
KL Divergence                75.080055
KL Loss                      7.5080056
QF Loss                      741.68567
VF Loss                      185.39462
Policy Loss                  -5298.4604
Q Predictions Mean           5307.5435
Q Predictions Std            643.5667
Q Predictions Max            6036.536
Q Predictions Min            3408.4182
V Predictions Mean           5300.971
V Predictions Std            643.05133
V Predictions Max            6031.6436
V Predictions Min            3415.052
Log Pis Mean                 6.226961
Log Pis Std                  3.670109
Log Pis Max                  16.781261
Log Pis Min                  -3.1526868
Policy mu Mean               -0.008540715
Policy mu Std                1.4473492
Policy mu Max                4.64302
Policy mu Min                -3.5974243
Policy log std Mean          -0.9631894
Policy log std Std           0.50080067
Policy log std Max           0.02212745
Policy log std Min           -3.2123713
Z mean eval                  3.5454826
Z variance eval              0.029990535
total_rewards                [12806.2738162  12818.14534626 12886.62388551 13043.548759
 12773.71582893 13042.92181194 13109.66116256 12995.5197029
 13056.9355057  12912.23043729]
total_rewards_mean           12944.557625626458
total_rewards_std            114.30250126954341
total_rewards_max            13109.661162558532
total_rewards_min            12773.715828930652
Number of train steps total  1832000
Number of env steps total    2292000
Number of rollouts total     0
Train Time (s)               118.08589187497273
(Previous) Eval Time (s)     22.457036362960935
Sample Time (s)              16.315527584403753
Epoch Time (s)               156.85845582233742
Total Train Time (s)         71013.24508943036
Epoch                        457
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:19:53.573562 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #457 | Epoch Duration: 156.8279004096985
2020-01-14 04:19:53.573745 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #457 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5465374
Z variance train             0.029995408
KL Divergence                72.05567
KL Loss                      7.2055674
QF Loss                      611.5116
VF Loss                      458.65753
Policy Loss                  -5342.402
Q Predictions Mean           5351.83
Q Predictions Std            636.7641
Q Predictions Max            6022.647
Q Predictions Min            2709.3052
V Predictions Mean           5346.508
V Predictions Std            630.5126
V Predictions Max            6007.7773
V Predictions Min            3130.2295
Log Pis Mean                 6.130142
Log Pis Std                  3.6823213
Log Pis Max                  15.503077
Log Pis Min                  -4.4395537
Policy mu Mean               -0.031012274
Policy mu Std                1.440856
Policy mu Max                3.3423018
Policy mu Min                -3.4227738
Policy log std Mean          -0.97195435
Policy log std Std           0.5299282
Policy log std Max           -0.1724329
Policy log std Min           -3.4777377
Z mean eval                  3.5716293
Z variance eval              0.013296844
total_rewards                [12237.80873761 12840.36862159 13057.6007165  12497.23375909
 12849.82414125 12700.727532   12493.57103946 12258.86019982
 12238.02588456 11982.70575679]
total_rewards_mean           12515.672638867183
total_rewards_std            324.05970584929486
total_rewards_max            13057.600716497556
total_rewards_min            11982.705756794996
Number of train steps total  1836000
Number of env steps total    2297000
Number of rollouts total     0
Train Time (s)               121.24003232317045
(Previous) Eval Time (s)     22.426172377076
Sample Time (s)              16.46619999455288
Epoch Time (s)               160.13240469479933
Total Train Time (s)         71174.2441839301
Epoch                        458
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:22:34.576337 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #458 | Epoch Duration: 161.0024220943451
2020-01-14 04:22:34.576531 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #458 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5731971
Z variance train             0.013316858
KL Divergence                73.79766
KL Loss                      7.379766
QF Loss                      577.90173
VF Loss                      751.3661
Policy Loss                  -5321.714
Q Predictions Mean           5321.98
Q Predictions Std            618.33246
Q Predictions Max            6009.2876
Q Predictions Min            3664.5007
V Predictions Mean           5309.502
V Predictions Std            614.8951
V Predictions Max            5988.987
V Predictions Min            3683.238
Log Pis Mean                 6.2483997
Log Pis Std                  3.7596602
Log Pis Max                  26.176868
Log Pis Min                  -2.911005
Policy mu Mean               0.049710613
Policy mu Std                1.391552
Policy mu Max                5.7193513
Policy mu Min                -3.7501333
Policy log std Mean          -1.0233544
Policy log std Std           0.52772
Policy log std Max           0.19449127
Policy log std Min           -3.4229422
Z mean eval                  3.6137948
Z variance eval              0.011941455
total_rewards                [11228.394416    3523.715674   12726.31530723 12975.35476031
 12234.4544872  13012.08965532 12945.97578704 13002.40966058
 13084.75088565 12802.71081759]
total_rewards_mean           11753.617145091748
total_rewards_std            2794.898848070387
total_rewards_max            13084.750885650472
total_rewards_min            3523.71567399555
Number of train steps total  1840000
Number of env steps total    2302000
Number of rollouts total     0
Train Time (s)               119.57016637502238
(Previous) Eval Time (s)     23.295829707290977
Sample Time (s)              15.90203312318772
Epoch Time (s)               158.76802920550108
Total Train Time (s)         71332.54747979064
Epoch                        459
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:25:12.885676 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #459 | Epoch Duration: 158.30900955200195
2020-01-14 04:25:12.885870 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #459 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6136994
Z variance train             0.011939985
KL Divergence                75.17722
KL Loss                      7.5177226
QF Loss                      930.1256
VF Loss                      81.55016
Policy Loss                  -5313.5103
Q Predictions Mean           5317.0815
Q Predictions Std            649.05035
Q Predictions Max            6021.5845
Q Predictions Min            3605.5308
V Predictions Mean           5313.8037
V Predictions Std            648.6371
V Predictions Max            6011.8276
V Predictions Min            3636.6338
Log Pis Mean                 6.638636
Log Pis Std                  4.1619096
Log Pis Max                  16.87125
Log Pis Min                  -6.1665554
Policy mu Mean               -0.07847101
Policy mu Std                1.4655014
Policy mu Max                2.8247316
Policy mu Min                -2.949756
Policy log std Mean          -0.9838031
Policy log std Std           0.5430225
Policy log std Max           -0.27936423
Policy log std Min           -3.6549196
Z mean eval                  3.60179
Z variance eval              0.009180127
total_rewards                [12490.56188881 12997.23416731 13014.45504686 13027.93406865
 13132.37261216 13000.34219167 13069.92809152 12772.44963593
 12924.25410365 13166.80750232]
total_rewards_mean           12959.633930887529
total_rewards_std            187.6123182380373
total_rewards_max            13166.80750232402
total_rewards_min            12490.561888805798
Number of train steps total  1844000
Number of env steps total    2307000
Number of rollouts total     0
Train Time (s)               120.66961340187117
(Previous) Eval Time (s)     22.83654581522569
Sample Time (s)              16.528185362461954
Epoch Time (s)               160.03434457955882
Total Train Time (s)         71492.36122785555
Epoch                        460
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:27:52.701565 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #460 | Epoch Duration: 159.81552624702454
2020-01-14 04:27:52.701780 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #460 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.599638
Z variance train             0.009164199
KL Divergence                74.9272
KL Loss                      7.49272
QF Loss                      690.38806
VF Loss                      180.78886
Policy Loss                  -5387.6406
Q Predictions Mean           5399.1216
Q Predictions Std            576.4742
Q Predictions Max            6029.263
Q Predictions Min            3660.378
V Predictions Mean           5396.802
V Predictions Std            576.5167
V Predictions Max            6023.7764
V Predictions Min            3645.9119
Log Pis Mean                 6.6187687
Log Pis Std                  3.9908164
Log Pis Max                  22.821701
Log Pis Min                  -8.377647
Policy mu Mean               -0.03900882
Policy mu Std                1.4735636
Policy mu Max                3.9119043
Policy mu Min                -3.7922328
Policy log std Mean          -0.99270296
Policy log std Std           0.5407003
Policy log std Max           -0.13537502
Policy log std Min           -3.4906883
Z mean eval                  3.5898945
Z variance eval              0.020241467
total_rewards                [12869.52926471 13177.96278941 13068.56287477 13227.50730114
 13129.32449682 13170.48659462 13113.60685437 12986.08870866
 12983.46320825 13056.63972706]
total_rewards_mean           13078.3171819803
total_rewards_std            103.04856480830297
total_rewards_max            13227.507301144915
total_rewards_min            12869.529264708703
Number of train steps total  1848000
Number of env steps total    2312000
Number of rollouts total     0
Train Time (s)               114.03134875930846
(Previous) Eval Time (s)     22.61733476119116
Sample Time (s)              16.541375891771168
Epoch Time (s)               153.19005941227078
Total Train Time (s)         71646.56638550712
Epoch                        461
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:30:26.914131 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #461 | Epoch Duration: 154.21216821670532
2020-01-14 04:30:26.914447 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #461 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5909603
Z variance train             0.02023799
KL Divergence                76.823044
KL Loss                      7.6823044
QF Loss                      681.92596
VF Loss                      390.70258
Policy Loss                  -5312.134
Q Predictions Mean           5318.0854
Q Predictions Std            803.6083
Q Predictions Max            6015.9946
Q Predictions Min            -3207.528
V Predictions Mean           5312.634
V Predictions Std            810.674
V Predictions Max            6012.41
V Predictions Min            -3387.3555
Log Pis Mean                 6.6101875
Log Pis Std                  4.6263504
Log Pis Max                  50.6129
Log Pis Min                  -1.2846293
Policy mu Mean               -0.1161279
Policy mu Std                2.0413766
Policy mu Max                45.13744
Policy mu Min                -28.610643
Policy log std Mean          -0.9766709
Policy log std Std           0.5444893
Policy log std Max           2.0
Policy log std Min           -3.389207
Z mean eval                  3.5674183
Z variance eval              0.028272439
total_rewards                [12988.44723794 13084.38243763 12952.81176389 13053.58850631
 13144.7320868  12993.06992019 13159.1255936  13050.85847011
 13090.84305875 12981.43464021]
total_rewards_mean           13049.929371543532
total_rewards_std            67.02460270879595
total_rewards_max            13159.125593600133
total_rewards_min            12952.811763893133
Number of train steps total  1852000
Number of env steps total    2317000
Number of rollouts total     0
Train Time (s)               119.01109948894009
(Previous) Eval Time (s)     23.639124325010926
Sample Time (s)              16.1421486181207
Epoch Time (s)               158.79237243207172
Total Train Time (s)         71803.99417022662
Epoch                        462
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:33:04.345716 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #462 | Epoch Duration: 157.4310359954834
2020-01-14 04:33:04.345928 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #462 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.569847
Z variance train             0.028178727
KL Divergence                76.04458
KL Loss                      7.604458
QF Loss                      492.5464
VF Loss                      413.5355
Policy Loss                  -5319.3706
Q Predictions Mean           5325.2793
Q Predictions Std            630.12964
Q Predictions Max            6006.081
Q Predictions Min            3645.9795
V Predictions Mean           5301.836
V Predictions Std            628.85876
V Predictions Max            5974.6167
V Predictions Min            3624.108
Log Pis Mean                 6.77182
Log Pis Std                  3.8365152
Log Pis Max                  18.757648
Log Pis Min                  -1.9075452
Policy mu Mean               -0.09914342
Policy mu Std                1.4882392
Policy mu Max                3.1583831
Policy mu Min                -3.3910506
Policy log std Mean          -0.9902175
Policy log std Std           0.52302676
Policy log std Max           -0.34518296
Policy log std Min           -3.5818276
Z mean eval                  3.5676155
Z variance eval              0.022786008
total_rewards                [12996.1299104  12950.13257339 13291.99133569 13448.3328515
 12019.45209973 13305.76457536 13258.49828354 12986.4634165
 13070.10609397 13411.87522055]
total_rewards_mean           13073.87463606445
total_rewards_std            391.24355953869645
total_rewards_max            13448.332851496983
total_rewards_min            12019.452099734835
Number of train steps total  1856000
Number of env steps total    2322000
Number of rollouts total     0
Train Time (s)               117.39770666509867
(Previous) Eval Time (s)     22.27746627992019
Sample Time (s)              16.358815306331962
Epoch Time (s)               156.03398825135082
Total Train Time (s)         71961.3823236241
Epoch                        463
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:35:41.743111 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #463 | Epoch Duration: 157.39699006080627
2020-01-14 04:35:41.743408 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #463 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5672271
Z variance train             0.02279675
KL Divergence                76.35419
KL Loss                      7.635419
QF Loss                      946.05664
VF Loss                      221.5835
Policy Loss                  -5275.1978
Q Predictions Mean           5282.7065
Q Predictions Std            746.5847
Q Predictions Max            6029.034
Q Predictions Min            -537.89124
V Predictions Mean           5280.757
V Predictions Std            744.3198
V Predictions Max            6010.917
V Predictions Min            -441.9919
Log Pis Mean                 6.463922
Log Pis Std                  4.122373
Log Pis Max                  16.917484
Log Pis Min                  -4.1846414
Policy mu Mean               -0.05980983
Policy mu Std                1.4816217
Policy mu Max                3.131625
Policy mu Min                -2.9411201
Policy log std Mean          -0.9663188
Policy log std Std           0.5328956
Policy log std Max           -0.089353204
Policy log std Min           -3.5585573
Z mean eval                  3.58326
Z variance eval              0.027235707
total_rewards                [12735.01812943 12918.760984   13079.50427193 12949.06412664
 13139.78363669 13031.88695592 13034.03856928 13006.6538385
 12933.47244722 13010.95098546]
total_rewards_mean           12983.913394506533
total_rewards_std            104.61728026816301
total_rewards_max            13139.783636687147
total_rewards_min            12735.018129431875
Number of train steps total  1860000
Number of env steps total    2327000
Number of rollouts total     0
Train Time (s)               116.86139551177621
(Previous) Eval Time (s)     23.63996919291094
Sample Time (s)              16.968534318730235
Epoch Time (s)               157.46989902341738
Total Train Time (s)         72118.5042687133
Epoch                        464
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:38:18.867589 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #464 | Epoch Duration: 157.12396335601807
2020-01-14 04:38:18.867770 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #464 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.582561
Z variance train             0.027218074
KL Divergence                76.958374
KL Loss                      7.6958375
QF Loss                      758.5318
VF Loss                      347.23755
Policy Loss                  -5247.3286
Q Predictions Mean           5257.9517
Q Predictions Std            706.35315
Q Predictions Max            5991.3257
Q Predictions Min            -338.5485
V Predictions Mean           5247.5376
V Predictions Std            705.27606
V Predictions Max            5979.0605
V Predictions Min            -350.70178
Log Pis Mean                 6.106145
Log Pis Std                  3.8368504
Log Pis Max                  23.38173
Log Pis Min                  -5.6551085
Policy mu Mean               -0.06843386
Policy mu Std                1.4115485
Policy mu Max                2.7291946
Policy mu Min                -5.31583
Policy log std Mean          -0.9982391
Policy log std Std           0.52202964
Policy log std Max           -0.28310966
Policy log std Min           -3.4542048
Z mean eval                  3.579097
Z variance eval              0.01912935
total_rewards                [12785.93796874 13047.21069991 13190.91671825 13080.82289501
 13128.65359058 12743.44059001  3257.90478771 13242.55055748
 13207.46568045 13264.66760477]
total_rewards_mean           12094.957109292705
total_rewards_std            2950.639285338924
total_rewards_max            13264.667604771774
total_rewards_min            3257.9047877147195
Number of train steps total  1864000
Number of env steps total    2332000
Number of rollouts total     0
Train Time (s)               118.09793049562722
(Previous) Eval Time (s)     23.293748788069934
Sample Time (s)              16.797021941747516
Epoch Time (s)               158.18870122544467
Total Train Time (s)         72276.6977974805
Epoch                        465
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:40:57.063503 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #465 | Epoch Duration: 158.19556093215942
2020-01-14 04:40:57.063664 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #465 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5794632
Z variance train             0.019108474
KL Divergence                78.20822
KL Loss                      7.8208222
QF Loss                      2164.3643
VF Loss                      388.5176
Policy Loss                  -5347.48
Q Predictions Mean           5354.7275
Q Predictions Std            634.1979
Q Predictions Max            6018.2656
Q Predictions Min            3176.1453
V Predictions Mean           5341.3193
V Predictions Std            634.1339
V Predictions Max            6031.0913
V Predictions Min            3119.297
Log Pis Mean                 6.565111
Log Pis Std                  3.5380528
Log Pis Max                  18.082062
Log Pis Min                  -2.4679818
Policy mu Mean               -0.024774991
Policy mu Std                1.4473999
Policy mu Max                3.5032115
Policy mu Min                -2.9281619
Policy log std Mean          -1.0128881
Policy log std Std           0.55372095
Policy log std Max           -0.26354587
Policy log std Min           -3.7571836
Z mean eval                  3.5565403
Z variance eval              0.01985703
total_rewards                [12725.49291831 13025.57083464 13119.06703295 13234.04628864
 13215.85589005 13173.1330368  13142.57146013 13262.15706443
 13026.20721344 12984.51730609]
total_rewards_mean           13090.861904549378
total_rewards_std            151.3116206001084
total_rewards_max            13262.157064430956
total_rewards_min            12725.49291831307
Number of train steps total  1868000
Number of env steps total    2337000
Number of rollouts total     0
Train Time (s)               123.52045821212232
(Previous) Eval Time (s)     23.30028081871569
Sample Time (s)              16.016572087537497
Epoch Time (s)               162.8373111183755
Total Train Time (s)         72438.69812268252
Epoch                        466
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:43:39.072016 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #466 | Epoch Duration: 162.0081970691681
2020-01-14 04:43:39.072286 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #466 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5573
Z variance train             0.019895118
KL Divergence                78.52819
KL Loss                      7.852819
QF Loss                      505.205
VF Loss                      195.26456
Policy Loss                  -5361.971
Q Predictions Mean           5365.496
Q Predictions Std            624.8904
Q Predictions Max            5992.4795
Q Predictions Min            3671.36
V Predictions Mean           5351.7393
V Predictions Std            624.3805
V Predictions Max            5980.262
V Predictions Min            3649.953
Log Pis Mean                 6.570653
Log Pis Std                  3.4172711
Log Pis Max                  16.542553
Log Pis Min                  -3.0271297
Policy mu Mean               0.0003029847
Policy mu Std                1.423977
Policy mu Max                3.0132885
Policy mu Min                -2.9599552
Policy log std Mean          -1.0101231
Policy log std Std           0.527204
Policy log std Max           -0.35716957
Policy log std Min           -3.3361945
Z mean eval                  3.5655613
Z variance eval              0.0142497225
total_rewards                [12967.70926439 13349.80463031 13103.90949487 13356.94017326
 13248.06636889 13145.78071114 13152.95710624 13073.79923882
 13319.91581442 13315.72937175]
total_rewards_mean           13203.461217409418
total_rewards_std            127.00672388869586
total_rewards_max            13356.940173260815
total_rewards_min            12967.709264386169
Number of train steps total  1872000
Number of env steps total    2342000
Number of rollouts total     0
Train Time (s)               114.56886998284608
(Previous) Eval Time (s)     22.470856379251927
Sample Time (s)              16.04075023299083
Epoch Time (s)               153.08047659508884
Total Train Time (s)         72591.70046423469
Epoch                        467
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:46:12.076177 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #467 | Epoch Duration: 153.0037019252777
2020-01-14 04:46:12.076335 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #467 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.564341
Z variance train             0.014246209
KL Divergence                78.693855
KL Loss                      7.8693857
QF Loss                      637.9449
VF Loss                      190.24529
Policy Loss                  -5357.755
Q Predictions Mean           5370.5557
Q Predictions Std            736.88464
Q Predictions Max            6030.409
Q Predictions Min            -1114.12
V Predictions Mean           5362.533
V Predictions Std            736.23773
V Predictions Max            6008.328
V Predictions Min            -1139.3506
Log Pis Mean                 6.430085
Log Pis Std                  3.8576334
Log Pis Max                  23.04182
Log Pis Min                  -2.9153357
Policy mu Mean               -0.05236587
Policy mu Std                1.4249923
Policy mu Max                5.1013365
Policy mu Min                -5.2486405
Policy log std Mean          -1.0293405
Policy log std Std           0.5635779
Policy log std Max           -0.0043178797
Policy log std Min           -3.686987
Z mean eval                  3.5158584
Z variance eval              0.018803053
total_rewards                [12653.06939076 12627.61515932 12955.28899035  2893.98282459
 13277.63004952 13190.93311904 13016.47541741 13075.76493849
 13055.3597735  13210.59800803]
total_rewards_mean           11995.67176709989
total_rewards_std            3040.934452408221
total_rewards_max            13277.630049518184
total_rewards_min            2893.9828245880217
Number of train steps total  1876000
Number of env steps total    2347000
Number of rollouts total     0
Train Time (s)               115.78157930728048
(Previous) Eval Time (s)     22.393797317985445
Sample Time (s)              16.379375270567834
Epoch Time (s)               154.55475189583376
Total Train Time (s)         72746.63226682926
Epoch                        468
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:48:47.012753 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #468 | Epoch Duration: 154.93628406524658
2020-01-14 04:48:47.012956 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #468 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.510905
Z variance train             0.018985514
KL Divergence                78.621796
KL Loss                      7.8621798
QF Loss                      1255.9404
VF Loss                      131.87993
Policy Loss                  -5295.616
Q Predictions Mean           5301.0874
Q Predictions Std            587.2277
Q Predictions Max            5988.8623
Q Predictions Min            3542.6711
V Predictions Mean           5298.998
V Predictions Std            586.69745
V Predictions Max            5971.4316
V Predictions Min            3542.6387
Log Pis Mean                 6.4709544
Log Pis Std                  3.7994359
Log Pis Max                  18.36776
Log Pis Min                  -2.2332308
Policy mu Mean               -0.02630873
Policy mu Std                1.4341598
Policy mu Max                2.9217715
Policy mu Min                -3.6210809
Policy log std Mean          -1.0027875
Policy log std Std           0.52924657
Policy log std Max           -0.076322556
Policy log std Min           -3.5394745
Z mean eval                  3.5515525
Z variance eval              0.015264009
total_rewards                [12953.40785845 13042.30387185 13245.65202207 12952.78491947
 13052.64131042 13216.89463401 13307.02520468 13214.18457
 13207.07110841 13091.37136543]
total_rewards_mean           13128.333686480391
total_rewards_std            119.59111199023367
total_rewards_max            13307.02520467983
total_rewards_min            12952.784919469612
Number of train steps total  1880000
Number of env steps total    2352000
Number of rollouts total     0
Train Time (s)               115.4560198080726
(Previous) Eval Time (s)     22.775028716772795
Sample Time (s)              16.18064737971872
Epoch Time (s)               154.4116959045641
Total Train Time (s)         72900.7365931333
Epoch                        469
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:51:21.122713 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #469 | Epoch Duration: 154.10958242416382
2020-01-14 04:51:21.122945 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #469 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5522828
Z variance train             0.015251058
KL Divergence                79.34999
KL Loss                      7.934999
QF Loss                      1284.8989
VF Loss                      658.6583
Policy Loss                  -5257.5425
Q Predictions Mean           5261.4883
Q Predictions Std            716.2256
Q Predictions Max            5991.2573
Q Predictions Min            1461.8546
V Predictions Mean           5250.9404
V Predictions Std            703.3476
V Predictions Max            5979.984
V Predictions Min            1879.4094
Log Pis Mean                 6.2285933
Log Pis Std                  3.9640253
Log Pis Max                  20.925941
Log Pis Min                  -4.4502726
Policy mu Mean               -0.11469564
Policy mu Std                1.4275217
Policy mu Max                3.474951
Policy mu Min                -3.3850157
Policy log std Mean          -0.9886053
Policy log std Std           0.50751716
Policy log std Max           -0.21014988
Policy log std Min           -3.3810306
Z mean eval                  3.5656502
Z variance eval              0.016672092
total_rewards                [12698.5003483  12676.8276188  13060.16651143 12841.3109703
 12737.7123774  12983.89662034 12957.21165384 12980.58012954
 12666.2636228  12798.23127104]
total_rewards_mean           12840.070112378122
total_rewards_std            138.46358179674104
total_rewards_max            13060.166511426272
total_rewards_min            12666.263622799646
Number of train steps total  1884000
Number of env steps total    2357000
Number of rollouts total     0
Train Time (s)               117.84047393873334
(Previous) Eval Time (s)     22.472625297959894
Sample Time (s)              16.56792123289779
Epoch Time (s)               156.88102046959102
Total Train Time (s)         73057.93043122254
Epoch                        470
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:53:58.322683 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #470 | Epoch Duration: 157.1995542049408
2020-01-14 04:53:58.322913 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #470 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5673943
Z variance train             0.016707381
KL Divergence                79.813255
KL Loss                      7.9813256
QF Loss                      1294.2064
VF Loss                      321.92844
Policy Loss                  -5413.144
Q Predictions Mean           5422.9634
Q Predictions Std            594.8818
Q Predictions Max            6034.237
Q Predictions Min            3594.5767
V Predictions Mean           5408.5703
V Predictions Std            592.66846
V Predictions Max            6015.127
V Predictions Min            3606.9705
Log Pis Mean                 6.8109264
Log Pis Std                  3.954212
Log Pis Max                  17.69564
Log Pis Min                  -2.523944
Policy mu Mean               -0.03125663
Policy mu Std                1.4774176
Policy mu Max                2.9575546
Policy mu Min                -3.4579573
Policy log std Mean          -0.99530786
Policy log std Std           0.5451099
Policy log std Max           -0.30549812
Policy log std Min           -3.7480273
Z mean eval                  3.6010349
Z variance eval              0.014022422
total_rewards                [12688.10343057 12999.13617529 13201.5831406  13300.90279324
 13064.17046016 13045.35490287 12889.90412758 13041.97162433
 13144.92731906 13016.88889537]
total_rewards_mean           13039.294286908358
total_rewards_std            159.48819895892447
total_rewards_max            13300.902793239105
total_rewards_min            12688.103430573557
Number of train steps total  1888000
Number of env steps total    2362000
Number of rollouts total     0
Train Time (s)               111.34651868697256
(Previous) Eval Time (s)     22.790889780968428
Sample Time (s)              16.149417239241302
Epoch Time (s)               150.2868257071823
Total Train Time (s)         73208.22094654618
Epoch                        471
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:56:28.615044 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #471 | Epoch Duration: 150.29196524620056
2020-01-14 04:56:28.615255 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #471 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5992622
Z variance train             0.014023635
KL Divergence                79.45716
KL Loss                      7.9457164
QF Loss                      842.108
VF Loss                      434.82236
Policy Loss                  -5342.769
Q Predictions Mean           5350.25
Q Predictions Std            624.92206
Q Predictions Max            6012.359
Q Predictions Min            1662.3444
V Predictions Mean           5345.129
V Predictions Std            622.0842
V Predictions Max            5984.0225
V Predictions Min            1748.2865
Log Pis Mean                 6.537447
Log Pis Std                  3.9008
Log Pis Max                  16.250458
Log Pis Min                  -3.8633156
Policy mu Mean               -0.10363665
Policy mu Std                1.4661465
Policy mu Max                3.1765559
Policy mu Min                -4.0549617
Policy log std Mean          -0.9882295
Policy log std Std           0.54025424
Policy log std Max           0.026753187
Policy log std Min           -3.5033545
Z mean eval                  3.567112
Z variance eval              0.029281149
total_rewards                [12875.4691775  12979.51469465 13202.25267318 13149.88975646
 13160.12672598 13223.03547218 12992.1997881  12822.61208205
 12997.94444516  5238.22249878]
total_rewards_mean           12264.126731403881
total_rewards_std            2345.555646170542
total_rewards_max            13223.035472183774
total_rewards_min            5238.22249877595
Number of train steps total  1892000
Number of env steps total    2367000
Number of rollouts total     0
Train Time (s)               119.42250650702044
(Previous) Eval Time (s)     22.795730461832136
Sample Time (s)              15.685677247587591
Epoch Time (s)               157.90391421644017
Total Train Time (s)         73366.59731199685
Epoch                        472
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:59:06.998057 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #472 | Epoch Duration: 158.38263130187988
2020-01-14 04:59:06.998291 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #472 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5659878
Z variance train             0.029331392
KL Divergence                77.58458
KL Loss                      7.758458
QF Loss                      539.9325
VF Loss                      159.99539
Policy Loss                  -5375.726
Q Predictions Mean           5385.547
Q Predictions Std            630.0239
Q Predictions Max            6026.047
Q Predictions Min            3604.7969
V Predictions Mean           5384.0312
V Predictions Std            628.47784
V Predictions Max            6006.826
V Predictions Min            3619.786
Log Pis Mean                 6.471221
Log Pis Std                  3.622575
Log Pis Max                  16.496712
Log Pis Min                  -3.2146845
Policy mu Mean               -0.09513435
Policy mu Std                1.433028
Policy mu Max                3.5445278
Policy mu Min                -3.3770828
Policy log std Mean          -1.0012561
Policy log std Std           0.52612966
Policy log std Max           -0.15797174
Policy log std Min           -3.469027
Z mean eval                  3.549274
Z variance eval              0.021171505
total_rewards                [12823.72218591 13075.0494593  12971.00647252 13047.8370445
 13300.25426989 12674.62751256 12873.56472259 12831.8018283
 13072.20488456 12981.05698311]
total_rewards_mean           12965.112536325345
total_rewards_std            165.3882447687278
total_rewards_max            13300.254269888475
total_rewards_min            12674.62751255877
Number of train steps total  1896000
Number of env steps total    2372000
Number of rollouts total     0
Train Time (s)               119.73472787998617
(Previous) Eval Time (s)     23.274125042837113
Sample Time (s)              15.915616211015731
Epoch Time (s)               158.924469133839
Total Train Time (s)         73524.84471377265
Epoch                        473
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:01:45.247595 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #473 | Epoch Duration: 158.24913549423218
2020-01-14 05:01:45.247781 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #473 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.549024
Z variance train             0.021165837
KL Divergence                76.67758
KL Loss                      7.6677585
QF Loss                      445.64896
VF Loss                      336.48047
Policy Loss                  -5318.3696
Q Predictions Mean           5327.42
Q Predictions Std            693.33875
Q Predictions Max            6012.866
Q Predictions Min            297.7652
V Predictions Mean           5330.6074
V Predictions Std            696.582
V Predictions Max            6002.6978
V Predictions Min            189.32285
Log Pis Mean                 6.4632626
Log Pis Std                  3.7791235
Log Pis Max                  17.996529
Log Pis Min                  -1.8568189
Policy mu Mean               -0.052014153
Policy mu Std                1.4351134
Policy mu Max                3.1115701
Policy mu Min                -3.3672833
Policy log std Mean          -1.0078686
Policy log std Std           0.53818977
Policy log std Max           -0.14890862
Policy log std Min           -3.3621545
Z mean eval                  3.5476966
Z variance eval              0.021546047
total_rewards                [12727.88535656 12911.2186002  13144.49641973 13054.40989806
 13142.97175018 12885.28791916 12847.71416944 13036.94940166
 12826.30334446 13029.20808459]
total_rewards_mean           12960.644494404109
total_rewards_std            133.96240737755375
total_rewards_max            13144.496419732923
total_rewards_min            12727.885356562372
Number of train steps total  1900000
Number of env steps total    2377000
Number of rollouts total     0
Train Time (s)               113.39160765195265
(Previous) Eval Time (s)     22.59852330107242
Sample Time (s)              15.993200935889035
Epoch Time (s)               151.9833318889141
Total Train Time (s)         73677.15177958878
Epoch                        474
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:04:17.561645 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #474 | Epoch Duration: 152.31366395950317
2020-01-14 05:04:17.561910 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #474 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5468712
Z variance train             0.021582713
KL Divergence                75.508865
KL Loss                      7.5508866
QF Loss                      395.8102
VF Loss                      101.27165
Policy Loss                  -5368.857
Q Predictions Mean           5373.5444
Q Predictions Std            613.8495
Q Predictions Max            6079.3403
Q Predictions Min            3555.8423
V Predictions Mean           5363.9033
V Predictions Std            612.48676
V Predictions Max            6075.369
V Predictions Min            3561.9104
Log Pis Mean                 6.517996
Log Pis Std                  3.8339195
Log Pis Max                  18.638206
Log Pis Min                  -3.5483656
Policy mu Mean               -0.013560932
Policy mu Std                1.4521497
Policy mu Max                3.6204286
Policy mu Min                -4.165516
Policy log std Mean          -0.9867573
Policy log std Std           0.525553
Policy log std Max           -0.04034686
Policy log std Min           -3.5263433
Z mean eval                  3.568103
Z variance eval              0.015491486
total_rewards                [12843.72616278 12880.33577051 13152.19408207 13047.90328967
 13324.01930411 11708.23076578 12835.26625435 13034.81489342
 13415.39378796 13086.89490648]
total_rewards_mean           12932.877921712809
total_rewards_std            447.3537013791881
total_rewards_max            13415.39378796186
total_rewards_min            11708.23076578106
Number of train steps total  1904000
Number of env steps total    2382000
Number of rollouts total     0
Train Time (s)               121.09337280411273
(Previous) Eval Time (s)     22.9285723939538
Sample Time (s)              16.256325806491077
Epoch Time (s)               160.2782710045576
Total Train Time (s)         73837.20185772469
Epoch                        475
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:06:57.618381 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #475 | Epoch Duration: 160.05625176429749
2020-01-14 05:06:57.618652 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #475 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.570767
Z variance train             0.015459174
KL Divergence                76.94018
KL Loss                      7.694018
QF Loss                      452.50195
VF Loss                      584.83746
Policy Loss                  -5393.4585
Q Predictions Mean           5396.58
Q Predictions Std            576.3541
Q Predictions Max            6052.443
Q Predictions Min            3721.6418
V Predictions Mean           5374.921
V Predictions Std            576.30444
V Predictions Max            6019.5864
V Predictions Min            3700.6055
Log Pis Mean                 6.4510536
Log Pis Std                  3.8560164
Log Pis Max                  18.29361
Log Pis Min                  -8.124022
Policy mu Mean               0.042541534
Policy mu Std                1.4668573
Policy mu Max                3.2278142
Policy mu Min                -2.738926
Policy log std Mean          -0.97525173
Policy log std Std           0.50289637
Policy log std Max           -0.26137745
Policy log std Min           -3.5046096
Z mean eval                  3.5541706
Z variance eval              0.010248121
total_rewards                [12980.43048962 12989.54969756 13306.46338979 13272.44584213
 12885.83517348 13151.84232132 12960.90512987 12861.94368326
 13079.80970355 13033.35953202]
total_rewards_mean           13052.258496259974
total_rewards_std            143.34898576488627
total_rewards_max            13306.463389793878
total_rewards_min            12861.943683257045
Number of train steps total  1908000
Number of env steps total    2387000
Number of rollouts total     0
Train Time (s)               114.11431391071528
(Previous) Eval Time (s)     22.706233971752226
Sample Time (s)              16.64960194239393
Epoch Time (s)               153.47014982486144
Total Train Time (s)         73990.61511813477
Epoch                        476
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:09:31.039587 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #476 | Epoch Duration: 153.42070484161377
2020-01-14 05:09:31.039904 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #476 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5535674
Z variance train             0.010257275
KL Divergence                76.14734
KL Loss                      7.614734
QF Loss                      777.99585
VF Loss                      246.11545
Policy Loss                  -5360.0454
Q Predictions Mean           5370.26
Q Predictions Std            685.4519
Q Predictions Max            6064.358
Q Predictions Min            981.7002
V Predictions Mean           5366.207
V Predictions Std            683.19836
V Predictions Max            6053.3286
V Predictions Min            1041.5502
Log Pis Mean                 6.333898
Log Pis Std                  3.719105
Log Pis Max                  16.964859
Log Pis Min                  -3.641591
Policy mu Mean               -0.08428076
Policy mu Std                1.4270923
Policy mu Max                3.9417408
Policy mu Min                -2.8982012
Policy log std Mean          -1.0112286
Policy log std Std           0.5185442
Policy log std Max           -0.16936052
Policy log std Min           -3.7464309
Z mean eval                  3.6512032
Z variance eval              0.014175232
total_rewards                [12905.88609365 12597.38154287 13028.17349538 12942.92575987
 12515.04929118 12853.09396668 12960.12867404 12310.48774012
 12465.92774961 12616.03348399]
total_rewards_mean           12719.508779739353
total_rewards_std            235.51983430342327
total_rewards_max            13028.173495377969
total_rewards_min            12310.487740123734
Number of train steps total  1912000
Number of env steps total    2392000
Number of rollouts total     0
Train Time (s)               115.22703768312931
(Previous) Eval Time (s)     22.656469046138227
Sample Time (s)              15.779647261369973
Epoch Time (s)               153.6631539906375
Total Train Time (s)         74144.27419028059
Epoch                        477
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:12:04.703044 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #477 | Epoch Duration: 153.66292309761047
2020-01-14 05:12:04.703286 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #477 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6493402
Z variance train             0.014066276
KL Divergence                76.8732
KL Loss                      7.68732
QF Loss                      994.155
VF Loss                      136.7248
Policy Loss                  -5405.8823
Q Predictions Mean           5416.2725
Q Predictions Std            620.39655
Q Predictions Max            6051.7407
Q Predictions Min            3581.726
V Predictions Mean           5409.4375
V Predictions Std            620.5391
V Predictions Max            6038.2886
V Predictions Min            3580.9727
Log Pis Mean                 6.6561856
Log Pis Std                  3.8070493
Log Pis Max                  18.499615
Log Pis Min                  -3.0586388
Policy mu Mean               -0.010981792
Policy mu Std                1.4550874
Policy mu Max                3.2135012
Policy mu Min                -2.701363
Policy log std Mean          -0.9879226
Policy log std Std           0.5372723
Policy log std Max           -0.19846046
Policy log std Min           -3.5378466
Z mean eval                  3.528078
Z variance eval              0.034230106
total_rewards                [ 1823.79081611  7223.80919177 10388.6984915   4660.2692856
  4147.95245377 12114.26930794  2879.9502964  13122.97172127
  5480.96559427 10550.69966123]
total_rewards_mean           7239.337681986258
total_rewards_std            3832.7336943944656
total_rewards_max            13122.97172126987
total_rewards_min            1823.7908161126086
Number of train steps total  1916000
Number of env steps total    2397000
Number of rollouts total     0
Train Time (s)               114.12058365670964
(Previous) Eval Time (s)     22.65594699513167
Sample Time (s)              17.057369150221348
Epoch Time (s)               153.83389980206266
Total Train Time (s)         74298.13416749611
Epoch                        478
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:14:38.565923 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #478 | Epoch Duration: 153.8624665737152
2020-01-14 05:14:38.566160 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #478 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5283768
Z variance train             0.033978716
KL Divergence                73.24462
KL Loss                      7.3244624
QF Loss                      523.8196
VF Loss                      112.00443
Policy Loss                  -5355.9644
Q Predictions Mean           5365.522
Q Predictions Std            628.2368
Q Predictions Max            6044.4526
Q Predictions Min            3578.1345
V Predictions Mean           5355.5137
V Predictions Std            627.68427
V Predictions Max            6050.415
V Predictions Min            3586.7964
Log Pis Mean                 6.351439
Log Pis Std                  3.9531841
Log Pis Max                  17.845264
Log Pis Min                  -4.6560574
Policy mu Mean               -0.06697291
Policy mu Std                1.4433032
Policy mu Max                3.263451
Policy mu Min                -2.7997048
Policy log std Mean          -0.995492
Policy log std Std           0.5224773
Policy log std Max           -0.32565737
Policy log std Min           -3.5895586
Z mean eval                  3.5324035
Z variance eval              0.031260338
total_rewards                [12978.96433477 12949.56225685 13342.8793088  13348.3858662
 13161.04447281 12995.21585342 13199.46980435 13162.41611698
 13167.84140913 12873.04751152]
total_rewards_mean           13117.882693484638
total_rewards_std            154.71754400380445
total_rewards_max            13348.385866201746
total_rewards_min            12873.047511522109
Number of train steps total  1920000
Number of env steps total    2402000
Number of rollouts total     0
Train Time (s)               117.3356073629111
(Previous) Eval Time (s)     22.684187688864768
Sample Time (s)              15.658706936985254
Epoch Time (s)               155.67850198876113
Total Train Time (s)         74453.92328050826
Epoch                        479
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:17:14.360263 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #479 | Epoch Duration: 155.79396724700928
2020-01-14 05:17:14.360466 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #479 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.53132
Z variance train             0.031418927
KL Divergence                72.56613
KL Loss                      7.2566133
QF Loss                      579.2805
VF Loss                      73.04822
Policy Loss                  -5361.237
Q Predictions Mean           5368.525
Q Predictions Std            623.401
Q Predictions Max            6074.7793
Q Predictions Min            3572.4797
V Predictions Mean           5362.123
V Predictions Std            622.71686
V Predictions Max            6041.369
V Predictions Min            3577.9604
Log Pis Mean                 6.372864
Log Pis Std                  3.539332
Log Pis Max                  15.276401
Log Pis Min                  -1.532776
Policy mu Mean               -0.06241096
Policy mu Std                1.425034
Policy mu Max                2.9443169
Policy mu Min                -2.6730273
Policy log std Mean          -0.98589617
Policy log std Std           0.5375068
Policy log std Max           -0.23591614
Policy log std Min           -3.682165
Z mean eval                  3.5299506
Z variance eval              0.025920134
total_rewards                [13181.13304212 12940.93174964 12862.65836516 13209.71617662
  1858.66011084 12821.80381028 13305.14825982 13044.5578955
 13158.64791011 13161.84465348]
total_rewards_mean           11954.510197355059
total_rewards_std            3368.6247147443073
total_rewards_max            13305.148259815318
total_rewards_min            1858.6601108364018
Number of train steps total  1924000
Number of env steps total    2407000
Number of rollouts total     0
Train Time (s)               120.45521801058203
(Previous) Eval Time (s)     22.799384942278266
Sample Time (s)              16.080142317339778
Epoch Time (s)               159.33474527020007
Total Train Time (s)         74612.91376024252
Epoch                        480
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:19:53.354635 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #480 | Epoch Duration: 158.9940164089203
2020-01-14 05:19:53.354824 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #480 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5296814
Z variance train             0.02595627
KL Divergence                73.47758
KL Loss                      7.347758
QF Loss                      1153.6465
VF Loss                      217.13991
Policy Loss                  -5288.818
Q Predictions Mean           5296.076
Q Predictions Std            609.2439
Q Predictions Max            5994.686
Q Predictions Min            3552.2524
V Predictions Mean           5284.548
V Predictions Std            608.7404
V Predictions Max            5980.2925
V Predictions Min            3565.3796
Log Pis Mean                 6.2655907
Log Pis Std                  3.7920468
Log Pis Max                  18.95657
Log Pis Min                  -3.7325354
Policy mu Mean               0.033901636
Policy mu Std                1.4352776
Policy mu Max                4.0021024
Policy mu Min                -2.922018
Policy log std Mean          -1.00819
Policy log std Std           0.5413265
Policy log std Max           -0.22608083
Policy log std Min           -3.3137264
Z mean eval                  3.6116567
Z variance eval              0.0136049045
total_rewards                [12105.64602594 12508.32248622 12526.73861645 12386.66613965
 12493.47528816 12460.82258167 12474.61191891 12562.3723577
 12378.40018828 12374.76612438]
total_rewards_mean           12427.182172735414
total_rewards_std            123.57257945170984
total_rewards_max            12562.372357698165
total_rewards_min            12105.646025939956
Number of train steps total  1928000
Number of env steps total    2412000
Number of rollouts total     0
Train Time (s)               120.28565428033471
(Previous) Eval Time (s)     22.458371792919934
Sample Time (s)              15.868911283556372
Epoch Time (s)               158.61293735681102
Total Train Time (s)         74772.77927478403
Epoch                        481
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:22:33.227322 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #481 | Epoch Duration: 159.87233352661133
2020-01-14 05:22:33.227655 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #481 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.6114242
Z variance train             0.013627035
KL Divergence                75.08388
KL Loss                      7.508388
QF Loss                      869.82275
VF Loss                      134.67523
Policy Loss                  -5405.114
Q Predictions Mean           5414.043
Q Predictions Std            630.1704
Q Predictions Max            6107.2646
Q Predictions Min            3655.1636
V Predictions Mean           5409.708
V Predictions Std            629.7812
V Predictions Max            6095.1934
V Predictions Min            3650.3455
Log Pis Mean                 6.3956203
Log Pis Std                  3.7142694
Log Pis Max                  17.019056
Log Pis Min                  -4.741676
Policy mu Mean               0.014601525
Policy mu Std                1.4333576
Policy mu Max                2.905946
Policy mu Min                -3.0147388
Policy log std Mean          -0.98765993
Policy log std Std           0.51769376
Policy log std Max           -0.20982122
Policy log std Min           -3.1989918
Z mean eval                  3.5371819
Z variance eval              0.025213424
total_rewards                [12835.52383876 13028.40743276 13173.43808186 12958.69236921
 12918.89620366 13191.98718426 13230.82386736 13225.7730182
 13007.94404595 13121.87706114]
total_rewards_mean           13069.33631031607
total_rewards_std            131.976658262216
total_rewards_max            13230.82386736249
total_rewards_min            12835.523838760268
Number of train steps total  1932000
Number of env steps total    2417000
Number of rollouts total     0
Train Time (s)               113.89703554287553
(Previous) Eval Time (s)     23.71746027097106
Sample Time (s)              16.644599173218012
Epoch Time (s)               154.2590949870646
Total Train Time (s)         74926.0390917589
Epoch                        482
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:25:06.495842 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #482 | Epoch Duration: 153.26790833473206
2020-01-14 05:25:06.496133 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #482 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5365689
Z variance train             0.025202721
KL Divergence                73.24543
KL Loss                      7.324543
QF Loss                      676.3805
VF Loss                      301.6175
Policy Loss                  -5380.4663
Q Predictions Mean           5389.319
Q Predictions Std            662.68646
Q Predictions Max            6090.076
Q Predictions Min            3626.7075
V Predictions Mean           5393.6816
V Predictions Std            662.1063
V Predictions Max            6079.799
V Predictions Min            3647.8372
Log Pis Mean                 5.9742007
Log Pis Std                  3.414237
Log Pis Max                  18.64941
Log Pis Min                  -4.3301873
Policy mu Mean               -0.051923543
Policy mu Std                1.418828
Policy mu Max                3.3133993
Policy mu Min                -3.0371492
Policy log std Mean          -0.9982552
Policy log std Std           0.5456761
Policy log std Max           -0.25682223
Policy log std Min           -3.5674071
Z mean eval                  3.5103173
Z variance eval              0.011686119
total_rewards                [12380.76163607 12959.54945668 12915.44683206 12822.15439067
 12971.50093977 13077.39336851 12574.3599587  13072.91927122
 12902.17872845 12913.91031291]
total_rewards_mean           12859.017489505895
total_rewards_std            208.65738527809853
total_rewards_max            13077.393368508167
total_rewards_min            12380.761636072699
Number of train steps total  1936000
Number of env steps total    2422000
Number of rollouts total     0
Train Time (s)               120.64464849093929
(Previous) Eval Time (s)     22.725974797271192
Sample Time (s)              15.799412985797971
Epoch Time (s)               159.17003627400845
Total Train Time (s)         75084.89256490581
Epoch                        483
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:27:45.353665 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #483 | Epoch Duration: 158.85730838775635
2020-01-14 05:27:45.353900 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #483 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5107853
Z variance train             0.011691274
KL Divergence                75.25512
KL Loss                      7.525512
QF Loss                      521.5545
VF Loss                      179.13857
Policy Loss                  -5399.8066
Q Predictions Mean           5411.3457
Q Predictions Std            678.533
Q Predictions Max            6076.2134
Q Predictions Min            601.6872
V Predictions Mean           5391.8965
V Predictions Std            676.3011
V Predictions Max            6060.599
V Predictions Min            609.83575
Log Pis Mean                 6.8575125
Log Pis Std                  3.8704925
Log Pis Max                  28.967442
Log Pis Min                  -2.8830347
Policy mu Mean               -0.03855654
Policy mu Std                1.4775474
Policy mu Max                3.9303863
Policy mu Min                -5.3106003
Policy log std Mean          -1.0019749
Policy log std Std           0.524785
Policy log std Max           -0.21973205
Policy log std Min           -3.5260131
Z mean eval                  3.5300603
Z variance eval              0.015668482
total_rewards                [13096.01315282 13218.59004187 12963.78348001 13210.66093337
 13095.14949594 13254.73370641 13362.12182165 13282.73632024
 12894.70897824 13243.30122178]
total_rewards_mean           13162.179915232216
total_rewards_std            139.62913738785429
total_rewards_max            13362.121821646859
total_rewards_min            12894.708978235874
Number of train steps total  1940000
Number of env steps total    2427000
Number of rollouts total     0
Train Time (s)               117.5146568827331
(Previous) Eval Time (s)     22.412962111178786
Sample Time (s)              16.605829945299774
Epoch Time (s)               156.53344893921167
Total Train Time (s)         75241.42381233582
Epoch                        484
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:30:21.888655 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #484 | Epoch Duration: 156.53457283973694
2020-01-14 05:30:21.888866 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #484 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.531596
Z variance train             0.015768113
KL Divergence                75.4456
KL Loss                      7.5445604
QF Loss                      666.58954
VF Loss                      157.70703
Policy Loss                  -5440.163
Q Predictions Mean           5448.032
Q Predictions Std            675.1172
Q Predictions Max            6026.159
Q Predictions Min            -86.66032
V Predictions Mean           5435.8525
V Predictions Std            672.11096
V Predictions Max            6000.15
V Predictions Min            -42.77907
Log Pis Mean                 6.5961676
Log Pis Std                  4.091284
Log Pis Max                  17.511505
Log Pis Min                  -5.1442723
Policy mu Mean               -0.0659995
Policy mu Std                1.473244
Policy mu Max                3.0268018
Policy mu Min                -2.8074257
Policy log std Mean          -1.0043008
Policy log std Std           0.5292717
Policy log std Max           -0.108913064
Policy log std Min           -3.446175
Z mean eval                  3.516185
Z variance eval              0.010385848
total_rewards                [12855.49132327 13273.88086086 12983.22710522 13237.6231437
 13165.60617594 13075.29359786 13002.47902424 13209.17538403
 13158.29855263 13193.95796921]
total_rewards_mean           13115.503313697609
total_rewards_std            126.00101630139287
total_rewards_max            13273.880860862451
total_rewards_min            12855.491323274064
Number of train steps total  1944000
Number of env steps total    2432000
Number of rollouts total     0
Train Time (s)               115.94744376465678
(Previous) Eval Time (s)     22.41379124019295
Sample Time (s)              15.50751801719889
Epoch Time (s)               153.86875302204862
Total Train Time (s)         75396.16401904961
Epoch                        485
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:32:56.634081 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #485 | Epoch Duration: 154.74505352973938
2020-01-14 05:32:56.634374 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #485 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5156448
Z variance train             0.010367336
KL Divergence                77.35645
KL Loss                      7.7356453
QF Loss                      662.51074
VF Loss                      186.79854
Policy Loss                  -5415.474
Q Predictions Mean           5422.0234
Q Predictions Std            616.1584
Q Predictions Max            6079.1147
Q Predictions Min            3219.4338
V Predictions Mean           5419.9062
V Predictions Std            614.2181
V Predictions Max            6071.305
V Predictions Min            3306.1196
Log Pis Mean                 6.4501176
Log Pis Std                  3.553695
Log Pis Max                  15.665527
Log Pis Min                  -4.214583
Policy mu Mean               -0.09329056
Policy mu Std                1.4500668
Policy mu Max                3.366591
Policy mu Min                -2.786057
Policy log std Mean          -0.9690632
Policy log std Std           0.53407997
Policy log std Max           0.10267365
Policy log std Min           -3.388239
Z mean eval                  3.581747
Z variance eval              0.027802413
total_rewards                [13105.32726992 13246.25903206 13008.37281602 13264.89898436
 13129.55858119 13406.90739607 13305.77042937 13080.0307657
 13277.14645722 13016.06057353]
total_rewards_mean           13184.033230543419
total_rewards_std            127.52421566994738
total_rewards_max            13406.907396067087
total_rewards_min            13008.372816016034
Number of train steps total  1948000
Number of env steps total    2437000
Number of rollouts total     0
Train Time (s)               112.85969808278605
(Previous) Eval Time (s)     23.289781959261745
Sample Time (s)              16.2569846464321
Epoch Time (s)               152.4064646884799
Total Train Time (s)         75548.12824703753
Epoch                        486
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:35:28.605415 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #486 | Epoch Duration: 151.970787525177
2020-01-14 05:35:28.605711 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #486 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5809522
Z variance train             0.027947927
KL Divergence                75.29759
KL Loss                      7.5297594
QF Loss                      548.081
VF Loss                      232.9002
Policy Loss                  -5439.107
Q Predictions Mean           5450.8853
Q Predictions Std            593.35693
Q Predictions Max            6063.868
Q Predictions Min            3662.1174
V Predictions Mean           5451.756
V Predictions Std            592.0936
V Predictions Max            6067.0117
V Predictions Min            3647.3682
Log Pis Mean                 6.1955276
Log Pis Std                  3.7521346
Log Pis Max                  19.080795
Log Pis Min                  -2.762765
Policy mu Mean               -0.02335324
Policy mu Std                1.4242858
Policy mu Max                3.6677737
Policy mu Min                -3.325457
Policy log std Mean          -0.98762554
Policy log std Std           0.52788913
Policy log std Max           -0.06803143
Policy log std Min           -3.2360375
Z mean eval                  3.5394256
Z variance eval              0.007858206
total_rewards                [12339.22872651  2178.74012012 12406.1593703  12842.91185885
 12913.48521626 12598.16612532 12689.55806856  2138.87016487
 13002.9702648  12521.08303876]
total_rewards_mean           10563.117295435364
total_rewards_std            4206.999825534546
total_rewards_max            13002.970264796508
total_rewards_min            2138.87016487123
Number of train steps total  1952000
Number of env steps total    2442000
Number of rollouts total     0
Train Time (s)               112.63330550072715
(Previous) Eval Time (s)     22.85378688108176
Sample Time (s)              17.272118663880974
Epoch Time (s)               152.75921104568988
Total Train Time (s)         75701.85008374415
Epoch                        487
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:38:02.334459 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #487 | Epoch Duration: 153.72850155830383
2020-01-14 05:38:02.334739 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #487 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5376499
Z variance train             0.007839267
KL Divergence                78.36119
KL Loss                      7.836119
QF Loss                      785.8553
VF Loss                      316.54315
Policy Loss                  -5384.0566
Q Predictions Mean           5397.079
Q Predictions Std            620.60187
Q Predictions Max            6083.5493
Q Predictions Min            3694.2212
V Predictions Mean           5397.9365
V Predictions Std            623.9703
V Predictions Max            6094.936
V Predictions Min            3681.562
Log Pis Mean                 6.44336
Log Pis Std                  3.8074033
Log Pis Max                  21.364323
Log Pis Min                  -4.6856623
Policy mu Mean               -0.029482735
Policy mu Std                1.4652374
Policy mu Max                3.6917772
Policy mu Min                -3.4079986
Policy log std Mean          -0.9726841
Policy log std Std           0.5059098
Policy log std Max           -0.19169676
Policy log std Min           -3.3264933
Z mean eval                  3.5394263
Z variance eval              0.008829357
total_rewards                [12937.94245513 13056.94272306 13087.43594207 13091.11452778
 12968.16508653 13372.90333976 13114.02231951 12887.33521125
 12813.31607553 13138.49057047]
total_rewards_mean           13046.76682511094
total_rewards_std            148.64874256851235
total_rewards_max            13372.903339762284
total_rewards_min            12813.316075528719
Number of train steps total  1956000
Number of env steps total    2447000
Number of rollouts total     0
Train Time (s)               119.66712308814749
(Previous) Eval Time (s)     23.82276271423325
Sample Time (s)              15.881980582606047
Epoch Time (s)               159.3718663849868
Total Train Time (s)         75859.76037281333
Epoch                        488
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:40:40.248676 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #488 | Epoch Duration: 157.91374373435974
2020-01-14 05:40:40.248887 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #488 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.538834
Z variance train             0.008823304
KL Divergence                78.030556
KL Loss                      7.803056
QF Loss                      591.52795
VF Loss                      143.24841
Policy Loss                  -5396.154
Q Predictions Mean           5403.9326
Q Predictions Std            626.2992
Q Predictions Max            6087.698
Q Predictions Min            983.3869
V Predictions Mean           5400.547
V Predictions Std            629.3366
V Predictions Max            6091.955
V Predictions Min            808.2163
Log Pis Mean                 6.667535
Log Pis Std                  3.4981043
Log Pis Max                  16.477394
Log Pis Min                  -3.0308135
Policy mu Mean               -0.06519016
Policy mu Std                1.4836401
Policy mu Max                3.5973177
Policy mu Min                -5.2111864
Policy log std Mean          -0.9907837
Policy log std Std           0.5284662
Policy log std Max           0.7735534
Policy log std Min           -3.6539207
Z mean eval                  3.5777855
Z variance eval              0.0075131305
total_rewards                [13204.55194145 13270.82798691 13356.04272202 13158.07559814
 13376.94419194 13419.08730584 13243.26268264 13237.77328122
 13302.82793824 13257.59366858]
total_rewards_mean           13282.698731696466
total_rewards_std            76.97473539452872
total_rewards_max            13419.087305838859
total_rewards_min            13158.075598139298
Number of train steps total  1960000
Number of env steps total    2452000
Number of rollouts total     0
Train Time (s)               118.0360409449786
(Previous) Eval Time (s)     22.364352153614163
Sample Time (s)              15.695122501812875
Epoch Time (s)               156.09551560040563
Total Train Time (s)         76016.38726301212
Epoch                        489
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:43:16.877795 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #489 | Epoch Duration: 156.62878561019897
2020-01-14 05:43:16.877953 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #489 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5765393
Z variance train             0.007514718
KL Divergence                78.726265
KL Loss                      7.872627
QF Loss                      793.1472
VF Loss                      378.24683
Policy Loss                  -5427.8247
Q Predictions Mean           5440.259
Q Predictions Std            714.3324
Q Predictions Max            6107.1416
Q Predictions Min            1013.5117
V Predictions Mean           5443.2295
V Predictions Std            712.6535
V Predictions Max            6114.5635
V Predictions Min            1084.469
Log Pis Mean                 6.3051243
Log Pis Std                  3.69406
Log Pis Max                  16.720991
Log Pis Min                  -3.777493
Policy mu Mean               -0.051121235
Policy mu Std                1.4336524
Policy mu Max                4.204022
Policy mu Min                -3.0303357
Policy log std Mean          -0.99995154
Policy log std Std           0.5209066
Policy log std Max           0.49594498
Policy log std Min           -3.5478387
Z mean eval                  3.567079
Z variance eval              0.009188113
total_rewards                [12645.66837691 13153.00148743 13082.36786981 13256.45044886
 13031.20157697 13178.5525218  13284.59954463 13045.72029828
 13219.27589596 12927.22811874]
total_rewards_mean           13082.406613940733
total_rewards_std            179.70047466279672
total_rewards_max            13284.59954463122
total_rewards_min            12645.668376913358
Number of train steps total  1964000
Number of env steps total    2457000
Number of rollouts total     0
Train Time (s)               113.59463269915432
(Previous) Eval Time (s)     22.89733713492751
Sample Time (s)              15.732187456917018
Epoch Time (s)               152.22415729099885
Total Train Time (s)         76168.02830390818
Epoch                        490
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:45:48.527346 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #490 | Epoch Duration: 151.64923524856567
2020-01-14 05:45:48.527637 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #490 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5681596
Z variance train             0.00916822
KL Divergence                76.89708
KL Loss                      7.689708
QF Loss                      656.6394
VF Loss                      240.49956
Policy Loss                  -5477.314
Q Predictions Mean           5479.536
Q Predictions Std            600.69806
Q Predictions Max            6123.8306
Q Predictions Min            3697.8584
V Predictions Mean           5465.415
V Predictions Std            599.981
V Predictions Max            6098.2676
V Predictions Min            3680.4092
Log Pis Mean                 6.215776
Log Pis Std                  3.8299754
Log Pis Max                  17.51551
Log Pis Min                  -3.3849795
Policy mu Mean               -0.06577774
Policy mu Std                1.4083719
Policy mu Max                3.332422
Policy mu Min                -3.052981
Policy log std Mean          -1.0093247
Policy log std Std           0.5246599
Policy log std Max           -0.40192816
Policy log std Min           -3.496281
Z mean eval                  3.5931919
Z variance eval              0.012799779
total_rewards                [12921.9221406  13346.92467919 12975.8983308  13282.1203848
 12968.77820231 13321.35176877 13404.98973729 13178.7272909
 13195.83293843 13221.84278052]
total_rewards_mean           13181.838825359204
total_rewards_std            162.40035525335207
total_rewards_max            13404.989737291411
total_rewards_min            12921.922140597206
Number of train steps total  1968000
Number of env steps total    2462000
Number of rollouts total     0
Train Time (s)               113.52604211913422
(Previous) Eval Time (s)     22.32209821091965
Sample Time (s)              16.450861254241318
Epoch Time (s)               152.29900158429518
Total Train Time (s)         76320.36095209932
Epoch                        491
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:48:20.865197 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #491 | Epoch Duration: 152.33733677864075
2020-01-14 05:48:20.865447 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #491 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5924206
Z variance train             0.012778605
KL Divergence                76.9573
KL Loss                      7.6957297
QF Loss                      525.38074
VF Loss                      153.63881
Policy Loss                  -5468.0054
Q Predictions Mean           5475.1543
Q Predictions Std            600.1372
Q Predictions Max            6093.298
Q Predictions Min            3654.4763
V Predictions Mean           5463.705
V Predictions Std            599.2377
V Predictions Max            6074.814
V Predictions Min            3644.0112
Log Pis Mean                 6.4812255
Log Pis Std                  3.590219
Log Pis Max                  20.131943
Log Pis Min                  -1.9055278
Policy mu Mean               -0.06002085
Policy mu Std                1.4541912
Policy mu Max                3.0060267
Policy mu Min                -2.9474053
Policy log std Mean          -0.9885846
Policy log std Std           0.5338541
Policy log std Max           -0.2946438
Policy log std Min           -3.4223049
Z mean eval                  3.5777917
Z variance eval              0.0074282996
total_rewards                [12669.59465127 13297.61865967 13092.53097226 12885.34443966
 12588.8993173  12928.29787624 11492.28763581 13160.18489899
 13114.23509424 13229.55385147]
total_rewards_mean           12845.854739689814
total_rewards_std            502.05479730726245
total_rewards_max            13297.61865966641
total_rewards_min            11492.287635805964
Number of train steps total  1972000
Number of env steps total    2467000
Number of rollouts total     0
Train Time (s)               117.97722209710628
(Previous) Eval Time (s)     22.360114466864616
Sample Time (s)              15.73214984452352
Epoch Time (s)               156.0694864084944
Total Train Time (s)         76476.63619829668
Epoch                        492
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:50:57.143327 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #492 | Epoch Duration: 156.27770519256592
2020-01-14 05:50:57.143490 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #492 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5779743
Z variance train             0.0074285455
KL Divergence                79.577866
KL Loss                      7.9577866
QF Loss                      1055.0818
VF Loss                      144.6442
Policy Loss                  -5490.9663
Q Predictions Mean           5500.001
Q Predictions Std            578.0813
Q Predictions Max            6106.4316
Q Predictions Min            3681.1902
V Predictions Mean           5498.768
V Predictions Std            575.831
V Predictions Max            6106.1562
V Predictions Min            3690.8044
Log Pis Mean                 6.357158
Log Pis Std                  3.5415657
Log Pis Max                  17.075954
Log Pis Min                  -3.421979
Policy mu Mean               -0.05619678
Policy mu Std                1.4402249
Policy mu Max                3.278336
Policy mu Min                -2.977169
Policy log std Mean          -0.9955985
Policy log std Std           0.5272695
Policy log std Max           -0.24442065
Policy log std Min           -3.4705014
Z mean eval                  3.5097604
Z variance eval              0.019751774
total_rewards                [12623.96337524  4559.69451222 13349.96398211 13298.42102465
 12722.55750241 13146.02189454 13233.91866068 13083.42399186
 13312.53584219  6632.51228216]
total_rewards_mean           11596.301306806226
total_rewards_std            3044.5121559784025
total_rewards_max            13349.96398211224
total_rewards_min            4559.694512222237
Number of train steps total  1976000
Number of env steps total    2472000
Number of rollouts total     0
Train Time (s)               114.17954267188907
(Previous) Eval Time (s)     22.5680509833619
Sample Time (s)              16.03111583646387
Epoch Time (s)               152.77870949171484
Total Train Time (s)         76629.34816748742
Epoch                        493
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:53:29.858517 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #493 | Epoch Duration: 152.7149040699005
2020-01-14 05:53:29.858753 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #493 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.508407
Z variance train             0.01984121
KL Divergence                78.58656
KL Loss                      7.8586564
QF Loss                      549.31104
VF Loss                      221.79742
Policy Loss                  -5485.284
Q Predictions Mean           5497.461
Q Predictions Std            565.40955
Q Predictions Max            6082.5
Q Predictions Min            3690.7922
V Predictions Mean           5496.071
V Predictions Std            563.60236
V Predictions Max            6085.752
V Predictions Min            3691.3816
Log Pis Mean                 6.524304
Log Pis Std                  3.5658092
Log Pis Max                  25.370937
Log Pis Min                  -2.9369206
Policy mu Mean               -0.030142495
Policy mu Std                1.4398198
Policy mu Max                3.3067746
Policy mu Min                -3.8519032
Policy log std Mean          -1.0017627
Policy log std Std           0.5239129
Policy log std Max           -0.08666992
Policy log std Min           -3.498178
Z mean eval                  3.5459213
Z variance eval              0.019402923
total_rewards                [13080.60741894 13379.2282909  13415.05502812 13315.65580635
 13216.03612728 13268.50658105 13136.77542255 13218.04076433
 13239.515232   13150.41263132]
total_rewards_mean           13241.983330284096
total_rewards_std            100.83143617162642
total_rewards_max            13415.05502811965
total_rewards_min            13080.607418940228
Number of train steps total  1980000
Number of env steps total    2477000
Number of rollouts total     0
Train Time (s)               116.51121239829808
(Previous) Eval Time (s)     22.503953936044127
Sample Time (s)              16.2820161934942
Epoch Time (s)               155.2971825278364
Total Train Time (s)         76784.55099266768
Epoch                        494
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:56:05.066406 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #494 | Epoch Duration: 155.20749831199646
2020-01-14 05:56:05.066628 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #494 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5475554
Z variance train             0.019329501
KL Divergence                79.08012
KL Loss                      7.908012
QF Loss                      428.50632
VF Loss                      318.42538
Policy Loss                  -5382.6167
Q Predictions Mean           5386.2554
Q Predictions Std            712.77124
Q Predictions Max            6079.098
Q Predictions Min            356.27267
V Predictions Mean           5370.8926
V Predictions Std            709.8478
V Predictions Max            6043.19
V Predictions Min            382.8947
Log Pis Mean                 6.280253
Log Pis Std                  3.8138106
Log Pis Max                  18.217474
Log Pis Min                  -6.348219
Policy mu Mean               -0.06917866
Policy mu Std                1.4329307
Policy mu Max                3.539236
Policy mu Min                -3.724547
Policy log std Mean          -0.97131795
Policy log std Std           0.49463516
Policy log std Max           0.020179749
Policy log std Min           -3.609963
Z mean eval                  3.5250843
Z variance eval              0.0103826225
total_rewards                [13049.56309655 12807.53732421 13166.87670718 13207.81566256
 13148.59947235 13027.42166142 13302.96064479 13171.23353143
 13175.22954    13282.44374369]
total_rewards_mean           13133.968138417671
total_rewards_std            136.19053980224768
total_rewards_max            13302.960644785811
total_rewards_min            12807.537324209567
Number of train steps total  1984000
Number of env steps total    2482000
Number of rollouts total     0
Train Time (s)               115.67095313593745
(Previous) Eval Time (s)     22.413949157111347
Sample Time (s)              16.378462272230536
Epoch Time (s)               154.46336456527933
Total Train Time (s)         76939.38410753198
Epoch                        495
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:58:39.906664 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #495 | Epoch Duration: 154.83979630470276
2020-01-14 05:58:39.906976 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #495 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5247726
Z variance train             0.01037926
KL Divergence                79.559494
KL Loss                      7.9559493
QF Loss                      792.51855
VF Loss                      136.81381
Policy Loss                  -5425.773
Q Predictions Mean           5433.271
Q Predictions Std            586.5724
Q Predictions Max            6106.385
Q Predictions Min            3516.7073
V Predictions Mean           5425.628
V Predictions Std            585.2097
V Predictions Max            6101.9414
V Predictions Min            3526.5874
Log Pis Mean                 6.1892424
Log Pis Std                  3.585325
Log Pis Max                  16.560675
Log Pis Min                  -3.3440812
Policy mu Mean               -0.048663557
Policy mu Std                1.433456
Policy mu Max                4.4710875
Policy mu Min                -2.8125024
Policy log std Mean          -1.0144702
Policy log std Std           0.5248443
Policy log std Max           -0.29206324
Policy log std Min           -3.5529194
Z mean eval                  3.535242
Z variance eval              0.02954402
total_rewards                [13039.97986948 13283.50259317 13151.79718726 12486.99593546
 12891.22201771 13122.38759934 13127.94399242 12695.64380506
 13273.36636105 13134.86503647]
total_rewards_mean           13020.770439741696
total_rewards_std            243.4348029423089
total_rewards_max            13283.502593171748
total_rewards_min            12486.99593545673
Number of train steps total  1988000
Number of env steps total    2487000
Number of rollouts total     0
Train Time (s)               110.7907543098554
(Previous) Eval Time (s)     22.79008462605998
Sample Time (s)              16.576596279162914
Epoch Time (s)               150.1574352150783
Total Train Time (s)         77089.29989318084
Epoch                        496
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:01:09.828283 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #496 | Epoch Duration: 149.92106533050537
2020-01-14 06:01:09.828565 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #496 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5355663
Z variance train             0.029753994
KL Divergence                77.57367
KL Loss                      7.757367
QF Loss                      524.7605
VF Loss                      263.2417
Policy Loss                  -5498.9917
Q Predictions Mean           5505.0166
Q Predictions Std            609.6139
Q Predictions Max            6086.3696
Q Predictions Min            3697.9338
V Predictions Mean           5505.5674
V Predictions Std            610.03125
V Predictions Max            6075.745
V Predictions Min            3695.3752
Log Pis Mean                 6.8117876
Log Pis Std                  4.2496953
Log Pis Max                  35.087498
Log Pis Min                  -2.7954261
Policy mu Mean               -0.016677374
Policy mu Std                1.4992661
Policy mu Max                4.4668894
Policy mu Min                -4.7212505
Policy log std Mean          -0.99245334
Policy log std Std           0.55375934
Policy log std Max           0.83842623
Policy log std Min           -3.654678
Z mean eval                  3.5123322
Z variance eval              0.031465676
total_rewards                [13040.1830823  12720.95533765 10243.93010292 13004.11027727
 13133.52591399 13390.98665866 13585.16061998 13380.34653373
 13355.53081081 13193.81399453]
total_rewards_mean           12904.85433318445
total_rewards_std            916.8769815140519
total_rewards_max            13585.160619984048
total_rewards_min            10243.930102917177
Number of train steps total  1992000
Number of env steps total    2492000
Number of rollouts total     0
Train Time (s)               114.7962974938564
(Previous) Eval Time (s)     22.553427605889738
Sample Time (s)              15.833653574809432
Epoch Time (s)               153.18337867455557
Total Train Time (s)         77242.36015869817
Epoch                        497
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:03:42.892759 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #497 | Epoch Duration: 153.06393241882324
2020-01-14 06:03:42.893008 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #497 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5125458
Z variance train             0.03145063
KL Divergence                75.798164
KL Loss                      7.5798163
QF Loss                      450.72357
VF Loss                      837.25525
Policy Loss                  -5397.2817
Q Predictions Mean           5400.4863
Q Predictions Std            626.301
Q Predictions Max            6081.3833
Q Predictions Min            3582.7349
V Predictions Mean           5391.9404
V Predictions Std            620.1979
V Predictions Max            6064.675
V Predictions Min            3657.3716
Log Pis Mean                 6.3442307
Log Pis Std                  3.6806257
Log Pis Max                  18.032822
Log Pis Min                  -3.9925804
Policy mu Mean               -0.052730884
Policy mu Std                1.4433185
Policy mu Max                3.583838
Policy mu Min                -3.6148045
Policy log std Mean          -0.9823968
Policy log std Std           0.5232692
Policy log std Max           0.03524387
Policy log std Min           -3.494501
Z mean eval                  3.4854445
Z variance eval              0.026212296
total_rewards                [  641.59379411 12562.38696189 12902.18548417 12650.45111384
 12716.08288084 12999.19701112 12770.69334513  3968.92087665
 12652.37223182 12582.95324625]
total_rewards_mean           10644.683694584057
total_rewards_std            4237.5307261192565
total_rewards_max            12999.197011124475
total_rewards_min            641.5937941134872
Number of train steps total  1996000
Number of env steps total    2497000
Number of rollouts total     0
Train Time (s)               120.6142520098947
(Previous) Eval Time (s)     22.43366262782365
Sample Time (s)              16.33241991698742
Epoch Time (s)               159.38033455470577
Total Train Time (s)         77402.60740650911
Epoch                        498
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:06:23.149182 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #498 | Epoch Duration: 160.2559950351715
2020-01-14 06:06:23.149479 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #498 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.486169
Z variance train             0.026179269
KL Divergence                75.33525
KL Loss                      7.533525
QF Loss                      458.76434
VF Loss                      179.34512
Policy Loss                  -5401.662
Q Predictions Mean           5410.197
Q Predictions Std            652.88947
Q Predictions Max            6098.799
Q Predictions Min            3682.8625
V Predictions Mean           5406.6235
V Predictions Std            653.1525
V Predictions Max            6116.443
V Predictions Min            3676.1536
Log Pis Mean                 6.121054
Log Pis Std                  3.4789212
Log Pis Max                  15.199281
Log Pis Min                  -3.6140442
Policy mu Mean               -0.016280213
Policy mu Std                1.4245265
Policy mu Max                4.0267596
Policy mu Min                -2.7911675
Policy log std Mean          -0.999335
Policy log std Std           0.5194811
Policy log std Max           -0.30896288
Policy log std Min           -3.3875186
Z mean eval                  3.4508567
Z variance eval              0.023422621
total_rewards                [ 2749.55094567 13202.05346797 13331.96107457 13308.59282149
 13086.38650616 13128.87281407 12938.62693464 13217.58737388
 12826.26452665 13029.45515842]
total_rewards_mean           12081.935162351188
total_rewards_std            3114.4142629511935
total_rewards_max            13331.96107456801
total_rewards_min            2749.550945667948
Number of train steps total  2000000
Number of env steps total    2502000
Number of rollouts total     0
Train Time (s)               121.78571936907247
(Previous) Eval Time (s)     23.30900694662705
Sample Time (s)              16.612434970680624
Epoch Time (s)               161.70716128638014
Total Train Time (s)         77563.67885782616
Epoch                        499
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:09:04.223060 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #499 | Epoch Duration: 161.07337832450867
2020-01-14 06:09:04.223295 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #499 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.45018
Z variance train             0.023387395
KL Divergence                74.97217
KL Loss                      7.4972167
QF Loss                      1805.5006
VF Loss                      208.32593
Policy Loss                  -5429.9624
Q Predictions Mean           5439.882
Q Predictions Std            633.43585
Q Predictions Max            6402.6367
Q Predictions Min            3650.9404
V Predictions Mean           5437.9736
V Predictions Std            632.3258
V Predictions Max            6513.3145
V Predictions Min            3667.4646
Log Pis Mean                 6.613641
Log Pis Std                  3.6687975
Log Pis Max                  17.154295
Log Pis Min                  -3.1847978
Policy mu Mean               -0.032986593
Policy mu Std                1.4572037
Policy mu Max                3.0571842
Policy mu Min                -2.8753426
Policy log std Mean          -0.9746943
Policy log std Std           0.52162105
Policy log std Max           -0.24986929
Policy log std Min           -3.343862
Z mean eval                  3.5101547
Z variance eval              0.014658803
total_rewards                [ 4603.98456055 13173.0699128  12484.03836218  6630.44047589
  7551.03063084  5979.32203556  9543.05267642 10159.91782209
   913.95345483  8485.0129242 ]
total_rewards_mean           7952.382285534256
total_rewards_std            3493.3000831833147
total_rewards_max            13173.069912797644
total_rewards_min            913.9534548342775
Number of train steps total  2004000
Number of env steps total    2507000
Number of rollouts total     0
Train Time (s)               115.35361867584288
(Previous) Eval Time (s)     22.67492461996153
Sample Time (s)              16.73574497550726
Epoch Time (s)               154.76428827131167
Total Train Time (s)         77718.71573483059
Epoch                        500
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:11:39.267195 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #500 | Epoch Duration: 155.0437047481537
2020-01-14 06:11:39.267483 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #500 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5120015
Z variance train             0.014701215
KL Divergence                76.56323
KL Loss                      7.6563234
QF Loss                      588.55615
VF Loss                      143.10033
Policy Loss                  -5388.2837
Q Predictions Mean           5394.1484
Q Predictions Std            658.66364
Q Predictions Max            6093.3823
Q Predictions Min            3654.3594
V Predictions Mean           5393.089
V Predictions Std            659.9464
V Predictions Max            6097.3594
V Predictions Min            3673.9583
Log Pis Mean                 6.2039566
Log Pis Std                  3.860566
Log Pis Max                  19.35127
Log Pis Min                  -4.7414846
Policy mu Mean               -0.091911614
Policy mu Std                1.4355865
Policy mu Max                3.2542756
Policy mu Min                -2.8430922
Policy log std Mean          -0.9849866
Policy log std Std           0.51928633
Policy log std Max           -0.20525825
Policy log std Min           -3.4181309
Z mean eval                  3.5486271
Z variance eval              0.018008474
total_rewards                [ 4244.31664222  5756.32592054 12279.65063494  1716.24764339
 11860.54313237  3599.98417291 12501.29055685 12798.18729265
  5012.32733466 12730.81944956]
total_rewards_mean           8249.969278006805
total_rewards_std            4303.142210562539
total_rewards_max            12798.18729265417
total_rewards_min            1716.2476433873671
Number of train steps total  2008000
Number of env steps total    2512000
Number of rollouts total     0
Train Time (s)               114.21886805677786
(Previous) Eval Time (s)     22.954012522939593
Sample Time (s)              15.741876946762204
Epoch Time (s)               152.91475752647966
Total Train Time (s)         77871.23170125578
Epoch                        501
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:14:11.788981 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #501 | Epoch Duration: 152.5212700366974
2020-01-14 06:14:11.789223 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #501 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5479608
Z variance train             0.017920628
KL Divergence                78.12283
KL Loss                      7.8122835
QF Loss                      974.7047
VF Loss                      329.0747
Policy Loss                  -5473.6445
Q Predictions Mean           5485.189
Q Predictions Std            615.0996
Q Predictions Max            6157.1753
Q Predictions Min            3698.2832
V Predictions Mean           5484.297
V Predictions Std            615.03564
V Predictions Max            6165.565
V Predictions Min            3694.9265
Log Pis Mean                 5.8615603
Log Pis Std                  3.2894003
Log Pis Max                  18.081985
Log Pis Min                  -3.2952504
Policy mu Mean               -0.006663665
Policy mu Std                1.432318
Policy mu Max                3.7074814
Policy mu Min                -2.7620707
Policy log std Mean          -0.9436302
Policy log std Std           0.48260415
Policy log std Max           -0.09895074
Policy log std Min           -3.5866165
Z mean eval                  3.5818756
Z variance eval              0.01770582
total_rewards                [1307.75094445 1081.40664972 7665.99735029 2888.19891196 4171.15718623
 1675.70075902 2092.76609578 1426.18260287 2393.4560583  2448.30815737]
total_rewards_mean           2715.0924715993187
total_rewards_std            1860.5006504174573
total_rewards_max            7665.997350294948
total_rewards_min            1081.4066497243216
Number of train steps total  2012000
Number of env steps total    2517000
Number of rollouts total     0
Train Time (s)               117.0890942090191
(Previous) Eval Time (s)     22.560264135710895
Sample Time (s)              16.532285004854202
Epoch Time (s)               156.1816433495842
Total Train Time (s)         78027.33874400612
Epoch                        502
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:16:47.900991 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #502 | Epoch Duration: 156.11158680915833
2020-01-14 06:16:47.901198 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #502 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5823464
Z variance train             0.017697478
KL Divergence                78.5317
KL Loss                      7.85317
QF Loss                      1715.634
VF Loss                      333.00885
Policy Loss                  -5481.137
Q Predictions Mean           5487.2495
Q Predictions Std            646.0357
Q Predictions Max            6161.6504
Q Predictions Min            3651.1064
V Predictions Mean           5481.5107
V Predictions Std            644.16003
V Predictions Max            6151.479
V Predictions Min            3657.0054
Log Pis Mean                 5.912306
Log Pis Std                  3.639995
Log Pis Max                  18.20922
Log Pis Min                  -3.2648535
Policy mu Mean               -0.016514359
Policy mu Std                1.4216018
Policy mu Max                4.0200152
Policy mu Min                -3.0781474
Policy log std Mean          -0.9291434
Policy log std Std           0.49425107
Policy log std Max           0.009354591
Policy log std Min           -3.5353827
Z mean eval                  3.6449857
Z variance eval              0.018373897
total_rewards                [ 370.8839011  -179.96010489  666.2543687   -99.30376046  782.42440983
  261.61573921 1087.18407082  203.34436617  574.21154044  -68.51561926]
total_rewards_mean           359.8138911666646
total_rewards_std            395.9038312270076
total_rewards_max            1087.1840708200373
total_rewards_min            -179.96010489372563
Number of train steps total  2016000
Number of env steps total    2522000
Number of rollouts total     0
Train Time (s)               113.75773151218891
(Previous) Eval Time (s)     22.489922178909183
Sample Time (s)              15.385707203764468
Epoch Time (s)               151.63336089486256
Total Train Time (s)         78179.09026092524
Epoch                        503
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:19:19.661654 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #503 | Epoch Duration: 151.7602677345276
2020-01-14 06:19:19.661955 UTC | [2020_01_11_13_23_39] [2020_01_11_23_31_34] [2020_01_13_08_36_18] Iteration #503 | Started Training: True
