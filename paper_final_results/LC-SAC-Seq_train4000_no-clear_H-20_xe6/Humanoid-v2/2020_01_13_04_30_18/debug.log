---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0041896636
Z variance train             0.6935758
KL Divergence                0.14877881
KL Loss                      0.014877881
QF Loss                      1077.6908
VF Loss                      133.73419
Policy Loss                  -11.531786
Q Predictions Mean           0.012762958
Q Predictions Std            0.014552694
Q Predictions Max            0.054910507
Q Predictions Min            -0.017390016
V Predictions Mean           0.001235443
V Predictions Std            0.014981115
V Predictions Max            0.04866788
V Predictions Min            -0.037118345
Log Pis Mean                 -11.435495
Log Pis Std                  0.8828459
Log Pis Max                  -8.004576
Log Pis Min                  -13.6958475
Policy mu Mean               0.00060793856
Policy mu Std                0.008607104
Policy mu Max                0.02766342
Policy mu Min                -0.030299714
Policy log std Mean          -0.0006233995
Policy log std Std           0.009405437
Policy log std Max           0.031497348
Policy log std Min           -0.03502097
Z mean eval                  0.02095649
Z variance eval              0.46604323
total_rewards                [ 89.46296927  83.11585364  95.30655365  83.40360074  83.32227654
 119.97605525  83.41124326  83.4999289  102.9672155   76.69575081]
total_rewards_mean           90.11614475582797
total_rewards_std            12.219603983335604
total_rewards_max            119.97605524885748
total_rewards_min            76.69575080638108
Number of train steps total  4000
Number of env steps total    7000
Number of rollouts total     0
Train Time (s)               204.26593184517696
(Previous) Eval Time (s)     0
Sample Time (s)              15.108672910835594
Epoch Time (s)               219.37460475601256
Total Train Time (s)         219.93515612045303
Epoch                        0
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:33:58.567482 UTC | [2020_01_13_04_30_18] Iteration #0 | Epoch Duration: 219.93848991394043
2020-01-13 04:33:58.567675 UTC | [2020_01_13_04_30_18] Iteration #0 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021308258
Z variance train             0.46587268
KL Divergence                0.59480107
KL Loss                      0.05948011
QF Loss                      38659.03
VF Loss                      9300.203
Policy Loss                  -99.08603
Q Predictions Mean           133.94751
Q Predictions Std            244.34888
Q Predictions Max            1066.6481
Q Predictions Min            18.244812
V Predictions Mean           142.12856
V Predictions Std            250.2823
V Predictions Max            1079.1759
V Predictions Min            28.634785
Log Pis Mean                 -6.6654205
Log Pis Std                  9.920384
Log Pis Max                  27.271656
Log Pis Min                  -13.367846
Policy mu Mean               -0.053917907
Policy mu Std                0.6423232
Policy mu Max                2.5236874
Policy mu Min                -2.2618213
Policy log std Mean          -0.20259863
Policy log std Std           0.1603128
Policy log std Max           -0.09075259
Policy log std Min           -0.8811023
Z mean eval                  0.048176117
Z variance eval              0.3387769
total_rewards                [66.2130519  70.6708073  66.32587735 70.94473525 66.39687091 70.84655814
 66.2495412  66.49908685 66.42180545 66.24239634]
total_rewards_mean           67.6810730701158
total_rewards_std            2.0579852945919526
total_rewards_max            70.94473525172641
total_rewards_min            66.21305190365736
Number of train steps total  8000
Number of env steps total    12000
Number of rollouts total     0
Train Time (s)               212.77627434860915
(Previous) Eval Time (s)     0.5635602339170873
Sample Time (s)              12.750789484474808
Epoch Time (s)               226.09062406700104
Total Train Time (s)         445.84727338235825
Epoch                        1
---------------------------  --------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:37:44.479718 UTC | [2020_01_13_04_30_18] Iteration #1 | Epoch Duration: 225.91186237335205
2020-01-13 04:37:44.479900 UTC | [2020_01_13_04_30_18] Iteration #1 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04792937
Z variance train             0.33879447
KL Divergence                1.1120052
KL Loss                      0.11120053
QF Loss                      14586.59
VF Loss                      8446.099
Policy Loss                  -130.32622
Q Predictions Mean           136.1879
Q Predictions Std            372.2228
Q Predictions Max            2053.3262
Q Predictions Min            16.460854
V Predictions Mean           154.00853
V Predictions Std            392.40497
V Predictions Max            2156.3286
V Predictions Min            25.319992
Log Pis Mean                 -7.7452297
Log Pis Std                  10.786425
Log Pis Max                  34.377235
Log Pis Min                  -13.790083
Policy mu Mean               0.054775055
Policy mu Std                0.58223873
Policy mu Max                2.5942993
Policy mu Min                -2.3808908
Policy log std Mean          -0.18291233
Policy log std Std           0.13725889
Policy log std Max           -0.08850606
Policy log std Min           -0.8367494
Z mean eval                  0.043388914
Z variance eval              0.21203776
total_rewards                [81.4097908  86.50891734 92.6064982  91.96754466 86.85804818 81.59115494
 91.33004316 76.32988589 76.14690641 80.56926438]
total_rewards_mean           84.53180539579381
total_rewards_std            5.896621424810764
total_rewards_max            92.60649819826101
total_rewards_min            76.14690640699952
Number of train steps total  12000
Number of env steps total    17000
Number of rollouts total     0
Train Time (s)               207.31280856393278
(Previous) Eval Time (s)     0.38450770592316985
Sample Time (s)              12.03334287693724
Epoch Time (s)               219.7306591467932
Total Train Time (s)         665.7699847519398
Epoch                        2
---------------------------  --------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:41:24.403999 UTC | [2020_01_13_04_30_18] Iteration #2 | Epoch Duration: 219.92395424842834
2020-01-13 04:41:24.404168 UTC | [2020_01_13_04_30_18] Iteration #2 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043531723
Z variance train             0.2119647
KL Divergence                2.038206
KL Loss                      0.20382062
QF Loss                      34248.23
VF Loss                      2290.0034
Policy Loss                  -114.25239
Q Predictions Mean           111.34545
Q Predictions Std            389.03864
Q Predictions Max            3541.3318
Q Predictions Min            13.978962
V Predictions Mean           127.667755
V Predictions Std            418.08246
V Predictions Max            3543.913
V Predictions Min            24.546158
Log Pis Mean                 -9.046454
Log Pis Std                  8.181458
Log Pis Max                  38.15178
Log Pis Min                  -13.396572
Policy mu Mean               -0.0068132537
Policy mu Std                0.4840243
Policy mu Max                2.887839
Policy mu Min                -2.9179032
Policy log std Mean          -0.17217255
Policy log std Std           0.1200215
Policy log std Max           -0.008182608
Policy log std Min           -1.1238027
Z mean eval                  0.01857021
Z variance eval              0.12426291
total_rewards                [71.04900045 86.1956567  78.92144027 71.07072715 71.06134538 71.02847898
 76.20233352 71.25173549 71.19598332 71.04735695]
total_rewards_mean           73.9024058201009
total_rewards_std            4.864132786706011
total_rewards_max            86.195656701591
total_rewards_min            71.02847898066318
Number of train steps total  16000
Number of env steps total    22000
Number of rollouts total     0
Train Time (s)               208.99074145406485
(Previous) Eval Time (s)     0.5775736710056663
Sample Time (s)              11.961987481918186
Epoch Time (s)               221.5303026069887
Total Train Time (s)         887.1742493263446
Epoch                        3
---------------------------  --------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:45:05.809048 UTC | [2020_01_13_04_30_18] Iteration #3 | Epoch Duration: 221.4047269821167
2020-01-13 04:45:05.809280 UTC | [2020_01_13_04_30_18] Iteration #3 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018692994
Z variance train             0.12427406
KL Divergence                3.238318
KL Loss                      0.3238318
QF Loss                      19769.674
VF Loss                      15986.977
Policy Loss                  -267.1113
Q Predictions Mean           219.36624
Q Predictions Std            927.95874
Q Predictions Max            7990.818
Q Predictions Min            13.025439
V Predictions Mean           286.565
V Predictions Std            1117.0958
V Predictions Max            7953.437
V Predictions Min            13.4391365
Log Pis Mean                 -7.5805807
Log Pis Std                  13.183317
Log Pis Max                  59.32447
Log Pis Min                  -13.316786
Policy mu Mean               0.038748592
Policy mu Std                0.62333137
Policy mu Max                3.6631973
Policy mu Min                -3.713913
Policy log std Mean          -0.18560041
Policy log std Std           0.1779136
Policy log std Max           0.017044067
Policy log std Min           -2.3999412
Z mean eval                  0.019548759
Z variance eval              0.08385299
total_rewards                [153.71216387 144.36190239 121.3592222  117.89784429 145.61000968
 163.23526726 122.1542896  150.63396223 125.52532511 128.37293768]
total_rewards_mean           137.28629243056838
total_rewards_std            15.22168388721922
total_rewards_max            163.23526726073717
total_rewards_min            117.89784429249728
Number of train steps total  20000
Number of env steps total    27000
Number of rollouts total     0
Train Time (s)               207.38818511599675
(Previous) Eval Time (s)     0.45176186319440603
Sample Time (s)              12.00193158024922
Epoch Time (s)               219.84187855944037
Total Train Time (s)         1107.4292951654643
Epoch                        4
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:48:46.063884 UTC | [2020_01_13_04_30_18] Iteration #4 | Epoch Duration: 220.25444912910461
2020-01-13 04:48:46.064003 UTC | [2020_01_13_04_30_18] Iteration #4 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020267084
Z variance train             0.083877996
KL Divergence                4.099314
KL Loss                      0.40993142
QF Loss                      355294.12
VF Loss                      167538.03
Policy Loss                  -717.87054
Q Predictions Mean           676.6013
Q Predictions Std            2499.815
Q Predictions Max            16123.021
Q Predictions Min            15.561525
V Predictions Mean           785.8436
V Predictions Std            2797.2307
V Predictions Max            17713.559
V Predictions Min            18.179424
Log Pis Mean                 -5.309043
Log Pis Std                  18.553844
Log Pis Max                  73.27833
Log Pis Min                  -15.11742
Policy mu Mean               -0.04014877
Policy mu Std                0.8142893
Policy mu Max                4.469491
Policy mu Min                -4.1603866
Policy log std Mean          -0.2127456
Policy log std Std           0.25095654
Policy log std Max           0.012409627
Policy log std Min           -3.147727
Z mean eval                  0.026672
Z variance eval              0.052862626
total_rewards                [ 93.7857      92.85140363 104.31773784  98.41323177  93.90638116
  98.83050333  95.25431073  94.82255685  89.44215085  93.61147472]
total_rewards_mean           95.52354508754736
total_rewards_std            3.880760150872917
total_rewards_max            104.31773784038802
total_rewards_min            89.44215084615318
Number of train steps total  24000
Number of env steps total    32000
Number of rollouts total     0
Train Time (s)               210.26672205515206
(Previous) Eval Time (s)     0.8641531239263713
Sample Time (s)              12.333427073899657
Epoch Time (s)               223.4643022529781
Total Train Time (s)         1330.576036516577
Epoch                        5
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:52:29.214622 UTC | [2020_01_13_04_30_18] Iteration #5 | Epoch Duration: 223.15048384666443
2020-01-13 04:52:29.214874 UTC | [2020_01_13_04_30_18] Iteration #5 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026440676
Z variance train             0.052871875
KL Divergence                5.2962875
KL Loss                      0.52962875
QF Loss                      2103816.8
VF Loss                      445353.0
Policy Loss                  -948.6711
Q Predictions Mean           958.40265
Q Predictions Std            3293.7966
Q Predictions Max            23694.385
Q Predictions Min            9.365328
V Predictions Mean           1095.7954
V Predictions Std            3558.8938
V Predictions Max            24799.729
V Predictions Min            9.645875
Log Pis Mean                 -3.2445104
Log Pis Std                  21.85201
Log Pis Max                  74.83139
Log Pis Min                  -13.631825
Policy mu Mean               0.06321765
Policy mu Std                0.94916844
Policy mu Max                4.627154
Policy mu Min                -5.2293587
Policy log std Mean          -0.22177929
Policy log std Std           0.2426907
Policy log std Max           -0.023173481
Policy log std Min           -2.025083
Z mean eval                  0.035472028
Z variance eval              0.040992636
total_rewards                [259.5459     308.93747687 296.33964124 304.5671062  351.87103543
 303.99702938 243.41577327 345.53881354 309.28213191 344.65401371]
total_rewards_mean           306.81489215691613
total_rewards_std            33.68756381992081
total_rewards_max            351.87103543402804
total_rewards_min            243.41577327367705
Number of train steps total  28000
Number of env steps total    37000
Number of rollouts total     0
Train Time (s)               195.99220474809408
(Previous) Eval Time (s)     0.5500717828981578
Sample Time (s)              12.113516603596509
Epoch Time (s)               208.65579313458875
Total Train Time (s)         1540.2537356447428
Epoch                        6
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:55:58.890722 UTC | [2020_01_13_04_30_18] Iteration #6 | Epoch Duration: 209.67566752433777
2020-01-13 04:55:58.890832 UTC | [2020_01_13_04_30_18] Iteration #6 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03552427
Z variance train             0.040982887
KL Divergence                5.9956083
KL Loss                      0.59956086
QF Loss                      1075731.0
VF Loss                      123321.21
Policy Loss                  -806.646
Q Predictions Mean           824.5763
Q Predictions Std            3117.6865
Q Predictions Max            23132.078
Q Predictions Min            7.583593
V Predictions Mean           835.48065
V Predictions Std            3088.6472
V Predictions Max            23613.248
V Predictions Min            22.696566
Log Pis Mean                 -5.7125673
Log Pis Std                  17.773762
Log Pis Max                  71.26563
Log Pis Min                  -13.174145
Policy mu Mean               0.02090923
Policy mu Std                0.77212924
Policy mu Max                5.492174
Policy mu Min                -4.569234
Policy log std Mean          -0.21668532
Policy log std Std           0.27506548
Policy log std Max           -0.029992044
Policy log std Min           -2.3389735
Z mean eval                  0.029831786
Z variance eval              0.03325927
total_rewards                [ 80.7619545   75.8275527   80.80489725  80.96637434 101.83163033
 124.65796508  80.73238363  89.97480849  80.95905114  80.78871059]
total_rewards_mean           87.73053280566596
total_rewards_std            14.122638626219251
total_rewards_max            124.6579650842458
total_rewards_min            75.82755269735745
Number of train steps total  32000
Number of env steps total    42000
Number of rollouts total     0
Train Time (s)               195.42412251466885
(Previous) Eval Time (s)     1.569717874750495
Sample Time (s)              12.60138912126422
Epoch Time (s)               209.59522951068357
Total Train Time (s)         1748.7781658349559
Epoch                        7
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:59:27.416759 UTC | [2020_01_13_04_30_18] Iteration #7 | Epoch Duration: 208.5258228778839
2020-01-13 04:59:27.416923 UTC | [2020_01_13_04_30_18] Iteration #7 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029667234
Z variance train             0.033259157
KL Divergence                6.6428504
KL Loss                      0.66428506
QF Loss                      50363.13
VF Loss                      25937.486
Policy Loss                  -670.3402
Q Predictions Mean           542.25275
Q Predictions Std            2093.8738
Q Predictions Max            17355.014
Q Predictions Min            15.64802
V Predictions Mean           667.30145
V Predictions Std            2581.7273
V Predictions Max            18855.857
V Predictions Min            23.882858
Log Pis Mean                 -6.211299
Log Pis Std                  16.655819
Log Pis Max                  63.58352
Log Pis Min                  -16.301737
Policy mu Mean               -0.033370417
Policy mu Std                0.7546335
Policy mu Max                4.980165
Policy mu Min                -3.8674114
Policy log std Mean          -0.20825538
Policy log std Std           0.24846305
Policy log std Max           -0.057380132
Policy log std Min           -3.4296947
Z mean eval                  0.020719957
Z variance eval              0.028662633
total_rewards                [241.59735313 396.12204369 314.69593834 280.25808131 287.73368752
 378.79460707 305.28949801 310.21123517 266.36735597 296.16931585]
total_rewards_mean           307.72391160584783
total_rewards_std            45.051716747378954
total_rewards_max            396.12204368502296
total_rewards_min            241.59735313029503
Number of train steps total  36000
Number of env steps total    47000
Number of rollouts total     0
Train Time (s)               199.5718027469702
(Previous) Eval Time (s)     0.4999931789934635
Sample Time (s)              12.005664368160069
Epoch Time (s)               212.07746029412374
Total Train Time (s)         1961.8505030791275
Epoch                        8
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:03:00.489106 UTC | [2020_01_13_04_30_18] Iteration #8 | Epoch Duration: 213.07207226753235
2020-01-13 05:03:00.489211 UTC | [2020_01_13_04_30_18] Iteration #8 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021365415
Z variance train             0.02863073
KL Divergence                7.2023983
KL Loss                      0.7202398
QF Loss                      395250.53
VF Loss                      54870.742
Policy Loss                  -769.60126
Q Predictions Mean           695.4113
Q Predictions Std            2071.1055
Q Predictions Max            13633.278
Q Predictions Min            15.039899
V Predictions Mean           810.1526
V Predictions Std            2372.019
V Predictions Max            16109.913
V Predictions Min            22.198254
Log Pis Mean                 -3.8229547
Log Pis Std                  20.302404
Log Pis Max                  71.11529
Log Pis Min                  -14.422606
Policy mu Mean               0.1030007
Policy mu Std                0.89565635
Policy mu Max                4.5349355
Policy mu Min                -5.037664
Policy log std Mean          -0.22403516
Policy log std Std           0.24173217
Policy log std Max           0.015612051
Policy log std Min           -2.2553327
Z mean eval                  0.014646834
Z variance eval              0.024171585
total_rewards                [138.78091549 160.68015987 150.34523207 174.18206302 160.11375728
 138.25870647 131.87355549 160.34319729 131.21401074 142.77111329]
total_rewards_mean           148.85627109972967
total_rewards_std            13.757215732990128
total_rewards_max            174.18206301621433
total_rewards_min            131.21401074055737
Number of train steps total  40000
Number of env steps total    52000
Number of rollouts total     0
Train Time (s)               196.54005451407284
(Previous) Eval Time (s)     1.4943908820860088
Sample Time (s)              12.649012181907892
Epoch Time (s)               210.68345757806674
Total Train Time (s)         2171.7993037546985
Epoch                        9
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:06:30.438576 UTC | [2020_01_13_04_30_18] Iteration #9 | Epoch Duration: 209.94928121566772
2020-01-13 05:06:30.438680 UTC | [2020_01_13_04_30_18] Iteration #9 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014688574
Z variance train             0.024172034
KL Divergence                7.5873237
KL Loss                      0.7587324
QF Loss                      1712828.8
VF Loss                      325452.8
Policy Loss                  -1089.1947
Q Predictions Mean           987.5868
Q Predictions Std            3465.2126
Q Predictions Max            27882.963
Q Predictions Min            9.063799
V Predictions Mean           1146.0039
V Predictions Std            3964.1848
V Predictions Max            28982.408
V Predictions Min            8.995134
Log Pis Mean                 -3.067819
Log Pis Std                  22.834759
Log Pis Max                  86.81366
Log Pis Min                  -14.364859
Policy mu Mean               -0.019341173
Policy mu Std                0.97979784
Policy mu Max                7.3014755
Policy mu Min                -6.22442
Policy log std Mean          -0.23366424
Policy log std Std           0.28369385
Policy log std Max           0.043866187
Policy log std Min           -3.742084
Z mean eval                  0.012623508
Z variance eval              0.016570093
total_rewards                [267.51183425 287.01551891 305.73109472 274.35202765 277.0554259
 240.10163545 265.90264278 253.76965539 263.68068959 298.46539476]
total_rewards_mean           273.35859193895664
total_rewards_std            18.84856697864186
total_rewards_max            305.7310947182102
total_rewards_min            240.10163544927727
Number of train steps total  44000
Number of env steps total    57000
Number of rollouts total     0
Train Time (s)               196.23148200800642
(Previous) Eval Time (s)     0.7600051909685135
Sample Time (s)              12.228416757658124
Epoch Time (s)               209.21990395663306
Total Train Time (s)         2381.7736188773997
Epoch                        10
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:10:00.415542 UTC | [2020_01_13_04_30_18] Iteration #10 | Epoch Duration: 209.97674894332886
2020-01-13 05:10:00.415753 UTC | [2020_01_13_04_30_18] Iteration #10 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012947652
Z variance train             0.016572628
KL Divergence                8.297616
KL Loss                      0.8297616
QF Loss                      1026754.8
VF Loss                      152972.7
Policy Loss                  -1194.56
Q Predictions Mean           1154.7256
Q Predictions Std            3557.4644
Q Predictions Max            20844.81
Q Predictions Min            6.6100316
V Predictions Mean           1246.6267
V Predictions Std            3738.851
V Predictions Max            23731.621
V Predictions Min            -2.2994869
Log Pis Mean                 -3.7113912
Log Pis Std                  20.832111
Log Pis Max                  76.39926
Log Pis Min                  -14.976601
Policy mu Mean               0.084567
Policy mu Std                0.93925345
Policy mu Max                5.2775054
Policy mu Min                -4.364135
Policy log std Mean          -0.2246506
Policy log std Std           0.24053918
Policy log std Max           -0.043133274
Policy log std Min           -1.7691268
Z mean eval                  0.0076230625
Z variance eval              0.013062942
total_rewards                [259.98375847 238.44163192 315.49597249 332.91840701 312.04039737
 319.69152326 537.29733527 489.87369341 363.81209923 330.93815395]
total_rewards_mean           350.0492972369937
total_rewards_std            89.21271367950493
total_rewards_max            537.2973352669678
total_rewards_min            238.44163191991322
Number of train steps total  48000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               200.08477920107543
(Previous) Eval Time (s)     1.516594654880464
Sample Time (s)              12.715670788194984
Epoch Time (s)               214.31704464415088
Total Train Time (s)         2596.4700614511967
Epoch                        11
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:13:35.115642 UTC | [2020_01_13_04_30_18] Iteration #11 | Epoch Duration: 214.6997103691101
2020-01-13 05:13:35.115996 UTC | [2020_01_13_04_30_18] Iteration #11 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008103749
Z variance train             0.01307112
KL Divergence                8.874065
KL Loss                      0.8874065
QF Loss                      105916.16
VF Loss                      39085.42
Policy Loss                  -1321.5946
Q Predictions Mean           1251.8599
Q Predictions Std            3864.362
Q Predictions Max            19993.236
Q Predictions Min            9.556967
V Predictions Mean           1306.4839
V Predictions Std            3991.0356
V Predictions Max            21310.72
V Predictions Min            0.93827677
Log Pis Mean                 -5.0869718
Log Pis Std                  18.403574
Log Pis Max                  65.665146
Log Pis Min                  -14.062023
Policy mu Mean               0.025211548
Policy mu Std                0.8473516
Policy mu Max                4.7150607
Policy mu Min                -4.639477
Policy log std Mean          -0.20556217
Policy log std Std           0.20998812
Policy log std Max           0.02033171
Policy log std Min           -2.1961942
Z mean eval                  0.02201199
Z variance eval              0.011353416
total_rewards                [186.14367499 145.13383131 172.65847588 227.25624389 180.46471438
 238.65073594 191.9095069  170.31358971 200.74948115 220.85788116]
total_rewards_mean           193.41381352994742
total_rewards_std            27.416849189090126
total_rewards_max            238.6507359382332
total_rewards_min            145.1338313128601
Number of train steps total  52000
Number of env steps total    67000
Number of rollouts total     0
Train Time (s)               194.5610964219086
(Previous) Eval Time (s)     1.8989892788231373
Sample Time (s)              12.983790200203657
Epoch Time (s)               209.44387590093538
Total Train Time (s)         2805.3224273915403
Epoch                        12
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:17:03.965714 UTC | [2020_01_13_04_30_18] Iteration #12 | Epoch Duration: 208.84951424598694
2020-01-13 05:17:03.965826 UTC | [2020_01_13_04_30_18] Iteration #12 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021719363
Z variance train             0.011347624
KL Divergence                9.091851
KL Loss                      0.9091851
QF Loss                      451933.88
VF Loss                      32403.494
Policy Loss                  -1009.26105
Q Predictions Mean           992.79596
Q Predictions Std            2955.8914
Q Predictions Max            20765.549
Q Predictions Min            13.525948
V Predictions Mean           988.0492
V Predictions Std            2893.9304
V Predictions Max            20788.143
V Predictions Min            25.706993
Log Pis Mean                 -4.3106937
Log Pis Std                  18.784578
Log Pis Max                  68.075584
Log Pis Min                  -13.645096
Policy mu Mean               0.037108097
Policy mu Std                0.8717229
Policy mu Max                4.5830708
Policy mu Min                -4.909288
Policy log std Mean          -0.23033455
Policy log std Std           0.27483898
Policy log std Max           0.6238675
Policy log std Min           -3.798127
Z mean eval                  0.013929898
Z variance eval              0.010461743
total_rewards                [280.69830063 375.14330584 227.99869359 239.22678014 554.62571658
 475.25366112 226.07655522 462.53804115 328.07958895 491.45159262]
total_rewards_mean           366.1092235844391
total_rewards_std            116.64729631859767
total_rewards_max            554.625716582746
total_rewards_min            226.07655521744002
Number of train steps total  56000
Number of env steps total    72000
Number of rollouts total     0
Train Time (s)               196.5636133006774
(Previous) Eval Time (s)     1.304419412277639
Sample Time (s)              12.746874509844929
Epoch Time (s)               210.61490722279996
Total Train Time (s)         3016.5374722215347
Epoch                        13
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:20:35.185395 UTC | [2020_01_13_04_30_18] Iteration #13 | Epoch Duration: 211.21942925453186
2020-01-13 05:20:35.185664 UTC | [2020_01_13_04_30_18] Iteration #13 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014199036
Z variance train             0.01045921
KL Divergence                9.1601515
KL Loss                      0.91601515
QF Loss                      222350.56
VF Loss                      22531.047
Policy Loss                  -918.34625
Q Predictions Mean           784.4818
Q Predictions Std            2161.7756
Q Predictions Max            12289.197
Q Predictions Min            3.7144933
V Predictions Mean           911.69434
V Predictions Std            2664.1943
V Predictions Max            16335.323
V Predictions Min            22.447577
Log Pis Mean                 -3.923238
Log Pis Std                  19.037033
Log Pis Max                  78.02916
Log Pis Min                  -13.648029
Policy mu Mean               0.068996914
Policy mu Std                0.8557879
Policy mu Max                5.487876
Policy mu Min                -6.189232
Policy log std Mean          -0.2501347
Policy log std Std           0.34581098
Policy log std Max           0.070620745
Policy log std Min           -3.752587
Z mean eval                  0.03745878
Z variance eval              0.009880094
total_rewards                [282.07067052 360.37111242 306.16831097 332.80247379 310.63169312
 305.04620038 246.2291867  362.07654336 288.51119115 254.58276402]
total_rewards_mean           304.8490146439854
total_rewards_std            37.3136244223528
total_rewards_max            362.0765433593183
total_rewards_min            246.2291867018444
Number of train steps total  60000
Number of env steps total    77000
Number of rollouts total     0
Train Time (s)               200.76366246538237
(Previous) Eval Time (s)     1.9086543172597885
Sample Time (s)              13.170845420099795
Epoch Time (s)               215.84316220274195
Total Train Time (s)         3232.0067924768664
Epoch                        14
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:24:10.656482 UTC | [2020_01_13_04_30_18] Iteration #14 | Epoch Duration: 215.47057223320007
2020-01-13 05:24:10.656778 UTC | [2020_01_13_04_30_18] Iteration #14 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03756177
Z variance train             0.00987931
KL Divergence                9.195526
KL Loss                      0.9195526
QF Loss                      17193.375
VF Loss                      6889.1406
Policy Loss                  -611.9213
Q Predictions Mean           493.73773
Q Predictions Std            1210.6346
Q Predictions Max            4976.064
Q Predictions Min            13.711442
V Predictions Mean           631.9237
V Predictions Std            1770.4923
V Predictions Max            11400.695
V Predictions Min            20.750599
Log Pis Mean                 -4.9154243
Log Pis Std                  16.088259
Log Pis Max                  66.47757
Log Pis Min                  -14.603053
Policy mu Mean               0.07344207
Policy mu Std                0.7901331
Policy mu Max                4.4761147
Policy mu Min                -4.595596
Policy log std Mean          -0.25081366
Policy log std Std           0.3100962
Policy log std Max           0.079983816
Policy log std Min           -3.4238076
Z mean eval                  0.073282935
Z variance eval              0.009476928
total_rewards                [355.68681296 266.09320638 350.64647074 334.6445368  464.2754592
 187.7858617  306.60491306 267.57424922 568.64721732 297.2369358 ]
total_rewards_mean           339.91956631854094
total_rewards_std            102.43668209587021
total_rewards_max            568.6472173179642
total_rewards_min            187.78586169734962
Number of train steps total  64000
Number of env steps total    82000
Number of rollouts total     0
Train Time (s)               192.93773366091773
(Previous) Eval Time (s)     1.5358101748861372
Sample Time (s)              12.980258512310684
Epoch Time (s)               207.45380234811455
Total Train Time (s)         3440.058182266541
Epoch                        15
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:27:38.707066 UTC | [2020_01_13_04_30_18] Iteration #15 | Epoch Duration: 208.05007553100586
2020-01-13 05:27:38.707242 UTC | [2020_01_13_04_30_18] Iteration #15 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07351879
Z variance train             0.009478161
KL Divergence                9.289972
KL Loss                      0.9289972
QF Loss                      3749.3506
VF Loss                      2072.239
Policy Loss                  -244.03912
Q Predictions Mean           215.64499
Q Predictions Std            573.4172
Q Predictions Max            3238.5535
Q Predictions Min            14.822796
V Predictions Mean           249.7375
V Predictions Std            706.1946
V Predictions Max            6772.2397
V Predictions Min            23.869492
Log Pis Mean                 -8.154047
Log Pis Std                  10.150374
Log Pis Max                  55.749123
Log Pis Min                  -12.906457
Policy mu Mean               0.015200895
Policy mu Std                0.5514935
Policy mu Max                3.5982733
Policy mu Min                -3.4921067
Policy log std Mean          -0.20082407
Policy log std Std           0.20725262
Policy log std Max           0.070496425
Policy log std Min           -3.7631996
Z mean eval                  0.09825832
Z variance eval              0.011508925
total_rewards                [343.17794859 290.11532021 331.54129694 302.20048433 289.16810747
 313.20402266 395.99290585 349.67876567 260.78074379 219.42326488]
total_rewards_mean           309.5282860406506
total_rewards_std            46.96691332862427
total_rewards_max            395.992905850622
total_rewards_min            219.42326488372572
Number of train steps total  68000
Number of env steps total    87000
Number of rollouts total     0
Train Time (s)               194.7174280011095
(Previous) Eval Time (s)     2.1318687717430294
Sample Time (s)              13.029877880588174
Epoch Time (s)               209.8791746534407
Total Train Time (s)         3649.5750303734094
Epoch                        16
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:31:08.224000 UTC | [2020_01_13_04_30_18] Iteration #16 | Epoch Duration: 209.51662755012512
2020-01-13 05:31:08.224112 UTC | [2020_01_13_04_30_18] Iteration #16 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09859268
Z variance train             0.011508842
KL Divergence                8.839699
KL Loss                      0.8839699
QF Loss                      11666.821
VF Loss                      441.8193
Policy Loss                  -154.7073
Q Predictions Mean           137.35934
Q Predictions Std            291.9684
Q Predictions Max            1633.0137
Q Predictions Min            6.281156
V Predictions Mean           153.14508
V Predictions Std            332.3953
V Predictions Max            2792.9377
V Predictions Min            6.586907
Log Pis Mean                 -8.366137
Log Pis Std                  7.7742677
Log Pis Max                  43.01102
Log Pis Min                  -14.268904
Policy mu Mean               0.03229475
Policy mu Std                0.509429
Policy mu Max                3.165903
Policy mu Min                -3.0667262
Policy log std Mean          -0.19662464
Policy log std Std           0.18128592
Policy log std Max           -0.05015485
Policy log std Min           -3.2540631
Z mean eval                  0.07022804
Z variance eval              0.018555893
total_rewards                [366.61270714 370.31513855 338.84998655 406.06648817 373.71653995
 466.1444009  408.39918763 691.68069924 609.92675358 341.8251191 ]
total_rewards_mean           437.3537020798006
total_rewards_std            113.79221216686722
total_rewards_max            691.6806992352135
total_rewards_min            338.84998654637184
Number of train steps total  72000
Number of env steps total    92000
Number of rollouts total     0
Train Time (s)               197.98246689001098
(Previous) Eval Time (s)     1.7690989249385893
Sample Time (s)              12.779292629566044
Epoch Time (s)               212.53085844451562
Total Train Time (s)         3862.7812667512335
Epoch                        17
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:34:41.431128 UTC | [2020_01_13_04_30_18] Iteration #17 | Epoch Duration: 213.20692682266235
2020-01-13 05:34:41.431251 UTC | [2020_01_13_04_30_18] Iteration #17 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07034984
Z variance train             0.018558834
KL Divergence                7.614649
KL Loss                      0.7614649
QF Loss                      447.53897
VF Loss                      137.68709
Policy Loss                  -143.07819
Q Predictions Mean           133.87819
Q Predictions Std            232.01204
Q Predictions Max            997.4956
Q Predictions Min            13.46071
V Predictions Mean           144.16957
V Predictions Std            229.20045
V Predictions Max            1238.1692
V Predictions Min            25.494844
Log Pis Mean                 -8.742074
Log Pis Std                  6.214658
Log Pis Max                  37.66249
Log Pis Min                  -13.70006
Policy mu Mean               0.06698086
Policy mu Std                0.49279428
Policy mu Max                2.7040877
Policy mu Min                -2.4821765
Policy log std Mean          -0.19275169
Policy log std Std           0.15128647
Policy log std Max           -0.06420924
Policy log std Min           -3.0963898
Z mean eval                  0.027345678
Z variance eval              0.043665998
total_rewards                [615.32301512 357.97749328 350.51177747 271.86017442 408.8739268
 346.28345298 305.8162466  315.28941172 295.83288235 346.61613714]
total_rewards_mean           361.4384517871392
total_rewards_std            92.10872019720198
total_rewards_max            615.3230151248723
total_rewards_min            271.86017441829495
Number of train steps total  76000
Number of env steps total    97000
Number of rollouts total     0
Train Time (s)               195.53199189715087
(Previous) Eval Time (s)     2.4449021480977535
Sample Time (s)              13.685908807441592
Epoch Time (s)               211.66280285269022
Total Train Time (s)         4074.0992539399303
Epoch                        18
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:38:12.749890 UTC | [2020_01_13_04_30_18] Iteration #18 | Epoch Duration: 211.31855082511902
2020-01-13 05:38:12.750008 UTC | [2020_01_13_04_30_18] Iteration #18 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026954766
Z variance train             0.043647908
KL Divergence                5.6552353
KL Loss                      0.56552356
QF Loss                      398.81042
VF Loss                      83.20712
Policy Loss                  -129.11064
Q Predictions Mean           120.93851
Q Predictions Std            234.1334
Q Predictions Max            963.87756
Q Predictions Min            5.4233465
V Predictions Mean           132.71039
V Predictions Std            232.87662
V Predictions Max            951.7968
V Predictions Min            27.709824
Log Pis Mean                 -9.609346
Log Pis Std                  4.8547645
Log Pis Max                  7.8791018
Log Pis Min                  -15.515501
Policy mu Mean               0.06924671
Policy mu Std                0.406851
Policy mu Max                2.2979221
Policy mu Min                -1.8691201
Policy log std Mean          -0.17161575
Policy log std Std           0.09530267
Policy log std Max           -0.06109623
Policy log std Min           -0.6856673
Z mean eval                  0.014664041
Z variance eval              0.078587465
total_rewards                [318.62160706 380.89378299 313.05812044 331.36995212 373.24135116
 359.5356839  470.76599858 346.73629204 368.91997355 344.3583036 ]
total_rewards_mean           360.7501065428574
total_rewards_std            42.557166993118734
total_rewards_max            470.7659985796768
total_rewards_min            313.05812043861505
Number of train steps total  80000
Number of env steps total    102000
Number of rollouts total     0
Train Time (s)               196.22467539831996
(Previous) Eval Time (s)     2.1004156288690865
Sample Time (s)              13.218797111418098
Epoch Time (s)               211.54388813860714
Total Train Time (s)         4285.518688231707
Epoch                        19
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:41:44.170231 UTC | [2020_01_13_04_30_18] Iteration #19 | Epoch Duration: 211.42012786865234
2020-01-13 05:41:44.170367 UTC | [2020_01_13_04_30_18] Iteration #19 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01438354
Z variance train             0.078579985
KL Divergence                4.4087014
KL Loss                      0.44087014
QF Loss                      639.20557
VF Loss                      128.97832
Policy Loss                  -167.22667
Q Predictions Mean           155.18497
Q Predictions Std            274.0362
Q Predictions Max            1116.6382
Q Predictions Min            15.528707
V Predictions Mean           165.0656
V Predictions Std            271.72147
V Predictions Max            1095.1571
V Predictions Min            24.367104
Log Pis Mean                 -8.593729
Log Pis Std                  5.767299
Log Pis Max                  21.322262
Log Pis Min                  -14.510939
Policy mu Mean               0.08247007
Policy mu Std                0.4853811
Policy mu Max                2.357612
Policy mu Min                -2.2106752
Policy log std Mean          -0.19479458
Policy log std Std           0.13502552
Policy log std Max           -0.083622865
Policy log std Min           -2.1649318
Z mean eval                  0.009520386
Z variance eval              0.09558518
total_rewards                [288.68958325 486.92682992 291.46824032 350.7053027  491.61266837
 387.31543136 459.14687596 410.47524813 426.42228904 364.07763683]
total_rewards_mean           395.6840105887037
total_rewards_std            69.36824317624628
total_rewards_max            491.6126683702269
total_rewards_min            288.68958324845056
Number of train steps total  84000
Number of env steps total    107000
Number of rollouts total     0
Train Time (s)               202.6350695732981
(Previous) Eval Time (s)     1.9764066808857024
Sample Time (s)              13.025779959745705
Epoch Time (s)               217.6372562139295
Total Train Time (s)         4503.575650437269
Epoch                        20
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:45:22.227732 UTC | [2020_01_13_04_30_18] Iteration #20 | Epoch Duration: 218.0572738647461
2020-01-13 05:45:22.227846 UTC | [2020_01_13_04_30_18] Iteration #20 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009577039
Z variance train             0.09556284
KL Divergence                3.9350686
KL Loss                      0.39350685
QF Loss                      328.09525
VF Loss                      111.736626
Policy Loss                  -181.76895
Q Predictions Mean           174.02539
Q Predictions Std            318.5026
Q Predictions Max            1162.2897
Q Predictions Min            16.552135
V Predictions Mean           180.81111
V Predictions Std            309.53162
V Predictions Max            1125.8148
V Predictions Min            25.617151
Log Pis Mean                 -9.032327
Log Pis Std                  5.024802
Log Pis Max                  13.139429
Log Pis Min                  -13.920146
Policy mu Mean               0.091052115
Policy mu Std                0.44105554
Policy mu Max                2.1387472
Policy mu Min                -1.846887
Policy log std Mean          -0.18160096
Policy log std Std           0.10331465
Policy log std Max           -0.005681649
Policy log std Min           -0.72453827
Z mean eval                  0.010632491
Z variance eval              0.113184966
total_rewards                [318.03415793 320.01662134 370.10876576 340.02961001 304.95620757
 307.3164054  558.36344461 302.92787528 398.86485889 370.03453464]
total_rewards_mean           359.06524814242846
total_rewards_std            73.3988429250658
total_rewards_max            558.3634446136725
total_rewards_min            302.9278752811045
Number of train steps total  88000
Number of env steps total    112000
Number of rollouts total     0
Train Time (s)               198.6539279757999
(Previous) Eval Time (s)     2.396195058710873
Sample Time (s)              13.695295423269272
Epoch Time (s)               214.74541845778003
Total Train Time (s)         4717.74988191342
Epoch                        21
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:48:56.402970 UTC | [2020_01_13_04_30_18] Iteration #21 | Epoch Duration: 214.17503428459167
2020-01-13 05:48:56.403088 UTC | [2020_01_13_04_30_18] Iteration #21 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010195786
Z variance train             0.113162756
KL Divergence                3.3719049
KL Loss                      0.33719048
QF Loss                      286.67017
VF Loss                      261.83948
Policy Loss                  -176.86299
Q Predictions Mean           168.2167
Q Predictions Std            305.55252
Q Predictions Max            1198.1466
Q Predictions Min            16.505537
V Predictions Mean           178.9304
V Predictions Std            305.89023
V Predictions Max            1162.4287
V Predictions Min            26.89771
Log Pis Mean                 -9.047322
Log Pis Std                  5.374448
Log Pis Max                  13.045396
Log Pis Min                  -14.089529
Policy mu Mean               0.08589498
Policy mu Std                0.4545181
Policy mu Max                2.0390391
Policy mu Min                -1.8921596
Policy log std Mean          -0.18653171
Policy log std Std           0.11497014
Policy log std Max           -0.05602277
Policy log std Min           -1.1594715
Z mean eval                  0.014654873
Z variance eval              0.11765957
total_rewards                [321.30893972 447.19339635 380.2802064  398.53433079 319.01343484
 312.91008373 332.69880427 341.93644062 338.40749275 446.00426014]
total_rewards_mean           363.8287389608648
total_rewards_std            48.66338546457247
total_rewards_max            447.1933963538599
total_rewards_min            312.9100837307412
Number of train steps total  92000
Number of env steps total    117000
Number of rollouts total     0
Train Time (s)               200.36933112610132
(Previous) Eval Time (s)     1.8255424029193819
Sample Time (s)              13.360335810109973
Epoch Time (s)               215.55520933913067
Total Train Time (s)         4933.3948689503595
Epoch                        22
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:52:32.048770 UTC | [2020_01_13_04_30_18] Iteration #22 | Epoch Duration: 215.64558863639832
2020-01-13 05:52:32.048884 UTC | [2020_01_13_04_30_18] Iteration #22 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014552774
Z variance train             0.117648266
KL Divergence                3.2694964
KL Loss                      0.32694966
QF Loss                      274.72693
VF Loss                      138.5298
Policy Loss                  -218.65213
Q Predictions Mean           208.62277
Q Predictions Std            350.8387
Q Predictions Max            1191.7505
Q Predictions Min            16.394981
V Predictions Mean           218.73456
V Predictions Std            352.26675
V Predictions Max            1191.362
V Predictions Min            29.615217
Log Pis Mean                 -8.621971
Log Pis Std                  5.714759
Log Pis Max                  21.665886
Log Pis Min                  -13.687313
Policy mu Mean               0.091597386
Policy mu Std                0.4825801
Policy mu Max                2.2203128
Policy mu Min                -2.206541
Policy log std Mean          -0.19349183
Policy log std Std           0.120038934
Policy log std Max           -0.058404386
Policy log std Min           -1.204583
Z mean eval                  0.013991269
Z variance eval              0.12763989
total_rewards                [342.92593245 384.06181397 490.53805049 380.99813498 380.18999649
 369.92548457 351.99284088 310.43303699 506.00773859 417.96427334]
total_rewards_mean           393.50373027361536
total_rewards_std            59.018527499970126
total_rewards_max            506.0077385900618
total_rewards_min            310.43303698752214
Number of train steps total  96000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               198.33533609192818
(Previous) Eval Time (s)     1.9156718701124191
Sample Time (s)              13.408191715367138
Epoch Time (s)               213.65919967740774
Total Train Time (s)         5147.35356650129
Epoch                        23
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:56:06.008068 UTC | [2020_01_13_04_30_18] Iteration #23 | Epoch Duration: 213.95909237861633
2020-01-13 05:56:06.008182 UTC | [2020_01_13_04_30_18] Iteration #23 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01455299
Z variance train             0.12759306
KL Divergence                3.053575
KL Loss                      0.30535752
QF Loss                      302.54877
VF Loss                      164.88646
Policy Loss                  -187.37492
Q Predictions Mean           174.49039
Q Predictions Std            333.766
Q Predictions Max            1173.0774
Q Predictions Min            17.34683
V Predictions Mean           184.05154
V Predictions Std            333.18137
V Predictions Max            1204.9976
V Predictions Min            25.954258
Log Pis Mean                 -9.40027
Log Pis Std                  5.1319866
Log Pis Max                  20.210865
Log Pis Min                  -13.187483
Policy mu Mean               0.06420056
Policy mu Std                0.44297546
Policy mu Max                2.4912524
Policy mu Min                -2.3303082
Policy log std Mean          -0.18758237
Policy log std Std           0.12757884
Policy log std Max           -0.025465563
Policy log std Min           -1.4215288
Z mean eval                  0.030077925
Z variance eval              0.13747159
total_rewards                [529.00869639 353.43206275 281.42781032 388.96532854 373.23739388
 440.69594502 312.38801361 381.3795723  406.92991942 298.23790914]
total_rewards_mean           376.57026513785564
total_rewards_std            69.49960024452051
total_rewards_max            529.0086963921126
total_rewards_min            281.42781032008946
Number of train steps total  100000
Number of env steps total    127000
Number of rollouts total     0
Train Time (s)               196.6394672440365
(Previous) Eval Time (s)     2.215337439905852
Sample Time (s)              13.66157257463783
Epoch Time (s)               212.51637725858018
Total Train Time (s)         5359.736193506513
Epoch                        24
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:59:38.395216 UTC | [2020_01_13_04_30_18] Iteration #24 | Epoch Duration: 212.38689637184143
2020-01-13 05:59:38.395507 UTC | [2020_01_13_04_30_18] Iteration #24 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030482333
Z variance train             0.13746789
KL Divergence                2.9135497
KL Loss                      0.29135498
QF Loss                      212.67355
VF Loss                      128.29842
Policy Loss                  -161.41812
Q Predictions Mean           149.3876
Q Predictions Std            297.48233
Q Predictions Max            1210.2292
Q Predictions Min            17.968723
V Predictions Mean           158.78705
V Predictions Std            296.11868
V Predictions Max            1204.8167
V Predictions Min            26.664173
Log Pis Mean                 -9.555929
Log Pis Std                  4.598566
Log Pis Max                  11.969869
Log Pis Min                  -12.97344
Policy mu Mean               0.05471353
Policy mu Std                0.40487704
Policy mu Max                2.2436814
Policy mu Min                -1.9730868
Policy log std Mean          -0.17915633
Policy log std Std           0.11429418
Policy log std Max           -0.084702045
Policy log std Min           -1.1020883
Z mean eval                  0.05393555
Z variance eval              0.13953158
total_rewards                [396.2587757  540.8358392  386.67332803 309.76647895 527.10409559
 513.6747261  383.36450682 321.86686263 377.01332577 400.36502524]
total_rewards_mean           415.69229640285323
total_rewards_std            78.54513282044735
total_rewards_max            540.8358392017922
total_rewards_min            309.7664789526356
Number of train steps total  104000
Number of env steps total    132000
Number of rollouts total     0
Train Time (s)               193.59951613517478
(Previous) Eval Time (s)     2.0856039370410144
Sample Time (s)              13.571773287374526
Epoch Time (s)               209.25689335959032
Total Train Time (s)         5568.950559658464
Epoch                        25
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:03:07.608921 UTC | [2020_01_13_04_30_18] Iteration #25 | Epoch Duration: 209.21320366859436
2020-01-13 06:03:07.609068 UTC | [2020_01_13_04_30_18] Iteration #25 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.053443722
Z variance train             0.13942985
KL Divergence                2.8221176
KL Loss                      0.28221175
QF Loss                      300.88388
VF Loss                      200.36783
Policy Loss                  -223.5444
Q Predictions Mean           216.00319
Q Predictions Std            359.95047
Q Predictions Max            1221.7615
Q Predictions Min            11.373498
V Predictions Mean           226.14232
V Predictions Std            361.0132
V Predictions Max            1221.5095
V Predictions Min            21.394243
Log Pis Mean                 -9.032444
Log Pis Std                  4.7685127
Log Pis Max                  10.796114
Log Pis Min                  -14.831865
Policy mu Mean               0.097029604
Policy mu Std                0.45928508
Policy mu Max                2.0638227
Policy mu Min                -1.9435378
Policy log std Mean          -0.19533966
Policy log std Std           0.115264066
Policy log std Max           -0.027601928
Policy log std Min           -0.768764
Z mean eval                  0.057667382
Z variance eval              0.13146135
total_rewards                [410.05631491 395.10054095 325.83410553 357.86566177 425.16749208
 424.08672821 509.10841635 352.59963591 440.06134886 411.01253726]
total_rewards_mean           405.08927818404766
total_rewards_std            49.22723922890488
total_rewards_max            509.1084163483156
total_rewards_min            325.8341055347199
Number of train steps total  108000
Number of env steps total    137000
Number of rollouts total     0
Train Time (s)               198.06925900513306
(Previous) Eval Time (s)     2.041687846183777
Sample Time (s)              13.370978238992393
Epoch Time (s)               213.48192509030923
Total Train Time (s)         5782.640510556288
Epoch                        26
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:06:41.299091 UTC | [2020_01_13_04_30_18] Iteration #26 | Epoch Duration: 213.68990755081177
2020-01-13 06:06:41.299221 UTC | [2020_01_13_04_30_18] Iteration #26 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.057634734
Z variance train             0.1314745
KL Divergence                2.9407158
KL Loss                      0.29407158
QF Loss                      348.42896
VF Loss                      168.21417
Policy Loss                  -243.0528
Q Predictions Mean           233.75084
Q Predictions Std            387.86728
Q Predictions Max            1246.6416
Q Predictions Min            15.976815
V Predictions Mean           244.15614
V Predictions Std            389.98416
V Predictions Max            1244.7699
V Predictions Min            16.52786
Log Pis Mean                 -8.825222
Log Pis Std                  5.501431
Log Pis Max                  20.004154
Log Pis Min                  -13.261028
Policy mu Mean               0.08068442
Policy mu Std                0.4978589
Policy mu Max                2.3162618
Policy mu Min                -2.1212385
Policy log std Mean          -0.19426633
Policy log std Std           0.114572525
Policy log std Max           -0.06552993
Policy log std Min           -0.7793845
Z mean eval                  0.04900609
Z variance eval              0.14196616
total_rewards                [454.56087127 442.99517062 411.62248874 708.33355863 344.46695472
 391.25813633 414.64658287 357.79642833 433.79618263 327.68240403]
total_rewards_mean           428.71587781773405
total_rewards_std            101.64258084102725
total_rewards_max            708.3335586309847
total_rewards_min            327.68240403222984
Number of train steps total  112000
Number of env steps total    142000
Number of rollouts total     0
Train Time (s)               197.88196256617084
(Previous) Eval Time (s)     2.249432714190334
Sample Time (s)              13.55109870294109
Epoch Time (s)               213.68249398330227
Total Train Time (s)         5996.302335184533
Epoch                        27
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:10:14.961665 UTC | [2020_01_13_04_30_18] Iteration #27 | Epoch Duration: 213.66235375404358
2020-01-13 06:10:14.961774 UTC | [2020_01_13_04_30_18] Iteration #27 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.049036086
Z variance train             0.14197464
KL Divergence                2.7912111
KL Loss                      0.27912113
QF Loss                      339.72446
VF Loss                      131.069
Policy Loss                  -236.20802
Q Predictions Mean           226.83054
Q Predictions Std            372.64185
Q Predictions Max            1270.3302
Q Predictions Min            14.956679
V Predictions Mean           237.09616
V Predictions Std            373.31018
V Predictions Max            1262.1146
V Predictions Min            23.94848
Log Pis Mean                 -8.863422
Log Pis Std                  4.9797325
Log Pis Max                  20.435087
Log Pis Min                  -12.819811
Policy mu Mean               0.066396855
Policy mu Std                0.45493862
Policy mu Max                2.2774723
Policy mu Min                -2.161385
Policy log std Mean          -0.19192569
Policy log std Std           0.121272124
Policy log std Max           -0.07827681
Policy log std Min           -1.589139
Z mean eval                  0.035443604
Z variance eval              0.16213386
total_rewards                [399.97933582 353.54431138 282.74904728 357.17525279 429.79507514
 381.97574003 301.55961539 441.30678731 436.24962242 356.15430776]
total_rewards_mean           374.0489095322394
total_rewards_std            51.81809110461016
total_rewards_max            441.30678730954594
total_rewards_min            282.7490472845419
Number of train steps total  116000
Number of env steps total    147000
Number of rollouts total     0
Train Time (s)               197.48355436883867
(Previous) Eval Time (s)     2.229056806769222
Sample Time (s)              13.104462924413383
Epoch Time (s)               212.81707410002127
Total Train Time (s)         6208.97147349501
Epoch                        28
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:13:47.631770 UTC | [2020_01_13_04_30_18] Iteration #28 | Epoch Duration: 212.66991114616394
2020-01-13 06:13:47.631917 UTC | [2020_01_13_04_30_18] Iteration #28 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0357069
Z variance train             0.16223685
KL Divergence                2.4808939
KL Loss                      0.24808939
QF Loss                      474.20312
VF Loss                      166.48196
Policy Loss                  -266.14117
Q Predictions Mean           256.41934
Q Predictions Std            407.24478
Q Predictions Max            1268.6825
Q Predictions Min            16.721119
V Predictions Mean           265.59406
V Predictions Std            403.35165
V Predictions Max            1271.1403
V Predictions Min            29.00374
Log Pis Mean                 -8.791386
Log Pis Std                  4.993993
Log Pis Max                  17.297443
Log Pis Min                  -13.243059
Policy mu Mean               0.093200415
Policy mu Std                0.4841563
Policy mu Max                2.4830358
Policy mu Min                -2.0791402
Policy log std Mean          -0.19629905
Policy log std Std           0.11760287
Policy log std Max           -0.0692389
Policy log std Min           -1.1745617
Z mean eval                  0.05006656
Z variance eval              0.17943922
total_rewards                [363.72309572 345.5316711  358.89829161 390.71205709 414.13221936
 441.42700929 361.47946737 399.50413386 403.03253346 444.95653092]
total_rewards_mean           392.33970097847316
total_rewards_std            33.01803615356263
total_rewards_max            444.956530919502
total_rewards_min            345.5316711008139
Number of train steps total  120000
Number of env steps total    152000
Number of rollouts total     0
Train Time (s)               196.73833439825103
(Previous) Eval Time (s)     2.081651239655912
Sample Time (s)              13.670840339269489
Epoch Time (s)               212.49082597717643
Total Train Time (s)         6421.452648732346
Epoch                        29
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:17:20.113714 UTC | [2020_01_13_04_30_18] Iteration #29 | Epoch Duration: 212.48169827461243
2020-01-13 06:17:20.113823 UTC | [2020_01_13_04_30_18] Iteration #29 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.049607325
Z variance train             0.17931323
KL Divergence                2.3383398
KL Loss                      0.23383398
QF Loss                      349.03632
VF Loss                      196.58505
Policy Loss                  -258.63855
Q Predictions Mean           252.52011
Q Predictions Std            403.79697
Q Predictions Max            1276.7758
Q Predictions Min            16.527767
V Predictions Mean           261.8205
V Predictions Std            400.3145
V Predictions Max            1261.5753
V Predictions Min            26.808306
Log Pis Mean                 -8.5633955
Log Pis Std                  5.5509505
Log Pis Max                  15.769255
Log Pis Min                  -14.410094
Policy mu Mean               0.07529855
Policy mu Std                0.47825179
Policy mu Max                2.3189518
Policy mu Min                -2.1507921
Policy log std Mean          -0.20205492
Policy log std Std           0.120332524
Policy log std Max           -0.07113667
Policy log std Min           -0.7979178
Z mean eval                  0.058812678
Z variance eval              0.20708457
total_rewards                [453.67859419 427.93051011 298.42869426 574.66547353 392.94865896
 406.55304406 390.43369513 516.87737075 364.36640961 428.41780359]
total_rewards_mean           425.43002541980593
total_rewards_std            73.4446886022533
total_rewards_max            574.6654735337595
total_rewards_min            298.42869426463886
Number of train steps total  124000
Number of env steps total    157000
Number of rollouts total     0
Train Time (s)               196.16450813878328
(Previous) Eval Time (s)     2.0723146870732307
Sample Time (s)              13.231935249175876
Epoch Time (s)               211.46875807503238
Total Train Time (s)         6633.092326884158
Epoch                        30
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:20:51.754169 UTC | [2020_01_13_04_30_18] Iteration #30 | Epoch Duration: 211.64024186134338
2020-01-13 06:20:51.754276 UTC | [2020_01_13_04_30_18] Iteration #30 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.058712035
Z variance train             0.2070195
KL Divergence                2.0750914
KL Loss                      0.20750915
QF Loss                      243.89009
VF Loss                      109.957245
Policy Loss                  -205.54695
Q Predictions Mean           195.74069
Q Predictions Std            355.32687
Q Predictions Max            1332.0398
Q Predictions Min            16.145872
V Predictions Mean           206.32788
V Predictions Std            350.1356
V Predictions Max            1306.6556
V Predictions Min            28.577118
Log Pis Mean                 -9.5653715
Log Pis Std                  4.2211785
Log Pis Max                  7.540333
Log Pis Min                  -14.194649
Policy mu Mean               0.06304834
Policy mu Std                0.41287386
Policy mu Max                2.3325725
Policy mu Min                -2.0241387
Policy log std Mean          -0.18533054
Policy log std Std           0.10883001
Policy log std Max           0.0025426447
Policy log std Min           -1.061935
Z mean eval                  0.07690965
Z variance eval              0.21517953
total_rewards                [341.5689484  478.70301837 416.74706736 291.86761459 319.54614191
 458.29493663 453.46480796 476.43529199 407.34479478 524.46035069]
total_rewards_mean           416.84329726768374
total_rewards_std            72.70539916471449
total_rewards_max            524.4603506874334
total_rewards_min            291.86761458654206
Number of train steps total  128000
Number of env steps total    162000
Number of rollouts total     0
Train Time (s)               192.0065041212365
(Previous) Eval Time (s)     2.243594989180565
Sample Time (s)              13.528987286612391
Epoch Time (s)               207.77908639702946
Total Train Time (s)         6840.886541638058
Epoch                        31
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:24:19.549691 UTC | [2020_01_13_04_30_18] Iteration #31 | Epoch Duration: 207.7953143119812
2020-01-13 06:24:19.549840 UTC | [2020_01_13_04_30_18] Iteration #31 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07716719
Z variance train             0.21518305
KL Divergence                1.9844368
KL Loss                      0.19844368
QF Loss                      381.9485
VF Loss                      174.6121
Policy Loss                  -243.34406
Q Predictions Mean           233.38031
Q Predictions Std            380.34384
Q Predictions Max            1335.7274
Q Predictions Min            13.46315
V Predictions Mean           239.40038
V Predictions Std            376.16876
V Predictions Max            1305.8466
V Predictions Min            21.848764
Log Pis Mean                 -8.942417
Log Pis Std                  4.9160895
Log Pis Max                  15.548786
Log Pis Min                  -14.985196
Policy mu Mean               0.058625266
Policy mu Std                0.46324193
Policy mu Max                2.3748322
Policy mu Min                -2.0735955
Policy log std Mean          -0.19460599
Policy log std Std           0.11380782
Policy log std Max           -0.026171982
Policy log std Min           -0.7701581
Z mean eval                  0.08137613
Z variance eval              0.21711
total_rewards                [391.30659842 310.74244287 383.44290414 395.58254199 458.38505144
 538.07280658 500.99309591 299.77882005 322.4063841  312.47324488]
total_rewards_mean           391.31838903744375
total_rewards_std            79.98808722404834
total_rewards_max            538.0728065846743
total_rewards_min            299.7788200493253
Number of train steps total  132000
Number of env steps total    167000
Number of rollouts total     0
Train Time (s)               195.5228674216196
(Previous) Eval Time (s)     2.259593018796295
Sample Time (s)              14.007432270795107
Epoch Time (s)               211.789892711211
Total Train Time (s)         7052.663319692016
Epoch                        32
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:27:51.326796 UTC | [2020_01_13_04_30_18] Iteration #32 | Epoch Duration: 211.77684497833252
2020-01-13 06:27:51.326901 UTC | [2020_01_13_04_30_18] Iteration #32 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08168726
Z variance train             0.21704534
KL Divergence                1.9935595
KL Loss                      0.19935594
QF Loss                      225.5766
VF Loss                      128.69852
Policy Loss                  -249.87308
Q Predictions Mean           237.87476
Q Predictions Std            391.5153
Q Predictions Max            1333.1123
Q Predictions Min            15.537224
V Predictions Mean           249.25027
V Predictions Std            394.92914
V Predictions Max            1340.0775
V Predictions Min            28.507683
Log Pis Mean                 -9.12633
Log Pis Std                  4.3813643
Log Pis Max                  10.944096
Log Pis Min                  -13.077613
Policy mu Mean               0.07928269
Policy mu Std                0.46093553
Policy mu Max                2.4845347
Policy mu Min                -2.0444462
Policy log std Mean          -0.19875562
Policy log std Std           0.12726076
Policy log std Max           -0.06430917
Policy log std Min           -1.0354277
Z mean eval                  0.095107876
Z variance eval              0.21234322
total_rewards                [426.94773652 245.11413917 317.51010734 339.45407136 411.51528996
 325.71023972 331.43287615 273.72070236 394.40732944 345.44568324]
total_rewards_mean           341.12581752439297
total_rewards_std            54.618167257625124
total_rewards_max            426.94773651566265
total_rewards_min            245.11413916646578
Number of train steps total  136000
Number of env steps total    172000
Number of rollouts total     0
Train Time (s)               195.29766412777826
(Previous) Eval Time (s)     2.2463125227950513
Sample Time (s)              12.069893296808004
Epoch Time (s)               209.61386994738132
Total Train Time (s)         7261.809419624507
Epoch                        33
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:31:20.474946 UTC | [2020_01_13_04_30_18] Iteration #33 | Epoch Duration: 209.1479377746582
2020-01-13 06:31:20.475113 UTC | [2020_01_13_04_30_18] Iteration #33 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09538199
Z variance train             0.21237457
KL Divergence                2.015546
KL Loss                      0.20155461
QF Loss                      457.06833
VF Loss                      306.65872
Policy Loss                  -266.42935
Q Predictions Mean           259.60678
Q Predictions Std            418.43893
Q Predictions Max            1372.068
Q Predictions Min            17.569593
V Predictions Mean           270.44244
V Predictions Std            419.1401
V Predictions Max            1374.8448
V Predictions Min            27.50144
Log Pis Mean                 -9.012001
Log Pis Std                  4.7560873
Log Pis Max                  10.009054
Log Pis Min                  -14.465626
Policy mu Mean               0.041257862
Policy mu Std                0.45277128
Policy mu Max                2.3053768
Policy mu Min                -2.1388543
Policy log std Mean          -0.19755948
Policy log std Std           0.1160982
Policy log std Max           -0.077264026
Policy log std Min           -1.1192998
Z mean eval                  0.1036364
Z variance eval              0.207305
total_rewards                [410.39706684 439.7878623  393.90018712 205.30373915 320.01385465
 555.30701298 325.73788974 362.596525   460.72599004 504.25621396]
total_rewards_mean           397.80263417749075
total_rewards_std            95.69517606973668
total_rewards_max            555.3070129764849
total_rewards_min            205.3037391511164
Number of train steps total  140000
Number of env steps total    177000
Number of rollouts total     0
Train Time (s)               196.29075078479946
(Previous) Eval Time (s)     1.7801068471744657
Sample Time (s)              12.929561694618315
Epoch Time (s)               211.00041932659224
Total Train Time (s)         7473.010776143987
Epoch                        34
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:34:51.676423 UTC | [2020_01_13_04_30_18] Iteration #34 | Epoch Duration: 211.201189994812
2020-01-13 06:34:51.676554 UTC | [2020_01_13_04_30_18] Iteration #34 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10358193
Z variance train             0.20734414
KL Divergence                2.0901523
KL Loss                      0.20901524
QF Loss                      366.19714
VF Loss                      165.01686
Policy Loss                  -258.4777
Q Predictions Mean           247.80252
Q Predictions Std            404.46582
Q Predictions Max            1362.8303
Q Predictions Min            16.360527
V Predictions Mean           260.5185
V Predictions Std            404.43356
V Predictions Max            1361.8438
V Predictions Min            29.238884
Log Pis Mean                 -8.908345
Log Pis Std                  5.1428084
Log Pis Max                  16.905422
Log Pis Min                  -13.334684
Policy mu Mean               0.08423581
Policy mu Std                0.46969894
Policy mu Max                2.415424
Policy mu Min                -2.015604
Policy log std Mean          -0.19261965
Policy log std Std           0.111168094
Policy log std Max           -0.028356954
Policy log std Min           -0.71998394
Z mean eval                  0.109057024
Z variance eval              0.21121378
total_rewards                [344.92811582 387.34688383 385.03144089 406.04030765 547.06109366
 360.97677291 417.23310169 326.37180373 390.58154614 305.95449516]
total_rewards_mean           387.152556146896
total_rewards_std            62.93180560852948
total_rewards_max            547.0610936561903
total_rewards_min            305.95449516483546
Number of train steps total  144000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               199.93202690593898
(Previous) Eval Time (s)     1.9806538559496403
Sample Time (s)              13.439030225854367
Epoch Time (s)               215.351710987743
Total Train Time (s)         7688.447662128601
Epoch                        35
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:38:27.115718 UTC | [2020_01_13_04_30_18] Iteration #35 | Epoch Duration: 215.43904995918274
2020-01-13 06:38:27.115905 UTC | [2020_01_13_04_30_18] Iteration #35 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10899316
Z variance train             0.211249
KL Divergence                2.0409226
KL Loss                      0.20409226
QF Loss                      224.28575
VF Loss                      101.25666
Policy Loss                  -237.86073
Q Predictions Mean           228.81165
Q Predictions Std            392.7822
Q Predictions Max            1372.2078
Q Predictions Min            16.095083
V Predictions Mean           238.61588
V Predictions Std            390.09946
V Predictions Max            1365.9967
V Predictions Min            27.6627
Log Pis Mean                 -9.167327
Log Pis Std                  4.7859964
Log Pis Max                  9.773838
Log Pis Min                  -13.460803
Policy mu Mean               0.092059374
Policy mu Std                0.42490512
Policy mu Max                2.2405162
Policy mu Min                -1.7107991
Policy log std Mean          -0.18631788
Policy log std Std           0.10395597
Policy log std Max           0.019282043
Policy log std Min           -0.7460694
Z mean eval                  0.109065905
Z variance eval              0.19894734
total_rewards                [333.66679422 357.67122834 410.27062217 504.99637611 404.77601685
 344.50784369 468.95097523 319.80601698 373.34431867 719.67416926]
total_rewards_mean           423.7664361524543
total_rewards_std            113.5177124457468
total_rewards_max            719.6741692647405
total_rewards_min            319.80601698306646
Number of train steps total  148000
Number of env steps total    187000
Number of rollouts total     0
Train Time (s)               194.78669620724395
(Previous) Eval Time (s)     2.06773785315454
Sample Time (s)              13.580283445306122
Epoch Time (s)               210.4347175057046
Total Train Time (s)         7899.257386929356
Epoch                        36
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:41:57.925518 UTC | [2020_01_13_04_30_18] Iteration #36 | Epoch Duration: 210.80947017669678
2020-01-13 06:41:57.925647 UTC | [2020_01_13_04_30_18] Iteration #36 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10879419
Z variance train             0.19899753
KL Divergence                2.1217105
KL Loss                      0.21217106
QF Loss                      215.36179
VF Loss                      97.68508
Policy Loss                  -264.68216
Q Predictions Mean           254.76416
Q Predictions Std            426.63953
Q Predictions Max            1390.1274
Q Predictions Min            12.228068
V Predictions Mean           265.21072
V Predictions Std            423.9678
V Predictions Max            1406.8232
V Predictions Min            30.744968
Log Pis Mean                 -9.198888
Log Pis Std                  5.0074306
Log Pis Max                  16.929081
Log Pis Min                  -14.016765
Policy mu Mean               0.06991956
Policy mu Std                0.4369372
Policy mu Max                2.3777053
Policy mu Min                -1.8473055
Policy log std Mean          -0.18836164
Policy log std Std           0.11127564
Policy log std Max           -0.04523626
Policy log std Min           -0.93872297
Z mean eval                  0.101858035
Z variance eval              0.20949951
total_rewards                [414.5769069  583.26267671 315.35185597 379.27678224 519.5751534
 493.82587817 413.71849037 325.17974002 667.97619478 661.52500463]
total_rewards_mean           477.42686831948095
total_rewards_std            122.69376739566243
total_rewards_max            667.9761947836513
total_rewards_min            315.35185596882854
Number of train steps total  152000
Number of env steps total    192000
Number of rollouts total     0
Train Time (s)               195.72147946013138
(Previous) Eval Time (s)     2.442242412827909
Sample Time (s)              12.852548603899777
Epoch Time (s)               211.01627047685906
Total Train Time (s)         8110.359753146768
Epoch                        37
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:45:29.029061 UTC | [2020_01_13_04_30_18] Iteration #37 | Epoch Duration: 211.10332536697388
2020-01-13 06:45:29.029188 UTC | [2020_01_13_04_30_18] Iteration #37 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.101728305
Z variance train             0.20960185
KL Divergence                2.0417671
KL Loss                      0.20417671
QF Loss                      311.7735
VF Loss                      160.54027
Policy Loss                  -269.51468
Q Predictions Mean           259.60092
Q Predictions Std            420.86777
Q Predictions Max            1389.7968
Q Predictions Min            6.367676
V Predictions Mean           270.31372
V Predictions Std            423.429
V Predictions Max            1411.5065
V Predictions Min            23.020546
Log Pis Mean                 -8.645107
Log Pis Std                  5.285494
Log Pis Max                  8.877921
Log Pis Min                  -15.1395855
Policy mu Mean               0.09326083
Policy mu Std                0.48181948
Policy mu Max                2.3205893
Policy mu Min                -2.3609798
Policy log std Mean          -0.19907507
Policy log std Std           0.123587996
Policy log std Max           0.014085144
Policy log std Min           -0.8244091
Z mean eval                  0.091051206
Z variance eval              0.17936923
total_rewards                [ 391.7609644   706.95472872  381.09597668  488.92763188  474.18527067
  512.95257283  385.54168681  611.45150894  335.6698346  1071.05943195]
total_rewards_mean           535.9599607457513
total_rewards_std            208.64925513325028
total_rewards_max            1071.0594319522224
total_rewards_min            335.66983459588954
Number of train steps total  156000
Number of env steps total    197000
Number of rollouts total     0
Train Time (s)               199.95942464796826
(Previous) Eval Time (s)     2.52896074205637
Sample Time (s)              13.990435529500246
Epoch Time (s)               216.47882091952488
Total Train Time (s)         8327.263511499856
Epoch                        38
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:49:05.933890 UTC | [2020_01_13_04_30_18] Iteration #38 | Epoch Duration: 216.90461921691895
2020-01-13 06:49:05.934003 UTC | [2020_01_13_04_30_18] Iteration #38 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.090516455
Z variance train             0.17948897
KL Divergence                2.31327
KL Loss                      0.23132701
QF Loss                      247.59647
VF Loss                      256.5249
Policy Loss                  -315.83057
Q Predictions Mean           307.11624
Q Predictions Std            461.52762
Q Predictions Max            1399.3737
Q Predictions Min            17.627808
V Predictions Mean           321.55365
V Predictions Std            464.3447
V Predictions Max            1421.3092
V Predictions Min            30.306625
Log Pis Mean                 -8.843437
Log Pis Std                  4.820386
Log Pis Max                  10.87418
Log Pis Min                  -17.703623
Policy mu Mean               0.079078496
Policy mu Std                0.4818402
Policy mu Max                2.4047775
Policy mu Min                -2.504679
Policy log std Mean          -0.20001431
Policy log std Std           0.111417
Policy log std Max           -0.054559678
Policy log std Min           -0.7968992
Z mean eval                  0.0720835
Z variance eval              0.20764486
total_rewards                [601.98761773 441.64270695 603.99863687 490.52662291 455.65660708
 524.02818586 456.09105954 479.45440366 501.16855894 527.9153012 ]
total_rewards_mean           508.2469700732082
total_rewards_std            54.503963502409334
total_rewards_max            603.9986368661101
total_rewards_min            441.64270695083417
Number of train steps total  160000
Number of env steps total    202000
Number of rollouts total     0
Train Time (s)               195.06886586500332
(Previous) Eval Time (s)     2.9544483269564807
Sample Time (s)              13.377852988895029
Epoch Time (s)               211.40116718085483
Total Train Time (s)         8538.260973549914
Epoch                        39
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:52:36.931891 UTC | [2020_01_13_04_30_18] Iteration #39 | Epoch Duration: 210.9978003501892
2020-01-13 06:52:36.932009 UTC | [2020_01_13_04_30_18] Iteration #39 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07180885
Z variance train             0.2076753
KL Divergence                2.0396237
KL Loss                      0.20396237
QF Loss                      237.39693
VF Loss                      95.83874
Policy Loss                  -234.52586
Q Predictions Mean           227.23596
Q Predictions Std            405.4282
Q Predictions Max            1408.9882
Q Predictions Min            14.580551
V Predictions Mean           236.40622
V Predictions Std            402.03314
V Predictions Max            1410.0985
V Predictions Min            19.43576
Log Pis Mean                 -9.488193
Log Pis Std                  4.044337
Log Pis Max                  14.661204
Log Pis Min                  -13.691465
Policy mu Mean               0.046076264
Policy mu Std                0.400139
Policy mu Max                2.3239076
Policy mu Min                -2.2686107
Policy log std Mean          -0.1880517
Policy log std Std           0.10568743
Policy log std Max           -0.08514416
Policy log std Min           -0.78301895
Z mean eval                  0.080732055
Z variance eval              0.19509888
total_rewards                [ 561.42788581  502.49959766  457.45532402 1111.62714148  504.5639373
  446.84925156  493.5538063   488.87436758  383.07656225  405.6792126 ]
total_rewards_mean           535.5607086558618
total_rewards_std            198.14400538873548
total_rewards_max            1111.6271414784362
total_rewards_min            383.0765622453665
Number of train steps total  164000
Number of env steps total    207000
Number of rollouts total     0
Train Time (s)               193.27535551367328
(Previous) Eval Time (s)     2.550860083196312
Sample Time (s)              14.169007997959852
Epoch Time (s)               209.99522359482944
Total Train Time (s)         8748.350565729663
Epoch                        40
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:56:07.023369 UTC | [2020_01_13_04_30_18] Iteration #40 | Epoch Duration: 210.09124565124512
2020-01-13 06:56:07.023515 UTC | [2020_01_13_04_30_18] Iteration #40 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08017968
Z variance train             0.19521591
KL Divergence                2.1585016
KL Loss                      0.21585016
QF Loss                      253.4184
VF Loss                      131.06493
Policy Loss                  -268.91666
Q Predictions Mean           259.34827
Q Predictions Std            419.509
Q Predictions Max            1399.5193
Q Predictions Min            10.899259
V Predictions Mean           269.51608
V Predictions Std            420.75397
V Predictions Max            1407.7961
V Predictions Min            25.236506
Log Pis Mean                 -9.07198
Log Pis Std                  4.4971504
Log Pis Max                  10.00148
Log Pis Min                  -13.124427
Policy mu Mean               0.052907642
Policy mu Std                0.4354834
Policy mu Max                2.08776
Policy mu Min                -1.9457438
Policy log std Mean          -0.18943971
Policy log std Std           0.10622322
Policy log std Max           0.01436682
Policy log std Min           -0.72808623
Z mean eval                  0.08383982
Z variance eval              0.21761909
total_rewards                [435.69979031 522.76709103 558.41121853 646.60264277 404.46191138
 343.2555078  440.44357567 419.25113073 462.0934054  439.84963971]
total_rewards_mean           467.28359133248307
total_rewards_std            82.26306236345168
total_rewards_max            646.6026427700657
total_rewards_min            343.2555078003698
Number of train steps total  168000
Number of env steps total    212000
Number of rollouts total     0
Train Time (s)               196.34987307013944
(Previous) Eval Time (s)     2.646641807630658
Sample Time (s)              12.78006752114743
Epoch Time (s)               211.77658239891753
Total Train Time (s)         8959.826376984362
Epoch                        41
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:59:38.499501 UTC | [2020_01_13_04_30_18] Iteration #41 | Epoch Duration: 211.47587776184082
2020-01-13 06:59:38.499609 UTC | [2020_01_13_04_30_18] Iteration #41 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08509137
Z variance train             0.21767136
KL Divergence                1.9384832
KL Loss                      0.19384833
QF Loss                      306.65244
VF Loss                      226.0624
Policy Loss                  -296.77972
Q Predictions Mean           285.44434
Q Predictions Std            437.7727
Q Predictions Max            1440.1833
Q Predictions Min            15.18582
V Predictions Mean           292.46448
V Predictions Std            432.90018
V Predictions Max            1421.2559
V Predictions Min            25.624762
Log Pis Mean                 -8.83305
Log Pis Std                  5.1911163
Log Pis Max                  18.294464
Log Pis Min                  -14.792981
Policy mu Mean               0.06573025
Policy mu Std                0.47334763
Policy mu Max                2.5036654
Policy mu Min                -2.258181
Policy log std Mean          -0.19674575
Policy log std Std           0.11816159
Policy log std Max           0.04742992
Policy log std Min           -0.8830729
Z mean eval                  0.07938309
Z variance eval              0.23854566
total_rewards                [436.22840346 782.97836097 386.46532827 397.73986869 451.41995721
 550.66542378 799.26023805 541.3123028  445.37018006 393.93631456]
total_rewards_mean           518.5376377858006
total_rewards_std            146.45091671183096
total_rewards_max            799.260238052498
total_rewards_min            386.4653282683395
Number of train steps total  172000
Number of env steps total    217000
Number of rollouts total     0
Train Time (s)               202.95939043303952
(Previous) Eval Time (s)     2.3456324711441994
Sample Time (s)              14.273624270223081
Epoch Time (s)               219.5786471744068
Total Train Time (s)         9179.948063414078
Epoch                        42
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:03:18.622121 UTC | [2020_01_13_04_30_18] Iteration #42 | Epoch Duration: 220.12242317199707
2020-01-13 07:03:18.622234 UTC | [2020_01_13_04_30_18] Iteration #42 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07922446
Z variance train             0.23859744
KL Divergence                1.7741556
KL Loss                      0.17741556
QF Loss                      317.5428
VF Loss                      144.86504
Policy Loss                  -333.82034
Q Predictions Mean           324.72546
Q Predictions Std            473.63852
Q Predictions Max            1440.1215
Q Predictions Min            13.019208
V Predictions Mean           333.28537
V Predictions Std            468.3348
V Predictions Max            1436.9799
V Predictions Min            26.365486
Log Pis Mean                 -8.399156
Log Pis Std                  5.5513287
Log Pis Max                  29.242199
Log Pis Min                  -13.48803
Policy mu Mean               0.091864586
Policy mu Std                0.50539523
Policy mu Max                2.6812363
Policy mu Min                -2.2941213
Policy log std Mean          -0.20710418
Policy log std Std           0.12094526
Policy log std Max           -0.050223976
Policy log std Min           -0.84869426
Z mean eval                  0.07018935
Z variance eval              0.22417128
total_rewards                [375.23972064 634.41885981 440.99971267 429.09828036 463.64863952
 579.33207545 499.03476691 454.23254325 364.75047569 358.1221277 ]
total_rewards_mean           459.8877202015125
total_rewards_std            86.130163631243
total_rewards_max            634.4188598068188
total_rewards_min            358.1221277042359
Number of train steps total  176000
Number of env steps total    222000
Number of rollouts total     0
Train Time (s)               197.98085335083306
(Previous) Eval Time (s)     2.889149332419038
Sample Time (s)              13.738264875486493
Epoch Time (s)               214.6082675587386
Total Train Time (s)         9393.733122760896
Epoch                        43
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:06:52.409091 UTC | [2020_01_13_04_30_18] Iteration #43 | Epoch Duration: 213.78674030303955
2020-01-13 07:06:52.409286 UTC | [2020_01_13_04_30_18] Iteration #43 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07047842
Z variance train             0.22410889
KL Divergence                1.8760455
KL Loss                      0.18760455
QF Loss                      369.21097
VF Loss                      145.62926
Policy Loss                  -278.3779
Q Predictions Mean           266.90536
Q Predictions Std            424.3492
Q Predictions Max            1429.2981
Q Predictions Min            16.607946
V Predictions Mean           277.6783
V Predictions Std            423.86288
V Predictions Max            1438.531
V Predictions Min            25.350039
Log Pis Mean                 -8.751476
Log Pis Std                  5.2997994
Log Pis Max                  17.875614
Log Pis Min                  -13.2207985
Policy mu Mean               0.09406545
Policy mu Std                0.4731725
Policy mu Max                2.4221704
Policy mu Min                -1.8848898
Policy log std Mean          -0.19590107
Policy log std Std           0.11418012
Policy log std Max           -0.057705
Policy log std Min           -0.809121
Z mean eval                  0.07844017
Z variance eval              0.24148402
total_rewards                [621.45404173 459.69593424 456.59285815 446.66071212 480.86466829
 627.19295156 474.37252677 448.47400599 408.15711443 464.78117893]
total_rewards_mean           488.824599220491
total_rewards_std            70.27606279268345
total_rewards_max            627.1929515598665
total_rewards_min            408.1571144287842
Number of train steps total  180000
Number of env steps total    227000
Number of rollouts total     0
Train Time (s)               200.60740371001884
(Previous) Eval Time (s)     2.0673707528039813
Sample Time (s)              13.986662119161338
Epoch Time (s)               216.66143658198416
Total Train Time (s)         9611.021386214066
Epoch                        44
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:10:29.697573 UTC | [2020_01_13_04_30_18] Iteration #44 | Epoch Duration: 217.28814148902893
2020-01-13 07:10:29.697698 UTC | [2020_01_13_04_30_18] Iteration #44 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0786673
Z variance train             0.24127682
KL Divergence                1.7364018
KL Loss                      0.17364018
QF Loss                      369.41028
VF Loss                      159.53467
Policy Loss                  -359.8539
Q Predictions Mean           349.20624
Q Predictions Std            481.02667
Q Predictions Max            1475.8062
Q Predictions Min            16.186623
V Predictions Mean           360.89886
V Predictions Std            482.74393
V Predictions Max            1484.0312
V Predictions Min            28.660782
Log Pis Mean                 -8.4788
Log Pis Std                  4.939699
Log Pis Max                  11.628099
Log Pis Min                  -13.686483
Policy mu Mean               0.08705908
Policy mu Std                0.5024244
Policy mu Max                2.7600546
Policy mu Min                -2.2617896
Policy log std Mean          -0.2087847
Policy log std Std           0.12600929
Policy log std Max           0.05204542
Policy log std Min           -0.7785352
Z mean eval                  0.08716062
Z variance eval              0.25891408
total_rewards                [483.61742631 558.60858406 474.67176535 676.0686207  424.80510446
 412.79356054 457.06605414 389.95794757 560.67972226 524.57928984]
total_rewards_mean           496.28480752101603
total_rewards_std            81.6731226002104
total_rewards_max            676.0686206987485
total_rewards_min            389.95794756543125
Number of train steps total  184000
Number of env steps total    232000
Number of rollouts total     0
Train Time (s)               195.32370932679623
(Previous) Eval Time (s)     2.6938311806879938
Sample Time (s)              14.127285476308316
Epoch Time (s)               212.14482598379254
Total Train Time (s)         9823.16844714526
Epoch                        45
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:14:01.845816 UTC | [2020_01_13_04_30_18] Iteration #45 | Epoch Duration: 212.14802980422974
2020-01-13 07:14:01.845935 UTC | [2020_01_13_04_30_18] Iteration #45 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08781074
Z variance train             0.25897798
KL Divergence                1.6103032
KL Loss                      0.16103032
QF Loss                      315.92462
VF Loss                      164.08862
Policy Loss                  -301.47668
Q Predictions Mean           291.87903
Q Predictions Std            473.12476
Q Predictions Max            1486.4231
Q Predictions Min            17.807705
V Predictions Mean           300.4469
V Predictions Std            469.7621
V Predictions Max            1485.6699
V Predictions Min            24.416985
Log Pis Mean                 -9.208733
Log Pis Std                  4.620018
Log Pis Max                  8.440571
Log Pis Min                  -14.173473
Policy mu Mean               0.06645124
Policy mu Std                0.44949618
Policy mu Max                2.372686
Policy mu Min                -2.1535435
Policy log std Mean          -0.19460379
Policy log std Std           0.110152945
Policy log std Max           -0.03884381
Policy log std Min           -0.7204361
Z mean eval                  0.07900221
Z variance eval              0.25091377
total_rewards                [497.62562948 350.37624928 377.87464053 544.42201373 367.70412518
 719.37373762 418.84279985 356.40008264 816.55381511 520.56020992]
total_rewards_mean           496.9733303336134
total_rewards_std            152.52957700160061
total_rewards_max            816.5538151114581
total_rewards_min            350.3762492775945
Number of train steps total  188000
Number of env steps total    237000
Number of rollouts total     0
Train Time (s)               196.75686826370656
(Previous) Eval Time (s)     2.6967990729026496
Sample Time (s)              13.99729824764654
Epoch Time (s)               213.45096558425575
Total Train Time (s)         10036.473634248134
Epoch                        46
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:17:35.154040 UTC | [2020_01_13_04_30_18] Iteration #46 | Epoch Duration: 213.30799555778503
2020-01-13 07:17:35.154212 UTC | [2020_01_13_04_30_18] Iteration #46 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07933223
Z variance train             0.25085765
KL Divergence                1.6742076
KL Loss                      0.16742076
QF Loss                      337.29312
VF Loss                      225.22525
Policy Loss                  -345.36102
Q Predictions Mean           337.7051
Q Predictions Std            475.19904
Q Predictions Max            1475.6616
Q Predictions Min            16.74983
V Predictions Mean           344.84476
V Predictions Std            469.8407
V Predictions Max            1487.1198
V Predictions Min            26.827555
Log Pis Mean                 -8.19282
Log Pis Std                  5.3294826
Log Pis Max                  18.10414
Log Pis Min                  -13.775721
Policy mu Mean               0.1015775
Policy mu Std                0.51652545
Policy mu Max                2.3509037
Policy mu Min                -2.5622838
Policy log std Mean          -0.21503337
Policy log std Std           0.12597579
Policy log std Max           -0.031932227
Policy log std Min           -0.8616502
Z mean eval                  0.07924385
Z variance eval              0.22256498
total_rewards                [515.21418943 401.96540155 417.28160177 483.8602946  487.59132001
 450.66153267 615.11012045 468.02591714 705.33430045 440.62814563]
total_rewards_mean           498.56728236891587
total_rewards_std            89.14745329137433
total_rewards_max            705.3343004458088
total_rewards_min            401.96540155366813
Number of train steps total  192000
Number of env steps total    242000
Number of rollouts total     0
Train Time (s)               196.84174529090524
(Previous) Eval Time (s)     2.5535920611582696
Sample Time (s)              13.904136321507394
Epoch Time (s)               213.2994736735709
Total Train Time (s)         10250.098554728553
Epoch                        47
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:21:08.779191 UTC | [2020_01_13_04_30_18] Iteration #47 | Epoch Duration: 213.62485146522522
2020-01-13 07:21:08.779322 UTC | [2020_01_13_04_30_18] Iteration #47 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07878255
Z variance train             0.22246496
KL Divergence                1.9700351
KL Loss                      0.19700351
QF Loss                      340.74127
VF Loss                      183.49356
Policy Loss                  -323.38696
Q Predictions Mean           315.6999
Q Predictions Std            484.31345
Q Predictions Max            1492.5037
Q Predictions Min            16.734346
V Predictions Mean           326.05182
V Predictions Std            486.3405
V Predictions Max            1518.7863
V Predictions Min            28.713928
Log Pis Mean                 -9.126265
Log Pis Std                  4.3986397
Log Pis Max                  10.918547
Log Pis Min                  -13.354473
Policy mu Mean               0.06519142
Policy mu Std                0.46045607
Policy mu Max                2.2273796
Policy mu Min                -2.1142423
Policy log std Mean          -0.19708917
Policy log std Std           0.114666425
Policy log std Max           -0.021429718
Policy log std Min           -0.80544657
Z mean eval                  0.06841317
Z variance eval              0.20481269
total_rewards                [ 540.33387433  419.36799135  429.63994408  423.83577037  374.34659991
  533.0772015  1075.33498198  382.01047472  592.01649138  489.86678686]
total_rewards_mean           525.9830116475337
total_rewards_std            195.57943785263646
total_rewards_max            1075.334981975849
total_rewards_min            374.34659991291386
Number of train steps total  196000
Number of env steps total    247000
Number of rollouts total     0
Train Time (s)               193.78761559305713
(Previous) Eval Time (s)     2.878729742951691
Sample Time (s)              13.7140566050075
Epoch Time (s)               210.38040194101632
Total Train Time (s)         10460.276003857143
Epoch                        48
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:24:38.957766 UTC | [2020_01_13_04_30_18] Iteration #48 | Epoch Duration: 210.17834854125977
2020-01-13 07:24:38.957881 UTC | [2020_01_13_04_30_18] Iteration #48 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06794173
Z variance train             0.20478694
KL Divergence                2.0388227
KL Loss                      0.20388226
QF Loss                      289.82422
VF Loss                      144.58452
Policy Loss                  -323.1564
Q Predictions Mean           315.10883
Q Predictions Std            477.3435
Q Predictions Max            1498.0436
Q Predictions Min            18.192684
V Predictions Mean           321.73453
V Predictions Std            473.3162
V Predictions Max            1479.751
V Predictions Min            27.474298
Log Pis Mean                 -9.064242
Log Pis Std                  4.5012507
Log Pis Max                  7.830685
Log Pis Min                  -17.955887
Policy mu Mean               0.0703647
Policy mu Std                0.45156953
Policy mu Max                2.0463843
Policy mu Min                -2.4669106
Policy log std Mean          -0.19605738
Policy log std Std           0.10989626
Policy log std Max           0.00048029423
Policy log std Min           -0.7371611
Z mean eval                  0.07084449
Z variance eval              0.24537316
total_rewards                [713.38807618 677.34409186 730.18477522 504.92376974 438.50441443
 446.11055886 448.83838084 648.02691563 617.41298414 558.46614066]
total_rewards_mean           578.3200107564132
total_rewards_std            108.20064129348866
total_rewards_max            730.1847752188454
total_rewards_min            438.5044144251101
Number of train steps total  200000
Number of env steps total    252000
Number of rollouts total     0
Train Time (s)               194.084574340377
(Previous) Eval Time (s)     2.676452187821269
Sample Time (s)              14.284102546051145
Epoch Time (s)               211.04512907424942
Total Train Time (s)         10671.605655801948
Epoch                        49
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:28:10.288422 UTC | [2020_01_13_04_30_18] Iteration #49 | Epoch Duration: 211.33044934272766
2020-01-13 07:28:10.288533 UTC | [2020_01_13_04_30_18] Iteration #49 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07080666
Z variance train             0.24524045
KL Divergence                1.6585896
KL Loss                      0.16585897
QF Loss                      363.79596
VF Loss                      134.62465
Policy Loss                  -294.90186
Q Predictions Mean           287.2495
Q Predictions Std            475.19553
Q Predictions Max            1512.8549
Q Predictions Min            17.059017
V Predictions Mean           295.12366
V Predictions Std            465.858
V Predictions Max            1493.0444
V Predictions Min            30.56905
Log Pis Mean                 -9.009222
Log Pis Std                  5.040964
Log Pis Max                  17.243185
Log Pis Min                  -14.091114
Policy mu Mean               0.05557182
Policy mu Std                0.43592227
Policy mu Max                2.5006738
Policy mu Min                -2.1371078
Policy log std Mean          -0.19185692
Policy log std Std           0.109285586
Policy log std Max           -0.043707296
Policy log std Min           -0.77126276
Z mean eval                  0.06687252
Z variance eval              0.22449723
total_rewards                [338.17714157 376.83601911 478.19737035 442.30646824 470.91150229
 573.63669466 593.40493803 383.27661807 558.25925794 466.32162445]
total_rewards_mean           468.13276347326837
total_rewards_std            82.55325691946342
total_rewards_max            593.4049380347457
total_rewards_min            338.1771415743727
Number of train steps total  204000
Number of env steps total    257000
Number of rollouts total     0
Train Time (s)               195.20808955281973
(Previous) Eval Time (s)     2.9615146457217634
Sample Time (s)              14.016065135132521
Epoch Time (s)               212.185669333674
Total Train Time (s)         10883.246047384571
Epoch                        50
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:31:41.930931 UTC | [2020_01_13_04_30_18] Iteration #50 | Epoch Duration: 211.64228796958923
2020-01-13 07:31:41.931097 UTC | [2020_01_13_04_30_18] Iteration #50 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06644706
Z variance train             0.22439471
KL Divergence                1.8657004
KL Loss                      0.18657003
QF Loss                      284.05078
VF Loss                      223.08998
Policy Loss                  -326.059
Q Predictions Mean           317.77563
Q Predictions Std            467.75754
Q Predictions Max            1488.259
Q Predictions Min            18.41608
V Predictions Mean           329.6993
V Predictions Std            467.2084
V Predictions Max            1500.3724
V Predictions Min            28.210588
Log Pis Mean                 -8.693563
Log Pis Std                  5.2333403
Log Pis Max                  18.263046
Log Pis Min                  -13.835495
Policy mu Mean               0.094267905
Policy mu Std                0.48629802
Policy mu Max                2.168182
Policy mu Min                -2.2893162
Policy log std Mean          -0.20417584
Policy log std Std           0.11750741
Policy log std Max           -0.053631797
Policy log std Min           -0.75041807
Z mean eval                  0.06258239
Z variance eval              0.21041127
total_rewards                [464.31456768 562.41900977 366.1005107  442.65130848 409.97452666
 343.12854288 351.02935465 579.18416368 307.50019842 344.34703873]
total_rewards_mean           417.06492216476875
total_rewards_std            89.4789919381363
total_rewards_max            579.1841636812106
total_rewards_min            307.50019842136226
Number of train steps total  208000
Number of env steps total    262000
Number of rollouts total     0
Train Time (s)               195.3212280808948
(Previous) Eval Time (s)     2.4178979019634426
Sample Time (s)              13.849854852538556
Epoch Time (s)               211.5889808353968
Total Train Time (s)         11094.65690227691
Epoch                        51
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:35:13.344276 UTC | [2020_01_13_04_30_18] Iteration #51 | Epoch Duration: 211.41302061080933
2020-01-13 07:35:13.344437 UTC | [2020_01_13_04_30_18] Iteration #51 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.062348224
Z variance train             0.21056361
KL Divergence                1.9591389
KL Loss                      0.1959139
QF Loss                      259.3045
VF Loss                      81.65125
Policy Loss                  -268.08487
Q Predictions Mean           259.29025
Q Predictions Std            438.64893
Q Predictions Max            1523.51
Q Predictions Min            16.858849
V Predictions Mean           269.08234
V Predictions Std            435.66742
V Predictions Max            1523.3846
V Predictions Min            28.84012
Log Pis Mean                 -9.612671
Log Pis Std                  4.1858864
Log Pis Max                  20.760082
Log Pis Min                  -13.134921
Policy mu Mean               0.0562782
Policy mu Std                0.40406078
Policy mu Max                2.484879
Policy mu Min                -1.963968
Policy log std Mean          -0.18151048
Policy log std Std           0.10093685
Policy log std Max           -0.04270059
Policy log std Min           -0.7683902
Z mean eval                  0.055004753
Z variance eval              0.23465712
total_rewards                [ 431.80163979  983.3148992   419.95595099  439.17839039  506.46401107
 1320.2616391  1177.78189157  531.12829757  455.2836507   354.38017218]
total_rewards_mean           661.9550542546593
total_rewards_std            338.00726615240194
total_rewards_max            1320.2616390950432
total_rewards_min            354.38017218105233
Number of train steps total  212000
Number of env steps total    267000
Number of rollouts total     0
Train Time (s)               200.2623873599805
(Previous) Eval Time (s)     2.2416790178976953
Sample Time (s)              13.693308002315462
Epoch Time (s)               216.19737438019365
Total Train Time (s)         11312.293606612366
Epoch                        52
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:38:50.980562 UTC | [2020_01_13_04_30_18] Iteration #52 | Epoch Duration: 217.6360092163086
2020-01-13 07:38:50.980671 UTC | [2020_01_13_04_30_18] Iteration #52 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05493743
Z variance train             0.2345295
KL Divergence                1.7571092
KL Loss                      0.17571092
QF Loss                      332.88177
VF Loss                      152.37418
Policy Loss                  -288.08884
Q Predictions Mean           279.73203
Q Predictions Std            451.60898
Q Predictions Max            1522.698
Q Predictions Min            14.647266
V Predictions Mean           290.92554
V Predictions Std            450.68533
V Predictions Max            1516.5703
V Predictions Min            27.238583
Log Pis Mean                 -9.166712
Log Pis Std                  4.7119694
Log Pis Max                  11.401938
Log Pis Min                  -15.297574
Policy mu Mean               0.0874434
Policy mu Std                0.45564693
Policy mu Max                2.3284874
Policy mu Min                -2.0632708
Policy log std Mean          -0.19792865
Policy log std Std           0.11839748
Policy log std Max           -0.03509648
Policy log std Min           -0.841382
Z mean eval                  0.04276728
Z variance eval              0.23677619
total_rewards                [364.27513274 612.2328526  881.98070955 539.34738384 593.37921253
 486.28021933 642.06010904 587.4580281  533.40615373 501.26063112]
total_rewards_mean           574.168043258175
total_rewards_std            127.01236032273493
total_rewards_max            881.9807095545759
total_rewards_min            364.27513273851156
Number of train steps total  216000
Number of env steps total    272000
Number of rollouts total     0
Train Time (s)               200.0090381852351
(Previous) Eval Time (s)     3.6800791318528354
Sample Time (s)              14.671786873601377
Epoch Time (s)               218.36090419068933
Total Train Time (s)         11529.99029784603
Epoch                        53
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:42:28.678368 UTC | [2020_01_13_04_30_18] Iteration #53 | Epoch Duration: 217.69760990142822
2020-01-13 07:42:28.678477 UTC | [2020_01_13_04_30_18] Iteration #53 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04298876
Z variance train             0.23676857
KL Divergence                1.7901431
KL Loss                      0.17901431
QF Loss                      369.32147
VF Loss                      197.43633
Policy Loss                  -358.23605
Q Predictions Mean           349.5876
Q Predictions Std            497.81088
Q Predictions Max            1498.64
Q Predictions Min            5.2845616
V Predictions Mean           355.30176
V Predictions Std            491.17728
V Predictions Max            1484.9747
V Predictions Min            22.413952
Log Pis Mean                 -8.930655
Log Pis Std                  4.597077
Log Pis Max                  11.896338
Log Pis Min                  -14.639484
Policy mu Mean               0.08811253
Policy mu Std                0.47423583
Policy mu Max                2.3119385
Policy mu Min                -2.34895
Policy log std Mean          -0.19854708
Policy log std Std           0.11113713
Policy log std Max           0.030178294
Policy log std Min           -0.84791017
Z mean eval                  0.046069738
Z variance eval              0.23828539
total_rewards                [749.47341181 470.40015638 779.20691311 416.33210371 379.8116071
 517.950469   644.18651683 550.22054163 476.12786577 486.54032437]
total_rewards_mean           547.0249909725422
total_rewards_std            128.36931822052776
total_rewards_max            779.2069131149228
total_rewards_min            379.8116071004615
Number of train steps total  220000
Number of env steps total    277000
Number of rollouts total     0
Train Time (s)               200.5051794727333
(Previous) Eval Time (s)     3.0165530117228627
Sample Time (s)              14.57637171074748
Epoch Time (s)               218.09810419520363
Total Train Time (s)         11748.440788373817
Epoch                        54
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:46:07.129992 UTC | [2020_01_13_04_30_18] Iteration #54 | Epoch Duration: 218.45142531394958
2020-01-13 07:46:07.130118 UTC | [2020_01_13_04_30_18] Iteration #54 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045509182
Z variance train             0.23838544
KL Divergence                1.7883326
KL Loss                      0.17883326
QF Loss                      393.6125
VF Loss                      171.00233
Policy Loss                  -344.67334
Q Predictions Mean           335.12582
Q Predictions Std            489.8721
Q Predictions Max            1520.7191
Q Predictions Min            9.732577
V Predictions Mean           347.84308
V Predictions Std            492.17014
V Predictions Max            1530.0739
V Predictions Min            30.988283
Log Pis Mean                 -8.683483
Log Pis Std                  5.5172925
Log Pis Max                  35.84729
Log Pis Min                  -14.37557
Policy mu Mean               0.07759668
Policy mu Std                0.4900755
Policy mu Max                3.0408008
Policy mu Min                -2.7319815
Policy log std Mean          -0.20134497
Policy log std Std           0.123240545
Policy log std Max           0.0076559484
Policy log std Min           -0.9936737
Z mean eval                  0.04814731
Z variance eval              0.2737549
total_rewards                [376.09722032 461.82035455 348.39909418 501.16368823 407.48392848
 787.82766657 803.02966202 408.291461   456.17186091 598.97490614]
total_rewards_mean           514.9259842407695
total_rewards_std            155.21735793473192
total_rewards_max            803.0296620201385
total_rewards_min            348.3990941818089
Number of train steps total  224000
Number of env steps total    282000
Number of rollouts total     0
Train Time (s)               198.01554925600067
(Previous) Eval Time (s)     3.369599279947579
Sample Time (s)              14.496641287580132
Epoch Time (s)               215.88178982352838
Total Train Time (s)         11963.648774496745
Epoch                        55
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:49:42.338931 UTC | [2020_01_13_04_30_18] Iteration #55 | Epoch Duration: 215.2087206840515
2020-01-13 07:49:42.339042 UTC | [2020_01_13_04_30_18] Iteration #55 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.048405826
Z variance train             0.27347797
KL Divergence                1.5724003
KL Loss                      0.15724003
QF Loss                      328.10614
VF Loss                      166.22305
Policy Loss                  -332.96548
Q Predictions Mean           324.902
Q Predictions Std            507.22537
Q Predictions Max            1551.4539
Q Predictions Min            13.953418
V Predictions Mean           331.97357
V Predictions Std            499.93735
V Predictions Max            1545.4512
V Predictions Min            29.397793
Log Pis Mean                 -9.295731
Log Pis Std                  4.09094
Log Pis Max                  6.6413045
Log Pis Min                  -14.121346
Policy mu Mean               0.060577266
Policy mu Std                0.4278711
Policy mu Max                2.0305383
Policy mu Min                -1.8104762
Policy log std Mean          -0.19314101
Policy log std Std           0.110633984
Policy log std Max           -0.0053006113
Policy log std Min           -0.7984952
Z mean eval                  0.06028069
Z variance eval              0.26421395
total_rewards                [ 676.2116486  1046.82171597  544.53196141  450.0608857   406.38655323
  553.03226958  836.26932636  730.28816033  853.50348482  533.28919722]
total_rewards_mean           663.039520321647
total_rewards_std            192.99771323025817
total_rewards_max            1046.8217159716182
total_rewards_min            406.38655323046794
Number of train steps total  228000
Number of env steps total    287000
Number of rollouts total     0
Train Time (s)               193.52392804203555
(Previous) Eval Time (s)     2.6962714698165655
Sample Time (s)              14.136263752356172
Epoch Time (s)               210.3564632642083
Total Train Time (s)         12174.883191716392
Epoch                        56
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:53:13.575206 UTC | [2020_01_13_04_30_18] Iteration #56 | Epoch Duration: 211.2360610961914
2020-01-13 07:53:13.575356 UTC | [2020_01_13_04_30_18] Iteration #56 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06081288
Z variance train             0.26413292
KL Divergence                1.676957
KL Loss                      0.1676957
QF Loss                      234.66663
VF Loss                      112.0732
Policy Loss                  -356.0185
Q Predictions Mean           345.60785
Q Predictions Std            508.52576
Q Predictions Max            1537.5896
Q Predictions Min            19.522795
V Predictions Mean           356.20084
V Predictions Std            506.75323
V Predictions Max            1544.4661
V Predictions Min            28.038288
Log Pis Mean                 -8.882886
Log Pis Std                  4.6145506
Log Pis Max                  8.961489
Log Pis Min                  -13.417128
Policy mu Mean               0.08056721
Policy mu Std                0.4542599
Policy mu Max                2.3046021
Policy mu Min                -2.2038
Policy log std Mean          -0.1938219
Policy log std Std           0.1087302
Policy log std Max           -0.01568757
Policy log std Min           -0.77901185
Z mean eval                  0.060195677
Z variance eval              0.26706514
total_rewards                [485.14017629 632.79281016 452.18990473 473.24443375 762.23391401
 812.13926262 613.61559625 701.85690159 458.87342373 663.2020193 ]
total_rewards_mean           605.5288442427694
total_rewards_std            125.56734941564778
total_rewards_max            812.139262621068
total_rewards_min            452.18990472854915
Number of train steps total  232000
Number of env steps total    292000
Number of rollouts total     0
Train Time (s)               198.1955484552309
(Previous) Eval Time (s)     3.5756023502908647
Sample Time (s)              14.311883793678135
Epoch Time (s)               216.0830345991999
Total Train Time (s)         12390.76312277792
Epoch                        57
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:56:49.455691 UTC | [2020_01_13_04_30_18] Iteration #57 | Epoch Duration: 215.88022375106812
2020-01-13 07:56:49.455811 UTC | [2020_01_13_04_30_18] Iteration #57 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.060008634
Z variance train             0.26710472
KL Divergence                1.6348424
KL Loss                      0.16348425
QF Loss                      245.52774
VF Loss                      110.300964
Policy Loss                  -340.2687
Q Predictions Mean           329.9592
Q Predictions Std            508.56967
Q Predictions Max            1514.3922
Q Predictions Min            15.862278
V Predictions Mean           342.49945
V Predictions Std            507.66885
V Predictions Max            1524.6279
V Predictions Min            27.168837
Log Pis Mean                 -8.994355
Log Pis Std                  4.716047
Log Pis Max                  11.024607
Log Pis Min                  -13.797985
Policy mu Mean               0.07228966
Policy mu Std                0.4610825
Policy mu Max                2.2871983
Policy mu Min                -2.0770438
Policy log std Mean          -0.19956027
Policy log std Std           0.11755396
Policy log std Max           -0.08210334
Policy log std Min           -0.7833835
Z mean eval                  0.066508494
Z variance eval              0.24520592
total_rewards                [373.72002534 438.59881013 437.07925254 542.97063136 388.44696866
 466.32714757 488.33401255 521.28769849 457.92892545 732.21390032]
total_rewards_mean           484.69073724022576
total_rewards_std            96.45671073317776
total_rewards_max            732.2139003225714
total_rewards_min            373.7200253402366
Number of train steps total  236000
Number of env steps total    297000
Number of rollouts total     0
Train Time (s)               191.12027861410752
(Previous) Eval Time (s)     3.37253323988989
Sample Time (s)              14.233056707307696
Epoch Time (s)               208.7258685613051
Total Train Time (s)         12598.844094336033
Epoch                        58
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:00:17.537702 UTC | [2020_01_13_04_30_18] Iteration #58 | Epoch Duration: 208.08180165290833
2020-01-13 08:00:17.537812 UTC | [2020_01_13_04_30_18] Iteration #58 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06661864
Z variance train             0.24542058
KL Divergence                1.7722187
KL Loss                      0.17722188
QF Loss                      460.29507
VF Loss                      229.37384
Policy Loss                  -392.4985
Q Predictions Mean           384.8351
Q Predictions Std            505.7164
Q Predictions Max            1553.6469
Q Predictions Min            14.725359
V Predictions Mean           395.1449
V Predictions Std            503.45187
V Predictions Max            1559.8348
V Predictions Min            26.184116
Log Pis Mean                 -8.560076
Log Pis Std                  5.054714
Log Pis Max                  22.617659
Log Pis Min                  -13.849585
Policy mu Mean               0.09202328
Policy mu Std                0.506442
Policy mu Max                2.7158341
Policy mu Min                -2.185152
Policy log std Mean          -0.20373923
Policy log std Std           0.118496776
Policy log std Max           -0.0040445775
Policy log std Min           -0.89055735
Z mean eval                  0.06585108
Z variance eval              0.23514871
total_rewards                [520.86747813 702.33204616 511.01627244 411.9241678  352.62608023
 572.97709231 603.37382805 555.58455461 446.77672788 563.22814395]
total_rewards_mean           524.0706391569975
total_rewards_std            95.45129463691886
total_rewards_max            702.3320461622302
total_rewards_min            352.62608023386554
Number of train steps total  240000
Number of env steps total    302000
Number of rollouts total     0
Train Time (s)               197.48011298431084
(Previous) Eval Time (s)     2.7282428089529276
Sample Time (s)              14.208977183327079
Epoch Time (s)               214.41733297659084
Total Train Time (s)         12813.167532104999
Epoch                        59
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:03:51.864855 UTC | [2020_01_13_04_30_18] Iteration #59 | Epoch Duration: 214.32695245742798
2020-01-13 08:03:51.864982 UTC | [2020_01_13_04_30_18] Iteration #59 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06545677
Z variance train             0.23514357
KL Divergence                1.823291
KL Loss                      0.1823291
QF Loss                      390.80713
VF Loss                      220.2641
Policy Loss                  -397.45242
Q Predictions Mean           388.83902
Q Predictions Std            526.3228
Q Predictions Max            1520.1143
Q Predictions Min            16.58471
V Predictions Mean           401.39185
V Predictions Std            528.32947
V Predictions Max            1568.5934
V Predictions Min            29.564596
Log Pis Mean                 -8.878558
Log Pis Std                  4.207208
Log Pis Max                  4.3783054
Log Pis Min                  -14.939777
Policy mu Mean               0.08723274
Policy mu Std                0.47587782
Policy mu Max                2.1969664
Policy mu Min                -2.4424949
Policy log std Mean          -0.21085587
Policy log std Std           0.119901024
Policy log std Max           -0.014796846
Policy log std Min           -0.8537017
Z mean eval                  0.07362752
Z variance eval              0.24966767
total_rewards                [405.21809035 623.20746731 426.72065493 420.30730521 562.68405366
 505.13405463 568.82649445 569.06382343 423.50111503 359.95204793]
total_rewards_mean           486.4615106941331
total_rewards_std            85.42811417285183
total_rewards_max            623.2074673076264
total_rewards_min            359.9520479330396
Number of train steps total  244000
Number of env steps total    307000
Number of rollouts total     0
Train Time (s)               194.8333951048553
(Previous) Eval Time (s)     2.637617610860616
Sample Time (s)              14.495976253878325
Epoch Time (s)               211.96698896959424
Total Train Time (s)         13025.030470173806
Epoch                        60
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:07:23.736061 UTC | [2020_01_13_04_30_18] Iteration #60 | Epoch Duration: 211.87090969085693
2020-01-13 08:07:23.736295 UTC | [2020_01_13_04_30_18] Iteration #60 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0730311
Z variance train             0.24955945
KL Divergence                1.7080473
KL Loss                      0.17080472
QF Loss                      340.89563
VF Loss                      122.380745
Policy Loss                  -393.9117
Q Predictions Mean           386.86523
Q Predictions Std            546.4506
Q Predictions Max            1556.0684
Q Predictions Min            16.450426
V Predictions Mean           397.1799
V Predictions Std            547.79034
V Predictions Max            1561.1815
V Predictions Min            24.0225
Log Pis Mean                 -9.233597
Log Pis Std                  4.061692
Log Pis Max                  4.7974806
Log Pis Min                  -14.67675
Policy mu Mean               0.0791167
Policy mu Std                0.45410296
Policy mu Max                2.1787333
Policy mu Min                -2.4265854
Policy log std Mean          -0.20343487
Policy log std Std           0.11460821
Policy log std Max           -0.04429023
Policy log std Min           -0.7197716
Z mean eval                  0.070521
Z variance eval              0.2345877
total_rewards                [581.46302704 651.32810111 517.01622953 641.03342445 472.08164059
 574.45524991 673.47623363 550.50617769 593.33275407 535.96907029]
total_rewards_mean           579.0661908308285
total_rewards_std            60.145196121367796
total_rewards_max            673.4762336258921
total_rewards_min            472.08164058655547
Number of train steps total  248000
Number of env steps total    312000
Number of rollouts total     0
Train Time (s)               190.74040168710053
(Previous) Eval Time (s)     2.541269757784903
Sample Time (s)              14.00668309489265
Epoch Time (s)               207.28835453977808
Total Train Time (s)         13232.650436249562
Epoch                        61
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:10:51.354957 UTC | [2020_01_13_04_30_18] Iteration #61 | Epoch Duration: 207.61855244636536
2020-01-13 08:10:51.355068 UTC | [2020_01_13_04_30_18] Iteration #61 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07030134
Z variance train             0.2347165
KL Divergence                1.8049405
KL Loss                      0.18049406
QF Loss                      375.44336
VF Loss                      169.61803
Policy Loss                  -406.90994
Q Predictions Mean           397.84924
Q Predictions Std            528.1273
Q Predictions Max            1560.6428
Q Predictions Min            13.146892
V Predictions Mean           407.8346
V Predictions Std            530.55176
V Predictions Max            1573.2806
V Predictions Min            23.203634
Log Pis Mean                 -8.47739
Log Pis Std                  4.9801245
Log Pis Max                  9.386099
Log Pis Min                  -14.416493
Policy mu Mean               0.09758325
Policy mu Std                0.49518958
Policy mu Max                2.4024403
Policy mu Min                -2.1113899
Policy log std Mean          -0.2075872
Policy log std Std           0.12038754
Policy log std Max           -0.012493283
Policy log std Min           -0.9199439
Z mean eval                  0.07375769
Z variance eval              0.24618265
total_rewards                [ 706.57972183  537.59179233  564.88182268  589.86491317  512.15524468
  717.54323706 1042.56992169  552.1953588   668.24099389  432.30340026]
total_rewards_mean           632.39264063921
total_rewards_std            160.79885320021341
total_rewards_max            1042.569921687544
total_rewards_min            432.3034002620288
Number of train steps total  252000
Number of env steps total    317000
Number of rollouts total     0
Train Time (s)               196.20458202576265
(Previous) Eval Time (s)     2.871224767062813
Sample Time (s)              12.950615348760039
Epoch Time (s)               212.0264221415855
Total Train Time (s)         13445.195467373822
Epoch                        62
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:14:23.901011 UTC | [2020_01_13_04_30_18] Iteration #62 | Epoch Duration: 212.54584956169128
2020-01-13 08:14:23.901161 UTC | [2020_01_13_04_30_18] Iteration #62 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07347449
Z variance train             0.2461386
KL Divergence                1.6451963
KL Loss                      0.16451964
QF Loss                      346.97516
VF Loss                      211.10283
Policy Loss                  -410.02933
Q Predictions Mean           401.80228
Q Predictions Std            555.5075
Q Predictions Max            1582.9124
Q Predictions Min            17.550999
V Predictions Mean           412.04156
V Predictions Std            555.0955
V Predictions Max            1586.3839
V Predictions Min            29.085197
Log Pis Mean                 -8.723621
Log Pis Std                  5.0528803
Log Pis Max                  19.903332
Log Pis Min                  -13.422993
Policy mu Mean               0.068309836
Policy mu Std                0.48382935
Policy mu Max                2.8779962
Policy mu Min                -2.6304066
Policy log std Mean          -0.20189145
Policy log std Std           0.11765479
Policy log std Max           -0.0006901622
Policy log std Min           -0.9861485
Z mean eval                  0.069916956
Z variance eval              0.23308678
total_rewards                [544.77807087 556.70833279 575.48559208 368.7131972  626.04335865
 451.78458456 347.21151908 671.62111062 621.31397534 433.03952528]
total_rewards_mean           519.6699266474549
total_rewards_std            107.00313805935474
total_rewards_max            671.6211106236494
total_rewards_min            347.2115190764552
Number of train steps total  256000
Number of env steps total    322000
Number of rollouts total     0
Train Time (s)               199.60752566205338
(Previous) Eval Time (s)     3.390383606776595
Sample Time (s)              14.754810186102986
Epoch Time (s)               217.75271945493296
Total Train Time (s)         13662.44588208478
Epoch                        63
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:18:01.153288 UTC | [2020_01_13_04_30_18] Iteration #63 | Epoch Duration: 217.2520353794098
2020-01-13 08:18:01.153426 UTC | [2020_01_13_04_30_18] Iteration #63 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06980349
Z variance train             0.23300107
KL Divergence                1.7718531
KL Loss                      0.17718531
QF Loss                      404.38843
VF Loss                      237.96179
Policy Loss                  -408.21725
Q Predictions Mean           400.28134
Q Predictions Std            537.83716
Q Predictions Max            1559.7959
Q Predictions Min            16.729536
V Predictions Mean           413.02362
V Predictions Std            539.8811
V Predictions Max            1588.0076
V Predictions Min            27.726967
Log Pis Mean                 -8.419437
Log Pis Std                  4.9852004
Log Pis Max                  9.70999
Log Pis Min                  -13.391289
Policy mu Mean               0.10275407
Policy mu Std                0.49549037
Policy mu Max                2.3566632
Policy mu Min                -1.921666
Policy log std Mean          -0.21242198
Policy log std Std           0.12846446
Policy log std Max           -0.023833647
Policy log std Min           -0.83547705
Z mean eval                  0.073132694
Z variance eval              0.2094671
total_rewards                [503.68104218 551.03586865 516.96545983 481.05268853 472.64027842
 445.68766074 457.65240651 670.00860094 680.00855387 457.09983015]
total_rewards_mean           523.583238980881
total_rewards_std            81.45027775092179
total_rewards_max            680.0085538683866
total_rewards_min            445.6876607372428
Number of train steps total  260000
Number of env steps total    327000
Number of rollouts total     0
Train Time (s)               202.14130129572004
(Previous) Eval Time (s)     2.8894562968052924
Sample Time (s)              14.370351873338223
Epoch Time (s)               219.40110946586356
Total Train Time (s)         13881.638325207867
Epoch                        64
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:21:40.346353 UTC | [2020_01_13_04_30_18] Iteration #64 | Epoch Duration: 219.19283866882324
2020-01-13 08:21:40.346464 UTC | [2020_01_13_04_30_18] Iteration #64 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.072905466
Z variance train             0.20959274
KL Divergence                1.952323
KL Loss                      0.1952323
QF Loss                      270.42932
VF Loss                      136.61426
Policy Loss                  -352.17923
Q Predictions Mean           342.6209
Q Predictions Std            490.09668
Q Predictions Max            1586.661
Q Predictions Min            13.778596
V Predictions Mean           353.0674
V Predictions Std            490.52933
V Predictions Max            1596.7151
V Predictions Min            28.119694
Log Pis Mean                 -8.839314
Log Pis Std                  4.387039
Log Pis Max                  11.485825
Log Pis Min                  -13.781522
Policy mu Mean               0.0869666
Policy mu Std                0.4582258
Policy mu Max                2.280697
Policy mu Min                -2.0758522
Policy log std Mean          -0.19703309
Policy log std Std           0.1109747
Policy log std Max           -0.015103348
Policy log std Min           -0.79374206
Z mean eval                  0.06935012
Z variance eval              0.2044299
total_rewards                [426.44851101 849.05466304 456.03956453 865.35098868 456.09923314
 725.35062817 522.07739598 689.5983295  963.53866223 525.76701118]
total_rewards_mean           647.9324987478428
total_rewards_std            186.68148098930035
total_rewards_max            963.5386622308232
total_rewards_min            426.4485110148727
Number of train steps total  264000
Number of env steps total    332000
Number of rollouts total     0
Train Time (s)               201.17163217673078
(Previous) Eval Time (s)     2.6809381088241935
Sample Time (s)              13.769343567080796
Epoch Time (s)               217.62191385263577
Total Train Time (s)         14100.148742107209
Epoch                        65
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:25:18.858280 UTC | [2020_01_13_04_30_18] Iteration #65 | Epoch Duration: 218.51172542572021
2020-01-13 08:25:18.858408 UTC | [2020_01_13_04_30_18] Iteration #65 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.069969095
Z variance train             0.20426016
KL Divergence                2.0139093
KL Loss                      0.20139094
QF Loss                      361.69415
VF Loss                      368.3246
Policy Loss                  -427.58307
Q Predictions Mean           420.80286
Q Predictions Std            555.2434
Q Predictions Max            1597.6383
Q Predictions Min            13.384043
V Predictions Mean           418.57916
V Predictions Std            541.6807
V Predictions Max            1587.9357
V Predictions Min            24.786999
Log Pis Mean                 -8.311694
Log Pis Std                  4.8265376
Log Pis Max                  13.796272
Log Pis Min                  -13.89061
Policy mu Mean               0.093901664
Policy mu Std                0.49773702
Policy mu Max                2.6313605
Policy mu Min                -2.111391
Policy log std Mean          -0.21666266
Policy log std Std           0.12516983
Policy log std Max           -0.045595042
Policy log std Min           -0.82076627
Z mean eval                  0.052876066
Z variance eval              0.19079417
total_rewards                [554.98594342 516.74654789 700.00815181 403.4674201  703.05723331
 419.15928996 536.39512782 775.47306467 524.27039153 722.86063428]
total_rewards_mean           585.6423804797626
total_rewards_std            124.3032246479366
total_rewards_max            775.473064671378
total_rewards_min            403.46742009598336
Number of train steps total  268000
Number of env steps total    337000
Number of rollouts total     0
Train Time (s)               199.97071687038988
(Previous) Eval Time (s)     3.570387878920883
Sample Time (s)              14.716759551782161
Epoch Time (s)               218.25786430109292
Total Train Time (s)         14318.073558146134
Epoch                        66
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:28:56.786454 UTC | [2020_01_13_04_30_18] Iteration #66 | Epoch Duration: 217.9279305934906
2020-01-13 08:28:56.786670 UTC | [2020_01_13_04_30_18] Iteration #66 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.052823655
Z variance train             0.19083156
KL Divergence                2.136838
KL Loss                      0.2136838
QF Loss                      424.2252
VF Loss                      256.67883
Policy Loss                  -426.40686
Q Predictions Mean           417.55228
Q Predictions Std            553.9108
Q Predictions Max            1599.064
Q Predictions Min            15.212816
V Predictions Mean           425.13486
V Predictions Std            548.7907
V Predictions Max            1607.8834
V Predictions Min            28.153135
Log Pis Mean                 -8.654863
Log Pis Std                  4.4042573
Log Pis Max                  6.7493687
Log Pis Min                  -13.995261
Policy mu Mean               0.09703618
Policy mu Std                0.47709298
Policy mu Max                2.2215855
Policy mu Min                -2.0081468
Policy log std Mean          -0.21151952
Policy log std Std           0.12582158
Policy log std Max           -0.01845795
Policy log std Min           -0.85315144
Z mean eval                  0.04257695
Z variance eval              0.20034468
total_rewards                [357.33842843 808.22684048 365.80195026 606.87413326 603.52088226
 734.28872122 397.91443081 746.72304423 374.12698709 502.92712062]
total_rewards_mean           549.7742538664313
total_rewards_std            165.15647973665608
total_rewards_max            808.2268404845101
total_rewards_min            357.33842843480215
Number of train steps total  272000
Number of env steps total    342000
Number of rollouts total     0
Train Time (s)               201.0223740390502
(Previous) Eval Time (s)     3.2401256849989295
Sample Time (s)              14.323835193179548
Epoch Time (s)               218.58633491722867
Total Train Time (s)         14536.395529654343
Epoch                        67
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:32:35.108575 UTC | [2020_01_13_04_30_18] Iteration #67 | Epoch Duration: 218.3217613697052
2020-01-13 08:32:35.108697 UTC | [2020_01_13_04_30_18] Iteration #67 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04265058
Z variance train             0.20046036
KL Divergence                2.0365343
KL Loss                      0.20365344
QF Loss                      565.06537
VF Loss                      208.64227
Policy Loss                  -454.53925
Q Predictions Mean           442.26654
Q Predictions Std            559.9631
Q Predictions Max            1593.1923
Q Predictions Min            11.242006
V Predictions Mean           453.6034
V Predictions Std            562.1169
V Predictions Max            1614.1517
V Predictions Min            24.442223
Log Pis Mean                 -8.239212
Log Pis Std                  5.0266976
Log Pis Max                  13.937485
Log Pis Min                  -14.722829
Policy mu Mean               0.07831714
Policy mu Std                0.5146664
Policy mu Max                2.4931846
Policy mu Min                -2.3732858
Policy log std Mean          -0.21547012
Policy log std Std           0.1247574
Policy log std Max           -0.047952943
Policy log std Min           -0.77292323
Z mean eval                  0.036315065
Z variance eval              0.18592001
total_rewards                [507.44753548 457.76813901 630.34547186 575.10305146 400.09745038
 524.86059832 626.90803275 564.48064624 559.7678048  659.6136378 ]
total_rewards_mean           550.6392368113732
total_rewards_std            76.63991019173447
total_rewards_max            659.6136378021266
total_rewards_min            400.0974503808554
Number of train steps total  276000
Number of env steps total    347000
Number of rollouts total     0
Train Time (s)               201.99142795987427
(Previous) Eval Time (s)     2.975344595964998
Sample Time (s)              14.276838696561754
Epoch Time (s)               219.24361125240102
Total Train Time (s)         14755.72881225124
Epoch                        68
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:36:14.442703 UTC | [2020_01_13_04_30_18] Iteration #68 | Epoch Duration: 219.33391952514648
2020-01-13 08:36:14.442850 UTC | [2020_01_13_04_30_18] Iteration #68 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03672071
Z variance train             0.18590848
KL Divergence                2.2073908
KL Loss                      0.22073908
QF Loss                      351.2358
VF Loss                      174.63293
Policy Loss                  -404.12488
Q Predictions Mean           395.7417
Q Predictions Std            535.00934
Q Predictions Max            1616.031
Q Predictions Min            12.737694
V Predictions Mean           408.662
V Predictions Std            533.4535
V Predictions Max            1623.9608
V Predictions Min            27.91253
Log Pis Mean                 -8.6021805
Log Pis Std                  4.7707567
Log Pis Max                  14.695736
Log Pis Min                  -14.532179
Policy mu Mean               0.08070961
Policy mu Std                0.4949325
Policy mu Max                2.6098099
Policy mu Min                -2.1000218
Policy log std Mean          -0.20643747
Policy log std Std           0.122300506
Policy log std Max           0.039181635
Policy log std Min           -0.9341311
Z mean eval                  0.03557547
Z variance eval              0.19685487
total_rewards                [447.20923016 720.37210391 387.39721569 442.50242086 575.40602058
 718.06499903 565.87167906 414.6810148  654.29421014 455.56944265]
total_rewards_mean           538.1368336884452
total_rewards_std            119.7620574970802
total_rewards_max            720.3721039111726
total_rewards_min            387.39721568602357
Number of train steps total  280000
Number of env steps total    352000
Number of rollouts total     0
Train Time (s)               205.20791180012748
(Previous) Eval Time (s)     3.065397137776017
Sample Time (s)              14.400358725804836
Epoch Time (s)               222.67366766370833
Total Train Time (s)         14978.379887696821
Epoch                        69
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:39:57.094753 UTC | [2020_01_13_04_30_18] Iteration #69 | Epoch Duration: 222.65181279182434
2020-01-13 08:39:57.094863 UTC | [2020_01_13_04_30_18] Iteration #69 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035919692
Z variance train             0.19675322
KL Divergence                2.1481333
KL Loss                      0.21481334
QF Loss                      451.0324
VF Loss                      222.19046
Policy Loss                  -407.2782
Q Predictions Mean           400.10522
Q Predictions Std            537.55927
Q Predictions Max            1610.2893
Q Predictions Min            14.686514
V Predictions Mean           411.5901
V Predictions Std            537.1348
V Predictions Max            1613.5204
V Predictions Min            31.076422
Log Pis Mean                 -8.904982
Log Pis Std                  4.424477
Log Pis Max                  11.264362
Log Pis Min                  -15.590836
Policy mu Mean               0.07969552
Policy mu Std                0.48106253
Policy mu Max                2.711405
Policy mu Min                -2.164619
Policy log std Mean          -0.2050579
Policy log std Std           0.11695621
Policy log std Max           0.023031965
Policy log std Min           -0.8940602
Z mean eval                  0.035811067
Z variance eval              0.2251058
total_rewards                [592.42827031 494.08974269 757.45110037 467.78295678 691.31689316
 635.70982776 526.96120375 553.82818189 437.17659778 780.50242858]
total_rewards_mean           593.7247203071095
total_rewards_std            113.72149059079919
total_rewards_max            780.5024285796654
total_rewards_min            437.1765977844961
Number of train steps total  284000
Number of env steps total    357000
Number of rollouts total     0
Train Time (s)               195.63450432475656
(Previous) Eval Time (s)     3.043303776998073
Sample Time (s)              14.745823045261204
Epoch Time (s)               213.42363114701584
Total Train Time (s)         15191.722802571487
Epoch                        70
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:43:30.438663 UTC | [2020_01_13_04_30_18] Iteration #70 | Epoch Duration: 213.3437111377716
2020-01-13 08:43:30.438773 UTC | [2020_01_13_04_30_18] Iteration #70 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03582073
Z variance train             0.22531052
KL Divergence                1.8640612
KL Loss                      0.18640612
QF Loss                      323.58142
VF Loss                      249.57571
Policy Loss                  -451.0292
Q Predictions Mean           440.80554
Q Predictions Std            574.11115
Q Predictions Max            1623.65
Q Predictions Min            5.215476
V Predictions Mean           455.63116
V Predictions Std            579.3075
V Predictions Max            1625.904
V Predictions Min            26.099762
Log Pis Mean                 -8.342539
Log Pis Std                  5.722806
Log Pis Max                  23.813463
Log Pis Min                  -14.459997
Policy mu Mean               0.087675504
Policy mu Std                0.5213536
Policy mu Max                2.693104
Policy mu Min                -2.6858337
Policy log std Mean          -0.21423651
Policy log std Std           0.12614802
Policy log std Max           -0.040701002
Policy log std Min           -0.90240955
Z mean eval                  0.044014577
Z variance eval              0.24112704
total_rewards                [555.97364819 540.37373029 637.7724775  498.04439851 458.80487419
 509.22606959 611.91796797 564.99203541 514.485825   920.1710524 ]
total_rewards_mean           581.1762079047012
total_rewards_std            123.74882116448842
total_rewards_max            920.1710523974102
total_rewards_min            458.80487418720963
Number of train steps total  288000
Number of env steps total    362000
Number of rollouts total     0
Train Time (s)               200.67248666426167
(Previous) Eval Time (s)     2.9631278961896896
Sample Time (s)              14.290632906835526
Epoch Time (s)               217.92624746728688
Total Train Time (s)         15409.831564726774
Epoch                        71
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:47:08.548389 UTC | [2020_01_13_04_30_18] Iteration #71 | Epoch Duration: 218.10951042175293
2020-01-13 08:47:08.548498 UTC | [2020_01_13_04_30_18] Iteration #71 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.044174753
Z variance train             0.24087305
KL Divergence                1.7397007
KL Loss                      0.17397007
QF Loss                      293.95746
VF Loss                      167.36108
Policy Loss                  -417.22678
Q Predictions Mean           410.701
Q Predictions Std            558.53503
Q Predictions Max            1651.9589
Q Predictions Min            15.01289
V Predictions Mean           419.7163
V Predictions Std            555.37225
V Predictions Max            1635.9027
V Predictions Min            29.414467
Log Pis Mean                 -8.857741
Log Pis Std                  4.6714563
Log Pis Max                  11.460926
Log Pis Min                  -14.519133
Policy mu Mean               0.092843324
Policy mu Std                0.48222113
Policy mu Max                2.5917804
Policy mu Min                -1.9781909
Policy log std Mean          -0.20902169
Policy log std Std           0.12263186
Policy log std Max           -0.08026342
Policy log std Min           -0.9143883
Z mean eval                  0.043046627
Z variance eval              0.24429548
total_rewards                [ 568.97244331 1175.99294562  446.65759732  523.09203867  594.11108373
  744.08272441  733.55997776  937.41136653  689.10582251  575.97084865]
total_rewards_mean           698.8956848512042
total_rewards_std            206.24068494946096
total_rewards_max            1175.9929456197744
total_rewards_min            446.6575973152304
Number of train steps total  292000
Number of env steps total    367000
Number of rollouts total     0
Train Time (s)               195.6396371331066
(Previous) Eval Time (s)     3.1461580842733383
Sample Time (s)              14.332700408995152
Epoch Time (s)               213.11849562637508
Total Train Time (s)         15623.463436059654
Epoch                        72
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:50:42.181316 UTC | [2020_01_13_04_30_18] Iteration #72 | Epoch Duration: 213.63271570205688
2020-01-13 08:50:42.181462 UTC | [2020_01_13_04_30_18] Iteration #72 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.042760175
Z variance train             0.24441504
KL Divergence                1.6666715
KL Loss                      0.16666715
QF Loss                      564.1459
VF Loss                      168.33252
Policy Loss                  -450.66632
Q Predictions Mean           445.3453
Q Predictions Std            568.3196
Q Predictions Max            1628.7762
Q Predictions Min            10.519542
V Predictions Mean           449.32434
V Predictions Std            561.2945
V Predictions Max            1626.5724
V Predictions Min            25.155548
Log Pis Mean                 -8.629782
Log Pis Std                  4.8001103
Log Pis Max                  14.597574
Log Pis Min                  -14.745146
Policy mu Mean               0.09989834
Policy mu Std                0.48756376
Policy mu Max                2.3138232
Policy mu Min                -2.2840478
Policy log std Mean          -0.20922834
Policy log std Std           0.11941087
Policy log std Max           -0.042487226
Policy log std Min           -0.8238216
Z mean eval                  0.043171167
Z variance eval              0.24741733
total_rewards                [702.35803453 530.50721797 448.10831352 671.93201616 457.5773683
 550.66206689 779.38890735 375.7431185  856.01778309 727.54991555]
total_rewards_mean           609.9844741859754
total_rewards_std            151.51200248537543
total_rewards_max            856.0177830920169
total_rewards_min            375.7431184977535
Number of train steps total  296000
Number of env steps total    372000
Number of rollouts total     0
Train Time (s)               201.37200728664175
(Previous) Eval Time (s)     3.6601325729861856
Sample Time (s)              14.650880432222039
Epoch Time (s)               219.68302029184997
Total Train Time (s)         15842.787049182225
Epoch                        73
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:54:21.507582 UTC | [2020_01_13_04_30_18] Iteration #73 | Epoch Duration: 219.3260064125061
2020-01-13 08:54:21.507770 UTC | [2020_01_13_04_30_18] Iteration #73 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04332108
Z variance train             0.2475169
KL Divergence                1.6503968
KL Loss                      0.16503969
QF Loss                      322.60153
VF Loss                      149.59605
Policy Loss                  -344.26965
Q Predictions Mean           334.58163
Q Predictions Std            500.21152
Q Predictions Max            1568.4979
Q Predictions Min            2.8819816
V Predictions Mean           345.24622
V Predictions Std            499.3539
V Predictions Max            1584.0441
V Predictions Min            26.583576
Log Pis Mean                 -9.395089
Log Pis Std                  4.0638733
Log Pis Max                  20.349329
Log Pis Min                  -14.372776
Policy mu Mean               0.080246784
Policy mu Std                0.43118793
Policy mu Max                2.2848074
Policy mu Min                -3.5158205
Policy log std Mean          -0.19171126
Policy log std Std           0.10385404
Policy log std Max           0.048064277
Policy log std Min           -0.84388745
Z mean eval                  0.054953605
Z variance eval              0.23290443
total_rewards                [ 610.30586628  580.09617357  496.5238544   440.68019467  867.39216147
  760.03397006  414.7613228   820.18464934 1073.86174131  566.30683798]
total_rewards_mean           663.0146771872462
total_rewards_std            200.61611521283467
total_rewards_max            1073.8617413148925
total_rewards_min            414.7613227969228
Number of train steps total  300000
Number of env steps total    377000
Number of rollouts total     0
Train Time (s)               197.45747718866915
(Previous) Eval Time (s)     3.3028774387203157
Sample Time (s)              14.420039254706353
Epoch Time (s)               215.1803938820958
Total Train Time (s)         16058.200307939667
Epoch                        74
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:57:56.921224 UTC | [2020_01_13_04_30_18] Iteration #74 | Epoch Duration: 215.4133162498474
2020-01-13 08:57:56.921350 UTC | [2020_01_13_04_30_18] Iteration #74 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.054845817
Z variance train             0.23283443
KL Divergence                1.7928605
KL Loss                      0.17928605
QF Loss                      734.862
VF Loss                      180.20981
Policy Loss                  -508.42123
Q Predictions Mean           502.03522
Q Predictions Std            583.4639
Q Predictions Max            1631.1306
Q Predictions Min            19.134588
V Predictions Mean           507.83588
V Predictions Std            576.7914
V Predictions Max            1638.3741
V Predictions Min            29.356125
Log Pis Mean                 -8.36252
Log Pis Std                  4.4450817
Log Pis Max                  8.228678
Log Pis Min                  -14.193539
Policy mu Mean               0.110766046
Policy mu Std                0.5038672
Policy mu Max                1.8977003
Policy mu Min                -2.9930356
Policy log std Mean          -0.22053766
Policy log std Std           0.1255088
Policy log std Max           -0.012329347
Policy log std Min           -0.77553767
Z mean eval                  0.059694074
Z variance eval              0.22786888
total_rewards                [504.55766104 525.44336563 442.76290611 447.76569603 397.35006301
 552.94266109 559.4761692  862.96083996 520.37085523 553.03743995]
total_rewards_mean           536.6667657249552
total_rewards_std            120.446664638408
total_rewards_max            862.9608399639899
total_rewards_min            397.3500630128665
Number of train steps total  304000
Number of env steps total    382000
Number of rollouts total     0
Train Time (s)               202.18872190779075
(Previous) Eval Time (s)     3.535558889620006
Sample Time (s)              15.269945000298321
Epoch Time (s)               220.99422579770908
Total Train Time (s)         16278.636265148409
Epoch                        75
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:01:37.362704 UTC | [2020_01_13_04_30_18] Iteration #75 | Epoch Duration: 220.4412055015564
2020-01-13 09:01:37.363067 UTC | [2020_01_13_04_30_18] Iteration #75 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.059454422
Z variance train             0.22784226
KL Divergence                1.9147544
KL Loss                      0.19147544
QF Loss                      398.63397
VF Loss                      200.43567
Policy Loss                  -437.47687
Q Predictions Mean           427.22418
Q Predictions Std            571.7469
Q Predictions Max            1609.6171
Q Predictions Min            15.006781
V Predictions Mean           432.5097
V Predictions Std            567.0111
V Predictions Max            1599.4683
V Predictions Min            20.629456
Log Pis Mean                 -8.649241
Log Pis Std                  5.012521
Log Pis Max                  23.576778
Log Pis Min                  -15.127769
Policy mu Mean               0.08453476
Policy mu Std                0.48928034
Policy mu Max                2.5996935
Policy mu Min                -2.6848574
Policy log std Mean          -0.20797539
Policy log std Std           0.12223227
Policy log std Max           -0.026426889
Policy log std Min           -0.87853885
Z mean eval                  0.055492323
Z variance eval              0.2295028
total_rewards                [638.60602715 582.40304854 736.9683143  729.81558837 474.07164413
 372.00524079 689.305622   554.83840505 984.84711694 533.80165452]
total_rewards_mean           629.6662661791457
total_rewards_std            160.92102405574926
total_rewards_max            984.8471169424961
total_rewards_min            372.0052407890563
Number of train steps total  308000
Number of env steps total    387000
Number of rollouts total     0
Train Time (s)               197.06845198292285
(Previous) Eval Time (s)     2.9822537978179753
Sample Time (s)              13.660173781216145
Epoch Time (s)               213.71087956195697
Total Train Time (s)         16492.730004257523
Epoch                        76
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:05:11.456424 UTC | [2020_01_13_04_30_18] Iteration #76 | Epoch Duration: 214.09313416481018
2020-01-13 09:05:11.456598 UTC | [2020_01_13_04_30_18] Iteration #76 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05530072
Z variance train             0.22969382
KL Divergence                1.907668
KL Loss                      0.1907668
QF Loss                      465.89276
VF Loss                      240.26402
Policy Loss                  -433.702
Q Predictions Mean           424.9389
Q Predictions Std            559.9597
Q Predictions Max            1639.1008
Q Predictions Min            17.64314
V Predictions Mean           438.3827
V Predictions Std            561.7785
V Predictions Max            1659.1277
V Predictions Min            32.406918
Log Pis Mean                 -8.961677
Log Pis Std                  4.2224927
Log Pis Max                  13.273878
Log Pis Min                  -14.473576
Policy mu Mean               0.08129912
Policy mu Std                0.46321383
Policy mu Max                2.1264133
Policy mu Min                -3.25757
Policy log std Mean          -0.20379332
Policy log std Std           0.1141673
Policy log std Max           0.16622676
Policy log std Min           -0.8916632
Z mean eval                  0.047454044
Z variance eval              0.21469116
total_rewards                [742.73205679 813.03259674 876.94146588 934.88640502 771.5670435
 759.61017301 489.54018084 633.45731059 969.3785882  979.85549617]
total_rewards_mean           797.1001316738675
total_rewards_std            146.6554971544436
total_rewards_max            979.8554961703004
total_rewards_min            489.54018083859233
Number of train steps total  312000
Number of env steps total    392000
Number of rollouts total     0
Train Time (s)               195.61518014688045
(Previous) Eval Time (s)     3.3642425751313567
Sample Time (s)              14.270825447514653
Epoch Time (s)               213.25024816952646
Total Train Time (s)         16706.67992104264
Epoch                        77
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:08:45.407910 UTC | [2020_01_13_04_30_18] Iteration #77 | Epoch Duration: 213.95118188858032
2020-01-13 09:08:45.408080 UTC | [2020_01_13_04_30_18] Iteration #77 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04642559
Z variance train             0.21454528
KL Divergence                2.0189183
KL Loss                      0.20189182
QF Loss                      485.91617
VF Loss                      252.23538
Policy Loss                  -446.43518
Q Predictions Mean           439.7998
Q Predictions Std            570.43494
Q Predictions Max            1621.4965
Q Predictions Min            16.262793
V Predictions Mean           451.36154
V Predictions Std            573.0307
V Predictions Max            1651.5896
V Predictions Min            25.826351
Log Pis Mean                 -8.406736
Log Pis Std                  4.6074
Log Pis Max                  8.38023
Log Pis Min                  -14.147726
Policy mu Mean               0.10468065
Policy mu Std                0.4953025
Policy mu Max                2.2706523
Policy mu Min                -2.4689834
Policy log std Mean          -0.21393503
Policy log std Std           0.12527966
Policy log std Max           -0.058245197
Policy log std Min           -0.79475373
Z mean eval                  0.04455505
Z variance eval              0.22482815
total_rewards                [488.9658591  979.00632882 986.77055295 529.27828068 600.61493586
 745.18786555 450.53907893 447.18074226 675.45570681 481.26223723]
total_rewards_mean           638.4261588190877
total_rewards_std            195.54183952288608
total_rewards_max            986.7705529471862
total_rewards_min            447.18074225552084
Number of train steps total  316000
Number of env steps total    397000
Number of rollouts total     0
Train Time (s)               201.68977414164692
(Previous) Eval Time (s)     4.064794545993209
Sample Time (s)              15.251828911248595
Epoch Time (s)               221.00639759888873
Total Train Time (s)         16927.142498988193
Epoch                        78
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:12:25.872285 UTC | [2020_01_13_04_30_18] Iteration #78 | Epoch Duration: 220.4640510082245
2020-01-13 09:12:25.872510 UTC | [2020_01_13_04_30_18] Iteration #78 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.044236563
Z variance train             0.22470956
KL Divergence                2.0491343
KL Loss                      0.20491342
QF Loss                      420.69946
VF Loss                      154.34511
Policy Loss                  -497.04657
Q Predictions Mean           487.90973
Q Predictions Std            593.5116
Q Predictions Max            1661.8561
Q Predictions Min            16.639679
V Predictions Mean           497.21753
V Predictions Std            589.72375
V Predictions Max            1658.3207
V Predictions Min            28.767946
Log Pis Mean                 -8.501366
Log Pis Std                  4.456055
Log Pis Max                  6.6826854
Log Pis Min                  -13.027515
Policy mu Mean               0.106667615
Policy mu Std                0.4855293
Policy mu Max                1.9980772
Policy mu Min                -2.5929804
Policy log std Mean          -0.22073591
Policy log std Std           0.13023789
Policy log std Max           -0.064755715
Policy log std Min           -0.9486111
Z mean eval                  0.04364384
Z variance eval              0.21476984
total_rewards                [ 669.10561452  483.02641208  722.0829492   623.59824415  762.0184471
  385.43231103  907.66809563 1214.46508883  516.5849672   837.43900529]
total_rewards_mean           712.1421135030632
total_rewards_std            227.1591106193
total_rewards_max            1214.465088831691
total_rewards_min            385.4323110300885
Number of train steps total  320000
Number of env steps total    402000
Number of rollouts total     0
Train Time (s)               200.04780412325636
(Previous) Eval Time (s)     3.5220974846743047
Sample Time (s)              15.114871573634446
Epoch Time (s)               218.6847731815651
Total Train Time (s)         17145.970377569553
Epoch                        79
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:16:04.704942 UTC | [2020_01_13_04_30_18] Iteration #79 | Epoch Duration: 218.83225059509277
2020-01-13 09:16:04.705123 UTC | [2020_01_13_04_30_18] Iteration #79 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04360932
Z variance train             0.21478482
KL Divergence                2.1393437
KL Loss                      0.21393438
QF Loss                      410.6226
VF Loss                      172.61328
Policy Loss                  -381.21902
Q Predictions Mean           371.94238
Q Predictions Std            535.05347
Q Predictions Max            1650.2858
Q Predictions Min            13.521149
V Predictions Mean           382.9344
V Predictions Std            535.6531
V Predictions Max            1679.5852
V Predictions Min            27.45078
Log Pis Mean                 -8.639505
Log Pis Std                  5.203605
Log Pis Max                  25.285322
Log Pis Min                  -12.726849
Policy mu Mean               0.09630364
Policy mu Std                0.47389397
Policy mu Max                2.826263
Policy mu Min                -3.0338058
Policy log std Mean          -0.2013832
Policy log std Std           0.121163994
Policy log std Max           0.035862967
Policy log std Min           -0.82548356
Z mean eval                  0.03565806
Z variance eval              0.22198315
total_rewards                [788.20613131 454.68241743 575.35509434 595.28836557 535.0117231
 515.08817464 573.14444982 779.38663162 632.2795606  646.23029712]
total_rewards_mean           609.4672845560625
total_rewards_std            101.87517488367325
total_rewards_max            788.2061313084184
total_rewards_min            454.68241742869805
Number of train steps total  324000
Number of env steps total    407000
Number of rollouts total     0
Train Time (s)               203.51856095390394
(Previous) Eval Time (s)     3.6690080109983683
Sample Time (s)              13.68234866624698
Epoch Time (s)               220.8699176311493
Total Train Time (s)         17366.463097973727
Epoch                        80
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:19:45.198670 UTC | [2020_01_13_04_30_18] Iteration #80 | Epoch Duration: 220.4933888912201
2020-01-13 09:19:45.198891 UTC | [2020_01_13_04_30_18] Iteration #80 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0352756
Z variance train             0.22208841
KL Divergence                1.9814658
KL Loss                      0.19814658
QF Loss                      454.64648
VF Loss                      202.63861
Policy Loss                  -458.99606
Q Predictions Mean           452.64938
Q Predictions Std            582.75104
Q Predictions Max            1696.546
Q Predictions Min            14.4131975
V Predictions Mean           463.157
V Predictions Std            580.2499
V Predictions Max            1697.2181
V Predictions Min            26.66182
Log Pis Mean                 -8.362558
Log Pis Std                  4.995758
Log Pis Max                  16.133585
Log Pis Min                  -14.020276
Policy mu Mean               0.11853737
Policy mu Std                0.49177337
Policy mu Max                2.3174996
Policy mu Min                -2.1433704
Policy log std Mean          -0.21465729
Policy log std Std           0.12506439
Policy log std Max           0.08099045
Policy log std Min           -0.79916245
Z mean eval                  0.04085679
Z variance eval              0.22779846
total_rewards                [716.08497165 676.6825665  433.89625199 555.21927158 741.84458998
 423.16650413 449.03870107 687.44661029 469.82674125 392.87236755]
total_rewards_mean           554.6078575983597
total_rewards_std            130.39185913256856
total_rewards_max            741.8445899753218
total_rewards_min            392.87236755489016
Number of train steps total  328000
Number of env steps total    412000
Number of rollouts total     0
Train Time (s)               191.441668916028
(Previous) Eval Time (s)     3.2921637231484056
Sample Time (s)              13.901336336042732
Epoch Time (s)               208.63516897521913
Total Train Time (s)         17574.721164325252
Epoch                        81
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:23:13.457441 UTC | [2020_01_13_04_30_18] Iteration #81 | Epoch Duration: 208.2583520412445
2020-01-13 09:23:13.457684 UTC | [2020_01_13_04_30_18] Iteration #81 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04071833
Z variance train             0.22786243
KL Divergence                1.9680667
KL Loss                      0.19680667
QF Loss                      560.9906
VF Loss                      230.06915
Policy Loss                  -458.87912
Q Predictions Mean           453.80627
Q Predictions Std            582.947
Q Predictions Max            1679.5203
Q Predictions Min            16.641134
V Predictions Mean           464.2844
V Predictions Std            583.11847
V Predictions Max            1677.2784
V Predictions Min            26.667152
Log Pis Mean                 -8.201225
Log Pis Std                  5.203681
Log Pis Max                  12.005234
Log Pis Min                  -14.135078
Policy mu Mean               0.08593068
Policy mu Std                0.52048963
Policy mu Max                2.2873209
Policy mu Min                -2.457109
Policy log std Mean          -0.2199079
Policy log std Std           0.1359171
Policy log std Max           -0.014190428
Policy log std Min           -1.0042967
Z mean eval                  0.044572704
Z variance eval              0.20717692
total_rewards                [1136.96667817  511.26096939  550.61822031  592.19596748  537.72598676
  555.51003693  475.66503298  694.2410975  1007.89857772  536.17381272]
total_rewards_mean           659.8256379949775
total_rewards_std            215.30657964892788
total_rewards_max            1136.9666781663575
total_rewards_min            475.6650329750223
Number of train steps total  332000
Number of env steps total    417000
Number of rollouts total     0
Train Time (s)               201.6532835648395
(Previous) Eval Time (s)     2.9150174390524626
Sample Time (s)              14.665426375344396
Epoch Time (s)               219.23372737923637
Total Train Time (s)         17794.504498328082
Epoch                        82
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:26:53.242346 UTC | [2020_01_13_04_30_18] Iteration #82 | Epoch Duration: 219.78447318077087
2020-01-13 09:26:53.242546 UTC | [2020_01_13_04_30_18] Iteration #82 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.044567846
Z variance train             0.20718761
KL Divergence                2.0474443
KL Loss                      0.20474444
QF Loss                      460.8253
VF Loss                      174.5812
Policy Loss                  -458.15866
Q Predictions Mean           449.21844
Q Predictions Std            570.12195
Q Predictions Max            1689.5187
Q Predictions Min            17.105404
V Predictions Mean           457.37524
V Predictions Std            564.2554
V Predictions Max            1677.5715
V Predictions Min            26.393066
Log Pis Mean                 -8.141656
Log Pis Std                  5.4016457
Log Pis Max                  13.639608
Log Pis Min                  -14.037134
Policy mu Mean               0.09823556
Policy mu Std                0.5284427
Policy mu Max                2.47963
Policy mu Min                -2.154241
Policy log std Mean          -0.21936692
Policy log std Std           0.13336982
Policy log std Max           0.13499875
Policy log std Min           -0.8225385
Z mean eval                  0.0436866
Z variance eval              0.18667796
total_rewards                [727.53047353 828.41303153 668.30040872 884.1191689  444.37653418
 511.80027693 766.78001672 623.4845454  682.87614993 734.15418119]
total_rewards_mean           687.1834787032969
total_rewards_std            127.68960243452828
total_rewards_max            884.1191689004322
total_rewards_min            444.3765341838444
Number of train steps total  336000
Number of env steps total    422000
Number of rollouts total     0
Train Time (s)               195.9644761569798
(Previous) Eval Time (s)     3.4654074939899147
Sample Time (s)              13.765414118301123
Epoch Time (s)               213.19529776927084
Total Train Time (s)         18007.68153566541
Epoch                        83
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:30:26.421536 UTC | [2020_01_13_04_30_18] Iteration #83 | Epoch Duration: 213.1788468360901
2020-01-13 09:30:26.421732 UTC | [2020_01_13_04_30_18] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043358356
Z variance train             0.18670847
KL Divergence                2.294332
KL Loss                      0.22943321
QF Loss                      391.51913
VF Loss                      174.30273
Policy Loss                  -437.16235
Q Predictions Mean           429.81512
Q Predictions Std            590.79584
Q Predictions Max            1692.2593
Q Predictions Min            17.19542
V Predictions Mean           439.93835
V Predictions Std            589.0114
V Predictions Max            1689.5223
V Predictions Min            28.63704
Log Pis Mean                 -8.652735
Log Pis Std                  4.754525
Log Pis Max                  10.80475
Log Pis Min                  -14.420106
Policy mu Mean               0.08371232
Policy mu Std                0.4795482
Policy mu Max                2.2907598
Policy mu Min                -2.1233308
Policy log std Mean          -0.20781596
Policy log std Std           0.118613064
Policy log std Max           -0.045588866
Policy log std Min           -0.86928433
Z mean eval                  0.04661093
Z variance eval              0.24737556
total_rewards                [ 695.38043837  447.75404649  950.46535629  719.49483008  573.33311397
 1034.1172945   617.18170443  579.27489477  761.38265615  859.07089838]
total_rewards_mean           723.7455233435422
total_rewards_std            173.00505036854543
total_rewards_max            1034.1172945048922
total_rewards_min            447.75404648763373
Number of train steps total  340000
Number of env steps total    427000
Number of rollouts total     0
Train Time (s)               195.528148972895
(Previous) Eval Time (s)     3.4485757020302117
Sample Time (s)              14.040563779417425
Epoch Time (s)               213.01728845434263
Total Train Time (s)         18221.17744129477
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:33:59.918042 UTC | [2020_01_13_04_30_18] Iteration #84 | Epoch Duration: 213.49618864059448
2020-01-13 09:33:59.918195 UTC | [2020_01_13_04_30_18] Iteration #84 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04673417
Z variance train             0.24736217
KL Divergence                1.7324976
KL Loss                      0.17324977
QF Loss                      484.0783
VF Loss                      179.23108
Policy Loss                  -501.40765
Q Predictions Mean           492.16974
Q Predictions Std            613.1966
Q Predictions Max            1706.5193
Q Predictions Min            18.11976
V Predictions Mean           497.52875
V Predictions Std            607.1291
V Predictions Max            1700.5845
V Predictions Min            24.591831
Log Pis Mean                 -8.169088
Log Pis Std                  5.5865216
Log Pis Max                  29.434006
Log Pis Min                  -14.986075
Policy mu Mean               0.109182164
Policy mu Std                0.52051526
Policy mu Max                2.7348187
Policy mu Min                -2.659396
Policy log std Mean          -0.21782862
Policy log std Std           0.1350965
Policy log std Max           -0.022759348
Policy log std Min           -1.1144106
Z mean eval                  0.04858234
Z variance eval              0.21692267
total_rewards                [771.47699915 548.31344779 492.17787278 806.61207215 729.34919254
 554.92242951 553.30518861 757.39497406 711.6351552  749.95628011]
total_rewards_mean           667.5143611892719
total_rewards_std            110.21533867320636
total_rewards_max            806.6120721520981
total_rewards_min            492.17787278299505
Number of train steps total  344000
Number of env steps total    432000
Number of rollouts total     0
Train Time (s)               197.29609500104561
(Previous) Eval Time (s)     3.927060396876186
Sample Time (s)              15.469379003625363
Epoch Time (s)               216.69253440154716
Total Train Time (s)         18437.695123868994
Epoch                        85
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:37:36.436954 UTC | [2020_01_13_04_30_18] Iteration #85 | Epoch Duration: 216.51866221427917
2020-01-13 09:37:36.437082 UTC | [2020_01_13_04_30_18] Iteration #85 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.048592508
Z variance train             0.2168757
KL Divergence                1.9255158
KL Loss                      0.19255158
QF Loss                      670.9503
VF Loss                      217.37294
Policy Loss                  -488.28934
Q Predictions Mean           480.4909
Q Predictions Std            609.3034
Q Predictions Max            1722.993
Q Predictions Min            14.326375
V Predictions Mean           490.33813
V Predictions Std            605.75195
V Predictions Max            1719.8489
V Predictions Min            23.87177
Log Pis Mean                 -8.174479
Log Pis Std                  5.2086883
Log Pis Max                  12.963567
Log Pis Min                  -13.468854
Policy mu Mean               0.09446573
Policy mu Std                0.5069184
Policy mu Max                2.275001
Policy mu Min                -2.88345
Policy log std Mean          -0.21687898
Policy log std Std           0.12730896
Policy log std Max           0.004147902
Policy log std Min           -0.8329938
Z mean eval                  0.04411619
Z variance eval              0.22210889
total_rewards                [617.59550668 475.34621142 454.60620535 619.44430068 908.30980459
 512.86917833 711.48564693 638.9279728  470.03086631 661.26905353]
total_rewards_mean           606.9884746604339
total_rewards_std            131.95235590863132
total_rewards_max            908.3098045928415
total_rewards_min            454.6062053467284
Number of train steps total  348000
Number of env steps total    437000
Number of rollouts total     0
Train Time (s)               196.37088998733088
(Previous) Eval Time (s)     3.7527955370023847
Sample Time (s)              14.437278917990625
Epoch Time (s)               214.5609644423239
Total Train Time (s)         18651.71379614668
Epoch                        86
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:41:10.457376 UTC | [2020_01_13_04_30_18] Iteration #86 | Epoch Duration: 214.02014899253845
2020-01-13 09:41:10.457541 UTC | [2020_01_13_04_30_18] Iteration #86 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043130707
Z variance train             0.2223964
KL Divergence                1.9284804
KL Loss                      0.19284804
QF Loss                      532.96826
VF Loss                      169.50807
Policy Loss                  -456.94327
Q Predictions Mean           451.1969
Q Predictions Std            608.694
Q Predictions Max            1732.6415
Q Predictions Min            15.654548
V Predictions Mean           460.01373
V Predictions Std            604.6832
V Predictions Max            1729.3789
V Predictions Min            24.323349
Log Pis Mean                 -8.455565
Log Pis Std                  5.126457
Log Pis Max                  19.619688
Log Pis Min                  -14.292102
Policy mu Mean               0.08552679
Policy mu Std                0.5018954
Policy mu Max                2.5917146
Policy mu Min                -2.9027724
Policy log std Mean          -0.21330048
Policy log std Std           0.12716353
Policy log std Max           -0.054473057
Policy log std Min           -0.8785693
Z mean eval                  0.046187997
Z variance eval              0.22792454
total_rewards                [685.92054719 978.19949589 518.84607083 686.27210423 564.82435456
 853.89026888 569.45717764 772.07267938 618.00839921 516.36021697]
total_rewards_mean           676.3851314779365
total_rewards_std            144.79590242736927
total_rewards_max            978.1994958901436
total_rewards_min            516.3602169692443
Number of train steps total  352000
Number of env steps total    442000
Number of rollouts total     0
Train Time (s)               190.04183595534414
(Previous) Eval Time (s)     3.2116548120975494
Sample Time (s)              15.319687951821834
Epoch Time (s)               208.57317871926352
Total Train Time (s)         18860.77563863201
Epoch                        87
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:44:39.519970 UTC | [2020_01_13_04_30_18] Iteration #87 | Epoch Duration: 209.06232023239136
2020-01-13 09:44:39.520090 UTC | [2020_01_13_04_30_18] Iteration #87 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04667929
Z variance train             0.22808997
KL Divergence                1.8949058
KL Loss                      0.18949059
QF Loss                      525.33124
VF Loss                      252.79366
Policy Loss                  -546.0246
Q Predictions Mean           537.27203
Q Predictions Std            628.63184
Q Predictions Max            1728.2068
Q Predictions Min            19.370441
V Predictions Mean           540.8358
V Predictions Std            622.3951
V Predictions Max            1716.8157
V Predictions Min            31.336409
Log Pis Mean                 -8.174715
Log Pis Std                  4.507456
Log Pis Max                  8.721491
Log Pis Min                  -13.842385
Policy mu Mean               0.1359989
Policy mu Std                0.5293464
Policy mu Max                2.4144962
Policy mu Min                -2.3678808
Policy log std Mean          -0.22824655
Policy log std Std           0.13197435
Policy log std Max           -0.030961141
Policy log std Min           -0.8641346
Z mean eval                  0.045338653
Z variance eval              0.23122057
total_rewards                [478.27926496 607.32378682 836.58259515 789.09364832 892.77654469
 694.17574363 784.2947447  521.65121185 637.13806733 500.59367049]
total_rewards_mean           674.1909277944031
total_rewards_std            140.53664483373092
total_rewards_max            892.7765446892324
total_rewards_min            478.279264958443
Number of train steps total  356000
Number of env steps total    447000
Number of rollouts total     0
Train Time (s)               192.0521344942972
(Previous) Eval Time (s)     3.7005296503193676
Sample Time (s)              15.266240028198808
Epoch Time (s)               211.01890417281538
Total Train Time (s)         19071.636313147843
Epoch                        88
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:48:10.381764 UTC | [2020_01_13_04_30_18] Iteration #88 | Epoch Duration: 210.8615846633911
2020-01-13 09:48:10.381887 UTC | [2020_01_13_04_30_18] Iteration #88 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045544997
Z variance train             0.23115484
KL Divergence                1.92214
KL Loss                      0.192214
QF Loss                      530.2302
VF Loss                      181.85123
Policy Loss                  -445.69385
Q Predictions Mean           438.09528
Q Predictions Std            608.6789
Q Predictions Max            1734.0228
Q Predictions Min            16.184166
V Predictions Mean           446.1192
V Predictions Std            606.3738
V Predictions Max            1731.6923
V Predictions Min            25.871552
Log Pis Mean                 -8.672597
Log Pis Std                  4.6974993
Log Pis Max                  11.131631
Log Pis Min                  -14.726762
Policy mu Mean               0.08278584
Policy mu Std                0.48479724
Policy mu Max                2.3794758
Policy mu Min                -2.079899
Policy log std Mean          -0.20374003
Policy log std Std           0.11869173
Policy log std Max           -0.026729316
Policy log std Min           -0.81689095
Z mean eval                  0.047378533
Z variance eval              0.23754175
total_rewards                [775.98425047 543.66012289 477.59710782 569.76563693 573.57559499
 646.39149027 587.99038869 578.5144753  623.04659308 598.1261969 ]
total_rewards_mean           597.4651857341531
total_rewards_std            73.46285097474293
total_rewards_max            775.9842504678329
total_rewards_min            477.5971078163363
Number of train steps total  360000
Number of env steps total    452000
Number of rollouts total     0
Train Time (s)               194.0079005123116
(Previous) Eval Time (s)     3.5429482948966324
Sample Time (s)              15.19648502022028
Epoch Time (s)               212.74733382742852
Total Train Time (s)         19283.791719714645
Epoch                        89
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:51:42.541773 UTC | [2020_01_13_04_30_18] Iteration #89 | Epoch Duration: 212.1597421169281
2020-01-13 09:51:42.542024 UTC | [2020_01_13_04_30_18] Iteration #89 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046876274
Z variance train             0.23752165
KL Divergence                1.8651556
KL Loss                      0.18651555
QF Loss                      525.84155
VF Loss                      208.95193
Policy Loss                  -599.99664
Q Predictions Mean           594.2576
Q Predictions Std            665.5709
Q Predictions Max            1754.1749
Q Predictions Min            14.49164
V Predictions Mean           605.8396
V Predictions Std            664.81647
V Predictions Max            1753.1918
V Predictions Min            28.539772
Log Pis Mean                 -8.2204075
Log Pis Std                  4.8678203
Log Pis Max                  18.057453
Log Pis Min                  -13.961981
Policy mu Mean               0.10475403
Policy mu Std                0.51760167
Policy mu Max                2.3947973
Policy mu Min                -2.3455536
Policy log std Mean          -0.22991611
Policy log std Std           0.1297808
Policy log std Max           -0.08741379
Policy log std Min           -0.7795664
Z mean eval                  0.052285142
Z variance eval              0.21594325
total_rewards                [549.21320967 490.06075958 514.30115058 617.1783853  820.21815802
 566.54811208 766.9784891  836.42690095 651.4009969  774.21614742]
total_rewards_mean           658.6542309603088
total_rewards_std            124.21353630898219
total_rewards_max            836.426900952743
total_rewards_min            490.0607595758689
Number of train steps total  364000
Number of env steps total    457000
Number of rollouts total     0
Train Time (s)               192.72158800717443
(Previous) Eval Time (s)     2.9550722371786833
Sample Time (s)              14.982861559838057
Epoch Time (s)               210.65952180419117
Total Train Time (s)         19494.951971686445
Epoch                        90
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:55:13.701373 UTC | [2020_01_13_04_30_18] Iteration #90 | Epoch Duration: 211.15916895866394
2020-01-13 09:55:13.701491 UTC | [2020_01_13_04_30_18] Iteration #90 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.050977416
Z variance train             0.21585691
KL Divergence                2.0440254
KL Loss                      0.20440255
QF Loss                      647.5125
VF Loss                      423.43964
Policy Loss                  -537.3616
Q Predictions Mean           532.6128
Q Predictions Std            629.8786
Q Predictions Max            1754.813
Q Predictions Min            14.421121
V Predictions Mean           548.9004
V Predictions Std            633.0386
V Predictions Max            1766.6354
V Predictions Min            31.37519
Log Pis Mean                 -8.32049
Log Pis Std                  5.106947
Log Pis Max                  23.745106
Log Pis Min                  -13.918691
Policy mu Mean               0.08430691
Policy mu Std                0.5204117
Policy mu Max                2.9085853
Policy mu Min                -2.7652667
Policy log std Mean          -0.2240086
Policy log std Std           0.1301935
Policy log std Max           -0.0650121
Policy log std Min           -0.91898084
Z mean eval                  0.056239307
Z variance eval              0.19618556
total_rewards                [ 905.53086636  890.34006134  577.52539939  482.21265536  789.54077503
 1273.97605876  744.90174008 1082.21416925  549.90025248  621.70057494]
total_rewards_mean           791.7842552996697
total_rewards_std            238.9332070014822
total_rewards_max            1273.9760587599008
total_rewards_min            482.21265536064794
Number of train steps total  368000
Number of env steps total    462000
Number of rollouts total     0
Train Time (s)               194.48128535831347
(Previous) Eval Time (s)     3.454457112122327
Sample Time (s)              16.26306692045182
Epoch Time (s)               214.19880939088762
Total Train Time (s)         19709.955785288475
Epoch                        91
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:58:48.706298 UTC | [2020_01_13_04_30_18] Iteration #91 | Epoch Duration: 215.00471949577332
2020-01-13 09:58:48.706407 UTC | [2020_01_13_04_30_18] Iteration #91 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.055810403
Z variance train             0.19609699
KL Divergence                2.1569893
KL Loss                      0.21569894
QF Loss                      576.6356
VF Loss                      255.01613
Policy Loss                  -500.94913
Q Predictions Mean           492.74237
Q Predictions Std            606.47064
Q Predictions Max            1687.212
Q Predictions Min            12.110965
V Predictions Mean           499.5909
V Predictions Std            603.10205
V Predictions Max            1702.7426
V Predictions Min            28.729887
Log Pis Mean                 -8.367197
Log Pis Std                  4.751779
Log Pis Max                  9.692049
Log Pis Min                  -15.414226
Policy mu Mean               0.09331167
Policy mu Std                0.5093174
Policy mu Max                2.4178123
Policy mu Min                -2.6236343
Policy log std Mean          -0.22073096
Policy log std Std           0.1302821
Policy log std Max           -0.05925083
Policy log std Min           -0.95248747
Z mean eval                  0.044679124
Z variance eval              0.16802132
total_rewards                [721.99362587 972.31003117 753.56229043 538.37140084 782.34081039
 663.81617661 683.76031624 755.46308849 488.45210134 725.67795198]
total_rewards_mean           708.5747793355137
total_rewards_std            126.38629576026042
total_rewards_max            972.3100311710512
total_rewards_min            488.4521013410785
Number of train steps total  372000
Number of env steps total    467000
Number of rollouts total     0
Train Time (s)               196.06557942507789
(Previous) Eval Time (s)     4.26009166566655
Sample Time (s)              15.42488662386313
Epoch Time (s)               215.75055771460757
Total Train Time (s)         19924.919780526776
Epoch                        92
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:02:23.672279 UTC | [2020_01_13_04_30_18] Iteration #92 | Epoch Duration: 214.96577334403992
2020-01-13 10:02:23.672431 UTC | [2020_01_13_04_30_18] Iteration #92 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.044576038
Z variance train             0.16804922
KL Divergence                2.4190567
KL Loss                      0.24190567
QF Loss                      580.7711
VF Loss                      186.2092
Policy Loss                  -585.6217
Q Predictions Mean           576.3901
Q Predictions Std            647.6138
Q Predictions Max            1753.1633
Q Predictions Min            15.247085
V Predictions Mean           583.0714
V Predictions Std            642.9208
V Predictions Max            1761.5636
V Predictions Min            25.400244
Log Pis Mean                 -8.03221
Log Pis Std                  4.740523
Log Pis Max                  10.40196
Log Pis Min                  -12.907557
Policy mu Mean               0.10663801
Policy mu Std                0.51622635
Policy mu Max                2.0671306
Policy mu Min                -2.5715232
Policy log std Mean          -0.22649278
Policy log std Std           0.12455818
Policy log std Max           -0.07348849
Policy log std Min           -0.7430619
Z mean eval                  0.038193554
Z variance eval              0.16356733
total_rewards                [1009.0115596   798.07294086  608.66508952  636.43718139  925.18995112
  600.28319675  607.92254239  749.89238807 1075.33225091  675.5995395 ]
total_rewards_mean           768.6406640100856
total_rewards_std            168.36403430991632
total_rewards_max            1075.3322509124605
total_rewards_min            600.2831967452605
Number of train steps total  376000
Number of env steps total    472000
Number of rollouts total     0
Train Time (s)               190.04711879324168
(Previous) Eval Time (s)     3.475037503056228
Sample Time (s)              14.450060041621327
Epoch Time (s)               207.97221633791924
Total Train Time (s)         20133.361229747068
Epoch                        93
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:05:52.115463 UTC | [2020_01_13_04_30_18] Iteration #93 | Epoch Duration: 208.44291520118713
2020-01-13 10:05:52.115609 UTC | [2020_01_13_04_30_18] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03860445
Z variance train             0.16346128
KL Divergence                2.4510937
KL Loss                      0.24510936
QF Loss                      544.88855
VF Loss                      189.55217
Policy Loss                  -545.3339
Q Predictions Mean           537.36694
Q Predictions Std            636.547
Q Predictions Max            1786.484
Q Predictions Min            18.942392
V Predictions Mean           544.11
V Predictions Std            631.3835
V Predictions Max            1771.5027
V Predictions Min            28.826632
Log Pis Mean                 -8.430229
Log Pis Std                  4.546547
Log Pis Max                  7.3167343
Log Pis Min                  -15.465736
Policy mu Mean               0.09413945
Policy mu Std                0.4975454
Policy mu Max                2.6641288
Policy mu Min                -2.3377917
Policy log std Mean          -0.22614339
Policy log std Std           0.13174097
Policy log std Max           -0.02182813
Policy log std Min           -0.85554874
Z mean eval                  0.03955873
Z variance eval              0.17142653
total_rewards                [ 825.27419317  686.01815281  897.49440085  498.9546374   759.77852332
 1110.04426518  280.29232525  673.92458007  547.58679987  955.0675715 ]
total_rewards_mean           723.4435449417986
total_rewards_std            229.48853443068248
total_rewards_max            1110.0442651785079
total_rewards_min            280.29232524823806
Number of train steps total  380000
Number of env steps total    477000
Number of rollouts total     0
Train Time (s)               195.20842442987487
(Previous) Eval Time (s)     3.9454678050242364
Sample Time (s)              15.256835944019258
Epoch Time (s)               214.41072817891836
Total Train Time (s)         20347.72419163119
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:09:26.479038 UTC | [2020_01_13_04_30_18] Iteration #94 | Epoch Duration: 214.36332201957703
2020-01-13 10:09:26.479149 UTC | [2020_01_13_04_30_18] Iteration #94 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03949561
Z variance train             0.1713882
KL Divergence                2.3757658
KL Loss                      0.23757659
QF Loss                      453.42737
VF Loss                      137.64835
Policy Loss                  -506.65204
Q Predictions Mean           497.63818
Q Predictions Std            641.3224
Q Predictions Max            1773.5085
Q Predictions Min            8.8234005
V Predictions Mean           504.2329
V Predictions Std            636.2999
V Predictions Max            1774.7882
V Predictions Min            24.18498
Log Pis Mean                 -8.594889
Log Pis Std                  4.4043803
Log Pis Max                  7.956844
Log Pis Min                  -14.061462
Policy mu Mean               0.11160439
Policy mu Std                0.47785982
Policy mu Max                2.2950191
Policy mu Min                -2.1126664
Policy log std Mean          -0.21412499
Policy log std Std           0.12929821
Policy log std Max           0.002675429
Policy log std Min           -0.8427582
Z mean eval                  0.033227313
Z variance eval              0.16771829
total_rewards                [ 922.37130898  566.71197257  765.07377655  657.94870821  512.30994791
  804.61554589 1070.60121343  652.00010227  492.04395456  819.4521222 ]
total_rewards_mean           726.3128652572474
total_rewards_std            175.96297339878723
total_rewards_max            1070.601213428687
total_rewards_min            492.0439545595432
Number of train steps total  384000
Number of env steps total    482000
Number of rollouts total     0
Train Time (s)               194.51247344026342
(Previous) Eval Time (s)     3.8978146612644196
Sample Time (s)              15.659951070789248
Epoch Time (s)               214.0702391723171
Total Train Time (s)         20561.88637944311
Epoch                        95
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:13:00.642359 UTC | [2020_01_13_04_30_18] Iteration #95 | Epoch Duration: 214.16310501098633
2020-01-13 10:13:00.642472 UTC | [2020_01_13_04_30_18] Iteration #95 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033251356
Z variance train             0.16766766
KL Divergence                2.5091329
KL Loss                      0.2509133
QF Loss                      545.6889
VF Loss                      187.39424
Policy Loss                  -486.14795
Q Predictions Mean           478.8563
Q Predictions Std            642.1481
Q Predictions Max            1779.5879
Q Predictions Min            16.182467
V Predictions Mean           484.88776
V Predictions Std            639.8975
V Predictions Max            1781.8038
V Predictions Min            23.50887
Log Pis Mean                 -9.16581
Log Pis Std                  3.713536
Log Pis Max                  5.6284475
Log Pis Min                  -13.697033
Policy mu Mean               0.090598166
Policy mu Std                0.44140556
Policy mu Max                2.0356448
Policy mu Min                -2.2968652
Policy log std Mean          -0.20057738
Policy log std Std           0.11125297
Policy log std Max           0.061527938
Policy log std Min           -0.7837416
Z mean eval                  0.030899948
Z variance eval              0.17930558
total_rewards                [ 727.58532863  411.30363293  644.92167684  542.32442905  591.45765758
  563.1905867   777.01609256  856.20248114 1114.5909804   725.89861407]
total_rewards_mean           695.4491479902366
total_rewards_std            185.79020858550078
total_rewards_max            1114.5909803991533
total_rewards_min            411.3036329290218
Number of train steps total  388000
Number of env steps total    487000
Number of rollouts total     0
Train Time (s)               193.13147903000936
(Previous) Eval Time (s)     3.9903715811669827
Sample Time (s)              15.184452624525875
Epoch Time (s)               212.30630323570222
Total Train Time (s)         20773.91439941665
Epoch                        96
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:16:32.671585 UTC | [2020_01_13_04_30_18] Iteration #96 | Epoch Duration: 212.0290277004242
2020-01-13 10:16:32.671698 UTC | [2020_01_13_04_30_18] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030756554
Z variance train             0.17932983
KL Divergence                2.3447702
KL Loss                      0.23447703
QF Loss                      765.5624
VF Loss                      215.50964
Policy Loss                  -549.46826
Q Predictions Mean           543.69135
Q Predictions Std            644.5123
Q Predictions Max            1803.8743
Q Predictions Min            10.73088
V Predictions Mean           551.40466
V Predictions Std            641.3667
V Predictions Max            1809.8949
V Predictions Min            23.917492
Log Pis Mean                 -8.101716
Log Pis Std                  4.917375
Log Pis Max                  18.459229
Log Pis Min                  -13.77748
Policy mu Mean               0.12507927
Policy mu Std                0.5210363
Policy mu Max                2.3718057
Policy mu Min                -2.1812618
Policy log std Mean          -0.22752008
Policy log std Std           0.13787055
Policy log std Max           -0.049497902
Policy log std Min           -1.0655186
Z mean eval                  0.024250668
Z variance eval              0.165084
total_rewards                [ 483.67190207  743.93678527 1033.08578027  688.38210036  710.05203707
 1053.92542495 1044.90868177  555.1901911   735.97149144  656.26270934]
total_rewards_mean           770.5387103631754
total_rewards_std            194.56498432333655
total_rewards_max            1053.9254249496062
total_rewards_min            483.6719020713694
Number of train steps total  392000
Number of env steps total    492000
Number of rollouts total     0
Train Time (s)               196.43826511595398
(Previous) Eval Time (s)     3.7127965819090605
Sample Time (s)              16.235297977924347
Epoch Time (s)               216.3863596757874
Total Train Time (s)         20990.734463471454
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:20:09.494289 UTC | [2020_01_13_04_30_18] Iteration #97 | Epoch Duration: 216.82248735427856
2020-01-13 10:20:09.494457 UTC | [2020_01_13_04_30_18] Iteration #97 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023843095
Z variance train             0.16509958
KL Divergence                2.5199242
KL Loss                      0.25199243
QF Loss                      545.9359
VF Loss                      261.64716
Policy Loss                  -550.94946
Q Predictions Mean           541.4307
Q Predictions Std            650.9564
Q Predictions Max            1811.5513
Q Predictions Min            17.231129
V Predictions Mean           550.87244
V Predictions Std            649.3247
V Predictions Max            1811.2329
V Predictions Min            26.489315
Log Pis Mean                 -7.871702
Log Pis Std                  5.6594796
Log Pis Max                  30.005188
Log Pis Min                  -13.987775
Policy mu Mean               0.10346975
Policy mu Std                0.53818583
Policy mu Max                2.540522
Policy mu Min                -2.599307
Policy log std Mean          -0.22583559
Policy log std Std           0.12964688
Policy log std Max           0.022346571
Policy log std Min           -0.9049596
Z mean eval                  0.027928863
Z variance eval              0.17396463
total_rewards                [ 741.75164497  949.4391388  1704.47942576 1159.47189603  364.40028001
  706.87474348  805.51020232  509.39305747  617.58961805  344.87974504]
total_rewards_mean           790.3789751916662
total_rewards_std            386.70564287313545
total_rewards_max            1704.4794257624258
total_rewards_min            344.87974503704544
Number of train steps total  396000
Number of env steps total    497000
Number of rollouts total     0
Train Time (s)               191.2342375088483
(Previous) Eval Time (s)     4.148656012956053
Sample Time (s)              14.994436545297503
Epoch Time (s)               210.37733006710187
Total Train Time (s)         21201.414296393283
Epoch                        98
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:23:40.175334 UTC | [2020_01_13_04_30_18] Iteration #98 | Epoch Duration: 210.680757522583
2020-01-13 10:23:40.175460 UTC | [2020_01_13_04_30_18] Iteration #98 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02746886
Z variance train             0.17404827
KL Divergence                2.3784304
KL Loss                      0.23784304
QF Loss                      749.136
VF Loss                      257.6445
Policy Loss                  -566.9061
Q Predictions Mean           560.99054
Q Predictions Std            655.7582
Q Predictions Max            1828.4972
Q Predictions Min            16.512032
V Predictions Mean           570.2736
V Predictions Std            653.572
V Predictions Max            1823.5859
V Predictions Min            26.498482
Log Pis Mean                 -8.246218
Log Pis Std                  4.9338183
Log Pis Max                  10.854992
Log Pis Min                  -16.992008
Policy mu Mean               0.11997708
Policy mu Std                0.5144333
Policy mu Max                2.4373572
Policy mu Min                -2.1758642
Policy log std Mean          -0.22195664
Policy log std Std           0.13091901
Policy log std Max           -0.018041015
Policy log std Min           -0.9066092
Z mean eval                  0.02318771
Z variance eval              0.16872554
total_rewards                [ 859.21865873  977.1962744   672.11910237  773.62762805  528.61195614
 1115.5351727   777.82768819 1178.60992569  482.95367758  802.90599569]
total_rewards_mean           816.8606079546313
total_rewards_std            216.02995448605927
total_rewards_max            1178.6099256924965
total_rewards_min            482.95367758455836
Number of train steps total  400000
Number of env steps total    502000
Number of rollouts total     0
Train Time (s)               190.73930527362972
(Previous) Eval Time (s)     4.45160140004009
Sample Time (s)              15.666707369033247
Epoch Time (s)               210.85761404270306
Total Train Time (s)         21412.34026281396
Epoch                        99
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:27:11.107043 UTC | [2020_01_13_04_30_18] Iteration #99 | Epoch Duration: 210.93134999275208
2020-01-13 10:27:11.107357 UTC | [2020_01_13_04_30_18] Iteration #99 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023480967
Z variance train             0.16859357
KL Divergence                2.441575
KL Loss                      0.24415751
QF Loss                      578.5114
VF Loss                      274.43582
Policy Loss                  -535.13635
Q Predictions Mean           526.64575
Q Predictions Std            668.7378
Q Predictions Max            1810.7506
Q Predictions Min            14.294271
V Predictions Mean           530.27673
V Predictions Std            660.9604
V Predictions Max            1812.3103
V Predictions Min            23.536428
Log Pis Mean                 -8.428226
Log Pis Std                  4.813566
Log Pis Max                  13.028891
Log Pis Min                  -13.561055
Policy mu Mean               0.11501134
Policy mu Std                0.49372822
Policy mu Max                2.613834
Policy mu Min                -2.3105588
Policy log std Mean          -0.21856704
Policy log std Std           0.12731394
Policy log std Max           -0.078430384
Policy log std Min           -0.801277
Z mean eval                  0.031643018
Z variance eval              0.17530815
total_rewards                [ 655.38332385 1027.941317    409.34423197  943.92365631  557.70549074
  528.23784836  805.13676093  613.48807637  584.52777256  396.43173761]
total_rewards_mean           652.2120215692098
total_rewards_std            201.1104951860492
total_rewards_max            1027.9413170048479
total_rewards_min            396.4317376051611
Number of train steps total  404000
Number of env steps total    507000
Number of rollouts total     0
Train Time (s)               194.11496054101735
(Previous) Eval Time (s)     4.525054442696273
Sample Time (s)              15.613498689141124
Epoch Time (s)               214.25351367285475
Total Train Time (s)         21625.345895042643
Epoch                        100
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:30:44.114034 UTC | [2020_01_13_04_30_18] Iteration #100 | Epoch Duration: 213.0063829421997
2020-01-13 10:30:44.114345 UTC | [2020_01_13_04_30_18] Iteration #100 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031394903
Z variance train             0.17532936
KL Divergence                2.3895528
KL Loss                      0.23895529
QF Loss                      643.80585
VF Loss                      201.05708
Policy Loss                  -534.83295
Q Predictions Mean           527.3758
Q Predictions Std            643.94885
Q Predictions Max            1821.2197
Q Predictions Min            7.5590773
V Predictions Mean           536.1316
V Predictions Std            642.47375
V Predictions Max            1832.0526
V Predictions Min            30.01068
Log Pis Mean                 -8.710339
Log Pis Std                  4.493087
Log Pis Max                  12.24675
Log Pis Min                  -14.999298
Policy mu Mean               0.105213925
Policy mu Std                0.49302676
Policy mu Max                2.1297598
Policy mu Min                -2.3727481
Policy log std Mean          -0.21960895
Policy log std Std           0.1263113
Policy log std Max           0.05677311
Policy log std Min           -0.81130296
Z mean eval                  0.028298894
Z variance eval              0.19604973
total_rewards                [ 853.17836701  418.19433339  646.93651412  634.4517533   406.31601957
  805.06988033  547.85743637  823.92545602  940.94315424 1145.68164706]
total_rewards_mean           722.255456141597
total_rewards_std            223.05108636355556
total_rewards_max            1145.6816470606952
total_rewards_min            406.3160195702972
Number of train steps total  408000
Number of env steps total    512000
Number of rollouts total     0
Train Time (s)               193.63224679091945
(Previous) Eval Time (s)     3.277602151967585
Sample Time (s)              16.042442904319614
Epoch Time (s)               212.95229184720665
Total Train Time (s)         21838.84604346007
Epoch                        101
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:34:17.614355 UTC | [2020_01_13_04_30_18] Iteration #101 | Epoch Duration: 213.4998505115509
2020-01-13 10:34:17.614485 UTC | [2020_01_13_04_30_18] Iteration #101 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028734684
Z variance train             0.19586569
KL Divergence                2.1547287
KL Loss                      0.21547286
QF Loss                      779.2704
VF Loss                      397.9499
Policy Loss                  -628.4947
Q Predictions Mean           621.2507
Q Predictions Std            668.0498
Q Predictions Max            1847.6073
Q Predictions Min            12.686891
V Predictions Mean           622.15063
V Predictions Std            657.98065
V Predictions Max            1831.3779
V Predictions Min            29.29532
Log Pis Mean                 -7.7176027
Log Pis Std                  5.267147
Log Pis Max                  16.912107
Log Pis Min                  -13.801485
Policy mu Mean               0.16511624
Policy mu Std                0.5440345
Policy mu Max                2.7765398
Policy mu Min                -2.7318916
Policy log std Mean          -0.23450479
Policy log std Std           0.1364394
Policy log std Max           0.012335777
Policy log std Min           -0.9372046
Z mean eval                  0.030849233
Z variance eval              0.20487614
total_rewards                [ 852.50209981 1365.73595797  446.07134201  539.85699245 1406.45735322
  589.14680989  734.82699247  439.90254041 1221.83895345  664.42255104]
total_rewards_mean           826.0761592743854
total_rewards_std            353.7584629092282
total_rewards_max            1406.4573532232484
total_rewards_min            439.9025404107855
Number of train steps total  412000
Number of env steps total    517000
Number of rollouts total     0
Train Time (s)               191.73463875288144
(Previous) Eval Time (s)     3.8248256049118936
Sample Time (s)              15.695690835826099
Epoch Time (s)               211.25515519361943
Total Train Time (s)         22050.626680389978
Epoch                        102
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:37:49.396795 UTC | [2020_01_13_04_30_18] Iteration #102 | Epoch Duration: 211.78216195106506
2020-01-13 10:37:49.396968 UTC | [2020_01_13_04_30_18] Iteration #102 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03097319
Z variance train             0.2050344
KL Divergence                2.0934527
KL Loss                      0.20934527
QF Loss                      611.4572
VF Loss                      287.0242
Policy Loss                  -588.09406
Q Predictions Mean           579.305
Q Predictions Std            666.73724
Q Predictions Max            1835.9664
Q Predictions Min            14.086322
V Predictions Mean           583.984
V Predictions Std            659.4227
V Predictions Max            1826.5194
V Predictions Min            25.90524
Log Pis Mean                 -8.072282
Log Pis Std                  5.348584
Log Pis Max                  23.78325
Log Pis Min                  -14.425401
Policy mu Mean               0.115349814
Policy mu Std                0.54109955
Policy mu Max                2.6881907
Policy mu Min                -2.7084715
Policy log std Mean          -0.23117624
Policy log std Std           0.14050166
Policy log std Max           0.09046261
Policy log std Min           -0.9510569
Z mean eval                  0.03436169
Z variance eval              0.23406605
total_rewards                [753.00814385 937.01129128 635.49506944 618.6654234  525.09935714
 558.43870663 925.31383366 804.15034469 695.74156372 639.46752704]
total_rewards_mean           709.2391260822335
total_rewards_std            135.9531417702222
total_rewards_max            937.0112912775862
total_rewards_min            525.0993571381251
Number of train steps total  416000
Number of env steps total    522000
Number of rollouts total     0
Train Time (s)               193.63501736009493
(Previous) Eval Time (s)     4.351552842184901
Sample Time (s)              16.00290686264634
Epoch Time (s)               213.98947706492618
Total Train Time (s)         22264.00610211352
Epoch                        103
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:41:22.780822 UTC | [2020_01_13_04_30_18] Iteration #103 | Epoch Duration: 213.38370990753174
2020-01-13 10:41:22.781070 UTC | [2020_01_13_04_30_18] Iteration #103 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034363195
Z variance train             0.23405907
KL Divergence                1.8293452
KL Loss                      0.18293452
QF Loss                      902.3111
VF Loss                      332.78052
Policy Loss                  -484.13278
Q Predictions Mean           480.72968
Q Predictions Std            639.9794
Q Predictions Max            1832.1287
Q Predictions Min            14.713449
V Predictions Mean           486.8836
V Predictions Std            631.48236
V Predictions Max            1827.2029
V Predictions Min            25.184462
Log Pis Mean                 -8.55478
Log Pis Std                  5.214608
Log Pis Max                  17.955702
Log Pis Min                  -13.154828
Policy mu Mean               0.08677056
Policy mu Std                0.5025963
Policy mu Max                2.6618497
Policy mu Min                -2.5185204
Policy log std Mean          -0.21154967
Policy log std Std           0.12660627
Policy log std Max           0.061847776
Policy log std Min           -0.9361955
Z mean eval                  0.029101267
Z variance eval              0.22956541
total_rewards                [ 534.33696267  934.51625904 1177.67091486  554.88017611  570.96370375
  820.58209722 1560.9549365  1277.70809326  866.58090135  869.72923544]
total_rewards_mean           916.792328019999
total_rewards_std            320.06560431756566
total_rewards_max            1560.954936498309
total_rewards_min            534.3369626693658
Number of train steps total  420000
Number of env steps total    527000
Number of rollouts total     0
Train Time (s)               191.39936754200608
(Previous) Eval Time (s)     3.745524018071592
Sample Time (s)              15.301030406262726
Epoch Time (s)               210.4459219663404
Total Train Time (s)         22475.70471504517
Epoch                        104
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:44:54.480677 UTC | [2020_01_13_04_30_18] Iteration #104 | Epoch Duration: 211.6994113922119
2020-01-13 10:44:54.480862 UTC | [2020_01_13_04_30_18] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029056733
Z variance train             0.22957692
KL Divergence                1.7909768
KL Loss                      0.17909768
QF Loss                      799.1022
VF Loss                      295.95135
Policy Loss                  -562.0591
Q Predictions Mean           553.6636
Q Predictions Std            642.89185
Q Predictions Max            1827.049
Q Predictions Min            17.936636
V Predictions Mean           561.14294
V Predictions Std            639.7471
V Predictions Max            1831.866
V Predictions Min            24.565306
Log Pis Mean                 -7.9622865
Log Pis Std                  5.2330832
Log Pis Max                  15.211053
Log Pis Min                  -13.717519
Policy mu Mean               0.08435556
Policy mu Std                0.5550621
Policy mu Max                2.3934824
Policy mu Min                -2.6688569
Policy log std Mean          -0.22974457
Policy log std Std           0.13815022
Policy log std Max           -0.05637543
Policy log std Min           -0.92365074
Z mean eval                  0.03540866
Z variance eval              0.2109739
total_rewards                [ 942.79898362  970.98057188  724.10590042  921.65207886  908.98389969
  742.920147    644.44237501  538.64922148  811.55866487 1082.25459102]
total_rewards_mean           828.8346433828419
total_rewards_std            157.89551695858017
total_rewards_max            1082.254591021274
total_rewards_min            538.6492214777871
Number of train steps total  424000
Number of env steps total    532000
Number of rollouts total     0
Train Time (s)               193.72579171601683
(Previous) Eval Time (s)     4.998728996608406
Sample Time (s)              16.30172387138009
Epoch Time (s)               215.02624458400533
Total Train Time (s)         22690.185204474255
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:48:28.963002 UTC | [2020_01_13_04_30_18] Iteration #105 | Epoch Duration: 214.48198699951172
2020-01-13 10:48:28.963180 UTC | [2020_01_13_04_30_18] Iteration #105 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036376964
Z variance train             0.21088418
KL Divergence                1.9791079
KL Loss                      0.19791079
QF Loss                      693.1256
VF Loss                      232.43188
Policy Loss                  -587.64856
Q Predictions Mean           580.05383
Q Predictions Std            675.9382
Q Predictions Max            1864.5946
Q Predictions Min            13.665172
V Predictions Mean           583.7277
V Predictions Std            667.63873
V Predictions Max            1840.9723
V Predictions Min            25.603607
Log Pis Mean                 -8.095882
Log Pis Std                  4.864996
Log Pis Max                  11.074024
Log Pis Min                  -17.479115
Policy mu Mean               0.10854253
Policy mu Std                0.5156297
Policy mu Max                2.2909048
Policy mu Min                -2.9911208
Policy log std Mean          -0.22743362
Policy log std Std           0.12456017
Policy log std Max           -0.011966288
Policy log std Min           -0.84047556
Z mean eval                  0.035382826
Z variance eval              0.18124798
total_rewards                [ 905.62267118 1369.98620215 1118.16134356  691.08336802  533.42997005
  689.05604221  776.81192841  722.64575765 1187.62495837  821.81549043]
total_rewards_mean           881.6237732051329
total_rewards_std            249.62452225988616
total_rewards_max            1369.9862021501754
total_rewards_min            533.4299700545527
Number of train steps total  428000
Number of env steps total    537000
Number of rollouts total     0
Train Time (s)               196.26435722596943
(Previous) Eval Time (s)     4.454172160942107
Sample Time (s)              14.684381025843322
Epoch Time (s)               215.40291041275486
Total Train Time (s)         22905.927846495062
Epoch                        106
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:52:04.710547 UTC | [2020_01_13_04_30_18] Iteration #106 | Epoch Duration: 215.74716067314148
2020-01-13 10:52:04.710843 UTC | [2020_01_13_04_30_18] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036190916
Z variance train             0.18142833
KL Divergence                2.298744
KL Loss                      0.2298744
QF Loss                      720.47437
VF Loss                      356.34903
Policy Loss                  -604.95685
Q Predictions Mean           593.03644
Q Predictions Std            682.5491
Q Predictions Max            1850.8832
Q Predictions Min            21.014711
V Predictions Mean           596.0642
V Predictions Std            677.2222
V Predictions Max            1847.4784
V Predictions Min            24.20754
Log Pis Mean                 -7.6571703
Log Pis Std                  4.9775877
Log Pis Max                  9.70158
Log Pis Min                  -13.740565
Policy mu Mean               0.115286626
Policy mu Std                0.54448307
Policy mu Max                2.4683635
Policy mu Min                -2.3075404
Policy log std Mean          -0.23179638
Policy log std Std           0.1372953
Policy log std Max           0.051248595
Policy log std Min           -0.8678197
Z mean eval                  0.031029176
Z variance eval              0.1665587
total_rewards                [ 660.79262458  675.33366646  699.67446124  809.83247666  570.99036331
  682.07801092  746.99193137 1031.90903629  981.6095077  1187.06789061]
total_rewards_mean           804.6279969135093
total_rewards_std            187.24698308606543
total_rewards_max            1187.0678906092392
total_rewards_min            570.9903633056832
Number of train steps total  432000
Number of env steps total    542000
Number of rollouts total     0
Train Time (s)               192.39661249425262
(Previous) Eval Time (s)     4.7981567131355405
Sample Time (s)              13.969669083599001
Epoch Time (s)               211.16443829098716
Total Train Time (s)         23116.513172996696
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:55:35.298478 UTC | [2020_01_13_04_30_18] Iteration #107 | Epoch Duration: 210.58732867240906
2020-01-13 10:55:35.298724 UTC | [2020_01_13_04_30_18] Iteration #107 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030061472
Z variance train             0.1664751
KL Divergence                2.4265037
KL Loss                      0.24265037
QF Loss                      516.52234
VF Loss                      232.58589
Policy Loss                  -551.97736
Q Predictions Mean           543.3273
Q Predictions Std            658.6618
Q Predictions Max            1852.3469
Q Predictions Min            15.932886
V Predictions Mean           554.1663
V Predictions Std            661.39514
V Predictions Max            1859.3752
V Predictions Min            27.889656
Log Pis Mean                 -8.336393
Log Pis Std                  5.101277
Log Pis Max                  21.1324
Log Pis Min                  -14.416836
Policy mu Mean               0.08119527
Policy mu Std                0.50485045
Policy mu Max                2.5451586
Policy mu Min                -2.630952
Policy log std Mean          -0.21926264
Policy log std Std           0.13310823
Policy log std Max           0.005159691
Policy log std Min           -0.9590089
Z mean eval                  0.033238657
Z variance eval              0.16743621
total_rewards                [ 933.8058871  1058.83705614  376.50471588  626.4768103   450.2051347
  447.43889236  758.01730992 1286.9279708  1096.15546897  695.67936037]
total_rewards_mean           773.0048606538655
total_rewards_std            295.1575595657136
total_rewards_max            1286.9279708028532
total_rewards_min            376.504715878935
Number of train steps total  436000
Number of env steps total    547000
Number of rollouts total     0
Train Time (s)               191.48286153003573
(Previous) Eval Time (s)     4.220804996788502
Sample Time (s)              14.587077607866377
Epoch Time (s)               210.2907441346906
Total Train Time (s)         23326.898549733218
Epoch                        108
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:59:05.683608 UTC | [2020_01_13_04_30_18] Iteration #108 | Epoch Duration: 210.384703874588
2020-01-13 10:59:05.683739 UTC | [2020_01_13_04_30_18] Iteration #108 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03308758
Z variance train             0.16746525
KL Divergence                2.4225194
KL Loss                      0.24225195
QF Loss                      645.07935
VF Loss                      514.4101
Policy Loss                  -587.68176
Q Predictions Mean           580.72754
Q Predictions Std            660.6006
Q Predictions Max            1851.191
Q Predictions Min            19.89279
V Predictions Mean           594.5122
V Predictions Std            662.41864
V Predictions Max            1860.9028
V Predictions Min            34.463543
Log Pis Mean                 -7.4749746
Log Pis Std                  5.599741
Log Pis Max                  19.477901
Log Pis Min                  -14.949634
Policy mu Mean               0.13115378
Policy mu Std                0.5456313
Policy mu Max                2.4439392
Policy mu Min                -2.858857
Policy log std Mean          -0.23506075
Policy log std Std           0.14338677
Policy log std Max           0.18564005
Policy log std Min           -1.1416354
Z mean eval                  0.033243082
Z variance eval              0.16269016
total_rewards                [ 589.67868854  831.67701738  755.92598781  590.54259757 1302.93453899
 2371.41018247 1372.55168257 1468.44871576  768.68494134  616.12907568]
total_rewards_mean           1066.7983428103223
total_rewards_std            539.5313919338922
total_rewards_max            2371.4101824737204
total_rewards_min            589.6786885370299
Number of train steps total  440000
Number of env steps total    552000
Number of rollouts total     0
Train Time (s)               193.9503320818767
(Previous) Eval Time (s)     4.31451022811234
Sample Time (s)              16.06765086390078
Epoch Time (s)               214.33249317388982
Total Train Time (s)         23543.025829970837
Epoch                        109
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:02:41.814111 UTC | [2020_01_13_04_30_18] Iteration #109 | Epoch Duration: 216.13025093078613
2020-01-13 11:02:41.814322 UTC | [2020_01_13_04_30_18] Iteration #109 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033758033
Z variance train             0.16271368
KL Divergence                2.465537
KL Loss                      0.2465537
QF Loss                      854.8724
VF Loss                      220.4352
Policy Loss                  -609.40607
Q Predictions Mean           598.61816
Q Predictions Std            662.95215
Q Predictions Max            1881.5426
Q Predictions Min            18.185736
V Predictions Mean           604.79095
V Predictions Std            661.28766
V Predictions Max            1865.9872
V Predictions Min            26.828827
Log Pis Mean                 -7.892685
Log Pis Std                  5.064655
Log Pis Max                  24.104631
Log Pis Min                  -13.972215
Policy mu Mean               0.12013416
Policy mu Std                0.54196703
Policy mu Max                2.601546
Policy mu Min                -2.5991278
Policy log std Mean          -0.22883104
Policy log std Std           0.13453096
Policy log std Max           -0.064393215
Policy log std Min           -0.8218459
Z mean eval                  0.030762559
Z variance eval              0.16405883
total_rewards                [ 824.61358116  491.46247601  514.69684861 1107.01715623 1515.60801547
  627.83028949  610.52310119  837.77671285  588.00423971  945.92548756]
total_rewards_mean           806.345790828839
total_rewards_std            302.7140945550959
total_rewards_max            1515.6080154653127
total_rewards_min            491.4624760067024
Number of train steps total  444000
Number of env steps total    557000
Number of rollouts total     0
Train Time (s)               194.52460666606203
(Previous) Eval Time (s)     6.111996749881655
Sample Time (s)              15.408161310944706
Epoch Time (s)               216.0447647268884
Total Train Time (s)         23757.2031078632
Epoch                        110
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:06:15.991646 UTC | [2020_01_13_04_30_18] Iteration #110 | Epoch Duration: 214.17718744277954
2020-01-13 11:06:15.991771 UTC | [2020_01_13_04_30_18] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03088295
Z variance train             0.16401708
KL Divergence                2.4437537
KL Loss                      0.24437538
QF Loss                      758.7677
VF Loss                      407.82233
Policy Loss                  -591.1877
Q Predictions Mean           583.66266
Q Predictions Std            684.7145
Q Predictions Max            1880.9164
Q Predictions Min            17.134945
V Predictions Mean           586.08655
V Predictions Std            676.2478
V Predictions Max            1867.4718
V Predictions Min            22.513103
Log Pis Mean                 -7.758016
Log Pis Std                  5.8087287
Log Pis Max                  21.998898
Log Pis Min                  -14.144273
Policy mu Mean               0.10431375
Policy mu Std                0.556587
Policy mu Max                3.218589
Policy mu Min                -3.563551
Policy log std Mean          -0.2397912
Policy log std Std           0.14831145
Policy log std Max           -0.056126483
Policy log std Min           -0.9403672
Z mean eval                  0.038165964
Z variance eval              0.15550455
total_rewards                [1069.87822535  791.15729541 1171.32720191  644.46868211 1160.03861236
 2267.31301584 1163.97252004  703.22416489 1436.71899884 1214.4357416 ]
total_rewards_mean           1162.253445836161
total_rewards_std            438.6747833351248
total_rewards_max            2267.313015844052
total_rewards_min            644.4686821073781
Number of train steps total  448000
Number of env steps total    562000
Number of rollouts total     0
Train Time (s)               193.37205765536055
(Previous) Eval Time (s)     4.244168556760997
Sample Time (s)              16.105438413564116
Epoch Time (s)               213.72166462568566
Total Train Time (s)         23972.999691640027
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:09:51.789453 UTC | [2020_01_13_04_30_18] Iteration #111 | Epoch Duration: 215.7975926399231
2020-01-13 11:09:51.789566 UTC | [2020_01_13_04_30_18] Iteration #111 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038226545
Z variance train             0.15558326
KL Divergence                2.58962
KL Loss                      0.258962
QF Loss                      786.34265
VF Loss                      228.84111
Policy Loss                  -614.9342
Q Predictions Mean           609.4927
Q Predictions Std            696.45483
Q Predictions Max            1876.3712
Q Predictions Min            15.831051
V Predictions Mean           613.7487
V Predictions Std            689.3528
V Predictions Max            1872.7234
V Predictions Min            31.050034
Log Pis Mean                 -7.906497
Log Pis Std                  5.236611
Log Pis Max                  11.695368
Log Pis Min                  -14.3409195
Policy mu Mean               0.1278424
Policy mu Std                0.5479404
Policy mu Max                2.7089384
Policy mu Min                -2.8332088
Policy log std Mean          -0.23141561
Policy log std Std           0.13508217
Policy log std Max           -0.048845626
Policy log std Min           -0.79207826
Z mean eval                  0.034944825
Z variance eval              0.15617204
total_rewards                [ 754.44566613 1073.20349186  767.78847413 1187.04334477 1171.44974588
  782.42993843 1589.32324631  693.92261013  696.89429289 1313.23639387]
total_rewards_mean           1002.9737204390667
total_rewards_std            293.6293190318364
total_rewards_max            1589.323246308853
total_rewards_min            693.9226101251666
Number of train steps total  452000
Number of env steps total    567000
Number of rollouts total     0
Train Time (s)               190.26528719393536
(Previous) Eval Time (s)     6.319830919150263
Sample Time (s)              14.24062440590933
Epoch Time (s)               210.82574251899496
Total Train Time (s)         24182.906229394022
Epoch                        112
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:13:21.697559 UTC | [2020_01_13_04_30_18] Iteration #112 | Epoch Duration: 209.9079074859619
2020-01-13 11:13:21.697673 UTC | [2020_01_13_04_30_18] Iteration #112 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034844063
Z variance train             0.15620765
KL Divergence                2.610136
KL Loss                      0.2610136
QF Loss                      703.3353
VF Loss                      212.82303
Policy Loss                  -632.8184
Q Predictions Mean           624.72546
Q Predictions Std            687.7512
Q Predictions Max            1888.4889
Q Predictions Min            5.913876
V Predictions Mean           634.0397
V Predictions Std            686.70776
V Predictions Max            1886.6099
V Predictions Min            30.62833
Log Pis Mean                 -7.5759296
Log Pis Std                  5.204735
Log Pis Max                  19.766582
Log Pis Min                  -14.21558
Policy mu Mean               0.11068123
Policy mu Std                0.55672544
Policy mu Max                2.6551025
Policy mu Min                -2.3659503
Policy log std Mean          -0.23528881
Policy log std Std           0.13376436
Policy log std Max           -0.016964793
Policy log std Min           -0.8658571
Z mean eval                  0.031812374
Z variance eval              0.13753851
total_rewards                [ 573.67088809  638.03526728  827.90222567  842.39465727  651.3590658
  867.64237422  437.53156248  675.67779051  801.2462555  1836.05378991]
total_rewards_mean           815.1513876727399
total_rewards_std            363.95819046100644
total_rewards_max            1836.053789909173
total_rewards_min            437.5315624826909
Number of train steps total  456000
Number of env steps total    572000
Number of rollouts total     0
Train Time (s)               191.51682283123955
(Previous) Eval Time (s)     5.401725491974503
Sample Time (s)              17.158006029203534
Epoch Time (s)               214.0765543524176
Total Train Time (s)         24395.892642955296
Epoch                        113
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:16:54.685748 UTC | [2020_01_13_04_30_18] Iteration #113 | Epoch Duration: 212.98798942565918
2020-01-13 11:16:54.685861 UTC | [2020_01_13_04_30_18] Iteration #113 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03194787
Z variance train             0.13752684
KL Divergence                2.8238232
KL Loss                      0.28238234
QF Loss                      578.7234
VF Loss                      289.4005
Policy Loss                  -671.8742
Q Predictions Mean           665.18994
Q Predictions Std            711.77423
Q Predictions Max            1889.336
Q Predictions Min            14.825468
V Predictions Mean           676.3281
V Predictions Std            709.8992
V Predictions Max            1903.4491
V Predictions Min            31.86368
Log Pis Mean                 -7.309051
Log Pis Std                  5.500013
Log Pis Max                  16.584297
Log Pis Min                  -14.598276
Policy mu Mean               0.12252836
Policy mu Std                0.57731897
Policy mu Max                2.419019
Policy mu Min                -2.3144915
Policy log std Mean          -0.24016708
Policy log std Std           0.14168532
Policy log std Max           0.0022723526
Policy log std Min           -0.8944404
Z mean eval                  0.03380094
Z variance eval              0.1320771
total_rewards                [1021.54046653 1017.73091791 1309.87262406  787.79498738  974.231373
  777.17965808 1077.29377665  653.00517556  898.9608974  1174.98061692]
total_rewards_mean           969.259049347311
total_rewards_std            187.05616984397975
total_rewards_max            1309.872624064182
total_rewards_min            653.0051755562749
Number of train steps total  460000
Number of env steps total    577000
Number of rollouts total     0
Train Time (s)               193.51055991603062
(Previous) Eval Time (s)     4.3128915736451745
Sample Time (s)              16.28111974755302
Epoch Time (s)               214.1045712372288
Total Train Time (s)         24610.95187019417
Epoch                        114
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:20:29.746466 UTC | [2020_01_13_04_30_18] Iteration #114 | Epoch Duration: 215.0605206489563
2020-01-13 11:20:29.746580 UTC | [2020_01_13_04_30_18] Iteration #114 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032879267
Z variance train             0.1320035
KL Divergence                2.9114285
KL Loss                      0.29114285
QF Loss                      898.3891
VF Loss                      299.42206
Policy Loss                  -632.63873
Q Predictions Mean           625.53015
Q Predictions Std            692.10864
Q Predictions Max            1899.1475
Q Predictions Min            16.46112
V Predictions Mean           636.82794
V Predictions Std            692.5305
V Predictions Max            1901.7576
V Predictions Min            27.719057
Log Pis Mean                 -7.404309
Log Pis Std                  5.7023582
Log Pis Max                  18.118492
Log Pis Min                  -12.9515705
Policy mu Mean               0.099406116
Policy mu Std                0.56838834
Policy mu Max                2.4383788
Policy mu Min                -3.0435467
Policy log std Mean          -0.2367796
Policy log std Std           0.13930963
Policy log std Max           -0.05949635
Policy log std Min           -0.8621595
Z mean eval                  0.026297312
Z variance eval              0.12683329
total_rewards                [1163.25238509  658.12927925  739.27302671 1001.36221425  705.2513355
 1082.53190874 1851.37707178  809.4056968   635.77889941  518.95181225]
total_rewards_mean           916.5313629788967
total_rewards_std            368.8846668706999
total_rewards_max            1851.377071784678
total_rewards_min            518.9518122508119
Number of train steps total  464000
Number of env steps total    582000
Number of rollouts total     0
Train Time (s)               191.64502149587497
(Previous) Eval Time (s)     5.26858247583732
Sample Time (s)              16.745188160333782
Epoch Time (s)               213.65879213204607
Total Train Time (s)         24824.200160538778
Epoch                        115
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:24:02.997066 UTC | [2020_01_13_04_30_18] Iteration #115 | Epoch Duration: 213.2503776550293
2020-01-13 11:24:02.997260 UTC | [2020_01_13_04_30_18] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026043808
Z variance train             0.12682647
KL Divergence                2.9908142
KL Loss                      0.29908141
QF Loss                      544.6649
VF Loss                      218.73108
Policy Loss                  -656.73303
Q Predictions Mean           650.6565
Q Predictions Std            714.5461
Q Predictions Max            1891.94
Q Predictions Min            15.249566
V Predictions Mean           656.38745
V Predictions Std            708.98895
V Predictions Max            1885.0171
V Predictions Min            27.854387
Log Pis Mean                 -7.4196424
Log Pis Std                  5.6829667
Log Pis Max                  16.556244
Log Pis Min                  -13.293623
Policy mu Mean               0.09992833
Policy mu Std                0.5745162
Policy mu Max                2.480774
Policy mu Min                -2.7360225
Policy log std Mean          -0.23751764
Policy log std Std           0.1443685
Policy log std Max           -0.03641045
Policy log std Min           -0.9989855
Z mean eval                  0.031993024
Z variance eval              0.12902923
total_rewards                [ 671.18829967 1564.54047463  856.29279506  926.70201326 1199.74632669
  861.26628941  833.03244314  976.71386282 1389.33258664 1598.62922743]
total_rewards_mean           1087.7444318756693
total_rewards_std            311.9870904051026
total_rewards_max            1598.6292274304833
total_rewards_min            671.1882996726941
Number of train steps total  468000
Number of env steps total    587000
Number of rollouts total     0
Train Time (s)               193.73351597134024
(Previous) Eval Time (s)     4.85989525122568
Sample Time (s)              16.49885814683512
Epoch Time (s)               215.09226936940104
Total Train Time (s)         25040.121693645604
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:27:38.921539 UTC | [2020_01_13_04_30_18] Iteration #116 | Epoch Duration: 215.92415308952332
2020-01-13 11:27:38.921678 UTC | [2020_01_13_04_30_18] Iteration #116 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032918163
Z variance train             0.12899016
KL Divergence                2.9676988
KL Loss                      0.2967699
QF Loss                      849.862
VF Loss                      222.11201
Policy Loss                  -686.2529
Q Predictions Mean           677.6724
Q Predictions Std            714.35834
Q Predictions Max            1902.0698
Q Predictions Min            15.856544
V Predictions Mean           681.4597
V Predictions Std            708.5799
V Predictions Max            1907.3107
V Predictions Min            25.716507
Log Pis Mean                 -6.937375
Log Pis Std                  5.9606423
Log Pis Max                  15.90185
Log Pis Min                  -15.670233
Policy mu Mean               0.11012778
Policy mu Std                0.60112995
Policy mu Max                2.5731404
Policy mu Min                -2.9942546
Policy log std Mean          -0.24925992
Policy log std Std           0.14830326
Policy log std Max           0.14143167
Policy log std Min           -0.8655467
Z mean eval                  0.028126245
Z variance eval              0.14478783
total_rewards                [1715.88100607  969.22937132 1200.85487988  804.78568126 1031.12915427
  834.3325894   748.0328715   825.31763799  809.42020541  805.6354147 ]
total_rewards_mean           974.4618811789935
total_rewards_std            279.62048048568124
total_rewards_max            1715.8810060666328
total_rewards_min            748.0328714955401
Number of train steps total  472000
Number of env steps total    592000
Number of rollouts total     0
Train Time (s)               189.77362653100863
(Previous) Eval Time (s)     5.691507115028799
Sample Time (s)              16.797581466846168
Epoch Time (s)               212.2627151128836
Total Train Time (s)         25251.759717133362
Epoch                        117
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:31:10.561725 UTC | [2020_01_13_04_30_18] Iteration #117 | Epoch Duration: 211.63994669914246
2020-01-13 11:31:10.561869 UTC | [2020_01_13_04_30_18] Iteration #117 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028552007
Z variance train             0.1447165
KL Divergence                2.7922273
KL Loss                      0.27922273
QF Loss                      997.50366
VF Loss                      267.88254
Policy Loss                  -698.4136
Q Predictions Mean           690.50665
Q Predictions Std            688.85895
Q Predictions Max            1916.5773
Q Predictions Min            15.762141
V Predictions Mean           697.9905
V Predictions Std            685.94855
V Predictions Max            1912.7349
V Predictions Min            26.670729
Log Pis Mean                 -7.1907735
Log Pis Std                  5.6213326
Log Pis Max                  13.811085
Log Pis Min                  -14.166296
Policy mu Mean               0.089883626
Policy mu Std                0.59791434
Policy mu Max                2.5557687
Policy mu Min                -2.9625137
Policy log std Mean          -0.24619089
Policy log std Std           0.144651
Policy log std Max           0.048942775
Policy log std Min           -1.1671089
Z mean eval                  0.030333554
Z variance eval              0.14978923
total_rewards                [ 889.61936557  576.0713187   861.59952856 1302.37247021 1004.08161414
 1029.58973574 1115.80742981 1492.08049651  704.72175319  810.22355678]
total_rewards_mean           978.6167269201836
total_rewards_std            260.30019173370454
total_rewards_max            1492.0804965105601
total_rewards_min            576.0713186987938
Number of train steps total  476000
Number of env steps total    597000
Number of rollouts total     0
Train Time (s)               193.3996966360137
(Previous) Eval Time (s)     5.0684776129201055
Sample Time (s)              16.91405459633097
Epoch Time (s)               215.38222884526476
Total Train Time (s)         25466.79505710723
Epoch                        118
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:34:45.598843 UTC | [2020_01_13_04_30_18] Iteration #118 | Epoch Duration: 215.03685116767883
2020-01-13 11:34:45.599005 UTC | [2020_01_13_04_30_18] Iteration #118 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030061359
Z variance train             0.14975674
KL Divergence                2.6724682
KL Loss                      0.2672468
QF Loss                      692.7261
VF Loss                      218.12073
Policy Loss                  -684.6475
Q Predictions Mean           678.6408
Q Predictions Std            732.0653
Q Predictions Max            1898.537
Q Predictions Min            13.379256
V Predictions Mean           686.2633
V Predictions Std            727.1366
V Predictions Max            1908.7115
V Predictions Min            32.358326
Log Pis Mean                 -7.5634522
Log Pis Std                  5.0499907
Log Pis Max                  10.658388
Log Pis Min                  -14.065172
Policy mu Mean               0.10738461
Policy mu Std                0.5582213
Policy mu Max                2.2111917
Policy mu Min                -2.3866227
Policy log std Mean          -0.23697957
Policy log std Std           0.14044864
Policy log std Max           -0.045474067
Policy log std Min           -1.0454
Z mean eval                  0.027723726
Z variance eval              0.14375332
total_rewards                [1006.59882411  926.38277843  721.81049103 1581.79023505  744.33372561
  949.81772047  808.82242681 1519.99832257 1074.94744397  957.75230755]
total_rewards_mean           1029.225427560691
total_rewards_std            281.9616420749562
total_rewards_max            1581.7902350521863
total_rewards_min            721.8104910333539
Number of train steps total  480000
Number of env steps total    602000
Number of rollouts total     0
Train Time (s)               187.37981027411297
(Previous) Eval Time (s)     4.722836334258318
Sample Time (s)              16.41772308992222
Epoch Time (s)               208.5203696982935
Total Train Time (s)         25675.87607945921
Epoch                        119
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:38:14.682185 UTC | [2020_01_13_04_30_18] Iteration #119 | Epoch Duration: 209.08305478096008
2020-01-13 11:38:14.682364 UTC | [2020_01_13_04_30_18] Iteration #119 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027940214
Z variance train             0.14382878
KL Divergence                2.795829
KL Loss                      0.27958292
QF Loss                      731.9749
VF Loss                      333.73975
Policy Loss                  -671.14984
Q Predictions Mean           661.97217
Q Predictions Std            712.2553
Q Predictions Max            1887.4795
Q Predictions Min            17.07286
V Predictions Mean           672.5233
V Predictions Std            711.6772
V Predictions Max            1872.3344
V Predictions Min            23.967596
Log Pis Mean                 -7.3950763
Log Pis Std                  5.7943974
Log Pis Max                  19.559929
Log Pis Min                  -13.841953
Policy mu Mean               0.122133605
Policy mu Std                0.57845956
Policy mu Max                2.7019134
Policy mu Min                -2.6625493
Policy log std Mean          -0.23754495
Policy log std Std           0.14038232
Policy log std Max           -0.020684786
Policy log std Min           -0.9074662
Z mean eval                  0.03291966
Z variance eval              0.1365263
total_rewards                [ 655.76270491  881.66195303  772.51613929  679.82761741 1024.82418313
  622.71509331  503.84327692  599.47514901 1013.89968338  872.24792643]
total_rewards_mean           762.6773726812237
total_rewards_std            170.1786591427057
total_rewards_max            1024.8241831288822
total_rewards_min            503.84327692117927
Number of train steps total  484000
Number of env steps total    607000
Number of rollouts total     0
Train Time (s)               192.11383609799668
(Previous) Eval Time (s)     5.285224694292992
Sample Time (s)              16.825150401331484
Epoch Time (s)               214.22421119362116
Total Train Time (s)         25888.600054861046
Epoch                        120
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:41:47.410635 UTC | [2020_01_13_04_30_18] Iteration #120 | Epoch Duration: 212.7281038761139
2020-01-13 11:41:47.410903 UTC | [2020_01_13_04_30_18] Iteration #120 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032782823
Z variance train             0.13649943
KL Divergence                2.9044771
KL Loss                      0.2904477
QF Loss                      941.8069
VF Loss                      380.0004
Policy Loss                  -758.85596
Q Predictions Mean           748.98755
Q Predictions Std            724.3821
Q Predictions Max            1916.4746
Q Predictions Min            9.393062
V Predictions Mean           756.85297
V Predictions Std            720.5446
V Predictions Max            1908.3896
V Predictions Min            23.079771
Log Pis Mean                 -7.0319986
Log Pis Std                  5.593269
Log Pis Max                  14.508124
Log Pis Min                  -16.068548
Policy mu Mean               0.13209975
Policy mu Std                0.61529803
Policy mu Max                2.8401449
Policy mu Min                -2.6984541
Policy log std Mean          -0.2509856
Policy log std Std           0.1496044
Policy log std Max           0.37152666
Policy log std Min           -0.9747686
Z mean eval                  0.03428626
Z variance eval              0.13005129
total_rewards                [ 336.61756854 1584.73280456 1115.76064178  912.46606376  740.99171627
  954.62326292  736.43601219  556.9967858  1108.83086612 1088.08172733]
total_rewards_mean           913.5537449264042
total_rewards_std            329.05722602449083
total_rewards_max            1584.7328045557254
total_rewards_min            336.6175685373841
Number of train steps total  488000
Number of env steps total    612000
Number of rollouts total     0
Train Time (s)               190.6985369338654
(Previous) Eval Time (s)     3.788834994658828
Sample Time (s)              16.80907647870481
Epoch Time (s)               211.29644840722904
Total Train Time (s)         26100.749456974678
Epoch                        121
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:45:19.563067 UTC | [2020_01_13_04_30_18] Iteration #121 | Epoch Duration: 212.15194940567017
2020-01-13 11:45:19.563294 UTC | [2020_01_13_04_30_18] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03470795
Z variance train             0.13001968
KL Divergence                3.0854042
KL Loss                      0.30854043
QF Loss                      836.0579
VF Loss                      352.7364
Policy Loss                  -687.1713
Q Predictions Mean           681.36163
Q Predictions Std            736.48474
Q Predictions Max            1951.9854
Q Predictions Min            9.508974
V Predictions Mean           686.2936
V Predictions Std            730.86444
V Predictions Max            1955.8118
V Predictions Min            22.773424
Log Pis Mean                 -7.3186054
Log Pis Std                  5.507645
Log Pis Max                  11.09707
Log Pis Min                  -15.115145
Policy mu Mean               0.09963417
Policy mu Std                0.58460647
Policy mu Max                2.856543
Policy mu Min                -3.2608798
Policy log std Mean          -0.24410674
Policy log std Std           0.14672378
Policy log std Max           0.051077113
Policy log std Min           -1.0485543
Z mean eval                  0.026242089
Z variance eval              0.13558158
total_rewards                [ 750.71465935  705.17556085 1214.51372023 1351.16974105  915.45233498
 1461.27420427  817.00178452 1623.13306622  919.94248507  716.37199069]
total_rewards_mean           1047.4749547231327
total_rewards_std            320.0658773666622
total_rewards_max            1623.133066216889
total_rewards_min            705.1755608455798
Number of train steps total  492000
Number of env steps total    617000
Number of rollouts total     0
Train Time (s)               195.3071385016665
(Previous) Eval Time (s)     4.644060400314629
Sample Time (s)              16.55094528477639
Epoch Time (s)               216.5021441867575
Total Train Time (s)         26318.139419075567
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:48:56.953827 UTC | [2020_01_13_04_30_18] Iteration #122 | Epoch Duration: 217.39038157463074
2020-01-13 11:48:56.953944 UTC | [2020_01_13_04_30_18] Iteration #122 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02650297
Z variance train             0.13565676
KL Divergence                2.989179
KL Loss                      0.2989179
QF Loss                      902.4834
VF Loss                      231.80693
Policy Loss                  -685.55597
Q Predictions Mean           675.6248
Q Predictions Std            730.6938
Q Predictions Max            1931.6067
Q Predictions Min            17.825478
V Predictions Mean           686.1288
V Predictions Std            732.1888
V Predictions Max            1951.5609
V Predictions Min            26.802189
Log Pis Mean                 -7.6088467
Log Pis Std                  5.641861
Log Pis Max                  17.925514
Log Pis Min                  -13.823806
Policy mu Mean               0.103912584
Policy mu Std                0.58462983
Policy mu Max                2.6888962
Policy mu Min                -3.1298935
Policy log std Mean          -0.2409597
Policy log std Std           0.14273506
Policy log std Max           -0.068439074
Policy log std Min           -0.9037574
Z mean eval                  0.023583366
Z variance eval              0.16331553
total_rewards                [ 449.60928478 2129.71918677  864.04565112 1184.86644912  682.99383071
 1204.64188104  997.52819466  542.81218317  973.02430881 1022.30705504]
total_rewards_mean           1005.15480252207
total_rewards_std            445.4449643446645
total_rewards_max            2129.7191867707666
total_rewards_min            449.6092847812349
Number of train steps total  496000
Number of env steps total    622000
Number of rollouts total     0
Train Time (s)               192.36580417584628
(Previous) Eval Time (s)     5.532050128560513
Sample Time (s)              17.053118080366403
Epoch Time (s)               214.9509723847732
Total Train Time (s)         26533.01854420267
Epoch                        123
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:52:31.838548 UTC | [2020_01_13_04_30_18] Iteration #123 | Epoch Duration: 214.88446688652039
2020-01-13 11:52:31.838820 UTC | [2020_01_13_04_30_18] Iteration #123 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02338783
Z variance train             0.16332068
KL Divergence                2.5629396
KL Loss                      0.25629398
QF Loss                      726.8229
VF Loss                      238.657
Policy Loss                  -750.4456
Q Predictions Mean           745.21344
Q Predictions Std            734.9868
Q Predictions Max            1959.7423
Q Predictions Min            16.403564
V Predictions Mean           753.1973
V Predictions Std            731.8863
V Predictions Max            1970.5029
V Predictions Min            31.474915
Log Pis Mean                 -7.0416718
Log Pis Std                  5.3418026
Log Pis Max                  7.90545
Log Pis Min                  -15.010962
Policy mu Mean               0.12862994
Policy mu Std                0.5922849
Policy mu Max                2.7317524
Policy mu Min                -2.791268
Policy log std Mean          -0.24946553
Policy log std Std           0.14397639
Policy log std Max           -0.04325942
Policy log std Min           -0.9759575
Z mean eval                  0.03321441
Z variance eval              0.14335155
total_rewards                [1292.5374941  1231.2177097  1437.07255899  956.95064625 1218.45898907
 1752.04455235  653.38784383  951.70388455  879.85155553  831.03430426]
total_rewards_mean           1120.4259538626843
total_rewards_std            310.74978278628373
total_rewards_max            1752.0445523504234
total_rewards_min            653.3878438300898
Number of train steps total  500000
Number of env steps total    627000
Number of rollouts total     0
Train Time (s)               190.7168998126872
(Previous) Eval Time (s)     5.46525952918455
Sample Time (s)              17.130495409015566
Epoch Time (s)               213.3126547508873
Total Train Time (s)         26746.983665028587
Epoch                        124
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:56:05.803127 UTC | [2020_01_13_04_30_18] Iteration #124 | Epoch Duration: 213.96412467956543
2020-01-13 11:56:05.803236 UTC | [2020_01_13_04_30_18] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033196017
Z variance train             0.1432518
KL Divergence                2.8423421
KL Loss                      0.28423423
QF Loss                      656.27344
VF Loss                      324.88693
Policy Loss                  -651.2995
Q Predictions Mean           645.2991
Q Predictions Std            717.5002
Q Predictions Max            1982.3748
Q Predictions Min            15.70712
V Predictions Mean           652.98724
V Predictions Std            713.07074
V Predictions Max            1998.1456
V Predictions Min            28.271746
Log Pis Mean                 -7.3557854
Log Pis Std                  5.8157716
Log Pis Max                  18.949429
Log Pis Min                  -14.368344
Policy mu Mean               0.090384424
Policy mu Std                0.5621307
Policy mu Max                2.6675842
Policy mu Min                -3.2793708
Policy log std Mean          -0.23734704
Policy log std Std           0.14211957
Policy log std Max           0.03150162
Policy log std Min           -0.94406426
Z mean eval                  0.028969854
Z variance eval              0.14533947
total_rewards                [1109.71520512  670.22795651  675.67621695  856.81521906  900.56561756
  989.02634716  856.47497683 1083.50766789 1202.0791227  1162.2344211 ]
total_rewards_mean           950.632275089081
total_rewards_std            180.78707408960824
total_rewards_max            1202.0791227048662
total_rewards_min            670.2279565138803
Number of train steps total  504000
Number of env steps total    632000
Number of rollouts total     0
Train Time (s)               194.035033646971
(Previous) Eval Time (s)     6.116499207913876
Sample Time (s)              17.52392370905727
Epoch Time (s)               217.67545656394213
Total Train Time (s)         26963.528042932972
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:59:42.349029 UTC | [2020_01_13_04_30_18] Iteration #125 | Epoch Duration: 216.54570364952087
2020-01-13 11:59:42.349148 UTC | [2020_01_13_04_30_18] Iteration #125 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029033255
Z variance train             0.14535114
KL Divergence                2.8021417
KL Loss                      0.28021416
QF Loss                      753.96375
VF Loss                      334.8207
Policy Loss                  -721.17535
Q Predictions Mean           711.5999
Q Predictions Std            750.126
Q Predictions Max            1960.0742
Q Predictions Min            19.682419
V Predictions Mean           712.34753
V Predictions Std            745.1706
V Predictions Max            1950.4851
V Predictions Min            23.083017
Log Pis Mean                 -7.353963
Log Pis Std                  5.967499
Log Pis Max                  41.808266
Log Pis Min                  -15.913813
Policy mu Mean               0.10387296
Policy mu Std                0.59033084
Policy mu Max                3.5987418
Policy mu Min                -3.1957572
Policy log std Mean          -0.2400362
Policy log std Std           0.1411564
Policy log std Max           -0.0537581
Policy log std Min           -1.2053562
Z mean eval                  0.027091363
Z variance eval              0.14584841
total_rewards                [ 651.00593594 1849.48415138  942.24605797  986.22459886 1994.61677462
  825.76792195  908.95799108  698.91826557  739.35354899 1538.80587309]
total_rewards_mean           1113.5381119462968
total_rewards_std            468.4915128278494
total_rewards_max            1994.6167746220767
total_rewards_min            651.0059359416308
Number of train steps total  508000
Number of env steps total    637000
Number of rollouts total     0
Train Time (s)               194.2162655047141
(Previous) Eval Time (s)     4.986476290039718
Sample Time (s)              17.189440100453794
Epoch Time (s)               216.3921818952076
Total Train Time (s)         27180.763422440272
Epoch                        126
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:03:19.588281 UTC | [2020_01_13_04_30_18] Iteration #126 | Epoch Duration: 217.2390034198761
2020-01-13 12:03:19.588532 UTC | [2020_01_13_04_30_18] Iteration #126 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02719998
Z variance train             0.14566454
KL Divergence                2.7728798
KL Loss                      0.277288
QF Loss                      855.20544
VF Loss                      233.9102
Policy Loss                  -640.4183
Q Predictions Mean           632.94244
Q Predictions Std            710.23584
Q Predictions Max            1983.4991
Q Predictions Min            17.106617
V Predictions Mean           639.9209
V Predictions Std            707.3747
V Predictions Max            1984.5796
V Predictions Min            25.384453
Log Pis Mean                 -7.9719567
Log Pis Std                  4.852808
Log Pis Max                  8.757437
Log Pis Min                  -13.731243
Policy mu Mean               0.09682386
Policy mu Std                0.5410251
Policy mu Max                2.9042811
Policy mu Min                -2.49696
Policy log std Mean          -0.23230135
Policy log std Std           0.133352
Policy log std Max           -0.05587683
Policy log std Min           -0.91132426
Z mean eval                  0.024007719
Z variance eval              0.13789275
total_rewards                [1147.44725173 1126.11256272  968.18086642  563.03487552 1309.76613499
  697.81881884  927.83667609 2287.31842747 1073.66828735  827.24593397]
total_rewards_mean           1092.8429835093689
total_rewards_std            450.37025206734194
total_rewards_max            2287.3184274700925
total_rewards_min            563.0348755189142
Number of train steps total  512000
Number of env steps total    642000
Number of rollouts total     0
Train Time (s)               191.87442041700706
(Previous) Eval Time (s)     5.832969082985073
Sample Time (s)              15.028860398568213
Epoch Time (s)               212.73624989856035
Total Train Time (s)         27393.5599205452
Epoch                        127
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:06:52.389639 UTC | [2020_01_13_04_30_18] Iteration #127 | Epoch Duration: 212.80077576637268
2020-01-13 12:06:52.390034 UTC | [2020_01_13_04_30_18] Iteration #127 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023856577
Z variance train             0.13794357
KL Divergence                2.8584845
KL Loss                      0.28584847
QF Loss                      855.99976
VF Loss                      290.48285
Policy Loss                  -762.51013
Q Predictions Mean           755.5332
Q Predictions Std            732.997
Q Predictions Max            1976.5052
Q Predictions Min            17.131718
V Predictions Mean           762.2079
V Predictions Std            732.1024
V Predictions Max            1982.8802
V Predictions Min            28.792252
Log Pis Mean                 -6.4144773
Log Pis Std                  5.7832932
Log Pis Max                  18.94754
Log Pis Min                  -13.710182
Policy mu Mean               0.11126843
Policy mu Std                0.6267361
Policy mu Max                2.7788048
Policy mu Min                -2.3722641
Policy log std Mean          -0.25967774
Policy log std Std           0.15697403
Policy log std Max           0.046581358
Policy log std Min           -0.99332464
Z mean eval                  0.027809063
Z variance eval              0.1324947
total_rewards                [ 766.25421518  836.64906417  899.75456061 1305.76010576 1720.82414362
 1044.16375307  723.65221233 1185.2447746   976.17909721 1871.01805645]
total_rewards_mean           1132.9499982997563
total_rewards_std            374.10740296331204
total_rewards_max            1871.0180564468903
total_rewards_min            723.6522123334537
Number of train steps total  516000
Number of env steps total    647000
Number of rollouts total     0
Train Time (s)               190.6814730381593
(Previous) Eval Time (s)     5.897206728812307
Sample Time (s)              14.834483706858009
Epoch Time (s)               211.41316347382963
Total Train Time (s)         27604.72771323705
Epoch                        128
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:10:23.560857 UTC | [2020_01_13_04_30_18] Iteration #128 | Epoch Duration: 211.17054629325867
2020-01-13 12:10:23.561177 UTC | [2020_01_13_04_30_18] Iteration #128 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02761918
Z variance train             0.13252589
KL Divergence                2.9442673
KL Loss                      0.29442674
QF Loss                      925.6961
VF Loss                      259.45642
Policy Loss                  -741.68304
Q Predictions Mean           733.1314
Q Predictions Std            741.2391
Q Predictions Max            1983.0684
Q Predictions Min            17.296247
V Predictions Mean           738.85767
V Predictions Std            737.557
V Predictions Max            1989.9119
V Predictions Min            30.911621
Log Pis Mean                 -6.750945
Log Pis Std                  5.971625
Log Pis Max                  15.697962
Log Pis Min                  -13.49095
Policy mu Mean               0.13369903
Policy mu Std                0.61563724
Policy mu Max                2.3416584
Policy mu Min                -2.8657398
Policy log std Mean          -0.2588651
Policy log std Std           0.15651976
Policy log std Max           -0.02755341
Policy log std Min           -0.96157163
Z mean eval                  0.022468325
Z variance eval              0.1253197
total_rewards                [1148.43051243  882.91371426  777.40365665  893.15417382 1508.14804974
  815.40974179  798.48823544  920.06118107 1157.33392186 1090.92578484]
total_rewards_mean           999.2268971893056
total_rewards_std            216.5656187672207
total_rewards_max            1508.1480497421846
total_rewards_min            777.4036566535557
Number of train steps total  520000
Number of env steps total    652000
Number of rollouts total     0
Train Time (s)               193.3065238459967
(Previous) Eval Time (s)     5.654308603145182
Sample Time (s)              17.31363800028339
Epoch Time (s)               216.27447044942528
Total Train Time (s)         27820.693571457174
Epoch                        129
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:13:59.526738 UTC | [2020_01_13_04_30_18] Iteration #129 | Epoch Duration: 215.96530032157898
2020-01-13 12:13:59.526913 UTC | [2020_01_13_04_30_18] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022431469
Z variance train             0.12535627
KL Divergence                3.1359048
KL Loss                      0.3135905
QF Loss                      714.6568
VF Loss                      234.38922
Policy Loss                  -749.95044
Q Predictions Mean           742.9923
Q Predictions Std            748.501
Q Predictions Max            1998.474
Q Predictions Min            20.260923
V Predictions Mean           747.7762
V Predictions Std            746.26917
V Predictions Max            1997.473
V Predictions Min            31.400734
Log Pis Mean                 -7.226484
Log Pis Std                  5.0293994
Log Pis Max                  9.933474
Log Pis Min                  -14.290897
Policy mu Mean               0.117454134
Policy mu Std                0.57024455
Policy mu Max                2.3661926
Policy mu Min                -2.581342
Policy log std Mean          -0.2380449
Policy log std Std           0.1409296
Policy log std Max           -0.007171333
Policy log std Min           -1.0000288
Z mean eval                  0.028942222
Z variance eval              0.12583211
total_rewards                [2187.41149348  813.561153    779.1292037   763.70847077 1140.73145375
 1800.72910903  702.48588395  728.12204499  978.104808   3012.68694172]
total_rewards_mean           1290.6670562380982
total_rewards_std            746.9432751364687
total_rewards_max            3012.6869417175517
total_rewards_min            702.4858839470244
Number of train steps total  524000
Number of env steps total    657000
Number of rollouts total     0
Train Time (s)               192.92311213957146
(Previous) Eval Time (s)     5.3448717962019145
Sample Time (s)              16.208750061225146
Epoch Time (s)               214.47673399699852
Total Train Time (s)         28036.649594741873
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:17:35.483574 UTC | [2020_01_13_04_30_18] Iteration #130 | Epoch Duration: 215.956561088562
2020-01-13 12:17:35.483689 UTC | [2020_01_13_04_30_18] Iteration #130 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027921263
Z variance train             0.12575307
KL Divergence                3.1255994
KL Loss                      0.31255993
QF Loss                      948.67944
VF Loss                      289.00497
Policy Loss                  -713.22406
Q Predictions Mean           707.13635
Q Predictions Std            769.40436
Q Predictions Max            1990.1572
Q Predictions Min            16.336252
V Predictions Mean           718.3579
V Predictions Std            767.3157
V Predictions Max            1995.7014
V Predictions Min            29.972132
Log Pis Mean                 -7.274455
Log Pis Std                  5.8426666
Log Pis Max                  16.85141
Log Pis Min                  -16.91358
Policy mu Mean               0.10959222
Policy mu Std                0.59097147
Policy mu Max                3.08252
Policy mu Min                -2.925043
Policy log std Mean          -0.24580523
Policy log std Std           0.15052268
Policy log std Max           -0.05488848
Policy log std Min           -1.002613
Z mean eval                  0.022112224
Z variance eval              0.1275637
total_rewards                [2448.15066858 1281.51847585  815.91245709 1731.10373365  985.84725504
 1481.06607619 1400.35201729  917.86035784 1414.77804076 1161.12495785]
total_rewards_mean           1363.7714040136998
total_rewards_std            449.2385962625025
total_rewards_max            2448.150668578057
total_rewards_min            815.9124570917606
Number of train steps total  528000
Number of env steps total    662000
Number of rollouts total     0
Train Time (s)               191.3290622360073
(Previous) Eval Time (s)     6.824424446094781
Sample Time (s)              16.966647426597774
Epoch Time (s)               215.12013410869986
Total Train Time (s)         28252.176053090487
Epoch                        131
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:21:11.011564 UTC | [2020_01_13_04_30_18] Iteration #131 | Epoch Duration: 215.52778482437134
2020-01-13 12:21:11.011684 UTC | [2020_01_13_04_30_18] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02216563
Z variance train             0.12758395
KL Divergence                3.0064769
KL Loss                      0.3006477
QF Loss                      1074.7239
VF Loss                      231.37593
Policy Loss                  -730.2236
Q Predictions Mean           720.4641
Q Predictions Std            751.2255
Q Predictions Max            2003.0771
Q Predictions Min            17.215595
V Predictions Mean           729.79443
V Predictions Std            747.4373
V Predictions Max            2000.895
V Predictions Min            28.042768
Log Pis Mean                 -7.143738
Log Pis Std                  5.7079916
Log Pis Max                  27.13358
Log Pis Min                  -13.907516
Policy mu Mean               0.1392349
Policy mu Std                0.5955906
Policy mu Max                3.2304866
Policy mu Min                -2.6922815
Policy log std Mean          -0.2583097
Policy log std Std           0.1516252
Policy log std Max           -0.021642417
Policy log std Min           -0.9944361
Z mean eval                  0.030001167
Z variance eval              0.115987696
total_rewards                [ 792.19508669 1049.51080194 1741.39580055  939.91494834 1451.06340218
  776.22722049  738.5297611   849.50464274 1075.13891498 1303.12737713]
total_rewards_mean           1071.660795613518
total_rewards_std            314.5853625112896
total_rewards_max            1741.3958005465615
total_rewards_min            738.529761100796
Number of train steps total  532000
Number of env steps total    667000
Number of rollouts total     0
Train Time (s)               192.81855178205296
(Previous) Eval Time (s)     7.231810190714896
Sample Time (s)              17.49635630333796
Epoch Time (s)               217.54671827610582
Total Train Time (s)         28468.463229288347
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:24:47.300073 UTC | [2020_01_13_04_30_18] Iteration #132 | Epoch Duration: 216.28829979896545
2020-01-13 12:24:47.300191 UTC | [2020_01_13_04_30_18] Iteration #132 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029645752
Z variance train             0.11604581
KL Divergence                3.2238564
KL Loss                      0.32238564
QF Loss                      940.03864
VF Loss                      258.1643
Policy Loss                  -722.83716
Q Predictions Mean           720.1747
Q Predictions Std            778.8226
Q Predictions Max            2014.5941
Q Predictions Min            14.110641
V Predictions Mean           725.2025
V Predictions Std            772.3686
V Predictions Max            2010.4702
V Predictions Min            31.606853
Log Pis Mean                 -6.799324
Log Pis Std                  6.0927916
Log Pis Max                  15.28163
Log Pis Min                  -13.0743265
Policy mu Mean               0.12807441
Policy mu Std                0.60102683
Policy mu Max                2.97276
Policy mu Min                -2.5791163
Policy log std Mean          -0.25427577
Policy log std Std           0.15811197
Policy log std Max           -0.039550632
Policy log std Min           -0.99666923
Z mean eval                  0.025220316
Z variance eval              0.120419696
total_rewards                [ 793.04867712 2015.4148397  1173.70921731 2223.79496735 1363.46257743
 1857.01243956 1103.9800716  1294.99748621 1206.96847808 1701.3472656 ]
total_rewards_mean           1473.373601997073
total_rewards_std            431.2834528620426
total_rewards_max            2223.7949673464736
total_rewards_min            793.0486771246141
Number of train steps total  536000
Number of env steps total    672000
Number of rollouts total     0
Train Time (s)               189.5281628658995
(Previous) Eval Time (s)     5.973119841422886
Sample Time (s)              17.36618709610775
Epoch Time (s)               212.86746980343014
Total Train Time (s)         28683.427864695434
Epoch                        133
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:28:22.268321 UTC | [2020_01_13_04_30_18] Iteration #133 | Epoch Duration: 214.9680163860321
2020-01-13 12:28:22.268527 UTC | [2020_01_13_04_30_18] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025371289
Z variance train             0.12045561
KL Divergence                3.25583
KL Loss                      0.325583
QF Loss                      1143.595
VF Loss                      370.40262
Policy Loss                  -774.8203
Q Predictions Mean           763.64606
Q Predictions Std            778.87396
Q Predictions Max            2021.3834
Q Predictions Min            10.875393
V Predictions Mean           775.1514
V Predictions Std            779.29706
V Predictions Max            2031.6653
V Predictions Min            10.165159
Log Pis Mean                 -6.701815
Log Pis Std                  6.6336765
Log Pis Max                  23.442486
Log Pis Min                  -16.491287
Policy mu Mean               0.086624846
Policy mu Std                0.61912775
Policy mu Max                2.7690146
Policy mu Min                -2.6932294
Policy log std Mean          -0.25990862
Policy log std Std           0.15783134
Policy log std Max           -0.059047095
Policy log std Min           -0.9307612
Z mean eval                  0.027056033
Z variance eval              0.1289549
total_rewards                [1367.81888769 1389.30482361  911.15186948  621.78599117  511.61946547
 1594.3049624   809.77269261 1521.62866743  706.16526559 1195.18772997]
total_rewards_mean           1062.8740355398988
total_rewards_std            377.18580225488716
total_rewards_max            1594.3049624035298
total_rewards_min            511.61946546594623
Number of train steps total  540000
Number of env steps total    677000
Number of rollouts total     0
Train Time (s)               192.1731800911948
(Previous) Eval Time (s)     8.073377287015319
Sample Time (s)              16.429660023655742
Epoch Time (s)               216.67621740186587
Total Train Time (s)         28898.30015734071
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:31:57.145193 UTC | [2020_01_13_04_30_18] Iteration #134 | Epoch Duration: 214.87650299072266
2020-01-13 12:31:57.145386 UTC | [2020_01_13_04_30_18] Iteration #134 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02671046
Z variance train             0.1288715
KL Divergence                3.0489085
KL Loss                      0.30489084
QF Loss                      948.12823
VF Loss                      421.53357
Policy Loss                  -800.5198
Q Predictions Mean           797.62384
Q Predictions Std            776.0474
Q Predictions Max            2029.6405
Q Predictions Min            9.014299
V Predictions Mean           800.15717
V Predictions Std            769.8111
V Predictions Max            2034.1638
V Predictions Min            26.366543
Log Pis Mean                 -7.112588
Log Pis Std                  6.007066
Log Pis Max                  20.785486
Log Pis Min                  -16.58723
Policy mu Mean               0.13496593
Policy mu Std                0.6084374
Policy mu Max                2.4669452
Policy mu Min                -3.6843324
Policy log std Mean          -0.25358272
Policy log std Std           0.14681222
Policy log std Max           0.09450205
Policy log std Min           -0.96821165
Z mean eval                  0.02554611
Z variance eval              0.1325858
total_rewards                [3244.14242854 1191.27565008 2992.93787722  673.18948809  914.87522903
 1171.51155491  819.97506679 2079.4638039  1671.52455585 3036.03845414]
total_rewards_mean           1779.493410853033
total_rewards_std            943.7149817510964
total_rewards_max            3244.142428536977
total_rewards_min            673.1894880916734
Number of train steps total  544000
Number of env steps total    682000
Number of rollouts total     0
Train Time (s)               188.65708435000852
(Previous) Eval Time (s)     6.273379577323794
Sample Time (s)              18.185605115722865
Epoch Time (s)               213.11606904305518
Total Train Time (s)         29113.97204254754
Epoch                        135
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:35:32.818966 UTC | [2020_01_13_04_30_18] Iteration #135 | Epoch Duration: 215.67330503463745
2020-01-13 12:35:32.819206 UTC | [2020_01_13_04_30_18] Iteration #135 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026277263
Z variance train             0.13254869
KL Divergence                3.0300527
KL Loss                      0.30300528
QF Loss                      1188.722
VF Loss                      369.86368
Policy Loss                  -784.2274
Q Predictions Mean           773.2
Q Predictions Std            761.7404
Q Predictions Max            2034.1404
Q Predictions Min            19.901861
V Predictions Mean           775.43677
V Predictions Std            757.7563
V Predictions Max            2031.4517
V Predictions Min            26.026329
Log Pis Mean                 -6.23685
Log Pis Std                  5.8247223
Log Pis Max                  14.475031
Log Pis Min                  -14.341534
Policy mu Mean               0.13311972
Policy mu Std                0.6318859
Policy mu Max                2.5765927
Policy mu Min                -2.7703393
Policy log std Mean          -0.26432666
Policy log std Std           0.16016984
Policy log std Max           -0.00059843063
Policy log std Min           -1.1076359
Z mean eval                  0.025746515
Z variance eval              0.120695665
total_rewards                [2469.97713805  643.2163218   497.92059387  516.62452471 1303.43022039
 2669.87411265  788.33251438  816.91073481  661.19726967  467.78037905]
total_rewards_mean           1083.5263809383778
total_rewards_std            778.5252510808463
total_rewards_max            2669.874112645094
total_rewards_min            467.78037905195566
Number of train steps total  548000
Number of env steps total    687000
Number of rollouts total     0
Train Time (s)               192.12920920923352
(Previous) Eval Time (s)     8.830379854887724
Sample Time (s)              17.72212439822033
Epoch Time (s)               218.68171346234158
Total Train Time (s)         29329.19327463489
Epoch                        136
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:39:08.041608 UTC | [2020_01_13_04_30_18] Iteration #136 | Epoch Duration: 215.22224950790405
2020-01-13 12:39:08.041792 UTC | [2020_01_13_04_30_18] Iteration #136 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025094032
Z variance train             0.12059009
KL Divergence                3.142142
KL Loss                      0.3142142
QF Loss                      878.2992
VF Loss                      301.07016
Policy Loss                  -762.3882
Q Predictions Mean           757.94653
Q Predictions Std            779.3461
Q Predictions Max            2035.8516
Q Predictions Min            17.843725
V Predictions Mean           766.20026
V Predictions Std            776.81476
V Predictions Max            2041.1843
V Predictions Min            18.637121
Log Pis Mean                 -7.212754
Log Pis Std                  5.8655148
Log Pis Max                  16.619617
Log Pis Min                  -13.593934
Policy mu Mean               0.13359608
Policy mu Std                0.5798323
Policy mu Max                2.6061878
Policy mu Min                -2.825265
Policy log std Mean          -0.24541283
Policy log std Std           0.1407432
Policy log std Max           -0.02580753
Policy log std Min           -0.9889665
Z mean eval                  0.02091518
Z variance eval              0.11653624
total_rewards                [2202.98426226 1169.02520282 1366.99775906  659.22262083  999.29176119
  899.34986511  943.88636154  788.2598699   836.16770308  595.59831055]
total_rewards_mean           1046.0783716337032
total_rewards_std            442.0204057206562
total_rewards_max            2202.984262260272
total_rewards_min            595.5983105525205
Number of train steps total  552000
Number of env steps total    692000
Number of rollouts total     0
Train Time (s)               197.52928431564942
(Previous) Eval Time (s)     5.370643059257418
Sample Time (s)              17.904313201550394
Epoch Time (s)               220.80424057645723
Total Train Time (s)         29549.59645805834
Epoch                        137
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:42:48.449819 UTC | [2020_01_13_04_30_18] Iteration #137 | Epoch Duration: 220.40786337852478
2020-01-13 12:42:48.450102 UTC | [2020_01_13_04_30_18] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020995852
Z variance train             0.116424106
KL Divergence                3.2090373
KL Loss                      0.32090375
QF Loss                      1062.9868
VF Loss                      300.96613
Policy Loss                  -711.2877
Q Predictions Mean           702.3644
Q Predictions Std            743.577
Q Predictions Max            2041.6978
Q Predictions Min            13.4589615
V Predictions Mean           706.5851
V Predictions Std            736.7035
V Predictions Max            2051.567
V Predictions Min            27.325655
Log Pis Mean                 -7.1377473
Log Pis Std                  5.7276278
Log Pis Max                  18.204645
Log Pis Min                  -14.131937
Policy mu Mean               0.10214256
Policy mu Std                0.6093355
Policy mu Max                3.2274935
Policy mu Min                -3.0156507
Policy log std Mean          -0.24621414
Policy log std Std           0.14221843
Policy log std Max           -0.06575931
Policy log std Min           -0.906384
Z mean eval                  0.026179472
Z variance eval              0.09472055
total_rewards                [ 695.91939821 1363.7039351   932.46660144 1556.7717664   947.37246674
  808.49878903 1435.15954617  655.13894678  904.32990694  953.85841656]
total_rewards_mean           1025.3219773362405
total_rewards_std            298.64799670324095
total_rewards_max            1556.7717664025404
total_rewards_min            655.1389467829806
Number of train steps total  556000
Number of env steps total    697000
Number of rollouts total     0
Train Time (s)               193.304671744816
(Previous) Eval Time (s)     4.974000809248537
Sample Time (s)              17.769477097317576
Epoch Time (s)               216.04814965138212
Total Train Time (s)         29766.431443830952
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:46:25.285143 UTC | [2020_01_13_04_30_18] Iteration #138 | Epoch Duration: 216.83485746383667
2020-01-13 12:46:25.285262 UTC | [2020_01_13_04_30_18] Iteration #138 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026069993
Z variance train             0.09473287
KL Divergence                3.6528478
KL Loss                      0.36528477
QF Loss                      1217.0568
VF Loss                      286.2792
Policy Loss                  -760.9236
Q Predictions Mean           751.6021
Q Predictions Std            753.8139
Q Predictions Max            2062.4648
Q Predictions Min            16.65142
V Predictions Mean           762.4251
V Predictions Std            754.59204
V Predictions Max            2069.8074
V Predictions Min            23.488003
Log Pis Mean                 -6.7334805
Log Pis Std                  6.2392216
Log Pis Max                  24.417925
Log Pis Min                  -17.309193
Policy mu Mean               0.14492802
Policy mu Std                0.61842144
Policy mu Max                2.748229
Policy mu Min                -2.9806314
Policy log std Mean          -0.2599536
Policy log std Std           0.15766576
Policy log std Max           0.025321811
Policy log std Min           -1.1181257
Z mean eval                  0.014082983
Z variance eval              0.10507431
total_rewards                [1920.97635498 1967.53369034  721.81873763 1243.73663931 2318.4560893
  887.45739068 1262.47413897 1166.2595808  1501.85858109 1576.78212921]
total_rewards_mean           1456.735333232579
total_rewards_std            476.1414166377976
total_rewards_max            2318.4560893002244
total_rewards_min            721.8187376329594
Number of train steps total  560000
Number of env steps total    702000
Number of rollouts total     0
Train Time (s)               186.57842676201835
(Previous) Eval Time (s)     5.760413689073175
Sample Time (s)              17.898180495016277
Epoch Time (s)               210.2370209461078
Total Train Time (s)         29978.69552034512
Epoch                        139
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:49:57.555237 UTC | [2020_01_13_04_30_18] Iteration #139 | Epoch Duration: 212.26983737945557
2020-01-13 12:49:57.555535 UTC | [2020_01_13_04_30_18] Iteration #139 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014117266
Z variance train             0.105070055
KL Divergence                3.4473505
KL Loss                      0.34473506
QF Loss                      916.4131
VF Loss                      363.45724
Policy Loss                  -830.80194
Q Predictions Mean           824.4167
Q Predictions Std            776.55475
Q Predictions Max            2074.6472
Q Predictions Min            15.216946
V Predictions Mean           831.7854
V Predictions Std            772.843
V Predictions Max            2069.3752
V Predictions Min            26.639347
Log Pis Mean                 -5.9814425
Log Pis Std                  6.507526
Log Pis Max                  20.806736
Log Pis Min                  -16.414885
Policy mu Mean               0.13101676
Policy mu Std                0.65518457
Policy mu Max                3.135256
Policy mu Min                -2.9953887
Policy log std Mean          -0.27774328
Policy log std Std           0.16746053
Policy log std Max           -0.04887849
Policy log std Min           -1.1943226
Z mean eval                  0.016507143
Z variance eval              0.110401295
total_rewards                [ 704.20707737 1528.28653178  816.66779877  541.88850457  806.43673423
  812.96128701 1477.31342807  601.90179505 1157.51343371 1339.35535242]
total_rewards_mean           978.6531942982714
total_rewards_std            347.0206239243672
total_rewards_max            1528.286531784585
total_rewards_min            541.8885045702167
Number of train steps total  564000
Number of env steps total    707000
Number of rollouts total     0
Train Time (s)               190.51843629823998
(Previous) Eval Time (s)     7.792949585709721
Sample Time (s)              18.181452004238963
Epoch Time (s)               216.49283788818866
Total Train Time (s)         30191.970629980322
Epoch                        140
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:53:30.832300 UTC | [2020_01_13_04_30_18] Iteration #140 | Epoch Duration: 213.27649450302124
2020-01-13 12:53:30.832683 UTC | [2020_01_13_04_30_18] Iteration #140 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016521515
Z variance train             0.11043133
KL Divergence                3.3281486
KL Loss                      0.33281487
QF Loss                      1236.6199
VF Loss                      284.5056
Policy Loss                  -860.4473
Q Predictions Mean           849.14923
Q Predictions Std            818.9449
Q Predictions Max            2085.7253
Q Predictions Min            16.46991
V Predictions Mean           856.3422
V Predictions Std            815.14264
V Predictions Max            2071.0237
V Predictions Min            29.318506
Log Pis Mean                 -6.151169
Log Pis Std                  7.2279525
Log Pis Max                  41.75982
Log Pis Min                  -16.034618
Policy mu Mean               0.13470204
Policy mu Std                0.66130704
Policy mu Max                3.5214214
Policy mu Min                -2.7881515
Policy log std Mean          -0.26955682
Policy log std Std           0.16474818
Policy log std Max           0.047767103
Policy log std Min           -1.2575161
Z mean eval                  0.020670436
Z variance eval              0.10184772
total_rewards                [3643.06348203 1088.30429493 1065.05922711 1842.77126156 2486.4310316
 1285.29693665  679.30626327 1727.30461116 2490.20774599 1404.06547824]
total_rewards_mean           1771.1810332538867
total_rewards_std            840.6873688384945
total_rewards_max            3643.063482030971
total_rewards_min            679.3062632720197
Number of train steps total  568000
Number of env steps total    712000
Number of rollouts total     0
Train Time (s)               198.00223744194955
(Previous) Eval Time (s)     4.576322388835251
Sample Time (s)              17.837381110992283
Epoch Time (s)               220.41594094177708
Total Train Time (s)         30417.06654659519
Epoch                        141
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:57:15.933388 UTC | [2020_01_13_04_30_18] Iteration #141 | Epoch Duration: 225.1004192829132
2020-01-13 12:57:15.933684 UTC | [2020_01_13_04_30_18] Iteration #141 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020567562
Z variance train             0.10192947
KL Divergence                3.468903
KL Loss                      0.3468903
QF Loss                      783.3295
VF Loss                      222.62305
Policy Loss                  -749.18616
Q Predictions Mean           742.0022
Q Predictions Std            785.3214
Q Predictions Max            2068.4048
Q Predictions Min            16.835234
V Predictions Mean           747.3312
V Predictions Std            780.0207
V Predictions Max            2072.4395
V Predictions Min            26.832417
Log Pis Mean                 -7.363412
Log Pis Std                  5.426853
Log Pis Max                  19.046867
Log Pis Min                  -13.127224
Policy mu Mean               0.11262014
Policy mu Std                0.5800483
Policy mu Max                2.9188201
Policy mu Min                -2.4476662
Policy log std Mean          -0.24094734
Policy log std Std           0.14090179
Policy log std Max           -0.026278913
Policy log std Min           -0.93945384
Z mean eval                  0.015591577
Z variance eval              0.09479964
total_rewards                [2011.78019773  874.69757491  799.52300658  888.39377115 4401.75620154
  638.49894922 4008.36838131 1674.49431129 1972.44127258 1023.72380398]
total_rewards_mean           1829.3677470296432
total_rewards_std            1279.3589898409127
total_rewards_max            4401.756201535262
total_rewards_min            638.4989492188313
Number of train steps total  572000
Number of env steps total    717000
Number of rollouts total     0
Train Time (s)               192.89262015698478
(Previous) Eval Time (s)     9.260534724220634
Sample Time (s)              17.173547787126154
Epoch Time (s)               219.32670266833156
Total Train Time (s)         30636.628542138264
Epoch                        142
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:00:55.495015 UTC | [2020_01_13_04_30_18] Iteration #142 | Epoch Duration: 219.56113600730896
2020-01-13 13:00:55.495134 UTC | [2020_01_13_04_30_18] Iteration #142 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015187102
Z variance train             0.0948509
KL Divergence                3.6480231
KL Loss                      0.36480233
QF Loss                      1595.2499
VF Loss                      373.58737
Policy Loss                  -871.95746
Q Predictions Mean           862.6156
Q Predictions Std            771.60004
Q Predictions Max            2068.4956
Q Predictions Min            15.935402
V Predictions Mean           874.8174
V Predictions Std            776.3694
V Predictions Max            2098.0164
V Predictions Min            28.174921
Log Pis Mean                 -5.9764137
Log Pis Std                  5.9961524
Log Pis Max                  14.744331
Log Pis Min                  -13.27154
Policy mu Mean               0.14013027
Policy mu Std                0.6608737
Policy mu Max                3.5953014
Policy mu Min                -2.5032125
Policy log std Mean          -0.27531886
Policy log std Std           0.15730588
Policy log std Max           -0.07304719
Policy log std Min           -1.2546788
Z mean eval                  0.016680498
Z variance eval              0.09978689
total_rewards                [1399.90623529  702.21390779 1621.4362418  1947.67879974  902.23489875
 5259.2327675  1689.67758056 1294.06655667 3210.99550676  960.59767147]
total_rewards_mean           1898.804016633641
total_rewards_std            1306.0321137983433
total_rewards_max            5259.232767499869
total_rewards_min            702.2139077927952
Number of train steps total  576000
Number of env steps total    722000
Number of rollouts total     0
Train Time (s)               191.5300719407387
(Previous) Eval Time (s)     9.494735154788941
Sample Time (s)              17.37107002735138
Epoch Time (s)               218.39587712287903
Total Train Time (s)         30855.49858658435
Epoch                        143
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:04:34.366422 UTC | [2020_01_13_04_30_18] Iteration #143 | Epoch Duration: 218.87120151519775
2020-01-13 13:04:34.366538 UTC | [2020_01_13_04_30_18] Iteration #143 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017041624
Z variance train             0.09980697
KL Divergence                3.5510626
KL Loss                      0.35510626
QF Loss                      993.0168
VF Loss                      396.94998
Policy Loss                  -859.8856
Q Predictions Mean           853.13574
Q Predictions Std            821.25397
Q Predictions Max            2096.078
Q Predictions Min            14.256033
V Predictions Mean           862.3307
V Predictions Std            818.52295
V Predictions Max            2101.9329
V Predictions Min            29.002289
Log Pis Mean                 -5.5775914
Log Pis Std                  7.4009457
Log Pis Max                  27.533905
Log Pis Min                  -16.989162
Policy mu Mean               0.12121218
Policy mu Std                0.6823965
Policy mu Max                3.3212833
Policy mu Min                -3.1544328
Policy log std Mean          -0.26946673
Policy log std Std           0.16720852
Policy log std Max           0.073438734
Policy log std Min           -1.1056836
Z mean eval                  0.014443813
Z variance eval              0.094158575
total_rewards                [1100.38229405  716.98469904  859.50060336 1309.75807007 1071.44680182
  872.67916449 1028.96677932  891.41747022 1091.43753358 1156.90225251]
total_rewards_mean           1009.9475668456714
total_rewards_std            164.86312116898634
total_rewards_max            1309.7580700674569
total_rewards_min            716.9846990357826
Number of train steps total  580000
Number of env steps total    727000
Number of rollouts total     0
Train Time (s)               191.07489326084033
(Previous) Eval Time (s)     9.96977173909545
Sample Time (s)              17.83160407608375
Epoch Time (s)               218.87626907601953
Total Train Time (s)         31069.600331308786
Epoch                        144
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:08:08.470703 UTC | [2020_01_13_04_30_18] Iteration #144 | Epoch Duration: 214.10405468940735
2020-01-13 13:08:08.470882 UTC | [2020_01_13_04_30_18] Iteration #144 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013644256
Z variance train             0.09415821
KL Divergence                3.6899223
KL Loss                      0.36899224
QF Loss                      1326.8381
VF Loss                      360.0276
Policy Loss                  -897.03046
Q Predictions Mean           887.088
Q Predictions Std            815.13007
Q Predictions Max            2084.8467
Q Predictions Min            16.318613
V Predictions Mean           896.53613
V Predictions Std            814.0517
V Predictions Max            2085.25
V Predictions Min            31.429773
Log Pis Mean                 -5.964823
Log Pis Std                  6.373275
Log Pis Max                  16.332441
Log Pis Min                  -14.661512
Policy mu Mean               0.110185035
Policy mu Std                0.65223914
Policy mu Max                2.6265426
Policy mu Min                -2.8699553
Policy log std Mean          -0.27390873
Policy log std Std           0.15653177
Policy log std Max           0.106067225
Policy log std Min           -1.0835092
Z mean eval                  0.018912017
Z variance eval              0.081978045
total_rewards                [ 934.80264714  666.15283848 1302.64304714  921.26500754 1770.15134966
 3607.36140814 1926.83227442  586.87021725  786.2352943  1332.9183922 ]
total_rewards_mean           1383.5232476273075
total_rewards_std            855.5867414826464
total_rewards_max            3607.361408141107
total_rewards_min            586.8702172474696
Number of train steps total  584000
Number of env steps total    732000
Number of rollouts total     0
Train Time (s)               190.22904644720256
(Previous) Eval Time (s)     5.197286661248654
Sample Time (s)              15.549410523846745
Epoch Time (s)               210.97574363229796
Total Train Time (s)         31282.398578733206
Epoch                        145
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:11:41.273680 UTC | [2020_01_13_04_30_18] Iteration #145 | Epoch Duration: 212.80263924598694
2020-01-13 13:11:41.273939 UTC | [2020_01_13_04_30_18] Iteration #145 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018695658
Z variance train             0.08194966
KL Divergence                3.9948444
KL Loss                      0.39948446
QF Loss                      941.2471
VF Loss                      275.9871
Policy Loss                  -853.4301
Q Predictions Mean           848.2448
Q Predictions Std            824.075
Q Predictions Max            2122.7625
Q Predictions Min            15.06018
V Predictions Mean           853.1589
V Predictions Std            819.0651
V Predictions Max            2119.4119
V Predictions Min            22.316704
Log Pis Mean                 -6.413947
Log Pis Std                  6.350922
Log Pis Max                  19.755198
Log Pis Min                  -13.203699
Policy mu Mean               0.1190546
Policy mu Std                0.63219255
Policy mu Max                2.8190591
Policy mu Min                -2.868546
Policy log std Mean          -0.2613837
Policy log std Std           0.1559497
Policy log std Max           -0.007877678
Policy log std Min           -0.9734988
Z mean eval                  0.023284465
Z variance eval              0.07668705
total_rewards                [2935.15513032  849.11292462 2583.7704018  2039.17372755 2569.09182303
 1748.11442422  805.53510259  822.3497846  3636.04190947 1782.68822968]
total_rewards_mean           1977.1033457861631
total_rewards_std            919.8321518418402
total_rewards_max            3636.041909467025
total_rewards_min            805.5351025856883
Number of train steps total  588000
Number of env steps total    737000
Number of rollouts total     0
Train Time (s)               194.63113759737462
(Previous) Eval Time (s)     7.023890381678939
Sample Time (s)              15.547814118210226
Epoch Time (s)               217.20284209726378
Total Train Time (s)         31502.702795656398
Epoch                        146
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:15:21.581217 UTC | [2020_01_13_04_30_18] Iteration #146 | Epoch Duration: 220.30707216262817
2020-01-13 13:15:21.581454 UTC | [2020_01_13_04_30_18] Iteration #146 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022979934
Z variance train             0.07670347
KL Divergence                4.185939
KL Loss                      0.41859388
QF Loss                      1252.5564
VF Loss                      298.1458
Policy Loss                  -851.258
Q Predictions Mean           841.4502
Q Predictions Std            807.6571
Q Predictions Max            2133.4717
Q Predictions Min            12.80764
V Predictions Mean           854.3414
V Predictions Std            807.0618
V Predictions Max            2153.1636
V Predictions Min            28.289118
Log Pis Mean                 -5.9487205
Log Pis Std                  6.2632446
Log Pis Max                  18.988474
Log Pis Min                  -13.908568
Policy mu Mean               0.13375254
Policy mu Std                0.65512586
Policy mu Max                2.6615298
Policy mu Min                -2.6909416
Policy log std Mean          -0.2660638
Policy log std Std           0.16773851
Policy log std Max           -0.035633445
Policy log std Min           -1.1842816
Z mean eval                  0.015199086
Z variance eval              0.08546473
total_rewards                [1013.44890778  953.00651683 2332.72026868 2098.05363668 1328.88373959
 4854.75693133 5157.13759588 1247.95813358 2843.98288031 1612.86246817]
total_rewards_mean           2344.281107880627
total_rewards_std            1449.1308568495342
total_rewards_max            5157.13759587591
total_rewards_min            953.0065168261964
Number of train steps total  592000
Number of env steps total    742000
Number of rollouts total     0
Train Time (s)               197.51068068481982
(Previous) Eval Time (s)     10.127863413654268
Sample Time (s)              16.706958008930087
Epoch Time (s)               224.34550210740417
Total Train Time (s)         31727.764438359067
Epoch                        147
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:19:06.647742 UTC | [2020_01_13_04_30_18] Iteration #147 | Epoch Duration: 225.06607627868652
2020-01-13 13:19:06.648040 UTC | [2020_01_13_04_30_18] Iteration #147 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015127746
Z variance train             0.085431695
KL Divergence                3.8998523
KL Loss                      0.38998523
QF Loss                      1103.6476
VF Loss                      417.5999
Policy Loss                  -949.56866
Q Predictions Mean           941.2817
Q Predictions Std            827.5306
Q Predictions Max            2128.4297
Q Predictions Min            19.1131
V Predictions Mean           957.4916
V Predictions Std            832.1128
V Predictions Max            2164.491
V Predictions Min            29.181307
Log Pis Mean                 -5.7075486
Log Pis Std                  6.404392
Log Pis Max                  15.320873
Log Pis Min                  -13.71229
Policy mu Mean               0.13546006
Policy mu Std                0.67062175
Policy mu Max                2.592446
Policy mu Min                -3.0116208
Policy log std Mean          -0.28337878
Policy log std Std           0.16756293
Policy log std Max           -0.02470471
Policy log std Min           -1.0434421
Z mean eval                  0.008059641
Z variance eval              0.089506514
total_rewards                [1100.55889089  820.93720963 1671.50947427 3589.58749075 1232.61776374
 1604.93635855 1122.02481368 3391.13173882 1730.16586027 1570.93260089]
total_rewards_mean           1783.4402201495272
total_rewards_std            898.4900902064121
total_rewards_max            3589.5874907539737
total_rewards_min            820.9372096252005
Number of train steps total  596000
Number of env steps total    747000
Number of rollouts total     0
Train Time (s)               197.26273280195892
(Previous) Eval Time (s)     10.848148102872074
Sample Time (s)              18.483347546309233
Epoch Time (s)               226.59422845114022
Total Train Time (s)         31952.297280586325
Epoch                        148
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:22:51.184808 UTC | [2020_01_13_04_30_18] Iteration #148 | Epoch Duration: 224.536559343338
2020-01-13 13:22:51.184966 UTC | [2020_01_13_04_30_18] Iteration #148 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.007976279
Z variance train             0.08950056
KL Divergence                3.7894833
KL Loss                      0.37894833
QF Loss                      1026.7119
VF Loss                      239.29884
Policy Loss                  -879.21924
Q Predictions Mean           873.7537
Q Predictions Std            829.6334
Q Predictions Max            2140.8308
Q Predictions Min            18.238272
V Predictions Mean           879.9645
V Predictions Std            827.5354
V Predictions Max            2132.1084
V Predictions Min            26.396315
Log Pis Mean                 -7.0837817
Log Pis Std                  5.439475
Log Pis Max                  12.077354
Log Pis Min                  -13.5787525
Policy mu Mean               0.09296107
Policy mu Std                0.61707467
Policy mu Max                2.200912
Policy mu Min                -2.8955996
Policy log std Mean          -0.26781055
Policy log std Std           0.1516285
Policy log std Max           -0.07514169
Policy log std Min           -0.9181498
Z mean eval                  0.012354879
Z variance eval              0.10472
total_rewards                [1654.99866058 1629.92762538 1075.03299828 2613.02896925 2439.7963861
 1274.01231119 4072.4342581   942.54843645 3227.57133312 1955.84974756]
total_rewards_mean           2088.5200725997893
total_rewards_std            951.3956641253992
total_rewards_max            4072.4342580988055
total_rewards_min            942.54843644852
Number of train steps total  600000
Number of env steps total    752000
Number of rollouts total     0
Train Time (s)               192.71303483610973
(Previous) Eval Time (s)     8.790228197351098
Sample Time (s)              17.702529173810035
Epoch Time (s)               219.20579220727086
Total Train Time (s)         32173.783558453433
Epoch                        149
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:26:32.671098 UTC | [2020_01_13_04_30_18] Iteration #149 | Epoch Duration: 221.4860224723816
2020-01-13 13:26:32.671215 UTC | [2020_01_13_04_30_18] Iteration #149 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012554394
Z variance train             0.10470251
KL Divergence                3.4253023
KL Loss                      0.34253022
QF Loss                      1196.7329
VF Loss                      457.82178
Policy Loss                  -852.1438
Q Predictions Mean           847.5402
Q Predictions Std            853.7037
Q Predictions Max            2135.23
Q Predictions Min            11.790028
V Predictions Mean           864.3263
V Predictions Std            856.6894
V Predictions Max            2155.5474
V Predictions Min            28.29624
Log Pis Mean                 -6.5553493
Log Pis Std                  6.417669
Log Pis Max                  16.082775
Log Pis Min                  -15.988944
Policy mu Mean               0.10030338
Policy mu Std                0.63996303
Policy mu Max                2.6332753
Policy mu Min                -2.715989
Policy log std Mean          -0.26468477
Policy log std Std           0.16001071
Policy log std Max           -0.011542857
Policy log std Min           -0.97827953
Z mean eval                  0.0076043764
Z variance eval              0.09328927
total_rewards                [2278.06511413 1249.50314712 1409.73913459  628.17957116 1375.61682218
 1104.6086362  2112.80049784 3030.33122343 4193.22090119  912.1407853 ]
total_rewards_mean           1829.4205833147819
total_rewards_std            1041.126003899638
total_rewards_max            4193.220901192014
total_rewards_min            628.1795711551291
Number of train steps total  604000
Number of env steps total    757000
Number of rollouts total     0
Train Time (s)               194.58912582928315
(Previous) Eval Time (s)     11.070161728654057
Sample Time (s)              18.629789802711457
Epoch Time (s)               224.28907736064866
Total Train Time (s)         32396.822550413664
Epoch                        150
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:30:15.711365 UTC | [2020_01_13_04_30_18] Iteration #150 | Epoch Duration: 223.04006004333496
2020-01-13 13:30:15.711486 UTC | [2020_01_13_04_30_18] Iteration #150 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.007679929
Z variance train             0.09331639
KL Divergence                3.6821034
KL Loss                      0.36821035
QF Loss                      1091.6523
VF Loss                      267.1873
Policy Loss                  -967.6638
Q Predictions Mean           959.84845
Q Predictions Std            857.9375
Q Predictions Max            2151.0403
Q Predictions Min            18.22888
V Predictions Mean           968.47107
V Predictions Std            858.6533
V Predictions Max            2159.731
V Predictions Min            28.154692
Log Pis Mean                 -6.2248974
Log Pis Std                  5.8439307
Log Pis Max                  12.103296
Log Pis Min                  -14.673582
Policy mu Mean               0.14470395
Policy mu Std                0.6458983
Policy mu Max                2.7473922
Policy mu Min                -2.8321743
Policy log std Mean          -0.27484098
Policy log std Std           0.1561556
Policy log std Max           -0.053519577
Policy log std Min           -0.9927545
Z mean eval                  0.01391119
Z variance eval              0.093710795
total_rewards                [ 694.41875731  944.44053538 4341.5402318  1380.84705882 1092.60359739
  717.75861125 2584.91598582 2133.29426335 1705.99912322 2626.77001306]
total_rewards_mean           1822.2588177392038
total_rewards_std            1080.540251633745
total_rewards_max            4341.540231798151
total_rewards_min            694.4187573109997
Number of train steps total  608000
Number of env steps total    762000
Number of rollouts total     0
Train Time (s)               193.85003217495978
(Previous) Eval Time (s)     9.820877309888601
Sample Time (s)              17.168105787597597
Epoch Time (s)               220.83901527244598
Total Train Time (s)         32617.413073306438
Epoch                        151
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:33:56.304448 UTC | [2020_01_13_04_30_18] Iteration #151 | Epoch Duration: 220.59285640716553
2020-01-13 13:33:56.304631 UTC | [2020_01_13_04_30_18] Iteration #151 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013204657
Z variance train             0.09367012
KL Divergence                3.6915698
KL Loss                      0.369157
QF Loss                      834.81226
VF Loss                      390.3315
Policy Loss                  -857.7601
Q Predictions Mean           853.16895
Q Predictions Std            846.021
Q Predictions Max            2157.6794
Q Predictions Min            16.246603
V Predictions Mean           858.14667
V Predictions Std            840.4955
V Predictions Max            2168.8289
V Predictions Min            27.793125
Log Pis Mean                 -6.19666
Log Pis Std                  6.1743355
Log Pis Max                  17.411467
Log Pis Min                  -14.078122
Policy mu Mean               0.11083514
Policy mu Std                0.6526823
Policy mu Max                2.719057
Policy mu Min                -2.5691013
Policy log std Mean          -0.26971212
Policy log std Std           0.16303143
Policy log std Max           -0.06419591
Policy log std Min           -0.9711744
Z mean eval                  0.008905591
Z variance eval              0.08869016
total_rewards                [1710.25672459 1117.90526558 1866.33239599 3269.70429342 2586.2356564
 1936.26020064 2204.18462198 1312.2324336  1449.68783899 1319.66725154]
total_rewards_mean           1877.2466682735412
total_rewards_std            630.0413651506213
total_rewards_max            3269.7042934202195
total_rewards_min            1117.905265581338
Number of train steps total  612000
Number of env steps total    767000
Number of rollouts total     0
Train Time (s)               196.5386259299703
(Previous) Eval Time (s)     9.57443939615041
Sample Time (s)              15.248416156042367
Epoch Time (s)               221.36148148216307
Total Train Time (s)         32838.89373604208
Epoch                        152
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:37:37.786119 UTC | [2020_01_13_04_30_18] Iteration #152 | Epoch Duration: 221.48137068748474
2020-01-13 13:37:37.786246 UTC | [2020_01_13_04_30_18] Iteration #152 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009103587
Z variance train             0.08865478
KL Divergence                3.8281019
KL Loss                      0.3828102
QF Loss                      1181.556
VF Loss                      448.23862
Policy Loss                  -959.2704
Q Predictions Mean           956.4079
Q Predictions Std            871.02295
Q Predictions Max            2180.2837
Q Predictions Min            21.214005
V Predictions Mean           956.1792
V Predictions Std            864.32544
V Predictions Max            2157.4998
V Predictions Min            26.143602
Log Pis Mean                 -5.6786246
Log Pis Std                  6.438148
Log Pis Max                  22.049004
Log Pis Min                  -12.759636
Policy mu Mean               0.13069478
Policy mu Std                0.6729601
Policy mu Max                2.7647543
Policy mu Min                -2.4861145
Policy log std Mean          -0.2830234
Policy log std Std           0.16719565
Policy log std Max           -0.04140307
Policy log std Min           -0.9833602
Z mean eval                  0.0103944335
Z variance eval              0.10471205
total_rewards                [1798.23258869 2735.92888191 2734.69575142 2831.01660553 1383.38335999
 1968.33712054 3180.26943055 1850.45405007 2135.98585481 3179.97264829]
total_rewards_mean           2379.8276291799984
total_rewards_std            598.1156841572064
total_rewards_max            3180.2694305487707
total_rewards_min            1383.3833599923444
Number of train steps total  616000
Number of env steps total    772000
Number of rollouts total     0
Train Time (s)               195.62144926795736
(Previous) Eval Time (s)     9.69403605023399
Sample Time (s)              17.309482569806278
Epoch Time (s)               222.62496788799763
Total Train Time (s)         33064.07353845565
Epoch                        153
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:41:22.967432 UTC | [2020_01_13_04_30_18] Iteration #153 | Epoch Duration: 225.1810965538025
2020-01-13 13:41:22.967555 UTC | [2020_01_13_04_30_18] Iteration #153 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010272308
Z variance train             0.10463921
KL Divergence                3.433996
KL Loss                      0.3433996
QF Loss                      1357.1156
VF Loss                      302.48596
Policy Loss                  -972.37415
Q Predictions Mean           961.2426
Q Predictions Std            856.9172
Q Predictions Max            2182.972
Q Predictions Min            10.817981
V Predictions Mean           969.59424
V Predictions Std            854.7163
V Predictions Max            2169.5364
V Predictions Min            27.93599
Log Pis Mean                 -5.371889
Log Pis Std                  6.900485
Log Pis Max                  34.72243
Log Pis Min                  -14.629702
Policy mu Mean               0.14167848
Policy mu Std                0.69692856
Policy mu Max                2.951531
Policy mu Min                -3.105594
Policy log std Mean          -0.2935749
Policy log std Std           0.17219117
Policy log std Max           -0.005530894
Policy log std Min           -0.99173766
Z mean eval                  0.008923142
Z variance eval              0.10063644
total_rewards                [4232.10702507 3014.55119558  731.91806888 5052.58174113 4503.68178486
 5102.81604888 1105.23287721 1410.41049056 3759.69375349 1426.56150811]
total_rewards_mean           3033.9554493773185
total_rewards_std            1634.525373738709
total_rewards_max            5102.8160488818785
total_rewards_min            731.9180688761553
Number of train steps total  620000
Number of env steps total    777000
Number of rollouts total     0
Train Time (s)               191.3629629937932
(Previous) Eval Time (s)     12.249889705330133
Sample Time (s)              18.098582888022065
Epoch Time (s)               221.7114355871454
Total Train Time (s)         33289.459065697156
Epoch                        154
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:45:08.355728 UTC | [2020_01_13_04_30_18] Iteration #154 | Epoch Duration: 225.38807559013367
2020-01-13 13:45:08.355881 UTC | [2020_01_13_04_30_18] Iteration #154 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0088386005
Z variance train             0.10063444
KL Divergence                3.4988623
KL Loss                      0.34988624
QF Loss                      1102.3542
VF Loss                      338.78906
Policy Loss                  -925.8414
Q Predictions Mean           917.3525
Q Predictions Std            864.0516
Q Predictions Max            2191.6978
Q Predictions Min            14.5345
V Predictions Mean           928.7755
V Predictions Std            864.8168
V Predictions Max            2205.8489
V Predictions Min            23.084927
Log Pis Mean                 -6.3761215
Log Pis Std                  6.094429
Log Pis Max                  17.549732
Log Pis Min                  -13.621255
Policy mu Mean               0.15796112
Policy mu Std                0.63111216
Policy mu Max                2.4914315
Policy mu Min                -2.6759436
Policy log std Mean          -0.27390593
Policy log std Std           0.15766323
Policy log std Max           -0.02859366
Policy log std Min           -0.9231866
Z mean eval                  0.010890228
Z variance eval              0.09366633
total_rewards                [1819.06606309 4661.02023077  869.98371008 3182.5159894  1077.03891933
 1398.64072044 4146.43983776 1393.54561044 1058.02309944 2581.48607554]
total_rewards_mean           2218.7760256286942
total_rewards_std            1293.226381009545
total_rewards_max            4661.020230769284
total_rewards_min            869.9837100812749
Number of train steps total  624000
Number of env steps total    782000
Number of rollouts total     0
Train Time (s)               194.07294199382886
(Previous) Eval Time (s)     15.92626699525863
Sample Time (s)              18.613687689881772
Epoch Time (s)               228.61289667896926
Total Train Time (s)         33513.76931077335
Epoch                        155
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:48:52.666747 UTC | [2020_01_13_04_30_18] Iteration #155 | Epoch Duration: 224.31075620651245
2020-01-13 13:48:52.666865 UTC | [2020_01_13_04_30_18] Iteration #155 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01093507
Z variance train             0.093624964
KL Divergence                3.7127304
KL Loss                      0.37127304
QF Loss                      1322.6201
VF Loss                      348.50134
Policy Loss                  -898.0393
Q Predictions Mean           888.2086
Q Predictions Std            848.753
Q Predictions Max            2186.0125
Q Predictions Min            15.146846
V Predictions Mean           897.64075
V Predictions Std            847.6064
V Predictions Max            2192.4624
V Predictions Min            26.885616
Log Pis Mean                 -5.6812944
Log Pis Std                  6.48552
Log Pis Max                  18.386957
Log Pis Min                  -12.980185
Policy mu Mean               0.09359325
Policy mu Std                0.69527817
Policy mu Max                2.8387637
Policy mu Min                -2.7269957
Policy log std Mean          -0.27861726
Policy log std Std           0.15663037
Policy log std Max           -0.012814559
Policy log std Min           -0.89042807
Z mean eval                  0.011599173
Z variance eval              0.08305358
total_rewards                [2823.68090265 4695.59403031 5172.2264139  3243.89310935 1116.41721969
 3363.99129707  779.26177851 5154.87163673 4453.76601171 2472.6614353 ]
total_rewards_mean           3327.6363835224583
total_rewards_std            1491.903761510338
total_rewards_max            5172.226413896285
total_rewards_min            779.2617785074784
Number of train steps total  628000
Number of env steps total    787000
Number of rollouts total     0
Train Time (s)               188.75782304583117
(Previous) Eval Time (s)     11.623863044194877
Sample Time (s)              18.144336400553584
Epoch Time (s)               218.52602249057963
Total Train Time (s)         33738.29399492964
Epoch                        156
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:52:37.194496 UTC | [2020_01_13_04_30_18] Iteration #156 | Epoch Duration: 224.52751851081848
2020-01-13 13:52:37.194714 UTC | [2020_01_13_04_30_18] Iteration #156 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0114380475
Z variance train             0.083074465
KL Divergence                3.937733
KL Loss                      0.3937733
QF Loss                      1285.0768
VF Loss                      422.69388
Policy Loss                  -935.7797
Q Predictions Mean           926.34534
Q Predictions Std            860.6408
Q Predictions Max            2206.632
Q Predictions Min            19.768732
V Predictions Mean           935.3146
V Predictions Std            859.30304
V Predictions Max            2210.4287
V Predictions Min            28.624464
Log Pis Mean                 -5.619075
Log Pis Std                  7.2276344
Log Pis Max                  38.289024
Log Pis Min                  -15.74129
Policy mu Mean               0.14679325
Policy mu Std                0.6760576
Policy mu Max                3.4012074
Policy mu Min                -3.2327483
Policy log std Mean          -0.28189915
Policy log std Std           0.16504619
Policy log std Max           0.037010178
Policy log std Min           -1.3112254
Z mean eval                  0.01556927
Z variance eval              0.080535546
total_rewards                [4193.89575177  686.80594582 2425.060309   1497.8044188  3482.36644528
 1812.89281158 2712.52542746  881.83951989  904.081954    690.10544627]
total_rewards_mean           1928.7378029868473
total_rewards_std            1175.882888807627
total_rewards_max            4193.895751767425
total_rewards_min            686.8059458195982
Number of train steps total  632000
Number of env steps total    792000
Number of rollouts total     0
Train Time (s)               189.92089648498222
(Previous) Eval Time (s)     17.62507606903091
Sample Time (s)              18.522355746477842
Epoch Time (s)               226.06832830049098
Total Train Time (s)         33956.85360774305
Epoch                        157
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:56:15.754735 UTC | [2020_01_13_04_30_18] Iteration #157 | Epoch Duration: 218.55989265441895
2020-01-13 13:56:15.754866 UTC | [2020_01_13_04_30_18] Iteration #157 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01647654
Z variance train             0.08051098
KL Divergence                4.0437117
KL Loss                      0.40437117
QF Loss                      1487.2393
VF Loss                      833.682
Policy Loss                  -1005.2426
Q Predictions Mean           993.0978
Q Predictions Std            885.2059
Q Predictions Max            2216.6406
Q Predictions Min            14.514297
V Predictions Mean           991.8113
V Predictions Std            875.9549
V Predictions Max            2200.5623
V Predictions Min            28.534857
Log Pis Mean                 -5.6689835
Log Pis Std                  6.3576155
Log Pis Max                  16.25502
Log Pis Min                  -13.010156
Policy mu Mean               0.12562996
Policy mu Std                0.67575103
Policy mu Max                2.757112
Policy mu Min                -2.6956527
Policy log std Mean          -0.27970645
Policy log std Std           0.16652304
Policy log std Max           -0.015609086
Policy log std Min           -1.0333115
Z mean eval                  0.017737271
Z variance eval              0.08550941
total_rewards                [1827.25000468 2703.17475803 1944.64449472 4520.2110655  1103.05822695
 1471.77133267 4064.06754274 5130.91747698 2967.53518062 4532.14358753]
total_rewards_mean           3026.4773670444165
total_rewards_std            1372.4682913946965
total_rewards_max            5130.917476983499
total_rewards_min            1103.0582269514243
Number of train steps total  636000
Number of env steps total    797000
Number of rollouts total     0
Train Time (s)               195.69457522500306
(Previous) Eval Time (s)     10.116347949020565
Sample Time (s)              18.252910072449595
Epoch Time (s)               224.06383324647322
Total Train Time (s)         34185.23717263853
Epoch                        158
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:00:04.141702 UTC | [2020_01_13_04_30_18] Iteration #158 | Epoch Duration: 228.38671684265137
2020-01-13 14:00:04.141909 UTC | [2020_01_13_04_30_18] Iteration #158 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017780947
Z variance train             0.08543293
KL Divergence                3.9106307
KL Loss                      0.39106306
QF Loss                      1282.0103
VF Loss                      475.959
Policy Loss                  -1068.1744
Q Predictions Mean           1060.1506
Q Predictions Std            876.23596
Q Predictions Max            2225.7761
Q Predictions Min            -9.476826
V Predictions Mean           1070.0659
V Predictions Std            873.9183
V Predictions Max            2226.7507
V Predictions Min            30.455109
Log Pis Mean                 -5.222741
Log Pis Std                  6.735549
Log Pis Max                  19.041826
Log Pis Min                  -13.782455
Policy mu Mean               0.14171411
Policy mu Std                0.7135073
Policy mu Max                2.7998636
Policy mu Min                -3.4607856
Policy log std Mean          -0.29987937
Policy log std Std           0.16985568
Policy log std Max           -0.064602375
Policy log std Min           -1.0854058
Z mean eval                  0.017214721
Z variance eval              0.08567791
total_rewards                [2127.91414465 1389.14596727 3970.1838993  5049.78331649 4738.43670911
 1069.07572155 2930.02495872 1232.32154016 1136.25248089  993.28576345]
total_rewards_mean           2463.6424501574097
total_rewards_std            1516.6453089224754
total_rewards_max            5049.783316488019
total_rewards_min            993.2857634487348
Number of train steps total  640000
Number of env steps total    802000
Number of rollouts total     0
Train Time (s)               193.00379002233967
(Previous) Eval Time (s)     14.438825362827629
Sample Time (s)              16.70687961857766
Epoch Time (s)               224.14949500374496
Total Train Time (s)         34407.449775089044
Epoch                        159
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:03:46.357290 UTC | [2020_01_13_04_30_18] Iteration #159 | Epoch Duration: 222.21517777442932
2020-01-13 14:03:46.357459 UTC | [2020_01_13_04_30_18] Iteration #159 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016906817
Z variance train             0.08559423
KL Divergence                3.8960662
KL Loss                      0.38960662
QF Loss                      1399.6105
VF Loss                      636.2552
Policy Loss                  -959.52045
Q Predictions Mean           950.84393
Q Predictions Std            885.92303
Q Predictions Max            2217.243
Q Predictions Min            13.950507
V Predictions Mean           972.0574
V Predictions Std            891.94855
V Predictions Max            2261.6995
V Predictions Min            29.87756
Log Pis Mean                 -5.6427755
Log Pis Std                  6.4391704
Log Pis Max                  23.679575
Log Pis Min                  -13.820204
Policy mu Mean               0.1683039
Policy mu Std                0.6697256
Policy mu Max                2.6758595
Policy mu Min                -3.0236323
Policy log std Mean          -0.282048
Policy log std Std           0.16740611
Policy log std Max           0.03646852
Policy log std Min           -1.0377742
Z mean eval                  0.010881506
Z variance eval              0.091326945
total_rewards                [1248.32529565 2579.7340813  5147.87422059 1408.13278338 2147.22753215
 1448.84025537 1043.54795602 2342.44866089  948.10269398 5209.94205249]
total_rewards_mean           2352.4175531821757
total_rewards_std            1506.1966866886305
total_rewards_max            5209.942052491866
total_rewards_min            948.102693976162
Number of train steps total  644000
Number of env steps total    807000
Number of rollouts total     0
Train Time (s)               190.86817676527426
(Previous) Eval Time (s)     12.504105771891773
Sample Time (s)              18.531192829832435
Epoch Time (s)               221.90347536699846
Total Train Time (s)         34629.00584479561
Epoch                        160
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:07:27.914481 UTC | [2020_01_13_04_30_18] Iteration #160 | Epoch Duration: 221.55691528320312
2020-01-13 14:07:27.914598 UTC | [2020_01_13_04_30_18] Iteration #160 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010585951
Z variance train             0.0913202
KL Divergence                3.847671
KL Loss                      0.38476712
QF Loss                      1450.9382
VF Loss                      442.18808
Policy Loss                  -959.05164
Q Predictions Mean           948.31415
Q Predictions Std            892.8739
Q Predictions Max            2228.7488
Q Predictions Min            18.841827
V Predictions Mean           953.19824
V Predictions Std            887.8341
V Predictions Max            2228.109
V Predictions Min            23.09602
Log Pis Mean                 -5.6134644
Log Pis Std                  6.988241
Log Pis Max                  22.744978
Log Pis Min                  -15.530157
Policy mu Mean               0.15936263
Policy mu Std                0.69375134
Policy mu Max                3.1980214
Policy mu Min                -3.250684
Policy log std Mean          -0.2893435
Policy log std Std           0.17252521
Policy log std Max           0.038233384
Policy log std Min           -1.0711958
Z mean eval                  0.014512886
Z variance eval              0.09830812
total_rewards                [ 817.24325474 1406.67513862 2094.4555643  1410.8469581  1206.47601678
 1236.97015767 1064.79349266 3149.30688046 1274.45658313 2026.81429054]
total_rewards_mean           1568.8038337012922
total_rewards_std            646.7004218890854
total_rewards_max            3149.3068804641875
total_rewards_min            817.2432547378306
Number of train steps total  648000
Number of env steps total    812000
Number of rollouts total     0
Train Time (s)               198.31860545277596
(Previous) Eval Time (s)     12.157272713258862
Sample Time (s)              18.331530143506825
Epoch Time (s)               228.80740830954164
Total Train Time (s)         34853.49389764201
Epoch                        161
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:11:12.405371 UTC | [2020_01_13_04_30_18] Iteration #161 | Epoch Duration: 224.49067044258118
2020-01-13 14:11:12.405549 UTC | [2020_01_13_04_30_18] Iteration #161 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014578955
Z variance train             0.098344274
KL Divergence                3.6888738
KL Loss                      0.3688874
QF Loss                      1193.196
VF Loss                      325.3178
Policy Loss                  -917.87665
Q Predictions Mean           908.1039
Q Predictions Std            890.8218
Q Predictions Max            2258.3713
Q Predictions Min            14.559195
V Predictions Mean           914.5771
V Predictions Std            887.89264
V Predictions Max            2254.9663
V Predictions Min            25.110714
Log Pis Mean                 -5.8730497
Log Pis Std                  6.380378
Log Pis Max                  14.386437
Log Pis Min                  -13.817492
Policy mu Mean               0.14991513
Policy mu Std                0.652466
Policy mu Max                2.661119
Policy mu Min                -2.3448029
Policy log std Mean          -0.27372193
Policy log std Std           0.16161004
Policy log std Max           -0.0305541
Policy log std Min           -0.9739424
Z mean eval                  0.020758513
Z variance eval              0.101829015
total_rewards                [ 684.02470145 1965.93530358 1825.32487214 5147.12722835 1107.74684213
 1181.32095064 2030.39738702 1480.93334179 4617.83551336 1769.45597714]
total_rewards_mean           2181.0102117597858
total_rewards_std            1413.617494793725
total_rewards_max            5147.127228345097
total_rewards_min            684.0247014545594
Number of train steps total  652000
Number of env steps total    817000
Number of rollouts total     0
Train Time (s)               191.83900848496705
(Previous) Eval Time (s)     7.840272212866694
Sample Time (s)              15.995660963002592
Epoch Time (s)               215.67494166083634
Total Train Time (s)         35071.84247863572
Epoch                        162
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:14:50.756329 UTC | [2020_01_13_04_30_18] Iteration #162 | Epoch Duration: 218.35064840316772
2020-01-13 14:14:50.756506 UTC | [2020_01_13_04_30_18] Iteration #162 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02067471
Z variance train             0.101942495
KL Divergence                3.6249604
KL Loss                      0.36249605
QF Loss                      1456.192
VF Loss                      514.86566
Policy Loss                  -1055.632
Q Predictions Mean           1048.4436
Q Predictions Std            888.65546
Q Predictions Max            2253.5796
Q Predictions Min            18.279182
V Predictions Mean           1057.6907
V Predictions Std            887.07477
V Predictions Max            2258.9773
V Predictions Min            21.969284
Log Pis Mean                 -5.163804
Log Pis Std                  6.968667
Log Pis Max                  31.084335
Log Pis Min                  -14.554271
Policy mu Mean               0.153444
Policy mu Std                0.7158493
Policy mu Max                2.598808
Policy mu Min                -3.5150585
Policy log std Mean          -0.28983688
Policy log std Std           0.16308925
Policy log std Max           0.03224936
Policy log std Min           -0.99801475
Z mean eval                  0.012786521
Z variance eval              0.09309483
total_rewards                [3903.66218354 5337.60655115 5360.20041013 1690.95887267 2582.25613209
 3489.95881369 5227.72336716 3208.26999774 3960.31281204 2136.97667563]
total_rewards_mean           3689.792581583607
total_rewards_std            1260.7423864175219
total_rewards_max            5360.200410133774
total_rewards_min            1690.958872669341
Number of train steps total  656000
Number of env steps total    822000
Number of rollouts total     0
Train Time (s)               197.06097300490364
(Previous) Eval Time (s)     10.515707924962044
Sample Time (s)              16.672363077290356
Epoch Time (s)               224.24904400715604
Total Train Time (s)         35304.14226272516
Epoch                        163
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:18:43.061495 UTC | [2020_01_13_04_30_18] Iteration #163 | Epoch Duration: 232.30481815338135
2020-01-13 14:18:43.061788 UTC | [2020_01_13_04_30_18] Iteration #163 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012653217
Z variance train             0.093094304
KL Divergence                3.7904477
KL Loss                      0.37904477
QF Loss                      1687.9589
VF Loss                      518.7456
Policy Loss                  -1003.85236
Q Predictions Mean           999.8237
Q Predictions Std            875.3552
Q Predictions Max            2270.3928
Q Predictions Min            16.664913
V Predictions Mean           1008.42365
V Predictions Std            871.14496
V Predictions Max            2269.3403
V Predictions Min            30.183743
Log Pis Mean                 -4.9714537
Log Pis Std                  7.43737
Log Pis Max                  25.003132
Log Pis Min                  -15.67236
Policy mu Mean               0.12124497
Policy mu Std                0.73566836
Policy mu Max                4.2900977
Policy mu Min                -2.765562
Policy log std Mean          -0.29589102
Policy log std Std           0.17621537
Policy log std Max           -0.070218325
Policy log std Min           -1.1592544
Z mean eval                  0.015386961
Z variance eval              0.09935958
total_rewards                [1993.01459169 1468.86989775  866.10125917 5258.72379702 1997.76605079
 1966.2722745  3425.34802211 2180.12965183 5160.60867575 2239.833409  ]
total_rewards_mean           2655.666762961552
total_rewards_std            1414.2255679890172
total_rewards_max            5258.723797021281
total_rewards_min            866.1012591738712
Number of train steps total  660000
Number of env steps total    827000
Number of rollouts total     0
Train Time (s)               190.06403123307973
(Previous) Eval Time (s)     18.57119332300499
Sample Time (s)              17.468121564015746
Epoch Time (s)               226.10334612010047
Total Train Time (s)         35525.385811516084
Epoch                        164
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:22:24.304662 UTC | [2020_01_13_04_30_18] Iteration #164 | Epoch Duration: 221.24269247055054
2020-01-13 14:22:24.304787 UTC | [2020_01_13_04_30_18] Iteration #164 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015467296
Z variance train             0.099394485
KL Divergence                3.6362178
KL Loss                      0.3636218
QF Loss                      1332.9619
VF Loss                      278.6619
Policy Loss                  -948.29224
Q Predictions Mean           937.2218
Q Predictions Std            930.844
Q Predictions Max            2278.2056
Q Predictions Min            17.877361
V Predictions Mean           948.327
V Predictions Std            932.3339
V Predictions Max            2281.4294
V Predictions Min            29.636251
Log Pis Mean                 -6.354368
Log Pis Std                  6.3472977
Log Pis Max                  23.516703
Log Pis Min                  -14.880265
Policy mu Mean               0.11786453
Policy mu Std                0.63808966
Policy mu Max                2.4458866
Policy mu Min                -3.0811744
Policy log std Mean          -0.26740813
Policy log std Std           0.15767719
Policy log std Max           -0.073765315
Policy log std Min           -0.9466973
Z mean eval                  0.012865347
Z variance eval              0.096258715
total_rewards                [3627.45250088 1026.24244084  890.73443245 1886.82875104 1235.07079493
 3175.09848334 3966.16339146 1166.86306522 1979.59863109 2442.21111534]
total_rewards_mean           2139.6263606589805
total_rewards_std            1066.1605745101929
total_rewards_max            3966.1633914575787
total_rewards_min            890.7344324465639
Number of train steps total  664000
Number of env steps total    832000
Number of rollouts total     0
Train Time (s)               194.30622513731942
(Previous) Eval Time (s)     13.710285062901676
Sample Time (s)              18.1519837891683
Epoch Time (s)               226.1684939893894
Total Train Time (s)         35748.08801172022
Epoch                        165
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:26:07.011837 UTC | [2020_01_13_04_30_18] Iteration #165 | Epoch Duration: 222.7069170475006
2020-01-13 14:26:07.012115 UTC | [2020_01_13_04_30_18] Iteration #165 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012887371
Z variance train             0.09625495
KL Divergence                3.8319693
KL Loss                      0.38319692
QF Loss                      1405.5184
VF Loss                      581.78955
Policy Loss                  -1005.58026
Q Predictions Mean           996.34106
Q Predictions Std            889.9594
Q Predictions Max            2288.8875
Q Predictions Min            19.435928
V Predictions Mean           1006.4463
V Predictions Std            890.42786
V Predictions Max            2295.4788
V Predictions Min            26.33204
Log Pis Mean                 -4.9375896
Log Pis Std                  7.3477674
Log Pis Max                  24.925081
Log Pis Min                  -16.714632
Policy mu Mean               0.18990055
Policy mu Std                0.7117938
Policy mu Max                2.930552
Policy mu Min                -2.966348
Policy log std Mean          -0.28747812
Policy log std Std           0.1662674
Policy log std Max           0.3878411
Policy log std Min           -1.0236546
Z mean eval                  0.015240642
Z variance eval              0.08946355
total_rewards                [3367.9637878  1989.63844433 5163.56506859  708.19095845 1619.48261514
 2593.75715802 5273.70022275 1977.84435492 5134.40002419 2792.97140274]
total_rewards_mean           3062.1514036938406
total_rewards_std            1547.0909154643077
total_rewards_max            5273.700222753828
total_rewards_min            708.1909584482208
Number of train steps total  668000
Number of env steps total    837000
Number of rollouts total     0
Train Time (s)               195.64478968828917
(Previous) Eval Time (s)     10.248399430885911
Sample Time (s)              18.379069722257555
Epoch Time (s)               224.27225884143263
Total Train Time (s)         35976.51223003352
Epoch                        166
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:29:55.438284 UTC | [2020_01_13_04_30_18] Iteration #166 | Epoch Duration: 228.4259741306305
2020-01-13 14:29:55.438496 UTC | [2020_01_13_04_30_18] Iteration #166 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014630589
Z variance train             0.0894484
KL Divergence                3.9877012
KL Loss                      0.39877012
QF Loss                      983.4529
VF Loss                      417.15457
Policy Loss                  -1047.6793
Q Predictions Mean           1039.0453
Q Predictions Std            917.32367
Q Predictions Max            2290.8777
Q Predictions Min            16.936249
V Predictions Mean           1049.5864
V Predictions Std            917.44336
V Predictions Max            2298.2056
V Predictions Min            27.116558
Log Pis Mean                 -5.6648307
Log Pis Std                  6.364714
Log Pis Max                  20.54581
Log Pis Min                  -12.810797
Policy mu Mean               0.14435956
Policy mu Std                0.69428116
Policy mu Max                3.2942863
Policy mu Min                -2.666583
Policy log std Mean          -0.28609982
Policy log std Std           0.17004724
Policy log std Max           -0.01697088
Policy log std Min           -1.0443076
Z mean eval                  0.021057326
Z variance eval              0.093162715
total_rewards                [ 923.25690975 1143.51567745  960.47077703 2495.8450288  5094.6771123
 1833.92729971 4614.85457342 5145.8084114  3614.76035508 2664.61758685]
total_rewards_mean           2849.17337317743
total_rewards_std            1593.6065797935573
total_rewards_max            5145.808411395096
total_rewards_min            923.256909747368
Number of train steps total  672000
Number of env steps total    842000
Number of rollouts total     0
Train Time (s)               193.07108265487477
(Previous) Eval Time (s)     14.4018510770984
Sample Time (s)              18.37664847774431
Epoch Time (s)               225.84958220971748
Total Train Time (s)         36203.60574173508
Epoch                        167
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:33:42.537846 UTC | [2020_01_13_04_30_18] Iteration #167 | Epoch Duration: 227.09915494918823
2020-01-13 14:33:42.538196 UTC | [2020_01_13_04_30_18] Iteration #167 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02098542
Z variance train             0.0932108
KL Divergence                3.7548351
KL Loss                      0.3754835
QF Loss                      1325.914
VF Loss                      351.73688
Policy Loss                  -986.5235
Q Predictions Mean           982.0105
Q Predictions Std            921.77747
Q Predictions Max            2305.3745
Q Predictions Min            16.168633
V Predictions Mean           991.42365
V Predictions Std            918.7449
V Predictions Max            2308.132
V Predictions Min            27.509018
Log Pis Mean                 -6.0215263
Log Pis Std                  6.050055
Log Pis Max                  14.315058
Log Pis Min                  -14.055737
Policy mu Mean               0.13020775
Policy mu Std                0.6665852
Policy mu Max                2.754424
Policy mu Min                -2.748819
Policy log std Mean          -0.27428746
Policy log std Std           0.15621813
Policy log std Max           -0.078083135
Policy log std Min           -0.9611611
Z mean eval                  0.01576159
Z variance eval              0.08580558
total_rewards                [1751.31568886  976.48886154 1240.58719675 3084.58448303 2334.92111799
 1244.45942569 1001.44253429 5119.64445715  726.07765359 5097.284764  ]
total_rewards_mean           2257.680618289137
total_rewards_std            1575.6528981142915
total_rewards_max            5119.6444571529655
total_rewards_min            726.07765359346
Number of train steps total  676000
Number of env steps total    847000
Number of rollouts total     0
Train Time (s)               194.91836244799197
(Previous) Eval Time (s)     15.651127432007343
Sample Time (s)              16.633057828061283
Epoch Time (s)               227.2025477080606
Total Train Time (s)         36427.34378368175
Epoch                        168
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:37:26.275517 UTC | [2020_01_13_04_30_18] Iteration #168 | Epoch Duration: 223.73711228370667
2020-01-13 14:37:26.275650 UTC | [2020_01_13_04_30_18] Iteration #168 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015272346
Z variance train             0.08588548
KL Divergence                4.013968
KL Loss                      0.4013968
QF Loss                      1386.1526
VF Loss                      463.56604
Policy Loss                  -1077.4751
Q Predictions Mean           1071.0957
Q Predictions Std            919.29926
Q Predictions Max            2300.0913
Q Predictions Min            13.011816
V Predictions Mean           1081.5846
V Predictions Std            917.82697
V Predictions Max            2301.6204
V Predictions Min            30.179396
Log Pis Mean                 -4.852502
Log Pis Std                  6.7412925
Log Pis Max                  21.994339
Log Pis Min                  -13.112664
Policy mu Mean               0.14155357
Policy mu Std                0.7055009
Policy mu Max                2.6909142
Policy mu Min                -2.773641
Policy log std Mean          -0.30349845
Policy log std Std           0.17814411
Policy log std Max           -0.028337218
Policy log std Min           -1.085679
Z mean eval                  0.016642734
Z variance eval              0.08362661
total_rewards                [2717.40187603  632.30104517 1340.43090018 1244.26290176 1654.99096254
 1758.01956204 2093.72494552 1559.78133821 1449.08610792 1898.37192914]
total_rewards_mean           1634.8371568510138
total_rewards_std            524.5944916661556
total_rewards_max            2717.401876033122
total_rewards_min            632.3010451701739
Number of train steps total  680000
Number of env steps total    852000
Number of rollouts total     0
Train Time (s)               197.5558169777505
(Previous) Eval Time (s)     12.185396390967071
Sample Time (s)              18.65828887326643
Epoch Time (s)               228.399502241984
Total Train Time (s)         36652.16688936995
Epoch                        169
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:41:11.100602 UTC | [2020_01_13_04_30_18] Iteration #169 | Epoch Duration: 224.82485938072205
2020-01-13 14:41:11.100718 UTC | [2020_01_13_04_30_18] Iteration #169 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016150285
Z variance train             0.083624125
KL Divergence                4.0749245
KL Loss                      0.40749246
QF Loss                      1674.8617
VF Loss                      583.77466
Policy Loss                  -1125.5392
Q Predictions Mean           1117.1196
Q Predictions Std            931.9366
Q Predictions Max            2299.6885
Q Predictions Min            16.084553
V Predictions Mean           1135.1199
V Predictions Std            937.10834
V Predictions Max            2312.2844
V Predictions Min            26.296085
Log Pis Mean                 -5.1440043
Log Pis Std                  6.4023147
Log Pis Max                  14.94047
Log Pis Min                  -15.3737
Policy mu Mean               0.147323
Policy mu Std                0.70175326
Policy mu Max                2.410367
Policy mu Min                -2.6303072
Policy log std Mean          -0.2985252
Policy log std Std           0.17198543
Policy log std Max           0.03979285
Policy log std Min           -1.2308683
Z mean eval                  0.017030109
Z variance eval              0.080484584
total_rewards                [5236.54583495 5144.66159162 2041.17601014 1750.54984965 1166.81280362
 3185.18696363 3619.18215314 1050.89440745 1237.21034676 2865.6258089 ]
total_rewards_mean           2729.784576985977
total_rewards_std            1485.0847932273437
total_rewards_max            5236.545834946706
total_rewards_min            1050.894407446066
Number of train steps total  684000
Number of env steps total    857000
Number of rollouts total     0
Train Time (s)               194.77848885208368
(Previous) Eval Time (s)     8.610489523038268
Sample Time (s)              18.23622317565605
Epoch Time (s)               221.625201550778
Total Train Time (s)         36879.404240882024
Epoch                        170
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:44:58.339206 UTC | [2020_01_13_04_30_18] Iteration #170 | Epoch Duration: 227.23840141296387
2020-01-13 14:44:58.339327 UTC | [2020_01_13_04_30_18] Iteration #170 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017399672
Z variance train             0.0805476
KL Divergence                4.1287622
KL Loss                      0.41287622
QF Loss                      1394.1211
VF Loss                      494.92798
Policy Loss                  -1110.9619
Q Predictions Mean           1103.175
Q Predictions Std            918.84106
Q Predictions Max            2299.45
Q Predictions Min            21.44822
V Predictions Mean           1109.5397
V Predictions Std            915.738
V Predictions Max            2307.0667
V Predictions Min            29.355047
Log Pis Mean                 -4.8433943
Log Pis Std                  7.2345533
Log Pis Max                  26.218655
Log Pis Min                  -17.247322
Policy mu Mean               0.16853346
Policy mu Std                0.72627735
Policy mu Max                3.1939347
Policy mu Min                -2.7222369
Policy log std Mean          -0.29863524
Policy log std Std           0.17292333
Policy log std Max           -0.0587703
Policy log std Min           -1.0394181
Z mean eval                  0.018785488
Z variance eval              0.08364059
total_rewards                [2718.97892908 2549.38879843 1640.00419489 1832.45283574 4268.62929578
  697.57893261 1284.51505889  913.58075048  731.41900081 1850.53839087]
total_rewards_mean           1848.7086187578327
total_rewards_std            1044.71902888476
total_rewards_max            4268.629295784549
total_rewards_min            697.5789326139601
Number of train steps total  688000
Number of env steps total    862000
Number of rollouts total     0
Train Time (s)               197.42148123309016
(Previous) Eval Time (s)     14.223416620865464
Sample Time (s)              18.174606043845415
Epoch Time (s)               229.81950389780104
Total Train Time (s)         37103.792473969515
Epoch                        171
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:48:42.729833 UTC | [2020_01_13_04_30_18] Iteration #171 | Epoch Duration: 224.3904092311859
2020-01-13 14:48:42.729981 UTC | [2020_01_13_04_30_18] Iteration #171 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019011509
Z variance train             0.08365743
KL Divergence                4.1189
KL Loss                      0.41189
QF Loss                      1406.0752
VF Loss                      529.225
Policy Loss                  -1020.7493
Q Predictions Mean           1011.89795
Q Predictions Std            960.94403
Q Predictions Max            2336.2725
Q Predictions Min            18.22195
V Predictions Mean           1012.1765
V Predictions Std            951.2299
V Predictions Max            2318.1592
V Predictions Min            29.33417
Log Pis Mean                 -5.571124
Log Pis Std                  6.630822
Log Pis Max                  18.92531
Log Pis Min                  -13.119747
Policy mu Mean               0.12892236
Policy mu Std                0.6669104
Policy mu Max                2.4060063
Policy mu Min                -2.904426
Policy log std Mean          -0.27649295
Policy log std Std           0.16482382
Policy log std Max           0.1053811
Policy log std Min           -0.9918752
Z mean eval                  0.016843129
Z variance eval              0.076896966
total_rewards                [1679.51517645  799.24264881 4303.0015081  2270.19636411 1085.24524721
  486.30376906  801.96552236 5243.45781092 4046.16590713 4935.80079332]
total_rewards_mean           2565.089474746575
total_rewards_std            1778.121721117888
total_rewards_max            5243.457810918704
total_rewards_min            486.30376905537105
Number of train steps total  692000
Number of env steps total    867000
Number of rollouts total     0
Train Time (s)               194.4688148717396
(Previous) Eval Time (s)     8.794045960064977
Sample Time (s)              17.486935871187598
Epoch Time (s)               220.74979670299217
Total Train Time (s)         37329.0046034432
Epoch                        172
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:52:27.944371 UTC | [2020_01_13_04_30_18] Iteration #172 | Epoch Duration: 225.21426558494568
2020-01-13 14:52:27.944549 UTC | [2020_01_13_04_30_18] Iteration #172 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016909469
Z variance train             0.07687718
KL Divergence                4.2350407
KL Loss                      0.42350408
QF Loss                      1866.8896
VF Loss                      568.0909
Policy Loss                  -1273.1792
Q Predictions Mean           1266.611
Q Predictions Std            923.05096
Q Predictions Max            2333.4788
Q Predictions Min            13.250698
V Predictions Mean           1275.5237
V Predictions Std            919.3816
V Predictions Max            2336.6008
V Predictions Min            24.17461
Log Pis Mean                 -4.662719
Log Pis Std                  6.3310213
Log Pis Max                  25.120325
Log Pis Min                  -13.318414
Policy mu Mean               0.20829228
Policy mu Std                0.7271019
Policy mu Max                3.4126523
Policy mu Min                -2.8065593
Policy log std Mean          -0.31204534
Policy log std Std           0.16702779
Policy log std Max           0.010761201
Policy log std Min           -1.0649453
Z mean eval                  0.023973614
Z variance eval              0.08117144
total_rewards                [4571.78341181 2703.78290257  748.04294719 2111.4233775  5119.54476834
 3854.4808625  1191.45632962 5195.33546154 4750.73387706 2030.96589632]
total_rewards_mean           3227.7549834452657
total_rewards_std            1587.9998453252047
total_rewards_max            5195.335461542928
total_rewards_min            748.0429471865642
Number of train steps total  696000
Number of env steps total    872000
Number of rollouts total     0
Train Time (s)               196.11891787918285
(Previous) Eval Time (s)     13.258249159902334
Sample Time (s)              16.395418306812644
Epoch Time (s)               225.77258534589782
Total Train Time (s)         37558.04974643933
Epoch                        173
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 14:56:16.991690 UTC | [2020_01_13_04_30_18] Iteration #173 | Epoch Duration: 229.0470085144043
2020-01-13 14:56:16.991894 UTC | [2020_01_13_04_30_18] Iteration #173 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023209361
Z variance train             0.081187494
KL Divergence                4.04183
KL Loss                      0.404183
QF Loss                      1838.5657
VF Loss                      586.8071
Policy Loss                  -1012.5082
Q Predictions Mean           1003.6346
Q Predictions Std            911.6398
Q Predictions Max            2325.5972
Q Predictions Min            17.274628
V Predictions Mean           1023.60266
V Predictions Std            915.8721
V Predictions Max            2354.8904
V Predictions Min            29.207298
Log Pis Mean                 -5.6807003
Log Pis Std                  6.5215406
Log Pis Max                  23.209095
Log Pis Min                  -15.376697
Policy mu Mean               0.11892556
Policy mu Std                0.694093
Policy mu Max                2.8303292
Policy mu Min                -2.7923677
Policy log std Mean          -0.2840705
Policy log std Std           0.16920881
Policy log std Max           -0.039479934
Policy log std Min           -1.1444567
Z mean eval                  0.027225384
Z variance eval              0.075500816
total_rewards                [5269.59013326 4269.89223026 1595.9681947  1466.51182363 2512.94794147
 3406.3309672  1788.52347487 4636.93218731 2813.20290838  913.46123479]
total_rewards_mean           2867.3361095843093
total_rewards_std            1408.85215548763
total_rewards_max            5269.590133257104
total_rewards_min            913.4612347865906
Number of train steps total  700000
Number of env steps total    877000
Number of rollouts total     0
Train Time (s)               193.8331961100921
(Previous) Eval Time (s)     16.532394194975495
Sample Time (s)              18.59306744718924
Epoch Time (s)               228.95865775225684
Total Train Time (s)         37785.375622374006
Epoch                        174
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:00:04.318638 UTC | [2020_01_13_04_30_18] Iteration #174 | Epoch Duration: 227.32660818099976
2020-01-13 15:00:04.318754 UTC | [2020_01_13_04_30_18] Iteration #174 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027088825
Z variance train             0.07551418
KL Divergence                4.2604523
KL Loss                      0.42604524
QF Loss                      1367.49
VF Loss                      445.20853
Policy Loss                  -1068.1686
Q Predictions Mean           1059.177
Q Predictions Std            919.3508
Q Predictions Max            2321.7556
Q Predictions Min            15.825832
V Predictions Mean           1072.6119
V Predictions Std            920.4684
V Predictions Max            2347.794
V Predictions Min            30.056458
Log Pis Mean                 -5.461669
Log Pis Std                  6.5000997
Log Pis Max                  16.81253
Log Pis Min                  -15.983089
Policy mu Mean               0.17008108
Policy mu Std                0.6998947
Policy mu Max                3.4495873
Policy mu Min                -2.9792686
Policy log std Mean          -0.28493196
Policy log std Std           0.16557628
Policy log std Max           -0.052531242
Policy log std Min           -1.0814681
Z mean eval                  0.022856776
Z variance eval              0.07599426
total_rewards                [1800.97173942 1520.29277393 3777.9646307  1747.09153541 4085.48044151
 5071.18493283 1102.44489664 3249.05624188 3330.59674415 3416.35902764]
total_rewards_mean           2910.144296411319
total_rewards_std            1230.2413828618596
total_rewards_max            5071.184932828794
total_rewards_min            1102.4448966365394
Number of train steps total  704000
Number of env steps total    882000
Number of rollouts total     0
Train Time (s)               197.206043981947
(Previous) Eval Time (s)     14.900103522930294
Sample Time (s)              18.0244757886976
Epoch Time (s)               230.1306232935749
Total Train Time (s)         38016.489947378635
Epoch                        175
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:03:55.435953 UTC | [2020_01_13_04_30_18] Iteration #175 | Epoch Duration: 231.117094039917
2020-01-13 15:03:55.436153 UTC | [2020_01_13_04_30_18] Iteration #175 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022638027
Z variance train             0.07600518
KL Divergence                4.1628876
KL Loss                      0.41628876
QF Loss                      1574.0349
VF Loss                      470.5458
Policy Loss                  -1101.8502
Q Predictions Mean           1093.5378
Q Predictions Std            932.9025
Q Predictions Max            2336.895
Q Predictions Min            14.731103
V Predictions Mean           1104.6409
V Predictions Std            933.43835
V Predictions Max            2360.1094
V Predictions Min            29.18039
Log Pis Mean                 -5.1508656
Log Pis Std                  6.944829
Log Pis Max                  24.144005
Log Pis Min                  -16.180408
Policy mu Mean               0.14225361
Policy mu Std                0.71200365
Policy mu Max                2.8634222
Policy mu Min                -3.2835517
Policy log std Mean          -0.2992957
Policy log std Std           0.1744796
Policy log std Max           0.0074845254
Policy log std Min           -1.127515
Z mean eval                  0.024438346
Z variance eval              0.070356615
total_rewards                [2807.86298361  978.61605704 4884.00312859 3997.47287449 2367.58440721
 4266.72475014 1174.72989486 4820.39217823 1823.34280779 4589.7511668 ]
total_rewards_mean           3171.0480248748563
total_rewards_std            1446.947337255436
total_rewards_max            4884.003128588745
total_rewards_min            978.6160570395581
Number of train steps total  708000
Number of env steps total    887000
Number of rollouts total     0
Train Time (s)               193.0134503832087
(Previous) Eval Time (s)     15.886294225230813
Sample Time (s)              16.63384090177715
Epoch Time (s)               225.53358551021665
Total Train Time (s)         38241.89216586389
Epoch                        176
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:07:40.841960 UTC | [2020_01_13_04_30_18] Iteration #176 | Epoch Duration: 225.40567135810852
2020-01-13 15:07:40.842135 UTC | [2020_01_13_04_30_18] Iteration #176 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024031848
Z variance train             0.07040599
KL Divergence                4.343211
KL Loss                      0.43432114
QF Loss                      1592.0132
VF Loss                      336.88306
Policy Loss                  -1128.6095
Q Predictions Mean           1121.708
Q Predictions Std            939.3234
Q Predictions Max            2346.0222
Q Predictions Min            17.615852
V Predictions Mean           1129.8208
V Predictions Std            938.83044
V Predictions Max            2346.688
V Predictions Min            26.346083
Log Pis Mean                 -4.970605
Log Pis Std                  6.6088834
Log Pis Max                  18.695719
Log Pis Min                  -13.162419
Policy mu Mean               0.17801242
Policy mu Std                0.71390206
Policy mu Max                3.0652652
Policy mu Min                -2.2995808
Policy log std Mean          -0.29362223
Policy log std Std           0.16314246
Policy log std Max           -0.03272894
Policy log std Min           -1.0972501
Z mean eval                  0.028389966
Z variance eval              0.07109733
total_rewards                [2256.54816301 1494.60545584 1063.00492561 3671.47071847  999.82724574
 5255.88526548 2281.71726122 1906.53911929 4416.74377409 3824.95617989]
total_rewards_mean           2717.129810863583
total_rewards_std            1403.9448906925015
total_rewards_max            5255.885265482941
total_rewards_min            999.8272457428014
Number of train steps total  712000
Number of env steps total    892000
Number of rollouts total     0
Train Time (s)               194.16986527387053
(Previous) Eval Time (s)     15.758119013160467
Sample Time (s)              18.838168277405202
Epoch Time (s)               228.7661525644362
Total Train Time (s)         38469.6012566532
Epoch                        177
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:11:28.553124 UTC | [2020_01_13_04_30_18] Iteration #177 | Epoch Duration: 227.71086859703064
2020-01-13 15:11:28.553257 UTC | [2020_01_13_04_30_18] Iteration #177 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02799431
Z variance train             0.07105891
KL Divergence                4.297389
KL Loss                      0.4297389
QF Loss                      1534.737
VF Loss                      682.5541
Policy Loss                  -1227.2854
Q Predictions Mean           1222.9594
Q Predictions Std            923.23956
Q Predictions Max            2346.575
Q Predictions Min            18.790176
V Predictions Mean           1238.2839
V Predictions Std            926.06366
V Predictions Max            2357.5503
V Predictions Min            29.128248
Log Pis Mean                 -4.5044594
Log Pis Std                  6.5774155
Log Pis Max                  21.677914
Log Pis Min                  -13.17131
Policy mu Mean               0.16121638
Policy mu Std                0.7303092
Policy mu Max                2.7191365
Policy mu Min                -3.1920178
Policy log std Mean          -0.30917612
Policy log std Std           0.17061071
Policy log std Max           -0.023075238
Policy log std Min           -1.0679641
Z mean eval                  0.02470089
Z variance eval              0.07252486
total_rewards                [2793.69411147 5151.47934225 1012.21205785 5104.78641422 4105.59237869
 5080.49612571 5188.86579162 4865.74099925 2490.11357364 5161.7523152 ]
total_rewards_mean           4095.4733109904155
total_rewards_std            1407.4200967820796
total_rewards_max            5188.865791615115
total_rewards_min            1012.212057850933
Number of train steps total  716000
Number of env steps total    897000
Number of rollouts total     0
Train Time (s)               195.9204948861152
(Previous) Eval Time (s)     14.702552706003189
Sample Time (s)              16.48221416492015
Epoch Time (s)               227.10526175703853
Total Train Time (s)         38703.33350016689
Epoch                        178
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:15:22.287892 UTC | [2020_01_13_04_30_18] Iteration #178 | Epoch Duration: 233.73453426361084
2020-01-13 15:15:22.288076 UTC | [2020_01_13_04_30_18] Iteration #178 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025345337
Z variance train             0.07253344
KL Divergence                4.2713337
KL Loss                      0.42713338
QF Loss                      1114.1978
VF Loss                      567.72156
Policy Loss                  -996.8124
Q Predictions Mean           988.78015
Q Predictions Std            945.8308
Q Predictions Max            2344.9844
Q Predictions Min            19.734516
V Predictions Mean           985.6776
V Predictions Std            936.2389
V Predictions Max            2341.6042
V Predictions Min            30.369854
Log Pis Mean                 -5.35386
Log Pis Std                  7.4481387
Log Pis Max                  25.748356
Log Pis Min                  -12.862422
Policy mu Mean               0.111468375
Policy mu Std                0.69365656
Policy mu Max                2.6602511
Policy mu Min                -3.194784
Policy log std Mean          -0.27509406
Policy log std Std           0.16517907
Policy log std Max           0.049962163
Policy log std Min           -0.9574105
Z mean eval                  0.02723893
Z variance eval              0.07506462
total_rewards                [5200.31168252  950.21488555 5190.71178205 1343.20176857 1659.84045879
 5152.92306208 2158.66516098 1122.25726504 2484.72007879 5036.61441754]
total_rewards_mean           3029.9460561926608
total_rewards_std            1779.2245621249028
total_rewards_max            5200.311682521704
total_rewards_min            950.2148855528459
Number of train steps total  720000
Number of env steps total    902000
Number of rollouts total     0
Train Time (s)               193.97060112003237
(Previous) Eval Time (s)     21.33156350813806
Sample Time (s)              18.925594535656273
Epoch Time (s)               234.2277591638267
Total Train Time (s)         38932.31035237247
Epoch                        179
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:19:11.266083 UTC | [2020_01_13_04_30_18] Iteration #179 | Epoch Duration: 228.97789001464844
2020-01-13 15:19:11.266209 UTC | [2020_01_13_04_30_18] Iteration #179 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026425386
Z variance train             0.07509587
KL Divergence                4.1889186
KL Loss                      0.41889188
QF Loss                      1463.9758
VF Loss                      466.02356
Policy Loss                  -1246.4775
Q Predictions Mean           1244.4275
Q Predictions Std            961.5311
Q Predictions Max            2353.766
Q Predictions Min            18.925573
V Predictions Mean           1252.0684
V Predictions Std            960.073
V Predictions Max            2380.0542
V Predictions Min            27.385263
Log Pis Mean                 -4.690834
Log Pis Std                  7.098873
Log Pis Max                  25.676258
Log Pis Min                  -15.708666
Policy mu Mean               0.13112184
Policy mu Std                0.7414806
Policy mu Max                3.2188964
Policy mu Min                -4.1966896
Policy log std Mean          -0.3042768
Policy log std Std           0.17320347
Policy log std Max           -0.05957564
Policy log std Min           -1.0751076
Z mean eval                  0.02515396
Z variance eval              0.058982283
total_rewards                [1556.63263817 4530.49400568 2544.66242468 1265.50374528 1385.08449703
 1014.1811053  1918.28665179 4089.97046317 1979.70743995 3026.91581233]
total_rewards_mean           2331.143878337789
total_rewards_std            1145.3879344805184
total_rewards_max            4530.494005683534
total_rewards_min            1014.1811052983376
Number of train steps total  724000
Number of env steps total    907000
Number of rollouts total     0
Train Time (s)               190.99489309964702
(Previous) Eval Time (s)     16.081424683798105
Sample Time (s)              18.4905754821375
Epoch Time (s)               225.56689326558262
Total Train Time (s)         39153.07539263414
Epoch                        180
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:22:52.035174 UTC | [2020_01_13_04_30_18] Iteration #180 | Epoch Duration: 220.76884865760803
2020-01-13 15:22:52.035443 UTC | [2020_01_13_04_30_18] Iteration #180 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024867384
Z variance train             0.058944166
KL Divergence                4.771745
KL Loss                      0.47717452
QF Loss                      1023.7854
VF Loss                      339.49387
Policy Loss                  -1194.0669
Q Predictions Mean           1187.232
Q Predictions Std            953.56323
Q Predictions Max            2366.6975
Q Predictions Min            11.61276
V Predictions Mean           1198.0989
V Predictions Std            953.80237
V Predictions Max            2362.7144
V Predictions Min            23.97018
Log Pis Mean                 -5.23082
Log Pis Std                  6.1277056
Log Pis Max                  16.143564
Log Pis Min                  -16.26373
Policy mu Mean               0.17390664
Policy mu Std                0.7029635
Policy mu Max                2.8719842
Policy mu Min                -2.5956624
Policy log std Mean          -0.30121347
Policy log std Std           0.16925602
Policy log std Max           -0.020729914
Policy log std Min           -1.0018573
Z mean eval                  0.020102207
Z variance eval              0.052860804
total_rewards                [1321.81651932 2087.80353362 5171.24830472 3516.36586459 5185.52277806
 2445.30374514 3828.11593328 1359.11287044 5139.23104983 2656.25824485]
total_rewards_mean           3271.077884383055
total_rewards_std            1450.9126472400985
total_rewards_max            5185.522778057973
total_rewards_min            1321.8165193197742
Number of train steps total  728000
Number of env steps total    912000
Number of rollouts total     0
Train Time (s)               190.09488770086318
(Previous) Eval Time (s)     11.283064126037061
Sample Time (s)              19.266255131922662
Epoch Time (s)               220.6442069588229
Total Train Time (s)         39377.95177929429
Epoch                        181
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:26:36.917137 UTC | [2020_01_13_04_30_18] Iteration #181 | Epoch Duration: 224.88150119781494
2020-01-13 15:26:36.918206 UTC | [2020_01_13_04_30_18] Iteration #181 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020897333
Z variance train             0.05287627
KL Divergence                5.0298843
KL Loss                      0.50298846
QF Loss                      1437.5847
VF Loss                      698.6739
Policy Loss                  -1217.7427
Q Predictions Mean           1206.5212
Q Predictions Std            954.66205
Q Predictions Max            2358.634
Q Predictions Min            20.133373
V Predictions Mean           1208.3013
V Predictions Std            947.8447
V Predictions Max            2344.1765
V Predictions Min            30.512531
Log Pis Mean                 -4.635378
Log Pis Std                  6.8619823
Log Pis Max                  16.81836
Log Pis Min                  -13.220434
Policy mu Mean               0.15535015
Policy mu Std                0.7303762
Policy mu Max                2.850069
Policy mu Min                -3.2814748
Policy log std Mean          -0.3079764
Policy log std Std           0.16858491
Policy log std Max           0.028892115
Policy log std Min           -1.0251641
Z mean eval                  0.026569217
Z variance eval              0.06311394
total_rewards                [3738.94381247 5124.01346659  855.6633234  1721.81801926 2665.39327467
 5240.86382639 1705.42365998 2861.23872867 2393.7517114  2750.20929659]
total_rewards_mean           2905.7319119430713
total_rewards_std            1358.6420691647913
total_rewards_max            5240.863826393257
total_rewards_min            855.6633234049909
Number of train steps total  732000
Number of env steps total    917000
Number of rollouts total     0
Train Time (s)               196.1402267292142
(Previous) Eval Time (s)     15.519993999041617
Sample Time (s)              18.83907243795693
Epoch Time (s)               230.49929316621274
Total Train Time (s)         39606.54480343405
Epoch                        182
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:30:25.513178 UTC | [2020_01_13_04_30_18] Iteration #182 | Epoch Duration: 228.59468960762024
2020-01-13 15:30:25.513348 UTC | [2020_01_13_04_30_18] Iteration #182 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02707531
Z variance train             0.06312749
KL Divergence                4.632343
KL Loss                      0.46323428
QF Loss                      1847.6802
VF Loss                      753.9915
Policy Loss                  -1227.0118
Q Predictions Mean           1220.1008
Q Predictions Std            938.4571
Q Predictions Max            2378.6792
Q Predictions Min            21.223637
V Predictions Mean           1223.8777
V Predictions Std            935.6748
V Predictions Max            2389.4216
V Predictions Min            29.121204
Log Pis Mean                 -4.501786
Log Pis Std                  7.424576
Log Pis Max                  32.591328
Log Pis Min                  -14.843264
Policy mu Mean               0.1408727
Policy mu Std                0.74455917
Policy mu Max                3.1744676
Policy mu Min                -3.4612854
Policy log std Mean          -0.31383952
Policy log std Std           0.17653266
Policy log std Max           -0.057508104
Policy log std Min           -1.2191269
Z mean eval                  0.03411121
Z variance eval              0.06430001
total_rewards                [3646.22121525 5148.04450348 5272.10131324  777.20176425 1782.33849891
 5225.7267575  3211.56992827 2600.83713587 3493.35858427 5124.13218255]
total_rewards_mean           3628.1531883600574
total_rewards_std            1502.837360479054
total_rewards_max            5272.101313242486
total_rewards_min            777.2017642517586
Number of train steps total  736000
Number of env steps total    922000
Number of rollouts total     0
Train Time (s)               190.97664402984083
(Previous) Eval Time (s)     13.615136853884906
Sample Time (s)              18.141935898922384
Epoch Time (s)               222.73371678264812
Total Train Time (s)         39834.523943223525
Epoch                        183
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:34:13.493873 UTC | [2020_01_13_04_30_18] Iteration #183 | Epoch Duration: 227.9804127216339
2020-01-13 15:34:13.493995 UTC | [2020_01_13_04_30_18] Iteration #183 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033893764
Z variance train             0.06428268
KL Divergence                4.558486
KL Loss                      0.4558486
QF Loss                      1117.5237
VF Loss                      438.52554
Policy Loss                  -1088.9574
Q Predictions Mean           1084.9675
Q Predictions Std            964.9519
Q Predictions Max            2374.4714
Q Predictions Min            17.289062
V Predictions Mean           1094.3396
V Predictions Std            963.85547
V Predictions Max            2373.201
V Predictions Min            31.333893
Log Pis Mean                 -5.2239666
Log Pis Std                  6.8849616
Log Pis Max                  23.993374
Log Pis Min                  -12.742226
Policy mu Mean               0.12742077
Policy mu Std                0.703712
Policy mu Max                2.9900022
Policy mu Min                -3.2636611
Policy log std Mean          -0.2906496
Policy log std Std           0.17317596
Policy log std Max           -0.014216945
Policy log std Min           -1.1080309
Z mean eval                  0.017080605
Z variance eval              0.07501756
total_rewards                [3053.2103914  2131.76535014 3964.33485506 5164.14367648 5239.73592872
 1904.77587846 4529.54002393 2814.75550547 4211.85158813 5295.00368311]
total_rewards_mean           3830.9116880887414
total_rewards_std            1216.1968292811182
total_rewards_max            5295.003683106568
total_rewards_min            1904.7758784622536
Number of train steps total  740000
Number of env steps total    927000
Number of rollouts total     0
Train Time (s)               196.07588153705
(Previous) Eval Time (s)     18.861557451076806
Sample Time (s)              18.396958069875836
Epoch Time (s)               233.33439705800265
Total Train Time (s)         40068.79141938267
Epoch                        184
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:38:07.767119 UTC | [2020_01_13_04_30_18] Iteration #184 | Epoch Duration: 234.2729775905609
2020-01-13 15:38:07.767426 UTC | [2020_01_13_04_30_18] Iteration #184 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01719824
Z variance train             0.07501256
KL Divergence                4.3059444
KL Loss                      0.43059444
QF Loss                      1868.1279
VF Loss                      408.46283
Policy Loss                  -1257.0267
Q Predictions Mean           1250.261
Q Predictions Std            970.13635
Q Predictions Max            2389.5728
Q Predictions Min            19.673412
V Predictions Mean           1254.4203
V Predictions Std            963.8332
V Predictions Max            2382.8079
V Predictions Min            20.971836
Log Pis Mean                 -4.7637234
Log Pis Std                  6.6065307
Log Pis Max                  23.963837
Log Pis Min                  -12.871728
Policy mu Mean               0.19083783
Policy mu Std                0.73189265
Policy mu Max                3.4838486
Policy mu Min                -3.3730938
Policy log std Mean          -0.30920434
Policy log std Std           0.16835007
Policy log std Max           0.037094593
Policy log std Min           -0.9967907
Z mean eval                  0.022842642
Z variance eval              0.08100923
total_rewards                [4009.0896913  3728.45866958 2911.52706477 2219.54665808 2843.71196023
 1160.29500102 3863.10576405 3790.22279946 1134.30187602 5237.55785763]
total_rewards_mean           3089.781734213699
total_rewards_std            1238.9947555585456
total_rewards_max            5237.557857629293
total_rewards_min            1134.3018760223092
Number of train steps total  744000
Number of env steps total    932000
Number of rollouts total     0
Train Time (s)               196.86525024287403
(Previous) Eval Time (s)     19.799797507934272
Sample Time (s)              18.541397321037948
Epoch Time (s)               235.20644507184625
Total Train Time (s)         40300.363501170184
Epoch                        185
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:41:59.338988 UTC | [2020_01_13_04_30_18] Iteration #185 | Epoch Duration: 231.5713438987732
2020-01-13 15:41:59.339111 UTC | [2020_01_13_04_30_18] Iteration #185 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023268307
Z variance train             0.08100993
KL Divergence                4.152142
KL Loss                      0.4152142
QF Loss                      1565.3286
VF Loss                      590.61896
Policy Loss                  -1094.1952
Q Predictions Mean           1077.6443
Q Predictions Std            947.3409
Q Predictions Max            2360.7383
Q Predictions Min            12.384217
V Predictions Mean           1083.2412
V Predictions Std            942.90656
V Predictions Max            2362.37
V Predictions Min            30.058193
Log Pis Mean                 -5.3103952
Log Pis Std                  6.8986664
Log Pis Max                  22.085087
Log Pis Min                  -14.500658
Policy mu Mean               0.1988245
Policy mu Std                0.6918255
Policy mu Max                3.2105827
Policy mu Min                -2.6196904
Policy log std Mean          -0.28614017
Policy log std Std           0.16821201
Policy log std Max           -0.028852925
Policy log std Min           -0.9703765
Z mean eval                  0.030446026
Z variance eval              0.086871505
total_rewards                [ 981.87311914  974.19037658 2925.75523516 3957.55382104 5125.36505703
 4534.26105999 5064.00876006 5170.57318066 1703.42184607 5162.78950051]
total_rewards_mean           3559.97919562255
total_rewards_std            1678.2378377455962
total_rewards_max            5170.573180663324
total_rewards_min            974.1903765760119
Number of train steps total  748000
Number of env steps total    937000
Number of rollouts total     0
Train Time (s)               194.9012074531056
(Previous) Eval Time (s)     16.164462821092457
Sample Time (s)              18.806941070593894
Epoch Time (s)               229.87261134479195
Total Train Time (s)         40530.96476668026
Epoch                        186
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:45:49.951475 UTC | [2020_01_13_04_30_18] Iteration #186 | Epoch Duration: 230.61223816871643
2020-01-13 15:45:49.951732 UTC | [2020_01_13_04_30_18] Iteration #186 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029405225
Z variance train             0.0868476
KL Divergence                4.1191053
KL Loss                      0.41191053
QF Loss                      2212.5757
VF Loss                      569.33185
Policy Loss                  -1141.6256
Q Predictions Mean           1137.5889
Q Predictions Std            962.5812
Q Predictions Max            2377.3218
Q Predictions Min            18.16702
V Predictions Mean           1146.4761
V Predictions Std            959.54767
V Predictions Max            2380.8145
V Predictions Min            29.159035
Log Pis Mean                 -5.073159
Log Pis Std                  6.9908104
Log Pis Max                  25.759094
Log Pis Min                  -13.948118
Policy mu Mean               0.13423197
Policy mu Std                0.713603
Policy mu Max                3.1498609
Policy mu Min                -3.3694701
Policy log std Mean          -0.30121288
Policy log std Std           0.1750216
Policy log std Max           0.037844077
Policy log std Min           -1.1483463
Z mean eval                  0.029432705
Z variance eval              0.08471088
total_rewards                [ 635.04469338 3489.79286457 1992.92134384 4353.48963134 5173.82921707
 5199.46648048 5191.19572644 3110.17682102 5184.49414642 3066.95980447]
total_rewards_mean           3739.7370729030617
total_rewards_std            1495.3295650935045
total_rewards_max            5199.466480482149
total_rewards_min            635.0446933778139
Number of train steps total  752000
Number of env steps total    942000
Number of rollouts total     0
Train Time (s)               194.16176271811128
(Previous) Eval Time (s)     16.903798442799598
Sample Time (s)              17.394682350568473
Epoch Time (s)               228.46024351147935
Total Train Time (s)         40762.04245899245
Epoch                        187
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:49:41.029918 UTC | [2020_01_13_04_30_18] Iteration #187 | Epoch Duration: 231.07801485061646
2020-01-13 15:49:41.030041 UTC | [2020_01_13_04_30_18] Iteration #187 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029923081
Z variance train             0.08478846
KL Divergence                4.3136797
KL Loss                      0.43136796
QF Loss                      1990.5277
VF Loss                      567.10736
Policy Loss                  -1163.1891
Q Predictions Mean           1157.3611
Q Predictions Std            955.21545
Q Predictions Max            2400.2644
Q Predictions Min            17.45796
V Predictions Mean           1155.2289
V Predictions Std            946.22064
V Predictions Max            2390.0312
V Predictions Min            29.277676
Log Pis Mean                 -5.1028976
Log Pis Std                  6.5374165
Log Pis Max                  16.440874
Log Pis Min                  -13.872522
Policy mu Mean               0.15496673
Policy mu Std                0.71159697
Policy mu Max                3.308444
Policy mu Min                -2.5391839
Policy log std Mean          -0.3064128
Policy log std Std           0.17257659
Policy log std Max           -0.039249837
Policy log std Min           -0.95915747
Z mean eval                  0.030775642
Z variance eval              0.08083175
total_rewards                [1725.47936056 5115.2339407  3487.98414351 5176.69951632 5095.50815545
 5113.07822616 1627.27598622 5275.15453527 2355.09425995 3571.3321787 ]
total_rewards_mean           3854.2840302829936
total_rewards_std            1429.5465021354464
total_rewards_max            5275.154535270687
total_rewards_min            1627.2759862152284
Number of train steps total  756000
Number of env steps total    947000
Number of rollouts total     0
Train Time (s)               192.0699797780253
(Previous) Eval Time (s)     19.5212933588773
Sample Time (s)              17.46936431573704
Epoch Time (s)               229.06063745263964
Total Train Time (s)         40990.81436826289
Epoch                        188
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:53:29.808537 UTC | [2020_01_13_04_30_18] Iteration #188 | Epoch Duration: 228.77838826179504
2020-01-13 15:53:29.808742 UTC | [2020_01_13_04_30_18] Iteration #188 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030984873
Z variance train             0.080859005
KL Divergence                4.3036675
KL Loss                      0.43036675
QF Loss                      1418.0785
VF Loss                      674.7916
Policy Loss                  -1182.8286
Q Predictions Mean           1175.1542
Q Predictions Std            948.1553
Q Predictions Max            2401.5645
Q Predictions Min            18.372696
V Predictions Mean           1175.8168
V Predictions Std            940.1566
V Predictions Max            2401.5776
V Predictions Min            24.92055
Log Pis Mean                 -4.656539
Log Pis Std                  7.1084003
Log Pis Max                  31.381145
Log Pis Min                  -13.377215
Policy mu Mean               0.11614816
Policy mu Std                0.731445
Policy mu Max                3.056431
Policy mu Min                -3.6820738
Policy log std Mean          -0.30498657
Policy log std Std           0.17844628
Policy log std Max           -0.0028791279
Policy log std Min           -1.0990994
Z mean eval                  0.02374022
Z variance eval              0.08533071
total_rewards                [2132.56302262 5318.34113227 2076.21157011 5277.61981466 5307.55841176
 3446.38889396 1386.70206561 4929.89370848 5311.31928843 5197.2422405 ]
total_rewards_mean           4038.3840148386616
total_rewards_std            1529.9364402438298
total_rewards_max            5318.341132265863
total_rewards_min            1386.7020656057769
Number of train steps total  760000
Number of env steps total    952000
Number of rollouts total     0
Train Time (s)               196.54131659772247
(Previous) Eval Time (s)     19.238766417838633
Sample Time (s)              18.710216495674103
Epoch Time (s)               234.4902995112352
Total Train Time (s)         41226.86003816174
Epoch                        189
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 15:57:25.854746 UTC | [2020_01_13_04_30_18] Iteration #189 | Epoch Duration: 236.0458791255951
2020-01-13 15:57:25.854882 UTC | [2020_01_13_04_30_18] Iteration #189 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023825284
Z variance train             0.08524816
KL Divergence                4.1829987
KL Loss                      0.41829988
QF Loss                      2352.2295
VF Loss                      705.11206
Policy Loss                  -1166.3998
Q Predictions Mean           1150.9937
Q Predictions Std            945.1576
Q Predictions Max            2396.3706
Q Predictions Min            15.929733
V Predictions Mean           1153.1792
V Predictions Std            938.78143
V Predictions Max            2377.5823
V Predictions Min            17.884916
Log Pis Mean                 -4.4240975
Log Pis Std                  7.3039527
Log Pis Max                  21.83955
Log Pis Min                  -13.946906
Policy mu Mean               0.19066063
Policy mu Std                0.7430855
Policy mu Max                3.5648582
Policy mu Min                -2.5526464
Policy log std Mean          -0.30976942
Policy log std Std           0.17591256
Policy log std Max           -0.07648672
Policy log std Min           -1.1568667
Z mean eval                  0.025194809
Z variance eval              0.07290371
total_rewards                [3623.42615607 1688.15580238  961.91090834 4897.94879993 1566.51198869
 1879.41627362 5290.57341692 1904.85082702 5247.72625818 2517.73190242]
total_rewards_mean           2957.8252333577616
total_rewards_std            1577.6360467354868
total_rewards_max            5290.573416916726
total_rewards_min            961.9109083410951
Number of train steps total  764000
Number of env steps total    957000
Number of rollouts total     0
Train Time (s)               194.55320946266875
(Previous) Eval Time (s)     20.794059136882424
Sample Time (s)              18.463901123031974
Epoch Time (s)               233.81116972258314
Total Train Time (s)         41455.40220777178
Epoch                        190
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:01:14.398544 UTC | [2020_01_13_04_30_18] Iteration #190 | Epoch Duration: 228.54357028007507
2020-01-13 16:01:14.398662 UTC | [2020_01_13_04_30_18] Iteration #190 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025130948
Z variance train             0.07286386
KL Divergence                4.3952856
KL Loss                      0.43952855
QF Loss                      1544.783
VF Loss                      294.31552
Policy Loss                  -1206.8475
Q Predictions Mean           1198.753
Q Predictions Std            990.37384
Q Predictions Max            2407.1938
Q Predictions Min            18.399035
V Predictions Mean           1202.8398
V Predictions Std            986.5493
V Predictions Max            2406.8035
V Predictions Min            30.943892
Log Pis Mean                 -5.174967
Log Pis Std                  6.6379004
Log Pis Max                  17.742004
Log Pis Min                  -14.79481
Policy mu Mean               0.17967294
Policy mu Std                0.69429445
Policy mu Max                2.631859
Policy mu Min                -2.6471949
Policy log std Mean          -0.29192442
Policy log std Std           0.16504581
Policy log std Max           -0.021889105
Policy log std Min           -0.97020626
Z mean eval                  0.03233061
Z variance eval              0.074588925
total_rewards                [1215.13223276 1376.85319316 3297.39113924 5277.21831477 1557.30514616
 3273.84799472 5283.73614082 1152.69139703  849.83376074  645.83607032]
total_rewards_mean           2392.984538972599
total_rewards_std            1684.028183016015
total_rewards_max            5283.736140818853
total_rewards_min            645.8360703227503
Number of train steps total  768000
Number of env steps total    962000
Number of rollouts total     0
Train Time (s)               192.43838351219893
(Previous) Eval Time (s)     15.526161764748394
Sample Time (s)              18.72717754682526
Epoch Time (s)               226.69172282377258
Total Train Time (s)         41678.89427900873
Epoch                        191
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:04:57.892214 UTC | [2020_01_13_04_30_18] Iteration #191 | Epoch Duration: 223.49346590042114
2020-01-13 16:04:57.892341 UTC | [2020_01_13_04_30_18] Iteration #191 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031966876
Z variance train             0.074580565
KL Divergence                4.462366
KL Loss                      0.4462366
QF Loss                      1352.2332
VF Loss                      452.32855
Policy Loss                  -1234.9374
Q Predictions Mean           1224.3804
Q Predictions Std            976.229
Q Predictions Max            2394.7976
Q Predictions Min            14.746088
V Predictions Mean           1236.8945
V Predictions Std            975.1413
V Predictions Max            2398.9595
V Predictions Min            31.681007
Log Pis Mean                 -5.3593416
Log Pis Std                  6.08519
Log Pis Max                  17.803772
Log Pis Min                  -13.329046
Policy mu Mean               0.17315981
Policy mu Std                0.6925686
Policy mu Max                2.6751251
Policy mu Min                -2.5770314
Policy log std Mean          -0.2995088
Policy log std Std           0.17076948
Policy log std Max           0.0051839054
Policy log std Min           -1.128055
Z mean eval                  0.04146724
Z variance eval              0.070955426
total_rewards                [4414.83547388 5167.24808513 3728.15176534 3979.75057419 2518.67898797
 5206.86760482  742.23305345 1823.18705568 3418.60361874 5170.12276323]
total_rewards_mean           3616.96789824162
total_rewards_std            1443.9993980896106
total_rewards_max            5206.867604822842
total_rewards_min            742.2330534452634
Number of train steps total  772000
Number of env steps total    967000
Number of rollouts total     0
Train Time (s)               193.12638263683766
(Previous) Eval Time (s)     12.327592744026333
Sample Time (s)              18.723128288518637
Epoch Time (s)               224.17710366938263
Total Train Time (s)         41907.82540670037
Epoch                        192
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:08:46.827417 UTC | [2020_01_13_04_30_18] Iteration #192 | Epoch Duration: 228.93495965003967
2020-01-13 16:08:46.827633 UTC | [2020_01_13_04_30_18] Iteration #192 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04092613
Z variance train             0.07093305
KL Divergence                4.547805
KL Loss                      0.4547805
QF Loss                      1746.698
VF Loss                      533.543
Policy Loss                  -1311.1501
Q Predictions Mean           1302.5934
Q Predictions Std            969.06885
Q Predictions Max            2405.263
Q Predictions Min            12.344127
V Predictions Mean           1310.9615
V Predictions Std            967.72034
V Predictions Max            2402.1318
V Predictions Min            22.330074
Log Pis Mean                 -4.4648256
Log Pis Std                  7.1415124
Log Pis Max                  19.438185
Log Pis Min                  -14.217559
Policy mu Mean               0.17380714
Policy mu Std                0.7406748
Policy mu Max                2.4878664
Policy mu Min                -3.1039453
Policy log std Mean          -0.30936
Policy log std Std           0.1714051
Policy log std Max           0.003891319
Policy log std Min           -1.1335453
Z mean eval                  0.025024485
Z variance eval              0.06215598
total_rewards                [4723.29032775 1073.11263492 5271.12056833 5362.8140168  4878.15697065
 3467.42390707 3592.86075983 5279.11088266 5257.17785176 1252.47807012]
total_rewards_mean           4015.754598988785
total_rewards_std            1566.7291690911102
total_rewards_max            5362.814016796559
total_rewards_min            1073.1126349175368
Number of train steps total  776000
Number of env steps total    972000
Number of rollouts total     0
Train Time (s)               196.77988560404629
(Previous) Eval Time (s)     17.085157466121018
Sample Time (s)              16.381975619122386
Epoch Time (s)               230.2470186892897
Total Train Time (s)         42139.662532150745
Epoch                        193
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:12:38.666525 UTC | [2020_01_13_04_30_18] Iteration #193 | Epoch Duration: 231.8387415409088
2020-01-13 16:12:38.666726 UTC | [2020_01_13_04_30_18] Iteration #193 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024669407
Z variance train             0.062230818
KL Divergence                4.691851
KL Loss                      0.4691851
QF Loss                      1749.4796
VF Loss                      717.9046
Policy Loss                  -1116.7246
Q Predictions Mean           1113.1951
Q Predictions Std            974.58514
Q Predictions Max            2402.694
Q Predictions Min            15.13092
V Predictions Mean           1123.3995
V Predictions Std            976.3486
V Predictions Max            2405.383
V Predictions Min            26.830194
Log Pis Mean                 -5.2868547
Log Pis Std                  7.4210944
Log Pis Max                  30.290049
Log Pis Min                  -13.805427
Policy mu Mean               0.1584672
Policy mu Std                0.7231638
Policy mu Max                3.279236
Policy mu Min                -3.5621321
Policy log std Mean          -0.28948334
Policy log std Std           0.17391226
Policy log std Max           -0.023003742
Policy log std Min           -1.3695253
Z mean eval                  0.023963064
Z variance eval              0.060074616
total_rewards                [2813.32717984 4471.3910591  5260.23707148 5273.52661835 4416.91867174
 4618.89719861 2013.83894257 4135.38227815 5165.23126657  958.30896343]
total_rewards_mean           3912.7059249844374
total_rewards_std            1410.4585841659216
total_rewards_max            5273.526618347906
total_rewards_min            958.3089634319078
Number of train steps total  780000
Number of env steps total    977000
Number of rollouts total     0
Train Time (s)               197.33703080099076
(Previous) Eval Time (s)     18.67659445013851
Sample Time (s)              18.667550864163786
Epoch Time (s)               234.68117611529306
Total Train Time (s)         42375.570881021675
Epoch                        194
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:16:34.576204 UTC | [2020_01_13_04_30_18] Iteration #194 | Epoch Duration: 235.909353017807
2020-01-13 16:16:34.576335 UTC | [2020_01_13_04_30_18] Iteration #194 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023916703
Z variance train             0.060041405
KL Divergence                4.79679
KL Loss                      0.47967902
QF Loss                      1691.5859
VF Loss                      589.49176
Policy Loss                  -1217.904
Q Predictions Mean           1210.9343
Q Predictions Std            988.2622
Q Predictions Max            2427.0059
Q Predictions Min            1.5518723
V Predictions Mean           1219.6912
V Predictions Std            986.63403
V Predictions Max            2430.7134
V Predictions Min            31.180408
Log Pis Mean                 -4.9698815
Log Pis Std                  6.8476424
Log Pis Max                  22.500132
Log Pis Min                  -14.520542
Policy mu Mean               0.11930025
Policy mu Std                0.73543006
Policy mu Max                3.2064145
Policy mu Min                -3.417918
Policy log std Mean          -0.30262992
Policy log std Std           0.1761516
Policy log std Max           0.0126720965
Policy log std Min           -1.2138522
Z mean eval                  0.017097523
Z variance eval              0.05276568
total_rewards                [2609.98499397 5314.21828206 4315.20308154 5333.75753436 2367.92617512
 5239.05213417 4897.41667735 1968.15071728  971.08863721 1872.15390531]
total_rewards_mean           3488.895213835981
total_rewards_std            1604.9924902150528
total_rewards_max            5333.757534359605
total_rewards_min            971.0886372082354
Number of train steps total  784000
Number of env steps total    982000
Number of rollouts total     0
Train Time (s)               192.2911462453194
(Previous) Eval Time (s)     19.904492439702153
Sample Time (s)              18.886462622322142
Epoch Time (s)               231.0821013073437
Total Train Time (s)         42604.12652852293
Epoch                        195
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:20:23.134546 UTC | [2020_01_13_04_30_18] Iteration #195 | Epoch Duration: 228.55810356140137
2020-01-13 16:20:23.134728 UTC | [2020_01_13_04_30_18] Iteration #195 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017173132
Z variance train             0.05282398
KL Divergence                5.136154
KL Loss                      0.5136154
QF Loss                      1520.9119
VF Loss                      587.7919
Policy Loss                  -1287.0924
Q Predictions Mean           1281.2273
Q Predictions Std            957.85785
Q Predictions Max            2427.048
Q Predictions Min            20.695354
V Predictions Mean           1282.7848
V Predictions Std            951.81464
V Predictions Max            2422.464
V Predictions Min            32.212517
Log Pis Mean                 -4.695664
Log Pis Std                  6.241164
Log Pis Max                  18.16785
Log Pis Min                  -13.251097
Policy mu Mean               0.14462382
Policy mu Std                0.71991235
Policy mu Max                3.0411007
Policy mu Min                -2.7693093
Policy log std Mean          -0.30195418
Policy log std Std           0.16865243
Policy log std Max           0.007380903
Policy log std Min           -1.0616854
Z mean eval                  0.022554148
Z variance eval              0.061479412
total_rewards                [5202.64120476 2574.61478823 4769.2544083  3761.10596408 5208.48480632
 3741.92973709  685.54339975 5371.83732616 2729.27857425  960.54682844]
total_rewards_mean           3500.5237037370725
total_rewards_std            1639.5039001231314
total_rewards_max            5371.8373261591105
total_rewards_min            685.5433997492298
Number of train steps total  788000
Number of env steps total    987000
Number of rollouts total     0
Train Time (s)               198.54968396527693
(Previous) Eval Time (s)     17.380196494050324
Sample Time (s)              16.818740526679903
Epoch Time (s)               232.74862098600715
Total Train Time (s)         42837.427320187446
Epoch                        196
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:24:16.438560 UTC | [2020_01_13_04_30_18] Iteration #196 | Epoch Duration: 233.3036994934082
2020-01-13 16:24:16.438734 UTC | [2020_01_13_04_30_18] Iteration #196 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022514734
Z variance train             0.061542638
KL Divergence                4.8601093
KL Loss                      0.48601094
QF Loss                      1552.7395
VF Loss                      389.6672
Policy Loss                  -1273.4081
Q Predictions Mean           1268.122
Q Predictions Std            991.7904
Q Predictions Max            2431.2473
Q Predictions Min            16.169754
V Predictions Mean           1267.4763
V Predictions Std            985.00946
V Predictions Max            2427.84
V Predictions Min            17.992956
Log Pis Mean                 -5.4684553
Log Pis Std                  6.002594
Log Pis Max                  15.398039
Log Pis Min                  -15.043508
Policy mu Mean               0.10023464
Policy mu Std                0.68583465
Policy mu Max                2.5040402
Policy mu Min                -3.261056
Policy log std Mean          -0.3009188
Policy log std Std           0.17004316
Policy log std Max           -0.07787014
Policy log std Min           -1.088113
Z mean eval                  0.03600981
Z variance eval              0.061368268
total_rewards                [2249.86045479 1243.50438926 1070.40233733 5221.61139452 2096.34113206
 1898.62755545 2226.36361058 4265.12813958 5258.36646692 2736.44771514]
total_rewards_mean           2826.6653195640492
total_rewards_std            1463.0380504640125
total_rewards_max            5258.366466922275
total_rewards_min            1070.4023373338405
Number of train steps total  792000
Number of env steps total    992000
Number of rollouts total     0
Train Time (s)               191.32824752712622
(Previous) Eval Time (s)     17.93493625940755
Sample Time (s)              16.061270451173186
Epoch Time (s)               225.32445423770696
Total Train Time (s)         43059.199103694875
Epoch                        197
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:27:58.212740 UTC | [2020_01_13_04_30_18] Iteration #197 | Epoch Duration: 221.77388668060303
2020-01-13 16:27:58.212862 UTC | [2020_01_13_04_30_18] Iteration #197 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035524122
Z variance train             0.061296374
KL Divergence                4.839138
KL Loss                      0.4839138
QF Loss                      1625.9564
VF Loss                      355.48944
Policy Loss                  -1304.7001
Q Predictions Mean           1301.6349
Q Predictions Std            1002.3043
Q Predictions Max            2414.12
Q Predictions Min            16.300951
V Predictions Mean           1304.8472
V Predictions Std            996.9014
V Predictions Max            2425.6316
V Predictions Min            31.337118
Log Pis Mean                 -4.9694743
Log Pis Std                  7.061312
Log Pis Max                  22.264603
Log Pis Min                  -13.704813
Policy mu Mean               0.14492892
Policy mu Std                0.719698
Policy mu Max                2.8909357
Policy mu Min                -3.3131216
Policy log std Mean          -0.2997012
Policy log std Std           0.1733021
Policy log std Max           0.026918277
Policy log std Min           -1.2208253
Z mean eval                  0.032900717
Z variance eval              0.06481601
total_rewards                [5260.72987235 1801.39389418 5318.46517798 1600.72020079 3082.13740839
 1938.62941706 5232.00206242 4792.01624744 2207.36594135 5298.92302917]
total_rewards_mean           3653.2383251117762
total_rewards_std            1576.4943116797058
total_rewards_max            5318.465177979433
total_rewards_min            1600.720200792814
Number of train steps total  796000
Number of env steps total    997000
Number of rollouts total     0
Train Time (s)               195.5582740320824
(Previous) Eval Time (s)     14.384097782894969
Sample Time (s)              18.94524185033515
Epoch Time (s)               228.88761366531253
Total Train Time (s)         43292.49665821064
Epoch                        198
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:31:51.512823 UTC | [2020_01_13_04_30_18] Iteration #198 | Epoch Duration: 233.29987382888794
2020-01-13 16:31:51.512943 UTC | [2020_01_13_04_30_18] Iteration #198 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033318616
Z variance train             0.064832196
KL Divergence                4.6289043
KL Loss                      0.46289045
QF Loss                      1903.5475
VF Loss                      425.16986
Policy Loss                  -1250.0001
Q Predictions Mean           1243.6218
Q Predictions Std            995.1516
Q Predictions Max            2433.7664
Q Predictions Min            14.319372
V Predictions Mean           1253.7943
V Predictions Std            995.9955
V Predictions Max            2438.089
V Predictions Min            28.515162
Log Pis Mean                 -5.520651
Log Pis Std                  5.6682615
Log Pis Max                  11.355846
Log Pis Min                  -17.0288
Policy mu Mean               0.13635445
Policy mu Std                0.6873194
Policy mu Max                2.6225865
Policy mu Min                -2.97611
Policy log std Mean          -0.30383098
Policy log std Std           0.1689013
Policy log std Max           -0.06767821
Policy log std Min           -1.0749509
Z mean eval                  0.03112195
Z variance eval              0.06537397
total_rewards                [2800.05821831 4611.53991359 3991.62350427 5358.51322223  945.63140525
 5284.34020778 1224.74996178 5501.39109768 2404.07132774 5219.27032721]
total_rewards_mean           3734.118918581503
total_rewards_std            1670.9588844133066
total_rewards_max            5501.391097679156
total_rewards_min            945.6314052466406
Number of train steps total  800000
Number of env steps total    1002000
Number of rollouts total     0
Train Time (s)               197.2679197350517
(Previous) Eval Time (s)     18.796068326104432
Sample Time (s)              17.564037563744932
Epoch Time (s)               233.62802562490106
Total Train Time (s)         43526.427905436605
Epoch                        199
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:35:45.446824 UTC | [2020_01_13_04_30_18] Iteration #199 | Epoch Duration: 233.93379163742065
2020-01-13 16:35:45.446948 UTC | [2020_01_13_04_30_18] Iteration #199 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031549033
Z variance train             0.06537802
KL Divergence                4.6994953
KL Loss                      0.46994954
QF Loss                      2198.0027
VF Loss                      582.7245
Policy Loss                  -1375.8473
Q Predictions Mean           1370.9058
Q Predictions Std            985.48486
Q Predictions Max            2421.6606
Q Predictions Min            17.155375
V Predictions Mean           1379.0391
V Predictions Std            983.8263
V Predictions Max            2435.6392
V Predictions Min            24.023462
Log Pis Mean                 -4.691867
Log Pis Std                  6.7251062
Log Pis Max                  23.65044
Log Pis Min                  -15.140101
Policy mu Mean               0.19080353
Policy mu Std                0.72003144
Policy mu Max                2.655023
Policy mu Min                -3.0110497
Policy log std Mean          -0.31144056
Policy log std Std           0.17973147
Policy log std Max           0.11813238
Policy log std Min           -1.0475662
Z mean eval                  0.034173302
Z variance eval              0.060919374
total_rewards                [2795.90386495 4076.5220201  2040.58757291 2382.48126525 1235.93264422
 2182.64335691  769.00818452 5183.46043452 3101.18636779 3308.93674823]
total_rewards_mean           2707.6662459380364
total_rewards_std            1236.0532476601622
total_rewards_max            5183.460434517769
total_rewards_min            769.0081845197151
Number of train steps total  804000
Number of env steps total    1007000
Number of rollouts total     0
Train Time (s)               199.92588548269123
(Previous) Eval Time (s)     19.101571518927813
Sample Time (s)              18.875037549063563
Epoch Time (s)               237.9024945506826
Total Train Time (s)         43758.028600668535
Epoch                        200
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:39:37.053578 UTC | [2020_01_13_04_30_18] Iteration #200 | Epoch Duration: 231.60649394989014
2020-01-13 16:39:37.053850 UTC | [2020_01_13_04_30_18] Iteration #200 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033825874
Z variance train             0.06095148
KL Divergence                4.7496853
KL Loss                      0.47496852
QF Loss                      1840.4247
VF Loss                      992.4003
Policy Loss                  -1245.0386
Q Predictions Mean           1235.8921
Q Predictions Std            992.5715
Q Predictions Max            2435.2854
Q Predictions Min            -1.2921646
V Predictions Mean           1257.5269
V Predictions Std            998.3238
V Predictions Max            2449.856
V Predictions Min            21.46593
Log Pis Mean                 -4.736451
Log Pis Std                  7.5662603
Log Pis Max                  27.392448
Log Pis Min                  -13.6219015
Policy mu Mean               0.16582982
Policy mu Std                0.7391529
Policy mu Max                4.1181874
Policy mu Min                -2.8655381
Policy log std Mean          -0.30339512
Policy log std Std           0.17389554
Policy log std Max           0.059162036
Policy log std Min           -1.1363692
Z mean eval                  0.026148105
Z variance eval              0.06286347
total_rewards                [1148.00751415 5002.49745045 4949.06162876 4314.66743893 4918.65334326
 3270.04734389 5049.65919011 4978.09051224 3438.36019843 4997.00518777]
total_rewards_mean           4206.604980799204
total_rewards_std            1202.3476448507308
total_rewards_max            5049.659190107101
total_rewards_min            1148.0075141527393
Number of train steps total  808000
Number of env steps total    1012000
Number of rollouts total     0
Train Time (s)               195.86586156394333
(Previous) Eval Time (s)     12.805235635023564
Sample Time (s)              18.39840750815347
Epoch Time (s)               227.06950470712036
Total Train Time (s)         43995.25137196714
Epoch                        201
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:43:34.276787 UTC | [2020_01_13_04_30_18] Iteration #201 | Epoch Duration: 237.22276425361633
2020-01-13 16:43:34.276914 UTC | [2020_01_13_04_30_18] Iteration #201 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02635023
Z variance train             0.06285953
KL Divergence                4.7762866
KL Loss                      0.47762868
QF Loss                      1229.6594
VF Loss                      603.2006
Policy Loss                  -1333.9146
Q Predictions Mean           1328.4358
Q Predictions Std            995.4631
Q Predictions Max            2439.1099
Q Predictions Min            13.794948
V Predictions Mean           1328.3984
V Predictions Std            989.79803
V Predictions Max            2435.5515
V Predictions Min            26.391808
Log Pis Mean                 -4.4943714
Log Pis Std                  6.8838754
Log Pis Max                  26.030378
Log Pis Min                  -14.4158
Policy mu Mean               0.14720875
Policy mu Std                0.7328195
Policy mu Max                2.692859
Policy mu Min                -3.1017506
Policy log std Mean          -0.3027537
Policy log std Std           0.16838785
Policy log std Max           -0.017825395
Policy log std Min           -1.2442307
Z mean eval                  0.023830742
Z variance eval              0.06572661
total_rewards                [1044.29111033 2482.13064371 5243.46397841 5206.43971157 5247.99665123
 5193.67935034 3097.62722534 2411.27096321 5205.503752   1156.05512283]
total_rewards_mean           3628.845850897528
total_rewards_std            1688.9716460817974
total_rewards_max            5247.996651233873
total_rewards_min            1044.2911103329516
Number of train steps total  812000
Number of env steps total    1017000
Number of rollouts total     0
Train Time (s)               190.39651289070025
(Previous) Eval Time (s)     22.958226412069052
Sample Time (s)              16.75140612060204
Epoch Time (s)               230.10614542337134
Total Train Time (s)         44219.23248020653
Epoch                        202
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:47:18.260998 UTC | [2020_01_13_04_30_18] Iteration #202 | Epoch Duration: 223.98396348953247
2020-01-13 16:47:18.261245 UTC | [2020_01_13_04_30_18] Iteration #202 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0232129
Z variance train             0.06574843
KL Divergence                4.5122805
KL Loss                      0.45122805
QF Loss                      2819.7656
VF Loss                      751.23865
Policy Loss                  -1357.6733
Q Predictions Mean           1346.8967
Q Predictions Std            958.11365
Q Predictions Max            2456.5198
Q Predictions Min            11.860102
V Predictions Mean           1365.4583
V Predictions Std            962.05396
V Predictions Max            2463.0852
V Predictions Min            28.982178
Log Pis Mean                 -4.407139
Log Pis Std                  6.5842156
Log Pis Max                  24.27494
Log Pis Min                  -12.657002
Policy mu Mean               0.14676055
Policy mu Std                0.75165147
Policy mu Max                2.8440654
Policy mu Min                -2.926603
Policy log std Mean          -0.3211492
Policy log std Std           0.18283422
Policy log std Max           -0.039080404
Policy log std Min           -1.2241503
Z mean eval                  0.023618618
Z variance eval              0.06872366
total_rewards                [ 922.30351156 4175.90674029 5353.14750746 2493.80999424 3906.73635376
 2415.1718011  4115.63018226 1969.72548928 1381.34051455 5336.30584719]
total_rewards_mean           3207.0077941682016
total_rewards_std            1503.7707024389417
total_rewards_max            5353.147507461687
total_rewards_min            922.3035115639843
Number of train steps total  816000
Number of env steps total    1022000
Number of rollouts total     0
Train Time (s)               196.73482454707846
(Previous) Eval Time (s)     16.835760936141014
Sample Time (s)              16.70230479585007
Epoch Time (s)               230.27289027906954
Total Train Time (s)         44449.03610217199
Epoch                        203
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:51:08.068484 UTC | [2020_01_13_04_30_18] Iteration #203 | Epoch Duration: 229.80697679519653
2020-01-13 16:51:08.068835 UTC | [2020_01_13_04_30_18] Iteration #203 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023683924
Z variance train             0.06878068
KL Divergence                4.417012
KL Loss                      0.44170123
QF Loss                      1863.2793
VF Loss                      628.2823
Policy Loss                  -1359.9006
Q Predictions Mean           1348.529
Q Predictions Std            988.9045
Q Predictions Max            2444.814
Q Predictions Min            12.525719
V Predictions Mean           1361.7988
V Predictions Std            990.17786
V Predictions Max            2451.8179
V Predictions Min            22.157896
Log Pis Mean                 -4.366877
Log Pis Std                  6.916228
Log Pis Max                  23.440865
Log Pis Min                  -14.497383
Policy mu Mean               0.17294267
Policy mu Std                0.74165773
Policy mu Max                3.291501
Policy mu Min                -3.1328158
Policy log std Mean          -0.3195759
Policy log std Std           0.1791478
Policy log std Max           0.15122452
Policy log std Min           -1.1074946
Z mean eval                  0.029354865
Z variance eval              0.060507514
total_rewards                [5111.01263596 2811.81378662 1070.98643686 5149.31950017 3534.35329518
 3194.60667528 5186.42887658 2059.88708524 1184.3725143  5176.84430261]
total_rewards_mean           3447.9625108793543
total_rewards_std            1576.3437106395045
total_rewards_max            5186.428876581614
total_rewards_min            1070.9864368647645
Number of train steps total  820000
Number of env steps total    1027000
Number of rollouts total     0
Train Time (s)               196.74475417798385
(Previous) Eval Time (s)     16.369506241753697
Sample Time (s)              17.175560069270432
Epoch Time (s)               230.28982048900798
Total Train Time (s)         44680.02891303692
Epoch                        204
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:54:59.064945 UTC | [2020_01_13_04_30_18] Iteration #204 | Epoch Duration: 230.99590635299683
2020-01-13 16:54:59.065183 UTC | [2020_01_13_04_30_18] Iteration #204 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029212708
Z variance train             0.06052472
KL Divergence                4.703914
KL Loss                      0.47039142
QF Loss                      2030.7412
VF Loss                      639.2637
Policy Loss                  -1402.7178
Q Predictions Mean           1398.2732
Q Predictions Std            985.9112
Q Predictions Max            2455.0383
Q Predictions Min            18.717714
V Predictions Mean           1400.4456
V Predictions Std            980.96326
V Predictions Max            2449.761
V Predictions Min            31.150679
Log Pis Mean                 -4.2006855
Log Pis Std                  7.788992
Log Pis Max                  30.070507
Log Pis Min                  -13.793055
Policy mu Mean               0.12306091
Policy mu Std                0.7634031
Policy mu Max                2.9125338
Policy mu Min                -3.4850585
Policy log std Mean          -0.320297
Policy log std Std           0.1771756
Policy log std Max           -0.03994731
Policy log std Min           -1.2559726
Z mean eval                  0.024975093
Z variance eval              0.062151212
total_rewards                [2387.261087   5126.56296131 2008.56855354 1074.52779765 5261.47189766
 5317.67170143 5234.75344551 5104.54864804 5296.44859317 3865.49078337]
total_rewards_mean           4067.730546868369
total_rewards_std            1553.0443967488582
total_rewards_max            5317.671701427934
total_rewards_min            1074.5277976459092
Number of train steps total  824000
Number of env steps total    1032000
Number of rollouts total     0
Train Time (s)               194.58675431413576
(Previous) Eval Time (s)     17.07532701874152
Sample Time (s)              16.63869807543233
Epoch Time (s)               228.3007794083096
Total Train Time (s)         44912.384950864594
Epoch                        205
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 16:58:51.421846 UTC | [2020_01_13_04_30_18] Iteration #205 | Epoch Duration: 232.3565309047699
2020-01-13 16:58:51.421988 UTC | [2020_01_13_04_30_18] Iteration #205 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024929006
Z variance train             0.06222079
KL Divergence                4.69236
KL Loss                      0.469236
QF Loss                      1734.3168
VF Loss                      600.528
Policy Loss                  -1464.072
Q Predictions Mean           1460.8789
Q Predictions Std            958.4197
Q Predictions Max            2458.5745
Q Predictions Min            18.464956
V Predictions Mean           1468.7798
V Predictions Std            956.1071
V Predictions Max            2465.5679
V Predictions Min            27.11793
Log Pis Mean                 -4.9775076
Log Pis Std                  6.5465603
Log Pis Max                  22.976387
Log Pis Min                  -17.06569
Policy mu Mean               0.15500343
Policy mu Std                0.74274606
Policy mu Max                3.141407
Policy mu Min                -2.9030645
Policy log std Mean          -0.3150352
Policy log std Std           0.17043476
Policy log std Max           -0.028519914
Policy log std Min           -1.2273979
Z mean eval                  0.023127705
Z variance eval              0.06380038
total_rewards                [5110.69172705 5079.8606087  5026.89037821 5099.32153707 2931.30640464
 5083.29824199 5182.2506603  5038.51048341 5044.72908699 5162.6593129 ]
total_rewards_mean           4875.951844127124
total_rewards_std            649.9944367507999
total_rewards_max            5182.250660302522
total_rewards_min            2931.3064046429104
Number of train steps total  828000
Number of env steps total    1037000
Number of rollouts total     0
Train Time (s)               192.07880939217284
(Previous) Eval Time (s)     21.13080046325922
Sample Time (s)              18.469258188270032
Epoch Time (s)               231.6788680437021
Total Train Time (s)         45148.494320868514
Epoch                        206
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:02:47.533542 UTC | [2020_01_13_04_30_18] Iteration #206 | Epoch Duration: 236.11140251159668
2020-01-13 17:02:47.533735 UTC | [2020_01_13_04_30_18] Iteration #206 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02328127
Z variance train             0.063775375
KL Divergence                4.6441784
KL Loss                      0.46441785
QF Loss                      1548.9736
VF Loss                      599.4358
Policy Loss                  -1239.9166
Q Predictions Mean           1238.2355
Q Predictions Std            1052.0747
Q Predictions Max            2467.322
Q Predictions Min            14.9845915
V Predictions Mean           1243.7628
V Predictions Std            1049.3616
V Predictions Max            2477.602
V Predictions Min            25.329498
Log Pis Mean                 -5.3593636
Log Pis Std                  6.9837756
Log Pis Max                  35.87136
Log Pis Min                  -14.294315
Policy mu Mean               0.11996592
Policy mu Std                0.6986743
Policy mu Max                2.6926622
Policy mu Min                -3.4380958
Policy log std Mean          -0.2937999
Policy log std Std           0.17200182
Policy log std Max           -0.0032690912
Policy log std Min           -1.1874002
Z mean eval                  0.020281766
Z variance eval              0.06590219
total_rewards                [5118.63431992 5089.47675831 5140.25625307 5029.52020334 4988.389355
 5118.33476709 4986.66912836 5132.31923123 1134.81848637 5008.95971333]
total_rewards_mean           4674.737821600677
total_rewards_std            1181.363662433185
total_rewards_max            5140.256253068015
total_rewards_min            1134.818486365481
Number of train steps total  832000
Number of env steps total    1042000
Number of rollouts total     0
Train Time (s)               194.76503819506615
(Previous) Eval Time (s)     25.56307012727484
Sample Time (s)              18.772278408985585
Epoch Time (s)               239.10038673132658
Total Train Time (s)         45387.13416695269
Epoch                        207
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:06:46.174540 UTC | [2020_01_13_04_30_18] Iteration #207 | Epoch Duration: 238.6407024860382
2020-01-13 17:06:46.174660 UTC | [2020_01_13_04_30_18] Iteration #207 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020235505
Z variance train             0.06587058
KL Divergence                4.625829
KL Loss                      0.46258292
QF Loss                      1873.5511
VF Loss                      616.25604
Policy Loss                  -1423.3079
Q Predictions Mean           1414.6548
Q Predictions Std            999.764
Q Predictions Max            2480.5808
Q Predictions Min            15.348812
V Predictions Mean           1424.685
V Predictions Std            1002.31775
V Predictions Max            2479.8064
V Predictions Min            20.863894
Log Pis Mean                 -5.323621
Log Pis Std                  6.408341
Log Pis Max                  20.715197
Log Pis Min                  -16.345947
Policy mu Mean               0.16497126
Policy mu Std                0.7073955
Policy mu Max                2.663922
Policy mu Min                -3.5876408
Policy log std Mean          -0.30474675
Policy log std Std           0.16925864
Policy log std Max           -0.010802515
Policy log std Min           -1.19263
Z mean eval                  0.020389557
Z variance eval              0.069859505
total_rewards                [3274.74392655 5113.44056407 5282.48932454 5237.32093346 4451.48255866
 3129.98446099 3579.52468651 1141.92602872 2714.0734598  2871.01575565]
total_rewards_mean           3679.600169894892
total_rewards_std            1270.798569982177
total_rewards_max            5282.489324540759
total_rewards_min            1141.926028715037
Number of train steps total  836000
Number of env steps total    1047000
Number of rollouts total     0
Train Time (s)               197.21609155507758
(Previous) Eval Time (s)     25.103107389993966
Sample Time (s)              17.551141305360943
Epoch Time (s)               239.8703402504325
Total Train Time (s)         45619.812054730486
Epoch                        208
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:10:38.855467 UTC | [2020_01_13_04_30_18] Iteration #208 | Epoch Duration: 232.68070030212402
2020-01-13 17:10:38.855650 UTC | [2020_01_13_04_30_18] Iteration #208 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02075906
Z variance train             0.069853514
KL Divergence                4.543561
KL Loss                      0.4543561
QF Loss                      1273.8887
VF Loss                      320.77057
Policy Loss                  -1492.8531
Q Predictions Mean           1485.3455
Q Predictions Std            992.144
Q Predictions Max            2469.626
Q Predictions Min            17.118645
V Predictions Mean           1490.5879
V Predictions Std            988.9897
V Predictions Max            2465.978
V Predictions Min            25.724644
Log Pis Mean                 -4.262811
Log Pis Std                  7.2545595
Log Pis Max                  26.138998
Log Pis Min                  -14.045915
Policy mu Mean               0.18693706
Policy mu Std                0.7435738
Policy mu Max                2.9248788
Policy mu Min                -3.0091827
Policy log std Mean          -0.32397053
Policy log std Std           0.18032831
Policy log std Max           0.06512019
Policy log std Min           -1.2444791
Z mean eval                  0.027814567
Z variance eval              0.0741107
total_rewards                [ 690.62280741 1509.4513981  2946.20998618 5063.3518474  1633.74265838
 3144.71688693 5189.50577987 2959.34046501 1759.98741202 5088.94101505]
total_rewards_mean           2998.5870256348253
total_rewards_std            1562.0419021451587
total_rewards_max            5189.505779873788
total_rewards_min            690.6228074071158
Number of train steps total  840000
Number of env steps total    1052000
Number of rollouts total     0
Train Time (s)               198.77003526315093
(Previous) Eval Time (s)     17.913193522021174
Sample Time (s)              19.75309706479311
Epoch Time (s)               236.43632584996521
Total Train Time (s)         45854.454081457574
Epoch                        209
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:14:33.499021 UTC | [2020_01_13_04_30_18] Iteration #209 | Epoch Duration: 234.64324760437012
2020-01-13 17:14:33.499154 UTC | [2020_01_13_04_30_18] Iteration #209 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026849827
Z variance train             0.07413715
KL Divergence                4.2861567
KL Loss                      0.42861566
QF Loss                      1801.5089
VF Loss                      908.0772
Policy Loss                  -1404.8618
Q Predictions Mean           1407.3708
Q Predictions Std            985.1304
Q Predictions Max            2476.266
Q Predictions Min            17.840704
V Predictions Mean           1418.7742
V Predictions Std            987.3679
V Predictions Max            2499.274
V Predictions Min            24.818975
Log Pis Mean                 -4.4454956
Log Pis Std                  7.075356
Log Pis Max                  35.793243
Log Pis Min                  -13.026425
Policy mu Mean               0.14030349
Policy mu Std                0.7491392
Policy mu Max                3.1831307
Policy mu Min                -4.6565266
Policy log std Mean          -0.3134131
Policy log std Std           0.17177644
Policy log std Max           -0.03059166
Policy log std Min           -1.074887
Z mean eval                  0.01646048
Z variance eval              0.06453722
total_rewards                [ 676.25936888 5231.23931424 4562.53112555 4187.67431183 5205.54968246
 5188.01739791 3149.94641118 3485.16642168 1353.75579628  749.92103193]
total_rewards_mean           3379.0060861932698
total_rewards_std            1745.7529124380035
total_rewards_max            5231.23931424097
total_rewards_min            676.2593688806774
Number of train steps total  844000
Number of env steps total    1057000
Number of rollouts total     0
Train Time (s)               194.90539408102632
(Previous) Eval Time (s)     16.11975032230839
Sample Time (s)              18.64917582599446
Epoch Time (s)               229.67432022932917
Total Train Time (s)         46085.96846418455
Epoch                        210
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:18:25.020868 UTC | [2020_01_13_04_30_18] Iteration #210 | Epoch Duration: 231.52159786224365
2020-01-13 17:18:25.021068 UTC | [2020_01_13_04_30_18] Iteration #210 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016326413
Z variance train             0.064559504
KL Divergence                4.614806
KL Loss                      0.46148062
QF Loss                      1473.4299
VF Loss                      614.073
Policy Loss                  -1556.4946
Q Predictions Mean           1551.535
Q Predictions Std            972.08154
Q Predictions Max            2490.7727
Q Predictions Min            17.847614
V Predictions Mean           1564.906
V Predictions Std            970.1643
V Predictions Max            2489.5186
V Predictions Min            28.89493
Log Pis Mean                 -4.769963
Log Pis Std                  6.330371
Log Pis Max                  18.56393
Log Pis Min                  -14.138861
Policy mu Mean               0.1446023
Policy mu Std                0.7321882
Policy mu Max                3.3203099
Policy mu Min                -3.737854
Policy log std Mean          -0.3285581
Policy log std Std           0.16882925
Policy log std Max           -0.028427422
Policy log std Min           -1.1012304
Z mean eval                  0.024774088
Z variance eval              0.07102473
total_rewards                [5205.54670975 2917.88653083  606.52160541 5283.4315428  4157.78342125
 5287.69375458 3250.77245653 2515.44203393 2989.98177988 5167.30510419]
total_rewards_mean           3738.2364939154118
total_rewards_std            1480.9809698073243
total_rewards_max            5287.693754583321
total_rewards_min            606.52160541325
Number of train steps total  848000
Number of env steps total    1062000
Number of rollouts total     0
Train Time (s)               197.76611645612866
(Previous) Eval Time (s)     17.96676021721214
Sample Time (s)              18.936864549759775
Epoch Time (s)               234.66974122310057
Total Train Time (s)         46321.45808157977
Epoch                        211
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:22:20.513134 UTC | [2020_01_13_04_30_18] Iteration #211 | Epoch Duration: 235.4919192790985
2020-01-13 17:22:20.513367 UTC | [2020_01_13_04_30_18] Iteration #211 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024985705
Z variance train             0.07101564
KL Divergence                4.47176
KL Loss                      0.44717598
QF Loss                      1560.1782
VF Loss                      467.96027
Policy Loss                  -1426.5918
Q Predictions Mean           1422.3339
Q Predictions Std            982.06384
Q Predictions Max            2490.4812
Q Predictions Min            15.849014
V Predictions Mean           1428.9355
V Predictions Std            979.4765
V Predictions Max            2508.5215
V Predictions Min            27.143223
Log Pis Mean                 -4.2170854
Log Pis Std                  6.742357
Log Pis Max                  20.554674
Log Pis Min                  -14.093067
Policy mu Mean               0.17041428
Policy mu Std                0.74181026
Policy mu Max                3.0228534
Policy mu Min                -3.1039855
Policy log std Mean          -0.33538824
Policy log std Std           0.18827537
Policy log std Max           0.015847951
Policy log std Min           -1.2166219
Z mean eval                  0.022098776
Z variance eval              0.063169554
total_rewards                [5262.41257989 1433.19501699 5199.27509186 5135.53477426 5051.22900748
 3865.38061028 5070.90090573 2198.20835446 5200.78911047 5280.6449373 ]
total_rewards_mean           4369.757038871168
total_rewards_std            1346.8891293478125
total_rewards_max            5280.644937301954
total_rewards_min            1433.1950169933
Number of train steps total  852000
Number of env steps total    1067000
Number of rollouts total     0
Train Time (s)               197.13387493882328
(Previous) Eval Time (s)     18.788642033934593
Sample Time (s)              19.363136671483517
Epoch Time (s)               235.2856536442414
Total Train Time (s)         46560.81540308613
Epoch                        212
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:26:19.876507 UTC | [2020_01_13_04_30_18] Iteration #212 | Epoch Duration: 239.36294531822205
2020-01-13 17:26:19.876824 UTC | [2020_01_13_04_30_18] Iteration #212 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021587556
Z variance train             0.063180305
KL Divergence                4.742809
KL Loss                      0.4742809
QF Loss                      1477.802
VF Loss                      423.3446
Policy Loss                  -1427.8307
Q Predictions Mean           1423.6045
Q Predictions Std            1012.0575
Q Predictions Max            2505.2112
Q Predictions Min            21.894737
V Predictions Mean           1420.4645
V Predictions Std            1004.7542
V Predictions Max            2501.5864
V Predictions Min            23.030125
Log Pis Mean                 -5.137453
Log Pis Std                  5.8848157
Log Pis Max                  16.199982
Log Pis Min                  -14.512591
Policy mu Mean               0.15303488
Policy mu Std                0.69382745
Policy mu Max                2.6618862
Policy mu Min                -2.6702182
Policy log std Mean          -0.30295417
Policy log std Std           0.16349503
Policy log std Max           0.12349665
Policy log std Min           -1.018975
Z mean eval                  0.021786468
Z variance eval              0.05631671
total_rewards                [2086.12733146 5241.47271127 5302.00370708  852.36703135 2039.02151724
 5217.34690494 2629.71734845 1499.70477229 5116.16518484 5146.85440271]
total_rewards_mean           3513.078091162412
total_rewards_std            1745.0977393336848
total_rewards_max            5302.0037070800045
total_rewards_min            852.3670313467869
Number of train steps total  856000
Number of env steps total    1072000
Number of rollouts total     0
Train Time (s)               199.44940310670063
(Previous) Eval Time (s)     22.865604416001588
Sample Time (s)              18.826187260914594
Epoch Time (s)               241.1411947836168
Total Train Time (s)         46796.41844987124
Epoch                        213
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:30:15.481812 UTC | [2020_01_13_04_30_18] Iteration #213 | Epoch Duration: 235.60477781295776
2020-01-13 17:30:15.481976 UTC | [2020_01_13_04_30_18] Iteration #213 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021838097
Z variance train             0.05634027
KL Divergence                4.954299
KL Loss                      0.4954299
QF Loss                      1837.2563
VF Loss                      815.468
Policy Loss                  -1503.5504
Q Predictions Mean           1497.0891
Q Predictions Std            974.5827
Q Predictions Max            2501.4036
Q Predictions Min            21.816383
V Predictions Mean           1493.3853
V Predictions Std            967.199
V Predictions Max            2496.6155
V Predictions Min            28.509956
Log Pis Mean                 -4.141675
Log Pis Std                  7.1009383
Log Pis Max                  41.606514
Log Pis Min                  -16.608343
Policy mu Mean               0.1970874
Policy mu Std                0.77124053
Policy mu Max                3.9315898
Policy mu Min                -3.3593402
Policy log std Mean          -0.32774976
Policy log std Std           0.17580183
Policy log std Max           0.115431964
Policy log std Min           -1.170995
Z mean eval                  0.023505908
Z variance eval              0.055055343
total_rewards                [5164.35809327 3409.98847084 2486.00135119 5125.56693952 5163.79602211
 2443.61221561 1312.79231809 1922.52275299  711.26862805 2357.47663434]
total_rewards_mean           3009.738342602245
total_rewards_std            1558.3373419872428
total_rewards_max            5164.358093274406
total_rewards_min            711.2686280530264
Number of train steps total  860000
Number of env steps total    1077000
Number of rollouts total     0
Train Time (s)               196.41703486815095
(Previous) Eval Time (s)     17.328946157824248
Sample Time (s)              17.191981986165047
Epoch Time (s)               230.93796301214024
Total Train Time (s)         47026.06724016648
Epoch                        214
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:34:05.136750 UTC | [2020_01_13_04_30_18] Iteration #214 | Epoch Duration: 229.6546392440796
2020-01-13 17:34:05.136948 UTC | [2020_01_13_04_30_18] Iteration #214 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023668101
Z variance train             0.055080116
KL Divergence                5.102747
KL Loss                      0.5102747
QF Loss                      2212.7126
VF Loss                      739.5948
Policy Loss                  -1593.7302
Q Predictions Mean           1577.7661
Q Predictions Std            983.4738
Q Predictions Max            2505.279
Q Predictions Min            15.305283
V Predictions Mean           1579.9551
V Predictions Std            979.1538
V Predictions Max            2494.2705
V Predictions Min            31.165958
Log Pis Mean                 -4.5005097
Log Pis Std                  6.582052
Log Pis Max                  18.423523
Log Pis Min                  -13.582458
Policy mu Mean               0.16942278
Policy mu Std                0.7308309
Policy mu Max                2.9781363
Policy mu Min                -3.0164917
Policy log std Mean          -0.3150406
Policy log std Std           0.17126231
Policy log std Max           -0.030231774
Policy log std Min           -1.1188276
Z mean eval                  0.021658817
Z variance eval              0.056190602
total_rewards                [5109.43311426 5105.65476929 4179.79059747 5037.52866084 4480.4239462
 5133.33488424 5232.393042   5176.77541065 1831.46350913 3892.34910498]
total_rewards_mean           4517.914703907399
total_rewards_std            1000.63657798815
total_rewards_max            5232.393042002621
total_rewards_min            1831.4635091311272
Number of train steps total  864000
Number of env steps total    1082000
Number of rollouts total     0
Train Time (s)               201.85992142232135
(Previous) Eval Time (s)     16.045299891382456
Sample Time (s)              17.581520214211196
Epoch Time (s)               235.486741527915
Total Train Time (s)         47267.52027807385
Epoch                        215
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:38:06.593926 UTC | [2020_01_13_04_30_18] Iteration #215 | Epoch Duration: 241.4568314552307
2020-01-13 17:38:06.594128 UTC | [2020_01_13_04_30_18] Iteration #215 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022147927
Z variance train             0.05620002
KL Divergence                5.0605383
KL Loss                      0.50605386
QF Loss                      1511.3093
VF Loss                      771.64966
Policy Loss                  -1477.2164
Q Predictions Mean           1467.7642
Q Predictions Std            999.7332
Q Predictions Max            2504.9434
Q Predictions Min            13.340943
V Predictions Mean           1466.0828
V Predictions Std            990.76526
V Predictions Max            2497.1382
V Predictions Min            32.885956
Log Pis Mean                 -5.035202
Log Pis Std                  5.919025
Log Pis Max                  22.59707
Log Pis Min                  -12.998026
Policy mu Mean               0.17248356
Policy mu Std                0.69857997
Policy mu Max                3.101309
Policy mu Min                -3.079799
Policy log std Mean          -0.31240475
Policy log std Std           0.16712308
Policy log std Max           -0.009662062
Policy log std Min           -1.2073665
Z mean eval                  0.021606471
Z variance eval              0.05384891
total_rewards                [5128.94449185 5158.55376461 5266.82345821 1192.26429153 5193.36823287
 1620.01648512  863.80690636 1021.53256371 1338.91468058 1229.28587309]
total_rewards_mean           2801.3510747924447
total_rewards_std            1956.8098534412031
total_rewards_max            5266.823458207978
total_rewards_min            863.8069063622286
Number of train steps total  868000
Number of env steps total    1087000
Number of rollouts total     0
Train Time (s)               196.1722203413956
(Previous) Eval Time (s)     22.015097516123205
Sample Time (s)              18.418606396298856
Epoch Time (s)               236.60592425381765
Total Train Time (s)         47496.784544277936
Epoch                        216
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:41:55.862432 UTC | [2020_01_13_04_30_18] Iteration #216 | Epoch Duration: 229.2681336402893
2020-01-13 17:41:55.862710 UTC | [2020_01_13_04_30_18] Iteration #216 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021890245
Z variance train             0.053825777
KL Divergence                5.0774364
KL Loss                      0.50774366
QF Loss                      1617.4625
VF Loss                      424.4187
Policy Loss                  -1545.7063
Q Predictions Mean           1541.5
Q Predictions Std            979.64716
Q Predictions Max            2510.0884
Q Predictions Min            16.551807
V Predictions Mean           1545.8184
V Predictions Std            975.65045
V Predictions Max            2513.2034
V Predictions Min            26.333567
Log Pis Mean                 -4.691129
Log Pis Std                  6.892467
Log Pis Max                  29.941446
Log Pis Min                  -14.071533
Policy mu Mean               0.1769225
Policy mu Std                0.73779327
Policy mu Max                3.954617
Policy mu Min                -4.13163
Policy log std Mean          -0.31983358
Policy log std Std           0.16622713
Policy log std Max           0.03168966
Policy log std Min           -1.0953894
Z mean eval                  0.01891617
Z variance eval              0.05624196
total_rewards                [3353.09686883 4111.28470094 2912.35419919 1824.89042253 5087.657453
 2111.91562472 5117.47445027 2717.85849588 4551.72070411 5154.89182198]
total_rewards_mean           3694.3144741438446
total_rewards_std            1211.9890586657855
total_rewards_max            5154.891821982124
total_rewards_min            1824.890422534265
Number of train steps total  872000
Number of env steps total    1092000
Number of rollouts total     0
Train Time (s)               195.3557049371302
(Previous) Eval Time (s)     14.67701378185302
Sample Time (s)              17.069579997565597
Epoch Time (s)               227.10229871654883
Total Train Time (s)         47728.940510300454
Epoch                        217
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:45:48.021365 UTC | [2020_01_13_04_30_18] Iteration #217 | Epoch Duration: 232.1584551334381
2020-01-13 17:45:48.021553 UTC | [2020_01_13_04_30_18] Iteration #217 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018949257
Z variance train             0.05617383
KL Divergence                5.0798683
KL Loss                      0.50798684
QF Loss                      1869.2091
VF Loss                      561.7788
Policy Loss                  -1422.5775
Q Predictions Mean           1412.0544
Q Predictions Std            1026.4269
Q Predictions Max            2518.6804
Q Predictions Min            14.137321
V Predictions Mean           1426.2268
V Predictions Std            1027.4635
V Predictions Max            2515.3252
V Predictions Min            26.092173
Log Pis Mean                 -5.4846754
Log Pis Std                  6.506479
Log Pis Max                  20.043148
Log Pis Min                  -14.096266
Policy mu Mean               0.13924982
Policy mu Std                0.6905722
Policy mu Max                2.9053612
Policy mu Min                -2.9089768
Policy log std Mean          -0.29158863
Policy log std Std           0.1721785
Policy log std Max           -0.0046450943
Policy log std Min           -1.3003144
Z mean eval                  0.026412267
Z variance eval              0.061505027
total_rewards                [2632.0689493  1571.34373756 2117.76718011 3735.52903601 4210.49147008
 5196.63290332 5248.29648992  958.85957076  831.2096061  4351.23297516]
total_rewards_mean           3085.34319183121
total_rewards_std            1595.7441673739495
total_rewards_max            5248.296489921027
total_rewards_min            831.2096060969021
Number of train steps total  876000
Number of env steps total    1097000
Number of rollouts total     0
Train Time (s)               193.79812964610755
(Previous) Eval Time (s)     19.732894218992442
Sample Time (s)              18.771982844453305
Epoch Time (s)               232.3030067095533
Total Train Time (s)         47956.95448851772
Epoch                        218
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:49:36.036715 UTC | [2020_01_13_04_30_18] Iteration #218 | Epoch Duration: 228.01502203941345
2020-01-13 17:49:36.036872 UTC | [2020_01_13_04_30_18] Iteration #218 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027529646
Z variance train             0.061529785
KL Divergence                4.8292255
KL Loss                      0.48292255
QF Loss                      1713.8723
VF Loss                      506.95084
Policy Loss                  -1571.5326
Q Predictions Mean           1563.699
Q Predictions Std            1022.8734
Q Predictions Max            2542.7432
Q Predictions Min            18.762312
V Predictions Mean           1568.1615
V Predictions Std            1018.29083
V Predictions Max            2533.887
V Predictions Min            27.346375
Log Pis Mean                 -5.3324995
Log Pis Std                  6.256186
Log Pis Max                  17.023956
Log Pis Min                  -14.879308
Policy mu Mean               0.12288973
Policy mu Std                0.7118093
Policy mu Max                3.1628835
Policy mu Min                -2.8917842
Policy log std Mean          -0.30565402
Policy log std Std           0.16284193
Policy log std Max           0.053237945
Policy log std Min           -1.1106629
Z mean eval                  0.028059289
Z variance eval              0.05584238
total_rewards                [4884.22069837 5200.50609965 1145.99425235 1705.45942609 1643.64926453
 5339.1350975  1608.11742666 5103.87023095 1851.79949958 5079.4214167 ]
total_rewards_mean           3356.2173412366305
total_rewards_std            1776.344127374418
total_rewards_max            5339.135097500999
total_rewards_min            1145.9942523464474
Number of train steps total  880000
Number of env steps total    1102000
Number of rollouts total     0
Train Time (s)               201.5329785142094
(Previous) Eval Time (s)     15.444613728206605
Sample Time (s)              18.04722485039383
Epoch Time (s)               235.02481709280983
Total Train Time (s)         48193.98160060728
Epoch                        219
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:53:33.069937 UTC | [2020_01_13_04_30_18] Iteration #219 | Epoch Duration: 237.03291535377502
2020-01-13 17:53:33.070196 UTC | [2020_01_13_04_30_18] Iteration #219 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027986681
Z variance train             0.055874437
KL Divergence                4.9353285
KL Loss                      0.49353287
QF Loss                      1377.0527
VF Loss                      553.18835
Policy Loss                  -1550.9246
Q Predictions Mean           1547.8934
Q Predictions Std            1010.4661
Q Predictions Max            2545.9849
Q Predictions Min            19.557514
V Predictions Mean           1557.2863
V Predictions Std            1009.77563
V Predictions Max            2544.377
V Predictions Min            26.603422
Log Pis Mean                 -4.940643
Log Pis Std                  5.9944015
Log Pis Max                  16.334515
Log Pis Min                  -12.827726
Policy mu Mean               0.16369095
Policy mu Std                0.7258951
Policy mu Max                2.6745038
Policy mu Min                -4.729936
Policy log std Mean          -0.3143702
Policy log std Std           0.16127175
Policy log std Max           -0.032838672
Policy log std Min           -1.277995
Z mean eval                  0.025982643
Z variance eval              0.057074893
total_rewards                [3057.6587515  5111.81287783 5332.02853775 5154.05226457 2648.36109416
 2316.90968053 3812.68218756 2349.22240164 5176.06540471 2337.43639496]
total_rewards_mean           3729.6229595197647
total_rewards_std            1267.5313444987087
total_rewards_max            5332.028537749655
total_rewards_min            2316.9096805283843
Number of train steps total  884000
Number of env steps total    1107000
Number of rollouts total     0
Train Time (s)               198.3948986218311
(Previous) Eval Time (s)     17.452439249958843
Sample Time (s)              16.205330254975706
Epoch Time (s)               232.05266812676564
Total Train Time (s)         48427.40363136586
Epoch                        220
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 17:57:26.497181 UTC | [2020_01_13_04_30_18] Iteration #220 | Epoch Duration: 233.42676305770874
2020-01-13 17:57:26.497479 UTC | [2020_01_13_04_30_18] Iteration #220 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026420671
Z variance train             0.05709393
KL Divergence                4.8794737
KL Loss                      0.48794737
QF Loss                      2064.947
VF Loss                      476.92572
Policy Loss                  -1578.9453
Q Predictions Mean           1567.765
Q Predictions Std            970.2981
Q Predictions Max            2538.718
Q Predictions Min            14.009533
V Predictions Mean           1575.0493
V Predictions Std            966.2286
V Predictions Max            2544.7183
V Predictions Min            21.979164
Log Pis Mean                 -4.200612
Log Pis Std                  6.61767
Log Pis Max                  23.276348
Log Pis Min                  -13.521187
Policy mu Mean               0.13347667
Policy mu Std                0.7607548
Policy mu Max                2.8358464
Policy mu Min                -3.43629
Policy log std Mean          -0.33199933
Policy log std Std           0.17686956
Policy log std Max           -0.062518045
Policy log std Min           -1.2294798
Z mean eval                  0.022718297
Z variance eval              0.05993102
total_rewards                [1536.4251404  4241.56457015 1027.0536595  5260.64636683 3671.95555876
 1344.32897814 5114.37872245 5145.52721626 5096.54884297 5151.81335883]
total_rewards_mean           3759.0242414297522
total_rewards_std            1679.8174967685268
total_rewards_max            5260.646366828977
total_rewards_min            1027.0536595047797
Number of train steps total  888000
Number of env steps total    1112000
Number of rollouts total     0
Train Time (s)               196.03925174474716
(Previous) Eval Time (s)     18.82624316494912
Sample Time (s)              18.583147454541177
Epoch Time (s)               233.44864236423746
Total Train Time (s)         48661.5176974982
Epoch                        221
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:01:20.612073 UTC | [2020_01_13_04_30_18] Iteration #221 | Epoch Duration: 234.11441731452942
2020-01-13 18:01:20.612192 UTC | [2020_01_13_04_30_18] Iteration #221 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022856815
Z variance train             0.05995658
KL Divergence                4.7761984
KL Loss                      0.47761986
QF Loss                      1604.3816
VF Loss                      490.19855
Policy Loss                  -1566.2244
Q Predictions Mean           1563.7891
Q Predictions Std            998.51
Q Predictions Max            2554.8442
Q Predictions Min            18.815802
V Predictions Mean           1567.3328
V Predictions Std            992.8556
V Predictions Max            2545.5183
V Predictions Min            30.060684
Log Pis Mean                 -4.4097786
Log Pis Std                  7.0265718
Log Pis Max                  24.313095
Log Pis Min                  -15.601037
Policy mu Mean               0.14767422
Policy mu Std                0.7526073
Policy mu Max                3.3750253
Policy mu Min                -2.9596164
Policy log std Mean          -0.32434714
Policy log std Std           0.17521887
Policy log std Max           0.07879141
Policy log std Min           -1.166002
Z mean eval                  0.029591167
Z variance eval              0.06968404
total_rewards                [4668.31258259 5241.54757371 5044.19285337 2247.78143144 5043.81311372
 2428.81219562 5193.89701476 1132.31512143  966.31294124 4434.10057043]
total_rewards_mean           3640.1085398316054
total_rewards_std            1656.8752558722103
total_rewards_max            5241.547573714026
total_rewards_min            966.3129412423235
Number of train steps total  892000
Number of env steps total    1117000
Number of rollouts total     0
Train Time (s)               194.32392651680857
(Previous) Eval Time (s)     19.491769039072096
Sample Time (s)              18.552299953531474
Epoch Time (s)               232.36799550941214
Total Train Time (s)         48893.33148791781
Epoch                        222
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:05:12.427853 UTC | [2020_01_13_04_30_18] Iteration #222 | Epoch Duration: 231.81557440757751
2020-01-13 18:05:12.427980 UTC | [2020_01_13_04_30_18] Iteration #222 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028798545
Z variance train             0.069646604
KL Divergence                4.407922
KL Loss                      0.44079217
QF Loss                      2192.1938
VF Loss                      672.3637
Policy Loss                  -1599.8817
Q Predictions Mean           1598.5566
Q Predictions Std            982.94214
Q Predictions Max            2529.6052
Q Predictions Min            17.504803
V Predictions Mean           1607.9744
V Predictions Std            982.02826
V Predictions Max            2544.6973
V Predictions Min            34.432343
Log Pis Mean                 -3.8920286
Log Pis Std                  7.548356
Log Pis Max                  27.777878
Log Pis Min                  -17.92134
Policy mu Mean               0.1451601
Policy mu Std                0.7696673
Policy mu Max                2.803778
Policy mu Min                -3.3215592
Policy log std Mean          -0.32967117
Policy log std Std           0.18491533
Policy log std Max           0.25206244
Policy log std Min           -1.2603109
Z mean eval                  0.032169826
Z variance eval              0.060780577
total_rewards                [5196.30864971 3080.67474216 5187.11566793 4141.47550889 5199.77948886
 5128.33243163 2091.04099084 3360.75512947 4601.79603    4984.12299482]
total_rewards_mean           4297.140163431058
total_rewards_std            1044.9243708741326
total_rewards_max            5199.779488860035
total_rewards_min            2091.040990838863
Number of train steps total  896000
Number of env steps total    1122000
Number of rollouts total     0
Train Time (s)               192.26013647392392
(Previous) Eval Time (s)     18.939080012962222
Sample Time (s)              17.073508868459612
Epoch Time (s)               228.27272535534576
Total Train Time (s)         49125.23420937918
Epoch                        223
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:09:04.332316 UTC | [2020_01_13_04_30_18] Iteration #223 | Epoch Duration: 231.90424370765686
2020-01-13 18:09:04.332436 UTC | [2020_01_13_04_30_18] Iteration #223 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032586295
Z variance train             0.06077661
KL Divergence                4.788181
KL Loss                      0.4788181
QF Loss                      1668.8958
VF Loss                      284.33548
Policy Loss                  -1570.3569
Q Predictions Mean           1558.6407
Q Predictions Std            1003.8327
Q Predictions Max            2537.974
Q Predictions Min            16.22626
V Predictions Mean           1568.028
V Predictions Std            1003.1137
V Predictions Max            2546.1567
V Predictions Min            25.503628
Log Pis Mean                 -4.7107916
Log Pis Std                  6.524901
Log Pis Max                  22.679321
Log Pis Min                  -14.821039
Policy mu Mean               0.12906899
Policy mu Std                0.7359305
Policy mu Max                2.8528883
Policy mu Min                -2.603762
Policy log std Mean          -0.33086562
Policy log std Std           0.17849414
Policy log std Max           0.018249571
Policy log std Min           -1.3009543
Z mean eval                  0.030522346
Z variance eval              0.06476567
total_rewards                [5182.6919746  1661.03347017 4629.09286466 3306.62416798 5228.66095538
 5195.69592221 5212.73316954 5210.45241437 5206.6992632  5184.26612838]
total_rewards_mean           4601.795033049185
total_rewards_std            1133.9445593805365
total_rewards_max            5228.660955383703
total_rewards_min            1661.0334701665502
Number of train steps total  900000
Number of env steps total    1127000
Number of rollouts total     0
Train Time (s)               193.84226909698918
(Previous) Eval Time (s)     22.57032898813486
Sample Time (s)              18.546316056046635
Epoch Time (s)               234.95891414117068
Total Train Time (s)         49358.91444628686
Epoch                        224
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:12:58.019517 UTC | [2020_01_13_04_30_18] Iteration #224 | Epoch Duration: 233.68693256378174
2020-01-13 18:12:58.019837 UTC | [2020_01_13_04_30_18] Iteration #224 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030498903
Z variance train             0.06475716
KL Divergence                4.611391
KL Loss                      0.4611391
QF Loss                      2097.5684
VF Loss                      379.6559
Policy Loss                  -1713.9003
Q Predictions Mean           1707.3354
Q Predictions Std            956.0468
Q Predictions Max            2546.997
Q Predictions Min            20.095497
V Predictions Mean           1713.7483
V Predictions Std            956.14844
V Predictions Max            2564.175
V Predictions Min            33.507633
Log Pis Mean                 -4.6532707
Log Pis Std                  5.759521
Log Pis Max                  14.796358
Log Pis Min                  -15.827635
Policy mu Mean               0.18292737
Policy mu Std                0.724473
Policy mu Max                2.3320627
Policy mu Min                -3.161502
Policy log std Mean          -0.32759437
Policy log std Std           0.16545714
Policy log std Max           0.045621872
Policy log std Min           -1.2166214
Z mean eval                  0.022381049
Z variance eval              0.066644594
total_rewards                [4942.33702764 3155.21880264 5229.35813773 2604.04153366 5208.65340114
 5227.78884085  574.32558155 5089.15228361 5108.14652192 5193.88159492]
total_rewards_mean           4233.290372565536
total_rewards_std            1518.5710458507858
total_rewards_max            5229.358137727923
total_rewards_min            574.3255815482703
Number of train steps total  904000
Number of env steps total    1132000
Number of rollouts total     0
Train Time (s)               191.8535777963698
(Previous) Eval Time (s)     21.298050378914922
Sample Time (s)              19.22119500208646
Epoch Time (s)               232.37282317737117
Total Train Time (s)         49591.34624620201
Epoch                        225
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:16:50.454502 UTC | [2020_01_13_04_30_18] Iteration #225 | Epoch Duration: 232.43436193466187
2020-01-13 18:16:50.454767 UTC | [2020_01_13_04_30_18] Iteration #225 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022790255
Z variance train             0.06659448
KL Divergence                4.5660768
KL Loss                      0.45660767
QF Loss                      2295.2622
VF Loss                      455.42596
Policy Loss                  -1615.475
Q Predictions Mean           1610.7969
Q Predictions Std            974.1773
Q Predictions Max            2547.0093
Q Predictions Min            21.407928
V Predictions Mean           1608.5242
V Predictions Std            970.4459
V Predictions Max            2541.883
V Predictions Min            31.640188
Log Pis Mean                 -4.775142
Log Pis Std                  5.8057594
Log Pis Max                  16.523834
Log Pis Min                  -14.599743
Policy mu Mean               0.17665793
Policy mu Std                0.72654045
Policy mu Max                2.4598277
Policy mu Min                -3.311184
Policy log std Mean          -0.32105705
Policy log std Std           0.16369706
Policy log std Max           0.06021315
Policy log std Min           -1.0910908
Z mean eval                  0.025756925
Z variance eval              0.07313083
total_rewards                [5272.06719362 5191.88562385 5233.77710243 2350.01431133 5257.32941387
 1201.30842045 5171.14183268 5102.31883934 5203.47129952 1102.4501215 ]
total_rewards_mean           4108.576415860352
total_rewards_std            1703.228901567974
total_rewards_max            5272.067193624946
total_rewards_min            1102.4501215002165
Number of train steps total  908000
Number of env steps total    1137000
Number of rollouts total     0
Train Time (s)               194.5690573048778
(Previous) Eval Time (s)     21.359274392947555
Sample Time (s)              19.10664426209405
Epoch Time (s)               235.0349759599194
Total Train Time (s)         49824.508075858
Epoch                        226
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:20:43.622730 UTC | [2020_01_13_04_30_18] Iteration #226 | Epoch Duration: 233.1677703857422
2020-01-13 18:20:43.623047 UTC | [2020_01_13_04_30_18] Iteration #226 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025482828
Z variance train             0.0731705
KL Divergence                4.3458343
KL Loss                      0.43458343
QF Loss                      2644.4214
VF Loss                      765.54297
Policy Loss                  -1595.0543
Q Predictions Mean           1592.0712
Q Predictions Std            979.86554
Q Predictions Max            2541.157
Q Predictions Min            12.1906395
V Predictions Mean           1594.2576
V Predictions Std            978.63776
V Predictions Max            2560.922
V Predictions Min            27.220531
Log Pis Mean                 -4.0236626
Log Pis Std                  7.010575
Log Pis Max                  28.801275
Log Pis Min                  -15.399202
Policy mu Mean               0.17993589
Policy mu Std                0.75910854
Policy mu Max                2.8104932
Policy mu Min                -2.7205496
Policy log std Mean          -0.34065136
Policy log std Std           0.17878577
Policy log std Max           0.008724138
Policy log std Min           -1.2445045
Z mean eval                  0.027036224
Z variance eval              0.070035756
total_rewards                [5261.62169845 5186.12702965 5198.76146354 5245.31602033 5327.82936061
 1883.40801847 5338.67154579 5238.68197559 5261.76283392 5143.53920109]
total_rewards_mean           4908.571914743259
total_rewards_std            1009.9798393850325
total_rewards_max            5338.671545788458
total_rewards_min            1883.4080184684599
Number of train steps total  912000
Number of env steps total    1142000
Number of rollouts total     0
Train Time (s)               190.2531187213026
(Previous) Eval Time (s)     19.491669775918126
Sample Time (s)              18.91640243353322
Epoch Time (s)               228.66119093075395
Total Train Time (s)         50058.9406146761
Epoch                        227
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:24:38.058936 UTC | [2020_01_13_04_30_18] Iteration #227 | Epoch Duration: 234.43561339378357
2020-01-13 18:24:38.059138 UTC | [2020_01_13_04_30_18] Iteration #227 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027753448
Z variance train             0.070023626
KL Divergence                4.417348
KL Loss                      0.4417348
QF Loss                      1710.64
VF Loss                      667.6038
Policy Loss                  -1558.7465
Q Predictions Mean           1548.5425
Q Predictions Std            1007.3518
Q Predictions Max            2569.7673
Q Predictions Min            17.110615
V Predictions Mean           1549.8738
V Predictions Std            1001.809
V Predictions Max            2569.6567
V Predictions Min            26.814697
Log Pis Mean                 -4.262573
Log Pis Std                  6.8753877
Log Pis Max                  22.488037
Log Pis Min                  -15.383486
Policy mu Mean               0.16669142
Policy mu Std                0.75582474
Policy mu Max                3.1904693
Policy mu Min                -3.0747602
Policy log std Mean          -0.32232064
Policy log std Std           0.18072022
Policy log std Max           0.04179509
Policy log std Min           -1.2295318
Z mean eval                  0.02916335
Z variance eval              0.072091766
total_rewards                [5187.81159198 3929.03858748 3360.6871723  5182.68003999 1150.58786412
 5127.11506571 5189.32822502 5180.42690397 5159.01611879 5285.61719053]
total_rewards_mean           4475.230875987977
total_rewards_std            1271.161599951971
total_rewards_max            5285.617190531297
total_rewards_min            1150.5878641188774
Number of train steps total  916000
Number of env steps total    1147000
Number of rollouts total     0
Train Time (s)               194.04764792928472
(Previous) Eval Time (s)     25.265820171684027
Sample Time (s)              18.966933802701533
Epoch Time (s)               238.28040190367028
Total Train Time (s)         50294.7524454114
Epoch                        228
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:28:33.874652 UTC | [2020_01_13_04_30_18] Iteration #228 | Epoch Duration: 235.81539154052734
2020-01-13 18:28:33.874836 UTC | [2020_01_13_04_30_18] Iteration #228 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02949942
Z variance train             0.07209189
KL Divergence                4.281828
KL Loss                      0.4281828
QF Loss                      4647.4727
VF Loss                      849.44214
Policy Loss                  -1637.9062
Q Predictions Mean           1631.0542
Q Predictions Std            984.2296
Q Predictions Max            2585.4053
Q Predictions Min            17.10577
V Predictions Mean           1647.6664
V Predictions Std            987.06885
V Predictions Max            2595.777
V Predictions Min            20.23019
Log Pis Mean                 -4.87633
Log Pis Std                  6.249547
Log Pis Max                  18.75656
Log Pis Min                  -14.93581
Policy mu Mean               0.13001065
Policy mu Std                0.7374836
Policy mu Max                2.8186967
Policy mu Min                -3.7422123
Policy log std Mean          -0.31692287
Policy log std Std           0.1696808
Policy log std Max           0.14094202
Policy log std Min           -1.2548412
Z mean eval                  0.033908494
Z variance eval              0.0683057
total_rewards                [5288.44979777 5212.54773676 5164.83194001 5163.27816418 5303.64689048
 4600.2944894  5205.90113639 2457.99700752 2383.53402933 5315.35754776]
total_rewards_mean           4609.583873960203
total_rewards_std            1111.7304807603439
total_rewards_max            5315.357547763566
total_rewards_min            2383.5340293254117
Number of train steps total  920000
Number of env steps total    1152000
Number of rollouts total     0
Train Time (s)               197.43056913930923
(Previous) Eval Time (s)     22.80052772304043
Sample Time (s)              18.67950431536883
Epoch Time (s)               238.9106011777185
Total Train Time (s)         50534.161977114156
Epoch                        229
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:32:33.285717 UTC | [2020_01_13_04_30_18] Iteration #229 | Epoch Duration: 239.41075682640076
2020-01-13 18:32:33.285832 UTC | [2020_01_13_04_30_18] Iteration #229 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03409426
Z variance train             0.06831804
KL Divergence                4.4624996
KL Loss                      0.44624996
QF Loss                      2191.348
VF Loss                      940.881
Policy Loss                  -1668.9047
Q Predictions Mean           1661.8679
Q Predictions Std            996.6215
Q Predictions Max            2594.4922
Q Predictions Min            18.496471
V Predictions Mean           1661.0459
V Predictions Std            989.5964
V Predictions Max            2577.6997
V Predictions Min            29.63235
Log Pis Mean                 -4.572477
Log Pis Std                  6.6296554
Log Pis Max                  22.821743
Log Pis Min                  -13.44433
Policy mu Mean               0.1767142
Policy mu Std                0.7413529
Policy mu Max                3.4695287
Policy mu Min                -3.1231277
Policy log std Mean          -0.32661375
Policy log std Std           0.17004201
Policy log std Max           -0.023929805
Policy log std Min           -1.0786768
Z mean eval                  0.027831424
Z variance eval              0.07023739
total_rewards                [2565.07051749 5178.38107945 5290.01818331 5295.18302374 1548.65429297
 5230.04549675 5294.7063415   676.98428542 5278.43817529 4298.15632402]
total_rewards_mean           4065.5637719943225
total_rewards_std            1694.4135119736115
total_rewards_max            5295.183023741244
total_rewards_min            676.9842854223529
Number of train steps total  924000
Number of env steps total    1157000
Number of rollouts total     0
Train Time (s)               194.15365136694163
(Previous) Eval Time (s)     23.30042302981019
Sample Time (s)              18.564397404436022
Epoch Time (s)               236.01847180118784
Total Train Time (s)         50767.78947683936
Epoch                        230
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:36:26.914844 UTC | [2020_01_13_04_30_18] Iteration #230 | Epoch Duration: 233.6289255619049
2020-01-13 18:36:26.914960 UTC | [2020_01_13_04_30_18] Iteration #230 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028277561
Z variance train             0.0702244
KL Divergence                4.404754
KL Loss                      0.44047543
QF Loss                      1776.3844
VF Loss                      705.24725
Policy Loss                  -1694.2701
Q Predictions Mean           1687.8276
Q Predictions Std            1025.0747
Q Predictions Max            2594.825
Q Predictions Min            11.469755
V Predictions Mean           1681.6208
V Predictions Std            1014.5978
V Predictions Max            2587.0735
V Predictions Min            24.714138
Log Pis Mean                 -4.3590965
Log Pis Std                  6.903856
Log Pis Max                  29.060555
Log Pis Min                  -13.26964
Policy mu Mean               0.19946286
Policy mu Std                0.7274735
Policy mu Max                3.0216644
Policy mu Min                -2.9855783
Policy log std Mean          -0.3161412
Policy log std Std           0.16611712
Policy log std Max           0.012381256
Policy log std Min           -1.1404066
Z mean eval                  0.03926285
Z variance eval              0.06731735
total_rewards                [5198.6528149  2294.10996595 4389.71100471 3633.63885132 5228.94903412
 4951.31047209 3108.00638853 3240.35715814 1896.35181218 5344.34850527]
total_rewards_mean           3928.5436007207963
total_rewards_std            1208.4076366014317
total_rewards_max            5344.348505269352
total_rewards_min            1896.3518121841673
Number of train steps total  928000
Number of env steps total    1162000
Number of rollouts total     0
Train Time (s)               192.9240882010199
(Previous) Eval Time (s)     20.910614942200482
Sample Time (s)              18.916460300330073
Epoch Time (s)               232.75116344355047
Total Train Time (s)         50997.47566876514
Epoch                        231
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:40:16.603950 UTC | [2020_01_13_04_30_18] Iteration #231 | Epoch Duration: 229.68888926506042
2020-01-13 18:40:16.604124 UTC | [2020_01_13_04_30_18] Iteration #231 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038656436
Z variance train             0.06729342
KL Divergence                4.491128
KL Loss                      0.4491128
QF Loss                      1794.468
VF Loss                      623.7666
Policy Loss                  -1774.1427
Q Predictions Mean           1770.1487
Q Predictions Std            968.3062
Q Predictions Max            2596.0603
Q Predictions Min            21.180485
V Predictions Mean           1777.4435
V Predictions Std            967.8605
V Predictions Max            2597.0918
V Predictions Min            30.11148
Log Pis Mean                 -3.7361498
Log Pis Std                  7.388264
Log Pis Max                  41.319115
Log Pis Min                  -14.733582
Policy mu Mean               0.17283028
Policy mu Std                0.7885661
Policy mu Max                4.475828
Policy mu Min                -4.8257136
Policy log std Mean          -0.3338605
Policy log std Std           0.17159726
Policy log std Max           0.6339899
Policy log std Min           -1.17984
Z mean eval                  0.036266964
Z variance eval              0.07373874
total_rewards                [5181.05327216 5112.05118713 4268.35760592 5165.65023699 5180.80680138
 5152.02304977 3786.71238524 5222.03560514 5139.64837145 5105.41507897]
total_rewards_mean           4931.375359413044
total_rewards_std            465.7000855122609
total_rewards_max            5222.035605135187
total_rewards_min            3786.712385236301
Number of train steps total  932000
Number of env steps total    1167000
Number of rollouts total     0
Train Time (s)               189.04813032597303
(Previous) Eval Time (s)     17.848051322624087
Sample Time (s)              18.685373421292752
Epoch Time (s)               225.58155506988987
Total Train Time (s)         51230.27617523121
Epoch                        232
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:44:09.407305 UTC | [2020_01_13_04_30_18] Iteration #232 | Epoch Duration: 232.80305767059326
2020-01-13 18:44:09.407468 UTC | [2020_01_13_04_30_18] Iteration #232 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036594357
Z variance train             0.07366094
KL Divergence                4.431426
KL Loss                      0.44314262
QF Loss                      2146.5469
VF Loss                      308.38757
Policy Loss                  -1647.6516
Q Predictions Mean           1646.9243
Q Predictions Std            1022.373
Q Predictions Max            2604.6602
Q Predictions Min            20.865152
V Predictions Mean           1648.1648
V Predictions Std            1018.2167
V Predictions Max            2593.4758
V Predictions Min            25.24499
Log Pis Mean                 -4.9527206
Log Pis Std                  6.1873384
Log Pis Max                  24.876877
Log Pis Min                  -15.033293
Policy mu Mean               0.1658085
Policy mu Std                0.7117305
Policy mu Max                2.9186463
Policy mu Min                -2.7640235
Policy log std Mean          -0.30901864
Policy log std Std           0.17090532
Policy log std Max           -0.012931757
Policy log std Min           -1.2094831
Z mean eval                  0.027164703
Z variance eval              0.072588444
total_rewards                [2803.03502878 4046.76186056 5214.05886373 4177.90632857 4517.02819941
 5241.45403425 5025.98746508 5221.66988175 5252.31014859 2377.5024755 ]
total_rewards_mean           4387.771428622516
total_rewards_std            999.5632733152811
total_rewards_max            5252.310148589052
total_rewards_min            2377.502475499435
Number of train steps total  936000
Number of env steps total    1172000
Number of rollouts total     0
Train Time (s)               200.44490332482383
(Previous) Eval Time (s)     25.069283518008888
Sample Time (s)              18.75907072564587
Epoch Time (s)               244.27325756847858
Total Train Time (s)         51470.39596623136
Epoch                        233
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:48:09.531529 UTC | [2020_01_13_04_30_18] Iteration #233 | Epoch Duration: 240.12394189834595
2020-01-13 18:48:09.531680 UTC | [2020_01_13_04_30_18] Iteration #233 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027203023
Z variance train             0.07253697
KL Divergence                4.307274
KL Loss                      0.4307274
QF Loss                      1505.3555
VF Loss                      536.782
Policy Loss                  -1676.4606
Q Predictions Mean           1666.1201
Q Predictions Std            1007.4867
Q Predictions Max            2591.6401
Q Predictions Min            14.489126
V Predictions Mean           1673.4307
V Predictions Std            1003.9383
V Predictions Max            2594.4983
V Predictions Min            29.468529
Log Pis Mean                 -4.2808876
Log Pis Std                  7.220977
Log Pis Max                  21.188442
Log Pis Min                  -13.059818
Policy mu Mean               0.1805734
Policy mu Std                0.75246495
Policy mu Max                3.0888438
Policy mu Min                -3.2141454
Policy log std Mean          -0.32050502
Policy log std Std           0.17227282
Policy log std Max           -0.04991789
Policy log std Min           -1.3227892
Z mean eval                  0.02385379
Z variance eval              0.07599365
total_rewards                [5193.31486618 5313.42300856 5252.2351152  5217.34713243 5094.18610041
 1584.54786276 2966.73022879 1117.31823661 5262.91445369 2860.32379042]
total_rewards_mean           3986.234079505767
total_rewards_std            1596.8775716043888
total_rewards_max            5313.423008564848
total_rewards_min            1117.3182366129035
Number of train steps total  940000
Number of env steps total    1177000
Number of rollouts total     0
Train Time (s)               194.2397967572324
(Previous) Eval Time (s)     20.91968468297273
Sample Time (s)              16.678340250160545
Epoch Time (s)               231.83782169036567
Total Train Time (s)         51701.5436383402
Epoch                        234
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:52:00.682407 UTC | [2020_01_13_04_30_18] Iteration #234 | Epoch Duration: 231.1505994796753
2020-01-13 18:52:00.682595 UTC | [2020_01_13_04_30_18] Iteration #234 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0233659
Z variance train             0.07598546
KL Divergence                4.2509604
KL Loss                      0.42509604
QF Loss                      2114.714
VF Loss                      584.1747
Policy Loss                  -1662.7218
Q Predictions Mean           1655.2078
Q Predictions Std            990.4896
Q Predictions Max            2600.1782
Q Predictions Min            20.4343
V Predictions Mean           1665.7715
V Predictions Std            991.20483
V Predictions Max            2616.8496
V Predictions Min            26.99317
Log Pis Mean                 -3.7379756
Log Pis Std                  6.815457
Log Pis Max                  16.614384
Log Pis Min                  -14.210913
Policy mu Mean               0.18498324
Policy mu Std                0.77207273
Policy mu Max                2.8948643
Policy mu Min                -3.0577893
Policy log std Mean          -0.31869292
Policy log std Std           0.16769889
Policy log std Max           -0.02162192
Policy log std Min           -1.1301392
Z mean eval                  0.028945109
Z variance eval              0.06996134
total_rewards                [5077.26919272  757.26913883 5186.16034064 4882.48696864 3907.09957724
 2607.7365897  5024.38386452 5378.26978313 1242.66764511 5084.72226244]
total_rewards_mean           3914.806536296054
total_rewards_std            1657.242124243259
total_rewards_max            5378.26978312646
total_rewards_min            757.2691388262829
Number of train steps total  944000
Number of env steps total    1182000
Number of rollouts total     0
Train Time (s)               191.46188399707898
(Previous) Eval Time (s)     20.232202591374516
Sample Time (s)              16.633310437668115
Epoch Time (s)               228.32739702612162
Total Train Time (s)         51929.88087988924
Epoch                        235
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:55:49.035437 UTC | [2020_01_13_04_30_18] Iteration #235 | Epoch Duration: 228.352721452713
2020-01-13 18:55:49.035562 UTC | [2020_01_13_04_30_18] Iteration #235 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028780704
Z variance train             0.070007004
KL Divergence                4.4046216
KL Loss                      0.44046217
QF Loss                      2162.1184
VF Loss                      508.12415
Policy Loss                  -1754.9316
Q Predictions Mean           1746.7084
Q Predictions Std            983.3782
Q Predictions Max            2602.112
Q Predictions Min            12.459283
V Predictions Mean           1757.6332
V Predictions Std            984.1216
V Predictions Max            2618.2874
V Predictions Min            30.067062
Log Pis Mean                 -4.2276454
Log Pis Std                  6.9516654
Log Pis Max                  31.38881
Log Pis Min                  -14.440243
Policy mu Mean               0.19889209
Policy mu Std                0.73885185
Policy mu Max                2.9469156
Policy mu Min                -3.114006
Policy log std Mean          -0.32293728
Policy log std Std           0.1728811
Policy log std Max           0.2129129
Policy log std Min           -1.2482983
Z mean eval                  0.02550866
Z variance eval              0.07527326
total_rewards                [5213.42726982 4087.04233401 3555.40964787 1468.02287925 1041.07619122
  931.6422517  5047.61344319 5315.40797803 5275.58092458 5355.40328589]
total_rewards_mean           3729.062620556039
total_rewards_std            1783.7193279152611
total_rewards_max            5355.403285887881
total_rewards_min            931.6422517030272
Number of train steps total  948000
Number of env steps total    1187000
Number of rollouts total     0
Train Time (s)               195.04016679292545
(Previous) Eval Time (s)     20.257256750017405
Sample Time (s)              18.529955346602947
Epoch Time (s)               233.8273788895458
Total Train Time (s)         52163.02221961878
Epoch                        236
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 18:59:42.164390 UTC | [2020_01_13_04_30_18] Iteration #236 | Epoch Duration: 233.12873363494873
2020-01-13 18:59:42.164523 UTC | [2020_01_13_04_30_18] Iteration #236 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02507015
Z variance train             0.07526455
KL Divergence                4.324898
KL Loss                      0.43248978
QF Loss                      2053.2134
VF Loss                      682.1714
Policy Loss                  -1828.3162
Q Predictions Mean           1825.3848
Q Predictions Std            962.0055
Q Predictions Max            2606.6055
Q Predictions Min            18.084476
V Predictions Mean           1840.8986
V Predictions Std            963.4502
V Predictions Max            2610.1267
V Predictions Min            24.00674
Log Pis Mean                 -4.001581
Log Pis Std                  6.5906897
Log Pis Max                  17.933632
Log Pis Min                  -13.174337
Policy mu Mean               0.13733155
Policy mu Std                0.7719442
Policy mu Max                3.880275
Policy mu Min                -2.9029813
Policy log std Mean          -0.32932478
Policy log std Std           0.168898
Policy log std Max           0.11137313
Policy log std Min           -1.238583
Z mean eval                  0.030960793
Z variance eval              0.07610242
total_rewards                [5135.02382156 5197.39795709 5219.82911585 5200.48442325 5158.07813958
 1515.94379901 2513.47229196 5234.51479377 5212.22052999 5068.06373973]
total_rewards_mean           4545.502861179148
total_rewards_std            1285.735723439077
total_rewards_max            5234.514793768769
total_rewards_min            1515.9437990073777
Number of train steps total  952000
Number of env steps total    1192000
Number of rollouts total     0
Train Time (s)               191.84245882602409
(Previous) Eval Time (s)     19.55834267800674
Sample Time (s)              17.585425106342882
Epoch Time (s)               228.9862266103737
Total Train Time (s)         52396.3315330199
Epoch                        237
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:03:35.479434 UTC | [2020_01_13_04_30_18] Iteration #237 | Epoch Duration: 233.3148000240326
2020-01-13 19:03:35.479615 UTC | [2020_01_13_04_30_18] Iteration #237 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030809503
Z variance train             0.076095745
KL Divergence                4.295726
KL Loss                      0.42957258
QF Loss                      2632.869
VF Loss                      530.7904
Policy Loss                  -1740.4629
Q Predictions Mean           1732.407
Q Predictions Std            970.88995
Q Predictions Max            2620.0073
Q Predictions Min            18.448006
V Predictions Mean           1737.8765
V Predictions Std            966.89056
V Predictions Max            2613.0657
V Predictions Min            29.12812
Log Pis Mean                 -3.867502
Log Pis Std                  6.5346117
Log Pis Max                  24.854437
Log Pis Min                  -13.415157
Policy mu Mean               0.18443823
Policy mu Std                0.7852331
Policy mu Max                2.993628
Policy mu Min                -3.0391006
Policy log std Mean          -0.34244525
Policy log std Std           0.17114101
Policy log std Max           -0.034232385
Policy log std Min           -1.0447137
Z mean eval                  0.034860294
Z variance eval              0.08100432
total_rewards                [5149.87076368 5092.48956796 5202.21377748 4070.01907745 1804.5806525
 5166.26505908 5071.92846939 5250.50691651 5090.53375877  906.90328909]
total_rewards_mean           4280.531133190859
total_rewards_std            1510.9046738142908
total_rewards_max            5250.506916512216
total_rewards_min            906.9032890913286
Number of train steps total  956000
Number of env steps total    1197000
Number of rollouts total     0
Train Time (s)               193.41384918708354
(Previous) Eval Time (s)     23.886637852992862
Sample Time (s)              18.702087147627026
Epoch Time (s)               236.00257418770343
Total Train Time (s)         52631.13936247025
Epoch                        238
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:07:30.285967 UTC | [2020_01_13_04_30_18] Iteration #238 | Epoch Duration: 234.80623149871826
2020-01-13 19:07:30.286091 UTC | [2020_01_13_04_30_18] Iteration #238 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035041798
Z variance train             0.08100796
KL Divergence                4.140195
KL Loss                      0.4140195
QF Loss                      2548.4473
VF Loss                      664.1365
Policy Loss                  -1815.9052
Q Predictions Mean           1812.8396
Q Predictions Std            937.4304
Q Predictions Max            2633.0928
Q Predictions Min            18.406452
V Predictions Mean           1815.3794
V Predictions Std            935.33826
V Predictions Max            2627.8794
V Predictions Min            29.716957
Log Pis Mean                 -3.6918468
Log Pis Std                  7.1639347
Log Pis Max                  26.561077
Log Pis Min                  -15.937167
Policy mu Mean               0.20551634
Policy mu Std                0.7799483
Policy mu Max                3.7218704
Policy mu Min                -3.1034513
Policy log std Mean          -0.34074515
Policy log std Std           0.18656252
Policy log std Max           0.020404994
Policy log std Min           -1.4174292
Z mean eval                  0.03400268
Z variance eval              0.07339479
total_rewards                [5275.57576403 5230.75694851 5246.01351938 5072.58672882 5235.0943826
 5221.94159694 5240.2266179  5302.78270888 2649.31902541 5172.42159622]
total_rewards_mean           4964.671888867319
total_rewards_std            774.0701124994898
total_rewards_max            5302.782708877646
total_rewards_min            2649.319025405274
Number of train steps total  960000
Number of env steps total    1202000
Number of rollouts total     0
Train Time (s)               196.9460354950279
(Previous) Eval Time (s)     22.690043415874243
Sample Time (s)              16.85987870208919
Epoch Time (s)               236.49595761299133
Total Train Time (s)         52870.47572283633
Epoch                        239
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:11:29.624477 UTC | [2020_01_13_04_30_18] Iteration #239 | Epoch Duration: 239.33829593658447
2020-01-13 19:11:29.624607 UTC | [2020_01_13_04_30_18] Iteration #239 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034296215
Z variance train             0.07337162
KL Divergence                4.323822
KL Loss                      0.4323822
QF Loss                      1988.0251
VF Loss                      601.9241
Policy Loss                  -1771.5192
Q Predictions Mean           1761.903
Q Predictions Std            941.84784
Q Predictions Max            2622.134
Q Predictions Min            21.86261
V Predictions Mean           1769.4956
V Predictions Std            938.62024
V Predictions Max            2622.0872
V Predictions Min            22.958668
Log Pis Mean                 -3.42694
Log Pis Std                  7.165193
Log Pis Max                  35.15972
Log Pis Min                  -15.814619
Policy mu Mean               0.18179066
Policy mu Std                0.7965899
Policy mu Max                3.3809612
Policy mu Min                -4.321704
Policy log std Mean          -0.33858687
Policy log std Std           0.1738065
Policy log std Max           -0.01937177
Policy log std Min           -1.6770794
Z mean eval                  0.03402402
Z variance eval              0.066175655
total_rewards                [5335.59617061 5217.59786252 5261.28597983 5309.1585917  5317.3931714
 5232.02884439 5237.22139839 5254.11052254 3811.09569963 5136.9791006 ]
total_rewards_mean           5111.246734160564
total_rewards_std            436.7772118361244
total_rewards_max            5335.596170606103
total_rewards_min            3811.095699632908
Number of train steps total  964000
Number of env steps total    1207000
Number of rollouts total     0
Train Time (s)               196.15287707420066
(Previous) Eval Time (s)     25.532088238745928
Sample Time (s)              17.437953961547464
Epoch Time (s)               239.12291927449405
Total Train Time (s)         53108.07470029732
Epoch                        240
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:15:27.230110 UTC | [2020_01_13_04_30_18] Iteration #240 | Epoch Duration: 237.6053524017334
2020-01-13 19:15:27.230409 UTC | [2020_01_13_04_30_18] Iteration #240 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03432835
Z variance train             0.06616259
KL Divergence                4.543846
KL Loss                      0.45438462
QF Loss                      1495.77
VF Loss                      240.24576
Policy Loss                  -1741.8533
Q Predictions Mean           1731.2124
Q Predictions Std            1047.3646
Q Predictions Max            2646.4075
Q Predictions Min            13.0135565
V Predictions Mean           1738.7836
V Predictions Std            1044.3916
V Predictions Max            2640.5754
V Predictions Min            27.55123
Log Pis Mean                 -4.788378
Log Pis Std                  6.3915596
Log Pis Max                  23.01228
Log Pis Min                  -14.115253
Policy mu Mean               0.19787264
Policy mu Std                0.7188829
Policy mu Max                3.6039245
Policy mu Min                -3.2399228
Policy log std Mean          -0.32863942
Policy log std Std           0.16378526
Policy log std Max           -0.08832088
Policy log std Min           -1.062667
Z mean eval                  0.029849142
Z variance eval              0.06879364
total_rewards                [ 692.88764854 5145.62120748 5239.03810378 5189.94844574 5151.08889436
 5249.48888261 1379.42138776 5109.71211661 5219.99615116 5255.93116289]
total_rewards_mean           4363.313400092987
total_rewards_std            1671.2732142127259
total_rewards_max            5255.93116289179
total_rewards_min            692.8876485355067
Number of train steps total  968000
Number of env steps total    1212000
Number of rollouts total     0
Train Time (s)               197.18295959662646
(Previous) Eval Time (s)     24.01423435518518
Sample Time (s)              18.89645877899602
Epoch Time (s)               240.09365273080766
Total Train Time (s)         53347.32023004023
Epoch                        241
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:19:26.476736 UTC | [2020_01_13_04_30_18] Iteration #241 | Epoch Duration: 239.24613285064697
2020-01-13 19:19:26.476882 UTC | [2020_01_13_04_30_18] Iteration #241 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03000476
Z variance train             0.06878577
KL Divergence                4.4737554
KL Loss                      0.44737554
QF Loss                      2252.6033
VF Loss                      432.73355
Policy Loss                  -1693.895
Q Predictions Mean           1683.9562
Q Predictions Std            1049.4653
Q Predictions Max            2610.0938
Q Predictions Min            20.942049
V Predictions Mean           1697.951
V Predictions Std            1050.3826
V Predictions Max            2619.399
V Predictions Min            25.599024
Log Pis Mean                 -4.1965933
Log Pis Std                  6.8476853
Log Pis Max                  33.70034
Log Pis Min                  -13.019789
Policy mu Mean               0.18050203
Policy mu Std                0.7387586
Policy mu Max                3.1128125
Policy mu Min                -4.097527
Policy log std Mean          -0.3293795
Policy log std Std           0.18147722
Policy log std Max           0.35254747
Policy log std Min           -1.4235278
Z mean eval                  0.031903766
Z variance eval              0.059446223
total_rewards                [5254.01620247 1438.11656388 5208.74428581 5054.61543263 5016.45353012
 1199.668957   5207.61914245 5208.78750435 2457.93811832 5265.8673991 ]
total_rewards_mean           4131.182713613297
total_rewards_std            1622.09459848186
total_rewards_max            5265.8673991041705
total_rewards_min            1199.6689570033586
Number of train steps total  972000
Number of env steps total    1217000
Number of rollouts total     0
Train Time (s)               196.6955616660416
(Previous) Eval Time (s)     23.16644214000553
Sample Time (s)              17.04173915879801
Epoch Time (s)               236.90374296484515
Total Train Time (s)         53580.44468248775
Epoch                        242
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:23:19.606255 UTC | [2020_01_13_04_30_18] Iteration #242 | Epoch Duration: 233.12926697731018
2020-01-13 19:23:19.606409 UTC | [2020_01_13_04_30_18] Iteration #242 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031723507
Z variance train             0.05943356
KL Divergence                4.8700833
KL Loss                      0.48700833
QF Loss                      2241.0369
VF Loss                      638.4838
Policy Loss                  -1921.6411
Q Predictions Mean           1917.979
Q Predictions Std            904.9868
Q Predictions Max            2636.3264
Q Predictions Min            19.85347
V Predictions Mean           1926.7283
V Predictions Std            902.1746
V Predictions Max            2637.5962
V Predictions Min            26.801182
Log Pis Mean                 -3.7893798
Log Pis Std                  6.7124124
Log Pis Max                  27.361252
Log Pis Min                  -14.396205
Policy mu Mean               0.1554964
Policy mu Std                0.7845079
Policy mu Max                3.1467175
Policy mu Min                -3.4373398
Policy log std Mean          -0.34077445
Policy log std Std           0.16825908
Policy log std Max           -0.025957815
Policy log std Min           -1.5702044
Z mean eval                  0.03136296
Z variance eval              0.051523864
total_rewards                [1640.30004181 5430.8747058  5352.02057227 5129.81062395 5301.80715926
 5366.27517152 5363.16698662 3874.04523223 5430.21665611 5399.49348452]
total_rewards_mean           4828.801063410539
total_rewards_std            1152.844578463278
total_rewards_max            5430.874705803334
total_rewards_min            1640.3000418082229
Number of train steps total  976000
Number of env steps total    1222000
Number of rollouts total     0
Train Time (s)               192.55726090585813
(Previous) Eval Time (s)     19.391691379714757
Sample Time (s)              16.626721613574773
Epoch Time (s)               228.57567389914766
Total Train Time (s)         53813.72254307382
Epoch                        243
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:27:12.888334 UTC | [2020_01_13_04_30_18] Iteration #243 | Epoch Duration: 233.28178548812866
2020-01-13 19:27:12.888601 UTC | [2020_01_13_04_30_18] Iteration #243 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03095006
Z variance train             0.051543962
KL Divergence                5.159976
KL Loss                      0.5159976
QF Loss                      2205.9668
VF Loss                      573.2117
Policy Loss                  -1814.346
Q Predictions Mean           1811.935
Q Predictions Std            979.8847
Q Predictions Max            2623.7693
Q Predictions Min            20.925674
V Predictions Mean           1824.0503
V Predictions Std            980.68585
V Predictions Max            2638.377
V Predictions Min            23.036888
Log Pis Mean                 -4.060231
Log Pis Std                  6.159665
Log Pis Max                  25.644344
Log Pis Min                  -16.220188
Policy mu Mean               0.20913851
Policy mu Std                0.74905956
Policy mu Max                3.2606394
Policy mu Min                -4.1328473
Policy log std Mean          -0.33216178
Policy log std Std           0.16014509
Policy log std Max           -0.021976545
Policy log std Min           -1.0995524
Z mean eval                  0.03250101
Z variance eval              0.04830565
total_rewards                [5236.86577431 5112.11044624 4166.52170209 5256.777173   1243.08232542
 2709.55263105 1373.68194106 5258.34618567 5188.90604329 5310.35548538]
total_rewards_mean           4085.619970750602
total_rewards_std            1586.7544661412992
total_rewards_max            5310.355485379472
total_rewards_min            1243.0823254236254
Number of train steps total  980000
Number of env steps total    1227000
Number of rollouts total     0
Train Time (s)               194.2271006172523
(Previous) Eval Time (s)     24.09752856893465
Sample Time (s)              19.10556317633018
Epoch Time (s)               237.43019236251712
Total Train Time (s)         54048.53244009428
Epoch                        244
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:31:07.703842 UTC | [2020_01_13_04_30_18] Iteration #244 | Epoch Duration: 234.8149824142456
2020-01-13 19:31:07.704216 UTC | [2020_01_13_04_30_18] Iteration #244 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032574523
Z variance train             0.04827947
KL Divergence                5.332695
KL Loss                      0.5332695
QF Loss                      1759.324
VF Loss                      570.007
Policy Loss                  -1823.2124
Q Predictions Mean           1815.2424
Q Predictions Std            989.5081
Q Predictions Max            2635.9075
Q Predictions Min            22.13217
V Predictions Mean           1821.7937
V Predictions Std            986.5348
V Predictions Max            2631.1213
V Predictions Min            28.807673
Log Pis Mean                 -3.932331
Log Pis Std                  6.457282
Log Pis Max                  21.516174
Log Pis Min                  -14.012208
Policy mu Mean               0.19023012
Policy mu Std                0.7468127
Policy mu Max                3.302381
Policy mu Min                -3.5962312
Policy log std Mean          -0.33052042
Policy log std Std           0.17396832
Policy log std Max           0.23416212
Policy log std Min           -1.3619276
Z mean eval                  0.032118876
Z variance eval              0.047811236
total_rewards                [5178.26427245 5029.41290873 5147.66327753 5157.38286157 5228.41705317
 3962.78057798 5014.54754401 5160.98069105 5156.34578964 5129.45752929]
total_rewards_mean           5016.525250542438
total_rewards_std            356.6250679591429
total_rewards_max            5228.417053173843
total_rewards_min            3962.7805779830796
Number of train steps total  984000
Number of env steps total    1232000
Number of rollouts total     0
Train Time (s)               195.34900665609166
(Previous) Eval Time (s)     21.48192178690806
Sample Time (s)              16.67333459155634
Epoch Time (s)               233.50426303455606
Total Train Time (s)         54287.10350465216
Epoch                        245
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:35:06.275311 UTC | [2020_01_13_04_30_18] Iteration #245 | Epoch Duration: 238.57084035873413
2020-01-13 19:35:06.275455 UTC | [2020_01_13_04_30_18] Iteration #245 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031754892
Z variance train             0.04782602
KL Divergence                5.311709
KL Loss                      0.5311709
QF Loss                      2041.621
VF Loss                      686.1471
Policy Loss                  -1788.8604
Q Predictions Mean           1788.0981
Q Predictions Std            1001.1329
Q Predictions Max            2662.756
Q Predictions Min            13.660452
V Predictions Mean           1801.2734
V Predictions Std            1003.9805
V Predictions Max            2681.6467
V Predictions Min            24.381474
Log Pis Mean                 -4.678834
Log Pis Std                  6.100469
Log Pis Max                  28.862999
Log Pis Min                  -14.428796
Policy mu Mean               0.14311755
Policy mu Std                0.7452294
Policy mu Max                3.259697
Policy mu Min                -3.2434149
Policy log std Mean          -0.31305385
Policy log std Std           0.16448298
Policy log std Max           0.13317633
Policy log std Min           -1.156052
Z mean eval                  0.03513997
Z variance eval              0.044313915
total_rewards                [5417.477442   2668.56791693 2035.6928469  4145.95349951 5318.71266771
 5264.04321124 1342.4668957  5311.26779981 5312.54157772 5423.50393554]
total_rewards_mean           4224.022779304365
total_rewards_std            1517.4893502270131
total_rewards_max            5423.503935535206
total_rewards_min            1342.4668956996436
Number of train steps total  988000
Number of env steps total    1237000
Number of rollouts total     0
Train Time (s)               200.89006337197497
(Previous) Eval Time (s)     26.54823650699109
Sample Time (s)              18.994753181003034
Epoch Time (s)               246.4330530599691
Total Train Time (s)         54528.50051698787
Epoch                        246
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:39:07.674649 UTC | [2020_01_13_04_30_18] Iteration #246 | Epoch Duration: 241.3990409374237
2020-01-13 19:39:07.674818 UTC | [2020_01_13_04_30_18] Iteration #246 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036103234
Z variance train             0.0443322
KL Divergence                5.4553056
KL Loss                      0.54553056
QF Loss                      2150.3684
VF Loss                      810.004
Policy Loss                  -1817.3169
Q Predictions Mean           1811.8535
Q Predictions Std            979.3441
Q Predictions Max            2686.0803
Q Predictions Min            16.443851
V Predictions Mean           1803.5275
V Predictions Std            971.97766
V Predictions Max            2663.8528
V Predictions Min            22.797228
Log Pis Mean                 -3.6329913
Log Pis Std                  7.0463543
Log Pis Max                  27.693367
Log Pis Min                  -14.625272
Policy mu Mean               0.17392127
Policy mu Std                0.772708
Policy mu Max                2.951622
Policy mu Min                -2.9975255
Policy log std Mean          -0.33101904
Policy log std Std           0.17715755
Policy log std Max           0.18609868
Policy log std Min           -1.5018306
Z mean eval                  0.030757595
Z variance eval              0.04282552
total_rewards                [5250.69023023 3025.99732303 3584.78781589 5257.31072621 5245.05051168
 5315.76250968 5183.38733418 4772.07702152 5317.67506608 4217.49255618]
total_rewards_mean           4717.0231094678675
total_rewards_std            786.5353235453025
total_rewards_max            5317.675066080067
total_rewards_min            3025.9973230284836
Number of train steps total  992000
Number of env steps total    1242000
Number of rollouts total     0
Train Time (s)               195.80245998688042
(Previous) Eval Time (s)     21.51395705388859
Sample Time (s)              18.920482086017728
Epoch Time (s)               236.23689912678674
Total Train Time (s)         54768.20885007875
Epoch                        247
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:43:07.385937 UTC | [2020_01_13_04_30_18] Iteration #247 | Epoch Duration: 239.71099543571472
2020-01-13 19:43:07.386132 UTC | [2020_01_13_04_30_18] Iteration #247 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03087008
Z variance train             0.042808432
KL Divergence                5.5342436
KL Loss                      0.55342436
QF Loss                      1902.9231
VF Loss                      399.31076
Policy Loss                  -1835.9973
Q Predictions Mean           1831.5928
Q Predictions Std            978.323
Q Predictions Max            2653.7358
Q Predictions Min            17.752453
V Predictions Mean           1832.2775
V Predictions Std            973.55066
V Predictions Max            2630.6797
V Predictions Min            23.663836
Log Pis Mean                 -3.7702541
Log Pis Std                  7.0441318
Log Pis Max                  35.154243
Log Pis Min                  -17.505222
Policy mu Mean               0.17147982
Policy mu Std                0.776384
Policy mu Max                2.8596313
Policy mu Min                -3.603497
Policy log std Mean          -0.3295896
Policy log std Std           0.17237215
Policy log std Max           0.038151532
Policy log std Min           -1.3652719
Z mean eval                  0.023958128
Z variance eval              0.049215324
total_rewards                [2915.93195632 5190.13318171 2727.51738823 5318.34535892 5147.1195807
 3974.37075418 3238.34303449 5254.51023429 5228.55844546 5288.54398904]
total_rewards_mean           4428.33739233447
total_rewards_std            1037.0292520842506
total_rewards_max            5318.345358922682
total_rewards_min            2727.517388233938
Number of train steps total  996000
Number of env steps total    1247000
Number of rollouts total     0
Train Time (s)               199.52205071831122
(Previous) Eval Time (s)     24.98776351287961
Sample Time (s)              16.932342261541635
Epoch Time (s)               241.44215649273247
Total Train Time (s)         55004.96557695605
Epoch                        248
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:47:04.149572 UTC | [2020_01_13_04_30_18] Iteration #248 | Epoch Duration: 236.76326370239258
2020-01-13 19:47:04.149883 UTC | [2020_01_13_04_30_18] Iteration #248 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023827245
Z variance train             0.049191196
KL Divergence                5.2501054
KL Loss                      0.5250105
QF Loss                      1688.8391
VF Loss                      387.19037
Policy Loss                  -1912.0276
Q Predictions Mean           1904.0609
Q Predictions Std            964.95746
Q Predictions Max            2678.9785
Q Predictions Min            16.793032
V Predictions Mean           1911.3555
V Predictions Std            961.39026
V Predictions Max            2673.2007
V Predictions Min            32.544853
Log Pis Mean                 -3.8137343
Log Pis Std                  6.796098
Log Pis Max                  22.09037
Log Pis Min                  -15.035924
Policy mu Mean               0.17639309
Policy mu Std                0.7791179
Policy mu Max                3.159533
Policy mu Min                -3.419833
Policy log std Mean          -0.3245276
Policy log std Std           0.16716093
Policy log std Max           -0.02660951
Policy log std Min           -1.1768345
Z mean eval                  0.024179058
Z variance eval              0.050605785
total_rewards                [3704.21133827 5161.30349466 1760.12731789 2635.68734094 5073.53594074
 4768.98015961 5167.70774742 5161.70919422 5243.3945898  5304.79593442]
total_rewards_mean           4398.145305797426
total_rewards_std            1201.446654297242
total_rewards_max            5304.79593441835
total_rewards_min            1760.127317891911
Number of train steps total  1000000
Number of env steps total    1252000
Number of rollouts total     0
Train Time (s)               197.75508301798254
(Previous) Eval Time (s)     20.308577886782587
Sample Time (s)              18.740391470957547
Epoch Time (s)               236.80405237572268
Total Train Time (s)         55241.66871361155
Epoch                        249
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:51:00.855867 UTC | [2020_01_13_04_30_18] Iteration #249 | Epoch Duration: 236.70576119422913
2020-01-13 19:51:00.856171 UTC | [2020_01_13_04_30_18] Iteration #249 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023802664
Z variance train             0.05059604
KL Divergence                5.229329
KL Loss                      0.52293295
QF Loss                      1784.132
VF Loss                      1035.5684
Policy Loss                  -1853.744
Q Predictions Mean           1850.9558
Q Predictions Std            959.2144
Q Predictions Max            2665.7888
Q Predictions Min            22.478281
V Predictions Mean           1873.2817
V Predictions Std            963.79785
V Predictions Max            2686.3186
V Predictions Min            28.332163
Log Pis Mean                 -3.87087
Log Pis Std                  6.471149
Log Pis Max                  21.723518
Log Pis Min                  -12.7212305
Policy mu Mean               0.22247006
Policy mu Std                0.75662225
Policy mu Max                3.2527819
Policy mu Min                -2.7953577
Policy log std Mean          -0.34325993
Policy log std Std           0.1734731
Policy log std Max           -0.082496315
Policy log std Min           -1.3766712
Z mean eval                  0.032523286
Z variance eval              0.047519013
total_rewards                [5353.38233056 5240.10580195 5265.54175691 5363.39272789 2311.62473154
 5327.33525545 3516.46190839 5348.01981658 5282.74520962 5299.11819041]
total_rewards_mean           4830.772772930113
total_rewards_std            996.2252548556455
total_rewards_max            5363.392727892844
total_rewards_min            2311.624731539366
Number of train steps total  1004000
Number of env steps total    1257000
Number of rollouts total     0
Train Time (s)               195.90172563912347
(Previous) Eval Time (s)     20.210004163440317
Sample Time (s)              18.88577348133549
Epoch Time (s)               234.99750328389928
Total Train Time (s)         55480.97483716672
Epoch                        250
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:55:00.163380 UTC | [2020_01_13_04_30_18] Iteration #250 | Epoch Duration: 239.3070547580719
2020-01-13 19:55:00.163520 UTC | [2020_01_13_04_30_18] Iteration #250 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032465886
Z variance train             0.047495637
KL Divergence                5.330839
KL Loss                      0.5330839
QF Loss                      1620.7666
VF Loss                      398.71887
Policy Loss                  -1887.6697
Q Predictions Mean           1882.3062
Q Predictions Std            985.59296
Q Predictions Max            2677.983
Q Predictions Min            20.700113
V Predictions Mean           1888.74
V Predictions Std            982.99243
V Predictions Max            2670.6438
V Predictions Min            30.824482
Log Pis Mean                 -4.44067
Log Pis Std                  6.716952
Log Pis Max                  41.383465
Log Pis Min                  -15.442457
Policy mu Mean               0.1548058
Policy mu Std                0.7486838
Policy mu Max                4.1583877
Policy mu Min                -4.2505565
Policy log std Mean          -0.32248884
Policy log std Std           0.16136298
Policy log std Max           0.20333408
Policy log std Min           -1.3262635
Z mean eval                  0.023404364
Z variance eval              0.04537069
total_rewards                [5279.31382579 5165.52371034 1086.09780851 4339.7377905  1982.04866275
 5238.62890731 5177.73941166 5319.81706073 5242.31639471 5215.79484172]
total_rewards_mean           4404.701841401185
total_rewards_std            1473.781693962036
total_rewards_max            5319.817060733612
total_rewards_min            1086.097808509919
Number of train steps total  1008000
Number of env steps total    1262000
Number of rollouts total     0
Train Time (s)               195.04421926289797
(Previous) Eval Time (s)     24.519275196827948
Sample Time (s)              18.806375382002443
Epoch Time (s)               238.36986984172836
Total Train Time (s)         55718.427581583615
Epoch                        251
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 19:58:57.623014 UTC | [2020_01_13_04_30_18] Iteration #251 | Epoch Duration: 237.4593460559845
2020-01-13 19:58:57.623319 UTC | [2020_01_13_04_30_18] Iteration #251 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023636365
Z variance train             0.04535701
KL Divergence                5.4218407
KL Loss                      0.54218405
QF Loss                      1774.5231
VF Loss                      854.2741
Policy Loss                  -1933.4758
Q Predictions Mean           1930.2917
Q Predictions Std            956.97974
Q Predictions Max            2662.797
Q Predictions Min            20.253067
V Predictions Mean           1933.134
V Predictions Std            951.80444
V Predictions Max            2665.8625
V Predictions Min            26.404844
Log Pis Mean                 -3.4409726
Log Pis Std                  7.459096
Log Pis Max                  41.73669
Log Pis Min                  -18.410206
Policy mu Mean               0.18586022
Policy mu Std                0.7880215
Policy mu Max                3.124128
Policy mu Min                -4.143139
Policy log std Mean          -0.34827283
Policy log std Std           0.1737665
Policy log std Max           -0.02094324
Policy log std Min           -1.2652323
Z mean eval                  0.025837427
Z variance eval              0.044459302
total_rewards                [2815.10463531 5024.84909941 4950.90613478 4916.46565517 5058.91777111
 4958.9185461  5073.32020858 5006.78604738 1891.96475058 5073.08851209]
total_rewards_mean           4477.032136051863
total_rewards_std            1082.8030982032724
total_rewards_max            5073.320208576096
total_rewards_min            1891.9647505784715
Number of train steps total  1012000
Number of env steps total    1267000
Number of rollouts total     0
Train Time (s)               195.0832382007502
(Previous) Eval Time (s)     23.608465996105224
Sample Time (s)              16.817426757887006
Epoch Time (s)               235.50913095474243
Total Train Time (s)         55952.35729287518
Epoch                        252
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:02:51.554638 UTC | [2020_01_13_04_30_18] Iteration #252 | Epoch Duration: 233.93111181259155
2020-01-13 20:02:51.554813 UTC | [2020_01_13_04_30_18] Iteration #252 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02580601
Z variance train             0.044456087
KL Divergence                5.539444
KL Loss                      0.5539444
QF Loss                      1611.3146
VF Loss                      427.80115
Policy Loss                  -1846.4764
Q Predictions Mean           1847.8682
Q Predictions Std            1008.886
Q Predictions Max            2678.162
Q Predictions Min            16.41223
V Predictions Mean           1850.2571
V Predictions Std            1004.34625
V Predictions Max            2680.5276
V Predictions Min            34.770405
Log Pis Mean                 -4.8070345
Log Pis Std                  5.733302
Log Pis Max                  14.219242
Log Pis Min                  -13.424522
Policy mu Mean               0.19538501
Policy mu Std                0.7074449
Policy mu Max                2.5727487
Policy mu Min                -2.9878237
Policy log std Mean          -0.31874707
Policy log std Std           0.16246267
Policy log std Max           0.03998606
Policy log std Min           -1.324133
Z mean eval                  0.012794549
Z variance eval              0.042096835
total_rewards                [5118.54846173 5078.52459886 5152.08381219 5119.86161222 5143.6625482
 5170.71308292 5199.9248798  5225.77147772 5207.28551016 2026.68280596]
total_rewards_mean           4844.305878975793
total_rewards_std            940.1923510880015
total_rewards_max            5225.7714777238325
total_rewards_min            2026.6828059610634
Number of train steps total  1016000
Number of env steps total    1272000
Number of rollouts total     0
Train Time (s)               196.77371297916397
(Previous) Eval Time (s)     22.030195218976587
Sample Time (s)              18.833051657304168
Epoch Time (s)               237.63695985544473
Total Train Time (s)         56190.44149181107
Epoch                        253
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:06:49.642964 UTC | [2020_01_13_04_30_18] Iteration #253 | Epoch Duration: 238.0879979133606
2020-01-13 20:06:49.643207 UTC | [2020_01_13_04_30_18] Iteration #253 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012455894
Z variance train             0.042090055
KL Divergence                5.62924
KL Loss                      0.562924
QF Loss                      2105.2207
VF Loss                      745.9426
Policy Loss                  -1891.6792
Q Predictions Mean           1887.2288
Q Predictions Std            950.88696
Q Predictions Max            2678.5042
Q Predictions Min            18.48462
V Predictions Mean           1892.491
V Predictions Std            946.59296
V Predictions Max            2669.1602
V Predictions Min            26.894388
Log Pis Mean                 -4.50765
Log Pis Std                  6.379998
Log Pis Max                  24.362507
Log Pis Min                  -14.985025
Policy mu Mean               0.16490781
Policy mu Std                0.7465392
Policy mu Max                3.6335866
Policy mu Min                -3.250575
Policy log std Mean          -0.32274628
Policy log std Std           0.1651996
Policy log std Max           0.048942327
Policy log std Min           -1.2452523
Z mean eval                  0.020531919
Z variance eval              0.044415303
total_rewards                [5139.21946206 5047.40390784 5284.8124744  5240.28777453 5124.69861282
 5194.93339013 1768.00058323 5201.99253027 5049.21891958 5280.76735446]
total_rewards_mean           4833.133500932114
total_rewards_std            1024.8640913031152
total_rewards_max            5284.812474402534
total_rewards_min            1768.0005832315362
Number of train steps total  1020000
Number of env steps total    1277000
Number of rollouts total     0
Train Time (s)               195.56125695072114
(Previous) Eval Time (s)     22.480953922960907
Sample Time (s)              16.691552466712892
Epoch Time (s)               234.73376334039494
Total Train Time (s)         56425.06670699362
Epoch                        254
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:10:44.275212 UTC | [2020_01_13_04_30_18] Iteration #254 | Epoch Duration: 234.6318120956421
2020-01-13 20:10:44.275495 UTC | [2020_01_13_04_30_18] Iteration #254 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020607166
Z variance train             0.044399112
KL Divergence                5.413762
KL Loss                      0.54137623
QF Loss                      2217.2988
VF Loss                      594.02203
Policy Loss                  -1997.5471
Q Predictions Mean           1990.7496
Q Predictions Std            897.13025
Q Predictions Max            2695.4404
Q Predictions Min            17.489529
V Predictions Mean           1995.665
V Predictions Std            895.43915
V Predictions Max            2699.0908
V Predictions Min            28.80626
Log Pis Mean                 -3.300782
Log Pis Std                  7.6063194
Log Pis Max                  37.095993
Log Pis Min                  -13.190912
Policy mu Mean               0.19453144
Policy mu Std                0.8141754
Policy mu Max                3.553695
Policy mu Min                -4.1735487
Policy log std Mean          -0.34778124
Policy log std Std           0.17903215
Policy log std Max           0.31556427
Policy log std Min           -1.3104987
Z mean eval                  0.017605824
Z variance eval              0.049530644
total_rewards                [5287.21302322 1080.55560336 1494.29996434 5266.24443583 5226.53395184
 2013.03515522 4973.22261697 5217.53153761 5246.23214083 5159.10325851]
total_rewards_mean           4096.39716877291
total_rewards_std            1695.5126510924397
total_rewards_max            5287.213023223047
total_rewards_min            1080.5556033605053
Number of train steps total  1024000
Number of env steps total    1282000
Number of rollouts total     0
Train Time (s)               194.04739712784067
(Previous) Eval Time (s)     22.37870906572789
Sample Time (s)              16.473070398904383
Epoch Time (s)               232.89917659247294
Total Train Time (s)         56654.161109342705
Epoch                        255
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:14:33.375952 UTC | [2020_01_13_04_30_18] Iteration #255 | Epoch Duration: 229.10021376609802
2020-01-13 20:14:33.376236 UTC | [2020_01_13_04_30_18] Iteration #255 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017941445
Z variance train             0.049553156
KL Divergence                5.245361
KL Loss                      0.5245361
QF Loss                      1759.2354
VF Loss                      636.21594
Policy Loss                  -1961.0701
Q Predictions Mean           1950.6239
Q Predictions Std            955.56976
Q Predictions Max            2710.4675
Q Predictions Min            21.634447
V Predictions Mean           1952.8337
V Predictions Std            952.33167
V Predictions Max            2697.319
V Predictions Min            26.439526
Log Pis Mean                 -3.9198513
Log Pis Std                  6.729222
Log Pis Max                  23.238081
Log Pis Min                  -17.02321
Policy mu Mean               0.21145183
Policy mu Std                0.74807084
Policy mu Max                2.699533
Policy mu Min                -3.995385
Policy log std Mean          -0.3392635
Policy log std Std           0.17684077
Policy log std Max           0.36114812
Policy log std Min           -1.4665321
Z mean eval                  0.016824774
Z variance eval              0.052984558
total_rewards                [1793.00183611 5106.5203221  5200.71884863 5197.49797679 5144.3749309
 1465.27686937  861.12053703 5158.34506474 5198.98065399 5200.40914349]
total_rewards_mean           4032.624618314653
total_rewards_std            1754.0693043102317
total_rewards_max            5200.718848626286
total_rewards_min            861.1205370264863
Number of train steps total  1028000
Number of env steps total    1287000
Number of rollouts total     0
Train Time (s)               193.93081059399992
(Previous) Eval Time (s)     18.579478280153126
Sample Time (s)              18.80340813053772
Epoch Time (s)               231.31369700469077
Total Train Time (s)         56886.103747745045
Epoch                        256
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:18:25.321530 UTC | [2020_01_13_04_30_18] Iteration #256 | Epoch Duration: 231.94517469406128
2020-01-13 20:18:25.321681 UTC | [2020_01_13_04_30_18] Iteration #256 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016678713
Z variance train             0.053004123
KL Divergence                5.096896
KL Loss                      0.5096896
QF Loss                      1886.4503
VF Loss                      639.6437
Policy Loss                  -2015.0278
Q Predictions Mean           2010.3168
Q Predictions Std            912.9397
Q Predictions Max            2707.788
Q Predictions Min            20.318016
V Predictions Mean           2013.6097
V Predictions Std            910.36633
V Predictions Max            2715.4897
V Predictions Min            31.677746
Log Pis Mean                 -3.774727
Log Pis Std                  6.568826
Log Pis Max                  22.642353
Log Pis Min                  -14.765516
Policy mu Mean               0.12426445
Policy mu Std                0.78195435
Policy mu Max                2.8492644
Policy mu Min                -3.08071
Policy log std Mean          -0.32655448
Policy log std Std           0.16738577
Policy log std Max           -0.05212909
Policy log std Min           -1.1708695
Z mean eval                  0.030519992
Z variance eval              0.066489555
total_rewards                [5145.2573922  5169.21200392 1980.72242857 1893.8054073  5168.19041077
 5258.38711253 5025.61163216 3347.29716635 5201.62774058 5115.61012433]
total_rewards_mean           4330.572141871542
total_rewards_std            1312.0225498764073
total_rewards_max            5258.387112529939
total_rewards_min            1893.8054072987502
Number of train steps total  1032000
Number of env steps total    1292000
Number of rollouts total     0
Train Time (s)               194.79678181093186
(Previous) Eval Time (s)     19.210659340955317
Sample Time (s)              16.521825439762324
Epoch Time (s)               230.5292665916495
Total Train Time (s)         57120.41431064764
Epoch                        257
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:22:19.634130 UTC | [2020_01_13_04_30_18] Iteration #257 | Epoch Duration: 234.3123424053192
2020-01-13 20:22:19.634250 UTC | [2020_01_13_04_30_18] Iteration #257 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030418545
Z variance train             0.066511616
KL Divergence                4.6420183
KL Loss                      0.46420184
QF Loss                      1900.9258
VF Loss                      875.2174
Policy Loss                  -1876.7502
Q Predictions Mean           1871.3206
Q Predictions Std            1021.39307
Q Predictions Max            2697.0942
Q Predictions Min            18.125048
V Predictions Mean           1878.7207
V Predictions Std            1020.5456
V Predictions Max            2692.1753
V Predictions Min            29.578924
Log Pis Mean                 -4.294969
Log Pis Std                  6.919544
Log Pis Max                  23.252115
Log Pis Min                  -13.235834
Policy mu Mean               0.18953337
Policy mu Std                0.7391491
Policy mu Max                3.443679
Policy mu Min                -2.67591
Policy log std Mean          -0.33709255
Policy log std Std           0.18150777
Policy log std Max           0.0119859725
Policy log std Min           -1.5424575
Z mean eval                  0.032619867
Z variance eval              0.059883963
total_rewards                [5231.80229355 5187.96986699 5259.83627418 5303.02393206 1566.29353893
 2237.55309436 5229.94027993 3413.09251175 5211.88507676 4809.510476  ]
total_rewards_mean           4345.090734451738
total_rewards_std            1342.8746898472036
total_rewards_max            5303.023932062662
total_rewards_min            1566.2935389271308
Number of train steps total  1036000
Number of env steps total    1297000
Number of rollouts total     0
Train Time (s)               195.20131325814873
(Previous) Eval Time (s)     22.993473050184548
Sample Time (s)              18.001396261621267
Epoch Time (s)               236.19618256995454
Total Train Time (s)         57355.18198737409
Epoch                        258
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:26:14.404699 UTC | [2020_01_13_04_30_18] Iteration #258 | Epoch Duration: 234.7703537940979
2020-01-13 20:26:14.404848 UTC | [2020_01_13_04_30_18] Iteration #258 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032514513
Z variance train             0.059923243
KL Divergence                4.919612
KL Loss                      0.4919612
QF Loss                      1948.317
VF Loss                      683.89453
Policy Loss                  -2019.7797
Q Predictions Mean           2020.9006
Q Predictions Std            905.1977
Q Predictions Max            2708.7815
Q Predictions Min            15.537802
V Predictions Mean           2026.1809
V Predictions Std            901.87445
V Predictions Max            2708.5212
V Predictions Min            33.778408
Log Pis Mean                 -3.775537
Log Pis Std                  6.3691487
Log Pis Max                  23.117592
Log Pis Min                  -14.413167
Policy mu Mean               0.19433829
Policy mu Std                0.76763535
Policy mu Max                3.01801
Policy mu Min                -3.3246539
Policy log std Mean          -0.3531667
Policy log std Std           0.17758168
Policy log std Max           -0.042459443
Policy log std Min           -1.3406363
Z mean eval                  0.024945106
Z variance eval              0.055989563
total_rewards                [5072.32526015 5080.45850003 5199.49752674 1651.64270685 5266.87945257
 5187.25354601 3073.43582688 5214.71095662 5283.40814812 5022.17124712]
total_rewards_mean           4605.178317108289
total_rewards_std            1168.2897461587427
total_rewards_max            5283.408148120874
total_rewards_min            1651.6427068511011
Number of train steps total  1040000
Number of env steps total    1302000
Number of rollouts total     0
Train Time (s)               196.41223292797804
(Previous) Eval Time (s)     21.567381727974862
Sample Time (s)              16.211290852166712
Epoch Time (s)               234.1909055081196
Total Train Time (s)         57591.74837877881
Epoch                        259
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:30:10.973595 UTC | [2020_01_13_04_30_18] Iteration #259 | Epoch Duration: 236.56863522529602
2020-01-13 20:30:10.973724 UTC | [2020_01_13_04_30_18] Iteration #259 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024925422
Z variance train             0.05597198
KL Divergence                5.097477
KL Loss                      0.5097477
QF Loss                      1646.425
VF Loss                      391.78754
Policy Loss                  -2024.4586
Q Predictions Mean           2019.4719
Q Predictions Std            941.6591
Q Predictions Max            2711.232
Q Predictions Min            18.114872
V Predictions Mean           2026.4685
V Predictions Std            942.616
V Predictions Max            2713.616
V Predictions Min            25.07563
Log Pis Mean                 -4.7601366
Log Pis Std                  5.7725797
Log Pis Max                  17.323458
Log Pis Min                  -14.917958
Policy mu Mean               0.13969646
Policy mu Std                0.71948224
Policy mu Max                2.65637
Policy mu Min                -3.4009118
Policy log std Mean          -0.3250853
Policy log std Std           0.15880176
Policy log std Max           0.008954197
Policy log std Min           -1.274884
Z mean eval                  0.022686644
Z variance eval              0.064157926
total_rewards                [1126.34461924 5335.07147091 5246.62220841 5246.0189942  4982.45477146
 1253.15704921 5188.13581195 5277.78364899 4667.2599244  2205.5839865 ]
total_rewards_mean           4052.84324852728
total_rewards_std            1683.4174534813415
total_rewards_max            5335.071470914761
total_rewards_min            1126.3446192358022
Number of train steps total  1044000
Number of env steps total    1307000
Number of rollouts total     0
Train Time (s)               194.396607208997
(Previous) Eval Time (s)     23.944874260108918
Sample Time (s)              17.798405117355287
Epoch Time (s)               236.13988658646122
Total Train Time (s)         57825.23402409442
Epoch                        260
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:34:04.461595 UTC | [2020_01_13_04_30_18] Iteration #260 | Epoch Duration: 233.48777604103088
2020-01-13 20:34:04.461727 UTC | [2020_01_13_04_30_18] Iteration #260 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02218602
Z variance train             0.064117506
KL Divergence                4.626711
KL Loss                      0.4626711
QF Loss                      2300.8242
VF Loss                      564.2725
Policy Loss                  -1911.9462
Q Predictions Mean           1908.5718
Q Predictions Std            1002.5624
Q Predictions Max            2712.7583
Q Predictions Min            16.294388
V Predictions Mean           1916.9438
V Predictions Std            999.19775
V Predictions Max            2732.5718
V Predictions Min            30.918686
Log Pis Mean                 -4.8429904
Log Pis Std                  6.176267
Log Pis Max                  25.189243
Log Pis Min                  -14.871368
Policy mu Mean               0.12915622
Policy mu Std                0.74042493
Policy mu Max                3.0921695
Policy mu Min                -3.6163547
Policy log std Mean          -0.32965463
Policy log std Std           0.16344638
Policy log std Max           -0.057222784
Policy log std Min           -1.2712703
Z mean eval                  0.030290997
Z variance eval              0.059710454
total_rewards                [5183.1005541  5239.79658087 2855.80581706 5182.84810337 2829.41426979
 3715.2308517  2468.52895533 5234.01306227 5234.28926193 1381.03022888]
total_rewards_mean           3932.405768529944
total_rewards_std            1389.2973586652652
total_rewards_max            5239.796580868205
total_rewards_min            1381.030228880099
Number of train steps total  1048000
Number of env steps total    1312000
Number of rollouts total     0
Train Time (s)               198.4085421920754
(Previous) Eval Time (s)     21.292495070025325
Sample Time (s)              18.55783007480204
Epoch Time (s)               238.25886733690277
Total Train Time (s)         58062.672900756355
Epoch                        261
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:38:01.902340 UTC | [2020_01_13_04_30_18] Iteration #261 | Epoch Duration: 237.44052362442017
2020-01-13 20:38:01.902458 UTC | [2020_01_13_04_30_18] Iteration #261 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030033737
Z variance train             0.05976603
KL Divergence                4.8428054
KL Loss                      0.48428056
QF Loss                      2108.1157
VF Loss                      695.1214
Policy Loss                  -1950.44
Q Predictions Mean           1948.4683
Q Predictions Std            1000.57965
Q Predictions Max            2707.1562
Q Predictions Min            19.713175
V Predictions Mean           1942.7765
V Predictions Std            993.75244
V Predictions Max            2699.8066
V Predictions Min            29.834146
Log Pis Mean                 -5.3560114
Log Pis Std                  5.9945498
Log Pis Max                  20.41118
Log Pis Min                  -14.496015
Policy mu Mean               0.1856095
Policy mu Std                0.68679327
Policy mu Max                3.3258977
Policy mu Min                -2.9963927
Policy log std Mean          -0.3128261
Policy log std Std           0.1658063
Policy log std Max           -0.033671193
Policy log std Min           -1.2520597
Z mean eval                  0.020163437
Z variance eval              0.057930447
total_rewards                [4176.46557891 5342.29461739 5257.59543199 5315.67951848 5231.66091521
 5324.82314886 5262.25818107 5271.83035738 3210.95031133 5257.82400274]
total_rewards_mean           4965.138206336791
total_rewards_std            672.179293457386
total_rewards_max            5342.294617385794
total_rewards_min            3210.9503113304017
Number of train steps total  1052000
Number of env steps total    1317000
Number of rollouts total     0
Train Time (s)               193.46352054923773
(Previous) Eval Time (s)     20.473847610875964
Sample Time (s)              18.97478030109778
Epoch Time (s)               232.91214846121147
Total Train Time (s)         58300.78990956256
Epoch                        262
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:42:00.025812 UTC | [2020_01_13_04_30_18] Iteration #262 | Epoch Duration: 238.1232466697693
2020-01-13 20:42:00.026000 UTC | [2020_01_13_04_30_18] Iteration #262 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019686481
Z variance train             0.05793333
KL Divergence                4.8637853
KL Loss                      0.48637852
QF Loss                      1957.9004
VF Loss                      598.174
Policy Loss                  -2145.2935
Q Predictions Mean           2134.4304
Q Predictions Std            863.4459
Q Predictions Max            2716.2632
Q Predictions Min            13.307968
V Predictions Mean           2147.3125
V Predictions Std            862.84717
V Predictions Max            2724.5234
V Predictions Min            29.735626
Log Pis Mean                 -3.970695
Log Pis Std                  6.2739296
Log Pis Max                  20.753002
Log Pis Min                  -14.2190275
Policy mu Mean               0.1552344
Policy mu Std                0.74307525
Policy mu Max                2.806216
Policy mu Min                -3.0810604
Policy log std Mean          -0.34817123
Policy log std Std           0.16661246
Policy log std Max           -0.080462724
Policy log std Min           -1.4256476
Z mean eval                  0.021120537
Z variance eval              0.059758373
total_rewards                [5106.60096068 1207.53212647 5252.5651156  5105.48714837 5096.20010076
 4441.61219212 5248.5066973  5060.99114284 5113.07486537 5150.38043228]
total_rewards_mean           4678.295078178816
total_rewards_std            1177.1184964351978
total_rewards_max            5252.565115603126
total_rewards_min            1207.5321264708114
Number of train steps total  1056000
Number of env steps total    1322000
Number of rollouts total     0
Train Time (s)               196.89487515063956
(Previous) Eval Time (s)     25.684633182827383
Sample Time (s)              18.393692628480494
Epoch Time (s)               240.97320096194744
Total Train Time (s)         58538.17897191923
Epoch                        263
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:45:57.418415 UTC | [2020_01_13_04_30_18] Iteration #263 | Epoch Duration: 237.3922712802887
2020-01-13 20:45:57.418619 UTC | [2020_01_13_04_30_18] Iteration #263 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021856045
Z variance train             0.059717447
KL Divergence                4.771441
KL Loss                      0.4771441
QF Loss                      1878.067
VF Loss                      600.32294
Policy Loss                  -2092.5503
Q Predictions Mean           2086.5254
Q Predictions Std            924.93463
Q Predictions Max            2721.6948
Q Predictions Min            14.193496
V Predictions Mean           2083.0767
V Predictions Std            920.7023
V Predictions Max            2726.915
V Predictions Min            33.26188
Log Pis Mean                 -4.1913285
Log Pis Std                  6.1670656
Log Pis Max                  23.279696
Log Pis Min                  -17.184278
Policy mu Mean               0.22879994
Policy mu Std                0.7372843
Policy mu Max                3.4816566
Policy mu Min                -3.4049757
Policy log std Mean          -0.33088672
Policy log std Std           0.16824532
Policy log std Max           0.08905281
Policy log std Min           -1.2833211
Z mean eval                  0.022465711
Z variance eval              0.06574072
total_rewards                [ 895.12230971 1720.18064617 5265.13042717 4783.20402824 5245.77871252
 4635.97541221 2641.79698416 5176.71748342 5295.26037746 5206.31906839]
total_rewards_mean           4086.5485449458674
total_rewards_std            1590.4594535156336
total_rewards_max            5295.260377464254
total_rewards_min            895.122309709884
Number of train steps total  1060000
Number of env steps total    1327000
Number of rollouts total     0
Train Time (s)               194.90176845388487
(Previous) Eval Time (s)     22.103433534968644
Sample Time (s)              16.556276014074683
Epoch Time (s)               233.5614780029282
Total Train Time (s)         58770.737853611354
Epoch                        264
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:49:49.984752 UTC | [2020_01_13_04_30_18] Iteration #264 | Epoch Duration: 232.5659782886505
2020-01-13 20:49:49.984985 UTC | [2020_01_13_04_30_18] Iteration #264 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022176266
Z variance train             0.06580545
KL Divergence                4.5579414
KL Loss                      0.45579416
QF Loss                      1534.0741
VF Loss                      381.5585
Policy Loss                  -2124.7468
Q Predictions Mean           2120.9514
Q Predictions Std            836.33563
Q Predictions Max            2730.357
Q Predictions Min            20.382624
V Predictions Mean           2129.396
V Predictions Std            831.7583
V Predictions Max            2730.3364
V Predictions Min            29.204172
Log Pis Mean                 -3.9021006
Log Pis Std                  6.3378267
Log Pis Max                  27.1182
Log Pis Min                  -14.175146
Policy mu Mean               0.1988423
Policy mu Std                0.76707274
Policy mu Max                2.8352604
Policy mu Min                -3.1186693
Policy log std Mean          -0.3347795
Policy log std Std           0.15197262
Policy log std Max           -0.017662168
Policy log std Min           -1.252984
Z mean eval                  0.020413037
Z variance eval              0.06093207
total_rewards                [5211.41697455 5329.76684801 5203.22161331 5060.79003684 5223.87389126
 4525.54138765 5272.44121032 5212.393006   3448.57938111 3675.69341943]
total_rewards_mean           4816.371776848242
total_rewards_std            664.567819913171
total_rewards_max            5329.766848009289
total_rewards_min            3448.579381111416
Number of train steps total  1064000
Number of env steps total    1332000
Number of rollouts total     0
Train Time (s)               199.47262260410935
(Previous) Eval Time (s)     21.107671330217272
Sample Time (s)              17.350623827893287
Epoch Time (s)               237.9309177622199
Total Train Time (s)         59009.82587845111
Epoch                        265
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:53:49.080711 UTC | [2020_01_13_04_30_18] Iteration #265 | Epoch Duration: 239.09549641609192
2020-01-13 20:53:49.080997 UTC | [2020_01_13_04_30_18] Iteration #265 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020455059
Z variance train             0.060914166
KL Divergence                4.78096
KL Loss                      0.478096
QF Loss                      1359.656
VF Loss                      541.2859
Policy Loss                  -2164.655
Q Predictions Mean           2158.7065
Q Predictions Std            889.78754
Q Predictions Max            2765.8074
Q Predictions Min            16.784122
V Predictions Mean           2160.2869
V Predictions Std            888.42163
V Predictions Max            2754.9722
V Predictions Min            29.064941
Log Pis Mean                 -4.953141
Log Pis Std                  5.705854
Log Pis Max                  20.488152
Log Pis Min                  -13.100415
Policy mu Mean               0.16610345
Policy mu Std                0.70649683
Policy mu Max                2.6518807
Policy mu Min                -3.3560648
Policy log std Mean          -0.3240811
Policy log std Std           0.15277314
Policy log std Max           0.042666182
Policy log std Min           -1.2520628
Z mean eval                  0.016508777
Z variance eval              0.058653284
total_rewards                [5338.13290542 5280.36210432  640.81770029 5216.56592945 5264.57862577
 5276.59584911 5299.75328643 1364.31419999 5186.27142543 1972.76381589]
total_rewards_mean           4084.015584209644
total_rewards_std            1830.4496643128189
total_rewards_max            5338.132905415785
total_rewards_min            640.8177002917166
Number of train steps total  1068000
Number of env steps total    1337000
Number of rollouts total     0
Train Time (s)               197.26079247612506
(Previous) Eval Time (s)     22.271921628154814
Sample Time (s)              17.586189257446676
Epoch Time (s)               237.11890336172655
Total Train Time (s)         59245.95602165861
Epoch                        266
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 20:57:45.215867 UTC | [2020_01_13_04_30_18] Iteration #266 | Epoch Duration: 236.13468027114868
2020-01-13 20:57:45.216203 UTC | [2020_01_13_04_30_18] Iteration #266 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016322996
Z variance train             0.05865193
KL Divergence                4.8587875
KL Loss                      0.48587877
QF Loss                      1550.684
VF Loss                      491.13638
Policy Loss                  -2079.757
Q Predictions Mean           2074.406
Q Predictions Std            923.90344
Q Predictions Max            2718.8113
Q Predictions Min            21.557299
V Predictions Mean           2081.849
V Predictions Std            922.98706
V Predictions Max            2748.4053
V Predictions Min            30.517132
Log Pis Mean                 -4.463073
Log Pis Std                  6.1079936
Log Pis Max                  21.828512
Log Pis Min                  -17.279621
Policy mu Mean               0.19192673
Policy mu Std                0.7207988
Policy mu Max                3.1492927
Policy mu Min                -3.1066554
Policy log std Mean          -0.33525532
Policy log std Std           0.16993813
Policy log std Max           -0.028348342
Policy log std Min           -1.3047124
Z mean eval                  0.02814417
Z variance eval              0.056809343
total_rewards                [5253.24822888  858.23996448 5314.87067472 5314.83006879 5232.14063217
 5300.51765731 4410.12854437 5325.41514628 5226.19576535 5243.13419753]
total_rewards_mean           4747.8720879873135
total_rewards_std            1322.4677606834618
total_rewards_max            5325.415146275279
total_rewards_min            858.2399644764888
Number of train steps total  1072000
Number of env steps total    1342000
Number of rollouts total     0
Train Time (s)               193.54003322310746
(Previous) Eval Time (s)     21.28740748995915
Sample Time (s)              18.812859621364623
Epoch Time (s)               233.64030033443123
Total Train Time (s)         59482.34355738666
Epoch                        267
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:01:41.604816 UTC | [2020_01_13_04_30_18] Iteration #267 | Epoch Duration: 236.38840746879578
2020-01-13 21:01:41.604965 UTC | [2020_01_13_04_30_18] Iteration #267 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028346524
Z variance train             0.056839924
KL Divergence                4.9271593
KL Loss                      0.49271592
QF Loss                      1581.2153
VF Loss                      808.89246
Policy Loss                  -2075.2288
Q Predictions Mean           2069.477
Q Predictions Std            915.43066
Q Predictions Max            2725.2297
Q Predictions Min            19.960047
V Predictions Mean           2077.2842
V Predictions Std            914.14856
V Predictions Max            2739.6787
V Predictions Min            27.241615
Log Pis Mean                 -4.579918
Log Pis Std                  6.235122
Log Pis Max                  30.078222
Log Pis Min                  -13.910102
Policy mu Mean               0.15152858
Policy mu Std                0.74242693
Policy mu Max                3.0955255
Policy mu Min                -4.030878
Policy log std Mean          -0.3235813
Policy log std Std           0.15496281
Policy log std Max           0.104934216
Policy log std Min           -1.0515295
Z mean eval                  0.020652462
Z variance eval              0.06220299
total_rewards                [5385.28089719 5359.5962315  2097.62913106 5283.98605581 5417.76755091
 2608.35576256 5175.17303536 5351.51776196 5294.24852604 5398.69747115]
total_rewards_mean           4737.225242353692
total_rewards_std            1199.4137697483964
total_rewards_max            5417.76755091119
total_rewards_min            2097.6291310563747
Number of train steps total  1076000
Number of env steps total    1347000
Number of rollouts total     0
Train Time (s)               191.89667172776535
(Previous) Eval Time (s)     24.035215734969825
Sample Time (s)              18.988264176994562
Epoch Time (s)               234.92015163972974
Total Train Time (s)         59717.38333683042
Epoch                        268
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:05:36.648718 UTC | [2020_01_13_04_30_18] Iteration #268 | Epoch Duration: 235.04362893104553
2020-01-13 21:05:36.648915 UTC | [2020_01_13_04_30_18] Iteration #268 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020634323
Z variance train             0.062226605
KL Divergence                4.685248
KL Loss                      0.46852478
QF Loss                      1467.4806
VF Loss                      285.0454
Policy Loss                  -2038.7742
Q Predictions Mean           2033.7058
Q Predictions Std            969.49316
Q Predictions Max            2729.2373
Q Predictions Min            14.5972805
V Predictions Mean           2037.8435
V Predictions Std            965.7697
V Predictions Max            2747.1145
V Predictions Min            22.690397
Log Pis Mean                 -4.208298
Log Pis Std                  6.646744
Log Pis Max                  32.455814
Log Pis Min                  -13.269449
Policy mu Mean               0.15655772
Policy mu Std                0.7458173
Policy mu Max                3.2132943
Policy mu Min                -3.0466375
Policy log std Mean          -0.342865
Policy log std Std           0.16943693
Policy log std Max           0.017350689
Policy log std Min           -1.2907144
Z mean eval                  0.02078737
Z variance eval              0.060298435
total_rewards                [5380.66836886 1309.71020617 5292.05951689 5373.26905014 5405.16151721
 1071.50903677 4340.85366447 5425.21644781 5339.12519638 5389.93117197]
total_rewards_mean           4432.750417666354
total_rewards_std            1650.7448945283809
total_rewards_max            5425.21644780882
total_rewards_min            1071.509036771348
Number of train steps total  1080000
Number of env steps total    1352000
Number of rollouts total     0
Train Time (s)               191.0996865592897
(Previous) Eval Time (s)     24.158415663056076
Sample Time (s)              17.049602275248617
Epoch Time (s)               232.3077044975944
Total Train Time (s)         59945.30253765499
Epoch                        269
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:09:24.571241 UTC | [2020_01_13_04_30_18] Iteration #269 | Epoch Duration: 227.92218255996704
2020-01-13 21:09:24.571432 UTC | [2020_01_13_04_30_18] Iteration #269 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019949207
Z variance train             0.060261972
KL Divergence                4.803223
KL Loss                      0.48032233
QF Loss                      1790.231
VF Loss                      466.16113
Policy Loss                  -2070.0007
Q Predictions Mean           2064.342
Q Predictions Std            940.29724
Q Predictions Max            2750.2717
Q Predictions Min            9.35295
V Predictions Mean           2069.6218
V Predictions Std            934.2031
V Predictions Max            2756.9246
V Predictions Min            25.63968
Log Pis Mean                 -3.813672
Log Pis Std                  6.5270343
Log Pis Max                  20.341816
Log Pis Min                  -13.758898
Policy mu Mean               0.18642314
Policy mu Std                0.7635204
Policy mu Max                3.378269
Policy mu Min                -3.0922365
Policy log std Mean          -0.34750608
Policy log std Std           0.17214003
Policy log std Max           0.017804578
Policy log std Min           -1.2465582
Z mean eval                  0.019085184
Z variance eval              0.07348738
total_rewards                [4555.59355157 5211.85023149 5215.05362966 5272.32132185 4739.98162874
 5267.35813853 3206.29976786 5117.68177576 5303.48283908 4263.3066446 ]
total_rewards_mean           4815.292952911986
total_rewards_std            634.565680585852
total_rewards_max            5303.4828390768425
total_rewards_min            3206.2997678595348
Number of train steps total  1084000
Number of env steps total    1357000
Number of rollouts total     0
Train Time (s)               195.0135375680402
(Previous) Eval Time (s)     19.772631200030446
Sample Time (s)              18.923353222198784
Epoch Time (s)               233.70952199026942
Total Train Time (s)         60181.77605734533
Epoch                        270
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:13:21.048789 UTC | [2020_01_13_04_30_18] Iteration #270 | Epoch Duration: 236.47721338272095
2020-01-13 21:13:21.049003 UTC | [2020_01_13_04_30_18] Iteration #270 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01960717
Z variance train             0.073500425
KL Divergence                4.38042
KL Loss                      0.438042
QF Loss                      1803.8838
VF Loss                      534.55707
Policy Loss                  -2171.6106
Q Predictions Mean           2167.4292
Q Predictions Std            818.067
Q Predictions Max            2731.8474
Q Predictions Min            21.283619
V Predictions Mean           2162.44
V Predictions Std            815.6313
V Predictions Max            2725.0503
V Predictions Min            31.58375
Log Pis Mean                 -3.6045175
Log Pis Std                  6.6349397
Log Pis Max                  19.813108
Log Pis Min                  -13.071055
Policy mu Mean               0.2116411
Policy mu Std                0.7731405
Policy mu Max                3.0661979
Policy mu Min                -3.0245218
Policy log std Mean          -0.34529012
Policy log std Std           0.17046395
Policy log std Max           -0.019451201
Policy log std Min           -1.287884
Z mean eval                  0.031511758
Z variance eval              0.06023098
total_rewards                [5282.41698488 2979.98514027 5175.21162467 5324.87567656 5187.06205396
 5253.85333357 5297.9954993  5265.1921184  5322.92413817 5265.32763124]
total_rewards_mean           5035.484420100783
total_rewards_std            686.8123411824813
total_rewards_max            5324.87567655657
total_rewards_min            2979.98514026595
Number of train steps total  1088000
Number of env steps total    1362000
Number of rollouts total     0
Train Time (s)               201.35945157520473
(Previous) Eval Time (s)     22.54004147835076
Sample Time (s)              18.888612907379866
Epoch Time (s)               242.78810596093535
Total Train Time (s)         60428.27554942062
Epoch                        271
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:17:27.549966 UTC | [2020_01_13_04_30_18] Iteration #271 | Epoch Duration: 246.50084519386292
2020-01-13 21:17:27.550114 UTC | [2020_01_13_04_30_18] Iteration #271 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031532634
Z variance train             0.06024432
KL Divergence                4.7622795
KL Loss                      0.47622797
QF Loss                      2043.7632
VF Loss                      1073.2705
Policy Loss                  -2030.4851
Q Predictions Mean           2029.9152
Q Predictions Std            960.34534
Q Predictions Max            2770.7493
Q Predictions Min            21.112234
V Predictions Mean           2032.1799
V Predictions Std            960.0818
V Predictions Max            2776.1956
V Predictions Min            26.618591
Log Pis Mean                 -3.817031
Log Pis Std                  6.9386697
Log Pis Max                  21.354435
Log Pis Min                  -15.747216
Policy mu Mean               0.17603213
Policy mu Std                0.7592627
Policy mu Max                2.7593455
Policy mu Min                -4.3014607
Policy log std Mean          -0.35089678
Policy log std Std           0.18573575
Policy log std Max           -0.02347514
Policy log std Min           -1.3337536
Z mean eval                  0.021482434
Z variance eval              0.06289965
total_rewards                [5404.40668792 5384.60118792 5312.89679192 5370.82295642 5429.12717112
 1807.31746689 5311.89461352 5346.48862033 5453.06991151 1063.14790198]
total_rewards_mean           4588.377330951803
total_rewards_std            1585.9169581096342
total_rewards_max            5453.069911506071
total_rewards_min            1063.1479019815902
Number of train steps total  1092000
Number of env steps total    1367000
Number of rollouts total     0
Train Time (s)               197.65876549622044
(Previous) Eval Time (s)     26.25250446330756
Sample Time (s)              18.966696669813246
Epoch Time (s)               242.87796662934124
Total Train Time (s)         60668.058177456725
Epoch                        272
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:21:27.337551 UTC | [2020_01_13_04_30_18] Iteration #272 | Epoch Duration: 239.78734469413757
2020-01-13 21:21:27.337679 UTC | [2020_01_13_04_30_18] Iteration #272 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021946441
Z variance train             0.06287281
KL Divergence                4.6255984
KL Loss                      0.46255985
QF Loss                      1651.2692
VF Loss                      639.8871
Policy Loss                  -2099.7134
Q Predictions Mean           2092.9497
Q Predictions Std            916.72705
Q Predictions Max            2773.1602
Q Predictions Min            18.306824
V Predictions Mean           2095.6672
V Predictions Std            912.4248
V Predictions Max            2761.24
V Predictions Min            22.895996
Log Pis Mean                 -4.2844553
Log Pis Std                  6.257777
Log Pis Max                  23.666271
Log Pis Min                  -16.455956
Policy mu Mean               0.19487917
Policy mu Std                0.74867314
Policy mu Max                2.7564383
Policy mu Min                -2.8196368
Policy log std Mean          -0.32798472
Policy log std Std           0.1641631
Policy log std Max           0.10335606
Policy log std Min           -1.528936
Z mean eval                  0.033778198
Z variance eval              0.07299699
total_rewards                [5302.72441622 5232.48418839 5308.011823   3535.91791317 5364.79358165
 3787.6762918  5444.52445391 5406.09185387 5425.54318607 3154.03781455]
total_rewards_mean           4796.180552264627
total_rewards_std            867.3323495212331
total_rewards_max            5444.524453911891
total_rewards_min            3154.0378145476693
Number of train steps total  1096000
Number of env steps total    1372000
Number of rollouts total     0
Train Time (s)               199.03214644128457
(Previous) Eval Time (s)     23.161612110678107
Sample Time (s)              16.451579596847296
Epoch Time (s)               238.64533814880997
Total Train Time (s)         60907.72691500373
Epoch                        273
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:25:27.011855 UTC | [2020_01_13_04_30_18] Iteration #273 | Epoch Duration: 239.6740620136261
2020-01-13 21:25:27.012097 UTC | [2020_01_13_04_30_18] Iteration #273 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033655502
Z variance train             0.07294653
KL Divergence                4.4025927
KL Loss                      0.44025928
QF Loss                      1437.867
VF Loss                      550.94226
Policy Loss                  -2199.883
Q Predictions Mean           2198.641
Q Predictions Std            887.3389
Q Predictions Max            2758.3186
Q Predictions Min            21.753363
V Predictions Mean           2194.477
V Predictions Std            881.7487
V Predictions Max            2757.9778
V Predictions Min            30.081131
Log Pis Mean                 -4.3358297
Log Pis Std                  5.8533154
Log Pis Max                  21.537779
Log Pis Min                  -13.374659
Policy mu Mean               0.1765858
Policy mu Std                0.7485178
Policy mu Max                3.0307896
Policy mu Min                -3.2865388
Policy log std Mean          -0.33003858
Policy log std Std           0.15874505
Policy log std Max           -0.01658804
Policy log std Min           -1.267597
Z mean eval                  0.034020208
Z variance eval              0.060775496
total_rewards                [1887.24711227 5419.40382292 5323.47204265 5389.85879114 1126.74181076
 5324.95121208 5351.9934673  5385.13304599 5386.75351964 3326.20290698]
total_rewards_mean           4392.17577317442
total_rewards_std            1573.4794370255497
total_rewards_max            5419.403822923029
total_rewards_min            1126.741810760172
Number of train steps total  1100000
Number of env steps total    1377000
Number of rollouts total     0
Train Time (s)               194.9431993784383
(Previous) Eval Time (s)     24.190059361979365
Sample Time (s)              18.85998610733077
Epoch Time (s)               237.99324484774843
Total Train Time (s)         61143.72382702073
Epoch                        274
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:29:23.012341 UTC | [2020_01_13_04_30_18] Iteration #274 | Epoch Duration: 236.00007820129395
2020-01-13 21:29:23.012522 UTC | [2020_01_13_04_30_18] Iteration #274 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0334371
Z variance train             0.060759306
KL Divergence                4.7419043
KL Loss                      0.47419044
QF Loss                      2070.1045
VF Loss                      594.76324
Policy Loss                  -2108.0889
Q Predictions Mean           2104.163
Q Predictions Std            920.50824
Q Predictions Max            2766.1855
Q Predictions Min            19.178305
V Predictions Mean           2119.3113
V Predictions Std            918.20593
V Predictions Max            2774.1064
V Predictions Min            30.326918
Log Pis Mean                 -3.794178
Log Pis Std                  7.1277537
Log Pis Max                  33.31946
Log Pis Min                  -15.17032
Policy mu Mean               0.20734644
Policy mu Std                0.7737243
Policy mu Max                2.8064227
Policy mu Min                -3.8390849
Policy log std Mean          -0.34354508
Policy log std Std           0.17269321
Policy log std Max           0.010621309
Policy log std Min           -1.3733214
Z mean eval                  0.032752916
Z variance eval              0.06720936
total_rewards                [5268.32921888 5363.14135282 5272.19175644 5213.70707594 5257.16068578
 5299.69288003 5344.50065741 3191.42159356 5268.71827651 4318.85762939]
total_rewards_mean           4979.772112675206
total_rewards_std            663.4220407232231
total_rewards_max            5363.141352822529
total_rewards_min            3191.421593558853
Number of train steps total  1104000
Number of env steps total    1382000
Number of rollouts total     0
Train Time (s)               194.75200262479484
(Previous) Eval Time (s)     22.196591761894524
Sample Time (s)              17.58837756467983
Epoch Time (s)               234.5369719513692
Total Train Time (s)         61379.62205197988
Epoch                        275
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:33:18.916771 UTC | [2020_01_13_04_30_18] Iteration #275 | Epoch Duration: 235.90411186218262
2020-01-13 21:33:18.916946 UTC | [2020_01_13_04_30_18] Iteration #275 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03229933
Z variance train             0.06726548
KL Divergence                4.5475254
KL Loss                      0.45475253
QF Loss                      1919.155
VF Loss                      725.7489
Policy Loss                  -2216.6462
Q Predictions Mean           2213.4238
Q Predictions Std            806.8341
Q Predictions Max            2758.2903
Q Predictions Min            20.527948
V Predictions Mean           2230.3503
V Predictions Std            808.20825
V Predictions Max            2775.4878
V Predictions Min            31.993946
Log Pis Mean                 -3.9558682
Log Pis Std                  6.67666
Log Pis Max                  28.099415
Log Pis Min                  -13.62398
Policy mu Mean               0.16079557
Policy mu Std                0.7638502
Policy mu Max                3.084709
Policy mu Min                -3.5515375
Policy log std Mean          -0.33347386
Policy log std Std           0.16802393
Policy log std Max           -0.01319509
Policy log std Min           -1.1702665
Z mean eval                  0.04043808
Z variance eval              0.06323012
total_rewards                [5251.39440031 5331.97667609 5193.25281321 5193.43041025 5230.12480984
 5267.47425295 5244.02874001 5279.48564236 5125.47251693 5201.18296649]
total_rewards_mean           5231.782322844061
total_rewards_std            54.147273625527845
total_rewards_max            5331.976676089552
total_rewards_min            5125.472516926542
Number of train steps total  1108000
Number of env steps total    1387000
Number of rollouts total     0
Train Time (s)               199.67516907164827
(Previous) Eval Time (s)     23.563424873631448
Sample Time (s)              18.896982669830322
Epoch Time (s)               242.13557661511004
Total Train Time (s)         61625.38270390406
Epoch                        276
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:37:24.680026 UTC | [2020_01_13_04_30_18] Iteration #276 | Epoch Duration: 245.76293873786926
2020-01-13 21:37:24.680230 UTC | [2020_01_13_04_30_18] Iteration #276 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04058347
Z variance train             0.06326297
KL Divergence                4.6942806
KL Loss                      0.46942806
QF Loss                      2124.7793
VF Loss                      685.2439
Policy Loss                  -2070.1255
Q Predictions Mean           2071.4722
Q Predictions Std            971.3671
Q Predictions Max            2795.332
Q Predictions Min            23.568638
V Predictions Mean           2071.9048
V Predictions Std            967.2995
V Predictions Max            2786.3923
V Predictions Min            23.918291
Log Pis Mean                 -3.9660068
Log Pis Std                  6.5197353
Log Pis Max                  31.90878
Log Pis Min                  -14.07748
Policy mu Mean               0.16682824
Policy mu Std                0.7556848
Policy mu Max                2.8741555
Policy mu Min                -2.830851
Policy log std Mean          -0.33102888
Policy log std Std           0.17118439
Policy log std Max           0.078113556
Policy log std Min           -1.3724658
Z mean eval                  0.030508459
Z variance eval              0.06877737
total_rewards                [5239.18964234 5289.66987934 5272.47547596 5257.83840142 5272.14791757
 5249.40679873 5275.51088218 3173.33396423 5314.91197361 5248.82836749]
total_rewards_mean           5059.331330286323
total_rewards_std            629.0159125997384
total_rewards_max            5314.911973609208
total_rewards_min            3173.3339642267847
Number of train steps total  1112000
Number of env steps total    1392000
Number of rollouts total     0
Train Time (s)               194.5687924171798
(Previous) Eval Time (s)     27.190502339974046
Sample Time (s)              17.02467473829165
Epoch Time (s)               238.7839694954455
Total Train Time (s)         61859.575910812244
Epoch                        277
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:41:18.880944 UTC | [2020_01_13_04_30_18] Iteration #277 | Epoch Duration: 234.20049142837524
2020-01-13 21:41:18.881225 UTC | [2020_01_13_04_30_18] Iteration #277 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029484164
Z variance train             0.06873159
KL Divergence                4.4589953
KL Loss                      0.44589955
QF Loss                      1419.4413
VF Loss                      407.22565
Policy Loss                  -2250.661
Q Predictions Mean           2245.3623
Q Predictions Std            837.8376
Q Predictions Max            2768.602
Q Predictions Min            20.13853
V Predictions Mean           2261.7532
V Predictions Std            841.6045
V Predictions Max            2777.5674
V Predictions Min            26.671606
Log Pis Mean                 -5.163092
Log Pis Std                  5.3535285
Log Pis Max                  15.577377
Log Pis Min                  -14.410178
Policy mu Mean               0.1642032
Policy mu Std                0.7025107
Policy mu Max                3.3157482
Policy mu Min                -2.9563994
Policy log std Mean          -0.3219106
Policy log std Std           0.14851303
Policy log std Max           0.044063106
Policy log std Min           -1.2746584
Z mean eval                  0.032796074
Z variance eval              0.063121244
total_rewards                [2079.41173931 3219.43960494 5536.08485831 5411.30677318 3048.10973062
 1599.74947749 5398.21370734 2720.44988479 5469.74650527 4031.43830393]
total_rewards_mean           3851.3950585192056
total_rewards_std            1443.922916649287
total_rewards_max            5536.084858311633
total_rewards_min            1599.7494774931065
Number of train steps total  1116000
Number of env steps total    1397000
Number of rollouts total     0
Train Time (s)               198.26535242283717
(Previous) Eval Time (s)     22.606736508663744
Sample Time (s)              18.18622579984367
Epoch Time (s)               239.05831473134458
Total Train Time (s)         62093.615450102836
Epoch                        278
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:45:12.925975 UTC | [2020_01_13_04_30_18] Iteration #278 | Epoch Duration: 234.0445477962494
2020-01-13 21:45:12.926302 UTC | [2020_01_13_04_30_18] Iteration #278 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032439254
Z variance train             0.063114874
KL Divergence                4.6850786
KL Loss                      0.46850786
QF Loss                      1697.1134
VF Loss                      403.39758
Policy Loss                  -2263.1428
Q Predictions Mean           2262.0837
Q Predictions Std            812.21185
Q Predictions Max            2767.8643
Q Predictions Min            21.792742
V Predictions Mean           2270.283
V Predictions Std            812.64636
V Predictions Max            2777.568
V Predictions Min            31.681334
Log Pis Mean                 -4.023313
Log Pis Std                  5.6828165
Log Pis Max                  23.33347
Log Pis Min                  -14.050592
Policy mu Mean               0.19714421
Policy mu Std                0.76069796
Policy mu Max                3.124793
Policy mu Min                -2.5385256
Policy log std Mean          -0.34453872
Policy log std Std           0.16217475
Policy log std Max           0.01082024
Policy log std Min           -1.2697414
Z mean eval                  0.02855362
Z variance eval              0.061684005
total_rewards                [5293.40311652 5194.76554726 5291.5885868  5306.70833051 5321.87880037
 1005.87546649 1327.82195915 3550.96409643 5158.34657564 5303.53621433]
total_rewards_mean           4275.488869350318
total_rewards_std            1637.4489415870544
total_rewards_max            5321.878800371293
total_rewards_min            1005.8754664895561
Number of train steps total  1120000
Number of env steps total    1402000
Number of rollouts total     0
Train Time (s)               193.95475894305855
(Previous) Eval Time (s)     17.59268046123907
Sample Time (s)              17.065068610943854
Epoch Time (s)               228.61250801524147
Total Train Time (s)         62325.05963764014
Epoch                        279
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:49:04.373499 UTC | [2020_01_13_04_30_18] Iteration #279 | Epoch Duration: 231.44690418243408
2020-01-13 21:49:04.373749 UTC | [2020_01_13_04_30_18] Iteration #279 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029194165
Z variance train             0.061696738
KL Divergence                4.6812696
KL Loss                      0.46812698
QF Loss                      1447.414
VF Loss                      408.47174
Policy Loss                  -2191.7322
Q Predictions Mean           2183.669
Q Predictions Std            896.6939
Q Predictions Max            2784.58
Q Predictions Min            17.629456
V Predictions Mean           2182.887
V Predictions Std            897.3133
V Predictions Max            2785.2146
V Predictions Min            22.531862
Log Pis Mean                 -4.572319
Log Pis Std                  6.5597982
Log Pis Max                  31.647648
Log Pis Min                  -13.650381
Policy mu Mean               0.21781458
Policy mu Std                0.72437304
Policy mu Max                3.4923131
Policy mu Min                -3.385748
Policy log std Mean          -0.33688372
Policy log std Std           0.17269884
Policy log std Max           -0.04510536
Policy log std Min           -1.8131739
Z mean eval                  0.03628584
Z variance eval              0.065100655
total_rewards                [5284.39420281 5242.3707776  5245.57622051 5334.64834871 5264.18345206
 5274.21599739 5237.61380392 5101.24605106 1616.46520291 5261.29169094]
total_rewards_mean           4886.2005747909025
total_rewards_std            1091.3614078358755
total_rewards_max            5334.648348712019
total_rewards_min            1616.4652029093754
Number of train steps total  1124000
Number of env steps total    1407000
Number of rollouts total     0
Train Time (s)               198.16643799003214
(Previous) Eval Time (s)     20.426803972106427
Sample Time (s)              18.761394136119634
Epoch Time (s)               237.3546360982582
Total Train Time (s)         62566.76259749057
Epoch                        280
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:53:06.079197 UTC | [2020_01_13_04_30_18] Iteration #280 | Epoch Duration: 241.70528960227966
2020-01-13 21:53:06.079400 UTC | [2020_01_13_04_30_18] Iteration #280 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035756353
Z variance train             0.06510508
KL Divergence                4.5322437
KL Loss                      0.4532244
QF Loss                      1865.342
VF Loss                      874.11584
Policy Loss                  -2262.0144
Q Predictions Mean           2257.2273
Q Predictions Std            800.67346
Q Predictions Max            2772.4744
Q Predictions Min            24.777039
V Predictions Mean           2259.4912
V Predictions Std            800.72406
V Predictions Max            2776.4644
V Predictions Min            33.79534
Log Pis Mean                 -4.5531454
Log Pis Std                  6.119173
Log Pis Max                  29.010914
Log Pis Min                  -16.504105
Policy mu Mean               0.18938822
Policy mu Std                0.7288751
Policy mu Max                2.9817152
Policy mu Min                -3.1788769
Policy log std Mean          -0.33764064
Policy log std Std           0.166107
Policy log std Max           -0.019849814
Policy log std Min           -1.258234
Z mean eval                  0.033006463
Z variance eval              0.05524277
total_rewards                [3267.46445713 1073.66086581 2411.9780316  4469.68969004 2534.78185197
 5461.08781797 5402.44886846 5325.74741964 5545.81976868  719.4757124 ]
total_rewards_mean           3621.2154483690415
total_rewards_std            1776.6604375233596
total_rewards_max            5545.819768676794
total_rewards_min            719.4757123961745
Number of train steps total  1128000
Number of env steps total    1412000
Number of rollouts total     0
Train Time (s)               198.18776815198362
(Previous) Eval Time (s)     24.777177683077753
Sample Time (s)              18.934600742533803
Epoch Time (s)               241.89954657759517
Total Train Time (s)         62802.07692822302
Epoch                        281
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 21:57:01.396335 UTC | [2020_01_13_04_30_18] Iteration #281 | Epoch Duration: 235.31679940223694
2020-01-13 21:57:01.396533 UTC | [2020_01_13_04_30_18] Iteration #281 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032614976
Z variance train             0.05519762
KL Divergence                4.9201536
KL Loss                      0.49201536
QF Loss                      1759.3422
VF Loss                      943.91534
Policy Loss                  -2296.0679
Q Predictions Mean           2288.7935
Q Predictions Std            793.6093
Q Predictions Max            2796.8179
Q Predictions Min            16.674559
V Predictions Mean           2300.442
V Predictions Std            790.776
V Predictions Max            2804.903
V Predictions Min            20.830908
Log Pis Mean                 -4.5016446
Log Pis Std                  6.0297494
Log Pis Max                  20.738049
Log Pis Min                  -17.366158
Policy mu Mean               0.18414699
Policy mu Std                0.7226588
Policy mu Max                2.673902
Policy mu Min                -3.2115612
Policy log std Mean          -0.33053392
Policy log std Std           0.17141506
Policy log std Max           -0.004963018
Policy log std Min           -1.2354462
Z mean eval                  0.04311716
Z variance eval              0.060712326
total_rewards                [5313.54588784 2988.54744045 2281.2792321  5168.10223365 5196.02546332
  909.86152452 3910.53748898 4996.65175934 5258.44890162 5197.9555978 ]
total_rewards_mean           4122.095552962823
total_rewards_std            1480.4516869705294
total_rewards_max            5313.545887841483
total_rewards_min            909.8615245207727
Number of train steps total  1132000
Number of env steps total    1417000
Number of rollouts total     0
Train Time (s)               195.3494926779531
(Previous) Eval Time (s)     18.194069203920662
Sample Time (s)              18.891355664934963
Epoch Time (s)               232.43491754680872
Total Train Time (s)         63037.99579512561
Epoch                        282
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:00:57.316945 UTC | [2020_01_13_04_30_18] Iteration #282 | Epoch Duration: 235.92032122612
2020-01-13 22:00:57.317061 UTC | [2020_01_13_04_30_18] Iteration #282 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04362107
Z variance train             0.060725547
KL Divergence                4.694147
KL Loss                      0.4694147
QF Loss                      1756.528
VF Loss                      526.769
Policy Loss                  -2258.0566
Q Predictions Mean           2248.513
Q Predictions Std            821.61475
Q Predictions Max            2797.795
Q Predictions Min            17.834993
V Predictions Mean           2246.6704
V Predictions Std            819.8638
V Predictions Max            2791.388
V Predictions Min            22.989677
Log Pis Mean                 -4.5183563
Log Pis Std                  5.382231
Log Pis Max                  14.635756
Log Pis Min                  -14.418131
Policy mu Mean               0.16101469
Policy mu Std                0.7371058
Policy mu Max                3.1342885
Policy mu Min                -2.6958587
Policy log std Mean          -0.32725084
Policy log std Std           0.14776419
Policy log std Max           0.018518545
Policy log std Min           -1.1027715
Z mean eval                  0.02981469
Z variance eval              0.072589874
total_rewards                [5245.52472345 4885.6500871  5153.28839203 5238.51131652 5206.88057941
 5249.66081004 1956.2447493  3794.04242047 5332.45842761 5183.91636077]
total_rewards_mean           4724.617786670377
total_rewards_std            1018.0202981919547
total_rewards_max            5332.458427614724
total_rewards_min            1956.2447492993042
Number of train steps total  1136000
Number of env steps total    1422000
Number of rollouts total     0
Train Time (s)               192.3012446630746
(Previous) Eval Time (s)     21.67919434979558
Sample Time (s)              18.668384852819145
Epoch Time (s)               232.64882386568934
Total Train Time (s)         63271.247773098294
Epoch                        283
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:04:50.574734 UTC | [2020_01_13_04_30_18] Iteration #283 | Epoch Duration: 233.25754714012146
2020-01-13 22:04:50.574990 UTC | [2020_01_13_04_30_18] Iteration #283 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030092523
Z variance train             0.07258831
KL Divergence                4.342202
KL Loss                      0.43422022
QF Loss                      1081.9254
VF Loss                      359.53165
Policy Loss                  -2325.8608
Q Predictions Mean           2321.69
Q Predictions Std            819.669
Q Predictions Max            2804.492
Q Predictions Min            18.50982
V Predictions Mean           2319.9937
V Predictions Std            820.01495
V Predictions Max            2809.907
V Predictions Min            29.038261
Log Pis Mean                 -5.5396595
Log Pis Std                  5.452466
Log Pis Max                  34.231495
Log Pis Min                  -13.506767
Policy mu Mean               0.14674243
Policy mu Std                0.6785045
Policy mu Max                2.42073
Policy mu Min                -4.5788226
Policy log std Mean          -0.3153675
Policy log std Std           0.13716169
Policy log std Max           0.006638989
Policy log std Min           -1.0891399
Z mean eval                  0.031910345
Z variance eval              0.070829034
total_rewards                [5218.80969593 5405.87618074 5197.61669352 1357.68243138 5333.26957609
 5289.24765582 3158.94815756 5164.14044686 5254.25420038 5274.3757871 ]
total_rewards_mean           4665.422082537581
total_rewards_std            1270.818359066594
total_rewards_max            5405.876180736685
total_rewards_min            1357.6824313758768
Number of train steps total  1140000
Number of env steps total    1427000
Number of rollouts total     0
Train Time (s)               192.47605944005772
(Previous) Eval Time (s)     22.287630639970303
Sample Time (s)              18.738726270850748
Epoch Time (s)               233.50241635087878
Total Train Time (s)         63506.327994862106
Epoch                        284
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:08:45.655861 UTC | [2020_01_13_04_30_18] Iteration #284 | Epoch Duration: 235.08069777488708
2020-01-13 22:08:45.655992 UTC | [2020_01_13_04_30_18] Iteration #284 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03173764
Z variance train             0.0707538
KL Divergence                4.520941
KL Loss                      0.45209408
QF Loss                      1991.2822
VF Loss                      396.04214
Policy Loss                  -2280.8005
Q Predictions Mean           2274.5952
Q Predictions Std            809.8169
Q Predictions Max            2835.7937
Q Predictions Min            21.763859
V Predictions Mean           2274.375
V Predictions Std            804.7519
V Predictions Max            2814.1833
V Predictions Min            33.74936
Log Pis Mean                 -4.468341
Log Pis Std                  6.9309683
Log Pis Max                  55.73825
Log Pis Min                  -15.500135
Policy mu Mean               0.15680812
Policy mu Std                0.75090384
Policy mu Max                5.1025734
Policy mu Min                -3.3732393
Policy log std Mean          -0.33019483
Policy log std Std           0.1651292
Policy log std Max           0.00071389973
Policy log std Min           -1.3144621
Z mean eval                  0.027960446
Z variance eval              0.07065587
total_rewards                [5341.81285929 5310.91994559 5342.52025857  769.73369822 5376.32135963
 5236.97631406 2923.59580942 5206.3123802  5354.27639699 5194.03496215]
total_rewards_mean           4605.650398411265
total_rewards_std            1462.3891514965917
total_rewards_max            5376.32135963296
total_rewards_min            769.7336982204397
Number of train steps total  1144000
Number of env steps total    1432000
Number of rollouts total     0
Train Time (s)               199.31808628886938
(Previous) Eval Time (s)     23.865662932861596
Sample Time (s)              16.80972619075328
Epoch Time (s)               239.99347541248426
Total Train Time (s)         63746.046644470654
Epoch                        285
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:12:45.380991 UTC | [2020_01_13_04_30_18] Iteration #285 | Epoch Duration: 239.72487831115723
2020-01-13 22:12:45.381221 UTC | [2020_01_13_04_30_18] Iteration #285 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0284104
Z variance train             0.07065955
KL Divergence                4.502015
KL Loss                      0.4502015
QF Loss                      2116.893
VF Loss                      401.5212
Policy Loss                  -2294.9734
Q Predictions Mean           2289.0752
Q Predictions Std            825.6853
Q Predictions Max            2815.8938
Q Predictions Min            21.92417
V Predictions Mean           2292.6704
V Predictions Std            823.0948
V Predictions Max            2814.652
V Predictions Min            29.234684
Log Pis Mean                 -4.186557
Log Pis Std                  6.3859854
Log Pis Max                  33.64311
Log Pis Min                  -13.370398
Policy mu Mean               0.18031064
Policy mu Std                0.7484464
Policy mu Max                2.901138
Policy mu Min                -3.523237
Policy log std Mean          -0.33284843
Policy log std Std           0.16397724
Policy log std Max           0.023863114
Policy log std Min           -1.3626062
Z mean eval                  0.037675656
Z variance eval              0.06949383
total_rewards                [5225.19428563 3508.52562828 4159.24984456 5459.67765174 5303.79215934
 5401.34970361 3063.44160814 2660.09048869 5431.20552535 1233.52929949]
total_rewards_mean           4144.6056194830035
total_rewards_std            1404.5434526092706
total_rewards_max            5459.677651739497
total_rewards_min            1233.5292994910246
Number of train steps total  1148000
Number of env steps total    1437000
Number of rollouts total     0
Train Time (s)               191.91925480216742
(Previous) Eval Time (s)     23.59678384801373
Sample Time (s)              16.534363699611276
Epoch Time (s)               232.05040234979242
Total Train Time (s)         63975.52818195056
Epoch                        286
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:16:34.869199 UTC | [2020_01_13_04_30_18] Iteration #286 | Epoch Duration: 229.48778247833252
2020-01-13 22:16:34.869469 UTC | [2020_01_13_04_30_18] Iteration #286 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037829544
Z variance train             0.06954594
KL Divergence                4.5836563
KL Loss                      0.45836565
QF Loss                      1625.7933
VF Loss                      470.56393
Policy Loss                  -2304.137
Q Predictions Mean           2290.1646
Q Predictions Std            815.8999
Q Predictions Max            2790.9565
Q Predictions Min            15.878784
V Predictions Mean           2302.2341
V Predictions Std            814.5236
V Predictions Max            2801.3662
V Predictions Min            30.037712
Log Pis Mean                 -4.331695
Log Pis Std                  6.2411723
Log Pis Max                  29.310123
Log Pis Min                  -14.869923
Policy mu Mean               0.18459377
Policy mu Std                0.7255654
Policy mu Max                2.6634078
Policy mu Min                -3.5747461
Policy log std Mean          -0.33889833
Policy log std Std           0.16674219
Policy log std Max           -0.030288614
Policy log std Min           -1.3811537
Z mean eval                  0.034470927
Z variance eval              0.07026942
total_rewards                [5273.81038603 5208.06113047 5118.60635756 5372.85326044 1558.15227208
 3981.32348562 4645.34243471 5282.55182945 5269.93072061 5253.02667868]
total_rewards_mean           4696.365855565353
total_rewards_std            1121.4246247019655
total_rewards_max            5372.853260441831
total_rewards_min            1558.1522720790279
Number of train steps total  1152000
Number of env steps total    1442000
Number of rollouts total     0
Train Time (s)               194.09549548197538
(Previous) Eval Time (s)     21.033897390123457
Sample Time (s)              18.59109726268798
Epoch Time (s)               233.72049013478681
Total Train Time (s)         64209.49337979825
Epoch                        287
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:20:28.836781 UTC | [2020_01_13_04_30_18] Iteration #287 | Epoch Duration: 233.9671175479889
2020-01-13 22:20:28.836950 UTC | [2020_01_13_04_30_18] Iteration #287 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03383539
Z variance train             0.07029332
KL Divergence                4.405509
KL Loss                      0.4405509
QF Loss                      1401.1626
VF Loss                      581.41547
Policy Loss                  -2308.0574
Q Predictions Mean           2306.6738
Q Predictions Std            813.5916
Q Predictions Max            2808.2437
Q Predictions Min            18.946417
V Predictions Mean           2315.6895
V Predictions Std            814.4035
V Predictions Max            2810.1782
V Predictions Min            26.485292
Log Pis Mean                 -5.049565
Log Pis Std                  5.296449
Log Pis Max                  17.727192
Log Pis Min                  -12.603846
Policy mu Mean               0.13238408
Policy mu Std                0.7207528
Policy mu Max                2.4675457
Policy mu Min                -3.2429068
Policy log std Mean          -0.3187363
Policy log std Std           0.15980859
Policy log std Max           0.08843966
Policy log std Min           -1.4805865
Z mean eval                  0.04150797
Z variance eval              0.076579034
total_rewards                [5270.13700423 5199.20028072 5095.02514161 5135.48041296 5249.53131534
 5309.0128575  5235.931664   5242.16581896 5169.09027621 5194.72143214]
total_rewards_mean           5210.029620366563
total_rewards_std            61.22570819729641
total_rewards_max            5309.012857498413
total_rewards_min            5095.025141605352
Number of train steps total  1156000
Number of env steps total    1447000
Number of rollouts total     0
Train Time (s)               197.29906566580757
(Previous) Eval Time (s)     21.280266084242612
Sample Time (s)              18.817821092903614
Epoch Time (s)               237.3971528429538
Total Train Time (s)         64452.24086413439
Epoch                        288
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:24:31.589401 UTC | [2020_01_13_04_30_18] Iteration #288 | Epoch Duration: 242.7523331642151
2020-01-13 22:24:31.589534 UTC | [2020_01_13_04_30_18] Iteration #288 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04121414
Z variance train             0.07656809
KL Divergence                4.1777296
KL Loss                      0.41777298
QF Loss                      1181.4268
VF Loss                      304.56802
Policy Loss                  -2394.2932
Q Predictions Mean           2389.3994
Q Predictions Std            754.8991
Q Predictions Max            2817.9985
Q Predictions Min            13.040944
V Predictions Mean           2392.2612
V Predictions Std            748.4088
V Predictions Max            2822.2896
V Predictions Min            29.054384
Log Pis Mean                 -4.611895
Log Pis Std                  6.100229
Log Pis Max                  36.54011
Log Pis Min                  -13.038832
Policy mu Mean               0.17714348
Policy mu Std                0.7234835
Policy mu Max                2.7840033
Policy mu Min                -4.2668386
Policy log std Mean          -0.32697493
Policy log std Std           0.15029626
Policy log std Max           -0.022332273
Policy log std Min           -1.1398687
Z mean eval                  0.03500595
Z variance eval              0.069296636
total_rewards                [3186.17756594 1988.0162335  2366.90764422 5126.31500905 5212.26281728
 5266.65549428 4676.32363863 5132.16128404 5322.08762489 4965.13170128]
total_rewards_mean           4324.203901309476
total_rewards_std            1228.3108353350613
total_rewards_max            5322.087624893896
total_rewards_min            1988.0162334975066
Number of train steps total  1160000
Number of env steps total    1452000
Number of rollouts total     0
Train Time (s)               198.56912968680263
(Previous) Eval Time (s)     26.635166666004807
Sample Time (s)              18.869497762061656
Epoch Time (s)               244.0737941148691
Total Train Time (s)         64692.34411706636
Epoch                        289
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:28:31.695806 UTC | [2020_01_13_04_30_18] Iteration #289 | Epoch Duration: 240.10618209838867
2020-01-13 22:28:31.695926 UTC | [2020_01_13_04_30_18] Iteration #289 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03541471
Z variance train             0.06930379
KL Divergence                4.469751
KL Loss                      0.44697508
QF Loss                      1492.9058
VF Loss                      717.0615
Policy Loss                  -2296.5525
Q Predictions Mean           2285.5225
Q Predictions Std            825.0259
Q Predictions Max            2808.976
Q Predictions Min            17.364004
V Predictions Mean           2280.586
V Predictions Std            821.3048
V Predictions Max            2806.4463
V Predictions Min            30.156492
Log Pis Mean                 -4.671975
Log Pis Std                  6.2834516
Log Pis Max                  25.356005
Log Pis Min                  -15.097099
Policy mu Mean               0.14173687
Policy mu Std                0.7388277
Policy mu Max                3.2572098
Policy mu Min                -3.1493504
Policy log std Mean          -0.31004512
Policy log std Std           0.15691145
Policy log std Max           -0.003009826
Policy log std Min           -1.4493432
Z mean eval                  0.03758485
Z variance eval              0.09272938
total_rewards                [5159.46226464 5036.25475959 5276.73795317 4300.47784709 3931.2657103
 1344.24397087 5212.44995662 3018.21763687 5275.30362935 3609.47340012]
total_rewards_mean           4216.3887128627275
total_rewards_std            1222.3292937649592
total_rewards_max            5276.737953173236
total_rewards_min            1344.2439708727675
Number of train steps total  1164000
Number of env steps total    1457000
Number of rollouts total     0
Train Time (s)               192.58086486626416
(Previous) Eval Time (s)     22.667288592085242
Sample Time (s)              18.259653569199145
Epoch Time (s)               233.50780702754855
Total Train Time (s)         64923.88843953516
Epoch                        290
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:32:23.246112 UTC | [2020_01_13_04_30_18] Iteration #290 | Epoch Duration: 231.55007457733154
2020-01-13 22:32:23.246289 UTC | [2020_01_13_04_30_18] Iteration #290 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03778121
Z variance train             0.09269135
KL Divergence                3.9488099
KL Loss                      0.39488098
QF Loss                      1789.5172
VF Loss                      820.52246
Policy Loss                  -2379.2886
Q Predictions Mean           2370.3003
Q Predictions Std            737.4215
Q Predictions Max            2824.6667
Q Predictions Min            23.198097
V Predictions Mean           2375.1707
V Predictions Std            735.93115
V Predictions Max            2820.9426
V Predictions Min            31.845894
Log Pis Mean                 -4.451915
Log Pis Std                  6.3402925
Log Pis Max                  35.7968
Log Pis Min                  -16.841955
Policy mu Mean               0.17641062
Policy mu Std                0.7471844
Policy mu Max                3.1370344
Policy mu Min                -3.3413446
Policy log std Mean          -0.3346223
Policy log std Std           0.15650706
Policy log std Max           -0.016032599
Policy log std Min           -1.2388977
Z mean eval                  0.048645053
Z variance eval              0.08298266
total_rewards                [3249.86778494 5047.06663215 1129.4239908  3932.67937524 5400.97516639
 5359.32255112 5422.74204646 5435.65888521 5337.83860362  849.54771982]
total_rewards_mean           4116.51227557517
total_rewards_std            1714.0302429959602
total_rewards_max            5435.658885209675
total_rewards_min            849.5477198215061
Number of train steps total  1168000
Number of env steps total    1462000
Number of rollouts total     0
Train Time (s)               194.0813251659274
(Previous) Eval Time (s)     20.70929275918752
Sample Time (s)              16.781144832726568
Epoch Time (s)               231.5717627578415
Total Train Time (s)         65153.15087470412
Epoch                        291
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:36:12.516173 UTC | [2020_01_13_04_30_18] Iteration #291 | Epoch Duration: 229.2697319984436
2020-01-13 22:36:12.516356 UTC | [2020_01_13_04_30_18] Iteration #291 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04825356
Z variance train             0.08298433
KL Divergence                4.1538277
KL Loss                      0.41538277
QF Loss                      1966.0059
VF Loss                      577.65704
Policy Loss                  -2417.8901
Q Predictions Mean           2417.5596
Q Predictions Std            703.31146
Q Predictions Max            2816.0906
Q Predictions Min            24.514736
V Predictions Mean           2430.1958
V Predictions Std            707.81445
V Predictions Max            2828.238
V Predictions Min            27.536245
Log Pis Mean                 -4.7330413
Log Pis Std                  5.6301217
Log Pis Max                  22.344437
Log Pis Min                  -14.412861
Policy mu Mean               0.1799649
Policy mu Std                0.70678645
Policy mu Max                3.442952
Policy mu Min                -2.8343325
Policy log std Mean          -0.32063794
Policy log std Std           0.14928798
Policy log std Max           -0.06385197
Policy log std Min           -1.3502288
Z mean eval                  0.053219896
Z variance eval              0.08056567
total_rewards                [5334.79304756 5135.75577668 5248.07413675 5373.59412391 4706.25276096
 5149.88979995 5310.08779459 5289.71361123 2549.60397992 2352.93503937]
total_rewards_mean           4645.070007092214
total_rewards_std            1112.2999925459917
total_rewards_max            5373.594123909116
total_rewards_min            2352.935039368404
Number of train steps total  1172000
Number of env steps total    1467000
Number of rollouts total     0
Train Time (s)               193.23786333063617
(Previous) Eval Time (s)     18.4069824363105
Sample Time (s)              18.79353811405599
Epoch Time (s)               230.43838388100266
Total Train Time (s)         65389.13394750608
Epoch                        292
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:40:08.500493 UTC | [2020_01_13_04_30_18] Iteration #292 | Epoch Duration: 235.98402571678162
2020-01-13 22:40:08.500616 UTC | [2020_01_13_04_30_18] Iteration #292 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05375757
Z variance train             0.080582455
KL Divergence                4.1093564
KL Loss                      0.41093564
QF Loss                      1434.607
VF Loss                      431.12488
Policy Loss                  -2402.4724
Q Predictions Mean           2398.4312
Q Predictions Std            767.0334
Q Predictions Max            2843.2344
Q Predictions Min            19.660364
V Predictions Mean           2397.0417
V Predictions Std            763.51355
V Predictions Max            2849.3628
V Predictions Min            26.452343
Log Pis Mean                 -4.1525273
Log Pis Std                  5.851971
Log Pis Max                  22.798592
Log Pis Min                  -13.787978
Policy mu Mean               0.2255159
Policy mu Std                0.7216897
Policy mu Max                3.6667402
Policy mu Min                -3.403235
Policy log std Mean          -0.33377916
Policy log std Std           0.14909896
Policy log std Max           0.031227931
Policy log std Min           -1.4200281
Z mean eval                  0.058137726
Z variance eval              0.083484665
total_rewards                [ 697.36511229 5445.62362683 5337.06837118 5341.6350179  5370.29655683
 5421.98747504 5308.26669973 5456.93322032 5366.0228204  5340.07380961]
total_rewards_mean           4908.527271013949
total_rewards_std            1404.5118924617732
total_rewards_max            5456.933220318087
total_rewards_min            697.3651122914896
Number of train steps total  1176000
Number of env steps total    1472000
Number of rollouts total     0
Train Time (s)               190.9156751553528
(Previous) Eval Time (s)     23.952344513032585
Sample Time (s)              18.88589618075639
Epoch Time (s)               233.75391584914178
Total Train Time (s)         65620.30755276838
Epoch                        293
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:43:59.680781 UTC | [2020_01_13_04_30_18] Iteration #293 | Epoch Duration: 231.18003821372986
2020-01-13 22:43:59.681026 UTC | [2020_01_13_04_30_18] Iteration #293 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.058797665
Z variance train             0.08347487
KL Divergence                4.0352745
KL Loss                      0.40352747
QF Loss                      1919.9639
VF Loss                      641.8203
Policy Loss                  -2451.7795
Q Predictions Mean           2444.13
Q Predictions Std            674.10504
Q Predictions Max            2840.342
Q Predictions Min            22.447353
V Predictions Mean           2441.8662
V Predictions Std            668.59235
V Predictions Max            2833.0579
V Predictions Min            27.581322
Log Pis Mean                 -4.116804
Log Pis Std                  6.282554
Log Pis Max                  35.459038
Log Pis Min                  -14.123566
Policy mu Mean               0.176787
Policy mu Std                0.756749
Policy mu Max                3.262591
Policy mu Min                -3.6810062
Policy log std Mean          -0.3388303
Policy log std Std           0.1614388
Policy log std Max           -0.008173801
Policy log std Min           -1.1980357
Z mean eval                  0.041973453
Z variance eval              0.0993852
total_rewards                [5242.00004582 5198.54426735 5200.99309557 1873.35293926 5199.28193234
 5307.03299477 2595.81228847 5180.30386795 5304.81720318 5316.71143913]
total_rewards_mean           4641.885007382448
total_rewards_std            1215.3876206526056
total_rewards_max            5316.711439128954
total_rewards_min            1873.3529392578816
Number of train steps total  1180000
Number of env steps total    1477000
Number of rollouts total     0
Train Time (s)               190.72128999978304
(Previous) Eval Time (s)     21.378186070825905
Sample Time (s)              18.33399378322065
Epoch Time (s)               230.4334698538296
Total Train Time (s)         65850.8721783557
Epoch                        294
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:47:50.252788 UTC | [2020_01_13_04_30_18] Iteration #294 | Epoch Duration: 230.5714876651764
2020-01-13 22:47:50.253130 UTC | [2020_01_13_04_30_18] Iteration #294 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04176993
Z variance train             0.09936967
KL Divergence                3.7468042
KL Loss                      0.37468043
QF Loss                      1603.7605
VF Loss                      440.21155
Policy Loss                  -2401.178
Q Predictions Mean           2393.6294
Q Predictions Std            774.2331
Q Predictions Max            2846.9697
Q Predictions Min            18.634134
V Predictions Mean           2404.8323
V Predictions Std            778.5949
V Predictions Max            2873.041
V Predictions Min            32.807095
Log Pis Mean                 -4.8721275
Log Pis Std                  5.964814
Log Pis Max                  30.380943
Log Pis Min                  -16.49553
Policy mu Mean               0.18175836
Policy mu Std                0.71047175
Policy mu Max                3.5200036
Policy mu Min                -3.1799843
Policy log std Mean          -0.32535842
Policy log std Std           0.15727352
Policy log std Max           -0.019250855
Policy log std Min           -1.2831872
Z mean eval                  0.044200495
Z variance eval              0.08670856
total_rewards                [5385.03282328 5187.11466788 3164.47855356 2563.66443163 5393.45901636
 2104.56317813 5196.2771236  5427.73377773 4726.32346851 5328.92366497]
total_rewards_mean           4447.757070565456
total_rewards_std            1240.2154863980338
total_rewards_max            5427.733777734847
total_rewards_min            2104.563178125555
Number of train steps total  1184000
Number of env steps total    1482000
Number of rollouts total     0
Train Time (s)               195.227368358057
(Previous) Eval Time (s)     21.515906292013824
Sample Time (s)              17.009769157506526
Epoch Time (s)               233.75304380757734
Total Train Time (s)         66083.62216447853
Epoch                        295
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:51:43.005575 UTC | [2020_01_13_04_30_18] Iteration #295 | Epoch Duration: 232.7522361278534
2020-01-13 22:51:43.005758 UTC | [2020_01_13_04_30_18] Iteration #295 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043525383
Z variance train             0.08668921
KL Divergence                3.8843844
KL Loss                      0.38843843
QF Loss                      1381.7739
VF Loss                      506.2642
Policy Loss                  -2459.5813
Q Predictions Mean           2456.8042
Q Predictions Std            679.89215
Q Predictions Max            2850.0916
Q Predictions Min            22.654099
V Predictions Mean           2468.7747
V Predictions Std            685.9092
V Predictions Max            2873.8706
V Predictions Min            32.034523
Log Pis Mean                 -4.895399
Log Pis Std                  6.4486284
Log Pis Max                  32.220985
Log Pis Min                  -15.02017
Policy mu Mean               0.17566538
Policy mu Std                0.70977163
Policy mu Max                3.1516888
Policy mu Min                -4.0168285
Policy log std Mean          -0.31788045
Policy log std Std           0.14741956
Policy log std Max           0.0039370954
Policy log std Min           -1.2072295
Z mean eval                  0.044496644
Z variance eval              0.08127035
total_rewards                [3122.59062988 5325.81670686 5475.52323111 5337.99917644 5469.90679311
 5512.05087499 5455.66904563 5437.59111605 1914.48341293 5418.74124942]
total_rewards_mean           4847.037223641856
total_rewards_std            1196.457176265644
total_rewards_max            5512.050874993411
total_rewards_min            1914.483412934461
Number of train steps total  1188000
Number of env steps total    1487000
Number of rollouts total     0
Train Time (s)               190.65613370900974
(Previous) Eval Time (s)     20.514826914295554
Sample Time (s)              17.737373339477926
Epoch Time (s)               228.90833396278322
Total Train Time (s)         66315.94983134326
Epoch                        296
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:55:35.337052 UTC | [2020_01_13_04_30_18] Iteration #296 | Epoch Duration: 232.33109736442566
2020-01-13 22:55:35.337284 UTC | [2020_01_13_04_30_18] Iteration #296 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045075126
Z variance train             0.08132472
KL Divergence                4.083104
KL Loss                      0.4083104
QF Loss                      1087.2839
VF Loss                      639.7647
Policy Loss                  -2443.4268
Q Predictions Mean           2434.5015
Q Predictions Std            718.35785
Q Predictions Max            2837.2007
Q Predictions Min            21.435738
V Predictions Mean           2431.9912
V Predictions Std            720.29645
V Predictions Max            2833.8691
V Predictions Min            11.441673
Log Pis Mean                 -4.596876
Log Pis Std                  5.412205
Log Pis Max                  24.358086
Log Pis Min                  -14.80467
Policy mu Mean               0.22491086
Policy mu Std                0.7125926
Policy mu Max                3.4140525
Policy mu Min                -3.0023444
Policy log std Mean          -0.32349098
Policy log std Std           0.15994968
Policy log std Max           0.0025882944
Policy log std Min           -1.1361555
Z mean eval                  0.04265281
Z variance eval              0.07938224
total_rewards                [5455.01630186 5323.98912217 4432.71493269 5458.12715669 1151.89638991
 5395.66429965 5399.39168973 5445.46087472 5397.82761786 4540.91243206]
total_rewards_mean           4800.100081736333
total_rewards_std            1270.2570923090616
total_rewards_max            5458.127156693845
total_rewards_min            1151.8963899117166
Number of train steps total  1192000
Number of env steps total    1492000
Number of rollouts total     0
Train Time (s)               193.5598750342615
(Previous) Eval Time (s)     23.937309687025845
Sample Time (s)              19.07064462453127
Epoch Time (s)               236.5678293458186
Total Train Time (s)         66551.22086100513
Epoch                        297
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 22:59:30.611534 UTC | [2020_01_13_04_30_18] Iteration #297 | Epoch Duration: 235.27410197257996
2020-01-13 22:59:30.611722 UTC | [2020_01_13_04_30_18] Iteration #297 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.042412013
Z variance train             0.07940073
KL Divergence                4.154154
KL Loss                      0.41541538
QF Loss                      1786.9088
VF Loss                      399.34012
Policy Loss                  -2424.4353
Q Predictions Mean           2425.7705
Q Predictions Std            699.8426
Q Predictions Max            2845.4954
Q Predictions Min            18.547764
V Predictions Mean           2427.2915
V Predictions Std            696.1953
V Predictions Max            2844.8953
V Predictions Min            26.718273
Log Pis Mean                 -3.65038
Log Pis Std                  6.074934
Log Pis Max                  21.724676
Log Pis Min                  -13.765186
Policy mu Mean               0.20090052
Policy mu Std                0.7454171
Policy mu Max                3.0431743
Policy mu Min                -3.3149166
Policy log std Mean          -0.33398813
Policy log std Std           0.17663138
Policy log std Max           0.14752367
Policy log std Min           -1.2078093
Z mean eval                  0.03376724
Z variance eval              0.09178382
total_rewards                [5379.91848635 5371.03874422 5218.7300864  5316.30600067 5300.51426755
 3193.51618762 5365.76722563 5233.7203428  3327.71631816 5395.52269947]
total_rewards_mean           4910.275035888301
total_rewards_std            827.3130496134472
total_rewards_max            5395.522699472573
total_rewards_min            3193.516187620297
Number of train steps total  1196000
Number of env steps total    1497000
Number of rollouts total     0
Train Time (s)               192.41386742563918
(Previous) Eval Time (s)     22.643310768995434
Sample Time (s)              17.133112887386233
Epoch Time (s)               232.19029108202085
Total Train Time (s)         66783.32257890468
Epoch                        298
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:03:22.717083 UTC | [2020_01_13_04_30_18] Iteration #298 | Epoch Duration: 232.10513973236084
2020-01-13 23:03:22.717351 UTC | [2020_01_13_04_30_18] Iteration #298 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033288624
Z variance train             0.091806516
KL Divergence                3.8403742
KL Loss                      0.38403744
QF Loss                      1460.383
VF Loss                      550.8888
Policy Loss                  -2409.6824
Q Predictions Mean           2399.5535
Q Predictions Std            761.8384
Q Predictions Max            2849.5771
Q Predictions Min            20.140526
V Predictions Mean           2413.2917
V Predictions Std            761.2691
V Predictions Max            2869.8457
V Predictions Min            26.776749
Log Pis Mean                 -4.82977
Log Pis Std                  5.615173
Log Pis Max                  23.014357
Log Pis Min                  -15.976612
Policy mu Mean               0.15902907
Policy mu Std                0.7187644
Policy mu Max                2.81053
Policy mu Min                -2.8925533
Policy log std Mean          -0.32878497
Policy log std Std           0.14725225
Policy log std Max           -0.073889844
Policy log std Min           -1.1458802
Z mean eval                  0.044342156
Z variance eval              0.09743825
total_rewards                [5408.76843503 3067.65021651 5305.23062353 5302.72776937 5308.73636887
 3522.06899492 5403.009724   5321.50170822 5370.18617477 5368.84905289]
total_rewards_mean           4937.87290681041
total_rewards_std            828.5979249993292
total_rewards_max            5408.768435025981
total_rewards_min            3067.6502165072347
Number of train steps total  1200000
Number of env steps total    1502000
Number of rollouts total     0
Train Time (s)               191.24267327226698
(Previous) Eval Time (s)     22.557863622903824
Sample Time (s)              17.030074431095272
Epoch Time (s)               230.83061132626608
Total Train Time (s)         67014.97003924754
Epoch                        299
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:07:14.365736 UTC | [2020_01_13_04_30_18] Iteration #299 | Epoch Duration: 231.6482343673706
2020-01-13 23:07:14.365871 UTC | [2020_01_13_04_30_18] Iteration #299 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04449965
Z variance train             0.09741379
KL Divergence                3.848764
KL Loss                      0.3848764
QF Loss                      1636.8191
VF Loss                      599.6531
Policy Loss                  -2454.4714
Q Predictions Mean           2448.505
Q Predictions Std            716.3697
Q Predictions Max            2886.0083
Q Predictions Min            21.257305
V Predictions Mean           2445.5854
V Predictions Std            715.5495
V Predictions Max            2886.9114
V Predictions Min            23.252686
Log Pis Mean                 -4.560828
Log Pis Std                  5.814873
Log Pis Max                  26.162216
Log Pis Min                  -15.136614
Policy mu Mean               0.15391672
Policy mu Std                0.73031914
Policy mu Max                3.8062646
Policy mu Min                -2.684847
Policy log std Mean          -0.33227208
Policy log std Std           0.1536606
Policy log std Max           0.029589206
Policy log std Min           -1.1415431
Z mean eval                  0.047521256
Z variance eval              0.10927421
total_rewards                [5385.40677455 5420.72659967 5382.00499548 5368.86422493 5256.09308944
 5356.69840517 2701.9082482  5269.62543213 4022.56921039 5473.16723816]
total_rewards_mean           4963.706421812783
total_rewards_std            855.591305949212
total_rewards_max            5473.16723815623
total_rewards_min            2701.908248202853
Number of train steps total  1204000
Number of env steps total    1507000
Number of rollouts total     0
Train Time (s)               192.34442918328568
(Previous) Eval Time (s)     23.375199063215405
Sample Time (s)              18.65215677721426
Epoch Time (s)               234.37178502371535
Total Train Time (s)         67248.63279121835
Epoch                        300
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:11:08.035300 UTC | [2020_01_13_04_30_18] Iteration #300 | Epoch Duration: 233.66920566558838
2020-01-13 23:11:08.035629 UTC | [2020_01_13_04_30_18] Iteration #300 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04742857
Z variance train             0.10937117
KL Divergence                3.6105337
KL Loss                      0.36105338
QF Loss                      1115.1073
VF Loss                      348.31668
Policy Loss                  -2497.912
Q Predictions Mean           2498.1277
Q Predictions Std            709.0944
Q Predictions Max            2882.684
Q Predictions Min            22.043373
V Predictions Mean           2501.2488
V Predictions Std            704.4307
V Predictions Max            2883.3203
V Predictions Min            36.063313
Log Pis Mean                 -4.8517437
Log Pis Std                  5.672429
Log Pis Max                  22.464867
Log Pis Min                  -17.011215
Policy mu Mean               0.20751324
Policy mu Std                0.70146716
Policy mu Max                3.6054254
Policy mu Min                -3.2478924
Policy log std Mean          -0.3259241
Policy log std Std           0.14949405
Policy log std Max           -0.0036441088
Policy log std Min           -1.1665363
Z mean eval                  0.04988337
Z variance eval              0.11099565
total_rewards                [5415.57166812 5420.48608177 5353.14057943 5411.02169863 5423.30537189
 4429.16885296 5160.73776588 5248.65054593 1449.30943291  914.65985496]
total_rewards_mean           4422.605185248116
total_rewards_std            1649.2245057720006
total_rewards_max            5423.30537188736
total_rewards_min            914.6598549629878
Number of train steps total  1208000
Number of env steps total    1512000
Number of rollouts total     0
Train Time (s)               194.74824919970706
(Previous) Eval Time (s)     22.67231827089563
Sample Time (s)              19.350075665861368
Epoch Time (s)               236.77064313646406
Total Train Time (s)         67485.00455907127
Epoch                        301
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:15:04.407758 UTC | [2020_01_13_04_30_18] Iteration #301 | Epoch Duration: 236.37194538116455
2020-01-13 23:15:04.407878 UTC | [2020_01_13_04_30_18] Iteration #301 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.050073404
Z variance train             0.11097834
KL Divergence                3.4712746
KL Loss                      0.34712747
QF Loss                      1064.2324
VF Loss                      273.74548
Policy Loss                  -2564.3157
Q Predictions Mean           2557.9749
Q Predictions Std            610.3693
Q Predictions Max            2858.9546
Q Predictions Min            21.674477
V Predictions Mean           2563.6116
V Predictions Std            611.1666
V Predictions Max            2861.5002
V Predictions Min            29.652708
Log Pis Mean                 -5.0076046
Log Pis Std                  4.8963833
Log Pis Max                  15.474311
Log Pis Min                  -14.303254
Policy mu Mean               0.1878367
Policy mu Std                0.6850926
Policy mu Max                2.8073468
Policy mu Min                -3.16643
Policy log std Mean          -0.33155143
Policy log std Std           0.1431903
Policy log std Max           -0.037323922
Policy log std Min           -1.2525382
Z mean eval                  0.051938765
Z variance eval              0.11925702
total_rewards                [4078.93605913 5399.82325038 2903.29391217 4896.81548111 4096.53025219
 5379.85746092 5204.25964524 3961.34452668 5429.42576045 3658.78505994]
total_rewards_mean           4500.907140820691
total_rewards_std            835.9691697345792
total_rewards_max            5429.425760451926
total_rewards_min            2903.2939121744716
Number of train steps total  1212000
Number of env steps total    1517000
Number of rollouts total     0
Train Time (s)               197.48472841084003
(Previous) Eval Time (s)     22.27332066791132
Sample Time (s)              18.755431099329144
Epoch Time (s)               238.5134801780805
Total Train Time (s)         67723.61315697152
Epoch                        302
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:19:03.018473 UTC | [2020_01_13_04_30_18] Iteration #302 | Epoch Duration: 238.61050415039062
2020-01-13 23:19:03.018595 UTC | [2020_01_13_04_30_18] Iteration #302 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.051842134
Z variance train             0.11927154
KL Divergence                3.4241643
KL Loss                      0.34241644
QF Loss                      1473.093
VF Loss                      194.5978
Policy Loss                  -2520.156
Q Predictions Mean           2513.4302
Q Predictions Std            715.38715
Q Predictions Max            2885.8423
Q Predictions Min            17.71761
V Predictions Mean           2517.2634
V Predictions Std            714.1021
V Predictions Max            2903.5947
V Predictions Min            32.4158
Log Pis Mean                 -5.5629025
Log Pis Std                  4.915244
Log Pis Max                  20.423737
Log Pis Min                  -13.840408
Policy mu Mean               0.18699987
Policy mu Std                0.6672976
Policy mu Max                2.5684845
Policy mu Min                -2.7357035
Policy log std Mean          -0.31522405
Policy log std Std           0.14529954
Policy log std Max           -0.004216112
Policy log std Min           -1.275036
Z mean eval                  0.057329267
Z variance eval              0.109438874
total_rewards                [5409.35043793 5421.24986633 5372.50199628 5391.57019404 5492.57649248
 5272.74198105 5520.64353687 5484.88990983 5474.67701749 5561.38190908]
total_rewards_mean           5440.158334137731
total_rewards_std            79.61546268371889
total_rewards_max            5561.381909082061
total_rewards_min            5272.741981052986
Number of train steps total  1216000
Number of env steps total    1522000
Number of rollouts total     0
Train Time (s)               197.89298526290804
(Previous) Eval Time (s)     22.37005309900269
Sample Time (s)              18.86045175557956
Epoch Time (s)               239.1234901174903
Total Train Time (s)         67965.24070527172
Epoch                        303
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:23:04.650285 UTC | [2020_01_13_04_30_18] Iteration #303 | Epoch Duration: 241.6315791606903
2020-01-13 23:23:04.650481 UTC | [2020_01_13_04_30_18] Iteration #303 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0573862
Z variance train             0.10950406
KL Divergence                3.5166183
KL Loss                      0.35166183
QF Loss                      1692.5858
VF Loss                      319.8744
Policy Loss                  -2549.6423
Q Predictions Mean           2544.7158
Q Predictions Std            632.70905
Q Predictions Max            2884.57
Q Predictions Min            18.64683
V Predictions Mean           2542.3975
V Predictions Std            630.9071
V Predictions Max            2877.7253
V Predictions Min            14.268245
Log Pis Mean                 -5.009617
Log Pis Std                  5.9557886
Log Pis Max                  35.14228
Log Pis Min                  -16.167362
Policy mu Mean               0.18876258
Policy mu Std                0.7099967
Policy mu Max                5.099863
Policy mu Min                -3.0098188
Policy log std Mean          -0.31942907
Policy log std Std           0.14778192
Policy log std Max           0.7970149
Policy log std Min           -1.1331173
Z mean eval                  0.056654483
Z variance eval              0.108731136
total_rewards                [5457.55873929 5356.30192923 5397.20758132 5410.27379022 5382.60782707
 5260.21281809 5431.00415269 5480.14374234 5427.937536   5402.12875257]
total_rewards_mean           5400.537686882576
total_rewards_std            57.745342224097456
total_rewards_max            5480.143742341783
total_rewards_min            5260.2128180861955
Number of train steps total  1220000
Number of env steps total    1527000
Number of rollouts total     0
Train Time (s)               195.40619593299925
(Previous) Eval Time (s)     24.87783114099875
Sample Time (s)              16.734588293358684
Epoch Time (s)               237.0186153673567
Total Train Time (s)         68201.1494056317
Epoch                        304
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:27:00.564490 UTC | [2020_01_13_04_30_18] Iteration #304 | Epoch Duration: 235.91385674476624
2020-01-13 23:27:00.564684 UTC | [2020_01_13_04_30_18] Iteration #304 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.056797385
Z variance train             0.10864209
KL Divergence                3.5357676
KL Loss                      0.35357675
QF Loss                      1290.2788
VF Loss                      534.35223
Policy Loss                  -2494.0847
Q Predictions Mean           2487.9805
Q Predictions Std            706.0323
Q Predictions Max            2883.9285
Q Predictions Min            20.26836
V Predictions Mean           2492.1646
V Predictions Std            701.25073
V Predictions Max            2882.0295
V Predictions Min            26.609203
Log Pis Mean                 -4.4471884
Log Pis Std                  6.4095254
Log Pis Max                  41.49233
Log Pis Min                  -14.205292
Policy mu Mean               0.20249857
Policy mu Std                0.7268851
Policy mu Max                4.516618
Policy mu Min                -4.5129356
Policy log std Mean          -0.32256866
Policy log std Std           0.1583011
Policy log std Max           0.6500909
Policy log std Min           -1.3017262
Z mean eval                  0.06393901
Z variance eval              0.12178218
total_rewards                [5448.91465087 5419.98392172 5557.80788288 5483.98953376 5041.40027731
 1081.13133623 2430.86184719 2117.547603   5516.34390275 5246.98172244]
total_rewards_mean           4334.496267815736
total_rewards_std            1645.9104908481856
total_rewards_max            5557.80788287555
total_rewards_min            1081.131336233102
Number of train steps total  1224000
Number of env steps total    1532000
Number of rollouts total     0
Train Time (s)               191.86124061094597
(Previous) Eval Time (s)     23.77278699306771
Sample Time (s)              18.927499674726278
Epoch Time (s)               234.56152727873996
Total Train Time (s)         68431.72685083747
Epoch                        305
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:30:51.144912 UTC | [2020_01_13_04_30_18] Iteration #305 | Epoch Duration: 230.5800964832306
2020-01-13 23:30:51.145069 UTC | [2020_01_13_04_30_18] Iteration #305 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06424072
Z variance train             0.12183899
KL Divergence                3.41541
KL Loss                      0.34154102
QF Loss                      1647.5844
VF Loss                      408.867
Policy Loss                  -2478.669
Q Predictions Mean           2477.7292
Q Predictions Std            745.44604
Q Predictions Max            2906.731
Q Predictions Min            21.94781
V Predictions Mean           2482.1416
V Predictions Std            743.4633
V Predictions Max            2899.1147
V Predictions Min            29.666683
Log Pis Mean                 -4.5205965
Log Pis Std                  5.563084
Log Pis Max                  15.968901
Log Pis Min                  -13.267548
Policy mu Mean               0.20389648
Policy mu Std                0.7176667
Policy mu Max                2.7303216
Policy mu Min                -3.2478824
Policy log std Mean          -0.33286756
Policy log std Std           0.15445161
Policy log std Max           0.108627886
Policy log std Min           -1.2284377
Z mean eval                  0.07018338
Z variance eval              0.11181507
total_rewards                [5237.26063485 5098.41180082 5176.82079414 5177.18176195 5267.35644271
 5148.73160568 5278.93864112 5296.47579463 5280.13683747 5134.63436497]
total_rewards_mean           5209.594867834962
total_rewards_std            67.2641475154695
total_rewards_max            5296.475794632399
total_rewards_min            5098.411800823115
Number of train steps total  1228000
Number of env steps total    1537000
Number of rollouts total     0
Train Time (s)               196.77559098880738
(Previous) Eval Time (s)     19.791074872016907
Sample Time (s)              18.589257821440697
Epoch Time (s)               235.15592368226498
Total Train Time (s)         68671.27657702239
Epoch                        306
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:34:50.697811 UTC | [2020_01_13_04_30_18] Iteration #306 | Epoch Duration: 239.55262112617493
2020-01-13 23:34:50.697966 UTC | [2020_01_13_04_30_18] Iteration #306 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07032943
Z variance train             0.11175849
KL Divergence                3.4956646
KL Loss                      0.34956646
QF Loss                      2463.455
VF Loss                      480.04233
Policy Loss                  -2544.7
Q Predictions Mean           2540.6704
Q Predictions Std            627.1199
Q Predictions Max            2896.2095
Q Predictions Min            14.647094
V Predictions Mean           2546.656
V Predictions Std            618.98895
V Predictions Max            2893.2532
V Predictions Min            32.641525
Log Pis Mean                 -4.5868154
Log Pis Std                  6.566361
Log Pis Max                  35.65799
Log Pis Min                  -14.138121
Policy mu Mean               0.1623555
Policy mu Std                0.7375198
Policy mu Max                3.6093698
Policy mu Min                -4.666481
Policy log std Mean          -0.33076945
Policy log std Std           0.16671953
Policy log std Max           0.048137657
Policy log std Min           -1.3990805
Z mean eval                  0.06584184
Z variance eval              0.10206817
total_rewards                [5382.57196086 5377.78610657 5250.11192597 5248.0321522  5516.92162618
 5368.0168359  5401.00434048 5409.56819689 5580.66976673 5388.89644086]
total_rewards_mean           5392.35793526317
total_rewards_std            96.60478546984575
total_rewards_max            5580.669766727784
total_rewards_min            5248.0321522009945
Number of train steps total  1232000
Number of env steps total    1542000
Number of rollouts total     0
Train Time (s)               195.09017537906766
(Previous) Eval Time (s)     24.18748025316745
Sample Time (s)              19.101735634729266
Epoch Time (s)               238.37939126696438
Total Train Time (s)         68912.0978981182
Epoch                        307
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:38:51.524170 UTC | [2020_01_13_04_30_18] Iteration #307 | Epoch Duration: 240.82607436180115
2020-01-13 23:38:51.524364 UTC | [2020_01_13_04_30_18] Iteration #307 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06578606
Z variance train             0.10201985
KL Divergence                3.724186
KL Loss                      0.3724186
QF Loss                      2256.4666
VF Loss                      804.7762
Policy Loss                  -2518.8298
Q Predictions Mean           2515.9258
Q Predictions Std            718.3348
Q Predictions Max            2906.365
Q Predictions Min            23.484543
V Predictions Mean           2519.3193
V Predictions Std            714.9997
V Predictions Max            2907.4812
V Predictions Min            27.248158
Log Pis Mean                 -4.67831
Log Pis Std                  5.490058
Log Pis Max                  19.22121
Log Pis Min                  -13.414802
Policy mu Mean               0.17582195
Policy mu Std                0.71932447
Policy mu Max                2.8748832
Policy mu Min                -2.857826
Policy log std Mean          -0.33130768
Policy log std Std           0.1456649
Policy log std Max           0.06506331
Policy log std Min           -1.1638751
Z mean eval                  0.06525079
Z variance eval              0.099108815
total_rewards                [5419.25597926 5541.18519837 2092.99343484 5531.38120463 2854.41502056
 4696.66310893 5443.74011186 5370.80284082 5539.11136977 1334.18933703]
total_rewards_mean           4382.373760606315
total_rewards_std            1553.893353053506
total_rewards_max            5541.185198365513
total_rewards_min            1334.189337025112
Number of train steps total  1236000
Number of env steps total    1547000
Number of rollouts total     0
Train Time (s)               192.0980690876022
(Previous) Eval Time (s)     26.633888536132872
Sample Time (s)              16.77634286135435
Epoch Time (s)               235.50830048508942
Total Train Time (s)         69141.63563286979
Epoch                        308
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:42:41.067537 UTC | [2020_01_13_04_30_18] Iteration #308 | Epoch Duration: 229.54296565055847
2020-01-13 23:42:41.067787 UTC | [2020_01_13_04_30_18] Iteration #308 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06459103
Z variance train             0.099176206
KL Divergence                3.8020763
KL Loss                      0.38020763
QF Loss                      1710.3308
VF Loss                      558.34656
Policy Loss                  -2541.99
Q Predictions Mean           2537.526
Q Predictions Std            642.5466
Q Predictions Max            2900.677
Q Predictions Min            20.470966
V Predictions Mean           2551.4075
V Predictions Std            644.2638
V Predictions Max            2911.7307
V Predictions Min            31.610893
Log Pis Mean                 -4.7352324
Log Pis Std                  5.1535063
Log Pis Max                  16.43501
Log Pis Min                  -14.225642
Policy mu Mean               0.18167423
Policy mu Std                0.7072573
Policy mu Max                2.4829319
Policy mu Min                -3.6715803
Policy log std Mean          -0.32786012
Policy log std Std           0.15415622
Policy log std Max           0.0026433915
Policy log std Min           -1.1522374
Z mean eval                  0.066656396
Z variance eval              0.09044298
total_rewards                [5309.15340697 5363.69850208 5155.02571444 1877.83785024 5323.76991426
 5384.50568085 5355.01935983 5389.89390442 5424.31958284 5327.66691461]
total_rewards_mean           4991.089083053805
total_rewards_std            1040.054236108187
total_rewards_max            5424.319582839378
total_rewards_min            1877.8378502353448
Number of train steps total  1240000
Number of env steps total    1552000
Number of rollouts total     0
Train Time (s)               194.65859717084095
(Previous) Eval Time (s)     20.66827906202525
Sample Time (s)              18.935397813562304
Epoch Time (s)               234.2622740464285
Total Train Time (s)         69379.03254507389
Epoch                        309
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:46:38.468337 UTC | [2020_01_13_04_30_18] Iteration #309 | Epoch Duration: 237.40039372444153
2020-01-13 23:46:38.468516 UTC | [2020_01_13_04_30_18] Iteration #309 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06643559
Z variance train             0.09038137
KL Divergence                4.0084248
KL Loss                      0.4008425
QF Loss                      1295.3408
VF Loss                      452.57703
Policy Loss                  -2534.9026
Q Predictions Mean           2533.6372
Q Predictions Std            702.1787
Q Predictions Max            2893.211
Q Predictions Min            23.373138
V Predictions Mean           2537.2246
V Predictions Std            697.9328
V Predictions Max            2887.1487
V Predictions Min            27.743645
Log Pis Mean                 -5.3503923
Log Pis Std                  5.265509
Log Pis Max                  20.8115
Log Pis Min                  -12.931159
Policy mu Mean               0.186952
Policy mu Std                0.6868441
Policy mu Max                3.7125154
Policy mu Min                -2.9524076
Policy log std Mean          -0.32238898
Policy log std Std           0.14043495
Policy log std Max           0.0006856322
Policy log std Min           -1.2303343
Z mean eval                  0.06925939
Z variance eval              0.09502212
total_rewards                [5391.37592329 5177.34231356 5423.39143547 5398.81173097 5250.81126468
 5436.0320793  5349.89918153 5421.10301481 5429.03430013 1326.22678582]
total_rewards_mean           4960.402802955622
total_rewards_std            1214.1138597614863
total_rewards_max            5436.03207929662
total_rewards_min            1326.2267858213454
Number of train steps total  1244000
Number of env steps total    1557000
Number of rollouts total     0
Train Time (s)               197.50878811394796
(Previous) Eval Time (s)     23.806095232255757
Sample Time (s)              18.74540687398985
Epoch Time (s)               240.06029022019356
Total Train Time (s)         69620.13781368732
Epoch                        310
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:50:39.576268 UTC | [2020_01_13_04_30_18] Iteration #310 | Epoch Duration: 241.10756397247314
2020-01-13 23:50:39.576594 UTC | [2020_01_13_04_30_18] Iteration #310 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06944737
Z variance train             0.09506981
KL Divergence                3.7556207
KL Loss                      0.37556207
QF Loss                      1250.7681
VF Loss                      587.96423
Policy Loss                  -2612.217
Q Predictions Mean           2606.3188
Q Predictions Std            560.8099
Q Predictions Max            2895.04
Q Predictions Min            26.11908
V Predictions Mean           2604.5776
V Predictions Std            557.506
V Predictions Max            2894.183
V Predictions Min            31.045927
Log Pis Mean                 -5.4049516
Log Pis Std                  5.3647857
Log Pis Max                  21.086636
Log Pis Min                  -13.689756
Policy mu Mean               0.17983721
Policy mu Std                0.6841178
Policy mu Max                3.1461637
Policy mu Min                -3.3937912
Policy log std Mean          -0.3084842
Policy log std Std           0.13316453
Policy log std Max           -0.019138753
Policy log std Min           -1.1035955
Z mean eval                  0.07101242
Z variance eval              0.09417963
total_rewards                [5281.34743108 5300.11922    1672.81574178 5286.36263999 5119.43520765
 5336.77603966 3099.13339642 5253.40547674 5382.56826482 5316.28114272]
total_rewards_mean           4704.824456085427
total_rewards_std            1204.2293736716372
total_rewards_max            5382.5682648174125
total_rewards_min            1672.815741777923
Number of train steps total  1248000
Number of env steps total    1562000
Number of rollouts total     0
Train Time (s)               194.49911906663328
(Previous) Eval Time (s)     24.853113489225507
Sample Time (s)              18.86962913814932
Epoch Time (s)               238.2218616940081
Total Train Time (s)         69854.73284051474
Epoch                        311
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:54:34.176540 UTC | [2020_01_13_04_30_18] Iteration #311 | Epoch Duration: 234.59975218772888
2020-01-13 23:54:34.176697 UTC | [2020_01_13_04_30_18] Iteration #311 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07112794
Z variance train             0.094229676
KL Divergence                3.8623276
KL Loss                      0.38623276
QF Loss                      1015.6932
VF Loss                      420.33423
Policy Loss                  -2618.617
Q Predictions Mean           2619.8274
Q Predictions Std            567.1994
Q Predictions Max            2909.2808
Q Predictions Min            15.99843
V Predictions Mean           2620.7026
V Predictions Std            559.5279
V Predictions Max            2908.4602
V Predictions Min            33.26521
Log Pis Mean                 -5.0638113
Log Pis Std                  4.9697294
Log Pis Max                  19.60514
Log Pis Min                  -17.472809
Policy mu Mean               0.1827203
Policy mu Std                0.71408075
Policy mu Max                3.2032533
Policy mu Min                -3.3207293
Policy log std Mean          -0.31258
Policy log std Std           0.1409952
Policy log std Max           -0.012046352
Policy log std Min           -1.1489184
Z mean eval                  0.06589126
Z variance eval              0.09515904
total_rewards                [5459.76799178 5306.80192759 5358.65743652 5593.90356854 5322.37350755
 5426.23828216 5428.92361458 5454.4739965  5472.53045922 3755.81490172]
total_rewards_mean           5257.948568615385
total_rewards_std            506.84350838090063
total_rewards_max            5593.903568538734
total_rewards_min            3755.8149017207556
Number of train steps total  1252000
Number of env steps total    1567000
Number of rollouts total     0
Train Time (s)               195.89950511977077
(Previous) Eval Time (s)     21.230717867147177
Sample Time (s)              19.11917598452419
Epoch Time (s)               236.24939897144213
Total Train Time (s)         70095.1654351321
Epoch                        312
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 23:58:34.611294 UTC | [2020_01_13_04_30_18] Iteration #312 | Epoch Duration: 240.43448662757874
2020-01-13 23:58:34.611414 UTC | [2020_01_13_04_30_18] Iteration #312 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06566024
Z variance train             0.09516064
KL Divergence                3.8129137
KL Loss                      0.38129136
QF Loss                      1200.2986
VF Loss                      351.9958
Policy Loss                  -2627.118
Q Predictions Mean           2619.2256
Q Predictions Std            554.0913
Q Predictions Max            2890.8047
Q Predictions Min            15.780403
V Predictions Mean           2626.6973
V Predictions Std            551.3505
V Predictions Max            2900.1199
V Predictions Min            26.863089
Log Pis Mean                 -5.6969686
Log Pis Std                  4.249856
Log Pis Max                  18.040756
Log Pis Min                  -16.545807
Policy mu Mean               0.19368137
Policy mu Std                0.64764374
Policy mu Max                3.0792742
Policy mu Min                -2.875785
Policy log std Mean          -0.31431946
Policy log std Std           0.13804553
Policy log std Max           -0.038213782
Policy log std Min           -1.275628
Z mean eval                  0.072181806
Z variance eval              0.08923119
total_rewards                [5207.50141104 5153.07457853 5259.55215978 5321.65851224  796.33816807
 5254.83264659 5142.99114675 5231.07455501 5471.50605011 1814.35604112]
total_rewards_mean           4465.288526923366
total_rewards_std            1598.698106929475
total_rewards_max            5471.5060501090475
total_rewards_min            796.3381680653126
Number of train steps total  1256000
Number of env steps total    1572000
Number of rollouts total     0
Train Time (s)               197.2973895710893
(Previous) Eval Time (s)     25.415527588687837
Sample Time (s)              18.687120617367327
Epoch Time (s)               241.40003777714446
Total Train Time (s)         70332.1068494767
Epoch                        313
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:02:31.556131 UTC | [2020_01_13_04_30_18] Iteration #313 | Epoch Duration: 236.94461226463318
2020-01-14 00:02:31.556301 UTC | [2020_01_13_04_30_18] Iteration #313 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07231118
Z variance train             0.089234926
KL Divergence                3.9113564
KL Loss                      0.39113566
QF Loss                      1532.1298
VF Loss                      374.49805
Policy Loss                  -2603.823
Q Predictions Mean           2601.7642
Q Predictions Std            598.3739
Q Predictions Max            2912.2727
Q Predictions Min            22.953127
V Predictions Mean           2602.9185
V Predictions Std            597.2586
V Predictions Max            2919.5881
V Predictions Min            29.845444
Log Pis Mean                 -5.017165
Log Pis Std                  5.468518
Log Pis Max                  19.191898
Log Pis Min                  -14.173695
Policy mu Mean               0.15803656
Policy mu Std                0.70384216
Policy mu Max                2.5663354
Policy mu Min                -3.6505454
Policy log std Mean          -0.32206878
Policy log std Std           0.14028303
Policy log std Max           -0.032967076
Policy log std Min           -1.2062988
Z mean eval                  0.06805709
Z variance eval              0.10193725
total_rewards                [3966.65368439 5303.09805221 5346.39710589 2117.50352443 5400.81622068
 5437.0038416  5323.04364666 2991.03628851 4223.97352587 5342.27480523]
total_rewards_mean           4545.180069547799
total_rewards_std            1128.3229039341647
total_rewards_max            5437.003841597106
total_rewards_min            2117.5035244250885
Number of train steps total  1260000
Number of env steps total    1577000
Number of rollouts total     0
Train Time (s)               198.41270991275087
(Previous) Eval Time (s)     20.959840553812683
Sample Time (s)              18.729866939596832
Epoch Time (s)               238.10241740616038
Total Train Time (s)         70572.07849220932
Epoch                        314
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:06:31.530007 UTC | [2020_01_13_04_30_18] Iteration #314 | Epoch Duration: 239.97358417510986
2020-01-14 00:06:31.530141 UTC | [2020_01_13_04_30_18] Iteration #314 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.067899145
Z variance train             0.10192418
KL Divergence                3.5695205
KL Loss                      0.35695204
QF Loss                      1378.2908
VF Loss                      461.27237
Policy Loss                  -2544.4768
Q Predictions Mean           2541.794
Q Predictions Std            722.7803
Q Predictions Max            2909.877
Q Predictions Min            23.880445
V Predictions Mean           2543.504
V Predictions Std            719.66003
V Predictions Max            2910.5896
V Predictions Min            29.403572
Log Pis Mean                 -5.5153475
Log Pis Std                  5.0474167
Log Pis Max                  23.687662
Log Pis Min                  -15.290291
Policy mu Mean               0.20662454
Policy mu Std                0.6590698
Policy mu Max                3.1902506
Policy mu Min                -3.1893253
Policy log std Mean          -0.3168677
Policy log std Std           0.13708472
Policy log std Max           -0.05582203
Policy log std Min           -1.3239838
Z mean eval                  0.063285485
Z variance eval              0.09612271
total_rewards                [5383.76196082 5337.10733885 5441.75525112 5460.09505514 5411.51964731
 5491.33024549 3685.92951271 5422.90395584 5293.95273614 5419.57690443]
total_rewards_mean           5234.79326078524
total_rewards_std            519.1634454145781
total_rewards_max            5491.33024549418
total_rewards_min            3685.9295127075
Number of train steps total  1264000
Number of env steps total    1582000
Number of rollouts total     0
Train Time (s)               199.2073127720505
(Previous) Eval Time (s)     22.830725028645247
Sample Time (s)              18.77755714673549
Epoch Time (s)               240.81559494743124
Total Train Time (s)         70813.92532015778
Epoch                        315
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:10:33.380287 UTC | [2020_01_13_04_30_18] Iteration #315 | Epoch Duration: 241.8500349521637
2020-01-14 00:10:33.380458 UTC | [2020_01_13_04_30_18] Iteration #315 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06323768
Z variance train             0.09612729
KL Divergence                3.685211
KL Loss                      0.3685211
QF Loss                      1085.7029
VF Loss                      390.4347
Policy Loss                  -2566.3896
Q Predictions Mean           2563.5298
Q Predictions Std            658.33026
Q Predictions Max            2903.7349
Q Predictions Min            20.178562
V Predictions Mean           2571.3044
V Predictions Std            656.5778
V Predictions Max            2912.81
V Predictions Min            32.20422
Log Pis Mean                 -4.920135
Log Pis Std                  5.257991
Log Pis Max                  23.259706
Log Pis Min                  -13.67247
Policy mu Mean               0.1962789
Policy mu Std                0.69529563
Policy mu Max                2.860596
Policy mu Min                -3.0552168
Policy log std Mean          -0.33094192
Policy log std Std           0.14575936
Policy log std Max           0.037129037
Policy log std Min           -1.5604627
Z mean eval                  0.06262036
Z variance eval              0.08278244
total_rewards                [5421.17043876 5429.60957818 5566.35239992 5444.64827345 5417.54135961
 5369.3043127  1097.23542804 5465.21833103 5397.76629943 1694.41818613]
total_rewards_mean           4630.32646072464
total_rewards_std            1623.5037979280971
total_rewards_max            5566.352399922227
total_rewards_min            1097.2354280415827
Number of train steps total  1268000
Number of env steps total    1587000
Number of rollouts total     0
Train Time (s)               197.59474701806903
(Previous) Eval Time (s)     23.864840193651617
Sample Time (s)              17.1785295791924
Epoch Time (s)               238.63811679091305
Total Train Time (s)         71049.066852557
Epoch                        316
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:14:28.527238 UTC | [2020_01_13_04_30_18] Iteration #316 | Epoch Duration: 235.14666056632996
2020-01-14 00:14:28.527390 UTC | [2020_01_13_04_30_18] Iteration #316 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0627569
Z variance train             0.082858875
KL Divergence                4.0260077
KL Loss                      0.40260077
QF Loss                      1135.5018
VF Loss                      494.68185
Policy Loss                  -2614.4614
Q Predictions Mean           2611.822
Q Predictions Std            595.21484
Q Predictions Max            2917.1404
Q Predictions Min            8.925231
V Predictions Mean           2612.2632
V Predictions Std            588.9336
V Predictions Max            2919.8835
V Predictions Min            27.00639
Log Pis Mean                 -5.581057
Log Pis Std                  5.8062963
Log Pis Max                  32.873405
Log Pis Min                  -17.162048
Policy mu Mean               0.2189581
Policy mu Std                0.68336165
Policy mu Max                2.7937846
Policy mu Min                -3.794416
Policy log std Mean          -0.32517573
Policy log std Std           0.15465064
Policy log std Max           -0.023156099
Policy log std Min           -1.2548156
Z mean eval                  0.06542347
Z variance eval              0.083667256
total_rewards                [ 473.46600457 5490.35172394 5432.55300258 4600.34857408 2234.24901271
 5512.01415541 1532.2750695  3698.57764066 5431.5754328  3064.46044744]
total_rewards_mean           3746.987106370375
total_rewards_std            1758.956769081228
total_rewards_max            5512.014155413231
total_rewards_min            473.4660045673509
Number of train steps total  1272000
Number of env steps total    1592000
Number of rollouts total     0
Train Time (s)               196.907955176197
(Previous) Eval Time (s)     20.373087846674025
Sample Time (s)              18.25598397059366
Epoch Time (s)               235.53702699346468
Total Train Time (s)         71282.03329741908
Epoch                        317
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:18:21.504310 UTC | [2020_01_13_04_30_18] Iteration #317 | Epoch Duration: 232.97673654556274
2020-01-14 00:18:21.504728 UTC | [2020_01_13_04_30_18] Iteration #317 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06439235
Z variance train             0.08368691
KL Divergence                4.050065
KL Loss                      0.4050065
QF Loss                      1347.3303
VF Loss                      1088.2198
Policy Loss                  -2616.2744
Q Predictions Mean           2614.76
Q Predictions Std            605.3033
Q Predictions Max            2913.886
Q Predictions Min            25.475779
V Predictions Mean           2628.6455
V Predictions Std            608.68066
V Predictions Max            2930.7898
V Predictions Min            29.825954
Log Pis Mean                 -4.952318
Log Pis Std                  5.164944
Log Pis Max                  18.538553
Log Pis Min                  -15.244989
Policy mu Mean               0.20604086
Policy mu Std                0.69330066
Policy mu Max                2.78563
Policy mu Min                -3.056507
Policy log std Mean          -0.32449618
Policy log std Std           0.14433318
Policy log std Max           -0.037118793
Policy log std Min           -1.2490042
Z mean eval                  0.058922373
Z variance eval              0.081625685
total_rewards                [2332.38500591 5437.96686522 5425.25115312 5505.61883558 4751.16235336
 5522.62430646 5467.86220258 5537.96722117 5533.01240861 5478.60190133]
total_rewards_mean           5099.245225333006
total_rewards_std            948.8150322258035
total_rewards_max            5537.967221167953
total_rewards_min            2332.3850059072142
Number of train steps total  1276000
Number of env steps total    1597000
Number of rollouts total     0
Train Time (s)               198.0612451680936
(Previous) Eval Time (s)     17.812469223048538
Sample Time (s)              19.276537232100964
Epoch Time (s)               235.1502516232431
Total Train Time (s)         71521.82566452492
Epoch                        318
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:22:21.298079 UTC | [2020_01_13_04_30_18] Iteration #318 | Epoch Duration: 239.7931056022644
2020-01-14 00:22:21.298263 UTC | [2020_01_13_04_30_18] Iteration #318 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05834229
Z variance train             0.08160424
KL Divergence                4.085129
KL Loss                      0.4085129
QF Loss                      1147.6296
VF Loss                      520.3275
Policy Loss                  -2600.236
Q Predictions Mean           2597.2861
Q Predictions Std            651.41235
Q Predictions Max            2920.1855
Q Predictions Min            13.088171
V Predictions Mean           2592.5024
V Predictions Std            643.4886
V Predictions Max            2909.828
V Predictions Min            32.908092
Log Pis Mean                 -5.393569
Log Pis Std                  4.398943
Log Pis Max                  11.98415
Log Pis Min                  -14.833184
Policy mu Mean               0.23022538
Policy mu Std                0.6620752
Policy mu Max                2.9386199
Policy mu Min                -2.5547128
Policy log std Mean          -0.31694186
Policy log std Std           0.1461498
Policy log std Max           -0.07361417
Policy log std Min           -1.1391933
Z mean eval                  0.060624074
Z variance eval              0.091379605
total_rewards                [5238.22886112 5526.64641167 5451.22205757 5503.81707006 5511.57008096
 5553.59122208 5467.45145609 5479.68755366 5420.57321783 5358.86251847]
total_rewards_mean           5451.165044951709
total_rewards_std            88.5922012455731
total_rewards_max            5553.591222083777
total_rewards_min            5238.228861121342
Number of train steps total  1280000
Number of env steps total    1602000
Number of rollouts total     0
Train Time (s)               196.5397052890621
(Previous) Eval Time (s)     22.454793606884778
Sample Time (s)              18.99217556696385
Epoch Time (s)               237.98667446291074
Total Train Time (s)         71764.51722769951
Epoch                        319
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:26:23.992810 UTC | [2020_01_13_04_30_18] Iteration #319 | Epoch Duration: 242.69441556930542
2020-01-14 00:26:23.992969 UTC | [2020_01_13_04_30_18] Iteration #319 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.061491907
Z variance train             0.0913464
KL Divergence                4.0058846
KL Loss                      0.40058848
QF Loss                      1205.6454
VF Loss                      444.969
Policy Loss                  -2688.0884
Q Predictions Mean           2678.8557
Q Predictions Std            475.87112
Q Predictions Max            2924.3167
Q Predictions Min            17.620384
V Predictions Mean           2675.7598
V Predictions Std            473.3732
V Predictions Max            2929.5085
V Predictions Min            25.777391
Log Pis Mean                 -4.394254
Log Pis Std                  5.7119365
Log Pis Max                  30.839058
Log Pis Min                  -14.131081
Policy mu Mean               0.21583384
Policy mu Std                0.7330717
Policy mu Max                3.7655544
Policy mu Min                -3.8064258
Policy log std Mean          -0.33470672
Policy log std Std           0.15973097
Policy log std Max           -0.07155252
Policy log std Min           -1.41309
Z mean eval                  0.058232892
Z variance eval              0.07641593
total_rewards                [5428.22920442 5416.34880531 4434.00599949 5494.07998061 5536.40668274
 1907.05306123 5387.48094324 5426.26824746 5402.62341819 5472.25081043]
total_rewards_mean           4990.474715311745
total_rewards_std            1071.9752303525597
total_rewards_max            5536.406682741447
total_rewards_min            1907.0530612313041
Number of train steps total  1284000
Number of env steps total    1607000
Number of rollouts total     0
Train Time (s)               195.98895269911736
(Previous) Eval Time (s)     27.162267340812832
Sample Time (s)              16.981161139905453
Epoch Time (s)               240.13238117983565
Total Train Time (s)         72002.10479775956
Epoch                        320
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:30:21.587753 UTC | [2020_01_13_04_30_18] Iteration #320 | Epoch Duration: 237.59463143348694
2020-01-14 00:30:21.588070 UTC | [2020_01_13_04_30_18] Iteration #320 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.058680117
Z variance train             0.07641141
KL Divergence                4.3246555
KL Loss                      0.43246555
QF Loss                      1224.8054
VF Loss                      271.42453
Policy Loss                  -2613.9524
Q Predictions Mean           2609.0242
Q Predictions Std            644.69946
Q Predictions Max            2941.536
Q Predictions Min            22.901976
V Predictions Mean           2606.9404
V Predictions Std            639.8496
V Predictions Max            2926.8909
V Predictions Min            31.734095
Log Pis Mean                 -5.887342
Log Pis Std                  5.360803
Log Pis Max                  25.765572
Log Pis Min                  -17.839294
Policy mu Mean               0.2054877
Policy mu Std                0.66600066
Policy mu Max                3.3573895
Policy mu Min                -2.7085958
Policy log std Mean          -0.3042715
Policy log std Std           0.1430531
Policy log std Max           -0.05041027
Policy log std Min           -1.212161
Z mean eval                  0.052470714
Z variance eval              0.06568958
total_rewards                [5543.01168348 5599.39618632 2602.96309107 5600.53451377 5582.8311971
 5631.11730577 1063.436447   3401.07841144 2885.06162752 3819.53954538]
total_rewards_mean           4172.89700088362
total_rewards_std            1567.7087333290299
total_rewards_max            5631.117305774142
total_rewards_min            1063.4364469995141
Number of train steps total  1288000
Number of env steps total    1612000
Number of rollouts total     0
Train Time (s)               192.3677944499068
(Previous) Eval Time (s)     24.6242016130127
Sample Time (s)              19.077895883936435
Epoch Time (s)               236.06989194685593
Total Train Time (s)         72233.94215774164
Epoch                        321
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:34:13.427989 UTC | [2020_01_13_04_30_18] Iteration #321 | Epoch Duration: 231.83979296684265
2020-01-14 00:34:13.428146 UTC | [2020_01_13_04_30_18] Iteration #321 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.052241374
Z variance train             0.065713346
KL Divergence                4.6205416
KL Loss                      0.46205416
QF Loss                      1020.4844
VF Loss                      1212.2521
Policy Loss                  -2648.2966
Q Predictions Mean           2645.0688
Q Predictions Std            580.0244
Q Predictions Max            2923.812
Q Predictions Min            23.220034
V Predictions Mean           2654.1416
V Predictions Std            582.0228
V Predictions Max            2939.861
V Predictions Min            28.306606
Log Pis Mean                 -5.762215
Log Pis Std                  5.194809
Log Pis Max                  26.465694
Log Pis Min                  -14.858978
Policy mu Mean               0.22908492
Policy mu Std                0.6528557
Policy mu Max                3.5050342
Policy mu Min                -3.6896257
Policy log std Mean          -0.306908
Policy log std Std           0.14758375
Policy log std Max           -0.0075756162
Policy log std Min           -1.7227199
Z mean eval                  0.053932894
Z variance eval              0.067298785
total_rewards                [5373.84333185 5436.87446127 1563.23507238 3778.41090902 3621.86033407
 2816.42004103 5376.40232395 1896.18309909 5484.9271252  5309.23879134]
total_rewards_mean           4065.7395489208584
total_rewards_std            1472.3877440667238
total_rewards_max            5484.927125198687
total_rewards_min            1563.2350723846705
Number of train steps total  1292000
Number of env steps total    1617000
Number of rollouts total     0
Train Time (s)               197.95138178393245
(Previous) Eval Time (s)     20.39383942866698
Sample Time (s)              16.54805956268683
Epoch Time (s)               234.89328077528626
Total Train Time (s)         72466.59354660194
Epoch                        322
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:38:06.085201 UTC | [2020_01_13_04_30_18] Iteration #322 | Epoch Duration: 232.65687656402588
2020-01-14 00:38:06.085591 UTC | [2020_01_13_04_30_18] Iteration #322 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.053334504
Z variance train             0.06729276
KL Divergence                4.5043354
KL Loss                      0.45043355
QF Loss                      1343.1155
VF Loss                      460.6753
Policy Loss                  -2710.4993
Q Predictions Mean           2713.954
Q Predictions Std            446.28848
Q Predictions Max            2947.6978
Q Predictions Min            26.072538
V Predictions Mean           2722.3938
V Predictions Std            446.31958
V Predictions Max            2949.1575
V Predictions Min            32.32791
Log Pis Mean                 -5.314088
Log Pis Std                  5.311923
Log Pis Max                  25.75779
Log Pis Min                  -12.948998
Policy mu Mean               0.22123899
Policy mu Std                0.6941273
Policy mu Max                2.9965723
Policy mu Min                -3.3177547
Policy log std Mean          -0.32192308
Policy log std Std           0.13258792
Policy log std Max           -0.027266197
Policy log std Min           -1.1206253
Z mean eval                  0.04334386
Z variance eval              0.063796684
total_rewards                [5156.25136854 2921.81509906 5540.22546887 5518.70359639 5479.69467191
 5360.07089012 5418.19304702 3969.77055038 5446.38652819 5364.36789742]
total_rewards_mean           5017.547911789103
total_rewards_std            826.3852445150449
total_rewards_max            5540.225468868401
total_rewards_min            2921.8150990593126
Number of train steps total  1296000
Number of env steps total    1622000
Number of rollouts total     0
Train Time (s)               197.62804404599592
(Previous) Eval Time (s)     18.157101074699312
Sample Time (s)              18.165314635261893
Epoch Time (s)               233.95045975595713
Total Train Time (s)         72707.64736549743
Epoch                        323
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:42:07.145728 UTC | [2020_01_13_04_30_18] Iteration #323 | Epoch Duration: 241.0598168373108
2020-01-14 00:42:07.145984 UTC | [2020_01_13_04_30_18] Iteration #323 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04323984
Z variance train             0.063772336
KL Divergence                4.5879116
KL Loss                      0.45879117
QF Loss                      1163.477
VF Loss                      338.88107
Policy Loss                  -2714.6187
Q Predictions Mean           2716.3462
Q Predictions Std            457.65134
Q Predictions Max            2950.8064
Q Predictions Min            24.67266
V Predictions Mean           2709.8743
V Predictions Std            453.87775
V Predictions Max            2949.055
V Predictions Min            35.844444
Log Pis Mean                 -5.0263844
Log Pis Std                  5.004665
Log Pis Max                  24.943453
Log Pis Min                  -14.019397
Policy mu Mean               0.20461972
Policy mu Std                0.7065649
Policy mu Max                3.2382324
Policy mu Min                -4.6737347
Policy log std Mean          -0.32106224
Policy log std Std           0.13818091
Policy log std Max           -0.0057715178
Policy log std Min           -1.6095117
Z mean eval                  0.052089013
Z variance eval              0.07052241
total_rewards                [5378.75287339 5370.17073461 5378.43403104 5273.04399131 5401.20196376
 5548.16901638 5288.57435986 3245.02740071 5412.1682325  5395.41837958]
total_rewards_mean           5169.096098313913
total_rewards_std            645.2290417150467
total_rewards_max            5548.16901638428
total_rewards_min            3245.027400707526
Number of train steps total  1300000
Number of env steps total    1627000
Number of rollouts total     0
Train Time (s)               197.57786796288565
(Previous) Eval Time (s)     25.26620408380404
Sample Time (s)              19.1202670247294
Epoch Time (s)               241.9643390714191
Total Train Time (s)         72950.27992576268
Epoch                        324
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:46:09.780693 UTC | [2020_01_13_04_30_18] Iteration #324 | Epoch Duration: 242.63455271720886
2020-01-14 00:46:09.780860 UTC | [2020_01_13_04_30_18] Iteration #324 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05194086
Z variance train             0.07062991
KL Divergence                4.3477144
KL Loss                      0.43477145
QF Loss                      1355.0459
VF Loss                      292.4511
Policy Loss                  -2694.7314
Q Predictions Mean           2692.5107
Q Predictions Std            478.7354
Q Predictions Max            2936.9805
Q Predictions Min            22.559418
V Predictions Mean           2692.6672
V Predictions Std            476.2694
V Predictions Max            2945.8914
V Predictions Min            27.371952
Log Pis Mean                 -5.5477333
Log Pis Std                  4.8532867
Log Pis Max                  15.119709
Log Pis Min                  -15.288889
Policy mu Mean               0.16662315
Policy mu Std                0.69250804
Policy mu Max                2.760698
Policy mu Min                -3.1891038
Policy log std Mean          -0.31957608
Policy log std Std           0.14118584
Policy log std Max           0.0045515597
Policy log std Min           -1.2993157
Z mean eval                  0.03712883
Z variance eval              0.076801136
total_rewards                [5535.77501474 1672.514897   5520.03449818 5464.98385423 5481.3513485
 2910.93065809 5264.81344475 5504.41375884 3637.64319306 5354.55509826]
total_rewards_mean           4634.701576565038
total_rewards_std            1319.6068764302556
total_rewards_max            5535.775014741019
total_rewards_min            1672.5148970014961
Number of train steps total  1304000
Number of env steps total    1632000
Number of rollouts total     0
Train Time (s)               195.4105012747459
(Previous) Eval Time (s)     25.93614382483065
Sample Time (s)              18.862236462067813
Epoch Time (s)               240.20888156164438
Total Train Time (s)         73184.91399508761
Epoch                        325
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:50:04.421927 UTC | [2020_01_13_04_30_18] Iteration #325 | Epoch Duration: 234.64084696769714
2020-01-14 00:50:04.422214 UTC | [2020_01_13_04_30_18] Iteration #325 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037620753
Z variance train             0.076767445
KL Divergence                4.185432
KL Loss                      0.4185432
QF Loss                      1065.9255
VF Loss                      452.36792
Policy Loss                  -2707.5044
Q Predictions Mean           2701.3032
Q Predictions Std            506.1567
Q Predictions Max            2942.8848
Q Predictions Min            17.291698
V Predictions Mean           2698.365
V Predictions Std            504.74115
V Predictions Max            2945.5403
V Predictions Min            25.400337
Log Pis Mean                 -5.3252277
Log Pis Std                  4.796062
Log Pis Max                  24.8972
Log Pis Min                  -13.659852
Policy mu Mean               0.17170408
Policy mu Std                0.66858995
Policy mu Max                2.955279
Policy mu Min                -2.7507112
Policy log std Mean          -0.3238272
Policy log std Std           0.13921902
Policy log std Max           0.026826918
Policy log std Min           -1.2607896
Z mean eval                  0.034664195
Z variance eval              0.07537563
total_rewards                [5236.82526573 5163.67085616 5294.05640349 5296.74646922 5316.42919076
 2684.556761   5250.32089321 3091.54191526 5059.58940458 1924.98470611]
total_rewards_mean           4431.872186552397
total_rewards_std            1251.2097129708648
total_rewards_max            5316.429190758723
total_rewards_min            1924.9847061086125
Number of train steps total  1308000
Number of env steps total    1637000
Number of rollouts total     0
Train Time (s)               194.69545345008373
(Previous) Eval Time (s)     20.367835886776447
Sample Time (s)              18.65639285510406
Epoch Time (s)               233.71968219196424
Total Train Time (s)         73420.52452970576
Epoch                        326
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:54:00.037634 UTC | [2020_01_13_04_30_18] Iteration #326 | Epoch Duration: 235.61523342132568
2020-01-14 00:54:00.037853 UTC | [2020_01_13_04_30_18] Iteration #326 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03471318
Z variance train             0.07537917
KL Divergence                4.273181
KL Loss                      0.4273181
QF Loss                      1314.2932
VF Loss                      301.85785
Policy Loss                  -2732.8274
Q Predictions Mean           2730.0063
Q Predictions Std            399.08194
Q Predictions Max            2938.7637
Q Predictions Min            25.731417
V Predictions Mean           2733.9219
V Predictions Std            396.55307
V Predictions Max            2950.4653
V Predictions Min            32.86699
Log Pis Mean                 -4.2625475
Log Pis Std                  6.16129
Log Pis Max                  28.503223
Log Pis Min                  -14.490719
Policy mu Mean               0.15289009
Policy mu Std                0.7315624
Policy mu Max                3.6142292
Policy mu Min                -3.0898347
Policy log std Mean          -0.33357996
Policy log std Std           0.15715435
Policy log std Max           -0.0490465
Policy log std Min           -1.3892817
Z mean eval                  0.036703896
Z variance eval              0.080003366
total_rewards                [5488.73620708 5444.09582882 5460.32089483 5501.06973701 5426.60424943
 5471.29191731 4640.71103855 5510.35133951 5468.18169185 5462.1833078 ]
total_rewards_mean           5387.354621217891
total_rewards_std            250.01523516771033
total_rewards_max            5510.3513395064765
total_rewards_min            4640.711038547998
Number of train steps total  1312000
Number of env steps total    1642000
Number of rollouts total     0
Train Time (s)               199.15148857282475
(Previous) Eval Time (s)     22.26305558718741
Sample Time (s)              19.02691635861993
Epoch Time (s)               240.44146051863208
Total Train Time (s)         73662.94399910793
Epoch                        327
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 00:58:02.463395 UTC | [2020_01_13_04_30_18] Iteration #327 | Epoch Duration: 242.4253511428833
2020-01-14 00:58:02.463673 UTC | [2020_01_13_04_30_18] Iteration #327 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037126165
Z variance train             0.08002517
KL Divergence                4.139695
KL Loss                      0.41396952
QF Loss                      1025.3243
VF Loss                      418.94354
Policy Loss                  -2685.6562
Q Predictions Mean           2683.796
Q Predictions Std            543.0672
Q Predictions Max            2951.321
Q Predictions Min            20.413078
V Predictions Mean           2687.7478
V Predictions Std            540.69745
V Predictions Max            2959.7856
V Predictions Min            35.84457
Log Pis Mean                 -5.661523
Log Pis Std                  5.0207005
Log Pis Max                  16.616879
Log Pis Min                  -20.416965
Policy mu Mean               0.1705668
Policy mu Std                0.6624617
Policy mu Max                3.1777587
Policy mu Min                -4.1167226
Policy log std Mean          -0.31089443
Policy log std Std           0.14301093
Policy log std Max           -0.021463662
Policy log std Min           -1.3210728
Z mean eval                  0.045610152
Z variance eval              0.08317014
total_rewards                [5343.52872122 5455.71265624 5343.46360142 5365.74787979 5310.47653524
 5368.65677406 5116.23406807 5418.67294714 5413.47859129 5449.3648626 ]
total_rewards_mean           5358.533663706886
total_rewards_std            92.71197374653465
total_rewards_max            5455.712656244071
total_rewards_min            5116.234068065943
Number of train steps total  1316000
Number of env steps total    1647000
Number of rollouts total     0
Train Time (s)               192.05605495581403
(Previous) Eval Time (s)     24.246677091810852
Sample Time (s)              18.82920117583126
Epoch Time (s)               235.13193322345614
Total Train Time (s)         73899.59657991491
Epoch                        328
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:01:59.120073 UTC | [2020_01_13_04_30_18] Iteration #328 | Epoch Duration: 236.65618991851807
2020-01-14 01:01:59.120297 UTC | [2020_01_13_04_30_18] Iteration #328 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045906603
Z variance train             0.083215095
KL Divergence                4.034961
KL Loss                      0.40349612
QF Loss                      797.94403
VF Loss                      287.89185
Policy Loss                  -2677.5962
Q Predictions Mean           2671.2834
Q Predictions Std            591.6309
Q Predictions Max            2955.2883
Q Predictions Min            19.819998
V Predictions Mean           2671.501
V Predictions Std            588.33405
V Predictions Max            2954.8254
V Predictions Min            24.49915
Log Pis Mean                 -5.693677
Log Pis Std                  4.37487
Log Pis Max                  12.954297
Log Pis Min                  -16.562542
Policy mu Mean               0.14337721
Policy mu Std                0.655378
Policy mu Max                2.6506352
Policy mu Min                -2.1816416
Policy log std Mean          -0.30329314
Policy log std Std           0.1405132
Policy log std Max           0.009053439
Policy log std Min           -1.3727686
Z mean eval                  0.04377123
Z variance eval              0.084842086
total_rewards                [5527.43101889 5485.17479849 5565.64426457 4580.07717731 5416.56269316
 5443.63859528 5549.14955058 5549.63665306 5476.36181437 5531.37552928]
total_rewards_mean           5412.505209498041
total_rewards_std            281.3444665084493
total_rewards_max            5565.644264570635
total_rewards_min            4580.077177308088
Number of train steps total  1320000
Number of env steps total    1652000
Number of rollouts total     0
Train Time (s)               198.89650493999943
(Previous) Eval Time (s)     25.77063956996426
Sample Time (s)              18.942042460665107
Epoch Time (s)               243.6091869706288
Total Train Time (s)         74141.6472810274
Epoch                        329
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:06:01.178042 UTC | [2020_01_13_04_30_18] Iteration #329 | Epoch Duration: 242.05755186080933
2020-01-14 01:06:01.178341 UTC | [2020_01_13_04_30_18] Iteration #329 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0439352
Z variance train             0.084886536
KL Divergence                3.9663892
KL Loss                      0.39663893
QF Loss                      1067.4358
VF Loss                      252.04936
Policy Loss                  -2725.67
Q Predictions Mean           2725.5356
Q Predictions Std            497.66464
Q Predictions Max            2966.2627
Q Predictions Min            16.63671
V Predictions Mean           2726.618
V Predictions Std            496.03415
V Predictions Max            2975.361
V Predictions Min            23.006987
Log Pis Mean                 -5.506653
Log Pis Std                  4.905069
Log Pis Max                  26.19733
Log Pis Min                  -14.85368
Policy mu Mean               0.1591363
Policy mu Std                0.6759042
Policy mu Max                2.9020526
Policy mu Min                -2.750657
Policy log std Mean          -0.32061827
Policy log std Std           0.13397233
Policy log std Max           0.013023332
Policy log std Min           -1.231346
Z mean eval                  0.056032456
Z variance eval              0.08257374
total_rewards                [5421.6694898  5462.87514528 5555.81190769 5545.68205403 4387.96267071
 5537.57610504 5433.47394588 5552.96901218 5595.90396467 1961.56486888]
total_rewards_mean           5045.548916415761
total_rewards_std            1082.7025923218675
total_rewards_max            5595.9039646706715
total_rewards_min            1961.5648688754077
Number of train steps total  1324000
Number of env steps total    1657000
Number of rollouts total     0
Train Time (s)               194.80564523069188
(Previous) Eval Time (s)     24.218734583817422
Sample Time (s)              17.237178315408528
Epoch Time (s)               236.26155812991783
Total Train Time (s)         74376.7596038687
Epoch                        330
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:09:56.297380 UTC | [2020_01_13_04_30_18] Iteration #330 | Epoch Duration: 235.1188280582428
2020-01-14 01:09:56.297568 UTC | [2020_01_13_04_30_18] Iteration #330 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05591591
Z variance train             0.08255732
KL Divergence                3.9965377
KL Loss                      0.39965376
QF Loss                      1185.3933
VF Loss                      440.69556
Policy Loss                  -2691.7834
Q Predictions Mean           2691.0505
Q Predictions Std            548.75867
Q Predictions Max            2957.0542
Q Predictions Min            25.064388
V Predictions Mean           2696.995
V Predictions Std            547.1639
V Predictions Max            2972.3315
V Predictions Min            32.804596
Log Pis Mean                 -5.431895
Log Pis Std                  5.3888535
Log Pis Max                  17.103313
Log Pis Min                  -15.104269
Policy mu Mean               0.11940426
Policy mu Std                0.69443
Policy mu Max                4.0854793
Policy mu Min                -3.4015055
Policy log std Mean          -0.31517377
Policy log std Std           0.14562385
Policy log std Max           0.008602291
Policy log std Min           -1.5413533
Z mean eval                  0.040345244
Z variance eval              0.09240223
total_rewards                [5443.10409353 5563.13304781 5457.92448805 5485.21498586 5390.95778519
 5409.57691417 5412.53464385 5420.08250547 5456.61312347 5368.40919562]
total_rewards_mean           5440.755078302245
total_rewards_std            52.35872243379035
total_rewards_max            5563.1330478050495
total_rewards_min            5368.409195620196
Number of train steps total  1328000
Number of env steps total    1662000
Number of rollouts total     0
Train Time (s)               194.07458909740672
(Previous) Eval Time (s)     23.07573797274381
Sample Time (s)              16.392074620816857
Epoch Time (s)               233.54240169096738
Total Train Time (s)         74612.308425833
Epoch                        331
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:13:51.849671 UTC | [2020_01_13_04_30_18] Iteration #331 | Epoch Duration: 235.5519676208496
2020-01-14 01:13:51.849858 UTC | [2020_01_13_04_30_18] Iteration #331 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.041248087
Z variance train             0.09240187
KL Divergence                3.7310119
KL Loss                      0.3731012
QF Loss                      894.9486
VF Loss                      356.3264
Policy Loss                  -2756.1348
Q Predictions Mean           2747.1782
Q Predictions Std            428.6562
Q Predictions Max            2952.8076
Q Predictions Min            24.577782
V Predictions Mean           2750.0273
V Predictions Std            430.44092
V Predictions Max            2971.161
V Predictions Min            36.04209
Log Pis Mean                 -5.327118
Log Pis Std                  4.3894067
Log Pis Max                  13.382747
Log Pis Min                  -13.915947
Policy mu Mean               0.185749
Policy mu Std                0.667453
Policy mu Max                2.5130243
Policy mu Min                -2.5982862
Policy log std Mean          -0.3221929
Policy log std Std           0.13708183
Policy log std Max           -0.079480715
Policy log std Min           -1.1455698
Z mean eval                  0.036400694
Z variance eval              0.089025624
total_rewards                [5334.03812008 5486.91930449 5420.34002388 5480.33436004 5494.52442338
 5542.46507274 5450.53645982 5483.7198889  1582.28041235 5610.41946501]
total_rewards_mean           5088.557753069073
total_rewards_std            1170.7631633967862
total_rewards_max            5610.4194650109885
total_rewards_min            1582.2804123476851
Number of train steps total  1332000
Number of env steps total    1667000
Number of rollouts total     0
Train Time (s)               194.16017794888467
(Previous) Eval Time (s)     25.085030358750373
Sample Time (s)              18.932801585644484
Epoch Time (s)               238.17800989327952
Total Train Time (s)         74850.27945646364
Epoch                        332
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:17:49.829009 UTC | [2020_01_13_04_30_18] Iteration #332 | Epoch Duration: 237.9790234565735
2020-01-14 01:17:49.829172 UTC | [2020_01_13_04_30_18] Iteration #332 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03658407
Z variance train             0.08902473
KL Divergence                3.813391
KL Loss                      0.3813391
QF Loss                      936.8711
VF Loss                      513.88983
Policy Loss                  -2686.0483
Q Predictions Mean           2682.011
Q Predictions Std            611.378
Q Predictions Max            2975.6697
Q Predictions Min            18.816917
V Predictions Mean           2683.7466
V Predictions Std            609.7637
V Predictions Max            2977.8813
V Predictions Min            32.208607
Log Pis Mean                 -5.737242
Log Pis Std                  4.4424257
Log Pis Max                  15.961424
Log Pis Min                  -16.378424
Policy mu Mean               0.17673784
Policy mu Std                0.6613709
Policy mu Max                2.6671379
Policy mu Min                -3.4674118
Policy log std Mean          -0.321817
Policy log std Std           0.14478098
Policy log std Max           0.008493446
Policy log std Min           -1.2012765
Z mean eval                  0.046041097
Z variance eval              0.0868626
total_rewards                [5498.69358495 5398.26953516 5529.23152142 1543.42028278 5617.0849545
 5559.47923517 5509.12611896 5379.07175782 5598.10514202 2804.12551605]
total_rewards_mean           4843.660764884658
total_rewards_std            1366.2808592348692
total_rewards_max            5617.0849545044985
total_rewards_min            1543.4202827798272
Number of train steps total  1336000
Number of env steps total    1672000
Number of rollouts total     0
Train Time (s)               193.62180363107473
(Previous) Eval Time (s)     24.885770032182336
Sample Time (s)              18.93126937933266
Epoch Time (s)               237.43884304258972
Total Train Time (s)         75086.31195722008
Epoch                        333
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:21:45.857905 UTC | [2020_01_13_04_30_18] Iteration #333 | Epoch Duration: 236.02861547470093
2020-01-14 01:21:45.858075 UTC | [2020_01_13_04_30_18] Iteration #333 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046082847
Z variance train             0.08684738
KL Divergence                3.8385015
KL Loss                      0.38385016
QF Loss                      1121.7001
VF Loss                      266.51154
Policy Loss                  -2746.71
Q Predictions Mean           2743.0974
Q Predictions Std            477.3336
Q Predictions Max            2974.9998
Q Predictions Min            21.322037
V Predictions Mean           2740.1792
V Predictions Std            479.6349
V Predictions Max            2974.744
V Predictions Min            28.187685
Log Pis Mean                 -6.0178328
Log Pis Std                  4.6118774
Log Pis Max                  17.25074
Log Pis Min                  -16.97471
Policy mu Mean               0.16929916
Policy mu Std                0.6648666
Policy mu Max                3.0996923
Policy mu Min                -2.893072
Policy log std Mean          -0.31510082
Policy log std Std           0.1382936
Policy log std Max           -0.07731316
Policy log std Min           -1.2137489
Z mean eval                  0.0520067
Z variance eval              0.09196275
total_rewards                [1216.93722898 4392.08379278 5597.8352901  5588.6714006  5621.041934
 5478.65910686 5466.50970986 1455.075568   4584.18891867 4649.65225385]
total_rewards_mean           4405.065520369191
total_rewards_std            1598.129134544701
total_rewards_max            5621.041934002477
total_rewards_min            1216.9372289808773
Number of train steps total  1340000
Number of env steps total    1677000
Number of rollouts total     0
Train Time (s)               195.2046877630055
(Previous) Eval Time (s)     23.475265129003674
Sample Time (s)              18.679068978875875
Epoch Time (s)               237.35902187088504
Total Train Time (s)         75319.45878504356
Epoch                        334
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:25:39.012583 UTC | [2020_01_13_04_30_18] Iteration #334 | Epoch Duration: 233.15440821647644
2020-01-14 01:25:39.012736 UTC | [2020_01_13_04_30_18] Iteration #334 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05209483
Z variance train             0.091980085
KL Divergence                3.7807167
KL Loss                      0.37807167
QF Loss                      1263.5872
VF Loss                      447.50626
Policy Loss                  -2725.891
Q Predictions Mean           2725.2856
Q Predictions Std            485.73288
Q Predictions Max            2978.32
Q Predictions Min            22.120981
V Predictions Mean           2728.962
V Predictions Std            488.73776
V Predictions Max            2987.2214
V Predictions Min            21.870737
Log Pis Mean                 -5.110647
Log Pis Std                  4.7492127
Log Pis Max                  19.347466
Log Pis Min                  -15.422494
Policy mu Mean               0.1969281
Policy mu Std                0.69210917
Policy mu Max                3.6609704
Policy mu Min                -3.0960252
Policy log std Mean          -0.3248489
Policy log std Std           0.14914638
Policy log std Max           0.15526499
Policy log std Min           -1.554397
Z mean eval                  0.054403592
Z variance eval              0.09803703
total_rewards                [5566.4925773  5537.78506427 5218.3589775  5547.72172206 5441.47368708
 5289.61685452 5545.79902424 5505.57042831 5503.32432513 5504.82107513]
total_rewards_mean           5466.096373553091
total_rewards_std            112.16180935114674
total_rewards_max            5566.49257729847
total_rewards_min            5218.358977497115
Number of train steps total  1344000
Number of env steps total    1682000
Number of rollouts total     0
Train Time (s)               195.3026862759143
(Previous) Eval Time (s)     19.270394060295075
Sample Time (s)              16.48592136753723
Epoch Time (s)               231.05900170374662
Total Train Time (s)         75557.5933788144
Epoch                        335
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:29:37.148537 UTC | [2020_01_13_04_30_18] Iteration #335 | Epoch Duration: 238.13568997383118
2020-01-14 01:29:37.148667 UTC | [2020_01_13_04_30_18] Iteration #335 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.055190228
Z variance train             0.097948015
KL Divergence                3.590703
KL Loss                      0.3590703
QF Loss                      944.91943
VF Loss                      455.10577
Policy Loss                  -2788.1204
Q Predictions Mean           2781.887
Q Predictions Std            431.94315
Q Predictions Max            2979.8516
Q Predictions Min            24.46343
V Predictions Mean           2774.4329
V Predictions Std            431.33154
V Predictions Max            2975.5642
V Predictions Min            33.28678
Log Pis Mean                 -5.1838627
Log Pis Std                  4.2312427
Log Pis Max                  13.973102
Log Pis Min                  -12.900101
Policy mu Mean               0.20903753
Policy mu Std                0.6809875
Policy mu Max                2.6997943
Policy mu Min                -3.626746
Policy log std Mean          -0.3208358
Policy log std Std           0.13990708
Policy log std Max           -0.037803926
Policy log std Min           -1.1852112
Z mean eval                  0.056605827
Z variance eval              0.12196547
total_rewards                [5582.17417264 5519.77220406 5482.24631915 5433.46208513 5496.86803206
 5533.09786992 5452.5806536  5521.3946929  5488.00132155 5500.7775412 ]
total_rewards_mean           5501.037489219024
total_rewards_std            39.78873776615153
total_rewards_max            5582.174172635028
total_rewards_min            5433.462085126881
Number of train steps total  1348000
Number of env steps total    1687000
Number of rollouts total     0
Train Time (s)               195.24367591599002
(Previous) Eval Time (s)     26.34682392794639
Sample Time (s)              18.91037306841463
Epoch Time (s)               240.50087291235104
Total Train Time (s)         75797.55613687169
Epoch                        336
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:33:37.114862 UTC | [2020_01_13_04_30_18] Iteration #336 | Epoch Duration: 239.96609020233154
2020-01-14 01:33:37.115025 UTC | [2020_01_13_04_30_18] Iteration #336 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05633424
Z variance train             0.121938445
KL Divergence                3.2806036
KL Loss                      0.32806036
QF Loss                      1026.7021
VF Loss                      190.44975
Policy Loss                  -2795.3987
Q Predictions Mean           2783.6792
Q Predictions Std            365.71622
Q Predictions Max            2971.6963
Q Predictions Min            16.677118
V Predictions Mean           2800.517
V Predictions Std            364.18915
V Predictions Max            2990.8813
V Predictions Min            27.564705
Log Pis Mean                 -5.053612
Log Pis Std                  5.257256
Log Pis Max                  22.366436
Log Pis Min                  -14.409152
Policy mu Mean               0.20855932
Policy mu Std                0.68261665
Policy mu Max                2.631518
Policy mu Min                -2.8217113
Policy log std Mean          -0.32608935
Policy log std Std           0.13949406
Policy log std Max           -0.049181946
Policy log std Min           -1.2920624
Z mean eval                  0.054142274
Z variance eval              0.106361315
total_rewards                [5614.99883702 5658.04539933 5634.25847831 5706.16681335 5598.25093699
 5715.84822292 5669.88052254 5562.50009079 5706.32238048 5668.8965494 ]
total_rewards_mean           5653.516823112332
total_rewards_std            48.12831727121376
total_rewards_max            5715.848222922679
total_rewards_min            5562.500090787652
Number of train steps total  1352000
Number of env steps total    1692000
Number of rollouts total     0
Train Time (s)               195.09339815890417
(Previous) Eval Time (s)     25.81176740815863
Sample Time (s)              17.423263987526298
Epoch Time (s)               238.3284295545891
Total Train Time (s)         76034.21900127549
Epoch                        337
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:37:33.781230 UTC | [2020_01_13_04_30_18] Iteration #337 | Epoch Duration: 236.66607928276062
2020-01-14 01:37:33.781400 UTC | [2020_01_13_04_30_18] Iteration #337 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05379069
Z variance train             0.10636512
KL Divergence                3.588978
KL Loss                      0.3588978
QF Loss                      841.5287
VF Loss                      299.42966
Policy Loss                  -2769.0127
Q Predictions Mean           2766.3936
Q Predictions Std            463.18344
Q Predictions Max            2978.5479
Q Predictions Min            22.531364
V Predictions Mean           2776.3157
V Predictions Std            466.9959
V Predictions Max            2994.4114
V Predictions Min            34.155754
Log Pis Mean                 -5.159033
Log Pis Std                  5.1417956
Log Pis Max                  15.785337
Log Pis Min                  -14.146625
Policy mu Mean               0.22424333
Policy mu Std                0.67814934
Policy mu Max                2.889146
Policy mu Min                -4.0620956
Policy log std Mean          -0.3295724
Policy log std Std           0.14511606
Policy log std Max           -0.04955528
Policy log std Min           -1.4843327
Z mean eval                  0.053048052
Z variance eval              0.103800036
total_rewards                [3242.72458476 2019.44702341 5672.43612721 1454.88210096 5662.38343557
 4677.11042567 1712.92708153 5679.48142103 2078.58901844 5029.94068224]
total_rewards_mean           3722.99219008171
total_rewards_std            1703.800051708242
total_rewards_max            5679.481421027519
total_rewards_min            1454.8821009617143
Number of train steps total  1356000
Number of env steps total    1697000
Number of rollouts total     0
Train Time (s)               194.0569338700734
(Previous) Eval Time (s)     24.149133739992976
Sample Time (s)              18.66452887048945
Epoch Time (s)               236.87059648055583
Total Train Time (s)         76264.99242554698
Epoch                        338
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:41:24.556868 UTC | [2020_01_13_04_30_18] Iteration #338 | Epoch Duration: 230.77535128593445
2020-01-14 01:41:24.557008 UTC | [2020_01_13_04_30_18] Iteration #338 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05233122
Z variance train             0.10383334
KL Divergence                3.6320047
KL Loss                      0.3632005
QF Loss                      1085.584
VF Loss                      499.54065
Policy Loss                  -2769.0168
Q Predictions Mean           2768.6475
Q Predictions Std            457.04303
Q Predictions Max            2982.5889
Q Predictions Min            23.412653
V Predictions Mean           2779.1475
V Predictions Std            458.2568
V Predictions Max            2994.1077
V Predictions Min            29.863949
Log Pis Mean                 -5.3118467
Log Pis Std                  4.867838
Log Pis Max                  28.003674
Log Pis Min                  -13.079734
Policy mu Mean               0.23148482
Policy mu Std                0.6860099
Policy mu Max                3.3250046
Policy mu Min                -2.9078627
Policy log std Mean          -0.3319199
Policy log std Std           0.13997796
Policy log std Max           0.12001878
Policy log std Min           -1.3257657
Z mean eval                  0.055265408
Z variance eval              0.09394691
total_rewards                [5530.56831427 5459.85309879 5630.16558314 4808.78666223 1527.47330349
 5487.22991354 5598.06478593  639.09295894 2119.66434774 5562.29537921]
total_rewards_mean           4236.319434728254
total_rewards_std            1880.9065546233917
total_rewards_max            5630.165583139902
total_rewards_min            639.0929589398295
Number of train steps total  1360000
Number of env steps total    1702000
Number of rollouts total     0
Train Time (s)               193.09142620814964
(Previous) Eval Time (s)     18.053619361948222
Sample Time (s)              18.102064018137753
Epoch Time (s)               229.24710958823562
Total Train Time (s)         76496.74377379613
Epoch                        339
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:45:16.312251 UTC | [2020_01_13_04_30_18] Iteration #339 | Epoch Duration: 231.7551383972168
2020-01-14 01:45:16.312429 UTC | [2020_01_13_04_30_18] Iteration #339 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.055355877
Z variance train             0.09393036
KL Divergence                3.8584437
KL Loss                      0.38584438
QF Loss                      544.3693
VF Loss                      206.91241
Policy Loss                  -2764.0308
Q Predictions Mean           2757.4883
Q Predictions Std            476.87027
Q Predictions Max            2995.2827
Q Predictions Min            21.856363
V Predictions Mean           2760.7808
V Predictions Std            475.11243
V Predictions Max            2995.2554
V Predictions Min            23.65413
Log Pis Mean                 -5.9987717
Log Pis Std                  4.838951
Log Pis Max                  16.362244
Log Pis Min                  -14.849947
Policy mu Mean               0.19406176
Policy mu Std                0.66179556
Policy mu Max                2.4782054
Policy mu Min                -3.2538831
Policy log std Mean          -0.31931624
Policy log std Std           0.13618426
Policy log std Max           0.032276295
Policy log std Min           -1.0995315
Z mean eval                  0.046084605
Z variance eval              0.08912368
total_rewards                [2698.21721436 5091.37767382 5460.29229974 5252.30665268 5500.46119681
 5520.89209614 5371.26968633 5486.08369004 5465.29177701 5417.3772049 ]
total_rewards_mean           5126.35694918289
total_rewards_std            819.0866511937422
total_rewards_max            5520.8920961442045
total_rewards_min            2698.2172143588805
Number of train steps total  1364000
Number of env steps total    1707000
Number of rollouts total     0
Train Time (s)               201.0733491461724
(Previous) Eval Time (s)     20.56133662769571
Sample Time (s)              17.98044770071283
Epoch Time (s)               239.61513347458094
Total Train Time (s)         76738.47398148803
Epoch                        340
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:49:18.049335 UTC | [2020_01_13_04_30_18] Iteration #340 | Epoch Duration: 241.73673272132874
2020-01-14 01:49:18.049645 UTC | [2020_01_13_04_30_18] Iteration #340 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046086606
Z variance train             0.089101836
KL Divergence                3.8584726
KL Loss                      0.38584727
QF Loss                      1162.1296
VF Loss                      216.96684
Policy Loss                  -2790.1284
Q Predictions Mean           2790.4155
Q Predictions Std            433.5644
Q Predictions Max            2978.9868
Q Predictions Min            20.263348
V Predictions Mean           2790.9636
V Predictions Std            433.90762
V Predictions Max            2980.787
V Predictions Min            32.64929
Log Pis Mean                 -5.4791274
Log Pis Std                  4.5664744
Log Pis Max                  18.458078
Log Pis Min                  -17.04283
Policy mu Mean               0.20934756
Policy mu Std                0.6578912
Policy mu Max                2.6334984
Policy mu Min                -2.52157
Policy log std Mean          -0.3203619
Policy log std Std           0.1438111
Policy log std Max           -0.00838507
Policy log std Min           -1.3130648
Z mean eval                  0.04490412
Z variance eval              0.08617399
total_rewards                [5544.54793845 5428.83107016 5557.62109736 5493.71649217 5517.61982954
 5527.70469008 5350.23619729 4342.33566481 5435.97324843 5463.28159998]
total_rewards_mean           5366.186782826459
total_rewards_std            346.4810271074882
total_rewards_max            5557.621097356541
total_rewards_min            4342.335664812007
Number of train steps total  1368000
Number of env steps total    1712000
Number of rollouts total     0
Train Time (s)               197.69397385418415
(Previous) Eval Time (s)     22.68263245606795
Sample Time (s)              18.556901949923486
Epoch Time (s)               238.93350826017559
Total Train Time (s)         76980.82384011755
Epoch                        341
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:53:20.403052 UTC | [2020_01_13_04_30_18] Iteration #341 | Epoch Duration: 242.35319304466248
2020-01-14 01:53:20.403240 UTC | [2020_01_13_04_30_18] Iteration #341 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.044541445
Z variance train             0.086282544
KL Divergence                3.968276
KL Loss                      0.3968276
QF Loss                      1038.4216
VF Loss                      310.3854
Policy Loss                  -2785.5793
Q Predictions Mean           2776.9275
Q Predictions Std            404.3021
Q Predictions Max            2969.0117
Q Predictions Min            23.574
V Predictions Mean           2792.4053
V Predictions Std            401.21954
V Predictions Max            2983.7622
V Predictions Min            26.337856
Log Pis Mean                 -4.8179617
Log Pis Std                  5.2227244
Log Pis Max                  15.687539
Log Pis Min                  -13.475521
Policy mu Mean               0.24364062
Policy mu Std                0.6952463
Policy mu Max                2.3750286
Policy mu Min                -3.2113488
Policy log std Mean          -0.31605738
Policy log std Std           0.1374114
Policy log std Max           -0.05758869
Policy log std Min           -1.090707
Z mean eval                  0.037756268
Z variance eval              0.083967485
total_rewards                [5501.37299003 5483.98029139 1203.45781089 5496.44272559 2695.18277011
 5600.10888706 5454.10415772 5454.48878376 5375.51254323 5467.20301942]
total_rewards_mean           4773.185397919142
total_rewards_std            1451.7480237821017
total_rewards_max            5600.10888706126
total_rewards_min            1203.457810886435
Number of train steps total  1372000
Number of env steps total    1717000
Number of rollouts total     0
Train Time (s)               196.49777497025207
(Previous) Eval Time (s)     26.10205440176651
Sample Time (s)              16.688825754914433
Epoch Time (s)               239.288655126933
Total Train Time (s)         77216.00144662987
Epoch                        342
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 01:57:15.589468 UTC | [2020_01_13_04_30_18] Iteration #342 | Epoch Duration: 235.18605065345764
2020-01-14 01:57:15.589788 UTC | [2020_01_13_04_30_18] Iteration #342 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037665956
Z variance train             0.08400073
KL Divergence                4.036974
KL Loss                      0.4036974
QF Loss                      851.92633
VF Loss                      234.06174
Policy Loss                  -2792.0823
Q Predictions Mean           2788.713
Q Predictions Std            418.4556
Q Predictions Max            2979.7722
Q Predictions Min            23.245642
V Predictions Mean           2795.454
V Predictions Std            416.63806
V Predictions Max            2985.6277
V Predictions Min            33.506927
Log Pis Mean                 -5.2111983
Log Pis Std                  4.7015843
Log Pis Max                  19.080063
Log Pis Min                  -14.321848
Policy mu Mean               0.24206963
Policy mu Std                0.663111
Policy mu Max                2.3618548
Policy mu Min                -2.7265224
Policy log std Mean          -0.31812504
Policy log std Std           0.13615549
Policy log std Max           -0.03773216
Policy log std Min           -1.1066114
Z mean eval                  0.040141236
Z variance eval              0.08085187
total_rewards                [1793.71357956 5632.41307702 5156.82686221 4864.71482508 5557.69223744
 5512.21004778 5492.37733076 5458.09166184 5410.79109128 5568.22728406]
total_rewards_mean           5044.7057997031525
total_rewards_std            1105.4602799795823
total_rewards_max            5632.4130770181455
total_rewards_min            1793.7135795617673
Number of train steps total  1376000
Number of env steps total    1722000
Number of rollouts total     0
Train Time (s)               194.27753164293244
(Previous) Eval Time (s)     21.999159925151616
Sample Time (s)              18.788215699139982
Epoch Time (s)               235.06490726722404
Total Train Time (s)         77454.1101195612
Epoch                        343
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:01:13.699706 UTC | [2020_01_13_04_30_18] Iteration #343 | Epoch Duration: 238.10971355438232
2020-01-14 02:01:13.699829 UTC | [2020_01_13_04_30_18] Iteration #343 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039519656
Z variance train             0.080887035
KL Divergence                4.0252905
KL Loss                      0.40252906
QF Loss                      662.6781
VF Loss                      262.17487
Policy Loss                  -2798.0994
Q Predictions Mean           2795.7659
Q Predictions Std            484.7356
Q Predictions Max            2997.2305
Q Predictions Min            16.928385
V Predictions Mean           2810.1638
V Predictions Std            484.79752
V Predictions Max            3016.687
V Predictions Min            19.658392
Log Pis Mean                 -5.956011
Log Pis Std                  3.9840841
Log Pis Max                  11.738703
Log Pis Min                  -19.653913
Policy mu Mean               0.23170024
Policy mu Std                0.62955517
Policy mu Max                3.151497
Policy mu Min                -2.4716449
Policy log std Mean          -0.30613992
Policy log std Std           0.12982753
Policy log std Max           -0.079163715
Policy log std Min           -1.063137
Z mean eval                  0.04108427
Z variance eval              0.08476694
total_rewards                [5384.20748556 1871.06782139 5496.48602662 2984.88697118 1980.29215172
 5435.62736067 5362.52654011 5471.47634395 5518.08209005 1331.69615904]
total_rewards_mean           4083.6348950278807
total_rewards_std            1709.8170969697935
total_rewards_max            5518.082090048155
total_rewards_min            1331.6961590404185
Number of train steps total  1380000
Number of env steps total    1727000
Number of rollouts total     0
Train Time (s)               193.5370298740454
(Previous) Eval Time (s)     25.043642946053296
Sample Time (s)              18.894722195807844
Epoch Time (s)               237.47539501590654
Total Train Time (s)         77684.97688332852
Epoch                        344
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:05:04.570329 UTC | [2020_01_13_04_30_18] Iteration #344 | Epoch Duration: 230.8703966140747
2020-01-14 02:05:04.570533 UTC | [2020_01_13_04_30_18] Iteration #344 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04164598
Z variance train             0.084799506
KL Divergence                3.9431117
KL Loss                      0.39431116
QF Loss                      734.5098
VF Loss                      324.5563
Policy Loss                  -2782.9426
Q Predictions Mean           2777.755
Q Predictions Std            490.5704
Q Predictions Max            2996.875
Q Predictions Min            25.828087
V Predictions Mean           2775.0635
V Predictions Std            486.61926
V Predictions Max            3000.763
V Predictions Min            33.600857
Log Pis Mean                 -5.727253
Log Pis Std                  5.074705
Log Pis Max                  34.633335
Log Pis Min                  -14.070113
Policy mu Mean               0.20641883
Policy mu Std                0.6734189
Policy mu Max                4.087413
Policy mu Min                -3.289683
Policy log std Mean          -0.31341907
Policy log std Std           0.1373711
Policy log std Max           0.36551547
Policy log std Min           -1.76449
Z mean eval                  0.05410359
Z variance eval              0.08776572
total_rewards                [5507.5058334  5583.12852582 5454.40859082 5620.74618525  750.84431509
 5521.52945941 5682.39577905 5483.40182453 5572.51713217 5482.46202262]
total_rewards_mean           5065.893966816074
total_rewards_std            1439.9026945812939
total_rewards_max            5682.395779053776
total_rewards_min            750.844315088275
Number of train steps total  1384000
Number of env steps total    1732000
Number of rollouts total     0
Train Time (s)               197.16467738710344
(Previous) Eval Time (s)     18.438372302334756
Sample Time (s)              18.799927074927837
Epoch Time (s)               234.40297676436603
Total Train Time (s)         77923.52034088783
Epoch                        345
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:09:03.117677 UTC | [2020_01_13_04_30_18] Iteration #345 | Epoch Duration: 238.5470039844513
2020-01-14 02:09:03.117914 UTC | [2020_01_13_04_30_18] Iteration #345 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.054179825
Z variance train             0.08779849
KL Divergence                3.9334278
KL Loss                      0.3933428
QF Loss                      1108.7185
VF Loss                      351.2508
Policy Loss                  -2842.7222
Q Predictions Mean           2836.3174
Q Predictions Std            316.91064
Q Predictions Max            3007.4902
Q Predictions Min            22.493727
V Predictions Mean           2837.0881
V Predictions Std            317.42474
V Predictions Max            3005.8223
V Predictions Min            33.55041
Log Pis Mean                 -5.6270666
Log Pis Std                  5.3894973
Log Pis Max                  24.254011
Log Pis Min                  -13.7432575
Policy mu Mean               0.19543368
Policy mu Std                0.6557621
Policy mu Max                3.0556877
Policy mu Min                -3.7757838
Policy log std Mean          -0.31522852
Policy log std Std           0.14680889
Policy log std Max           -0.016161352
Policy log std Min           -1.3532722
Z mean eval                  0.04810237
Z variance eval              0.08124476
total_rewards                [5725.57392721 5594.82751596 5633.93840747 5576.18380573 5589.83528124
 5680.41777493 4076.55451517 5631.34311744 5719.76526453 5663.36955155]
total_rewards_mean           5489.180916124476
total_rewards_std            473.4452654560784
total_rewards_max            5725.573927214436
total_rewards_min            4076.554515171621
Number of train steps total  1388000
Number of env steps total    1737000
Number of rollouts total     0
Train Time (s)               199.01100852480158
(Previous) Eval Time (s)     22.581969968043268
Sample Time (s)              19.39128921041265
Epoch Time (s)               240.9842677032575
Total Train Time (s)         78168.29484424694
Epoch                        346
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:13:07.901827 UTC | [2020_01_13_04_30_18] Iteration #346 | Epoch Duration: 244.78377842903137
2020-01-14 02:13:07.901966 UTC | [2020_01_13_04_30_18] Iteration #346 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04796076
Z variance train             0.08127619
KL Divergence                4.026813
KL Loss                      0.40268132
QF Loss                      1060.5818
VF Loss                      369.17212
Policy Loss                  -2791.0063
Q Predictions Mean           2793.2834
Q Predictions Std            514.40985
Q Predictions Max            3004.524
Q Predictions Min            19.91209
V Predictions Mean           2792.454
V Predictions Std            513.02893
V Predictions Max            3001.031
V Predictions Min            23.470613
Log Pis Mean                 -5.8055983
Log Pis Std                  5.1438565
Log Pis Max                  26.260054
Log Pis Min                  -16.098295
Policy mu Mean               0.2294892
Policy mu Std                0.6289757
Policy mu Max                2.976653
Policy mu Min                -3.0111063
Policy log std Mean          -0.30685952
Policy log std Std           0.14902593
Policy log std Max           0.025278486
Policy log std Min           -1.4547732
Z mean eval                  0.047727697
Z variance eval              0.103056476
total_rewards                [5469.53536391 5389.27831479 5527.18722377 1187.74556822 5510.99772975
 5658.89262685 1869.63119988 5565.67223544 5571.32381811 5545.00998378]
total_rewards_mean           4729.52740644953
total_rewards_std            1609.0231791698664
total_rewards_max            5658.892626850944
total_rewards_min            1187.745568215803
Number of train steps total  1392000
Number of env steps total    1742000
Number of rollouts total     0
Train Time (s)               203.1568631050177
(Previous) Eval Time (s)     26.38109750673175
Sample Time (s)              18.97872001491487
Epoch Time (s)               248.5166806266643
Total Train Time (s)         78412.60524021229
Epoch                        347
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:17:12.220536 UTC | [2020_01_13_04_30_18] Iteration #347 | Epoch Duration: 244.31846833229065
2020-01-14 02:17:12.220734 UTC | [2020_01_13_04_30_18] Iteration #347 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04777394
Z variance train             0.103079915
KL Divergence                3.4790921
KL Loss                      0.3479092
QF Loss                      875.1443
VF Loss                      236.62482
Policy Loss                  -2830.729
Q Predictions Mean           2824.6772
Q Predictions Std            417.1234
Q Predictions Max            3004.9946
Q Predictions Min            19.341192
V Predictions Mean           2827.0786
V Predictions Std            414.32608
V Predictions Max            3004.574
V Predictions Min            28.476988
Log Pis Mean                 -5.6965322
Log Pis Std                  4.5944476
Log Pis Max                  22.045162
Log Pis Min                  -13.199274
Policy mu Mean               0.18264122
Policy mu Std                0.64729017
Policy mu Max                2.3108816
Policy mu Min                -2.6468046
Policy log std Mean          -0.30918968
Policy log std Std           0.13281952
Policy log std Max           0.005438991
Policy log std Min           -1.1955079
Z mean eval                  0.057716716
Z variance eval              0.105425
total_rewards                [5440.89259872 2905.14436976 4815.46881784 5558.70052107 1658.75963021
 5536.3229044  5473.2136692  5539.11738119 5180.66171494 5170.73423231]
total_rewards_mean           4727.901583964883
total_rewards_std            1273.4412421371912
total_rewards_max            5558.700521069377
total_rewards_min            1658.7596302109714
Number of train steps total  1396000
Number of env steps total    1747000
Number of rollouts total     0
Train Time (s)               198.94789294013754
(Previous) Eval Time (s)     22.182594790123403
Sample Time (s)              18.827939672395587
Epoch Time (s)               239.95842740265653
Total Train Time (s)         78651.84967461089
Epoch                        348
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:21:11.471848 UTC | [2020_01_13_04_30_18] Iteration #348 | Epoch Duration: 239.25095534324646
2020-01-14 02:21:11.472144 UTC | [2020_01_13_04_30_18] Iteration #348 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.057769984
Z variance train             0.10548572
KL Divergence                3.4310684
KL Loss                      0.34310684
QF Loss                      462.79584
VF Loss                      109.00276
Policy Loss                  -2849.4204
Q Predictions Mean           2846.9966
Q Predictions Std            437.36093
Q Predictions Max            3017.0657
Q Predictions Min            13.730064
V Predictions Mean           2849.8708
V Predictions Std            434.86142
V Predictions Max            3024.5205
V Predictions Min            26.573935
Log Pis Mean                 -5.8547473
Log Pis Std                  4.055739
Log Pis Max                  11.959692
Log Pis Min                  -16.34844
Policy mu Mean               0.25564402
Policy mu Std                0.62007225
Policy mu Max                2.3512597
Policy mu Min                -2.2591786
Policy log std Mean          -0.3048977
Policy log std Std           0.12932707
Policy log std Max           -0.041873515
Policy log std Min           -1.1525638
Z mean eval                  0.055398148
Z variance eval              0.09494883
total_rewards                [5689.95417628 5619.34033723 2762.04196036 1933.96349681 5526.95544395
 5658.77462665 5572.55893314 5518.48712586 5432.85926365 5587.96194319]
total_rewards_mean           4930.28973071265
total_rewards_std            1306.1946676269695
total_rewards_max            5689.954176284522
total_rewards_min            1933.9634968072767
Number of train steps total  1400000
Number of env steps total    1752000
Number of rollouts total     0
Train Time (s)               193.63231425685808
(Previous) Eval Time (s)     21.47484095627442
Sample Time (s)              16.339464565273374
Epoch Time (s)               231.44661977840587
Total Train Time (s)         78882.62703787722
Epoch                        349
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:25:02.254503 UTC | [2020_01_13_04_30_18] Iteration #349 | Epoch Duration: 230.78212237358093
2020-01-14 02:25:02.254772 UTC | [2020_01_13_04_30_18] Iteration #349 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05489289
Z variance train             0.09498675
KL Divergence                3.6914124
KL Loss                      0.36914125
QF Loss                      1078.3945
VF Loss                      453.14624
Policy Loss                  -2802.166
Q Predictions Mean           2802.3262
Q Predictions Std            466.99698
Q Predictions Max            3034.4338
Q Predictions Min            23.962631
V Predictions Mean           2803.6633
V Predictions Std            461.78616
V Predictions Max            3037.9236
V Predictions Min            29.797356
Log Pis Mean                 -5.362195
Log Pis Std                  4.7581434
Log Pis Max                  22.016598
Log Pis Min                  -13.239975
Policy mu Mean               0.20844883
Policy mu Std                0.68022066
Policy mu Max                3.1444988
Policy mu Min                -2.8469684
Policy log std Mean          -0.31317
Policy log std Std           0.12861766
Policy log std Max           0.14469786
Policy log std Min           -1.3413217
Z mean eval                  0.054739974
Z variance eval              0.09694235
total_rewards                [5339.61930109 5345.75405017 5063.15759534 5344.16437167 5229.27560385
 5450.50643007 5295.78228057 5256.67254761 5286.08419368 5389.39278072]
total_rewards_mean           5300.040915476055
total_rewards_std            99.72052128603076
total_rewards_max            5450.506430069233
total_rewards_min            5063.157595342378
Number of train steps total  1404000
Number of env steps total    1757000
Number of rollouts total     0
Train Time (s)               197.80031963204965
(Previous) Eval Time (s)     20.810100734699517
Sample Time (s)              16.602878672536463
Epoch Time (s)               235.21329903928563
Total Train Time (s)         79120.98507176805
Epoch                        350
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:29:00.617203 UTC | [2020_01_13_04_30_18] Iteration #350 | Epoch Duration: 238.3622326850891
2020-01-14 02:29:00.617406 UTC | [2020_01_13_04_30_18] Iteration #350 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.055339843
Z variance train             0.09694858
KL Divergence                3.6592035
KL Loss                      0.36592036
QF Loss                      1380.354
VF Loss                      607.8722
Policy Loss                  -2860.4756
Q Predictions Mean           2851.194
Q Predictions Std            383.75424
Q Predictions Max            3022.1985
Q Predictions Min            27.760658
V Predictions Mean           2851.9329
V Predictions Std            381.311
V Predictions Max            3024.8562
V Predictions Min            35.822945
Log Pis Mean                 -5.950093
Log Pis Std                  4.6115046
Log Pis Max                  16.249166
Log Pis Min                  -14.363237
Policy mu Mean               0.20658252
Policy mu Std                0.648189
Policy mu Max                2.75217
Policy mu Min                -2.930076
Policy log std Mean          -0.31086648
Policy log std Std           0.13710326
Policy log std Max           -0.057546742
Policy log std Min           -1.3094047
Z mean eval                  0.0644805
Z variance eval              0.09712788
total_rewards                [5460.19764872 5433.40104513 5325.69337683 5444.76639207 5427.16715083
 5265.33314321 5409.31952856 5406.36687137 5449.19888433 5475.84992281]
total_rewards_mean           5409.729396386647
total_rewards_std            62.04242690813205
total_rewards_max            5475.849922809033
total_rewards_min            5265.333143213002
Number of train steps total  1408000
Number of env steps total    1762000
Number of rollouts total     0
Train Time (s)               195.55886019719765
(Previous) Eval Time (s)     23.95877406699583
Sample Time (s)              19.04566627321765
Epoch Time (s)               238.56330053741112
Total Train Time (s)         79360.68728949735
Epoch                        351
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:33:00.323652 UTC | [2020_01_13_04_30_18] Iteration #351 | Epoch Duration: 239.70602893829346
2020-01-14 02:33:00.323908 UTC | [2020_01_13_04_30_18] Iteration #351 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.064759016
Z variance train             0.09715334
KL Divergence                3.6083157
KL Loss                      0.3608316
QF Loss                      881.172
VF Loss                      225.47176
Policy Loss                  -2837.4568
Q Predictions Mean           2835.2168
Q Predictions Std            465.8057
Q Predictions Max            3029.8503
Q Predictions Min            19.168228
V Predictions Mean           2838.0337
V Predictions Std            465.48752
V Predictions Max            3037.8125
V Predictions Min            31.424019
Log Pis Mean                 -6.0448284
Log Pis Std                  4.6182404
Log Pis Max                  18.11637
Log Pis Min                  -14.970316
Policy mu Mean               0.1816105
Policy mu Std                0.6557552
Policy mu Max                2.9171638
Policy mu Min                -2.4811242
Policy log std Mean          -0.31356785
Policy log std Std           0.13034484
Policy log std Max           0.24834818
Policy log std Min           -1.6887591
Z mean eval                  0.05892221
Z variance eval              0.10348954
total_rewards                [5651.32738357 5479.25180054 5366.09283023 5612.06907839 5475.1291791
 5604.66773625 5608.38111771 5493.55536836 5587.21409741 5575.62084377]
total_rewards_mean           5545.330943531792
total_rewards_std            83.64139664457807
total_rewards_max            5651.327383567966
total_rewards_min            5366.092830228072
Number of train steps total  1412000
Number of env steps total    1767000
Number of rollouts total     0
Train Time (s)               192.73010372603312
(Previous) Eval Time (s)     25.101212026085705
Sample Time (s)              17.163001434411854
Epoch Time (s)               234.99431718653068
Total Train Time (s)         79597.44174605701
Epoch                        352
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:36:57.080013 UTC | [2020_01_13_04_30_18] Iteration #352 | Epoch Duration: 236.75576639175415
2020-01-14 02:36:57.080149 UTC | [2020_01_13_04_30_18] Iteration #352 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.059133567
Z variance train             0.103489816
KL Divergence                3.5212612
KL Loss                      0.35212612
QF Loss                      496.33472
VF Loss                      210.5311
Policy Loss                  -2855.2354
Q Predictions Mean           2849.8745
Q Predictions Std            400.89963
Q Predictions Max            3028.5332
Q Predictions Min            19.33165
V Predictions Mean           2845.9463
V Predictions Std            401.84824
V Predictions Max            3026.5996
V Predictions Min            31.411324
Log Pis Mean                 -5.6732264
Log Pis Std                  4.6162643
Log Pis Max                  29.298609
Log Pis Min                  -16.564194
Policy mu Mean               0.20472911
Policy mu Std                0.634815
Policy mu Max                3.015077
Policy mu Min                -3.1923268
Policy log std Mean          -0.30621013
Policy log std Std           0.12879688
Policy log std Max           0.036202192
Policy log std Min           -1.3849926
Z mean eval                  0.06313106
Z variance eval              0.09835867
total_rewards                [1576.65288418 1869.40995422 5493.01032366 5349.35937568 5419.60291057
 5521.58312326 5409.19992941 5454.90058612 5511.05923768 5385.62802071]
total_rewards_mean           4699.040634550545
total_rewards_std            1490.3566842698613
total_rewards_max            5521.5831232578175
total_rewards_min            1576.652884180842
Number of train steps total  1416000
Number of env steps total    1772000
Number of rollouts total     0
Train Time (s)               193.29190863110125
(Previous) Eval Time (s)     26.862434211652726
Sample Time (s)              18.88010944472626
Epoch Time (s)               239.03445228748024
Total Train Time (s)         79831.1978625129
Epoch                        353
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:40:50.840451 UTC | [2020_01_13_04_30_18] Iteration #353 | Epoch Duration: 233.7601180076599
2020-01-14 02:40:50.840694 UTC | [2020_01_13_04_30_18] Iteration #353 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06356572
Z variance train             0.098396964
KL Divergence                3.6237845
KL Loss                      0.36237845
QF Loss                      625.1484
VF Loss                      187.79793
Policy Loss                  -2881.522
Q Predictions Mean           2874.9216
Q Predictions Std            350.46024
Q Predictions Max            3033.5222
Q Predictions Min            27.051067
V Predictions Mean           2873.486
V Predictions Std            351.07086
V Predictions Max            3028.793
V Predictions Min            36.246407
Log Pis Mean                 -5.892349
Log Pis Std                  4.912769
Log Pis Max                  35.67911
Log Pis Min                  -15.937183
Policy mu Mean               0.2613026
Policy mu Std                0.63536763
Policy mu Max                3.2799683
Policy mu Min                -4.45403
Policy log std Mean          -0.311524
Policy log std Std           0.12994316
Policy log std Max           0.021429628
Policy log std Min           -1.2009554
Z mean eval                  0.06304045
Z variance eval              0.097979404
total_rewards                [5554.83805574 5584.22359264 5485.48955899 5568.32920585 4498.15608288
 5571.86118889 5670.19537043 1491.46586683 2948.00964589 5622.79877771]
total_rewards_mean           4799.536734583613
total_rewards_std            1369.028645796722
total_rewards_max            5670.195370428558
total_rewards_min            1491.4658668315296
Number of train steps total  1420000
Number of env steps total    1777000
Number of rollouts total     0
Train Time (s)               198.00872427690774
(Previous) Eval Time (s)     21.58783287089318
Sample Time (s)              18.901376529131085
Epoch Time (s)               238.497933676932
Total Train Time (s)         80071.00095644593
Epoch                        354
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:44:50.646624 UTC | [2020_01_13_04_30_18] Iteration #354 | Epoch Duration: 239.80580139160156
2020-01-14 02:44:50.646813 UTC | [2020_01_13_04_30_18] Iteration #354 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06255587
Z variance train             0.098002285
KL Divergence                3.6490583
KL Loss                      0.36490583
QF Loss                      905.2765
VF Loss                      365.5568
Policy Loss                  -2872.6653
Q Predictions Mean           2866.784
Q Predictions Std            367.20508
Q Predictions Max            3047.6252
Q Predictions Min            34.641426
V Predictions Mean           2882.4277
V Predictions Std            371.03125
V Predictions Max            3062.1624
V Predictions Min            45.37561
Log Pis Mean                 -5.577487
Log Pis Std                  4.526193
Log Pis Max                  13.887756
Log Pis Min                  -15.007715
Policy mu Mean               0.261687
Policy mu Std                0.6641833
Policy mu Max                2.7458627
Policy mu Min                -3.8884318
Policy log std Mean          -0.3144947
Policy log std Std           0.1346634
Policy log std Max           0.022526301
Policy log std Min           -1.3478891
Z mean eval                  0.07230739
Z variance eval              0.096202955
total_rewards                [5566.27108537 5574.86671215 5474.53452637 2702.61876374 5668.58903456
 5545.08483563 5628.82281497  484.32404517 5540.89338505 5535.66336626]
total_rewards_mean           4772.166856927783
total_rewards_std            1665.7003320607866
total_rewards_max            5668.5890345619855
total_rewards_min            484.32404517007797
Number of train steps total  1424000
Number of env steps total    1782000
Number of rollouts total     0
Train Time (s)               196.7697135163471
(Previous) Eval Time (s)     22.895420734304935
Sample Time (s)              16.65402996633202
Epoch Time (s)               236.31916421698406
Total Train Time (s)         80307.4062450882
Epoch                        355
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:48:47.055606 UTC | [2020_01_13_04_30_18] Iteration #355 | Epoch Duration: 236.40866708755493
2020-01-14 02:48:47.055738 UTC | [2020_01_13_04_30_18] Iteration #355 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07259906
Z variance train             0.09615426
KL Divergence                3.657106
KL Loss                      0.3657106
QF Loss                      862.04254
VF Loss                      325.08762
Policy Loss                  -2922.7573
Q Predictions Mean           2913.2737
Q Predictions Std            188.14108
Q Predictions Max            3050.8938
Q Predictions Min            513.57367
V Predictions Mean           2912.9893
V Predictions Std            184.9484
V Predictions Max            3048.3516
V Predictions Min            525.3519
Log Pis Mean                 -5.4316664
Log Pis Std                  4.7552094
Log Pis Max                  27.317513
Log Pis Min                  -14.50408
Policy mu Mean               0.22420079
Policy mu Std                0.6439173
Policy mu Max                2.350005
Policy mu Min                -2.744082
Policy log std Mean          -0.30883008
Policy log std Std           0.12888949
Policy log std Max           -0.046996117
Policy log std Min           -1.5052936
Z mean eval                  0.039519668
Z variance eval              0.10323207
total_rewards                [5434.54838681 3262.93664669 4146.14269315 5271.80316954  903.1970445
 3791.85793284 3571.49585998 5403.47416339 5198.56514557 1989.93790629]
total_rewards_mean           3897.395894875219
total_rewards_std            1462.8236956386684
total_rewards_max            5434.54838681308
total_rewards_min            903.1970444987563
Number of train steps total  1428000
Number of env steps total    1787000
Number of rollouts total     0
Train Time (s)               199.62499421695247
(Previous) Eval Time (s)     22.98467361787334
Sample Time (s)              19.255501449573785
Epoch Time (s)               241.8651692843996
Total Train Time (s)         80543.45248490106
Epoch                        356
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:52:43.108766 UTC | [2020_01_13_04_30_18] Iteration #356 | Epoch Duration: 236.05292057991028
2020-01-14 02:52:43.108946 UTC | [2020_01_13_04_30_18] Iteration #356 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039577596
Z variance train             0.10321157
KL Divergence                3.4553032
KL Loss                      0.34553033
QF Loss                      1194.9506
VF Loss                      421.2924
Policy Loss                  -2910.3418
Q Predictions Mean           2909.984
Q Predictions Std            289.11823
Q Predictions Max            3031.327
Q Predictions Min            78.389175
V Predictions Mean           2902.2644
V Predictions Std            290.3512
V Predictions Max            3040.724
V Predictions Min            106.70709
Log Pis Mean                 -6.2460213
Log Pis Std                  4.301766
Log Pis Max                  15.594926
Log Pis Min                  -15.237315
Policy mu Mean               0.25061727
Policy mu Std                0.61138827
Policy mu Max                3.3286827
Policy mu Min                -2.5658343
Policy log std Mean          -0.29919764
Policy log std Std           0.12676641
Policy log std Max           -0.031283803
Policy log std Min           -1.098835
Z mean eval                  0.05771613
Z variance eval              0.108831346
total_rewards                [5413.74023698 3488.77525003 5366.01033304 5426.64633209 5577.23355266
 4400.96669351 5604.20958397 5513.35910209 4033.92073095 5465.15347289]
total_rewards_mean           5029.001528821058
total_rewards_std            723.3867687170182
total_rewards_max            5604.209583969865
total_rewards_min            3488.7752500313795
Number of train steps total  1432000
Number of env steps total    1792000
Number of rollouts total     0
Train Time (s)               195.12445273483172
(Previous) Eval Time (s)     17.17209891602397
Sample Time (s)              19.006327615585178
Epoch Time (s)               231.30287926644087
Total Train Time (s)         80779.70559081016
Epoch                        357
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 02:56:39.369141 UTC | [2020_01_13_04_30_18] Iteration #357 | Epoch Duration: 236.26001572608948
2020-01-14 02:56:39.369444 UTC | [2020_01_13_04_30_18] Iteration #357 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.057341196
Z variance train             0.108812034
KL Divergence                3.3631604
KL Loss                      0.33631605
QF Loss                      977.5052
VF Loss                      264.47693
Policy Loss                  -2899.08
Q Predictions Mean           2897.4893
Q Predictions Std            332.4164
Q Predictions Max            3041.4878
Q Predictions Min            20.331762
V Predictions Mean           2900.427
V Predictions Std            329.37814
V Predictions Max            3046.456
V Predictions Min            33.529808
Log Pis Mean                 -5.4691343
Log Pis Std                  4.7323117
Log Pis Max                  18.151188
Log Pis Min                  -17.133862
Policy mu Mean               0.19500385
Policy mu Std                0.650765
Policy mu Max                2.5651426
Policy mu Min                -3.2347147
Policy log std Mean          -0.31349272
Policy log std Std           0.1386896
Policy log std Max           -0.0014167428
Policy log std Min           -1.5182481
Z mean eval                  0.055586345
Z variance eval              0.120764814
total_rewards                [5555.32352681 5448.20889913 5351.43726901 5270.83848355 5445.62501399
 5575.58935014 4893.55261419 5480.73137235 5482.95889355 5522.80155933]
total_rewards_mean           5402.706698204687
total_rewards_std            190.6041557282463
total_rewards_max            5575.5893501359715
total_rewards_min            4893.5526141864075
Number of train steps total  1436000
Number of env steps total    1797000
Number of rollouts total     0
Train Time (s)               194.30080254375935
(Previous) Eval Time (s)     22.12894084211439
Sample Time (s)              19.12247055117041
Epoch Time (s)               235.55221393704414
Total Train Time (s)         81019.5348484898
Epoch                        358
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:00:39.200048 UTC | [2020_01_13_04_30_18] Iteration #358 | Epoch Duration: 239.8304033279419
2020-01-14 03:00:39.200191 UTC | [2020_01_13_04_30_18] Iteration #358 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05516856
Z variance train             0.12079121
KL Divergence                3.2281792
KL Loss                      0.32281792
QF Loss                      531.61865
VF Loss                      149.68878
Policy Loss                  -2929.919
Q Predictions Mean           2926.8052
Q Predictions Std            262.5673
Q Predictions Max            3059.232
Q Predictions Min            28.8317
V Predictions Mean           2933.0898
V Predictions Std            263.28394
V Predictions Max            3070.3916
V Predictions Min            41.438087
Log Pis Mean                 -5.7936316
Log Pis Std                  4.501394
Log Pis Max                  17.863192
Log Pis Min                  -16.472069
Policy mu Mean               0.23739856
Policy mu Std                0.6227077
Policy mu Max                2.8580549
Policy mu Min                -2.3706582
Policy log std Mean          -0.30234072
Policy log std Std           0.13022925
Policy log std Max           -0.06346073
Policy log std Min           -1.1503932
Z mean eval                  0.055893265
Z variance eval              0.10467516
total_rewards                [5592.67488978 5572.62455021 5550.56169053 5441.78596332 5601.50656658
 5586.22099226 2105.15341764 5655.62458864 5613.1667191  5560.83304691]
total_rewards_mean           5228.015242496926
total_rewards_std            1042.2810837202062
total_rewards_max            5655.624588638537
total_rewards_min            2105.1534176368823
Number of train steps total  1440000
Number of env steps total    1802000
Number of rollouts total     0
Train Time (s)               194.68643395137042
(Previous) Eval Time (s)     26.40685178898275
Sample Time (s)              19.001041307579726
Epoch Time (s)               240.0943270479329
Total Train Time (s)         81257.9476038604
Epoch                        359
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:04:37.618198 UTC | [2020_01_13_04_30_18] Iteration #359 | Epoch Duration: 238.4178705215454
2020-01-14 03:04:37.618509 UTC | [2020_01_13_04_30_18] Iteration #359 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.055662733
Z variance train             0.10459019
KL Divergence                3.4707937
KL Loss                      0.34707937
QF Loss                      864.47
VF Loss                      379.3148
Policy Loss                  -2891.6636
Q Predictions Mean           2888.9292
Q Predictions Std            368.86807
Q Predictions Max            3061.4407
Q Predictions Min            24.144659
V Predictions Mean           2901.142
V Predictions Std            363.80957
V Predictions Max            3071.122
V Predictions Min            30.047665
Log Pis Mean                 -5.4665203
Log Pis Std                  5.2854805
Log Pis Max                  30.126661
Log Pis Min                  -17.34551
Policy mu Mean               0.2135698
Policy mu Std                0.6728794
Policy mu Max                3.764842
Policy mu Min                -2.9881766
Policy log std Mean          -0.29462355
Policy log std Std           0.13304256
Policy log std Max           -0.047666214
Policy log std Min           -1.4445937
Z mean eval                  0.055862904
Z variance eval              0.097079724
total_rewards                [5520.80127433 1460.5456617  4674.84228259 4825.63329584 5535.02373576
 5410.5280079  5468.93620372 5475.56464344 5531.37021534 4113.93251784]
total_rewards_mean           4801.71778384573
total_rewards_std            1204.5854192041566
total_rewards_max            5535.023735757084
total_rewards_min            1460.545661696936
Number of train steps total  1444000
Number of env steps total    1807000
Number of rollouts total     0
Train Time (s)               197.7219609809108
(Previous) Eval Time (s)     24.730061443988234
Sample Time (s)              16.627990934532136
Epoch Time (s)               239.08001335943118
Total Train Time (s)         81495.82330493815
Epoch                        360
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:08:35.495682 UTC | [2020_01_13_04_30_18] Iteration #360 | Epoch Duration: 237.8770091533661
2020-01-14 03:08:35.495815 UTC | [2020_01_13_04_30_18] Iteration #360 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.055800416
Z variance train             0.097078845
KL Divergence                3.622789
KL Loss                      0.3622789
QF Loss                      870.4077
VF Loss                      208.10815
Policy Loss                  -2891.79
Q Predictions Mean           2885.7104
Q Predictions Std            413.2812
Q Predictions Max            3066.1138
Q Predictions Min            22.550858
V Predictions Mean           2895.628
V Predictions Std            412.84778
V Predictions Max            3076.0952
V Predictions Min            31.482018
Log Pis Mean                 -5.5301127
Log Pis Std                  4.926079
Log Pis Max                  17.80655
Log Pis Min                  -15.326509
Policy mu Mean               0.24826947
Policy mu Std                0.6503495
Policy mu Max                2.498043
Policy mu Min                -2.9603462
Policy log std Mean          -0.30741605
Policy log std Std           0.1398692
Policy log std Max           -0.058045786
Policy log std Min           -1.399756
Z mean eval                  0.052897442
Z variance eval              0.111267254
total_rewards                [5417.37267812 4113.85501003 5330.1368467  5396.14601737 5465.77907206
 5383.15036573 5504.81585515 5449.00770359 3539.92063855 5355.25319406]
total_rewards_mean           5095.5437381355705
total_rewards_std            649.0244007100094
total_rewards_max            5504.815855152861
total_rewards_min            3539.9206385543516
Number of train steps total  1448000
Number of env steps total    1812000
Number of rollouts total     0
Train Time (s)               196.27811247576028
(Previous) Eval Time (s)     23.526777653954923
Sample Time (s)              18.92692720144987
Epoch Time (s)               238.73181733116508
Total Train Time (s)         81734.8147655204
Epoch                        361
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:12:34.490871 UTC | [2020_01_13_04_30_18] Iteration #361 | Epoch Duration: 238.99494981765747
2020-01-14 03:12:34.491048 UTC | [2020_01_13_04_30_18] Iteration #361 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.052512307
Z variance train             0.11129069
KL Divergence                3.406332
KL Loss                      0.3406332
QF Loss                      931.276
VF Loss                      313.61844
Policy Loss                  -2900.7512
Q Predictions Mean           2895.6943
Q Predictions Std            376.56598
Q Predictions Max            3062.7195
Q Predictions Min            26.765799
V Predictions Mean           2907.9736
V Predictions Std            372.41132
V Predictions Max            3076.705
V Predictions Min            38.73602
Log Pis Mean                 -5.2966003
Log Pis Std                  5.6892657
Log Pis Max                  35.171913
Log Pis Min                  -15.523142
Policy mu Mean               0.23332655
Policy mu Std                0.66050774
Policy mu Max                3.6772006
Policy mu Min                -3.8417587
Policy log std Mean          -0.3025809
Policy log std Std           0.12555178
Policy log std Max           0.33653837
Policy log std Min           -1.2634404
Z mean eval                  0.051190697
Z variance eval              0.112138525
total_rewards                [5461.81489794 5521.56372422 5537.96551421 5592.7251397  4236.30883655
 4578.87106884 4050.94223055 5538.71214769 5465.40864194 5534.5441885 ]
total_rewards_mean           5151.885639014619
total_rewards_std            578.7207549212714
total_rewards_max            5592.725139699612
total_rewards_min            4050.9422305473663
Number of train steps total  1452000
Number of env steps total    1817000
Number of rollouts total     0
Train Time (s)               194.54670547693968
(Previous) Eval Time (s)     23.78962940070778
Sample Time (s)              18.669012708589435
Epoch Time (s)               237.0053475862369
Total Train Time (s)         81970.26732601505
Epoch                        362
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:16:29.945603 UTC | [2020_01_13_04_30_18] Iteration #362 | Epoch Duration: 235.454443693161
2020-01-14 03:16:29.945718 UTC | [2020_01_13_04_30_18] Iteration #362 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.051543225
Z variance train             0.1120744
KL Divergence                3.3539934
KL Loss                      0.33539936
QF Loss                      928.9802
VF Loss                      226.54373
Policy Loss                  -2944.6982
Q Predictions Mean           2938.0718
Q Predictions Std            253.4828
Q Predictions Max            3081.2017
Q Predictions Min            20.719072
V Predictions Mean           2944.9163
V Predictions Std            246.60559
V Predictions Max            3083.5164
V Predictions Min            30.774763
Log Pis Mean                 -5.6970654
Log Pis Std                  5.7990236
Log Pis Max                  32.15557
Log Pis Min                  -14.714127
Policy mu Mean               0.24015401
Policy mu Std                0.6481774
Policy mu Max                2.984141
Policy mu Min                -4.8177676
Policy log std Mean          -0.2952895
Policy log std Std           0.13021338
Policy log std Max           -0.0075334534
Policy log std Min           -1.2721049
Z mean eval                  0.057856493
Z variance eval              0.12970862
total_rewards                [3121.7319712  4529.72801661 3891.89020911 3208.56487707 5635.6266227
 1807.30601645 5661.16378178 3785.24288595 1669.75654006 3073.79955529]
total_rewards_mean           3638.4810476220096
total_rewards_std            1302.2946357138783
total_rewards_max            5661.163781777729
total_rewards_min            1669.75654006151
Number of train steps total  1456000
Number of env steps total    1822000
Number of rollouts total     0
Train Time (s)               197.7110184156336
(Previous) Eval Time (s)     22.238463781774044
Sample Time (s)              18.70661899074912
Epoch Time (s)               238.65610118815675
Total Train Time (s)         82203.08673837408
Epoch                        363
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:20:22.774035 UTC | [2020_01_13_04_30_18] Iteration #363 | Epoch Duration: 232.8281762599945
2020-01-14 03:20:22.774350 UTC | [2020_01_13_04_30_18] Iteration #363 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.056837153
Z variance train             0.1296448
KL Divergence                3.0947149
KL Loss                      0.3094715
QF Loss                      1478.9158
VF Loss                      563.92786
Policy Loss                  -2893.4993
Q Predictions Mean           2894.5554
Q Predictions Std            420.55627
Q Predictions Max            3082.626
Q Predictions Min            25.071041
V Predictions Mean           2907.9763
V Predictions Std            413.6983
V Predictions Max            3102.742
V Predictions Min            41.62068
Log Pis Mean                 -5.438305
Log Pis Std                  4.9922547
Log Pis Max                  17.991373
Log Pis Min                  -13.193715
Policy mu Mean               0.19949663
Policy mu Std                0.6594999
Policy mu Max                2.929987
Policy mu Min                -2.9894755
Policy log std Mean          -0.31164533
Policy log std Std           0.14838792
Policy log std Max           0.18294537
Policy log std Min           -1.4295571
Z mean eval                  0.052287906
Z variance eval              0.11904617
total_rewards                [ 918.03919269 4230.95443533  854.51381528 2799.13579274 1166.47268047
 5647.96022945 5526.30635706 3138.36225534 5364.37230611 5306.78606268]
total_rewards_mean           3495.290312713595
total_rewards_std            1890.1466651409387
total_rewards_max            5647.960229446703
total_rewards_min            854.513815276739
Number of train steps total  1460000
Number of env steps total    1827000
Number of rollouts total     0
Train Time (s)               200.14200041489676
(Previous) Eval Time (s)     16.41022458486259
Sample Time (s)              18.6375132156536
Epoch Time (s)               235.18973821541294
Total Train Time (s)         82438.79491364211
Epoch                        364
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:24:18.484563 UTC | [2020_01_13_04_30_18] Iteration #364 | Epoch Duration: 235.70999836921692
2020-01-14 03:24:18.484755 UTC | [2020_01_13_04_30_18] Iteration #364 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05253166
Z variance train             0.119041145
KL Divergence                3.2027028
KL Loss                      0.32027027
QF Loss                      895.64307
VF Loss                      349.55487
Policy Loss                  -2890.538
Q Predictions Mean           2889.9087
Q Predictions Std            438.06805
Q Predictions Max            3086.8906
Q Predictions Min            24.89154
V Predictions Mean           2887.6104
V Predictions Std            437.81512
V Predictions Max            3082.8623
V Predictions Min            21.250061
Log Pis Mean                 -5.57574
Log Pis Std                  4.9622216
Log Pis Max                  30.91091
Log Pis Min                  -15.271397
Policy mu Mean               0.20377636
Policy mu Std                0.64841765
Policy mu Max                3.6015885
Policy mu Min                -3.1997774
Policy log std Mean          -0.30343834
Policy log std Std           0.12911336
Policy log std Max           0.051793106
Policy log std Min           -1.0442095
Z mean eval                  0.05281418
Z variance eval              0.10747342
total_rewards                [5626.65223255 4495.4220293  5614.60598318 5479.95837431 5419.52481949
 5507.50020197 5323.66448736 5416.1606818  5493.56678512 5616.87165416]
total_rewards_mean           5399.392724923781
total_rewards_std            315.57752917335046
total_rewards_max            5626.652232545227
total_rewards_min            4495.422029295984
Number of train steps total  1464000
Number of env steps total    1832000
Number of rollouts total     0
Train Time (s)               192.61478916788474
(Previous) Eval Time (s)     16.930219505913556
Sample Time (s)              19.00269690155983
Epoch Time (s)               228.54770557535812
Total Train Time (s)         82676.70159940887
Epoch                        365
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:28:16.397821 UTC | [2020_01_13_04_30_18] Iteration #365 | Epoch Duration: 237.91289901733398
2020-01-14 03:28:16.398142 UTC | [2020_01_13_04_30_18] Iteration #365 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.053390037
Z variance train             0.10735567
KL Divergence                3.3852189
KL Loss                      0.3385219
QF Loss                      605.109
VF Loss                      345.2329
Policy Loss                  -2947.7925
Q Predictions Mean           2939.3682
Q Predictions Std            286.09546
Q Predictions Max            3092.5168
Q Predictions Min            37.535942
V Predictions Mean           2938.761
V Predictions Std            283.34637
V Predictions Max            3094.3032
V Predictions Min            56.06482
Log Pis Mean                 -6.6702876
Log Pis Std                  4.0007405
Log Pis Max                  12.946933
Log Pis Min                  -14.125921
Policy mu Mean               0.23592192
Policy mu Std                0.5924602
Policy mu Max                2.6801798
Policy mu Min                -2.6246135
Policy log std Mean          -0.29712304
Policy log std Std           0.12139968
Policy log std Max           -0.07683852
Policy log std Min           -1.2225871
Z mean eval                  0.052626453
Z variance eval              0.11840127
total_rewards                [5470.10297943 5486.93339257 5398.45671142 5552.68876164 4131.15786758
 2478.83189268 5509.17238489 5576.1719067  5620.01393588 4495.45490986]
total_rewards_mean           4971.898474266438
total_rewards_std            962.0720081891385
total_rewards_max            5620.013935879474
total_rewards_min            2478.8318926811735
Number of train steps total  1468000
Number of env steps total    1837000
Number of rollouts total     0
Train Time (s)               195.23214635625482
(Previous) Eval Time (s)     26.29507089126855
Sample Time (s)              16.6803027279675
Epoch Time (s)               238.20751997549087
Total Train Time (s)         82912.67653141962
Epoch                        366
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:32:12.380747 UTC | [2020_01_13_04_30_18] Iteration #366 | Epoch Duration: 235.98237991333008
2020-01-14 03:32:12.380933 UTC | [2020_01_13_04_30_18] Iteration #366 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.052368633
Z variance train             0.11838965
KL Divergence                3.1926591
KL Loss                      0.31926593
QF Loss                      731.7599
VF Loss                      148.85893
Policy Loss                  -2966.6333
Q Predictions Mean           2959.9727
Q Predictions Std            197.79626
Q Predictions Max            3080.8772
Q Predictions Min            330.08878
V Predictions Mean           2967.356
V Predictions Std            196.8274
V Predictions Max            3091.507
V Predictions Min            328.9763
Log Pis Mean                 -6.3839793
Log Pis Std                  4.029644
Log Pis Max                  11.8058605
Log Pis Min                  -14.44338
Policy mu Mean               0.1903207
Policy mu Std                0.6144711
Policy mu Max                2.5365613
Policy mu Min                -2.2126725
Policy log std Mean          -0.29614645
Policy log std Std           0.12957327
Policy log std Max           -0.06664872
Policy log std Min           -1.0282186
Z mean eval                  0.041306246
Z variance eval              0.11169474
total_rewards                [5531.29966535 5533.93191255 5486.16132962 5605.24869419 5536.63413885
 5489.48413268 1822.56620223 3403.36636922 5496.92053612 5566.64568076]
total_rewards_mean           4947.225866157072
total_rewards_std            1219.9632413261677
total_rewards_max            5605.248694192439
total_rewards_min            1822.5662022283113
Number of train steps total  1472000
Number of env steps total    1842000
Number of rollouts total     0
Train Time (s)               195.9805513783358
(Previous) Eval Time (s)     24.069663742091507
Sample Time (s)              19.232726904563606
Epoch Time (s)               239.28294202499092
Total Train Time (s)         83151.87550505297
Epoch                        367
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:36:11.581824 UTC | [2020_01_13_04_30_18] Iteration #367 | Epoch Duration: 239.20076990127563
2020-01-14 03:36:11.581966 UTC | [2020_01_13_04_30_18] Iteration #367 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04137231
Z variance train             0.111684576
KL Divergence                3.3452616
KL Loss                      0.33452615
QF Loss                      1714.7848
VF Loss                      187.85008
Policy Loss                  -2874.5156
Q Predictions Mean           2868.1138
Q Predictions Std            481.56747
Q Predictions Max            3089.7002
Q Predictions Min            24.772045
V Predictions Mean           2872.9663
V Predictions Std            480.0955
V Predictions Max            3099.7869
V Predictions Min            32.468212
Log Pis Mean                 -5.8433847
Log Pis Std                  6.3239865
Log Pis Max                  52.011024
Log Pis Min                  -15.085205
Policy mu Mean               0.2283339
Policy mu Std                0.6512191
Policy mu Max                4.021608
Policy mu Min                -3.4321635
Policy log std Mean          -0.29962978
Policy log std Std           0.14158626
Policy log std Max           -0.012090541
Policy log std Min           -1.5132194
Z mean eval                  0.05231191
Z variance eval              0.12512968
total_rewards                [5675.67259739 5353.43497163 5598.28463706 2942.76757178 5638.46562875
 5649.15818907 5617.48389945 3805.77926269 5670.56915834 5692.30865891]
total_rewards_mean           5164.392457506661
total_rewards_std            920.1521196081317
total_rewards_max            5692.308658907026
total_rewards_min            2942.7675717816696
Number of train steps total  1476000
Number of env steps total    1847000
Number of rollouts total     0
Train Time (s)               193.52408648421988
(Previous) Eval Time (s)     23.987215094268322
Sample Time (s)              18.44062441959977
Epoch Time (s)               235.95192599808797
Total Train Time (s)         83388.16109306505
Epoch                        368
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:40:07.870368 UTC | [2020_01_13_04_30_18] Iteration #368 | Epoch Duration: 236.28830909729004
2020-01-14 03:40:07.870493 UTC | [2020_01_13_04_30_18] Iteration #368 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05217942
Z variance train             0.12512246
KL Divergence                3.0437536
KL Loss                      0.30437538
QF Loss                      672.62506
VF Loss                      210.3614
Policy Loss                  -2891.2515
Q Predictions Mean           2889.5703
Q Predictions Std            502.02393
Q Predictions Max            3084.8567
Q Predictions Min            19.589127
V Predictions Mean           2893.8774
V Predictions Std            501.47458
V Predictions Max            3089.4275
V Predictions Min            26.705305
Log Pis Mean                 -6.4534206
Log Pis Std                  4.0358925
Log Pis Max                  7.990645
Log Pis Min                  -16.27029
Policy mu Mean               0.18054657
Policy mu Std                0.6122092
Policy mu Max                2.6502323
Policy mu Min                -2.7070947
Policy log std Mean          -0.30280167
Policy log std Std           0.13147105
Policy log std Max           -0.058264688
Policy log std Min           -1.2000977
Z mean eval                  0.045112114
Z variance eval              0.11191337
total_rewards                [2463.98364628 5492.42196683 5504.16030038 5412.43998914 5507.37103046
 5631.40122723 5615.41532204 4226.8812719  5435.19564395 3704.92159112]
total_rewards_mean           4899.419198934293
total_rewards_std            1024.5068330532458
total_rewards_max            5631.40122723143
total_rewards_min            2463.983646280632
Number of train steps total  1480000
Number of env steps total    1852000
Number of rollouts total     0
Train Time (s)               195.90694672893733
(Previous) Eval Time (s)     24.32332747289911
Sample Time (s)              18.843092353083193
Epoch Time (s)               239.07336655491963
Total Train Time (s)         83626.5560258287
Epoch                        369
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:44:06.270352 UTC | [2020_01_13_04_30_18] Iteration #369 | Epoch Duration: 238.39976811408997
2020-01-14 03:44:06.270509 UTC | [2020_01_13_04_30_18] Iteration #369 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045401014
Z variance train             0.111998305
KL Divergence                3.281093
KL Loss                      0.3281093
QF Loss                      809.0725
VF Loss                      342.81485
Policy Loss                  -2942.9895
Q Predictions Mean           2937.168
Q Predictions Std            325.36328
Q Predictions Max            3104.0674
Q Predictions Min            27.79692
V Predictions Mean           2934.1501
V Predictions Std            327.0059
V Predictions Max            3098.1763
V Predictions Min            32.409653
Log Pis Mean                 -6.164401
Log Pis Std                  4.2451253
Log Pis Max                  14.33513
Log Pis Min                  -15.79834
Policy mu Mean               0.17041038
Policy mu Std                0.64039636
Policy mu Max                2.387499
Policy mu Min                -2.7584145
Policy log std Mean          -0.2970295
Policy log std Std           0.13192864
Policy log std Max           -0.01764436
Policy log std Min           -1.5548501
Z mean eval                  0.060382884
Z variance eval              0.11840546
total_rewards                [5499.8488127  5567.25380391 5483.30508277 5507.23766847 5194.37467473
 5374.39620988 5463.14163363 5597.09589906 5579.65559681  834.85336443]
total_rewards_mean           5010.116274639311
total_rewards_std            1396.2414192085666
total_rewards_max            5597.095899060566
total_rewards_min            834.8533644339501
Number of train steps total  1484000
Number of env steps total    1857000
Number of rollouts total     0
Train Time (s)               196.0832142601721
(Previous) Eval Time (s)     23.64944142801687
Sample Time (s)              18.820936707779765
Epoch Time (s)               238.55359239596874
Total Train Time (s)         83865.68517767685
Epoch                        370
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:48:05.405569 UTC | [2020_01_13_04_30_18] Iteration #370 | Epoch Duration: 239.13494062423706
2020-01-14 03:48:05.405760 UTC | [2020_01_13_04_30_18] Iteration #370 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.060764212
Z variance train             0.11838821
KL Divergence                3.164552
KL Loss                      0.31645522
QF Loss                      831.9227
VF Loss                      169.24191
Policy Loss                  -2952.1824
Q Predictions Mean           2948.8943
Q Predictions Std            322.6013
Q Predictions Max            3100.8079
Q Predictions Min            19.998642
V Predictions Mean           2947.8647
V Predictions Std            323.36276
V Predictions Max            3095.893
V Predictions Min            26.764383
Log Pis Mean                 -6.7512865
Log Pis Std                  3.741789
Log Pis Max                  13.527532
Log Pis Min                  -14.521477
Policy mu Mean               0.18909031
Policy mu Std                0.5982151
Policy mu Max                2.6533864
Policy mu Min                -2.451006
Policy log std Mean          -0.29777968
Policy log std Std           0.12895982
Policy log std Max           -0.062482424
Policy log std Min           -1.2778552
Z mean eval                  0.050007172
Z variance eval              0.1089056
total_rewards                [5454.56899654 4175.33052072 5429.90285958 5511.42242505 5304.8167347
 5498.21126663 5384.25686477 5444.43043595 5484.26598734 5473.69009667]
total_rewards_mean           5316.08961879606
total_rewards_std            384.5973127485457
total_rewards_max            5511.422425046218
total_rewards_min            4175.330520723197
Number of train steps total  1488000
Number of env steps total    1862000
Number of rollouts total     0
Train Time (s)               198.66416764771566
(Previous) Eval Time (s)     24.230495555326343
Sample Time (s)              18.39943218184635
Epoch Time (s)               241.29409538488835
Total Train Time (s)         84106.9135165466
Epoch                        371
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:52:06.640082 UTC | [2020_01_13_04_30_18] Iteration #371 | Epoch Duration: 241.2341821193695
2020-01-14 03:52:06.640275 UTC | [2020_01_13_04_30_18] Iteration #371 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04994236
Z variance train             0.10899522
KL Divergence                3.3778493
KL Loss                      0.33778495
QF Loss                      546.624
VF Loss                      154.23955
Policy Loss                  -2922.1326
Q Predictions Mean           2917.6436
Q Predictions Std            469.49292
Q Predictions Max            3105.524
Q Predictions Min            24.56725
V Predictions Mean           2927.4626
V Predictions Std            469.05478
V Predictions Max            3114.1843
V Predictions Min            29.437805
Log Pis Mean                 -6.561876
Log Pis Std                  3.5870616
Log Pis Max                  15.283041
Log Pis Min                  -14.474295
Policy mu Mean               0.14994419
Policy mu Std                0.602337
Policy mu Max                2.7329712
Policy mu Min                -2.4164863
Policy log std Mean          -0.28274372
Policy log std Std           0.124802865
Policy log std Max           -0.06115292
Policy log std Min           -1.4154887
Z mean eval                  0.07250708
Z variance eval              0.12103178
total_rewards                [5553.12277626 5530.05227195 5435.74461124 5555.30000362 1419.08588826
 5492.11224048 1587.03245778 5477.95398857 5670.08103231 5544.28119678]
total_rewards_mean           4726.476646723275
total_rewards_std            1613.1999204185427
total_rewards_max            5670.081032309933
total_rewards_min            1419.0858882561913
Number of train steps total  1492000
Number of env steps total    1867000
Number of rollouts total     0
Train Time (s)               194.48920066608116
(Previous) Eval Time (s)     24.170150035992265
Sample Time (s)              17.79978558141738
Epoch Time (s)               236.4591362834908
Total Train Time (s)         84342.06736471411
Epoch                        372
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:56:01.796325 UTC | [2020_01_13_04_30_18] Iteration #372 | Epoch Duration: 235.1559352874756
2020-01-14 03:56:01.796452 UTC | [2020_01_13_04_30_18] Iteration #372 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07172024
Z variance train             0.121044815
KL Divergence                3.140185
KL Loss                      0.31401852
QF Loss                      702.6207
VF Loss                      225.82027
Policy Loss                  -2914.589
Q Predictions Mean           2913.0605
Q Predictions Std            433.24188
Q Predictions Max            3088.341
Q Predictions Min            22.3821
V Predictions Mean           2918.3198
V Predictions Std            433.28558
V Predictions Max            3099.646
V Predictions Min            23.582481
Log Pis Mean                 -6.319977
Log Pis Std                  4.090761
Log Pis Max                  19.590874
Log Pis Min                  -14.2018175
Policy mu Mean               0.1930448
Policy mu Std                0.6058254
Policy mu Max                2.731104
Policy mu Min                -2.8370497
Policy log std Mean          -0.29713738
Policy log std Std           0.12701567
Policy log std Max           -0.07342537
Policy log std Min           -1.041887
Z mean eval                  0.06270405
Z variance eval              0.11917652
total_rewards                [3864.64795168 5627.68586006 5524.04135723 2554.62464554 5539.17388838
 5567.87502017 3713.29398328 5494.73203839 5662.70067153 2874.99345703]
total_rewards_mean           4642.376887328932
total_rewards_std            1188.567984808673
total_rewards_max            5662.700671527029
total_rewards_min            2554.6246455399805
Number of train steps total  1496000
Number of env steps total    1872000
Number of rollouts total     0
Train Time (s)               196.25160785391927
(Previous) Eval Time (s)     22.866681658197194
Sample Time (s)              18.91905677272007
Epoch Time (s)               238.03734628483653
Total Train Time (s)         84579.57524141483
Epoch                        373
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 03:59:59.307016 UTC | [2020_01_13_04_30_18] Iteration #373 | Epoch Duration: 237.51047158241272
2020-01-14 03:59:59.307135 UTC | [2020_01_13_04_30_18] Iteration #373 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06280251
Z variance train             0.11921996
KL Divergence                3.1317635
KL Loss                      0.31317636
QF Loss                      590.2051
VF Loss                      237.53339
Policy Loss                  -2978.3167
Q Predictions Mean           2971.0417
Q Predictions Std            258.56076
Q Predictions Max            3094.5994
Q Predictions Min            20.595686
V Predictions Mean           2976.6177
V Predictions Std            257.3448
V Predictions Max            3107.2744
V Predictions Min            36.831703
Log Pis Mean                 -6.912752
Log Pis Std                  3.8487103
Log Pis Max                  14.993117
Log Pis Min                  -14.216093
Policy mu Mean               0.1574033
Policy mu Std                0.607191
Policy mu Max                2.9121165
Policy mu Min                -2.58291
Policy log std Mean          -0.29743817
Policy log std Std           0.13296735
Policy log std Max           -0.039071564
Policy log std Min           -1.2399001
Z mean eval                  0.048672028
Z variance eval              0.11512862
total_rewards                [5553.45391787 5597.64702141 5595.61835725 5461.52408341 5577.90240021
 5586.9546155  5625.49167666 5630.04187309 5573.04991872 5653.67204945]
total_rewards_mean           5585.535591357538
total_rewards_std            50.092397456287614
total_rewards_max            5653.672049454958
total_rewards_min            5461.52408341087
Number of train steps total  1500000
Number of env steps total    1877000
Number of rollouts total     0
Train Time (s)               198.44820251083001
(Previous) Eval Time (s)     22.33951075002551
Sample Time (s)              17.111269597895443
Epoch Time (s)               237.89898285875097
Total Train Time (s)         84819.21399851562
Epoch                        374
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:03:58.954918 UTC | [2020_01_13_04_30_18] Iteration #374 | Epoch Duration: 239.64767718315125
2020-01-14 04:03:58.955105 UTC | [2020_01_13_04_30_18] Iteration #374 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04843951
Z variance train             0.11510025
KL Divergence                3.313297
KL Loss                      0.3313297
QF Loss                      786.6263
VF Loss                      268.3483
Policy Loss                  -2978.1802
Q Predictions Mean           2975.9453
Q Predictions Std            154.93486
Q Predictions Max            3108.5916
Q Predictions Min            1667.1726
V Predictions Mean           2978.8555
V Predictions Std            165.43074
V Predictions Max            3109.5137
V Predictions Min            1626.0447
Log Pis Mean                 -5.9568233
Log Pis Std                  5.212081
Log Pis Max                  21.9306
Log Pis Min                  -15.5947485
Policy mu Mean               0.16665168
Policy mu Std                0.6563898
Policy mu Max                2.8097966
Policy mu Min                -3.0024724
Policy log std Mean          -0.30224788
Policy log std Std           0.13548109
Policy log std Max           -0.06502042
Policy log std Min           -1.2534529
Z mean eval                  0.04824958
Z variance eval              0.09763888
total_rewards                [5718.78266512 5512.36080993 5696.86167308 2526.10613287 4177.88851445
 5575.09905399 4509.71449295 5545.27065187 5550.88193882 5523.09664599]
total_rewards_mean           5033.606257907723
total_rewards_std            974.4250900454239
total_rewards_max            5718.782665124342
total_rewards_min            2526.106132873538
Number of train steps total  1504000
Number of env steps total    1882000
Number of rollouts total     0
Train Time (s)               192.95529916882515
(Previous) Eval Time (s)     24.087891487870365
Sample Time (s)              18.747506021987647
Epoch Time (s)               235.79069667868316
Total Train Time (s)         85055.31744073518
Epoch                        375
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:07:55.062326 UTC | [2020_01_13_04_30_18] Iteration #375 | Epoch Duration: 236.10706686973572
2020-01-14 04:07:55.062521 UTC | [2020_01_13_04_30_18] Iteration #375 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04787144
Z variance train             0.09766282
KL Divergence                3.659152
KL Loss                      0.3659152
QF Loss                      714.021
VF Loss                      216.87218
Policy Loss                  -2953.4355
Q Predictions Mean           2947.6538
Q Predictions Std            354.2745
Q Predictions Max            3101.8894
Q Predictions Min            25.571121
V Predictions Mean           2958.9512
V Predictions Std            354.68585
V Predictions Max            3101.4275
V Predictions Min            36.54764
Log Pis Mean                 -6.631872
Log Pis Std                  3.562967
Log Pis Max                  10.195766
Log Pis Min                  -14.009036
Policy mu Mean               0.15621495
Policy mu Std                0.62090135
Policy mu Max                2.5488317
Policy mu Min                -2.1809032
Policy log std Mean          -0.29584983
Policy log std Std           0.12132908
Policy log std Max           -0.029981807
Policy log std Min           -0.99640965
Z mean eval                  0.043343496
Z variance eval              0.10100852
total_rewards                [5683.88376975 5528.32888412 5494.11433405 5323.76412965 5666.87305862
 5667.26794511 5652.40207014 5651.70102715 3724.93146231 5666.37663354]
total_rewards_mean           5405.964331444605
total_rewards_std            570.7798781803118
total_rewards_max            5683.883769753689
total_rewards_min            3724.931462314921
Number of train steps total  1508000
Number of env steps total    1887000
Number of rollouts total     0
Train Time (s)               198.1007843920961
(Previous) Eval Time (s)     24.403993792831898
Sample Time (s)              19.036137596704066
Epoch Time (s)               241.54091578163207
Total Train Time (s)         85298.03099807259
Epoch                        376
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:11:57.778116 UTC | [2020_01_13_04_30_18] Iteration #376 | Epoch Duration: 242.71546006202698
2020-01-14 04:11:57.778262 UTC | [2020_01_13_04_30_18] Iteration #376 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04314104
Z variance train             0.10100839
KL Divergence                3.5181704
KL Loss                      0.35181704
QF Loss                      913.9497
VF Loss                      300.96957
Policy Loss                  -2994.9805
Q Predictions Mean           2987.1155
Q Predictions Std            157.43484
Q Predictions Max            3122.3438
Q Predictions Min            1423.9164
V Predictions Mean           2992.1138
V Predictions Std            154.79349
V Predictions Max            3130.5625
V Predictions Min            1516.828
Log Pis Mean                 -6.67426
Log Pis Std                  4.9498878
Log Pis Max                  42.458054
Log Pis Min                  -15.334456
Policy mu Mean               0.1692437
Policy mu Std                0.6049334
Policy mu Max                3.0924463
Policy mu Min                -3.3986893
Policy log std Mean          -0.29124403
Policy log std Std           0.12235323
Policy log std Max           -0.0076716244
Policy log std Min           -1.4180228
Z mean eval                  0.04083275
Z variance eval              0.1308935
total_rewards                [5629.51908199 5660.37709589 1951.36106712 5767.86492713 5663.59078942
 5611.8054851  5738.49698989 5558.07421255 5635.6817507  5622.52597265]
total_rewards_mean           5283.929737243743
total_rewards_std            1112.3470820216164
total_rewards_max            5767.864927128286
total_rewards_min            1951.3610671207286
Number of train steps total  1512000
Number of env steps total    1892000
Number of rollouts total     0
Train Time (s)               196.00116472877562
(Previous) Eval Time (s)     25.578234899789095
Sample Time (s)              18.355184781365097
Epoch Time (s)               239.9345844099298
Total Train Time (s)         85537.49707111716
Epoch                        377
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:15:57.252059 UTC | [2020_01_13_04_30_18] Iteration #377 | Epoch Duration: 239.47363543510437
2020-01-14 04:15:57.252339 UTC | [2020_01_13_04_30_18] Iteration #377 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04042809
Z variance train             0.13088247
KL Divergence                2.9528112
KL Loss                      0.29528114
QF Loss                      888.3381
VF Loss                      211.52563
Policy Loss                  -2949.3386
Q Predictions Mean           2944.1853
Q Predictions Std            358.50128
Q Predictions Max            3122.2717
Q Predictions Min            13.37599
V Predictions Mean           2957.291
V Predictions Std            358.07147
V Predictions Max            3130.8809
V Predictions Min            33.463627
Log Pis Mean                 -6.356328
Log Pis Std                  4.065842
Log Pis Max                  14.971048
Log Pis Min                  -16.13378
Policy mu Mean               0.19602607
Policy mu Std                0.6077991
Policy mu Max                2.5927522
Policy mu Min                -2.761773
Policy log std Mean          -0.29890206
Policy log std Std           0.12729363
Policy log std Max           0.026654549
Policy log std Min           -1.1371028
Z mean eval                  0.056627143
Z variance eval              0.14842558
total_rewards                [4075.55315293 4142.80485487 5438.20244174 5614.27914612 5495.02114814
 5556.88184182 3066.00425623 5485.57796542 5453.71682622 5444.1485585 ]
total_rewards_mean           4977.219019198703
total_rewards_std            841.9009281998578
total_rewards_max            5614.279146115148
total_rewards_min            3066.004256225102
Number of train steps total  1516000
Number of env steps total    1897000
Number of rollouts total     0
Train Time (s)               199.06047849915922
(Previous) Eval Time (s)     25.117013284005225
Sample Time (s)              18.842548122629523
Epoch Time (s)               243.02003990579396
Total Train Time (s)         85780.29033046495
Epoch                        378
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:20:00.049009 UTC | [2020_01_13_04_30_18] Iteration #378 | Epoch Duration: 242.79645609855652
2020-01-14 04:20:00.049187 UTC | [2020_01_13_04_30_18] Iteration #378 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.056865416
Z variance train             0.1483855
KL Divergence                2.6839578
KL Loss                      0.26839578
QF Loss                      654.7217
VF Loss                      183.24936
Policy Loss                  -2966.142
Q Predictions Mean           2960.8267
Q Predictions Std            321.92075
Q Predictions Max            3115.517
Q Predictions Min            91.17124
V Predictions Mean           2965.2312
V Predictions Std            321.4075
V Predictions Max            3114.1907
V Predictions Min            98.93517
Log Pis Mean                 -6.3747897
Log Pis Std                  4.367887
Log Pis Max                  17.268667
Log Pis Min                  -15.04823
Policy mu Mean               0.15390845
Policy mu Std                0.6231708
Policy mu Max                2.2656095
Policy mu Min                -2.4970407
Policy log std Mean          -0.29794744
Policy log std Std           0.12776329
Policy log std Max           -0.075294316
Policy log std Min           -1.0817528
Z mean eval                  0.07004429
Z variance eval              0.157337
total_rewards                [3318.64920751 5627.61275941 5701.63635882 5568.76129218 2254.84667279
  846.28304413 2213.82128207 5698.78309311 5537.58417838 5720.81513933]
total_rewards_mean           4248.879302772582
total_rewards_std            1795.6528184867138
total_rewards_max            5720.815139333651
total_rewards_min            846.2830441333678
Number of train steps total  1520000
Number of env steps total    1902000
Number of rollouts total     0
Train Time (s)               196.22653420921415
(Previous) Eval Time (s)     24.893165471963584
Sample Time (s)              16.712886319495738
Epoch Time (s)               237.83258600067347
Total Train Time (s)         86013.44377806317
Epoch                        379
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:23:53.204690 UTC | [2020_01_13_04_30_18] Iteration #379 | Epoch Duration: 233.15538120269775
2020-01-14 04:23:53.204825 UTC | [2020_01_13_04_30_18] Iteration #379 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07025547
Z variance train             0.15742305
KL Divergence                2.625511
KL Loss                      0.2625511
QF Loss                      606.21655
VF Loss                      139.83997
Policy Loss                  -2986.7373
Q Predictions Mean           2979.7402
Q Predictions Std            208.98685
Q Predictions Max            3115.0962
Q Predictions Min            155.0084
V Predictions Mean           2981.6362
V Predictions Std            211.84714
V Predictions Max            3116.6074
V Predictions Min            128.13084
Log Pis Mean                 -6.8583364
Log Pis Std                  4.20138
Log Pis Max                  14.104966
Log Pis Min                  -15.94403
Policy mu Mean               0.17469439
Policy mu Std                0.60026294
Policy mu Max                2.4798245
Policy mu Min                -2.180948
Policy log std Mean          -0.29928988
Policy log std Std           0.13532187
Policy log std Max           -0.04897446
Policy log std Min           -1.1617901
Z mean eval                  0.05889563
Z variance eval              0.16369501
total_rewards                [5660.54542051 5560.05299983 3501.74646805 5481.62180388 5567.21324866
 5619.63133484 5418.39524054 5622.80534613 5665.48961462 5553.93750114]
total_rewards_mean           5365.143897820075
total_rewards_std            625.4390682866073
total_rewards_max            5665.4896146221445
total_rewards_min            3501.746468046804
Number of train steps total  1524000
Number of env steps total    1907000
Number of rollouts total     0
Train Time (s)               193.42187657114118
(Previous) Eval Time (s)     20.215664552990347
Sample Time (s)              18.657473822124302
Epoch Time (s)               232.29501494625583
Total Train Time (s)         86249.12548370706
Epoch                        380
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:27:48.888716 UTC | [2020_01_13_04_30_18] Iteration #380 | Epoch Duration: 235.6837968826294
2020-01-14 04:27:48.888829 UTC | [2020_01_13_04_30_18] Iteration #380 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05885916
Z variance train             0.16376993
KL Divergence                2.6799831
KL Loss                      0.2679983
QF Loss                      549.15125
VF Loss                      136.48161
Policy Loss                  -2978.9512
Q Predictions Mean           2971.15
Q Predictions Std            339.8952
Q Predictions Max            3117.7092
Q Predictions Min            6.745904
V Predictions Mean           2978.2979
V Predictions Std            337.61682
V Predictions Max            3126.3203
V Predictions Min            23.565884
Log Pis Mean                 -6.38588
Log Pis Std                  4.029424
Log Pis Max                  24.530933
Log Pis Min                  -16.44387
Policy mu Mean               0.21738908
Policy mu Std                0.59949476
Policy mu Max                2.5424426
Policy mu Min                -2.69952
Policy log std Mean          -0.30043182
Policy log std Std           0.11691344
Policy log std Max           0.18995193
Policy log std Min           -0.99740154
Z mean eval                  0.073287785
Z variance eval              0.18767355
total_rewards                [5691.01265827 5795.91450097 5706.91083878 5703.82498431 1615.40605791
 5756.98810963 5174.4260873  1796.52121328 5676.79081451 5796.16917138]
total_rewards_mean           4871.39644363482
total_rewards_std            1592.2883308663854
total_rewards_max            5796.169171382257
total_rewards_min            1615.406057906357
Number of train steps total  1528000
Number of env steps total    1912000
Number of rollouts total     0
Train Time (s)               194.79262213688344
(Previous) Eval Time (s)     23.604189530946314
Sample Time (s)              18.82390617253259
Epoch Time (s)               237.22071784036234
Total Train Time (s)         86482.57790327864
Epoch                        381
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:31:42.345688 UTC | [2020_01_13_04_30_18] Iteration #381 | Epoch Duration: 233.45675945281982
2020-01-14 04:31:42.345848 UTC | [2020_01_13_04_30_18] Iteration #381 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07344102
Z variance train             0.18758118
KL Divergence                2.3948617
KL Loss                      0.23948617
QF Loss                      436.91898
VF Loss                      265.33618
Policy Loss                  -3004.77
Q Predictions Mean           2996.0315
Q Predictions Std            212.11693
Q Predictions Max            3116.4207
Q Predictions Min            632.7904
V Predictions Mean           3002.2444
V Predictions Std            205.45436
V Predictions Max            3115.3022
V Predictions Min            684.8652
Log Pis Mean                 -6.4004955
Log Pis Std                  3.904599
Log Pis Max                  17.162308
Log Pis Min                  -14.982567
Policy mu Mean               0.19673894
Policy mu Std                0.60279244
Policy mu Max                2.2760596
Policy mu Min                -2.5517929
Policy log std Mean          -0.28238153
Policy log std Std           0.121906236
Policy log std Max           0.07822314
Policy log std Min           -1.2458173
Z mean eval                  0.06657362
Z variance eval              0.17934373
total_rewards                [ 579.22285754 5473.15645548 5471.02769825 5564.5701739  5531.86213314
 5564.61509801 5572.67551181 4276.28229029 5529.05840396 5550.95847182]
total_rewards_mean           4911.342909419034
total_rewards_std            1492.1797306814349
total_rewards_max            5572.6755118067385
total_rewards_min            579.2228575369501
Number of train steps total  1532000
Number of env steps total    1917000
Number of rollouts total     0
Train Time (s)               196.20830793492496
(Previous) Eval Time (s)     19.839949425309896
Sample Time (s)              18.740334298927337
Epoch Time (s)               234.7885916591622
Total Train Time (s)         86721.30368987471
Epoch                        382
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:35:41.078070 UTC | [2020_01_13_04_30_18] Iteration #382 | Epoch Duration: 238.73209190368652
2020-01-14 04:35:41.078248 UTC | [2020_01_13_04_30_18] Iteration #382 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06613664
Z variance train             0.1793557
KL Divergence                2.5587785
KL Loss                      0.25587785
QF Loss                      896.2359
VF Loss                      201.3249
Policy Loss                  -2949.8184
Q Predictions Mean           2940.7866
Q Predictions Std            415.57822
Q Predictions Max            3127.905
Q Predictions Min            24.840345
V Predictions Mean           2950.895
V Predictions Std            421.18152
V Predictions Max            3138.2075
V Predictions Min            35.3363
Log Pis Mean                 -6.40216
Log Pis Std                  4.008705
Log Pis Max                  9.832777
Log Pis Min                  -14.171215
Policy mu Mean               0.14183222
Policy mu Std                0.6356703
Policy mu Max                2.9898694
Policy mu Min                -2.9958532
Policy log std Mean          -0.31094074
Policy log std Std           0.13183358
Policy log std Max           -0.02970481
Policy log std Min           -1.0508298
Z mean eval                  0.07140143
Z variance eval              0.17534974
total_rewards                [5552.75490405 5574.60143085 5600.86008531 1260.40913723 5533.41209843
 5516.81081479 3533.85697141 5494.47108425 5546.39438082 5516.9968566 ]
total_rewards_mean           4913.056776374524
total_rewards_std            1357.1005009792857
total_rewards_max            5600.860085313452
total_rewards_min            1260.4091372307096
Number of train steps total  1536000
Number of env steps total    1922000
Number of rollouts total     0
Train Time (s)               200.63831421965733
(Previous) Eval Time (s)     23.78317117318511
Sample Time (s)              18.824085063301027
Epoch Time (s)               243.24557045614347
Total Train Time (s)         86962.26035541575
Epoch                        383
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:39:42.040702 UTC | [2020_01_13_04_30_18] Iteration #383 | Epoch Duration: 240.96223950386047
2020-01-14 04:39:42.040968 UTC | [2020_01_13_04_30_18] Iteration #383 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07224196
Z variance train             0.17547376
KL Divergence                2.6140027
KL Loss                      0.26140028
QF Loss                      661.4733
VF Loss                      361.6829
Policy Loss                  -2981.4766
Q Predictions Mean           2975.393
Q Predictions Std            331.40326
Q Predictions Max            3126.9302
Q Predictions Min            23.578106
V Predictions Mean           2975.3223
V Predictions Std            329.94885
V Predictions Max            3126.6106
V Predictions Min            24.43153
Log Pis Mean                 -6.1807013
Log Pis Std                  4.8174586
Log Pis Max                  19.403463
Log Pis Min                  -13.667471
Policy mu Mean               0.19219087
Policy mu Std                0.64187443
Policy mu Max                2.863301
Policy mu Min                -2.6063364
Policy log std Mean          -0.3052348
Policy log std Std           0.13459957
Policy log std Max           -0.06589926
Policy log std Min           -1.1186893
Z mean eval                  0.07182841
Z variance eval              0.16203226
total_rewards                [5700.64938605 2125.04287457 5678.79183983 5724.97203837 5622.41042219
 5753.65638297 5681.41707183 4243.08387848  702.71967698 5781.66639883]
total_rewards_mean           4701.440997009946
total_rewards_std            1729.7838166234858
total_rewards_max            5781.6663988344335
total_rewards_min            702.7196769791834
Number of train steps total  1540000
Number of env steps total    1927000
Number of rollouts total     0
Train Time (s)               197.77701631421223
(Previous) Eval Time (s)     21.499542934820056
Sample Time (s)              18.490499255713075
Epoch Time (s)               237.76705850474536
Total Train Time (s)         87198.68013530178
Epoch                        384
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:43:38.464072 UTC | [2020_01_13_04_30_18] Iteration #384 | Epoch Duration: 236.42294335365295
2020-01-14 04:43:38.464255 UTC | [2020_01_13_04_30_18] Iteration #384 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07216433
Z variance train             0.16225432
KL Divergence                2.5476403
KL Loss                      0.25476405
QF Loss                      549.9417
VF Loss                      159.16637
Policy Loss                  -3001.7178
Q Predictions Mean           2992.9397
Q Predictions Std            265.35312
Q Predictions Max            3132.5415
Q Predictions Min            23.843136
V Predictions Mean           3001.72
V Predictions Std            269.6568
V Predictions Max            3135.8855
V Predictions Min            20.780916
Log Pis Mean                 -6.235303
Log Pis Std                  4.2964425
Log Pis Max                  17.68254
Log Pis Min                  -16.780804
Policy mu Mean               0.20622613
Policy mu Std                0.6039545
Policy mu Max                3.0394292
Policy mu Min                -2.8049214
Policy log std Mean          -0.3108762
Policy log std Std           0.13098943
Policy log std Max           -0.03908509
Policy log std Min           -1.4005929
Z mean eval                  0.07375388
Z variance eval              0.1590469
total_rewards                [5442.45077411 5537.99508049 5627.28212217 5539.66979893 5634.7142515
 5532.05631621 5514.63653202 5513.21748911 5597.6855232  5452.87689154]
total_rewards_mean           5539.258477928733
total_rewards_std            62.0041983010879
total_rewards_max            5634.714251502922
total_rewards_min            5442.450774111851
Number of train steps total  1544000
Number of env steps total    1932000
Number of rollouts total     0
Train Time (s)               193.36900462582707
(Previous) Eval Time (s)     20.15510020731017
Sample Time (s)              18.93453157832846
Epoch Time (s)               232.4586364114657
Total Train Time (s)         87437.79179322533
Epoch                        385
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:47:37.583923 UTC | [2020_01_13_04_30_18] Iteration #385 | Epoch Duration: 239.1195011138916
2020-01-14 04:47:37.584129 UTC | [2020_01_13_04_30_18] Iteration #385 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0741855
Z variance train             0.1590268
KL Divergence                2.6169155
KL Loss                      0.26169154
QF Loss                      589.6273
VF Loss                      332.01996
Policy Loss                  -3001.5334
Q Predictions Mean           2992.7036
Q Predictions Std            314.73038
Q Predictions Max            3132.071
Q Predictions Min            55.091007
V Predictions Mean           2996.8926
V Predictions Std            310.50803
V Predictions Max            3124.9006
V Predictions Min            57.547188
Log Pis Mean                 -6.6109176
Log Pis Std                  4.0274286
Log Pis Max                  20.072521
Log Pis Min                  -15.713298
Policy mu Mean               0.18415457
Policy mu Std                0.6033815
Policy mu Max                3.4439151
Policy mu Min                -2.7307394
Policy log std Mean          -0.29903245
Policy log std Std           0.1244468
Policy log std Max           0.021784186
Policy log std Min           -1.3685676
Z mean eval                  0.07447801
Z variance eval              0.13197438
total_rewards                [5486.21322771 5568.86021735 5513.21879807 5556.93694317 5451.24160768
 4085.99532327 5380.39158489 5537.38572524 5512.15473329 5527.91239421]
total_rewards_mean           5362.031055487622
total_rewards_std            428.53370597710295
total_rewards_max            5568.860217346636
total_rewards_min            4085.9953232715156
Number of train steps total  1548000
Number of env steps total    1937000
Number of rollouts total     0
Train Time (s)               199.64803646178916
(Previous) Eval Time (s)     26.810409360099584
Sample Time (s)              16.75863872980699
Epoch Time (s)               243.21708455169573
Total Train Time (s)         87678.20895558968
Epoch                        386
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:51:38.009611 UTC | [2020_01_13_04_30_18] Iteration #386 | Epoch Duration: 240.42532753944397
2020-01-14 04:51:38.009914 UTC | [2020_01_13_04_30_18] Iteration #386 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07467949
Z variance train             0.13198459
KL Divergence                3.0136218
KL Loss                      0.3013622
QF Loss                      1399.4396
VF Loss                      209.73947
Policy Loss                  -3009.417
Q Predictions Mean           3003.7798
Q Predictions Std            230.93849
Q Predictions Max            3119.6873
Q Predictions Min            27.750517
V Predictions Mean           3006.9243
V Predictions Std            226.45166
V Predictions Max            3129.0217
V Predictions Min            35.082546
Log Pis Mean                 -6.392441
Log Pis Std                  4.2710896
Log Pis Max                  11.616758
Log Pis Min                  -15.190321
Policy mu Mean               0.14635693
Policy mu Std                0.61435986
Policy mu Max                2.949319
Policy mu Min                -2.565598
Policy log std Mean          -0.2977736
Policy log std Std           0.120294675
Policy log std Max           -0.068284474
Policy log std Min           -0.8841969
Z mean eval                  0.07533512
Z variance eval              0.13675219
total_rewards                [5711.24477915 5679.6129595  5605.849092   5531.18540143 5105.73675024
 5595.01529468 5661.49139129 5697.11776188 1437.19915522 5594.95012322]
total_rewards_mean           5161.940270860896
total_rewards_std            1252.6368370323576
total_rewards_max            5711.244779148166
total_rewards_min            1437.1991552208935
Number of train steps total  1552000
Number of env steps total    1942000
Number of rollouts total     0
Train Time (s)               200.18245274107903
(Previous) Eval Time (s)     24.01836823299527
Sample Time (s)              18.910580058582127
Epoch Time (s)               243.11140103265643
Total Train Time (s)         87921.92257319624
Epoch                        387
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:55:41.725264 UTC | [2020_01_13_04_30_18] Iteration #387 | Epoch Duration: 243.7151439189911
2020-01-14 04:55:41.725383 UTC | [2020_01_13_04_30_18] Iteration #387 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.075040355
Z variance train             0.13674507
KL Divergence                2.8971086
KL Loss                      0.28971085
QF Loss                      865.56616
VF Loss                      191.16164
Policy Loss                  -2980.1536
Q Predictions Mean           2976.3486
Q Predictions Std            354.95917
Q Predictions Max            3150.3218
Q Predictions Min            29.906214
V Predictions Mean           2984.5137
V Predictions Std            352.52072
V Predictions Max            3153.7874
V Predictions Min            39.965797
Log Pis Mean                 -6.717885
Log Pis Std                  4.080696
Log Pis Max                  20.094025
Log Pis Min                  -13.529131
Policy mu Mean               0.21665886
Policy mu Std                0.59739035
Policy mu Max                2.2869885
Policy mu Min                -2.4835968
Policy log std Mean          -0.29551187
Policy log std Std           0.12791438
Policy log std Max           0.34471697
Policy log std Min           -1.067459
Z mean eval                  0.07554312
Z variance eval              0.14314766
total_rewards                [5467.31288112 5583.40303198 5568.48257334 2651.31308094 5527.97882414
  671.43404777 5692.39767904 5465.79476936 5638.43490374 5552.92343907]
total_rewards_mean           4781.947523050893
total_rewards_std            1623.1981360858204
total_rewards_max            5692.397679041595
total_rewards_min            671.4340477725243
Number of train steps total  1556000
Number of env steps total    1947000
Number of rollouts total     0
Train Time (s)               196.23209111811593
(Previous) Eval Time (s)     24.621855730190873
Sample Time (s)              18.736545391846448
Epoch Time (s)               239.59049224015325
Total Train Time (s)         88159.96351177199
Epoch                        388
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 04:59:39.768368 UTC | [2020_01_13_04_30_18] Iteration #388 | Epoch Duration: 238.0428969860077
2020-01-14 04:59:39.768487 UTC | [2020_01_13_04_30_18] Iteration #388 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07658931
Z variance train             0.14309302
KL Divergence                2.7750547
KL Loss                      0.2775055
QF Loss                      537.1584
VF Loss                      139.53094
Policy Loss                  -3028.4285
Q Predictions Mean           3022.6777
Q Predictions Std            213.15675
Q Predictions Max            3149.472
Q Predictions Min            31.173906
V Predictions Mean           3026.7278
V Predictions Std            211.13899
V Predictions Max            3150.4565
V Predictions Min            33.553024
Log Pis Mean                 -6.709496
Log Pis Std                  3.9385571
Log Pis Max                  17.598757
Log Pis Min                  -15.193321
Policy mu Mean               0.19214372
Policy mu Std                0.5826421
Policy mu Max                2.5241451
Policy mu Min                -2.5923362
Policy log std Mean          -0.29370925
Policy log std Std           0.121418886
Policy log std Max           -0.046422802
Policy log std Min           -1.4154913
Z mean eval                  0.060423404
Z variance eval              0.13995108
total_rewards                [5402.38046491 5455.49387767 5473.44680482 5479.03269944 5587.10242109
 5536.47870034 5469.42236589 5538.38349114 5454.69953462 5409.57902059]
total_rewards_mean           5480.601938051605
total_rewards_std            55.17800056946406
total_rewards_max            5587.102421086267
total_rewards_min            5402.380464908593
Number of train steps total  1560000
Number of env steps total    1952000
Number of rollouts total     0
Train Time (s)               191.95372798200697
(Previous) Eval Time (s)     23.073962547816336
Sample Time (s)              18.767227546311915
Epoch Time (s)               233.79491807613522
Total Train Time (s)         88397.203866072
Epoch                        389
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:03:37.014537 UTC | [2020_01_13_04_30_18] Iteration #389 | Epoch Duration: 237.2459592819214
2020-01-14 05:03:37.014669 UTC | [2020_01_13_04_30_18] Iteration #389 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.061196722
Z variance train             0.13999912
KL Divergence                2.782123
KL Loss                      0.2782123
QF Loss                      760.51184
VF Loss                      212.05937
Policy Loss                  -3008.2341
Q Predictions Mean           3003.6963
Q Predictions Std            234.5598
Q Predictions Max            3140.0547
Q Predictions Min            32.658962
V Predictions Mean           3008.351
V Predictions Std            232.75925
V Predictions Max            3142.666
V Predictions Min            33.62713
Log Pis Mean                 -6.3133907
Log Pis Std                  5.1658516
Log Pis Max                  32.201687
Log Pis Min                  -16.463114
Policy mu Mean               0.19150902
Policy mu Std                0.61958134
Policy mu Max                2.7242444
Policy mu Min                -2.75216
Policy log std Mean          -0.30491504
Policy log std Std           0.13434376
Policy log std Max           -0.061757445
Policy log std Min           -1.2157722
Z mean eval                  0.059016652
Z variance eval              0.14032301
total_rewards                [1465.17340783 5447.8319589  3503.66543042 5600.3787404  2252.35206134
 5590.03269807 5555.96255294 2179.98947181 5610.9149073  2142.17269643]
total_rewards_mean           3934.8473925442077
total_rewards_std            1692.606833981508
total_rewards_max            5610.91490729517
total_rewards_min            1465.1734078266616
Number of train steps total  1564000
Number of env steps total    1957000
Number of rollouts total     0
Train Time (s)               194.659035962075
(Previous) Eval Time (s)     26.524733977857977
Sample Time (s)              16.770786141976714
Epoch Time (s)               237.9545560819097
Total Train Time (s)         88627.62988961348
Epoch                        390
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:07:27.444487 UTC | [2020_01_13_04_30_18] Iteration #390 | Epoch Duration: 230.42972946166992
2020-01-14 05:07:27.444605 UTC | [2020_01_13_04_30_18] Iteration #390 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0589453
Z variance train             0.14033513
KL Divergence                2.8417273
KL Loss                      0.28417274
QF Loss                      562.31415
VF Loss                      137.29927
Policy Loss                  -3006.5107
Q Predictions Mean           3000.111
Q Predictions Std            263.995
Q Predictions Max            3125.5032
Q Predictions Min            20.110867
V Predictions Mean           3011.068
V Predictions Std            264.7299
V Predictions Max            3135.445
V Predictions Min            27.611485
Log Pis Mean                 -6.3530273
Log Pis Std                  4.2254295
Log Pis Max                  21.847692
Log Pis Min                  -13.421177
Policy mu Mean               0.18971412
Policy mu Std                0.62097853
Policy mu Max                2.325111
Policy mu Min                -3.6617138
Policy log std Mean          -0.29355925
Policy log std Std           0.12613809
Policy log std Max           -0.01988341
Policy log std Min           -1.1102225
Z mean eval                  0.05840563
Z variance eval              0.1502882
total_rewards                [5611.8413747  5591.31791707 5407.73340979 5581.00745748 5547.76142737
 5550.16285135 5637.68781344 5651.09706064 5485.00816207 5195.79038319]
total_rewards_mean           5525.940785709039
total_rewards_std            129.82584902254942
total_rewards_max            5651.097060639091
total_rewards_min            5195.790383191064
Number of train steps total  1568000
Number of env steps total    1962000
Number of rollouts total     0
Train Time (s)               195.96297844685614
(Previous) Eval Time (s)     18.99965190840885
Sample Time (s)              18.61312532192096
Epoch Time (s)               233.57575567718595
Total Train Time (s)         88865.60186895402
Epoch                        391
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:11:25.421897 UTC | [2020_01_13_04_30_18] Iteration #391 | Epoch Duration: 237.97718286514282
2020-01-14 05:11:25.422089 UTC | [2020_01_13_04_30_18] Iteration #391 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.058323514
Z variance train             0.15026356
KL Divergence                2.7393367
KL Loss                      0.27393368
QF Loss                      540.8264
VF Loss                      345.42743
Policy Loss                  -2988.439
Q Predictions Mean           2984.8374
Q Predictions Std            358.5903
Q Predictions Max            3147.9133
Q Predictions Min            22.847406
V Predictions Mean           2988.4587
V Predictions Std            353.90256
V Predictions Max            3159.5483
V Predictions Min            33.77068
Log Pis Mean                 -6.229005
Log Pis Std                  4.586906
Log Pis Max                  19.28975
Log Pis Min                  -15.562247
Policy mu Mean               0.20841552
Policy mu Std                0.60978806
Policy mu Max                2.8983269
Policy mu Min                -2.7071624
Policy log std Mean          -0.30294132
Policy log std Std           0.13281606
Policy log std Max           -0.017633073
Policy log std Min           -1.1207104
Z mean eval                  0.06952885
Z variance eval              0.14993629
total_rewards                [ 634.39398616 5598.27880904 5621.67935366 3124.62090054 1052.27408722
 5649.27405865 5677.74420825 5636.18901631 5679.55502962 3838.67622063]
total_rewards_mean           4251.268567006666
total_rewards_std            1907.7378258073197
total_rewards_max            5679.555029615706
total_rewards_min            634.393986158783
Number of train steps total  1572000
Number of env steps total    1967000
Number of rollouts total     0
Train Time (s)               197.66519946418703
(Previous) Eval Time (s)     23.40076224785298
Sample Time (s)              18.956969425547868
Epoch Time (s)               240.02293113758788
Total Train Time (s)         89100.51566104265
Epoch                        392
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:15:20.340823 UTC | [2020_01_13_04_30_18] Iteration #392 | Epoch Duration: 234.91854071617126
2020-01-14 05:15:20.341195 UTC | [2020_01_13_04_30_18] Iteration #392 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.069338754
Z variance train             0.1498217
KL Divergence                2.7445142
KL Loss                      0.27445143
QF Loss                      528.54877
VF Loss                      153.35039
Policy Loss                  -3014.5996
Q Predictions Mean           3008.0564
Q Predictions Std            280.15796
Q Predictions Max            3142.2197
Q Predictions Min            29.50558
V Predictions Mean           3015.532
V Predictions Std            281.18527
V Predictions Max            3144.3738
V Predictions Min            33.35334
Log Pis Mean                 -6.409733
Log Pis Std                  4.561319
Log Pis Max                  24.007923
Log Pis Min                  -14.464339
Policy mu Mean               0.20093116
Policy mu Std                0.603389
Policy mu Max                2.8274798
Policy mu Min                -3.1672378
Policy log std Mean          -0.27765408
Policy log std Std           0.123187564
Policy log std Max           0.16588211
Policy log std Min           -1.1562595
Z mean eval                  0.05792772
Z variance eval              0.1613379
total_rewards                [3145.60672691 5618.50466411 4915.2633955  5441.06125641 5517.40093593
 5399.5795802  5662.37068885 5624.3937219  5691.42769276 5663.60634336]
total_rewards_mean           5267.921500592
total_rewards_std            740.245506715799
total_rewards_max            5691.427692761452
total_rewards_min            3145.606726907984
Number of train steps total  1576000
Number of env steps total    1972000
Number of rollouts total     0
Train Time (s)               193.73682157322764
(Previous) Eval Time (s)     18.296054270118475
Sample Time (s)              18.896170268766582
Epoch Time (s)               230.9290461121127
Total Train Time (s)         89338.15315682162
Epoch                        393
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:19:17.979879 UTC | [2020_01_13_04_30_18] Iteration #393 | Epoch Duration: 237.63844633102417
2020-01-14 05:19:17.980013 UTC | [2020_01_13_04_30_18] Iteration #393 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05801794
Z variance train             0.16135728
KL Divergence                2.6193771
KL Loss                      0.2619377
QF Loss                      706.5271
VF Loss                      308.38843
Policy Loss                  -2975.0312
Q Predictions Mean           2967.2278
Q Predictions Std            390.5811
Q Predictions Max            3144.9753
Q Predictions Min            25.25027
V Predictions Mean           2980.8254
V Predictions Std            389.4551
V Predictions Max            3157.2568
V Predictions Min            30.940186
Log Pis Mean                 -6.599144
Log Pis Std                  4.132904
Log Pis Max                  9.262335
Log Pis Min                  -14.402119
Policy mu Mean               0.18308872
Policy mu Std                0.6332856
Policy mu Max                2.8576984
Policy mu Min                -2.6924841
Policy log std Mean          -0.30377465
Policy log std Std           0.12896572
Policy log std Max           0.19384465
Policy log std Min           -1.0502709
Z mean eval                  0.0740072
Z variance eval              0.17988138
total_rewards                [5628.64953173 5604.67252916 5609.15453912 5446.49363909 5619.71228736
 2951.01529847 5552.89524732 5621.72899903 5493.9833953  5420.82067194]
total_rewards_mean           5294.912613851514
total_rewards_std            784.6815779125693
total_rewards_max            5628.6495317262315
total_rewards_min            2951.015298472577
Number of train steps total  1580000
Number of env steps total    1977000
Number of rollouts total     0
Train Time (s)               196.455298228655
(Previous) Eval Time (s)     25.00519570708275
Sample Time (s)              18.493366157170385
Epoch Time (s)               239.95386009290814
Total Train Time (s)         89578.58875560993
Epoch                        394
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:23:18.419137 UTC | [2020_01_13_04_30_18] Iteration #394 | Epoch Duration: 240.43900990486145
2020-01-14 05:23:18.419318 UTC | [2020_01_13_04_30_18] Iteration #394 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07433693
Z variance train             0.1799006
KL Divergence                2.32799
KL Loss                      0.23279901
QF Loss                      692.1089
VF Loss                      330.7046
Policy Loss                  -3003.4258
Q Predictions Mean           2993.1138
Q Predictions Std            327.35492
Q Predictions Max            3123.0369
Q Predictions Min            25.310682
V Predictions Mean           2996.6528
V Predictions Std            329.4128
V Predictions Max            3127.9631
V Predictions Min            30.324757
Log Pis Mean                 -6.294709
Log Pis Std                  3.7012098
Log Pis Max                  12.717847
Log Pis Min                  -15.150896
Policy mu Mean               0.17697233
Policy mu Std                0.6163506
Policy mu Max                2.7672348
Policy mu Min                -2.0490465
Policy log std Mean          -0.30383867
Policy log std Std           0.13177553
Policy log std Max           -0.0633093
Policy log std Min           -1.1046053
Z mean eval                  0.063541606
Z variance eval              0.17998151
total_rewards                [5567.17085483 5561.29834296 5476.84858392 5624.08646529 5582.65359564
 5618.10729214 3528.83919654 5676.59046061 5582.54685378 5652.59485154]
total_rewards_mean           5387.073649725201
total_rewards_std            621.6283832538343
total_rewards_max            5676.590460614592
total_rewards_min            3528.8391965358437
Number of train steps total  1584000
Number of env steps total    1982000
Number of rollouts total     0
Train Time (s)               194.9060311159119
(Previous) Eval Time (s)     25.49007766507566
Sample Time (s)              18.82508249860257
Epoch Time (s)               239.22119127959013
Total Train Time (s)         89815.48083390715
Epoch                        395
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:27:15.315168 UTC | [2020_01_13_04_30_18] Iteration #395 | Epoch Duration: 236.89571070671082
2020-01-14 05:27:15.315357 UTC | [2020_01_13_04_30_18] Iteration #395 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.063436136
Z variance train             0.17998633
KL Divergence                2.42486
KL Loss                      0.242486
QF Loss                      755.8972
VF Loss                      160.37817
Policy Loss                  -3009.7607
Q Predictions Mean           3003.8428
Q Predictions Std            256.56827
Q Predictions Max            3133.0408
Q Predictions Min            23.930447
V Predictions Mean           3010.42
V Predictions Std            257.60852
V Predictions Max            3141.1038
V Predictions Min            35.640167
Log Pis Mean                 -6.2286177
Log Pis Std                  4.270054
Log Pis Max                  13.843363
Log Pis Min                  -16.17556
Policy mu Mean               0.16967326
Policy mu Std                0.63073933
Policy mu Max                2.3623397
Policy mu Min                -3.2916296
Policy log std Mean          -0.29936147
Policy log std Std           0.123644024
Policy log std Max           0.07013277
Policy log std Min           -1.1214429
Z mean eval                  0.080735214
Z variance eval              0.18419048
total_rewards                [5546.93897737 5517.6645696  5589.13382917 5463.50654961 5543.72521835
 5630.16140705 5578.66232355 4405.19371597 5534.8425565  5563.8743877 ]
total_rewards_mean           5437.370353485437
total_rewards_std            346.6271164036516
total_rewards_max            5630.161407046346
total_rewards_min            4405.193715969741
Number of train steps total  1588000
Number of env steps total    1987000
Number of rollouts total     0
Train Time (s)               196.50790179194883
(Previous) Eval Time (s)     23.164332470856607
Sample Time (s)              18.88615669636056
Epoch Time (s)               238.558390959166
Total Train Time (s)         90054.5142159788
Epoch                        396
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:31:14.356199 UTC | [2020_01_13_04_30_18] Iteration #396 | Epoch Duration: 239.040629863739
2020-01-14 05:31:14.356471 UTC | [2020_01_13_04_30_18] Iteration #396 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08089782
Z variance train             0.18403447
KL Divergence                2.5069551
KL Loss                      0.25069553
QF Loss                      571.5471
VF Loss                      154.88298
Policy Loss                  -3010.405
Q Predictions Mean           3001.873
Q Predictions Std            319.10648
Q Predictions Max            3138.6365
Q Predictions Min            23.13985
V Predictions Mean           3004.1387
V Predictions Std            318.91473
V Predictions Max            3139.838
V Predictions Min            33.64508
Log Pis Mean                 -6.1597266
Log Pis Std                  3.8658426
Log Pis Max                  10.520845
Log Pis Min                  -13.9762745
Policy mu Mean               0.20629905
Policy mu Std                0.60890216
Policy mu Max                3.3707044
Policy mu Min                -2.3447
Policy log std Mean          -0.31105384
Policy log std Std           0.13155358
Policy log std Max           -0.049704112
Policy log std Min           -1.1266044
Z mean eval                  0.06805342
Z variance eval              0.1846389
total_rewards                [5649.84924328 5662.75903733 4207.6305439  5632.54384733 5597.56105328
 3686.58280417 5656.30344999  915.29475254 5692.02053584 5533.20932955]
total_rewards_mean           4823.375459720189
total_rewards_std            1467.5984499493766
total_rewards_max            5692.020535841918
total_rewards_min            915.2947525409768
Number of train steps total  1592000
Number of env steps total    1992000
Number of rollouts total     0
Train Time (s)               197.0011511151679
(Previous) Eval Time (s)     23.646283340640366
Sample Time (s)              19.340623659081757
Epoch Time (s)               239.98805811489
Total Train Time (s)         90293.9013687633
Epoch                        397
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:35:13.746135 UTC | [2020_01_13_04_30_18] Iteration #397 | Epoch Duration: 239.38951706886292
2020-01-14 05:35:13.746267 UTC | [2020_01_13_04_30_18] Iteration #397 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06798834
Z variance train             0.18460819
KL Divergence                2.4494882
KL Loss                      0.24494882
QF Loss                      705.5262
VF Loss                      229.64233
Policy Loss                  -2975.5947
Q Predictions Mean           2973.3257
Q Predictions Std            385.0598
Q Predictions Max            3147.7754
Q Predictions Min            27.763834
V Predictions Mean           2980.7686
V Predictions Std            375.40613
V Predictions Max            3145.4453
V Predictions Min            37.69638
Log Pis Mean                 -6.440357
Log Pis Std                  5.332983
Log Pis Max                  25.312925
Log Pis Min                  -13.876368
Policy mu Mean               0.20316166
Policy mu Std                0.60607594
Policy mu Max                3.7003322
Policy mu Min                -2.4309363
Policy log std Mean          -0.2982122
Policy log std Std           0.13453422
Policy log std Max           0.028424412
Policy log std Min           -1.360457
Z mean eval                  0.08129137
Z variance eval              0.19304316
total_rewards                [5631.51907211 5580.74640599 5579.86863495 4910.25972775 5622.1135512
 5638.35001327 5625.19376536 5546.34005063 3126.71229909 5576.77637934]
total_rewards_mean           5283.78798996712
total_rewards_std            748.3833210059613
total_rewards_max            5638.350013268504
total_rewards_min            3126.7122990889816
Number of train steps total  1596000
Number of env steps total    1997000
Number of rollouts total     0
Train Time (s)               197.38912485120818
(Previous) Eval Time (s)     23.047451191116124
Sample Time (s)              18.84243229078129
Epoch Time (s)               239.2790083331056
Total Train Time (s)         90535.26328535285
Epoch                        398
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:39:15.113294 UTC | [2020_01_13_04_30_18] Iteration #398 | Epoch Duration: 241.36673736572266
2020-01-14 05:39:15.113783 UTC | [2020_01_13_04_30_18] Iteration #398 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0812008
Z variance train             0.19311433
KL Divergence                2.4127817
KL Loss                      0.24127817
QF Loss                      395.95337
VF Loss                      126.64151
Policy Loss                  -3020.086
Q Predictions Mean           3012.5757
Q Predictions Std            371.68643
Q Predictions Max            3158.9976
Q Predictions Min            26.190989
V Predictions Mean           3019.6487
V Predictions Std            369.61353
V Predictions Max            3161.1628
V Predictions Min            21.889742
Log Pis Mean                 -6.463992
Log Pis Std                  5.170869
Log Pis Max                  49.621468
Log Pis Min                  -15.306887
Policy mu Mean               0.2258981
Policy mu Std                0.6061203
Policy mu Max                3.6009157
Policy mu Min                -5.7689
Policy log std Mean          -0.2973214
Policy log std Std           0.12380878
Policy log std Max           0.5933105
Policy log std Min           -1.1130017
Z mean eval                  0.0852584
Z variance eval              0.19380231
total_rewards                [3567.33481685 5393.66608128 2782.20246232 5581.65003315 5574.79723965
 5560.47164472 5458.86809071 5450.98242406 5556.63637613 5489.44297592]
total_rewards_mean           5041.605214478502
total_rewards_std            951.5775919847933
total_rewards_max            5581.650033148461
total_rewards_min            2782.202462322349
Number of train steps total  1600000
Number of env steps total    2002000
Number of rollouts total     0
Train Time (s)               200.4207518179901
(Previous) Eval Time (s)     25.13487382605672
Sample Time (s)              18.22342464281246
Epoch Time (s)               243.77905028685927
Total Train Time (s)         90775.81599642802
Epoch                        399
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:43:15.669582 UTC | [2020_01_13_04_30_18] Iteration #399 | Epoch Duration: 240.55552196502686
2020-01-14 05:43:15.669775 UTC | [2020_01_13_04_30_18] Iteration #399 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08537747
Z variance train             0.19397916
KL Divergence                2.4072843
KL Loss                      0.24072842
QF Loss                      717.82294
VF Loss                      219.03798
Policy Loss                  -3024.0059
Q Predictions Mean           3023.6577
Q Predictions Std            296.66953
Q Predictions Max            3156.8477
Q Predictions Min            25.530777
V Predictions Mean           3022.8213
V Predictions Std            300.02225
V Predictions Max            3156.1155
V Predictions Min            28.528444
Log Pis Mean                 -6.692697
Log Pis Std                  4.188643
Log Pis Max                  25.997982
Log Pis Min                  -13.519108
Policy mu Mean               0.16212802
Policy mu Std                0.6082083
Policy mu Max                2.5287766
Policy mu Min                -2.797571
Policy log std Mean          -0.28270373
Policy log std Std           0.110285796
Policy log std Max           0.2843315
Policy log std Min           -1.027095
Z mean eval                  0.09202489
Z variance eval              0.1865362
total_rewards                [5742.38145674 5660.07275187 1029.02448143 5760.72469656 1524.50627718
 5675.09156126 5617.69734027 2022.99241498 5722.71790498 5741.48603684]
total_rewards_mean           4449.669492212517
total_rewards_std            1927.604480487151
total_rewards_max            5760.72469655731
total_rewards_min            1029.024481434118
Number of train steps total  1604000
Number of env steps total    2007000
Number of rollouts total     0
Train Time (s)               198.049029618036
(Previous) Eval Time (s)     21.911078806966543
Sample Time (s)              16.872807785868645
Epoch Time (s)               236.8329162108712
Total Train Time (s)         91012.02612897381
Epoch                        400
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:47:11.883040 UTC | [2020_01_13_04_30_18] Iteration #400 | Epoch Duration: 236.21313071250916
2020-01-14 05:47:11.883204 UTC | [2020_01_13_04_30_18] Iteration #400 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09169781
Z variance train             0.18662807
KL Divergence                2.4126968
KL Loss                      0.2412697
QF Loss                      610.8404
VF Loss                      218.15756
Policy Loss                  -3004.271
Q Predictions Mean           3003.1362
Q Predictions Std            320.13907
Q Predictions Max            3147.0396
Q Predictions Min            20.370228
V Predictions Mean           3012.41
V Predictions Std            322.14508
V Predictions Max            3155.5632
V Predictions Min            36.93328
Log Pis Mean                 -6.4752746
Log Pis Std                  4.3591075
Log Pis Max                  25.94505
Log Pis Min                  -17.850756
Policy mu Mean               0.1837548
Policy mu Std                0.6098895
Policy mu Max                3.2390964
Policy mu Min                -2.5869148
Policy log std Mean          -0.295759
Policy log std Std           0.13256091
Policy log std Max           0.0137519315
Policy log std Min           -1.4778553
Z mean eval                  0.07766269
Z variance eval              0.1746379
total_rewards                [5700.34278257 1064.75021345 3791.47212693 5776.64758067 5613.73818696
 1468.83311049 5688.52407908 5576.42903441 5129.83933222 1825.24615653]
total_rewards_mean           4163.582260331259
total_rewards_std            1865.2752035450478
total_rewards_max            5776.647580671998
total_rewards_min            1064.750213448206
Number of train steps total  1608000
Number of env steps total    2012000
Number of rollouts total     0
Train Time (s)               197.34717051731423
(Previous) Eval Time (s)     21.291039824020118
Sample Time (s)              18.85655768448487
Epoch Time (s)               237.4947680258192
Total Train Time (s)         91246.0881199697
Epoch                        401
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:51:05.953638 UTC | [2020_01_13_04_30_18] Iteration #401 | Epoch Duration: 234.0702781677246
2020-01-14 05:51:05.953899 UTC | [2020_01_13_04_30_18] Iteration #401 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07737497
Z variance train             0.17485422
KL Divergence                2.546753
KL Loss                      0.2546753
QF Loss                      518.0479
VF Loss                      130.99106
Policy Loss                  -3021.9558
Q Predictions Mean           3015.1191
Q Predictions Std            304.31232
Q Predictions Max            3156.9927
Q Predictions Min            25.881641
V Predictions Mean           3020.0444
V Predictions Std            305.1496
V Predictions Max            3166.4058
V Predictions Min            28.18296
Log Pis Mean                 -6.5069585
Log Pis Std                  3.9407477
Log Pis Max                  9.588833
Log Pis Min                  -14.730265
Policy mu Mean               0.18231775
Policy mu Std                0.58237875
Policy mu Max                2.3051076
Policy mu Min                -2.460928
Policy log std Mean          -0.29708183
Policy log std Std           0.12476754
Policy log std Max           -0.05630888
Policy log std Min           -1.1553965
Z mean eval                  0.07468939
Z variance eval              0.1783841
total_rewards                [5588.22643344 5675.57179677 5678.71857827 5622.93305462 5758.82078826
 5702.25420215 2721.36765953 5754.84103785 5738.51208947 5657.55616034]
total_rewards_mean           5389.880180069963
total_rewards_std            891.0525820272155
total_rewards_max            5758.820788259703
total_rewards_min            2721.367659532068
Number of train steps total  1612000
Number of env steps total    2017000
Number of rollouts total     0
Train Time (s)               197.87133305612952
(Previous) Eval Time (s)     17.866269465070218
Sample Time (s)              18.837170883547515
Epoch Time (s)               234.57477340474725
Total Train Time (s)         91488.2215722925
Epoch                        402
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:55:08.094601 UTC | [2020_01_13_04_30_18] Iteration #402 | Epoch Duration: 242.14050602912903
2020-01-14 05:55:08.094785 UTC | [2020_01_13_04_30_18] Iteration #402 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07506663
Z variance train             0.17838554
KL Divergence                2.4019012
KL Loss                      0.24019013
QF Loss                      622.00354
VF Loss                      255.6727
Policy Loss                  -2999.0017
Q Predictions Mean           2989.6152
Q Predictions Std            416.81833
Q Predictions Max            3139.658
Q Predictions Min            20.530252
V Predictions Mean           2991.4407
V Predictions Std            416.75366
V Predictions Max            3155.4788
V Predictions Min            19.640646
Log Pis Mean                 -6.2010336
Log Pis Std                  3.8124166
Log Pis Max                  8.65069
Log Pis Min                  -14.470031
Policy mu Mean               0.232582
Policy mu Std                0.5926544
Policy mu Max                2.532846
Policy mu Min                -2.3441756
Policy log std Mean          -0.30395147
Policy log std Std           0.12834415
Policy log std Max           -0.077637985
Policy log std Min           -1.001485
Z mean eval                  0.08415629
Z variance eval              0.17646292
total_rewards                [5563.96922093 5583.53155089 5544.63150546 5459.18544339 5557.17912592
 5558.77034152 5606.63405889 2193.41430123 5453.81420093 5641.08772118]
total_rewards_mean           5216.221747032557
total_rewards_std            1009.1119113552946
total_rewards_max            5641.087721176954
total_rewards_min            2193.414301226702
Number of train steps total  1616000
Number of env steps total    2022000
Number of rollouts total     0
Train Time (s)               197.02789710834622
(Previous) Eval Time (s)     25.43172959284857
Sample Time (s)              17.41905407840386
Epoch Time (s)               239.87868077959865
Total Train Time (s)         91727.83608947787
Epoch                        403
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 05:59:07.714521 UTC | [2020_01_13_04_30_18] Iteration #403 | Epoch Duration: 239.61957788467407
2020-01-14 05:59:07.714734 UTC | [2020_01_13_04_30_18] Iteration #403 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08440528
Z variance train             0.17648163
KL Divergence                2.3971877
KL Loss                      0.23971878
QF Loss                      521.2501
VF Loss                      118.63777
Policy Loss                  -3025.516
Q Predictions Mean           3021.7822
Q Predictions Std            303.1796
Q Predictions Max            3157.081
Q Predictions Min            33.15669
V Predictions Mean           3020.2725
V Predictions Std            296.5412
V Predictions Max            3153.9297
V Predictions Min            42.2491
Log Pis Mean                 -6.3036156
Log Pis Std                  4.2790184
Log Pis Max                  23.104408
Log Pis Min                  -12.931513
Policy mu Mean               0.15428823
Policy mu Std                0.604949
Policy mu Max                2.9256403
Policy mu Min                -3.6932821
Policy log std Mean          -0.2910314
Policy log std Std           0.12915033
Policy log std Max           -0.06598021
Policy log std Min           -1.0841262
Z mean eval                  0.06495881
Z variance eval              0.16376321
total_rewards                [5491.00565692 5470.76874733  733.79063299 5616.29072037 5508.66646672
 5523.00824697 5604.92996352 5527.62681684 5519.26615657 5564.04538077]
total_rewards_mean           5055.939878900408
total_rewards_std            1441.394038269234
total_rewards_max            5616.290720371282
total_rewards_min            733.7906329880498
Number of train steps total  1620000
Number of env steps total    2027000
Number of rollouts total     0
Train Time (s)               196.81678814301267
(Previous) Eval Time (s)     25.172356578987092
Sample Time (s)              16.78297664038837
Epoch Time (s)               238.77212136238813
Total Train Time (s)         91962.5305150128
Epoch                        404
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:03:02.414984 UTC | [2020_01_13_04_30_18] Iteration #404 | Epoch Duration: 234.70009660720825
2020-01-14 06:03:02.415155 UTC | [2020_01_13_04_30_18] Iteration #404 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.064662
Z variance train             0.16378085
KL Divergence                2.6358485
KL Loss                      0.26358485
QF Loss                      639.08203
VF Loss                      171.46283
Policy Loss                  -2999.2234
Q Predictions Mean           2999.233
Q Predictions Std            377.52866
Q Predictions Max            3165.1758
Q Predictions Min            70.093155
V Predictions Mean           3001.7
V Predictions Std            377.48593
V Predictions Max            3163.7522
V Predictions Min            93.49956
Log Pis Mean                 -6.740469
Log Pis Std                  4.528106
Log Pis Max                  18.383032
Log Pis Min                  -16.413368
Policy mu Mean               0.17350857
Policy mu Std                0.6119499
Policy mu Max                2.480245
Policy mu Min                -2.3958673
Policy log std Mean          -0.29523706
Policy log std Std           0.13617428
Policy log std Max           0.052876145
Policy log std Min           -1.1545616
Z mean eval                  0.062896684
Z variance eval              0.15680477
total_rewards                [1583.9133221   771.94274164 3910.44048315 5609.61230387 5608.04315222
 5560.31320673 5503.66556194 5589.04378664 5729.20771495 5594.60329035]
total_rewards_mean           4546.078556358496
total_rewards_std            1766.7499147476333
total_rewards_max            5729.207714949564
total_rewards_min            771.9427416405917
Number of train steps total  1624000
Number of env steps total    2032000
Number of rollouts total     0
Train Time (s)               193.94408725528046
(Previous) Eval Time (s)     21.10007376782596
Sample Time (s)              19.351731571368873
Epoch Time (s)               234.3958925944753
Total Train Time (s)         92197.58608249249
Epoch                        405
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:06:57.474620 UTC | [2020_01_13_04_30_18] Iteration #405 | Epoch Duration: 235.05935502052307
2020-01-14 06:06:57.474740 UTC | [2020_01_13_04_30_18] Iteration #405 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06283196
Z variance train             0.15680644
KL Divergence                2.6728392
KL Loss                      0.26728392
QF Loss                      1081.2288
VF Loss                      198.3515
Policy Loss                  -3058.4797
Q Predictions Mean           3053.4675
Q Predictions Std            201.87317
Q Predictions Max            3175.4746
Q Predictions Min            25.147125
V Predictions Mean           3062.7964
V Predictions Std            201.61073
V Predictions Max            3184.9097
V Predictions Min            28.156982
Log Pis Mean                 -7.1802044
Log Pis Std                  3.1995986
Log Pis Max                  12.538141
Log Pis Min                  -14.954337
Policy mu Mean               0.15777667
Policy mu Std                0.57929444
Policy mu Max                2.4593863
Policy mu Min                -1.8922523
Policy log std Mean          -0.28631312
Policy log std Std           0.11376237
Policy log std Max           -0.060007423
Policy log std Min           -0.9174675
Z mean eval                  0.081679724
Z variance eval              0.17481127
total_rewards                [5400.18387571 5399.85835374 5635.30046174 5603.25647444 5663.21028457
 1931.4179049  5470.12057009 5570.18289177 5520.95027187 2560.70365386]
total_rewards_mean           4875.5184742708325
total_rewards_std            1325.0027951691425
total_rewards_max            5663.210284574637
total_rewards_min            1931.4179049021197
Number of train steps total  1628000
Number of env steps total    2037000
Number of rollouts total     0
Train Time (s)               193.55401493888348
(Previous) Eval Time (s)     21.763272288255394
Sample Time (s)              18.662009065039456
Epoch Time (s)               233.97929629217833
Total Train Time (s)         92433.6605715407
Epoch                        406
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:10:53.551838 UTC | [2020_01_13_04_30_18] Iteration #406 | Epoch Duration: 236.0770092010498
2020-01-14 06:10:53.551952 UTC | [2020_01_13_04_30_18] Iteration #406 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0814478
Z variance train             0.17481345
KL Divergence                2.5188632
KL Loss                      0.25188634
QF Loss                      519.95154
VF Loss                      183.50177
Policy Loss                  -3038.5525
Q Predictions Mean           3029.4937
Q Predictions Std            348.2307
Q Predictions Max            3167.5444
Q Predictions Min            21.290398
V Predictions Mean           3041.157
V Predictions Std            348.81396
V Predictions Max            3180.4402
V Predictions Min            36.37282
Log Pis Mean                 -6.3055787
Log Pis Std                  4.063029
Log Pis Max                  16.125347
Log Pis Min                  -15.594077
Policy mu Mean               0.1639011
Policy mu Std                0.6210614
Policy mu Max                3.0743003
Policy mu Min                -3.9596527
Policy log std Mean          -0.29094657
Policy log std Std           0.12048131
Policy log std Max           0.10700931
Policy log std Min           -1.3363166
Z mean eval                  0.08579633
Z variance eval              0.16548517
total_rewards                [1894.42524646 2971.851064   5621.70349815 5575.2554026  5542.72393522
 5515.78444228 3875.90266997 5529.75677388 5528.4582801  2717.77348522]
total_rewards_mean           4477.3634797897885
total_rewards_std            1390.560077012953
total_rewards_max            5621.703498152162
total_rewards_min            1894.425246464598
Number of train steps total  1632000
Number of env steps total    2042000
Number of rollouts total     0
Train Time (s)               198.1525170779787
(Previous) Eval Time (s)     23.860715415794402
Sample Time (s)              17.713879140559584
Epoch Time (s)               239.7271116343327
Total Train Time (s)         92671.1861052732
Epoch                        407
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:14:51.079885 UTC | [2020_01_13_04_30_18] Iteration #407 | Epoch Duration: 237.52783870697021
2020-01-14 06:14:51.080013 UTC | [2020_01_13_04_30_18] Iteration #407 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0854945
Z variance train             0.16548638
KL Divergence                2.643692
KL Loss                      0.26436922
QF Loss                      550.7758
VF Loss                      153.0972
Policy Loss                  -3034.3035
Q Predictions Mean           3033.2659
Q Predictions Std            334.2017
Q Predictions Max            3183.5498
Q Predictions Min            26.664879
V Predictions Mean           3038.187
V Predictions Std            334.99268
V Predictions Max            3194.5027
V Predictions Min            34.285217
Log Pis Mean                 -6.55415
Log Pis Std                  4.2987647
Log Pis Max                  19.68643
Log Pis Min                  -16.30631
Policy mu Mean               0.18565977
Policy mu Std                0.60670286
Policy mu Max                3.6245565
Policy mu Min                -3.218729
Policy log std Mean          -0.29244715
Policy log std Std           0.12875699
Policy log std Max           -0.018902428
Policy log std Min           -1.4669671
Z mean eval                  0.07758283
Z variance eval              0.18554275
total_rewards                [5625.14743204 5491.80540486 5566.82303481 5513.18994883 5613.72149825
 4228.71308531 5610.11942967 5569.82565601 5584.18069364 5532.01859236]
total_rewards_mean           5433.5544775774515
total_rewards_std            403.78642107612944
total_rewards_max            5625.147432037344
total_rewards_min            4228.713085311613
Number of train steps total  1636000
Number of env steps total    2047000
Number of rollouts total     0
Train Time (s)               195.48296029912308
(Previous) Eval Time (s)     21.66116184834391
Sample Time (s)              18.542548086028546
Epoch Time (s)               235.68667023349553
Total Train Time (s)         92908.3397723264
Epoch                        408
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:18:48.241870 UTC | [2020_01_13_04_30_18] Iteration #408 | Epoch Duration: 237.16172432899475
2020-01-14 06:18:48.242087 UTC | [2020_01_13_04_30_18] Iteration #408 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07748093
Z variance train             0.18545726
KL Divergence                2.2805233
KL Loss                      0.22805233
QF Loss                      410.38348
VF Loss                      156.47203
Policy Loss                  -3041.4626
Q Predictions Mean           3033.5
Q Predictions Std            339.9259
Q Predictions Max            3177.7458
Q Predictions Min            19.984516
V Predictions Mean           3043.4429
V Predictions Std            340.88596
V Predictions Max            3181.5461
V Predictions Min            25.918018
Log Pis Mean                 -6.8139358
Log Pis Std                  3.7641964
Log Pis Max                  17.348541
Log Pis Min                  -14.98657
Policy mu Mean               0.18103634
Policy mu Std                0.580286
Policy mu Max                2.2688491
Policy mu Min                -2.7108042
Policy log std Mean          -0.29749677
Policy log std Std           0.117553905
Policy log std Max           -0.058788598
Policy log std Min           -0.9905432
Z mean eval                  0.07958918
Z variance eval              0.19081458
total_rewards                [5683.46264844 2931.10770958 5723.46916151 5597.40295014 5674.22752023
 5617.88347128 5642.29184618 5734.64346716 5626.02649343 5668.54422258]
total_rewards_mean           5389.905949052971
total_rewards_std            820.6662563568135
total_rewards_max            5734.643467157444
total_rewards_min            2931.1077095827914
Number of train steps total  1640000
Number of env steps total    2052000
Number of rollouts total     0
Train Time (s)               205.65125675080344
(Previous) Eval Time (s)     23.135903910268098
Sample Time (s)              19.331897949799895
Epoch Time (s)               248.11905861087143
Total Train Time (s)         93158.86867287755
Epoch                        409
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:22:58.774496 UTC | [2020_01_13_04_30_18] Iteration #409 | Epoch Duration: 250.53228282928467
2020-01-14 06:22:58.774631 UTC | [2020_01_13_04_30_18] Iteration #409 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.079169616
Z variance train             0.19074224
KL Divergence                2.2907672
KL Loss                      0.22907673
QF Loss                      495.825
VF Loss                      156.89005
Policy Loss                  -3083.357
Q Predictions Mean           3078.59
Q Predictions Std            107.208595
Q Predictions Max            3184.326
Q Predictions Min            1956.5052
V Predictions Mean           3089.8308
V Predictions Std            103.50585
V Predictions Max            3194.699
V Predictions Min            1988.6259
Log Pis Mean                 -6.945144
Log Pis Std                  3.5242348
Log Pis Max                  9.738057
Log Pis Min                  -14.524134
Policy mu Mean               0.18615514
Policy mu Std                0.57873344
Policy mu Max                2.2340283
Policy mu Min                -2.3424835
Policy log std Mean          -0.285193
Policy log std Std           0.1254223
Policy log std Max           -0.06189832
Policy log std Min           -1.2665515
Z mean eval                  0.07410524
Z variance eval              0.16597214
total_rewards                [ 900.91171805 5603.08414962 5296.34839217 5662.23601173 5621.03073952
 5618.33399048 5572.40244263 5701.62004659 5677.10508035 5578.74027136]
total_rewards_mean           5123.181284248933
total_rewards_std            1411.4609733356037
total_rewards_max            5701.620046585617
total_rewards_min            900.9117180460304
Number of train steps total  1644000
Number of env steps total    2057000
Number of rollouts total     0
Train Time (s)               196.7706585759297
(Previous) Eval Time (s)     25.548778127878904
Sample Time (s)              18.660087956581265
Epoch Time (s)               240.97952466038987
Total Train Time (s)         93398.38790706359
Epoch                        410
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:26:58.298861 UTC | [2020_01_13_04_30_18] Iteration #410 | Epoch Duration: 239.52413034439087
2020-01-14 06:26:58.299012 UTC | [2020_01_13_04_30_18] Iteration #410 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07300633
Z variance train             0.16595754
KL Divergence                2.4411473
KL Loss                      0.24411474
QF Loss                      1133.2107
VF Loss                      255.3015
Policy Loss                  -3038.1384
Q Predictions Mean           3038.5288
Q Predictions Std            315.96582
Q Predictions Max            3194.129
Q Predictions Min            21.343666
V Predictions Mean           3035.8726
V Predictions Std            310.32635
V Predictions Max            3172.5964
V Predictions Min            22.747711
Log Pis Mean                 -6.2052393
Log Pis Std                  4.5302873
Log Pis Max                  29.66314
Log Pis Min                  -13.897799
Policy mu Mean               0.19792593
Policy mu Std                0.6306729
Policy mu Max                4.5410237
Policy mu Min                -4.159621
Policy log std Mean          -0.2990097
Policy log std Std           0.12640229
Policy log std Max           0.24905884
Policy log std Min           -1.2878
Z mean eval                  0.07237426
Z variance eval              0.1631363
total_rewards                [5567.90505818 1089.15214867 5645.13706338 5560.64647415 5614.11143437
 5717.47441424 5735.05151786 5572.80917141 5495.48555132 5541.79187755]
total_rewards_mean           5153.9564711129915
total_rewards_std            1356.8384303505281
total_rewards_max            5735.0515178563355
total_rewards_min            1089.1521486660438
Number of train steps total  1648000
Number of env steps total    2062000
Number of rollouts total     0
Train Time (s)               194.71318431710824
(Previous) Eval Time (s)     24.093108954373747
Sample Time (s)              16.82212928077206
Epoch Time (s)               235.62842255225405
Total Train Time (s)         93632.43282480212
Epoch                        411
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:30:52.351121 UTC | [2020_01_13_04_30_18] Iteration #411 | Epoch Duration: 234.05197668075562
2020-01-14 06:30:52.351353 UTC | [2020_01_13_04_30_18] Iteration #411 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07240151
Z variance train             0.16311142
KL Divergence                2.4960093
KL Loss                      0.24960093
QF Loss                      685.21326
VF Loss                      285.69522
Policy Loss                  -3056.4756
Q Predictions Mean           3049.4412
Q Predictions Std            231.95618
Q Predictions Max            3172.118
Q Predictions Min            356.44894
V Predictions Mean           3062.6846
V Predictions Std            223.63295
V Predictions Max            3180.3096
V Predictions Min            393.91293
Log Pis Mean                 -6.7855783
Log Pis Std                  4.1230726
Log Pis Max                  13.745773
Log Pis Min                  -15.489585
Policy mu Mean               0.21988547
Policy mu Std                0.60242945
Policy mu Max                3.4749153
Policy mu Min                -3.4196208
Policy log std Mean          -0.29812792
Policy log std Std           0.12789106
Policy log std Max           0.027251013
Policy log std Min           -1.2822424
Z mean eval                  0.06486777
Z variance eval              0.17080393
total_rewards                [5577.89286415 5536.65417457 5532.90690086 5516.69023099 5660.94556944
 5512.69278254 5520.90355624 5486.88957345 4185.74443861 5537.40954699]
total_rewards_mean           5406.872963782175
total_rewards_std            409.55907825930404
total_rewards_max            5660.945569438846
total_rewards_min            4185.744438605609
Number of train steps total  1652000
Number of env steps total    2067000
Number of rollouts total     0
Train Time (s)               197.09267300274223
(Previous) Eval Time (s)     22.516364227980375
Sample Time (s)              19.055401652120054
Epoch Time (s)               238.66443888284266
Total Train Time (s)         93874.6963743791
Epoch                        412
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:34:54.616765 UTC | [2020_01_13_04_30_18] Iteration #412 | Epoch Duration: 242.26526641845703
2020-01-14 06:34:54.616898 UTC | [2020_01_13_04_30_18] Iteration #412 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06556145
Z variance train             0.17069903
KL Divergence                2.4636378
KL Loss                      0.24636379
QF Loss                      676.6359
VF Loss                      291.34692
Policy Loss                  -3041.1748
Q Predictions Mean           3033.0518
Q Predictions Std            334.9787
Q Predictions Max            3190.479
Q Predictions Min            11.690967
V Predictions Mean           3035.365
V Predictions Std            334.5424
V Predictions Max            3191.3752
V Predictions Min            18.819921
Log Pis Mean                 -6.6296053
Log Pis Std                  4.0381045
Log Pis Max                  13.051132
Log Pis Min                  -15.052448
Policy mu Mean               0.19754422
Policy mu Std                0.59979635
Policy mu Max                2.856984
Policy mu Min                -2.6669018
Policy log std Mean          -0.27636847
Policy log std Std           0.12351439
Policy log std Max           -0.051882736
Policy log std Min           -0.9475863
Z mean eval                  0.091782525
Z variance eval              0.17874645
total_rewards                [5498.91152724 5367.2184511  5471.31191006 4380.78361301 5512.47400227
 5288.22824799 5454.38591188 5635.90235162 5538.06823541 5375.23899541]
total_rewards_mean           5352.252324599664
total_rewards_std            336.9531369125682
total_rewards_max            5635.902351617102
total_rewards_min            4380.783613011091
Number of train steps total  1656000
Number of env steps total    2072000
Number of rollouts total     0
Train Time (s)               196.7241114443168
(Previous) Eval Time (s)     26.116910646203905
Sample Time (s)              18.752646973822266
Epoch Time (s)               241.59366906434298
Total Train Time (s)         94117.03570123808
Epoch                        413
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:38:56.959109 UTC | [2020_01_13_04_30_18] Iteration #413 | Epoch Duration: 242.34211540222168
2020-01-14 06:38:56.959248 UTC | [2020_01_13_04_30_18] Iteration #413 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09204327
Z variance train             0.17879076
KL Divergence                2.3540468
KL Loss                      0.23540469
QF Loss                      1120.1616
VF Loss                      176.41306
Policy Loss                  -3050.1672
Q Predictions Mean           3041.3486
Q Predictions Std            324.96793
Q Predictions Max            3180.4683
Q Predictions Min            24.18835
V Predictions Mean           3048.8748
V Predictions Std            315.67746
V Predictions Max            3193.3833
V Predictions Min            36.43824
Log Pis Mean                 -6.5695376
Log Pis Std                  4.1246943
Log Pis Max                  21.809797
Log Pis Min                  -14.1427765
Policy mu Mean               0.14486936
Policy mu Std                0.61981106
Policy mu Max                3.0172064
Policy mu Min                -2.715116
Policy log std Mean          -0.2997003
Policy log std Std           0.124386355
Policy log std Max           -0.071627
Policy log std Min           -1.0958527
Z mean eval                  0.08223061
Z variance eval              0.14540803
total_rewards                [5400.40709643 5549.55090145 5475.19073949 5497.95459439 5632.58233223
 5428.99345443 5616.30608582 5476.74470054 5560.46854009 5518.24967659]
total_rewards_mean           5515.644812146396
total_rewards_std            71.57061814390971
total_rewards_max            5632.582332230093
total_rewards_min            5400.407096432684
Number of train steps total  1660000
Number of env steps total    2077000
Number of rollouts total     0
Train Time (s)               199.21157670533285
(Previous) Eval Time (s)     26.86509754974395
Sample Time (s)              18.567980853375047
Epoch Time (s)               244.64465510845184
Total Train Time (s)         94361.23359579826
Epoch                        414
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:43:01.162294 UTC | [2020_01_13_04_30_18] Iteration #414 | Epoch Duration: 244.2029161453247
2020-01-14 06:43:01.162541 UTC | [2020_01_13_04_30_18] Iteration #414 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08282934
Z variance train             0.14541814
KL Divergence                2.749959
KL Loss                      0.2749959
QF Loss                      493.82214
VF Loss                      101.52929
Policy Loss                  -3056.0337
Q Predictions Mean           3053.6235
Q Predictions Std            341.3626
Q Predictions Max            3200.0596
Q Predictions Min            8.790395
V Predictions Mean           3054.3413
V Predictions Std            340.753
V Predictions Max            3201.185
V Predictions Min            20.479052
Log Pis Mean                 -6.685849
Log Pis Std                  3.8647244
Log Pis Max                  16.864986
Log Pis Min                  -14.162367
Policy mu Mean               0.17140386
Policy mu Std                0.6088019
Policy mu Max                2.557534
Policy mu Min                -2.6968787
Policy log std Mean          -0.2889354
Policy log std Std           0.12217797
Policy log std Max           -0.069600075
Policy log std Min           -1.2625196
Z mean eval                  0.076863036
Z variance eval              0.16118595
total_rewards                [5577.75784096 5615.08493965 1567.39446272 5689.72881133 5569.29750169
 5623.89637411 5715.54594201 5559.85227109 5700.90596904 5622.85691122]
total_rewards_mean           5224.232102381234
total_rewards_std            1220.075680319809
total_rewards_max            5715.545942011418
total_rewards_min            1567.3944627159235
Number of train steps total  1664000
Number of env steps total    2082000
Number of rollouts total     0
Train Time (s)               194.3981770076789
(Previous) Eval Time (s)     26.423084560316056
Sample Time (s)              16.86734167439863
Epoch Time (s)               237.68860324239358
Total Train Time (s)         94597.16531911632
Epoch                        415
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:46:57.098029 UTC | [2020_01_13_04_30_18] Iteration #415 | Epoch Duration: 235.93530988693237
2020-01-14 06:46:57.098223 UTC | [2020_01_13_04_30_18] Iteration #415 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07681855
Z variance train             0.16116586
KL Divergence                2.6736093
KL Loss                      0.26736093
QF Loss                      585.2481
VF Loss                      150.74483
Policy Loss                  -3034.7783
Q Predictions Mean           3030.7898
Q Predictions Std            337.77063
Q Predictions Max            3172.5098
Q Predictions Min            28.0927
V Predictions Mean           3036.5557
V Predictions Std            337.74927
V Predictions Max            3177.637
V Predictions Min            33.478577
Log Pis Mean                 -7.0452547
Log Pis Std                  4.6735044
Log Pis Max                  26.422783
Log Pis Min                  -13.977871
Policy mu Mean               0.19784987
Policy mu Std                0.5770703
Policy mu Max                3.6970685
Policy mu Min                -3.4876504
Policy log std Mean          -0.28203672
Policy log std Std           0.12432306
Policy log std Max           -0.0005950928
Policy log std Min           -1.1944638
Z mean eval                  0.07991736
Z variance eval              0.1918198
total_rewards                [5618.74376026 5516.80786333 5621.697116   2212.69640574 5539.19038404
 5545.27206494 5543.54766078 5603.34357265 5617.0624625  5462.9525408 ]
total_rewards_mean           5228.13138310545
total_rewards_std            1006.3632603796684
total_rewards_max            5621.697115996565
total_rewards_min            2212.696405739905
Number of train steps total  1668000
Number of env steps total    2087000
Number of rollouts total     0
Train Time (s)               195.5137056140229
(Previous) Eval Time (s)     24.669524346012622
Sample Time (s)              18.63621132960543
Epoch Time (s)               238.81944128964096
Total Train Time (s)         94836.4146366925
Epoch                        416
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:50:56.354058 UTC | [2020_01_13_04_30_18] Iteration #416 | Epoch Duration: 239.2557053565979
2020-01-14 06:50:56.354232 UTC | [2020_01_13_04_30_18] Iteration #416 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07968951
Z variance train             0.19189811
KL Divergence                2.2923064
KL Loss                      0.22923064
QF Loss                      825.83044
VF Loss                      294.43094
Policy Loss                  -3068.6328
Q Predictions Mean           3064.329
Q Predictions Std            276.3997
Q Predictions Max            3180.487
Q Predictions Min            657.9003
V Predictions Mean           3073.1226
V Predictions Std            279.76556
V Predictions Max            3192.7302
V Predictions Min            647.46075
Log Pis Mean                 -7.2852917
Log Pis Std                  3.61242
Log Pis Max                  8.53731
Log Pis Min                  -16.937332
Policy mu Mean               0.2125555
Policy mu Std                0.5611042
Policy mu Max                2.6659327
Policy mu Min                -2.624618
Policy log std Mean          -0.27998418
Policy log std Std           0.12125323
Policy log std Max           -0.018178023
Policy log std Min           -1.1580861
Z mean eval                  0.07280838
Z variance eval              0.18812677
total_rewards                [5428.44554583 5331.67562707 5401.32077104 5416.11940904 5356.36760133
 5298.11664254 5512.72259705 5250.86577007 3976.44069438 1421.27910551]
total_rewards_mean           4839.335376386784
total_rewards_std            1215.1651413327102
total_rewards_max            5512.72259704837
total_rewards_min            1421.2791055129526
Number of train steps total  1672000
Number of env steps total    2092000
Number of rollouts total     0
Train Time (s)               196.00906650116667
(Previous) Eval Time (s)     25.105519351083785
Sample Time (s)              16.902755057439208
Epoch Time (s)               238.01734090968966
Total Train Time (s)         95070.48425110849
Epoch                        417
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:54:50.430798 UTC | [2020_01_13_04_30_18] Iteration #417 | Epoch Duration: 234.07645320892334
2020-01-14 06:54:50.430980 UTC | [2020_01_13_04_30_18] Iteration #417 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07291629
Z variance train             0.18825762
KL Divergence                2.187332
KL Loss                      0.21873319
QF Loss                      670.17285
VF Loss                      207.97626
Policy Loss                  -3072.8113
Q Predictions Mean           3066.978
Q Predictions Std            217.0119
Q Predictions Max            3198.2996
Q Predictions Min            556.0228
V Predictions Mean           3074.0063
V Predictions Std            220.48656
V Predictions Max            3204.408
V Predictions Min            522.99994
Log Pis Mean                 -6.8499517
Log Pis Std                  4.0207677
Log Pis Max                  12.926205
Log Pis Min                  -13.590073
Policy mu Mean               0.145268
Policy mu Std                0.5741398
Policy mu Max                2.1349323
Policy mu Min                -2.8416586
Policy log std Mean          -0.2872438
Policy log std Std           0.1272189
Policy log std Max           -0.07696526
Policy log std Min           -1.2864897
Z mean eval                  0.06579365
Z variance eval              0.18931143
total_rewards                [2369.09575694 5490.94154962  494.97906848 5574.73677601 3285.84938121
 5578.20594328 5455.96773953 5046.45851508 5579.34097842 5568.7380827 ]
total_rewards_mean           4444.431379125997
total_rewards_std            1698.335955495306
total_rewards_max            5579.34097841787
total_rewards_min            494.97906847962423
Number of train steps total  1676000
Number of env steps total    2097000
Number of rollouts total     0
Train Time (s)               193.2811327171512
(Previous) Eval Time (s)     21.164368154015392
Sample Time (s)              19.010206766426563
Epoch Time (s)               233.45570763759315
Total Train Time (s)         95302.15982951364
Epoch                        418
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 06:58:42.110451 UTC | [2020_01_13_04_30_18] Iteration #418 | Epoch Duration: 231.67931652069092
2020-01-14 06:58:42.110658 UTC | [2020_01_13_04_30_18] Iteration #418 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.065659456
Z variance train             0.18933415
KL Divergence                2.1753724
KL Loss                      0.21753724
QF Loss                      482.05576
VF Loss                      96.45505
Policy Loss                  -3042.1853
Q Predictions Mean           3036.172
Q Predictions Std            362.4033
Q Predictions Max            3175.16
Q Predictions Min            21.98175
V Predictions Mean           3039.5967
V Predictions Std            365.1871
V Predictions Max            3185.3447
V Predictions Min            14.1891
Log Pis Mean                 -7.2662907
Log Pis Std                  3.4897947
Log Pis Max                  4.5941577
Log Pis Min                  -16.58398
Policy mu Mean               0.16174662
Policy mu Std                0.5689584
Policy mu Max                2.3689744
Policy mu Min                -2.2543468
Policy log std Mean          -0.28874224
Policy log std Std           0.12232893
Policy log std Max           0.018075295
Policy log std Min           -1.0334778
Z mean eval                  0.09014509
Z variance eval              0.15967587
total_rewards                [5478.3117628  3596.33656475 4196.09351761 1487.51543492 5409.52120653
 5542.99272192 5412.11626383 5400.74791025 5236.74746204 5510.01450741]
total_rewards_mean           4727.039735206721
total_rewards_std            1246.8738969276412
total_rewards_max            5542.992721921158
total_rewards_min            1487.515434916945
Number of train steps total  1680000
Number of env steps total    2102000
Number of rollouts total     0
Train Time (s)               194.95850148098543
(Previous) Eval Time (s)     19.38769985595718
Sample Time (s)              19.021000743843615
Epoch Time (s)               233.36720208078623
Total Train Time (s)         95538.49623076338
Epoch                        419
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:02:38.450624 UTC | [2020_01_13_04_30_18] Iteration #419 | Epoch Duration: 236.3398232460022
2020-01-14 07:02:38.450794 UTC | [2020_01_13_04_30_18] Iteration #419 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09029532
Z variance train             0.15964302
KL Divergence                2.5519419
KL Loss                      0.2551942
QF Loss                      468.29663
VF Loss                      108.876854
Policy Loss                  -3084.9475
Q Predictions Mean           3076.315
Q Predictions Std            208.80736
Q Predictions Max            3197.2007
Q Predictions Min            27.259388
V Predictions Mean           3084.1514
V Predictions Std            208.72124
V Predictions Max            3208.2676
V Predictions Min            33.56855
Log Pis Mean                 -6.758779
Log Pis Std                  4.2892437
Log Pis Max                  11.9358635
Log Pis Min                  -14.964336
Policy mu Mean               0.20325863
Policy mu Std                0.59545296
Policy mu Max                2.747517
Policy mu Min                -2.404446
Policy log std Mean          -0.28943005
Policy log std Std           0.12447695
Policy log std Max           -0.06399581
Policy log std Min           -1.0616966
Z mean eval                  0.07374959
Z variance eval              0.13709764
total_rewards                [5413.60225141 1498.52775213 5414.72649809 2287.64673792 5490.49971989
 5367.68276724 5378.95481475 5376.55354203 5275.43517335 5311.07661018]
total_rewards_mean           4681.470586699868
total_rewards_std            1406.3938369611903
total_rewards_max            5490.499719892503
total_rewards_min            1498.5277521288085
Number of train steps total  1684000
Number of env steps total    2107000
Number of rollouts total     0
Train Time (s)               191.82333218026906
(Previous) Eval Time (s)     22.360041156876832
Sample Time (s)              18.83210643287748
Epoch Time (s)               233.01547977002338
Total Train Time (s)         95772.28169124993
Epoch                        420
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:06:32.243927 UTC | [2020_01_13_04_30_18] Iteration #420 | Epoch Duration: 233.79298996925354
2020-01-14 07:06:32.244171 UTC | [2020_01_13_04_30_18] Iteration #420 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07347573
Z variance train             0.13705821
KL Divergence                2.8643928
KL Loss                      0.28643927
QF Loss                      1002.9607
VF Loss                      199.69946
Policy Loss                  -3057.8567
Q Predictions Mean           3059.0806
Q Predictions Std            298.95273
Q Predictions Max            3201.269
Q Predictions Min            209.58734
V Predictions Mean           3067.6523
V Predictions Std            297.08508
V Predictions Max            3216.0806
V Predictions Min            275.63235
Log Pis Mean                 -6.7706914
Log Pis Std                  4.082388
Log Pis Max                  15.719427
Log Pis Min                  -14.266911
Policy mu Mean               0.16840133
Policy mu Std                0.58763963
Policy mu Max                2.3793926
Policy mu Min                -2.6864626
Policy log std Mean          -0.2877264
Policy log std Std           0.118450075
Policy log std Max           0.04160679
Policy log std Min           -1.0204232
Z mean eval                  0.06964822
Z variance eval              0.1226113
total_rewards                [5555.91006901 5478.0273317  5540.98336029 5466.79778942 5547.99594524
 5507.15728267 5525.00919793 5471.21754933 5588.56191536 5414.85749019]
total_rewards_mean           5509.651793114137
total_rewards_std            49.356227777535544
total_rewards_max            5588.561915355464
total_rewards_min            5414.8574901912325
Number of train steps total  1688000
Number of env steps total    2112000
Number of rollouts total     0
Train Time (s)               196.37264149915427
(Previous) Eval Time (s)     23.137274799402803
Sample Time (s)              18.682797347195446
Epoch Time (s)               238.19271364575252
Total Train Time (s)         96013.52262242138
Epoch                        421
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:10:33.488853 UTC | [2020_01_13_04_30_18] Iteration #421 | Epoch Duration: 241.24450874328613
2020-01-14 07:10:33.489027 UTC | [2020_01_13_04_30_18] Iteration #421 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07008766
Z variance train             0.122691765
KL Divergence                3.1306229
KL Loss                      0.31306228
QF Loss                      706.246
VF Loss                      341.97083
Policy Loss                  -3084.4075
Q Predictions Mean           3084.3848
Q Predictions Std            163.9977
Q Predictions Max            3203.3079
Q Predictions Min            1050.1663
V Predictions Mean           3089.4421
V Predictions Std            164.9277
V Predictions Max            3213.8557
V Predictions Min            1098.2598
Log Pis Mean                 -6.9939847
Log Pis Std                  4.0019655
Log Pis Max                  17.001743
Log Pis Min                  -15.132553
Policy mu Mean               0.23128396
Policy mu Std                0.5827153
Policy mu Max                2.531761
Policy mu Min                -2.7423146
Policy log std Mean          -0.29529318
Policy log std Std           0.13053185
Policy log std Max           -0.024336971
Policy log std Min           -1.1126227
Z mean eval                  0.0597471
Z variance eval              0.13960381
total_rewards                [5557.0975054  5619.08378341 5667.96784059 5646.25396491 5604.62576298
 5640.89693849 5607.87120478 5652.28834026 5679.92958638 5654.26349553]
total_rewards_mean           5633.027842271174
total_rewards_std            34.465543927737755
total_rewards_max            5679.929586375171
total_rewards_min            5557.097505401884
Number of train steps total  1692000
Number of env steps total    2117000
Number of rollouts total     0
Train Time (s)               192.4650703058578
(Previous) Eval Time (s)     26.188785729929805
Sample Time (s)              18.9792228625156
Epoch Time (s)               237.6330788983032
Total Train Time (s)         96249.65919429343
Epoch                        422
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:14:29.628540 UTC | [2020_01_13_04_30_18] Iteration #422 | Epoch Duration: 236.13940262794495
2020-01-14 07:14:29.628651 UTC | [2020_01_13_04_30_18] Iteration #422 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.059919875
Z variance train             0.13951471
KL Divergence                2.9169464
KL Loss                      0.29169464
QF Loss                      2042.8093
VF Loss                      477.5122
Policy Loss                  -3086.003
Q Predictions Mean           3072.292
Q Predictions Std            224.1867
Q Predictions Max            3178.3267
Q Predictions Min            27.503828
V Predictions Mean           3083.454
V Predictions Std            215.96904
V Predictions Max            3191.3345
V Predictions Min            27.907978
Log Pis Mean                 -6.504939
Log Pis Std                  4.5714726
Log Pis Max                  19.1363
Log Pis Min                  -14.554276
Policy mu Mean               0.17619765
Policy mu Std                0.5998805
Policy mu Max                2.7388096
Policy mu Min                -2.641693
Policy log std Mean          -0.29326266
Policy log std Std           0.13404182
Policy log std Max           -0.055912822
Policy log std Min           -1.2316754
Z mean eval                  0.0798098
Z variance eval              0.13954185
total_rewards                [5647.73814327 5606.26333848 5601.44185719 5556.87677245 5646.03312752
 3012.74898155 2431.27047651 5757.30332628 5706.09995288 5656.08727295]
total_rewards_mean           5062.186324908883
total_rewards_std            1178.4619363075237
total_rewards_max            5757.303326283153
total_rewards_min            2431.2704765090343
Number of train steps total  1696000
Number of env steps total    2122000
Number of rollouts total     0
Train Time (s)               190.76354424934834
(Previous) Eval Time (s)     24.694856024812907
Sample Time (s)              18.70558465179056
Epoch Time (s)               234.1639849259518
Total Train Time (s)         96480.84756561508
Epoch                        423
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:18:20.821504 UTC | [2020_01_13_04_30_18] Iteration #423 | Epoch Duration: 231.19275736808777
2020-01-14 07:18:20.821658 UTC | [2020_01_13_04_30_18] Iteration #423 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07915018
Z variance train             0.13949671
KL Divergence                2.9436295
KL Loss                      0.29436296
QF Loss                      553.6382
VF Loss                      141.15279
Policy Loss                  -3100.1694
Q Predictions Mean           3095.18
Q Predictions Std            212.33022
Q Predictions Max            3208.509
Q Predictions Min            24.125835
V Predictions Mean           3104.2983
V Predictions Std            208.69736
V Predictions Max            3226.9944
V Predictions Min            24.490189
Log Pis Mean                 -6.691662
Log Pis Std                  4.2012186
Log Pis Max                  29.947079
Log Pis Min                  -17.702011
Policy mu Mean               0.19768713
Policy mu Std                0.5842073
Policy mu Max                3.0804555
Policy mu Min                -2.467533
Policy log std Mean          -0.281664
Policy log std Std           0.12173461
Policy log std Max           -0.07294526
Policy log std Min           -1.1446617
Z mean eval                  0.059565466
Z variance eval              0.15691231
total_rewards                [5462.30812442 4337.49784343 5503.11604795 5316.48715415 4805.91928612
 5508.05232415 5497.44248163 5422.69109935 5448.7195431  5397.93557968]
total_rewards_mean           5270.016948396918
total_rewards_std            368.5701413701335
total_rewards_max            5508.052324150966
total_rewards_min            4337.497843428389
Number of train steps total  1700000
Number of env steps total    2127000
Number of rollouts total     0
Train Time (s)               193.39500604197383
(Previous) Eval Time (s)     21.72335640573874
Sample Time (s)              16.692257816437632
Epoch Time (s)               231.8106202641502
Total Train Time (s)         96716.90039568488
Epoch                        424
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:22:16.882905 UTC | [2020_01_13_04_30_18] Iteration #424 | Epoch Duration: 236.06109261512756
2020-01-14 07:22:16.883172 UTC | [2020_01_13_04_30_18] Iteration #424 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.059533685
Z variance train             0.15678144
KL Divergence                2.6385274
KL Loss                      0.26385275
QF Loss                      496.60052
VF Loss                      142.67014
Policy Loss                  -3101.965
Q Predictions Mean           3097.769
Q Predictions Std            261.76965
Q Predictions Max            3211.399
Q Predictions Min            13.647638
V Predictions Mean           3107.2349
V Predictions Std            263.38593
V Predictions Max            3217.6267
V Predictions Min            20.729795
Log Pis Mean                 -7.115963
Log Pis Std                  3.4299088
Log Pis Max                  9.391113
Log Pis Min                  -13.834359
Policy mu Mean               0.15210454
Policy mu Std                0.56778836
Policy mu Max                2.3793132
Policy mu Min                -1.8139265
Policy log std Mean          -0.28980795
Policy log std Std           0.12106523
Policy log std Max           -0.066919535
Policy log std Min           -1.1675763
Z mean eval                  0.069205984
Z variance eval              0.15520671
total_rewards                [5648.03885217 5606.90135012  386.47457396 5543.89365601 5514.37977345
 1864.69895422 5602.88775769 5553.7355592  5204.16185813 5634.58120536]
total_rewards_mean           4655.975354031224
total_rewards_std            1799.8433955628898
total_rewards_max            5648.038852168367
total_rewards_min            386.4745739647804
Number of train steps total  1704000
Number of env steps total    2132000
Number of rollouts total     0
Train Time (s)               192.78599306195974
(Previous) Eval Time (s)     25.973556166049093
Sample Time (s)              18.662919720634818
Epoch Time (s)               237.42246894864365
Total Train Time (s)         96950.12088079145
Epoch                        425
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:26:10.110710 UTC | [2020_01_13_04_30_18] Iteration #425 | Epoch Duration: 233.2273349761963
2020-01-14 07:26:10.110957 UTC | [2020_01_13_04_30_18] Iteration #425 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0689909
Z variance train             0.1552687
KL Divergence                2.6628883
KL Loss                      0.26628885
QF Loss                      1273.6647
VF Loss                      322.14124
Policy Loss                  -3095.8953
Q Predictions Mean           3090.7107
Q Predictions Std            276.6862
Q Predictions Max            3211.831
Q Predictions Min            27.447638
V Predictions Mean           3099.0098
V Predictions Std            272.30203
V Predictions Max            3212.11
V Predictions Min            35.109833
Log Pis Mean                 -7.501775
Log Pis Std                  3.7429194
Log Pis Max                  29.340252
Log Pis Min                  -14.744277
Policy mu Mean               0.14669329
Policy mu Std                0.56001246
Policy mu Max                2.77364
Policy mu Min                -2.664572
Policy log std Mean          -0.27153507
Policy log std Std           0.12076469
Policy log std Max           -0.018517405
Policy log std Min           -1.1973902
Z mean eval                  0.060767084
Z variance eval              0.1578945
total_rewards                [ 790.4055222  2700.86888438 5601.52978122 5739.3007639  5618.91277717
 5584.25570928 5585.16413581 3337.60927589 5571.35363687 5660.07563941]
total_rewards_mean           4618.947612614016
total_rewards_std            1644.8585533531166
total_rewards_max            5739.300763904955
total_rewards_min            790.4055221971827
Number of train steps total  1708000
Number of env steps total    2137000
Number of rollouts total     0
Train Time (s)               196.69937404897064
(Previous) Eval Time (s)     21.77815834619105
Sample Time (s)              16.4240895062685
Epoch Time (s)               234.9016219014302
Total Train Time (s)         97185.02870562486
Epoch                        426
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:30:05.029303 UTC | [2020_01_13_04_30_18] Iteration #426 | Epoch Duration: 234.91820001602173
2020-01-14 07:30:05.029509 UTC | [2020_01_13_04_30_18] Iteration #426 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.060668983
Z variance train             0.15790954
KL Divergence                2.5797873
KL Loss                      0.25797874
QF Loss                      506.51138
VF Loss                      158.834
Policy Loss                  -3098.392
Q Predictions Mean           3088.353
Q Predictions Std            206.36331
Q Predictions Max            3214.7578
Q Predictions Min            28.27896
V Predictions Mean           3097.323
V Predictions Std            208.18483
V Predictions Max            3232.147
V Predictions Min            33.384182
Log Pis Mean                 -7.1251965
Log Pis Std                  3.9328985
Log Pis Max                  20.503736
Log Pis Min                  -15.737606
Policy mu Mean               0.16709468
Policy mu Std                0.5798252
Policy mu Max                2.5385303
Policy mu Min                -2.617294
Policy log std Mean          -0.2862684
Policy log std Std           0.12060245
Policy log std Max           -0.048199728
Policy log std Min           -0.906103
Z mean eval                  0.059186034
Z variance eval              0.16550031
total_rewards                [5543.81396072 3098.96055771 5518.08053365 5609.4697503  5452.14992701
 5593.99144086 5557.41323909 5581.37668711 5566.33176767 5471.71079305]
total_rewards_mean           5299.329865716978
total_rewards_std            735.0359323783159
total_rewards_max            5609.469750295635
total_rewards_min            3098.9605577117327
Number of train steps total  1712000
Number of env steps total    2142000
Number of rollouts total     0
Train Time (s)               194.6590885031037
(Previous) Eval Time (s)     21.79443048685789
Sample Time (s)              16.564175815787166
Epoch Time (s)               233.01769480574876
Total Train Time (s)         97420.67416609172
Epoch                        427
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:34:00.679261 UTC | [2020_01_13_04_30_18] Iteration #427 | Epoch Duration: 235.6495852470398
2020-01-14 07:34:00.679460 UTC | [2020_01_13_04_30_18] Iteration #427 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.058646314
Z variance train             0.16552825
KL Divergence                2.5243638
KL Loss                      0.25243637
QF Loss                      505.01114
VF Loss                      182.89043
Policy Loss                  -3103.607
Q Predictions Mean           3096.7974
Q Predictions Std            184.40009
Q Predictions Max            3216.987
Q Predictions Min            631.91675
V Predictions Mean           3107.5857
V Predictions Std            180.03148
V Predictions Max            3228.1763
V Predictions Min            596.057
Log Pis Mean                 -7.4279537
Log Pis Std                  3.532338
Log Pis Max                  9.755196
Log Pis Min                  -20.04095
Policy mu Mean               0.1485916
Policy mu Std                0.57564515
Policy mu Max                2.3545809
Policy mu Min                -2.3441384
Policy log std Mean          -0.27766302
Policy log std Std           0.12332792
Policy log std Max           -0.08007461
Policy log std Min           -1.0887438
Z mean eval                  0.047349248
Z variance eval              0.18347952
total_rewards                [5513.4177156  5768.51586715 5536.16665358 5519.80349235 5574.78800973
 5551.77470778 5663.72762676 5593.26632589 5582.86580476 5727.32700249]
total_rewards_mean           5603.165320609447
total_rewards_std            83.5904869672175
total_rewards_max            5768.515867146852
total_rewards_min            5513.4177156019
Number of train steps total  1716000
Number of env steps total    2147000
Number of rollouts total     0
Train Time (s)               194.23858970217407
(Previous) Eval Time (s)     24.42605650005862
Sample Time (s)              16.658693371806294
Epoch Time (s)               235.32333957403898
Total Train Time (s)         97655.47154994495
Epoch                        428
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:37:55.480602 UTC | [2020_01_13_04_30_18] Iteration #428 | Epoch Duration: 234.80098152160645
2020-01-14 07:37:55.480796 UTC | [2020_01_13_04_30_18] Iteration #428 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.047574155
Z variance train             0.1834558
KL Divergence                2.432334
KL Loss                      0.2432334
QF Loss                      954.12396
VF Loss                      147.78828
Policy Loss                  -3101.44
Q Predictions Mean           3098.669
Q Predictions Std            272.0403
Q Predictions Max            3222.3115
Q Predictions Min            24.514942
V Predictions Mean           3104.9272
V Predictions Std            270.57452
V Predictions Max            3224.13
V Predictions Min            37.404423
Log Pis Mean                 -7.220598
Log Pis Std                  3.4639196
Log Pis Max                  10.8740425
Log Pis Min                  -15.268595
Policy mu Mean               0.14137568
Policy mu Std                0.56579655
Policy mu Max                2.4365542
Policy mu Min                -2.5837686
Policy log std Mean          -0.27951884
Policy log std Std           0.117698096
Policy log std Max           -0.04977773
Policy log std Min           -1.0975226
Z mean eval                  0.054354955
Z variance eval              0.17101741
total_rewards                [5662.01315785 5628.62800685 5793.00157242 5656.96055531 5627.58065727
 5560.75320652 5580.75396031 5484.87856336 5658.95808029 5483.20569239]
total_rewards_mean           5613.673345258127
total_rewards_std            87.36762949041471
total_rewards_max            5793.001572423668
total_rewards_min            5483.205692392588
Number of train steps total  1720000
Number of env steps total    2152000
Number of rollouts total     0
Train Time (s)               192.50303881568834
(Previous) Eval Time (s)     23.903430575039238
Sample Time (s)              18.768122295849025
Epoch Time (s)               235.1745916865766
Total Train Time (s)         97893.31885849265
Epoch                        429
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:41:53.333564 UTC | [2020_01_13_04_30_18] Iteration #429 | Epoch Duration: 237.85262489318848
2020-01-14 07:41:53.333755 UTC | [2020_01_13_04_30_18] Iteration #429 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.054183416
Z variance train             0.17103249
KL Divergence                2.5277746
KL Loss                      0.25277746
QF Loss                      977.0149
VF Loss                      166.40755
Policy Loss                  -3094.2583
Q Predictions Mean           3091.502
Q Predictions Std            256.1223
Q Predictions Max            3210.6118
Q Predictions Min            29.45928
V Predictions Mean           3097.0967
V Predictions Std            257.8042
V Predictions Max            3231.4802
V Predictions Min            30.74372
Log Pis Mean                 -6.637453
Log Pis Std                  3.923126
Log Pis Max                  13.300299
Log Pis Min                  -16.465559
Policy mu Mean               0.15819354
Policy mu Std                0.6020163
Policy mu Max                2.3157008
Policy mu Min                -2.902659
Policy log std Mean          -0.29105777
Policy log std Std           0.13018031
Policy log std Max           -0.026893474
Policy log std Min           -1.0645566
Z mean eval                  0.04402532
Z variance eval              0.16592224
total_rewards                [5538.636493   5553.84997142 5640.0498775  5609.86618251 2670.58088136
 5459.3415724  5475.57676227 5530.06364226 5535.70988042 5592.42730299]
total_rewards_mean           5260.610256612319
total_rewards_std            864.9616539229319
total_rewards_max            5640.049877495054
total_rewards_min            2670.5808813568674
Number of train steps total  1724000
Number of env steps total    2157000
Number of rollouts total     0
Train Time (s)               200.2715081977658
(Previous) Eval Time (s)     26.58116335514933
Sample Time (s)              16.43128563882783
Epoch Time (s)               243.28395719174296
Total Train Time (s)         98135.19712824095
Epoch                        430
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:45:55.215830 UTC | [2020_01_13_04_30_18] Iteration #430 | Epoch Duration: 241.88193941116333
2020-01-14 07:45:55.216022 UTC | [2020_01_13_04_30_18] Iteration #430 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.044072803
Z variance train             0.16591412
KL Divergence                2.6038144
KL Loss                      0.26038143
QF Loss                      502.98175
VF Loss                      335.66956
Policy Loss                  -3077.7104
Q Predictions Mean           3068.1667
Q Predictions Std            331.6731
Q Predictions Max            3201.1042
Q Predictions Min            24.174088
V Predictions Mean           3078.4678
V Predictions Std            333.74652
V Predictions Max            3211.0317
V Predictions Min            -5.0632186
Log Pis Mean                 -7.0899057
Log Pis Std                  4.138326
Log Pis Max                  22.600204
Log Pis Min                  -16.80963
Policy mu Mean               0.19830933
Policy mu Std                0.569339
Policy mu Max                4.0708675
Policy mu Min                -2.543461
Policy log std Mean          -0.29043764
Policy log std Std           0.12815759
Policy log std Max           0.09214082
Policy log std Min           -1.2500483
Z mean eval                  0.06012668
Z variance eval              0.1564475
total_rewards                [5492.64211828 5404.51485351 5587.77895475 5474.68656608 5437.64523653
 5507.66868955 5576.30831451 5461.99492028 5461.7326361  5556.19661865]
total_rewards_mean           5496.116890823027
total_rewards_std            57.62239360818417
total_rewards_max            5587.778954747172
total_rewards_min            5404.514853505913
Number of train steps total  1728000
Number of env steps total    2162000
Number of rollouts total     0
Train Time (s)               195.97756938729435
(Previous) Eval Time (s)     25.17887416901067
Sample Time (s)              16.615141790360212
Epoch Time (s)               237.77158534666523
Total Train Time (s)         98371.4249137668
Epoch                        431
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:49:51.447988 UTC | [2020_01_13_04_30_18] Iteration #431 | Epoch Duration: 236.23182821273804
2020-01-14 07:49:51.448152 UTC | [2020_01_13_04_30_18] Iteration #431 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.059983533
Z variance train             0.15648696
KL Divergence                2.6053877
KL Loss                      0.2605388
QF Loss                      472.25513
VF Loss                      135.72826
Policy Loss                  -3104.979
Q Predictions Mean           3100.0405
Q Predictions Std            251.99352
Q Predictions Max            3239.2378
Q Predictions Min            27.57573
V Predictions Mean           3109.6768
V Predictions Std            251.9519
V Predictions Max            3251.6606
V Predictions Min            36.938168
Log Pis Mean                 -7.3366404
Log Pis Std                  3.4450006
Log Pis Max                  14.581388
Log Pis Min                  -14.119104
Policy mu Mean               0.1834782
Policy mu Std                0.55950034
Policy mu Max                2.2761521
Policy mu Min                -2.4043674
Policy log std Mean          -0.27577755
Policy log std Std           0.113561265
Policy log std Max           -0.0685883
Policy log std Min           -1.0757991
Z mean eval                  0.060920168
Z variance eval              0.15937716
total_rewards                [5554.63279401 2634.93668764 4912.98570905 5602.07484529 4503.88967113
 5600.80514289 5417.56854632 5553.07681879 5434.77095515 5723.70653962]
total_rewards_mean           5093.844770987329
total_rewards_std            893.4912354818501
total_rewards_max            5723.706539619691
total_rewards_min            2634.936687637727
Number of train steps total  1732000
Number of env steps total    2167000
Number of rollouts total     0
Train Time (s)               198.33020591223612
(Previous) Eval Time (s)     23.638859721831977
Sample Time (s)              18.737250094302
Epoch Time (s)               240.7063157283701
Total Train Time (s)         98613.31302362168
Epoch                        432
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 07:53:53.342428 UTC | [2020_01_13_04_30_18] Iteration #432 | Epoch Duration: 241.89414763450623
2020-01-14 07:53:53.342605 UTC | [2020_01_13_04_30_18] Iteration #432 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.061445408
Z variance train             0.15940043
KL Divergence                2.523665
KL Loss                      0.2523665
QF Loss                      569.5796
VF Loss                      126.71126
Policy Loss                  -3103.6216
Q Predictions Mean           3094.2769
Q Predictions Std            212.85847
Q Predictions Max            3214.2039
Q Predictions Min            25.639626
V Predictions Mean           3103.856
V Predictions Std            212.16693
V Predictions Max            3220.8574
V Predictions Min            34.413597
Log Pis Mean                 -7.5140667
Log Pis Std                  3.6081216
Log Pis Max                  20.364763
Log Pis Min                  -14.781367
Policy mu Mean               0.20702118
Policy mu Std                0.5320184
Policy mu Max                2.4860616
Policy mu Min                -2.7132096
Policy log std Mean          -0.27838966
Policy log std Std           0.116835415
Policy log std Max           -0.06295584
Policy log std Min           -1.0033221
Z mean eval                  0.048924424
Z variance eval              0.16866148
total_rewards                [5528.77803864 3403.99424616 5451.44822982 5449.8695331  5590.61244014
 5546.70776019 5562.20943103 2622.70627756 2187.58562457 5492.92869655]
total_rewards_mean           4683.684027776173
total_rewards_std            1303.857406859238
total_rewards_max            5590.612440140856
total_rewards_min            2187.585624568635
Number of train steps total  1736000
Number of env steps total    2172000
Number of rollouts total     0
Train Time (s)               605.098784469068
(Previous) Eval Time (s)     24.82640641508624
Sample Time (s)              19.260901870206
Epoch Time (s)               649.1860927543603
Total Train Time (s)         99262.16792357666
Epoch                        433
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 08:04:42.205924 UTC | [2020_01_13_04_30_18] Iteration #433 | Epoch Duration: 648.8632016181946
2020-01-14 08:04:42.206167 UTC | [2020_01_13_04_30_18] Iteration #433 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.048716236
Z variance train             0.1687931
KL Divergence                2.409492
KL Loss                      0.2409492
QF Loss                      428.86664
VF Loss                      153.86035
Policy Loss                  -3109.9153
Q Predictions Mean           3103.821
Q Predictions Std            181.54732
Q Predictions Max            3212.8303
Q Predictions Min            496.8135
V Predictions Mean           3108.1052
V Predictions Std            183.00085
V Predictions Max            3218.9136
V Predictions Min            518.35114
Log Pis Mean                 -6.7227707
Log Pis Std                  4.0559373
Log Pis Max                  12.046091
Log Pis Min                  -14.614028
Policy mu Mean               0.16806939
Policy mu Std                0.5843749
Policy mu Max                2.407212
Policy mu Min                -2.7041852
Policy log std Mean          -0.29699144
Policy log std Std           0.1268116
Policy log std Max           0.06655651
Policy log std Min           -1.0007043
Z mean eval                  0.059631772
Z variance eval              0.1729728
total_rewards                [1624.50647971 5485.18901234  582.81515115 5531.35209949 5439.17936349
 5540.81757507 5499.55068114 3786.04413971 5517.84611701 4956.38228676]
total_rewards_mean           4396.368290585902
total_rewards_std            1739.487812607732
total_rewards_max            5540.817575074693
total_rewards_min            582.8151511462966
Number of train steps total  1740000
Number of env steps total    2177000
Number of rollouts total     0
Train Time (s)               682.0788456052542
(Previous) Eval Time (s)     24.503188902977854
Sample Time (s)              21.286989737767726
Epoch Time (s)               727.8690242459998
Total Train Time (s)         99988.04211213812
Epoch                        434
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 08:16:48.089221 UTC | [2020_01_13_04_30_18] Iteration #434 | Epoch Duration: 725.8829290866852
2020-01-14 08:16:48.089374 UTC | [2020_01_13_04_30_18] Iteration #434 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.059690017
Z variance train             0.17302015
KL Divergence                2.3593845
KL Loss                      0.23593846
QF Loss                      918.087
VF Loss                      253.32321
Policy Loss                  -3113.9946
Q Predictions Mean           3106.83
Q Predictions Std            214.12717
Q Predictions Max            3226.1711
Q Predictions Min            22.681377
V Predictions Mean           3106.9395
V Predictions Std            215.95534
V Predictions Max            3220.35
V Predictions Min            31.006763
Log Pis Mean                 -6.940093
Log Pis Std                  3.74917
Log Pis Max                  11.37361
Log Pis Min                  -15.284918
Policy mu Mean               0.18320699
Policy mu Std                0.56447273
Policy mu Max                2.7432938
Policy mu Min                -2.1664615
Policy log std Mean          -0.26859242
Policy log std Std           0.1207478
Policy log std Max           -0.03479486
Policy log std Min           -1.0179278
Z mean eval                  0.0448002
Z variance eval              0.15994626
total_rewards                [5327.81615797 5398.32311268 5361.70531831 5456.41643054 2135.28917524
 5276.01645857 1759.86858857 5460.18002201 5483.70842127 5293.35704112]
total_rewards_mean           4695.26807262836
total_rewards_std            1378.0297005703383
total_rewards_max            5483.708421265857
total_rewards_min            1759.8685885730536
Number of train steps total  1744000
Number of env steps total    2182000
Number of rollouts total     0
Train Time (s)               675.8066120697185
(Previous) Eval Time (s)     22.51681572990492
Sample Time (s)              23.700426570605487
Epoch Time (s)               722.023854370229
Total Train Time (s)         100713.43280501245
Epoch                        435
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 08:28:53.487775 UTC | [2020_01_13_04_30_18] Iteration #435 | Epoch Duration: 725.3982815742493
2020-01-14 08:28:53.487938 UTC | [2020_01_13_04_30_18] Iteration #435 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0448142
Z variance train             0.15994048
KL Divergence                2.5163856
KL Loss                      0.25163856
QF Loss                      665.5757
VF Loss                      99.75264
Policy Loss                  -3116.061
Q Predictions Mean           3113.2954
Q Predictions Std            207.385
Q Predictions Max            3228.7695
Q Predictions Min            41.256367
V Predictions Mean           3119.7573
V Predictions Std            209.10274
V Predictions Max            3235.769
V Predictions Min            41.91695
Log Pis Mean                 -7.0311174
Log Pis Std                  3.4476779
Log Pis Max                  6.3539133
Log Pis Min                  -17.688553
Policy mu Mean               0.17396688
Policy mu Std                0.5782569
Policy mu Max                2.3819602
Policy mu Min                -2.1277294
Policy log std Mean          -0.28231603
Policy log std Std           0.12109098
Policy log std Max           -0.07177825
Policy log std Min           -1.1434166
Z mean eval                  0.044775307
Z variance eval              0.1710549
total_rewards                [5567.68090196 5444.74732956 5594.40866959 5396.18806024 5495.48599284
 5492.98326943 5483.1205638  5452.18631964 5418.42299432 5330.52806783]
total_rewards_mean           5467.57521692011
total_rewards_std            74.04460145724491
total_rewards_max            5594.408669591994
total_rewards_min            5330.5280678277295
Number of train steps total  1748000
Number of env steps total    2187000
Number of rollouts total     0
Train Time (s)               688.4930272768252
(Previous) Eval Time (s)     25.89094805298373
Sample Time (s)              20.80196258984506
Epoch Time (s)               735.185937919654
Total Train Time (s)         101458.45188538684
Epoch                        436
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 08:41:18.517409 UTC | [2020_01_13_04_30_18] Iteration #436 | Epoch Duration: 745.0292291641235
2020-01-14 08:41:18.517754 UTC | [2020_01_13_04_30_18] Iteration #436 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045139976
Z variance train             0.17109993
KL Divergence                2.3818326
KL Loss                      0.23818326
QF Loss                      547.79474
VF Loss                      148.63397
Policy Loss                  -3110.834
Q Predictions Mean           3103.2578
Q Predictions Std            241.41763
Q Predictions Max            3213.8523
Q Predictions Min            319.58896
V Predictions Mean           3110.259
V Predictions Std            241.60698
V Predictions Max            3222.6465
V Predictions Min            294.53873
Log Pis Mean                 -6.820875
Log Pis Std                  4.1774416
Log Pis Max                  30.52124
Log Pis Min                  -16.248264
Policy mu Mean               0.1948668
Policy mu Std                0.58130884
Policy mu Max                2.9355586
Policy mu Min                -2.5918558
Policy log std Mean          -0.290213
Policy log std Std           0.13210359
Policy log std Max           -0.060415715
Policy log std Min           -1.3048614
Z mean eval                  0.045915384
Z variance eval              0.15362449
total_rewards                [5563.53928526 5604.4370738  5665.01258524 5623.23142075 5610.47717649
 5554.54408306 5632.49816739 5260.45816749 1992.15509966 5548.92419898]
total_rewards_mean           5205.5277258125625
total_rewards_std            1076.4620762640855
total_rewards_max            5665.012585244441
total_rewards_min            1992.1550996599706
Number of train steps total  1752000
Number of env steps total    2192000
Number of rollouts total     0
Train Time (s)               572.5086086001247
(Previous) Eval Time (s)     35.73391602514312
Sample Time (s)              20.374015238136053
Epoch Time (s)               628.6165398634039
Total Train Time (s)         102076.11978575401
Epoch                        437
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 08:51:36.192649 UTC | [2020_01_13_04_30_18] Iteration #437 | Epoch Duration: 617.6746690273285
2020-01-14 08:51:36.192831 UTC | [2020_01_13_04_30_18] Iteration #437 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0458815
Z variance train             0.15362878
KL Divergence                2.5786276
KL Loss                      0.25786278
QF Loss                      678.4451
VF Loss                      384.4275
Policy Loss                  -3105.6572
Q Predictions Mean           3099.8813
Q Predictions Std            214.00381
Q Predictions Max            3218.7996
Q Predictions Min            32.40876
V Predictions Mean           3111.7966
V Predictions Std            214.81091
V Predictions Max            3230.8452
V Predictions Min            45.084705
Log Pis Mean                 -6.4864626
Log Pis Std                  4.2661633
Log Pis Max                  20.184437
Log Pis Min                  -16.935799
Policy mu Mean               0.16927063
Policy mu Std                0.61021566
Policy mu Max                3.7056725
Policy mu Min                -2.4336255
Policy log std Mean          -0.291792
Policy log std Std           0.13087274
Policy log std Max           -0.072831705
Policy log std Min           -1.2665591
Z mean eval                  0.029859994
Z variance eval              0.15820827
total_rewards                [5673.72320507 5591.36039453 5570.71428182 1102.94393759 2223.45002481
 5673.47712816 5653.67809031 5513.68754504 5602.63768228 5620.22936141]
total_rewards_mean           4822.590165102264
total_rewards_std            1600.1079996836731
total_rewards_max            5673.723205072663
total_rewards_min            1102.9439375903796
Number of train steps total  1756000
Number of env steps total    2197000
Number of rollouts total     0
Train Time (s)               196.3230926799588
(Previous) Eval Time (s)     24.791743166279048
Sample Time (s)              18.784025271888822
Epoch Time (s)               239.89886111812666
Total Train Time (s)         102314.18284222716
Epoch                        438
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 08:55:34.258725 UTC | [2020_01_13_04_30_18] Iteration #438 | Epoch Duration: 238.0657982826233
2020-01-14 08:55:34.258852 UTC | [2020_01_13_04_30_18] Iteration #438 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029919421
Z variance train             0.1581665
KL Divergence                2.515226
KL Loss                      0.2515226
QF Loss                      981.6637
VF Loss                      156.26279
Policy Loss                  -3106.94
Q Predictions Mean           3101.962
Q Predictions Std            239.99269
Q Predictions Max            3239.6096
Q Predictions Min            601.69086
V Predictions Mean           3101.979
V Predictions Std            242.45253
V Predictions Max            3237.1113
V Predictions Min            629.5517
Log Pis Mean                 -6.880611
Log Pis Std                  3.8698723
Log Pis Max                  12.547354
Log Pis Min                  -14.742155
Policy mu Mean               0.2221073
Policy mu Std                0.5733669
Policy mu Max                2.3864245
Policy mu Min                -2.6425452
Policy log std Mean          -0.29497173
Policy log std Std           0.13240258
Policy log std Max           -0.031113766
Policy log std Min           -1.2278938
Z mean eval                  0.059577513
Z variance eval              0.14619802
total_rewards                [5687.44339515 5736.57145269 5642.23912847 1751.86699241 5605.91278061
 4994.52543237 2565.84668587  950.73764173 5592.99437402 5583.35267936]
total_rewards_mean           4411.149056268202
total_rewards_std            1785.8116269019333
total_rewards_max            5736.571452690497
total_rewards_min            950.7376417323579
Number of train steps total  1760000
Number of env steps total    2202000
Number of rollouts total     0
Train Time (s)               198.40442946599796
(Previous) Eval Time (s)     22.958417968824506
Sample Time (s)              18.778324015438557
Epoch Time (s)               240.14117145026103
Total Train Time (s)         102552.24768735887
Epoch                        439
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 08:59:32.330291 UTC | [2020_01_13_04_30_18] Iteration #439 | Epoch Duration: 238.07133603096008
2020-01-14 08:59:32.330459 UTC | [2020_01_13_04_30_18] Iteration #439 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.059434593
Z variance train             0.14622003
KL Divergence                2.687543
KL Loss                      0.2687543
QF Loss                      576.3488
VF Loss                      99.30995
Policy Loss                  -3109.668
Q Predictions Mean           3108.563
Q Predictions Std            313.20364
Q Predictions Max            3230.5554
Q Predictions Min            5.6267614
V Predictions Mean           3109.3745
V Predictions Std            312.0583
V Predictions Max            3241.4287
V Predictions Min            29.602638
Log Pis Mean                 -7.584917
Log Pis Std                  3.403145
Log Pis Max                  14.749437
Log Pis Min                  -14.8652725
Policy mu Mean               0.22644699
Policy mu Std                0.5293076
Policy mu Max                2.6855757
Policy mu Min                -2.3315003
Policy log std Mean          -0.27224872
Policy log std Std           0.117119916
Policy log std Max           -0.069632016
Policy log std Min           -0.90360284
Z mean eval                  0.050667614
Z variance eval              0.13273121
total_rewards                [5586.81621984 5583.0644455  3837.20234342 5482.37434326 5472.09278446
 5602.57806011 5474.64632561 5594.84014469 5589.54018294 5607.20585556]
total_rewards_mean           5383.0360705399125
total_rewards_std            518.0045302364246
total_rewards_max            5607.205855558129
total_rewards_min            3837.202343422637
Number of train steps total  1764000
Number of env steps total    2207000
Number of rollouts total     0
Train Time (s)               195.61114984285086
(Previous) Eval Time (s)     20.88826945098117
Sample Time (s)              18.121570287272334
Epoch Time (s)               234.62098958110437
Total Train Time (s)         102790.89535266487
Epoch                        440
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:03:30.985037 UTC | [2020_01_13_04_30_18] Iteration #440 | Epoch Duration: 238.65443086624146
2020-01-14 09:03:30.985235 UTC | [2020_01_13_04_30_18] Iteration #440 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.050392263
Z variance train             0.13267383
KL Divergence                2.9509702
KL Loss                      0.29509702
QF Loss                      710.7748
VF Loss                      202.37816
Policy Loss                  -3115.6978
Q Predictions Mean           3109.8706
Q Predictions Std            187.74753
Q Predictions Max            3213.4905
Q Predictions Min            748.74457
V Predictions Mean           3117.7844
V Predictions Std            190.73972
V Predictions Max            3223.606
V Predictions Min            735.9093
Log Pis Mean                 -6.3347898
Log Pis Std                  4.8861604
Log Pis Max                  26.415987
Log Pis Min                  -12.989037
Policy mu Mean               0.17702268
Policy mu Std                0.60314494
Policy mu Max                2.85095
Policy mu Min                -2.8753579
Policy log std Mean          -0.2948693
Policy log std Std           0.13130862
Policy log std Max           -0.08552193
Policy log std Min           -1.2703156
Z mean eval                  0.04048329
Z variance eval              0.13074622
total_rewards                [5592.62867517 5591.19280966 1851.48676109 5212.77153865 1866.5187902
 4466.21126083 5625.92370494 5553.90864795 5549.11939583 5261.89759664]
total_rewards_mean           4657.165918093468
total_rewards_std            1437.2239073234973
total_rewards_max            5625.92370493539
total_rewards_min            1851.4867610875144
Number of train steps total  1768000
Number of env steps total    2212000
Number of rollouts total     0
Train Time (s)               191.69370532408357
(Previous) Eval Time (s)     24.92127688601613
Sample Time (s)              17.15053092641756
Epoch Time (s)               233.76551313651726
Total Train Time (s)         103022.03405454336
Epoch                        441
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:07:22.133028 UTC | [2020_01_13_04_30_18] Iteration #441 | Epoch Duration: 231.14755034446716
2020-01-14 09:07:22.133303 UTC | [2020_01_13_04_30_18] Iteration #441 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04055924
Z variance train             0.13071941
KL Divergence                2.946148
KL Loss                      0.2946148
QF Loss                      1274.8899
VF Loss                      507.85248
Policy Loss                  -3104.3975
Q Predictions Mean           3097.2102
Q Predictions Std            279.5898
Q Predictions Max            3222.5771
Q Predictions Min            29.587692
V Predictions Mean           3102.588
V Predictions Std            279.48987
V Predictions Max            3227.3687
V Predictions Min            32.969078
Log Pis Mean                 -6.6511564
Log Pis Std                  4.0330496
Log Pis Max                  17.266813
Log Pis Min                  -17.289673
Policy mu Mean               0.23033422
Policy mu Std                0.59496677
Policy mu Max                2.4451182
Policy mu Min                -2.1573288
Policy log std Mean          -0.2965046
Policy log std Std           0.1326593
Policy log std Max           -0.06735201
Policy log std Min           -1.3844662
Z mean eval                  0.034565885
Z variance eval              0.13924
total_rewards                [3340.61957818 4765.32715175 5531.23419784 5610.83167456 5419.68972629
 5506.17114715 5696.25639217 5692.12896552 5683.78472649 5535.53226699]
total_rewards_mean           5278.157582695994
total_rewards_std            695.7545512459229
total_rewards_max            5696.25639217219
total_rewards_min            3340.619578184484
Number of train steps total  1772000
Number of env steps total    2217000
Number of rollouts total     0
Train Time (s)               189.1632601940073
(Previous) Eval Time (s)     22.302943584043533
Sample Time (s)              19.092528665903956
Epoch Time (s)               230.5587324439548
Total Train Time (s)         103252.45437676599
Epoch                        442
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:11:12.557274 UTC | [2020_01_13_04_30_18] Iteration #442 | Epoch Duration: 230.4237940311432
2020-01-14 09:11:12.557466 UTC | [2020_01_13_04_30_18] Iteration #442 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034509584
Z variance train             0.13915324
KL Divergence                2.875757
KL Loss                      0.2875757
QF Loss                      710.76434
VF Loss                      845.41003
Policy Loss                  -3129.48
Q Predictions Mean           3121.5513
Q Predictions Std            132.97838
Q Predictions Max            3226.61
Q Predictions Min            1308.1587
V Predictions Mean           3125.981
V Predictions Std            121.24182
V Predictions Max            3245.2769
V Predictions Min            1673.0936
Log Pis Mean                 -6.8647265
Log Pis Std                  3.9952075
Log Pis Max                  16.995129
Log Pis Min                  -17.638206
Policy mu Mean               0.17235737
Policy mu Std                0.5808
Policy mu Max                2.1378155
Policy mu Min                -2.5119874
Policy log std Mean          -0.28840134
Policy log std Std           0.12581007
Policy log std Max           -0.008890137
Policy log std Min           -1.0244935
Z mean eval                  0.050537515
Z variance eval              0.13028258
total_rewards                [5513.69512793 5585.93519319 5704.62946108 5599.55792863 4257.95508474
 5648.87578754 5572.42459119 5497.11371739 5629.64744596 3040.59796567]
total_rewards_mean           5205.043230331501
total_rewards_std            826.1308916951384
total_rewards_max            5704.629461081228
total_rewards_min            3040.597965665192
Number of train steps total  1776000
Number of env steps total    2222000
Number of rollouts total     0
Train Time (s)               192.20325905596837
(Previous) Eval Time (s)     22.167641006875783
Sample Time (s)              17.275775189045817
Epoch Time (s)               231.64667525188997
Total Train Time (s)         103486.58137701917
Epoch                        443
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:15:06.690840 UTC | [2020_01_13_04_30_18] Iteration #443 | Epoch Duration: 234.1331822872162
2020-01-14 09:15:06.691075 UTC | [2020_01_13_04_30_18] Iteration #443 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.049885307
Z variance train             0.13027957
KL Divergence                3.0151534
KL Loss                      0.30151534
QF Loss                      596.14343
VF Loss                      136.64017
Policy Loss                  -3116.1968
Q Predictions Mean           3115.666
Q Predictions Std            213.99292
Q Predictions Max            3230.1758
Q Predictions Min            25.968105
V Predictions Mean           3121.4363
V Predictions Std            212.70453
V Predictions Max            3235.6797
V Predictions Min            22.868212
Log Pis Mean                 -6.957529
Log Pis Std                  3.707174
Log Pis Max                  8.068537
Log Pis Min                  -14.145561
Policy mu Mean               0.19571142
Policy mu Std                0.5948217
Policy mu Max                2.52878
Policy mu Min                -2.5022535
Policy log std Mean          -0.2939525
Policy log std Std           0.12969531
Policy log std Max           -0.066518165
Policy log std Min           -1.1177238
Z mean eval                  0.034233935
Z variance eval              0.11597721
total_rewards                [5492.47772419 5478.35726876 5443.78152673 5479.99215638 5494.93785622
 5510.05708343 5478.68335194 5327.79857153 5425.04444877 4498.33078014]
total_rewards_mean           5362.946076810644
total_rewards_std            292.4794192296425
total_rewards_max            5510.057083434492
total_rewards_min            4498.3307801393385
Number of train steps total  1780000
Number of env steps total    2227000
Number of rollouts total     0
Train Time (s)               191.50955565739423
(Previous) Eval Time (s)     24.653870025184005
Sample Time (s)              18.66425213171169
Epoch Time (s)               234.82767781428993
Total Train Time (s)         103722.28677008767
Epoch                        444
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:19:02.403205 UTC | [2020_01_13_04_30_18] Iteration #444 | Epoch Duration: 235.71199917793274
2020-01-14 09:19:02.403396 UTC | [2020_01_13_04_30_18] Iteration #444 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034148626
Z variance train             0.11597165
KL Divergence                3.246735
KL Loss                      0.3246735
QF Loss                      916.8013
VF Loss                      277.17374
Policy Loss                  -3086.9504
Q Predictions Mean           3077.6816
Q Predictions Std            325.94482
Q Predictions Max            3208.715
Q Predictions Min            19.955765
V Predictions Mean           3085.7095
V Predictions Std            324.4176
V Predictions Max            3214.634
V Predictions Min            33.850307
Log Pis Mean                 -6.526535
Log Pis Std                  5.0144997
Log Pis Max                  30.894564
Log Pis Min                  -15.419683
Policy mu Mean               0.15016472
Policy mu Std                0.61366314
Policy mu Max                2.935147
Policy mu Min                -4.843475
Policy log std Mean          -0.2956134
Policy log std Std           0.13845338
Policy log std Max           -0.06761976
Policy log std Min           -1.3673701
Z mean eval                  0.0558199
Z variance eval              0.11778976
total_rewards                [5733.53318026 5569.30934905 5702.60744954 5632.94256972 5637.3226949
 1930.4672596  5624.91782553 3493.55412778 5599.03276586 5608.3489175 ]
total_rewards_mean           5053.203613973238
total_rewards_std            1222.5053340246636
total_rewards_max            5733.533180256399
total_rewards_min            1930.4672595957275
Number of train steps total  1784000
Number of env steps total    2232000
Number of rollouts total     0
Train Time (s)               189.31980809103698
(Previous) Eval Time (s)     25.537912256084383
Sample Time (s)              18.736849814187735
Epoch Time (s)               233.5945701613091
Total Train Time (s)         103952.58349531423
Epoch                        445
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:22:52.704546 UTC | [2020_01_13_04_30_18] Iteration #445 | Epoch Duration: 230.3010070323944
2020-01-14 09:22:52.704748 UTC | [2020_01_13_04_30_18] Iteration #445 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05597026
Z variance train             0.117717884
KL Divergence                3.2306771
KL Loss                      0.32306772
QF Loss                      777.5028
VF Loss                      263.06116
Policy Loss                  -3115.122
Q Predictions Mean           3115.3413
Q Predictions Std            214.46823
Q Predictions Max            3226.5444
Q Predictions Min            574.39105
V Predictions Mean           3123.0435
V Predictions Std            210.97353
V Predictions Max            3237.6162
V Predictions Min            679.9004
Log Pis Mean                 -6.391302
Log Pis Std                  4.498273
Log Pis Max                  27.883121
Log Pis Min                  -15.703867
Policy mu Mean               0.18891932
Policy mu Std                0.6114041
Policy mu Max                2.8418376
Policy mu Min                -4.496201
Policy log std Mean          -0.29569125
Policy log std Std           0.13048935
Policy log std Max           -0.05988252
Policy log std Min           -1.2559367
Z mean eval                  0.042322867
Z variance eval              0.11666063
total_rewards                [5593.18017194 5605.8334356  5611.30351458 5678.02324689 5585.56103675
 5505.94908099 5687.17829062 3658.7043813  5561.92345062 5550.08756595]
total_rewards_mean           5403.77441752374
total_rewards_std            583.9927234630242
total_rewards_max            5687.178290620065
total_rewards_min            3658.704381303843
Number of train steps total  1788000
Number of env steps total    2237000
Number of rollouts total     0
Train Time (s)               197.04712998587638
(Previous) Eval Time (s)     22.244079067837447
Sample Time (s)              18.195551631506532
Epoch Time (s)               237.48676068522036
Total Train Time (s)         104192.24278602796
Epoch                        446
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:26:52.370490 UTC | [2020_01_13_04_30_18] Iteration #446 | Epoch Duration: 239.6656141281128
2020-01-14 09:26:52.370643 UTC | [2020_01_13_04_30_18] Iteration #446 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.042726222
Z variance train             0.116656765
KL Divergence                3.250915
KL Loss                      0.3250915
QF Loss                      833.0741
VF Loss                      187.22083
Policy Loss                  -3111.9744
Q Predictions Mean           3106.7556
Q Predictions Std            222.70418
Q Predictions Max            3221.8135
Q Predictions Min            31.382444
V Predictions Mean           3111.1501
V Predictions Std            217.61754
V Predictions Max            3236.36
V Predictions Min            32.006508
Log Pis Mean                 -6.6463823
Log Pis Std                  4.572489
Log Pis Max                  28.265676
Log Pis Min                  -18.10743
Policy mu Mean               0.19145675
Policy mu Std                0.60181487
Policy mu Max                2.694634
Policy mu Min                -3.3675795
Policy log std Mean          -0.3054261
Policy log std Std           0.13417676
Policy log std Max           -0.06758443
Policy log std Min           -1.170346
Z mean eval                  0.059429385
Z variance eval              0.114238
total_rewards                [5520.55126142 5445.99894165 2220.22697763 5325.26257621 5541.72042281
 5552.13456895 5557.29956267 5522.23533139 5523.16875083 5556.9452663 ]
total_rewards_mean           5176.55436598716
total_rewards_std            987.7564347406649
total_rewards_max            5557.299562673685
total_rewards_min            2220.226977633651
Number of train steps total  1792000
Number of env steps total    2242000
Number of rollouts total     0
Train Time (s)               199.4676183508709
(Previous) Eval Time (s)     24.42264887597412
Sample Time (s)              16.5043961298652
Epoch Time (s)               240.39466335671023
Total Train Time (s)         104433.11438574316
Epoch                        447
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:30:53.249492 UTC | [2020_01_13_04_30_18] Iteration #447 | Epoch Duration: 240.87872505187988
2020-01-14 09:30:53.249673 UTC | [2020_01_13_04_30_18] Iteration #447 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.059444845
Z variance train             0.114282474
KL Divergence                3.2562292
KL Loss                      0.32562292
QF Loss                      579.91345
VF Loss                      104.40801
Policy Loss                  -3115.393
Q Predictions Mean           3108.9487
Q Predictions Std            281.38007
Q Predictions Max            3225.1665
Q Predictions Min            23.909353
V Predictions Mean           3112.5757
V Predictions Std            281.53445
V Predictions Max            3236.9768
V Predictions Min            29.719795
Log Pis Mean                 -6.9429054
Log Pis Std                  4.0132885
Log Pis Max                  11.099163
Log Pis Min                  -15.342937
Policy mu Mean               0.18115063
Policy mu Std                0.5854827
Policy mu Max                2.7768831
Policy mu Min                -2.4336054
Policy log std Mean          -0.2944723
Policy log std Std           0.122497365
Policy log std Max           -0.06394212
Policy log std Min           -0.9459272
Z mean eval                  0.029469112
Z variance eval              0.13975492
total_rewards                [5669.61911108 5620.0013957  5631.59383851 5475.45126361 5682.66021295
 4317.41820562 5679.47880727 5671.77020555 3186.30561666 5519.20839746]
total_rewards_mean           5245.350705440713
total_rewards_std            791.1864941980643
total_rewards_max            5682.660212954807
total_rewards_min            3186.305616661474
Number of train steps total  1796000
Number of env steps total    2247000
Number of rollouts total     0
Train Time (s)               198.91983442706987
(Previous) Eval Time (s)     24.90642465883866
Sample Time (s)              18.721140073612332
Epoch Time (s)               242.54739915952086
Total Train Time (s)         104675.2226349935
Epoch                        448
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:34:55.360537 UTC | [2020_01_13_04_30_18] Iteration #448 | Epoch Duration: 242.1107439994812
2020-01-14 09:34:55.360691 UTC | [2020_01_13_04_30_18] Iteration #448 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029490668
Z variance train             0.13973303
KL Divergence                2.8213813
KL Loss                      0.28213814
QF Loss                      643.2206
VF Loss                      112.8535
Policy Loss                  -3120.029
Q Predictions Mean           3111.7522
Q Predictions Std            204.83379
Q Predictions Max            3222.5242
Q Predictions Min            25.543612
V Predictions Mean           3121.0735
V Predictions Std            206.72073
V Predictions Max            3231.8184
V Predictions Min            34.852238
Log Pis Mean                 -7.008212
Log Pis Std                  3.1902297
Log Pis Max                  5.2835984
Log Pis Min                  -15.429047
Policy mu Mean               0.19172259
Policy mu Std                0.56240815
Policy mu Max                2.1917706
Policy mu Min                -1.8183978
Policy log std Mean          -0.2874497
Policy log std Std           0.11859577
Policy log std Max           0.30499992
Policy log std Min           -0.8749298
Z mean eval                  0.030106803
Z variance eval              0.1408654
total_rewards                [5473.29997916 5607.02457981 3493.73572336 5590.58143431 5591.87380429
 5533.43115934 5609.81812955 5430.52091495 5594.55124763 5553.50833584]
total_rewards_mean           5347.83453082504
total_rewards_std            620.6588498732442
total_rewards_max            5609.818129547214
total_rewards_min            3493.735723361645
Number of train steps total  1800000
Number of env steps total    2252000
Number of rollouts total     0
Train Time (s)               198.16068378277123
(Previous) Eval Time (s)     24.469484875909984
Sample Time (s)              18.576921154744923
Epoch Time (s)               241.20708981342614
Total Train Time (s)         104914.16903290199
Epoch                        449
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:38:54.315564 UTC | [2020_01_13_04_30_18] Iteration #449 | Epoch Duration: 238.95472383499146
2020-01-14 09:38:54.315920 UTC | [2020_01_13_04_30_18] Iteration #449 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030198103
Z variance train             0.14094275
KL Divergence                2.7769485
KL Loss                      0.27769485
QF Loss                      658.0793
VF Loss                      136.47064
Policy Loss                  -3120.2397
Q Predictions Mean           3116.0908
Q Predictions Std            237.62308
Q Predictions Max            3256.3455
Q Predictions Min            604.0843
V Predictions Mean           3124.013
V Predictions Std            235.82294
V Predictions Max            3250.2837
V Predictions Min            611.7928
Log Pis Mean                 -7.0009294
Log Pis Std                  3.566858
Log Pis Max                  12.186964
Log Pis Min                  -15.894945
Policy mu Mean               0.15802658
Policy mu Std                0.58491766
Policy mu Max                2.2742028
Policy mu Min                -3.4931805
Policy log std Mean          -0.2894698
Policy log std Std           0.12891047
Policy log std Max           0.015518323
Policy log std Min           -1.3318689
Z mean eval                  0.064062394
Z variance eval              0.13405302
total_rewards                [5730.94619115 5497.83755822 5747.15513898 5670.90977829 5738.96620412
 5684.95995224 5769.18041819 4594.80414641 5705.4807783  4800.64082742]
total_rewards_mean           5494.088099332673
total_rewards_std            407.15665200965657
total_rewards_max            5769.180418194297
total_rewards_min            4594.804146413823
Number of train steps total  1804000
Number of env steps total    2257000
Number of rollouts total     0
Train Time (s)               196.8883703961037
(Previous) Eval Time (s)     22.21679610805586
Sample Time (s)              18.955172165762633
Epoch Time (s)               238.0603386699222
Total Train Time (s)         105155.52438330138
Epoch                        450
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:42:55.677104 UTC | [2020_01_13_04_30_18] Iteration #450 | Epoch Duration: 241.3609185218811
2020-01-14 09:42:55.677297 UTC | [2020_01_13_04_30_18] Iteration #450 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06416274
Z variance train             0.13408466
KL Divergence                2.976619
KL Loss                      0.2976619
QF Loss                      463.3154
VF Loss                      115.653595
Policy Loss                  -3135.8828
Q Predictions Mean           3129.0693
Q Predictions Std            207.59084
Q Predictions Max            3232.332
Q Predictions Min            13.190457
V Predictions Mean           3138.6719
V Predictions Std            209.91563
V Predictions Max            3242.057
V Predictions Min            17.470835
Log Pis Mean                 -7.039008
Log Pis Std                  3.407705
Log Pis Max                  17.518543
Log Pis Min                  -15.720055
Policy mu Mean               0.16642895
Policy mu Std                0.57102007
Policy mu Max                2.583125
Policy mu Min                -2.724627
Policy log std Mean          -0.27663466
Policy log std Std           0.12816873
Policy log std Max           0.0015445948
Policy log std Min           -1.2386034
Z mean eval                  0.064983055
Z variance eval              0.13893501
total_rewards                [5747.57532116 5614.73913444 5665.19413762 5657.20501421 5620.29277355
 5721.43083283 1437.85051058 5733.04532043 5707.74377338 5571.17886391]
total_rewards_mean           5247.62556821143
total_rewards_std            1271.0872140374358
total_rewards_max            5747.575321160512
total_rewards_min            1437.8505105834206
Number of train steps total  1808000
Number of env steps total    2262000
Number of rollouts total     0
Train Time (s)               195.10289501817897
(Previous) Eval Time (s)     25.517104079015553
Sample Time (s)              18.66650652838871
Epoch Time (s)               239.28650562558323
Total Train Time (s)         105394.01130782394
Epoch                        451
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:46:54.166837 UTC | [2020_01_13_04_30_18] Iteration #451 | Epoch Duration: 238.48941159248352
2020-01-14 09:46:54.166977 UTC | [2020_01_13_04_30_18] Iteration #451 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.064128
Z variance train             0.13898769
KL Divergence                2.9290795
KL Loss                      0.29290795
QF Loss                      435.714
VF Loss                      84.210495
Policy Loss                  -3126.789
Q Predictions Mean           3125.4194
Q Predictions Std            228.77823
Q Predictions Max            3230.8
Q Predictions Min            30.888193
V Predictions Mean           3129.0474
V Predictions Std            228.89601
V Predictions Max            3237.5723
V Predictions Min            37.16929
Log Pis Mean                 -7.0037174
Log Pis Std                  4.396793
Log Pis Max                  19.369192
Log Pis Min                  -15.746558
Policy mu Mean               0.17637308
Policy mu Std                0.5824083
Policy mu Max                2.7271354
Policy mu Min                -2.634344
Policy log std Mean          -0.28764144
Policy log std Std           0.12383837
Policy log std Max           -0.059647754
Policy log std Min           -1.0399053
Z mean eval                  0.03353218
Z variance eval              0.14630541
total_rewards                [1933.90247313 5519.79799725 5647.63030972 5570.39889087 3375.44944807
 5627.66394408 5678.6016613  5700.39612833 5471.61431541 5650.93410111]
total_rewards_mean           5017.63892692733
total_rewards_std            1226.5043553885957
total_rewards_max            5700.396128331112
total_rewards_min            1933.9024731254715
Number of train steps total  1812000
Number of env steps total    2267000
Number of rollouts total     0
Train Time (s)               200.10613286681473
(Previous) Eval Time (s)     24.719719380605966
Sample Time (s)              18.9550977521576
Epoch Time (s)               243.7809499995783
Total Train Time (s)         105636.86406424455
Epoch                        452
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:50:57.025873 UTC | [2020_01_13_04_30_18] Iteration #452 | Epoch Duration: 242.85879063606262
2020-01-14 09:50:57.026042 UTC | [2020_01_13_04_30_18] Iteration #452 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033456214
Z variance train             0.1463383
KL Divergence                2.7615206
KL Loss                      0.27615207
QF Loss                      620.7237
VF Loss                      154.24017
Policy Loss                  -3091.655
Q Predictions Mean           3085.9905
Q Predictions Std            413.1972
Q Predictions Max            3231.2585
Q Predictions Min            21.191603
V Predictions Mean           3090.0332
V Predictions Std            415.31384
V Predictions Max            3234.0293
V Predictions Min            27.962765
Log Pis Mean                 -6.737371
Log Pis Std                  4.043429
Log Pis Max                  24.195251
Log Pis Min                  -14.89184
Policy mu Mean               0.17752804
Policy mu Std                0.60086733
Policy mu Max                2.864921
Policy mu Min                -4.093985
Policy log std Mean          -0.28111047
Policy log std Std           0.12176122
Policy log std Max           -0.0727559
Policy log std Min           -1.024992
Z mean eval                  0.053770013
Z variance eval              0.14006793
total_rewards                [5682.62421853 5596.23298028 3111.89607729 5664.73849522 4498.04091867
 5623.56601516 5606.25740378 5676.82917964 5567.53894146 5595.91384859]
total_rewards_mean           5262.363807862136
total_rewards_std            792.6911530594801
total_rewards_max            5682.624218532041
total_rewards_min            3111.8960772888654
Number of train steps total  1816000
Number of env steps total    2272000
Number of rollouts total     0
Train Time (s)               198.11320949392393
(Previous) Eval Time (s)     23.797292825765908
Sample Time (s)              18.70749593898654
Epoch Time (s)               240.61799825867638
Total Train Time (s)         105878.4451723923
Epoch                        453
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:54:58.610580 UTC | [2020_01_13_04_30_18] Iteration #453 | Epoch Duration: 241.5844213962555
2020-01-14 09:54:58.610717 UTC | [2020_01_13_04_30_18] Iteration #453 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.053845547
Z variance train             0.14006032
KL Divergence                2.8085139
KL Loss                      0.2808514
QF Loss                      478.39722
VF Loss                      87.83989
Policy Loss                  -3130.6704
Q Predictions Mean           3120.1138
Q Predictions Std            252.73009
Q Predictions Max            3238.925
Q Predictions Min            29.333397
V Predictions Mean           3127.1953
V Predictions Std            252.47688
V Predictions Max            3247.532
V Predictions Min            29.822445
Log Pis Mean                 -6.9245005
Log Pis Std                  3.998154
Log Pis Max                  22.113571
Log Pis Min                  -14.484415
Policy mu Mean               0.17400682
Policy mu Std                0.562372
Policy mu Max                2.3242283
Policy mu Min                -2.2315834
Policy log std Mean          -0.28044823
Policy log std Std           0.12388152
Policy log std Max           -0.055771664
Policy log std Min           -1.0412511
Z mean eval                  0.02617689
Z variance eval              0.15944684
total_rewards                [3577.55359482 3068.26389949 5588.0011343  3484.34281724 5524.44733409
 2047.9888252  2248.72136995 4496.05629246 5842.22701516 3811.56001579]
total_rewards_mean           3968.9162298488823
total_rewards_std            1292.332273085498
total_rewards_max            5842.227015159509
total_rewards_min            2047.988825204115
Number of train steps total  1820000
Number of env steps total    2277000
Number of rollouts total     0
Train Time (s)               196.16067512799054
(Previous) Eval Time (s)     24.763425478246063
Sample Time (s)              18.658132961019874
Epoch Time (s)               239.58223356725648
Total Train Time (s)         106111.86955936207
Epoch                        454
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 09:58:52.041472 UTC | [2020_01_13_04_30_18] Iteration #454 | Epoch Duration: 233.4305613040924
2020-01-14 09:58:52.041711 UTC | [2020_01_13_04_30_18] Iteration #454 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02590686
Z variance train             0.15949711
KL Divergence                2.653914
KL Loss                      0.2653914
QF Loss                      622.55347
VF Loss                      303.435
Policy Loss                  -3123.4834
Q Predictions Mean           3119.9663
Q Predictions Std            286.091
Q Predictions Max            3241.8176
Q Predictions Min            269.91425
V Predictions Mean           3127.7886
V Predictions Std            285.3454
V Predictions Max            3248.7258
V Predictions Min            250.69148
Log Pis Mean                 -6.8314714
Log Pis Std                  4.27505
Log Pis Max                  28.962547
Log Pis Min                  -15.666573
Policy mu Mean               0.20018718
Policy mu Std                0.5819133
Policy mu Max                2.7605977
Policy mu Min                -3.1845508
Policy log std Mean          -0.28056264
Policy log std Std           0.11794891
Policy log std Max           0.00781779
Policy log std Min           -1.0529594
Z mean eval                  0.03404192
Z variance eval              0.17435072
total_rewards                [5471.15480262 5551.55544631 5579.87929574 5551.37308041 5527.40949836
 5568.84798627 5604.80681693 5502.92577646 5569.06515895 5518.49634675]
total_rewards_mean           5544.551420879701
total_rewards_std            37.75987233924025
total_rewards_max            5604.806816931373
total_rewards_min            5471.1548026191485
Number of train steps total  1824000
Number of env steps total    2282000
Number of rollouts total     0
Train Time (s)               190.25325052486733
(Previous) Eval Time (s)     18.6114738387987
Sample Time (s)              16.59096711082384
Epoch Time (s)               225.45569147448987
Total Train Time (s)         106345.06607433269
Epoch                        455
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:02:45.243065 UTC | [2020_01_13_04_30_18] Iteration #455 | Epoch Duration: 233.20118379592896
2020-01-14 10:02:45.243206 UTC | [2020_01_13_04_30_18] Iteration #455 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034077358
Z variance train             0.17438893
KL Divergence                2.5219333
KL Loss                      0.25219333
QF Loss                      797.0851
VF Loss                      504.335
Policy Loss                  -3113.0374
Q Predictions Mean           3112.3975
Q Predictions Std            349.20096
Q Predictions Max            3249.973
Q Predictions Min            25.70718
V Predictions Mean           3113.5522
V Predictions Std            352.23474
V Predictions Max            3248.3535
V Predictions Min            31.5568
Log Pis Mean                 -6.5304585
Log Pis Std                  4.0143857
Log Pis Max                  17.149693
Log Pis Min                  -14.829539
Policy mu Mean               0.18816103
Policy mu Std                0.58236396
Policy mu Max                2.6256726
Policy mu Min                -2.7792494
Policy log std Mean          -0.29627773
Policy log std Std           0.1323227
Policy log std Max           -0.073345535
Policy log std Min           -1.2988458
Z mean eval                  0.041593365
Z variance eval              0.16895571
total_rewards                [5705.06389366 5720.19257642 4297.86391793 5590.73667643 4247.03810027
 5555.21190454 5554.3093     5658.29296949 5662.99461862 5678.03797449]
total_rewards_mean           5366.974193185179
total_rewards_std            550.1067559630795
total_rewards_max            5720.19257642482
total_rewards_min            4247.038100266428
Number of train steps total  1828000
Number of env steps total    2287000
Number of rollouts total     0
Train Time (s)               195.04012901615351
(Previous) Eval Time (s)     26.356701407115906
Sample Time (s)              18.604477012064308
Epoch Time (s)               240.00130743533373
Total Train Time (s)         106583.77500496618
Epoch                        456
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:06:43.961173 UTC | [2020_01_13_04_30_18] Iteration #456 | Epoch Duration: 238.71785616874695
2020-01-14 10:06:43.961357 UTC | [2020_01_13_04_30_18] Iteration #456 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04114105
Z variance train             0.16906285
KL Divergence                2.4437246
KL Loss                      0.24437247
QF Loss                      560.6982
VF Loss                      162.95108
Policy Loss                  -3124.9404
Q Predictions Mean           3122.5657
Q Predictions Std            280.01288
Q Predictions Max            3257.7798
Q Predictions Min            29.12304
V Predictions Mean           3122.1824
V Predictions Std            281.435
V Predictions Max            3262.9666
V Predictions Min            32.059822
Log Pis Mean                 -6.9149375
Log Pis Std                  4.5289245
Log Pis Max                  19.645226
Log Pis Min                  -15.39865
Policy mu Mean               0.22488114
Policy mu Std                0.56901455
Policy mu Max                2.6681893
Policy mu Min                -3.3290575
Policy log std Mean          -0.2924627
Policy log std Std           0.12959109
Policy log std Max           -0.073542215
Policy log std Min           -1.4041331
Z mean eval                  0.037473775
Z variance eval              0.16290537
total_rewards                [5689.99540176 5591.23739206 5747.52464276 5610.81980303 5623.53123911
 5643.45539414 5610.87380641 5604.60044131 1411.35375334 5585.79257782]
total_rewards_mean           5211.918445173381
total_rewards_std            1267.7351591231136
total_rewards_max            5747.524642757927
total_rewards_min            1411.3537533378276
Number of train steps total  1832000
Number of env steps total    2292000
Number of rollouts total     0
Train Time (s)               197.4258042210713
(Previous) Eval Time (s)     25.07296682614833
Sample Time (s)              16.39950597519055
Epoch Time (s)               238.89827702241018
Total Train Time (s)         106820.95599161042
Epoch                        457
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:10:41.150547 UTC | [2020_01_13_04_30_18] Iteration #457 | Epoch Duration: 237.188982963562
2020-01-14 10:10:41.150820 UTC | [2020_01_13_04_30_18] Iteration #457 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03702687
Z variance train             0.1629737
KL Divergence                2.51265
KL Loss                      0.25126502
QF Loss                      675.515
VF Loss                      189.5993
Policy Loss                  -3135.6711
Q Predictions Mean           3132.5684
Q Predictions Std            214.42451
Q Predictions Max            3241.7766
Q Predictions Min            822.0819
V Predictions Mean           3139.963
V Predictions Std            216.3777
V Predictions Max            3248.1826
V Predictions Min            749.223
Log Pis Mean                 -6.1392193
Log Pis Std                  5.194872
Log Pis Max                  37.66741
Log Pis Min                  -16.569878
Policy mu Mean               0.20919847
Policy mu Std                0.624967
Policy mu Max                3.529215
Policy mu Min                -3.7657597
Policy log std Mean          -0.301391
Policy log std Std           0.14232808
Policy log std Max           0.002229005
Policy log std Min           -1.2908195
Z mean eval                  0.052580375
Z variance eval              0.15749028
total_rewards                [5681.07859937 5706.53936    5808.80413116 5862.69501461 5787.66166909
 5752.08755489 5762.29737685 5645.50845932 5794.23883761 5825.99938141]
total_rewards_mean           5762.691038430797
total_rewards_std            64.35207982098754
total_rewards_max            5862.695014612709
total_rewards_min            5645.508459316622
Number of train steps total  1836000
Number of env steps total    2297000
Number of rollouts total     0
Train Time (s)               197.00512542808428
(Previous) Eval Time (s)     23.363404299132526
Sample Time (s)              17.641547111794353
Epoch Time (s)               238.01007683901116
Total Train Time (s)         107058.93270798773
Epoch                        458
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:14:39.137709 UTC | [2020_01_13_04_30_18] Iteration #458 | Epoch Duration: 237.98671531677246
2020-01-14 10:14:39.137910 UTC | [2020_01_13_04_30_18] Iteration #458 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.052727573
Z variance train             0.15736063
KL Divergence                2.5785182
KL Loss                      0.2578518
QF Loss                      749.6245
VF Loss                      125.637184
Policy Loss                  -3121.775
Q Predictions Mean           3115.3384
Q Predictions Std            331.11447
Q Predictions Max            3255.9631
Q Predictions Min            22.513168
V Predictions Mean           3117.8826
V Predictions Std            327.5777
V Predictions Max            3269.977
V Predictions Min            27.097256
Log Pis Mean                 -6.7111654
Log Pis Std                  4.9334006
Log Pis Max                  37.550156
Log Pis Min                  -17.079758
Policy mu Mean               0.16458213
Policy mu Std                0.62084585
Policy mu Max                3.5305789
Policy mu Min                -3.130764
Policy log std Mean          -0.28454813
Policy log std Std           0.123864785
Policy log std Max           -0.02760066
Policy log std Min           -1.2506598
Z mean eval                  0.06476393
Z variance eval              0.1642725
total_rewards                [5626.28125468 5583.37890338 5630.19520114 5539.3094812  5561.26192086
 3767.18204727 5628.2051486  5511.32369734 5570.01745849 5543.3823637 ]
total_rewards_mean           5396.053747665374
total_rewards_std            544.3442963113523
total_rewards_max            5630.19520113587
total_rewards_min            3767.1820472663194
Number of train steps total  1840000
Number of env steps total    2302000
Number of rollouts total     0
Train Time (s)               197.4256346882321
(Previous) Eval Time (s)     23.339718766044825
Sample Time (s)              16.798612458631396
Epoch Time (s)               237.56396591290832
Total Train Time (s)         107299.04020969197
Epoch                        459
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:18:39.249862 UTC | [2020_01_13_04_30_18] Iteration #459 | Epoch Duration: 240.11180067062378
2020-01-14 10:18:39.250055 UTC | [2020_01_13_04_30_18] Iteration #459 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06482504
Z variance train             0.16423494
KL Divergence                2.4748359
KL Loss                      0.2474836
QF Loss                      718.55066
VF Loss                      175.56683
Policy Loss                  -3129.3057
Q Predictions Mean           3129.3047
Q Predictions Std            259.89612
Q Predictions Max            3270.604
Q Predictions Min            22.884117
V Predictions Mean           3130.315
V Predictions Std            261.05716
V Predictions Max            3261.3271
V Predictions Min            32.44141
Log Pis Mean                 -6.324037
Log Pis Std                  4.8538275
Log Pis Max                  23.354212
Log Pis Min                  -15.121012
Policy mu Mean               0.23867366
Policy mu Std                0.60418826
Policy mu Max                3.2375257
Policy mu Min                -3.021486
Policy log std Mean          -0.29372635
Policy log std Std           0.12829581
Policy log std Max           -0.03439779
Policy log std Min           -1.2001584
Z mean eval                  0.038992226
Z variance eval              0.17050402
total_rewards                [5363.05688413 5520.97067027 5535.0698984  5587.55429215 3569.70734245
 5581.52913218 5549.52673067 5491.39365329 5569.16994863 5496.47832009]
total_rewards_mean           5326.445687226024
total_rewards_std            588.8020411372897
total_rewards_max            5587.554292146103
total_rewards_min            3569.707342451595
Number of train steps total  1844000
Number of env steps total    2307000
Number of rollouts total     0
Train Time (s)               191.94205491011962
(Previous) Eval Time (s)     25.887263611890376
Sample Time (s)              18.725722084753215
Epoch Time (s)               236.5550406067632
Total Train Time (s)         107532.93641442014
Epoch                        460
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:22:33.151474 UTC | [2020_01_13_04_30_18] Iteration #460 | Epoch Duration: 233.90125703811646
2020-01-14 10:22:33.151700 UTC | [2020_01_13_04_30_18] Iteration #460 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0388968
Z variance train             0.17043796
KL Divergence                2.4988565
KL Loss                      0.24988566
QF Loss                      664.20386
VF Loss                      181.11278
Policy Loss                  -3142.912
Q Predictions Mean           3141.5205
Q Predictions Std            271.75577
Q Predictions Max            3261.998
Q Predictions Min            51.269474
V Predictions Mean           3143.0312
V Predictions Std            271.9321
V Predictions Max            3265.3528
V Predictions Min            67.865234
Log Pis Mean                 -6.7701283
Log Pis Std                  3.9375408
Log Pis Max                  11.865168
Log Pis Min                  -15.812513
Policy mu Mean               0.2004797
Policy mu Std                0.57910657
Policy mu Max                2.5351412
Policy mu Min                -2.5969346
Policy log std Mean          -0.29350308
Policy log std Std           0.12853624
Policy log std Max           -0.08914233
Policy log std Min           -1.0324242
Z mean eval                  0.041471582
Z variance eval              0.17600144
total_rewards                [ 949.33758612 5529.50919561 5714.53491863 5644.17719625 5597.46939005
 5662.82805913 5634.55549284 5590.02344211 5617.47816126 5699.39839117]
total_rewards_mean           5163.931183317147
total_rewards_std            1405.7941703485399
total_rewards_max            5714.534918629473
total_rewards_min            949.3375861226153
Number of train steps total  1848000
Number of env steps total    2312000
Number of rollouts total     0
Train Time (s)               193.21058306097984
(Previous) Eval Time (s)     23.233179388102144
Sample Time (s)              18.689112914260477
Epoch Time (s)               235.13287536334246
Total Train Time (s)         107769.11399371829
Epoch                        461
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:26:29.336583 UTC | [2020_01_13_04_30_18] Iteration #461 | Epoch Duration: 236.18469977378845
2020-01-14 10:26:29.336872 UTC | [2020_01_13_04_30_18] Iteration #461 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.041479807
Z variance train             0.1758028
KL Divergence                2.3697534
KL Loss                      0.23697534
QF Loss                      697.3631
VF Loss                      171.14136
Policy Loss                  -3139.2822
Q Predictions Mean           3130.2117
Q Predictions Std            293.5174
Q Predictions Max            3258.3044
Q Predictions Min            18.085125
V Predictions Mean           3139.3271
V Predictions Std            289.99832
V Predictions Max            3273.8103
V Predictions Min            38.221928
Log Pis Mean                 -6.8895707
Log Pis Std                  4.161637
Log Pis Max                  20.002941
Log Pis Min                  -15.772707
Policy mu Mean               0.20733798
Policy mu Std                0.57627016
Policy mu Max                2.6962657
Policy mu Min                -2.528657
Policy log std Mean          -0.29441953
Policy log std Std           0.12839162
Policy log std Max           -0.0653133
Policy log std Min           -1.3150921
Z mean eval                  0.06849126
Z variance eval              0.18588327
total_rewards                [5559.91031539 5549.38710058 5604.3511782  5571.56274105 5705.51436276
 5613.5120981  5528.51801676 5662.81418611 5612.95152967 5626.02066218]
total_rewards_mean           5603.454219080706
total_rewards_std            51.08141832748052
total_rewards_max            5705.514362761118
total_rewards_min            5528.51801675721
Number of train steps total  1852000
Number of env steps total    2317000
Number of rollouts total     0
Train Time (s)               193.72229119203985
(Previous) Eval Time (s)     24.284718175884336
Sample Time (s)              16.888637476600707
Epoch Time (s)               234.8956468445249
Total Train Time (s)         108006.06548768468
Epoch                        462
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:30:26.293562 UTC | [2020_01_13_04_30_18] Iteration #462 | Epoch Duration: 236.956481218338
2020-01-14 10:30:26.293765 UTC | [2020_01_13_04_30_18] Iteration #462 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06821112
Z variance train             0.18600082
KL Divergence                2.3478298
KL Loss                      0.23478298
QF Loss                      447.5844
VF Loss                      118.646355
Policy Loss                  -3146.5552
Q Predictions Mean           3140.375
Q Predictions Std            207.25139
Q Predictions Max            3251.7273
Q Predictions Min            29.256754
V Predictions Mean           3149.6755
V Predictions Std            206.09128
V Predictions Max            3255.7769
V Predictions Min            33.908546
Log Pis Mean                 -7.3448157
Log Pis Std                  3.4302487
Log Pis Max                  8.4195
Log Pis Min                  -15.177464
Policy mu Mean               0.2176307
Policy mu Std                0.5427459
Policy mu Max                1.9493228
Policy mu Min                -2.2345831
Policy log std Mean          -0.28870028
Policy log std Std           0.11818208
Policy log std Max           -0.076705165
Policy log std Min           -1.0146929
Z mean eval                  0.07219058
Z variance eval              0.16631208
total_rewards                [5793.429754   5569.02262399 5598.56084781 5527.65517307 5640.50345701
 5616.07533163 5654.07843671 5663.50917145 5672.70049076 5679.64844229]
total_rewards_mean           5641.518372873317
total_rewards_std            68.45351272856965
total_rewards_max            5793.429754004695
total_rewards_min            5527.655173074144
Number of train steps total  1856000
Number of env steps total    2322000
Number of rollouts total     0
Train Time (s)               192.4300538226962
(Previous) Eval Time (s)     26.345275042112917
Sample Time (s)              17.106347942724824
Epoch Time (s)               235.88167680753395
Total Train Time (s)         108241.87331989128
Epoch                        463
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:34:22.108022 UTC | [2020_01_13_04_30_18] Iteration #463 | Epoch Duration: 235.8141040802002
2020-01-14 10:34:22.108219 UTC | [2020_01_13_04_30_18] Iteration #463 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07191308
Z variance train             0.16632964
KL Divergence                2.4444113
KL Loss                      0.24444114
QF Loss                      818.3096
VF Loss                      698.0727
Policy Loss                  -3126.8696
Q Predictions Mean           3121.6655
Q Predictions Std            331.7656
Q Predictions Max            3261.6824
Q Predictions Min            19.613968
V Predictions Mean           3128.4429
V Predictions Std            315.06906
V Predictions Max            3263.1335
V Predictions Min            24.427286
Log Pis Mean                 -7.05733
Log Pis Std                  4.4903154
Log Pis Max                  24.731651
Log Pis Min                  -13.561097
Policy mu Mean               0.23132488
Policy mu Std                0.5589457
Policy mu Max                3.1562805
Policy mu Min                -2.7454283
Policy log std Mean          -0.28404167
Policy log std Std           0.12145043
Policy log std Max           -0.040175818
Policy log std Min           -1.3724328
Z mean eval                  0.08931487
Z variance eval              0.1785962
total_rewards                [5622.91166173 5643.13778714 5599.89368933 4506.56937798 5532.66476824
 2091.83185281 5547.37742483 5561.47181346 5430.96287577 5612.25626052]
total_rewards_mean           5114.907751181376
total_rewards_std            1057.808420982921
total_rewards_max            5643.137787138407
total_rewards_min            2091.8318528094824
Number of train steps total  1860000
Number of env steps total    2327000
Number of rollouts total     0
Train Time (s)               195.31849460396916
(Previous) Eval Time (s)     26.2773407548666
Sample Time (s)              18.57601124746725
Epoch Time (s)               240.171846606303
Total Train Time (s)         108479.99175934307
Epoch                        464
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:38:20.231896 UTC | [2020_01_13_04_30_18] Iteration #464 | Epoch Duration: 238.12354683876038
2020-01-14 10:38:20.232055 UTC | [2020_01_13_04_30_18] Iteration #464 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08983399
Z variance train             0.17856774
KL Divergence                2.3262925
KL Loss                      0.23262925
QF Loss                      410.49524
VF Loss                      88.6986
Policy Loss                  -3154.3945
Q Predictions Mean           3148.2822
Q Predictions Std            206.23422
Q Predictions Max            3251.937
Q Predictions Min            37.97946
V Predictions Mean           3152.7852
V Predictions Std            206.1828
V Predictions Max            3263.7273
V Predictions Min            56.783844
Log Pis Mean                 -7.083167
Log Pis Std                  4.016577
Log Pis Max                  24.998224
Log Pis Min                  -14.29475
Policy mu Mean               0.1541051
Policy mu Std                0.58849806
Policy mu Max                2.6445749
Policy mu Min                -2.894254
Policy log std Mean          -0.28031132
Policy log std Std           0.1183862
Policy log std Max           -0.067360714
Policy log std Min           -1.1139632
Z mean eval                  0.058024745
Z variance eval              0.1967714
total_rewards                [5366.08579224 5430.33323847 5432.66116446 5429.69543513 5466.2248158
 5490.01895386 5517.70374883 5539.88247897 5357.26143705 5609.38764279]
total_rewards_mean           5463.925470759493
total_rewards_std            73.98268693812284
total_rewards_max            5609.387642790448
total_rewards_min            5357.26143704861
Number of train steps total  1864000
Number of env steps total    2332000
Number of rollouts total     0
Train Time (s)               192.34915318107232
(Previous) Eval Time (s)     24.228770941961557
Sample Time (s)              18.615033828187734
Epoch Time (s)               235.19295795122162
Total Train Time (s)         108718.12857412966
Epoch                        465
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:42:18.380658 UTC | [2020_01_13_04_30_18] Iteration #465 | Epoch Duration: 238.1484830379486
2020-01-14 10:42:18.380889 UTC | [2020_01_13_04_30_18] Iteration #465 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05815835
Z variance train             0.19663954
KL Divergence                2.117898
KL Loss                      0.2117898
QF Loss                      863.9536
VF Loss                      338.65564
Policy Loss                  -3157.6357
Q Predictions Mean           3149.0713
Q Predictions Std            205.70175
Q Predictions Max            3267.73
Q Predictions Min            540.50323
V Predictions Mean           3151.6577
V Predictions Std            205.03384
V Predictions Max            3267.2446
V Predictions Min            529.627
Log Pis Mean                 -6.703618
Log Pis Std                  4.3060346
Log Pis Max                  24.701138
Log Pis Min                  -15.487484
Policy mu Mean               0.19670448
Policy mu Std                0.59073305
Policy mu Max                2.6515515
Policy mu Min                -2.5851445
Policy log std Mean          -0.28299958
Policy log std Std           0.121830754
Policy log std Max           -0.07011913
Policy log std Min           -1.0674026
Z mean eval                  0.05552057
Z variance eval              0.16992569
total_rewards                [5588.65121523 5630.18222654 5470.72045544 5486.55812425 5713.22304393
 5548.7165625  5526.5484976  5619.19258929 5522.12553845 5507.98033428]
total_rewards_mean           5561.389858751331
total_rewards_std            71.73532562587927
total_rewards_max            5713.223043931686
total_rewards_min            5470.720455441358
Number of train steps total  1868000
Number of env steps total    2337000
Number of rollouts total     0
Train Time (s)               189.40235692681745
(Previous) Eval Time (s)     27.18400047486648
Sample Time (s)              17.014573717024177
Epoch Time (s)               233.6009311187081
Total Train Time (s)         108951.40738084819
Epoch                        466
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:46:11.662366 UTC | [2020_01_13_04_30_18] Iteration #466 | Epoch Duration: 233.28134727478027
2020-01-14 10:46:11.662498 UTC | [2020_01_13_04_30_18] Iteration #466 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05592649
Z variance train             0.17001529
KL Divergence                2.4067512
KL Loss                      0.24067512
QF Loss                      1086.601
VF Loss                      279.73758
Policy Loss                  -3117.2322
Q Predictions Mean           3116.398
Q Predictions Std            374.19464
Q Predictions Max            3255.1562
Q Predictions Min            17.2177
V Predictions Mean           3121.6545
V Predictions Std            370.85327
V Predictions Max            3275.485
V Predictions Min            31.998371
Log Pis Mean                 -6.2225995
Log Pis Std                  4.17209
Log Pis Max                  20.571796
Log Pis Min                  -15.48386
Policy mu Mean               0.17902404
Policy mu Std                0.60495776
Policy mu Max                3.1653929
Policy mu Min                -2.9491389
Policy log std Mean          -0.30155554
Policy log std Std           0.12890133
Policy log std Max           -0.035505608
Policy log std Min           -1.1825478
Z mean eval                  0.046690255
Z variance eval              0.20430675
total_rewards                [5482.30883587 5426.7734276  5423.91049888 5522.49627401 5417.20653376
 5555.38202406 5414.38468613 5421.46257319 5406.26257212 5399.35965152]
total_rewards_mean           5446.954707713234
total_rewards_std            51.15466110715453
total_rewards_max            5555.382024058193
total_rewards_min            5399.3596515163545
Number of train steps total  1872000
Number of env steps total    2342000
Number of rollouts total     0
Train Time (s)               194.4507684162818
(Previous) Eval Time (s)     26.8640621220693
Sample Time (s)              18.762327081058174
Epoch Time (s)               240.07715761940926
Total Train Time (s)         109191.32824627776
Epoch                        467
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:50:11.586787 UTC | [2020_01_13_04_30_18] Iteration #467 | Epoch Duration: 239.92414236068726
2020-01-14 10:50:11.586997 UTC | [2020_01_13_04_30_18] Iteration #467 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046477787
Z variance train             0.20420563
KL Divergence                2.1619482
KL Loss                      0.21619482
QF Loss                      561.5774
VF Loss                      236.46687
Policy Loss                  -3122.8765
Q Predictions Mean           3121.5508
Q Predictions Std            361.26974
Q Predictions Max            3254.1042
Q Predictions Min            33.134804
V Predictions Mean           3132.745
V Predictions Std            363.68103
V Predictions Max            3267.6921
V Predictions Min            23.19092
Log Pis Mean                 -6.6596746
Log Pis Std                  4.104917
Log Pis Max                  23.521477
Log Pis Min                  -15.5095825
Policy mu Mean               0.17323552
Policy mu Std                0.5967946
Policy mu Max                2.1432133
Policy mu Min                -2.1331637
Policy log std Mean          -0.2896125
Policy log std Std           0.12871525
Policy log std Max           0.043077596
Policy log std Min           -1.2866063
Z mean eval                  0.048165273
Z variance eval              0.20540304
total_rewards                [5418.76415525 5442.77083892 5489.21868638 4120.63705001 5561.5966108
 5497.08492491 5485.34235302 5529.05393018 3516.03197367 5638.74794732]
total_rewards_mean           5169.9248470454195
total_rewards_std            691.619729177628
total_rewards_max            5638.747947318019
total_rewards_min            3516.031973668222
Number of train steps total  1876000
Number of env steps total    2347000
Number of rollouts total     0
Train Time (s)               192.95805594231933
(Previous) Eval Time (s)     26.71076030516997
Sample Time (s)              18.749980926979333
Epoch Time (s)               238.41879717446864
Total Train Time (s)         109425.82389154052
Epoch                        468
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:54:06.086709 UTC | [2020_01_13_04_30_18] Iteration #468 | Epoch Duration: 234.49959230422974
2020-01-14 10:54:06.086890 UTC | [2020_01_13_04_30_18] Iteration #468 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04803179
Z variance train             0.20542514
KL Divergence                2.1833115
KL Loss                      0.21833114
QF Loss                      628.7352
VF Loss                      233.82385
Policy Loss                  -3147.1782
Q Predictions Mean           3139.3752
Q Predictions Std            247.84279
Q Predictions Max            3258.969
Q Predictions Min            64.41122
V Predictions Mean           3143.15
V Predictions Std            257.34265
V Predictions Max            3275.0627
V Predictions Min            52.590855
Log Pis Mean                 -6.537041
Log Pis Std                  4.1625524
Log Pis Max                  16.473755
Log Pis Min                  -17.291737
Policy mu Mean               0.19483866
Policy mu Std                0.6109421
Policy mu Max                2.5360606
Policy mu Min                -3.2890196
Policy log std Mean          -0.30225873
Policy log std Std           0.121825404
Policy log std Max           -0.08640511
Policy log std Min           -1.0860837
Z mean eval                  0.06630291
Z variance eval              0.21705827
total_rewards                [1171.69797603 5512.89472532 5603.49945139 5569.07963609 5701.90662312
 5666.85880411 5655.51939152 5641.2007381  3482.55566122 5614.837294  ]
total_rewards_mean           4962.0050300899375
total_rewards_std            1416.031930411936
total_rewards_max            5701.90662312359
total_rewards_min            1171.6979760267802
Number of train steps total  1880000
Number of env steps total    2352000
Number of rollouts total     0
Train Time (s)               196.62291749333963
(Previous) Eval Time (s)     22.79128183191642
Sample Time (s)              16.7795744179748
Epoch Time (s)               236.19377374323085
Total Train Time (s)         109662.66362774093
Epoch                        469
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 10:58:02.931654 UTC | [2020_01_13_04_30_18] Iteration #469 | Epoch Duration: 236.8445484638214
2020-01-14 10:58:02.931921 UTC | [2020_01_13_04_30_18] Iteration #469 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06634964
Z variance train             0.21699993
KL Divergence                2.0885625
KL Loss                      0.20885625
QF Loss                      538.9258
VF Loss                      221.32336
Policy Loss                  -3122.7573
Q Predictions Mean           3119.5479
Q Predictions Std            404.93378
Q Predictions Max            3275.485
Q Predictions Min            29.618135
V Predictions Mean           3118.4644
V Predictions Std            403.92923
V Predictions Max            3273.1091
V Predictions Min            41.67198
Log Pis Mean                 -6.6570215
Log Pis Std                  3.8336015
Log Pis Max                  17.880867
Log Pis Min                  -15.1569
Policy mu Mean               0.20370206
Policy mu Std                0.58647424
Policy mu Max                2.4964633
Policy mu Min                -2.2800152
Policy log std Mean          -0.29613662
Policy log std Std           0.1293819
Policy log std Max           0.13394743
Policy log std Min           -1.081113
Z mean eval                  0.051463433
Z variance eval              0.19829556
total_rewards                [5454.79432322 5591.39098988 5541.36014169 5585.05358551 2200.92776262
 5630.28141712 5602.77408592 5502.97067934 5390.11178843 5520.96417353]
total_rewards_mean           5202.062894726198
total_rewards_std            1002.776773833133
total_rewards_max            5630.281417121185
total_rewards_min            2200.927762616261
Number of train steps total  1884000
Number of env steps total    2357000
Number of rollouts total     0
Train Time (s)               193.77903413493186
(Previous) Eval Time (s)     23.441753750666976
Sample Time (s)              18.684419952332973
Epoch Time (s)               235.9052078379318
Total Train Time (s)         109897.0113345054
Epoch                        470
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:01:57.288907 UTC | [2020_01_13_04_30_18] Iteration #470 | Epoch Duration: 234.3567762374878
2020-01-14 11:01:57.289240 UTC | [2020_01_13_04_30_18] Iteration #470 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.051314317
Z variance train             0.19820324
KL Divergence                2.1741989
KL Loss                      0.2174199
QF Loss                      959.48267
VF Loss                      180.94049
Policy Loss                  -3137.0515
Q Predictions Mean           3135.6438
Q Predictions Std            296.73883
Q Predictions Max            3258.2197
Q Predictions Min            36.09491
V Predictions Mean           3139.7327
V Predictions Std            294.0588
V Predictions Max            3263.279
V Predictions Min            31.740652
Log Pis Mean                 -6.783351
Log Pis Std                  4.0478425
Log Pis Max                  16.251137
Log Pis Min                  -15.003356
Policy mu Mean               0.16650309
Policy mu Std                0.5902072
Policy mu Max                2.4850483
Policy mu Min                -3.9018338
Policy log std Mean          -0.27718443
Policy log std Std           0.12934075
Policy log std Max           0.5826414
Policy log std Min           -1.3694439
Z mean eval                  0.0587821
Z variance eval              0.2109057
total_rewards                [5463.85368962 5448.43811203 5506.04824896 5418.66007886 5527.06868114
 5604.23453061 5504.26266089 5484.12413929 5489.37646902 5682.22317536]
total_rewards_mean           5512.828978578779
total_rewards_std            73.59213977512104
total_rewards_max            5682.223175359248
total_rewards_min            5418.660078858898
Number of train steps total  1888000
Number of env steps total    2362000
Number of rollouts total     0
Train Time (s)               197.25033362675458
(Previous) Eval Time (s)     21.89301087614149
Sample Time (s)              16.669974638614804
Epoch Time (s)               235.81331914151087
Total Train Time (s)         110137.32121568546
Epoch                        471
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:05:57.606570 UTC | [2020_01_13_04_30_18] Iteration #471 | Epoch Duration: 240.3170976638794
2020-01-14 11:05:57.606815 UTC | [2020_01_13_04_30_18] Iteration #471 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.058948576
Z variance train             0.21096167
KL Divergence                1.9907721
KL Loss                      0.19907722
QF Loss                      461.4936
VF Loss                      135.45201
Policy Loss                  -3143.2463
Q Predictions Mean           3137.7017
Q Predictions Std            318.4352
Q Predictions Max            3266.5498
Q Predictions Min            198.67815
V Predictions Mean           3139.0122
V Predictions Std            319.0094
V Predictions Max            3264.389
V Predictions Min            178.33383
Log Pis Mean                 -6.9836464
Log Pis Std                  3.5335205
Log Pis Max                  7.8037615
Log Pis Min                  -15.572168
Policy mu Mean               0.17356479
Policy mu Std                0.5788008
Policy mu Max                2.9162714
Policy mu Min                -2.3934505
Policy log std Mean          -0.29183972
Policy log std Std           0.11781179
Policy log std Max           0.021446899
Policy log std Min           -0.89594483
Z mean eval                  0.07327935
Z variance eval              0.19625239
total_rewards                [5511.46403921 5504.57574328 5588.91681519 5689.1349444  5575.52158763
 5487.80059817 5583.38438806 5636.46582106 5670.75182202 5452.15093348]
total_rewards_mean           5570.0166692505145
total_rewards_std            75.94812643648854
total_rewards_max            5689.134944403583
total_rewards_min            5452.150933482553
Number of train steps total  1892000
Number of env steps total    2367000
Number of rollouts total     0
Train Time (s)               191.06064963713288
(Previous) Eval Time (s)     26.39653816493228
Sample Time (s)              16.8220204426907
Epoch Time (s)               234.27920824475586
Total Train Time (s)         110371.76112490473
Epoch                        472
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:09:52.056209 UTC | [2020_01_13_04_30_18] Iteration #472 | Epoch Duration: 234.44923758506775
2020-01-14 11:09:52.056427 UTC | [2020_01_13_04_30_18] Iteration #472 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07332094
Z variance train             0.19618605
KL Divergence                2.1071875
KL Loss                      0.21071875
QF Loss                      328.91895
VF Loss                      73.19797
Policy Loss                  -3170.5964
Q Predictions Mean           3166.6328
Q Predictions Std            178.13928
Q Predictions Max            3275.6638
Q Predictions Min            527.73285
V Predictions Mean           3169.1318
V Predictions Std            181.35573
V Predictions Max            3276.6748
V Predictions Min            480.33478
Log Pis Mean                 -6.5836983
Log Pis Std                  3.5680094
Log Pis Max                  8.820352
Log Pis Min                  -15.697316
Policy mu Mean               0.189103
Policy mu Std                0.5725375
Policy mu Max                2.4731958
Policy mu Min                -1.9831572
Policy log std Mean          -0.29007384
Policy log std Std           0.11366834
Policy log std Max           -0.047381133
Policy log std Min           -0.87724626
Z mean eval                  0.059279013
Z variance eval              0.20264442
total_rewards                [5593.81379801 5612.84795122 5573.79363065 5542.87851441 5480.67765257
 5606.2143475  5579.16359066 5527.39884885 5520.04136515 5524.38596449]
total_rewards_mean           5556.121566352273
total_rewards_std            41.22159255489396
total_rewards_max            5612.847951215823
total_rewards_min            5480.6776525714995
Number of train steps total  1896000
Number of env steps total    2372000
Number of rollouts total     0
Train Time (s)               198.31873240415007
(Previous) Eval Time (s)     26.56627841712907
Sample Time (s)              18.56838566530496
Epoch Time (s)               243.4533964865841
Total Train Time (s)         110615.35783852311
Epoch                        473
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:13:55.662252 UTC | [2020_01_13_04_30_18] Iteration #473 | Epoch Duration: 243.6056671142578
2020-01-14 11:13:55.662469 UTC | [2020_01_13_04_30_18] Iteration #473 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.060060762
Z variance train             0.20250192
KL Divergence                2.0803893
KL Loss                      0.20803893
QF Loss                      523.3248
VF Loss                      152.43597
Policy Loss                  -3150.9282
Q Predictions Mean           3144.982
Q Predictions Std            348.0483
Q Predictions Max            3270.1033
Q Predictions Min            28.073101
V Predictions Mean           3142.6304
V Predictions Std            345.1436
V Predictions Max            3275.3467
V Predictions Min            25.007925
Log Pis Mean                 -6.833242
Log Pis Std                  4.3609266
Log Pis Max                  27.01114
Log Pis Min                  -14.829578
Policy mu Mean               0.1704354
Policy mu Std                0.5815221
Policy mu Max                3.6467547
Policy mu Min                -3.0115452
Policy log std Mean          -0.2890253
Policy log std Std           0.12852502
Policy log std Max           -0.0062351674
Policy log std Min           -1.8957459
Z mean eval                  0.07092117
Z variance eval              0.1749752
total_rewards                [5774.86907143 5778.62863987 5461.94268488 5622.89569087 5704.22937434
 5774.75204495 2385.99597926 5828.72417198 2616.53632754 5782.28946221]
total_rewards_mean           5073.086344731195
total_rewards_std            1290.8723787329743
total_rewards_max            5828.724171975213
total_rewards_min            2385.9959792616037
Number of train steps total  1900000
Number of env steps total    2377000
Number of rollouts total     0
Train Time (s)               191.4756371350959
(Previous) Eval Time (s)     26.71814783802256
Sample Time (s)              16.8525765594095
Epoch Time (s)               235.04636153252795
Total Train Time (s)         110844.6216984922
Epoch                        474
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:17:44.935182 UTC | [2020_01_13_04_30_18] Iteration #474 | Epoch Duration: 229.27254724502563
2020-01-14 11:17:44.935454 UTC | [2020_01_13_04_30_18] Iteration #474 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07075913
Z variance train             0.17499785
KL Divergence                2.3306046
KL Loss                      0.23306046
QF Loss                      506.6595
VF Loss                      394.9637
Policy Loss                  -3173.9316
Q Predictions Mean           3169.2144
Q Predictions Std            114.944374
Q Predictions Max            3291.7869
Q Predictions Min            1723.648
V Predictions Mean           3181.4617
V Predictions Std            115.126205
V Predictions Max            3297.328
V Predictions Min            1657.9008
Log Pis Mean                 -6.686815
Log Pis Std                  3.5944014
Log Pis Max                  9.566937
Log Pis Min                  -15.40537
Policy mu Mean               0.17130889
Policy mu Std                0.59851795
Policy mu Max                2.2578428
Policy mu Min                -2.5842655
Policy log std Mean          -0.30427003
Policy log std Std           0.12535629
Policy log std Max           -0.096024945
Policy log std Min           -1.0706102
Z mean eval                  0.0719802
Z variance eval              0.17467102
total_rewards                [5571.27766019 5568.59072433 5553.83442014 5581.63881381 5513.70628545
 2908.21090617 5635.85270286 5506.95846227 5570.95543716 5561.17360696]
total_rewards_mean           5297.219901934937
total_rewards_std            797.0564836818653
total_rewards_max            5635.852702863426
total_rewards_min            2908.2109061688275
Number of train steps total  1904000
Number of env steps total    2382000
Number of rollouts total     0
Train Time (s)               196.88755833078176
(Previous) Eval Time (s)     20.94396166410297
Sample Time (s)              17.865759808104485
Epoch Time (s)               235.69727980298921
Total Train Time (s)         111081.98695181729
Epoch                        475
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:21:42.308417 UTC | [2020_01_13_04_30_18] Iteration #475 | Epoch Duration: 237.37272834777832
2020-01-14 11:21:42.308647 UTC | [2020_01_13_04_30_18] Iteration #475 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07196641
Z variance train             0.17466195
KL Divergence                2.3379142
KL Loss                      0.23379143
QF Loss                      733.7472
VF Loss                      162.03458
Policy Loss                  -3151.7974
Q Predictions Mean           3148.6758
Q Predictions Std            288.09732
Q Predictions Max            3272.3645
Q Predictions Min            26.714577
V Predictions Mean           3153.1245
V Predictions Std            290.5374
V Predictions Max            3278.9473
V Predictions Min            32.939175
Log Pis Mean                 -6.64686
Log Pis Std                  3.803447
Log Pis Max                  7.1866016
Log Pis Min                  -16.19099
Policy mu Mean               0.19966824
Policy mu Std                0.598714
Policy mu Max                2.8057923
Policy mu Min                -2.9406352
Policy log std Mean          -0.29791906
Policy log std Std           0.12896669
Policy log std Max           -0.03753297
Policy log std Min           -1.1456724
Z mean eval                  0.06582419
Z variance eval              0.195358
total_rewards                [5625.72457556 5470.38907351  551.91125715 5581.97791593 2412.62264524
 5736.8917322  5578.07969279 5684.57452612 5524.46556259 5566.51635567]
total_rewards_mean           4773.3153336761725
total_rewards_std            1698.8079298691116
total_rewards_max            5736.891732200765
total_rewards_min            551.911257151216
Number of train steps total  1908000
Number of env steps total    2387000
Number of rollouts total     0
Train Time (s)               195.76526413066313
(Previous) Eval Time (s)     22.61913280421868
Sample Time (s)              18.674916409887373
Epoch Time (s)               237.05931334476918
Total Train Time (s)         111318.98359118495
Epoch                        476
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:25:39.307476 UTC | [2020_01_13_04_30_18] Iteration #476 | Epoch Duration: 236.99871015548706
2020-01-14 11:25:39.307592 UTC | [2020_01_13_04_30_18] Iteration #476 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06564528
Z variance train             0.1953158
KL Divergence                2.1157746
KL Loss                      0.21157746
QF Loss                      419.30188
VF Loss                      130.33144
Policy Loss                  -3141.5703
Q Predictions Mean           3137.5427
Q Predictions Std            360.3744
Q Predictions Max            3276.9246
Q Predictions Min            21.539001
V Predictions Mean           3143.4429
V Predictions Std            359.50595
V Predictions Max            3289.3467
V Predictions Min            24.729355
Log Pis Mean                 -7.1552353
Log Pis Std                  4.521331
Log Pis Max                  24.715248
Log Pis Min                  -14.673769
Policy mu Mean               0.16462332
Policy mu Std                0.5667044
Policy mu Max                3.0322878
Policy mu Min                -3.0274165
Policy log std Mean          -0.27639484
Policy log std Std           0.13012104
Policy log std Max           -0.07079102
Policy log std Min           -1.1953499
Z mean eval                  0.047426295
Z variance eval              0.18596622
total_rewards                [5727.90794855 5565.70963424 5707.66166347 5747.05894826 5746.15045328
 5822.6743038  5834.10245415 5553.54035941 5594.95811649 5789.86730859]
total_rewards_mean           5708.963119024959
total_rewards_std            97.98229468806437
total_rewards_max            5834.102454146151
total_rewards_min            5553.540359414276
Number of train steps total  1912000
Number of env steps total    2392000
Number of rollouts total     0
Train Time (s)               194.499312734697
(Previous) Eval Time (s)     22.55825285287574
Sample Time (s)              18.63507752586156
Epoch Time (s)               235.69264311343431
Total Train Time (s)         111556.03860003594
Epoch                        477
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:29:36.373054 UTC | [2020_01_13_04_30_18] Iteration #477 | Epoch Duration: 237.0653214454651
2020-01-14 11:29:36.373356 UTC | [2020_01_13_04_30_18] Iteration #477 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.047542673
Z variance train             0.18598452
KL Divergence                2.2582307
KL Loss                      0.22582307
QF Loss                      946.6794
VF Loss                      157.99126
Policy Loss                  -3175.6519
Q Predictions Mean           3172.7417
Q Predictions Std            110.925896
Q Predictions Max            3280.1548
Q Predictions Min            1911.446
V Predictions Mean           3175.6729
V Predictions Std            122.739456
V Predictions Max            3281.924
V Predictions Min            1743.5033
Log Pis Mean                 -7.2117143
Log Pis Std                  3.4997602
Log Pis Max                  14.32719
Log Pis Min                  -16.88627
Policy mu Mean               0.1887742
Policy mu Std                0.5670311
Policy mu Max                2.2288978
Policy mu Min                -2.766045
Policy log std Mean          -0.28390592
Policy log std Std           0.11849868
Policy log std Max           -0.09307486
Policy log std Min           -1.017295
Z mean eval                  0.047369022
Z variance eval              0.1954558
total_rewards                [5582.8184314  5568.10370158 5693.21461784 5603.55110554 5620.46762735
 5447.10283698 5607.28934128 5614.04480463 5717.69863245 5600.46196926]
total_rewards_mean           5605.475306831099
total_rewards_std            69.00319151351019
total_rewards_max            5717.698632447589
total_rewards_min            5447.102836982419
Number of train steps total  1916000
Number of env steps total    2397000
Number of rollouts total     0
Train Time (s)               195.09198708692566
(Previous) Eval Time (s)     23.93061742419377
Sample Time (s)              18.688577795401216
Epoch Time (s)               237.71118230652064
Total Train Time (s)         111796.20655428339
Epoch                        478
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:33:36.543812 UTC | [2020_01_13_04_30_18] Iteration #478 | Epoch Duration: 240.17025899887085
2020-01-14 11:33:36.543945 UTC | [2020_01_13_04_30_18] Iteration #478 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.047252424
Z variance train             0.19545996
KL Divergence                2.0824418
KL Loss                      0.20824419
QF Loss                      832.7645
VF Loss                      360.26938
Policy Loss                  -3130.6855
Q Predictions Mean           3130.7883
Q Predictions Std            391.09628
Q Predictions Max            3276.4612
Q Predictions Min            22.945587
V Predictions Mean           3135.0786
V Predictions Std            393.16537
V Predictions Max            3280.7898
V Predictions Min            22.810009
Log Pis Mean                 -6.7987423
Log Pis Std                  4.1425414
Log Pis Max                  19.436932
Log Pis Min                  -15.590467
Policy mu Mean               0.16665001
Policy mu Std                0.5953446
Policy mu Max                2.5887618
Policy mu Min                -3.7690058
Policy log std Mean          -0.29112855
Policy log std Std           0.13451815
Policy log std Max           0.07202495
Policy log std Min           -1.2200454
Z mean eval                  0.050411105
Z variance eval              0.1839974
total_rewards                [4975.28505765 5637.08810628 5741.35422309 5721.94647666 4528.97847577
 3690.23012966 5754.15058063 5735.55190732 5683.05566138 5688.88518039]
total_rewards_mean           5315.652579883814
total_rewards_std            668.5211511534108
total_rewards_max            5754.15058062653
total_rewards_min            3690.230129657271
Number of train steps total  1920000
Number of env steps total    2402000
Number of rollouts total     0
Train Time (s)               198.5880368091166
(Previous) Eval Time (s)     26.389435821212828
Sample Time (s)              16.561418283730745
Epoch Time (s)               241.53889091406018
Total Train Time (s)         112036.15805558907
Epoch                        479
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:37:36.504252 UTC | [2020_01_13_04_30_18] Iteration #479 | Epoch Duration: 239.960196018219
2020-01-14 11:37:36.504374 UTC | [2020_01_13_04_30_18] Iteration #479 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.050773293
Z variance train             0.18405981
KL Divergence                2.2159922
KL Loss                      0.22159922
QF Loss                      365.9201
VF Loss                      68.37045
Policy Loss                  -3186.391
Q Predictions Mean           3179.4512
Q Predictions Std            217.63005
Q Predictions Max            3272.063
Q Predictions Min            25.107964
V Predictions Mean           3184.348
V Predictions Std            218.522
V Predictions Max            3282.4219
V Predictions Min            40.901867
Log Pis Mean                 -7.554829
Log Pis Std                  3.8949442
Log Pis Max                  21.86897
Log Pis Min                  -15.989685
Policy mu Mean               0.16581155
Policy mu Std                0.5493882
Policy mu Max                3.522255
Policy mu Min                -2.7670865
Policy log std Mean          -0.27652448
Policy log std Std           0.1274806
Policy log std Max           -0.04329957
Policy log std Min           -1.3461063
Z mean eval                  0.05049898
Z variance eval              0.18711078
total_rewards                [5678.33199176 5704.33129087 5558.22363861 5782.34497027 5598.93022054
 5651.14674778 5652.7221445  5719.91988448  497.81487878 5574.32725484]
total_rewards_mean           5141.809302244224
total_rewards_std            1549.366268998249
total_rewards_max            5782.344970274737
total_rewards_min            497.8148787842892
Number of train steps total  1924000
Number of env steps total    2407000
Number of rollouts total     0
Train Time (s)               194.2923651211895
(Previous) Eval Time (s)     24.81048401724547
Sample Time (s)              18.512524392921478
Epoch Time (s)               237.61537353135645
Total Train Time (s)         112273.30299693113
Epoch                        480
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:41:33.652395 UTC | [2020_01_13_04_30_18] Iteration #480 | Epoch Duration: 237.1479229927063
2020-01-14 11:41:33.652547 UTC | [2020_01_13_04_30_18] Iteration #480 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04994179
Z variance train             0.18705371
KL Divergence                2.1894188
KL Loss                      0.21894188
QF Loss                      803.8158
VF Loss                      324.07397
Policy Loss                  -3153.4097
Q Predictions Mean           3150.6204
Q Predictions Std            273.84833
Q Predictions Max            3265.185
Q Predictions Min            30.123318
V Predictions Mean           3160.874
V Predictions Std            272.7367
V Predictions Max            3276.5908
V Predictions Min            32.532764
Log Pis Mean                 -6.2741146
Log Pis Std                  4.7731495
Log Pis Max                  25.907051
Log Pis Min                  -16.447939
Policy mu Mean               0.15097399
Policy mu Std                0.64016795
Policy mu Max                2.7912483
Policy mu Min                -4.0300927
Policy log std Mean          -0.30564392
Policy log std Std           0.1360097
Policy log std Max           -0.026224382
Policy log std Min           -1.2257377
Z mean eval                  0.0500759
Z variance eval              0.15908569
total_rewards                [5680.95902003 5550.7900729  4858.00214103 5557.97791012 5596.24037896
 5576.59511801 2364.01063757 5512.97185265 5716.97090894 5587.21365157]
total_rewards_mean           5200.173169177664
total_rewards_std            972.4349012584667
total_rewards_max            5716.970908941395
total_rewards_min            2364.0106375669275
Number of train steps total  1928000
Number of env steps total    2412000
Number of rollouts total     0
Train Time (s)               196.00810744287446
(Previous) Eval Time (s)     24.342773600947112
Sample Time (s)              18.856577850412577
Epoch Time (s)               239.20745889423415
Total Train Time (s)         112512.85685641877
Epoch                        481
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:45:33.212154 UTC | [2020_01_13_04_30_18] Iteration #481 | Epoch Duration: 239.55945467948914
2020-01-14 11:45:33.212433 UTC | [2020_01_13_04_30_18] Iteration #481 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04943164
Z variance train             0.15888257
KL Divergence                2.535391
KL Loss                      0.25353912
QF Loss                      411.97086
VF Loss                      235.9862
Policy Loss                  -3185.2378
Q Predictions Mean           3180.2295
Q Predictions Std            61.608616
Q Predictions Max            3277.0203
Q Predictions Min            2851.205
V Predictions Mean           3193.2734
V Predictions Std            62.842754
V Predictions Max            3294.1035
V Predictions Min            2848.1714
Log Pis Mean                 -7.284648
Log Pis Std                  3.1826847
Log Pis Max                  3.9580739
Log Pis Min                  -15.690022
Policy mu Mean               0.1960113
Policy mu Std                0.57427466
Policy mu Max                2.4685068
Policy mu Min                -2.0270734
Policy log std Mean          -0.28010437
Policy log std Std           0.12971757
Policy log std Max           -0.03813766
Policy log std Min           -1.0514603
Z mean eval                  0.041383706
Z variance eval              0.18200752
total_rewards                [5618.74381535 5696.74345828 5562.91119684  980.46811801 5586.76299393
 5569.35567777 5647.2682772  5619.05108365 3226.46130487 5581.16684998]
total_rewards_mean           4908.893277588351
total_rewards_std            1490.3901552685722
total_rewards_max            5696.743458276844
total_rewards_min            980.4681180085774
Number of train steps total  1932000
Number of env steps total    2417000
Number of rollouts total     0
Train Time (s)               195.55979848187417
(Previous) Eval Time (s)     24.69449232891202
Sample Time (s)              18.621218157932162
Epoch Time (s)               238.87550896871835
Total Train Time (s)         112750.249284124
Epoch                        482
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:49:30.608197 UTC | [2020_01_13_04_30_18] Iteration #482 | Epoch Duration: 237.39557480812073
2020-01-14 11:49:30.608318 UTC | [2020_01_13_04_30_18] Iteration #482 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04137825
Z variance train             0.18202671
KL Divergence                2.2338066
KL Loss                      0.22338067
QF Loss                      715.69275
VF Loss                      510.94968
Policy Loss                  -3182.2666
Q Predictions Mean           3173.5142
Q Predictions Std            119.894516
Q Predictions Max            3276.7834
Q Predictions Min            2233.1926
V Predictions Mean           3179.9111
V Predictions Std            115.494576
V Predictions Max            3279.6553
V Predictions Min            2266.586
Log Pis Mean                 -6.027782
Log Pis Std                  4.9364223
Log Pis Max                  31.452585
Log Pis Min                  -15.219
Policy mu Mean               0.18070145
Policy mu Std                0.6272633
Policy mu Max                3.9666579
Policy mu Min                -2.7804437
Policy log std Mean          -0.30899325
Policy log std Std           0.12827076
Policy log std Max           -0.0058956295
Policy log std Min           -1.1641576
Z mean eval                  0.037872434
Z variance eval              0.22169423
total_rewards                [5438.82760281 5605.46974801 5471.88283651 5437.4431592  5430.45572964
 3139.74926455 3175.24606159 1407.70286623 5528.15591226 5520.85859873]
total_rewards_mean           4615.579177954185
total_rewards_std            1411.5874907322886
total_rewards_max            5605.469748009019
total_rewards_min            1407.7028662320984
Number of train steps total  1936000
Number of env steps total    2422000
Number of rollouts total     0
Train Time (s)               192.5780829237774
(Previous) Eval Time (s)     23.21428133128211
Sample Time (s)              18.536966773681343
Epoch Time (s)               234.32933102874085
Total Train Time (s)         112981.45221567526
Epoch                        483
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:53:21.818075 UTC | [2020_01_13_04_30_18] Iteration #483 | Epoch Duration: 231.20965600013733
2020-01-14 11:53:21.818236 UTC | [2020_01_13_04_30_18] Iteration #483 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038637683
Z variance train             0.22161917
KL Divergence                1.8433877
KL Loss                      0.18433878
QF Loss                      614.20654
VF Loss                      362.2148
Policy Loss                  -3171.6636
Q Predictions Mean           3162.6646
Q Predictions Std            271.65668
Q Predictions Max            3267.5208
Q Predictions Min            25.930952
V Predictions Mean           3158.23
V Predictions Std            273.91376
V Predictions Max            3267.6348
V Predictions Min            25.904991
Log Pis Mean                 -7.4425573
Log Pis Std                  3.5074234
Log Pis Max                  24.261827
Log Pis Min                  -14.020008
Policy mu Mean               0.17240697
Policy mu Std                0.55041367
Policy mu Max                2.953093
Policy mu Min                -2.2982183
Policy log std Mean          -0.28095913
Policy log std Std           0.11527169
Policy log std Max           0.1256265
Policy log std Min           -1.1305879
Z mean eval                  0.0414952
Z variance eval              0.254462
total_rewards                [1024.41766409 5751.99914717 5615.73444569 5698.25105596 5539.25597876
 5666.8674189  5645.2050049  1497.12798404 5684.88486295 5625.8217728 ]
total_rewards_mean           4774.956533524855
total_rewards_std            1761.0686143384517
total_rewards_max            5751.999147170215
total_rewards_min            1024.417664088018
Number of train steps total  1940000
Number of env steps total    2427000
Number of rollouts total     0
Train Time (s)               190.4500694689341
(Previous) Eval Time (s)     20.094329779036343
Sample Time (s)              18.58631098130718
Epoch Time (s)               229.1307102292776
Total Train Time (s)         113212.90563891921
Epoch                        484
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 11:57:13.276170 UTC | [2020_01_13_04_30_18] Iteration #484 | Epoch Duration: 231.45781898498535
2020-01-14 11:57:13.276298 UTC | [2020_01_13_04_30_18] Iteration #484 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.041386656
Z variance train             0.25445566
KL Divergence                1.7154526
KL Loss                      0.17154525
QF Loss                      421.89386
VF Loss                      142.20407
Policy Loss                  -3187.5132
Q Predictions Mean           3184.694
Q Predictions Std            205.60675
Q Predictions Max            3297.6191
Q Predictions Min            36.003075
V Predictions Mean           3190.5654
V Predictions Std            206.39249
V Predictions Max            3288.5315
V Predictions Min            31.767616
Log Pis Mean                 -6.7490835
Log Pis Std                  3.5164883
Log Pis Max                  12.861544
Log Pis Min                  -15.541706
Policy mu Mean               0.18488292
Policy mu Std                0.58522063
Policy mu Max                2.7419891
Policy mu Min                -2.6390946
Policy log std Mean          -0.2858348
Policy log std Std           0.12473815
Policy log std Max           -0.04648814
Policy log std Min           -1.157017
Z mean eval                  0.035740886
Z variance eval              0.2335482
total_rewards                [5503.07243614 5551.70479618 5543.05265579 5578.20083646 5430.81706623
 5588.36627535 5646.5704155  5665.77247786 5633.93326646 5539.58695123]
total_rewards_mean           5568.107717719371
total_rewards_std            67.32654774092278
total_rewards_max            5665.7724778563015
total_rewards_min            5430.817066228574
Number of train steps total  1944000
Number of env steps total    2432000
Number of rollouts total     0
Train Time (s)               192.52196829766035
(Previous) Eval Time (s)     22.42117184167728
Sample Time (s)              18.651119132060558
Epoch Time (s)               233.5942592713982
Total Train Time (s)         113448.07023064746
Epoch                        485
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:01:08.447578 UTC | [2020_01_13_04_30_18] Iteration #485 | Epoch Duration: 235.17116165161133
2020-01-14 12:01:08.447798 UTC | [2020_01_13_04_30_18] Iteration #485 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03526266
Z variance train             0.2335866
KL Divergence                1.8222382
KL Loss                      0.18222383
QF Loss                      879.8156
VF Loss                      369.42215
Policy Loss                  -3169.357
Q Predictions Mean           3165.3271
Q Predictions Std            288.70386
Q Predictions Max            3285.014
Q Predictions Min            23.918476
V Predictions Mean           3175.213
V Predictions Std            281.22385
V Predictions Max            3294.346
V Predictions Min            32.466877
Log Pis Mean                 -7.047641
Log Pis Std                  3.265842
Log Pis Max                  10.862874
Log Pis Min                  -14.260664
Policy mu Mean               0.16858193
Policy mu Std                0.5506189
Policy mu Max                2.4494548
Policy mu Min                -2.0783594
Policy log std Mean          -0.28280154
Policy log std Std           0.11495343
Policy log std Max           -0.067592844
Policy log std Min           -0.89596736
Z mean eval                  0.053112835
Z variance eval              0.2137826
total_rewards                [ 501.77603322 2035.91719919 5526.20210541 5535.71397343 5626.86191687
 5690.98327064 5532.34199041 5562.34106607 5348.97651766 5693.49056944]
total_rewards_mean           4705.460464232938
total_rewards_std            1754.6763642726198
total_rewards_max            5693.4905694362515
total_rewards_min            501.77603322166135
Number of train steps total  1948000
Number of env steps total    2437000
Number of rollouts total     0
Train Time (s)               192.5248944601044
(Previous) Eval Time (s)     23.99775336915627
Sample Time (s)              18.81325355730951
Epoch Time (s)               235.33590138657019
Total Train Time (s)         113681.21062932955
Epoch                        486
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:05:01.597203 UTC | [2020_01_13_04_30_18] Iteration #486 | Epoch Duration: 233.1492567062378
2020-01-14 12:05:01.597333 UTC | [2020_01_13_04_30_18] Iteration #486 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.052700877
Z variance train             0.21391265
KL Divergence                2.0153656
KL Loss                      0.20153657
QF Loss                      748.5939
VF Loss                      212.95607
Policy Loss                  -3150.6157
Q Predictions Mean           3146.669
Q Predictions Std            352.041
Q Predictions Max            3283.7146
Q Predictions Min            17.797462
V Predictions Mean           3155.3357
V Predictions Std            352.45953
V Predictions Max            3295.5178
V Predictions Min            7.883547
Log Pis Mean                 -6.800606
Log Pis Std                  4.282069
Log Pis Max                  16.638329
Log Pis Min                  -14.295329
Policy mu Mean               0.16947848
Policy mu Std                0.5940052
Policy mu Max                2.5175674
Policy mu Min                -2.6149998
Policy log std Mean          -0.29289684
Policy log std Std           0.12244115
Policy log std Max           -0.07468544
Policy log std Min           -0.94049555
Z mean eval                  0.06063785
Z variance eval              0.19661413
total_rewards                [5641.37182205 5598.3700219  5648.18083589 5690.16020903 5703.01628567
 5502.10713046 5721.63662876 5571.73862481 5592.65306872 2136.69681802]
total_rewards_mean           5280.593144530256
total_rewards_std            1049.8699728545755
total_rewards_max            5721.636628760721
total_rewards_min            2136.6968180222734
Number of train steps total  1952000
Number of env steps total    2442000
Number of rollouts total     0
Train Time (s)               195.00630197720602
(Previous) Eval Time (s)     21.810853556264192
Sample Time (s)              18.663968602661043
Epoch Time (s)               235.48112413613126
Total Train Time (s)         113917.13635373767
Epoch                        487
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:08:57.533402 UTC | [2020_01_13_04_30_18] Iteration #487 | Epoch Duration: 235.9359655380249
2020-01-14 12:08:57.533619 UTC | [2020_01_13_04_30_18] Iteration #487 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.061020862
Z variance train             0.19662617
KL Divergence                2.213832
KL Loss                      0.2213832
QF Loss                      973.26965
VF Loss                      140.20827
Policy Loss                  -3163.7212
Q Predictions Mean           3157.8706
Q Predictions Std            240.71933
Q Predictions Max            3283.711
Q Predictions Min            531.45514
V Predictions Mean           3163.6628
V Predictions Std            242.97757
V Predictions Max            3287.7322
V Predictions Min            502.15384
Log Pis Mean                 -6.8049397
Log Pis Std                  4.9577928
Log Pis Max                  25.752914
Log Pis Min                  -17.104393
Policy mu Mean               0.18285532
Policy mu Std                0.6074851
Policy mu Max                4.266525
Policy mu Min                -2.9352674
Policy log std Mean          -0.2773434
Policy log std Std           0.122386105
Policy log std Max           0.2615438
Policy log std Min           -1.5479342
Z mean eval                  0.050743043
Z variance eval              0.19003873
total_rewards                [5552.66211027 5677.21907456 4235.10953717 1976.17281286 5595.18107983
 5630.84572106 5711.25735548 5634.7410508  5751.95121849 4917.46914608]
total_rewards_mean           5068.260910659164
total_rewards_std            1126.0233517709037
total_rewards_max            5751.951218487463
total_rewards_min            1976.1728128632694
Number of train steps total  1956000
Number of env steps total    2447000
Number of rollouts total     0
Train Time (s)               193.81083552120253
(Previous) Eval Time (s)     22.2653995170258
Sample Time (s)              18.678095943294466
Epoch Time (s)               234.7543309815228
Total Train Time (s)         114153.0385686392
Epoch                        488
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:12:53.444567 UTC | [2020_01_13_04_30_18] Iteration #488 | Epoch Duration: 235.91076827049255
2020-01-14 12:12:53.444814 UTC | [2020_01_13_04_30_18] Iteration #488 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05070871
Z variance train             0.19004413
KL Divergence                2.2406259
KL Loss                      0.22406259
QF Loss                      539.4112
VF Loss                      138.5287
Policy Loss                  -3166.7888
Q Predictions Mean           3156.2976
Q Predictions Std            277.69424
Q Predictions Max            3282.9587
Q Predictions Min            26.646765
V Predictions Mean           3167.306
V Predictions Std            268.2561
V Predictions Max            3296.286
V Predictions Min            63.51799
Log Pis Mean                 -6.6169868
Log Pis Std                  4.0707293
Log Pis Max                  28.851074
Log Pis Min                  -15.1964855
Policy mu Mean               0.17167708
Policy mu Std                0.6114995
Policy mu Max                2.9884367
Policy mu Min                -2.5630276
Policy log std Mean          -0.28521058
Policy log std Std           0.13171585
Policy log std Max           0.008019216
Policy log std Min           -1.2689689
Z mean eval                  0.036973845
Z variance eval              0.210951
total_rewards                [5471.99692168 5674.49073025 5469.5789526  5779.07953716 5763.39137584
 5679.68511334 5669.72254147 5625.30215575 5603.34329502 5708.3034509 ]
total_rewards_mean           5644.48940740162
total_rewards_std            100.75138681012864
total_rewards_max            5779.079537164187
total_rewards_min            5469.578952596061
Number of train steps total  1960000
Number of env steps total    2452000
Number of rollouts total     0
Train Time (s)               191.93642868613824
(Previous) Eval Time (s)     23.421535958070308
Sample Time (s)              16.529360932763666
Epoch Time (s)               231.88732557697222
Total Train Time (s)         114385.04600348091
Epoch                        489
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:16:45.459501 UTC | [2020_01_13_04_30_18] Iteration #489 | Epoch Duration: 232.014399766922
2020-01-14 12:16:45.459758 UTC | [2020_01_13_04_30_18] Iteration #489 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03673669
Z variance train             0.21092074
KL Divergence                2.0552826
KL Loss                      0.20552826
QF Loss                      483.84558
VF Loss                      117.83623
Policy Loss                  -3180.9644
Q Predictions Mean           3169.5771
Q Predictions Std            255.7414
Q Predictions Max            3272.4548
Q Predictions Min            24.379066
V Predictions Mean           3179.9011
V Predictions Std            256.88168
V Predictions Max            3284.5696
V Predictions Min            24.109798
Log Pis Mean                 -6.5787387
Log Pis Std                  3.7880456
Log Pis Max                  13.579598
Log Pis Min                  -13.139616
Policy mu Mean               0.19394346
Policy mu Std                0.59595007
Policy mu Max                3.1138408
Policy mu Min                -3.0849285
Policy log std Mean          -0.29197812
Policy log std Std           0.13006267
Policy log std Max           -0.034031007
Policy log std Min           -1.1514312
Z mean eval                  0.04464335
Z variance eval              0.19857016
total_rewards                [5746.56124163 5757.50823372 5680.63556508 5731.04813    5517.74235179
 5575.28305089 5752.73236681 5664.1144648  5647.64824297 5646.11528693]
total_rewards_mean           5671.9388934631115
total_rewards_std            75.77913137770798
total_rewards_max            5757.508233722741
total_rewards_min            5517.74235179235
Number of train steps total  1964000
Number of env steps total    2457000
Number of rollouts total     0
Train Time (s)               195.0091020418331
(Previous) Eval Time (s)     23.54833107581362
Sample Time (s)              18.424069258850068
Epoch Time (s)               236.9815023764968
Total Train Time (s)         114624.74136831518
Epoch                        490
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:20:45.157599 UTC | [2020_01_13_04_30_18] Iteration #490 | Epoch Duration: 239.69767451286316
2020-01-14 12:20:45.157716 UTC | [2020_01_13_04_30_18] Iteration #490 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.044588555
Z variance train             0.19852598
KL Divergence                2.1518793
KL Loss                      0.21518794
QF Loss                      3205.1396
VF Loss                      190.00638
Policy Loss                  -3180.186
Q Predictions Mean           3172.5312
Q Predictions Std            201.56966
Q Predictions Max            3278.8545
Q Predictions Min            417.61975
V Predictions Mean           3174.749
V Predictions Std            208.27892
V Predictions Max            3283.5833
V Predictions Min            378.46198
Log Pis Mean                 -6.817388
Log Pis Std                  4.0307746
Log Pis Max                  18.17604
Log Pis Min                  -17.137741
Policy mu Mean               0.1905001
Policy mu Std                0.5929029
Policy mu Max                2.796209
Policy mu Min                -3.4246707
Policy log std Mean          -0.2847598
Policy log std Std           0.114860944
Policy log std Max           -0.03034874
Policy log std Min           -0.95777106
Z mean eval                  0.06072409
Z variance eval              0.18420479
total_rewards                [5073.95290774 5727.14097546 5633.52691302 5706.12692099 5661.96088646
 5761.87915811 5655.29566541 5603.76819426 5573.27706315 5671.3908691 ]
total_rewards_mean           5606.831955370131
total_rewards_std            185.4015066706019
total_rewards_max            5761.879158111914
total_rewards_min            5073.95290773958
Number of train steps total  1968000
Number of env steps total    2462000
Number of rollouts total     0
Train Time (s)               196.48869758611545
(Previous) Eval Time (s)     26.26425479305908
Sample Time (s)              16.8573837550357
Epoch Time (s)               239.61033613421023
Total Train Time (s)         114864.31612112466
Epoch                        491
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:24:44.739386 UTC | [2020_01_13_04_30_18] Iteration #491 | Epoch Duration: 239.5815727710724
2020-01-14 12:24:44.739572 UTC | [2020_01_13_04_30_18] Iteration #491 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.060457177
Z variance train             0.18417749
KL Divergence                2.2786064
KL Loss                      0.22786064
QF Loss                      962.34875
VF Loss                      114.9247
Policy Loss                  -3182.761
Q Predictions Mean           3179.544
Q Predictions Std            182.19379
Q Predictions Max            3288.951
Q Predictions Min            804.1472
V Predictions Mean           3185.3213
V Predictions Std            178.83896
V Predictions Max            3286.961
V Predictions Min            805.7436
Log Pis Mean                 -6.3727984
Log Pis Std                  4.4557056
Log Pis Max                  18.72899
Log Pis Min                  -15.422452
Policy mu Mean               0.20309299
Policy mu Std                0.6003686
Policy mu Max                2.9108927
Policy mu Min                -2.6092007
Policy log std Mean          -0.3028442
Policy log std Std           0.13329871
Policy log std Max           -0.07015748
Policy log std Min           -1.2419583
Z mean eval                  0.04106768
Z variance eval              0.17813374
total_rewards                [5482.18557683 5451.04581344 5488.14809225 5438.19935713 5485.36935186
 5371.89846193 5437.47331101 5493.20345374 5504.30290277 5500.4545976 ]
total_rewards_mean           5465.228091856002
total_rewards_std            38.96326308348658
total_rewards_max            5504.302902773212
total_rewards_min            5371.898461925181
Number of train steps total  1972000
Number of env steps total    2467000
Number of rollouts total     0
Train Time (s)               195.0825360729359
(Previous) Eval Time (s)     26.235181108117104
Sample Time (s)              16.42329627368599
Epoch Time (s)               237.741013454739
Total Train Time (s)         115099.48671518452
Epoch                        492
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:28:39.915796 UTC | [2020_01_13_04_30_18] Iteration #492 | Epoch Duration: 235.17609667778015
2020-01-14 12:28:39.915980 UTC | [2020_01_13_04_30_18] Iteration #492 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04060597
Z variance train             0.17814407
KL Divergence                2.4175262
KL Loss                      0.24175262
QF Loss                      495.565
VF Loss                      223.38678
Policy Loss                  -3193.5203
Q Predictions Mean           3186.5366
Q Predictions Std            101.9673
Q Predictions Max            3292.8767
Q Predictions Min            2246.187
V Predictions Mean           3187.1665
V Predictions Std            105.71342
V Predictions Max            3300.024
V Predictions Min            2253.2131
Log Pis Mean                 -6.7219524
Log Pis Std                  3.6142266
Log Pis Max                  8.811376
Log Pis Min                  -14.1611185
Policy mu Mean               0.15891103
Policy mu Std                0.5923412
Policy mu Max                2.0806847
Policy mu Min                -1.9641345
Policy log std Mean          -0.28284276
Policy log std Std           0.12737046
Policy log std Max           -0.031049572
Policy log std Min           -0.90492815
Z mean eval                  0.045663007
Z variance eval              0.19733718
total_rewards                [5400.66399241 5622.1552643  5365.99670643 2126.96186868 5426.51850827
 5552.49383044 5631.49889126 5417.757357   5535.77751734 5469.1427058 ]
total_rewards_mean           5154.896664193725
total_rewards_std            1013.0948963993418
total_rewards_max            5631.498891261137
total_rewards_min            2126.961868682941
Number of train steps total  1976000
Number of env steps total    2472000
Number of rollouts total     0
Train Time (s)               194.62652276735753
(Previous) Eval Time (s)     23.669994342140853
Sample Time (s)              18.69450913090259
Epoch Time (s)               236.99102624040097
Total Train Time (s)         115337.990405221
Epoch                        493
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:32:38.422468 UTC | [2020_01_13_04_30_18] Iteration #493 | Epoch Duration: 238.50635886192322
2020-01-14 12:32:38.422602 UTC | [2020_01_13_04_30_18] Iteration #493 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045991816
Z variance train             0.19708808
KL Divergence                2.1339107
KL Loss                      0.21339107
QF Loss                      581.2085
VF Loss                      112.91348
Policy Loss                  -3181.687
Q Predictions Mean           3174.9521
Q Predictions Std            280.12463
Q Predictions Max            3299.8599
Q Predictions Min            24.872335
V Predictions Mean           3177.1445
V Predictions Std            277.44937
V Predictions Max            3294.091
V Predictions Min            29.817158
Log Pis Mean                 -6.9288583
Log Pis Std                  4.1431255
Log Pis Max                  22.541924
Log Pis Min                  -14.0071335
Policy mu Mean               0.13422614
Policy mu Std                0.58187383
Policy mu Max                2.3819551
Policy mu Min                -3.4631968
Policy log std Mean          -0.2708627
Policy log std Std           0.11384568
Policy log std Max           -0.061445266
Policy log std Min           -1.2384443
Z mean eval                  0.058370374
Z variance eval              0.1773534
total_rewards                [5747.42354574 5145.66306525 5592.71883544 5690.9914281  5679.63499213
 5698.7878803  5411.3580643  5751.58799643 5732.54425675 5744.80441191]
total_rewards_mean           5619.551447635151
total_rewards_std            185.97510369665568
total_rewards_max            5751.5879964292935
total_rewards_min            5145.663065251949
Number of train steps total  1980000
Number of env steps total    2477000
Number of rollouts total     0
Train Time (s)               196.18664875999093
(Previous) Eval Time (s)     25.185059503186494
Sample Time (s)              17.89553840784356
Epoch Time (s)               239.26724667102098
Total Train Time (s)         115576.63916022843
Epoch                        494
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:36:37.081963 UTC | [2020_01_13_04_30_18] Iteration #494 | Epoch Duration: 238.65920615196228
2020-01-14 12:36:37.082296 UTC | [2020_01_13_04_30_18] Iteration #494 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0582544
Z variance train             0.17770655
KL Divergence                2.2960742
KL Loss                      0.22960742
QF Loss                      1110.6719
VF Loss                      513.68585
Policy Loss                  -3186.662
Q Predictions Mean           3182.3638
Q Predictions Std            220.14578
Q Predictions Max            3291.7212
Q Predictions Min            22.03629
V Predictions Mean           3186.2915
V Predictions Std            212.17789
V Predictions Max            3288.622
V Predictions Min            33.495625
Log Pis Mean                 -6.804429
Log Pis Std                  3.9403625
Log Pis Max                  16.455761
Log Pis Min                  -16.910946
Policy mu Mean               0.1898479
Policy mu Std                0.57395047
Policy mu Max                2.9064405
Policy mu Min                -2.570997
Policy log std Mean          -0.29587674
Policy log std Std           0.12698798
Policy log std Max           -0.07618462
Policy log std Min           -1.249199
Z mean eval                  0.05711935
Z variance eval              0.17229435
total_rewards                [5534.76729485 5470.35808258 5573.88790161 5530.91210601 5501.45925662
 5498.99535052 5751.63874211 5580.13605248 5692.19243628 5576.88812491]
total_rewards_mean           5571.123534796845
total_rewards_std            83.9723257072685
total_rewards_max            5751.638742110718
total_rewards_min            5470.358082575496
Number of train steps total  1984000
Number of env steps total    2482000
Number of rollouts total     0
Train Time (s)               192.37358496058732
(Previous) Eval Time (s)     24.576686702203006
Sample Time (s)              18.91912359278649
Epoch Time (s)               235.86939525557682
Total Train Time (s)         115814.34883291041
Epoch                        495
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:40:34.794709 UTC | [2020_01_13_04_30_18] Iteration #495 | Epoch Duration: 237.7122073173523
2020-01-14 12:40:34.794840 UTC | [2020_01_13_04_30_18] Iteration #495 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05703733
Z variance train             0.17235541
KL Divergence                2.3673065
KL Loss                      0.23673065
QF Loss                      287.56998
VF Loss                      142.46513
Policy Loss                  -3199.002
Q Predictions Mean           3196.5005
Q Predictions Std            193.02393
Q Predictions Max            3287.7673
Q Predictions Min            216.9567
V Predictions Mean           3197.7158
V Predictions Std            195.28214
V Predictions Max            3292.052
V Predictions Min            197.08003
Log Pis Mean                 -7.158081
Log Pis Std                  3.324274
Log Pis Max                  6.0947227
Log Pis Min                  -13.989415
Policy mu Mean               0.1515124
Policy mu Std                0.57960427
Policy mu Max                2.1644874
Policy mu Min                -2.6371813
Policy log std Mean          -0.28915432
Policy log std Std           0.12001846
Policy log std Max           0.09546981
Policy log std Min           -0.9605641
Z mean eval                  0.032469843
Z variance eval              0.17329204
total_rewards                [5475.58456661 5513.80577233 5521.13695985 5454.89460209 5531.49476097
 5603.51049498 2989.18199466 5656.84343138 5521.12349201 5513.58688791]
total_rewards_mean           5278.116296279303
total_rewards_std            764.9894291313753
total_rewards_max            5656.843431381601
total_rewards_min            2989.181994663651
Number of train steps total  1988000
Number of env steps total    2487000
Number of rollouts total     0
Train Time (s)               196.0798659408465
(Previous) Eval Time (s)     26.41921042324975
Sample Time (s)              16.61194874206558
Epoch Time (s)               239.11102510616183
Total Train Time (s)         116052.34236933338
Epoch                        496
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:44:32.795587 UTC | [2020_01_13_04_30_18] Iteration #496 | Epoch Duration: 238.00062775611877
2020-01-14 12:44:32.795803 UTC | [2020_01_13_04_30_18] Iteration #496 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03267173
Z variance train             0.17330906
KL Divergence                2.364024
KL Loss                      0.23640239
QF Loss                      329.61908
VF Loss                      70.10273
Policy Loss                  -3198.3267
Q Predictions Mean           3191.5613
Q Predictions Std            206.44885
Q Predictions Max            3289.2678
Q Predictions Min            21.822662
V Predictions Mean           3194.164
V Predictions Std            206.40837
V Predictions Max            3296.1855
V Predictions Min            33.846363
Log Pis Mean                 -7.4622064
Log Pis Std                  3.1573107
Log Pis Max                  6.754093
Log Pis Min                  -14.45866
Policy mu Mean               0.17777771
Policy mu Std                0.5378404
Policy mu Max                2.243845
Policy mu Min                -1.7988539
Policy log std Mean          -0.28167376
Policy log std Std           0.11462443
Policy log std Max           -0.07073884
Policy log std Min           -0.87022734
Z mean eval                  0.055660002
Z variance eval              0.16818954
total_rewards                [5693.16289749 5715.33035446 5585.6732864  5591.54393418 5555.63435294
 5639.81394886 5694.46943425 5626.24073682 5561.0771586  5635.0725838 ]
total_rewards_mean           5629.8018687789845
total_rewards_std            54.11769325223829
total_rewards_max            5715.330354459539
total_rewards_min            5555.634352938111
Number of train steps total  1992000
Number of env steps total    2492000
Number of rollouts total     0
Train Time (s)               194.89454677235335
(Previous) Eval Time (s)     25.308553909882903
Sample Time (s)              18.87133543100208
Epoch Time (s)               239.07443611323833
Total Train Time (s)         116292.70744666178
Epoch                        497
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:48:33.169985 UTC | [2020_01_13_04_30_18] Iteration #497 | Epoch Duration: 240.37401366233826
2020-01-14 12:48:33.170186 UTC | [2020_01_13_04_30_18] Iteration #497 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05542495
Z variance train             0.16819413
KL Divergence                2.3986278
KL Loss                      0.23986278
QF Loss                      467.4756
VF Loss                      210.77759
Policy Loss                  -3162.1128
Q Predictions Mean           3158.1182
Q Predictions Std            347.72748
Q Predictions Max            3298.804
Q Predictions Min            23.157707
V Predictions Mean           3164.8105
V Predictions Std            346.3677
V Predictions Max            3306.8354
V Predictions Min            37.74226
Log Pis Mean                 -6.6541348
Log Pis Std                  3.7831774
Log Pis Max                  13.366666
Log Pis Min                  -15.459376
Policy mu Mean               0.1612459
Policy mu Std                0.6010348
Policy mu Max                2.3515763
Policy mu Min                -2.440658
Policy log std Mean          -0.28265595
Policy log std Std           0.12053592
Policy log std Max           -0.0065966696
Policy log std Min           -0.9597635
Z mean eval                  0.03197189
Z variance eval              0.17088684
total_rewards                [5716.61306327 5652.39985027 5585.43004773 5566.04759944 1471.50804793
 5494.01186011 5701.69430126 5601.77182473 5521.8563331  5590.65270726]
total_rewards_mean           5190.198563508911
total_rewards_std            1241.3925722856566
total_rewards_max            5716.613063265097
total_rewards_min            1471.508047932289
Number of train steps total  1996000
Number of env steps total    2497000
Number of rollouts total     0
Train Time (s)               198.75358495209366
(Previous) Eval Time (s)     26.607858079951257
Sample Time (s)              19.050462575163692
Epoch Time (s)               244.4119056072086
Total Train Time (s)         116532.83394607343
Epoch                        498
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:52:33.303505 UTC | [2020_01_13_04_30_18] Iteration #498 | Epoch Duration: 240.13310599327087
2020-01-14 12:52:33.303809 UTC | [2020_01_13_04_30_18] Iteration #498 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03195072
Z variance train             0.17072693
KL Divergence                2.4238026
KL Loss                      0.24238026
QF Loss                      783.187
VF Loss                      380.41922
Policy Loss                  -3193.8892
Q Predictions Mean           3189.3862
Q Predictions Std            125.74324
Q Predictions Max            3295.7698
Q Predictions Min            1853.453
V Predictions Mean           3191.9697
V Predictions Std            122.30929
V Predictions Max            3299.252
V Predictions Min            2062.4326
Log Pis Mean                 -6.581411
Log Pis Std                  4.202236
Log Pis Max                  18.121437
Log Pis Min                  -13.486789
Policy mu Mean               0.20928252
Policy mu Std                0.6003953
Policy mu Max                3.0984108
Policy mu Min                -2.3961844
Policy log std Mean          -0.2844218
Policy log std Std           0.123155065
Policy log std Max           -0.040198497
Policy log std Min           -1.0960543
Z mean eval                  0.042737674
Z variance eval              0.15146741
total_rewards                [5622.54565846 5584.82150146 5647.31689097 5622.78719767 5551.7353631
 5526.61486958 5579.15187527 5550.21895568 5566.21176326 4436.87184687]
total_rewards_mean           5468.82759223159
total_rewards_std            345.84262710774846
total_rewards_max            5647.316890974979
total_rewards_min            4436.8718468714205
Number of train steps total  2000000
Number of env steps total    2502000
Number of rollouts total     0
Train Time (s)               193.2618174511008
(Previous) Eval Time (s)     22.328734258189797
Sample Time (s)              16.879921594634652
Epoch Time (s)               232.47047330392525
Total Train Time (s)         116769.04050166905
Epoch                        499
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 12:56:29.512441 UTC | [2020_01_13_04_30_18] Iteration #499 | Epoch Duration: 236.20847749710083
2020-01-14 12:56:29.512582 UTC | [2020_01_13_04_30_18] Iteration #499 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.042760454
Z variance train             0.15148702
KL Divergence                2.6788664
KL Loss                      0.26788664
QF Loss                      477.42072
VF Loss                      246.96945
Policy Loss                  -3133.9097
Q Predictions Mean           3126.0083
Q Predictions Std            438.0142
Q Predictions Max            3282.76
Q Predictions Min            21.302143
V Predictions Mean           3128.3496
V Predictions Std            436.00815
V Predictions Max            3296.7004
V Predictions Min            31.903215
Log Pis Mean                 -6.665923
Log Pis Std                  5.210039
Log Pis Max                  43.19295
Log Pis Min                  -14.888539
Policy mu Mean               0.18207991
Policy mu Std                0.6165669
Policy mu Max                3.5715177
Policy mu Min                -3.4156246
Policy log std Mean          -0.28756937
Policy log std Std           0.12507658
Policy log std Max           -0.066259965
Policy log std Min           -1.4248517
Z mean eval                  0.063471526
Z variance eval              0.18234602
total_rewards                [5694.88437584 5798.78267293 5729.71269965 2859.87683332 1913.42267841
 1491.67668193 5621.96087744 3879.83433679 5690.54308843 5672.57644329]
total_rewards_mean           4435.327068802616
total_rewards_std            1656.836684650912
total_rewards_max            5798.782672926166
total_rewards_min            1491.6766819340417
Number of train steps total  2004000
Number of env steps total    2507000
Number of rollouts total     0
Train Time (s)               196.08170982310548
(Previous) Eval Time (s)     26.066430373117328
Sample Time (s)              18.85584269091487
Epoch Time (s)               241.00398288713768
Total Train Time (s)         117004.6682272451
Epoch                        500
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-14 13:00:25.144252 UTC | [2020_01_13_04_30_18] Iteration #500 | Epoch Duration: 235.63151168823242
2020-01-14 13:00:25.144433 UTC | [2020_01_13_04_30_18] Iteration #500 | Started Training: True
