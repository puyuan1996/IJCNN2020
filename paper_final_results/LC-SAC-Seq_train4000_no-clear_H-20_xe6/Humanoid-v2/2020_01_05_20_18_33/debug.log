---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.006943104
Z variance train             0.0068859197
KL Divergence                9.963152
KL Loss                      0.9963152
QF Loss                      1119.0573
VF Loss                      131.84372
Policy Loss                  -11.51557
Q Predictions Mean           -0.008285135
Q Predictions Std            0.03862575
Q Predictions Max            0.20809883
Q Predictions Min            -0.2462841
V Predictions Mean           0.074856326
V Predictions Std            0.10970629
V Predictions Max            0.8067758
V Predictions Min            -0.01146394
Log Pis Mean                 -11.359797
Log Pis Std                  0.98695993
Log Pis Max                  -7.7815304
Log Pis Min                  -14.043204
Policy mu Mean               -2.9637054e-05
Policy mu Std                0.024679717
Policy mu Max                0.24490777
Policy mu Min                -0.31587854
Policy log std Mean          0.005160166
Policy log std Std           0.024809
Policy log std Max           0.34781525
Policy log std Min           -0.1359852
Z mean eval                  0.0951514
Z variance eval              0.045305632
total_rewards                [273.85484536 279.77707294 252.65891008 246.17465917 290.14795914
 244.817088   214.97998031 229.24599103 226.30604683 242.277978  ]
total_rewards_mean           250.02405308481025
total_rewards_std            23.225653656627156
total_rewards_max            290.1479591369993
total_rewards_min            214.97998030805505
Number of train steps total  4000
Number of env steps total    7110
Number of rollouts total     0
Train Time (s)               120.56596375495428
(Previous) Eval Time (s)     0
Sample Time (s)              10.420814175042324
Epoch Time (s)               130.9867779299966
Total Train Time (s)         132.34237536101136
Epoch                        0
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 20:20:45.444508 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #0 | Epoch Duration: 132.34502005577087
2020-01-05 20:20:45.444637 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #0 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10922706
Z variance train             0.042813033
KL Divergence                5.520955
KL Loss                      0.55209553
QF Loss                      2814.853
VF Loss                      643.3747
Policy Loss                  -489.3463
Q Predictions Mean           470.74268
Q Predictions Std            139.7089
Q Predictions Max            641.12146
Q Predictions Min            7.7331433
V Predictions Mean           494.1817
V Predictions Std            128.84584
V Predictions Max            661.38824
V Predictions Min            35.789734
Log Pis Mean                 -1.7576535
Log Pis Std                  4.6608834
Log Pis Max                  16.928799
Log Pis Min                  -13.463448
Policy mu Mean               0.4047916
Policy mu Std                0.83102036
Policy mu Max                2.4626212
Policy mu Min                -2.2589636
Policy log std Mean          -0.29334077
Policy log std Std           0.14624026
Policy log std Max           -0.024157967
Policy log std Min           -0.77811235
Z mean eval                  0.37114963
Z variance eval              0.051399477
total_rewards                [214.24646444 215.21653323 282.95632362 252.9442551  186.34025862
 223.79022604 227.22371343 148.87248192 296.71113564 152.31527326]
total_rewards_mean           220.06166653080746
total_rewards_std            46.721771969245836
total_rewards_max            296.71113564274486
total_rewards_min            148.87248191658028
Number of train steps total  8000
Number of env steps total    12364
Number of rollouts total     0
Train Time (s)               113.33389348501805
(Previous) Eval Time (s)     1.3579798869905062
Sample Time (s)              9.504889805917628
Epoch Time (s)               124.19676317792619
Total Train Time (s)         256.35433895292226
Epoch                        1
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 20:22:49.457383 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #1 | Epoch Duration: 124.0126404762268
2020-01-05 20:22:49.457508 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #1 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.31108895
Z variance train             0.041853204
KL Divergence                5.8252063
KL Loss                      0.58252066
QF Loss                      7512.995
VF Loss                      3806.0178
Policy Loss                  -845.5283
Q Predictions Mean           801.97974
Q Predictions Std            303.00726
Q Predictions Max            1214.5424
Q Predictions Min            17.252533
V Predictions Mean           826.7396
V Predictions Std            289.15134
V Predictions Max            1120.115
V Predictions Min            0.32331285
Log Pis Mean                 2.2145827
Log Pis Std                  7.1508694
Log Pis Max                  24.325884
Log Pis Min                  -11.008411
Policy mu Mean               0.19800787
Policy mu Std                1.0818496
Policy mu Max                2.8319023
Policy mu Min                -2.4687092
Policy log std Mean          -0.3556279
Policy log std Std           0.15082695
Policy log std Max           0.04307904
Policy log std Min           -0.8427564
Z mean eval                  0.093883395
Z variance eval              0.021108937
total_rewards                [249.85681525 210.16260674 318.9109862  328.72050811 214.62457537
 225.81532369 236.13242774 332.60932672 273.37281436 315.13851546]
total_rewards_mean           270.5343899642071
total_rewards_std            46.8596984753186
total_rewards_max            332.6093267212485
total_rewards_min            210.16260673917833
Number of train steps total  12000
Number of env steps total    17558
Number of rollouts total     0
Train Time (s)               125.95280888600973
(Previous) Eval Time (s)     1.1736056060181
Sample Time (s)              8.457299165020231
Epoch Time (s)               135.58371365704807
Total Train Time (s)         392.2269863599795
Epoch                        2
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 20:25:05.330813 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #2 | Epoch Duration: 135.8732032775879
2020-01-05 20:25:05.330940 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #2 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.26425815
Z variance train             0.06103593
KL Divergence                4.905781
KL Loss                      0.4905781
QF Loss                      9320.73
VF Loss                      3553.3223
Policy Loss                  -824.65643
Q Predictions Mean           817.133
Q Predictions Std            428.30615
Q Predictions Max            1392.943
Q Predictions Min            14.116048
V Predictions Mean           857.4968
V Predictions Std            431.68658
V Predictions Max            1425.829
V Predictions Min            31.160383
Log Pis Mean                 0.26545325
Log Pis Std                  6.5900283
Log Pis Max                  33.384888
Log Pis Min                  -14.030455
Policy mu Mean               0.41757718
Policy mu Std                0.93226206
Policy mu Max                2.7888362
Policy mu Min                -2.5304065
Policy log std Mean          -0.33187172
Policy log std Std           0.14733376
Policy log std Max           -0.0171173
Policy log std Min           -0.8182511
Z mean eval                  0.04592084
Z variance eval              0.0145421205
total_rewards                [272.95379593 375.14476252 239.5295442  354.13492023 118.18736906
 310.3008031  285.48438625 320.24923288 219.31080979 228.27509035]
total_rewards_mean           272.3570714295819
total_rewards_std            71.24750169118288
total_rewards_max            375.14476251890534
total_rewards_min            118.18736905864397
Number of train steps total  16000
Number of env steps total    22858
Number of rollouts total     0
Train Time (s)               124.47897331399145
(Previous) Eval Time (s)     1.4628450309974141
Sample Time (s)              8.708748305100016
Epoch Time (s)               134.65056665008888
Total Train Time (s)         526.7696640520007
Epoch                        3
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 20:27:19.874583 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #3 | Epoch Duration: 134.54353713989258
2020-01-05 20:27:19.874720 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #3 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.052006602
Z variance train             0.016287936
KL Divergence                7.85151
KL Loss                      0.785151
QF Loss                      8351.932
VF Loss                      1988.4391
Policy Loss                  -862.28204
Q Predictions Mean           836.44727
Q Predictions Std            450.44714
Q Predictions Max            1474.1462
Q Predictions Min            22.71114
V Predictions Mean           874.2512
V Predictions Std            440.6234
V Predictions Max            1465.3071
V Predictions Min            42.730976
Log Pis Mean                 0.65069413
Log Pis Std                  6.2514234
Log Pis Max                  22.515902
Log Pis Min                  -11.915646
Policy mu Mean               0.3964839
Policy mu Std                0.9434518
Policy mu Max                2.9103622
Policy mu Min                -2.8535547
Policy log std Mean          -0.34266287
Policy log std Std           0.1306173
Policy log std Max           0.0023613125
Policy log std Min           -0.7840905
Z mean eval                  0.074817225
Z variance eval              0.06297706
total_rewards                [171.97268358 228.37569954 184.43767584 155.77721705 148.93562191
 216.65310176 197.43282608 237.16504125 208.0695504  160.52686783]
total_rewards_mean           190.93462852614942
total_rewards_std            29.77031179300195
total_rewards_max            237.16504125295202
total_rewards_min            148.93562191359607
Number of train steps total  20000
Number of env steps total    28110
Number of rollouts total     0
Train Time (s)               123.61850429995684
(Previous) Eval Time (s)     1.3555695369723253
Sample Time (s)              8.691388474020641
Epoch Time (s)               133.6654623109498
Total Train Time (s)         660.1422215030179
Epoch                        4
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 20:29:33.248628 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #4 | Epoch Duration: 133.373792886734
2020-01-05 20:29:33.248809 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #4 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.041293792
Z variance train             0.04050464
KL Divergence                5.638084
KL Loss                      0.5638084
QF Loss                      23278.723
VF Loss                      1922.8513
Policy Loss                  -889.2762
Q Predictions Mean           893.4884
Q Predictions Std            429.08978
Q Predictions Max            1601.2356
Q Predictions Min            -28.436306
V Predictions Mean           895.99695
V Predictions Std            422.46442
V Predictions Max            1543.8154
V Predictions Min            3.66669
Log Pis Mean                 0.2944922
Log Pis Std                  5.74108
Log Pis Max                  27.317944
Log Pis Min                  -11.267056
Policy mu Mean               0.33149886
Policy mu Std                0.9490874
Policy mu Max                2.8692238
Policy mu Min                -2.6224139
Policy log std Mean          -0.33373225
Policy log std Std           0.13748905
Policy log std Max           -0.035862885
Policy log std Min           -0.82202893
Z mean eval                  0.04527331
Z variance eval              0.012877049
total_rewards                [364.72940534 766.14101969 315.62841275 348.36133377 298.9837769
 345.72655736 274.19049382 472.41272591 241.60899703 329.6061708 ]
total_rewards_mean           375.73888933624704
total_rewards_std            142.64181801293012
total_rewards_max            766.1410196878564
total_rewards_min            241.60899703404374
Number of train steps total  24000
Number of env steps total    33357
Number of rollouts total     0
Train Time (s)               125.76889996102545
(Previous) Eval Time (s)     1.0636361140059307
Sample Time (s)              8.584572038031183
Epoch Time (s)               135.41710811306257
Total Train Time (s)         796.4268780229613
Epoch                        5
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-05 20:31:49.533158 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #5 | Epoch Duration: 136.2841956615448
2020-01-05 20:31:49.533306 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #5 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06491978
Z variance train             0.016798383
KL Divergence                7.7714095
KL Loss                      0.777141
QF Loss                      14374.219
VF Loss                      3679.491
Policy Loss                  -831.6261
Q Predictions Mean           815.8655
Q Predictions Std            381.51434
Q Predictions Max            1348.5793
Q Predictions Min            -13.082329
V Predictions Mean           842.35815
V Predictions Std            375.80124
V Predictions Max            1376.6583
V Predictions Min            -35.419647
Log Pis Mean                 -1.3512497
Log Pis Std                  7.8926697
Log Pis Max                  34.269966
Log Pis Min                  -13.108225
Policy mu Mean               0.23361431
Policy mu Std                0.90399766
Policy mu Max                3.074807
Policy mu Min                -2.4974465
Policy log std Mean          -0.2974605
Policy log std Std           0.1388856
Policy log std Max           0.010631695
Policy log std Min           -0.8688117
Z mean eval                  0.04686519
Z variance eval              0.012271633
total_rewards                [387.63863725 231.84237986 283.47781377 232.49275142 210.178406
 262.49395217 313.95562904 308.50591736 185.08819775 349.57096226]
total_rewards_mean           276.524464689252
total_rewards_std            60.867832858419824
total_rewards_max            387.6386372494143
total_rewards_min            185.08819774922569
Number of train steps total  28000
Number of env steps total    38771
Number of rollouts total     0
Train Time (s)               131.687823285989
(Previous) Eval Time (s)     1.9304740859661251
Sample Time (s)              9.439724522060715
Epoch Time (s)               143.05802189401584
Total Train Time (s)         939.1551823799382
Epoch                        6
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------
2020-01-05 20:34:12.263389 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #6 | Epoch Duration: 142.7299439907074
2020-01-05 20:34:12.263613 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #6 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034331344
Z variance train             0.011866384
KL Divergence                8.619019
KL Loss                      0.8619019
QF Loss                      3864.9592
VF Loss                      1396.3472
Policy Loss                  -816.69806
Q Predictions Mean           791.06824
Q Predictions Std            386.20618
Q Predictions Max            1339.3209
Q Predictions Min            41.225235
V Predictions Mean           806.5311
V Predictions Std            378.01736
V Predictions Max            1310.3163
V Predictions Min            28.223074
Log Pis Mean                 -2.871815
Log Pis Std                  6.5729113
Log Pis Max                  25.782349
Log Pis Min                  -16.291588
Policy mu Mean               0.310042
Policy mu Std                0.81554985
Policy mu Max                2.9254873
Policy mu Min                -2.1965911
Policy log std Mean          -0.29081342
Policy log std Std           0.12448213
Policy log std Max           0.000608325
Policy log std Min           -0.7908216
Z mean eval                  0.018110972
Z variance eval              0.008589425
total_rewards                [418.99324317 364.71156294 484.96947497 437.8382176  253.73063469
 351.47537038 395.51798119 430.68289822 348.87786976 513.79986145]
total_rewards_mean           400.0597114370717
total_rewards_std            71.0860746707979
total_rewards_max            513.7998614463794
total_rewards_min            253.7306346867478
Number of train steps total  32000
Number of env steps total    44329
Number of rollouts total     0
Train Time (s)               116.37112674099626
(Previous) Eval Time (s)     1.602122034993954
Sample Time (s)              9.47976463305531
Epoch Time (s)               127.45301340904552
Total Train Time (s)         1066.9391637520748
Epoch                        7
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 20:36:20.048246 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #7 | Epoch Duration: 127.78448462486267
2020-01-05 20:36:20.048410 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #7 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015508165
Z variance train             0.008545469
KL Divergence                9.428839
KL Loss                      0.9428839
QF Loss                      3717.3228
VF Loss                      1345.9607
Policy Loss                  -821.2663
Q Predictions Mean           813.1926
Q Predictions Std            375.0221
Q Predictions Max            1315.5297
Q Predictions Min            23.320314
V Predictions Mean           822.57324
V Predictions Std            369.66873
V Predictions Max            1313.7981
V Predictions Min            7.0106206
Log Pis Mean                 -2.1988986
Log Pis Std                  5.5474677
Log Pis Max                  23.28064
Log Pis Min                  -13.28009
Policy mu Mean               0.26135388
Policy mu Std                0.87595564
Policy mu Max                2.8620358
Policy mu Min                -1.9405602
Policy log std Mean          -0.3062635
Policy log std Std           0.12780128
Policy log std Max           0.053051636
Policy log std Min           -0.9900497
Z mean eval                  0.019281868
Z variance eval              0.0114415
total_rewards                [407.58703242 314.8239245  432.41922282 311.03604956 266.17540004
 302.52948275 370.46791564 325.75065725 327.36350209 257.62125946]
total_rewards_mean           331.57744465353613
total_rewards_std            53.66941155034801
total_rewards_max            432.41922282053156
total_rewards_min            257.62125945927363
Number of train steps total  36000
Number of env steps total    49757
Number of rollouts total     0
Train Time (s)               139.51612757600378
(Previous) Eval Time (s)     1.933317243005149
Sample Time (s)              8.522545415966306
Epoch Time (s)               149.97199023497524
Total Train Time (s)         1216.761373271991
Epoch                        8
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 20:38:49.871015 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #8 | Epoch Duration: 149.8224859237671
2020-01-05 20:38:49.871144 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #8 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017799268
Z variance train             0.010943364
KL Divergence                8.816143
KL Loss                      0.8816143
QF Loss                      3121.6013
VF Loss                      989.09937
Policy Loss                  -811.66583
Q Predictions Mean           801.44543
Q Predictions Std            382.23535
Q Predictions Max            1282.7067
Q Predictions Min            50.181725
V Predictions Mean           809.9342
V Predictions Std            388.18414
V Predictions Max            1293.7047
V Predictions Min            23.251516
Log Pis Mean                 -3.5545878
Log Pis Std                  5.684406
Log Pis Max                  26.544445
Log Pis Min                  -13.706539
Policy mu Mean               0.2421793
Policy mu Std                0.8057446
Policy mu Max                2.7579958
Policy mu Min                -2.1729429
Policy log std Mean          -0.27834186
Policy log std Std           0.12059464
Policy log std Max           0.07523736
Policy log std Min           -0.7942628
Z mean eval                  0.01299909
Z variance eval              0.010015417
total_rewards                [326.8381879  457.94277765 285.00486215 293.41202824 509.87194584
 353.43731687 455.95097492 277.04636612 356.5261791  278.02824808]
total_rewards_mean           359.4058886868385
total_rewards_std            81.28418784852
total_rewards_max            509.87194583913976
total_rewards_min            277.04636612428754
Number of train steps total  40000
Number of env steps total    55163
Number of rollouts total     0
Train Time (s)               115.1041265729582
(Previous) Eval Time (s)     1.783578572969418
Sample Time (s)              8.558083407056984
Epoch Time (s)               125.4457885529846
Total Train Time (s)         1342.3491744711064
Epoch                        9
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 20:40:55.459603 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #9 | Epoch Duration: 125.5883481502533
2020-01-05 20:40:55.459754 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #9 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013958114
Z variance train             0.009928061
KL Divergence                9.056744
KL Loss                      0.9056744
QF Loss                      2198.744
VF Loss                      1235.9658
Policy Loss                  -773.05084
Q Predictions Mean           759.2167
Q Predictions Std            374.48898
Q Predictions Max            1275.6694
Q Predictions Min            -13.942502
V Predictions Mean           762.4934
V Predictions Std            379.13083
V Predictions Max            1273.0469
V Predictions Min            16.048208
Log Pis Mean                 -3.206573
Log Pis Std                  5.797595
Log Pis Max                  20.478437
Log Pis Min                  -21.265953
Policy mu Mean               0.29867315
Policy mu Std                0.79246485
Policy mu Max                2.7076516
Policy mu Min                -2.1882071
Policy log std Mean          -0.28928223
Policy log std Std           0.12268542
Policy log std Max           -0.025431097
Policy log std Min           -0.79172945
Z mean eval                  0.019160291
Z variance eval              0.008935119
total_rewards                [361.32772678 344.55214366 312.04795388 391.24858578 331.73335913
 385.25104154 304.56930215 478.87622638 422.10505715 438.17122575]
total_rewards_mean           376.9882622201234
total_rewards_std            54.072893058584675
total_rewards_max            478.8762263809761
total_rewards_min            304.56930215216795
Number of train steps total  44000
Number of env steps total    60540
Number of rollouts total     0
Train Time (s)               122.30180958396522
(Previous) Eval Time (s)     1.9258626340306364
Sample Time (s)              9.165374687989242
Epoch Time (s)               133.3930469059851
Total Train Time (s)         1475.7034845800372
Epoch                        10
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 20:43:08.814908 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #10 | Epoch Duration: 133.35504841804504
2020-01-05 20:43:08.815042 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #10 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019433789
Z variance train             0.009066802
KL Divergence                9.281918
KL Loss                      0.9281918
QF Loss                      2307.058
VF Loss                      1412.6714
Policy Loss                  -737.1197
Q Predictions Mean           732.7146
Q Predictions Std            368.86438
Q Predictions Max            1259.8873
Q Predictions Min            -6.908396
V Predictions Mean           744.5961
V Predictions Std            371.60495
V Predictions Max            1269.1628
V Predictions Min            -36.203636
Log Pis Mean                 -3.0240614
Log Pis Std                  5.1932096
Log Pis Max                  16.52407
Log Pis Min                  -14.508125
Policy mu Mean               0.25146198
Policy mu Std                0.7986274
Policy mu Max                2.4823089
Policy mu Min                -1.8922646
Policy log std Mean          -0.28600964
Policy log std Std           0.12176811
Policy log std Max           0.028213933
Policy log std Min           -0.76152146
Z mean eval                  0.019165855
Z variance eval              0.009396898
total_rewards                [330.37146516 383.16856917 308.21546149 429.79925221 306.96686662
 325.88222925 334.24784487 453.6396861  330.60036632 379.88777071]
total_rewards_mean           358.2779511908122
total_rewards_std            48.58653506927368
total_rewards_max            453.6396861037965
total_rewards_min            306.96686661935024
Number of train steps total  48000
Number of env steps total    65904
Number of rollouts total     0
Train Time (s)               126.20130839495687
(Previous) Eval Time (s)     1.8876102529466152
Sample Time (s)              8.585997477988712
Epoch Time (s)               136.6749161258922
Total Train Time (s)         1612.4692230789806
Epoch                        11
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 20:45:25.581561 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #11 | Epoch Duration: 136.76640915870667
2020-01-05 20:45:25.581688 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #11 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018897824
Z variance train             0.00825422
KL Divergence                9.514362
KL Loss                      0.9514362
QF Loss                      3038.927
VF Loss                      1677.1677
Policy Loss                  -759.4314
Q Predictions Mean           758.1179
Q Predictions Std            348.20117
Q Predictions Max            1256.2648
Q Predictions Min            5.889224
V Predictions Mean           746.63495
V Predictions Std            344.87686
V Predictions Max            1258.2241
V Predictions Min            -31.336428
Log Pis Mean                 -2.6807213
Log Pis Std                  6.1945176
Log Pis Max                  18.869911
Log Pis Min                  -15.801392
Policy mu Mean               0.26042053
Policy mu Std                0.8311358
Policy mu Max                2.9455402
Policy mu Min                -2.5514941
Policy log std Mean          -0.29456192
Policy log std Std           0.13205202
Policy log std Max           -0.052611254
Policy log std Min           -0.81029713
Z mean eval                  0.01876002
Z variance eval              0.010252954
total_rewards                [235.56542965 350.09226428 405.81882686 406.76348556 276.33415876
 573.5966942  225.92936925 378.26581499 252.02840719 310.98175187]
total_rewards_mean           341.53762026136263
total_rewards_std            100.72361572184728
total_rewards_max            573.5966942026748
total_rewards_min            225.92936924642552
Number of train steps total  52000
Number of env steps total    71311
Number of rollouts total     0
Train Time (s)               120.34846764302347
(Previous) Eval Time (s)     1.978837632050272
Sample Time (s)              8.650147772976197
Epoch Time (s)               130.97745304804994
Total Train Time (s)         1743.3186254780157
Epoch                        12
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 20:47:36.432186 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #12 | Epoch Duration: 130.8503921031952
2020-01-05 20:47:36.432363 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #12 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0154325515
Z variance train             0.013658315
KL Divergence                8.269392
KL Loss                      0.8269392
QF Loss                      2533.9133
VF Loss                      739.92566
Policy Loss                  -747.6807
Q Predictions Mean           733.2897
Q Predictions Std            360.79285
Q Predictions Max            1246.1709
Q Predictions Min            -54.793823
V Predictions Mean           741.98706
V Predictions Std            363.91168
V Predictions Max            1263.1309
V Predictions Min            -31.260052
Log Pis Mean                 -4.3369246
Log Pis Std                  5.1476893
Log Pis Max                  21.655647
Log Pis Min                  -15.53306
Policy mu Mean               0.20556091
Policy mu Std                0.76372063
Policy mu Max                2.6607294
Policy mu Min                -2.8314886
Policy log std Mean          -0.2701604
Policy log std Std           0.12107934
Policy log std Max           0.11615047
Policy log std Min           -0.9241901
Z mean eval                  0.027516171
Z variance eval              0.010109147
total_rewards                [268.72160676 191.78219537 322.38017748 307.17109487 448.97772235
 437.81280178 276.77547994 340.65214844 335.23239628 416.49194706]
total_rewards_mean           334.59975703336477
total_rewards_std            77.11076272097439
total_rewards_max            448.97772235167446
total_rewards_min            191.7821953718955
Number of train steps total  56000
Number of env steps total    76807
Number of rollouts total     0
Train Time (s)               123.16144130198518
(Previous) Eval Time (s)     1.8515130949672312
Sample Time (s)              8.766241986944806
Epoch Time (s)               133.77919638389722
Total Train Time (s)         1876.8508257298963
Epoch                        13
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 20:49:49.964570 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #13 | Epoch Duration: 133.5320816040039
2020-01-05 20:49:49.964689 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #13 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027435515
Z variance train             0.009859667
KL Divergence                9.075754
KL Loss                      0.9075754
QF Loss                      1438.7502
VF Loss                      738.7028
Policy Loss                  -746.42194
Q Predictions Mean           736.9883
Q Predictions Std            359.9713
Q Predictions Max            1245.2614
Q Predictions Min            4.2734933
V Predictions Mean           744.30994
V Predictions Std            361.24698
V Predictions Max            1244.6873
V Predictions Min            30.213085
Log Pis Mean                 -4.136909
Log Pis Std                  5.0136943
Log Pis Max                  19.419058
Log Pis Min                  -15.609134
Policy mu Mean               0.28717494
Policy mu Std                0.751777
Policy mu Max                2.6306875
Policy mu Min                -2.037206
Policy log std Mean          -0.2780457
Policy log std Std           0.120392404
Policy log std Max           -0.011416793
Policy log std Min           -0.84090716
Z mean eval                  0.034950674
Z variance eval              0.017138531
total_rewards                [562.71199921 461.97486311 340.96966813 403.97482248 357.51980961
 258.55972502 282.51734998 353.95897131 447.7749326  406.88790997]
total_rewards_mean           387.6850051406501
total_rewards_std            85.06563435652372
total_rewards_max            562.7119992053389
total_rewards_min            258.55972501590423
Number of train steps total  60000
Number of env steps total    82166
Number of rollouts total     0
Train Time (s)               124.72552789701149
(Previous) Eval Time (s)     1.6041623409837484
Sample Time (s)              8.740515060024336
Epoch Time (s)               135.07020529801957
Total Train Time (s)         2012.3962497488828
Epoch                        14
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 20:52:05.511388 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #14 | Epoch Duration: 135.5466115474701
2020-01-05 20:52:05.511521 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #14 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04640303
Z variance train             0.017569967
KL Divergence                7.655531
KL Loss                      0.7655531
QF Loss                      2797.1416
VF Loss                      785.30743
Policy Loss                  -724.1252
Q Predictions Mean           705.96436
Q Predictions Std            354.6982
Q Predictions Max            1224.7932
Q Predictions Min            24.194733
V Predictions Mean           717.2339
V Predictions Std            353.8649
V Predictions Max            1224.4872
V Predictions Min            11.65347
Log Pis Mean                 -4.607859
Log Pis Std                  4.7756968
Log Pis Max                  10.597316
Log Pis Min                  -15.376862
Policy mu Mean               0.29053527
Policy mu Std                0.70475453
Policy mu Max                2.901242
Policy mu Min                -1.9047627
Policy log std Mean          -0.27586344
Policy log std Std           0.12146143
Policy log std Max           0.010359079
Policy log std Min           -0.8341486
Z mean eval                  0.0504992
Z variance eval              0.028933838
total_rewards                [344.48114839 606.88118291 500.77280583 441.26834098 418.88222407
 454.85810168 650.12032075 384.23673068 337.80112307 271.48574866]
total_rewards_mean           441.07877270104274
total_rewards_std            112.88266639696086
total_rewards_max            650.1203207496889
total_rewards_min            271.48574865507953
Number of train steps total  64000
Number of env steps total    87452
Number of rollouts total     0
Train Time (s)               131.73201209504623
(Previous) Eval Time (s)     2.080310041026678
Sample Time (s)              8.42125774989836
Epoch Time (s)               142.23357988597127
Total Train Time (s)         2154.8731645807857
Epoch                        15
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 20:54:27.988717 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #15 | Epoch Duration: 142.47709393501282
2020-01-05 20:54:27.988839 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #15 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045454938
Z variance train             0.024518088
KL Divergence                6.8398075
KL Loss                      0.68398076
QF Loss                      1398.6692
VF Loss                      684.9425
Policy Loss                  -719.5494
Q Predictions Mean           714.73224
Q Predictions Std            364.3069
Q Predictions Max            1217.804
Q Predictions Min            9.312774
V Predictions Mean           728.9933
V Predictions Std            365.47107
V Predictions Max            1232.7157
V Predictions Min            4.994515
Log Pis Mean                 -4.6026163
Log Pis Std                  4.9377375
Log Pis Max                  15.958773
Log Pis Min                  -19.82106
Policy mu Mean               0.3116235
Policy mu Std                0.7007477
Policy mu Max                2.616279
Policy mu Min                -1.8047974
Policy log std Mean          -0.27218208
Policy log std Std           0.11376301
Policy log std Max           0.024292126
Policy log std Min           -0.725111
Z mean eval                  0.03700489
Z variance eval              0.037333332
total_rewards                [326.61043048 476.3022225  517.92703114 400.6751064  317.01517232
 474.4507664  384.0632583  341.57747314 453.60156538 560.50642843]
total_rewards_mean           425.272945448569
total_rewards_std            79.66184268657275
total_rewards_max            560.5064284258752
total_rewards_min            317.0151723157808
Number of train steps total  68000
Number of env steps total    92903
Number of rollouts total     0
Train Time (s)               125.29367531498428
(Previous) Eval Time (s)     2.3235772430198267
Sample Time (s)              8.725677493028343
Epoch Time (s)               136.34293005103245
Total Train Time (s)         2291.123049995862
Epoch                        16
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 20:56:44.240528 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #16 | Epoch Duration: 136.25158262252808
2020-01-05 20:56:44.240747 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #16 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038671114
Z variance train             0.039512746
KL Divergence                5.6827602
KL Loss                      0.56827605
QF Loss                      1654.7577
VF Loss                      632.72864
Policy Loss                  -773.39636
Q Predictions Mean           764.3717
Q Predictions Std            357.82635
Q Predictions Max            1238.6425
Q Predictions Min            42.71358
V Predictions Mean           763.4536
V Predictions Std            354.45636
V Predictions Max            1230.0201
V Predictions Min            47.938168
Log Pis Mean                 -4.8330984
Log Pis Std                  5.0927896
Log Pis Max                  24.660234
Log Pis Min                  -13.882641
Policy mu Mean               0.2539537
Policy mu Std                0.69273806
Policy mu Max                2.6000915
Policy mu Min                -2.029711
Policy log std Mean          -0.26508033
Policy log std Std           0.11873143
Policy log std Max           -0.012748793
Policy log std Min           -0.82167256
Z mean eval                  0.22129247
Z variance eval              0.10200818
total_rewards                [662.54043362 480.18632871 458.89179489 371.45572513 306.30111701
 423.85773162 520.94959485 411.31912021 333.94037697 289.28402132]
total_rewards_mean           425.8726244321794
total_rewards_std            106.6179719926887
total_rewards_max            662.5404336196747
total_rewards_min            289.28402132135557
Number of train steps total  72000
Number of env steps total    98577
Number of rollouts total     0
Train Time (s)               129.77072173799388
(Previous) Eval Time (s)     2.2319547839579172
Sample Time (s)              9.135923114954494
Epoch Time (s)               141.1385996369063
Total Train Time (s)         2432.1102137129055
Epoch                        17
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 20:59:05.228098 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #17 | Epoch Duration: 140.9871563911438
2020-01-05 20:59:05.228263 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #17 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.184904
Z variance train             0.07895
KL Divergence                4.1575007
KL Loss                      0.4157501
QF Loss                      1539.6508
VF Loss                      994.528
Policy Loss                  -774.7611
Q Predictions Mean           759.38074
Q Predictions Std            377.91403
Q Predictions Max            1285.3667
Q Predictions Min            32.504807
V Predictions Mean           758.6477
V Predictions Std            367.955
V Predictions Max            1250.598
V Predictions Min            34.865063
Log Pis Mean                 -5.081589
Log Pis Std                  5.006994
Log Pis Max                  18.173607
Log Pis Min                  -14.315589
Policy mu Mean               0.2373812
Policy mu Std                0.7170832
Policy mu Max                2.9460278
Policy mu Min                -2.1197145
Policy log std Mean          -0.2667183
Policy log std Std           0.11644856
Policy log std Max           -0.042408347
Policy log std Min           -0.8192713
Z mean eval                  0.096592404
Z variance eval              0.03989449
total_rewards                [374.28920051 580.65950133 271.45046719 342.88145618 442.73505928
 278.41247412 358.17554258 264.82473929 407.64185505 375.87481357]
total_rewards_mean           369.6945109100512
total_rewards_std            90.09664535001328
total_rewards_max            580.6595013324728
total_rewards_min            264.8247392884425
Number of train steps total  76000
Number of env steps total    104000
Number of rollouts total     0
Train Time (s)               130.62533668300603
(Previous) Eval Time (s)     2.0802369880257174
Sample Time (s)              8.5965126620722
Epoch Time (s)               141.30208633310394
Total Train Time (s)         2573.111565313884
Epoch                        18
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 21:01:26.230464 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #18 | Epoch Duration: 141.0020990371704
2020-01-05 21:01:26.230595 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #18 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0796604
Z variance train             0.03584697
KL Divergence                5.9359765
KL Loss                      0.59359765
QF Loss                      1869.5431
VF Loss                      718.7229
Policy Loss                  -787.16797
Q Predictions Mean           783.9789
Q Predictions Std            386.42032
Q Predictions Max            1303.0463
Q Predictions Min            37.82071
V Predictions Mean           781.92456
V Predictions Std            383.44156
V Predictions Max            1286.9578
V Predictions Min            16.765783
Log Pis Mean                 -4.8818846
Log Pis Std                  4.547875
Log Pis Max                  11.075657
Log Pis Min                  -14.089867
Policy mu Mean               0.23935528
Policy mu Std                0.7260677
Policy mu Max                2.4861155
Policy mu Min                -1.8989013
Policy log std Mean          -0.27671275
Policy log std Std           0.11394387
Policy log std Max           -0.008392513
Policy log std Min           -0.82230806
Z mean eval                  0.14583969
Z variance eval              0.046397246
total_rewards                [386.99889243 495.53083937 377.33597524 401.82359837 270.84410582
 391.50452355 664.32740818 326.16780706 369.2476568  457.66247974]
total_rewards_mean           414.1443286568923
total_rewards_std            102.05674451130338
total_rewards_max            664.3274081845622
total_rewards_min            270.84410582333015
Number of train steps total  80000
Number of env steps total    109359
Number of rollouts total     0
Train Time (s)               133.08330115600256
(Previous) Eval Time (s)     1.7800074630067684
Sample Time (s)              8.694897969951853
Epoch Time (s)               143.55820658896118
Total Train Time (s)         2717.024904497899
Epoch                        19
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 21:03:50.144685 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #19 | Epoch Duration: 143.9139802455902
2020-01-05 21:03:50.144809 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #19 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07975953
Z variance train             0.02770919
KL Divergence                6.558224
KL Loss                      0.65582246
QF Loss                      1535.0298
VF Loss                      875.5331
Policy Loss                  -819.22626
Q Predictions Mean           807.24426
Q Predictions Std            369.15237
Q Predictions Max            1312.4056
Q Predictions Min            38.685074
V Predictions Mean           817.8301
V Predictions Std            369.4772
V Predictions Max            1324.688
V Predictions Min            32.316174
Log Pis Mean                 -4.5947247
Log Pis Std                  4.275275
Log Pis Max                  15.456371
Log Pis Min                  -13.450315
Policy mu Mean               0.22354634
Policy mu Std                0.7250261
Policy mu Max                2.7195356
Policy mu Min                -2.0353134
Policy log std Mean          -0.27861455
Policy log std Std           0.11315824
Policy log std Max           -0.064590365
Policy log std Min           -0.7638509
Z mean eval                  0.12738727
Z variance eval              0.052832622
total_rewards                [326.4253577  378.76067824 396.70561974 358.74636883 339.53649359
 365.61180958 421.36137448 302.26926602 289.35087697 346.77264181]
total_rewards_mean           352.55404869652324
total_rewards_std            38.7146443487679
total_rewards_max            421.36137447542995
total_rewards_min            289.35087697430777
Number of train steps total  84000
Number of env steps total    114820
Number of rollouts total     0
Train Time (s)               124.2169141349732
(Previous) Eval Time (s)     2.1355218979879282
Sample Time (s)              8.597719871962909
Epoch Time (s)               134.95015590492403
Total Train Time (s)         2851.522330111882
Epoch                        20
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 21:06:04.642948 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #20 | Epoch Duration: 134.49804663658142
2020-01-05 21:06:04.643068 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #20 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.21420689
Z variance train             0.0778475
KL Divergence                4.226264
KL Loss                      0.4226264
QF Loss                      1532.9685
VF Loss                      662.3038
Policy Loss                  -804.43335
Q Predictions Mean           802.30914
Q Predictions Std            400.62646
Q Predictions Max            1340.7675
Q Predictions Min            21.290443
V Predictions Mean           801.72656
V Predictions Std            397.73965
V Predictions Max            1333.727
V Predictions Min            24.24612
Log Pis Mean                 -5.6407404
Log Pis Std                  4.1949515
Log Pis Max                  14.861038
Log Pis Min                  -17.220997
Policy mu Mean               0.25180772
Policy mu Std                0.67957604
Policy mu Max                2.263278
Policy mu Min                -2.2741973
Policy log std Mean          -0.2571411
Policy log std Std           0.108635865
Policy log std Max           -0.02629564
Policy log std Min           -0.73001444
Z mean eval                  0.26595974
Z variance eval              0.054989465
total_rewards                [293.41325681 469.07472357 443.67644614 431.49400863 365.76065213
 370.15666139 407.37798085 306.17919993 452.01651083 389.15291781]
total_rewards_mean           392.83023580913493
total_rewards_std            56.79842614349536
total_rewards_max            469.07472357262407
total_rewards_min            293.4132568061044
Number of train steps total  88000
Number of env steps total    120315
Number of rollouts total     0
Train Time (s)               132.92494611401344
(Previous) Eval Time (s)     1.6831694629509002
Sample Time (s)              8.714165399898775
Epoch Time (s)               143.3222809768631
Total Train Time (s)         2995.243185955682
Epoch                        21
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 21:08:28.365191 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #21 | Epoch Duration: 143.7220230102539
2020-01-05 21:08:28.365330 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #21 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.24775589
Z variance train             0.046375986
KL Divergence                5.4567714
KL Loss                      0.5456771
QF Loss                      1386.2681
VF Loss                      734.17786
Policy Loss                  -806.09973
Q Predictions Mean           805.5293
Q Predictions Std            390.15842
Q Predictions Max            1352.3496
Q Predictions Min            10.314684
V Predictions Mean           810.49
V Predictions Std            384.82846
V Predictions Max            1349.9548
V Predictions Min            27.048944
Log Pis Mean                 -5.160449
Log Pis Std                  4.964369
Log Pis Max                  24.516602
Log Pis Min                  -15.340816
Policy mu Mean               0.1964729
Policy mu Std                0.6982203
Policy mu Max                2.3596883
Policy mu Min                -2.4432905
Policy log std Mean          -0.26677662
Policy log std Std           0.113737404
Policy log std Max           -0.049442112
Policy log std Min           -0.7736295
Z mean eval                  0.22634074
Z variance eval              0.04303478
total_rewards                [411.25175433 662.17000159 444.69619102 799.47442731 582.71438622
 465.43807958 354.2375959  376.88947364 406.68518683 537.28161801]
total_rewards_mean           504.0838714431228
total_rewards_std            134.643482553128
total_rewards_max            799.4744273062183
total_rewards_min            354.23759589778905
Number of train steps total  92000
Number of env steps total    125743
Number of rollouts total     0
Train Time (s)               122.78548150399001
(Previous) Eval Time (s)     2.08267087204149
Sample Time (s)              8.58325957407942
Epoch Time (s)               133.45141195011092
Total Train Time (s)         3128.9961243018042
Epoch                        22
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 21:10:42.118230 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #22 | Epoch Duration: 133.75278520584106
2020-01-05 21:10:42.118347 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #22 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.36819234
Z variance train             0.08464482
KL Divergence                4.3241568
KL Loss                      0.4324157
QF Loss                      1372.7173
VF Loss                      829.29565
Policy Loss                  -794.8722
Q Predictions Mean           783.56415
Q Predictions Std            411.34558
Q Predictions Max            1367.6907
Q Predictions Min            15.310532
V Predictions Mean           800.03375
V Predictions Std            409.46954
V Predictions Max            1373.3896
V Predictions Min            25.145033
Log Pis Mean                 -4.8634453
Log Pis Std                  5.0603786
Log Pis Max                  18.555227
Log Pis Min                  -14.629454
Policy mu Mean               0.2305562
Policy mu Std                0.7077602
Policy mu Max                2.9669251
Policy mu Min                -2.054855
Policy log std Mean          -0.26899964
Policy log std Std           0.11305486
Policy log std Max           0.0024545789
Policy log std Min           -0.8512723
Z mean eval                  0.21496001
Z variance eval              0.058431417
total_rewards                [ 644.68470273  524.59944594  450.43866145 1394.25797319  631.58429874
  478.29433526  598.38619312  389.32425709  526.18381631  342.4759298 ]
total_rewards_mean           598.0229613642347
total_rewards_std            281.57084132366253
total_rewards_max            1394.2579731873457
total_rewards_min            342.4759297990001
Number of train steps total  96000
Number of env steps total    131111
Number of rollouts total     0
Train Time (s)               142.0539319679956
(Previous) Eval Time (s)     2.383801284013316
Sample Time (s)              7.847293546132278
Epoch Time (s)               152.2850267981412
Total Train Time (s)         3281.995045712043
Epoch                        23
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 21:13:15.119151 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #23 | Epoch Duration: 153.00071001052856
2020-01-05 21:13:15.119300 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #23 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.22147115
Z variance train             0.06616152
KL Divergence                4.637001
KL Loss                      0.46370012
QF Loss                      2297.3936
VF Loss                      701.7701
Policy Loss                  -867.1475
Q Predictions Mean           850.2218
Q Predictions Std            391.59726
Q Predictions Max            1370.1437
Q Predictions Min            12.017392
V Predictions Mean           859.2535
V Predictions Std            391.2314
V Predictions Max            1387.1832
V Predictions Min            39.25075
Log Pis Mean                 -4.501597
Log Pis Std                  5.2156806
Log Pis Max                  22.288784
Log Pis Min                  -14.046114
Policy mu Mean               0.2298026
Policy mu Std                0.7257713
Policy mu Max                2.587728
Policy mu Min                -2.185782
Policy log std Mean          -0.27827823
Policy log std Std           0.11002313
Policy log std Max           -0.047058657
Policy log std Min           -0.8271088
Z mean eval                  0.42627424
Z variance eval              0.086683884
total_rewards                [603.2870907  705.68937435 465.57736802 380.13889624 358.53136347
 390.48220989 485.12800167 579.70726132 553.90076639 548.07746571]
total_rewards_mean           507.05197977650414
total_rewards_std            105.74938300907692
total_rewards_max            705.6893743518048
total_rewards_min            358.5313634655442
Number of train steps total  100000
Number of env steps total    136488
Number of rollouts total     0
Train Time (s)               151.4360198249924
(Previous) Eval Time (s)     3.0992284700041637
Sample Time (s)              8.604185694886837
Epoch Time (s)               163.1394339898834
Total Train Time (s)         3444.515505249903
Epoch                        24
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 21:15:57.640268 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #24 | Epoch Duration: 162.52085185050964
2020-01-05 21:15:57.640388 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #24 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.49738693
Z variance train             0.09665398
KL Divergence                4.407552
KL Loss                      0.4407552
QF Loss                      1570.8884
VF Loss                      694.5679
Policy Loss                  -811.8365
Q Predictions Mean           807.2952
Q Predictions Std            406.8812
Q Predictions Max            1400.9451
Q Predictions Min            -0.95575154
V Predictions Mean           816.464
V Predictions Std            402.66022
V Predictions Max            1409.219
V Predictions Min            35.17282
Log Pis Mean                 -4.60431
Log Pis Std                  5.2663054
Log Pis Max                  23.67644
Log Pis Min                  -15.125393
Policy mu Mean               0.21918572
Policy mu Std                0.738695
Policy mu Max                2.7604382
Policy mu Min                -2.1110265
Policy log std Mean          -0.2733758
Policy log std Std           0.11818045
Policy log std Max           0.0004324764
Policy log std Min           -0.88473594
Z mean eval                  0.48073658
Z variance eval              0.090281114
total_rewards                [707.81807838 714.21106602 739.00069788 566.00744267 915.70051335
 482.5985182  589.33158331 501.58030446 640.19244871 475.09256559]
total_rewards_mean           633.1533218564851
total_rewards_std            132.14448147329054
total_rewards_max            915.7005133536898
total_rewards_min            475.09256558935385
Number of train steps total  104000
Number of env steps total    142210
Number of rollouts total     0
Train Time (s)               141.01772748300573
(Previous) Eval Time (s)     2.4803861439577304
Sample Time (s)              9.637485155952163
Epoch Time (s)               153.13559878291562
Total Train Time (s)         3598.4284504728275
Epoch                        25
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 21:18:31.554807 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #25 | Epoch Duration: 153.9143192768097
2020-01-05 21:18:31.554968 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #25 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.51118636
Z variance train             0.092810735
KL Divergence                4.531872
KL Loss                      0.4531872
QF Loss                      1485.457
VF Loss                      748.5163
Policy Loss                  -824.5579
Q Predictions Mean           821.31323
Q Predictions Std            422.33936
Q Predictions Max            1414.794
Q Predictions Min            19.92138
V Predictions Mean           833.3948
V Predictions Std            422.8843
V Predictions Max            1435.1937
V Predictions Min            30.940575
Log Pis Mean                 -4.42458
Log Pis Std                  5.4344735
Log Pis Max                  23.161926
Log Pis Min                  -13.778019
Policy mu Mean               0.1976905
Policy mu Std                0.7522825
Policy mu Max                2.6760416
Policy mu Min                -2.4131923
Policy log std Mean          -0.2821267
Policy log std Std           0.119380526
Policy log std Max           -0.049877048
Policy log std Min           -0.84014904
Z mean eval                  0.173923
Z variance eval              0.04640985
total_rewards                [299.78084229 592.30993102 634.34970648 692.13240155 499.18361622
 391.92632185 300.3470071  570.81747792 509.27205145 448.7124591 ]
total_rewards_mean           493.8831814995092
total_rewards_std            127.46481282492988
total_rewards_max            692.132401551816
total_rewards_min            299.7808422903958
Number of train steps total  108000
Number of env steps total    147684
Number of rollouts total     0
Train Time (s)               131.08715441497043
(Previous) Eval Time (s)     3.2588335539912805
Sample Time (s)              8.985278741107322
Epoch Time (s)               143.33126671006903
Total Train Time (s)         3740.7993345477735
Epoch                        26
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 21:20:53.925994 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #26 | Epoch Duration: 142.3708941936493
2020-01-05 21:20:53.926119 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #26 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.16087107
Z variance train             0.046467282
KL Divergence                5.395795
KL Loss                      0.5395795
QF Loss                      1828.7305
VF Loss                      889.45074
Policy Loss                  -916.3343
Q Predictions Mean           905.2356
Q Predictions Std            378.69247
Q Predictions Max            1430.5598
Q Predictions Min            45.824966
V Predictions Mean           902.1478
V Predictions Std            381.08057
V Predictions Max            1424.4904
V Predictions Min            10.438897
Log Pis Mean                 -4.79651
Log Pis Std                  4.630925
Log Pis Max                  18.219852
Log Pis Min                  -12.98717
Policy mu Mean               0.16091067
Policy mu Std                0.7477235
Policy mu Max                2.68887
Policy mu Min                -2.7014854
Policy log std Mean          -0.272764
Policy log std Std           0.11366952
Policy log std Max           -0.034001805
Policy log std Min           -0.8138356
Z mean eval                  0.5226785
Z variance eval              0.14566198
total_rewards                [697.17269622 700.94892151 808.78487216 481.38191779 499.20825072
 489.63769627 575.70801227 381.89848692 876.774619   336.3810845 ]
total_rewards_mean           584.789655734046
total_rewards_std            170.75636210668506
total_rewards_max            876.7746189970406
total_rewards_min            336.3810845035649
Number of train steps total  112000
Number of env steps total    153212
Number of rollouts total     0
Train Time (s)               131.00150764395948
(Previous) Eval Time (s)     2.2982100939843804
Sample Time (s)              8.322156807989813
Epoch Time (s)               141.62187454593368
Total Train Time (s)         3883.1433752307785
Epoch                        27
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 21:23:16.271365 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #27 | Epoch Duration: 142.34514474868774
2020-01-05 21:23:16.271536 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #27 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.2198871
Z variance train             0.06139949
KL Divergence                4.831128
KL Loss                      0.4831128
QF Loss                      2208.0742
VF Loss                      1080.1652
Policy Loss                  -923.6291
Q Predictions Mean           926.626
Q Predictions Std            420.09885
Q Predictions Max            1463.3707
Q Predictions Min            17.84825
V Predictions Mean           919.5836
V Predictions Std            422.62045
V Predictions Max            1455.6367
V Predictions Min            22.583055
Log Pis Mean                 -4.8408947
Log Pis Std                  5.168418
Log Pis Max                  24.4108
Log Pis Min                  -16.471626
Policy mu Mean               0.1982797
Policy mu Std                0.73290014
Policy mu Max                3.1234062
Policy mu Min                -2.5223927
Policy log std Mean          -0.2804804
Policy log std Std           0.11195782
Policy log std Max           -0.06321722
Policy log std Min           -0.9298055
Z mean eval                  0.38056827
Z variance eval              0.12597762
total_rewards                [ 707.03122294  985.99389123  467.76310292  480.00070877  609.65653449
  712.92590837 1110.46304733  562.78676891  627.64618374  653.59628323]
total_rewards_mean           691.7863651923893
total_rewards_std            196.60258263539203
total_rewards_max            1110.4630473291977
total_rewards_min            467.76310291946595
Number of train steps total  116000
Number of env steps total    158993
Number of rollouts total     0
Train Time (s)               130.08365418796893
(Previous) Eval Time (s)     3.021223118994385
Sample Time (s)              9.63297099294141
Epoch Time (s)               142.73784829990473
Total Train Time (s)         4026.4668517027167
Epoch                        28
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 21:25:39.596362 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #28 | Epoch Duration: 143.3246831893921
2020-01-05 21:25:39.596531 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #28 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.15511414
Z variance train             0.054050427
KL Divergence                5.045121
KL Loss                      0.50451213
QF Loss                      1663.6476
VF Loss                      946.27386
Policy Loss                  -961.12195
Q Predictions Mean           957.66895
Q Predictions Std            428.20428
Q Predictions Max            1476.7767
Q Predictions Min            24.340818
V Predictions Mean           949.69836
V Predictions Std            424.99277
V Predictions Max            1476.017
V Predictions Min            26.736353
Log Pis Mean                 -4.302056
Log Pis Std                  4.6269
Log Pis Max                  15.0653105
Log Pis Min                  -14.08304
Policy mu Mean               0.18238738
Policy mu Std                0.7462683
Policy mu Max                2.656363
Policy mu Min                -2.0846972
Policy log std Mean          -0.28341204
Policy log std Std           0.1111216
Policy log std Max           -0.04410559
Policy log std Min           -0.831792
Z mean eval                  0.2030601
Z variance eval              0.07117899
total_rewards                [700.47573582 675.37842934 503.91248841 793.30978825 380.33594576
 306.19969946 582.44939124 544.12812685 743.77121109 852.5893427 ]
total_rewards_mean           608.2550158911789
total_rewards_std            168.5732638725604
total_rewards_max            852.5893427018651
total_rewards_min            306.1996994585807
Number of train steps total  120000
Number of env steps total    164680
Number of rollouts total     0
Train Time (s)               131.15958859602688
(Previous) Eval Time (s)     3.60781442001462
Sample Time (s)              9.700689518882427
Epoch Time (s)               144.46809253492393
Total Train Time (s)         4170.744337262528
Epoch                        29
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 21:28:03.874915 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #29 | Epoch Duration: 144.27826476097107
2020-01-05 21:28:03.875055 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #29 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.2186964
Z variance train             0.08014689
KL Divergence                4.218543
KL Loss                      0.42185432
QF Loss                      1689.5845
VF Loss                      581.864
Policy Loss                  -946.1548
Q Predictions Mean           951.5815
Q Predictions Std            450.7161
Q Predictions Max            1513.3324
Q Predictions Min            38.10927
V Predictions Mean           941.33777
V Predictions Std            442.70316
V Predictions Max            1484.3392
V Predictions Min            42.689476
Log Pis Mean                 -4.71123
Log Pis Std                  4.571299
Log Pis Max                  8.655963
Log Pis Min                  -15.1824665
Policy mu Mean               0.1692323
Policy mu Std                0.72446054
Policy mu Max                2.2126284
Policy mu Min                -1.9771113
Policy log std Mean          -0.2810105
Policy log std Std           0.11331455
Policy log std Max           -0.0020387396
Policy log std Min           -0.7467805
Z mean eval                  0.21455655
Z variance eval              0.0834716
total_rewards                [1615.12301061  594.20358118  482.36342812  748.46818852  512.37278902
  656.1716671   602.22275764  580.53908237  642.38133913  490.73854721]
total_rewards_mean           692.4584390913394
total_rewards_std            317.15225946388705
total_rewards_max            1615.1230106147298
total_rewards_min            482.3634281247822
Number of train steps total  124000
Number of env steps total    170653
Number of rollouts total     0
Train Time (s)               137.8682422619895
(Previous) Eval Time (s)     3.41772986901924
Sample Time (s)              9.954077908827458
Epoch Time (s)               151.2400500398362
Total Train Time (s)         4322.173516776471
Epoch                        30
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 21:30:35.304942 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #30 | Epoch Duration: 151.42976880073547
2020-01-05 21:30:35.305081 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #30 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.43187705
Z variance train             0.18562403
KL Divergence                2.9739752
KL Loss                      0.29739752
QF Loss                      1699.1797
VF Loss                      842.3396
Policy Loss                  -939.8622
Q Predictions Mean           932.2265
Q Predictions Std            448.18396
Q Predictions Max            1523.6838
Q Predictions Min            22.497433
V Predictions Mean           926.4653
V Predictions Std            438.4618
V Predictions Max            1511.1824
V Predictions Min            27.460222
Log Pis Mean                 -4.8091373
Log Pis Std                  4.915998
Log Pis Max                  21.241821
Log Pis Min                  -15.000204
Policy mu Mean               0.14958318
Policy mu Std                0.7372506
Policy mu Max                2.6748161
Policy mu Min                -2.6280572
Policy log std Mean          -0.2817452
Policy log std Std           0.11393371
Policy log std Max           0.0021120608
Policy log std Min           -0.88433564
Z mean eval                  0.3487452
Z variance eval              0.12537143
total_rewards                [ 553.59197729  856.13878759  502.55997793  927.24456546  340.0991972
 1226.93299992  774.6661396   809.23779706 1552.08192342  903.62027229]
total_rewards_mean           844.6173637772299
total_rewards_std            334.5885814507319
total_rewards_max            1552.081923421783
total_rewards_min            340.09919720416656
Number of train steps total  128000
Number of env steps total    176552
Number of rollouts total     0
Train Time (s)               129.4858541219728
(Previous) Eval Time (s)     3.6071836860501207
Sample Time (s)              9.592312726017553
Epoch Time (s)               142.68535053404048
Total Train Time (s)         4465.815619072528
Epoch                        31
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 21:32:58.947451 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #31 | Epoch Duration: 143.64226484298706
2020-01-05 21:32:58.947569 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #31 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.23141184
Z variance train             0.09366532
KL Divergence                3.9082005
KL Loss                      0.39082006
QF Loss                      1879.7808
VF Loss                      734.65
Policy Loss                  -926.2282
Q Predictions Mean           912.10535
Q Predictions Std            456.4082
Q Predictions Max            1520.0581
Q Predictions Min            10.429752
V Predictions Mean           921.7737
V Predictions Std            449.69107
V Predictions Max            1523.7528
V Predictions Min            9.398117
Log Pis Mean                 -4.4467087
Log Pis Std                  5.048902
Log Pis Max                  21.058323
Log Pis Min                  -13.683121
Policy mu Mean               0.15401986
Policy mu Std                0.7515696
Policy mu Max                2.90207
Policy mu Min                -2.3342898
Policy log std Mean          -0.28663614
Policy log std Std           0.11962912
Policy log std Max           -0.025511086
Policy log std Min           -0.8072892
Z mean eval                  0.45773536
Z variance eval              0.105338916
total_rewards                [ 459.34977549  824.97318674 1081.68549919 1187.36906109  410.86047504
  437.48292586  914.29098479  656.50142897  684.17847068  843.9346638 ]
total_rewards_mean           750.0626471641605
total_rewards_std            255.53428394940116
total_rewards_max            1187.369061092275
total_rewards_min            410.8604750434885
Number of train steps total  132000
Number of env steps total    182570
Number of rollouts total     0
Train Time (s)               128.73438457900193
(Previous) Eval Time (s)     4.563824813987594
Sample Time (s)              9.439962346979883
Epoch Time (s)               142.7381717399694
Total Train Time (s)         4607.952912012406
Epoch                        32
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 21:35:21.086056 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #32 | Epoch Duration: 142.13838934898376
2020-01-05 21:35:21.086190 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #32 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.5915092
Z variance train             0.13533854
KL Divergence                3.9826686
KL Loss                      0.39826688
QF Loss                      2060.2192
VF Loss                      796.4083
Policy Loss                  -1000.6785
Q Predictions Mean           1002.92194
Q Predictions Std            457.32248
Q Predictions Max            1576.6802
Q Predictions Min            42.01236
V Predictions Mean           991.8942
V Predictions Std            456.52066
V Predictions Max            1565.9498
V Predictions Min            31.342402
Log Pis Mean                 -3.8330917
Log Pis Std                  5.3550825
Log Pis Max                  21.632896
Log Pis Min                  -13.529554
Policy mu Mean               0.12663059
Policy mu Std                0.8108427
Policy mu Max                2.8335056
Policy mu Min                -2.7943766
Policy log std Mean          -0.30506456
Policy log std Std           0.118637815
Policy log std Max           -0.0037815273
Policy log std Min           -0.88665485
Z mean eval                  0.62833107
Z variance eval              0.18444002
total_rewards                [1463.15163062  731.54390727  573.1608126   781.67479634  999.16456742
  457.12007991  438.26081625  602.18316275  877.13061057  890.24145162]
total_rewards_mean           781.3631835364188
total_rewards_std            288.80571253560447
total_rewards_max            1463.1516306245724
total_rewards_min            438.2608162492886
Number of train steps total  136000
Number of env steps total    188579
Number of rollouts total     0
Train Time (s)               130.52703908097465
(Previous) Eval Time (s)     3.9637939779786393
Sample Time (s)              9.730806377832778
Epoch Time (s)               144.22163943678606
Total Train Time (s)         4752.155723474221
Epoch                        33
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 21:37:45.290107 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #33 | Epoch Duration: 144.20380330085754
2020-01-05 21:37:45.290285 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #33 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.66900367
Z variance train             0.19974084
KL Divergence                3.5590663
KL Loss                      0.35590664
QF Loss                      2091.199
VF Loss                      886.84314
Policy Loss                  -941.27466
Q Predictions Mean           929.2938
Q Predictions Std            493.48358
Q Predictions Max            1576.6578
Q Predictions Min            14.17161
V Predictions Mean           928.5408
V Predictions Std            495.51724
V Predictions Max            1586.8793
V Predictions Min            -13.261064
Log Pis Mean                 -3.3389592
Log Pis Std                  5.817166
Log Pis Max                  31.861841
Log Pis Min                  -15.061075
Policy mu Mean               0.20275186
Policy mu Std                0.80453396
Policy mu Max                3.1315134
Policy mu Min                -2.78687
Policy log std Mean          -0.30268416
Policy log std Std           0.12823935
Policy log std Max           0.10998365
Policy log std Min           -0.8811388
Z mean eval                  0.3737381
Z variance eval              0.13270725
total_rewards                [ 394.30048541 1320.676199   1470.00758027  437.09138698  669.23533584
  478.06195533  781.42791769  504.58713137  530.83435474  863.02606091]
total_rewards_mean           744.9248407531747
total_rewards_std            356.47657760691214
total_rewards_max            1470.0075802657009
total_rewards_min            394.3004854110864
Number of train steps total  140000
Number of env steps total    194052
Number of rollouts total     0
Train Time (s)               129.1783872730448
(Previous) Eval Time (s)     3.945695343951229
Sample Time (s)              8.750741283001844
Epoch Time (s)               141.87482389999786
Total Train Time (s)         4894.256660886167
Epoch                        34
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 21:40:07.391977 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #34 | Epoch Duration: 142.10155963897705
2020-01-05 21:40:07.392173 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #34 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.35015863
Z variance train             0.12122728
KL Divergence                3.6120613
KL Loss                      0.36120614
QF Loss                      2123.3306
VF Loss                      772.9873
Policy Loss                  -1060.2738
Q Predictions Mean           1048.0864
Q Predictions Std            442.61636
Q Predictions Max            1585.9469
Q Predictions Min            6.18309
V Predictions Mean           1050.4017
V Predictions Std            433.60403
V Predictions Max            1577.8339
V Predictions Min            6.8164635
Log Pis Mean                 -2.9297993
Log Pis Std                  5.2432694
Log Pis Max                  17.648825
Log Pis Min                  -15.274503
Policy mu Mean               0.13171951
Policy mu Std                0.8144978
Policy mu Max                2.7762198
Policy mu Min                -2.2166338
Policy log std Mean          -0.31169686
Policy log std Std           0.118366875
Policy log std Max           0.0048577935
Policy log std Min           -0.86631215
Z mean eval                  0.56447816
Z variance eval              0.18179992
total_rewards                [ 411.448059    591.91634203  864.89771312  419.10332179  975.53773014
  728.07260072  874.44938349  888.26269715 1206.38491548 2259.88327647]
total_rewards_mean           921.9956039396502
total_rewards_std            504.0301656393456
total_rewards_max            2259.8832764748227
total_rewards_min            411.44805900091615
Number of train steps total  144000
Number of env steps total    199905
Number of rollouts total     0
Train Time (s)               124.1426100039971
(Previous) Eval Time (s)     4.172162063012365
Sample Time (s)              9.468793667969294
Epoch Time (s)               137.78356573497877
Total Train Time (s)         5032.9437620761455
Epoch                        35
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 21:42:26.080371 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #35 | Epoch Duration: 138.68805527687073
2020-01-05 21:42:26.080550 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #35 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.4677743
Z variance train             0.15099156
KL Divergence                3.4309745
KL Loss                      0.34309745
QF Loss                      2028.011
VF Loss                      1085.076
Policy Loss                  -1001.16187
Q Predictions Mean           983.1499
Q Predictions Std            470.7437
Q Predictions Max            1601.04
Q Predictions Min            -18.888687
V Predictions Mean           985.8715
V Predictions Std            472.86078
V Predictions Max            1598.7781
V Predictions Min            -28.347864
Log Pis Mean                 -3.9361057
Log Pis Std                  4.90839
Log Pis Max                  15.394657
Log Pis Min                  -13.49791
Policy mu Mean               0.14198156
Policy mu Std                0.7759171
Policy mu Max                3.0088108
Policy mu Min                -2.6310253
Policy log std Mean          -0.29779643
Policy log std Std           0.12023505
Policy log std Max           -0.027761102
Policy log std Min           -0.8773916
Z mean eval                  0.56267655
Z variance eval              0.14797129
total_rewards                [ 492.75627825  707.01767752  416.26443034  470.7750863   718.96067832
 1025.01856562 1704.9648945   805.84478355  775.82931498  603.95580509]
total_rewards_mean           772.1387514472565
total_rewards_std            355.828308745121
total_rewards_max            1704.9648945021568
total_rewards_min            416.2644303444164
Number of train steps total  148000
Number of env steps total    205739
Number of rollouts total     0
Train Time (s)               126.65129600500222
(Previous) Eval Time (s)     5.076396405987907
Sample Time (s)              9.380343365017325
Epoch Time (s)               141.10803577600745
Total Train Time (s)         5173.108457495167
Epoch                        36
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 21:44:46.245791 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #36 | Epoch Duration: 140.16510128974915
2020-01-05 21:44:46.245911 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #36 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8600788
Z variance train             0.23046508
KL Divergence                4.2060947
KL Loss                      0.42060947
QF Loss                      1823.3625
VF Loss                      632.7512
Policy Loss                  -994.1389
Q Predictions Mean           988.8131
Q Predictions Std            488.38794
Q Predictions Max            1630.364
Q Predictions Min            37.887997
V Predictions Mean           994.7427
V Predictions Std            485.29425
V Predictions Max            1612.0406
V Predictions Min            33.88747
Log Pis Mean                 -4.709196
Log Pis Std                  5.652413
Log Pis Max                  23.104992
Log Pis Min                  -15.393658
Policy mu Mean               0.14648598
Policy mu Std                0.7548427
Policy mu Max                3.0266328
Policy mu Min                -2.5404263
Policy log std Mean          -0.28315398
Policy log std Std           0.12695673
Policy log std Max           -0.024415493
Policy log std Min           -1.0687088
Z mean eval                  0.34657067
Z variance eval              0.0949441
total_rewards                [1091.6091048   437.73021083 1941.87471982  549.78542599 1051.8498867
  946.7677347   534.39004585  714.43712804  742.59149419 1080.39295614]
total_rewards_mean           909.1428707076491
total_rewards_std            413.327176612539
total_rewards_max            1941.874719816986
total_rewards_min            437.7302108322042
Number of train steps total  152000
Number of env steps total    211511
Number of rollouts total     0
Train Time (s)               129.59483647404704
(Previous) Eval Time (s)     4.133216670015827
Sample Time (s)              9.660643481940497
Epoch Time (s)               143.38869662600337
Total Train Time (s)         5317.53175358905
Epoch                        37
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 21:47:10.669878 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #37 | Epoch Duration: 144.4238624572754
2020-01-05 21:47:10.670014 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #37 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.41707548
Z variance train             0.11233586
KL Divergence                3.9019651
KL Loss                      0.39019653
QF Loss                      2614.241
VF Loss                      986.7138
Policy Loss                  -981.1294
Q Predictions Mean           984.3027
Q Predictions Std            471.94193
Q Predictions Max            1626.7559
Q Predictions Min            48.947105
V Predictions Mean           992.8223
V Predictions Std            475.3792
V Predictions Max            1617.6833
V Predictions Min            27.670593
Log Pis Mean                 -4.262869
Log Pis Std                  5.453215
Log Pis Max                  28.860388
Log Pis Min                  -13.859102
Policy mu Mean               0.12997772
Policy mu Std                0.78160703
Policy mu Max                3.0982447
Policy mu Min                -2.9281013
Policy log std Mean          -0.28760305
Policy log std Std           0.123546205
Policy log std Max           0.024364412
Policy log std Min           -0.93472606
Z mean eval                  0.33063832
Z variance eval              0.10705072
total_rewards                [ 981.72923615  872.54287971 1106.42051419 1184.49735199  530.06715241
  663.40080655  628.45719044  963.28969365 2710.79088525  986.61760281]
total_rewards_mean           1062.781331313824
total_rewards_std            585.0675967150394
total_rewards_max            2710.7908852517735
total_rewards_min            530.067152405216
Number of train steps total  156000
Number of env steps total    217319
Number of rollouts total     0
Train Time (s)               128.4497385440045
(Previous) Eval Time (s)     5.168122091970872
Sample Time (s)              9.476638951979112
Epoch Time (s)               143.0944995879545
Total Train Time (s)         5461.093022281944
Epoch                        38
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 21:49:34.232355 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #38 | Epoch Duration: 143.56221103668213
2020-01-05 21:49:34.232473 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #38 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.21880405
Z variance train             0.07168155
KL Divergence                4.5303755
KL Loss                      0.45303756
QF Loss                      1686.7305
VF Loss                      811.19135
Policy Loss                  -1037.8666
Q Predictions Mean           1031.869
Q Predictions Std            494.7284
Q Predictions Max            1650.3322
Q Predictions Min            56.094284
V Predictions Mean           1026.8485
V Predictions Std            489.98358
V Predictions Max            1648.057
V Predictions Min            55.796093
Log Pis Mean                 -3.92584
Log Pis Std                  4.8360825
Log Pis Max                  13.847782
Log Pis Min                  -14.793885
Policy mu Mean               0.122449316
Policy mu Std                0.7843894
Policy mu Max                2.381438
Policy mu Min                -2.8551016
Policy log std Mean          -0.30141726
Policy log std Std           0.12792656
Policy log std Max           0.0048168004
Policy log std Min           -0.80106246
Z mean eval                  0.40575147
Z variance eval              0.115259364
total_rewards                [ 388.17921559 1058.63202748  308.43002537 1008.45888414 1078.48153516
 2550.67127399  564.94208254  647.0820103   417.77970873  560.82479746]
total_rewards_mean           858.3481560766322
total_rewards_std            625.4496859849656
total_rewards_max            2550.6712739934023
total_rewards_min            308.4300253714831
Number of train steps total  160000
Number of env steps total    223220
Number of rollouts total     0
Train Time (s)               129.34682657400845
(Previous) Eval Time (s)     5.6355883670039475
Sample Time (s)              9.717713464051485
Epoch Time (s)               144.70012840506388
Total Train Time (s)         5604.832429137081
Epoch                        39
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 21:51:57.972907 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #39 | Epoch Duration: 143.74033069610596
2020-01-05 21:51:57.973031 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #39 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.33152807
Z variance train             0.09606508
KL Divergence                4.0832953
KL Loss                      0.40832955
QF Loss                      2236.18
VF Loss                      820.8155
Policy Loss                  -1013.33936
Q Predictions Mean           1009.0931
Q Predictions Std            495.86548
Q Predictions Max            1663.5045
Q Predictions Min            -0.45118484
V Predictions Mean           1010.8684
V Predictions Std            500.81708
V Predictions Max            1648.4016
V Predictions Min            14.4970455
Log Pis Mean                 -3.9531665
Log Pis Std                  4.6098223
Log Pis Max                  10.950424
Log Pis Min                  -13.682117
Policy mu Mean               0.1270047
Policy mu Std                0.7714674
Policy mu Max                2.5482843
Policy mu Min                -2.387044
Policy log std Mean          -0.29639408
Policy log std Std           0.12171679
Policy log std Max           0.02935183
Policy log std Min           -0.82178557
Z mean eval                  0.55657977
Z variance eval              0.13864078
total_rewards                [ 514.00657239  417.2596946   440.84104059  892.39670708  519.63043079
 1535.95861258  394.13407386  693.60076447  702.87411253  596.92758547]
total_rewards_mean           670.7629594350981
total_rewards_std            323.3812812655655
total_rewards_max            1535.9586125770043
total_rewards_min            394.1340738628449
Number of train steps total  164000
Number of env steps total    228748
Number of rollouts total     0
Train Time (s)               125.30125642899657
(Previous) Eval Time (s)     4.675535380025394
Sample Time (s)              8.922732749953866
Epoch Time (s)               138.89952455897583
Total Train Time (s)         5742.5248938319855
Epoch                        40
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 21:54:15.667116 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #40 | Epoch Duration: 137.69396924972534
2020-01-05 21:54:15.667267 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #40 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.27356988
Z variance train             0.077367
KL Divergence                4.4473743
KL Loss                      0.44473743
QF Loss                      2318.954
VF Loss                      1132.5205
Policy Loss                  -1068.3523
Q Predictions Mean           1054.1838
Q Predictions Std            476.24908
Q Predictions Max            1662.9701
Q Predictions Min            53.988026
V Predictions Mean           1053.95
V Predictions Std            469.8266
V Predictions Max            1642.567
V Predictions Min            50.524284
Log Pis Mean                 -3.644806
Log Pis Std                  5.7020144
Log Pis Max                  19.293884
Log Pis Min                  -16.89542
Policy mu Mean               0.076458275
Policy mu Std                0.8112575
Policy mu Max                2.7953713
Policy mu Min                -2.3708992
Policy log std Mean          -0.30312523
Policy log std Std           0.12324012
Policy log std Max           -0.015726477
Policy log std Min           -0.84260297
Z mean eval                  0.25846368
Z variance eval              0.07689749
total_rewards                [1180.38257673  874.94119529  493.17750793 1194.90209799  720.11420363
  608.34958733  462.30619218 2974.48529282  395.13700838  978.70179007]
total_rewards_mean           988.2497452336165
total_rewards_std            716.0585534499669
total_rewards_max            2974.4852928180485
total_rewards_min            395.13700837646206
Number of train steps total  168000
Number of env steps total    234272
Number of rollouts total     0
Train Time (s)               128.56129673903342
(Previous) Eval Time (s)     3.469731296005193
Sample Time (s)              8.48083235800732
Epoch Time (s)               140.51186039304594
Total Train Time (s)         5885.007043195015
Epoch                        41
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 21:56:38.150009 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #41 | Epoch Duration: 142.48262286186218
2020-01-05 21:56:38.150168 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #41 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.42411408
Z variance train             0.106506765
KL Divergence                4.082404
KL Loss                      0.4082404
QF Loss                      2490.3792
VF Loss                      957.6373
Policy Loss                  -1089.2745
Q Predictions Mean           1086.2996
Q Predictions Std            476.38055
Q Predictions Max            1661.2145
Q Predictions Min            28.17116
V Predictions Mean           1079.828
V Predictions Std            476.24823
V Predictions Max            1658.7925
V Predictions Min            33.61025
Log Pis Mean                 -3.7326572
Log Pis Std                  4.8878555
Log Pis Max                  12.201744
Log Pis Min                  -14.083165
Policy mu Mean               0.12764451
Policy mu Std                0.79515165
Policy mu Max                2.4224122
Policy mu Min                -2.4322066
Policy log std Mean          -0.29854572
Policy log std Std           0.12370775
Policy log std Max           -0.009775817
Policy log std Min           -0.81552744
Z mean eval                  0.23882642
Z variance eval              0.0779576
total_rewards                [1028.92809919  960.45947703  844.65009686  890.90846122  728.19946682
  441.76300837  442.87078549  567.09784786 1079.9239176   661.7587625 ]
total_rewards_mean           764.6559922945788
total_rewards_std            221.0572540065348
total_rewards_max            1079.9239176047129
total_rewards_min            441.76300836720094
Number of train steps total  172000
Number of env steps total    239817
Number of rollouts total     0
Train Time (s)               127.76839819399174
(Previous) Eval Time (s)     5.440232641994953
Sample Time (s)              9.3214932110277
Epoch Time (s)               142.5301240470144
Total Train Time (s)         6025.923000552983
Epoch                        42
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 21:58:59.066731 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #42 | Epoch Duration: 140.91644859313965
2020-01-05 21:58:59.066860 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #42 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.22045322
Z variance train             0.078273416
KL Divergence                4.310229
KL Loss                      0.43102288
QF Loss                      2126.7344
VF Loss                      1250.1359
Policy Loss                  -1050.5002
Q Predictions Mean           1047.8044
Q Predictions Std            528.21533
Q Predictions Max            1675.0419
Q Predictions Min            29.08788
V Predictions Mean           1041.9606
V Predictions Std            524.3241
V Predictions Max            1672.3915
V Predictions Min            34.857212
Log Pis Mean                 -4.1243362
Log Pis Std                  5.02586
Log Pis Max                  15.373418
Log Pis Min                  -15.365745
Policy mu Mean               0.15624213
Policy mu Std                0.77725327
Policy mu Max                2.734594
Policy mu Min                -2.413589
Policy log std Mean          -0.29336324
Policy log std Std           0.12351294
Policy log std Max           -0.038450062
Policy log std Min           -0.81507385
Z mean eval                  0.42269722
Z variance eval              0.12614009
total_rewards                [ 855.89009331 3790.21328573 1166.4074743  1109.69033687 1060.22587851
  696.52516255  511.68799663 3832.17804521  631.27186196  550.70390414]
total_rewards_mean           1420.479403921593
total_rewards_std            1215.359396176084
total_rewards_max            3832.1780452128887
total_rewards_min            511.6879966277124
Number of train steps total  176000
Number of env steps total    245506
Number of rollouts total     0
Train Time (s)               122.87981323699933
(Previous) Eval Time (s)     3.8263055539573543
Sample Time (s)              9.165722668985836
Epoch Time (s)               135.87184145994252
Total Train Time (s)         6166.128771266842
Epoch                        43
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 22:01:19.273677 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #43 | Epoch Duration: 140.20672416687012
2020-01-05 22:01:19.273786 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #43 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.15010677
Z variance train             0.06403675
KL Divergence                4.6455336
KL Loss                      0.46455336
QF Loss                      2040.5435
VF Loss                      753.4528
Policy Loss                  -1052.066
Q Predictions Mean           1045.8002
Q Predictions Std            503.8787
Q Predictions Max            1663.1381
Q Predictions Min            6.1082516
V Predictions Mean           1060.9907
V Predictions Std            510.2802
V Predictions Max            1680.7781
V Predictions Min            26.749977
Log Pis Mean                 -3.1122494
Log Pis Std                  5.320531
Log Pis Max                  16.508284
Log Pis Min                  -14.086146
Policy mu Mean               0.13454612
Policy mu Std                0.8223796
Policy mu Max                2.9609337
Policy mu Min                -3.055657
Policy log std Mean          -0.3109238
Policy log std Std           0.1300746
Policy log std Max           -0.037206218
Policy log std Min           -0.96408564
Z mean eval                  0.15054406
Z variance eval              0.0584818
total_rewards                [1069.45488885 1463.64157676  625.9452193  1018.38512657 2047.23110914
 2659.68925223  957.69103622 1743.47644453  710.2888766  1413.59608141]
total_rewards_mean           1370.9399611603205
total_rewards_std            603.7284880426939
total_rewards_max            2659.6892522280946
total_rewards_min            625.945219299294
Number of train steps total  180000
Number of env steps total    251254
Number of rollouts total     0
Train Time (s)               124.22045325202635
(Previous) Eval Time (s)     8.160939576977398
Sample Time (s)              9.559644363180269
Epoch Time (s)               141.941037192184
Total Train Time (s)         6306.926391952962
Epoch                        44
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 22:03:40.073225 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #44 | Epoch Duration: 140.7993459701538
2020-01-05 22:03:40.073374 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #44 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.12784621
Z variance train             0.050012697
KL Divergence                5.1795945
KL Loss                      0.5179595
QF Loss                      1887.6973
VF Loss                      969.9072
Policy Loss                  -1074.8159
Q Predictions Mean           1065.0996
Q Predictions Std            527.22437
Q Predictions Max            1689.3224
Q Predictions Min            28.382298
V Predictions Mean           1069.2532
V Predictions Std            528.1406
V Predictions Max            1695.1993
V Predictions Min            18.47052
Log Pis Mean                 -4.324746
Log Pis Std                  4.4537363
Log Pis Max                  12.468172
Log Pis Min                  -14.042479
Policy mu Mean               0.13128887
Policy mu Std                0.772922
Policy mu Max                2.7045321
Policy mu Min                -2.273116
Policy log std Mean          -0.29241028
Policy log std Std           0.12478812
Policy log std Max           0.22845247
Policy log std Min           -0.7770583
Z mean eval                  0.17423481
Z variance eval              0.06163306
total_rewards                [1801.37373881  684.39183557 1875.22514757 1693.46452913  607.8031229
  519.1458639   927.75488594 1224.2924125   394.27902319  496.01076903]
total_rewards_mean           1022.3741328527265
total_rewards_std            551.8317729805187
total_rewards_max            1875.2251475728908
total_rewards_min            394.2790231854911
Number of train steps total  184000
Number of env steps total    257216
Number of rollouts total     0
Train Time (s)               128.78908137604594
(Previous) Eval Time (s)     7.018992195022292
Sample Time (s)              10.051762490940746
Epoch Time (s)               145.85983606200898
Total Train Time (s)         6451.3141326780315
Epoch                        45
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 22:06:04.461342 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #45 | Epoch Duration: 144.38785648345947
2020-01-05 22:06:04.461468 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #45 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1841386
Z variance train             0.054513793
KL Divergence                5.0501194
KL Loss                      0.505012
QF Loss                      2091.8257
VF Loss                      1231.9584
Policy Loss                  -1132.3645
Q Predictions Mean           1132.841
Q Predictions Std            505.28082
Q Predictions Max            1733.3281
Q Predictions Min            21.64844
V Predictions Mean           1152.3104
V Predictions Std            506.0597
V Predictions Max            1743.6418
V Predictions Min            43.485504
Log Pis Mean                 -3.6597903
Log Pis Std                  5.0895658
Log Pis Max                  13.306894
Log Pis Min                  -14.279244
Policy mu Mean               0.102747664
Policy mu Std                0.8096632
Policy mu Max                2.731318
Policy mu Min                -2.5884337
Policy log std Mean          -0.30518308
Policy log std Std           0.12803331
Policy log std Max           -0.029011786
Policy log std Min           -0.82838863
Z mean eval                  0.19811536
Z variance eval              0.073591515
total_rewards                [ 978.03440641  883.04320571  692.08869509 1181.53697982  523.74305177
  736.13627227 1115.58237796  726.28879581  534.97361401  496.89337711]
total_rewards_mean           786.8320775950637
total_rewards_std            232.7248299935151
total_rewards_max            1181.536979823025
total_rewards_min            496.8933771100303
Number of train steps total  188000
Number of env steps total    263123
Number of rollouts total     0
Train Time (s)               128.9701539449743
(Previous) Eval Time (s)     5.546552451967727
Sample Time (s)              9.548955815902445
Epoch Time (s)               144.06566221284447
Total Train Time (s)         6593.808587760839
Epoch                        46
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 22:08:26.956749 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #46 | Epoch Duration: 142.49518990516663
2020-01-05 22:08:26.956868 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #46 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11396617
Z variance train             0.04172645
KL Divergence                5.6140633
KL Loss                      0.5614063
QF Loss                      1940.494
VF Loss                      959.0885
Policy Loss                  -1114.4722
Q Predictions Mean           1108.8167
Q Predictions Std            514.6552
Q Predictions Max            1719.2625
Q Predictions Min            48.75273
V Predictions Mean           1099.4132
V Predictions Std            509.23132
V Predictions Max            1699.6998
V Predictions Min            45.739807
Log Pis Mean                 -3.7512357
Log Pis Std                  5.425064
Log Pis Max                  21.942741
Log Pis Min                  -15.887692
Policy mu Mean               0.13922754
Policy mu Std                0.8127498
Policy mu Max                2.6221762
Policy mu Min                -2.609599
Policy log std Mean          -0.30936956
Policy log std Std           0.12936388
Policy log std Max           -0.011495739
Policy log std Min           -0.89499664
Z mean eval                  0.3629846
Z variance eval              0.11194618
total_rewards                [ 553.02824944 1252.14994459  995.98365073  642.96356494  550.13340836
  979.2390403   628.63617063  440.23835908  657.91170447  473.1518339 ]
total_rewards_mean           717.3435926450837
total_rewards_std            253.09219453978199
total_rewards_max            1252.149944585319
total_rewards_min            440.2383590847726
Number of train steps total  192000
Number of env steps total    268897
Number of rollouts total     0
Train Time (s)               132.05783448898
(Previous) Eval Time (s)     3.9758306759758852
Sample Time (s)              9.168168454954866
Epoch Time (s)               145.20183361991076
Total Train Time (s)         6738.687696960813
Epoch                        47
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 22:10:51.838136 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #47 | Epoch Duration: 144.88116788864136
2020-01-05 22:10:51.838305 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #47 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.32545763
Z variance train             0.10027337
KL Divergence                3.8776727
KL Loss                      0.3877673
QF Loss                      1879.824
VF Loss                      677.96985
Policy Loss                  -1073.0323
Q Predictions Mean           1070.7922
Q Predictions Std            526.961
Q Predictions Max            1745.0258
Q Predictions Min            22.117699
V Predictions Mean           1076.0892
V Predictions Std            526.97876
V Predictions Max            1737.7169
V Predictions Min            25.467371
Log Pis Mean                 -3.8771062
Log Pis Std                  5.06183
Log Pis Max                  15.157156
Log Pis Min                  -12.643574
Policy mu Mean               0.08316346
Policy mu Std                0.78918767
Policy mu Max                2.598105
Policy mu Min                -2.4644191
Policy log std Mean          -0.29836845
Policy log std Std           0.12776767
Policy log std Max           -0.027640417
Policy log std Min           -0.77906966
Z mean eval                  0.61675316
Z variance eval              0.19484787
total_rewards                [2118.79523114  736.16336806  885.32330758  985.85100252  861.48091952
  701.86556961  867.92778011 1848.57298013  571.26390705  635.78529995]
total_rewards_mean           1021.3029365673183
total_rewards_std            499.2177037791196
total_rewards_max            2118.7952311359436
total_rewards_min            571.26390705006
Number of train steps total  196000
Number of env steps total    274765
Number of rollouts total     0
Train Time (s)               125.40112374199089
(Previous) Eval Time (s)     3.6548932529985905
Sample Time (s)              9.714912261173595
Epoch Time (s)               138.77092925616307
Total Train Time (s)         6878.985563529946
Epoch                        48
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 22:13:12.137311 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #48 | Epoch Duration: 140.2988748550415
2020-01-05 22:13:12.137464 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #48 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.534659
Z variance train             0.17103472
KL Divergence                3.5562253
KL Loss                      0.35562253
QF Loss                      2609.1296
VF Loss                      938.6431
Policy Loss                  -1152.567
Q Predictions Mean           1149.0759
Q Predictions Std            506.57727
Q Predictions Max            1755.0662
Q Predictions Min            31.85776
V Predictions Mean           1163.2041
V Predictions Std            502.6626
V Predictions Max            1758.979
V Predictions Min            42.375587
Log Pis Mean                 -2.4294872
Log Pis Std                  6.214304
Log Pis Max                  22.415401
Log Pis Min                  -14.680012
Policy mu Mean               0.09285371
Policy mu Std                0.87665373
Policy mu Max                3.1688008
Policy mu Min                -2.96045
Policy log std Mean          -0.31981054
Policy log std Std           0.13909993
Policy log std Max           0.013162836
Policy log std Min           -1.2070793
Z mean eval                  0.2971711
Z variance eval              0.11367484
total_rewards                [ 551.52659856 2345.50052978 1193.99660137  938.76299095  619.50049381
  666.62301429  477.14214156 1521.13213807 1556.01437555 1250.93388   ]
total_rewards_mean           1112.113276394659
total_rewards_std            556.793479204723
total_rewards_max            2345.5005297838616
total_rewards_min            477.14214156438726
Number of train steps total  200000
Number of env steps total    280715
Number of rollouts total     0
Train Time (s)               130.6229038219899
(Previous) Eval Time (s)     5.182594279001933
Sample Time (s)              9.471756365033798
Epoch Time (s)               145.27725446602562
Total Train Time (s)         7024.610948513029
Epoch                        49
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 22:15:37.763524 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #49 | Epoch Duration: 145.62593865394592
2020-01-05 22:15:37.763644 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #49 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.27541387
Z variance train             0.10572269
KL Divergence                3.7614918
KL Loss                      0.37614918
QF Loss                      2715.1096
VF Loss                      1290.4142
Policy Loss                  -1121.7311
Q Predictions Mean           1118.8286
Q Predictions Std            502.46066
Q Predictions Max            1738.3011
Q Predictions Min            35.97626
V Predictions Mean           1130.5999
V Predictions Std            496.40155
V Predictions Max            1754.9473
V Predictions Min            45.95143
Log Pis Mean                 -3.2052355
Log Pis Std                  5.4844775
Log Pis Max                  36.89944
Log Pis Min                  -14.535564
Policy mu Mean               0.12027656
Policy mu Std                0.8379465
Policy mu Max                2.83916
Policy mu Min                -2.6507082
Policy log std Mean          -0.30779886
Policy log std Std           0.12821586
Policy log std Max           -0.012789115
Policy log std Min           -1.0212345
Z mean eval                  0.13217854
Z variance eval              0.043526836
total_rewards                [ 962.89567276  612.12284835  384.79034227  505.73430437  562.48494899
  856.57720808 1442.76074939  515.97369618 1511.32273566  620.45108425]
total_rewards_mean           797.511359030367
total_rewards_std            375.82001011544
total_rewards_max            1511.3227356620619
total_rewards_min            384.790342273831
Number of train steps total  204000
Number of env steps total    286385
Number of rollouts total     0
Train Time (s)               122.93684942799155
(Previous) Eval Time (s)     5.531038259039633
Sample Time (s)              8.89971518504899
Epoch Time (s)               137.36760287208017
Total Train Time (s)         7160.590805995918
Epoch                        50
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 22:17:53.744531 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #50 | Epoch Duration: 135.98079442977905
2020-01-05 22:17:53.744659 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #50 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.15318614
Z variance train             0.05413246
KL Divergence                5.0505157
KL Loss                      0.50505155
QF Loss                      2394.0732
VF Loss                      764.63513
Policy Loss                  -1208.4574
Q Predictions Mean           1203.3005
Q Predictions Std            506.13156
Q Predictions Max            1768.6898
Q Predictions Min            9.900746
V Predictions Mean           1207.3854
V Predictions Std            502.55527
V Predictions Max            1756.0887
V Predictions Min            37.57752
Log Pis Mean                 -3.3578978
Log Pis Std                  4.9524746
Log Pis Max                  14.6167345
Log Pis Min                  -15.084902
Policy mu Mean               0.09333974
Policy mu Std                0.82613885
Policy mu Max                2.4765077
Policy mu Min                -2.6755443
Policy log std Mean          -0.3137357
Policy log std Std           0.120899215
Policy log std Max           -0.026812807
Policy log std Min           -0.837957
Z mean eval                  0.15847553
Z variance eval              0.05198093
total_rewards                [1440.55607325 1641.54047115 1116.87876371  771.12331649 1885.65856246
  620.75513663  456.73840164 3102.7864802   766.31788559  437.26663178]
total_rewards_mean           1223.962172290907
total_rewards_std            786.5403067115229
total_rewards_max            3102.7864802037157
total_rewards_min            437.26663178488207
Number of train steps total  208000
Number of env steps total    292431
Number of rollouts total     0
Train Time (s)               127.17568427498918
(Previous) Eval Time (s)     4.143978541018441
Sample Time (s)              9.907116463058628
Epoch Time (s)               141.22677927906625
Total Train Time (s)         7304.022447279131
Epoch                        51
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 22:20:17.176934 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #51 | Epoch Duration: 143.43217611312866
2020-01-05 22:20:17.177062 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #51 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.13114476
Z variance train             0.0490636
KL Divergence                5.2655783
KL Loss                      0.52655786
QF Loss                      2264.1892
VF Loss                      792.56506
Policy Loss                  -1151.5369
Q Predictions Mean           1141.1357
Q Predictions Std            552.231
Q Predictions Max            1752.1079
Q Predictions Min            25.374022
V Predictions Mean           1149.923
V Predictions Std            552.75256
V Predictions Max            1779.0696
V Predictions Min            24.68127
Log Pis Mean                 -3.0406227
Log Pis Std                  5.3189025
Log Pis Max                  15.607883
Log Pis Min                  -14.444829
Policy mu Mean               0.12783353
Policy mu Std                0.81781584
Policy mu Max                2.4955478
Policy mu Min                -2.3252425
Policy log std Mean          -0.3224469
Policy log std Std           0.12120921
Policy log std Max           -0.04464653
Policy log std Min           -0.8972826
Z mean eval                  0.22179118
Z variance eval              0.0955807
total_rewards                [ 524.38098132 1850.87278813 1578.68154912  633.78986071  761.91314751
  672.14334441 1232.85330826 2308.94679024  582.09378107 2184.89767858]
total_rewards_mean           1233.0573229351915
total_rewards_std            662.2981814487798
total_rewards_max            2308.946790240414
total_rewards_min            524.3809813172833
Number of train steps total  212000
Number of env steps total    298241
Number of rollouts total     0
Train Time (s)               127.47477236995474
(Previous) Eval Time (s)     6.3491272940300405
Sample Time (s)              9.696203250903636
Epoch Time (s)               143.5201029148884
Total Train Time (s)         7447.911869544012
Epoch                        52
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 22:22:41.068084 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #52 | Epoch Duration: 143.89091420173645
2020-01-05 22:22:41.068261 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #52 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.31472728
Z variance train             0.11019914
KL Divergence                3.695475
KL Loss                      0.36954752
QF Loss                      2557.7747
VF Loss                      845.0636
Policy Loss                  -1121.6266
Q Predictions Mean           1115.6461
Q Predictions Std            553.7163
Q Predictions Max            1782.123
Q Predictions Min            32.22487
V Predictions Mean           1118.1422
V Predictions Std            552.6034
V Predictions Max            1774.1213
V Predictions Min            36.310154
Log Pis Mean                 -3.0627992
Log Pis Std                  5.3678784
Log Pis Max                  22.055687
Log Pis Min                  -12.620758
Policy mu Mean               0.0970298
Policy mu Std                0.844695
Policy mu Max                2.9342606
Policy mu Min                -2.4868026
Policy log std Mean          -0.31471506
Policy log std Std           0.13387614
Policy log std Max           0.1557025
Policy log std Min           -0.8794132
Z mean eval                  0.11564541
Z variance eval              0.0632372
total_rewards                [ 913.8289331  1078.73166581  658.53224888 1487.27210579  886.30191255
 1002.75746221 1515.00305724  756.37255229  893.68971062 3600.54678209]
total_rewards_mean           1279.303643056227
total_rewards_std            818.487384889978
total_rewards_max            3600.5467820872414
total_rewards_min            658.5322488789569
Number of train steps total  216000
Number of env steps total    303814
Number of rollouts total     0
Train Time (s)               129.31923849700252
(Previous) Eval Time (s)     6.719658398011234
Sample Time (s)              9.278453313978389
Epoch Time (s)               145.31735020899214
Total Train Time (s)         7593.855947261967
Epoch                        53
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 22:25:07.013814 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #53 | Epoch Duration: 145.94542050361633
2020-01-05 22:25:07.013997 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #53 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.2298269
Z variance train             0.06288357
KL Divergence                4.7939434
KL Loss                      0.47939435
QF Loss                      2340.0396
VF Loss                      1151.3042
Policy Loss                  -1194.3224
Q Predictions Mean           1185.3699
Q Predictions Std            513.3048
Q Predictions Max            1785.2155
Q Predictions Min            45.7085
V Predictions Mean           1204.9591
V Predictions Std            516.9583
V Predictions Max            1786.5223
V Predictions Min            48.90594
Log Pis Mean                 -2.499442
Log Pis Std                  5.4336305
Log Pis Max                  18.280203
Log Pis Min                  -12.864386
Policy mu Mean               0.093453914
Policy mu Std                0.8536497
Policy mu Max                2.8361
Policy mu Min                -2.7765813
Policy log std Mean          -0.32984602
Policy log std Std           0.13307048
Policy log std Max           0.0010629445
Policy log std Min           -0.86227596
Z mean eval                  0.091702744
Z variance eval              0.06638494
total_rewards                [ 364.12474255 2345.75332326 1779.17193821 3876.58315611 1139.33214641
  560.11920236 1499.57267655 1440.5105118  1129.63592848 3142.6475223 ]
total_rewards_mean           1727.7451148040964
total_rewards_std            1051.9208242209686
total_rewards_max            3876.5831561101973
total_rewards_min            364.1247425548548
Number of train steps total  220000
Number of env steps total    309392
Number of rollouts total     0
Train Time (s)               126.67449394799769
(Previous) Eval Time (s)     7.347475346003193
Sample Time (s)              9.414226615917869
Epoch Time (s)               143.43619590991875
Total Train Time (s)         7739.878332966997
Epoch                        54
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 22:27:33.036820 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #54 | Epoch Duration: 146.02269530296326
2020-01-05 22:27:33.036969 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #54 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1425719
Z variance train             0.09542083
KL Divergence                3.7070835
KL Loss                      0.37070835
QF Loss                      2085.444
VF Loss                      895.24146
Policy Loss                  -1270.0197
Q Predictions Mean           1275.0225
Q Predictions Std            516.6023
Q Predictions Max            1806.0754
Q Predictions Min            11.655924
V Predictions Mean           1282.1184
V Predictions Std            515.2841
V Predictions Max            1812.7006
V Predictions Min            28.767134
Log Pis Mean                 -3.499537
Log Pis Std                  5.0940466
Log Pis Max                  23.420797
Log Pis Min                  -16.96627
Policy mu Mean               0.1008436
Policy mu Std                0.8393714
Policy mu Max                2.5090637
Policy mu Min                -2.4162729
Policy log std Mean          -0.31709135
Policy log std Std           0.13114135
Policy log std Max           0.039828897
Policy log std Min           -1.0257967
Z mean eval                  0.22927622
Z variance eval              0.12914331
total_rewards                [1288.04702276 1284.05398427  290.9188913  1719.09136682 1547.32760884
 1865.43244934  715.68576271 1235.74081286  659.69631705 2222.70858947]
total_rewards_mean           1282.8702805422988
total_rewards_std            563.8406027642083
total_rewards_max            2222.708589474373
total_rewards_min            290.91889130002085
Number of train steps total  224000
Number of env steps total    315231
Number of rollouts total     0
Train Time (s)               123.58748764399206
(Previous) Eval Time (s)     9.933727630996145
Sample Time (s)              9.783505411935039
Epoch Time (s)               143.30472068692325
Total Train Time (s)         7880.117678248906
Epoch                        55
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 22:29:53.277653 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #55 | Epoch Duration: 140.24056792259216
2020-01-05 22:29:53.277828 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #55 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.16301695
Z variance train             0.085220754
KL Divergence                3.9732065
KL Loss                      0.39732066
QF Loss                      1998.814
VF Loss                      669.33325
Policy Loss                  -1199.8984
Q Predictions Mean           1189.6687
Q Predictions Std            558.80145
Q Predictions Max            1799.194
Q Predictions Min            12.720202
V Predictions Mean           1194.8877
V Predictions Std            560.6042
V Predictions Max            1804.862
V Predictions Min            16.052124
Log Pis Mean                 -3.4739602
Log Pis Std                  5.3713074
Log Pis Max                  22.8662
Log Pis Min                  -16.076733
Policy mu Mean               0.11866285
Policy mu Std                0.8183937
Policy mu Max                2.7521007
Policy mu Min                -3.1009624
Policy log std Mean          -0.3180241
Policy log std Std           0.134625
Policy log std Max           -0.04444784
Policy log std Min           -0.885776
Z mean eval                  0.3295042
Z variance eval              0.14783181
total_rewards                [ 821.45360319 1122.84729602  908.02718445 2490.59539402 1010.41588817
 1003.97960781 1061.89387373 1301.08274821  850.62425011  664.95799951]
total_rewards_mean           1123.5877845191485
total_rewards_std            485.15324941898945
total_rewards_max            2490.595394015755
total_rewards_min            664.957999507571
Number of train steps total  228000
Number of env steps total    320795
Number of rollouts total     0
Train Time (s)               128.2616716880002
(Previous) Eval Time (s)     6.869325483974535
Sample Time (s)              9.57382515707286
Epoch Time (s)               144.7048223290476
Total Train Time (s)         8023.956679798954
Epoch                        56
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 22:32:17.117297 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #56 | Epoch Duration: 143.8393394947052
2020-01-05 22:32:17.117412 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #56 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.31071848
Z variance train             0.0980272
KL Divergence                3.90503
KL Loss                      0.39050302
QF Loss                      1944.1567
VF Loss                      746.7934
Policy Loss                  -1266.8197
Q Predictions Mean           1261.5121
Q Predictions Std            557.36456
Q Predictions Max            1869.0531
Q Predictions Min            44.71989
V Predictions Mean           1257.5034
V Predictions Std            557.0373
V Predictions Max            1849.6022
V Predictions Min            4.342869
Log Pis Mean                 -3.15727
Log Pis Std                  5.3808365
Log Pis Max                  16.01881
Log Pis Min                  -15.60236
Policy mu Mean               0.07195019
Policy mu Std                0.8441409
Policy mu Max                2.7603202
Policy mu Min                -2.5967803
Policy log std Mean          -0.31946793
Policy log std Std           0.12844285
Policy log std Max           0.02359204
Policy log std Min           -0.8834242
Z mean eval                  0.20543203
Z variance eval              0.05766763
total_rewards                [ 517.16224792 1255.78529884 2057.34595176 1176.21330257 2247.97709702
  641.98157626  608.35161761  876.67556759 2081.19119682  674.00845446]
total_rewards_mean           1213.6692310848944
total_rewards_std            641.9120570477781
total_rewards_max            2247.9770970168975
total_rewards_min            517.1622479238475
Number of train steps total  232000
Number of env steps total    326395
Number of rollouts total     0
Train Time (s)               127.99473663500976
(Previous) Eval Time (s)     6.0035916460328735
Sample Time (s)              9.211712445947342
Epoch Time (s)               143.21004072698997
Total Train Time (s)         8167.857936349872
Epoch                        57
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 22:34:41.019971 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #57 | Epoch Duration: 143.9024579524994
2020-01-05 22:34:41.020152 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #57 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.13052127
Z variance train             0.037556004
KL Divergence                5.872632
KL Loss                      0.5872632
QF Loss                      1943.3462
VF Loss                      696.6435
Policy Loss                  -1218.7836
Q Predictions Mean           1214.6069
Q Predictions Std            560.6209
Q Predictions Max            1876.5111
Q Predictions Min            5.369616
V Predictions Mean           1225.3342
V Predictions Std            551.0371
V Predictions Max            1849.3016
V Predictions Min            9.020815
Log Pis Mean                 -3.5655699
Log Pis Std                  5.1949606
Log Pis Max                  19.419682
Log Pis Min                  -16.124104
Policy mu Mean               0.10381248
Policy mu Std                0.8310626
Policy mu Max                2.9620986
Policy mu Min                -2.9081
Policy log std Mean          -0.31344217
Policy log std Std           0.12858514
Policy log std Max           -0.018166333
Policy log std Min           -0.8820057
Z mean eval                  0.14457497
Z variance eval              0.03554917
total_rewards                [ 598.11947124 4265.23871085  688.79193395  828.3980383   649.17805042
 2748.40551317 1020.27703667 2059.82247696 2478.61240567 1198.1895978 ]
total_rewards_mean           1653.5033235032708
total_rewards_std            1149.2662892531825
total_rewards_max            4265.238710851204
total_rewards_min            598.1194712448878
Number of train steps total  236000
Number of env steps total    332425
Number of rollouts total     0
Train Time (s)               127.96532010898227
(Previous) Eval Time (s)     6.695758850954007
Sample Time (s)              9.971740560955368
Epoch Time (s)               144.63281952089164
Total Train Time (s)         8315.059985298838
Epoch                        58
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 22:37:08.223460 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #58 | Epoch Duration: 147.20318984985352
2020-01-05 22:37:08.223592 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #58 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.21345893
Z variance train             0.051205575
KL Divergence                5.224964
KL Loss                      0.5224964
QF Loss                      2780.706
VF Loss                      1351.8632
Policy Loss                  -1214.9425
Q Predictions Mean           1197.4092
Q Predictions Std            561.8114
Q Predictions Max            1850.0894
Q Predictions Min            28.878704
V Predictions Mean           1198.4993
V Predictions Std            558.9801
V Predictions Max            1850.9655
V Predictions Min            56.20673
Log Pis Mean                 -2.8793907
Log Pis Std                  5.9910283
Log Pis Max                  20.817753
Log Pis Min                  -14.395151
Policy mu Mean               0.082795195
Policy mu Std                0.86203545
Policy mu Max                2.6347585
Policy mu Min                -2.8927436
Policy log std Mean          -0.3305985
Policy log std Std           0.1324472
Policy log std Max           -0.0059008747
Policy log std Min           -0.9295322
Z mean eval                  0.21669674
Z variance eval              0.05501034
total_rewards                [1236.88789767 1785.83694618  972.9576136   873.05532631 3669.04551603
  769.24685061  374.10949382 2371.88374322  946.12621863 1723.07189736]
total_rewards_mean           1472.2221503432113
total_rewards_std            918.5398465212845
total_rewards_max            3669.045516032561
total_rewards_min            374.10949381817795
Number of train steps total  240000
Number of env steps total    338101
Number of rollouts total     0
Train Time (s)               128.72986648697406
(Previous) Eval Time (s)     9.265880569990259
Sample Time (s)              9.58161629998358
Epoch Time (s)               147.5773633569479
Total Train Time (s)         8461.543307120679
Epoch                        59
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 22:39:34.708704 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #59 | Epoch Duration: 146.4850037097931
2020-01-05 22:39:34.708872 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #59 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.22486079
Z variance train             0.05325343
KL Divergence                5.1616178
KL Loss                      0.5161618
QF Loss                      2243.8943
VF Loss                      841.5634
Policy Loss                  -1273.3947
Q Predictions Mean           1270.8844
Q Predictions Std            558.0756
Q Predictions Max            1876.2372
Q Predictions Min            14.531588
V Predictions Mean           1285.3833
V Predictions Std            560.0905
V Predictions Max            1887.0259
V Predictions Min            64.08239
Log Pis Mean                 -2.8597436
Log Pis Std                  5.201518
Log Pis Max                  16.247543
Log Pis Min                  -12.585547
Policy mu Mean               0.05252867
Policy mu Std                0.8452914
Policy mu Max                2.7777853
Policy mu Min                -2.7441936
Policy log std Mean          -0.3251332
Policy log std Std           0.1282589
Policy log std Max           -0.051260114
Policy log std Min           -0.9196598
Z mean eval                  0.17264582
Z variance eval              0.04082818
total_rewards                [ 738.31037522 2451.09619466 4619.33085929 2570.73307613 4582.32333522
  824.26368314 4590.52051079  484.34980303 4651.3423971  1202.26902392]
total_rewards_mean           2671.4539258510185
total_rewards_std            1708.7483162541873
total_rewards_max            4651.342397100029
total_rewards_min            484.34980303083876
Number of train steps total  244000
Number of env steps total    344080
Number of rollouts total     0
Train Time (s)               128.13303398003336
(Previous) Eval Time (s)     8.173252452979796
Sample Time (s)              10.062661047908477
Epoch Time (s)               146.36894748092163
Total Train Time (s)         8615.534279090585
Epoch                        60
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 22:42:08.700636 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #60 | Epoch Duration: 153.99162364006042
2020-01-05 22:42:08.700765 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #60 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.20134218
Z variance train             0.04756161
KL Divergence                5.3939886
KL Loss                      0.53939885
QF Loss                      2398.439
VF Loss                      1447.3333
Policy Loss                  -1258.3899
Q Predictions Mean           1263.1007
Q Predictions Std            566.39435
Q Predictions Max            1916.0001
Q Predictions Min            41.28159
V Predictions Mean           1281.3009
V Predictions Std            570.51605
V Predictions Max            1923.9536
V Predictions Min            63.971703
Log Pis Mean                 -3.0931969
Log Pis Std                  5.1549115
Log Pis Max                  14.868624
Log Pis Min                  -14.426561
Policy mu Mean               0.07831872
Policy mu Std                0.8356111
Policy mu Max                2.37432
Policy mu Min                -2.8277683
Policy log std Mean          -0.32518744
Policy log std Std           0.13427334
Policy log std Max           -0.008270502
Policy log std Min           -0.79903543
Z mean eval                  0.15213633
Z variance eval              0.031048859
total_rewards                [1050.36631549 1670.70292528  611.64688631 2887.54810213  649.57788211
  527.91937918 1889.65204835 1039.18177488  581.76917983  741.79314384]
total_rewards_mean           1165.0157637391676
total_rewards_std            726.2226027216632
total_rewards_max            2887.5481021255728
total_rewards_min            527.9193791822655
Number of train steps total  248000
Number of env steps total    349709
Number of rollouts total     0
Train Time (s)               124.94588559895055
(Previous) Eval Time (s)     15.795669394021388
Sample Time (s)              9.871229557029437
Epoch Time (s)               150.61278455000138
Total Train Time (s)         8756.729652547569
Epoch                        61
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 22:44:29.896583 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #61 | Epoch Duration: 141.19571661949158
2020-01-05 22:44:29.896724 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #61 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14628635
Z variance train             0.031613346
KL Divergence                6.305516
KL Loss                      0.6305516
QF Loss                      2826.8535
VF Loss                      1161.386
Policy Loss                  -1316.8851
Q Predictions Mean           1315.1818
Q Predictions Std            519.50824
Q Predictions Max            1894.9929
Q Predictions Min            52.227013
V Predictions Mean           1330.258
V Predictions Std            519.2851
V Predictions Max            1903.5677
V Predictions Min            74.32997
Log Pis Mean                 -2.3640287
Log Pis Std                  5.8899217
Log Pis Max                  26.615864
Log Pis Min                  -16.485958
Policy mu Mean               0.069375746
Policy mu Std                0.8834208
Policy mu Max                2.73776
Policy mu Min                -2.9082491
Policy log std Mean          -0.33586088
Policy log std Std           0.12955981
Policy log std Max           0.028362364
Policy log std Min           -0.91075397
Z mean eval                  0.15196851
Z variance eval              0.029699693
total_rewards                [2769.62741335 3403.47150039 1495.20519374 1692.43368028 4668.28603694
  895.30909399 2127.3824226  3335.2575761   857.88989811 2318.90951281]
total_rewards_mean           2356.377232830936
total_rewards_std            1148.3368989749135
total_rewards_max            4668.286036938928
total_rewards_min            857.8898981132115
Number of train steps total  252000
Number of env steps total    355349
Number of rollouts total     0
Train Time (s)               125.95721308502834
(Previous) Eval Time (s)     6.378342418989632
Sample Time (s)              9.118484890030231
Epoch Time (s)               141.4540403940482
Total Train Time (s)         8905.006588450517
Epoch                        62
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 22:46:58.175158 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #62 | Epoch Duration: 148.27833032608032
2020-01-05 22:46:58.175308 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #62 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.12006078
Z variance train             0.026875624
KL Divergence                6.6737103
KL Loss                      0.66737103
QF Loss                      2890.1907
VF Loss                      1775.8257
Policy Loss                  -1306.18
Q Predictions Mean           1301.6876
Q Predictions Std            572.72943
Q Predictions Max            1900.7725
Q Predictions Min            27.129292
V Predictions Mean           1277.2964
V Predictions Std            561.72943
V Predictions Max            1871.1271
V Predictions Min            58.08114
Log Pis Mean                 -3.3159842
Log Pis Std                  5.1533885
Log Pis Max                  12.21211
Log Pis Min                  -13.047588
Policy mu Mean               0.07591365
Policy mu Std                0.8454516
Policy mu Max                2.7395957
Policy mu Min                -2.5745237
Policy log std Mean          -0.3192675
Policy log std Std           0.12825778
Policy log std Max           0.0017636716
Policy log std Min           -0.82936037
Z mean eval                  0.2008107
Z variance eval              0.031642098
total_rewards                [4912.89053747 3255.60140846 1392.74121197 1757.88910767 1000.4999203
  567.78639101 4848.00339641 1721.14153809 4791.40250483 4047.44674956]
total_rewards_mean           2829.540276577686
total_rewards_std            1638.0037896923245
total_rewards_max            4912.890537473163
total_rewards_min            567.7863910133963
Number of train steps total  256000
Number of env steps total    360993
Number of rollouts total     0
Train Time (s)               127.6617018399993
(Previous) Eval Time (s)     13.2023680889979
Sample Time (s)              9.710930403030943
Epoch Time (s)               150.57500033202814
Total Train Time (s)         9057.389896122622
Epoch                        63
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 22:49:30.560427 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #63 | Epoch Duration: 152.38498997688293
2020-01-05 22:49:30.560619 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #63 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.18500434
Z variance train             0.032876026
KL Divergence                6.2694488
KL Loss                      0.6269449
QF Loss                      2354.8232
VF Loss                      917.05066
Policy Loss                  -1266.8861
Q Predictions Mean           1262.2483
Q Predictions Std            583.8358
Q Predictions Max            1926.9418
Q Predictions Min            21.426159
V Predictions Mean           1266.5143
V Predictions Std            580.19086
V Predictions Max            1922.8865
V Predictions Min            16.864637
Log Pis Mean                 -2.863669
Log Pis Std                  5.682502
Log Pis Max                  29.603497
Log Pis Min                  -13.529677
Policy mu Mean               0.08302214
Policy mu Std                0.85141414
Policy mu Max                2.9481633
Policy mu Min                -3.1681833
Policy log std Mean          -0.31775582
Policy log std Std           0.13117233
Policy log std Max           0.02586697
Policy log std Min           -0.95670795
Z mean eval                  0.38414472
Z variance eval              0.10959242
total_rewards                [1874.70948553  994.33907475  755.11213748 4494.06422018 1033.38566486
 4784.75100508 4665.36683103 4098.85861144 4815.31506777 4791.89255848]
total_rewards_mean           3230.7794656592023
total_rewards_std            1719.5407828889472
total_rewards_max            4815.315067769583
total_rewards_min            755.1121374812186
Number of train steps total  260000
Number of env steps total    366873
Number of rollouts total     0
Train Time (s)               130.9381663929671
(Previous) Eval Time (s)     15.012088219984435
Sample Time (s)              9.592861556098796
Epoch Time (s)               155.54311616905034
Total Train Time (s)         9215.96900457464
Epoch                        64
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 22:52:09.140474 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #64 | Epoch Duration: 158.579683303833
2020-01-05 22:52:09.140601 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #64 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.31599915
Z variance train             0.09283976
KL Divergence                3.9978404
KL Loss                      0.39978406
QF Loss                      2173.2551
VF Loss                      1168.5161
Policy Loss                  -1267.4391
Q Predictions Mean           1267.4663
Q Predictions Std            585.6059
Q Predictions Max            1925.3105
Q Predictions Min            55.02025
V Predictions Mean           1285.619
V Predictions Std            588.1513
V Predictions Max            1938.9623
V Predictions Min            27.702148
Log Pis Mean                 -2.6203878
Log Pis Std                  5.5299864
Log Pis Max                  21.581968
Log Pis Min                  -17.133469
Policy mu Mean               0.098547325
Policy mu Std                0.8614502
Policy mu Max                3.0875185
Policy mu Min                -2.3788004
Policy log std Mean          -0.3239709
Policy log std Std           0.1337168
Policy log std Max           0.017576694
Policy log std Min           -1.0540947
Z mean eval                  0.11634569
Z variance eval              0.04679851
total_rewards                [ 641.73216813 1502.40739278 4768.74757531 2285.38979877 4707.72324632
  540.071079   4619.88652871 4806.406629    722.28294793 2009.9479041 ]
total_rewards_mean           2660.4595270061714
total_rewards_std            1769.558520092371
total_rewards_max            4806.406629000244
total_rewards_min            540.071079000283
Number of train steps total  264000
Number of env steps total    372643
Number of rollouts total     0
Train Time (s)               130.59679726499598
(Previous) Eval Time (s)     18.04841241700342
Sample Time (s)              9.972681623883545
Epoch Time (s)               158.61789130588295
Total Train Time (s)         9372.800967125455
Epoch                        65
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 22:54:45.973857 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #65 | Epoch Duration: 156.83315324783325
2020-01-05 22:54:45.973964 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.092951864
Z variance train             0.037280887
KL Divergence                5.8656187
KL Loss                      0.58656186
QF Loss                      2564.4692
VF Loss                      937.6048
Policy Loss                  -1322.7534
Q Predictions Mean           1314.8896
Q Predictions Std            575.21277
Q Predictions Max            1958.921
Q Predictions Min            11.775014
V Predictions Mean           1329.6161
V Predictions Std            572.5885
V Predictions Max            1968.7681
V Predictions Min            18.432537
Log Pis Mean                 -3.1784582
Log Pis Std                  5.1872673
Log Pis Max                  14.573229
Log Pis Min                  -15.700911
Policy mu Mean               0.062381268
Policy mu Std                0.8470382
Policy mu Max                2.8101594
Policy mu Min                -2.7914386
Policy log std Mean          -0.31864113
Policy log std Std           0.12912959
Policy log std Max           0.0024870634
Policy log std Min           -0.8336781
Z mean eval                  0.12370571
Z variance eval              0.07352835
total_rewards                [4536.48006273  951.25535914 2153.20303752 1514.63808063 3232.33637741
 2444.79713724 3281.29972157 2510.21040999 3568.84943487  923.62661434]
total_rewards_mean           2511.6696235443333
total_rewards_std            1114.136214797332
total_rewards_max            4536.480062726705
total_rewards_min            923.62661434101
Number of train steps total  268000
Number of env steps total    378294
Number of rollouts total     0
Train Time (s)               135.2785187099944
(Previous) Eval Time (s)     16.263428343983833
Sample Time (s)              9.731077518023085
Epoch Time (s)               161.2730245720013
Total Train Time (s)         9531.338960942521
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 22:57:24.514159 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #66 | Epoch Duration: 158.54009246826172
2020-01-05 22:57:24.514361 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #66 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.107183
Z variance train             0.0453517
KL Divergence                5.396121
KL Loss                      0.5396121
QF Loss                      2834.8596
VF Loss                      667.32043
Policy Loss                  -1325.7429
Q Predictions Mean           1320.6294
Q Predictions Std            566.04895
Q Predictions Max            1932.3447
Q Predictions Min            19.584538
V Predictions Mean           1329.834
V Predictions Std            562.2821
V Predictions Max            1954.9459
V Predictions Min            8.129554
Log Pis Mean                 -2.1196022
Log Pis Std                  5.4549947
Log Pis Max                  21.68224
Log Pis Min                  -13.221674
Policy mu Mean               0.053098846
Policy mu Std                0.8778844
Policy mu Max                2.7592947
Policy mu Min                -2.9322946
Policy log std Mean          -0.3340388
Policy log std Std           0.13927656
Policy log std Max           0.05200599
Policy log std Min           -0.9503601
Z mean eval                  0.5424491
Z variance eval              0.29440463
total_rewards                [4181.63350459 4476.58250016  803.44098032 4650.67951376  616.62472246
 4694.37466635 1853.91591324 2326.24586238  516.91281126  718.16787312]
total_rewards_mean           2483.8578347645757
total_rewards_std            1736.475081689891
total_rewards_max            4694.374666351607
total_rewards_min            516.9128112618872
Number of train steps total  272000
Number of env steps total    383844
Number of rollouts total     0
Train Time (s)               135.23422399000265
(Previous) Eval Time (s)     13.530221765046008
Sample Time (s)              9.53431418602122
Epoch Time (s)               158.29875994106987
Total Train Time (s)         9690.373004631547
Epoch                        67
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 23:00:03.549731 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #67 | Epoch Duration: 159.03520727157593
2020-01-05 23:00:03.549912 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #67 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.675476
Z variance train             0.41536197
KL Divergence                2.6568995
KL Loss                      0.26568994
QF Loss                      3013.1702
VF Loss                      1005.9667
Policy Loss                  -1322.5365
Q Predictions Mean           1315.7867
Q Predictions Std            590.22174
Q Predictions Max            1982.9707
Q Predictions Min            4.1415644
V Predictions Mean           1330.0037
V Predictions Std            591.5982
V Predictions Max            1993.5969
V Predictions Min            39.909283
Log Pis Mean                 -2.627668
Log Pis Std                  5.4113536
Log Pis Max                  14.967598
Log Pis Min                  -13.603241
Policy mu Mean               0.0799801
Policy mu Std                0.86329025
Policy mu Max                2.7739778
Policy mu Min                -3.1616144
Policy log std Mean          -0.3269127
Policy log std Std           0.13853523
Policy log std Max           0.13617489
Policy log std Min           -0.9981898
Z mean eval                  0.40252727
Z variance eval              0.2956213
total_rewards                [4756.62359335 4898.0227762   741.39200918 4639.27772003 3473.58913071
  805.18346588 1784.65278151 4727.37117066 3025.52623408 4009.39848572]
total_rewards_mean           3286.103736732153
total_rewards_std            1554.9960811210135
total_rewards_max            4898.022776199988
total_rewards_min            741.3920091836069
Number of train steps total  276000
Number of env steps total    389379
Number of rollouts total     0
Train Time (s)               139.17539012100315
(Previous) Eval Time (s)     14.266416860977188
Sample Time (s)              9.7366410951945
Epoch Time (s)               163.17844807717483
Total Train Time (s)         9857.630189214717
Epoch                        68
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 23:02:50.808721 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #68 | Epoch Duration: 167.25866985321045
2020-01-05 23:02:50.808847 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #68 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.26924834
Z variance train             0.19479918
KL Divergence                2.3897395
KL Loss                      0.23897396
QF Loss                      1884.4135
VF Loss                      1004.4061
Policy Loss                  -1352.4318
Q Predictions Mean           1350.0593
Q Predictions Std            603.9952
Q Predictions Max            1996.0665
Q Predictions Min            -1.1016166
V Predictions Mean           1337.8536
V Predictions Std            592.753
V Predictions Max            1960.2098
V Predictions Min            55.558784
Log Pis Mean                 -2.6243863
Log Pis Std                  5.573958
Log Pis Max                  22.107803
Log Pis Min                  -14.655092
Policy mu Mean               0.06429106
Policy mu Std                0.87433296
Policy mu Max                2.8882895
Policy mu Min                -2.4296305
Policy log std Mean          -0.33209968
Policy log std Std           0.13914229
Policy log std Max           0.073201686
Policy log std Min           -0.8915151
Z mean eval                  0.29954797
Z variance eval              0.32711893
total_rewards                [4590.5357492  4548.59867459 4570.29277918  981.39456168 4594.65969413
 3185.64747034 1140.34030211 2235.50453038 1784.18376282 3705.36950647]
total_rewards_mean           3133.652703090598
total_rewards_std            1410.1725427604867
total_rewards_max            4594.65969413078
total_rewards_min            981.3945616837399
Number of train steps total  280000
Number of env steps total    394855
Number of rollouts total     0
Train Time (s)               126.28199510800187
(Previous) Eval Time (s)     18.346229995018803
Sample Time (s)              9.424251295044087
Epoch Time (s)               154.05247639806475
Total Train Time (s)         10011.372434300778
Epoch                        69
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 23:05:24.553178 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #69 | Epoch Duration: 153.74421763420105
2020-01-05 23:05:24.553375 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #69 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.34197968
Z variance train             0.30391663
KL Divergence                1.7220526
KL Loss                      0.17220525
QF Loss                      2132.689
VF Loss                      824.8959
Policy Loss                  -1364.0248
Q Predictions Mean           1361.7537
Q Predictions Std            610.4579
Q Predictions Max            2004.3903
Q Predictions Min            12.174889
V Predictions Mean           1372.1067
V Predictions Std            606.81805
V Predictions Max            2010.074
V Predictions Min            76.63995
Log Pis Mean                 -2.3461475
Log Pis Std                  5.0410457
Log Pis Max                  14.103237
Log Pis Min                  -14.885254
Policy mu Mean               0.07990033
Policy mu Std                0.87563795
Policy mu Max                2.5045314
Policy mu Min                -2.412323
Policy log std Mean          -0.32535458
Policy log std Std           0.13453226
Policy log std Max           -0.04005213
Policy log std Min           -0.8104565
Z mean eval                  0.38313842
Z variance eval              0.19282314
total_rewards                [2905.69367751  708.34750846 2097.31828385 1000.07718126 4725.20991304
 4608.76347144 4583.44805667 1989.88028208 4636.64523018 1213.33974679]
total_rewards_mean           2846.8723351292697
total_rewards_std            1574.9124033472249
total_rewards_max            4725.209913043675
total_rewards_min            708.3475084648323
Number of train steps total  284000
Number of env steps total    400010
Number of rollouts total     0
Train Time (s)               144.37934154301183
(Previous) Eval Time (s)     18.037703575973865
Sample Time (s)              8.936883308168035
Epoch Time (s)               171.35392842715373
Total Train Time (s)         10181.65678299684
Epoch                        70
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 23:08:14.838555 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #70 | Epoch Duration: 170.28501796722412
2020-01-05 23:08:14.838716 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #70 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.5766746
Z variance train             0.34973186
KL Divergence                2.1682909
KL Loss                      0.21682909
QF Loss                      2767.167
VF Loss                      1484.4551
Policy Loss                  -1440.71
Q Predictions Mean           1432.5226
Q Predictions Std            556.21234
Q Predictions Max            2001.3766
Q Predictions Min            53.780518
V Predictions Mean           1430.9102
V Predictions Std            550.5176
V Predictions Max            1995.4677
V Predictions Min            42.332058
Log Pis Mean                 -1.5840275
Log Pis Std                  5.6572576
Log Pis Max                  21.26542
Log Pis Min                  -13.744782
Policy mu Mean               0.03880468
Policy mu Std                0.9021869
Policy mu Max                3.0333104
Policy mu Min                -2.5519207
Policy log std Mean          -0.34466067
Policy log std Std           0.14058459
Policy log std Max           0.070811674
Policy log std Min           -0.9920978
Z mean eval                  0.297248
Z variance eval              0.18168351
total_rewards                [1373.28908057 4780.58246376 4676.78905468 3158.93080122 2581.87929167
 1009.93062148 2874.23648038 1128.40001743 1418.14364347 1939.4745712 ]
total_rewards_mean           2494.165602588516
total_rewards_std            1318.1709379497906
total_rewards_max            4780.582463763764
total_rewards_min            1009.930621481219
Number of train steps total  288000
Number of env steps total    405010
Number of rollouts total     0
Train Time (s)               129.49190870503662
(Previous) Eval Time (s)     16.968549910990987
Sample Time (s)              8.038402446953114
Epoch Time (s)               154.49886106298072
Total Train Time (s)         10332.575840016827
Epoch                        71
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 23:10:45.758119 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #71 | Epoch Duration: 150.919287443161
2020-01-05 23:10:45.758232 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #71 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.5512714
Z variance train             0.3548975
KL Divergence                2.1804936
KL Loss                      0.21804936
QF Loss                      3251.918
VF Loss                      945.6448
Policy Loss                  -1330.7484
Q Predictions Mean           1325.9546
Q Predictions Std            626.6599
Q Predictions Max            1988.4807
Q Predictions Min            21.067362
V Predictions Mean           1344.0287
V Predictions Std            630.00226
V Predictions Max            1992.7434
V Predictions Min            19.015368
Log Pis Mean                 -2.4281669
Log Pis Std                  5.4889083
Log Pis Max                  23.32433
Log Pis Min                  -14.470846
Policy mu Mean               0.04004925
Policy mu Std                0.87179095
Policy mu Max                3.6933777
Policy mu Min                -3.0496356
Policy log std Mean          -0.31699422
Policy log std Std           0.13664605
Policy log std Max           0.03709331
Policy log std Min           -0.8349576
Z mean eval                  0.67701435
Z variance eval              0.24217172
total_rewards                [ 633.11659958 1492.18622507  883.56297238 3530.56473901 4657.11270502
 4845.8440423  3349.86625892 4730.42968184 1284.64683287 1098.74765507]
total_rewards_mean           2650.6077712057386
total_rewards_std            1650.540752160003
total_rewards_max            4845.844042298584
total_rewards_min            633.1165995814277
Number of train steps total  292000
Number of env steps total    410344
Number of rollouts total     0
Train Time (s)               134.08166077494388
(Previous) Eval Time (s)     13.388727621990256
Sample Time (s)              8.86412400304107
Epoch Time (s)               156.3345123999752
Total Train Time (s)         10491.561428887886
Epoch                        72
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 23:13:24.745059 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #72 | Epoch Duration: 158.98673343658447
2020-01-05 23:13:24.745192 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #72 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.52366275
Z variance train             0.18712215
KL Divergence                3.1178985
KL Loss                      0.31178984
QF Loss                      3228.0063
VF Loss                      1228.9763
Policy Loss                  -1417.9391
Q Predictions Mean           1408.5242
Q Predictions Std            576.8484
Q Predictions Max            1992.9177
Q Predictions Min            44.95313
V Predictions Mean           1402.6658
V Predictions Std            573.12274
V Predictions Max            1985.9786
V Predictions Min            30.543169
Log Pis Mean                 -1.8647902
Log Pis Std                  5.4694934
Log Pis Max                  19.894382
Log Pis Min                  -14.4023695
Policy mu Mean               0.08745116
Policy mu Std                0.8939997
Policy mu Max                3.2231286
Policy mu Min                -2.6162035
Policy log std Mean          -0.34644005
Policy log std Std           0.13705352
Policy log std Max           -0.010372192
Policy log std Min           -0.8342676
Z mean eval                  0.50070685
Z variance eval              0.20205724
total_rewards                [4961.94474967  409.66411373 4879.31477708 4792.32403485 2170.31351111
 4739.11260287 4809.86286487 4788.16832558 4729.20213207 3978.65308509]
total_rewards_mean           4025.8560196917483
total_rewards_std            1446.1484948091352
total_rewards_max            4961.944749672095
total_rewards_min            409.6641137314001
Number of train steps total  296000
Number of env steps total    415432
Number of rollouts total     0
Train Time (s)               130.5572836640058
(Previous) Eval Time (s)     16.04068010597257
Sample Time (s)              8.844066210091114
Epoch Time (s)               155.4420299800695
Total Train Time (s)         10654.149837282894
Epoch                        73
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 23:16:07.334423 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #73 | Epoch Duration: 162.5891363620758
2020-01-05 23:16:07.334553 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #73 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.58196294
Z variance train             0.26125804
KL Divergence                2.8849523
KL Loss                      0.28849524
QF Loss                      2469.874
VF Loss                      836.62616
Policy Loss                  -1400.9148
Q Predictions Mean           1389.652
Q Predictions Std            608.00665
Q Predictions Max            2015.8615
Q Predictions Min            21.29302
V Predictions Mean           1402.3843
V Predictions Std            608.8529
V Predictions Max            2025.6025
V Predictions Min            11.098693
Log Pis Mean                 -1.5880091
Log Pis Std                  5.665155
Log Pis Max                  24.754871
Log Pis Min                  -14.8532295
Policy mu Mean               0.08469439
Policy mu Std                0.90647954
Policy mu Max                2.9612274
Policy mu Min                -2.877205
Policy log std Mean          -0.34150368
Policy log std Std           0.14604461
Policy log std Max           0.017314628
Policy log std Min           -1.0253199
Z mean eval                  0.31415206
Z variance eval              0.171765
total_rewards                [1217.90439334 4032.14139301 4091.37086115 1653.37599258  837.27127209
 4494.19352928 4669.4227066  2299.70846716 1177.41989865 4523.30375713]
total_rewards_mean           2899.611227097924
total_rewards_std            1515.7351662868177
total_rewards_max            4669.422706595019
total_rewards_min            837.271272085607
Number of train steps total  300000
Number of env steps total    420615
Number of rollouts total     0
Train Time (s)               124.1247767060413
(Previous) Eval Time (s)     23.187521936022677
Sample Time (s)              8.819723916007206
Epoch Time (s)               156.13202255807118
Total Train Time (s)         10803.98146852298
Epoch                        74
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 23:18:37.168233 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #74 | Epoch Duration: 149.8335793018341
2020-01-05 23:18:37.168379 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #74 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.39668462
Z variance train             0.21807489
KL Divergence                2.5026488
KL Loss                      0.25026488
QF Loss                      2798.5598
VF Loss                      1781.0995
Policy Loss                  -1391.0922
Q Predictions Mean           1393.158
Q Predictions Std            624.6771
Q Predictions Max            2023.654
Q Predictions Min            33.571953
V Predictions Mean           1395.1924
V Predictions Std            618.2208
V Predictions Max            2036.2473
V Predictions Min            54.663696
Log Pis Mean                 -2.3111582
Log Pis Std                  5.560661
Log Pis Max                  22.80767
Log Pis Min                  -14.156765
Policy mu Mean               0.02843256
Policy mu Std                0.8876932
Policy mu Max                2.919354
Policy mu Min                -2.9688528
Policy log std Mean          -0.32751027
Policy log std Std           0.13480614
Policy log std Max           -0.027668431
Policy log std Min           -0.8778699
Z mean eval                  0.31707603
Z variance eval              0.2005543
total_rewards                [4872.13807282 3059.21929165 4727.82507722 4616.76835788 1208.497278
 4584.00878428  655.00469273 3332.95170494 4732.66601085 1928.54833721]
total_rewards_mean           3371.762760757473
total_rewards_std            1523.2930656082035
total_rewards_max            4872.138072822115
total_rewards_min            655.0046927265099
Number of train steps total  304000
Number of env steps total    425928
Number of rollouts total     0
Train Time (s)               129.95658873103093
(Previous) Eval Time (s)     16.888820551976096
Sample Time (s)              9.021501183102373
Epoch Time (s)               155.8669104661094
Total Train Time (s)         10961.947912524105
Epoch                        75
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 23:21:15.135358 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #75 | Epoch Duration: 157.96687030792236
2020-01-05 23:21:15.135468 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #75 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.2519583
Z variance train             0.1588177
KL Divergence                2.7818112
KL Loss                      0.27818114
QF Loss                      2368.909
VF Loss                      681.88464
Policy Loss                  -1273.643
Q Predictions Mean           1269.9467
Q Predictions Std            656.7174
Q Predictions Max            2009.7051
Q Predictions Min            21.243406
V Predictions Mean           1278.3672
V Predictions Std            653.8748
V Predictions Max            2002.6754
V Predictions Min            32.678116
Log Pis Mean                 -2.265267
Log Pis Std                  6.2319007
Log Pis Max                  18.700794
Log Pis Min                  -14.578911
Policy mu Mean               0.048257228
Policy mu Std                0.8886509
Policy mu Max                2.696528
Policy mu Min                -2.5999794
Policy log std Mean          -0.32579222
Policy log std Std           0.14614248
Policy log std Max           0.31610447
Policy log std Min           -1.0245533
Z mean eval                  0.22215322
Z variance eval              0.16766478
total_rewards                [4844.94122947 2943.18484864 4824.24029729 3711.28998408 3462.21089722
 2294.86890569 4800.85772581 4912.82433925 1707.23041208 4566.446338  ]
total_rewards_mean           3806.809497753299
total_rewards_std            1116.6578778229928
total_rewards_max            4912.824339246785
total_rewards_min            1707.230412081982
Number of train steps total  308000
Number of env steps total    431052
Number of rollouts total     0
Train Time (s)               129.97570213198196
(Previous) Eval Time (s)     18.98853081901325
Sample Time (s)              8.616511280939449
Epoch Time (s)               157.58074423193466
Total Train Time (s)         11122.491648813942
Epoch                        76
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 23:23:55.680418 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #76 | Epoch Duration: 160.5448567867279
2020-01-05 23:23:55.680553 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #76 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.19246954
Z variance train             0.14257134
KL Divergence                2.9072752
KL Loss                      0.29072753
QF Loss                      2464.096
VF Loss                      908.04236
Policy Loss                  -1372.6111
Q Predictions Mean           1374.9465
Q Predictions Std            632.2206
Q Predictions Max            2073.1914
Q Predictions Min            6.637001
V Predictions Mean           1377.778
V Predictions Std            628.3712
V Predictions Max            2065.674
V Predictions Min            39.3577
Log Pis Mean                 -2.0155988
Log Pis Std                  6.0849986
Log Pis Max                  25.266926
Log Pis Min                  -15.149752
Policy mu Mean               0.044564914
Policy mu Std                0.89927274
Policy mu Max                3.7366645
Policy mu Min                -3.284907
Policy log std Mean          -0.34244812
Policy log std Std           0.1452999
Policy log std Max           0.030029207
Policy log std Min           -0.99567163
Z mean eval                  0.43185377
Z variance eval              0.07795092
total_rewards                [2115.84526086 4850.84202653 3964.98339766  745.4599758  4694.41813243
 3875.04239954 1128.77541992 5033.46007224  340.89923412 1135.15002324]
total_rewards_mean           2788.487594235826
total_rewards_std            1777.5204677397462
total_rewards_max            5033.4600722373125
total_rewards_min            340.89923412352914
Number of train steps total  312000
Number of env steps total    436250
Number of rollouts total     0
Train Time (s)               141.3120066410047
(Previous) Eval Time (s)     21.952376918983646
Sample Time (s)              9.040822025039233
Epoch Time (s)               172.30520558502758
Total Train Time (s)         11286.801327071968
Epoch                        77
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 23:26:39.992475 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #77 | Epoch Duration: 164.3118007183075
2020-01-05 23:26:39.992615 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10764804
Z variance train             0.087592855
KL Divergence                3.8668027
KL Loss                      0.38668028
QF Loss                      2694.2852
VF Loss                      791.6724
Policy Loss                  -1454.1158
Q Predictions Mean           1449.108
Q Predictions Std            611.61597
Q Predictions Max            2054.0513
Q Predictions Min            44.615936
V Predictions Mean           1460.1926
V Predictions Std            617.7349
V Predictions Max            2059.34
V Predictions Min            25.638197
Log Pis Mean                 -1.6362658
Log Pis Std                  5.787875
Log Pis Max                  32.601955
Log Pis Min                  -15.389509
Policy mu Mean               0.050671097
Policy mu Std                0.90762097
Policy mu Max                3.6888502
Policy mu Min                -2.860228
Policy log std Mean          -0.3405802
Policy log std Std           0.1395269
Policy log std Max           0.2418227
Policy log std Min           -0.89217
Z mean eval                  0.06465904
Z variance eval              0.07903725
total_rewards                [4654.48256337 4725.78500837 4599.31011428 4505.50318286 1585.96588155
 4522.50231835 1707.20616807 2554.98922861 4658.56879816 4665.329044  ]
total_rewards_mean           3817.9642307625777
total_rewards_std            1247.4113938013352
total_rewards_max            4725.785008371876
total_rewards_min            1585.9658815501584
Number of train steps total  316000
Number of env steps total    441786
Number of rollouts total     0
Train Time (s)               134.5649726089905
(Previous) Eval Time (s)     13.958709854981862
Sample Time (s)              9.45461123995483
Epoch Time (s)               157.9782937039272
Total Train Time (s)         11454.24645484297
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 23:29:27.438657 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #78 | Epoch Duration: 167.44590282440186
2020-01-05 23:29:27.438811 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #78 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08978899
Z variance train             0.051118385
KL Divergence                5.111271
KL Loss                      0.5111271
QF Loss                      2898.2473
VF Loss                      1157.4634
Policy Loss                  -1387.3735
Q Predictions Mean           1391.1495
Q Predictions Std            623.56946
Q Predictions Max            2055.4978
Q Predictions Min            45.848663
V Predictions Mean           1385.8185
V Predictions Std            620.11835
V Predictions Max            2042.8071
V Predictions Min            32.314114
Log Pis Mean                 -2.3867688
Log Pis Std                  5.775813
Log Pis Max                  17.075808
Log Pis Min                  -19.183556
Policy mu Mean               0.10098492
Policy mu Std                0.88375294
Policy mu Max                2.6555119
Policy mu Min                -2.8566976
Policy log std Mean          -0.33503175
Policy log std Std           0.13896275
Policy log std Max           -0.036788955
Policy log std Min           -0.987267
Z mean eval                  0.08557152
Z variance eval              0.0989555
total_rewards                [2321.32867078 4761.44864814 2140.11522239 2826.8207141  2388.2479583
 4266.64817778 1921.78603665 2110.65159978 4748.68354307 1168.13944421]
total_rewards_mean           2865.387001520799
total_rewards_std            1204.0437591513994
total_rewards_max            4761.448648135198
total_rewards_min            1168.1394442125634
Number of train steps total  320000
Number of env steps total    446938
Number of rollouts total     0
Train Time (s)               138.56680716003757
(Previous) Eval Time (s)     23.42604788101744
Sample Time (s)              9.2871062940103
Epoch Time (s)               171.2799613350653
Total Train Time (s)         11617.738112458086
Epoch                        79
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 23:32:10.932504 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #79 | Epoch Duration: 163.49357748031616
2020-01-05 23:32:10.932709 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #79 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11670512
Z variance train             0.09207018
KL Divergence                3.7622309
KL Loss                      0.3762231
QF Loss                      3150.2793
VF Loss                      1182.0413
Policy Loss                  -1441.3506
Q Predictions Mean           1431.2786
Q Predictions Std            592.5369
Q Predictions Max            2061.4905
Q Predictions Min            25.221106
V Predictions Mean           1439.4509
V Predictions Std            594.3059
V Predictions Max            2052.9473
V Predictions Min            25.194565
Log Pis Mean                 -1.5177033
Log Pis Std                  5.5622063
Log Pis Max                  19.28931
Log Pis Min                  -15.374231
Policy mu Mean               0.051115014
Policy mu Std                0.9070232
Policy mu Max                2.4122038
Policy mu Min                -3.9912446
Policy log std Mean          -0.3375321
Policy log std Std           0.13613264
Policy log std Max           0.018090308
Policy log std Min           -0.8542219
Z mean eval                  0.15144852
Z variance eval              0.072990626
total_rewards                [1633.85995815 2854.8575047  4719.73811977 4826.62883566 4890.60223639
 4793.14758226 4900.56721181 4842.22195764 3633.20125482 2356.8851191 ]
total_rewards_mean           3945.170978030315
total_rewards_std            1177.2097688853287
total_rewards_max            4900.56721181354
total_rewards_min            1633.8599581528706
Number of train steps total  324000
Number of env steps total    452089
Number of rollouts total     0
Train Time (s)               129.7109307849896
(Previous) Eval Time (s)     15.63940389896743
Sample Time (s)              8.92822687199805
Epoch Time (s)               154.2785615559551
Total Train Time (s)         11780.106985899969
Epoch                        80
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 23:34:53.302837 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #80 | Epoch Duration: 162.36995363235474
2020-01-05 23:34:53.303017 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #80 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.21341178
Z variance train             0.08696109
KL Divergence                4.0097075
KL Loss                      0.40097076
QF Loss                      2910.7495
VF Loss                      1025.5897
Policy Loss                  -1493.2412
Q Predictions Mean           1495.6439
Q Predictions Std            598.00415
Q Predictions Max            2064.4414
Q Predictions Min            60.826355
V Predictions Mean           1495.9695
V Predictions Std            602.0985
V Predictions Max            2071.2063
V Predictions Min            24.417053
Log Pis Mean                 -1.6365342
Log Pis Std                  5.2617645
Log Pis Max                  15.919773
Log Pis Min                  -13.555823
Policy mu Mean               0.037375614
Policy mu Std                0.9020434
Policy mu Max                3.0467796
Policy mu Min                -2.7100816
Policy log std Mean          -0.3362452
Policy log std Std           0.13640891
Policy log std Max           -0.018598929
Policy log std Min           -0.92857784
Z mean eval                  0.09750334
Z variance eval              0.064633146
total_rewards                [2367.2513552  4898.04666483 2397.94589596 4974.74243306 4850.52418076
 4995.34799362 4894.54416493 3193.14765749 3444.93653956 4938.61525481]
total_rewards_mean           4095.510214021256
total_rewards_std            1060.7665681174324
total_rewards_max            4995.347993622626
total_rewards_min            2367.2513551976344
Number of train steps total  328000
Number of env steps total    457226
Number of rollouts total     0
Train Time (s)               117.8525998420082
(Previous) Eval Time (s)     23.73054871201748
Sample Time (s)              9.2500820090645
Epoch Time (s)               150.83323056309018
Total Train Time (s)         11930.33124957903
Epoch                        81
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 23:37:23.527972 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #81 | Epoch Duration: 150.22481560707092
2020-01-05 23:37:23.528082 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #81 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1760565
Z variance train             0.12530605
KL Divergence                3.1212642
KL Loss                      0.31212643
QF Loss                      2526.6362
VF Loss                      991.79333
Policy Loss                  -1364.2854
Q Predictions Mean           1354.8369
Q Predictions Std            655.04065
Q Predictions Max            2083.6497
Q Predictions Min            25.363796
V Predictions Mean           1359.2673
V Predictions Std            648.90985
V Predictions Max            2063.1929
V Predictions Min            27.311651
Log Pis Mean                 -1.7902324
Log Pis Std                  5.6735325
Log Pis Max                  21.558739
Log Pis Min                  -14.640817
Policy mu Mean               0.07434137
Policy mu Std                0.91994005
Policy mu Max                2.9752197
Policy mu Min                -3.2808611
Policy log std Mean          -0.33533695
Policy log std Std           0.14291242
Policy log std Max           0.009417638
Policy log std Min           -0.969681
Z mean eval                  0.40289348
Z variance eval              0.20321567
total_rewards                [4878.70175312 5037.92594943 5057.48921629  637.17337652 5039.81435557
 4951.9740933  4299.35554535 5011.20567358 4499.66915164 1183.57380432]
total_rewards_mean           4059.688291912458
total_rewards_std            1597.5672589802548
total_rewards_max            5057.489216286782
total_rewards_min            637.1733765197672
Number of train steps total  332000
Number of env steps total    462386
Number of rollouts total     0
Train Time (s)               121.47154082200723
(Previous) Eval Time (s)     23.121878703997936
Sample Time (s)              9.365511096140835
Epoch Time (s)               153.958930622146
Total Train Time (s)         12082.22060156014
Epoch                        82
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 23:39:55.418906 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #82 | Epoch Duration: 151.89072465896606
2020-01-05 23:39:55.419057 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #82 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.32270026
Z variance train             0.17074493
KL Divergence                2.7724762
KL Loss                      0.27724764
QF Loss                      2806.7908
VF Loss                      1058.8086
Policy Loss                  -1522.0823
Q Predictions Mean           1518.6749
Q Predictions Std            627.9723
Q Predictions Max            2096.6091
Q Predictions Min            68.63787
V Predictions Mean           1509.4236
V Predictions Std            628.9355
V Predictions Max            2093.7478
V Predictions Min            33.432762
Log Pis Mean                 -1.6094816
Log Pis Std                  6.25777
Log Pis Max                  24.588345
Log Pis Min                  -13.966358
Policy mu Mean               0.0733825
Policy mu Std                0.89878285
Policy mu Max                2.6995873
Policy mu Min                -2.7781072
Policy log std Mean          -0.34156743
Policy log std Std           0.13636868
Policy log std Max           -0.04247576
Policy log std Min           -0.91893184
Z mean eval                  0.3893727
Z variance eval              0.1588829
total_rewards                [2084.04289731 2818.31278907 5080.72894803 4474.06236498 1529.031963
 4941.92661583 3565.34214899 4998.24698981 2867.56895126 5039.9804295 ]
total_rewards_mean           3739.9244097790142
total_rewards_std            1277.7279055423537
total_rewards_max            5080.728948034828
total_rewards_min            1529.0319630032056
Number of train steps total  336000
Number of env steps total    467386
Number of rollouts total     0
Train Time (s)               128.49251095898217
(Previous) Eval Time (s)     21.05340985598741
Sample Time (s)              8.418341472977772
Epoch Time (s)               157.96426228794735
Total Train Time (s)         12240.89089232427
Epoch                        83
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 23:42:34.090238 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #83 | Epoch Duration: 158.67105746269226
2020-01-05 23:42:34.090383 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.5370062
Z variance train             0.21123347
KL Divergence                2.8921695
KL Loss                      0.28921697
QF Loss                      2961.1384
VF Loss                      1261.4574
Policy Loss                  -1475.834
Q Predictions Mean           1466.7275
Q Predictions Std            653.33856
Q Predictions Max            2123.4165
Q Predictions Min            59.93932
V Predictions Mean           1465.7396
V Predictions Std            650.2574
V Predictions Max            2108.679
V Predictions Min            46.14844
Log Pis Mean                 -1.5270392
Log Pis Std                  5.912722
Log Pis Max                  21.773693
Log Pis Min                  -17.802197
Policy mu Mean               0.10955864
Policy mu Std                0.9117027
Policy mu Max                3.043486
Policy mu Min                -3.1325686
Policy log std Mean          -0.33612424
Policy log std Std           0.14491925
Policy log std Max           0.0035576671
Policy log std Min           -0.92481256
Z mean eval                  0.2366635
Z variance eval              0.11318292
total_rewards                [1109.46185855 4692.22785165 4048.99656958 1153.64831071 3377.43325775
 4803.4183826  1644.63191968 4623.86125547  413.27597865 4355.12759114]
total_rewards_mean           3022.2082975773765
total_rewards_std            1653.4351977856397
total_rewards_max            4803.418382598241
total_rewards_min            413.275978645058
Number of train steps total  340000
Number of env steps total    472554
Number of rollouts total     0
Train Time (s)               125.20319464203203
(Previous) Eval Time (s)     21.759946333011612
Sample Time (s)              8.882487557013519
Epoch Time (s)               155.84562853205716
Total Train Time (s)         12392.160645428346
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 23:45:05.361992 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #84 | Epoch Duration: 151.27150559425354
2020-01-05 23:45:05.362148 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #84 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.26683396
Z variance train             0.121204674
KL Divergence                3.3906472
KL Loss                      0.33906472
QF Loss                      2661.6123
VF Loss                      640.0488
Policy Loss                  -1513.9039
Q Predictions Mean           1503.944
Q Predictions Std            601.7862
Q Predictions Max            2112.2603
Q Predictions Min            27.83797
V Predictions Mean           1516.715
V Predictions Std            607.1932
V Predictions Max            2114.0679
V Predictions Min            29.709314
Log Pis Mean                 -1.8087462
Log Pis Std                  5.8494153
Log Pis Max                  27.580624
Log Pis Min                  -18.56757
Policy mu Mean               0.029940292
Policy mu Std                0.90479636
Policy mu Max                3.035253
Policy mu Min                -4.7141232
Policy log std Mean          -0.3374057
Policy log std Std           0.13594125
Policy log std Max           0.06420425
Policy log std Min           -1.0301211
Z mean eval                  0.18928912
Z variance eval              0.094083
total_rewards                [4891.71056396 4928.57929877 4681.41973922 3913.23764407 4828.69331032
  422.82540407 4917.14743292 4836.84427361 2905.11309892 4871.20938351]
total_rewards_mean           4119.678014936848
total_rewards_std            1377.2509248196882
total_rewards_max            4928.579298770357
total_rewards_min            422.8254040713681
Number of train steps total  344000
Number of env steps total    477898
Number of rollouts total     0
Train Time (s)               136.0072037380305
(Previous) Eval Time (s)     17.18554929899983
Sample Time (s)              10.079436827043537
Epoch Time (s)               163.27218986407388
Total Train Time (s)         12560.951479585376
Epoch                        85
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 23:47:54.154039 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #85 | Epoch Duration: 168.79178190231323
2020-01-05 23:47:54.154154 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #85 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.13766962
Z variance train             0.073197514
KL Divergence                4.3231955
KL Loss                      0.43231955
QF Loss                      2130.8062
VF Loss                      1425.0137
Policy Loss                  -1526.4958
Q Predictions Mean           1513.6841
Q Predictions Std            651.4522
Q Predictions Max            2096.702
Q Predictions Min            42.92372
V Predictions Mean           1512.8489
V Predictions Std            639.0771
V Predictions Max            2084.2498
V Predictions Min            70.93095
Log Pis Mean                 -2.120205
Log Pis Std                  5.357686
Log Pis Max                  16.780771
Log Pis Min                  -16.422783
Policy mu Mean               0.10840307
Policy mu Std                0.8886611
Policy mu Max                2.597232
Policy mu Min                -2.897609
Policy log std Mean          -0.33741236
Policy log std Std           0.13875572
Policy log std Max           -0.024493992
Policy log std Min           -0.9660405
Z mean eval                  0.15525766
Z variance eval              0.07126935
total_rewards                [4810.7783567  4938.60301959 4906.37946687 4958.82026332 4852.34458673
 4774.71708711 4892.7954399  1188.55385122 4715.30661751 4921.50892761]
total_rewards_mean           4495.980761654797
total_rewards_std            1104.9009599668375
total_rewards_max            4958.8202633206865
total_rewards_min            1188.553851220289
Number of train steps total  348000
Number of env steps total    483235
Number of rollouts total     0
Train Time (s)               129.22242771100719
(Previous) Eval Time (s)     22.70489414205076
Sample Time (s)              9.196339540067129
Epoch Time (s)               161.12366139312508
Total Train Time (s)         12724.394182780408
Epoch                        86
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 23:50:37.599153 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #86 | Epoch Duration: 163.44488787651062
2020-01-05 23:50:37.599351 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #86 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.13214968
Z variance train             0.07219031
KL Divergence                4.338004
KL Loss                      0.43380043
QF Loss                      2874.3843
VF Loss                      1715.0698
Policy Loss                  -1530.9943
Q Predictions Mean           1530.1499
Q Predictions Std            584.5533
Q Predictions Max            2095.1396
Q Predictions Min            41.244987
V Predictions Mean           1543.9614
V Predictions Std            577.7269
V Predictions Max            2092.6284
V Predictions Min            36.404068
Log Pis Mean                 -0.6324192
Log Pis Std                  6.3765697
Log Pis Max                  33.219795
Log Pis Min                  -13.792826
Policy mu Mean               0.1067913
Policy mu Std                0.94411266
Policy mu Max                2.9884188
Policy mu Min                -2.7386894
Policy log std Mean          -0.355458
Policy log std Std           0.14600705
Policy log std Max           0.015996903
Policy log std Min           -1.0491968
Z mean eval                  0.10995606
Z variance eval              0.105229
total_rewards                [4905.17801626 4975.51699827 3519.41470307 4855.15730128 5048.19842567
 2416.41614299 4753.2473888  2201.54219569 4924.49449955 4989.92501707]
total_rewards_mean           4258.909068864193
total_rewards_std            1063.2887343820503
total_rewards_max            5048.198425668191
total_rewards_min            2201.5421956948717
Number of train steps total  352000
Number of env steps total    488593
Number of rollouts total     0
Train Time (s)               132.90703355195
(Previous) Eval Time (s)     25.025864840019494
Sample Time (s)              9.271829999051988
Epoch Time (s)               167.2047283910215
Total Train Time (s)         12890.655823558336
Epoch                        87
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 23:53:23.862528 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #87 | Epoch Duration: 166.26300692558289
2020-01-05 23:53:23.862743 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.109646216
Z variance train             0.08468853
KL Divergence                3.9566395
KL Loss                      0.39566395
QF Loss                      2580.7397
VF Loss                      1420.5345
Policy Loss                  -1553.219
Q Predictions Mean           1559.7592
Q Predictions Std            599.0567
Q Predictions Max            2136.5552
Q Predictions Min            11.242273
V Predictions Mean           1576.2214
V Predictions Std            596.7588
V Predictions Max            2128.151
V Predictions Min            60.83789
Log Pis Mean                 -1.5836391
Log Pis Std                  5.7961664
Log Pis Max                  13.954876
Log Pis Min                  -16.59511
Policy mu Mean               0.059338387
Policy mu Std                0.9142645
Policy mu Max                2.8950486
Policy mu Min                -2.7483938
Policy log std Mean          -0.34572452
Policy log std Std           0.13690053
Policy log std Max           -0.02055046
Policy log std Min           -0.98293877
Z mean eval                  0.13292968
Z variance eval              0.089805424
total_rewards                [ 414.45676505 1889.37812202 5021.41416346 5100.77984883 4973.45727393
 3953.32959767 4991.18385952 4880.44056688 2112.15244634 5041.68564235]
total_rewards_mean           3837.82782860522
total_rewards_std            1632.7689863478931
total_rewards_max            5100.779848830503
total_rewards_min            414.45676504758336
Number of train steps total  356000
Number of env steps total    493669
Number of rollouts total     0
Train Time (s)               136.2910928799538
(Previous) Eval Time (s)     24.083872213959694
Sample Time (s)              9.000503672170453
Epoch Time (s)               169.37546876608394
Total Train Time (s)         13058.076910030446
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 23:56:11.285314 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #88 | Epoch Duration: 167.42241764068604
2020-01-05 23:56:11.285502 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #88 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.13396713
Z variance train             0.07594999
KL Divergence                4.219924
KL Loss                      0.4219924
QF Loss                      2297.2886
VF Loss                      999.38403
Policy Loss                  -1506.5742
Q Predictions Mean           1501.2888
Q Predictions Std            623.29694
Q Predictions Max            2135.2446
Q Predictions Min            39.672646
V Predictions Mean           1504.0928
V Predictions Std            624.54297
V Predictions Max            2128.3914
V Predictions Min            47.91206
Log Pis Mean                 -1.4432735
Log Pis Std                  6.2693925
Log Pis Max                  18.45512
Log Pis Min                  -13.487984
Policy mu Mean               0.11652756
Policy mu Std                0.9242268
Policy mu Max                2.625941
Policy mu Min                -2.7438388
Policy log std Mean          -0.33128193
Policy log std Std           0.13818158
Policy log std Max           0.2726671
Policy log std Min           -0.9015696
Z mean eval                  0.13297652
Z variance eval              0.10206373
total_rewards                [3548.74546062 3708.36223899 4636.71587703 1546.31990987 2285.19787
 3969.78100816 4812.02548728 1387.27399285 4849.32263736 4942.64090856]
total_rewards_mean           3568.6385390729133
total_rewards_std            1299.6542684009996
total_rewards_max            4942.6409085609885
total_rewards_min            1387.2739928539927
Number of train steps total  360000
Number of env steps total    499123
Number of rollouts total     0
Train Time (s)               128.73888813401572
(Previous) Eval Time (s)     22.13056709500961
Sample Time (s)              9.147349853999913
Epoch Time (s)               160.01680508302525
Total Train Time (s)         13215.257305601495
Epoch                        89
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------
2020-01-05 23:58:48.466363 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #89 | Epoch Duration: 157.1807279586792
2020-01-05 23:58:48.466476 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #89 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.160205
Z variance train             0.10698521
KL Divergence                3.473219
KL Loss                      0.3473219
QF Loss                      2435.5408
VF Loss                      1087.4917
Policy Loss                  -1533.7461
Q Predictions Mean           1530.072
Q Predictions Std            627.24414
Q Predictions Max            2141.8413
Q Predictions Min            13.782737
V Predictions Mean           1536.221
V Predictions Std            617.9075
V Predictions Max            2155.2825
V Predictions Min            52.188812
Log Pis Mean                 -1.9890494
Log Pis Std                  5.6006627
Log Pis Max                  19.159199
Log Pis Min                  -14.319383
Policy mu Mean               0.085184485
Policy mu Std                0.90389
Policy mu Max                3.2233253
Policy mu Min                -3.3172426
Policy log std Mean          -0.3337501
Policy log std Std           0.1450728
Policy log std Max           0.011457473
Policy log std Min           -1.0065218
Z mean eval                  0.09826914
Z variance eval              0.03565701
total_rewards                [1174.04521037 1880.1208431  1865.46763171 1697.28443186 4990.06405645
 4859.40569129 5058.4572963  4942.32070719 4857.60797286 4949.84061914]
total_rewards_mean           3627.461446027264
total_rewards_std            1622.2077415738825
total_rewards_max            5058.45729630016
total_rewards_min            1174.045210369999
Number of train steps total  364000
Number of env steps total    504302
Number of rollouts total     0
Train Time (s)               132.81236064300174
(Previous) Eval Time (s)     19.29424476699205
Sample Time (s)              9.114551653037779
Epoch Time (s)               161.22115706303157
Total Train Time (s)         13378.253943052609
Epoch                        90
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 00:01:31.464946 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #90 | Epoch Duration: 162.99837493896484
2020-01-06 00:01:31.465107 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #90 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07000397
Z variance train             0.04918151
KL Divergence                5.189758
KL Loss                      0.5189758
QF Loss                      2446.368
VF Loss                      1320.2372
Policy Loss                  -1521.1814
Q Predictions Mean           1516.7524
Q Predictions Std            630.4301
Q Predictions Max            2125.9033
Q Predictions Min            25.695192
V Predictions Mean           1541.43
V Predictions Std            633.3581
V Predictions Max            2146.775
V Predictions Min            58.417763
Log Pis Mean                 -1.6114106
Log Pis Std                  5.900604
Log Pis Max                  18.37721
Log Pis Min                  -14.110511
Policy mu Mean               0.11803122
Policy mu Std                0.89143145
Policy mu Max                3.3512685
Policy mu Min                -3.0786686
Policy log std Mean          -0.34233734
Policy log std Std           0.14165881
Policy log std Max           -0.038511008
Policy log std Min           -0.84668434
Z mean eval                  0.10200862
Z variance eval              0.015837986
total_rewards                [4012.68012201 4956.95480517 5049.17188681 4972.31893795 5152.03165252
 3385.74995797 4959.083044   5031.0133961  5112.80332238 5022.63966112]
total_rewards_mean           4765.444678603895
total_rewards_std            554.4786336152649
total_rewards_max            5152.031652523552
total_rewards_min            3385.7499579702194
Number of train steps total  368000
Number of env steps total    509434
Number of rollouts total     0
Train Time (s)               132.61131127201952
(Previous) Eval Time (s)     21.071197196026333
Sample Time (s)              8.751895319961477
Epoch Time (s)               162.43440378800733
Total Train Time (s)         13545.5835924485
Epoch                        91
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 00:04:18.795424 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #91 | Epoch Duration: 167.3302047252655
2020-01-06 00:04:18.795540 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #91 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.118314825
Z variance train             0.016087253
KL Divergence                7.9235463
KL Loss                      0.79235464
QF Loss                      2859.5884
VF Loss                      966.66583
Policy Loss                  -1611.405
Q Predictions Mean           1609.0095
Q Predictions Std            621.2673
Q Predictions Max            2162.164
Q Predictions Min            41.180336
V Predictions Mean           1616.5042
V Predictions Std            618.02094
V Predictions Max            2165.5854
V Predictions Min            33.68334
Log Pis Mean                 -1.4164118
Log Pis Std                  5.826653
Log Pis Max                  24.83009
Log Pis Min                  -14.295768
Policy mu Mean               0.11868283
Policy mu Std                0.9116425
Policy mu Max                2.8219674
Policy mu Min                -2.737289
Policy log std Mean          -0.35127163
Policy log std Std           0.13098262
Policy log std Max           -0.034304768
Policy log std Min           -0.8857982
Z mean eval                  0.114258006
Z variance eval              0.012227547
total_rewards                [2755.44920459 4884.97260924 4971.45529272 3649.65364645 4878.10487694
 4905.26410336 5043.6597862  5062.03499479 5034.6106686  4851.882127  ]
total_rewards_mean           4603.708730987846
total_rewards_std            731.96629574461
total_rewards_max            5062.034994791807
total_rewards_min            2755.4492045880597
Number of train steps total  372000
Number of env steps total    514792
Number of rollouts total     0
Train Time (s)               123.39794562704628
(Previous) Eval Time (s)     25.96674563799752
Sample Time (s)              9.597331397992093
Epoch Time (s)               158.9620226630359
Total Train Time (s)         13704.64910428552
Epoch                        92
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 00:06:57.863014 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #92 | Epoch Duration: 159.0673828125
2020-01-06 00:06:57.863137 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #92 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1030518
Z variance train             0.01700489
KL Divergence                7.7769446
KL Loss                      0.77769446
QF Loss                      2632.54
VF Loss                      737.87335
Policy Loss                  -1557.4575
Q Predictions Mean           1558.3838
Q Predictions Std            630.86755
Q Predictions Max            2160.693
Q Predictions Min            24.247955
V Predictions Mean           1552.3274
V Predictions Std            625.0117
V Predictions Max            2156.7378
V Predictions Min            49.192482
Log Pis Mean                 -1.7058587
Log Pis Std                  5.8329573
Log Pis Max                  19.879269
Log Pis Min                  -11.830095
Policy mu Mean               0.07316919
Policy mu Std                0.90235335
Policy mu Max                3.235745
Policy mu Min                -2.8981545
Policy log std Mean          -0.33185214
Policy log std Std           0.13671894
Policy log std Max           -0.006240353
Policy log std Min           -0.9932219
Z mean eval                  0.061693836
Z variance eval              0.03614583
total_rewards                [3808.19911299 5098.08924969 4872.10893514 4772.35239817 5138.00290114
 5049.84691982 5046.52890345 5041.0647842  5083.98257785 4941.82555262]
total_rewards_mean           4885.20013350885
total_rewards_std            374.4620712438487
total_rewards_max            5138.002901143994
total_rewards_min            3808.1991129949884
Number of train steps total  376000
Number of env steps total    519792
Number of rollouts total     0
Train Time (s)               130.67167531797895
(Previous) Eval Time (s)     26.071841940982267
Sample Time (s)              9.014262345910538
Epoch Time (s)               165.75777960487176
Total Train Time (s)         13870.126133247337
Epoch                        93
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 00:09:43.341686 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #93 | Epoch Duration: 165.47842979431152
2020-01-06 00:09:43.341885 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.12419672
Z variance train             0.02483471
KL Divergence                6.8685455
KL Loss                      0.68685454
QF Loss                      1973.2034
VF Loss                      799.61835
Policy Loss                  -1599.0457
Q Predictions Mean           1604.0261
Q Predictions Std            626.03656
Q Predictions Max            2160.3767
Q Predictions Min            32.308464
V Predictions Mean           1599.3037
V Predictions Std            625.8385
V Predictions Max            2157.7783
V Predictions Min            -17.088099
Log Pis Mean                 -2.5030003
Log Pis Std                  5.0914426
Log Pis Max                  13.588385
Log Pis Min                  -14.426561
Policy mu Mean               0.07103508
Policy mu Std                0.8765618
Policy mu Max                3.0570886
Policy mu Min                -3.0165503
Policy log std Mean          -0.3283629
Policy log std Std           0.12667665
Policy log std Max           0.0881964
Policy log std Min           -0.83444476
Z mean eval                  0.15110272
Z variance eval              0.0407506
total_rewards                [5033.12689822 4988.36691618 2937.52097946 4947.77648597 2520.67596194
 4998.46874275 3315.13934574 1211.17931923 2628.89327299 3623.86143414]
total_rewards_mean           3620.5009356631467
total_rewards_std            1268.2458401109495
total_rewards_max            5033.126898218597
total_rewards_min            1211.179319234645
Number of train steps total  380000
Number of env steps total    524792
Number of rollouts total     0
Train Time (s)               130.8004827820114
(Previous) Eval Time (s)     25.792218138987664
Sample Time (s)              8.138584440981504
Epoch Time (s)               164.73128536198055
Total Train Time (s)         14028.164635617344
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 00:12:21.381733 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #94 | Epoch Duration: 158.03972840309143
2020-01-06 00:12:21.381866 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #94 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.12124586
Z variance train             0.030077716
KL Divergence                6.402834
KL Loss                      0.6402834
QF Loss                      2698.1255
VF Loss                      943.67957
Policy Loss                  -1594.0635
Q Predictions Mean           1601.7202
Q Predictions Std            635.18054
Q Predictions Max            2174.398
Q Predictions Min            56.523964
V Predictions Mean           1592.315
V Predictions Std            640.6162
V Predictions Max            2169.5925
V Predictions Min            64.46083
Log Pis Mean                 -2.0822196
Log Pis Std                  5.358806
Log Pis Max                  21.425457
Log Pis Min                  -13.788713
Policy mu Mean               0.086592376
Policy mu Std                0.89087254
Policy mu Max                3.4764533
Policy mu Min                -2.6113138
Policy log std Mean          -0.33221307
Policy log std Std           0.13421184
Policy log std Max           0.016118273
Policy log std Min           -0.9318042
Z mean eval                  0.14881553
Z variance eval              0.046065655
total_rewards                [5125.05985832 3939.02334303 1308.44130912 4967.62667047 3661.74834869
 3455.57870151 1626.92818216 4892.4279075  4677.46923659 4997.68972698]
total_rewards_mean           3865.199328438038
total_rewards_std            1325.2022750225672
total_rewards_max            5125.0598583236815
total_rewards_min            1308.4413091198207
Number of train steps total  384000
Number of env steps total    529972
Number of rollouts total     0
Train Time (s)               118.76160501496634
(Previous) Eval Time (s)     19.100412258994766
Sample Time (s)              9.419958121958189
Epoch Time (s)               147.2819753959193
Total Train Time (s)         14176.821547342348
Epoch                        95
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 00:14:50.039873 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #95 | Epoch Duration: 148.65789365768433
2020-01-06 00:14:50.040027 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #95 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11243291
Z variance train             0.04508358
KL Divergence                5.4233594
KL Loss                      0.5423359
QF Loss                      2495.397
VF Loss                      1120.1128
Policy Loss                  -1614.9447
Q Predictions Mean           1603.8762
Q Predictions Std            629.1011
Q Predictions Max            2162.6318
Q Predictions Min            62.61052
V Predictions Mean           1616.6967
V Predictions Std            630.25726
V Predictions Max            2172.5947
V Predictions Min            51.24024
Log Pis Mean                 -1.8860273
Log Pis Std                  5.5964704
Log Pis Max                  17.181854
Log Pis Min                  -13.055471
Policy mu Mean               0.12324681
Policy mu Std                0.89063215
Policy mu Max                2.7473524
Policy mu Min                -2.6837406
Policy log std Mean          -0.32481968
Policy log std Std           0.13242216
Policy log std Max           -0.029875547
Policy log std Min           -1.0238221
Z mean eval                  0.1591386
Z variance eval              0.04957985
total_rewards                [3297.06397332 5020.36049463 5020.72307926 5170.7707978  1432.89566075
 2612.01811448 4970.9277724  5050.3650851  5017.90741155 4991.78481223]
total_rewards_mean           4258.481720153434
total_rewards_std            1259.4429336895937
total_rewards_max            5170.77079780248
total_rewards_min            1432.8956607482428
Number of train steps total  388000
Number of env steps total    535156
Number of rollouts total     0
Train Time (s)               122.00100243196357
(Previous) Eval Time (s)     20.476074015023187
Sample Time (s)              8.888010762922931
Epoch Time (s)               151.3650872099097
Total Train Time (s)         14329.108978511242
Epoch                        96
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 00:17:22.329345 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #96 | Epoch Duration: 152.2891891002655
2020-01-06 00:17:22.329538 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.19198681
Z variance train             0.060204186
KL Divergence                4.821791
KL Loss                      0.48217914
QF Loss                      3384.7644
VF Loss                      1185.4059
Policy Loss                  -1610.5654
Q Predictions Mean           1606.2651
Q Predictions Std            637.4775
Q Predictions Max            2186.0095
Q Predictions Min            33.150887
V Predictions Mean           1608.115
V Predictions Std            632.8416
V Predictions Max            2180.6958
V Predictions Min            54.98602
Log Pis Mean                 -1.1492798
Log Pis Std                  5.920019
Log Pis Max                  16.956123
Log Pis Min                  -13.927288
Policy mu Mean               0.09089678
Policy mu Std                0.9127422
Policy mu Max                2.9378946
Policy mu Min                -2.872316
Policy log std Mean          -0.3418368
Policy log std Std           0.13725087
Policy log std Max           0.25174317
Policy log std Min           -0.8857962
Z mean eval                  0.12363293
Z variance eval              0.02519108
total_rewards                [5043.39188134 5083.7125389  3610.4096551  5066.4574242  5089.46836885
 5035.94105083 5012.25988752 4927.0940922  5037.19201824 4959.33318796]
total_rewards_mean           4886.526010516221
total_rewards_std            428.17100062040276
total_rewards_max            5089.468368849203
total_rewards_min            3610.4096551020507
Number of train steps total  392000
Number of env steps total    540156
Number of rollouts total     0
Train Time (s)               116.69840098399436
(Previous) Eval Time (s)     21.399910418025684
Sample Time (s)              8.687557014985941
Epoch Time (s)               146.785868417006
Total Train Time (s)         14481.058953320142
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 00:19:54.280955 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #97 | Epoch Duration: 151.95126724243164
2020-01-06 00:19:54.281156 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #97 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.119592845
Z variance train             0.024784198
KL Divergence                6.863039
KL Loss                      0.6863039
QF Loss                      2661.6833
VF Loss                      1593.1248
Policy Loss                  -1649.9553
Q Predictions Mean           1636.1536
Q Predictions Std            603.9051
Q Predictions Max            2173.8943
Q Predictions Min            180.7768
V Predictions Mean           1668.9961
V Predictions Std            606.6893
V Predictions Max            2216.3203
V Predictions Min            193.15201
Log Pis Mean                 -1.6772044
Log Pis Std                  6.51522
Log Pis Max                  34.23271
Log Pis Min                  -14.462904
Policy mu Mean               0.063246034
Policy mu Std                0.91797763
Policy mu Max                4.2796545
Policy mu Min                -3.2587001
Policy log std Mean          -0.35291958
Policy log std Std           0.15151195
Policy log std Max           -0.021464206
Policy log std Min           -1.3435361
Z mean eval                  0.10158285
Z variance eval              0.032299783
total_rewards                [3889.7875055   400.85851874 5061.05203741 2891.57589705 2166.9460145
 5002.6631762  5136.64990264 5050.28702025 5062.0763505  5087.59651903]
total_rewards_mean           3974.9492941819967
total_rewards_std            1561.5855654696134
total_rewards_max            5136.649902643619
total_rewards_min            400.85851873832587
Number of train steps total  396000
Number of env steps total    545156
Number of rollouts total     0
Train Time (s)               128.58356070599984
(Previous) Eval Time (s)     26.565065296017565
Sample Time (s)              8.487699097022414
Epoch Time (s)               163.63632509903982
Total Train Time (s)         14640.954569664143
Epoch                        98
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 00:22:34.178020 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #98 | Epoch Duration: 159.89673686027527
2020-01-06 00:22:34.178131 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #98 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.049782194
Z variance train             0.033379007
KL Divergence                6.1002812
KL Loss                      0.61002815
QF Loss                      3562.4893
VF Loss                      781.8081
Policy Loss                  -1619.1825
Q Predictions Mean           1622.7764
Q Predictions Std            641.62683
Q Predictions Max            2223.0505
Q Predictions Min            36.815117
V Predictions Mean           1617.012
V Predictions Std            637.84546
V Predictions Max            2195.959
V Predictions Min            45.66042
Log Pis Mean                 -1.4690666
Log Pis Std                  5.8608713
Log Pis Max                  21.821974
Log Pis Min                  -14.451558
Policy mu Mean               0.0786399
Policy mu Std                0.912094
Policy mu Max                2.949744
Policy mu Min                -2.8097553
Policy log std Mean          -0.34626663
Policy log std Std           0.14351636
Policy log std Max           -0.0045337826
Policy log std Min           -1.029069
Z mean eval                  0.059101444
Z variance eval              0.019979527
total_rewards                [3170.19830127 4926.47131719 4991.20173615 5020.63784125 5044.5096687
 4111.52809334  910.94960711 5021.2098852   642.37246508 4948.737717  ]
total_rewards_mean           3878.7816632285385
total_rewards_std            1651.8616902097674
total_rewards_max            5044.509668699205
total_rewards_min            642.3724650779402
Number of train steps total  400000
Number of env steps total    550473
Number of rollouts total     0
Train Time (s)               137.7974639729946
(Previous) Eval Time (s)     22.825231182971038
Sample Time (s)              9.243026625888888
Epoch Time (s)               169.86572178185452
Total Train Time (s)         14809.40686353197
Epoch                        99
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 00:25:22.631335 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #99 | Epoch Duration: 168.45311570167542
2020-01-06 00:25:22.631506 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #99 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09818776
Z variance train             0.023857374
KL Divergence                6.9384136
KL Loss                      0.6938414
QF Loss                      2272.9536
VF Loss                      1096.5094
Policy Loss                  -1643.217
Q Predictions Mean           1643.9626
Q Predictions Std            620.2367
Q Predictions Max            2202.9058
Q Predictions Min            3.3692071
V Predictions Mean           1650.3254
V Predictions Std            621.42664
V Predictions Max            2209.485
V Predictions Min            33.520782
Log Pis Mean                 -1.9099879
Log Pis Std                  5.9877753
Log Pis Max                  21.037823
Log Pis Min                  -13.997822
Policy mu Mean               0.0929513
Policy mu Std                0.91411847
Policy mu Max                2.9254513
Policy mu Min                -2.7543452
Policy log std Mean          -0.33858117
Policy log std Std           0.14171612
Policy log std Max           0.085599884
Policy log std Min           -0.9179633
Z mean eval                  0.113731906
Z variance eval              0.02174522
total_rewards                [1408.18134019 4957.17002648 4941.30419787 4916.30446085 4265.0985472
 4878.80048314 5057.60456741 1994.04221857 1067.25379309 5025.61978138]
total_rewards_mean           3851.1379416186564
total_rewards_std            1574.0274641645601
total_rewards_max            5057.6045674124325
total_rewards_min            1067.253793089539
Number of train steps total  404000
Number of env steps total    555864
Number of rollouts total     0
Train Time (s)               136.86866778502008
(Previous) Eval Time (s)     21.412382566952147
Sample Time (s)              9.389913048944436
Epoch Time (s)               167.67096340091666
Total Train Time (s)         14977.403440861963
Epoch                        100
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 00:28:10.629384 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #100 | Epoch Duration: 167.9977662563324
2020-01-06 00:28:10.629511 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #100 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14049995
Z variance train             0.028949995
KL Divergence                6.505033
KL Loss                      0.65050334
QF Loss                      3104.1653
VF Loss                      1014.1044
Policy Loss                  -1642.9061
Q Predictions Mean           1637.581
Q Predictions Std            637.4087
Q Predictions Max            2213.4731
Q Predictions Min            22.34863
V Predictions Mean           1654.0208
V Predictions Std            632.2499
V Predictions Max            2222.4612
V Predictions Min            22.125576
Log Pis Mean                 -0.114268735
Log Pis Std                  6.8825755
Log Pis Max                  29.49106
Log Pis Min                  -12.870498
Policy mu Mean               0.058659494
Policy mu Std                0.9488866
Policy mu Max                3.0591247
Policy mu Min                -3.0672455
Policy log std Mean          -0.35594958
Policy log std Std           0.1461951
Policy log std Max           0.034852475
Policy log std Min           -1.1238762
Z mean eval                  0.12538962
Z variance eval              0.02312458
total_rewards                [5040.64284071 5056.43087457 5067.71180774 1258.37716992 5100.14422842
 5063.20810547 5032.88336258 5048.17301151 5042.91927272 5105.34904947]
total_rewards_mean           4681.583972311017
total_rewards_std            1141.2993244793513
total_rewards_max            5105.349049474124
total_rewards_min            1258.3771699170447
Number of train steps total  408000
Number of env steps total    560964
Number of rollouts total     0
Train Time (s)               124.958256714046
(Previous) Eval Time (s)     21.738930994004477
Sample Time (s)              8.825006847968325
Epoch Time (s)               155.5221945560188
Total Train Time (s)         15136.523344858957
Epoch                        101
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 00:30:49.751339 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #101 | Epoch Duration: 159.12172746658325
2020-01-06 00:30:49.751476 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #101 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10860944
Z variance train             0.021754911
KL Divergence                7.1763115
KL Loss                      0.71763116
QF Loss                      2755.8687
VF Loss                      1009.29083
Policy Loss                  -1631.7625
Q Predictions Mean           1633.6315
Q Predictions Std            672.8448
Q Predictions Max            2224.2095
Q Predictions Min            27.234549
V Predictions Mean           1622.5887
V Predictions Std            667.2724
V Predictions Max            2202.4229
V Predictions Min            49.81913
Log Pis Mean                 -1.8453274
Log Pis Std                  5.9451838
Log Pis Max                  17.45161
Log Pis Min                  -16.05342
Policy mu Mean               0.094026804
Policy mu Std                0.8832248
Policy mu Max                2.475256
Policy mu Min                -3.2485666
Policy log std Mean          -0.33609766
Policy log std Std           0.14175133
Policy log std Max           0.008244514
Policy log std Min           -1.1069036
Z mean eval                  0.08845451
Z variance eval              0.017494267
total_rewards                [1382.98242594 5094.33766304 3612.60487812 5045.02614741 5205.27505104
 5113.80793874 5062.62496333 1300.24141562 4927.86664893 5137.28888432]
total_rewards_mean           4188.205601649138
total_rewards_std            1489.9591897852454
total_rewards_max            5205.275051044627
total_rewards_min            1300.2414156185018
Number of train steps total  412000
Number of env steps total    566066
Number of rollouts total     0
Train Time (s)               127.9606070269947
(Previous) Eval Time (s)     25.33819029002916
Sample Time (s)              8.957937422965188
Epoch Time (s)               162.25673473998904
Total Train Time (s)         15295.485798596055
Epoch                        102
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 00:33:28.715989 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #102 | Epoch Duration: 158.9643952846527
2020-01-06 00:33:28.716152 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #102 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08745909
Z variance train             0.01814379
KL Divergence                7.606457
KL Loss                      0.76064575
QF Loss                      2668.4834
VF Loss                      909.1643
Policy Loss                  -1680.8613
Q Predictions Mean           1667.467
Q Predictions Std            613.1779
Q Predictions Max            2181.0583
Q Predictions Min            95.307915
V Predictions Mean           1673.3424
V Predictions Std            609.99976
V Predictions Max            2187.3188
V Predictions Min            73.879684
Log Pis Mean                 -1.7975339
Log Pis Std                  5.788278
Log Pis Max                  28.977776
Log Pis Min                  -13.940486
Policy mu Mean               0.08897042
Policy mu Std                0.9114549
Policy mu Max                3.38362
Policy mu Min                -3.1062684
Policy log std Mean          -0.33345404
Policy log std Std           0.14123704
Policy log std Max           0.09539811
Policy log std Min           -1.0646377
Z mean eval                  0.15304366
Z variance eval              0.04011227
total_rewards                [1312.40659594 4461.48052758 4923.93834059 1469.37341141 2214.32586115
 5070.9140583  4916.28174205 5006.58254243 4961.12595294 2417.26830338]
total_rewards_mean           3675.3697335763127
total_rewards_std            1525.0272092358598
total_rewards_max            5070.914058301418
total_rewards_min            1312.406595935589
Number of train steps total  416000
Number of env steps total    571320
Number of rollouts total     0
Train Time (s)               127.21572262898553
(Previous) Eval Time (s)     22.045581351965666
Sample Time (s)              8.918074639048427
Epoch Time (s)               158.17937861999962
Total Train Time (s)         15452.63270159805
Epoch                        103
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 00:36:05.864190 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #103 | Epoch Duration: 157.14791870117188
2020-01-06 00:36:05.864326 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #103 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.15172483
Z variance train             0.037632447
KL Divergence                5.8893814
KL Loss                      0.5889382
QF Loss                      2678.6838
VF Loss                      1333.7471
Policy Loss                  -1661.8867
Q Predictions Mean           1664.9884
Q Predictions Std            645.6613
Q Predictions Max            2210.7185
Q Predictions Min            30.645784
V Predictions Mean           1670.9976
V Predictions Std            640.5929
V Predictions Max            2205.9973
V Predictions Min            87.58667
Log Pis Mean                 -2.0411887
Log Pis Std                  5.837556
Log Pis Max                  18.637299
Log Pis Min                  -13.171726
Policy mu Mean               0.09622084
Policy mu Std                0.9034701
Policy mu Max                2.8646135
Policy mu Min                -4.4865203
Policy log std Mean          -0.33728528
Policy log std Std           0.13840728
Policy log std Max           -0.030456632
Policy log std Min           -1.2697592
Z mean eval                  0.20506391
Z variance eval              0.072102495
total_rewards                [3763.30236618 4103.99020926 4994.34039953 5001.35313203 4979.59228809
 5076.72164321 5018.21647514 4986.33665225 2762.91353721 5012.77504645]
total_rewards_mean           4569.954174936319
total_rewards_std            741.2445334832374
total_rewards_max            5076.7216432139185
total_rewards_min            2762.9135372071073
Number of train steps total  420000
Number of env steps total    576550
Number of rollouts total     0
Train Time (s)               121.99842137598898
(Previous) Eval Time (s)     21.013863631989807
Sample Time (s)              9.221950853941962
Epoch Time (s)               152.23423586192075
Total Train Time (s)         15608.569618561014
Epoch                        104
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 00:38:41.803311 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #104 | Epoch Duration: 155.93887186050415
2020-01-06 00:38:41.803543 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.21759453
Z variance train             0.07737597
KL Divergence                4.2678776
KL Loss                      0.42678776
QF Loss                      2768.024
VF Loss                      1106.1094
Policy Loss                  -1699.9642
Q Predictions Mean           1694.6748
Q Predictions Std            636.2892
Q Predictions Max            2236.9204
Q Predictions Min            57.525967
V Predictions Mean           1691.4324
V Predictions Std            627.7251
V Predictions Max            2212.7583
V Predictions Min            53.626892
Log Pis Mean                 -2.525517
Log Pis Std                  5.314039
Log Pis Max                  23.449356
Log Pis Min                  -17.119486
Policy mu Mean               0.08959919
Policy mu Std                0.86991686
Policy mu Max                2.6318448
Policy mu Min                -2.853216
Policy log std Mean          -0.33590496
Policy log std Std           0.14510277
Policy log std Max           -0.045445815
Policy log std Min           -0.922369
Z mean eval                  0.37518924
Z variance eval              0.2671543
total_rewards                [5142.80752071 1894.52467004 4958.6871699  5044.45110779  483.93764406
 5084.53389992 5116.20539562 3288.65366321 5085.10716259 5012.34436612]
total_rewards_mean           4111.125259997025
total_rewards_std            1584.8861600616867
total_rewards_max            5142.807520714876
total_rewards_min            483.93764406479625
Number of train steps total  424000
Number of env steps total    581550
Number of rollouts total     0
Train Time (s)               129.00328722101403
(Previous) Eval Time (s)     24.718236382992472
Sample Time (s)              8.237962234998122
Epoch Time (s)               161.95948583900463
Total Train Time (s)         15768.553466953977
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 00:41:21.788671 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #105 | Epoch Duration: 159.98495364189148
2020-01-06 00:41:21.788839 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #105 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.32372198
Z variance train             0.1877236
KL Divergence                2.5892465
KL Loss                      0.25892466
QF Loss                      3203.665
VF Loss                      982.31506
Policy Loss                  -1686.8152
Q Predictions Mean           1681.1272
Q Predictions Std            590.69305
Q Predictions Max            2212.3071
Q Predictions Min            67.37597
V Predictions Mean           1692.6895
V Predictions Std            588.81854
V Predictions Max            2223.9092
V Predictions Min            79.51786
Log Pis Mean                 -0.51072085
Log Pis Std                  6.465006
Log Pis Max                  24.279877
Log Pis Min                  -12.580948
Policy mu Mean               0.07454432
Policy mu Std                0.96893
Policy mu Max                2.637399
Policy mu Min                -2.8195515
Policy log std Mean          -0.35591614
Policy log std Std           0.15338191
Policy log std Max           -0.012845725
Policy log std Min           -1.0051912
Z mean eval                  0.2093993
Z variance eval              0.12177424
total_rewards                [5122.00384101 5131.84150728 1246.86913875 2405.62330885 5141.77023887
 5115.51797133 5098.49622769 3477.05218237 5078.15682695 5147.86799415]
total_rewards_mean           4296.519923724992
total_rewards_std            1352.430952693686
total_rewards_max            5147.867994149119
total_rewards_min            1246.8691387530419
Number of train steps total  428000
Number of env steps total    586855
Number of rollouts total     0
Train Time (s)               122.5714379750425
(Previous) Eval Time (s)     22.743454944051336
Sample Time (s)              9.667936202837154
Epoch Time (s)               154.982829121931
Total Train Time (s)         15922.454514112847
Epoch                        106
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 00:43:55.690570 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #106 | Epoch Duration: 153.9015974998474
2020-01-06 00:43:55.690683 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.20179848
Z variance train             0.112594105
KL Divergence                3.4082203
KL Loss                      0.34082204
QF Loss                      3484.2297
VF Loss                      969.5236
Policy Loss                  -1631.9733
Q Predictions Mean           1617.5391
Q Predictions Std            675.4665
Q Predictions Max            2268.2173
Q Predictions Min            17.156317
V Predictions Mean           1642.455
V Predictions Std            675.7829
V Predictions Max            2273.8523
V Predictions Min            46.319267
Log Pis Mean                 -0.021358937
Log Pis Std                  7.658296
Log Pis Max                  35.92662
Log Pis Min                  -11.98218
Policy mu Mean               0.11681119
Policy mu Std                0.971142
Policy mu Max                3.1463962
Policy mu Min                -4.996644
Policy log std Mean          -0.34730554
Policy log std Std           0.15316789
Policy log std Max           0.028602153
Policy log std Min           -1.1918658
Z mean eval                  0.27256575
Z variance eval              0.21644735
total_rewards                [5114.63234314  939.08430557 4364.25339695 5072.44157673 5033.75674546
 4960.42964909 5084.80028669 5132.23236894 2713.26332777 5049.69387806]
total_rewards_mean           4346.458787839441
total_rewards_std            1337.9631207540358
total_rewards_max            5132.23236893594
total_rewards_min            939.0843055650413
Number of train steps total  432000
Number of env steps total    592235
Number of rollouts total     0
Train Time (s)               138.6524733749684
(Previous) Eval Time (s)     21.661809888028074
Sample Time (s)              9.380417458945885
Epoch Time (s)               169.69470072194235
Total Train Time (s)         16094.511439766793
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 00:46:47.749606 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #107 | Epoch Duration: 172.05881214141846
2020-01-06 00:46:47.749793 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #107 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.3673373
Z variance train             0.29689997
KL Divergence                1.7843393
KL Loss                      0.17843394
QF Loss                      3085.3406
VF Loss                      1397.7175
Policy Loss                  -1736.0336
Q Predictions Mean           1732.4324
Q Predictions Std            638.9785
Q Predictions Max            2249.1438
Q Predictions Min            28.297146
V Predictions Mean           1754.6632
V Predictions Std            634.0896
V Predictions Max            2264.996
V Predictions Min            39.51677
Log Pis Mean                 -1.9593253
Log Pis Std                  6.0609727
Log Pis Max                  24.489632
Log Pis Min                  -14.020964
Policy mu Mean               0.10510939
Policy mu Std                0.88880366
Policy mu Max                3.093626
Policy mu Min                -3.133985
Policy log std Mean          -0.3362309
Policy log std Std           0.13518634
Policy log std Max           0.0034086555
Policy log std Min           -1.0814096
Z mean eval                  0.253374
Z variance eval              0.18209492
total_rewards                [5003.69189734 5012.16664727 5093.14869441 5064.32157102 1818.79300407
 5098.00972979 1895.80650484 5150.03237289 5082.63377669  430.08296816]
total_rewards_mean           3964.8687166493014
total_rewards_std            1731.392177086301
total_rewards_max            5150.032372892795
total_rewards_min            430.0829681639669
Number of train steps total  436000
Number of env steps total    597387
Number of rollouts total     0
Train Time (s)               131.7028457270353
(Previous) Eval Time (s)     24.025649544026237
Sample Time (s)              9.043452046986204
Epoch Time (s)               164.77194731804775
Total Train Time (s)         16256.248568021925
Epoch                        108
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 00:49:29.487820 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #108 | Epoch Duration: 161.7378740310669
2020-01-06 00:49:29.487964 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #108 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.302576
Z variance train             0.23752339
KL Divergence                2.084093
KL Loss                      0.20840931
QF Loss                      2610.4219
VF Loss                      1539.3527
Policy Loss                  -1723.0856
Q Predictions Mean           1726.9368
Q Predictions Std            610.4729
Q Predictions Max            2243.3826
Q Predictions Min            52.583385
V Predictions Mean           1744.5583
V Predictions Std            617.9054
V Predictions Max            2270.383
V Predictions Min            19.959364
Log Pis Mean                 -1.6059573
Log Pis Std                  5.36918
Log Pis Max                  17.920866
Log Pis Min                  -13.172162
Policy mu Mean               0.099665835
Policy mu Std                0.9011941
Policy mu Max                3.1161656
Policy mu Min                -3.4397235
Policy log std Mean          -0.33865538
Policy log std Std           0.13679464
Policy log std Max           0.031678893
Policy log std Min           -0.980312
Z mean eval                  0.11291728
Z variance eval              0.09216201
total_rewards                [5008.45202024 4076.15944418  661.97327034 3638.81152309 5040.84447246
 2763.92115453 5083.11374299 5082.71144171 5051.72371869 5115.46947796]
total_rewards_mean           4152.318026617761
total_rewards_std            1391.7862623471
total_rewards_max            5115.469477962782
total_rewards_min            661.973270335931
Number of train steps total  440000
Number of env steps total    602387
Number of rollouts total     0
Train Time (s)               138.57777827599784
(Previous) Eval Time (s)     20.99133221694501
Sample Time (s)              9.09536671807291
Epoch Time (s)               168.66447721101576
Total Train Time (s)         16426.721303240047
Epoch                        109
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 00:52:19.962102 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #109 | Epoch Duration: 170.47403407096863
2020-01-06 00:52:19.962217 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #109 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.13562448
Z variance train             0.12313968
KL Divergence                3.1064596
KL Loss                      0.31064597
QF Loss                      3904.2573
VF Loss                      1304.3835
Policy Loss                  -1686.8136
Q Predictions Mean           1670.2393
Q Predictions Std            636.52106
Q Predictions Max            2221.973
Q Predictions Min            88.52278
V Predictions Mean           1688.2996
V Predictions Std            635.66284
V Predictions Max            2236.388
V Predictions Min            55.402782
Log Pis Mean                 -1.7708783
Log Pis Std                  6.2457957
Log Pis Max                  24.534204
Log Pis Min                  -15.205458
Policy mu Mean               0.06994656
Policy mu Std                0.90165514
Policy mu Max                3.0063717
Policy mu Min                -3.5826216
Policy log std Mean          -0.32731628
Policy log std Std           0.14162824
Policy log std Max           -0.007528089
Policy log std Min           -1.0417622
Z mean eval                  0.22507219
Z variance eval              0.15512924
total_rewards                [3224.88949732 5071.61578449 5014.99585526 1441.64038479 5148.65859333
 3626.00449807 5019.93248546 3036.14880712 5133.06876888 4891.68077738]
total_rewards_mean           4160.863545210986
total_rewards_std            1207.1995040710156
total_rewards_max            5148.658593333586
total_rewards_min            1441.6403847850318
Number of train steps total  444000
Number of env steps total    607387
Number of rollouts total     0
Train Time (s)               120.37538289901568
(Previous) Eval Time (s)     22.800620165013243
Sample Time (s)              8.897928007121664
Epoch Time (s)               152.07393107115058
Total Train Time (s)         16578.70231834607
Epoch                        110
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 00:54:51.945309 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #110 | Epoch Duration: 151.98298335075378
2020-01-06 00:54:51.945488 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11216183
Z variance train             0.19116822
KL Divergence                2.1839497
KL Loss                      0.21839498
QF Loss                      2588.7407
VF Loss                      1082.0498
Policy Loss                  -1677.9485
Q Predictions Mean           1675.9736
Q Predictions Std            683.3373
Q Predictions Max            2245.1184
Q Predictions Min            32.009113
V Predictions Mean           1681.8044
V Predictions Std            675.9112
V Predictions Max            2238.5696
V Predictions Min            70.67348
Log Pis Mean                 -2.0181112
Log Pis Std                  6.1419063
Log Pis Max                  28.226116
Log Pis Min                  -14.0597
Policy mu Mean               0.096528396
Policy mu Std                0.88237965
Policy mu Max                4.0019703
Policy mu Min                -2.7367291
Policy log std Mean          -0.34022668
Policy log std Std           0.14242299
Policy log std Max           -0.048902467
Policy log std Min           -1.1366055
Z mean eval                  0.11176497
Z variance eval              0.07414036
total_rewards                [5018.54973397 5096.77423458 5086.78287832 1279.88207303 2830.38264884
 5132.26178031 1902.29594599 2564.87070032 4990.9527426  5103.65213468]
total_rewards_mean           3900.64048726294
total_rewards_std            1484.3108832212047
total_rewards_max            5132.261780309249
total_rewards_min            1279.8820730311472
Number of train steps total  448000
Number of env steps total    612578
Number of rollouts total     0
Train Time (s)               130.51765676797368
(Previous) Eval Time (s)     22.70939981000265
Sample Time (s)              9.063689868082292
Epoch Time (s)               162.29074644605862
Total Train Time (s)         16738.76553155511
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 00:57:32.010605 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #111 | Epoch Duration: 160.06496596336365
2020-01-06 00:57:32.010778 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #111 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1354984
Z variance train             0.08076127
KL Divergence                4.0706973
KL Loss                      0.40706974
QF Loss                      1827.0742
VF Loss                      763.9563
Policy Loss                  -1765.2067
Q Predictions Mean           1761.5823
Q Predictions Std            613.8984
Q Predictions Max            2276.7322
Q Predictions Min            90.130585
V Predictions Mean           1761.4778
V Predictions Std            609.0306
V Predictions Max            2257.7397
V Predictions Min            131.41914
Log Pis Mean                 -2.1356266
Log Pis Std                  5.538413
Log Pis Max                  15.0551815
Log Pis Min                  -14.584248
Policy mu Mean               0.06910111
Policy mu Std                0.8998172
Policy mu Max                2.5111208
Policy mu Min                -4.026438
Policy log std Mean          -0.33181334
Policy log std Std           0.13120131
Policy log std Max           0.021692067
Policy log std Min           -0.86400354
Z mean eval                  0.08325727
Z variance eval              0.052474122
total_rewards                [2205.07518686 4985.86737364 4008.11413606 3359.90817223 5062.66714168
 5079.71086405 1872.79607406 5043.09931208 2592.5151851  5040.61225457]
total_rewards_mean           3925.0365700328002
total_rewards_std            1245.7630144600516
total_rewards_max            5079.710864048614
total_rewards_min            1872.796074059067
Number of train steps total  452000
Number of env steps total    617769
Number of rollouts total     0
Train Time (s)               139.10369227099
(Previous) Eval Time (s)     20.483359863981605
Sample Time (s)              9.013996752968524
Epoch Time (s)               168.60104888794012
Total Train Time (s)         16908.231998372066
Epoch                        112
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 01:00:21.478059 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #112 | Epoch Duration: 169.4671449661255
2020-01-06 01:00:21.478170 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #112 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.102639556
Z variance train             0.043557532
KL Divergence                5.4919243
KL Loss                      0.5491924
QF Loss                      3620.9578
VF Loss                      1077.0355
Policy Loss                  -1693.0648
Q Predictions Mean           1683.4146
Q Predictions Std            648.5288
Q Predictions Max            2238.4487
Q Predictions Min            22.333414
V Predictions Mean           1697.8695
V Predictions Std            646.1246
V Predictions Max            2256.159
V Predictions Min            37.078884
Log Pis Mean                 -1.3383684
Log Pis Std                  6.1467285
Log Pis Max                  21.452497
Log Pis Min                  -15.374425
Policy mu Mean               0.05549039
Policy mu Std                0.9325537
Policy mu Max                3.2156215
Policy mu Min                -3.6337016
Policy log std Mean          -0.34450924
Policy log std Std           0.15728131
Policy log std Max           0.0014517605
Policy log std Min           -1.0100282
Z mean eval                  0.09222059
Z variance eval              0.0148978885
total_rewards                [5070.15959425 5074.33524548 5104.23554344 5055.63568187 1756.6702915
 2287.90100804 3527.18075011 5008.5624528  5035.86280443 5005.87732383]
total_rewards_mean           4292.642069575307
total_rewards_std            1227.4410429825118
total_rewards_max            5104.235543441578
total_rewards_min            1756.670291504178
Number of train steps total  456000
Number of env steps total    623091
Number of rollouts total     0
Train Time (s)               124.99531289603328
(Previous) Eval Time (s)     21.349204348982312
Sample Time (s)              9.30603803799022
Epoch Time (s)               155.65055528300581
Total Train Time (s)         17063.456717859022
Epoch                        113
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 01:02:56.704759 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #113 | Epoch Duration: 155.22649812698364
2020-01-06 01:02:56.704914 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #113 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.089440905
Z variance train             0.017618328
KL Divergence                7.6817975
KL Loss                      0.7681798
QF Loss                      2296.9814
VF Loss                      970.0403
Policy Loss                  -1575.3906
Q Predictions Mean           1571.7761
Q Predictions Std            732.0861
Q Predictions Max            2253.102
Q Predictions Min            -16.153383
V Predictions Mean           1586.9535
V Predictions Std            733.364
V Predictions Max            2284.4233
V Predictions Min            33.233826
Log Pis Mean                 -1.878222
Log Pis Std                  7.0465846
Log Pis Max                  31.083836
Log Pis Min                  -14.624944
Policy mu Mean               0.049524993
Policy mu Std                0.90528923
Policy mu Max                3.6516306
Policy mu Min                -4.1499076
Policy log std Mean          -0.3313395
Policy log std Std           0.15158723
Policy log std Max           0.08539897
Policy log std Min           -1.0173588
Z mean eval                  0.10275624
Z variance eval              0.04911471
total_rewards                [5124.34204017 4208.27992341 5183.24678673 5184.43336266 5135.72143262
 3398.5947831  5131.77257443 4909.13135972 5049.70132014 5055.59300937]
total_rewards_mean           4838.081659234694
total_rewards_std            553.3355295868613
total_rewards_max            5184.433362664431
total_rewards_min            3398.594783103184
Number of train steps total  460000
Number of env steps total    628262
Number of rollouts total     0
Train Time (s)               122.78809768595966
(Previous) Eval Time (s)     20.92487229697872
Sample Time (s)              8.572171399078798
Epoch Time (s)               152.28514138201717
Total Train Time (s)         17220.23467036296
Epoch                        114
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 01:05:33.484547 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #114 | Epoch Duration: 156.7795057296753
2020-01-06 01:05:33.484684 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #114 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.122913145
Z variance train             0.045184363
KL Divergence                5.416503
KL Loss                      0.5416503
QF Loss                      3034.5085
VF Loss                      1426.9615
Policy Loss                  -1700.1447
Q Predictions Mean           1697.2358
Q Predictions Std            657.6092
Q Predictions Max            2264.3032
Q Predictions Min            -3.7983508
V Predictions Mean           1706.1367
V Predictions Std            650.2044
V Predictions Max            2259.4263
V Predictions Min            24.189165
Log Pis Mean                 -1.9750048
Log Pis Std                  6.191408
Log Pis Max                  22.207542
Log Pis Min                  -14.1946945
Policy mu Mean               0.09391585
Policy mu Std                0.8925075
Policy mu Max                2.8953624
Policy mu Min                -3.0069633
Policy log std Mean          -0.32703418
Policy log std Std           0.14408056
Policy log std Max           0.036546
Policy log std Min           -1.152214
Z mean eval                  0.13460934
Z variance eval              0.08084158
total_rewards                [1938.58129748 5196.26078945 5233.71252172 3563.64188064 3480.14750942
 2999.22059042 5240.15783301 4150.49737067 1819.46317279 1295.8418775 ]
total_rewards_mean           3491.752484310461
total_rewards_std            1403.90332716692
total_rewards_max            5240.157833010587
total_rewards_min            1295.8418774984991
Number of train steps total  464000
Number of env steps total    633457
Number of rollouts total     0
Train Time (s)               128.9828756559873
(Previous) Eval Time (s)     25.418995985994115
Sample Time (s)              9.229120904114097
Epoch Time (s)               163.6309925460955
Total Train Time (s)         17376.49057735596
Epoch                        115
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 01:08:09.742016 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #115 | Epoch Duration: 156.25722360610962
2020-01-06 01:08:09.742168 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09045257
Z variance train             0.06786422
KL Divergence                4.4328604
KL Loss                      0.44328603
QF Loss                      3044.1172
VF Loss                      1278.5085
Policy Loss                  -1783.5156
Q Predictions Mean           1773.2474
Q Predictions Std            605.32623
Q Predictions Max            2267.3315
Q Predictions Min            78.926384
V Predictions Mean           1770.4363
V Predictions Std            597.794
V Predictions Max            2256.5876
V Predictions Min            69.612206
Log Pis Mean                 -1.0837915
Log Pis Std                  6.7626367
Log Pis Max                  23.938393
Log Pis Min                  -14.38332
Policy mu Mean               0.07943883
Policy mu Std                0.9313517
Policy mu Max                4.2378044
Policy mu Min                -3.8577516
Policy log std Mean          -0.3472921
Policy log std Std           0.14586838
Policy log std Max           0.035297394
Policy log std Min           -1.0715921
Z mean eval                  0.16418393
Z variance eval              0.08340386
total_rewards                [4429.93440313 5210.98147299 1050.00546518 2203.2751725  5274.92990201
 4145.11107463 1866.86092933 1207.32396326 4797.02447345 5296.3473822 ]
total_rewards_mean           3548.1794238689135
total_rewards_std            1668.8972112337176
total_rewards_max            5296.347382203796
total_rewards_min            1050.0054651783817
Number of train steps total  468000
Number of env steps total    638622
Number of rollouts total     0
Train Time (s)               119.59102181100752
(Previous) Eval Time (s)     18.044967588037252
Sample Time (s)              8.602592269016895
Epoch Time (s)               146.23858166806167
Total Train Time (s)         17521.539526455104
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 01:10:34.793168 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #116 | Epoch Duration: 145.05087614059448
2020-01-06 01:10:34.793338 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #116 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14550516
Z variance train             0.05062132
KL Divergence                5.1654134
KL Loss                      0.51654136
QF Loss                      3097.8315
VF Loss                      695.9563
Policy Loss                  -1799.952
Q Predictions Mean           1789.1981
Q Predictions Std            621.06195
Q Predictions Max            2276.8936
Q Predictions Min            16.73222
V Predictions Mean           1807.5212
V Predictions Std            627.07086
V Predictions Max            2290.5078
V Predictions Min            58.124866
Log Pis Mean                 -2.196669
Log Pis Std                  5.449543
Log Pis Max                  19.523365
Log Pis Min                  -14.043125
Policy mu Mean               0.085752524
Policy mu Std                0.8814986
Policy mu Max                2.5744228
Policy mu Min                -3.0687897
Policy log std Mean          -0.32662106
Policy log std Std           0.14212121
Policy log std Max           -0.01493746
Policy log std Min           -1.0502865
Z mean eval                  0.08718677
Z variance eval              0.021928776
total_rewards                [3093.56929574 4586.4339074  5192.18296106 5126.33133037 5109.5545231
 1946.36110631 5165.29310675 5050.47844383 5151.76780221 5225.89053796]
total_rewards_mean           4564.786301472866
total_rewards_std            1067.9392200264997
total_rewards_max            5225.890537958335
total_rewards_min            1946.361106313488
Number of train steps total  472000
Number of env steps total    643761
Number of rollouts total     0
Train Time (s)               140.73089194699423
(Previous) Eval Time (s)     16.85700136597734
Sample Time (s)              8.587944870989304
Epoch Time (s)               166.17583818396088
Total Train Time (s)         17694.708090991073
Epoch                        117
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 01:13:27.962808 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #117 | Epoch Duration: 173.16933131217957
2020-01-06 01:13:27.962936 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #117 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07123013
Z variance train             0.025180241
KL Divergence                6.793347
KL Loss                      0.6793347
QF Loss                      2805.6929
VF Loss                      1104.5095
Policy Loss                  -1713.4054
Q Predictions Mean           1704.936
Q Predictions Std            672.2347
Q Predictions Max            2271.6484
Q Predictions Min            22.0319
V Predictions Mean           1720.8064
V Predictions Std            670.4357
V Predictions Max            2289.1252
V Predictions Min            60.282513
Log Pis Mean                 -1.7869664
Log Pis Std                  6.3538475
Log Pis Max                  22.289452
Log Pis Min                  -13.877996
Policy mu Mean               0.07998655
Policy mu Std                0.9204978
Policy mu Max                2.8909023
Policy mu Min                -3.201785
Policy log std Mean          -0.34489024
Policy log std Std           0.15349996
Policy log std Max           0.12662488
Policy log std Min           -1.0952605
Z mean eval                  0.08879514
Z variance eval              0.03213656
total_rewards                [5220.59104939 5141.11821056 5048.58491914 3547.58032425 5189.39077468
 5237.66377663 4557.04456212 5191.26170357 4749.37101764 5144.29052735]
total_rewards_mean           4902.689686533468
total_rewards_std            499.45403559822734
total_rewards_max            5237.663776634633
total_rewards_min            3547.580324254684
Number of train steps total  476000
Number of env steps total    648761
Number of rollouts total     0
Train Time (s)               140.86375032400247
(Previous) Eval Time (s)     23.850252287986223
Sample Time (s)              8.74986828211695
Epoch Time (s)               173.46387089410564
Total Train Time (s)         17869.48710264027
Epoch                        118
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 01:16:22.743578 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #118 | Epoch Duration: 174.7805359363556
2020-01-06 01:16:22.743748 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #118 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.084734134
Z variance train             0.031041557
KL Divergence                6.2918663
KL Loss                      0.62918663
QF Loss                      3779.9546
VF Loss                      1637.9142
Policy Loss                  -1741.7434
Q Predictions Mean           1735.9443
Q Predictions Std            648.56946
Q Predictions Max            2279.065
Q Predictions Min            56.957916
V Predictions Mean           1741.5515
V Predictions Std            636.47894
V Predictions Max            2272.9414
V Predictions Min            65.51016
Log Pis Mean                 -1.2468462
Log Pis Std                  6.7143674
Log Pis Max                  27.970512
Log Pis Min                  -15.6733055
Policy mu Mean               0.060505327
Policy mu Std                0.9241432
Policy mu Max                3.0223942
Policy mu Min                -3.0311007
Policy log std Mean          -0.33708876
Policy log std Std           0.1417196
Policy log std Max           0.09843129
Policy log std Min           -1.03517
Z mean eval                  0.055546474
Z variance eval              0.031288933
total_rewards                [5224.31040704 5129.10231332 5163.8284323  5205.87676368 5199.81139736
 5198.26896701 5143.17205865 5040.63093894 5268.60848175 3528.02907313]
total_rewards_mean           5010.163883319786
total_rewards_std            497.53469559678314
total_rewards_max            5268.6084817544515
total_rewards_min            3528.029073128426
Number of train steps total  480000
Number of env steps total    653957
Number of rollouts total     0
Train Time (s)               141.78300265199505
(Previous) Eval Time (s)     25.166660882008728
Sample Time (s)              8.809668609930668
Epoch Time (s)               175.75933214393444
Total Train Time (s)         18046.582701193227
Epoch                        119
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 01:19:19.841452 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #119 | Epoch Duration: 177.0975489616394
2020-01-06 01:19:19.841612 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #119 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.044139437
Z variance train             0.021199558
KL Divergence                7.2023363
KL Loss                      0.7202336
QF Loss                      3955.4434
VF Loss                      1346.5123
Policy Loss                  -1671.4137
Q Predictions Mean           1664.0096
Q Predictions Std            672.4371
Q Predictions Max            2258.1035
Q Predictions Min            36.62994
V Predictions Mean           1679.2014
V Predictions Std            664.2932
V Predictions Max            2264.8003
V Predictions Min            -2.3052964
Log Pis Mean                 -1.020112
Log Pis Std                  6.5810704
Log Pis Max                  27.611427
Log Pis Min                  -15.121357
Policy mu Mean               0.052207407
Policy mu Std                0.94807464
Policy mu Max                3.0715828
Policy mu Min                -3.163978
Policy log std Mean          -0.36046147
Policy log std Std           0.15449414
Policy log std Max           -0.030619964
Policy log std Min           -1.247289
Z mean eval                  0.018175919
Z variance eval              0.046669625
total_rewards                [5212.68858229 5232.02157844 2511.09512887 5130.00015878 5272.40434374
 5248.07845062 5159.34995638 5233.68182168  949.34065612 5223.22880874]
total_rewards_mean           4517.188948565914
total_rewards_std            1437.1141812183746
total_rewards_max            5272.404343736201
total_rewards_min            949.3406561191572
Number of train steps total  484000
Number of env steps total    658957
Number of rollouts total     0
Train Time (s)               140.98201335896738
(Previous) Eval Time (s)     26.50461769400863
Sample Time (s)              8.763794100959785
Epoch Time (s)               176.2504251539358
Total Train Time (s)         18219.481389014225
Epoch                        120
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 01:22:12.741193 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #120 | Epoch Duration: 172.89945816993713
2020-01-06 01:22:12.741482 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #120 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05876527
Z variance train             0.029416764
KL Divergence                6.4099617
KL Loss                      0.64099616
QF Loss                      2376.933
VF Loss                      1059.6974
Policy Loss                  -1777.7924
Q Predictions Mean           1775.6826
Q Predictions Std            657.4628
Q Predictions Max            2293.0825
Q Predictions Min            40.77949
V Predictions Mean           1760.8479
V Predictions Std            652.07806
V Predictions Max            2273.973
V Predictions Min            15.532565
Log Pis Mean                 -1.8887607
Log Pis Std                  6.5546575
Log Pis Max                  36.665985
Log Pis Min                  -14.789704
Policy mu Mean               0.061850168
Policy mu Std                0.88431054
Policy mu Max                3.2242134
Policy mu Min                -2.9316726
Policy log std Mean          -0.32401326
Policy log std Std           0.14515889
Policy log std Max           -0.04067561
Policy log std Min           -1.0379857
Z mean eval                  0.065774456
Z variance eval              0.074275166
total_rewards                [5082.46310602 5114.25642747 5069.46555276 5063.1798459  5150.43319218
 5132.01961779 5091.48583452 5117.37024718 5074.44456173 5096.87792778]
total_rewards_mean           5099.199631331359
total_rewards_std            27.19975321509155
total_rewards_max            5150.4331921818375
total_rewards_min            5063.179845897563
Number of train steps total  488000
Number of env steps total    664135
Number of rollouts total     0
Train Time (s)               122.33267627999885
(Previous) Eval Time (s)     23.153412070998456
Sample Time (s)              8.812929918174632
Epoch Time (s)               154.29901826917194
Total Train Time (s)         18378.09023973433
Epoch                        121
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 01:24:51.352701 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #121 | Epoch Duration: 158.61109948158264
2020-01-06 01:24:51.352926 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.062499423
Z variance train             0.08157194
KL Divergence                3.9881792
KL Loss                      0.39881793
QF Loss                      3068.438
VF Loss                      1421.7976
Policy Loss                  -1739.1748
Q Predictions Mean           1736.2489
Q Predictions Std            664.11224
Q Predictions Max            2268.0598
Q Predictions Min            23.622345
V Predictions Mean           1757.4946
V Predictions Std            662.5296
V Predictions Max            2287.497
V Predictions Min            50.333176
Log Pis Mean                 -1.4106586
Log Pis Std                  6.1063957
Log Pis Max                  25.209782
Log Pis Min                  -13.598646
Policy mu Mean               0.058467973
Policy mu Std                0.92476344
Policy mu Max                3.1155076
Policy mu Min                -3.081179
Policy log std Mean          -0.33147284
Policy log std Std           0.14336948
Policy log std Max           0.004119754
Policy log std Min           -1.1487783
Z mean eval                  0.24994405
Z variance eval              0.17065106
total_rewards                [5059.13548791 4942.54424259 2916.36445128 4984.35752266 5028.14973299
 5058.7845999  4966.99607862 5002.42138454 4873.29823113 5027.96136415]
total_rewards_mean           4786.001309577822
total_rewards_std            625.5240919927121
total_rewards_max            5059.135487906374
total_rewards_min            2916.3644512847723
Number of train steps total  492000
Number of env steps total    669135
Number of rollouts total     0
Train Time (s)               121.66270415199688
(Previous) Eval Time (s)     27.4652191339992
Sample Time (s)              8.624050240963697
Epoch Time (s)               157.75197352695977
Total Train Time (s)         18534.17585012829
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 01:27:27.439626 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #122 | Epoch Duration: 156.08652257919312
2020-01-06 01:27:27.439736 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #122 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.48454207
Z variance train             0.1361756
KL Divergence                3.4449315
KL Loss                      0.34449315
QF Loss                      2432.1682
VF Loss                      887.17365
Policy Loss                  -1760.2703
Q Predictions Mean           1752.3645
Q Predictions Std            638.2153
Q Predictions Max            2250.2996
Q Predictions Min            63.66935
V Predictions Mean           1752.6965
V Predictions Std            634.83075
V Predictions Max            2245.3376
V Predictions Min            59.747944
Log Pis Mean                 -1.937628
Log Pis Std                  6.276598
Log Pis Max                  28.643557
Log Pis Min                  -13.100519
Policy mu Mean               0.059108693
Policy mu Std                0.9108981
Policy mu Max                2.9416194
Policy mu Min                -3.4435394
Policy log std Mean          -0.33282465
Policy log std Std           0.13960324
Policy log std Max           -0.024091646
Policy log std Min           -1.1620489
Z mean eval                  0.7909075
Z variance eval              0.29654962
total_rewards                [5133.76018734 5110.67458661 5067.98544666 5125.26103025 5087.39232375
 5030.99959448 5115.50615439 5099.95033544 5091.38940505 5132.49450802]
total_rewards_mean           5099.541357199572
total_rewards_std            30.339961999049034
total_rewards_max            5133.760187336799
total_rewards_min            5030.999594480863
Number of train steps total  496000
Number of env steps total    674135
Number of rollouts total     0
Train Time (s)               130.2274600500241
(Previous) Eval Time (s)     25.799527191964444
Sample Time (s)              8.725336398929358
Epoch Time (s)               164.7523236409179
Total Train Time (s)         18698.90882138716
Epoch                        123
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 01:30:12.174338 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #123 | Epoch Duration: 164.73450565338135
2020-01-06 01:30:12.174462 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #123 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.34875983
Z variance train             0.15722024
KL Divergence                2.9001927
KL Loss                      0.29001927
QF Loss                      2583.438
VF Loss                      1000.28326
Policy Loss                  -1782.868
Q Predictions Mean           1782.4269
Q Predictions Std            609.2102
Q Predictions Max            2291.8691
Q Predictions Min            22.603073
V Predictions Mean           1786.6074
V Predictions Std            604.87555
V Predictions Max            2288.72
V Predictions Min            28.601414
Log Pis Mean                 -1.195918
Log Pis Std                  6.6644697
Log Pis Max                  29.144606
Log Pis Min                  -11.356073
Policy mu Mean               0.05773463
Policy mu Std                0.9339801
Policy mu Max                3.4078033
Policy mu Min                -3.1702263
Policy log std Mean          -0.34385982
Policy log std Std           0.14304875
Policy log std Max           0.009519786
Policy log std Min           -1.1836184
Z mean eval                  0.35451174
Z variance eval              0.12326505
total_rewards                [5112.53750628 5056.29941921 4039.27384838 1436.74546525 5030.0463126
 2444.61677407 5034.51935342 5166.09605256 5077.63298705 5151.03610765]
total_rewards_mean           4354.880382646655
total_rewards_std            1267.3722108762101
total_rewards_max            5166.096052559626
total_rewards_min            1436.7454652514748
Number of train steps total  500000
Number of env steps total    679405
Number of rollouts total     0
Train Time (s)               127.76444880903
(Previous) Eval Time (s)     25.781456661992706
Sample Time (s)              9.028366026002914
Epoch Time (s)               162.57427149702562
Total Train Time (s)         18858.16131720424
Epoch                        124
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 01:32:51.428447 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #124 | Epoch Duration: 159.25389623641968
2020-01-06 01:32:51.428574 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.104499385
Z variance train             0.0845332
KL Divergence                3.9520993
KL Loss                      0.39520994
QF Loss                      2289.4673
VF Loss                      735.5314
Policy Loss                  -1831.0541
Q Predictions Mean           1818.1699
Q Predictions Std            643.2847
Q Predictions Max            2276.095
Q Predictions Min            -13.139515
V Predictions Mean           1821.9932
V Predictions Std            632.1482
V Predictions Max            2273.7627
V Predictions Min            26.225798
Log Pis Mean                 -2.254284
Log Pis Std                  5.2677035
Log Pis Max                  19.46285
Log Pis Min                  -16.790197
Policy mu Mean               0.11263069
Policy mu Std                0.8702705
Policy mu Max                2.9399645
Policy mu Min                -2.6726503
Policy log std Mean          -0.33215186
Policy log std Std           0.13467869
Policy log std Max           0.0010758936
Policy log std Min           -0.99832904
Z mean eval                  0.20438547
Z variance eval              0.17862317
total_rewards                [2034.16962585 4629.87980096  978.37202912 1704.37236326  855.16633748
 5348.40800868 5309.35062851 5374.67165264 5345.29232896 5323.11318439]
total_rewards_mean           3690.2795959858295
total_rewards_std            1912.4553921798977
total_rewards_max            5374.671652643993
total_rewards_min            855.1663374793652
Number of train steps total  504000
Number of env steps total    684405
Number of rollouts total     0
Train Time (s)               139.42004521097988
(Previous) Eval Time (s)     22.460836163023487
Sample Time (s)              8.56960937002441
Epoch Time (s)               170.45049074402777
Total Train Time (s)         19024.25729489827
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 01:35:37.527087 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #125 | Epoch Duration: 166.0984013080597
2020-01-06 01:35:37.527268 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #125 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6096087
Z variance train             0.25048947
KL Divergence                2.6155567
KL Loss                      0.26155567
QF Loss                      2213.709
VF Loss                      692.14044
Policy Loss                  -1793.639
Q Predictions Mean           1781.3795
Q Predictions Std            638.37195
Q Predictions Max            2274.3445
Q Predictions Min            -33.6178
V Predictions Mean           1791.5283
V Predictions Std            625.41565
V Predictions Max            2267.1152
V Predictions Min            35.52852
Log Pis Mean                 -1.5348299
Log Pis Std                  5.882764
Log Pis Max                  27.425304
Log Pis Min                  -13.270672
Policy mu Mean               0.1390292
Policy mu Std                0.9026257
Policy mu Max                3.4298544
Policy mu Min                -2.8576758
Policy log std Mean          -0.3351237
Policy log std Std           0.14775325
Policy log std Max           0.0297935
Policy log std Min           -1.1777596
Z mean eval                  0.7907728
Z variance eval              0.20845318
total_rewards                [5095.95739174 5122.50586381 5099.35607989  735.33333965 5140.37237551
 5170.22926132 5080.99341399 5196.26946784 5218.25608921 5184.85799468]
total_rewards_mean           4704.413127762535
total_rewards_std            1323.7569683604243
total_rewards_max            5218.256089210634
total_rewards_min            735.333339649123
Number of train steps total  508000
Number of env steps total    689405
Number of rollouts total     0
Train Time (s)               135.49654520500917
(Previous) Eval Time (s)     18.10850010003196
Sample Time (s)              9.04960059496807
Epoch Time (s)               162.6546459000092
Total Train Time (s)         19192.287676259293
Epoch                        126
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 01:38:25.558793 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #126 | Epoch Duration: 168.0313901901245
2020-01-06 01:38:25.558958 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #126 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.5555612
Z variance train             0.14057
KL Divergence                3.705111
KL Loss                      0.3705111
QF Loss                      2428.032
VF Loss                      1068.9268
Policy Loss                  -1775.4497
Q Predictions Mean           1769.028
Q Predictions Std            656.0391
Q Predictions Max            2293.8445
Q Predictions Min            -13.338177
V Predictions Mean           1775.6504
V Predictions Std            651.40967
V Predictions Max            2292.6787
V Predictions Min            -24.590187
Log Pis Mean                 -1.8428775
Log Pis Std                  6.0245013
Log Pis Max                  20.22037
Log Pis Min                  -13.486005
Policy mu Mean               0.11597107
Policy mu Std                0.8975945
Policy mu Max                3.3075714
Policy mu Min                -2.913075
Policy log std Mean          -0.34079343
Policy log std Std           0.141706
Policy log std Max           -0.002438113
Policy log std Min           -1.0073267
Z mean eval                  1.6924865
Z variance eval              0.07382162
total_rewards                [2932.55135604 5179.57314883 3894.790311   5034.86050536 5162.8068917
 5209.39698065 2912.66277976 5106.86719815 5178.32068113 5127.90315582]
total_rewards_mean           4573.9733008448575
total_rewards_std            905.6055747330319
total_rewards_max            5209.396980648511
total_rewards_min            2912.662779762688
Number of train steps total  512000
Number of env steps total    694405
Number of rollouts total     0
Train Time (s)               145.07485918799648
(Previous) Eval Time (s)     23.484994131023996
Sample Time (s)              8.383443750091828
Epoch Time (s)               176.9432970691123
Total Train Time (s)         19369.823337514477
Epoch                        127
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 01:41:23.096588 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #127 | Epoch Duration: 177.5375006198883
2020-01-06 01:41:23.096726 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #127 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.18557972
Z variance train             0.16402225
KL Divergence                2.5320773
KL Loss                      0.25320774
QF Loss                      1811.0552
VF Loss                      679.14636
Policy Loss                  -1846.6035
Q Predictions Mean           1839.1477
Q Predictions Std            644.4731
Q Predictions Max            2351.678
Q Predictions Min            70.3416
V Predictions Mean           1844.5828
V Predictions Std            644.7514
V Predictions Max            2345.7488
V Predictions Min            74.31255
Log Pis Mean                 -1.9789636
Log Pis Std                  5.599146
Log Pis Max                  27.223969
Log Pis Min                  -13.8307
Policy mu Mean               0.09113183
Policy mu Std                0.88175195
Policy mu Max                2.812994
Policy mu Min                -2.9130025
Policy log std Mean          -0.32424065
Policy log std Std           0.14366916
Policy log std Max           0.019332439
Policy log std Min           -1.0752934
Z mean eval                  0.4008922
Z variance eval              0.05230229
total_rewards                [5012.07504313 4871.39996021 5025.64642474 5011.24594132 5009.51438199
 5007.66979356 4682.80830215 5098.66372752 4968.20457663 4988.86437016]
total_rewards_mean           4967.609252140728
total_rewards_std            108.90628376942742
total_rewards_max            5098.663727523147
total_rewards_min            4682.808302146168
Number of train steps total  516000
Number of env steps total    699405
Number of rollouts total     0
Train Time (s)               124.64186568098376
(Previous) Eval Time (s)     24.078951530042104
Sample Time (s)              8.730988486029673
Epoch Time (s)               157.45180569705553
Total Train Time (s)         19529.901176498446
Epoch                        128
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 01:44:03.175940 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #128 | Epoch Duration: 160.0791072845459
2020-01-06 01:44:03.176077 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #128 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08712877
Z variance train             0.045450367
KL Divergence                5.376119
KL Loss                      0.5376119
QF Loss                      2773.5967
VF Loss                      1233.9851
Policy Loss                  -1843.0463
Q Predictions Mean           1832.6847
Q Predictions Std            625.40027
Q Predictions Max            2343.3467
Q Predictions Min            125.54636
V Predictions Mean           1855.929
V Predictions Std            627.1832
V Predictions Max            2365.5667
V Predictions Min            147.11449
Log Pis Mean                 -0.7582189
Log Pis Std                  6.9706926
Log Pis Max                  27.412315
Log Pis Min                  -16.193914
Policy mu Mean               0.0637622
Policy mu Std                0.9529079
Policy mu Max                3.9862816
Policy mu Min                -3.6698036
Policy log std Mean          -0.3520862
Policy log std Std           0.15396717
Policy log std Max           0.21687043
Policy log std Min           -1.0381442
Z mean eval                  0.059764527
Z variance eval              0.042054616
total_rewards                [5119.68655083 4177.69017356 5165.0437536  4440.57621041 5188.22577456
 5144.33378144 5189.48162925 5192.81175028 5160.07532212 5231.18398527]
total_rewards_mean           5000.910893132375
total_rewards_std            352.01071377778896
total_rewards_max            5231.183985271631
total_rewards_min            4177.690173562364
Number of train steps total  520000
Number of env steps total    704405
Number of rollouts total     0
Train Time (s)               132.34413098095683
(Previous) Eval Time (s)     26.705992361006793
Sample Time (s)              8.45672478096094
Epoch Time (s)               167.50684812292457
Total Train Time (s)         19695.948783093365
Epoch                        129
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 01:46:49.225161 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #129 | Epoch Duration: 166.04897141456604
2020-01-06 01:46:49.225288 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08813182
Z variance train             0.0743055
KL Divergence                4.228224
KL Loss                      0.4228224
QF Loss                      2398.1575
VF Loss                      1326.3801
Policy Loss                  -1856.6816
Q Predictions Mean           1850.4487
Q Predictions Std            615.449
Q Predictions Max            2327.9749
Q Predictions Min            17.3971
V Predictions Mean           1855.5305
V Predictions Std            609.7456
V Predictions Max            2328.1545
V Predictions Min            57.893543
Log Pis Mean                 -1.6134653
Log Pis Std                  5.9190927
Log Pis Max                  30.254747
Log Pis Min                  -13.747568
Policy mu Mean               0.06512869
Policy mu Std                0.9299893
Policy mu Max                3.3291025
Policy mu Min                -3.2433362
Policy log std Mean          -0.34878606
Policy log std Std           0.14524284
Policy log std Max           0.11985907
Policy log std Min           -1.1040184
Z mean eval                  0.083460264
Z variance eval              0.028720582
total_rewards                [5004.72004184 5144.31029794 3636.46945104 5135.27159332 5110.95563733
 5172.8854772   898.43902458 4038.54723837 5015.33879861 5093.17723767]
total_rewards_mean           4425.011479788452
total_rewards_std            1280.2560441189219
total_rewards_max            5172.885477196076
total_rewards_min            898.4390245790495
Number of train steps total  524000
Number of env steps total    709405
Number of rollouts total     0
Train Time (s)               121.9915525149554
(Previous) Eval Time (s)     25.24785022198921
Sample Time (s)              8.524538160127122
Epoch Time (s)               155.76394089707173
Total Train Time (s)         19849.52950377151
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 01:49:22.807134 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #130 | Epoch Duration: 153.58175683021545
2020-01-06 01:49:22.807247 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #130 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.092907324
Z variance train             0.024499733
KL Divergence                6.8758955
KL Loss                      0.6875896
QF Loss                      2266.9883
VF Loss                      1173.9105
Policy Loss                  -1899.4407
Q Predictions Mean           1891.2991
Q Predictions Std            599.4546
Q Predictions Max            2355.0203
Q Predictions Min            43.239666
V Predictions Mean           1903.4039
V Predictions Std            592.5098
V Predictions Max            2350.7913
V Predictions Min            63.258263
Log Pis Mean                 -1.6395003
Log Pis Std                  6.139913
Log Pis Max                  30.269642
Log Pis Min                  -12.950989
Policy mu Mean               0.07526897
Policy mu Std                0.9015834
Policy mu Max                3.3437703
Policy mu Min                -3.210902
Policy log std Mean          -0.34671757
Policy log std Std           0.15171258
Policy log std Max           0.40679434
Policy log std Min           -1.164255
Z mean eval                  0.0479124
Z variance eval              0.038607843
total_rewards                [5121.1293181  5162.83870092 5189.2677527  5127.21610184 5246.34823265
 5189.5920831  5161.42397388 5170.82235583 5116.01375685 5149.95233346]
total_rewards_mean           5163.460460933427
total_rewards_std            37.17153548443825
total_rewards_max            5246.348232648843
total_rewards_min            5116.013756854331
Number of train steps total  528000
Number of env steps total    714490
Number of rollouts total     0
Train Time (s)               127.18105155503144
(Previous) Eval Time (s)     23.065414805023465
Sample Time (s)              8.955669784976635
Epoch Time (s)               159.20213614503155
Total Train Time (s)         20011.937701626564
Epoch                        131
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 01:52:05.217356 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #131 | Epoch Duration: 162.4100158214569
2020-01-06 01:52:05.217493 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07616338
Z variance train             0.039760366
KL Divergence                5.7010827
KL Loss                      0.5701083
QF Loss                      2030.0587
VF Loss                      986.6328
Policy Loss                  -1867.6835
Q Predictions Mean           1872.86
Q Predictions Std            639.9017
Q Predictions Max            2355.5405
Q Predictions Min            50.432205
V Predictions Mean           1874.8684
V Predictions Std            640.97736
V Predictions Max            2351.9905
V Predictions Min            -9.774725
Log Pis Mean                 -2.3296213
Log Pis Std                  5.3568234
Log Pis Max                  16.022377
Log Pis Min                  -16.93132
Policy mu Mean               0.07967262
Policy mu Std                0.8773366
Policy mu Max                2.9124548
Policy mu Min                -2.5616364
Policy log std Mean          -0.32435393
Policy log std Std           0.13786808
Policy log std Max           0.011467293
Policy log std Min           -1.0179386
Z mean eval                  0.116995595
Z variance eval              0.013143416
total_rewards                [5167.87752698 5104.6284856  5051.41510989 5094.02751414 5080.06514227
  511.70056684 5158.11285556  368.48907394 5126.04602058 5195.75145001]
total_rewards_mean           4185.811374581777
total_rewards_std            1873.5774626321656
total_rewards_max            5195.7514500100715
total_rewards_min            368.489073942857
Number of train steps total  532000
Number of env steps total    719490
Number of rollouts total     0
Train Time (s)               129.09136041504098
(Previous) Eval Time (s)     26.273034025973175
Sample Time (s)              8.728561691998038
Epoch Time (s)               164.0929561330122
Total Train Time (s)         20171.29760490253
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 01:54:44.578726 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #132 | Epoch Duration: 159.3611297607422
2020-01-06 01:54:44.578869 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #132 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11130355
Z variance train             0.01387989
KL Divergence                8.279602
KL Loss                      0.8279602
QF Loss                      2689.6875
VF Loss                      1424.3593
Policy Loss                  -1866.6841
Q Predictions Mean           1862.9193
Q Predictions Std            646.8864
Q Predictions Max            2323.088
Q Predictions Min            48.528587
V Predictions Mean           1878.4133
V Predictions Std            651.35864
V Predictions Max            2341.6194
V Predictions Min            60.161705
Log Pis Mean                 -1.8728945
Log Pis Std                  6.1493583
Log Pis Max                  26.765726
Log Pis Min                  -16.813536
Policy mu Mean               0.09122139
Policy mu Std                0.886302
Policy mu Max                3.0882716
Policy mu Min                -3.307222
Policy log std Mean          -0.34318423
Policy log std Std           0.14609084
Policy log std Max           -0.029237375
Policy log std Min           -1.0776727
Z mean eval                  0.11154759
Z variance eval              0.011885599
total_rewards                [5164.07206965 5164.8164995  5193.64753355 5172.71121674 5167.29286152
 5215.88032839 5147.4302413  5197.45563897 5172.98748534 5162.61600525]
total_rewards_mean           5175.8909880212495
total_rewards_std            19.28863881766109
total_rewards_max            5215.880328392059
total_rewards_min            5147.430241301207
Number of train steps total  536000
Number of env steps total    724490
Number of rollouts total     0
Train Time (s)               124.74852225900395
(Previous) Eval Time (s)     21.540948977984954
Sample Time (s)              8.79861533996882
Epoch Time (s)               155.08808657695772
Total Train Time (s)         20331.139571953623
Epoch                        133
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 01:57:24.422752 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #133 | Epoch Duration: 159.84374976158142
2020-01-06 01:57:24.422897 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11476396
Z variance train             0.012576282
KL Divergence                8.52211
KL Loss                      0.852211
QF Loss                      1945.6554
VF Loss                      558.6478
Policy Loss                  -1830.1614
Q Predictions Mean           1827.4048
Q Predictions Std            680.55963
Q Predictions Max            2350.946
Q Predictions Min            7.0502796
V Predictions Mean           1830.7632
V Predictions Std            673.4011
V Predictions Max            2356.8044
V Predictions Min            -15.922821
Log Pis Mean                 -2.2968907
Log Pis Std                  5.9177575
Log Pis Max                  25.518234
Log Pis Min                  -13.400853
Policy mu Mean               0.09704116
Policy mu Std                0.87821084
Policy mu Max                3.2322147
Policy mu Min                -3.4547377
Policy log std Mean          -0.32353646
Policy log std Std           0.13881257
Policy log std Max           0.024139643
Policy log std Min           -1.2921534
Z mean eval                  0.11348852
Z variance eval              0.0091789495
total_rewards                [5041.04971457 4970.91974894 5018.27679334 4949.80215124 5093.30535134
 5091.64855095 4978.00095572 5045.45006641 4922.4903675  4902.75860091]
total_rewards_mean           5001.370230093072
total_rewards_std            63.62741135081935
total_rewards_max            5093.305351343905
total_rewards_min            4902.758600911288
Number of train steps total  540000
Number of env steps total    729490
Number of rollouts total     0
Train Time (s)               124.74950650002575
(Previous) Eval Time (s)     26.29635027499171
Sample Time (s)              8.425463691004552
Epoch Time (s)               159.471320466022
Total Train Time (s)         20491.04202198953
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 02:00:04.327095 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #134 | Epoch Duration: 159.90408849716187
2020-01-06 02:00:04.327237 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #134 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11020299
Z variance train             0.00953836
KL Divergence                9.202997
KL Loss                      0.9202997
QF Loss                      2952.1602
VF Loss                      1222.0498
Policy Loss                  -1936.1746
Q Predictions Mean           1940.3007
Q Predictions Std            624.2386
Q Predictions Max            2354.6433
Q Predictions Min            39.14326
V Predictions Mean           1942.4456
V Predictions Std            623.35266
V Predictions Max            2349.1926
V Predictions Min            33.161503
Log Pis Mean                 -1.9674265
Log Pis Std                  6.0245786
Log Pis Max                  25.466393
Log Pis Min                  -16.009676
Policy mu Mean               0.086800724
Policy mu Std                0.8938216
Policy mu Max                2.7077367
Policy mu Min                -3.0636542
Policy log std Mean          -0.3299731
Policy log std Std           0.14060158
Policy log std Max           0.030391872
Policy log std Min           -1.0335301
Z mean eval                  0.10907237
Z variance eval              0.023910493
total_rewards                [5101.30721759 3160.77228745 5078.18105551 5081.16896602 5130.99974842
 5049.16232658 5014.46565155  543.94947829 5075.20638142 5036.55593622]
total_rewards_mean           4427.176904905104
total_rewards_std            1414.4831260383078
total_rewards_max            5130.999748420473
total_rewards_min            543.9494782937379
Number of train steps total  544000
Number of env steps total    734490
Number of rollouts total     0
Train Time (s)               131.4630305430037
(Previous) Eval Time (s)     26.728857767011505
Sample Time (s)              8.55915423098486
Epoch Time (s)               166.75104254100006
Total Train Time (s)         20655.244715984445
Epoch                        135
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 02:02:48.531300 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #135 | Epoch Duration: 164.20397186279297
2020-01-06 02:02:48.531419 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #135 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07423556
Z variance train             0.024449509
KL Divergence                6.867834
KL Loss                      0.68678343
QF Loss                      3025.592
VF Loss                      1065.3528
Policy Loss                  -1816.3656
Q Predictions Mean           1809.2269
Q Predictions Std            670.427
Q Predictions Max            2352.2014
Q Predictions Min            81.32466
V Predictions Mean           1820.0173
V Predictions Std            664.1963
V Predictions Max            2358.0981
V Predictions Min            56.98497
Log Pis Mean                 -1.4278555
Log Pis Std                  6.882194
Log Pis Max                  22.89136
Log Pis Min                  -14.467018
Policy mu Mean               0.026753832
Policy mu Std                0.91955626
Policy mu Max                3.1725163
Policy mu Min                -2.886377
Policy log std Mean          -0.34206367
Policy log std Std           0.15107538
Policy log std Max           0.23970428
Policy log std Min           -1.3494107
Z mean eval                  0.099114224
Z variance eval              0.024785616
total_rewards                [1190.93926364 4742.22901872 5118.01274065 5142.79544391 5157.6165491
 4207.12197406 5125.59888621 5128.92421236 5158.19262824 5164.00680837]
total_rewards_mean           4613.543752525368
total_rewards_std            1177.0319035552682
total_rewards_max            5164.006808373523
total_rewards_min            1190.9392636362795
Number of train steps total  548000
Number of env steps total    739490
Number of rollouts total     0
Train Time (s)               132.5451820010203
(Previous) Eval Time (s)     24.181542742007878
Sample Time (s)              8.60514251695713
Epoch Time (s)               165.3318672599853
Total Train Time (s)         20821.29246974748
Epoch                        136
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 02:05:34.580284 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #136 | Epoch Duration: 166.0487699508667
2020-01-06 02:05:34.580397 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #136 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10579518
Z variance train             0.029931832
KL Divergence                6.39865
KL Loss                      0.63986504
QF Loss                      2932.0742
VF Loss                      1220.672
Policy Loss                  -1946.8228
Q Predictions Mean           1942.1821
Q Predictions Std            601.6057
Q Predictions Max            2366.4429
Q Predictions Min            43.197876
V Predictions Mean           1951.9299
V Predictions Std            597.6291
V Predictions Max            2364.926
V Predictions Min            49.233826
Log Pis Mean                 -1.5278279
Log Pis Std                  6.244626
Log Pis Max                  23.020126
Log Pis Min                  -14.929449
Policy mu Mean               0.07203702
Policy mu Std                0.90940434
Policy mu Max                3.1678631
Policy mu Min                -2.721772
Policy log std Mean          -0.3476326
Policy log std Std           0.15051335
Policy log std Max           -0.04092805
Policy log std Min           -1.1453984
Z mean eval                  0.77406824
Z variance eval              0.2911571
total_rewards                [5022.24280124 5038.56197242 5106.09631837 5057.93076762 4973.58768018
 5028.67973761 2511.25435064 5124.10164588 5103.99823612 5091.31377288]
total_rewards_mean           4805.776728295733
total_rewards_std            766.1134041213494
total_rewards_max            5124.101645877441
total_rewards_min            2511.254350642615
Number of train steps total  552000
Number of env steps total    744490
Number of rollouts total     0
Train Time (s)               142.70120212301845
(Previous) Eval Time (s)     24.89817684504669
Sample Time (s)              8.813313259044662
Epoch Time (s)               176.4126922271098
Total Train Time (s)         20999.142712305475
Epoch                        137
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 02:08:32.432887 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #137 | Epoch Duration: 177.85239481925964
2020-01-06 02:08:32.433044 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.5777932
Z variance train             0.31267756
KL Divergence                2.301107
KL Loss                      0.23011069
QF Loss                      2447.9094
VF Loss                      1463.9751
Policy Loss                  -1894.6145
Q Predictions Mean           1885.7717
Q Predictions Std            651.6463
Q Predictions Max            2381.3853
Q Predictions Min            41.57992
V Predictions Mean           1876.53
V Predictions Std            649.8721
V Predictions Max            2372.609
V Predictions Min            11.065451
Log Pis Mean                 -2.1283674
Log Pis Std                  6.770073
Log Pis Max                  25.032707
Log Pis Min                  -16.587185
Policy mu Mean               0.06400344
Policy mu Std                0.8938728
Policy mu Max                3.589816
Policy mu Min                -3.532001
Policy log std Mean          -0.33326894
Policy log std Std           0.15485013
Policy log std Max           0.015311003
Policy log std Min           -1.125063
Z mean eval                  0.33752146
Z variance eval              0.18523565
total_rewards                [5063.88456841 5095.18336226 5133.42861315 5087.87922005 5008.69969456
 5111.66784575 5123.02017283 5024.87361635 5025.65990647 5100.66474674]
total_rewards_mean           5077.496174658661
total_rewards_std            42.071802908815954
total_rewards_max            5133.428613153803
total_rewards_min            5008.699694564654
Number of train steps total  556000
Number of env steps total    749490
Number of rollouts total     0
Train Time (s)               138.99615295795957
(Previous) Eval Time (s)     26.337634017982055
Sample Time (s)              8.771150121989194
Epoch Time (s)               174.10493709793082
Total Train Time (s)         21173.696538475342
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 02:11:26.989163 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #138 | Epoch Duration: 174.55600929260254
2020-01-06 02:11:26.989347 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #138 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.53291404
Z variance train             0.13182963
KL Divergence                3.7768505
KL Loss                      0.37768504
QF Loss                      2275.997
VF Loss                      1402.4049
Policy Loss                  -1849.3657
Q Predictions Mean           1841.9866
Q Predictions Std            666.82104
Q Predictions Max            2371.1519
Q Predictions Min            31.212376
V Predictions Mean           1853.5623
V Predictions Std            664.9897
V Predictions Max            2379.3037
V Predictions Min            14.413606
Log Pis Mean                 -2.470306
Log Pis Std                  6.109458
Log Pis Max                  27.106815
Log Pis Min                  -14.647261
Policy mu Mean               0.07864067
Policy mu Std                0.86545664
Policy mu Max                2.682401
Policy mu Min                -2.8280373
Policy log std Mean          -0.32277134
Policy log std Std           0.1446795
Policy log std Max           0.0049159527
Policy log std Min           -1.1099489
Z mean eval                  0.20119914
Z variance eval              0.038643263
total_rewards                [5172.19449321 5038.35151139 1754.29268374 5173.51474042 5091.43367626
 5152.50617265 5213.32824394 5108.9441386  5166.95415056 5109.09090042]
total_rewards_mean           4798.061071119035
total_rewards_std            1015.717595973027
total_rewards_max            5213.328243938924
total_rewards_min            1754.2926837413127
Number of train steps total  560000
Number of env steps total    754677
Number of rollouts total     0
Train Time (s)               131.1266474039876
(Previous) Eval Time (s)     26.788432555971667
Sample Time (s)              8.767464716045652
Epoch Time (s)               166.6825446760049
Total Train Time (s)         21339.017535462393
Epoch                        139
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 02:14:12.311846 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #139 | Epoch Duration: 165.32237458229065
2020-01-06 02:14:12.311983 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #139 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.24548025
Z variance train             0.047791377
KL Divergence                5.426013
KL Loss                      0.5426013
QF Loss                      2482.0913
VF Loss                      1034.8845
Policy Loss                  -1892.505
Q Predictions Mean           1888.8002
Q Predictions Std            669.7559
Q Predictions Max            2374.4917
Q Predictions Min            124.53879
V Predictions Mean           1881.8728
V Predictions Std            664.9367
V Predictions Max            2366.3027
V Predictions Min            81.99675
Log Pis Mean                 -1.4671214
Log Pis Std                  6.5684905
Log Pis Max                  25.43388
Log Pis Min                  -16.586432
Policy mu Mean               0.0865139
Policy mu Std                0.89982086
Policy mu Max                3.4819326
Policy mu Min                -3.0773902
Policy log std Mean          -0.33446717
Policy log std Std           0.13959537
Policy log std Max           -0.04452651
Policy log std Min           -1.0895141
Z mean eval                  0.6488837
Z variance eval              0.13811989
total_rewards                [5132.85351788 5033.84594512 5082.13240572 5103.93369979 5209.71839348
 5134.96118793 4875.22784334 5058.09260132 5129.11303006 5043.55593816]
total_rewards_mean           5080.343456279718
total_rewards_std            84.55726110855159
total_rewards_max            5209.71839348219
total_rewards_min            4875.2278433437605
Number of train steps total  564000
Number of env steps total    759873
Number of rollouts total     0
Train Time (s)               129.81639334000647
(Previous) Eval Time (s)     25.42797956103459
Sample Time (s)              9.134705210046377
Epoch Time (s)               164.37907811108744
Total Train Time (s)         21505.370590388484
Epoch                        140
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 02:16:58.666722 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #140 | Epoch Duration: 166.35463619232178
2020-01-06 02:16:58.666845 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #140 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6752912
Z variance train             0.08086346
KL Divergence                5.323537
KL Loss                      0.5323537
QF Loss                      2574.5688
VF Loss                      967.69037
Policy Loss                  -1873.168
Q Predictions Mean           1871.8817
Q Predictions Std            669.56165
Q Predictions Max            2384.3079
Q Predictions Min            50.84693
V Predictions Mean           1885.1655
V Predictions Std            676.53
V Predictions Max            2392.5237
V Predictions Min            13.204807
Log Pis Mean                 -2.0441892
Log Pis Std                  6.0592556
Log Pis Max                  20.70261
Log Pis Min                  -16.81461
Policy mu Mean               0.10061997
Policy mu Std                0.8951015
Policy mu Max                3.0546694
Policy mu Min                -3.3494105
Policy log std Mean          -0.34116194
Policy log std Std           0.14101213
Policy log std Max           0.006335765
Policy log std Min           -1.077421
Z mean eval                  0.5419403
Z variance eval              0.099126056
total_rewards                [2034.31328085 1249.43828772 2182.82691676 5262.21166975 1867.71449127
 2018.33728342 1274.66387102 5322.03664976 4135.291012   5291.7175251 ]
total_rewards_mean           3063.855098766632
total_rewards_std            1640.025668042258
total_rewards_max            5322.036649764689
total_rewards_min            1249.4382877213523
Number of train steps total  568000
Number of env steps total    764873
Number of rollouts total     0
Train Time (s)               131.2681010980159
(Previous) Eval Time (s)     27.403260157967452
Sample Time (s)              8.398285707109608
Epoch Time (s)               167.06964696309296
Total Train Time (s)         21660.836091422534
Epoch                        141
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 02:19:34.134891 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #141 | Epoch Duration: 155.4679365158081
2020-01-06 02:19:34.135072 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #141 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6521294
Z variance train             0.1588803
KL Divergence                3.8061438
KL Loss                      0.38061437
QF Loss                      2203.129
VF Loss                      931.6784
Policy Loss                  -1902.9373
Q Predictions Mean           1906.3405
Q Predictions Std            675.257
Q Predictions Max            2401.1616
Q Predictions Min            70.21509
V Predictions Mean           1908.3253
V Predictions Std            672.86597
V Predictions Max            2395.523
V Predictions Min            104.74392
Log Pis Mean                 -1.2894616
Log Pis Std                  6.4345217
Log Pis Max                  29.633526
Log Pis Min                  -13.059177
Policy mu Mean               0.13194445
Policy mu Std                0.9107481
Policy mu Max                3.3278217
Policy mu Min                -3.1023633
Policy log std Mean          -0.335674
Policy log std Std           0.14099792
Policy log std Max           0.05182074
Policy log std Min           -1.0723382
Z mean eval                  0.41131908
Z variance eval              0.18621144
total_rewards                [5192.17410902 5186.15919855 5212.51480863 5168.25446453 5151.43794764
 5136.78158819 5122.31051106 5146.85236228 5158.59701853 5139.30490051]
total_rewards_mean           5161.438690894698
total_rewards_std            26.75955305548012
total_rewards_max            5212.514808631409
total_rewards_min            5122.310511056118
Number of train steps total  572000
Number of env steps total    769873
Number of rollouts total     0
Train Time (s)               134.80538466299186
(Previous) Eval Time (s)     15.801288908987772
Sample Time (s)              8.571571877982933
Epoch Time (s)               159.17824544996256
Total Train Time (s)         21831.436033396632
Epoch                        142
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 02:22:24.736641 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #142 | Epoch Duration: 170.6014256477356
2020-01-06 02:22:24.736824 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #142 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.28456485
Z variance train             0.1955274
KL Divergence                2.397493
KL Loss                      0.2397493
QF Loss                      2116.3403
VF Loss                      840.5638
Policy Loss                  -1860.4564
Q Predictions Mean           1854.7295
Q Predictions Std            681.7796
Q Predictions Max            2375.3225
Q Predictions Min            54.64942
V Predictions Mean           1859.2598
V Predictions Std            675.72675
V Predictions Max            2370.4727
V Predictions Min            71.99864
Log Pis Mean                 -2.406468
Log Pis Std                  6.263515
Log Pis Max                  25.103558
Log Pis Min                  -14.12884
Policy mu Mean               0.095798425
Policy mu Std                0.87043566
Policy mu Max                3.0716038
Policy mu Min                -2.9038024
Policy log std Mean          -0.32068896
Policy log std Std           0.13932537
Policy log std Max           0.014946163
Policy log std Min           -1.0106279
Z mean eval                  0.48400363
Z variance eval              0.19152671
total_rewards                [5198.47512201 5124.4928584  5099.01705976 2275.74426547 5270.79704761
 5232.6857194  5129.37939611 5168.41544588 5219.03178167 5262.15838445]
total_rewards_mean           4898.01970807566
total_rewards_std            875.8734581653505
total_rewards_max            5270.79704761106
total_rewards_min            2275.7442654653646
Number of train steps total  576000
Number of env steps total    774873
Number of rollouts total     0
Train Time (s)               134.36766433599405
(Previous) Eval Time (s)     27.224196055030916
Sample Time (s)              8.401009229011834
Epoch Time (s)               169.9928696200368
Total Train Time (s)         22000.375715355505
Epoch                        143
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 02:25:13.677974 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #143 | Epoch Duration: 168.9410195350647
2020-01-06 02:25:13.678094 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #143 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6323433
Z variance train             0.25747025
KL Divergence                9.578849
KL Loss                      0.9578849
QF Loss                      2478.8777
VF Loss                      1246.3315
Policy Loss                  -1915.8191
Q Predictions Mean           1907.75
Q Predictions Std            693.6853
Q Predictions Max            2443.5466
Q Predictions Min            41.554455
V Predictions Mean           1900.6211
V Predictions Std            685.0386
V Predictions Max            2422.2383
V Predictions Min            44.782482
Log Pis Mean                 -1.2197595
Log Pis Std                  6.0055184
Log Pis Max                  25.984447
Log Pis Min                  -11.517601
Policy mu Mean               0.07730852
Policy mu Std                0.91145295
Policy mu Max                3.9533832
Policy mu Min                -3.018836
Policy log std Mean          -0.34113616
Policy log std Std           0.15062924
Policy log std Max           0.027107537
Policy log std Min           -1.0209379
Z mean eval                  1.0103809
Z variance eval              0.17490219
total_rewards                [5054.17748169 5036.54579019 5013.07406526 4970.17424958 4996.76252075
 5016.81669245 3042.63612204 5040.17510974 5033.7564522  5050.05833013]
total_rewards_mean           4825.417681401967
total_rewards_std            594.7577194372368
total_rewards_max            5054.177481685386
total_rewards_min            3042.6361220356043
Number of train steps total  580000
Number of env steps total    779873
Number of rollouts total     0
Train Time (s)               132.99919264996424
(Previous) Eval Time (s)     26.17206776200328
Sample Time (s)              8.279019149020314
Epoch Time (s)               167.45027956098784
Total Train Time (s)         22168.00314360048
Epoch                        144
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 02:28:01.308447 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #144 | Epoch Duration: 167.6302514076233
2020-01-06 02:28:01.308621 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #144 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1548592
Z variance train             0.20211284
KL Divergence                5.9025292
KL Loss                      0.59025294
QF Loss                      2464.541
VF Loss                      915.91956
Policy Loss                  -2033.8748
Q Predictions Mean           2029.6726
Q Predictions Std            572.4189
Q Predictions Max            2405.5247
Q Predictions Min            37.50462
V Predictions Mean           2044.0624
V Predictions Std            566.1299
V Predictions Max            2415.2407
V Predictions Min            5.7039194
Log Pis Mean                 -2.413407
Log Pis Std                  6.211263
Log Pis Max                  39.39004
Log Pis Min                  -14.464909
Policy mu Mean               0.06973876
Policy mu Std                0.8815897
Policy mu Max                3.9938698
Policy mu Min                -2.9964113
Policy log std Mean          -0.3330237
Policy log std Std           0.14315619
Policy log std Max           0.026980177
Policy log std Min           -1.1880571
Z mean eval                  0.20933536
Z variance eval              0.03981231
total_rewards                [1542.92752175 5329.0769343  3275.54289283 5259.75996912 5219.61165189
 5312.65083621 5353.94751484 5242.82813694 5270.7562711  5272.30523665]
total_rewards_mean           4707.9406965663275
total_rewards_std            1213.489439919566
total_rewards_max            5353.947514844218
total_rewards_min            1542.9275217543893
Number of train steps total  584000
Number of env steps total    784873
Number of rollouts total     0
Train Time (s)               132.4924832980032
(Previous) Eval Time (s)     26.351762964040972
Sample Time (s)              8.860945498163346
Epoch Time (s)               167.70519176020753
Total Train Time (s)         22334.567799660726
Epoch                        145
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 02:30:47.874549 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #145 | Epoch Duration: 166.56581568717957
2020-01-06 02:30:47.874711 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #145 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.2548978
Z variance train             0.048936956
KL Divergence                5.3948574
KL Loss                      0.53948575
QF Loss                      2502.922
VF Loss                      1363.3207
Policy Loss                  -1900.9536
Q Predictions Mean           1893.8286
Q Predictions Std            663.3009
Q Predictions Max            2369.7957
Q Predictions Min            35.47558
V Predictions Mean           1894.0383
V Predictions Std            656.06024
V Predictions Max            2370.7275
V Predictions Min            29.920898
Log Pis Mean                 -1.5846658
Log Pis Std                  6.364555
Log Pis Max                  26.648006
Log Pis Min                  -13.799182
Policy mu Mean               0.07371366
Policy mu Std                0.90180546
Policy mu Max                4.4157743
Policy mu Min                -4.328108
Policy log std Mean          -0.33548972
Policy log std Std           0.1487998
Policy log std Max           0.31413516
Policy log std Min           -1.0514117
Z mean eval                  0.36478063
Z variance eval              0.052977424
total_rewards                [5317.48839047 5329.67128868 5298.54129479 5256.19982129 5168.36380186
 2342.70644552 5275.18979658 5315.72040856 5264.05386812 2359.33951778]
total_rewards_mean           4692.727463363012
total_rewards_std            1171.6594899845127
total_rewards_max            5329.671288677063
total_rewards_min            2342.706445517826
Number of train steps total  588000
Number of env steps total    789873
Number of rollouts total     0
Train Time (s)               137.98146852198988
(Previous) Eval Time (s)     25.212134219997097
Sample Time (s)              8.30286455800524
Epoch Time (s)               171.49646729999222
Total Train Time (s)         22503.93092802266
Epoch                        146
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 02:33:37.239272 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #146 | Epoch Duration: 169.36446261405945
2020-01-06 02:33:37.239383 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #146 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.37405285
Z variance train             0.062218696
KL Divergence                5.083236
KL Loss                      0.5083236
QF Loss                      2170.274
VF Loss                      1014.1535
Policy Loss                  -1948.783
Q Predictions Mean           1942.3452
Q Predictions Std            589.49426
Q Predictions Max            2387.6648
Q Predictions Min            55.271835
V Predictions Mean           1948.0918
V Predictions Std            590.6342
V Predictions Max            2390.5708
V Predictions Min            58.642635
Log Pis Mean                 -1.6044052
Log Pis Std                  5.76108
Log Pis Max                  21.553173
Log Pis Min                  -14.332352
Policy mu Mean               0.053976625
Policy mu Std                0.90418565
Policy mu Max                3.4206004
Policy mu Min                -2.653133
Policy log std Mean          -0.33846045
Policy log std Std           0.14208739
Policy log std Max           0.08385044
Policy log std Min           -0.98433596
Z mean eval                  0.27427712
Z variance eval              0.026782867
total_rewards                [5013.33853167 5147.12557303 5115.99784965 5209.43568588 5098.32750671
 5103.63563601 5063.62425704 3429.91055125 5215.8917199  5148.66882079]
total_rewards_mean           4954.595613193245
total_rewards_std            511.5541315119421
total_rewards_max            5215.891719900809
total_rewards_min            3429.910551253314
Number of train steps total  592000
Number of env steps total    794873
Number of rollouts total     0
Train Time (s)               128.46531125402544
(Previous) Eval Time (s)     23.079859454999678
Sample Time (s)              8.435126917029265
Epoch Time (s)               159.98029762605438
Total Train Time (s)         22666.34236951574
Epoch                        147
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 02:36:19.653399 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #147 | Epoch Duration: 162.41391944885254
2020-01-06 02:36:19.653539 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #147 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.35174626
Z variance train             0.030955981
KL Divergence                6.6706386
KL Loss                      0.6670639
QF Loss                      2963.0798
VF Loss                      1339.8107
Policy Loss                  -1896.3656
Q Predictions Mean           1893.1094
Q Predictions Std            630.86426
Q Predictions Max            2387.6274
Q Predictions Min            52.201893
V Predictions Mean           1893.178
V Predictions Std            625.4545
V Predictions Max            2389.0232
V Predictions Min            40.039368
Log Pis Mean                 -2.2403305
Log Pis Std                  6.080296
Log Pis Max                  27.623392
Log Pis Min                  -15.02257
Policy mu Mean               0.081811905
Policy mu Std                0.87742907
Policy mu Max                2.8585052
Policy mu Min                -2.842654
Policy log std Mean          -0.33503252
Policy log std Std           0.14428484
Policy log std Max           0.090394765
Policy log std Min           -1.0285691
Z mean eval                  1.7316242
Z variance eval              0.22249904
total_rewards                [5012.363877   5220.90291738 5282.28652661 5196.11095094 5191.18420822
 5229.07916681 5230.18612506 5119.09914967 4623.29637078 5197.45020919]
total_rewards_mean           5130.195950166599
total_rewards_std            182.94191244326345
total_rewards_max            5282.2865266064655
total_rewards_min            4623.296370781482
Number of train steps total  596000
Number of env steps total    799873
Number of rollouts total     0
Train Time (s)               127.02599158301018
(Previous) Eval Time (s)     25.51322285598144
Sample Time (s)              8.33577544282889
Epoch Time (s)               160.8749898818205
Total Train Time (s)         22827.746257830586
Epoch                        148
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 02:39:01.058865 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #148 | Epoch Duration: 161.40522861480713
2020-01-06 02:39:01.058996 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #148 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2259947
Z variance train             0.15210941
KL Divergence                7.277351
KL Loss                      0.7277351
QF Loss                      2773.7927
VF Loss                      902.92065
Policy Loss                  -1955.8918
Q Predictions Mean           1956.2917
Q Predictions Std            666.106
Q Predictions Max            2452.5625
Q Predictions Min            44.838806
V Predictions Mean           1953.0228
V Predictions Std            665.29443
V Predictions Max            2439.3503
V Predictions Min            19.077023
Log Pis Mean                 -1.6082854
Log Pis Std                  6.79318
Log Pis Max                  31.460562
Log Pis Min                  -12.899159
Policy mu Mean               0.10809563
Policy mu Std                0.8986172
Policy mu Max                3.1473284
Policy mu Min                -3.351018
Policy log std Mean          -0.33589205
Policy log std Std           0.1470931
Policy log std Max           0.16061611
Policy log std Min           -1.092834
Z mean eval                  0.45111004
Z variance eval              0.10480864
total_rewards                [5246.29234291 4217.63812945 3115.8221858  5268.06579707 5243.79783638
 1164.99930982 5258.25309029 5234.24222864 5239.92711456 5211.52302113]
total_rewards_mean           4520.0561056054785
total_rewards_std            1303.1428422048743
total_rewards_max            5268.0657970742
total_rewards_min            1164.999309817329
Number of train steps total  600000
Number of env steps total    804996
Number of rollouts total     0
Train Time (s)               129.29428006499074
(Previous) Eval Time (s)     26.043205352965742
Sample Time (s)              8.646366994129494
Epoch Time (s)               163.98385241208598
Total Train Time (s)         22987.939336845768
Epoch                        149
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 02:41:41.254543 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #149 | Epoch Duration: 160.1954369544983
2020-01-06 02:41:41.254708 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #149 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.31368145
Z variance train             0.08802097
KL Divergence                4.188396
KL Loss                      0.4188396
QF Loss                      2773.2358
VF Loss                      935.293
Policy Loss                  -1936.4812
Q Predictions Mean           1929.5767
Q Predictions Std            632.1208
Q Predictions Max            2402.3308
Q Predictions Min            50.58579
V Predictions Mean           1936.5471
V Predictions Std            639.82623
V Predictions Max            2404.1416
V Predictions Min            34.64502
Log Pis Mean                 -2.0397105
Log Pis Std                  6.1230583
Log Pis Max                  22.0684
Log Pis Min                  -14.22292
Policy mu Mean               0.083299436
Policy mu Std                0.8907977
Policy mu Max                2.9015582
Policy mu Min                -2.9250312
Policy log std Mean          -0.33478275
Policy log std Std           0.14878331
Policy log std Max           -0.0180161
Policy log std Min           -1.0549505
Z mean eval                  0.30391657
Z variance eval              0.072210655
total_rewards                [5200.15941752 5242.61556499 2844.65841719 2192.0387227  3766.87240324
 5316.07974999 5188.3953356  5236.54296388 2969.38441859 1032.92194049]
total_rewards_mean           3898.9668934185056
total_rewards_std            1485.9136712654254
total_rewards_max            5316.079749985913
total_rewards_min            1032.9219404882388
Number of train steps total  604000
Number of env steps total    809996
Number of rollouts total     0
Train Time (s)               123.03540156700183
(Previous) Eval Time (s)     22.254529907018878
Sample Time (s)              8.230245015933178
Epoch Time (s)               153.52017648995388
Total Train Time (s)         23138.135843912663
Epoch                        150
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 02:44:11.452653 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #150 | Epoch Duration: 150.1978199481964
2020-01-06 02:44:11.452770 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #150 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.36244267
Z variance train             0.05490104
KL Divergence                5.3367863
KL Loss                      0.53367865
QF Loss                      2077.4355
VF Loss                      740.09546
Policy Loss                  -1964.3264
Q Predictions Mean           1957.7937
Q Predictions Std            639.47595
Q Predictions Max            2392.0356
Q Predictions Min            36.864006
V Predictions Mean           1962.426
V Predictions Std            632.2444
V Predictions Max            2402.2366
V Predictions Min            30.21193
Log Pis Mean                 -2.2128503
Log Pis Std                  7.012745
Log Pis Max                  41.361515
Log Pis Min                  -16.513535
Policy mu Mean               0.080542885
Policy mu Std                0.8859496
Policy mu Max                3.8844893
Policy mu Min                -3.2088022
Policy log std Mean          -0.32412097
Policy log std Std           0.14526235
Policy log std Max           0.053316057
Policy log std Min           -1.3358396
Z mean eval                  0.12377095
Z variance eval              0.026464656
total_rewards                [5184.87842024 5202.65806271 2550.36951298 5273.49835299 5214.10927607
 5200.11156625 5259.3141525  3195.93266296 5295.30197691 5292.52706024]
total_rewards_mean           4766.870104384812
total_rewards_std            958.53071188329
total_rewards_max            5295.301976910357
total_rewards_min            2550.369512975797
Number of train steps total  608000
Number of env steps total    815099
Number of rollouts total     0
Train Time (s)               128.05980720598018
(Previous) Eval Time (s)     18.931930713006295
Sample Time (s)              8.372736762044951
Epoch Time (s)               155.36447468103142
Total Train Time (s)         23298.828343399742
Epoch                        151
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 02:46:52.148121 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #151 | Epoch Duration: 160.69524312019348
2020-01-06 02:46:52.148321 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #151 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.23034875
Z variance train             0.024448493
KL Divergence                7.042595
KL Loss                      0.7042595
QF Loss                      2393.1863
VF Loss                      1150.0101
Policy Loss                  -1975.5065
Q Predictions Mean           1970.4299
Q Predictions Std            610.9655
Q Predictions Max            2406.9534
Q Predictions Min            72.04656
V Predictions Mean           1965.2692
V Predictions Std            602.36755
V Predictions Max            2390.8865
V Predictions Min            60.956818
Log Pis Mean                 -1.8640783
Log Pis Std                  6.504006
Log Pis Max                  30.451975
Log Pis Min                  -12.838306
Policy mu Mean               0.10085589
Policy mu Std                0.89818364
Policy mu Max                3.4035945
Policy mu Min                -4.048991
Policy log std Mean          -0.34204236
Policy log std Std           0.14969414
Policy log std Max           0.024488859
Policy log std Min           -1.2918448
Z mean eval                  0.08823173
Z variance eval              0.02438796
total_rewards                [5294.15249399 5155.09397816 3121.56273595 5319.24911178 5251.4882165
 5225.35976026 5301.61282154 5351.39919975 5298.86967341 5213.56551531]
total_rewards_mean           5053.235350665828
total_rewards_std            646.2278780620828
total_rewards_max            5351.399199747684
total_rewards_min            3121.562735945044
Number of train steps total  612000
Number of env steps total    820099
Number of rollouts total     0
Train Time (s)               134.08307724096812
(Previous) Eval Time (s)     24.26242620497942
Sample Time (s)              8.184799928043503
Epoch Time (s)               166.53030337399105
Total Train Time (s)         23465.88793623977
Epoch                        152
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 02:49:39.208653 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #152 | Epoch Duration: 167.06018900871277
2020-01-06 02:49:39.208809 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #152 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.086833596
Z variance train             0.01915879
KL Divergence                7.4763937
KL Loss                      0.74763936
QF Loss                      1714.6471
VF Loss                      898.91614
Policy Loss                  -1986.9652
Q Predictions Mean           1982.7168
Q Predictions Std            621.13025
Q Predictions Max            2416.0698
Q Predictions Min            55.266766
V Predictions Mean           1994.3739
V Predictions Std            625.01666
V Predictions Max            2446.188
V Predictions Min            55.38496
Log Pis Mean                 -2.2136576
Log Pis Std                  6.3088517
Log Pis Max                  25.399672
Log Pis Min                  -11.630386
Policy mu Mean               0.06407219
Policy mu Std                0.88244545
Policy mu Max                2.8610764
Policy mu Min                -2.8054438
Policy log std Mean          -0.33546904
Policy log std Std           0.14388387
Policy log std Max           0.17144157
Policy log std Min           -1.2100779
Z mean eval                  0.12673753
Z variance eval              0.01831451
total_rewards                [5259.33344705 5182.80737441 5278.34744131 4681.84711947 5094.6914919
 5236.70269806 4278.03471088 5266.31564412 5201.00117523 5241.05410608]
total_rewards_mean           5072.01352084917
total_rewards_std            313.5558253196288
total_rewards_max            5278.347441305692
total_rewards_min            4278.034710881312
Number of train steps total  616000
Number of env steps total    825099
Number of rollouts total     0
Train Time (s)               128.64925261901226
(Previous) Eval Time (s)     24.792063773958944
Sample Time (s)              8.409239890926983
Epoch Time (s)               161.8505562838982
Total Train Time (s)         23628.507000751793
Epoch                        153
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 02:52:21.830878 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #153 | Epoch Duration: 162.6219346523285
2020-01-06 02:52:21.831119 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #153 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.099417076
Z variance train             0.013145466
KL Divergence                8.412131
KL Loss                      0.84121317
QF Loss                      1776.9946
VF Loss                      861.1961
Policy Loss                  -1988.7225
Q Predictions Mean           1984.897
Q Predictions Std            591.4456
Q Predictions Max            2402.0024
Q Predictions Min            34.693108
V Predictions Mean           1988.5966
V Predictions Std            591.2884
V Predictions Max            2412.7236
V Predictions Min            51.42281
Log Pis Mean                 -2.2028084
Log Pis Std                  5.9925547
Log Pis Max                  24.530378
Log Pis Min                  -14.9893875
Policy mu Mean               0.07200532
Policy mu Std                0.8845049
Policy mu Max                2.8953543
Policy mu Min                -3.1729784
Policy log std Mean          -0.3301762
Policy log std Std           0.14760081
Policy log std Max           0.053308666
Policy log std Min           -1.1403667
Z mean eval                  0.10832526
Z variance eval              0.01350376
total_rewards                [5149.96070199 5262.17729317 5214.48932419 5247.51623763 5155.88934846
 2641.40262455 5207.31064509 5224.72673927 5305.8115959  1356.77505052]
total_rewards_mean           4576.605956077486
total_rewards_std            1321.1071713932276
total_rewards_max            5305.811595900398
total_rewards_min            1356.7750505163751
Number of train steps total  620000
Number of env steps total    830099
Number of rollouts total     0
Train Time (s)               124.48890379798831
(Previous) Eval Time (s)     25.563177883974276
Sample Time (s)              8.15406704985071
Epoch Time (s)               158.2061487318133
Total Train Time (s)         23784.033047123638
Epoch                        154
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 02:54:57.358441 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #154 | Epoch Duration: 155.5271656513214
2020-01-06 02:54:57.358580 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #154 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05033634
Z variance train             0.01194402
KL Divergence                8.6182375
KL Loss                      0.86182374
QF Loss                      2571.6328
VF Loss                      870.6157
Policy Loss                  -2009.3372
Q Predictions Mean           2003.0453
Q Predictions Std            606.1231
Q Predictions Max            2411.2268
Q Predictions Min            18.290972
V Predictions Mean           2005.2251
V Predictions Std            599.23285
V Predictions Max            2405.1477
V Predictions Min            61.92027
Log Pis Mean                 -1.9765116
Log Pis Std                  6.3687787
Log Pis Max                  34.24861
Log Pis Min                  -17.488571
Policy mu Mean               0.043306187
Policy mu Std                0.8934107
Policy mu Max                3.716124
Policy mu Min                -3.6903894
Policy log std Mean          -0.33587024
Policy log std Std           0.14647402
Policy log std Max           0.19081184
Policy log std Min           -1.072175
Z mean eval                  0.097137816
Z variance eval              0.014390145
total_rewards                [5320.95614941 5300.37416198 5275.64912108 5240.10871972 5233.61427629
 5218.45337848 5305.89140117 5223.28916387 2397.77215768 5298.61225895]
total_rewards_mean           4981.472078862162
total_rewards_std            861.9700352588434
total_rewards_max            5320.956149409485
total_rewards_min            2397.7721576822205
Number of train steps total  624000
Number of env steps total    835099
Number of rollouts total     0
Train Time (s)               130.21364775800612
(Previous) Eval Time (s)     22.88395531300921
Sample Time (s)              8.477929104003124
Epoch Time (s)               161.57553217501845
Total Train Time (s)         23946.810008002736
Epoch                        155
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 02:57:40.136982 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #155 | Epoch Duration: 162.77829241752625
2020-01-06 02:57:40.137131 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #155 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14582615
Z variance train             0.014392887
KL Divergence                8.225229
KL Loss                      0.82252294
QF Loss                      2853.0137
VF Loss                      875.01965
Policy Loss                  -1954.824
Q Predictions Mean           1939.5334
Q Predictions Std            622.0356
Q Predictions Max            2397.3887
Q Predictions Min            41.05939
V Predictions Mean           1959.2671
V Predictions Std            620.01117
V Predictions Max            2406.1882
V Predictions Min            12.399147
Log Pis Mean                 -1.6794218
Log Pis Std                  6.4679537
Log Pis Max                  25.242134
Log Pis Min                  -14.833389
Policy mu Mean               0.077173695
Policy mu Std                0.91166717
Policy mu Max                2.6901605
Policy mu Min                -3.2962046
Policy log std Mean          -0.33893853
Policy log std Std           0.14632039
Policy log std Max           0.034479976
Policy log std Min           -1.1474631
Z mean eval                  0.11782092
Z variance eval              0.012513909
total_rewards                [5146.33922289 5183.18916729 5168.30910608 5100.40795342 5160.80343819
 5151.65312361 4918.89529344 5107.2807737  5134.98634283 5149.40326951]
total_rewards_mean           5122.126769093866
total_rewards_std            71.91653309733083
total_rewards_max            5183.189167289587
total_rewards_min            4918.895293435481
Number of train steps total  628000
Number of env steps total    840099
Number of rollouts total     0
Train Time (s)               121.86640669498593
(Previous) Eval Time (s)     24.086463879037183
Sample Time (s)              8.400254432926886
Epoch Time (s)               154.35312500695
Total Train Time (s)         24103.302657653694
Epoch                        156
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 03:00:16.631918 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #156 | Epoch Duration: 156.4946644306183
2020-01-06 03:00:16.632099 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #156 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1449602
Z variance train             0.0110342335
KL Divergence                8.877642
KL Loss                      0.88776416
QF Loss                      2405.1604
VF Loss                      986.1726
Policy Loss                  -1935.6958
Q Predictions Mean           1932.229
Q Predictions Std            677.9839
Q Predictions Max            2409.71
Q Predictions Min            29.441566
V Predictions Mean           1954.253
V Predictions Std            675.28455
V Predictions Max            2452.3
V Predictions Min            59.035336
Log Pis Mean                 -1.9013536
Log Pis Std                  6.4691668
Log Pis Max                  23.79852
Log Pis Min                  -13.440119
Policy mu Mean               0.08669382
Policy mu Std                0.8803095
Policy mu Max                3.7455158
Policy mu Min                -3.7741892
Policy log std Mean          -0.33549622
Policy log std Std           0.14730506
Policy log std Max           -0.021805868
Policy log std Min           -1.1240468
Z mean eval                  0.123988345
Z variance eval              0.010072803
total_rewards                [5337.26105176 5264.28645477 5334.77591841 5305.22272202 5080.33767252
 5262.20973074 5266.43750023 5186.86590518 5267.33535519 5194.07501761]
total_rewards_mean           5249.880732841716
total_rewards_std            73.9415738915829
total_rewards_max            5337.2610517567255
total_rewards_min            5080.3376725175685
Number of train steps total  632000
Number of env steps total    845263
Number of rollouts total     0
Train Time (s)               127.15623770095408
(Previous) Eval Time (s)     26.227739513036795
Sample Time (s)              8.419223007978871
Epoch Time (s)               161.80320022196975
Total Train Time (s)         24265.650897659652
Epoch                        157
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 03:02:58.982849 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #157 | Epoch Duration: 162.3506212234497
2020-01-06 03:02:58.982977 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #157 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14856192
Z variance train             0.010935238
KL Divergence                8.899578
KL Loss                      0.88995785
QF Loss                      2319.4683
VF Loss                      1130.082
Policy Loss                  -1991.9501
Q Predictions Mean           1976.1631
Q Predictions Std            629.2721
Q Predictions Max            2416.6394
Q Predictions Min            61.86634
V Predictions Mean           1984.9902
V Predictions Std            627.853
V Predictions Max            2426.2583
V Predictions Min            49.71549
Log Pis Mean                 -2.5912197
Log Pis Std                  6.7147985
Log Pis Max                  29.01186
Log Pis Min                  -15.607094
Policy mu Mean               0.07212019
Policy mu Std                0.8803744
Policy mu Max                3.6988802
Policy mu Min                -2.833134
Policy log std Mean          -0.32474118
Policy log std Std           0.14638196
Policy log std Max           -0.007974058
Policy log std Min           -1.2113683
Z mean eval                  0.07742891
Z variance eval              0.0104415305
total_rewards                [5336.01720358 5266.78256079 5325.82537615 3452.12785997 5311.43501266
 5279.51343858 5244.32562853 5291.42933194 5343.841294   5275.3492345 ]
total_rewards_mean           5112.664694069376
total_rewards_std            554.3471055852626
total_rewards_max            5343.841293996496
total_rewards_min            3452.1278599663383
Number of train steps total  636000
Number of env steps total    850382
Number of rollouts total     0
Train Time (s)               125.07850849599345
(Previous) Eval Time (s)     26.774882994999643
Sample Time (s)              8.633810023136903
Epoch Time (s)               160.48720151413
Total Train Time (s)         24424.768427027797
Epoch                        158
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 03:05:38.102509 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #158 | Epoch Duration: 159.11943292617798
2020-01-06 03:05:38.102689 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #158 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.111303434
Z variance train             0.010847652
KL Divergence                8.886764
KL Loss                      0.88867635
QF Loss                      2182.88
VF Loss                      958.2099
Policy Loss                  -2010.0491
Q Predictions Mean           2009.3718
Q Predictions Std            644.1085
Q Predictions Max            2448.2878
Q Predictions Min            13.392646
V Predictions Mean           2005.1658
V Predictions Std            637.5347
V Predictions Max            2429.811
V Predictions Min            47.398922
Log Pis Mean                 -1.9030237
Log Pis Std                  6.0412374
Log Pis Max                  23.704172
Log Pis Min                  -14.372514
Policy mu Mean               0.10889521
Policy mu Std                0.8900538
Policy mu Max                2.6481793
Policy mu Min                -3.2545128
Policy log std Mean          -0.34166157
Policy log std Std           0.13931546
Policy log std Max           0.018500142
Policy log std Min           -0.93703187
Z mean eval                  0.19408952
Z variance eval              0.013529204
total_rewards                [5171.31025318 4183.94647955 5190.32661284 5182.1587507  5136.07766074
 5189.74822036 5119.98584387 5175.79006946 5208.67500686 3352.84019542]
total_rewards_mean           4891.085909296396
total_rewards_std            591.8255433826856
total_rewards_max            5208.675006857479
total_rewards_min            3352.8401954172195
Number of train steps total  640000
Number of env steps total    855382
Number of rollouts total     0
Train Time (s)               125.63886546797585
(Previous) Eval Time (s)     25.406848770042416
Sample Time (s)              8.715829015127383
Epoch Time (s)               159.76154325314565
Total Train Time (s)         24584.06843062601
Epoch                        159
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 03:08:17.403430 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #159 | Epoch Duration: 159.30060839653015
2020-01-06 03:08:17.403603 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #159 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09619154
Z variance train             0.011179905
KL Divergence                8.807411
KL Loss                      0.8807411
QF Loss                      2058.2417
VF Loss                      883.5262
Policy Loss                  -1995.4761
Q Predictions Mean           1988.2148
Q Predictions Std            664.95496
Q Predictions Max            2442.5007
Q Predictions Min            47.50937
V Predictions Mean           1993.821
V Predictions Std            656.9229
V Predictions Max            2450.485
V Predictions Min            70.355095
Log Pis Mean                 -1.8078411
Log Pis Std                  6.839558
Log Pis Max                  30.977146
Log Pis Min                  -13.674169
Policy mu Mean               0.059402257
Policy mu Std                0.9072558
Policy mu Max                3.5381365
Policy mu Min                -4.3698435
Policy log std Mean          -0.3430058
Policy log std Std           0.15769134
Policy log std Max           0.2209026
Policy log std Min           -1.5783166
Z mean eval                  0.038076617
Z variance eval              0.0126598505
total_rewards                [5198.22611072 5109.26132932 5123.43228958 5173.82000791 1203.38644999
 5230.19463714 5175.28235071 5177.89114038 5169.96365753 5040.81372647]
total_rewards_mean           4760.227169975604
total_rewards_std            1186.6742197687454
total_rewards_max            5230.194637136312
total_rewards_min            1203.386449994261
Number of train steps total  644000
Number of env steps total    860382
Number of rollouts total     0
Train Time (s)               128.05618354596663
(Previous) Eval Time (s)     24.945660697005223
Sample Time (s)              8.38091586396331
Epoch Time (s)               161.38276010693517
Total Train Time (s)         24744.67350641894
Epoch                        160
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 03:10:58.010568 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #160 | Epoch Duration: 160.6068365573883
2020-01-06 03:10:58.010704 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #160 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09417808
Z variance train             0.013874715
KL Divergence                8.269012
KL Loss                      0.82690126
QF Loss                      2564.0522
VF Loss                      1072.1508
Policy Loss                  -1966.4095
Q Predictions Mean           1970.4932
Q Predictions Std            662.67914
Q Predictions Max            2450.8542
Q Predictions Min            45.32605
V Predictions Mean           1977.4436
V Predictions Std            659.3854
V Predictions Max            2455.848
V Predictions Min            71.65571
Log Pis Mean                 -2.1606212
Log Pis Std                  6.3772507
Log Pis Max                  24.321453
Log Pis Min                  -15.044332
Policy mu Mean               0.060745113
Policy mu Std                0.88976455
Policy mu Max                3.428306
Policy mu Min                -3.2002618
Policy log std Mean          -0.32660192
Policy log std Std           0.14587206
Policy log std Max           0.03414677
Policy log std Min           -1.3040919
Z mean eval                  0.060650546
Z variance eval              0.023146294
total_rewards                [5154.52007045 5263.8856865  5214.0972933  5232.59356931 5294.95080038
 5060.99896784 1744.12984103 5084.80097926 5261.71928632  409.66588177]
total_rewards_mean           4372.136237616621
total_rewards_std            1675.994729549058
total_rewards_max            5294.95080037947
total_rewards_min            409.6658817669744
Number of train steps total  648000
Number of env steps total    865382
Number of rollouts total     0
Train Time (s)               136.1548491549911
(Previous) Eval Time (s)     24.169484428013675
Sample Time (s)              8.06620459095575
Epoch Time (s)               168.39053817396052
Total Train Time (s)         24911.615548449918
Epoch                        161
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 03:13:44.954635 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #161 | Epoch Duration: 166.94382166862488
2020-01-06 03:13:44.954804 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #161 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06810119
Z variance train             0.01625058
KL Divergence                7.8677454
KL Loss                      0.7867746
QF Loss                      2634.6228
VF Loss                      1456.53
Policy Loss                  -2024.5728
Q Predictions Mean           2015.6443
Q Predictions Std            604.4467
Q Predictions Max            2430.4136
Q Predictions Min            39.93987
V Predictions Mean           2016.8506
V Predictions Std            603.0396
V Predictions Max            2433.624
V Predictions Min            92.98181
Log Pis Mean                 -1.4907571
Log Pis Std                  7.1402555
Log Pis Max                  29.733442
Log Pis Min                  -13.642478
Policy mu Mean               0.08141481
Policy mu Std                0.92371273
Policy mu Max                3.831444
Policy mu Min                -4.243234
Policy log std Mean          -0.33855006
Policy log std Std           0.15242015
Policy log std Max           0.02616258
Policy log std Min           -1.2745175
Z mean eval                  0.033349887
Z variance eval              0.041990265
total_rewards                [5280.77086771 5227.60526351 5143.4977133  5305.23529458 5269.252478
 5158.77687293 5238.57153566 5221.97441038 5216.05838087 5242.86311534]
total_rewards_mean           5230.460593227651
total_rewards_std            47.786494029479144
total_rewards_max            5305.235294584481
total_rewards_min            5143.49771329591
Number of train steps total  652000
Number of env steps total    870587
Number of rollouts total     0
Train Time (s)               133.58285750600044
(Previous) Eval Time (s)     22.72250279603759
Sample Time (s)              9.10190897504799
Epoch Time (s)               165.40726927708602
Total Train Time (s)         25082.507211506017
Epoch                        162
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 03:16:35.847773 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #162 | Epoch Duration: 170.8928472995758
2020-01-06 03:16:35.847891 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #162 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026116934
Z variance train             0.029066015
KL Divergence                6.4320016
KL Loss                      0.64320016
QF Loss                      2281.572
VF Loss                      985.94244
Policy Loss                  -1978.2921
Q Predictions Mean           1975.5164
Q Predictions Std            672.7082
Q Predictions Max            2452.2832
Q Predictions Min            45.990387
V Predictions Mean           1984.9171
V Predictions Std            661.9044
V Predictions Max            2457.4863
V Predictions Min            37.439407
Log Pis Mean                 -1.3544898
Log Pis Std                  6.9836054
Log Pis Max                  29.676464
Log Pis Min                  -12.866681
Policy mu Mean               0.07521367
Policy mu Std                0.9208028
Policy mu Max                2.9017804
Policy mu Min                -3.567353
Policy log std Mean          -0.3423164
Policy log std Std           0.14620812
Policy log std Max           -0.0059856772
Policy log std Min           -1.105898
Z mean eval                  0.039040454
Z variance eval              0.045856677
total_rewards                [5326.9214251  5289.0395211  4875.46489946 5193.49771042 4771.50265881
 5321.54405497 5312.20192132 4360.65434811 5258.76712809 5284.19983713]
total_rewards_mean           5099.379350452186
total_rewards_std            308.8970306888679
total_rewards_max            5326.921425100015
total_rewards_min            4360.654348105926
Number of train steps total  656000
Number of env steps total    875587
Number of rollouts total     0
Train Time (s)               137.07510373397963
(Previous) Eval Time (s)     28.20784366299631
Sample Time (s)              8.667425429041032
Epoch Time (s)               173.95037282601697
Total Train Time (s)         25255.00415303599
Epoch                        163
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 03:19:28.346945 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #163 | Epoch Duration: 172.49895000457764
2020-01-06 03:19:28.347065 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #163 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05034993
Z variance train             0.035621107
KL Divergence                5.94763
KL Loss                      0.594763
QF Loss                      2515.3218
VF Loss                      1082.0692
Policy Loss                  -1929.1282
Q Predictions Mean           1921.328
Q Predictions Std            705.30475
Q Predictions Max            2466.5486
Q Predictions Min            71.88218
V Predictions Mean           1922.9766
V Predictions Std            687.8088
V Predictions Max            2446.2454
V Predictions Min            103.60488
Log Pis Mean                 -2.0755687
Log Pis Std                  6.24773
Log Pis Max                  30.6776
Log Pis Min                  -13.96652
Policy mu Mean               0.110065095
Policy mu Std                0.8913657
Policy mu Max                3.5620332
Policy mu Min                -3.4914072
Policy log std Mean          -0.33705392
Policy log std Std           0.15244792
Policy log std Max           0.027384415
Policy log std Min           -1.1081609
Z mean eval                  0.12592034
Z variance eval              0.058938466
total_rewards                [5243.55661421 5107.39095123 5114.08519224 5197.05238654 5159.31975232
 5221.01755435 5238.16315389 5128.76836345 5175.8607437  5100.47479739]
total_rewards_mean           5168.568950932366
total_rewards_std            52.057190538834526
total_rewards_max            5243.556614205541
total_rewards_min            5100.474797394722
Number of train steps total  660000
Number of env steps total    880587
Number of rollouts total     0
Train Time (s)               134.03998085600324
(Previous) Eval Time (s)     26.75616444903426
Sample Time (s)              8.325582836871035
Epoch Time (s)               169.12172814190853
Total Train Time (s)         25423.432596648927
Epoch                        164
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 03:22:16.776856 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #164 | Epoch Duration: 168.42969346046448
2020-01-06 03:22:16.776979 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #164 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.052226804
Z variance train             0.032863356
KL Divergence                6.141863
KL Loss                      0.6141863
QF Loss                      1928.7222
VF Loss                      928.5044
Policy Loss                  -2015.2335
Q Predictions Mean           2016.3851
Q Predictions Std            640.6364
Q Predictions Max            2466.1577
Q Predictions Min            57.979603
V Predictions Mean           2016.4426
V Predictions Std            637.94885
V Predictions Max            2464.1194
V Predictions Min            41.56672
Log Pis Mean                 -3.1229396
Log Pis Std                  5.3995976
Log Pis Max                  21.503695
Log Pis Min                  -13.335673
Policy mu Mean               0.074701115
Policy mu Std                0.8461771
Policy mu Max                3.6724968
Policy mu Min                -3.3465133
Policy log std Mean          -0.3224725
Policy log std Std           0.13089825
Policy log std Max           -0.02442436
Policy log std Min           -1.0453262
Z mean eval                  0.22468427
Z variance eval              0.024944345
total_rewards                [5274.96484846 5244.23652281 5284.42189049 1385.87432115 5239.7717359
 5302.8085056  5262.37429683 5230.31181195 5172.68733281 5220.65539618]
total_rewards_mean           4861.810666218023
total_rewards_std            1159.1665738418603
total_rewards_max            5302.808505604715
total_rewards_min            1385.874321147432
Number of train steps total  664000
Number of env steps total    885587
Number of rollouts total     0
Train Time (s)               122.57442666898714
(Previous) Eval Time (s)     26.063853440980893
Sample Time (s)              8.400641089014243
Epoch Time (s)               157.03892119898228
Total Train Time (s)         25578.932890533935
Epoch                        165
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 03:24:52.279748 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #165 | Epoch Duration: 155.50266480445862
2020-01-06 03:24:52.279891 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #165 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.17589267
Z variance train             0.044886943
KL Divergence                5.4813137
KL Loss                      0.5481314
QF Loss                      2658.4678
VF Loss                      629.7808
Policy Loss                  -1996.8286
Q Predictions Mean           1994.8146
Q Predictions Std            629.6396
Q Predictions Max            2448.475
Q Predictions Min            68.01946
V Predictions Mean           1991.1096
V Predictions Std            628.47296
V Predictions Max            2444.8936
V Predictions Min            71.18725
Log Pis Mean                 -1.5340389
Log Pis Std                  6.982054
Log Pis Max                  26.15052
Log Pis Min                  -15.516131
Policy mu Mean               0.065534756
Policy mu Std                0.9137436
Policy mu Max                3.811965
Policy mu Min                -3.6366017
Policy log std Mean          -0.33853886
Policy log std Std           0.15080102
Policy log std Max           0.32408664
Policy log std Min           -1.2211901
Z mean eval                  0.2660349
Z variance eval              0.040887225
total_rewards                [ 950.40379471 5173.64778893 5200.37652085 1838.29368879 5193.73086023
 5231.99215009 5203.05003855 4435.9892651  5173.89362287 4664.2544519 ]
total_rewards_mean           4306.563218201792
total_rewards_std            1491.677858041224
total_rewards_max            5231.99215008655
total_rewards_min            950.4037947097795
Number of train steps total  668000
Number of env steps total    890587
Number of rollouts total     0
Train Time (s)               127.69878982804948
(Previous) Eval Time (s)     24.527340219006874
Sample Time (s)              8.32979409804102
Epoch Time (s)               160.55592414509738
Total Train Time (s)         25737.4748031341
Epoch                        166
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 03:27:30.823819 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #166 | Epoch Duration: 158.5438096523285
2020-01-06 03:27:30.823980 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #166 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.33143035
Z variance train             0.034455962
KL Divergence                6.3927073
KL Loss                      0.6392707
QF Loss                      2551.9883
VF Loss                      1076.9357
Policy Loss                  -2069.951
Q Predictions Mean           2062.6516
Q Predictions Std            583.1302
Q Predictions Max            2459.3618
Q Predictions Min            42.853176
V Predictions Mean           2070.751
V Predictions Std            583.9516
V Predictions Max            2470.0974
V Predictions Min            12.027913
Log Pis Mean                 -1.67061
Log Pis Std                  6.496173
Log Pis Max                  26.138203
Log Pis Min                  -14.587203
Policy mu Mean               0.071577676
Policy mu Std                0.8958987
Policy mu Max                3.3171914
Policy mu Min                -3.5252883
Policy log std Mean          -0.3371438
Policy log std Std           0.14843583
Policy log std Max           0.009059265
Policy log std Min           -1.0234123
Z mean eval                  0.47780007
Z variance eval              0.0651529
total_rewards                [5299.06230871 2368.25936708 5286.3909573  5334.563082   5302.26688681
 5311.33293985 5388.21938034 5258.25252075 5316.08896523 5309.90127622]
total_rewards_mean           5017.433768429672
total_rewards_std            883.6324492609456
total_rewards_max            5388.219380340418
total_rewards_min            2368.2593670831034
Number of train steps total  672000
Number of env steps total    895587
Number of rollouts total     0
Train Time (s)               122.17351307196077
(Previous) Eval Time (s)     22.514976485981606
Sample Time (s)              8.265416781010572
Epoch Time (s)               152.95390633895295
Total Train Time (s)         25892.922353465052
Epoch                        167
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 03:30:06.273413 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #167 | Epoch Duration: 155.44931840896606
2020-01-06 03:30:06.273538 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #167 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.3253792
Z variance train             0.027468722
KL Divergence                6.93796
KL Loss                      0.69379604
QF Loss                      2627.3833
VF Loss                      1560.1729
Policy Loss                  -2075.1062
Q Predictions Mean           2070.605
Q Predictions Std            595.90753
Q Predictions Max            2462.211
Q Predictions Min            52.279556
V Predictions Mean           2075.816
V Predictions Std            599.1156
V Predictions Max            2456.5996
V Predictions Min            14.592705
Log Pis Mean                 -2.0199313
Log Pis Std                  6.5921006
Log Pis Max                  34.642498
Log Pis Min                  -15.917203
Policy mu Mean               0.10470866
Policy mu Std                0.8857225
Policy mu Max                3.4176397
Policy mu Min                -3.5109744
Policy log std Mean          -0.3346965
Policy log std Std           0.15152052
Policy log std Max           -0.016490296
Policy log std Min           -1.3438492
Z mean eval                  0.6390654
Z variance eval              0.06296781
total_rewards                [5065.7146189  5146.70340658 5148.10838678 5207.41742868 5191.78957097
 5204.79825391 5141.41710019 5195.59349041 5147.88137658 5158.35146508]
total_rewards_mean           5160.777509808144
total_rewards_std            40.28594057383954
total_rewards_max            5207.417428680564
total_rewards_min            5065.714618902966
Number of train steps total  676000
Number of env steps total    900694
Number of rollouts total     0
Train Time (s)               125.84944755199831
(Previous) Eval Time (s)     25.010144061001483
Sample Time (s)              8.409453119907994
Epoch Time (s)               159.2690447329078
Total Train Time (s)         26054.869083283003
Epoch                        168
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 03:32:48.221911 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #168 | Epoch Duration: 161.94826817512512
2020-01-06 03:32:48.222066 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #168 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.5860617
Z variance train             0.09136596
KL Divergence                4.895838
KL Loss                      0.4895838
QF Loss                      2165.0913
VF Loss                      617.28577
Policy Loss                  -2045.3666
Q Predictions Mean           2047.5564
Q Predictions Std            634.8196
Q Predictions Max            2488.2598
Q Predictions Min            12.441191
V Predictions Mean           2036.3911
V Predictions Std            629.8183
V Predictions Max            2468.1052
V Predictions Min            -5.7396564
Log Pis Mean                 -2.4425874
Log Pis Std                  6.0016556
Log Pis Max                  25.024837
Log Pis Min                  -15.382903
Policy mu Mean               0.073592156
Policy mu Std                0.8703652
Policy mu Max                3.1915889
Policy mu Min                -3.3992908
Policy log std Mean          -0.3219209
Policy log std Std           0.13734691
Policy log std Max           0.073480144
Policy log std Min           -0.986632
Z mean eval                  0.14722961
Z variance eval              0.056488298
total_rewards                [5303.49914542 5225.48354517 5296.14971001 5218.8316625  5293.01418846
 2982.79777332 5243.13263243 5178.30014177 5243.27717256 5271.19370539]
total_rewards_mean           5025.567967703323
total_rewards_std            681.9534926910311
total_rewards_max            5303.4991454168
total_rewards_min            2982.7977733216376
Number of train steps total  680000
Number of env steps total    905694
Number of rollouts total     0
Train Time (s)               122.05308383400552
(Previous) Eval Time (s)     27.689103976998013
Sample Time (s)              8.728874593100045
Epoch Time (s)               158.47106240410358
Total Train Time (s)         26213.24551087717
Epoch                        169
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 03:35:26.600209 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #169 | Epoch Duration: 158.3780233860016
2020-01-06 03:35:26.600331 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #169 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.107545875
Z variance train             0.031155776
KL Divergence                6.303775
KL Loss                      0.6303775
QF Loss                      2469.799
VF Loss                      874.541
Policy Loss                  -2061.568
Q Predictions Mean           2062.5913
Q Predictions Std            567.66473
Q Predictions Max            2457.3015
Q Predictions Min            69.98876
V Predictions Mean           2071.4753
V Predictions Std            565.2566
V Predictions Max            2458.9722
V Predictions Min            30.710052
Log Pis Mean                 -1.6788425
Log Pis Std                  6.2836185
Log Pis Max                  21.674065
Log Pis Min                  -13.144779
Policy mu Mean               0.052371893
Policy mu Std                0.89596033
Policy mu Max                3.1186905
Policy mu Min                -3.590735
Policy log std Mean          -0.33798096
Policy log std Std           0.14366257
Policy log std Max           0.088725716
Policy log std Min           -1.0082594
Z mean eval                  0.2005625
Z variance eval              0.033990428
total_rewards                [3148.44478481 5326.53706084 5301.97096026 5333.82130217 5289.33270052
 5295.00668371 5314.15986638 3485.19264863 5361.60979398 5314.7231679 ]
total_rewards_mean           4917.0798969197895
total_rewards_std            803.9055453613751
total_rewards_max            5361.609793978197
total_rewards_min            3148.444784805289
Number of train steps total  684000
Number of env steps total    910694
Number of rollouts total     0
Train Time (s)               131.64626334398054
(Previous) Eval Time (s)     27.59581834200071
Sample Time (s)              8.408765819040127
Epoch Time (s)               167.65084750502137
Total Train Time (s)         26377.9774339
Epoch                        170
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 03:38:11.335173 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #170 | Epoch Duration: 164.7347400188446
2020-01-06 03:38:11.335361 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #170 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1721299
Z variance train             0.035982173
KL Divergence                6.0454593
KL Loss                      0.60454595
QF Loss                      2619.395
VF Loss                      859.4796
Policy Loss                  -2057.9336
Q Predictions Mean           2054.4895
Q Predictions Std            625.5552
Q Predictions Max            2468.9497
Q Predictions Min            45.951153
V Predictions Mean           2046.3281
V Predictions Std            622.9628
V Predictions Max            2457.4097
V Predictions Min            -0.72621226
Log Pis Mean                 -2.3823438
Log Pis Std                  5.2278495
Log Pis Max                  18.01927
Log Pis Min                  -16.65036
Policy mu Mean               0.0753045
Policy mu Std                0.8728598
Policy mu Max                2.574057
Policy mu Min                -2.5386243
Policy log std Mean          -0.33556613
Policy log std Std           0.13692875
Policy log std Max           0.0010514855
Policy log std Min           -1.065215
Z mean eval                  0.18570624
Z variance eval              0.019427598
total_rewards                [5264.51021886 5225.44754871 5245.13283064 5299.77576007 5282.20362049
 5276.58098545 5260.85560969 5140.42633508 5320.79093993 5260.99760262]
total_rewards_mean           5257.672145154464
total_rewards_std            46.61139939664369
total_rewards_max            5320.790939929384
total_rewards_min            5140.426335075751
Number of train steps total  688000
Number of env steps total    915694
Number of rollouts total     0
Train Time (s)               138.13054802297847
(Previous) Eval Time (s)     24.679443787958007
Sample Time (s)              8.3218249779311
Epoch Time (s)               171.13181678886758
Total Train Time (s)         26550.98641245585
Epoch                        171
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 03:41:04.345761 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #171 | Epoch Duration: 173.01025533676147
2020-01-06 03:41:04.345882 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #171 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09995486
Z variance train             0.022101633
KL Divergence                7.135659
KL Loss                      0.71356595
QF Loss                      2336.9666
VF Loss                      1037.3956
Policy Loss                  -2067.1138
Q Predictions Mean           2057.5913
Q Predictions Std            591.0871
Q Predictions Max            2471.1724
Q Predictions Min            39.68367
V Predictions Mean           2069.686
V Predictions Std            592.71796
V Predictions Max            2476.9568
V Predictions Min            58.992825
Log Pis Mean                 -1.9813459
Log Pis Std                  6.1476893
Log Pis Max                  22.789654
Log Pis Min                  -13.772013
Policy mu Mean               0.034206614
Policy mu Std                0.87067336
Policy mu Max                2.7091331
Policy mu Min                -3.2912092
Policy log std Mean          -0.3203855
Policy log std Std           0.14187197
Policy log std Max           0.14512065
Policy log std Min           -1.0135483
Z mean eval                  0.0844866
Z variance eval              0.017059531
total_rewards                [5125.66176122 1199.64011324 5337.67530507 5323.99838133 5248.54452234
 1222.46740105 5309.4379266  1845.79001464 5287.54643051 5420.45243544]
total_rewards_mean           4132.121429143688
total_rewards_std            1782.7275773506244
total_rewards_max            5420.452435441906
total_rewards_min            1199.6401132359774
Number of train steps total  692000
Number of env steps total    920694
Number of rollouts total     0
Train Time (s)               122.13613743399037
(Previous) Eval Time (s)     26.5576414350071
Sample Time (s)              8.859816232055891
Epoch Time (s)               157.55359510105336
Total Train Time (s)         26702.600734838867
Epoch                        172
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 03:43:35.962378 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #172 | Epoch Duration: 151.61640095710754
2020-01-06 03:43:35.962533 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #172 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.17707965
Z variance train             0.016839925
KL Divergence                7.8663993
KL Loss                      0.7866399
QF Loss                      1627.0867
VF Loss                      611.5365
Policy Loss                  -2028.7881
Q Predictions Mean           2027.3998
Q Predictions Std            660.7468
Q Predictions Max            2484.9065
Q Predictions Min            41.79606
V Predictions Mean           2030.2603
V Predictions Std            657.7308
V Predictions Max            2477.5127
V Predictions Min            29.399199
Log Pis Mean                 -2.0203884
Log Pis Std                  5.7956533
Log Pis Max                  21.498293
Log Pis Min                  -13.933651
Policy mu Mean               0.10423694
Policy mu Std                0.87517875
Policy mu Max                2.906528
Policy mu Min                -3.1337752
Policy log std Mean          -0.3364737
Policy log std Std           0.14627858
Policy log std Max           -0.011675864
Policy log std Min           -1.0475215
Z mean eval                  0.05545063
Z variance eval              0.017642971
total_rewards                [5319.14530775 5342.99629952 5297.81620969 3375.92503774 5264.69534933
 5296.42368772 5299.69746903 5253.98476133 2283.94849959 3748.05916186]
total_rewards_mean           4648.269178354835
total_rewards_std            1047.1493463405104
total_rewards_max            5342.996299520242
total_rewards_min            2283.9484995851744
Number of train steps total  696000
Number of env steps total    925694
Number of rollouts total     0
Train Time (s)               114.45459433301585
(Previous) Eval Time (s)     20.62019434897229
Sample Time (s)              8.301972954010125
Epoch Time (s)               143.37676163599826
Total Train Time (s)         26846.45008552278
Epoch                        173
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 03:45:59.813314 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #173 | Epoch Duration: 143.85067558288574
2020-01-06 03:45:59.813430 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #173 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1010019
Z variance train             0.020525277
KL Divergence                7.3182793
KL Loss                      0.7318279
QF Loss                      1524.6562
VF Loss                      656.76135
Policy Loss                  -2064.281
Q Predictions Mean           2061.2078
Q Predictions Std            628.37585
Q Predictions Max            2476.4792
Q Predictions Min            68.7999
V Predictions Mean           2065.479
V Predictions Std            628.9877
V Predictions Max            2485.4875
V Predictions Min            86.86528
Log Pis Mean                 -2.784525
Log Pis Std                  5.7464123
Log Pis Max                  24.270653
Log Pis Min                  -13.593924
Policy mu Mean               0.06366397
Policy mu Std                0.8588895
Policy mu Max                3.1267033
Policy mu Min                -2.862945
Policy log std Mean          -0.3297541
Policy log std Std           0.13815714
Policy log std Max           -0.0005007386
Policy log std Min           -1.0424325
Z mean eval                  0.05924811
Z variance eval              0.023228098
total_rewards                [5251.23689391 5318.27056809 5346.55234299 2692.04841023 5280.16093779
 5265.43248354 5250.67900023 5314.88958622 5228.51980716 5287.74435804]
total_rewards_mean           5023.5534388213455
total_rewards_std            777.9180958561698
total_rewards_max            5346.552342989133
total_rewards_min            2692.0484102346213
Number of train steps total  700000
Number of env steps total    930809
Number of rollouts total     0
Train Time (s)               117.41987668600632
(Previous) Eval Time (s)     21.093856692954432
Sample Time (s)              8.411679620097857
Epoch Time (s)               146.9254129990586
Total Train Time (s)         26996.86524495686
Epoch                        174
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 03:48:30.230914 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #174 | Epoch Duration: 150.4173891544342
2020-01-06 03:48:30.231045 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #174 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0657167
Z variance train             0.022814061
KL Divergence                7.038786
KL Loss                      0.7038786
QF Loss                      2213.8408
VF Loss                      1742.2683
Policy Loss                  -2145.9243
Q Predictions Mean           2142.7012
Q Predictions Std            528.63995
Q Predictions Max            2469.1313
Q Predictions Min            59.114357
V Predictions Mean           2165.6553
V Predictions Std            529.8608
V Predictions Max            2508.6418
V Predictions Min            75.83516
Log Pis Mean                 -2.5585158
Log Pis Std                  5.9091887
Log Pis Max                  34.42939
Log Pis Min                  -13.8009815
Policy mu Mean               0.1216016
Policy mu Std                0.8556771
Policy mu Max                3.8383205
Policy mu Min                -3.183251
Policy log std Mean          -0.32658777
Policy log std Std           0.13946277
Policy log std Max           0.010969698
Policy log std Min           -1.3252429
Z mean eval                  0.15915616
Z variance eval              0.022535162
total_rewards                [5364.99543924 5293.63582015 5348.12968019 1835.8461351  5270.67573439
 5399.03591416 5343.61602187 5351.03910375 5262.72087705 5328.58860719]
total_rewards_mean           4979.828333308737
total_rewards_std            1048.77198799231
total_rewards_max            5399.035914163144
total_rewards_min            1835.8461351032954
Number of train steps total  704000
Number of env steps total    935809
Number of rollouts total     0
Train Time (s)               122.053977322008
(Previous) Eval Time (s)     24.585585096967407
Sample Time (s)              8.40353865805082
Epoch Time (s)               155.04310107702622
Total Train Time (s)         27151.18438139587
Epoch                        175
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 03:51:04.551802 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #175 | Epoch Duration: 154.32066011428833
2020-01-06 03:51:04.551927 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #175 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05677808
Z variance train             0.025841702
KL Divergence                6.731242
KL Loss                      0.67312425
QF Loss                      2196.68
VF Loss                      949.2924
Policy Loss                  -2061.0981
Q Predictions Mean           2059.3706
Q Predictions Std            608.76465
Q Predictions Max            2492.1458
Q Predictions Min            50.470436
V Predictions Mean           2060.3745
V Predictions Std            605.6158
V Predictions Max            2488.0232
V Predictions Min            111.31572
Log Pis Mean                 -1.6293521
Log Pis Std                  6.664908
Log Pis Max                  28.318958
Log Pis Min                  -13.108142
Policy mu Mean               0.053557426
Policy mu Std                0.9121637
Policy mu Max                3.0896761
Policy mu Min                -3.2326653
Policy log std Mean          -0.33669424
Policy log std Std           0.15007584
Policy log std Max           0.013662294
Policy log std Min           -1.1685418
Z mean eval                  0.04253425
Z variance eval              0.024218082
total_rewards                [5285.99859027 5356.98212965 5311.34364383 5275.6830889  5155.53999596
 5276.54821273 5281.04868862 5247.16598791 1131.32508046 5248.92141395]
total_rewards_mean           4857.055683226541
total_rewards_std            1242.8674581903138
total_rewards_max            5356.982129652666
total_rewards_min            1131.3250804573422
Number of train steps total  708000
Number of env steps total    940809
Number of rollouts total     0
Train Time (s)               125.71834775997559
(Previous) Eval Time (s)     23.862889365991578
Sample Time (s)              8.297398020979017
Epoch Time (s)               157.87863514694618
Total Train Time (s)         27309.182317580853
Epoch                        176
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 03:53:42.551322 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #176 | Epoch Duration: 157.99930095672607
2020-01-06 03:53:42.551466 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #176 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05422104
Z variance train             0.021149945
KL Divergence                7.2173886
KL Loss                      0.7217389
QF Loss                      1783.6183
VF Loss                      1361.6102
Policy Loss                  -2025.6622
Q Predictions Mean           2024.7935
Q Predictions Std            672.8782
Q Predictions Max            2496.7402
Q Predictions Min            36.417656
V Predictions Mean           2028.841
V Predictions Std            672.434
V Predictions Max            2505.2102
V Predictions Min            71.198586
Log Pis Mean                 -2.457487
Log Pis Std                  5.971228
Log Pis Max                  26.398067
Log Pis Min                  -12.480785
Policy mu Mean               0.09077898
Policy mu Std                0.86437714
Policy mu Max                3.2160926
Policy mu Min                -3.799736
Policy log std Mean          -0.32923767
Policy log std Std           0.14785449
Policy log std Max           0.016459748
Policy log std Min           -1.0610292
Z mean eval                  0.061296035
Z variance eval              0.018676488
total_rewards                [5250.54988148 2678.92789376 5285.52788426 5296.33660374 5231.89311471
 4175.73970397 4989.63054092 5244.51827793 5277.93788732 5345.32683814]
total_rewards_mean           4877.638862622662
total_rewards_std            803.7005849220351
total_rewards_max            5345.326838143521
total_rewards_min            2678.9278937560734
Number of train steps total  712000
Number of env steps total    945809
Number of rollouts total     0
Train Time (s)               131.38269475102425
(Previous) Eval Time (s)     23.98330184700899
Sample Time (s)              8.404732528026216
Epoch Time (s)               163.77072912605945
Total Train Time (s)         27474.049957773997
Epoch                        177
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 03:56:27.420948 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #177 | Epoch Duration: 164.86935806274414
2020-01-06 03:56:27.421065 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #177 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10548116
Z variance train             0.02935039
KL Divergence                6.444252
KL Loss                      0.6444252
QF Loss                      2332.1394
VF Loss                      1145.5284
Policy Loss                  -2037.8651
Q Predictions Mean           2035.0891
Q Predictions Std            673.046
Q Predictions Max            2466.5305
Q Predictions Min            31.195885
V Predictions Mean           2042.8496
V Predictions Std            674.24475
V Predictions Max            2487.6506
V Predictions Min            72.176636
Log Pis Mean                 -2.3648105
Log Pis Std                  5.661489
Log Pis Max                  25.118782
Log Pis Min                  -12.436364
Policy mu Mean               0.14604172
Policy mu Std                0.85407555
Policy mu Max                2.954556
Policy mu Min                -3.1674836
Policy log std Mean          -0.3343331
Policy log std Std           0.13917431
Policy log std Max           0.008531228
Policy log std Min           -0.98490834
Z mean eval                  0.16578639
Z variance eval              0.068189725
total_rewards                [3338.84861407 1692.5612427  5221.12660776 5278.61893383 3947.72100835
 5218.50866389 1958.88971385 1824.20014839 3270.62845037 5311.31675443]
total_rewards_mean           3706.242013765111
total_rewards_std            1437.4888152073065
total_rewards_max            5311.316754432503
total_rewards_min            1692.561242703952
Number of train steps total  716000
Number of env steps total    950809
Number of rollouts total     0
Train Time (s)               129.78595734998817
(Previous) Eval Time (s)     25.081698558002245
Sample Time (s)              8.599796731898095
Epoch Time (s)               163.4674526398885
Total Train Time (s)         27630.451002890768
Epoch                        178
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 03:59:03.824172 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #178 | Epoch Duration: 156.40297746658325
2020-01-06 03:59:03.824362 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #178 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14196941
Z variance train             0.10794224
KL Divergence                3.4490695
KL Loss                      0.34490696
QF Loss                      3063.4878
VF Loss                      1337.2252
Policy Loss                  -1979.1448
Q Predictions Mean           1976.7034
Q Predictions Std            690.5778
Q Predictions Max            2478.6094
Q Predictions Min            33.041027
V Predictions Mean           1982.641
V Predictions Std            700.8609
V Predictions Max            2485.2754
V Predictions Min            37.058784
Log Pis Mean                 -2.0187302
Log Pis Std                  6.8392005
Log Pis Max                  40.933624
Log Pis Min                  -13.214652
Policy mu Mean               0.09294744
Policy mu Std                0.89130735
Policy mu Max                3.7082763
Policy mu Min                -4.715099
Policy log std Mean          -0.32694143
Policy log std Std           0.15108603
Policy log std Max           0.06322588
Policy log std Min           -1.1514363
Z mean eval                  0.23751536
Z variance eval              0.041073292
total_rewards                [4616.60316059 5407.98005598 5274.70331541 5285.15286098 1367.95128309
 5384.36039341 5358.3119575  5349.40635637 1548.23365415 2356.48363742]
total_rewards_mean           4194.918667490926
total_rewards_std            1627.313987185941
total_rewards_max            5407.980055978182
total_rewards_min            1367.9512830949475
Number of train steps total  720000
Number of env steps total    955809
Number of rollouts total     0
Train Time (s)               128.35365439299494
(Previous) Eval Time (s)     18.016961962974165
Sample Time (s)              8.198455814097542
Epoch Time (s)               154.56907217006665
Total Train Time (s)         27787.626724296773
Epoch                        179
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 04:01:41.002248 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #179 | Epoch Duration: 157.1777377128601
2020-01-06 04:01:41.002427 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #179 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14204974
Z variance train             0.031432208
KL Divergence                6.309531
KL Loss                      0.63095313
QF Loss                      1867.8755
VF Loss                      1017.6544
Policy Loss                  -2072.6772
Q Predictions Mean           2071.864
Q Predictions Std            628.28156
Q Predictions Max            2484.8557
Q Predictions Min            36.66825
V Predictions Mean           2085.441
V Predictions Std            620.22876
V Predictions Max            2491.738
V Predictions Min            67.45539
Log Pis Mean                 -2.2267025
Log Pis Std                  5.8432817
Log Pis Max                  20.711037
Log Pis Min                  -13.251169
Policy mu Mean               0.08597687
Policy mu Std                0.8758263
Policy mu Max                2.9618738
Policy mu Min                -2.7604125
Policy log std Mean          -0.33247548
Policy log std Std           0.148172
Policy log std Max           0.04237418
Policy log std Min           -0.9792785
Z mean eval                  0.09246123
Z variance eval              0.042394746
total_rewards                [5339.06781696 5257.83520249 5184.45608614 5313.33988799 5205.22374088
 5262.82199421 5158.19332748 5241.4444616  2365.94068915 5332.65469288]
total_rewards_mean           4966.097789977046
total_rewards_std            868.6540536904192
total_rewards_max            5339.067816960943
total_rewards_min            2365.9406891519957
Number of train steps total  724000
Number of env steps total    960809
Number of rollouts total     0
Train Time (s)               133.59620905999327
(Previous) Eval Time (s)     20.62538563797716
Sample Time (s)              8.621029115049168
Epoch Time (s)               162.8426238130196
Total Train Time (s)         27954.409521091788
Epoch                        180
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 04:04:27.786594 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #180 | Epoch Duration: 166.78403186798096
2020-01-06 04:04:27.786726 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #180 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.071798034
Z variance train             0.056106888
KL Divergence                4.8773165
KL Loss                      0.48773167
QF Loss                      2381.1794
VF Loss                      646.2582
Policy Loss                  -2094.596
Q Predictions Mean           2095.1965
Q Predictions Std            631.07166
Q Predictions Max            2484.749
Q Predictions Min            86.84915
V Predictions Mean           2081.8503
V Predictions Std            625.3089
V Predictions Max            2487.9766
V Predictions Min            118.52959
Log Pis Mean                 -2.6865118
Log Pis Std                  6.6400757
Log Pis Max                  47.276043
Log Pis Min                  -15.443136
Policy mu Mean               0.051178675
Policy mu Std                0.8542821
Policy mu Max                3.7647676
Policy mu Min                -3.988457
Policy log std Mean          -0.31798923
Policy log std Std           0.13805518
Policy log std Max           0.1266164
Policy log std Min           -0.9529718
Z mean eval                  0.16122073
Z variance eval              0.028314728
total_rewards                [5151.37561804 5267.57628685 5230.85665471 5254.67644463 5152.5679327
 5251.71055201 3205.35918287 5208.53827991 5114.90944804 5240.01912639]
total_rewards_mean           5007.758952614783
total_rewards_std            602.8048552483301
total_rewards_max            5267.576286850005
total_rewards_min            3205.3591828672347
Number of train steps total  728000
Number of env steps total    965809
Number of rollouts total     0
Train Time (s)               130.76761350000743
(Previous) Eval Time (s)     24.56655555299949
Sample Time (s)              8.26830400887411
Epoch Time (s)               163.60247306188103
Total Train Time (s)         28119.47296134563
Epoch                        181
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 04:07:12.851761 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #181 | Epoch Duration: 165.06493830680847
2020-01-06 04:07:12.851878 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #181 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.23607412
Z variance train             0.04207693
KL Divergence                5.7209616
KL Loss                      0.57209617
QF Loss                      2557.5732
VF Loss                      1106.3776
Policy Loss                  -2108.6484
Q Predictions Mean           2098.29
Q Predictions Std            604.2647
Q Predictions Max            2502.8787
Q Predictions Min            66.10825
V Predictions Mean           2099.5288
V Predictions Std            604.5127
V Predictions Max            2489.88
V Predictions Min            9.661322
Log Pis Mean                 -1.5953082
Log Pis Std                  5.962477
Log Pis Max                  24.660286
Log Pis Min                  -14.679535
Policy mu Mean               0.057369635
Policy mu Std                0.9017593
Policy mu Max                3.895011
Policy mu Min                -2.548927
Policy log std Mean          -0.3411058
Policy log std Std           0.14097808
Policy log std Max           0.010607794
Policy log std Min           -1.0750562
Z mean eval                  0.15907747
Z variance eval              0.037575252
total_rewards                [5360.56776805 5302.57579992 5268.09232876 5308.82137422 5310.01941826
 5285.45431625 5386.13944589 5229.98258287 5285.26427527 5230.19153542]
total_rewards_mean           5296.710884492552
total_rewards_std            47.31553064108626
total_rewards_max            5386.139445891322
total_rewards_min            5229.9825828715975
Number of train steps total  732000
Number of env steps total    970809
Number of rollouts total     0
Train Time (s)               131.01359317300376
(Previous) Eval Time (s)     26.028757439984474
Sample Time (s)              8.823507959081326
Epoch Time (s)               165.86585857206956
Total Train Time (s)         28286.666763046698
Epoch                        182
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 04:10:00.048108 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #182 | Epoch Duration: 167.19611716270447
2020-01-06 04:10:00.048277 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #182 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07551237
Z variance train             0.030835724
KL Divergence                6.3094893
KL Loss                      0.63094896
QF Loss                      1913.0535
VF Loss                      967.9712
Policy Loss                  -2045.5168
Q Predictions Mean           2034.8523
Q Predictions Std            680.9735
Q Predictions Max            2504.4124
Q Predictions Min            28.761265
V Predictions Mean           2043.0955
V Predictions Std            675.7655
V Predictions Max            2511.7268
V Predictions Min            7.7191114
Log Pis Mean                 -2.1364675
Log Pis Std                  7.0745215
Log Pis Max                  43.83303
Log Pis Min                  -15.224871
Policy mu Mean               0.059943404
Policy mu Std                0.8859753
Policy mu Max                3.6878273
Policy mu Min                -3.5920382
Policy log std Mean          -0.33104756
Policy log std Std           0.14921457
Policy log std Max           0.15162937
Policy log std Min           -1.0424225
Z mean eval                  0.34230864
Z variance eval              0.26737708
total_rewards                [5298.37738923 5341.35123769 5264.13298824 3554.80823791 5233.09023567
 5231.13121167 5294.39029617 5310.12748299 5195.3529058  1909.65124192]
total_rewards_mean           4763.24132272871
total_rewards_std            1080.8498548572277
total_rewards_max            5341.351237689658
total_rewards_min            1909.651241920479
Number of train steps total  736000
Number of env steps total    975809
Number of rollouts total     0
Train Time (s)               118.2767021000036
(Previous) Eval Time (s)     27.358757957001217
Sample Time (s)              8.5195948019973
Epoch Time (s)               154.15505485900212
Total Train Time (s)         28436.453240876668
Epoch                        183
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 04:12:29.837038 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #183 | Epoch Duration: 149.78863978385925
2020-01-06 04:12:29.837171 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #183 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.083651185
Z variance train             0.11298601
KL Divergence                3.3160596
KL Loss                      0.33160597
QF Loss                      2133.2354
VF Loss                      1602.927
Policy Loss                  -2116.7776
Q Predictions Mean           2114.8096
Q Predictions Std            589.9557
Q Predictions Max            2496.5967
Q Predictions Min            75.18296
V Predictions Mean           2129.9092
V Predictions Std            588.3367
V Predictions Max            2503.3887
V Predictions Min            93.21525
Log Pis Mean                 -1.9241004
Log Pis Std                  7.090572
Log Pis Max                  39.1623
Log Pis Min                  -13.22299
Policy mu Mean               0.10263931
Policy mu Std                0.88886803
Policy mu Max                6.24962
Policy mu Min                -5.8048196
Policy log std Mean          -0.33657634
Policy log std Std           0.14649282
Policy log std Max           0.6081304
Policy log std Min           -1.0960284
Z mean eval                  0.05770885
Z variance eval              0.04527985
total_rewards                [5178.26287149 5121.95323406 5278.25869094 5201.8745161  1106.63723159
 5176.78907841 5305.82326321 5316.23023386 5302.10749466 5274.64629513]
total_rewards_mean           4826.258290944701
total_rewards_std            1241.4800291141644
total_rewards_max            5316.230233855261
total_rewards_min            1106.6372315907138
Number of train steps total  740000
Number of env steps total    980809
Number of rollouts total     0
Train Time (s)               126.04661627998576
(Previous) Eval Time (s)     22.99208360997727
Sample Time (s)              8.172861504077446
Epoch Time (s)               157.21156139404047
Total Train Time (s)         28595.187837654667
Epoch                        184
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 04:15:08.573529 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #184 | Epoch Duration: 158.73625206947327
2020-01-06 04:15:08.573659 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #184 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043230884
Z variance train             0.04566543
KL Divergence                5.351553
KL Loss                      0.5351553
QF Loss                      2844.8723
VF Loss                      1194.604
Policy Loss                  -2098.5908
Q Predictions Mean           2088.7441
Q Predictions Std            629.01227
Q Predictions Max            2486.9495
Q Predictions Min            -71.99368
V Predictions Mean           2096.2607
V Predictions Std            621.2777
V Predictions Max            2498.151
V Predictions Min            -8.078337
Log Pis Mean                 -2.5562656
Log Pis Std                  6.6702657
Log Pis Max                  28.027985
Log Pis Min                  -13.997633
Policy mu Mean               0.09333838
Policy mu Std                0.86520135
Policy mu Max                3.8270876
Policy mu Min                -3.4475176
Policy log std Mean          -0.33041665
Policy log std Std           0.14738463
Policy log std Max           0.047116056
Policy log std Min           -1.0738077
Z mean eval                  0.2520209
Z variance eval              0.032512777
total_rewards                [5447.30035684 4190.15632456 2195.84999941 5340.02847779 5376.12074699
 5384.16174197 5342.57896721 3670.05142314 2442.1524499  5406.42206052]
total_rewards_mean           4479.482254833015
total_rewards_std            1225.0856033805383
total_rewards_max            5447.300356837147
total_rewards_min            2195.8499994073445
Number of train steps total  744000
Number of env steps total    985809
Number of rollouts total     0
Train Time (s)               126.87606659397716
(Previous) Eval Time (s)     24.516521154961083
Sample Time (s)              8.463107716233935
Epoch Time (s)               159.85569546517218
Total Train Time (s)         28752.244098154828
Epoch                        185
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 04:17:45.631702 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #185 | Epoch Duration: 157.05794501304626
2020-01-06 04:17:45.631822 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #185 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.24340753
Z variance train             0.04298268
KL Divergence                5.6865
KL Loss                      0.56865
QF Loss                      2445.0007
VF Loss                      950.26526
Policy Loss                  -2120.2505
Q Predictions Mean           2106.7136
Q Predictions Std            603.4453
Q Predictions Max            2504.3306
Q Predictions Min            52.02582
V Predictions Mean           2115.4294
V Predictions Std            611.4731
V Predictions Max            2518.5852
V Predictions Min            -2.6708655
Log Pis Mean                 -1.6244067
Log Pis Std                  6.6419473
Log Pis Max                  26.42605
Log Pis Min                  -12.439922
Policy mu Mean               0.12798128
Policy mu Std                0.89388317
Policy mu Max                3.6278026
Policy mu Min                -2.9986873
Policy log std Mean          -0.34126866
Policy log std Std           0.14918673
Policy log std Max           0.22029895
Policy log std Min           -1.0487454
Z mean eval                  0.36775273
Z variance eval              0.04543783
total_rewards                [4954.41136453 5159.1631269  5249.98352613 5270.49411367 5239.32281413
 5220.74326255 5170.93297261 5259.40829494 5183.36718495 5199.11292298]
total_rewards_mean           5190.693958338527
total_rewards_std            86.72451705830457
total_rewards_max            5270.4941136681955
total_rewards_min            4954.4113645330235
Number of train steps total  748000
Number of env steps total    990809
Number of rollouts total     0
Train Time (s)               125.95737801300129
(Previous) Eval Time (s)     21.71851139701903
Sample Time (s)              8.23672072699992
Epoch Time (s)               155.91261013702024
Total Train Time (s)         28912.54651934182
Epoch                        186
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 04:20:25.936083 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #186 | Epoch Duration: 160.30416655540466
2020-01-06 04:20:25.936190 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #186 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.4056805
Z variance train             0.054181077
KL Divergence                5.434842
KL Loss                      0.5434842
QF Loss                      2526.5415
VF Loss                      1076.6306
Policy Loss                  -2127.5933
Q Predictions Mean           2126.148
Q Predictions Std            598.11786
Q Predictions Max            2509.9243
Q Predictions Min            -0.38183284
V Predictions Mean           2144.696
V Predictions Std            591.00574
V Predictions Max            2531.126
V Predictions Min            47.206352
Log Pis Mean                 -1.7726593
Log Pis Std                  6.706141
Log Pis Max                  31.952454
Log Pis Min                  -13.294899
Policy mu Mean               0.050354864
Policy mu Std                0.8969156
Policy mu Max                3.4829535
Policy mu Min                -3.2020285
Policy log std Mean          -0.34419745
Policy log std Std           0.1540517
Policy log std Max           0.04873316
Policy log std Min           -1.18684
Z mean eval                  0.27700695
Z variance eval              0.029086005
total_rewards                [5265.92301498 5267.56592646 5346.77517871 5362.19167364 5293.28448105
 5372.97131537 5319.80983973 5320.77588944 5464.1500097  5169.04090696]
total_rewards_mean           5318.248823604391
total_rewards_std            74.31569426846241
total_rewards_max            5464.150009701087
total_rewards_min            5169.040906964025
Number of train steps total  752000
Number of env steps total    996008
Number of rollouts total     0
Train Time (s)               128.88266163197113
(Previous) Eval Time (s)     26.109817002958152
Sample Time (s)              8.51097479998134
Epoch Time (s)               163.50345343491063
Total Train Time (s)         29075.87149664975
Epoch                        187
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 04:23:09.263479 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #187 | Epoch Duration: 163.3271884918213
2020-01-06 04:23:09.263665 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #187 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.3625874
Z variance train             0.03233263
KL Divergence                6.5735006
KL Loss                      0.65735006
QF Loss                      3998.1277
VF Loss                      620.9418
Policy Loss                  -2076.4285
Q Predictions Mean           2072.8145
Q Predictions Std            684.6256
Q Predictions Max            2529.5854
Q Predictions Min            46.3309
V Predictions Mean           2077.856
V Predictions Std            683.8252
V Predictions Max            2525.146
V Predictions Min            23.756828
Log Pis Mean                 -2.1385634
Log Pis Std                  6.360114
Log Pis Max                  28.760727
Log Pis Min                  -15.518704
Policy mu Mean               0.06147429
Policy mu Std                0.8786607
Policy mu Max                3.474147
Policy mu Min                -2.9943497
Policy log std Mean          -0.32512352
Policy log std Std           0.14102124
Policy log std Max           0.15430853
Policy log std Min           -1.2112746
Z mean eval                  0.41675505
Z variance eval              0.05051399
total_rewards                [5154.26151398 5212.00261805 5241.88923037 5303.35756936 5301.70074045
 5334.16941679 5206.549894   5230.60665197 5268.33605587 5409.46140425]
total_rewards_mean           5266.233509509582
total_rewards_std            69.76591328036004
total_rewards_max            5409.461404247666
total_rewards_min            5154.261513979092
Number of train steps total  756000
Number of env steps total    1001008
Number of rollouts total     0
Train Time (s)               125.25413552200189
(Previous) Eval Time (s)     25.93328764499165
Sample Time (s)              8.196299083007034
Epoch Time (s)               159.38372225000057
Total Train Time (s)         29235.31090046669
Epoch                        188
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 04:25:48.704819 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #188 | Epoch Duration: 159.44100785255432
2020-01-06 04:25:48.704935 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #188 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.34096393
Z variance train             0.04874481
KL Divergence                5.555032
KL Loss                      0.5555032
QF Loss                      2501.2969
VF Loss                      1338.4495
Policy Loss                  -2133.0806
Q Predictions Mean           2129.8052
Q Predictions Std            599.12164
Q Predictions Max            2544.013
Q Predictions Min            79.32121
V Predictions Mean           2123.9585
V Predictions Std            592.2445
V Predictions Max            2517.7732
V Predictions Min            113.82628
Log Pis Mean                 -2.336145
Log Pis Std                  6.529288
Log Pis Max                  33.35431
Log Pis Min                  -12.247139
Policy mu Mean               0.055289928
Policy mu Std                0.8688138
Policy mu Max                2.8655512
Policy mu Min                -3.40346
Policy log std Mean          -0.33594304
Policy log std Std           0.14899303
Policy log std Max           -0.021925211
Policy log std Min           -1.0832653
Z mean eval                  0.19678804
Z variance eval              0.031115428
total_rewards                [5251.40677215 5199.49310024 5313.73526219 5162.61128859 5224.62187132
 5257.77986661 5241.65445202 5159.64647049 5184.63967848 5182.77092203]
total_rewards_mean           5217.835968413294
total_rewards_std            46.51489217429714
total_rewards_max            5313.735262192497
total_rewards_min            5159.646470489837
Number of train steps total  760000
Number of env steps total    1006008
Number of rollouts total     0
Train Time (s)               120.2122486239532
(Previous) Eval Time (s)     25.99031854700297
Sample Time (s)              8.114800513954833
Epoch Time (s)               154.317367684911
Total Train Time (s)         29390.611248336616
Epoch                        189
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 04:28:24.008113 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #189 | Epoch Duration: 155.30308294296265
2020-01-06 04:28:24.008252 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #189 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.17565945
Z variance train             0.021468347
KL Divergence                7.271573
KL Loss                      0.7271573
QF Loss                      2342.074
VF Loss                      640.98126
Policy Loss                  -2139.513
Q Predictions Mean           2139.5984
Q Predictions Std            621.45905
Q Predictions Max            2536.4746
Q Predictions Min            36.822956
V Predictions Mean           2137.623
V Predictions Std            610.3271
V Predictions Max            2538.4902
V Predictions Min            51.41507
Log Pis Mean                 -2.215838
Log Pis Std                  6.4907613
Log Pis Max                  32.58654
Log Pis Min                  -13.318724
Policy mu Mean               0.08333365
Policy mu Std                0.8736324
Policy mu Max                2.9756684
Policy mu Min                -3.5282698
Policy log std Mean          -0.33113024
Policy log std Std           0.1476722
Policy log std Max           0.0023014098
Policy log std Min           -1.0278445
Z mean eval                  0.17557447
Z variance eval              0.02911869
total_rewards                [2731.12711498 5395.89779957 3575.55401346 5376.33278071 1532.13412087
 5323.76127092 5279.43138782 5189.86290012 5361.69677258 5333.34394176]
total_rewards_mean           4509.914210278236
total_rewards_std            1325.1542864868102
total_rewards_max            5395.897799567013
total_rewards_min            1532.1341208673243
Number of train steps total  764000
Number of env steps total    1011008
Number of rollouts total     0
Train Time (s)               120.85707008896861
(Previous) Eval Time (s)     26.975775762984995
Sample Time (s)              8.552705443988089
Epoch Time (s)               156.3855512959417
Total Train Time (s)         29542.958244445617
Epoch                        190
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 04:30:56.357212 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #190 | Epoch Duration: 152.34884572029114
2020-01-06 04:30:56.357376 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #190 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.22038543
Z variance train             0.028186258
KL Divergence                6.6646132
KL Loss                      0.66646135
QF Loss                      1931.1858
VF Loss                      772.7567
Policy Loss                  -2090.6301
Q Predictions Mean           2091.6929
Q Predictions Std            671.08575
Q Predictions Max            2532.6926
Q Predictions Min            18.151346
V Predictions Mean           2094.6125
V Predictions Std            667.0293
V Predictions Max            2526.9172
V Predictions Min            49.78853
Log Pis Mean                 -3.3587055
Log Pis Std                  5.891613
Log Pis Max                  40.90649
Log Pis Min                  -15.492631
Policy mu Mean               0.076879516
Policy mu Std                0.82277185
Policy mu Max                4.1324615
Policy mu Min                -3.2735207
Policy log std Mean          -0.3199037
Policy log std Std           0.13354923
Policy log std Max           0.00906539
Policy log std Min           -1.0435145
Z mean eval                  0.30214566
Z variance eval              0.034986395
total_rewards                [5361.23769362 5267.46893414 5294.33929749 5277.32093429 5210.78693108
 5204.41514141 5277.47055687 5282.3322439  5241.61012808 5232.53802624]
total_rewards_mean           5264.951988710988
total_rewards_std            43.52784776055464
total_rewards_max            5361.237693624951
total_rewards_min            5204.4151414053385
Number of train steps total  768000
Number of env steps total    1016008
Number of rollouts total     0
Train Time (s)               116.62180671800161
(Previous) Eval Time (s)     22.93880134198116
Sample Time (s)              8.019630375958513
Epoch Time (s)               147.58023843594128
Total Train Time (s)         29694.607069427497
Epoch                        191
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 04:33:28.007743 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #191 | Epoch Duration: 151.65024518966675
2020-01-06 04:33:28.007886 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #191 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.26834324
Z variance train             0.028754938
KL Divergence                6.6906385
KL Loss                      0.66906387
QF Loss                      3232.0762
VF Loss                      1238.9166
Policy Loss                  -2140.829
Q Predictions Mean           2136.483
Q Predictions Std            586.9891
Q Predictions Max            2525.8574
Q Predictions Min            40.955315
V Predictions Mean           2165.038
V Predictions Std            585.7906
V Predictions Max            2552.3774
V Predictions Min            68.81941
Log Pis Mean                 -2.7439
Log Pis Std                  6.3128853
Log Pis Max                  23.627499
Log Pis Min                  -15.154968
Policy mu Mean               0.051626332
Policy mu Std                0.8770756
Policy mu Max                3.8813643
Policy mu Min                -3.1934025
Policy log std Mean          -0.32423198
Policy log std Std           0.14554094
Policy log std Max           0.06255507
Policy log std Min           -1.0915786
Z mean eval                  0.37757757
Z variance eval              0.048969198
total_rewards                [5260.45929278 5103.2156697  5206.52533842 5139.1560787  5251.45145806
 5245.59432416 5204.30759472 5243.99670255 1610.17144612 5188.80953627]
total_rewards_mean           4845.368744148524
total_rewards_std            1079.4817484380399
total_rewards_max            5260.45929278434
total_rewards_min            1610.17144611576
Number of train steps total  772000
Number of env steps total    1021008
Number of rollouts total     0
Train Time (s)               122.87409079802455
(Previous) Eval Time (s)     27.00855520903133
Sample Time (s)              8.378613516979385
Epoch Time (s)               158.26125952403527
Total Train Time (s)         29848.82437939348
Epoch                        192
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 04:36:02.227575 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #192 | Epoch Duration: 154.2195611000061
2020-01-06 04:36:02.227727 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #192 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.32419586
Z variance train             0.04721736
KL Divergence                5.6054335
KL Loss                      0.56054336
QF Loss                      2051.444
VF Loss                      765.1225
Policy Loss                  -2185.0984
Q Predictions Mean           2179.33
Q Predictions Std            592.3926
Q Predictions Max            2534.435
Q Predictions Min            2.8420777
V Predictions Mean           2187.1008
V Predictions Std            596.2442
V Predictions Max            2542.1501
V Predictions Min            32.102802
Log Pis Mean                 -3.084124
Log Pis Std                  6.8869247
Log Pis Max                  45.64447
Log Pis Min                  -18.694174
Policy mu Mean               0.06321328
Policy mu Std                0.85024226
Policy mu Max                3.5108695
Policy mu Min                -4.4791574
Policy log std Mean          -0.326051
Policy log std Std           0.14200029
Policy log std Max           0.4508384
Policy log std Min           -1.1302943
Z mean eval                  0.20224643
Z variance eval              0.026562199
total_rewards                [5394.92032172 5419.50580147 5396.68075386 5333.57347456 5274.09620813
 5313.49153713 5305.78209021 5171.64080787 5245.87569458 5275.55608375]
total_rewards_mean           5313.112277326154
total_rewards_std            72.75714433022823
total_rewards_max            5419.505801465643
total_rewards_min            5171.640807869991
Number of train steps total  776000
Number of env steps total    1026008
Number of rollouts total     0
Train Time (s)               120.15366479702061
(Previous) Eval Time (s)     22.966587881965097
Sample Time (s)              8.50883440306643
Epoch Time (s)               151.62908708205214
Total Train Time (s)         30004.325382628478
Epoch                        193
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 04:38:37.731062 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #193 | Epoch Duration: 155.5032103061676
2020-01-06 04:38:37.731240 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #193 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.16217557
Z variance train             0.027744198
KL Divergence                6.6407866
KL Loss                      0.66407865
QF Loss                      2295.4429
VF Loss                      959.0609
Policy Loss                  -2120.1602
Q Predictions Mean           2114.0952
Q Predictions Std            636.94916
Q Predictions Max            2546.9463
Q Predictions Min            33.260654
V Predictions Mean           2124.312
V Predictions Std            629.10974
V Predictions Max            2542.1763
V Predictions Min            53.738674
Log Pis Mean                 -2.447165
Log Pis Std                  6.816056
Log Pis Max                  28.581242
Log Pis Min                  -13.516095
Policy mu Mean               0.03521896
Policy mu Std                0.8662847
Policy mu Max                3.839347
Policy mu Min                -2.99722
Policy log std Mean          -0.31887856
Policy log std Std           0.14527565
Policy log std Max           0.035309568
Policy log std Min           -1.1461784
Z mean eval                  0.2033472
Z variance eval              0.024533918
total_rewards                [5267.09003218 2556.14581624 5458.3250196  5424.11176471 5421.91789822
 5377.44929876 5305.90212843 1356.53053753 3166.25058043 3832.75564677]
total_rewards_mean           4316.6478722875245
total_rewards_std            1420.4934530263934
total_rewards_max            5458.325019604828
total_rewards_min            1356.5305375256166
Number of train steps total  780000
Number of env steps total    1031008
Number of rollouts total     0
Train Time (s)               120.80702927999664
(Previous) Eval Time (s)     26.840448145987466
Sample Time (s)              8.68117344804341
Epoch Time (s)               156.32865087402752
Total Train Time (s)         30153.959087465424
Epoch                        194
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 04:41:07.366660 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #194 | Epoch Duration: 149.6352894306183
2020-01-06 04:41:07.366781 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #194 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.17534438
Z variance train             0.029071257
KL Divergence                6.5401278
KL Loss                      0.6540128
QF Loss                      1783.0901
VF Loss                      893.2989
Policy Loss                  -2175.2358
Q Predictions Mean           2174.6746
Q Predictions Std            587.88837
Q Predictions Max            2541.4424
Q Predictions Min            109.933876
V Predictions Mean           2166.5723
V Predictions Std            579.45294
V Predictions Max            2528.18
V Predictions Min            114.39136
Log Pis Mean                 -3.4691114
Log Pis Std                  5.491649
Log Pis Max                  22.51481
Log Pis Min                  -13.535481
Policy mu Mean               0.037526965
Policy mu Std                0.8144499
Policy mu Max                2.8021982
Policy mu Min                -3.517284
Policy log std Mean          -0.30427843
Policy log std Std           0.13525186
Policy log std Max           0.07930769
Policy log std Min           -0.9843708
Z mean eval                  0.29532754
Z variance eval              0.036161132
total_rewards                [5251.4301358  5242.54717591 5268.81149748 5267.13712993 1920.13667366
 5252.8128876  5211.18695128 5249.46374645 5326.83300832 5214.55662249]
total_rewards_mean           4920.491582892411
total_rewards_std            1000.580388725281
total_rewards_max            5326.83300831683
total_rewards_min            1920.1366736609775
Number of train steps total  784000
Number of env steps total    1036008
Number of rollouts total     0
Train Time (s)               124.6403928080108
(Previous) Eval Time (s)     20.146837268024683
Sample Time (s)              8.106436813075561
Epoch Time (s)               152.89366688911105
Total Train Time (s)         30311.26961847447
Epoch                        195
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 04:43:44.679489 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #195 | Epoch Duration: 157.3126130104065
2020-01-06 04:43:44.679603 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #195 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.25690356
Z variance train             0.030036548
KL Divergence                6.5697193
KL Loss                      0.65697193
QF Loss                      1957.6179
VF Loss                      829.21655
Policy Loss                  -2205.9592
Q Predictions Mean           2196.2454
Q Predictions Std            556.70123
Q Predictions Max            2541.0889
Q Predictions Min            23.98521
V Predictions Mean           2204.3115
V Predictions Std            551.73785
V Predictions Max            2544.769
V Predictions Min            67.664246
Log Pis Mean                 -3.3759737
Log Pis Std                  5.7090173
Log Pis Max                  20.1526
Log Pis Min                  -15.483315
Policy mu Mean               0.049919114
Policy mu Std                0.8211058
Policy mu Max                2.742232
Policy mu Min                -2.8525457
Policy log std Mean          -0.32136643
Policy log std Std           0.13606234
Policy log std Max           0.0043674856
Policy log std Min           -1.0713605
Z mean eval                  0.43750063
Z variance eval              0.10473249
total_rewards                [5359.62925505 5313.87143712 5374.01579621 5187.27028943 1107.00682103
 5170.49499267 5361.27708452 5290.26930244 5379.56987394 3733.68512073]
total_rewards_mean           4727.708997313677
total_rewards_std            1296.4663918604062
total_rewards_max            5379.569873940917
total_rewards_min            1107.0068210296286
Number of train steps total  788000
Number of env steps total    1041008
Number of rollouts total     0
Train Time (s)               128.97142787498888
(Previous) Eval Time (s)     24.565526131016668
Sample Time (s)              8.33713015698595
Epoch Time (s)               161.8740841629915
Total Train Time (s)         30471.58137185953
Epoch                        196
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 04:46:24.993437 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #196 | Epoch Duration: 160.3137445449829
2020-01-06 04:46:24.993553 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #196 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90644014
Z variance train             0.2141113
KL Divergence                5.046887
KL Loss                      0.5046887
QF Loss                      1807.8167
VF Loss                      612.6785
Policy Loss                  -2149.9158
Q Predictions Mean           2146.1428
Q Predictions Std            676.1389
Q Predictions Max            2575.2905
Q Predictions Min            68.64274
V Predictions Mean           2147.669
V Predictions Std            676.2668
V Predictions Max            2575.0571
V Predictions Min            55.56386
Log Pis Mean                 -2.9338362
Log Pis Std                  6.2124777
Log Pis Max                  22.977217
Log Pis Min                  -12.611371
Policy mu Mean               0.041565865
Policy mu Std                0.8463684
Policy mu Max                3.1601272
Policy mu Min                -2.7714527
Policy log std Mean          -0.31379184
Policy log std Std           0.14261495
Policy log std Max           0.03686738
Policy log std Min           -1.1208194
Z mean eval                  2.533669
Z variance eval              0.6260284
total_rewards                [5215.62855429 5208.03657774 5235.51670066 5273.50980252 5230.43527914
 5222.88150936 5206.96173326 5348.75643406 5261.80848079 5241.69899383]
total_rewards_mean           5244.523406565485
total_rewards_std            40.41847911196916
total_rewards_max            5348.756434061135
total_rewards_min            5206.9617332622765
Number of train steps total  792000
Number of env steps total    1046008
Number of rollouts total     0
Train Time (s)               135.1329535500263
(Previous) Eval Time (s)     23.004931761010084
Sample Time (s)              8.14309181011049
Epoch Time (s)               166.28097712114686
Total Train Time (s)         30640.674000693776
Epoch                        197
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 04:49:14.088872 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #197 | Epoch Duration: 169.09521794319153
2020-01-06 04:49:14.089002 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #197 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5496432
Z variance train             0.3398599
KL Divergence                9.677393
KL Loss                      0.9677393
QF Loss                      2089.1694
VF Loss                      797.87384
Policy Loss                  -2231.8784
Q Predictions Mean           2228.6387
Q Predictions Std            579.44836
Q Predictions Max            2587.8667
Q Predictions Min            47.000572
V Predictions Mean           2224.6719
V Predictions Std            575.1667
V Predictions Max            2580.6604
V Predictions Min            34.431915
Log Pis Mean                 -2.492136
Log Pis Std                  6.792829
Log Pis Max                  47.935158
Log Pis Min                  -14.468
Policy mu Mean               0.08790647
Policy mu Std                0.88400394
Policy mu Max                7.940525
Policy mu Min                -5.9704742
Policy log std Mean          -0.32811728
Policy log std Std           0.14178
Policy log std Max           0.11595306
Policy log std Min           -1.2580299
Z mean eval                  0.6502093
Z variance eval              0.18524352
total_rewards                [5289.64766298 5356.8476687  5389.2449477  2923.41126463 5333.36119889
 5391.23521466 5306.62832057 5357.08694049 5225.97382337 5330.89053078]
total_rewards_mean           5090.4327572751945
total_rewards_std            723.8416263930181
total_rewards_max            5391.235214661144
total_rewards_min            2923.4112646261756
Number of train steps total  796000
Number of env steps total    1051008
Number of rollouts total     0
Train Time (s)               128.69854667404434
(Previous) Eval Time (s)     25.81890850100899
Sample Time (s)              7.993889172910713
Epoch Time (s)               162.51134434796404
Total Train Time (s)         30801.364913000725
Epoch                        198
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 04:51:54.781304 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #198 | Epoch Duration: 160.69217038154602
2020-01-06 04:51:54.781413 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #198 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.45824417
Z variance train             0.13504434
KL Divergence                3.6206813
KL Loss                      0.36206815
QF Loss                      1981.6738
VF Loss                      807.58374
Policy Loss                  -2235.9702
Q Predictions Mean           2234.3643
Q Predictions Std            537.5538
Q Predictions Max            2549.5818
Q Predictions Min            38.922596
V Predictions Mean           2250.4995
V Predictions Std            536.6621
V Predictions Max            2568.1035
V Predictions Min            39.039604
Log Pis Mean                 -2.3941946
Log Pis Std                  7.3626294
Log Pis Max                  33.69566
Log Pis Min                  -19.326057
Policy mu Mean               0.07169916
Policy mu Std                0.8768833
Policy mu Max                3.7356246
Policy mu Min                -3.6779373
Policy log std Mean          -0.33633974
Policy log std Std           0.1481046
Policy log std Max           0.11825533
Policy log std Min           -1.1525322
Z mean eval                  0.1459867
Z variance eval              0.069902666
total_rewards                [5310.34946701 5357.84937735 5315.93940385 5343.19423875 5302.81454961
 5376.89217721 5298.00948414 4103.2819384  5183.32890305 5257.62740716]
total_rewards_mean           5184.928694652553
total_rewards_std            364.22869283371676
total_rewards_max            5376.892177206763
total_rewards_min            4103.281938404391
Number of train steps total  800000
Number of env steps total    1056008
Number of rollouts total     0
Train Time (s)               123.12754346901784
(Previous) Eval Time (s)     23.999486072047148
Sample Time (s)              8.139635944913607
Epoch Time (s)               155.2666654859786
Total Train Time (s)         30958.065547466744
Epoch                        199
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 04:54:31.485255 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #199 | Epoch Duration: 156.70374631881714
2020-01-06 04:54:31.485429 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #199 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.2209578
Z variance train             0.07100932
KL Divergence                4.50072
KL Loss                      0.45007202
QF Loss                      2034.3899
VF Loss                      904.75146
Policy Loss                  -2153.6018
Q Predictions Mean           2149.7642
Q Predictions Std            637.6073
Q Predictions Max            2546.0493
Q Predictions Min            -1.2511072
V Predictions Mean           2161.9724
V Predictions Std            628.76135
V Predictions Max            2567.0232
V Predictions Min            46.186684
Log Pis Mean                 -3.1099653
Log Pis Std                  6.3212643
Log Pis Max                  28.61464
Log Pis Min                  -12.586746
Policy mu Mean               0.08572308
Policy mu Std                0.8336176
Policy mu Max                3.1190047
Policy mu Min                -3.944584
Policy log std Mean          -0.31499615
Policy log std Std           0.14056613
Policy log std Max           0.03130333
Policy log std Min           -1.0359071
Z mean eval                  0.12812297
Z variance eval              0.03619165
total_rewards                [5282.49194263 5268.38429597 5223.88533407 5260.9252232  5346.45932202
 5370.42421267 5254.86804354 5375.53474568 5355.50518811 5317.7383203 ]
total_rewards_mean           5305.621662819102
total_rewards_std            51.54244656841633
total_rewards_max            5375.534745681579
total_rewards_min            5223.885334072457
Number of train steps total  804000
Number of env steps total    1061008
Number of rollouts total     0
Train Time (s)               129.33350070397137
(Previous) Eval Time (s)     25.436308236967307
Sample Time (s)              8.486992071033455
Epoch Time (s)               163.25680101197213
Total Train Time (s)         31121.836155446654
Epoch                        200
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 04:57:15.258286 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #200 | Epoch Duration: 163.77269983291626
2020-01-06 04:57:15.258424 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #200 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14337006
Z variance train             0.03438994
KL Divergence                6.098997
KL Loss                      0.6098997
QF Loss                      1563.4177
VF Loss                      688.55304
Policy Loss                  -2281.4226
Q Predictions Mean           2268.8809
Q Predictions Std            481.53903
Q Predictions Max            2546.47
Q Predictions Min            166.69402
V Predictions Mean           2267.6794
V Predictions Std            473.3708
V Predictions Max            2535.0547
V Predictions Min            158.93558
Log Pis Mean                 -3.4103768
Log Pis Std                  5.240613
Log Pis Max                  15.484956
Log Pis Min                  -12.823433
Policy mu Mean               0.03983433
Policy mu Std                0.82736486
Policy mu Max                3.3305082
Policy mu Min                -3.042853
Policy log std Mean          -0.30962506
Policy log std Std           0.14163907
Policy log std Max           0.03922069
Policy log std Min           -1.1877406
Z mean eval                  0.2534735
Z variance eval              0.0744628
total_rewards                [2924.50411271 4965.06399971 5255.71447828 4863.83320438 2932.39990611
 5020.05671745 5132.35551445 5161.08571164 5234.34449386 5327.87864402]
total_rewards_mean           4681.723678259191
total_rewards_std            886.6283087630496
total_rewards_max            5327.878644021085
total_rewards_min            2924.5041127071618
Number of train steps total  808000
Number of env steps total    1066008
Number of rollouts total     0
Train Time (s)               129.26883486198494
(Previous) Eval Time (s)     25.95196284900885
Sample Time (s)              8.21885037899483
Epoch Time (s)               163.43964808998862
Total Train Time (s)         31283.09446383774
Epoch                        201
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 04:59:56.518624 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #201 | Epoch Duration: 161.2601089477539
2020-01-06 04:59:56.518731 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #201 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.24275199
Z variance train             0.07415037
KL Divergence                4.4123116
KL Loss                      0.44123116
QF Loss                      1489.4485
VF Loss                      946.7136
Policy Loss                  -2254.1372
Q Predictions Mean           2249.8667
Q Predictions Std            560.64923
Q Predictions Max            2570.0837
Q Predictions Min            93.854324
V Predictions Mean           2243.918
V Predictions Std            559.52185
V Predictions Max            2569.701
V Predictions Min            91.89104
Log Pis Mean                 -3.571835
Log Pis Std                  5.684076
Log Pis Max                  16.772495
Log Pis Min                  -14.4658375
Policy mu Mean               0.083870456
Policy mu Std                0.804543
Policy mu Max                2.3622594
Policy mu Min                -3.4416986
Policy log std Mean          -0.30396098
Policy log std Std           0.13108495
Policy log std Max           -0.06418315
Policy log std Min           -0.93651485
Z mean eval                  0.19546437
Z variance eval              0.059310474
total_rewards                [5341.81519697 2244.13833201 4172.34147359 5340.60814684 3958.64568799
 5339.74265975 2507.30484334 4849.95220017 5394.01442756 5367.49007952]
total_rewards_mean           4451.605304774102
total_rewards_std            1150.2808345107944
total_rewards_max            5394.014427555828
total_rewards_min            2244.1383320073005
Number of train steps total  812000
Number of env steps total    1071008
Number of rollouts total     0
Train Time (s)               133.4687570099486
(Previous) Eval Time (s)     23.772184289002325
Sample Time (s)              8.381949108908884
Epoch Time (s)               165.6228904078598
Total Train Time (s)         31447.13003356353
Epoch                        202
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 05:02:40.556819 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #202 | Epoch Duration: 164.0379991531372
2020-01-06 05:02:40.556939 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #202 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.31793767
Z variance train             0.06653087
KL Divergence                4.7731
KL Loss                      0.47731
QF Loss                      2722.6008
VF Loss                      648.9755
Policy Loss                  -2257.8577
Q Predictions Mean           2243.9136
Q Predictions Std            538.7228
Q Predictions Max            2553.3833
Q Predictions Min            108.79176
V Predictions Mean           2244.6672
V Predictions Std            534.3596
V Predictions Max            2561.5989
V Predictions Min            153.39082
Log Pis Mean                 -2.8965845
Log Pis Std                  6.307254
Log Pis Max                  33.017128
Log Pis Min                  -12.479197
Policy mu Mean               0.11277732
Policy mu Std                0.8402568
Policy mu Max                2.6872993
Policy mu Min                -3.1522286
Policy log std Mean          -0.32444808
Policy log std Std           0.13847844
Policy log std Max           0.037602514
Policy log std Min           -1.1647942
Z mean eval                  0.12862025
Z variance eval              0.04307301
total_rewards                [5416.03653962 5361.2125033  5389.16995869 5359.1719967  5399.91425662
 5379.08566971 5446.54743913 5321.16032807 5307.89252577 5341.58488372]
total_rewards_mean           5372.177610132588
total_rewards_std            40.64589710494813
total_rewards_max            5446.547439132774
total_rewards_min            5307.892525767772
Number of train steps total  816000
Number of env steps total    1076185
Number of rollouts total     0
Train Time (s)               129.9801164829987
(Previous) Eval Time (s)     22.187034987960942
Sample Time (s)              8.444717745063826
Epoch Time (s)               160.61186921602348
Total Train Time (s)         31612.187591650523
Epoch                        203
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 05:05:25.616829 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #203 | Epoch Duration: 165.05980372428894
2020-01-06 05:05:25.616943 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #203 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09365706
Z variance train             0.040772595
KL Divergence                5.6472816
KL Loss                      0.5647282
QF Loss                      2173.4312
VF Loss                      1156.2883
Policy Loss                  -2253.9868
Q Predictions Mean           2243.8013
Q Predictions Std            537.2905
Q Predictions Max            2580.1816
Q Predictions Min            210.69946
V Predictions Mean           2236.1592
V Predictions Std            538.98535
V Predictions Max            2629.5527
V Predictions Min            205.02318
Log Pis Mean                 -2.1638556
Log Pis Std                  6.184108
Log Pis Max                  26.356415
Log Pis Min                  -15.018622
Policy mu Mean               0.0737941
Policy mu Std                0.8767173
Policy mu Max                3.405705
Policy mu Min                -3.2375891
Policy log std Mean          -0.33500037
Policy log std Std           0.14420581
Policy log std Max           0.030635133
Policy log std Min           -1.1142713
Z mean eval                  0.1326698
Z variance eval              0.051946234
total_rewards                [5263.36302441 5142.55454917 5329.89562317 4987.51562879 5261.10320222
 5229.36734775 5187.28337212 5129.82516898 5202.36161742 5144.31511884]
total_rewards_mean           5187.758465286326
total_rewards_std            89.7927764826457
total_rewards_max            5329.895623167592
total_rewards_min            4987.515628788999
Number of train steps total  820000
Number of env steps total    1081185
Number of rollouts total     0
Train Time (s)               128.09358815505402
(Previous) Eval Time (s)     26.634709183999803
Sample Time (s)              8.646190546976868
Epoch Time (s)               163.3744878860307
Total Train Time (s)         31776.069317447545
Epoch                        204
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 05:08:09.501171 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #204 | Epoch Duration: 163.88413882255554
2020-01-06 05:08:09.501284 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #204 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09049169
Z variance train             0.043153413
KL Divergence                5.511257
KL Loss                      0.5511257
QF Loss                      1715.5881
VF Loss                      916.4746
Policy Loss                  -2289.6843
Q Predictions Mean           2289.5386
Q Predictions Std            495.39694
Q Predictions Max            2569.697
Q Predictions Min            63.264114
V Predictions Mean           2292.824
V Predictions Std            484.64545
V Predictions Max            2582.1682
V Predictions Min            103.4822
Log Pis Mean                 -3.0415142
Log Pis Std                  5.807819
Log Pis Max                  22.432173
Log Pis Min                  -15.010997
Policy mu Mean               0.05976184
Policy mu Std                0.8259783
Policy mu Max                2.6523528
Policy mu Min                -2.9098504
Policy log std Mean          -0.3309508
Policy log std Std           0.14854099
Policy log std Max           -0.037119508
Policy log std Min           -1.3246734
Z mean eval                  0.14913647
Z variance eval              0.14743738
total_rewards                [5202.95055583 5286.73860555 5335.8583537  2338.46957029 5302.34202401
 4929.40434284 5288.89300855 5333.7681006  5168.03157199 5374.85968499]
total_rewards_mean           4956.13158183552
total_rewards_std            880.94936240582
total_rewards_max            5374.8596849927435
total_rewards_min            2338.4695702852127
Number of train steps total  824000
Number of env steps total    1086185
Number of rollouts total     0
Train Time (s)               125.51983556500636
(Previous) Eval Time (s)     27.144086081010755
Sample Time (s)              8.374488274217583
Epoch Time (s)               161.0384099202347
Total Train Time (s)         31935.06468850578
Epoch                        205
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 05:10:48.498548 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #205 | Epoch Duration: 158.997154712677
2020-01-06 05:10:48.498699 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #205 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08959927
Z variance train             0.08306928
KL Divergence                3.970286
KL Loss                      0.3970286
QF Loss                      1807.7019
VF Loss                      1085.6831
Policy Loss                  -2250.82
Q Predictions Mean           2253.9316
Q Predictions Std            539.74976
Q Predictions Max            2563.8333
Q Predictions Min            110.96819
V Predictions Mean           2266.4521
V Predictions Std            548.3232
V Predictions Max            2588.864
V Predictions Min            125.32439
Log Pis Mean                 -2.645155
Log Pis Std                  5.862332
Log Pis Max                  24.064444
Log Pis Min                  -14.403772
Policy mu Mean               0.07260197
Policy mu Std                0.8390892
Policy mu Max                3.3962429
Policy mu Min                -3.6912782
Policy log std Mean          -0.32292995
Policy log std Std           0.14054428
Policy log std Max           0.006221384
Policy log std Min           -1.2297927
Z mean eval                  0.14523241
Z variance eval              0.074130535
total_rewards                [5257.27362295 5179.05029488 5212.79718001  911.118381   5163.58827738
 5176.49767636 5240.08683166 5243.03080063 1318.44189575 5099.31631332]
total_rewards_mean           4380.1201273953475
total_rewards_std            1635.79722798004
total_rewards_max            5257.273622947924
total_rewards_min            911.1183810011432
Number of train steps total  828000
Number of env steps total    1091185
Number of rollouts total     0
Train Time (s)               125.51652996701887
(Previous) Eval Time (s)     25.102564043016173
Sample Time (s)              8.615456581988838
Epoch Time (s)               159.23455059202388
Total Train Time (s)         32091.567713059776
Epoch                        206
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 05:13:25.003829 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #206 | Epoch Duration: 156.5050163269043
2020-01-06 05:13:25.003987 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #206 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.17683832
Z variance train             0.12893033
KL Divergence                3.072455
KL Loss                      0.3072455
QF Loss                      1887.2396
VF Loss                      712.95044
Policy Loss                  -2263.6238
Q Predictions Mean           2259.6152
Q Predictions Std            530.0364
Q Predictions Max            2578.7363
Q Predictions Min            154.17253
V Predictions Mean           2271.319
V Predictions Std            529.5922
V Predictions Max            2601.2046
V Predictions Min            138.96591
Log Pis Mean                 -2.7495997
Log Pis Std                  5.666521
Log Pis Max                  19.806622
Log Pis Min                  -16.115137
Policy mu Mean               0.08221316
Policy mu Std                0.84659153
Policy mu Max                2.847452
Policy mu Min                -2.5906324
Policy log std Mean          -0.31973824
Policy log std Std           0.14647731
Policy log std Max           0.037618548
Policy log std Min           -1.0722208
Z mean eval                  0.52887106
Z variance eval              0.45510095
total_rewards                [1961.23915591 5384.89241931 5420.74807264 5429.06620838 5267.1743334
 5297.75868122 5348.80053791 5466.30762912 1512.41979046 5339.86308697]
total_rewards_mean           4642.826991532709
total_rewards_std            1457.5829453867734
total_rewards_max            5466.307629118222
total_rewards_min            1512.419790458418
Number of train steps total  832000
Number of env steps total    1096185
Number of rollouts total     0
Train Time (s)               129.96119097003248
(Previous) Eval Time (s)     22.372772895963863
Sample Time (s)              8.222924341098405
Epoch Time (s)               160.55688820709474
Total Train Time (s)         32252.94006123196
Epoch                        207
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 05:16:06.378783 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #207 | Epoch Duration: 161.37468481063843
2020-01-06 05:16:06.378942 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #207 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.35621458
Z variance train             0.31560117
KL Divergence                1.7099645
KL Loss                      0.17099646
QF Loss                      1503.3984
VF Loss                      437.45477
Policy Loss                  -2357.1223
Q Predictions Mean           2347.9675
Q Predictions Std            423.77188
Q Predictions Max            2589.0566
Q Predictions Min            265.90253
V Predictions Mean           2346.875
V Predictions Std            420.33627
V Predictions Max            2582.8499
V Predictions Min            285.83392
Log Pis Mean                 -3.1063685
Log Pis Std                  5.922393
Log Pis Max                  24.323475
Log Pis Min                  -17.440395
Policy mu Mean               0.06720446
Policy mu Std                0.84580725
Policy mu Max                2.7878864
Policy mu Min                -3.1499586
Policy log std Mean          -0.32458934
Policy log std Std           0.13144445
Policy log std Max           -0.0063586235
Policy log std Min           -1.0398463
Z mean eval                  0.13189085
Z variance eval              0.10809624
total_rewards                [5349.20759252 5331.95164993 5279.66493774 2821.5345162  5333.49488426
 1284.65925654 5366.34267322 5370.01711641 5276.16426064 5203.74038773]
total_rewards_mean           4661.677727519093
total_rewards_std            1349.6412384209675
total_rewards_max            5370.017116410304
total_rewards_min            1284.6592565388241
Number of train steps total  836000
Number of env steps total    1101185
Number of rollouts total     0
Train Time (s)               122.212206221011
(Previous) Eval Time (s)     23.190318198001478
Sample Time (s)              8.393032971012872
Epoch Time (s)               153.79555739002535
Total Train Time (s)         32405.987259330985
Epoch                        208
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 05:18:39.429205 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #208 | Epoch Duration: 153.0501401424408
2020-01-06 05:18:39.429403 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #208 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.21108504
Z variance train             0.25845996
KL Divergence                1.7248049
KL Loss                      0.1724805
QF Loss                      2882.7866
VF Loss                      570.68695
Policy Loss                  -2315.3113
Q Predictions Mean           2307.3213
Q Predictions Std            526.5629
Q Predictions Max            2591.0864
Q Predictions Min            152.94638
V Predictions Mean           2301.6367
V Predictions Std            518.64056
V Predictions Max            2574.052
V Predictions Min            148.09451
Log Pis Mean                 -4.0354834
Log Pis Std                  4.9152093
Log Pis Max                  23.455166
Log Pis Min                  -14.783202
Policy mu Mean               0.08375387
Policy mu Std                0.80085117
Policy mu Max                2.7112014
Policy mu Min                -3.4552648
Policy log std Mean          -0.31715506
Policy log std Std           0.123174846
Policy log std Max           -0.048170015
Policy log std Min           -1.0518202
Z mean eval                  0.109003976
Z variance eval              0.077744916
total_rewards                [5238.83763053 5363.55228597 3999.30921092 2639.56488932 5366.94018041
 5423.03786806 5364.73743721 3350.31717696 5413.12996116 5403.04532947]
total_rewards_mean           4756.247197000323
total_rewards_std            983.3265076632258
total_rewards_max            5423.037868056669
total_rewards_min            2639.564889322545
Number of train steps total  840000
Number of env steps total    1106323
Number of rollouts total     0
Train Time (s)               130.1186425999622
(Previous) Eval Time (s)     22.444623609015252
Sample Time (s)              8.491650020005181
Epoch Time (s)               161.05491622898262
Total Train Time (s)         32567.019469522056
Epoch                        209
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 05:21:20.463643 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #209 | Epoch Duration: 161.03410410881042
2020-01-06 05:21:20.463778 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #209 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.12811556
Z variance train             0.137332
KL Divergence                2.8784811
KL Loss                      0.28784811
QF Loss                      2370.586
VF Loss                      798.6292
Policy Loss                  -2324.1306
Q Predictions Mean           2320.5576
Q Predictions Std            468.4186
Q Predictions Max            2586.44
Q Predictions Min            82.67032
V Predictions Mean           2321.2502
V Predictions Std            479.85724
V Predictions Max            2608.5247
V Predictions Min            35.623646
Log Pis Mean                 -3.424954
Log Pis Std                  5.9033513
Log Pis Max                  24.742373
Log Pis Min                  -13.703836
Policy mu Mean               0.07330125
Policy mu Std                0.82986695
Policy mu Max                3.4533534
Policy mu Min                -3.2641454
Policy log std Mean          -0.31383616
Policy log std Std           0.13148741
Policy log std Max           0.2054416
Policy log std Min           -1.1469502
Z mean eval                  0.07530755
Z variance eval              0.07327382
total_rewards                [3183.28099007 5310.74602607 5409.94151557 5246.33323246 5244.48822166
 5326.43283309 5243.46393579 5357.23351308 4254.89053145 1309.63467284]
total_rewards_mean           4588.644547207541
total_rewards_std            1282.997965699299
total_rewards_max            5409.941515568471
total_rewards_min            1309.6346728449582
Number of train steps total  844000
Number of env steps total    1111323
Number of rollouts total     0
Train Time (s)               117.68325135600753
(Previous) Eval Time (s)     22.42356797098182
Sample Time (s)              8.177866345853545
Epoch Time (s)               148.2846856728429
Total Train Time (s)         32716.218940838822
Epoch                        210
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 05:23:49.665970 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #210 | Epoch Duration: 149.20208501815796
2020-01-06 05:23:49.666088 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #210 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14038917
Z variance train             0.07089843
KL Divergence                4.3749275
KL Loss                      0.43749276
QF Loss                      1410.9026
VF Loss                      791.26184
Policy Loss                  -2342.4434
Q Predictions Mean           2339.5254
Q Predictions Std            470.566
Q Predictions Max            2613.9849
Q Predictions Min            28.432192
V Predictions Mean           2338.3584
V Predictions Std            464.24176
V Predictions Max            2593.9514
V Predictions Min            75.6187
Log Pis Mean                 -3.036734
Log Pis Std                  5.896531
Log Pis Max                  22.308249
Log Pis Min                  -14.665169
Policy mu Mean               0.08879889
Policy mu Std                0.83734065
Policy mu Max                2.9743137
Policy mu Min                -2.9115076
Policy log std Mean          -0.32261175
Policy log std Std           0.13138138
Policy log std Max           -0.009116963
Policy log std Min           -1.1026286
Z mean eval                  0.115316354
Z variance eval              0.061855994
total_rewards                [5005.65704047 5322.27125389 5151.61293344 5231.01711571 5299.06411546
 1539.24778865 3795.95264323 5328.82783177 5258.74705763 5244.07011675]
total_rewards_mean           4717.64678970045
total_rewards_std            1146.0207700741214
total_rewards_max            5328.827831767552
total_rewards_min            1539.2477886474626
Number of train steps total  848000
Number of env steps total    1116323
Number of rollouts total     0
Train Time (s)               128.67598076700233
(Previous) Eval Time (s)     23.340716117992997
Sample Time (s)              8.402906897012144
Epoch Time (s)               160.41960378200747
Total Train Time (s)         32876.46663056483
Epoch                        211
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 05:26:29.915971 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #211 | Epoch Duration: 160.24978017807007
2020-01-06 05:26:29.916124 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #211 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14101237
Z variance train             0.05949647
KL Divergence                4.788495
KL Loss                      0.4788495
QF Loss                      1746.3201
VF Loss                      537.3318
Policy Loss                  -2403.8088
Q Predictions Mean           2403.229
Q Predictions Std            351.8739
Q Predictions Max            2612.3035
Q Predictions Min            559.4234
V Predictions Mean           2400.5737
V Predictions Std            345.04453
V Predictions Max            2601.906
V Predictions Min            569.03436
Log Pis Mean                 -3.1834536
Log Pis Std                  5.6750674
Log Pis Max                  20.355158
Log Pis Min                  -15.791353
Policy mu Mean               0.076687224
Policy mu Std                0.8273369
Policy mu Max                3.1170878
Policy mu Min                -2.6559873
Policy log std Mean          -0.3166387
Policy log std Std           0.13787876
Policy log std Max           0.011891782
Policy log std Min           -1.1114553
Z mean eval                  0.20914523
Z variance eval              0.05173231
total_rewards                [5380.24617595 5252.99383385 5503.6092837  5409.21653941 5266.47617915
 5221.63020074 5492.89592009 5375.47045179 5323.51606038 1240.39231006]
total_rewards_mean           4946.644695512099
total_rewards_std            1238.7321020960437
total_rewards_max            5503.609283699527
total_rewards_min            1240.3923100559869
Number of train steps total  852000
Number of env steps total    1121323
Number of rollouts total     0
Train Time (s)               130.94771528802812
(Previous) Eval Time (s)     23.17060093098553
Sample Time (s)              8.155661235039588
Epoch Time (s)               162.27397745405324
Total Train Time (s)         33039.293796718994
Epoch                        212
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 05:29:12.744555 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #212 | Epoch Duration: 162.82831501960754
2020-01-06 05:29:12.744665 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #212 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.26232287
Z variance train             0.09082715
KL Divergence                3.9604263
KL Loss                      0.39604264
QF Loss                      2756.809
VF Loss                      709.03107
Policy Loss                  -2393.6748
Q Predictions Mean           2389.746
Q Predictions Std            382.40677
Q Predictions Max            2606.7336
Q Predictions Min            102.42611
V Predictions Mean           2396.5273
V Predictions Std            383.7647
V Predictions Max            2619.123
V Predictions Min            101.207794
Log Pis Mean                 -3.1903677
Log Pis Std                  5.4793096
Log Pis Max                  23.050262
Log Pis Min                  -12.437314
Policy mu Mean               0.085666224
Policy mu Std                0.8252996
Policy mu Max                3.0651195
Policy mu Min                -2.732558
Policy log std Mean          -0.31762338
Policy log std Std           0.14221005
Policy log std Max           0.07804163
Policy log std Min           -0.9997351
Z mean eval                  0.30895782
Z variance eval              0.07236722
total_rewards                [5087.52762798 5215.46154648 4976.84660787 4949.98765479 5077.03116783
 5199.30090514 5034.24539781 5039.95709224 5125.83832622 4844.96032378]
total_rewards_mean           5055.115665012596
total_rewards_std            107.257291714303
total_rewards_max            5215.46154647573
total_rewards_min            4844.960323781849
Number of train steps total  856000
Number of env steps total    1126323
Number of rollouts total     0
Train Time (s)               129.3526017809636
(Previous) Eval Time (s)     23.724695894983597
Sample Time (s)              8.112456113041844
Epoch Time (s)               161.18975378898904
Total Train Time (s)         33203.355854957015
Epoch                        213
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 05:31:56.809040 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #213 | Epoch Duration: 164.0642671585083
2020-01-06 05:31:56.809221 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #213 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.4575952
Z variance train             0.14525478
KL Divergence                3.5423553
KL Loss                      0.35423553
QF Loss                      2106.4
VF Loss                      717.4178
Policy Loss                  -2398.5896
Q Predictions Mean           2401.2166
Q Predictions Std            467.67532
Q Predictions Max            2646.37
Q Predictions Min            183.70314
V Predictions Mean           2397.5247
V Predictions Std            464.48196
V Predictions Max            2653.9175
V Predictions Min            203.5207
Log Pis Mean                 -3.5443778
Log Pis Std                  5.7692075
Log Pis Max                  34.584827
Log Pis Min                  -16.256752
Policy mu Mean               0.08141689
Policy mu Std                0.8320268
Policy mu Max                2.9893777
Policy mu Min                -2.9827776
Policy log std Mean          -0.30727804
Policy log std Std           0.13100076
Policy log std Max           0.02568075
Policy log std Min           -1.1292363
Z mean eval                  0.22578311
Z variance eval              0.09430344
total_rewards                [5331.38738665 5445.07783393 5361.50456526 5333.67031196 5299.30763928
 5397.63620347 4892.94902573 5312.76226542 5427.36373565 5188.76945745]
total_rewards_mean           5299.04284248107
total_rewards_std            151.96069205687846
total_rewards_max            5445.0778339266935
total_rewards_min            4892.949025734381
Number of train steps total  860000
Number of env steps total    1131323
Number of rollouts total     0
Train Time (s)               119.26446604199009
(Previous) Eval Time (s)     26.598943908000365
Sample Time (s)              8.260011223959737
Epoch Time (s)               154.1234211739502
Total Train Time (s)         33357.459463621024
Epoch                        214
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 05:34:30.915136 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #214 | Epoch Duration: 154.10576963424683
2020-01-06 05:34:30.915270 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #214 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1800993
Z variance train             0.074285164
KL Divergence                4.3258295
KL Loss                      0.43258294
QF Loss                      2119.273
VF Loss                      746.4335
Policy Loss                  -2345.2334
Q Predictions Mean           2344.0623
Q Predictions Std            532.02563
Q Predictions Max            2626.681
Q Predictions Min            80.54786
V Predictions Mean           2347.0566
V Predictions Std            535.10364
V Predictions Max            2632.3225
V Predictions Min            72.22995
Log Pis Mean                 -3.7524343
Log Pis Std                  5.3028116
Log Pis Max                  22.986366
Log Pis Min                  -13.421673
Policy mu Mean               0.045216378
Policy mu Std                0.8032483
Policy mu Max                2.755725
Policy mu Min                -3.714171
Policy log std Mean          -0.31523392
Policy log std Std           0.1335755
Policy log std Max           0.034872517
Policy log std Min           -1.1676304
Z mean eval                  0.19423962
Z variance eval              0.0828884
total_rewards                [3391.83578353 5415.62359676 5009.68296195 5299.71003551 5281.68930171
 5404.41915273 5309.3008186  5463.81698507 5294.44237537 5464.66472864]
total_rewards_mean           5133.518573988278
total_rewards_std            593.8762007960762
total_rewards_max            5464.66472863982
total_rewards_min            3391.83578353477
Number of train steps total  864000
Number of env steps total    1136323
Number of rollouts total     0
Train Time (s)               126.01203010499012
(Previous) Eval Time (s)     26.5810409259866
Sample Time (s)              8.388672599918209
Epoch Time (s)               160.98174363089493
Total Train Time (s)         33517.38361901895
Epoch                        215
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 05:37:10.842142 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #215 | Epoch Duration: 159.9267590045929
2020-01-06 05:37:10.842321 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #215 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.27480417
Z variance train             0.13676631
KL Divergence                3.0863757
KL Loss                      0.3086376
QF Loss                      1346.7104
VF Loss                      414.32724
Policy Loss                  -2384.8035
Q Predictions Mean           2380.3152
Q Predictions Std            502.34784
Q Predictions Max            2639.793
Q Predictions Min            75.599365
V Predictions Mean           2393.0347
V Predictions Std            498.1117
V Predictions Max            2659.0857
V Predictions Min            82.42445
Log Pis Mean                 -3.271319
Log Pis Std                  6.0460625
Log Pis Max                  33.500473
Log Pis Min                  -14.887926
Policy mu Mean               0.08154594
Policy mu Std                0.8260907
Policy mu Max                3.1350338
Policy mu Min                -2.7616782
Policy log std Mean          -0.30575743
Policy log std Std           0.1345471
Policy log std Max           0.025636002
Policy log std Min           -1.1409956
Z mean eval                  0.11277653
Z variance eval              0.07061134
total_rewards                [5068.47237425 5081.71824175 5235.210492   5233.44577714 4945.09525203
 5282.20533646 5323.80151356 5114.64088013 5342.54960455 2293.85226702]
total_rewards_mean           4892.099173890429
total_rewards_std            874.4130305446128
total_rewards_max            5342.5496045489235
total_rewards_min            2293.85226702308
Number of train steps total  868000
Number of env steps total    1141323
Number of rollouts total     0
Train Time (s)               124.18768939498113
(Previous) Eval Time (s)     25.525786719983444
Sample Time (s)              8.268127128016204
Epoch Time (s)               157.98160324298078
Total Train Time (s)         33674.29622014292
Epoch                        216
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 05:39:47.757093 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #216 | Epoch Duration: 156.91462922096252
2020-01-06 05:39:47.757279 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #216 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.188155
Z variance train             0.1907284
KL Divergence                57.089924
KL Loss                      5.7089925
QF Loss                      1581.021
VF Loss                      410.75385
Policy Loss                  -2272.6094
Q Predictions Mean           2269.0527
Q Predictions Std            445.08984
Q Predictions Max            2502.8586
Q Predictions Min            95.58616
V Predictions Mean           2277.1328
V Predictions Std            446.40036
V Predictions Max            2525.3496
V Predictions Min            92.54544
Log Pis Mean                 -3.6366405
Log Pis Std                  4.931811
Log Pis Max                  22.874435
Log Pis Min                  -13.292141
Policy mu Mean               0.08342211
Policy mu Std                0.787133
Policy mu Max                2.435273
Policy mu Min                -2.746852
Policy log std Mean          -0.31465945
Policy log std Std           0.12270611
Policy log std Max           -0.022991091
Policy log std Min           -1.1621859
Z mean eval                  0.19841455
Z variance eval              0.04181407
total_rewards                [5254.19647917 5314.08974648 5241.61299844 4450.29586323 1168.78857709
 5356.29875894 5129.75999189 5339.26848364 5189.72844179 5258.41489132]
total_rewards_mean           4770.245423200534
total_rewards_std            1226.2052728692222
total_rewards_max            5356.298758942493
total_rewards_min            1168.7885770871653
Number of train steps total  872000
Number of env steps total    1146323
Number of rollouts total     0
Train Time (s)               121.00924793502782
(Previous) Eval Time (s)     24.45851519203279
Sample Time (s)              8.320787140983157
Epoch Time (s)               153.78855026804376
Total Train Time (s)         33827.75191311701
Epoch                        217
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 05:42:21.215020 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #217 | Epoch Duration: 153.45759654045105
2020-01-06 05:42:21.215149 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #217 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.2186987
Z variance train             0.06709739
KL Divergence                4.5958033
KL Loss                      0.45958033
QF Loss                      1200.8999
VF Loss                      551.5357
Policy Loss                  -2437.3416
Q Predictions Mean           2430.078
Q Predictions Std            375.02985
Q Predictions Max            2627.138
Q Predictions Min            275.31885
V Predictions Mean           2434.9546
V Predictions Std            369.8091
V Predictions Max            2640.7253
V Predictions Min            258.0193
Log Pis Mean                 -3.6929083
Log Pis Std                  5.2469764
Log Pis Max                  24.210695
Log Pis Min                  -14.050756
Policy mu Mean               0.045165192
Policy mu Std                0.8070609
Policy mu Max                2.7097082
Policy mu Min                -3.3365805
Policy log std Mean          -0.31081176
Policy log std Std           0.12850648
Policy log std Max           -0.050740562
Policy log std Min           -1.1918075
Z mean eval                  0.1915503
Z variance eval              0.034502484
total_rewards                [5320.58664099 5027.65616011 5286.07331263 5348.84108215 5353.46477097
 5343.28470183 5148.76201142 5295.19259573 5362.72284552 5223.22852537]
total_rewards_mean           5270.9812646719265
total_rewards_std            103.05804819548277
total_rewards_max            5362.722845515087
total_rewards_min            5027.656160108794
Number of train steps total  876000
Number of env steps total    1151323
Number of rollouts total     0
Train Time (s)               116.53092801896855
(Previous) Eval Time (s)     24.127300827007275
Sample Time (s)              8.516394116100855
Epoch Time (s)               149.17462296207668
Total Train Time (s)         33979.1353243551
Epoch                        218
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 05:44:52.600459 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #218 | Epoch Duration: 151.3852047920227
2020-01-06 05:44:52.600613 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #218 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.15884769
Z variance train             0.025991995
KL Divergence                6.7827163
KL Loss                      0.67827165
QF Loss                      1432.7659
VF Loss                      302.57175
Policy Loss                  -2403.474
Q Predictions Mean           2404.841
Q Predictions Std            453.34695
Q Predictions Max            2650.3916
Q Predictions Min            183.07387
V Predictions Mean           2404.726
V Predictions Std            453.42154
V Predictions Max            2653.7092
V Predictions Min            179.8095
Log Pis Mean                 -3.555078
Log Pis Std                  5.7686024
Log Pis Max                  23.75369
Log Pis Min                  -13.081866
Policy mu Mean               0.039428353
Policy mu Std                0.8058378
Policy mu Max                2.6301095
Policy mu Min                -4.1930676
Policy log std Mean          -0.30587128
Policy log std Std           0.12890041
Policy log std Max           0.007528074
Policy log std Min           -1.1563616
Z mean eval                  0.25915655
Z variance eval              0.08100276
total_rewards                [5336.39260795  998.48943671 4767.43382147 5199.13497068 5213.71093171
 5246.35090566 5358.95334743 5314.22430943 5342.77399821 5250.25537138]
total_rewards_mean           4802.771970063567
total_rewards_std            1278.4391615923334
total_rewards_max            5358.953347427654
total_rewards_min            998.4894367062633
Number of train steps total  880000
Number of env steps total    1156323
Number of rollouts total     0
Train Time (s)               129.17172572901472
(Previous) Eval Time (s)     26.33761934598442
Sample Time (s)              8.702157506893855
Epoch Time (s)               164.211502581893
Total Train Time (s)         34141.72779501008
Epoch                        219
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 05:47:35.196431 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #219 | Epoch Duration: 162.5957088470459
2020-01-06 05:47:35.196566 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #219 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.16613533
Z variance train             0.027340671
KL Divergence                6.669188
KL Loss                      0.6669188
QF Loss                      3316.3103
VF Loss                      1162.0934
Policy Loss                  -2398.2808
Q Predictions Mean           2407.0835
Q Predictions Std            414.89035
Q Predictions Max            2650.437
Q Predictions Min            166.38116
V Predictions Mean           2407.75
V Predictions Std            423.3142
V Predictions Max            2663.9824
V Predictions Min            195.4739
Log Pis Mean                 -2.726952
Log Pis Std                  6.272739
Log Pis Max                  35.49682
Log Pis Min                  -15.795943
Policy mu Mean               0.05233696
Policy mu Std                0.8684117
Policy mu Max                2.887138
Policy mu Min                -4.6844525
Policy log std Mean          -0.33140236
Policy log std Std           0.14287537
Policy log std Max           0.06342594
Policy log std Min           -1.3531083
Z mean eval                  0.38496673
Z variance eval              0.31868958
total_rewards                [5282.328481   4728.3622433  5143.74513025 5028.65011458 5362.80385245
 3963.01011921 5320.96193688 5267.28532826 5330.43843698 2564.89754457]
total_rewards_mean           4799.248318748594
total_rewards_std            848.0750996973659
total_rewards_max            5362.803852447361
total_rewards_min            2564.897544568079
Number of train steps total  884000
Number of env steps total    1161323
Number of rollouts total     0
Train Time (s)               127.78076627396513
(Previous) Eval Time (s)     24.721570333989803
Sample Time (s)              8.052488160203211
Epoch Time (s)               160.55482476815814
Total Train Time (s)         34301.82112970424
Epoch                        220
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 05:50:15.291991 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #220 | Epoch Duration: 160.09530591964722
2020-01-06 05:50:15.292116 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #220 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.45850962
Z variance train             0.3812287
KL Divergence                1.5233648
KL Loss                      0.15233648
QF Loss                      1896.6624
VF Loss                      630.46124
Policy Loss                  -2460.484
Q Predictions Mean           2457.2725
Q Predictions Std            390.91696
Q Predictions Max            2663.0842
Q Predictions Min            99.740295
V Predictions Mean           2461.621
V Predictions Std            395.4644
V Predictions Max            2673.8347
V Predictions Min            102.80165
Log Pis Mean                 -4.0190005
Log Pis Std                  5.327785
Log Pis Max                  21.788939
Log Pis Min                  -14.390412
Policy mu Mean               0.07582666
Policy mu Std                0.78825873
Policy mu Max                2.6653433
Policy mu Min                -2.7237968
Policy log std Mean          -0.30693543
Policy log std Std           0.12713233
Policy log std Max           0.06112297
Policy log std Min           -1.101903
Z mean eval                  0.16600132
Z variance eval              0.2988854
total_rewards                [5166.72859878 4891.4519386  5081.21061263 5203.52518286 4990.0481362
 5113.98111052 5215.08638351 5157.76257368 4965.35204577 2922.54199777]
total_rewards_mean           4870.768858033892
total_rewards_std            657.4090079506541
total_rewards_max            5215.0863835149985
total_rewards_min            2922.5419977702795
Number of train steps total  888000
Number of env steps total    1166467
Number of rollouts total     0
Train Time (s)               121.32896490296116
(Previous) Eval Time (s)     24.261802085966337
Sample Time (s)              8.200375505082775
Epoch Time (s)               153.79114249401027
Total Train Time (s)         34457.274824097345
Epoch                        221
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 05:52:50.749430 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #221 | Epoch Duration: 155.45720100402832
2020-01-06 05:52:50.749619 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #221 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.4510091
Z variance train             0.64919007
KL Divergence                1.0125606
KL Loss                      0.101256065
QF Loss                      2102.5493
VF Loss                      996.46106
Policy Loss                  -2443.559
Q Predictions Mean           2444.0059
Q Predictions Std            397.25174
Q Predictions Max            2662.1023
Q Predictions Min            365.35132
V Predictions Mean           2456.6008
V Predictions Std            396.08878
V Predictions Max            2681.3784
V Predictions Min            373.76077
Log Pis Mean                 -3.102744
Log Pis Std                  5.7443113
Log Pis Max                  26.699644
Log Pis Min                  -14.106505
Policy mu Mean               0.06527484
Policy mu Std                0.82707614
Policy mu Max                2.990319
Policy mu Min                -3.9183538
Policy log std Mean          -0.31790075
Policy log std Std           0.1426066
Policy log std Max           0.44158283
Policy log std Min           -1.606017
Z mean eval                  0.5620066
Z variance eval              0.31383005
total_rewards                [5100.45245098 5332.81808505 5440.19091208 5424.1160861  5164.46259281
 5456.40395364 5351.21189976 5330.17208557 5188.01674727 5379.28477142]
total_rewards_mean           5316.712958467797
total_rewards_std            117.62365350282238
total_rewards_max            5456.403953638745
total_rewards_min            5100.452450979337
Number of train steps total  892000
Number of env steps total    1171467
Number of rollouts total     0
Train Time (s)               121.32665960496524
(Previous) Eval Time (s)     25.927603690011892
Sample Time (s)              8.25717447703937
Epoch Time (s)               155.5114377720165
Total Train Time (s)         34613.02773086127
Epoch                        222
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 05:55:26.504331 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #222 | Epoch Duration: 155.75456190109253
2020-01-06 05:55:26.504520 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #222 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1033087
Z variance train             0.14614609
KL Divergence                2.728539
KL Loss                      0.2728539
QF Loss                      2271.9941
VF Loss                      675.3685
Policy Loss                  -2363.7048
Q Predictions Mean           2364.5232
Q Predictions Std            534.552
Q Predictions Max            2657.6064
Q Predictions Min            76.412285
V Predictions Mean           2349.96
V Predictions Std            532.7879
V Predictions Max            2646.8474
V Predictions Min            21.94176
Log Pis Mean                 -3.6471996
Log Pis Std                  5.1411657
Log Pis Max                  18.748394
Log Pis Min                  -14.380234
Policy mu Mean               0.051248405
Policy mu Std                0.81298184
Policy mu Max                2.8497212
Policy mu Min                -3.3199122
Policy log std Mean          -0.30641627
Policy log std Std           0.14064358
Policy log std Max           0.05218005
Policy log std Min           -0.95987594
Z mean eval                  0.27942476
Z variance eval              0.18959676
total_rewards                [5498.96854587 4518.29479577 5149.43119391 2853.86875233 5431.16765994
 5399.69059255 3226.3420923  5007.74916481 5513.66942436 5045.891742  ]
total_rewards_mean           4764.507396385197
total_rewards_std            911.7123305761604
total_rewards_max            5513.6694243568745
total_rewards_min            2853.8687523345034
Number of train steps total  896000
Number of env steps total    1176559
Number of rollouts total     0
Train Time (s)               123.21135851094732
(Previous) Eval Time (s)     26.170478497981094
Sample Time (s)              8.068581360974349
Epoch Time (s)               157.45041836990276
Total Train Time (s)         34767.33791398723
Epoch                        223
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 05:58:00.816865 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #223 | Epoch Duration: 154.31220054626465
2020-01-06 05:58:00.817027 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #223 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.27260667
Z variance train             0.16102186
KL Divergence                2.7465444
KL Loss                      0.27465445
QF Loss                      1735.129
VF Loss                      403.12866
Policy Loss                  -2481.971
Q Predictions Mean           2485.4321
Q Predictions Std            368.207
Q Predictions Max            2687.0742
Q Predictions Min            25.669907
V Predictions Mean           2488.9753
V Predictions Std            369.37146
V Predictions Max            2701.6318
V Predictions Min            76.174515
Log Pis Mean                 -3.697132
Log Pis Std                  4.885836
Log Pis Max                  27.781544
Log Pis Min                  -14.481689
Policy mu Mean               0.089127064
Policy mu Std                0.79815876
Policy mu Max                2.8608038
Policy mu Min                -3.568912
Policy log std Mean          -0.30920672
Policy log std Std           0.12133817
Policy log std Max           0.019309282
Policy log std Min           -0.9462663
Z mean eval                  0.44068617
Z variance eval              0.19633384
total_rewards                [5216.06028139 3570.8102395  5224.83486419 5262.47980016 5410.3408783
 1052.90891381 1520.98881708 3655.40415194 4406.57360215 5429.99790411]
total_rewards_mean           4075.0399452611427
total_rewards_std            1544.332163801741
total_rewards_max            5429.997904107991
total_rewards_min            1052.90891381415
Number of train steps total  900000
Number of env steps total    1181629
Number of rollouts total     0
Train Time (s)               116.28992256103083
(Previous) Eval Time (s)     23.0320057090139
Sample Time (s)              8.500007511058357
Epoch Time (s)               147.8219357811031
Total Train Time (s)         34911.06212346832
Epoch                        224
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 06:00:24.543735 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #224 | Epoch Duration: 143.72658228874207
2020-01-06 06:00:24.543909 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #224 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.24102959
Z variance train             0.068632625
KL Divergence                4.5671663
KL Loss                      0.45671663
QF Loss                      1708.4272
VF Loss                      541.79083
Policy Loss                  -2475.9773
Q Predictions Mean           2469.9868
Q Predictions Std            379.04077
Q Predictions Max            2708.3972
Q Predictions Min            387.51163
V Predictions Mean           2468.6953
V Predictions Std            368.50357
V Predictions Max            2675.8037
V Predictions Min            372.2642
Log Pis Mean                 -3.9035482
Log Pis Std                  5.618176
Log Pis Max                  28.5043
Log Pis Min                  -16.79662
Policy mu Mean               0.086899415
Policy mu Std                0.8177485
Policy mu Max                3.3462114
Policy mu Min                -3.022633
Policy log std Mean          -0.29656234
Policy log std Std           0.13413203
Policy log std Max           0.10392593
Policy log std Min           -1.1830829
Z mean eval                  0.15731013
Z variance eval              0.057101358
total_rewards                [2855.60957389 5442.37219256 5411.90891579 1834.00280885 5337.16716929
 5419.27244083 5071.68580907 5199.65683679 4744.25564489 5382.40706847]
total_rewards_mean           4669.833846042068
total_rewards_std            1201.8039300157157
total_rewards_max            5442.372192558009
total_rewards_min            1834.0028088460274
Number of train steps total  904000
Number of env steps total    1186743
Number of rollouts total     0
Train Time (s)               120.99365748901619
(Previous) Eval Time (s)     18.93639665900264
Sample Time (s)              8.36115720908856
Epoch Time (s)               148.2912113571074
Total Train Time (s)         35063.75920762529
Epoch                        225
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 06:02:57.243614 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #225 | Epoch Duration: 152.6995780467987
2020-01-06 06:02:57.243746 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #225 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.12465291
Z variance train             0.05781582
KL Divergence                4.834469
KL Loss                      0.4834469
QF Loss                      1531.1741
VF Loss                      554.7028
Policy Loss                  -2472.8557
Q Predictions Mean           2478.9827
Q Predictions Std            392.84204
Q Predictions Max            2679.4019
Q Predictions Min            -3.2689362
V Predictions Mean           2480.3423
V Predictions Std            384.91946
V Predictions Max            2686.5417
V Predictions Min            10.489808
Log Pis Mean                 -3.968292
Log Pis Std                  4.770947
Log Pis Max                  22.141314
Log Pis Min                  -14.057608
Policy mu Mean               0.09767856
Policy mu Std                0.7784176
Policy mu Max                2.4017968
Policy mu Min                -2.7007775
Policy log std Mean          -0.3093183
Policy log std Std           0.13188276
Policy log std Max           0.028430387
Policy log std Min           -1.0634891
Z mean eval                  0.1533585
Z variance eval              0.027849957
total_rewards                [5132.82751379 5292.62577352 5144.83237771 3402.28990223 5187.32419928
 5303.90179417 4270.54137467 5212.79455212 4066.3436364  5244.11349871]
total_rewards_mean           4825.759462260727
total_rewards_std            633.203994391941
total_rewards_max            5303.90179417321
total_rewards_min            3402.2899022294005
Number of train steps total  908000
Number of env steps total    1192082
Number of rollouts total     0
Train Time (s)               120.44045340799494
(Previous) Eval Time (s)     23.34452398796566
Sample Time (s)              8.74174832686549
Epoch Time (s)               152.5267257228261
Total Train Time (s)         35217.12894435128
Epoch                        226
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 06:05:30.616011 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #226 | Epoch Duration: 153.37215304374695
2020-01-06 06:05:30.616150 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #226 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.16369347
Z variance train             0.04888042
KL Divergence                5.2765303
KL Loss                      0.52765304
QF Loss                      2251.2314
VF Loss                      360.76187
Policy Loss                  -2525.6682
Q Predictions Mean           2527.176
Q Predictions Std            287.87842
Q Predictions Max            2686.638
Q Predictions Min            50.172447
V Predictions Mean           2525.761
V Predictions Std            287.16162
V Predictions Max            2685.0535
V Predictions Min            37.636955
Log Pis Mean                 -3.989715
Log Pis Std                  5.025194
Log Pis Max                  24.140242
Log Pis Min                  -13.910095
Policy mu Mean               0.053632252
Policy mu Std                0.7899959
Policy mu Max                3.0722363
Policy mu Min                -2.7376976
Policy log std Mean          -0.31489423
Policy log std Std           0.13095841
Policy log std Max           0.10078877
Policy log std Min           -1.1066728
Z mean eval                  0.22912931
Z variance eval              0.16348556
total_rewards                [1248.01630662 4374.42824936 3280.12369248 5491.39324563 5385.99399045
 4451.02114763 5496.17926188 3314.44097578 5396.10100337 5385.69785338]
total_rewards_mean           4382.339572658635
total_rewards_std            1330.280065045468
total_rewards_max            5496.179261880773
total_rewards_min            1248.0163066221462
Number of train steps total  912000
Number of env steps total    1197082
Number of rollouts total     0
Train Time (s)               125.58286916802172
(Previous) Eval Time (s)     24.189681890013162
Sample Time (s)              8.485262048896402
Epoch Time (s)               158.25781310693128
Total Train Time (s)         35373.52269561525
Epoch                        227
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 06:08:07.012239 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #227 | Epoch Duration: 156.39599871635437
2020-01-06 06:08:07.012355 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #227 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.22525266
Z variance train             0.12015005
KL Divergence                3.2685087
KL Loss                      0.32685086
QF Loss                      1003.49475
VF Loss                      293.32632
Policy Loss                  -2467.6145
Q Predictions Mean           2466.6152
Q Predictions Std            413.56027
Q Predictions Max            2687.7844
Q Predictions Min            23.45364
V Predictions Mean           2469.0503
V Predictions Std            419.02118
V Predictions Max            2697.5188
V Predictions Min            6.9224195
Log Pis Mean                 -3.5851038
Log Pis Std                  5.044205
Log Pis Max                  20.26966
Log Pis Min                  -13.749828
Policy mu Mean               0.09060836
Policy mu Std                0.7966676
Policy mu Max                2.6960354
Policy mu Min                -2.4542708
Policy log std Mean          -0.3113194
Policy log std Std           0.13122763
Policy log std Max           -0.0022824258
Policy log std Min           -0.9601175
Z mean eval                  0.13210395
Z variance eval              0.035709362
total_rewards                [5154.77185915 5337.22145831 5343.05660366 4625.14388328 5431.31467936
 5278.99394768 4822.50408228 5189.85550376 5361.96653293 5220.01566941]
total_rewards_mean           5176.484421982165
total_rewards_std            243.97881551302345
total_rewards_max            5431.314679362703
total_rewards_min            4625.143883284637
Number of train steps total  916000
Number of env steps total    1202342
Number of rollouts total     0
Train Time (s)               126.5098529009847
(Previous) Eval Time (s)     22.32762652199017
Sample Time (s)              8.4459684920148
Epoch Time (s)               157.28344791498967
Total Train Time (s)         35533.91985689715
Epoch                        228
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 06:10:47.412938 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #228 | Epoch Duration: 160.40047121047974
2020-01-06 06:10:47.413165 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #228 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.15694782
Z variance train             0.04016364
KL Divergence                5.724119
KL Loss                      0.57241195
QF Loss                      993.047
VF Loss                      499.95566
Policy Loss                  -2487.6892
Q Predictions Mean           2488.8696
Q Predictions Std            422.5475
Q Predictions Max            2700.8184
Q Predictions Min            340.2818
V Predictions Mean           2488.7202
V Predictions Std            415.83807
V Predictions Max            2701.66
V Predictions Min            377.27106
Log Pis Mean                 -4.6679344
Log Pis Std                  4.8702726
Log Pis Max                  25.460218
Log Pis Min                  -15.199144
Policy mu Mean               0.101473376
Policy mu Std                0.7511255
Policy mu Max                2.833159
Policy mu Min                -3.0199778
Policy log std Mean          -0.3001912
Policy log std Std           0.12091257
Policy log std Max           0.018311307
Policy log std Min           -1.221452
Z mean eval                  0.14099585
Z variance eval              0.031691033
total_rewards                [5341.63920718 2492.61532619 5041.57775496 5207.8969676  4802.63297492
 5302.24858116 5158.88705208 5104.42810574 4025.18205189 4041.37674162]
total_rewards_mean           4651.848476333282
total_rewards_std            852.7741277908912
total_rewards_max            5341.639207177812
total_rewards_min            2492.6153261936265
Number of train steps total  920000
Number of env steps total    1207342
Number of rollouts total     0
Train Time (s)               125.72922253701836
(Previous) Eval Time (s)     25.444385113019962
Sample Time (s)              8.159607105015311
Epoch Time (s)               159.33321475505363
Total Train Time (s)         35691.018135250255
Epoch                        229
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 06:13:24.513067 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #229 | Epoch Duration: 157.09972858428955
2020-01-06 06:13:24.513228 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #229 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.15387827
Z variance train             0.038204324
KL Divergence                5.841051
KL Loss                      0.58410513
QF Loss                      1235.4137
VF Loss                      530.44055
Policy Loss                  -2500.5334
Q Predictions Mean           2495.3804
Q Predictions Std            393.7282
Q Predictions Max            2693.7422
Q Predictions Min            135.73837
V Predictions Mean           2508.0205
V Predictions Std            395.11017
V Predictions Max            2703.8315
V Predictions Min            101.99233
Log Pis Mean                 -4.0407143
Log Pis Std                  4.7013426
Log Pis Max                  22.3284
Log Pis Min                  -13.669449
Policy mu Mean               0.08827908
Policy mu Std                0.7742678
Policy mu Max                2.8092666
Policy mu Min                -2.3471506
Policy log std Mean          -0.30378985
Policy log std Std           0.122035086
Policy log std Max           0.035193145
Policy log std Min           -0.90563005
Z mean eval                  0.27618212
Z variance eval              0.10722445
total_rewards                [5357.13008393 5371.72442926 5491.14257724 5404.45202561 5499.35620866
 5303.2674514  5206.58504116 5214.67851655 2119.43379034 5250.16300527]
total_rewards_mean           5021.793312942797
total_rewards_std            972.4252756798177
total_rewards_max            5499.356208663565
total_rewards_min            2119.433790341368
Number of train steps total  924000
Number of env steps total    1212342
Number of rollouts total     0
Train Time (s)               129.03842895594425
(Previous) Eval Time (s)     23.21063716005301
Sample Time (s)              8.37768326193327
Epoch Time (s)               160.62674937793054
Total Train Time (s)         35852.59545889613
Epoch                        230
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 06:16:06.093257 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #230 | Epoch Duration: 161.57991576194763
2020-01-06 06:16:06.093427 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #230 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.2566262
Z variance train             0.09488487
KL Divergence                3.8593519
KL Loss                      0.3859352
QF Loss                      1426.9199
VF Loss                      396.56314
Policy Loss                  -2525.1892
Q Predictions Mean           2524.0005
Q Predictions Std            342.00995
Q Predictions Max            2700.152
Q Predictions Min            53.453545
V Predictions Mean           2516.3267
V Predictions Std            331.9985
V Predictions Max            2690.4688
V Predictions Min            86.965576
Log Pis Mean                 -4.3213067
Log Pis Std                  4.8090267
Log Pis Max                  29.163635
Log Pis Min                  -14.376181
Policy mu Mean               0.09079
Policy mu Std                0.77641726
Policy mu Max                3.1370704
Policy mu Min                -2.7774467
Policy log std Mean          -0.29891893
Policy log std Std           0.12554833
Policy log std Max           0.07624236
Policy log std Min           -1.1429224
Z mean eval                  0.2511652
Z variance eval              0.06448455
total_rewards                [5463.15119855 5253.31250749 4242.32911457 5254.12135147 1715.44543969
 4246.22785266 5421.55327969 5394.04350447 5330.13086188 5439.12934232]
total_rewards_mean           4775.944445278519
total_rewards_std            1113.848270687976
total_rewards_max            5463.151198550932
total_rewards_min            1715.4454396850647
Number of train steps total  928000
Number of env steps total    1217342
Number of rollouts total     0
Train Time (s)               117.3986835909891
(Previous) Eval Time (s)     24.163568555028178
Sample Time (s)              8.129440422984771
Epoch Time (s)               149.69169256900204
Total Train Time (s)         36001.29933604004
Epoch                        231
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 06:18:34.799742 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #231 | Epoch Duration: 148.70617771148682
2020-01-06 06:18:34.799868 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #231 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.3016253
Z variance train             0.081302814
KL Divergence                4.273703
KL Loss                      0.4273703
QF Loss                      1427.0581
VF Loss                      598.8038
Policy Loss                  -2500.3396
Q Predictions Mean           2502.8682
Q Predictions Std            397.96576
Q Predictions Max            2709.581
Q Predictions Min            200.49149
V Predictions Mean           2513.064
V Predictions Std            398.7652
V Predictions Max            2717.379
V Predictions Min            154.055
Log Pis Mean                 -3.9085345
Log Pis Std                  5.4940405
Log Pis Max                  20.415958
Log Pis Min                  -15.413577
Policy mu Mean               0.099629164
Policy mu Std                0.79672676
Policy mu Max                2.6644647
Policy mu Min                -5.0206423
Policy log std Mean          -0.29974338
Policy log std Std           0.124793746
Policy log std Max           0.120882645
Policy log std Min           -1.2247807
Z mean eval                  0.1875579
Z variance eval              0.038746126
total_rewards                [4450.18199499 5263.49164678 1387.29328315 5342.4013824  2708.47587832
 5277.41096583 5452.25803295 3589.93862513 5377.86755801 3856.54506628]
total_rewards_mean           4270.586443382582
total_rewards_std            1311.1559014765676
total_rewards_max            5452.258032946807
total_rewards_min            1387.2932831478613
Number of train steps total  932000
Number of env steps total    1222342
Number of rollouts total     0
Train Time (s)               123.11167712300085
(Previous) Eval Time (s)     23.17780569201568
Sample Time (s)              8.074919895909261
Epoch Time (s)               154.3644027109258
Total Train Time (s)         36151.164135636005
Epoch                        232
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 06:21:04.667695 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #232 | Epoch Duration: 149.86771941184998
2020-01-06 06:21:04.667815 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #232 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.24002095
Z variance train             0.0418796
KL Divergence                5.718209
KL Loss                      0.5718209
QF Loss                      1003.3214
VF Loss                      580.7334
Policy Loss                  -2535.0007
Q Predictions Mean           2533.0286
Q Predictions Std            351.57394
Q Predictions Max            2720.4675
Q Predictions Min            146.97704
V Predictions Mean           2545.645
V Predictions Std            354.37912
V Predictions Max            2736.8606
V Predictions Min            125.45195
Log Pis Mean                 -4.2630615
Log Pis Std                  4.876928
Log Pis Max                  29.328732
Log Pis Min                  -14.28909
Policy mu Mean               0.05086318
Policy mu Std                0.7765884
Policy mu Max                3.0409265
Policy mu Min                -2.9572926
Policy log std Mean          -0.30146423
Policy log std Std           0.12277054
Policy log std Max           -0.011879936
Policy log std Min           -1.0838385
Z mean eval                  0.39484164
Z variance eval              0.06324112
total_rewards                [5418.22373153 5385.96592131 5288.73235734 5294.64075154 5296.14270907
 4218.31815147 5351.80136752 1748.98369268 5231.35107606 5021.66084241]
total_rewards_mean           4825.582060093918
total_rewards_std            1078.6767315852753
total_rewards_max            5418.223731526667
total_rewards_min            1748.9836926844198
Number of train steps total  936000
Number of env steps total    1227453
Number of rollouts total     0
Train Time (s)               120.63975363102509
(Previous) Eval Time (s)     18.680875035992358
Sample Time (s)              8.278797289123759
Epoch Time (s)               147.5994259561412
Total Train Time (s)         36303.708184593066
Epoch                        233
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 06:23:37.214489 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #233 | Epoch Duration: 152.5465807914734
2020-01-06 06:23:37.214657 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #233 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.31838194
Z variance train             0.045432977
KL Divergence                5.641865
KL Loss                      0.5641865
QF Loss                      2351.7632
VF Loss                      472.0578
Policy Loss                  -2534.9617
Q Predictions Mean           2534.2676
Q Predictions Std            377.27908
Q Predictions Max            2732.5374
Q Predictions Min            79.50691
V Predictions Mean           2535.2979
V Predictions Std            374.15936
V Predictions Max            2733.765
V Predictions Min            52.039417
Log Pis Mean                 -4.553398
Log Pis Std                  4.673345
Log Pis Max                  17.333548
Log Pis Min                  -16.092268
Policy mu Mean               0.07723141
Policy mu Std                0.75616616
Policy mu Max                2.6650357
Policy mu Min                -3.09936
Policy log std Mean          -0.30340514
Policy log std Std           0.1272221
Policy log std Max           0.12445739
Policy log std Min           -0.983674
Z mean eval                  0.27034655
Z variance eval              0.040534846
total_rewards                [5214.89843315 2254.22898741 1614.25513214 5312.40934969 4962.7743306
 5331.48522946 5331.70125427 2458.27351919 5313.01951598 5345.1414519 ]
total_rewards_mean           4313.818720380072
total_rewards_std            1460.7063869733342
total_rewards_max            5345.141451904404
total_rewards_min            1614.255132144354
Number of train steps total  940000
Number of env steps total    1232636
Number of rollouts total     0
Train Time (s)               115.74080339499051
(Previous) Eval Time (s)     23.627768912992906
Sample Time (s)              8.571030981023796
Epoch Time (s)               147.9396032890072
Total Train Time (s)         36449.54986490705
Epoch                        234
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 06:26:03.058125 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #234 | Epoch Duration: 145.843346118927
2020-01-06 06:26:03.058245 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #234 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.44615564
Z variance train             0.076001264
KL Divergence                4.7114325
KL Loss                      0.47114325
QF Loss                      1228.8147
VF Loss                      286.33807
Policy Loss                  -2569.971
Q Predictions Mean           2571.8967
Q Predictions Std            316.0563
Q Predictions Max            2751.8298
Q Predictions Min            128.6867
V Predictions Mean           2572.2393
V Predictions Std            318.50754
V Predictions Max            2752.9917
V Predictions Min            96.17901
Log Pis Mean                 -4.243572
Log Pis Std                  5.0245385
Log Pis Max                  23.47416
Log Pis Min                  -13.457313
Policy mu Mean               0.090676956
Policy mu Std                0.7781337
Policy mu Max                2.7869263
Policy mu Min                -2.6125162
Policy log std Mean          -0.30765933
Policy log std Std           0.120621696
Policy log std Max           -0.050955266
Policy log std Min           -0.932212
Z mean eval                  0.37929216
Z variance eval              0.04698247
total_rewards                [5496.66168847 5595.73760747 2949.63845867 4958.25696439 5609.50767055
 3053.49086322 5571.27200668 3892.65690374 5459.4416386  5535.00792778]
total_rewards_mean           4812.167172957019
total_rewards_std            1032.7036028004802
total_rewards_max            5609.507670554856
total_rewards_min            2949.638458667918
Number of train steps total  944000
Number of env steps total    1237636
Number of rollouts total     0
Train Time (s)               118.09208401601063
(Previous) Eval Time (s)     21.531245256017428
Sample Time (s)              8.520121557987295
Epoch Time (s)               148.14345083001535
Total Train Time (s)         36597.877726141014
Epoch                        235
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 06:28:31.389463 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #235 | Epoch Duration: 148.33110904693604
2020-01-06 06:28:31.389644 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #235 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.3233882
Z variance train             0.040785704
KL Divergence                5.9126086
KL Loss                      0.59126085
QF Loss                      1492.8407
VF Loss                      464.64124
Policy Loss                  -2544.7551
Q Predictions Mean           2544.078
Q Predictions Std            352.34396
Q Predictions Max            2727.3198
Q Predictions Min            196.50256
V Predictions Mean           2552.4563
V Predictions Std            354.63193
V Predictions Max            2739.6365
V Predictions Min            191.03162
Log Pis Mean                 -3.8360384
Log Pis Std                  5.8475723
Log Pis Max                  35.987766
Log Pis Min                  -16.699457
Policy mu Mean               0.09242585
Policy mu Std                0.803626
Policy mu Max                3.3485048
Policy mu Min                -3.543838
Policy log std Mean          -0.30927712
Policy log std Std           0.13769287
Policy log std Max           0.034577206
Policy log std Min           -1.2474226
Z mean eval                  0.87907076
Z variance eval              0.18425754
total_rewards                [1762.35850158 2217.17605778 4328.41819972 4678.3926755  2158.01733158
 3397.94112611 5563.84434309 5048.64093546 1729.00283568 1752.10285853]
total_rewards_mean           3263.589486502178
total_rewards_std            1443.664539803447
total_rewards_max            5563.844343085749
total_rewards_min            1729.0028356821456
Number of train steps total  948000
Number of env steps total    1242636
Number of rollouts total     0
Train Time (s)               122.47987674298929
(Previous) Eval Time (s)     21.718641973973718
Sample Time (s)              8.013812150107697
Epoch Time (s)               152.2123308670707
Total Train Time (s)         36745.79451933812
Epoch                        236
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 06:30:59.308752 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #236 | Epoch Duration: 147.91895985603333
2020-01-06 06:30:59.309001 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #236 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9047009
Z variance train             0.43004355
KL Divergence                12.24238
KL Loss                      1.224238
QF Loss                      1226.7266
VF Loss                      545.9296
Policy Loss                  -2608.8896
Q Predictions Mean           2609.5723
Q Predictions Std            331.30093
Q Predictions Max            2793.2844
Q Predictions Min            71.38653
V Predictions Mean           2599.7651
V Predictions Std            322.49356
V Predictions Max            2782.2236
V Predictions Min            81.56533
Log Pis Mean                 -4.16519
Log Pis Std                  4.7503223
Log Pis Max                  20.50838
Log Pis Min                  -16.884165
Policy mu Mean               0.089455254
Policy mu Std                0.7925014
Policy mu Max                2.9994383
Policy mu Min                -4.2269945
Policy log std Mean          -0.2999882
Policy log std Std           0.12347623
Policy log std Max           -0.004990682
Policy log std Min           -1.0758928
Z mean eval                  0.36217952
Z variance eval              0.11666308
total_rewards                [5300.34698512 5418.5477361  5417.87456525 5374.96052799 5360.92603683
 3886.17631211 1241.12570377 5379.47023856 5326.67838996 5403.64174925]
total_rewards_mean           4810.974824493872
total_rewards_std            1270.3129448966367
total_rewards_max            5418.547736096114
total_rewards_min            1241.1257037707974
Number of train steps total  952000
Number of env steps total    1248053
Number of rollouts total     0
Train Time (s)               126.21717375802109
(Previous) Eval Time (s)     17.42501236498356
Sample Time (s)              8.868071607954334
Epoch Time (s)               152.51025773095898
Total Train Time (s)         36903.57818892802
Epoch                        237
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 06:33:37.094658 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #237 | Epoch Duration: 157.78554034233093
2020-01-06 06:33:37.094773 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #237 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.21326439
Z variance train             0.06878512
KL Divergence                4.5428667
KL Loss                      0.45428666
QF Loss                      1303.5704
VF Loss                      308.6208
Policy Loss                  -2564.3323
Q Predictions Mean           2567.0632
Q Predictions Std            307.7499
Q Predictions Max            2749.6416
Q Predictions Min            124.87783
V Predictions Mean           2563.6018
V Predictions Std            301.0538
V Predictions Max            2745.4644
V Predictions Min            141.07352
Log Pis Mean                 -4.4192657
Log Pis Std                  5.0260577
Log Pis Max                  28.795563
Log Pis Min                  -14.115553
Policy mu Mean               0.09521872
Policy mu Std                0.7671708
Policy mu Max                2.7720819
Policy mu Min                -3.453638
Policy log std Mean          -0.29679865
Policy log std Std           0.119307734
Policy log std Max           0.0482246
Policy log std Min           -1.0380349
Z mean eval                  0.16120125
Z variance eval              0.05494063
total_rewards                [5351.14906508 5336.90436251 5303.25303399 5284.51345851 4750.86709118
 5366.36343098 5403.47806029 5310.59954969 5335.7222532  5299.62242366]
total_rewards_mean           5274.247272909969
total_rewards_std            177.6636942011862
total_rewards_max            5403.478060290527
total_rewards_min            4750.867091183735
Number of train steps total  956000
Number of env steps total    1253053
Number of rollouts total     0
Train Time (s)               127.79528960603056
(Previous) Eval Time (s)     22.700058311980683
Sample Time (s)              8.507794107077643
Epoch Time (s)               159.0031420250889
Total Train Time (s)         37067.27956701617
Epoch                        238
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 06:36:20.798949 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #238 | Epoch Duration: 163.7040843963623
2020-01-06 06:36:20.799073 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #238 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.2370936
Z variance train             0.097172335
KL Divergence                3.7683656
KL Loss                      0.37683657
QF Loss                      1377.1926
VF Loss                      365.80386
Policy Loss                  -2564.0833
Q Predictions Mean           2561.5889
Q Predictions Std            362.9269
Q Predictions Max            2738.3022
Q Predictions Min            61.024986
V Predictions Mean           2564.9607
V Predictions Std            370.0797
V Predictions Max            2742.5037
V Predictions Min            10.317964
Log Pis Mean                 -4.9227233
Log Pis Std                  4.727901
Log Pis Max                  23.502985
Log Pis Min                  -13.457851
Policy mu Mean               0.07346819
Policy mu Std                0.7374458
Policy mu Max                3.0532694
Policy mu Min                -2.3665452
Policy log std Mean          -0.28924865
Policy log std Std           0.114672124
Policy log std Max           0.032737434
Policy log std Min           -0.8933741
Z mean eval                  0.19053943
Z variance eval              0.06690799
total_rewards                [2791.61924062 5255.26406648 5292.13710156 2304.08689053 5156.92957589
 5294.23685976 5231.35099551 5354.23520204 5223.07655497 5426.49914165]
total_rewards_mean           4732.943562900805
total_rewards_std            1100.1853592060797
total_rewards_max            5426.499141646531
total_rewards_min            2304.08689052848
Number of train steps total  960000
Number of env steps total    1258053
Number of rollouts total     0
Train Time (s)               120.55349137802841
(Previous) Eval Time (s)     27.400759610987734
Sample Time (s)              8.341857295890804
Epoch Time (s)               156.29610828490695
Total Train Time (s)         37220.039976367145
Epoch                        239
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 06:38:53.561119 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #239 | Epoch Duration: 152.76195287704468
2020-01-06 06:38:53.561255 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #239 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.16951844
Z variance train             0.052557696
KL Divergence                5.108013
KL Loss                      0.5108013
QF Loss                      1309.6729
VF Loss                      952.30414
Policy Loss                  -2607.9473
Q Predictions Mean           2607.8345
Q Predictions Std            205.21326
Q Predictions Max            2741.9792
Q Predictions Min            882.53094
V Predictions Mean           2602.7373
V Predictions Std            183.05003
V Predictions Max            2738.7979
V Predictions Min            1037.9393
Log Pis Mean                 -3.9002094
Log Pis Std                  4.766145
Log Pis Max                  14.985902
Log Pis Min                  -14.399494
Policy mu Mean               0.078718916
Policy mu Std                0.7962342
Policy mu Max                2.7376018
Policy mu Min                -2.6214309
Policy log std Mean          -0.29894552
Policy log std Std           0.12108525
Policy log std Max           0.09958224
Policy log std Min           -0.9268906
Z mean eval                  0.30628937
Z variance eval              0.066834815
total_rewards                [2502.5159723  5520.86010119 5393.16443101 3919.26535549 3091.06778007
 5464.08967226 4651.2373807  1951.51807129 5424.13758617 3616.61147161]
total_rewards_mean           4153.446782208899
total_rewards_std            1266.2029553251525
total_rewards_max            5520.860101192025
total_rewards_min            1951.5180712906783
Number of train steps total  964000
Number of env steps total    1263053
Number of rollouts total     0
Train Time (s)               125.42158812202979
(Previous) Eval Time (s)     23.866339789994527
Sample Time (s)              8.182337642007042
Epoch Time (s)               157.47026555403136
Total Train Time (s)         37373.09485366114
Epoch                        240
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 06:41:26.618302 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #240 | Epoch Duration: 153.05694317817688
2020-01-06 06:41:26.618495 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #240 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.32809144
Z variance train             0.07122085
KL Divergence                4.618362
KL Loss                      0.4618362
QF Loss                      1486.481
VF Loss                      433.95776
Policy Loss                  -2591.5347
Q Predictions Mean           2590.9414
Q Predictions Std            300.6498
Q Predictions Max            2750.3413
Q Predictions Min            288.0707
V Predictions Mean           2587.1626
V Predictions Std            298.8476
V Predictions Max            2744.0264
V Predictions Min            311.2384
Log Pis Mean                 -4.279484
Log Pis Std                  4.7734566
Log Pis Max                  25.674515
Log Pis Min                  -16.073433
Policy mu Mean               0.09065968
Policy mu Std                0.7493002
Policy mu Max                2.9778955
Policy mu Min                -2.3954363
Policy log std Mean          -0.29550865
Policy log std Std           0.120351836
Policy log std Max           -0.00512366
Policy log std Min           -1.1896875
Z mean eval                  0.25712684
Z variance eval              0.039649393
total_rewards                [5410.34675711 5446.77905279 5497.78233737 5404.07900293 5570.58059747
 5394.31670657  798.87794197 5513.63571662 5496.36449543 5386.08291809]
total_rewards_mean           4991.884552635227
total_rewards_std            1398.8616187929254
total_rewards_max            5570.580597473422
total_rewards_min            798.8779419722526
Number of train steps total  968000
Number of env steps total    1268053
Number of rollouts total     0
Train Time (s)               128.157468090998
(Previous) Eval Time (s)     19.45276187796844
Sample Time (s)              7.838943626033142
Epoch Time (s)               155.4491735949996
Total Train Time (s)         37532.39586579811
Epoch                        241
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 06:44:05.921520 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #241 | Epoch Duration: 159.30289936065674
2020-01-06 06:44:05.921679 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #241 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.33862796
Z variance train             0.058565855
KL Divergence                5.089566
KL Loss                      0.5089566
QF Loss                      2269.9473
VF Loss                      420.54636
Policy Loss                  -2582.5557
Q Predictions Mean           2583.7317
Q Predictions Std            299.47852
Q Predictions Max            2738.1028
Q Predictions Min            442.55173
V Predictions Mean           2590.2544
V Predictions Std            299.46155
V Predictions Max            2739.4146
V Predictions Min            451.7188
Log Pis Mean                 -4.1299534
Log Pis Std                  4.470241
Log Pis Max                  22.798256
Log Pis Min                  -12.491882
Policy mu Mean               0.091548346
Policy mu Std                0.75893176
Policy mu Max                3.1274428
Policy mu Min                -3.0923839
Policy log std Mean          -0.2912264
Policy log std Std           0.123116694
Policy log std Max           -0.017961621
Policy log std Min           -1.0901179
Z mean eval                  0.28747708
Z variance eval              0.044289567
total_rewards                [5305.04494045 5386.41932419 4424.36853678 3707.89338947 5314.24778883
 5357.4995451  5548.91283021 5452.4543288  5202.41844239 5315.67352404]
total_rewards_mean           5101.4932650257515
total_rewards_std            548.9494847170042
total_rewards_max            5548.912830209267
total_rewards_min            3707.89338947405
Number of train steps total  972000
Number of env steps total    1273053
Number of rollouts total     0
Train Time (s)               122.86771488102386
(Previous) Eval Time (s)     23.306242752005346
Sample Time (s)              8.187678973947186
Epoch Time (s)               154.3616366069764
Total Train Time (s)         37688.35940114525
Epoch                        242
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 06:46:41.888137 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #242 | Epoch Duration: 155.96633052825928
2020-01-06 06:46:41.888275 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #242 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7055017
Z variance train             0.14246745
KL Divergence                4.2538753
KL Loss                      0.42538753
QF Loss                      1179.1816
VF Loss                      292.86932
Policy Loss                  -2618.6648
Q Predictions Mean           2611.7148
Q Predictions Std            263.90912
Q Predictions Max            2772.9575
Q Predictions Min            284.19894
V Predictions Mean           2613.2708
V Predictions Std            264.48062
V Predictions Max            2778.4958
V Predictions Min            291.0325
Log Pis Mean                 -3.8414927
Log Pis Std                  4.8034964
Log Pis Max                  24.580992
Log Pis Min                  -13.286087
Policy mu Mean               0.07437209
Policy mu Std                0.80068624
Policy mu Max                3.3187156
Policy mu Min                -2.5576742
Policy log std Mean          -0.30105716
Policy log std Std           0.12567988
Policy log std Max           0.086541235
Policy log std Min           -0.9877387
Z mean eval                  0.24308772
Z variance eval              0.037635375
total_rewards                [5433.11320243 2132.63774819 3271.543167   5472.38070112 1953.93703427
 5405.97513149 1447.26250173 5390.66681443 2083.64523986 5270.56652927]
total_rewards_mean           3786.172806978797
total_rewards_std            1663.8060691730007
total_rewards_max            5472.380701116261
total_rewards_min            1447.2625017318685
Number of train steps total  976000
Number of env steps total    1278053
Number of rollouts total     0
Train Time (s)               127.59722534497268
(Previous) Eval Time (s)     24.910689085023478
Sample Time (s)              8.254328158101998
Epoch Time (s)               160.76224258809816
Total Train Time (s)         37842.283144910296
Epoch                        243
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 06:49:15.813791 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #243 | Epoch Duration: 153.92540907859802
2020-01-06 06:49:15.813932 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #243 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.27490297
Z variance train             0.04253114
KL Divergence                5.739444
KL Loss                      0.5739444
QF Loss                      1378.5303
VF Loss                      656.0974
Policy Loss                  -2595.8157
Q Predictions Mean           2588.5596
Q Predictions Std            304.84213
Q Predictions Max            2759.3716
Q Predictions Min            167.79718
V Predictions Mean           2594.4446
V Predictions Std            304.17035
V Predictions Max            2766.8127
V Predictions Min            164.53975
Log Pis Mean                 -3.3063517
Log Pis Std                  5.307015
Log Pis Max                  25.264675
Log Pis Min                  -13.247499
Policy mu Mean               0.07385151
Policy mu Std                0.8038345
Policy mu Max                2.7784798
Policy mu Min                -3.32297
Policy log std Mean          -0.31064245
Policy log std Std           0.13189021
Policy log std Max           -0.021073654
Policy log std Min           -1.0025263
Z mean eval                  0.19176415
Z variance eval              0.037165724
total_rewards                [4032.37221276 5467.92535365 2036.76571792 5417.96617765 4732.65074857
 5494.58656034 5450.46632925 3930.65721625 5414.0623445  3267.50851758]
total_rewards_mean           4524.496117848636
total_rewards_std            1126.2837626730916
total_rewards_max            5494.586560343255
total_rewards_min            2036.7657179237785
Number of train steps total  980000
Number of env steps total    1283053
Number of rollouts total     0
Train Time (s)               121.62089165003272
(Previous) Eval Time (s)     18.073617955029476
Sample Time (s)              8.169406256929506
Epoch Time (s)               147.8639158619917
Total Train Time (s)         37993.61185690126
Epoch                        244
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 06:51:47.144717 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #244 | Epoch Duration: 151.33065032958984
2020-01-06 06:51:47.144827 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #244 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.22858255
Z variance train             0.056137405
KL Divergence                5.0124063
KL Loss                      0.5012407
QF Loss                      1388.8024
VF Loss                      824.3617
Policy Loss                  -2613.2065
Q Predictions Mean           2614.5337
Q Predictions Std            262.23596
Q Predictions Max            2766.8748
Q Predictions Min            160.8305
V Predictions Mean           2614.249
V Predictions Std            258.05606
V Predictions Max            2762.6895
V Predictions Min            203.47414
Log Pis Mean                 -4.3984566
Log Pis Std                  4.6491776
Log Pis Max                  16.10994
Log Pis Min                  -15.653502
Policy mu Mean               0.10412333
Policy mu Std                0.7592872
Policy mu Max                2.8332381
Policy mu Min                -2.903144
Policy log std Mean          -0.30416706
Policy log std Std           0.12274769
Policy log std Max           0.07506432
Policy log std Min           -0.94418836
Z mean eval                  0.29298174
Z variance eval              0.07427467
total_rewards                [4233.23720455 5550.31193704 2002.59347079 2472.72390855 5486.84819338
 4011.03463373  556.72975123 5377.90065776 4246.00812592 5310.97152319]
total_rewards_mean           3924.8359406140567
total_rewards_std            1626.9081508987927
total_rewards_max            5550.311937039908
total_rewards_min            556.7297512265603
Number of train steps total  984000
Number of env steps total    1288053
Number of rollouts total     0
Train Time (s)               122.39824578602565
(Previous) Eval Time (s)     21.540097093035
Sample Time (s)              8.385132222960237
Epoch Time (s)               152.3234751020209
Total Train Time (s)         38142.02178025432
Epoch                        245
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 06:54:15.557486 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #245 | Epoch Duration: 148.41256833076477
2020-01-06 06:54:15.557600 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #245 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.3046659
Z variance train             0.08147054
KL Divergence                4.278467
KL Loss                      0.42784673
QF Loss                      1501.6624
VF Loss                      637.13947
Policy Loss                  -2601.7
Q Predictions Mean           2603.9536
Q Predictions Std            302.67917
Q Predictions Max            2772.6191
Q Predictions Min            466.4326
V Predictions Mean           2597.5283
V Predictions Std            313.31772
V Predictions Max            2777.8557
V Predictions Min            467.60074
Log Pis Mean                 -3.6900783
Log Pis Std                  4.9125595
Log Pis Max                  23.790697
Log Pis Min                  -15.261205
Policy mu Mean               0.07548927
Policy mu Std                0.79857415
Policy mu Max                2.6733966
Policy mu Min                -3.3708363
Policy log std Mean          -0.31362796
Policy log std Std           0.12521791
Policy log std Max           0.024336949
Policy log std Min           -1.250633
Z mean eval                  0.3361313
Z variance eval              0.053416915
total_rewards                [1441.27965803 5505.36176895 1684.55246159 5485.61825253 5452.98262446
 2669.44996642 1713.23387583 5337.32798505 2536.38014429 5238.71360444]
total_rewards_mean           3706.490034157048
total_rewards_std            1734.8170958235326
total_rewards_max            5505.361768945729
total_rewards_min            1441.2796580268027
Number of train steps total  988000
Number of env steps total    1293053
Number of rollouts total     0
Train Time (s)               120.74884164700052
(Previous) Eval Time (s)     17.628941851027776
Sample Time (s)              8.136262842046563
Epoch Time (s)               146.51404634007486
Total Train Time (s)         38288.57829115749
Epoch                        246
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 06:56:42.116244 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #246 | Epoch Duration: 146.55852341651917
2020-01-06 06:56:42.116367 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #246 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.3021676
Z variance train             0.060451638
KL Divergence                4.955229
KL Loss                      0.4955229
QF Loss                      831.261
VF Loss                      532.51105
Policy Loss                  -2621.8508
Q Predictions Mean           2607.5967
Q Predictions Std            283.19247
Q Predictions Max            2765.351
Q Predictions Min            189.3718
V Predictions Mean           2612.3306
V Predictions Std            279.19376
V Predictions Max            2767.5989
V Predictions Min            184.11278
Log Pis Mean                 -4.2794294
Log Pis Std                  4.337301
Log Pis Max                  30.604149
Log Pis Min                  -15.007622
Policy mu Mean               0.09651392
Policy mu Std                0.7634124
Policy mu Max                3.0544717
Policy mu Min                -3.5993598
Policy log std Mean          -0.29816353
Policy log std Std           0.11790922
Policy log std Max           0.027654648
Policy log std Min           -0.97289246
Z mean eval                  0.280996
Z variance eval              0.055336118
total_rewards                [1312.0383332  5360.1933726  5469.88614264 4499.47298487 1226.73199185
 5268.24196175 5493.10549656 1155.8306174  5306.37030609 1570.92692572]
total_rewards_mean           3666.279813267631
total_rewards_std            1938.987540800061
total_rewards_max            5493.105496556945
total_rewards_min            1155.830617402854
Number of train steps total  992000
Number of env steps total    1298053
Number of rollouts total     0
Train Time (s)               126.4487542869756
(Previous) Eval Time (s)     17.673148875997867
Sample Time (s)              8.108752216969151
Epoch Time (s)               152.23065537994262
Total Train Time (s)         38440.306429039396
Epoch                        247
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 06:59:13.848173 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #247 | Epoch Duration: 151.73168921470642
2020-01-06 06:59:13.848400 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #247 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.39936948
Z variance train             0.073111795
KL Divergence                4.743078
KL Loss                      0.47430784
QF Loss                      1149.2139
VF Loss                      196.7524
Policy Loss                  -2634.1428
Q Predictions Mean           2631.7102
Q Predictions Std            277.0071
Q Predictions Max            2783.9585
Q Predictions Min            411.08923
V Predictions Mean           2637.688
V Predictions Std            278.6186
V Predictions Max            2796.3018
V Predictions Min            451.91257
Log Pis Mean                 -5.007575
Log Pis Std                  3.810004
Log Pis Max                  12.094405
Log Pis Min                  -14.6290655
Policy mu Mean               0.07770785
Policy mu Std                0.74701273
Policy mu Max                2.2881021
Policy mu Min                -2.7476301
Policy log std Mean          -0.28531623
Policy log std Std           0.111468256
Policy log std Max           0.0061876774
Policy log std Min           -0.9337887
Z mean eval                  0.20443872
Z variance eval              0.056854744
total_rewards                [4504.37075734 1552.85716097 2069.37950113 4274.52706903 1841.51032234
 1349.64255835 5640.25936824 2003.71774349 5394.13848433 5371.26625948]
total_rewards_mean           3400.166922469497
total_rewards_std            1692.0585248863051
total_rewards_max            5640.259368235376
total_rewards_min            1349.6425583521388
Number of train steps total  996000
Number of env steps total    1303228
Number of rollouts total     0
Train Time (s)               122.91913319501327
(Previous) Eval Time (s)     17.173926301999018
Sample Time (s)              8.035952817939688
Epoch Time (s)               148.12901231495198
Total Train Time (s)         38587.89305034635
Epoch                        248
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 07:01:41.436734 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #248 | Epoch Duration: 147.58815169334412
2020-01-06 07:01:41.436840 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #248 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.18255138
Z variance train             0.041450948
KL Divergence                5.67739
KL Loss                      0.567739
QF Loss                      744.7156
VF Loss                      418.12976
Policy Loss                  -2642.176
Q Predictions Mean           2639.4824
Q Predictions Std            229.50258
Q Predictions Max            2784.0596
Q Predictions Min            604.48676
V Predictions Mean           2647.258
V Predictions Std            223.86226
V Predictions Max            2796.5068
V Predictions Min            601.79596
Log Pis Mean                 -4.7972083
Log Pis Std                  4.3186383
Log Pis Max                  16.829247
Log Pis Min                  -14.740014
Policy mu Mean               0.089536846
Policy mu Std                0.7473559
Policy mu Max                2.6486511
Policy mu Min                -2.6788418
Policy log std Mean          -0.29873052
Policy log std Std           0.11750587
Policy log std Max           -0.06442881
Policy log std Min           -1.1222355
Z mean eval                  1.5560704
Z variance eval              0.93983096
total_rewards                [4973.42777281 4437.32763248 5560.68032878 5475.98097599 5525.0520312
 4708.69310398 4648.00701463 2970.33699012 5498.71956727 5528.16363238]
total_rewards_mean           4932.638904962824
total_rewards_std            771.0058231723892
total_rewards_max            5560.680328776164
total_rewards_min            2970.3369901192905
Number of train steps total  1000000
Number of env steps total    1308756
Number of rollouts total     0
Train Time (s)               125.08785182400607
(Previous) Eval Time (s)     16.63281623797957
Sample Time (s)              8.648450462904293
Epoch Time (s)               150.36911852488993
Total Train Time (s)         38744.98493619828
Epoch                        249
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 07:04:18.531179 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #249 | Epoch Duration: 157.09425044059753
2020-01-06 07:04:18.531304 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #249 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.52924496
Z variance train             0.27741355
KL Divergence                2.600854
KL Loss                      0.2600854
QF Loss                      855.6944
VF Loss                      356.18198
Policy Loss                  -2656.2087
Q Predictions Mean           2647.7761
Q Predictions Std            265.50476
Q Predictions Max            2790.2058
Q Predictions Min            243.90013
V Predictions Mean           2645.9705
V Predictions Std            262.8361
V Predictions Max            2788.95
V Predictions Min            281.40204
Log Pis Mean                 -4.4299545
Log Pis Std                  4.1190767
Log Pis Max                  17.833458
Log Pis Min                  -12.630241
Policy mu Mean               0.08946847
Policy mu Std                0.76054937
Policy mu Max                2.7246976
Policy mu Min                -2.283059
Policy log std Mean          -0.29898822
Policy log std Std           0.110879876
Policy log std Max           -0.017881423
Policy log std Min           -0.94055057
Z mean eval                  0.33504772
Z variance eval              0.2867085
total_rewards                [ 773.97657045 2733.37829331 4274.37052292 5180.67174854 2378.76572521
 5596.31418792 4069.86094992 5614.16880775 3260.95261682 5648.82088597]
total_rewards_mean           3953.1280308824266
total_rewards_std            1565.5891946420106
total_rewards_max            5648.820885967626
total_rewards_min            773.9765704473589
Number of train steps total  1004000
Number of env steps total    1313955
Number of rollouts total     0
Train Time (s)               126.73176371003501
(Previous) Eval Time (s)     23.357710362994112
Sample Time (s)              8.765656799077988
Epoch Time (s)               158.8551308721071
Total Train Time (s)         38899.9901397404
Epoch                        250
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 07:06:53.538910 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #250 | Epoch Duration: 155.00750255584717
2020-01-06 07:06:53.539075 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #250 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.5603915
Z variance train             0.71357125
KL Divergence                1.7324091
KL Loss                      0.17324091
QF Loss                      984.20905
VF Loss                      455.77243
Policy Loss                  -2625.0469
Q Predictions Mean           2620.0474
Q Predictions Std            368.53726
Q Predictions Max            2793.3784
Q Predictions Min            -0.79543054
V Predictions Mean           2631.6748
V Predictions Std            370.86752
V Predictions Max            2815.385
V Predictions Min            23.841393
Log Pis Mean                 -4.2689123
Log Pis Std                  4.9624867
Log Pis Max                  23.809296
Log Pis Min                  -15.856011
Policy mu Mean               0.11806965
Policy mu Std                0.7623322
Policy mu Max                2.895997
Policy mu Min                -2.4924824
Policy log std Mean          -0.29646564
Policy log std Std           0.11515548
Policy log std Max           0.115489006
Policy log std Min           -0.9594915
Z mean eval                  0.94629115
Z variance eval              0.41275924
total_rewards                [5539.13156247 5220.67054912 5570.00392854 2725.20461381 5550.39479006
 4056.86547    5003.53549852 5588.86993089 2944.10711856 5516.9828727 ]
total_rewards_mean           4771.576633466962
total_rewards_std            1065.3810965645182
total_rewards_max            5588.869930887167
total_rewards_min            2725.204613807854
Number of train steps total  1008000
Number of env steps total    1319245
Number of rollouts total     0
Train Time (s)               125.42043596302392
(Previous) Eval Time (s)     19.50982998200925
Sample Time (s)              8.832147635985166
Epoch Time (s)               153.76241358101834
Total Train Time (s)         39056.18206020747
Epoch                        251
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 07:09:29.732858 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #251 | Epoch Duration: 156.19367456436157
2020-01-06 07:09:29.732978 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #251 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6643886
Z variance train             0.23728934
KL Divergence                3.2045448
KL Loss                      0.32045448
QF Loss                      842.47925
VF Loss                      212.7162
Policy Loss                  -2655.118
Q Predictions Mean           2650.2998
Q Predictions Std            297.7485
Q Predictions Max            2829.4792
Q Predictions Min            191.69283
V Predictions Mean           2656.1123
V Predictions Std            301.89288
V Predictions Max            2814.3835
V Predictions Min            179.06337
Log Pis Mean                 -4.534947
Log Pis Std                  4.3084354
Log Pis Max                  11.734295
Log Pis Min                  -15.201871
Policy mu Mean               0.09251736
Policy mu Std                0.754186
Policy mu Max                2.6118135
Policy mu Min                -2.863821
Policy log std Mean          -0.29901105
Policy log std Std           0.1196979
Policy log std Max           0.04646182
Policy log std Min           -1.1051537
Z mean eval                  0.14572802
Z variance eval              0.19551326
total_rewards                [5564.51028583 3862.68237418 1431.97957823 1714.62076927 5436.77460107
 4967.79511591 5535.13859894 5260.3916251  1752.47207677 4269.87068711]
total_rewards_mean           3979.6235712400653
total_rewards_std            1623.2831500367624
total_rewards_max            5564.510285831372
total_rewards_min            1431.9795782290987
Number of train steps total  1012000
Number of env steps total    1324423
Number of rollouts total     0
Train Time (s)               126.99341094400734
(Previous) Eval Time (s)     21.940702288004104
Sample Time (s)              8.537058295973111
Epoch Time (s)               157.47117152798455
Total Train Time (s)         39210.3295053285
Epoch                        252
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 07:12:03.883412 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #252 | Epoch Duration: 154.15034770965576
2020-01-06 07:12:03.883519 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #252 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1480368
Z variance train             0.17585188
KL Divergence                2.4218938
KL Loss                      0.24218939
QF Loss                      890.89606
VF Loss                      278.0896
Policy Loss                  -2646.4314
Q Predictions Mean           2640.3845
Q Predictions Std            234.987
Q Predictions Max            2780.0295
Q Predictions Min            203.71889
V Predictions Mean           2650.295
V Predictions Std            239.31644
V Predictions Max            2786.753
V Predictions Min            184.33032
Log Pis Mean                 -4.8444138
Log Pis Std                  4.2196207
Log Pis Max                  19.61952
Log Pis Min                  -13.880972
Policy mu Mean               0.099230275
Policy mu Std                0.743921
Policy mu Max                2.7205632
Policy mu Min                -2.698474
Policy log std Mean          -0.28916317
Policy log std Std           0.11197186
Policy log std Max           -0.03606859
Policy log std Min           -1.1291916
Z mean eval                  0.10299186
Z variance eval              0.07510413
total_rewards                [2364.03419213 3593.98571277 5585.50700706 5510.1782612  1709.5434039
 4131.97008138 1718.13386288 5550.2231362  3875.7300465  5520.98939459]
total_rewards_mean           3956.0295098616916
total_rewards_std            1510.5936798654043
total_rewards_max            5585.507007059583
total_rewards_min            1709.5434039035706
Number of train steps total  1016000
Number of env steps total    1329423
Number of rollouts total     0
Train Time (s)               125.6375332250027
(Previous) Eval Time (s)     18.619491450022906
Sample Time (s)              8.437889494001865
Epoch Time (s)               152.69491416902747
Total Train Time (s)         39364.399577091564
Epoch                        253
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 07:14:37.956031 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #253 | Epoch Duration: 154.07241678237915
2020-01-06 07:14:37.956185 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #253 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.21376464
Z variance train             0.35370454
KL Divergence                1.2971339
KL Loss                      0.1297134
QF Loss                      1404.1772
VF Loss                      622.24146
Policy Loss                  -2633.4045
Q Predictions Mean           2633.5588
Q Predictions Std            283.0967
Q Predictions Max            2779.1953
Q Predictions Min            92.82117
V Predictions Mean           2643.5806
V Predictions Std            286.64413
V Predictions Max            2793.3901
V Predictions Min            18.246603
Log Pis Mean                 -4.9952497
Log Pis Std                  4.495117
Log Pis Max                  15.077137
Log Pis Min                  -14.241236
Policy mu Mean               0.038386703
Policy mu Std                0.7444442
Policy mu Max                2.3278441
Policy mu Min                -2.542242
Policy log std Mean          -0.29515916
Policy log std Std           0.10756462
Policy log std Max           0.07432845
Policy log std Min           -0.85805637
Z mean eval                  0.10079573
Z variance eval              0.06899913
total_rewards                [2267.35793802 1375.932619   5062.32431877 2236.28099814 5499.50947485
 4930.58456035 5598.22373428 5560.78610258 5557.37966874 2080.2565646 ]
total_rewards_mean           4016.863597933424
total_rewards_std            1683.446077059856
total_rewards_max            5598.223734282869
total_rewards_min            1375.9326190033014
Number of train steps total  1020000
Number of env steps total    1334423
Number of rollouts total     0
Train Time (s)               113.97834936704021
(Previous) Eval Time (s)     19.996714739012532
Sample Time (s)              8.028250150033273
Epoch Time (s)               142.00331425608601
Total Train Time (s)         39505.65003667073
Epoch                        254
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 07:16:59.209183 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #254 | Epoch Duration: 141.25287771224976
2020-01-06 07:16:59.209410 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #254 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14063773
Z variance train             0.18851039
KL Divergence                2.241004
KL Loss                      0.2241004
QF Loss                      1927.1263
VF Loss                      1354.5149
Policy Loss                  -2632.4495
Q Predictions Mean           2631.6934
Q Predictions Std            283.6873
Q Predictions Max            2791.2317
Q Predictions Min            401.07822
V Predictions Mean           2642.014
V Predictions Std            275.0972
V Predictions Max            2802.5337
V Predictions Min            417.59253
Log Pis Mean                 -4.156294
Log Pis Std                  4.5308614
Log Pis Max                  17.023214
Log Pis Min                  -13.941188
Policy mu Mean               0.12212542
Policy mu Std                0.7594495
Policy mu Max                2.583627
Policy mu Min                -2.2216024
Policy log std Mean          -0.2951985
Policy log std Std           0.12083139
Policy log std Max           0.07604027
Policy log std Min           -1.0141382
Z mean eval                  0.120729364
Z variance eval              0.04918035
total_rewards                [1775.02091602 1922.4351281  5551.91105466 1181.92298731 2791.62168096
  937.97304191 4584.66143185 5231.44880027 3468.24090967 1366.17472407]
total_rewards_mean           2881.1410674822355
total_rewards_std            1643.5518333545965
total_rewards_max            5551.911054658193
total_rewards_min            937.9730419077803
Number of train steps total  1024000
Number of env steps total    1339622
Number of rollouts total     0
Train Time (s)               123.31597661896376
(Previous) Eval Time (s)     19.246014675998595
Sample Time (s)              8.69090866507031
Epoch Time (s)               151.25289996003266
Total Train Time (s)         39651.68949937064
Epoch                        255
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 07:19:25.251033 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #255 | Epoch Duration: 146.0414469242096
2020-01-06 07:19:25.251139 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #255 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10554282
Z variance train             0.0802233
KL Divergence                4.059837
KL Loss                      0.4059837
QF Loss                      1312.341
VF Loss                      322.20346
Policy Loss                  -2647.0625
Q Predictions Mean           2645.0898
Q Predictions Std            308.69754
Q Predictions Max            2787.705
Q Predictions Min            335.23532
V Predictions Mean           2651.9922
V Predictions Std            311.66113
V Predictions Max            2799.1558
V Predictions Min            329.0479
Log Pis Mean                 -4.9537106
Log Pis Std                  4.0447936
Log Pis Max                  19.554127
Log Pis Min                  -15.895302
Policy mu Mean               0.1036814
Policy mu Std                0.7557177
Policy mu Max                3.1806426
Policy mu Min                -2.5092194
Policy log std Mean          -0.2957503
Policy log std Std           0.11196172
Policy log std Max           0.54275805
Policy log std Min           -1.0349979
Z mean eval                  0.20990792
Z variance eval              0.06239956
total_rewards                [2962.43134306 5341.86153019 5396.18753269 5423.56635759 4845.48520389
 5385.15329485 5344.21297825 5455.06513615 2346.4858033  5448.77582652]
total_rewards_mean           4794.922500649936
total_rewards_std            1092.001951479459
total_rewards_max            5455.065136149404
total_rewards_min            2346.4858033038036
Number of train steps total  1028000
Number of env steps total    1344622
Number of rollouts total     0
Train Time (s)               125.33210787799908
(Previous) Eval Time (s)     14.034333827032242
Sample Time (s)              8.082778203010093
Epoch Time (s)               147.4492199080414
Total Train Time (s)         39808.44657421461
Epoch                        256
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 07:22:02.010458 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #256 | Epoch Duration: 156.7592167854309
2020-01-06 07:22:02.010624 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #256 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.20107631
Z variance train             0.08988131
KL Divergence                3.8892584
KL Loss                      0.38892585
QF Loss                      954.4736
VF Loss                      382.94128
Policy Loss                  -2682.263
Q Predictions Mean           2678.7534
Q Predictions Std            189.06943
Q Predictions Max            2829.147
Q Predictions Min            1067.9508
V Predictions Mean           2674.6865
V Predictions Std            183.07997
V Predictions Max            2809.225
V Predictions Min            1209.953
Log Pis Mean                 -4.8576694
Log Pis Std                  5.3782067
Log Pis Max                  25.599606
Log Pis Min                  -16.461838
Policy mu Mean               0.075205885
Policy mu Std                0.7540157
Policy mu Max                3.0382094
Policy mu Min                -3.2337775
Policy log std Mean          -0.2886769
Policy log std Std           0.118567616
Policy log std Max           0.008069634
Policy log std Min           -1.1456242
Z mean eval                  0.28234023
Z variance eval              0.06770954
total_rewards                [5287.35803716 1474.43785338 3516.86801909 5573.70507529 1928.5872119
 5501.15718608 2082.13744938 1406.83296126 5490.09716142 5517.8440248 ]
total_rewards_mean           3777.9024979767223
total_rewards_std            1781.1126288693035
total_rewards_max            5573.7050752893565
total_rewards_min            1406.8329612603889
Number of train steps total  1032000
Number of env steps total    1349622
Number of rollouts total     0
Train Time (s)               126.87003790901508
(Previous) Eval Time (s)     23.344068566977512
Sample Time (s)              8.093196721107233
Epoch Time (s)               158.30730319709983
Total Train Time (s)         39961.39927299076
Epoch                        257
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 07:24:34.965095 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #257 | Epoch Duration: 152.95432949066162
2020-01-06 07:24:34.965218 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #257 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.20497552
Z variance train             0.044103354
KL Divergence                5.55054
KL Loss                      0.555054
QF Loss                      628.6372
VF Loss                      331.12747
Policy Loss                  -2681.0437
Q Predictions Mean           2678.961
Q Predictions Std            228.34132
Q Predictions Max            2805.1025
Q Predictions Min            556.70483
V Predictions Mean           2676.627
V Predictions Std            233.103
V Predictions Max            2800.9956
V Predictions Min            507.25296
Log Pis Mean                 -4.557435
Log Pis Std                  4.5832944
Log Pis Max                  18.503132
Log Pis Min                  -14.428087
Policy mu Mean               0.092428125
Policy mu Std                0.76042676
Policy mu Max                2.428913
Policy mu Min                -2.209324
Policy log std Mean          -0.29235622
Policy log std Std           0.116508774
Policy log std Max           -0.034929037
Policy log std Min           -0.89093065
Z mean eval                  0.25238
Z variance eval              0.05712719
total_rewards                [1629.79514952 5197.61099069 5349.26155682 5578.45329237 3138.15860019
 2514.79367102 3688.56128177 3290.78967801 5600.28630669 5532.82825592]
total_rewards_mean           4152.053878300185
total_rewards_std            1399.7150196995235
total_rewards_max            5600.286306689342
total_rewards_min            1629.7951495234452
Number of train steps total  1036000
Number of env steps total    1354622
Number of rollouts total     0
Train Time (s)               128.11119113402674
(Previous) Eval Time (s)     17.99086649203673
Sample Time (s)              8.053103908838239
Epoch Time (s)               154.1551615349017
Total Train Time (s)         40117.25543904072
Epoch                        258
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 07:27:10.823918 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #258 | Epoch Duration: 155.85859560966492
2020-01-06 07:27:10.824030 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #258 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.2910715
Z variance train             0.057021387
KL Divergence                5.073987
KL Loss                      0.5073987
QF Loss                      1369.225
VF Loss                      484.47247
Policy Loss                  -2669.91
Q Predictions Mean           2668.2637
Q Predictions Std            269.08698
Q Predictions Max            2820.2478
Q Predictions Min            324.37173
V Predictions Mean           2662.2402
V Predictions Std            275.96964
V Predictions Max            2819.4773
V Predictions Min            282.30045
Log Pis Mean                 -4.396665
Log Pis Std                  5.1505165
Log Pis Max                  34.18592
Log Pis Min                  -14.364197
Policy mu Mean               0.07612802
Policy mu Std                0.7620339
Policy mu Max                3.5740104
Policy mu Min                -2.9882846
Policy log std Mean          -0.29619193
Policy log std Std           0.13039772
Policy log std Max           0.042959094
Policy log std Min           -1.4004978
Z mean eval                  0.28778002
Z variance eval              0.04723524
total_rewards                [5585.56425443  576.3117169  4569.37240548 5356.45940838 5571.76616782
 5619.46279509 5495.45151987 5339.2740191  5619.3039983  3271.29558888]
total_rewards_mean           4700.42618742394
total_rewards_std            1541.7570633002028
total_rewards_max            5619.462795090988
total_rewards_min            576.3117168990983
Number of train steps total  1040000
Number of env steps total    1359799
Number of rollouts total     0
Train Time (s)               129.89667978300713
(Previous) Eval Time (s)     19.694060471025296
Sample Time (s)              8.080699819955043
Epoch Time (s)               157.67144007398747
Total Train Time (s)         40278.32143966755
Epoch                        259
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 07:29:51.892498 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #259 | Epoch Duration: 161.06837368011475
2020-01-06 07:29:51.892636 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #259 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.40561008
Z variance train             0.06521134
KL Divergence                5.0506053
KL Loss                      0.50506055
QF Loss                      977.9719
VF Loss                      547.27576
Policy Loss                  -2689.922
Q Predictions Mean           2690.31
Q Predictions Std            214.66327
Q Predictions Max            2804.4705
Q Predictions Min            163.34447
V Predictions Mean           2688.3372
V Predictions Std            220.63896
V Predictions Max            2813.3406
V Predictions Min            151.20691
Log Pis Mean                 -4.849412
Log Pis Std                  4.049301
Log Pis Max                  15.589912
Log Pis Min                  -12.433319
Policy mu Mean               0.08053077
Policy mu Std                0.7473897
Policy mu Max                2.5698113
Policy mu Min                -2.8737614
Policy log std Mean          -0.29259345
Policy log std Std           0.11541484
Policy log std Max           0.3767435
Policy log std Min           -1.050901
Z mean eval                  0.29254198
Z variance eval              0.06936498
total_rewards                [5498.20818663 5522.80852666 3613.08908392 3950.36454567 5416.55138825
 5538.29284684 3076.58034454 3682.36854356 3350.98714193 5543.05758043]
total_rewards_mean           4519.230818842706
total_rewards_std            1007.3992053385232
total_rewards_max            5543.057580433094
total_rewards_min            3076.580344535918
Number of train steps total  1044000
Number of env steps total    1365244
Number of rollouts total     0
Train Time (s)               130.33357315399917
(Previous) Eval Time (s)     23.090734373021405
Sample Time (s)              8.97264923795592
Epoch Time (s)               162.3969567649765
Total Train Time (s)         40438.68487811065
Epoch                        260
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 07:32:32.259370 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #260 | Epoch Duration: 160.36661624908447
2020-01-06 07:32:32.259556 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #260 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.38739994
Z variance train             0.090966456
KL Divergence                4.175948
KL Loss                      0.41759482
QF Loss                      911.12616
VF Loss                      390.46234
Policy Loss                  -2696.1755
Q Predictions Mean           2686.0898
Q Predictions Std            209.48737
Q Predictions Max            2805.8274
Q Predictions Min            674.54065
V Predictions Mean           2697.226
V Predictions Std            214.65378
V Predictions Max            2818.9282
V Predictions Min            682.99243
Log Pis Mean                 -5.2680635
Log Pis Std                  4.125112
Log Pis Max                  23.111485
Log Pis Min                  -15.696947
Policy mu Mean               0.12630421
Policy mu Std                0.71977466
Policy mu Max                2.3846722
Policy mu Min                -4.27654
Policy log std Mean          -0.28113052
Policy log std Std           0.11315989
Policy log std Max           -0.040051505
Policy log std Min           -1.0878553
Z mean eval                  0.18645325
Z variance eval              0.04731999
total_rewards                [2585.73067822 5506.60916846 5262.74524048 1462.83273246  922.77316261
 1964.481352   5215.89286459 1979.35505435 4731.40410293 5545.74014388]
total_rewards_mean           3517.75644999662
total_rewards_std            1790.9358155867665
total_rewards_max            5545.740143875275
total_rewards_min            922.7731626052782
Number of train steps total  1048000
Number of env steps total    1370244
Number of rollouts total     0
Train Time (s)               122.32610558101442
(Previous) Eval Time (s)     21.060102880001068
Sample Time (s)              8.075223103980534
Epoch Time (s)               151.46143156499602
Total Train Time (s)         40584.615083891666
Epoch                        261
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 07:34:58.192476 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #261 | Epoch Duration: 145.93276810646057
2020-01-06 07:34:58.192622 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #261 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.19539505
Z variance train             0.037522305
KL Divergence                5.9361267
KL Loss                      0.5936127
QF Loss                      1259.3516
VF Loss                      936.00055
Policy Loss                  -2690.84
Q Predictions Mean           2689.3733
Q Predictions Std            205.12677
Q Predictions Max            2815.3062
Q Predictions Min            635.97034
V Predictions Mean           2687.0474
V Predictions Std            197.84802
V Predictions Max            2813.6333
V Predictions Min            581.67114
Log Pis Mean                 -5.377519
Log Pis Std                  4.4561415
Log Pis Max                  15.488516
Log Pis Min                  -13.9205265
Policy mu Mean               0.08737117
Policy mu Std                0.7242879
Policy mu Max                2.6055026
Policy mu Min                -2.6288476
Policy log std Mean          -0.27593625
Policy log std Std           0.11595198
Policy log std Max           0.009002119
Policy log std Min           -1.1194791
Z mean eval                  0.23688436
Z variance eval              0.076691225
total_rewards                [5520.24887905 3983.88409617 2799.42340551 3011.63023242 1815.42516032
 3700.71672391 4198.81984455 5241.87318848 4741.65049931 1963.22360506]
total_rewards_mean           3697.689563478046
total_rewards_std            1223.0281654780438
total_rewards_max            5520.248879053277
total_rewards_min            1815.425160315425
Number of train steps total  1052000
Number of env steps total    1375577
Number of rollouts total     0
Train Time (s)               121.59676520200446
(Previous) Eval Time (s)     15.531186920008622
Sample Time (s)              8.516558486095164
Epoch Time (s)               145.64451060810825
Total Train Time (s)         40731.14796211274
Epoch                        262
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 07:37:24.727271 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #262 | Epoch Duration: 146.53452682495117
2020-01-06 07:37:24.727381 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #262 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.2980985
Z variance train             0.12962463
KL Divergence                3.2389588
KL Loss                      0.3238959
QF Loss                      726.16406
VF Loss                      529.73645
Policy Loss                  -2691.887
Q Predictions Mean           2685.1611
Q Predictions Std            195.56187
Q Predictions Max            2816.7175
Q Predictions Min            450.05753
V Predictions Mean           2677.2788
V Predictions Std            194.82426
V Predictions Max            2813.323
V Predictions Min            409.74265
Log Pis Mean                 -4.4031105
Log Pis Std                  4.189082
Log Pis Max                  16.428978
Log Pis Min                  -14.832886
Policy mu Mean               0.12186405
Policy mu Std                0.74219763
Policy mu Max                2.2962508
Policy mu Min                -2.363892
Policy log std Mean          -0.30198887
Policy log std Std           0.11958275
Policy log std Max           -0.0014173687
Policy log std Min           -0.9449916
Z mean eval                  0.15731177
Z variance eval              0.04956445
total_rewards                [5576.31394526 5518.68730635 5491.14646228 2781.99813372 5553.06878609
 1891.399693   1511.57846194 1222.26023045 5568.42174007 1358.49245844]
total_rewards_mean           3647.336721759069
total_rewards_std            1935.4150966358934
total_rewards_max            5576.3139452621945
total_rewards_min            1222.2602304461232
Number of train steps total  1056000
Number of env steps total    1380744
Number of rollouts total     0
Train Time (s)               123.16212794202147
(Previous) Eval Time (s)     16.420966175035574
Sample Time (s)              7.409833244048059
Epoch Time (s)               146.9929273611051
Total Train Time (s)         40878.083734143875
Epoch                        263
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 07:39:51.666391 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #263 | Epoch Duration: 146.93891739845276
2020-01-06 07:39:51.666526 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #263 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.17600074
Z variance train             0.052673448
KL Divergence                5.0950565
KL Loss                      0.5095057
QF Loss                      485.38538
VF Loss                      200.70175
Policy Loss                  -2685.9001
Q Predictions Mean           2679.92
Q Predictions Std            291.7718
Q Predictions Max            2822.9587
Q Predictions Min            66.3896
V Predictions Mean           2679.145
V Predictions Std            295.15692
V Predictions Max            2820.7676
V Predictions Min            -31.367384
Log Pis Mean                 -4.536901
Log Pis Std                  3.7739239
Log Pis Max                  14.717004
Log Pis Min                  -14.635891
Policy mu Mean               0.09994048
Policy mu Std                0.7474265
Policy mu Max                2.805802
Policy mu Min                -2.5541413
Policy log std Mean          -0.29376063
Policy log std Std           0.11641886
Policy log std Max           0.25489652
Policy log std Min           -1.2434893
Z mean eval                  0.1819404
Z variance eval              0.041992944
total_rewards                [5519.43546189  563.434766   5489.95897223 5368.91851393 2924.86230432
 3325.13266506  504.84223698 5315.9347533  5363.3145793  3085.45644105]
total_rewards_mean           3746.1290694065538
total_rewards_std            1892.6772435944
total_rewards_max            5519.435461886263
total_rewards_min            504.84223698424756
Number of train steps total  1060000
Number of env steps total    1385943
Number of rollouts total     0
Train Time (s)               117.17503575701267
(Previous) Eval Time (s)     16.366724284016527
Sample Time (s)              8.666624262928963
Epoch Time (s)               142.20838430395816
Total Train Time (s)         41021.8680460779
Epoch                        264
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 07:42:15.453204 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #264 | Epoch Duration: 143.78656578063965
2020-01-06 07:42:15.453379 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #264 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.19484434
Z variance train             0.042326044
KL Divergence                5.6473217
KL Loss                      0.5647322
QF Loss                      1526.7134
VF Loss                      373.85693
Policy Loss                  -2692.3748
Q Predictions Mean           2696.6318
Q Predictions Std            173.89342
Q Predictions Max            2810.4832
Q Predictions Min            716.8199
V Predictions Mean           2697.193
V Predictions Std            182.08199
V Predictions Max            2834.0757
V Predictions Min            734.65094
Log Pis Mean                 -4.673366
Log Pis Std                  3.879728
Log Pis Max                  12.344357
Log Pis Min                  -15.718483
Policy mu Mean               0.09559199
Policy mu Std                0.7353881
Policy mu Max                2.014912
Policy mu Min                -2.7292857
Policy log std Mean          -0.28563753
Policy log std Std           0.11689819
Policy log std Max           -0.04795354
Policy log std Min           -0.8668723
Z mean eval                  0.20017591
Z variance eval              0.050365068
total_rewards                [5562.59449847  882.31087427 3289.67926341 5351.84272369 5490.0343383
 5388.60343939 5510.48562224 5466.71601155 5412.60050594 5446.8886984 ]
total_rewards_mean           4780.175597567319
total_rewards_std            1451.7972767935873
total_rewards_max            5562.59449847087
total_rewards_min            882.3108742726062
Number of train steps total  1064000
Number of env steps total    1391106
Number of rollouts total     0
Train Time (s)               119.0786806170363
(Previous) Eval Time (s)     17.94464506098302
Sample Time (s)              8.568617027951404
Epoch Time (s)               145.59194270597072
Total Train Time (s)         41173.28778421797
Epoch                        265
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 07:44:46.875246 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #265 | Epoch Duration: 151.42173647880554
2020-01-06 07:44:46.875405 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #265 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.18327834
Z variance train             0.04247671
KL Divergence                5.628949
KL Loss                      0.56289494
QF Loss                      792.96234
VF Loss                      205.2645
Policy Loss                  -2709.2021
Q Predictions Mean           2707.058
Q Predictions Std            224.97313
Q Predictions Max            2825.9585
Q Predictions Min            189.50858
V Predictions Mean           2705.4666
V Predictions Std            225.85017
V Predictions Max            2817.396
V Predictions Min            146.50934
Log Pis Mean                 -5.498395
Log Pis Std                  3.6505313
Log Pis Max                  8.806536
Log Pis Min                  -15.423534
Policy mu Mean               0.0828834
Policy mu Std                0.7128838
Policy mu Max                2.461314
Policy mu Min                -2.2045047
Policy log std Mean          -0.2753187
Policy log std Std           0.12065456
Policy log std Max           -0.011790842
Policy log std Min           -1.1336503
Z mean eval                  0.20727357
Z variance eval              0.036587916
total_rewards                [4372.69645294 1915.08607575 2436.87863757 2968.14128234 1268.5134593
 5566.7263899  5520.60788795 3337.25748524  801.51569572 4830.37601394]
total_rewards_mean           3301.7799380651913
total_rewards_std            1634.1875485206506
total_rewards_max            5566.726389896018
total_rewards_min            801.5156957229314
Number of train steps total  1068000
Number of env steps total    1396106
Number of rollouts total     0
Train Time (s)               95.9719353110413
(Previous) Eval Time (s)     23.774169376993086
Sample Time (s)              8.39773980010068
Epoch Time (s)               128.14384448813507
Total Train Time (s)         41289.371901943116
Epoch                        266
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 07:46:42.961307 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #266 | Epoch Duration: 116.08576703071594
2020-01-06 07:46:42.961414 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #266 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.24115507
Z variance train             0.055599846
KL Divergence                5.0739536
KL Loss                      0.5073954
QF Loss                      563.40314
VF Loss                      473.3812
Policy Loss                  -2723.9832
Q Predictions Mean           2714.2869
Q Predictions Std            78.79474
Q Predictions Max            2818.1187
Q Predictions Min            2050.5283
V Predictions Mean           2718.7883
V Predictions Std            87.22724
V Predictions Max            2828.3364
V Predictions Min            1956.2316
Log Pis Mean                 -5.0864544
Log Pis Std                  4.2257314
Log Pis Max                  17.697647
Log Pis Min                  -16.731441
Policy mu Mean               0.10994963
Policy mu Std                0.73755366
Policy mu Max                2.3861313
Policy mu Min                -2.276678
Policy log std Mean          -0.28524825
Policy log std Std           0.116650656
Policy log std Max           -0.05308801
Policy log std Min           -1.0772214
Z mean eval                  0.18309607
Z variance eval              0.04265182
total_rewards                [3612.32696327 2299.66017963 5614.89001434 5622.28931469 4273.87004384
 2039.45778102 3001.90378796 2709.91892763 2926.74273808 5510.75341087]
total_rewards_mean           3761.1813161333944
total_rewards_std            1331.3259354218208
total_rewards_max            5622.289314685828
total_rewards_min            2039.4577810237593
Number of train steps total  1072000
Number of env steps total    1401280
Number of rollouts total     0
Train Time (s)               88.46513158001471
(Previous) Eval Time (s)     11.71584001701558
Sample Time (s)              6.180731320811901
Epoch Time (s)               106.3617029178422
Total Train Time (s)         41397.37977927993
Epoch                        267
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 07:48:30.971392 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #267 | Epoch Duration: 108.00988936424255
2020-01-06 07:48:30.971514 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #267 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.25785127
Z variance train             0.09656177
KL Divergence                3.8282802
KL Loss                      0.38282803
QF Loss                      628.5681
VF Loss                      552.86707
Policy Loss                  -2693.5667
Q Predictions Mean           2695.7942
Q Predictions Std            255.23177
Q Predictions Max            2827.7083
Q Predictions Min            442.5973
V Predictions Mean           2698.3357
V Predictions Std            266.96762
V Predictions Max            2832.4597
V Predictions Min            439.4528
Log Pis Mean                 -5.1029644
Log Pis Std                  3.6814272
Log Pis Max                  15.162678
Log Pis Min                  -13.653557
Policy mu Mean               0.079265654
Policy mu Std                0.7191844
Policy mu Max                2.485288
Policy mu Min                -2.3773415
Policy log std Mean          -0.2791354
Policy log std Std           0.11494078
Policy log std Max           -0.046783842
Policy log std Min           -0.9195627
Z mean eval                  0.13309184
Z variance eval              0.08285136
total_rewards                [1735.01049195 5461.31102538 5387.15774247 3171.41076857 5440.76423683
 5551.89135516 4159.76056445 5413.78101133 5484.74796175 5483.36369857]
total_rewards_mean           4728.919885646151
total_rewards_std            1244.0436096439732
total_rewards_max            5551.89135515864
total_rewards_min            1735.0104919490113
Number of train steps total  1076000
Number of env steps total    1406916
Number of rollouts total     0
Train Time (s)               87.26685252401512
(Previous) Eval Time (s)     13.363789518014528
Sample Time (s)              6.940471998008434
Epoch Time (s)               107.57111404003808
Total Train Time (s)         41509.195849804964
Epoch                        268
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 07:50:22.789725 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #268 | Epoch Duration: 111.81812334060669
2020-01-06 07:50:22.789832 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #268 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.15228939
Z variance train             0.043578085
KL Divergence                5.5363817
KL Loss                      0.55363816
QF Loss                      959.4531
VF Loss                      395.7028
Policy Loss                  -2708.1125
Q Predictions Mean           2710.2903
Q Predictions Std            125.698364
Q Predictions Max            2819.1338
Q Predictions Min            1381.247
V Predictions Mean           2711.2554
V Predictions Std            128.91971
V Predictions Max            2837.1482
V Predictions Min            1422.4252
Log Pis Mean                 -4.97724
Log Pis Std                  5.2386312
Log Pis Max                  29.23248
Log Pis Min                  -14.380606
Policy mu Mean               0.098713525
Policy mu Std                0.73837155
Policy mu Max                3.6339893
Policy mu Min                -2.8480601
Policy log std Mean          -0.2825828
Policy log std Std           0.11303341
Policy log std Max           -0.06732057
Policy log std Min           -1.222962
Z mean eval                  0.19608267
Z variance eval              0.0808243
total_rewards                [5310.18645559 4003.31221346 4239.74576039 1520.70842746 3451.22361251
 5061.43565113 5626.29891877 1741.27571559 4383.92237699 2096.48787081]
total_rewards_mean           3743.459700269588
total_rewards_std            1421.5510734842842
total_rewards_max            5626.298918768062
total_rewards_min            1520.7084274635713
Number of train steps total  1080000
Number of env steps total    1411916
Number of rollouts total     0
Train Time (s)               87.02682257100241
(Previous) Eval Time (s)     17.61056457197992
Sample Time (s)              6.259555487893522
Epoch Time (s)               110.89694263087586
Total Train Time (s)         41617.46149448096
Epoch                        269
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 07:52:11.058532 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #269 | Epoch Duration: 108.26861095428467
2020-01-06 07:52:11.058702 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #269 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.23231813
Z variance train             0.08842053
KL Divergence                3.9895964
KL Loss                      0.39895964
QF Loss                      1440.9602
VF Loss                      452.38794
Policy Loss                  -2707.5515
Q Predictions Mean           2706.2888
Q Predictions Std            116.29685
Q Predictions Max            2821.278
Q Predictions Min            1786.0208
V Predictions Mean           2716.3467
V Predictions Std            131.54518
V Predictions Max            2836.5608
V Predictions Min            1751.0951
Log Pis Mean                 -4.6338944
Log Pis Std                  4.780334
Log Pis Max                  25.750162
Log Pis Min                  -13.742937
Policy mu Mean               0.05935594
Policy mu Std                0.75574154
Policy mu Max                2.8049664
Policy mu Min                -2.7328823
Policy log std Mean          -0.28424045
Policy log std Std           0.12161012
Policy log std Max           -0.024177834
Policy log std Min           -1.1541039
Z mean eval                  0.3144276
Z variance eval              0.13611202
total_rewards                [2268.87183619 5414.58166431 5391.19951756 1668.31429885 1814.93480069
 2071.06606301 2016.82015556 5301.78550049  668.48927661 4127.54655029]
total_rewards_mean           3074.3609663548955
total_rewards_std            1704.116773311978
total_rewards_max            5414.581664307132
total_rewards_min            668.4892766063386
Number of train steps total  1084000
Number of env steps total    1417110
Number of rollouts total     0
Train Time (s)               89.38692021404859
(Previous) Eval Time (s)     14.981990622996818
Sample Time (s)              7.342489426955581
Epoch Time (s)               111.71140026400099
Total Train Time (s)         41726.558178608946
Epoch                        270
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 07:54:00.157855 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #270 | Epoch Duration: 109.09904837608337
2020-01-06 07:54:00.157972 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #270 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.2883937
Z variance train             0.103709675
KL Divergence                3.728334
KL Loss                      0.3728334
QF Loss                      516.3967
VF Loss                      200.78622
Policy Loss                  -2716.0852
Q Predictions Mean           2719.5615
Q Predictions Std            238.05339
Q Predictions Max            2839.7932
Q Predictions Min            108.83183
V Predictions Mean           2720.4102
V Predictions Std            236.19437
V Predictions Max            2841.682
V Predictions Min            158.55177
Log Pis Mean                 -5.157888
Log Pis Std                  3.7024193
Log Pis Max                  8.03708
Log Pis Min                  -13.812856
Policy mu Mean               0.07703508
Policy mu Std                0.7243912
Policy mu Max                2.3631177
Policy mu Min                -2.3885577
Policy log std Mean          -0.283123
Policy log std Std           0.10400233
Policy log std Max           0.044357836
Policy log std Min           -0.7455237
Z mean eval                  0.2702164
Z variance eval              0.08769819
total_rewards                [5356.94546902 5428.04624253 3753.19440646 2835.92896889 5210.18503588
 1284.05497392 5510.60934459 3277.34359465 2618.41790617 4482.62176871]
total_rewards_mean           3975.7347710819813
total_rewards_std            1381.2123066842146
total_rewards_max            5510.609344586291
total_rewards_min            1284.0549739185208
Number of train steps total  1088000
Number of env steps total    1422253
Number of rollouts total     0
Train Time (s)               88.85351015802007
(Previous) Eval Time (s)     12.369407930003945
Sample Time (s)              6.918736218067352
Epoch Time (s)               108.14165430609137
Total Train Time (s)         41838.69913073699
Epoch                        271
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 07:55:52.301166 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #271 | Epoch Duration: 112.1430983543396
2020-01-06 07:55:52.301275 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #271 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.23941985
Z variance train             0.11924269
KL Divergence                3.326532
KL Loss                      0.3326532
QF Loss                      1122.8507
VF Loss                      301.39465
Policy Loss                  -2700.903
Q Predictions Mean           2700.0142
Q Predictions Std            254.57497
Q Predictions Max            2821.8481
Q Predictions Min            357.58157
V Predictions Mean           2700.004
V Predictions Std            252.13371
V Predictions Max            2824.6692
V Predictions Min            407.0124
Log Pis Mean                 -5.402953
Log Pis Std                  4.190323
Log Pis Max                  15.039245
Log Pis Min                  -13.982409
Policy mu Mean               0.07871907
Policy mu Std                0.73286194
Policy mu Max                2.4245408
Policy mu Min                -2.3452125
Policy log std Mean          -0.2862421
Policy log std Std           0.1156835
Policy log std Max           0.0017700344
Policy log std Min           -1.1918344
Z mean eval                  0.30384937
Z variance eval              0.13687298
total_rewards                [5409.51074542 3836.88177451 1181.90290415  832.5181391  4506.61611901
 1689.93416844 5273.07749906 2469.16880478 5402.40737839 1385.22629716]
total_rewards_mean           3198.7243830019734
total_rewards_std            1786.8558142951213
total_rewards_max            5409.510745419609
total_rewards_min            832.518139101501
Number of train steps total  1092000
Number of env steps total    1427253
Number of rollouts total     0
Train Time (s)               91.90719817799982
(Previous) Eval Time (s)     16.370596266002394
Sample Time (s)              6.843943781801499
Epoch Time (s)               115.12173822580371
Total Train Time (s)         41950.32505251386
Epoch                        272
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 07:57:43.929921 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #272 | Epoch Duration: 111.62854814529419
2020-01-06 07:57:43.930080 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #272 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.36200485
Z variance train             0.16951862
KL Divergence                2.809665
KL Loss                      0.2809665
QF Loss                      895.60876
VF Loss                      344.07156
Policy Loss                  -2706.3782
Q Predictions Mean           2707.3276
Q Predictions Std            208.96883
Q Predictions Max            2827.8213
Q Predictions Min            371.3072
V Predictions Mean           2712.4426
V Predictions Std            206.1095
V Predictions Max            2835.0413
V Predictions Min            398.0276
Log Pis Mean                 -4.6778564
Log Pis Std                  4.3818693
Log Pis Max                  17.14568
Log Pis Min                  -14.186251
Policy mu Mean               0.07606735
Policy mu Std                0.750788
Policy mu Max                2.3890598
Policy mu Min                -2.01552
Policy log std Mean          -0.28987202
Policy log std Std           0.11514364
Policy log std Max           0.091603994
Policy log std Min           -0.9530668
Z mean eval                  0.12773776
Z variance eval              0.071587175
total_rewards                [5294.39178418 4876.88814539 5392.26052122 5324.22347661 5212.90554825
 1877.48498268 5058.67842718 5268.89598092 5152.57213004 3720.46656886]
total_rewards_mean           4717.876756532607
total_rewards_std            1053.401065791917
total_rewards_max            5392.260521221964
total_rewards_min            1877.4849826756556
Number of train steps total  1096000
Number of env steps total    1432434
Number of rollouts total     0
Train Time (s)               91.55210363201331
(Previous) Eval Time (s)     12.877162773977034
Sample Time (s)              7.279084587120451
Epoch Time (s)               111.7083509931108
Total Train Time (s)         42068.35226131894
Epoch                        273
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 07:59:41.960291 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #273 | Epoch Duration: 118.03009390830994
2020-01-06 07:59:41.960480 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #273 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.15350586
Z variance train             0.09134155
KL Divergence                3.8179507
KL Loss                      0.38179508
QF Loss                      693.6376
VF Loss                      308.7462
Policy Loss                  -2718.115
Q Predictions Mean           2710.2979
Q Predictions Std            181.90836
Q Predictions Max            2822.4653
Q Predictions Min            785.7472
V Predictions Mean           2708.958
V Predictions Std            189.13248
V Predictions Max            2829.6409
V Predictions Min            667.655
Log Pis Mean                 -5.3090544
Log Pis Std                  3.8213367
Log Pis Max                  8.227493
Log Pis Min                  -17.501348
Policy mu Mean               0.057899248
Policy mu Std                0.7238938
Policy mu Max                2.2529469
Policy mu Min                -2.6521063
Policy log std Mean          -0.28606585
Policy log std Std           0.11079405
Policy log std Max           -0.06263198
Policy log std Min           -0.9471865
Z mean eval                  0.122729614
Z variance eval              0.06494393
total_rewards                [5430.77411002 5552.94193924  609.88391173 2134.01173615 5388.45900133
  264.24426272 1346.45418734 1273.11892639 4550.62259293 3878.32780785]
total_rewards_mean           3042.8838475676107
total_rewards_std            2023.6524820133957
total_rewards_max            5552.941939235131
total_rewards_min            264.244262717131
Number of train steps total  1100000
Number of env steps total    1437618
Number of rollouts total     0
Train Time (s)               94.91270282998448
(Previous) Eval Time (s)     19.198653662984725
Sample Time (s)              7.044101914041676
Epoch Time (s)               121.15545840701088
Total Train Time (s)         42181.792789323896
Epoch                        274
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 08:01:35.403874 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #274 | Epoch Duration: 113.44325494766235
2020-01-06 08:01:35.404007 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #274 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2745092
Z variance train             0.035390556
KL Divergence                17.459438
KL Loss                      1.7459439
QF Loss                      887.0576
VF Loss                      488.50635
Policy Loss                  -2681.1077
Q Predictions Mean           2675.9941
Q Predictions Std            236.35939
Q Predictions Max            2801.3013
Q Predictions Min            488.66632
V Predictions Mean           2675.7495
V Predictions Std            237.41034
V Predictions Max            2805.8435
V Predictions Min            500.5489
Log Pis Mean                 -4.611437
Log Pis Std                  4.7837534
Log Pis Max                  22.178232
Log Pis Min                  -15.84788
Policy mu Mean               0.07678175
Policy mu Std                0.7351321
Policy mu Max                2.5225549
Policy mu Min                -3.1483197
Policy log std Mean          -0.28115776
Policy log std Std           0.13047361
Policy log std Max           -0.015751898
Policy log std Min           -1.169674
Z mean eval                  0.15085378
Z variance eval              0.07152828
total_rewards                [1271.93326706 5580.42886402 3018.22072156 1081.11843967 5482.11506247
 5487.17321371 1748.34351543 2680.32641941 3812.40407385 3052.89780558]
total_rewards_mean           3321.496138277137
total_rewards_std            1642.3223804294887
total_rewards_max            5580.428864017659
total_rewards_min            1081.118439672753
Number of train steps total  1104000
Number of env steps total    1442965
Number of rollouts total     0
Train Time (s)               128.6369207939715
(Previous) Eval Time (s)     11.486212546005845
Sample Time (s)              8.734955188876484
Epoch Time (s)               148.85808852885384
Total Train Time (s)         42332.81187747978
Epoch                        275
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 08:04:06.613002 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #275 | Epoch Duration: 151.20887184143066
2020-01-06 08:04:06.613284 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #275 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.17158584
Z variance train             0.06262563
KL Divergence                4.7060337
KL Loss                      0.47060338
QF Loss                      1433.4751
VF Loss                      698.3293
Policy Loss                  -2714.4268
Q Predictions Mean           2719.459
Q Predictions Std            131.28506
Q Predictions Max            2820.9104
Q Predictions Min            1292.0416
V Predictions Mean           2735.4446
V Predictions Std            129.95984
V Predictions Max            2845.5994
V Predictions Min            1449.947
Log Pis Mean                 -4.366207
Log Pis Std                  4.1626472
Log Pis Max                  16.677303
Log Pis Min                  -14.140009
Policy mu Mean               0.11162872
Policy mu Std                0.749185
Policy mu Max                2.3070786
Policy mu Min                -2.5199263
Policy log std Mean          -0.2946071
Policy log std Std           0.11279987
Policy log std Max           -0.06850952
Policy log std Min           -1.0140936
Z mean eval                  0.14157943
Z variance eval              0.04856211
total_rewards                [5570.91314736 3211.35615758 5397.07261136 5437.16094396 1755.89313543
 1846.88956626 5469.01352148 5459.20977654 1386.05724433 3795.20954846]
total_rewards_mean           3932.877565276291
total_rewards_std            1670.201975548121
total_rewards_max            5570.913147357863
total_rewards_min            1386.0572443295591
Number of train steps total  1108000
Number of env steps total    1448618
Number of rollouts total     0
Train Time (s)               100.20599376200698
(Previous) Eval Time (s)     13.836729689035565
Sample Time (s)              7.254207794030663
Epoch Time (s)               121.29693124507321
Total Train Time (s)         42457.754663995875
Epoch                        276
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 08:06:11.369997 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #276 | Epoch Duration: 124.75650572776794
2020-01-06 08:06:11.370115 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #276 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.13955064
Z variance train             0.03958353
KL Divergence                5.7635303
KL Loss                      0.576353
QF Loss                      2438.5137
VF Loss                      1195.9144
Policy Loss                  -2703.6057
Q Predictions Mean           2707.4727
Q Predictions Std            180.06831
Q Predictions Max            2836.3757
Q Predictions Min            1185.4142
V Predictions Mean           2707.898
V Predictions Std            162.63803
V Predictions Max            2831.0017
V Predictions Min            1410.8802
Log Pis Mean                 -4.7598605
Log Pis Std                  4.7787056
Log Pis Max                  25.600704
Log Pis Min                  -15.49209
Policy mu Mean               0.061618693
Policy mu Std                0.73433053
Policy mu Max                3.3323166
Policy mu Min                -2.4732106
Policy log std Mean          -0.29199052
Policy log std Std           0.12253011
Policy log std Max           -0.05368101
Policy log std Min           -1.1958125
Z mean eval                  0.115213886
Z variance eval              0.042693708
total_rewards                [5491.23537386 5385.72725083 5532.28684377 2038.82049575 4090.50779267
 5460.26153125 5229.8765467  5436.551321   5504.05110373 5480.37314414]
total_rewards_mean           4964.96914036951
total_rewards_std            1058.158888894248
total_rewards_max            5532.286843773509
total_rewards_min            2038.8204957488663
Number of train steps total  1112000
Number of env steps total    1453713
Number of rollouts total     0
Train Time (s)               111.15736764401663
(Previous) Eval Time (s)     17.296097552985884
Sample Time (s)              9.011019563069567
Epoch Time (s)               137.46448476007208
Total Train Time (s)         42595.6192398048
Epoch                        277
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 08:08:29.236559 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #277 | Epoch Duration: 137.86632657051086
2020-01-06 08:08:29.236685 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #277 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11245097
Z variance train             0.058388542
KL Divergence                4.8174887
KL Loss                      0.48174888
QF Loss                      730.3296
VF Loss                      275.9375
Policy Loss                  -2707.66
Q Predictions Mean           2708.5103
Q Predictions Std            169.75961
Q Predictions Max            2823.2517
Q Predictions Min            294.8271
V Predictions Mean           2714.8555
V Predictions Std            168.81824
V Predictions Max            2830.7744
V Predictions Min            324.48157
Log Pis Mean                 -4.4778314
Log Pis Std                  4.0777497
Log Pis Max                  14.75811
Log Pis Min                  -13.749323
Policy mu Mean               0.065186195
Policy mu Std                0.73098046
Policy mu Max                2.9943392
Policy mu Min                -2.145105
Policy log std Mean          -0.28352386
Policy log std Std           0.113725156
Policy log std Max           0.08455096
Policy log std Min           -0.83367705
Z mean eval                  0.11416642
Z variance eval              0.0365965
total_rewards                [5546.69211036 5527.11912358 1089.56364086 5524.79608151 5331.92635608
 5480.14280539 4535.80023215 5539.3318565  4993.53776188 4146.12888389]
total_rewards_mean           4771.503885218749
total_rewards_std            1311.4021379458527
total_rewards_max            5546.692110357883
total_rewards_min            1089.5636408617747
Number of train steps total  1116000
Number of env steps total    1458713
Number of rollouts total     0
Train Time (s)               85.43464970798232
(Previous) Eval Time (s)     17.6976623829687
Sample Time (s)              6.11631016805768
Epoch Time (s)               109.2486222590087
Total Train Time (s)         42703.56233327283
Epoch                        278
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 08:10:17.181875 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #278 | Epoch Duration: 107.94510531425476
2020-01-06 08:10:17.181983 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #278 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1178867
Z variance train             0.034660473
KL Divergence                6.06513
KL Loss                      0.606513
QF Loss                      841.24524
VF Loss                      661.2564
Policy Loss                  -2713.6316
Q Predictions Mean           2716.6199
Q Predictions Std            165.33727
Q Predictions Max            2828.6843
Q Predictions Min            943.6489
V Predictions Mean           2727.7207
V Predictions Std            160.018
V Predictions Max            2838.6973
V Predictions Min            1173.5787
Log Pis Mean                 -4.9001756
Log Pis Std                  4.2025967
Log Pis Max                  19.874002
Log Pis Min                  -13.754218
Policy mu Mean               0.05382465
Policy mu Std                0.74094164
Policy mu Max                2.7788723
Policy mu Min                -2.6086857
Policy log std Mean          -0.28526723
Policy log std Std           0.118671596
Policy log std Max           -0.0884453
Policy log std Min           -1.0856316
Z mean eval                  0.11877178
Z variance eval              0.035388954
total_rewards                [5394.43001839 5389.20119451 5326.67730416 4925.6758279  5276.33442337
 5462.14315591 5322.36119216 5430.75875273 5492.87032242 5430.98403981]
total_rewards_mean           5345.14362313703
total_rewards_std            153.6648286264468
total_rewards_max            5492.870322421419
total_rewards_min            4925.675827897144
Number of train steps total  1120000
Number of env steps total    1464065
Number of rollouts total     0
Train Time (s)               84.7121895889868
(Previous) Eval Time (s)     16.39391283201985
Sample Time (s)              6.483438699855469
Epoch Time (s)               107.58954112086212
Total Train Time (s)         42814.24769891758
Epoch                        279
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 08:12:07.875199 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #279 | Epoch Duration: 110.69312596321106
2020-01-06 08:12:07.875312 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #279 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11734484
Z variance train             0.03526757
KL Divergence                6.0214806
KL Loss                      0.60214806
QF Loss                      1448.049
VF Loss                      246.52573
Policy Loss                  -2695.461
Q Predictions Mean           2695.6182
Q Predictions Std            204.57475
Q Predictions Max            2825.6514
Q Predictions Min            600.3496
V Predictions Mean           2694.538
V Predictions Std            206.22884
V Predictions Max            2835.5635
V Predictions Min            582.51666
Log Pis Mean                 -4.214529
Log Pis Std                  4.829412
Log Pis Max                  35.585327
Log Pis Min                  -18.037561
Policy mu Mean               0.08799818
Policy mu Std                0.76335084
Policy mu Max                3.0753932
Policy mu Min                -4.1328382
Policy log std Mean          -0.29075325
Policy log std Std           0.119851224
Policy log std Max           0.037722617
Policy log std Min           -1.1225914
Z mean eval                  0.123964526
Z variance eval              0.028614277
total_rewards                [5545.44299894 5428.55206765 5504.86458972 5468.60562852 5481.89432569
 5487.22618555 2957.58538213 1557.56067264 3131.72265557 5552.23931851]
total_rewards_mean           4611.569382492679
total_rewards_std            1404.768556528237
total_rewards_max            5552.239318511371
total_rewards_min            1557.5606726398169
Number of train steps total  1124000
Number of env steps total    1469065
Number of rollouts total     0
Train Time (s)               85.05295810801908
(Previous) Eval Time (s)     19.49725605599815
Sample Time (s)              6.272470662021078
Epoch Time (s)               110.82268482603831
Total Train Time (s)         42921.504350036674
Epoch                        280
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 08:13:55.128403 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #280 | Epoch Duration: 107.2529993057251
2020-01-06 08:13:55.128509 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #280 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11639501
Z variance train             0.030705508
KL Divergence                6.355183
KL Loss                      0.6355183
QF Loss                      627.16095
VF Loss                      648.91296
Policy Loss                  -2708.9153
Q Predictions Mean           2705.8389
Q Predictions Std            211.55165
Q Predictions Max            2824.9683
Q Predictions Min            559.516
V Predictions Mean           2717.2832
V Predictions Std            204.22173
V Predictions Max            2842.27
V Predictions Min            550.1546
Log Pis Mean                 -5.4902544
Log Pis Std                  4.5053144
Log Pis Max                  28.6843
Log Pis Min                  -14.787905
Policy mu Mean               0.034307536
Policy mu Std                0.72419876
Policy mu Max                2.3902955
Policy mu Min                -3.3927567
Policy log std Mean          -0.27572164
Policy log std Std           0.10731717
Policy log std Max           0.32310018
Policy log std Min           -0.8518546
Z mean eval                  0.11186489
Z variance eval              0.04409044
total_rewards                [5405.91192892 1773.8288453  5489.23033694 5420.12744491 5407.65801158
 2321.65327152 5456.29672221 5488.30903508 5452.66712084 5371.89649118]
total_rewards_mean           4758.7579208478255
total_rewards_std            1361.4849975569582
total_rewards_max            5489.2303369393485
total_rewards_min            1773.8288452999386
Number of train steps total  1128000
Number of env steps total    1474065
Number of rollouts total     0
Train Time (s)               84.88479703001212
(Previous) Eval Time (s)     15.927330309990793
Sample Time (s)              6.220088339992799
Epoch Time (s)               107.03221567999572
Total Train Time (s)         43029.97884481773
Epoch                        281
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 08:15:43.605494 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #281 | Epoch Duration: 108.47689628601074
2020-01-06 08:15:43.605602 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #281 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1253335
Z variance train             0.027751893
KL Divergence                6.6112022
KL Loss                      0.66112024
QF Loss                      1126.6245
VF Loss                      555.6305
Policy Loss                  -2696.1716
Q Predictions Mean           2694.442
Q Predictions Std            275.6273
Q Predictions Max            2829.7344
Q Predictions Min            95.33038
V Predictions Mean           2708.805
V Predictions Std            277.781
V Predictions Max            2853.7444
V Predictions Min            110.24287
Log Pis Mean                 -4.4977455
Log Pis Std                  4.4102044
Log Pis Max                  13.794411
Log Pis Min                  -14.933341
Policy mu Mean               0.052892078
Policy mu Std                0.7396012
Policy mu Max                2.6111846
Policy mu Min                -2.7731524
Policy log std Mean          -0.2866757
Policy log std Std           0.12018827
Policy log std Max           -0.004468128
Policy log std Min           -0.9017531
Z mean eval                  0.13775088
Z variance eval              0.023552896
total_rewards                [2132.33783995 5479.1591969  5369.43365087 5399.10636214 5484.59747664
 5481.99033546 4404.7333755  5520.89543517 1737.90263771 5369.06025691]
total_rewards_mean           4637.921656724122
total_rewards_std            1389.537625433236
total_rewards_max            5520.895435167875
total_rewards_min            1737.902637706107
Number of train steps total  1132000
Number of env steps total    1479065
Number of rollouts total     0
Train Time (s)               85.95655097602867
(Previous) Eval Time (s)     17.37177723000059
Sample Time (s)              6.078027470095549
Epoch Time (s)               109.4063556761248
Total Train Time (s)         43138.75480444083
Epoch                        282
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 08:17:32.383521 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #282 | Epoch Duration: 108.77782678604126
2020-01-06 08:17:32.383628 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #282 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.13885775
Z variance train             0.029996246
KL Divergence                6.435355
KL Loss                      0.64353555
QF Loss                      2174.353
VF Loss                      679.76807
Policy Loss                  -2711.1736
Q Predictions Mean           2705.4973
Q Predictions Std            241.57637
Q Predictions Max            2837.2427
Q Predictions Min            207.24014
V Predictions Mean           2705.0078
V Predictions Std            234.94391
V Predictions Max            2822.7961
V Predictions Min            206.23442
Log Pis Mean                 -5.3062963
Log Pis Std                  4.097978
Log Pis Max                  19.384083
Log Pis Min                  -16.359419
Policy mu Mean               0.044077452
Policy mu Std                0.7263614
Policy mu Max                2.1921363
Policy mu Min                -3.6670587
Policy log std Mean          -0.28171083
Policy log std Std           0.11019704
Policy log std Max           -0.014456503
Policy log std Min           -0.92011404
Z mean eval                  0.16191968
Z variance eval              0.03603094
total_rewards                [5453.92028073 5582.6012227  5616.91017086 5394.33779583 5485.59708453
 5437.24089982 5553.09957748 5606.3642406  1553.99035548 4378.11141244]
total_rewards_mean           5006.217304045887
total_rewards_std            1201.8099045471631
total_rewards_max            5616.91017085769
total_rewards_min            1553.9903554838588
Number of train steps total  1136000
Number of env steps total    1484192
Number of rollouts total     0
Train Time (s)               86.764720999985
(Previous) Eval Time (s)     16.743023467017338
Sample Time (s)              6.433333637949545
Epoch Time (s)               109.94107810495188
Total Train Time (s)         43249.60971652588
Epoch                        283
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 08:19:23.240744 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #283 | Epoch Duration: 110.85703110694885
2020-01-06 08:19:23.240854 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #283 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14907359
Z variance train             0.041972823
KL Divergence                5.640936
KL Loss                      0.5640936
QF Loss                      1498.8823
VF Loss                      268.49026
Policy Loss                  -2703.64
Q Predictions Mean           2701.6016
Q Predictions Std            245.84415
Q Predictions Max            2827.9949
Q Predictions Min            353.95206
V Predictions Mean           2699.8005
V Predictions Std            255.16443
V Predictions Max            2828.519
V Predictions Min            306.92532
Log Pis Mean                 -5.1293573
Log Pis Std                  4.347854
Log Pis Max                  17.424316
Log Pis Min                  -14.132774
Policy mu Mean               0.074271664
Policy mu Std                0.72885025
Policy mu Max                3.4837348
Policy mu Min                -2.576822
Policy log std Mean          -0.27523112
Policy log std Std           0.11411017
Policy log std Max           -0.07076131
Policy log std Min           -1.0360922
Z mean eval                  0.13006078
Z variance eval              0.027236883
total_rewards                [ 931.34202442 5547.65324777 2709.16889322 1960.31923939  937.65342602
 3970.34271785 1082.86063122 5512.46496061 3824.92761238 2057.04779089]
total_rewards_mean           2853.3780543761213
total_rewards_std            1687.3893478172135
total_rewards_max            5547.65324776709
total_rewards_min            931.3420244232917
Number of train steps total  1140000
Number of env steps total    1489272
Number of rollouts total     0
Train Time (s)               85.6298113950179
(Previous) Eval Time (s)     17.658747265988495
Sample Time (s)              6.247800657059997
Epoch Time (s)               109.53635931806639
Total Train Time (s)         43351.640530972974
Epoch                        284
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 08:21:05.273839 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #284 | Epoch Duration: 102.03290224075317
2020-01-06 08:21:05.273948 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #284 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1277747
Z variance train             0.030223032
KL Divergence                6.413997
KL Loss                      0.64139974
QF Loss                      2440.811
VF Loss                      320.73306
Policy Loss                  -2707.0247
Q Predictions Mean           2710.6096
Q Predictions Std            215.81964
Q Predictions Max            2829.7773
Q Predictions Min            503.23654
V Predictions Mean           2711.399
V Predictions Std            216.91023
V Predictions Max            2846.25
V Predictions Min            458.82507
Log Pis Mean                 -4.8160877
Log Pis Std                  4.4956527
Log Pis Max                  19.654697
Log Pis Min                  -15.08041
Policy mu Mean               0.08434612
Policy mu Std                0.7379815
Policy mu Max                2.2519546
Policy mu Min                -2.7916148
Policy log std Mean          -0.2898906
Policy log std Std           0.11495197
Policy log std Max           0.26040018
Policy log std Min           -0.8594044
Z mean eval                  0.13149163
Z variance eval              0.031812835
total_rewards                [1184.86658638 1820.59021195  755.87834628 2761.37047611 1648.90227006
 1375.95433776 1534.1402306  1175.22774573 2055.21584998 1826.04857126]
total_rewards_mean           1613.8194626086986
total_rewards_std            526.8856670044115
total_rewards_max            2761.3704761083554
total_rewards_min            755.8783462789735
Number of train steps total  1144000
Number of env steps total    1494272
Number of rollouts total     0
Train Time (s)               89.25805235898588
(Previous) Eval Time (s)     10.155065957980696
Sample Time (s)              6.4461748819448985
Epoch Time (s)               105.85929319891147
Total Train Time (s)         43453.12697026989
Epoch                        285
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 08:22:46.762616 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #285 | Epoch Duration: 101.48858284950256
2020-01-06 08:22:46.762722 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #285 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.13673808
Z variance train             0.026255265
KL Divergence                6.7606363
KL Loss                      0.67606366
QF Loss                      767.7787
VF Loss                      266.30762
Policy Loss                  -2707.8567
Q Predictions Mean           2708.1965
Q Predictions Std            268.61124
Q Predictions Max            2822.8345
Q Predictions Min            176.95337
V Predictions Mean           2715.1475
V Predictions Std            274.05292
V Predictions Max            2847.6946
V Predictions Min            104.55178
Log Pis Mean                 -5.0298066
Log Pis Std                  4.3738794
Log Pis Max                  21.200695
Log Pis Min                  -15.922731
Policy mu Mean               0.09062069
Policy mu Std                0.73815346
Policy mu Max                3.417751
Policy mu Min                -2.6845484
Policy log std Mean          -0.2786979
Policy log std Std           0.11479916
Policy log std Max           0.0028427541
Policy log std Min           -1.1919165
Z mean eval                  0.13327864
Z variance eval              0.025754426
total_rewards                [5347.03339713 4096.44714207 4388.87918897 4508.34110839 1404.19587525
 5345.03571863 5302.99280372 3563.30653356 5462.70060731 5266.73189554]
total_rewards_mean           4468.566427056977
total_rewards_std            1192.3845057325439
total_rewards_max            5462.7006073146
total_rewards_min            1404.19587524852
Number of train steps total  1148000
Number of env steps total    1499330
Number of rollouts total     0
Train Time (s)               87.03707081504399
(Previous) Eval Time (s)     5.784090784029104
Sample Time (s)              6.301796206913423
Epoch Time (s)               99.12295780598652
Total Train Time (s)         43562.55651639984
Epoch                        286
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 08:24:36.194473 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #286 | Epoch Duration: 109.43166422843933
2020-01-06 08:24:36.194592 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #286 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.13937365
Z variance train             0.022013178
KL Divergence                7.192916
KL Loss                      0.7192916
QF Loss                      1159.5029
VF Loss                      613.6741
Policy Loss                  -2743.6567
Q Predictions Mean           2735.4526
Q Predictions Std            119.136635
Q Predictions Max            2836.8179
Q Predictions Min            1389.0017
V Predictions Mean           2731.1016
V Predictions Std            110.997696
V Predictions Max            2829.7363
V Predictions Min            1518.3564
Log Pis Mean                 -5.2118826
Log Pis Std                  3.7849133
Log Pis Max                  10.2768135
Log Pis Min                  -14.371445
Policy mu Mean               0.07542448
Policy mu Std                0.71119237
Policy mu Max                2.42501
Policy mu Min                -2.232327
Policy log std Mean          -0.2744006
Policy log std Std           0.10947729
Policy log std Max           0.0057837665
Policy log std Min           -0.9344723
Z mean eval                  0.12991725
Z variance eval              0.025990441
total_rewards                [2710.86571752 5370.70888094 2010.81670302 5417.89586951 5384.53850383
 3065.71033732 5488.29512808 5440.71908037 5447.32679515 5515.5550757 ]
total_rewards_mean           4585.243209142583
total_rewards_std            1324.9563283545738
total_rewards_max            5515.555075702163
total_rewards_min            2010.8167030179884
Number of train steps total  1152000
Number of env steps total    1504503
Number of rollouts total     0
Train Time (s)               85.06750494299922
(Previous) Eval Time (s)     16.092561476980336
Sample Time (s)              6.307237194036134
Epoch Time (s)               107.46730361401569
Total Train Time (s)         43670.874417205865
Epoch                        287
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 08:26:24.514704 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #287 | Epoch Duration: 108.32002282142639
2020-01-06 08:26:24.514811 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #287 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1291044
Z variance train             0.026720906
KL Divergence                6.7141924
KL Loss                      0.67141926
QF Loss                      720.54584
VF Loss                      356.04343
Policy Loss                  -2725.0916
Q Predictions Mean           2717.113
Q Predictions Std            238.48965
Q Predictions Max            2840.881
Q Predictions Min            354.46912
V Predictions Mean           2719.9604
V Predictions Std            243.2325
V Predictions Max            2841.1453
V Predictions Min            328.98007
Log Pis Mean                 -4.9666567
Log Pis Std                  3.7514663
Log Pis Max                  10.214106
Log Pis Min                  -15.275509
Policy mu Mean               0.06293203
Policy mu Std                0.7266955
Policy mu Max                2.6358957
Policy mu Min                -2.471889
Policy log std Mean          -0.279455
Policy log std Std           0.11453
Policy log std Max           -0.0452416
Policy log std Min           -0.931088
Z mean eval                  0.13566157
Z variance eval              0.030296665
total_rewards                [5520.88003708 5123.88999002 5539.71240638 5582.5609986  5497.66970283
 5447.62024941 5520.6027535  5595.09005976 5593.88113583 5367.74449273]
total_rewards_mean           5478.9651826138015
total_rewards_std            135.7881888021668
total_rewards_max            5595.090059759599
total_rewards_min            5123.889990022495
Number of train steps total  1156000
Number of env steps total    1509675
Number of rollouts total     0
Train Time (s)               98.8436829210259
(Previous) Eval Time (s)     16.945048580993898
Sample Time (s)              6.403495555045083
Epoch Time (s)               122.19222705706488
Total Train Time (s)         43796.481964548875
Epoch                        288
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 08:28:30.124547 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #288 | Epoch Duration: 125.6096510887146
2020-01-06 08:28:30.124656 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #288 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.13331023
Z variance train             0.02797702
KL Divergence                6.6061864
KL Loss                      0.66061866
QF Loss                      1983.5103
VF Loss                      714.7924
Policy Loss                  -2702.807
Q Predictions Mean           2697.9849
Q Predictions Std            298.67215
Q Predictions Max            2854.2793
Q Predictions Min            146.3193
V Predictions Mean           2700.6562
V Predictions Std            291.78964
V Predictions Max            2849.214
V Predictions Min            100.37586
Log Pis Mean                 -4.6052675
Log Pis Std                  5.380896
Log Pis Max                  30.052145
Log Pis Min                  -12.859392
Policy mu Mean               0.04681527
Policy mu Std                0.7477417
Policy mu Max                3.470426
Policy mu Min                -3.2306619
Policy log std Mean          -0.28369415
Policy log std Std           0.11783938
Policy log std Max           0.061154842
Policy log std Min           -1.0594208
Z mean eval                  0.13704176
Z variance eval              0.020422222
total_rewards                [5161.68594021 2459.79504611 5257.99393672 5367.27388903 5356.57862901
 5299.98378259 3089.81283781 5426.39437584 5359.95571832 5365.29110688]
total_rewards_mean           4814.47652625292
total_rewards_std            1031.8341144584128
total_rewards_max            5426.394375841947
total_rewards_min            2459.7950461125956
Number of train steps total  1160000
Number of env steps total    1514675
Number of rollouts total     0
Train Time (s)               88.32026736595435
(Previous) Eval Time (s)     20.362250198959373
Sample Time (s)              6.117773748876061
Epoch Time (s)               114.80029131378978
Total Train Time (s)         43908.81636769074
Epoch                        289
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 08:30:22.461290 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #289 | Epoch Duration: 112.33654618263245
2020-01-06 08:30:22.461399 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #289 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.13315794
Z variance train             0.028588569
KL Divergence                6.5527773
KL Loss                      0.6552777
QF Loss                      568.0648
VF Loss                      314.6217
Policy Loss                  -2740.7896
Q Predictions Mean           2734.6458
Q Predictions Std            155.9933
Q Predictions Max            2836.5066
Q Predictions Min            500.94986
V Predictions Mean           2731.646
V Predictions Std            155.7763
V Predictions Max            2842.7698
V Predictions Min            503.9377
Log Pis Mean                 -5.882594
Log Pis Std                  3.8069134
Log Pis Max                  16.831059
Log Pis Min                  -15.0602865
Policy mu Mean               0.038719136
Policy mu Std                0.7152273
Policy mu Max                2.3558629
Policy mu Min                -2.1825438
Policy log std Mean          -0.2766917
Policy log std Std           0.10671573
Policy log std Max           -0.06767513
Policy log std Min           -0.84395933
Z mean eval                  0.14223412
Z variance eval              0.02734315
total_rewards                [5386.03224138 5308.30041568 5387.08769671 4028.48235729 5432.20563535
 5454.06091044 3310.01517942 2962.08664852 5382.10971489 1550.21532872]
total_rewards_mean           4420.059612840807
total_rewards_std            1319.9840749845546
total_rewards_max            5454.060910443497
total_rewards_min            1550.215328715408
Number of train steps total  1164000
Number of env steps total    1519675
Number of rollouts total     0
Train Time (s)               97.83047690201784
(Previous) Eval Time (s)     17.89827713003615
Sample Time (s)              6.256621769978665
Epoch Time (s)               121.98537580203265
Total Train Time (s)         44031.669659042906
Epoch                        290
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 08:32:25.317025 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #290 | Epoch Duration: 122.85553121566772
2020-01-06 08:32:25.317165 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #290 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14528936
Z variance train             0.023387643
KL Divergence                7.05207
KL Loss                      0.70520705
QF Loss                      969.63245
VF Loss                      723.6101
Policy Loss                  -2695.8035
Q Predictions Mean           2691.2637
Q Predictions Std            332.25092
Q Predictions Max            2843.4453
Q Predictions Min            86.230225
V Predictions Mean           2685.8015
V Predictions Std            329.5959
V Predictions Max            2836.8079
V Predictions Min            112.161064
Log Pis Mean                 -4.886058
Log Pis Std                  4.0551195
Log Pis Max                  19.832455
Log Pis Min                  -14.547611
Policy mu Mean               0.060427412
Policy mu Std                0.73603
Policy mu Max                2.8588881
Policy mu Min                -2.5410078
Policy log std Mean          -0.27906135
Policy log std Std           0.11068456
Policy log std Max           0.28236195
Policy log std Min           -0.83278644
Z mean eval                  0.13687655
Z variance eval              0.021952841
total_rewards                [5486.25846864 5328.30985038 5419.93485941 5460.90122203 5379.07195212
 1832.28816452 5380.22409549 5237.75720944 5440.6902853  5434.04244458]
total_rewards_mean           5039.947855191226
total_rewards_std            1071.3937189307396
total_rewards_max            5486.258468638181
total_rewards_min            1832.2881645232585
Number of train steps total  1168000
Number of env steps total    1524947
Number of rollouts total     0
Train Time (s)               100.59221128700301
(Previous) Eval Time (s)     18.76819184300257
Sample Time (s)              8.232132647011895
Epoch Time (s)               127.59253577701747
Total Train Time (s)         44163.55511249887
Epoch                        291
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 08:34:37.204997 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #291 | Epoch Duration: 131.8877077102661
2020-01-06 08:34:37.205106 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #291 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.13204047
Z variance train             0.025905302
KL Divergence                6.7946415
KL Loss                      0.67946416
QF Loss                      1257.1837
VF Loss                      642.7254
Policy Loss                  -2734.6401
Q Predictions Mean           2735.8958
Q Predictions Std            118.72887
Q Predictions Max            2843.0132
Q Predictions Min            1288.5203
V Predictions Mean           2737.6582
V Predictions Std            110.4597
V Predictions Max            2848.7117
V Predictions Min            1588.2699
Log Pis Mean                 -5.438094
Log Pis Std                  3.7955973
Log Pis Max                  16.657745
Log Pis Min                  -16.409262
Policy mu Mean               0.05934101
Policy mu Std                0.72033966
Policy mu Max                3.1586058
Policy mu Min                -2.9672194
Policy log std Mean          -0.2768683
Policy log std Std           0.104834795
Policy log std Max           -0.07202187
Policy log std Min           -1.2415913
Z mean eval                  0.13671976
Z variance eval              0.030107593
total_rewards                [5377.456071   5203.48055999 5372.45682748 5312.01586247 5356.23465782
 5295.97928059 5415.3352402  5362.24052097 5262.85146094 5481.04910463]
total_rewards_mean           5343.909958608016
total_rewards_std            74.79463124630104
total_rewards_max            5481.049104632575
total_rewards_min            5203.480559993632
Number of train steps total  1172000
Number of env steps total    1529947
Number of rollouts total     0
Train Time (s)               100.40095476299757
(Previous) Eval Time (s)     23.063113842974417
Sample Time (s)              7.592075353022665
Epoch Time (s)               131.05614395899465
Total Train Time (s)         44295.696071116894
Epoch                        292
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 08:36:49.802961 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #292 | Epoch Duration: 132.59773659706116
2020-01-06 08:36:49.803225 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #292 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.13867962
Z variance train             0.02469726
KL Divergence                6.9185004
KL Loss                      0.69185007
QF Loss                      995.48364
VF Loss                      313.4701
Policy Loss                  -2740.3206
Q Predictions Mean           2741.7144
Q Predictions Std            106.558975
Q Predictions Max            2837.1138
Q Predictions Min            1583.3837
V Predictions Mean           2743.2603
V Predictions Std            89.78243
V Predictions Max            2845.3435
V Predictions Min            1974.149
Log Pis Mean                 -5.5026383
Log Pis Std                  4.134045
Log Pis Max                  15.821282
Log Pis Min                  -19.675695
Policy mu Mean               0.0471106
Policy mu Std                0.7281494
Policy mu Max                2.2216094
Policy mu Min                -3.0813758
Policy log std Mean          -0.28130078
Policy log std Std           0.110352084
Policy log std Max           0.07815568
Policy log std Min           -0.9088397
Z mean eval                  0.10204265
Z variance eval              0.03554148
total_rewards                [5500.71400506 5683.31190882 3017.0150566  5639.03223155 5576.51969767
 3932.06558832 5606.10106918 1342.48385779 5645.68265487 5688.22302627]
total_rewards_mean           4763.1149096136205
total_rewards_std            1435.4537411047356
total_rewards_max            5688.22302626571
total_rewards_min            1342.4838577944101
Number of train steps total  1176000
Number of env steps total    1534947
Number of rollouts total     0
Train Time (s)               100.37400995701319
(Previous) Eval Time (s)     24.604450204991736
Sample Time (s)              7.644905099004973
Epoch Time (s)               132.6233652610099
Total Train Time (s)         44424.33509378182
Epoch                        293
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 08:38:58.030888 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #293 | Epoch Duration: 128.22742104530334
2020-01-06 08:38:58.031117 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #293 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.12145789
Z variance train             0.02693303
KL Divergence                6.6936073
KL Loss                      0.66936076
QF Loss                      1296.7565
VF Loss                      383.7441
Policy Loss                  -2720.1882
Q Predictions Mean           2718.9092
Q Predictions Std            163.18506
Q Predictions Max            2838.7896
Q Predictions Min            1241.5763
V Predictions Mean           2723.216
V Predictions Std            159.34897
V Predictions Max            2845.255
V Predictions Min            1297.8585
Log Pis Mean                 -5.023662
Log Pis Std                  4.645947
Log Pis Max                  16.31557
Log Pis Min                  -16.20919
Policy mu Mean               0.058401603
Policy mu Std                0.74053943
Policy mu Max                2.5376883
Policy mu Min                -2.5454044
Policy log std Mean          -0.283069
Policy log std Std           0.12423778
Policy log std Max           0.060631216
Policy log std Min           -1.1440406
Z mean eval                  0.121488035
Z variance eval              0.023128215
total_rewards                [5412.19282866 5457.59444729 5485.41330568 5430.42378693 5570.71004832
 5361.25564475 5387.08987881 2080.30673954 5429.53762128 5335.34777239]
total_rewards_mean           5094.987207364846
total_rewards_std            1006.8557111312086
total_rewards_max            5570.710048321938
total_rewards_min            2080.3067395371154
Number of train steps total  1180000
Number of env steps total    1539947
Number of rollouts total     0
Train Time (s)               99.50547548796749
(Previous) Eval Time (s)     20.208254380035214
Sample Time (s)              7.709442214865703
Epoch Time (s)               127.4231720828684
Total Train Time (s)         44555.01275997766
Epoch                        294
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 08:41:08.671595 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #294 | Epoch Duration: 130.64030289649963
2020-01-06 08:41:08.671710 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #294 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.12535152
Z variance train             0.022489998
KL Divergence                7.134357
KL Loss                      0.7134357
QF Loss                      487.62708
VF Loss                      321.9243
Policy Loss                  -2744.3286
Q Predictions Mean           2746.3738
Q Predictions Std            178.5341
Q Predictions Max            2845.805
Q Predictions Min            98.87648
V Predictions Mean           2752.3452
V Predictions Std            175.14041
V Predictions Max            2870.5679
V Predictions Min            173.10147
Log Pis Mean                 -5.492385
Log Pis Std                  3.7956297
Log Pis Max                  11.071764
Log Pis Min                  -13.793625
Policy mu Mean               0.046596542
Policy mu Std                0.69385433
Policy mu Max                2.2687104
Policy mu Min                -1.9493998
Policy log std Mean          -0.27865276
Policy log std Std           0.110539764
Policy log std Max           0.08626044
Policy log std Min           -0.8854054
Z mean eval                  0.13134071
Z variance eval              0.02510792
total_rewards                [2143.74559766 5328.39144357 5336.46593816 5370.05281562 2918.38968287
 5439.94993685 5496.63677997 5521.53354433 5546.56813361 5107.3205204 ]
total_rewards_mean           4820.90543930519
total_rewards_std            1164.0870738660492
total_rewards_max            5546.568133614509
total_rewards_min            2143.7455976640813
Number of train steps total  1184000
Number of env steps total    1544947
Number of rollouts total     0
Train Time (s)               102.43659259501146
(Previous) Eval Time (s)     23.425161132996436
Sample Time (s)              8.15613446594216
Epoch Time (s)               134.01788819395006
Total Train Time (s)         44686.07698761468
Epoch                        295
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 08:43:19.758139 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #295 | Epoch Duration: 131.08632111549377
2020-01-06 08:43:19.758275 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #295 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11677215
Z variance train             0.025135737
KL Divergence                6.854274
KL Loss                      0.68542737
QF Loss                      691.012
VF Loss                      157.93025
Policy Loss                  -2734.55
Q Predictions Mean           2732.288
Q Predictions Std            227.44728
Q Predictions Max            2847.1287
Q Predictions Min            230.74564
V Predictions Mean           2731.5046
V Predictions Std            226.65186
V Predictions Max            2836.9448
V Predictions Min            218.65236
Log Pis Mean                 -6.0084133
Log Pis Std                  3.1246543
Log Pis Max                  5.0532446
Log Pis Min                  -15.392952
Policy mu Mean               0.052501425
Policy mu Std                0.6786647
Policy mu Max                2.065647
Policy mu Min                -2.1572878
Policy log std Mean          -0.26422572
Policy log std Std           0.10153093
Policy log std Max           -0.018547267
Policy log std Min           -0.7913064
Z mean eval                  0.11338608
Z variance eval              0.027152553
total_rewards                [5405.02035931 4961.39733296 5455.25397736 5322.24895173 4157.19755752
 5321.06360078 5380.13480227 5343.6119204  5401.96673118 5324.51934825]
total_rewards_mean           5207.241458175743
total_rewards_std            372.8272362883771
total_rewards_max            5455.253977355299
total_rewards_min            4157.197557518092
Number of train steps total  1188000
Number of env steps total    1549947
Number of rollouts total     0
Train Time (s)               87.85489968897309
(Previous) Eval Time (s)     20.49331476003863
Sample Time (s)              6.4762046479736455
Epoch Time (s)               114.82441909698537
Total Train Time (s)         44801.25519030559
Epoch                        296
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 08:45:14.920810 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #296 | Epoch Duration: 115.16240930557251
2020-01-06 08:45:14.921043 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #296 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10887375
Z variance train             0.025416141
KL Divergence                6.8237867
KL Loss                      0.6823787
QF Loss                      493.01532
VF Loss                      277.4042
Policy Loss                  -2747.5574
Q Predictions Mean           2744.2134
Q Predictions Std            211.98137
Q Predictions Max            2843.5798
Q Predictions Min            402.69635
V Predictions Mean           2740.7683
V Predictions Std            209.39551
V Predictions Max            2843.0671
V Predictions Min            422.93518
Log Pis Mean                 -5.8686113
Log Pis Std                  3.7492383
Log Pis Max                  18.169483
Log Pis Min                  -13.831608
Policy mu Mean               0.04167692
Policy mu Std                0.67804766
Policy mu Max                2.3297513
Policy mu Min                -2.4370646
Policy log std Mean          -0.26994792
Policy log std Std           0.10334246
Policy log std Max           0.022664666
Policy log std Min           -0.95370775
Z mean eval                  0.12842876
Z variance eval              0.020114698
total_rewards                [5398.17523827 5410.42761461 5583.04605992 5476.01064171 5525.91511767
 5541.36427898 5415.00689253 3893.11202929 5483.38541134 5519.65492036]
total_rewards_mean           5324.609820469028
total_rewards_std            480.6874469997881
total_rewards_max            5583.046059922048
total_rewards_min            3893.112029288062
Number of train steps total  1192000
Number of env steps total    1554947
Number of rollouts total     0
Train Time (s)               117.9232471450232
(Previous) Eval Time (s)     20.8310440069763
Sample Time (s)              7.901965524884872
Epoch Time (s)               146.65625667688437
Total Train Time (s)         44951.027232268534
Epoch                        297
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 08:47:44.695346 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #297 | Epoch Duration: 149.77413511276245
2020-01-06 08:47:44.695470 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #297 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10793181
Z variance train             0.029829722
KL Divergence                6.4337177
KL Loss                      0.64337176
QF Loss                      989.41174
VF Loss                      480.01855
Policy Loss                  -2734.4758
Q Predictions Mean           2729.7983
Q Predictions Std            195.99516
Q Predictions Max            2847.8406
Q Predictions Min            535.28125
V Predictions Mean           2730.872
V Predictions Std            207.78787
V Predictions Max            2856.8374
V Predictions Min            541.1818
Log Pis Mean                 -4.8727508
Log Pis Std                  4.700744
Log Pis Max                  23.40284
Log Pis Min                  -15.560274
Policy mu Mean               0.051433045
Policy mu Std                0.73455435
Policy mu Max                3.609223
Policy mu Min                -3.5652018
Policy log std Mean          -0.2811569
Policy log std Std           0.12421238
Policy log std Max           -0.00614509
Policy log std Min           -1.0203338
Z mean eval                  0.107497856
Z variance eval              0.031137222
total_rewards                [5469.53931665 5510.20675568 3774.17045743 5520.73878882 5487.84892628
 5592.90737531 5419.9277261  5480.48481436 5502.35204404 5396.2115179 ]
total_rewards_mean           5315.438772256739
total_rewards_std            516.301335677084
total_rewards_max            5592.907375310629
total_rewards_min            3774.170457431574
Number of train steps total  1196000
Number of env steps total    1560097
Number of rollouts total     0
Train Time (s)               90.52152628399199
(Previous) Eval Time (s)     23.948688426055014
Sample Time (s)              7.828663080057595
Epoch Time (s)               122.2988777901046
Total Train Time (s)         45070.70303259161
Epoch                        298
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 08:49:44.374422 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #298 | Epoch Duration: 119.67884826660156
2020-01-06 08:49:44.374580 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #298 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.118327476
Z variance train             0.026301881
KL Divergence                6.7434583
KL Loss                      0.67434585
QF Loss                      1003.90674
VF Loss                      173.38795
Policy Loss                  -2762.357
Q Predictions Mean           2756.2046
Q Predictions Std            106.75511
Q Predictions Max            2853.7732
Q Predictions Min            1395.532
V Predictions Mean           2757.6992
V Predictions Std            105.65821
V Predictions Max            2850.8652
V Predictions Min            1431.6656
Log Pis Mean                 -5.343894
Log Pis Std                  4.02482
Log Pis Max                  21.449808
Log Pis Min                  -15.127564
Policy mu Mean               0.0739745
Policy mu Std                0.71207
Policy mu Max                2.422017
Policy mu Min                -3.133287
Policy log std Mean          -0.26199448
Policy log std Std           0.10531591
Policy log std Max           -0.06503594
Policy log std Min           -1.1545129
Z mean eval                  0.115221165
Z variance eval              0.025723636
total_rewards                [5475.12231313 5372.70050685 5358.42241175 5413.76269967 5336.16997834
 4891.11706696 5441.59852909 5363.69950308 5500.89340262 5485.62179448]
total_rewards_mean           5363.910820597773
total_rewards_std            166.9961941456874
total_rewards_max            5500.893402623651
total_rewards_min            4891.117066958812
Number of train steps total  1200000
Number of env steps total    1565294
Number of rollouts total     0
Train Time (s)               117.81874247803353
(Previous) Eval Time (s)     21.32841809699312
Sample Time (s)              8.307529678975698
Epoch Time (s)               147.45469025400234
Total Train Time (s)         45220.29918481747
Epoch                        299
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 08:52:13.973551 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #299 | Epoch Duration: 149.5988564491272
2020-01-06 08:52:13.973665 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #299 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11010627
Z variance train             0.03185901
KL Divergence                6.277254
KL Loss                      0.6277254
QF Loss                      623.31946
VF Loss                      321.69003
Policy Loss                  -2761.0361
Q Predictions Mean           2758.223
Q Predictions Std            141.81854
Q Predictions Max            2862.4053
Q Predictions Min            897.7905
V Predictions Mean           2760.1567
V Predictions Std            138.15887
V Predictions Max            2860.2642
V Predictions Min            916.60046
Log Pis Mean                 -5.5768986
Log Pis Std                  4.2416773
Log Pis Max                  15.701182
Log Pis Min                  -18.306505
Policy mu Mean               0.047743075
Policy mu Std                0.7163283
Policy mu Max                2.4566197
Policy mu Min                -2.6583793
Policy log std Mean          -0.280564
Policy log std Std           0.11640554
Policy log std Max           -0.03075406
Policy log std Min           -1.0367024
Z mean eval                  0.11670171
Z variance eval              0.048584655
total_rewards                [5654.82902548 5594.28804232 5637.05724674 3918.35082239 5517.39882955
 3422.58593888 5650.36874363 5502.99779726 5510.24226053 5537.9233955 ]
total_rewards_mean           5194.604210227606
total_rewards_std            772.0563400542253
total_rewards_max            5654.829025483099
total_rewards_min            3422.5859388765234
Number of train steps total  1204000
Number of env steps total    1570384
Number of rollouts total     0
Train Time (s)               109.28516702103661
(Previous) Eval Time (s)     23.472338636987843
Sample Time (s)              7.4449984769453295
Epoch Time (s)               140.2025041349698
Total Train Time (s)         45358.83862674335
Epoch                        300
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 08:54:32.516098 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #300 | Epoch Duration: 138.54234552383423
2020-01-06 08:54:32.516206 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #300 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.12746896
Z variance train             0.02791075
KL Divergence                6.610627
KL Loss                      0.6610627
QF Loss                      1030.5275
VF Loss                      394.06387
Policy Loss                  -2747.493
Q Predictions Mean           2749.704
Q Predictions Std            224.49469
Q Predictions Max            2853.392
Q Predictions Min            461.50787
V Predictions Mean           2743.3862
V Predictions Std            228.03912
V Predictions Max            2856.7837
V Predictions Min            505.67303
Log Pis Mean                 -4.964324
Log Pis Std                  3.8774085
Log Pis Max                  8.22352
Log Pis Min                  -14.626766
Policy mu Mean               0.06499519
Policy mu Std                0.7395279
Policy mu Max                3.8054767
Policy mu Min                -2.3239636
Policy log std Mean          -0.2781728
Policy log std Std           0.11028114
Policy log std Max           0.35695928
Policy log std Min           -1.0258684
Z mean eval                  0.09108364
Z variance eval              0.04867618
total_rewards                [5432.26537895 5276.06319711 5389.34559567 5407.71026768 5418.23568877
 5444.09168024 2899.38936139 5479.906836   5378.73565815 5280.71810349]
total_rewards_mean           5140.646176745586
total_rewards_std            749.6883300417612
total_rewards_max            5479.906835996693
total_rewards_min            2899.3893613944056
Number of train steps total  1208000
Number of env steps total    1575384
Number of rollouts total     0
Train Time (s)               111.08819036599016
(Previous) Eval Time (s)     21.81194082600996
Sample Time (s)              8.018094298022334
Epoch Time (s)               140.91822549002245
Total Train Time (s)         45501.17313784349
Epoch                        301
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 08:56:54.853381 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #301 | Epoch Duration: 142.33707237243652
2020-01-06 08:56:54.853546 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #301 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09295897
Z variance train             0.04913802
KL Divergence                5.2344847
KL Loss                      0.52344847
QF Loss                      576.9878
VF Loss                      518.5124
Policy Loss                  -2754.2957
Q Predictions Mean           2747.4849
Q Predictions Std            228.55052
Q Predictions Max            2873.2397
Q Predictions Min            721.73376
V Predictions Mean           2748.0264
V Predictions Std            221.44724
V Predictions Max            2878.1453
V Predictions Min            717.7611
Log Pis Mean                 -5.3752813
Log Pis Std                  4.6872253
Log Pis Max                  35.04915
Log Pis Min                  -16.594145
Policy mu Mean               0.032715652
Policy mu Std                0.72718716
Policy mu Max                3.8010573
Policy mu Min                -5.86658
Policy log std Mean          -0.27564836
Policy log std Std           0.114631124
Policy log std Max           0.17853135
Policy log std Min           -1.1563933
Z mean eval                  0.14456758
Z variance eval              0.024518784
total_rewards                [2645.13395421 5419.72984493 5228.0701593  5437.99456253 5334.76049705
 5484.35252538 5310.68437183 5360.95657661 5377.77057728 3182.17564276]
total_rewards_mean           4878.162871187616
total_rewards_std            991.8493838431164
total_rewards_max            5484.352525378439
total_rewards_min            2645.1339542089354
Number of train steps total  1212000
Number of env steps total    1580384
Number of rollouts total     0
Train Time (s)               116.42286655894713
(Previous) Eval Time (s)     23.230524703045376
Sample Time (s)              7.93663683795603
Epoch Time (s)               147.59002809994854
Total Train Time (s)         45648.167537732515
Epoch                        302
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 08:59:21.851284 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #302 | Epoch Duration: 146.99762272834778
2020-01-06 08:59:21.851477 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #302 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14033529
Z variance train             0.026736919
KL Divergence                6.723336
KL Loss                      0.67233366
QF Loss                      1133.7181
VF Loss                      414.23938
Policy Loss                  -2763.9944
Q Predictions Mean           2760.9805
Q Predictions Std            108.531006
Q Predictions Max            2858.6106
Q Predictions Min            1736.4138
V Predictions Mean           2761.9297
V Predictions Std            104.77946
V Predictions Max            2862.1956
V Predictions Min            1754.3905
Log Pis Mean                 -5.0817637
Log Pis Std                  3.6817627
Log Pis Max                  10.402986
Log Pis Min                  -16.29865
Policy mu Mean               0.015617178
Policy mu Std                0.7124653
Policy mu Max                2.5184078
Policy mu Min                -2.5002308
Policy log std Mean          -0.27368137
Policy log std Std           0.11445448
Policy log std Max           -0.0651253
Policy log std Min           -1.0872698
Z mean eval                  0.13396244
Z variance eval              0.028474014
total_rewards                [5400.0444353  1197.24150531 2338.39050941 5270.76498886 5439.67902114
 2590.42567349 5424.80510298 5349.99484037 5425.68763278 5381.84926503]
total_rewards_mean           4381.888297467007
total_rewards_std            1568.0308151615595
total_rewards_max            5439.679021135665
total_rewards_min            1197.2415053097716
Number of train steps total  1216000
Number of env steps total    1585384
Number of rollouts total     0
Train Time (s)               119.35416487400653
(Previous) Eval Time (s)     22.637861554976553
Sample Time (s)              7.594848885026295
Epoch Time (s)               149.58687531400938
Total Train Time (s)         45794.30592602462
Epoch                        303
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 09:01:47.991970 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #303 | Epoch Duration: 146.1403443813324
2020-01-06 09:01:47.992122 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #303 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.13016076
Z variance train             0.031817682
KL Divergence                6.2939334
KL Loss                      0.62939334
QF Loss                      619.3916
VF Loss                      152.61792
Policy Loss                  -2773.2295
Q Predictions Mean           2765.1968
Q Predictions Std            57.933296
Q Predictions Max            2858.1387
Q Predictions Min            2537.5266
V Predictions Mean           2767.5974
V Predictions Std            62.262733
V Predictions Max            2868.8367
V Predictions Min            2529.784
Log Pis Mean                 -5.359351
Log Pis Std                  3.8785992
Log Pis Max                  14.373942
Log Pis Min                  -14.130687
Policy mu Mean               0.05447028
Policy mu Std                0.7035128
Policy mu Max                2.6119092
Policy mu Min                -2.457765
Policy log std Mean          -0.26879972
Policy log std Std           0.10831661
Policy log std Max           -0.036636487
Policy log std Min           -0.87515706
Z mean eval                  0.15706606
Z variance eval              0.035727832
total_rewards                [3983.63274798 1903.62770567 3841.24615982 5368.14336028 2240.37163065
 4009.30936538 3604.11002454 5521.21191617 4744.23471041 2686.59134525]
total_rewards_mean           3790.2478966146773
total_rewards_std            1170.394168574167
total_rewards_max            5521.211916169859
total_rewards_min            1903.627705665475
Number of train steps total  1220000
Number of env steps total    1590384
Number of rollouts total     0
Train Time (s)               111.70602053101175
(Previous) Eval Time (s)     19.191097919014283
Sample Time (s)              7.697639049962163
Epoch Time (s)               138.5947574999882
Total Train Time (s)         45931.1744736947
Epoch                        304
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 09:04:04.863367 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #304 | Epoch Duration: 136.87114667892456
2020-01-06 09:04:04.863487 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #304 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1522989
Z variance train             0.04273843
KL Divergence                5.601496
KL Loss                      0.5601496
QF Loss                      450.18713
VF Loss                      192.76332
Policy Loss                  -2767.0696
Q Predictions Mean           2763.1958
Q Predictions Std            188.70905
Q Predictions Max            2863.7805
Q Predictions Min            -20.38719
V Predictions Mean           2765.0337
V Predictions Std            190.15285
V Predictions Max            2866.2683
V Predictions Min            -7.041102
Log Pis Mean                 -5.222946
Log Pis Std                  4.169495
Log Pis Max                  14.213881
Log Pis Min                  -15.097893
Policy mu Mean               0.07515163
Policy mu Std                0.71780866
Policy mu Max                2.4220831
Policy mu Min                -2.906891
Policy log std Mean          -0.27963093
Policy log std Std           0.11358953
Policy log std Max           -0.06390554
Policy log std Min           -0.9166177
Z mean eval                  0.18773814
Z variance eval              0.04511264
total_rewards                [5355.67101751 5346.58494106 5284.81049813 5398.35827544 5341.01387786
  308.75457296 5309.46335162 5400.34883183 5362.2423047  5425.6874169 ]
total_rewards_mean           4853.293508801098
total_rewards_std            1515.3795406742208
total_rewards_max            5425.687416897395
total_rewards_min            308.7545729565589
Number of train steps total  1224000
Number of env steps total    1595570
Number of rollouts total     0
Train Time (s)               113.88312312401831
(Previous) Eval Time (s)     17.467209646012634
Sample Time (s)              8.01871441397816
Epoch Time (s)               139.3690471840091
Total Train Time (s)         46074.97865454288
Epoch                        305
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 09:06:28.670879 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #305 | Epoch Duration: 143.8072865009308
2020-01-06 09:06:28.671081 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #305 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.20256872
Z variance train             0.043444373
KL Divergence                5.6086016
KL Loss                      0.56086016
QF Loss                      921.3784
VF Loss                      398.807
Policy Loss                  -2759.9243
Q Predictions Mean           2758.6191
Q Predictions Std            204.35663
Q Predictions Max            2875.3586
Q Predictions Min            240.05756
V Predictions Mean           2759.548
V Predictions Std            207.64915
V Predictions Max            2885.2776
V Predictions Min            204.88145
Log Pis Mean                 -5.6297207
Log Pis Std                  4.1800494
Log Pis Max                  16.46684
Log Pis Min                  -15.5626545
Policy mu Mean               0.015139661
Policy mu Std                0.7099519
Policy mu Max                2.515127
Policy mu Min                -3.394431
Policy log std Mean          -0.27719083
Policy log std Std           0.11784571
Policy log std Max           -0.04493191
Policy log std Min           -0.97503895
Z mean eval                  0.18406603
Z variance eval              0.039890498
total_rewards                [5335.60581213 5408.49478063 5269.96736082 5458.08600376 5439.81237911
 5216.01699196 5435.35079684 5348.09580297 5335.15628383 2587.35449506]
total_rewards_mean           5083.394070709949
total_rewards_std            835.2643917031431
total_rewards_max            5458.0860037611465
total_rewards_min            2587.354495059608
Number of train steps total  1228000
Number of env steps total    1600570
Number of rollouts total     0
Train Time (s)               115.78243029798614
(Previous) Eval Time (s)     21.905185058014467
Sample Time (s)              7.711767009925097
Epoch Time (s)               145.3993823659257
Total Train Time (s)         46221.65721771569
Epoch                        306
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 09:08:55.351971 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #306 | Epoch Duration: 146.68073534965515
2020-01-06 09:08:55.352089 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #306 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.20142265
Z variance train             0.05179717
KL Divergence                5.1886663
KL Loss                      0.51886666
QF Loss                      1430.5214
VF Loss                      208.90515
Policy Loss                  -2743.42
Q Predictions Mean           2741.9766
Q Predictions Std            235.2696
Q Predictions Max            2884.2063
Q Predictions Min            475.1377
V Predictions Mean           2745.6301
V Predictions Std            232.13354
V Predictions Max            2879.2158
V Predictions Min            514.1828
Log Pis Mean                 -5.7099752
Log Pis Std                  4.525231
Log Pis Max                  20.888216
Log Pis Min                  -14.062441
Policy mu Mean               0.050980102
Policy mu Std                0.70682293
Policy mu Max                2.802794
Policy mu Min                -2.9765036
Policy log std Mean          -0.27180204
Policy log std Std           0.11382846
Policy log std Max           -0.012641534
Policy log std Min           -0.9871298
Z mean eval                  0.17203073
Z variance eval              0.04418475
total_rewards                [5470.77649593 5310.94123316  476.5922894  5383.8950702  1846.69834295
 5193.18793201  734.64671802 5388.81695318 1281.21410732 5428.75583524]
total_rewards_mean           3651.55249773963
total_rewards_std            2123.253429994061
total_rewards_max            5470.77649592807
total_rewards_min            476.59228939713734
Number of train steps total  1232000
Number of env steps total    1605741
Number of rollouts total     0
Train Time (s)               116.29813501500757
(Previous) Eval Time (s)     23.18628996401094
Sample Time (s)              7.924506968120113
Epoch Time (s)               147.40893194713863
Total Train Time (s)         46360.84790113475
Epoch                        307
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 09:11:14.545127 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #307 | Epoch Duration: 139.19294261932373
2020-01-06 09:11:14.545305 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #307 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1819832
Z variance train             0.036638673
KL Divergence                5.9959536
KL Loss                      0.59959537
QF Loss                      1750.7041
VF Loss                      861.8842
Policy Loss                  -2760.0593
Q Predictions Mean           2750.3184
Q Predictions Std            201.76382
Q Predictions Max            2891.2588
Q Predictions Min            754.4803
V Predictions Mean           2748.0435
V Predictions Std            195.64455
V Predictions Max            2877.9084
V Predictions Min            715.051
Log Pis Mean                 -4.327264
Log Pis Std                  4.5152316
Log Pis Max                  24.477125
Log Pis Min                  -13.766226
Policy mu Mean               0.07132907
Policy mu Std                0.7487996
Policy mu Max                2.638211
Policy mu Min                -2.3869603
Policy log std Mean          -0.29113036
Policy log std Std           0.12523496
Policy log std Max           0.0036325455
Policy log std Min           -1.1295137
Z mean eval                  0.1782113
Z variance eval              0.048741885
total_rewards                [5503.76853143 3231.01526998 5333.48894666 5504.38822086 1973.80174416
 5486.16042201 5429.42421194 5515.94211907 5391.16617215 5444.59096896]
total_rewards_mean           4881.374660721974
total_rewards_std            1174.8827056151865
total_rewards_max            5515.94211906903
total_rewards_min            1973.801744158144
Number of train steps total  1236000
Number of env steps total    1610937
Number of rollouts total     0
Train Time (s)               117.96014435502002
(Previous) Eval Time (s)     14.970046720991377
Sample Time (s)              8.129598499042913
Epoch Time (s)               141.0597895750543
Total Train Time (s)         46509.49199158477
Epoch                        308
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 09:13:43.191660 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #308 | Epoch Duration: 148.64622831344604
2020-01-06 09:13:43.191773 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #308 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.15029767
Z variance train             0.036711074
KL Divergence                5.9651914
KL Loss                      0.5965192
QF Loss                      1064.2896
VF Loss                      613.2607
Policy Loss                  -2757.009
Q Predictions Mean           2757.7095
Q Predictions Std            201.80646
Q Predictions Max            2878.2036
Q Predictions Min            474.1012
V Predictions Mean           2759.3213
V Predictions Std            190.59244
V Predictions Max            2872.4775
V Predictions Min            593.2742
Log Pis Mean                 -4.847521
Log Pis Std                  5.0006046
Log Pis Max                  16.971214
Log Pis Min                  -13.886625
Policy mu Mean               0.084869444
Policy mu Std                0.7468672
Policy mu Max                2.838667
Policy mu Min                -3.229643
Policy log std Mean          -0.27639982
Policy log std Std           0.12538618
Policy log std Max           -0.046375714
Policy log std Min           -1.2062706
Z mean eval                  0.127406
Z variance eval              0.046487223
total_rewards                [5400.80035427 5358.85762492 1656.02872178 5307.08179504 5330.04332629
 5373.69236545 5297.92494313 5073.48242879 5444.49134899 4677.06913902]
total_rewards_mean           4891.947204767535
total_rewards_std            1099.713563268758
total_rewards_max            5444.4913489910505
total_rewards_min            1656.0287217812859
Number of train steps total  1240000
Number of env steps total    1616086
Number of rollouts total     0
Train Time (s)               118.30465970200021
(Previous) Eval Time (s)     22.55624407500727
Sample Time (s)              7.973176927946042
Epoch Time (s)               148.83408070495352
Total Train Time (s)         46659.02402750787
Epoch                        309
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 09:16:12.727342 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #309 | Epoch Duration: 149.53547716140747
2020-01-06 09:16:12.727490 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #309 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14716554
Z variance train             0.05473184
KL Divergence                5.013983
KL Loss                      0.50139827
QF Loss                      1760.6692
VF Loss                      237.94739
Policy Loss                  -2764.7886
Q Predictions Mean           2752.1777
Q Predictions Std            176.99013
Q Predictions Max            2861.8723
Q Predictions Min            164.14272
V Predictions Mean           2761.7349
V Predictions Std            183.76382
V Predictions Max            2874.1638
V Predictions Min            110.018
Log Pis Mean                 -5.6186876
Log Pis Std                  3.6710567
Log Pis Max                  10.239051
Log Pis Min                  -14.902606
Policy mu Mean               0.0676642
Policy mu Std                0.71052676
Policy mu Max                2.1354294
Policy mu Min                -2.0633447
Policy log std Mean          -0.28598613
Policy log std Std           0.107457586
Policy log std Max           -0.063721985
Policy log std Min           -0.9158579
Z mean eval                  0.1222172
Z variance eval              0.07428522
total_rewards                [5608.40288364 5499.2310826  5577.16559095 5529.74689925 5614.83360935
 5454.20947591 5618.66596204 5511.31346411 5269.7887641  5494.66320251]
total_rewards_mean           5517.802093444905
total_rewards_std            98.96507820431118
total_rewards_max            5618.665962038771
total_rewards_min            5269.7887640981435
Number of train steps total  1244000
Number of env steps total    1621086
Number of rollouts total     0
Train Time (s)               117.98822696099523
(Previous) Eval Time (s)     23.257363773009274
Sample Time (s)              7.876255367940757
Epoch Time (s)               149.12184610194527
Total Train Time (s)         46809.748789057776
Epoch                        310
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 09:18:43.455290 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #310 | Epoch Duration: 150.72769355773926
2020-01-06 09:18:43.455420 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #310 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.103118494
Z variance train             0.07285248
KL Divergence                4.320337
KL Loss                      0.4320337
QF Loss                      1065.4631
VF Loss                      325.6405
Policy Loss                  -2739.5256
Q Predictions Mean           2736.5308
Q Predictions Std            253.06833
Q Predictions Max            2856.512
Q Predictions Min            209.61906
V Predictions Mean           2740.1875
V Predictions Std            255.01949
V Predictions Max            2884.571
V Predictions Min            133.12427
Log Pis Mean                 -5.6084976
Log Pis Std                  3.9997637
Log Pis Max                  23.694668
Log Pis Min                  -15.103693
Policy mu Mean               0.047195785
Policy mu Std                0.7249702
Policy mu Max                2.586496
Policy mu Min                -2.5204825
Policy log std Mean          -0.28155246
Policy log std Std           0.11726916
Policy log std Max           0.54305595
Policy log std Min           -1.0635862
Z mean eval                  0.114421174
Z variance eval              0.08789779
total_rewards                [5482.71437543 5567.976402   2228.62540926 5432.75007599 3777.4358485
 3730.30190011 5415.55473318 4129.65190501 5567.61566141 1027.7053097 ]
total_rewards_mean           4236.033162056943
total_rewards_std            1507.4895480558696
total_rewards_max            5567.97640199549
total_rewards_min            1027.7053097012574
Number of train steps total  1248000
Number of env steps total    1626086
Number of rollouts total     0
Train Time (s)               116.23218707798515
(Previous) Eval Time (s)     24.862965356034692
Sample Time (s)              8.096047949860804
Epoch Time (s)               149.19120038388064
Total Train Time (s)         46953.269193200744
Epoch                        311
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 09:21:06.978613 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #311 | Epoch Duration: 143.52309250831604
2020-01-06 09:21:06.978737 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #311 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.13305596
Z variance train             0.0884306
KL Divergence                3.8960752
KL Loss                      0.38960752
QF Loss                      784.2479
VF Loss                      442.4978
Policy Loss                  -2751.077
Q Predictions Mean           2747.6438
Q Predictions Std            214.42531
Q Predictions Max            2878.1086
Q Predictions Min            728.323
V Predictions Mean           2753.9927
V Predictions Std            218.9535
V Predictions Max            2879.406
V Predictions Min            742.42505
Log Pis Mean                 -5.6405606
Log Pis Std                  4.176678
Log Pis Max                  20.920126
Log Pis Min                  -16.66091
Policy mu Mean               0.06960991
Policy mu Std                0.71995986
Policy mu Max                2.9524298
Policy mu Min                -3.1773891
Policy log std Mean          -0.2816734
Policy log std Std           0.11489743
Policy log std Max           0.26651514
Policy log std Min           -1.0462373
Z mean eval                  0.14606817
Z variance eval              0.063630976
total_rewards                [3257.74808515 5484.41877648 5594.87309565 5497.76369581 5535.04993125
 5570.9956327  5644.58397627 5662.54758168 5390.34537659 5442.5802716 ]
total_rewards_mean           5308.090642318619
total_rewards_std            688.299832597911
total_rewards_max            5662.547581678444
total_rewards_min            3257.7480851502323
Number of train steps total  1252000
Number of env steps total    1631086
Number of rollouts total     0
Train Time (s)               109.4808518649661
(Previous) Eval Time (s)     19.19459916901542
Sample Time (s)              7.843200200004503
Epoch Time (s)               136.51865123398602
Total Train Time (s)         47094.37937550462
Epoch                        312
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 09:23:28.092225 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #312 | Epoch Duration: 141.11338639259338
2020-01-06 09:23:28.092391 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #312 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.12696888
Z variance train             0.07848354
KL Divergence                4.1712766
KL Loss                      0.41712767
QF Loss                      1370.0212
VF Loss                      506.96918
Policy Loss                  -2749.0486
Q Predictions Mean           2746.9048
Q Predictions Std            153.9312
Q Predictions Max            2853.9092
Q Predictions Min            1493.3077
V Predictions Mean           2753.4246
V Predictions Std            161.03067
V Predictions Max            2870.6694
V Predictions Min            1330.8003
Log Pis Mean                 -4.798325
Log Pis Std                  5.126708
Log Pis Max                  20.98655
Log Pis Min                  -14.938919
Policy mu Mean               0.10823062
Policy mu Std                0.74086046
Policy mu Max                2.4672556
Policy mu Min                -3.500236
Policy log std Mean          -0.274832
Policy log std Std           0.11916802
Policy log std Max           0.0054256916
Policy log std Min           -1.3145545
Z mean eval                  0.11117134
Z variance eval              0.12411207
total_rewards                [5753.28194899 5669.44571081 5542.93697582 1003.24142479 2821.91000771
 5612.39161974 5693.6232712  5530.83127964 5588.4540224  5685.6302951 ]
total_rewards_mean           4890.174655619068
total_rewards_std            1544.7393468872365
total_rewards_max            5753.281948991726
total_rewards_min            1003.2414247880051
Number of train steps total  1256000
Number of env steps total    1636086
Number of rollouts total     0
Train Time (s)               116.97199047799222
(Previous) Eval Time (s)     23.789071801002137
Sample Time (s)              7.864391552051529
Epoch Time (s)               148.6254538310459
Total Train Time (s)         47240.05634198454
Epoch                        313
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 09:25:53.771686 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #313 | Epoch Duration: 145.6792013645172
2020-01-06 09:25:53.771792 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #313 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.13165453
Z variance train             0.07062543
KL Divergence                4.4124174
KL Loss                      0.44124174
QF Loss                      737.8989
VF Loss                      127.33954
Policy Loss                  -2780.9187
Q Predictions Mean           2780.9685
Q Predictions Std            87.64928
Q Predictions Max            2885.2712
Q Predictions Min            1943.0918
V Predictions Mean           2784.5103
V Predictions Std            89.28246
V Predictions Max            2888.5261
V Predictions Min            1997.5183
Log Pis Mean                 -5.7606754
Log Pis Std                  4.1017723
Log Pis Max                  15.799576
Log Pis Min                  -16.030153
Policy mu Mean               0.054573067
Policy mu Std                0.70611703
Policy mu Max                2.761444
Policy mu Min                -2.776352
Policy log std Mean          -0.26552653
Policy log std Std           0.104816586
Policy log std Max           -0.021946207
Policy log std Min           -1.068424
Z mean eval                  0.21608694
Z variance eval              0.07371514
total_rewards                [5432.99394836 5455.84468011 5555.68347657 5486.42951559 1944.65425707
 5470.26278545 5482.05967754 4735.47594198 5470.06473338 5447.18452351]
total_rewards_mean           5048.065353956072
total_rewards_std            1058.1657340318313
total_rewards_max            5555.683476569975
total_rewards_min            1944.6542570705951
Number of train steps total  1260000
Number of env steps total    1641286
Number of rollouts total     0
Train Time (s)               112.42354383901693
(Previous) Eval Time (s)     20.842566245002672
Sample Time (s)              8.181173950026277
Epoch Time (s)               141.44728403404588
Total Train Time (s)         47383.02280885965
Epoch                        314
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 09:28:16.741344 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #314 | Epoch Duration: 142.9694652557373
2020-01-06 09:28:16.741462 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #314 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1994378
Z variance train             0.058699172
KL Divergence                4.899852
KL Loss                      0.4899852
QF Loss                      1211.357
VF Loss                      735.4085
Policy Loss                  -2764.752
Q Predictions Mean           2762.4014
Q Predictions Std            132.95258
Q Predictions Max            2870.6274
Q Predictions Min            1455.2102
V Predictions Mean           2772.9907
V Predictions Std            133.54616
V Predictions Max            2884.1902
V Predictions Min            1184.1365
Log Pis Mean                 -5.427202
Log Pis Std                  4.032229
Log Pis Max                  23.015713
Log Pis Min                  -14.674295
Policy mu Mean               0.050617706
Policy mu Std                0.710522
Policy mu Max                2.706222
Policy mu Min                -2.6781979
Policy log std Mean          -0.27989224
Policy log std Std           0.10621131
Policy log std Max           0.0051769316
Policy log std Min           -0.8798405
Z mean eval                  0.21252823
Z variance eval              0.20631044
total_rewards                [5432.9724044  5471.99779901 5455.55202899 5382.76546984 5396.58137715
 5398.08751328 5434.91011051 5434.15464334 5437.13957946 5444.1473069 ]
total_rewards_mean           5428.830823286688
total_rewards_std            26.590766983337048
total_rewards_max            5471.997799006289
total_rewards_min            5382.7654698387705
Number of train steps total  1264000
Number of env steps total    1646286
Number of rollouts total     0
Train Time (s)               119.14820305100875
(Previous) Eval Time (s)     22.364499629009515
Sample Time (s)              7.528825668036006
Epoch Time (s)               149.04152834805427
Total Train Time (s)         47534.400561581715
Epoch                        315
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 09:30:48.121990 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #315 | Epoch Duration: 151.38042783737183
2020-01-06 09:30:48.122117 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #315 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.44844994
Z variance train             0.60298437
KL Divergence                1.1529304
KL Loss                      0.11529304
QF Loss                      615.81006
VF Loss                      480.52518
Policy Loss                  -2782.6123
Q Predictions Mean           2777.58
Q Predictions Std            175.84903
Q Predictions Max            2894.8672
Q Predictions Min            488.59857
V Predictions Mean           2777.6594
V Predictions Std            173.17218
V Predictions Max            2892.1611
V Predictions Min            475.41968
Log Pis Mean                 -4.946684
Log Pis Std                  4.0262747
Log Pis Max                  11.800592
Log Pis Min                  -15.180616
Policy mu Mean               0.04071358
Policy mu Std                0.72354877
Policy mu Max                2.1623244
Policy mu Min                -2.5422826
Policy log std Mean          -0.2836302
Policy log std Std           0.10759246
Policy log std Max           0.034116358
Policy log std Min           -0.9026275
Z mean eval                  0.08509275
Z variance eval              0.20012817
total_rewards                [5514.85909282 5573.48730155 5452.59621572 5487.96209754 5467.94625707
 5511.27505604 5504.12575949 5452.71079504  950.3616986  5551.59373011]
total_rewards_mean           5046.691800398357
total_rewards_std            1365.957847607153
total_rewards_max            5573.487301552952
total_rewards_min            950.3616986006527
Number of train steps total  1268000
Number of env steps total    1651286
Number of rollouts total     0
Train Time (s)               121.77117464301409
(Previous) Eval Time (s)     24.70314421103103
Sample Time (s)              7.843718855001498
Epoch Time (s)               154.31803770904662
Total Train Time (s)         47686.41151829471
Epoch                        316
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 09:33:20.135744 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #316 | Epoch Duration: 152.01352763175964
2020-01-06 09:33:20.135864 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #316 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.4118523
Z variance train             0.6896618
KL Divergence                0.78228676
KL Loss                      0.078228675
QF Loss                      672.74744
VF Loss                      466.82065
Policy Loss                  -2759.3198
Q Predictions Mean           2757.316
Q Predictions Std            184.63603
Q Predictions Max            2862.2231
Q Predictions Min            130.66246
V Predictions Mean           2756.4233
V Predictions Std            193.23953
V Predictions Max            2865.4868
V Predictions Min            86.66654
Log Pis Mean                 -5.270164
Log Pis Std                  3.6273632
Log Pis Max                  14.931068
Log Pis Min                  -12.416887
Policy mu Mean               0.068938695
Policy mu Std                0.7075671
Policy mu Max                2.2545362
Policy mu Min                -1.9927907
Policy log std Mean          -0.2711576
Policy log std Std           0.108181775
Policy log std Max           0.110518396
Policy log std Min           -0.75950176
Z mean eval                  1.3067534
Z variance eval              3.1995382
total_rewards                [5498.48029513 5370.81702059 5510.52525738 4086.7980903  1910.68592712
 1942.72187922 5296.75298008 5370.85158621 5444.06325183 5435.06702471]
total_rewards_mean           4586.676331257146
total_rewards_std            1388.347101728294
total_rewards_max            5510.525257376331
total_rewards_min            1910.6859271184278
Number of train steps total  1272000
Number of env steps total    1656286
Number of rollouts total     0
Train Time (s)               125.90917013504077
(Previous) Eval Time (s)     22.398375718970783
Sample Time (s)              7.846792813099455
Epoch Time (s)               156.154338667111
Total Train Time (s)         47841.04722237494
Epoch                        317
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 09:35:54.774165 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #317 | Epoch Duration: 154.63819670677185
2020-01-06 09:35:54.774281 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #317 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.84902096
Z variance train             2.9590194
KL Divergence                6.3427563
KL Loss                      0.6342756
QF Loss                      1789.6272
VF Loss                      370.3903
Policy Loss                  -2754.5518
Q Predictions Mean           2757.168
Q Predictions Std            226.01253
Q Predictions Max            2887.173
Q Predictions Min            8.944461
V Predictions Mean           2762.991
V Predictions Std            227.00352
V Predictions Max            2888.5012
V Predictions Min            48.363228
Log Pis Mean                 -5.8736577
Log Pis Std                  4.456712
Log Pis Max                  16.221922
Log Pis Min                  -15.421846
Policy mu Mean               0.0934008
Policy mu Std                0.7045001
Policy mu Max                2.7024074
Policy mu Min                -2.7329826
Policy log std Mean          -0.27952448
Policy log std Std           0.11411063
Policy log std Max           0.25715235
Policy log std Min           -1.0169777
Z mean eval                  0.25796822
Z variance eval              0.7726304
total_rewards                [5510.014077   5448.33223292 3079.30589422 5489.6440898  5522.40654121
 5502.83952384 4377.06235909 5505.68637274 5476.63322356 5440.39984359]
total_rewards_mean           5135.232415798064
total_rewards_std            761.4271281459551
total_rewards_max            5522.406541214103
total_rewards_min            3079.3058942166176
Number of train steps total  1276000
Number of env steps total    1661286
Number of rollouts total     0
Train Time (s)               111.22454468702199
(Previous) Eval Time (s)     20.88197314599529
Sample Time (s)              7.932919212908018
Epoch Time (s)               140.0394370459253
Total Train Time (s)         47984.47509275278
Epoch                        318
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 09:38:18.722258 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #318 | Epoch Duration: 143.9478816986084
2020-01-06 09:38:18.722427 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #318 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.33816168
Z variance train             0.79048526
KL Divergence                0.6372853
KL Loss                      0.06372853
QF Loss                      2096.8267
VF Loss                      2439.5925
Policy Loss                  -2751.9036
Q Predictions Mean           2746.6377
Q Predictions Std            242.59787
Q Predictions Max            2877.5479
Q Predictions Min            908.6295
V Predictions Mean           2761.915
V Predictions Std            215.08775
V Predictions Max            2885.2363
V Predictions Min            982.2353
Log Pis Mean                 -4.9206586
Log Pis Std                  4.8724546
Log Pis Max                  24.991562
Log Pis Min                  -14.035973
Policy mu Mean               0.055595834
Policy mu Std                0.7380923
Policy mu Max                2.6572516
Policy mu Min                -3.2219107
Policy log std Mean          -0.27328885
Policy log std Std           0.112323366
Policy log std Max           -0.0050925314
Policy log std Min           -0.8839345
Z mean eval                  0.09871549
Z variance eval              0.35372764
total_rewards                [5437.06975457 5397.58540264 5419.58777448 5449.39412012 5371.6907871
 5300.92513466 5329.79026018 5442.63746873 5440.48750857 5180.59484437]
total_rewards_mean           5376.976305543512
total_rewards_std            81.26808375870561
total_rewards_max            5449.394120120615
total_rewards_min            5180.5948443745265
Number of train steps total  1280000
Number of env steps total    1666286
Number of rollouts total     0
Train Time (s)               114.50043825700413
(Previous) Eval Time (s)     24.790145792998374
Sample Time (s)              7.954955075925682
Epoch Time (s)               147.2455391259282
Total Train Time (s)         48132.58171767078
Epoch                        319
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 09:40:46.314464 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #319 | Epoch Duration: 147.59192609786987
2020-01-06 09:40:46.314637 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #319 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.108790316
Z variance train             0.20118241
KL Divergence                2.091228
KL Loss                      0.2091228
QF Loss                      1298.2153
VF Loss                      279.60498
Policy Loss                  -2750.2314
Q Predictions Mean           2748.6504
Q Predictions Std            229.61665
Q Predictions Max            2863.3223
Q Predictions Min            290.33298
V Predictions Mean           2747.269
V Predictions Std            238.0097
V Predictions Max            2871.6497
V Predictions Min            287.81152
Log Pis Mean                 -4.3371334
Log Pis Std                  5.132904
Log Pis Max                  28.815746
Log Pis Min                  -16.07857
Policy mu Mean               0.06233232
Policy mu Std                0.7566843
Policy mu Max                2.8285306
Policy mu Min                -2.993544
Policy log std Mean          -0.2862006
Policy log std Std           0.11673785
Policy log std Max           -0.03047204
Policy log std Min           -1.0002329
Z mean eval                  0.41643125
Z variance eval              0.6483863
total_rewards                [4093.58714565 5380.55938853 5440.48453389 2541.42682872 5354.40907676
 5431.34521579 3943.699246   5491.2080717  5468.26322081 5482.29458669]
total_rewards_mean           4862.727731452605
total_rewards_std            955.886042922635
total_rewards_max            5491.20807169501
total_rewards_min            2541.426828715993
Number of train steps total  1284000
Number of env steps total    1671286
Number of rollouts total     0
Train Time (s)               129.85522115800995
(Previous) Eval Time (s)     25.1362829519785
Sample Time (s)              8.093884695961606
Epoch Time (s)               163.08538880595006
Total Train Time (s)         48292.639464444714
Epoch                        320
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 09:43:26.375559 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #320 | Epoch Duration: 160.06080174446106
2020-01-06 09:43:26.375695 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #320 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.20766445
Z variance train             0.099964
KL Divergence                3.6688232
KL Loss                      0.36688232
QF Loss                      685.9865
VF Loss                      181.94498
Policy Loss                  -2778.5393
Q Predictions Mean           2773.7642
Q Predictions Std            117.81594
Q Predictions Max            2878.028
Q Predictions Min            1199.3494
V Predictions Mean           2780.1753
V Predictions Std            123.00245
V Predictions Max            2882.66
V Predictions Min            1114.6006
Log Pis Mean                 -5.0314193
Log Pis Std                  3.7908797
Log Pis Max                  14.918936
Log Pis Min                  -14.018038
Policy mu Mean               0.07049984
Policy mu Std                0.72174597
Policy mu Max                1.8964232
Policy mu Min                -2.7161758
Policy log std Mean          -0.2770416
Policy log std Std           0.10509915
Policy log std Max           -0.062037908
Policy log std Min           -1.0439966
Z mean eval                  0.2639187
Z variance eval              0.26162225
total_rewards                [5361.20991438 5294.26197029 5369.52382468 4433.16700222 5488.74055682
  864.102692   5381.79168073 5258.84342276 5468.98197496 5352.65596605]
total_rewards_mean           4827.327900488798
total_rewards_std            1351.9742111694761
total_rewards_max            5488.740556816627
total_rewards_min            864.1026920022189
Number of train steps total  1288000
Number of env steps total    1676286
Number of rollouts total     0
Train Time (s)               121.97001202404499
(Previous) Eval Time (s)     22.111458870989736
Sample Time (s)              7.723684195952956
Epoch Time (s)               151.80515509098768
Total Train Time (s)         48444.58233417163
Epoch                        321
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 09:45:58.320685 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #321 | Epoch Duration: 151.9448745250702
2020-01-06 09:45:58.320816 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #321 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.30573934
Z variance train             0.5871818
KL Divergence                0.6681144
KL Loss                      0.06681144
QF Loss                      1798.666
VF Loss                      443.51688
Policy Loss                  -2786.4014
Q Predictions Mean           2780.4045
Q Predictions Std            109.46316
Q Predictions Max            2879.1436
Q Predictions Min            1581.9733
V Predictions Mean           2777.8904
V Predictions Std            117.42484
V Predictions Max            2888.8147
V Predictions Min            1409.1643
Log Pis Mean                 -6.2974253
Log Pis Std                  3.7792659
Log Pis Max                  14.636807
Log Pis Min                  -16.28311
Policy mu Mean               0.019149134
Policy mu Std                0.6806878
Policy mu Max                2.4970348
Policy mu Min                -2.9517984
Policy log std Mean          -0.27018377
Policy log std Std           0.10911247
Policy log std Max           -0.06528589
Policy log std Min           -0.9494437
Z mean eval                  0.21865627
Z variance eval              0.19581339
total_rewards                [ 421.63188167 3270.16651832 5303.67530717 5423.38490107 5353.37786696
 4750.8016451  5161.29368656 5418.9266047  5308.32748136 5502.48133604]
total_rewards_mean           4591.406722894818
total_rewards_std            1526.1655062985658
total_rewards_max            5502.481336042988
total_rewards_min            421.63188167136354
Number of train steps total  1292000
Number of env steps total    1681425
Number of rollouts total     0
Train Time (s)               128.21445247303927
(Previous) Eval Time (s)     22.25092418200802
Sample Time (s)              7.876005163125228
Epoch Time (s)               158.34138181817252
Total Train Time (s)         48602.97628556797
Epoch                        322
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 09:48:36.718955 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #322 | Epoch Duration: 158.3980212211609
2020-01-06 09:48:36.719205 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #322 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.2107807
Z variance train             0.15763466
KL Divergence                2.672333
KL Loss                      0.2672333
QF Loss                      600.2347
VF Loss                      471.26672
Policy Loss                  -2769.7322
Q Predictions Mean           2762.763
Q Predictions Std            192.88374
Q Predictions Max            2883.2317
Q Predictions Min            465.50818
V Predictions Mean           2756.975
V Predictions Std            188.35979
V Predictions Max            2887.1943
V Predictions Min            457.39606
Log Pis Mean                 -4.879547
Log Pis Std                  4.2307363
Log Pis Max                  18.872236
Log Pis Min                  -16.691023
Policy mu Mean               0.06183376
Policy mu Std                0.7258345
Policy mu Max                2.5253658
Policy mu Min                -3.1086626
Policy log std Mean          -0.2838421
Policy log std Std           0.10160535
Policy log std Max           0.11627975
Policy log std Min           -1.0190609
Z mean eval                  0.20835133
Z variance eval              0.11670538
total_rewards                [5331.73467421 5467.241265   5461.20116727 5474.67224534 5557.94193524
 5419.92892737 5441.66267829 5371.42062379 1016.6129135  5469.15554732]
total_rewards_mean           5001.157197733006
total_rewards_std            1329.4550566554497
total_rewards_max            5557.94193523593
total_rewards_min            1016.6129135037719
Number of train steps total  1296000
Number of env steps total    1686425
Number of rollouts total     0
Train Time (s)               114.3259147159988
(Previous) Eval Time (s)     22.307291553006507
Sample Time (s)              7.6693894160562195
Epoch Time (s)               144.30259568506153
Total Train Time (s)         48747.716068902926
Epoch                        323
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 09:51:01.461782 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #323 | Epoch Duration: 144.74241304397583
2020-01-06 09:51:01.461919 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #323 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.25191736
Z variance train             0.1549589
KL Divergence                2.7610598
KL Loss                      0.27610597
QF Loss                      1470.6086
VF Loss                      300.42902
Policy Loss                  -2743.9712
Q Predictions Mean           2740.828
Q Predictions Std            278.01
Q Predictions Max            2882.1772
Q Predictions Min            494.1867
V Predictions Mean           2741.437
V Predictions Std            279.2204
V Predictions Max            2898.09
V Predictions Min            521.1698
Log Pis Mean                 -5.010701
Log Pis Std                  5.8188543
Log Pis Max                  34.349228
Log Pis Min                  -14.626643
Policy mu Mean               0.09045876
Policy mu Std                0.7500159
Policy mu Max                3.354221
Policy mu Min                -3.7208116
Policy log std Mean          -0.28730416
Policy log std Std           0.12415612
Policy log std Max           0.043564335
Policy log std Min           -1.4390752
Z mean eval                  0.081311144
Z variance eval              0.36249763
total_rewards                [5495.86462497 5612.76251756 2226.73002357 5536.11157067 3141.42770464
 5470.88408865 5413.46246622 1232.12878501 5519.24320253 5544.54347449]
total_rewards_mean           4519.315845829029
total_rewards_std            1577.9479602206227
total_rewards_max            5612.762517558394
total_rewards_min            1232.128785008709
Number of train steps total  1300000
Number of env steps total    1691425
Number of rollouts total     0
Train Time (s)               111.72044980700593
(Previous) Eval Time (s)     22.746878210979048
Sample Time (s)              7.778418840025552
Epoch Time (s)               142.24574685801053
Total Train Time (s)         48886.20968045911
Epoch                        324
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 09:53:19.958841 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #324 | Epoch Duration: 138.49681282043457
2020-01-06 09:53:19.958989 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #324 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.071012735
Z variance train             0.3642171
KL Divergence                1.0004939
KL Loss                      0.10004939
QF Loss                      849.8594
VF Loss                      366.53613
Policy Loss                  -2755.247
Q Predictions Mean           2750.084
Q Predictions Std            245.07835
Q Predictions Max            2872.965
Q Predictions Min            410.00378
V Predictions Mean           2766.1545
V Predictions Std            236.2513
V Predictions Max            2894.5657
V Predictions Min            508.9168
Log Pis Mean                 -5.5336103
Log Pis Std                  4.2912226
Log Pis Max                  21.00911
Log Pis Min                  -13.537107
Policy mu Mean               0.053701144
Policy mu Std                0.6975246
Policy mu Max                2.7596407
Policy mu Min                -2.4394474
Policy log std Mean          -0.26207092
Policy log std Std           0.10238541
Policy log std Max           -0.019756466
Policy log std Min           -0.8673717
Z mean eval                  0.10604645
Z variance eval              0.26705056
total_rewards                [5363.05208163  783.27997756 5616.49406506  991.62070409 5603.39960869
 5658.74909866 5555.13761126 5529.1394564  5576.73780838 2868.54466385]
total_rewards_mean           4354.615507557531
total_rewards_std            1909.3566661842817
total_rewards_max            5658.749098656434
total_rewards_min            783.279977557839
Number of train steps total  1304000
Number of env steps total    1696425
Number of rollouts total     0
Train Time (s)               124.13329056603834
(Previous) Eval Time (s)     18.997686752991285
Sample Time (s)              7.620969161042012
Epoch Time (s)               150.75194648007164
Total Train Time (s)         49038.240176565014
Epoch                        325
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 09:55:51.993222 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #325 | Epoch Duration: 152.03411293029785
2020-01-06 09:55:51.993396 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #325 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.12478069
Z variance train             0.21375027
KL Divergence                1.978956
KL Loss                      0.1978956
QF Loss                      1302.2327
VF Loss                      381.34177
Policy Loss                  -2763.666
Q Predictions Mean           2763.1406
Q Predictions Std            248.63794
Q Predictions Max            2888.5542
Q Predictions Min            75.17604
V Predictions Mean           2769.848
V Predictions Std            247.99924
V Predictions Max            2896.8923
V Predictions Min            106.62544
Log Pis Mean                 -5.3334093
Log Pis Std                  4.2100916
Log Pis Max                  16.306435
Log Pis Min                  -16.661314
Policy mu Mean               0.063275196
Policy mu Std                0.7208325
Policy mu Max                2.6266603
Policy mu Min                -2.126079
Policy log std Mean          -0.28058183
Policy log std Std           0.11216305
Policy log std Max           0.36475784
Policy log std Min           -0.9371773
Z mean eval                  0.36284232
Z variance eval              0.37054837
total_rewards                [5453.09098572 5434.10725396 5393.80082312 5521.21650185 3417.37412899
 5507.56256649 1456.73218353 5478.17993347 5469.65201708 5426.51992704]
total_rewards_mean           4855.823632124154
total_rewards_std            1286.8891781597613
total_rewards_max            5521.216501846827
total_rewards_min            1456.7321835263688
Number of train steps total  1308000
Number of env steps total    1701425
Number of rollouts total     0
Train Time (s)               123.73537794896401
(Previous) Eval Time (s)     20.2796047530137
Sample Time (s)              7.932544892071746
Epoch Time (s)               151.94752759404946
Total Train Time (s)         49191.15364203206
Epoch                        326
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 09:58:24.908908 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #326 | Epoch Duration: 152.91538047790527
2020-01-06 09:58:24.909017 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #326 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.23497312
Z variance train             0.09297306
KL Divergence                3.8656154
KL Loss                      0.38656154
QF Loss                      642.1419
VF Loss                      234.44496
Policy Loss                  -2786.9685
Q Predictions Mean           2776.721
Q Predictions Std            196.83829
Q Predictions Max            2888.159
Q Predictions Min            461.00305
V Predictions Mean           2781.6394
V Predictions Std            194.60307
V Predictions Max            2897.3372
V Predictions Min            498.20578
Log Pis Mean                 -5.7941217
Log Pis Std                  3.4119022
Log Pis Max                  6.226116
Log Pis Min                  -14.328758
Policy mu Mean               0.07077573
Policy mu Std                0.6734351
Policy mu Max                2.1450648
Policy mu Min                -2.0942256
Policy log std Mean          -0.26622748
Policy log std Std           0.10258377
Policy log std Max           -0.009066954
Policy log std Min           -0.81333065
Z mean eval                  0.27701095
Z variance eval              0.13669316
total_rewards                [5426.71580607 1342.03781371 3734.97686087 5422.98631475 5197.23711346
 5119.1969828   469.00941927 5327.86812019 3738.85450869 5407.46920564]
total_rewards_mean           4118.63521454566
total_rewards_std            1732.6551445798375
total_rewards_max            5426.715806067666
total_rewards_min            469.00941927201467
Number of train steps total  1312000
Number of env steps total    1706425
Number of rollouts total     0
Train Time (s)               116.409772730025
(Previous) Eval Time (s)     21.24720000202069
Sample Time (s)              7.7082490109605715
Epoch Time (s)               145.36522174300626
Total Train Time (s)         49334.544494258065
Epoch                        327
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 10:00:48.303485 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #327 | Epoch Duration: 143.39436984062195
2020-01-06 10:00:48.303712 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #327 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.28552502
Z variance train             0.14890769
KL Divergence                2.892188
KL Loss                      0.2892188
QF Loss                      857.0896
VF Loss                      214.59898
Policy Loss                  -2776.5867
Q Predictions Mean           2777.4333
Q Predictions Std            223.35426
Q Predictions Max            2897.9788
Q Predictions Min            439.99973
V Predictions Mean           2770.879
V Predictions Std            222.38838
V Predictions Max            2896.641
V Predictions Min            425.94553
Log Pis Mean                 -5.565918
Log Pis Std                  4.1638637
Log Pis Max                  29.005604
Log Pis Min                  -15.444903
Policy mu Mean               0.041565478
Policy mu Std                0.7163403
Policy mu Max                3.4068208
Policy mu Min                -3.1908536
Policy log std Mean          -0.27739316
Policy log std Std           0.11062093
Policy log std Max           0.11034557
Policy log std Min           -1.39165
Z mean eval                  0.22793455
Z variance eval              0.1024289
total_rewards                [5281.65705236 5492.06824309 5453.04348664  948.32173671 5283.37444315
 5418.80927022 5560.16781971 5431.02775605 5324.62977445 5517.22415524]
total_rewards_mean           4971.032373761417
total_rewards_std            1343.9715873897264
total_rewards_max            5560.167819711408
total_rewards_min            948.32173670929
Number of train steps total  1316000
Number of env steps total    1711425
Number of rollouts total     0
Train Time (s)               116.10212683997815
(Previous) Eval Time (s)     19.27609618799761
Sample Time (s)              7.637844026088715
Epoch Time (s)               143.01606705406448
Total Train Time (s)         49481.41570164112
Epoch                        328
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 10:03:15.189053 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #328 | Epoch Duration: 146.88513445854187
2020-01-06 10:03:15.189232 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #328 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.25688332
Z variance train             0.14936663
KL Divergence                2.8419242
KL Loss                      0.2841924
QF Loss                      762.18005
VF Loss                      551.3542
Policy Loss                  -2788.011
Q Predictions Mean           2780.4854
Q Predictions Std            228.34357
Q Predictions Max            2888.0513
Q Predictions Min            256.75568
V Predictions Mean           2773.2783
V Predictions Std            240.68987
V Predictions Max            2886.035
V Predictions Min            181.03557
Log Pis Mean                 -5.476054
Log Pis Std                  4.332067
Log Pis Max                  27.455818
Log Pis Min                  -14.179142
Policy mu Mean               0.054156415
Policy mu Std                0.68372035
Policy mu Max                3.065942
Policy mu Min                -2.9612565
Policy log std Mean          -0.2619784
Policy log std Std           0.103092164
Policy log std Max           0.007361442
Policy log std Min           -1.5799423
Z mean eval                  0.25339413
Z variance eval              0.13204366
total_rewards                [5459.85900111 2691.59352983 1014.57115926 5495.53893175 5465.4538431
 5518.71116334 5367.93084509 3731.203005   5286.51459153 5409.13556046]
total_rewards_mean           4544.051163046199
total_rewards_std            1485.6287955289476
total_rewards_max            5518.711163340524
total_rewards_min            1014.5711592566879
Number of train steps total  1320000
Number of env steps total    1716425
Number of rollouts total     0
Train Time (s)               108.51508698397083
(Previous) Eval Time (s)     23.144944228988606
Sample Time (s)              7.9723208849318326
Epoch Time (s)               139.63235209789127
Total Train Time (s)         49619.017997947
Epoch                        329
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 10:05:32.782860 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #329 | Epoch Duration: 137.59352946281433
2020-01-06 10:05:32.782991 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #329 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.32082158
Z variance train             0.2484812
KL Divergence                1.9205167
KL Loss                      0.19205168
QF Loss                      1600.6873
VF Loss                      689.2432
Policy Loss                  -2773.7102
Q Predictions Mean           2774.814
Q Predictions Std            260.87946
Q Predictions Max            2916.2937
Q Predictions Min            345.51404
V Predictions Mean           2763.0425
V Predictions Std            267.67004
V Predictions Max            2898.163
V Predictions Min            347.1945
Log Pis Mean                 -5.4556146
Log Pis Std                  4.8175793
Log Pis Max                  30.035238
Log Pis Min                  -13.344081
Policy mu Mean               0.06997336
Policy mu Std                0.7094043
Policy mu Max                2.8781755
Policy mu Min                -3.7704182
Policy log std Mean          -0.27348804
Policy log std Std           0.11286572
Policy log std Max           -0.0439772
Policy log std Min           -1.6107343
Z mean eval                  0.16002606
Z variance eval              0.16218372
total_rewards                [5467.56469865 5465.09966276 5434.91843655 4550.82893279 5434.43235534
 5443.37417077 5511.35130446 1832.20992186 5290.18359539 5470.79370462]
total_rewards_mean           4990.075678319222
total_rewards_std            1086.8485501630887
total_rewards_max            5511.3513044622905
total_rewards_min            1832.209921863454
Number of train steps total  1324000
Number of env steps total    1721571
Number of rollouts total     0
Train Time (s)               124.57555741502438
(Previous) Eval Time (s)     21.10584100097185
Sample Time (s)              8.244607884029392
Epoch Time (s)               153.92600630002562
Total Train Time (s)         49774.63007616601
Epoch                        330
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 10:08:08.426257 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #330 | Epoch Duration: 155.64314818382263
2020-01-06 10:08:08.426479 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #330 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.21278086
Z variance train             0.14790827
KL Divergence                2.8261948
KL Loss                      0.28261948
QF Loss                      801.57056
VF Loss                      229.9885
Policy Loss                  -2805.0928
Q Predictions Mean           2802.8003
Q Predictions Std            70.74938
Q Predictions Max            2906.359
Q Predictions Min            2457.5999
V Predictions Mean           2797.1711
V Predictions Std            73.15488
V Predictions Max            2897.1543
V Predictions Min            2463.2356
Log Pis Mean                 -5.7478776
Log Pis Std                  4.042028
Log Pis Max                  20.771317
Log Pis Min                  -15.125299
Policy mu Mean               0.079732426
Policy mu Std                0.6970403
Policy mu Max                2.6379364
Policy mu Min                -2.3477972
Policy log std Mean          -0.25987664
Policy log std Std           0.10249369
Policy log std Max           -0.029426798
Policy log std Min           -1.0366018
Z mean eval                  0.21423332
Z variance eval              0.07434067
total_rewards                [2280.72996756 5426.98483927 5543.71239708 5496.24290197 5584.55408721
 5586.55100125 5563.3281495  5461.41238394 5523.2069798  5525.20470496]
total_rewards_mean           5199.192741253564
total_rewards_std            974.033846689527
total_rewards_max            5586.551001248852
total_rewards_min            2280.7299675553754
Number of train steps total  1328000
Number of env steps total    1726738
Number of rollouts total     0
Train Time (s)               118.78726511599962
(Previous) Eval Time (s)     22.822704958030954
Sample Time (s)              7.87789237202378
Epoch Time (s)               149.48786244605435
Total Train Time (s)         49925.15842596319
Epoch                        331
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 10:10:38.929350 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #331 | Epoch Duration: 150.5027093887329
2020-01-06 10:10:38.929500 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #331 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.21008046
Z variance train             0.049281612
KL Divergence                5.31419
KL Loss                      0.531419
QF Loss                      788.17706
VF Loss                      707.1481
Policy Loss                  -2793.7764
Q Predictions Mean           2792.2437
Q Predictions Std            195.21832
Q Predictions Max            2904.4805
Q Predictions Min            638.025
V Predictions Mean           2785.3608
V Predictions Std            188.7121
V Predictions Max            2901.7334
V Predictions Min            683.4557
Log Pis Mean                 -5.5273595
Log Pis Std                  3.9715266
Log Pis Max                  16.440039
Log Pis Min                  -13.739565
Policy mu Mean               0.058198646
Policy mu Std                0.70241445
Policy mu Max                2.6430402
Policy mu Min                -2.7041698
Policy log std Mean          -0.28012595
Policy log std Std           0.11352441
Policy log std Max           -0.066285335
Policy log std Min           -0.96685576
Z mean eval                  0.2510905
Z variance eval              0.06250493
total_rewards                [5511.54877707 5462.58431015 5529.33557373 5526.82134138 5566.72613813
 5524.26953444 5462.66437322 5531.12551887 3397.9292482  5437.85167405]
total_rewards_mean           5295.085648922697
total_rewards_std            633.4968311139427
total_rewards_max            5566.726138130969
total_rewards_min            3397.9292482011665
Number of train steps total  1332000
Number of env steps total    1731738
Number of rollouts total     0
Train Time (s)               117.46605434501544
(Previous) Eval Time (s)     23.837292687036097
Sample Time (s)              7.545024246035609
Epoch Time (s)               148.84837127808714
Total Train Time (s)         50074.16085256421
Epoch                        332
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 10:13:07.935477 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #332 | Epoch Duration: 149.00585222244263
2020-01-06 10:13:07.935656 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #332 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.20552304
Z variance train             0.05060131
KL Divergence                5.2457237
KL Loss                      0.5245724
QF Loss                      686.0486
VF Loss                      204.5487
Policy Loss                  -2795.465
Q Predictions Mean           2789.909
Q Predictions Std            198.03275
Q Predictions Max            2899.0144
Q Predictions Min            210.23045
V Predictions Mean           2799.5864
V Predictions Std            202.32959
V Predictions Max            2911.569
V Predictions Min            158.43965
Log Pis Mean                 -5.4497004
Log Pis Std                  3.8609087
Log Pis Max                  20.923655
Log Pis Min                  -17.022167
Policy mu Mean               0.06288793
Policy mu Std                0.7160136
Policy mu Max                2.584601
Policy mu Min                -2.7207139
Policy log std Mean          -0.27894616
Policy log std Std           0.10522697
Policy log std Max           -0.029248595
Policy log std Min           -1.0152537
Z mean eval                  0.17075135
Z variance eval              0.07540102
total_rewards                [5649.04750719 3827.6092081  2475.52278683 5573.8492201  1398.28657925
 5053.06281738 3008.1377715  4367.3104542  5048.61669227 4119.28658098]
total_rewards_mean           4052.0729617819716
total_rewards_std            1327.9073913699785
total_rewards_max            5649.0475071915425
total_rewards_min            1398.2865792515872
Number of train steps total  1336000
Number of env steps total    1736738
Number of rollouts total     0
Train Time (s)               116.58373502199538
(Previous) Eval Time (s)     23.99452464701608
Sample Time (s)              7.866347537143156
Epoch Time (s)               148.44460720615461
Total Train Time (s)         50216.47621148534
Epoch                        333
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 10:15:30.253805 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #333 | Epoch Duration: 142.31802678108215
2020-01-06 10:15:30.253942 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #333 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.20550866
Z variance train             0.0978769
KL Divergence                3.7187583
KL Loss                      0.37187585
QF Loss                      964.24316
VF Loss                      244.11223
Policy Loss                  -2796.6855
Q Predictions Mean           2791.878
Q Predictions Std            161.43044
Q Predictions Max            2896.3323
Q Predictions Min            856.64246
V Predictions Mean           2799.4456
V Predictions Std            151.17807
V Predictions Max            2902.6016
V Predictions Min            859.6876
Log Pis Mean                 -5.2800922
Log Pis Std                  4.251561
Log Pis Max                  19.75275
Log Pis Min                  -14.865628
Policy mu Mean               0.10197423
Policy mu Std                0.7105178
Policy mu Max                2.429678
Policy mu Min                -2.4573846
Policy log std Mean          -0.27180552
Policy log std Std           0.106599584
Policy log std Max           0.040070653
Policy log std Min           -0.9044745
Z mean eval                  0.21293244
Z variance eval              0.112738654
total_rewards                [5065.08894762  931.89412472 5434.5045739  5584.39065043  976.56054183
 5582.89108493 5590.70299741 5576.29093602 5340.51478932 5504.85176146]
total_rewards_mean           4558.769040762274
total_rewards_std            1808.7806675792094
total_rewards_max            5590.702997408772
total_rewards_min            931.8941247206974
Number of train steps total  1340000
Number of env steps total    1741909
Number of rollouts total     0
Train Time (s)               123.1040798080503
(Previous) Eval Time (s)     17.867694555025082
Sample Time (s)              8.151401936949696
Epoch Time (s)               149.12317630002508
Total Train Time (s)         50369.41892057541
Epoch                        334
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 10:18:03.200705 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #334 | Epoch Duration: 152.9466586112976
2020-01-06 10:18:03.200844 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #334 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.24427721
Z variance train             0.15336019
KL Divergence                2.8220186
KL Loss                      0.28220186
QF Loss                      632.3794
VF Loss                      216.88007
Policy Loss                  -2791.7603
Q Predictions Mean           2791.0427
Q Predictions Std            175.76306
Q Predictions Max            2903.6167
Q Predictions Min            760.77295
V Predictions Mean           2795.8704
V Predictions Std            177.70518
V Predictions Max            2910.6042
V Predictions Min            703.6497
Log Pis Mean                 -5.8019166
Log Pis Std                  3.8112082
Log Pis Max                  17.369835
Log Pis Min                  -16.392056
Policy mu Mean               0.053254846
Policy mu Std                0.6841117
Policy mu Max                2.3950696
Policy mu Min                -2.385953
Policy log std Mean          -0.26710004
Policy log std Std           0.107097335
Policy log std Max           -0.03817594
Policy log std Min           -1.1535585
Z mean eval                  0.2159311
Z variance eval              0.112631105
total_rewards                [5497.49126412 5519.41459799 4715.36158463 5583.57685395 5561.88245501
 5518.66217831 5476.79384656 5529.43268035 5402.77734359 5615.20785447]
total_rewards_mean           5442.060065897635
total_rewards_std            248.54838807316503
total_rewards_max            5615.207854471178
total_rewards_min            4715.361584632922
Number of train steps total  1344000
Number of env steps total    1747100
Number of rollouts total     0
Train Time (s)               112.03324600600172
(Previous) Eval Time (s)     21.690923825022765
Sample Time (s)              7.968163006007671
Epoch Time (s)               141.69233283703215
Total Train Time (s)         50513.77598337544
Epoch                        335
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 10:20:27.589341 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #335 | Epoch Duration: 144.38836240768433
2020-01-06 10:20:27.589531 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #335 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.29717964
Z variance train             0.1819255
KL Divergence                2.6043391
KL Loss                      0.2604339
QF Loss                      806.59265
VF Loss                      301.92838
Policy Loss                  -2777.5588
Q Predictions Mean           2776.6265
Q Predictions Std            233.02963
Q Predictions Max            2899.9128
Q Predictions Min            638.2301
V Predictions Mean           2781.583
V Predictions Std            222.86446
V Predictions Max            2905.722
V Predictions Min            717.8809
Log Pis Mean                 -5.1930666
Log Pis Std                  5.233738
Log Pis Max                  33.109566
Log Pis Min                  -13.599136
Policy mu Mean               0.06260586
Policy mu Std                0.7307881
Policy mu Max                3.1622822
Policy mu Min                -3.256744
Policy log std Mean          -0.27450725
Policy log std Std           0.11537759
Policy log std Max           -0.062014714
Policy log std Min           -1.1668782
Z mean eval                  0.20826383
Z variance eval              0.1748044
total_rewards                [5431.46778291 5442.54717563 5449.77057156 5529.47372883 5460.76577327
 5411.63196796 5481.94646283 5518.12571526 5434.63415385 5399.78888066]
total_rewards_mean           5456.015221275093
total_rewards_std            40.4478034751235
total_rewards_max            5529.473728829544
total_rewards_min            5399.788880661337
Number of train steps total  1348000
Number of env steps total    1752100
Number of rollouts total     0
Train Time (s)               109.9997170889983
(Previous) Eval Time (s)     24.386687026999425
Sample Time (s)              7.911374590941705
Epoch Time (s)               142.29777870693943
Total Train Time (s)         50656.28731669934
Epoch                        336
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 10:22:50.075758 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #336 | Epoch Duration: 142.48611879348755
2020-01-06 10:22:50.075909 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #336 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.20015094
Z variance train             0.07597549
KL Divergence                4.2933717
KL Loss                      0.42933717
QF Loss                      961.98444
VF Loss                      213.62224
Policy Loss                  -2801.0125
Q Predictions Mean           2798.705
Q Predictions Std            84.16947
Q Predictions Max            2892.8208
Q Predictions Min            2288.4968
V Predictions Mean           2805.3857
V Predictions Std            91.12095
V Predictions Max            2916.274
V Predictions Min            2213.6504
Log Pis Mean                 -5.307225
Log Pis Std                  4.9320245
Log Pis Max                  17.355852
Log Pis Min                  -16.596664
Policy mu Mean               0.09778326
Policy mu Std                0.7148405
Policy mu Max                2.8899555
Policy mu Min                -2.9917753
Policy log std Mean          -0.2880176
Policy log std Std           0.11256379
Policy log std Max           -0.041798666
Policy log std Min           -1.0025053
Z mean eval                  0.24687085
Z variance eval              0.09712182
total_rewards                [5438.60961514 5422.69958035 5447.66916308 1732.67698386 5440.73360609
 5488.69672361 4832.09253066 5441.15298616 5383.28604148 2000.01109757]
total_rewards_mean           4662.76283279971
total_rewards_std            1411.1092342789461
total_rewards_max            5488.696723611265
total_rewards_min            1732.6769838573384
Number of train steps total  1352000
Number of env steps total    1757100
Number of rollouts total     0
Train Time (s)               114.10267549997661
(Previous) Eval Time (s)     24.57476260099793
Sample Time (s)              8.017250904114917
Epoch Time (s)               146.69468900508946
Total Train Time (s)         50799.49950200133
Epoch                        337
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 10:25:13.354223 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #337 | Epoch Duration: 143.27818393707275
2020-01-06 10:25:13.354395 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #337 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.2328215
Z variance train             0.064662434
KL Divergence                4.7023277
KL Loss                      0.47023278
QF Loss                      700.5337
VF Loss                      168.14932
Policy Loss                  -2796.1172
Q Predictions Mean           2797.1611
Q Predictions Std            185.68542
Q Predictions Max            2906.1997
Q Predictions Min            851.2457
V Predictions Mean           2794.6353
V Predictions Std            189.42645
V Predictions Max            2903.2478
V Predictions Min            838.13666
Log Pis Mean                 -5.622882
Log Pis Std                  4.7141547
Log Pis Max                  22.364393
Log Pis Min                  -14.224422
Policy mu Mean               0.059129428
Policy mu Std                0.7056648
Policy mu Max                2.7764807
Policy mu Min                -2.6640556
Policy log std Mean          -0.26864406
Policy log std Std           0.10881253
Policy log std Max           -0.009596467
Policy log std Min           -0.9742675
Z mean eval                  0.20129737
Z variance eval              0.06553723
total_rewards                [5603.2795017  4290.63978508 5648.92102789 4215.8930468  5552.48563832
 2802.6633742  5673.67667539 5646.16365042 1301.10674033 3128.74417989]
total_rewards_mean           4386.357362001466
total_rewards_std            1460.3353539162495
total_rewards_max            5673.676675391001
total_rewards_min            1301.106740326208
Number of train steps total  1356000
Number of env steps total    1762100
Number of rollouts total     0
Train Time (s)               119.68770104902796
(Previous) Eval Time (s)     21.157992255990393
Sample Time (s)              7.76703905093018
Epoch Time (s)               148.61273235594854
Total Train Time (s)         50946.265054470336
Epoch                        338
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 10:27:40.059533 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #338 | Epoch Duration: 146.70502185821533
2020-01-06 10:27:40.059665 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #338 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.19410537
Z variance train             0.063912734
KL Divergence                4.699661
KL Loss                      0.46996608
QF Loss                      1349.3528
VF Loss                      681.9637
Policy Loss                  -2800.6694
Q Predictions Mean           2798.421
Q Predictions Std            168.36807
Q Predictions Max            2901.6802
Q Predictions Min            620.7266
V Predictions Mean           2795.0754
V Predictions Std            153.975
V Predictions Max            2896.7773
V Predictions Min            757.228
Log Pis Mean                 -5.689353
Log Pis Std                  3.9828181
Log Pis Max                  13.391774
Log Pis Min                  -16.00534
Policy mu Mean               0.08580936
Policy mu Std                0.6995505
Policy mu Max                2.9269137
Policy mu Min                -3.0857136
Policy log std Mean          -0.27377695
Policy log std Std           0.104749374
Policy log std Max           -0.018176079
Policy log std Min           -1.1465333
Z mean eval                  0.19103464
Z variance eval              0.044093102
total_rewards                [5551.31113907 5492.17943467  979.19255734 5472.99703276 5661.60692795
 5464.72783385 5523.36554213 5481.61952634  463.33793074 4867.57612995]
total_rewards_mean           4495.791405480935
total_rewards_std            1901.3927406386442
total_rewards_max            5661.606927948652
total_rewards_min            463.3379307438145
Number of train steps total  1360000
Number of env steps total    1767100
Number of rollouts total     0
Train Time (s)               115.15875478897942
(Previous) Eval Time (s)     19.25003629695857
Sample Time (s)              8.186419079022016
Epoch Time (s)               142.59521016496
Total Train Time (s)         51090.77091181232
Epoch                        339
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 10:30:04.568944 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #339 | Epoch Duration: 144.50917863845825
2020-01-06 10:30:04.569097 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #339 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.20260468
Z variance train             0.028262919
KL Divergence                6.6425233
KL Loss                      0.66425234
QF Loss                      1300.4006
VF Loss                      363.0492
Policy Loss                  -2796.6675
Q Predictions Mean           2795.1494
Q Predictions Std            103.7483
Q Predictions Max            2913.4312
Q Predictions Min            2175.3606
V Predictions Mean           2794.9568
V Predictions Std            106.40494
V Predictions Max            2904.874
V Predictions Min            2137.6914
Log Pis Mean                 -5.4740887
Log Pis Std                  4.2360673
Log Pis Max                  19.638464
Log Pis Min                  -13.519844
Policy mu Mean               0.056529794
Policy mu Std                0.7085306
Policy mu Max                2.319705
Policy mu Min                -2.4159913
Policy log std Mean          -0.27387106
Policy log std Std           0.108315885
Policy log std Max           -0.012037754
Policy log std Min           -0.89902616
Z mean eval                  0.20860028
Z variance eval              0.04393428
total_rewards                [5401.52971873 5256.12148589 5346.97231611 5491.8907258  5386.59688108
 5389.1380137  5362.59254718 5315.22409224 5307.1246611  5440.13014263]
total_rewards_mean           5369.732058446541
total_rewards_std            64.74401908941991
total_rewards_max            5491.890725796544
total_rewards_min            5256.121485889462
Number of train steps total  1364000
Number of env steps total    1772100
Number of rollouts total     0
Train Time (s)               123.64605790801579
(Previous) Eval Time (s)     21.16373787203338
Sample Time (s)              7.713644964969717
Epoch Time (s)               152.5234407450189
Total Train Time (s)         51247.57785213919
Epoch                        340
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 10:32:41.486236 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #340 | Epoch Duration: 156.91676568984985
2020-01-06 10:32:41.486560 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #340 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.20072451
Z variance train             0.030077195
KL Divergence                6.4880924
KL Loss                      0.64880925
QF Loss                      960.5802
VF Loss                      442.3641
Policy Loss                  -2800.411
Q Predictions Mean           2803.171
Q Predictions Std            94.65401
Q Predictions Max            2915.0906
Q Predictions Min            2266.1687
V Predictions Mean           2802.4458
V Predictions Std            106.33184
V Predictions Max            2917.8623
V Predictions Min            2134.305
Log Pis Mean                 -4.833926
Log Pis Std                  5.3587494
Log Pis Max                  27.439625
Log Pis Min                  -16.10569
Policy mu Mean               0.033486865
Policy mu Std                0.73921293
Policy mu Max                2.7924757
Policy mu Min                -3.777731
Policy log std Mean          -0.27285856
Policy log std Std           0.11457743
Policy log std Max           -0.044538483
Policy log std Min           -1.1250927
Z mean eval                  0.2531587
Z variance eval              0.052765645
total_rewards                [5329.81704222 5287.23472496 5362.87564693 5398.66369558 5317.82540218
 5266.16310488 5325.65039202 5373.01442827 5413.46750144 5334.73299625]
total_rewards_mean           5340.944493472834
total_rewards_std            44.16825703083263
total_rewards_max            5413.467501439357
total_rewards_min            5266.163104882538
Number of train steps total  1368000
Number of env steps total    1777100
Number of rollouts total     0
Train Time (s)               148.37087841000175
(Previous) Eval Time (s)     25.55679396900814
Sample Time (s)              7.434107564971782
Epoch Time (s)               181.36177994398167
Total Train Time (s)         51428.140171067265
Epoch                        341
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 10:35:42.124472 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #341 | Epoch Duration: 180.63778400421143
2020-01-06 10:35:42.124671 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #341 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.26436746
Z variance train             0.043121804
KL Divergence                5.7026653
KL Loss                      0.57026654
QF Loss                      1588.0852
VF Loss                      679.6164
Policy Loss                  -2772.3625
Q Predictions Mean           2779.3662
Q Predictions Std            252.69284
Q Predictions Max            2912.5417
Q Predictions Min            680.47784
V Predictions Mean           2786.4038
V Predictions Std            265.23245
V Predictions Max            2924.0745
V Predictions Min            683.80066
Log Pis Mean                 -4.88313
Log Pis Std                  4.726137
Log Pis Max                  19.155806
Log Pis Min                  -15.468037
Policy mu Mean               0.07237735
Policy mu Std                0.7345684
Policy mu Max                2.7118816
Policy mu Min                -3.1347427
Policy log std Mean          -0.28498447
Policy log std Std           0.11196023
Policy log std Max           0.026619345
Policy log std Min           -1.037995
Z mean eval                  0.2553448
Z variance eval              0.050554954
total_rewards                [5273.42057019 5392.62577179 2542.24375675 5393.36776123 5184.65567402
 5433.52775566 3022.78362615 5450.61385673 5378.1577369  1949.95266884]
total_rewards_mean           4502.134917825119
total_rewards_std            1331.3825452236092
total_rewards_max            5450.613856728766
total_rewards_min            1949.9526688417886
Number of train steps total  1372000
Number of env steps total    1782100
Number of rollouts total     0
Train Time (s)               113.67159666499356
(Previous) Eval Time (s)     24.832522192038596
Sample Time (s)              7.664494929078501
Epoch Time (s)               146.16861378611065
Total Train Time (s)         51569.098207516305
Epoch                        342
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 10:38:02.906916 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #342 | Epoch Duration: 140.78211545944214
2020-01-06 10:38:02.907039 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #342 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.2560243
Z variance train             0.03640686
KL Divergence                6.101009
KL Loss                      0.6101009
QF Loss                      684.82385
VF Loss                      445.30542
Policy Loss                  -2783.5215
Q Predictions Mean           2785.6375
Q Predictions Std            231.04877
Q Predictions Max            2903.0925
Q Predictions Min            669.70856
V Predictions Mean           2786.769
V Predictions Std            232.68123
V Predictions Max            2913.8418
V Predictions Min            631.41565
Log Pis Mean                 -5.6281166
Log Pis Std                  4.2642126
Log Pis Max                  20.44331
Log Pis Min                  -16.34325
Policy mu Mean               0.060286593
Policy mu Std                0.6899161
Policy mu Max                2.3416467
Policy mu Min                -2.6640885
Policy log std Mean          -0.27530104
Policy log std Std           0.106234975
Policy log std Max           -0.036884494
Policy log std Min           -1.0298457
Z mean eval                  0.24884434
Z variance eval              0.042747
total_rewards                [3118.97347376 5462.5676201  5373.08566168 5401.5185915  2410.64760272
 5501.98789229 5434.32441493 5511.23799013 5483.37259971 5435.49414804]
total_rewards_mean           4913.320999486099
total_rewards_std            1086.625560115819
total_rewards_max            5511.237990132677
total_rewards_min            2410.647602716849
Number of train steps total  1376000
Number of env steps total    1787100
Number of rollouts total     0
Train Time (s)               120.77410073200008
(Previous) Eval Time (s)     19.44578297197586
Sample Time (s)              7.741937438026071
Epoch Time (s)               147.961821142002
Total Train Time (s)         51720.27172470436
Epoch                        343
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 10:40:34.083961 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #343 | Epoch Duration: 151.17683362960815
2020-01-06 10:40:34.084101 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #343 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.2783134
Z variance train             0.06496464
KL Divergence                4.7542653
KL Loss                      0.47542652
QF Loss                      868.4741
VF Loss                      277.77017
Policy Loss                  -2786.0657
Q Predictions Mean           2785.212
Q Predictions Std            267.51956
Q Predictions Max            2906.3872
Q Predictions Min            186.10428
V Predictions Mean           2791.3782
V Predictions Std            264.392
V Predictions Max            2914.923
V Predictions Min            171.20842
Log Pis Mean                 -5.1950445
Log Pis Std                  5.1808176
Log Pis Max                  30.411812
Log Pis Min                  -14.031404
Policy mu Mean               0.067421325
Policy mu Std                0.7254146
Policy mu Max                2.4608846
Policy mu Min                -3.4831946
Policy log std Mean          -0.28058082
Policy log std Std           0.1105669
Policy log std Max           0.03936112
Policy log std Min           -1.2607213
Z mean eval                  0.23354492
Z variance eval              0.046025716
total_rewards                [5403.1582367  5239.72098603 5245.36412912 5484.13461482 5386.50137186
 5516.33396381 5443.19002815 5451.01625798 5465.96257143 5283.01890737]
total_rewards_mean           5391.84010672771
total_rewards_std            96.04366831767398
total_rewards_max            5516.33396380809
total_rewards_min            5239.720986026483
Number of train steps total  1380000
Number of env steps total    1792100
Number of rollouts total     0
Train Time (s)               119.58899101498537
(Previous) Eval Time (s)     22.66052034799941
Sample Time (s)              7.513313453120645
Epoch Time (s)               149.76282481610542
Total Train Time (s)         51873.023766530445
Epoch                        344
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 10:43:06.839656 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #344 | Epoch Duration: 152.7554576396942
2020-01-06 10:43:06.839794 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #344 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.23223431
Z variance train             0.037820064
KL Divergence                5.977579
KL Loss                      0.59775794
QF Loss                      711.90094
VF Loss                      206.91751
Policy Loss                  -2806.1064
Q Predictions Mean           2803.063
Q Predictions Std            227.62889
Q Predictions Max            2916.0615
Q Predictions Min            234.86662
V Predictions Mean           2811.7305
V Predictions Std            226.35106
V Predictions Max            2922.3772
V Predictions Min            216.4981
Log Pis Mean                 -5.648514
Log Pis Std                  4.4151297
Log Pis Max                  33.11792
Log Pis Min                  -16.4146
Policy mu Mean               0.08320452
Policy mu Std                0.69640505
Policy mu Max                2.9242673
Policy mu Min                -2.7286637
Policy log std Mean          -0.2757314
Policy log std Std           0.1150039
Policy log std Max           0.30507067
Policy log std Min           -1.3377757
Z mean eval                  0.226576
Z variance eval              0.060849346
total_rewards                [5346.70135703 5407.35071143 5222.8266654  5425.05747015 5372.43224911
 5470.27476317 5400.47994171 5369.34814373 5217.31943382 5418.92018093]
total_rewards_mean           5365.0710916485405
total_rewards_std            79.42368134820082
total_rewards_max            5470.274763166317
total_rewards_min            5217.319433815421
Number of train steps total  1384000
Number of env steps total    1797163
Number of rollouts total     0
Train Time (s)               126.6317214880255
(Previous) Eval Time (s)     25.652880818990525
Sample Time (s)              8.48330540797906
Epoch Time (s)               160.7679077149951
Total Train Time (s)         52033.88827763643
Epoch                        345
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 10:45:47.707213 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #345 | Epoch Duration: 160.86731576919556
2020-01-06 10:45:47.707355 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #345 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.2119631
Z variance train             0.041804362
KL Divergence                5.7120113
KL Loss                      0.57120115
QF Loss                      709.1796
VF Loss                      230.56134
Policy Loss                  -2828.7627
Q Predictions Mean           2821.5732
Q Predictions Std            78.1689
Q Predictions Max            2918.3542
Q Predictions Min            1990.4426
V Predictions Mean           2824.8696
V Predictions Std            75.86979
V Predictions Max            2914.5352
V Predictions Min            2140.7275
Log Pis Mean                 -5.953497
Log Pis Std                  4.1640124
Log Pis Max                  20.967234
Log Pis Min                  -14.798283
Policy mu Mean               0.04013363
Policy mu Std                0.68403655
Policy mu Max                3.2308118
Policy mu Min                -2.8712642
Policy log std Mean          -0.26484123
Policy log std Std           0.103024155
Policy log std Max           -0.034366027
Policy log std Min           -0.94945955
Z mean eval                  0.20871934
Z variance eval              0.029612953
total_rewards                [5354.13746654 5434.99580489 5337.39423485 5353.42582206 2477.74324454
 1166.54332704 5473.32293441 2759.67342528 5454.61062333 5508.85935256]
total_rewards_mean           4432.070623549398
total_rewards_std            1552.2183234201339
total_rewards_max            5508.8593525567585
total_rewards_min            1166.5433270443746
Number of train steps total  1388000
Number of env steps total    1802163
Number of rollouts total     0
Train Time (s)               120.01221008202992
(Previous) Eval Time (s)     25.752026592963375
Sample Time (s)              7.945717301976401
Epoch Time (s)               153.7099539769697
Total Train Time (s)         52182.22242455953
Epoch                        346
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 10:48:16.044943 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #346 | Epoch Duration: 148.33744168281555
2020-01-06 10:48:16.045114 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #346 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.2015728
Z variance train             0.031117594
KL Divergence                6.414804
KL Loss                      0.6414804
QF Loss                      1211.006
VF Loss                      307.86694
Policy Loss                  -2814.5261
Q Predictions Mean           2806.9731
Q Predictions Std            93.80521
Q Predictions Max            2908.329
Q Predictions Min            2136.2349
V Predictions Mean           2823.3562
V Predictions Std            91.91005
V Predictions Max            2930.7776
V Predictions Min            2231.2825
Log Pis Mean                 -5.5723095
Log Pis Std                  4.349062
Log Pis Max                  17.754723
Log Pis Min                  -14.601639
Policy mu Mean               0.041786246
Policy mu Std                0.7087812
Policy mu Max                2.5369673
Policy mu Min                -2.9031565
Policy log std Mean          -0.27330253
Policy log std Std           0.10214825
Policy log std Max           0.032625437
Policy log std Min           -0.84348494
Z mean eval                  0.19937913
Z variance eval              0.022711549
total_rewards                [5545.95199728 5472.71865718 5423.64145108 5571.92751468 5551.00900202
 5503.11158643 5581.72093226 5490.27949784 5482.6561417  3062.76933804]
total_rewards_mean           5268.578611851428
total_rewards_std            736.7550456122611
total_rewards_max            5581.720932256463
total_rewards_min            3062.7693380421624
Number of train steps total  1392000
Number of env steps total    1807565
Number of rollouts total     0
Train Time (s)               114.93934746802552
(Previous) Eval Time (s)     20.37923908600351
Sample Time (s)              8.629213315958623
Epoch Time (s)               143.94779986998765
Total Train Time (s)         52329.25290152058
Epoch                        347
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 10:50:43.078933 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #347 | Epoch Duration: 147.0336983203888
2020-01-06 10:50:43.079123 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #347 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.21640559
Z variance train             0.025923211
KL Divergence                6.876677
KL Loss                      0.6876677
QF Loss                      1813.1506
VF Loss                      194.7086
Policy Loss                  -2801.589
Q Predictions Mean           2798.521
Q Predictions Std            279.80685
Q Predictions Max            2923.4653
Q Predictions Min            62.680046
V Predictions Mean           2795.0703
V Predictions Std            291.29144
V Predictions Max            2929.3853
V Predictions Min            12.373837
Log Pis Mean                 -5.77017
Log Pis Std                  4.131956
Log Pis Max                  19.837626
Log Pis Min                  -16.180542
Policy mu Mean               0.073154785
Policy mu Std                0.6852715
Policy mu Max                2.4251926
Policy mu Min                -3.6302528
Policy log std Mean          -0.26657918
Policy log std Std           0.10777715
Policy log std Max           -0.043716535
Policy log std Min           -0.89810044
Z mean eval                  0.2249084
Z variance eval              0.028300617
total_rewards                [5533.68816361 4476.81670705 5525.88093308 5487.08551214 5530.87258576
 5581.8688616  5502.40187207 2836.7867278  5484.11588587 5390.64864274]
total_rewards_mean           5135.016589173158
total_rewards_std            826.3971806526068
total_rewards_max            5581.868861599664
total_rewards_min            2836.7867278029203
Number of train steps total  1396000
Number of env steps total    1812565
Number of rollouts total     0
Train Time (s)               117.18423839501338
(Previous) Eval Time (s)     23.464867706992663
Sample Time (s)              7.6656284491182305
Epoch Time (s)               148.31473455112427
Total Train Time (s)         52476.93643172871
Epoch                        348
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 10:53:10.766247 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #348 | Epoch Duration: 147.6869773864746
2020-01-06 10:53:10.766380 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #348 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.21348739
Z variance train             0.024130125
KL Divergence                7.0495853
KL Loss                      0.70495856
QF Loss                      1619.983
VF Loss                      256.53247
Policy Loss                  -2807.9568
Q Predictions Mean           2808.2495
Q Predictions Std            192.96587
Q Predictions Max            2924.7925
Q Predictions Min            491.2398
V Predictions Mean           2812.7505
V Predictions Std            193.64117
V Predictions Max            2924.9282
V Predictions Min            460.6089
Log Pis Mean                 -5.3121214
Log Pis Std                  4.160614
Log Pis Max                  23.524117
Log Pis Min                  -12.415368
Policy mu Mean               0.06394807
Policy mu Std                0.7065946
Policy mu Max                2.530503
Policy mu Min                -2.6392012
Policy log std Mean          -0.280795
Policy log std Std           0.11757304
Policy log std Max           0.13396338
Policy log std Min           -1.4185979
Z mean eval                  0.24038629
Z variance eval              0.037674177
total_rewards                [5492.83554615 5544.56754725 5441.01661623 5543.58321529 5382.53951625
 2759.96606866 5374.56843561 5449.3727085  5454.86091588 5527.57661543]
total_rewards_mean           5197.088718525856
total_rewards_std            814.4041259848174
total_rewards_max            5544.567547251006
total_rewards_min            2759.966068658124
Number of train steps total  1400000
Number of env steps total    1817670
Number of rollouts total     0
Train Time (s)               132.33215378201567
(Previous) Eval Time (s)     22.836871006991714
Sample Time (s)              7.714028558868449
Epoch Time (s)               162.88305334787583
Total Train Time (s)         52639.63010760269
Epoch                        349
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 10:55:53.463353 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #349 | Epoch Duration: 162.69686818122864
2020-01-06 10:55:53.463486 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #349 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.21271014
Z variance train             0.03127453
KL Divergence                6.4182806
KL Loss                      0.64182806
QF Loss                      715.11755
VF Loss                      315.25964
Policy Loss                  -2817.81
Q Predictions Mean           2813.7285
Q Predictions Std            190.12483
Q Predictions Max            2924.4614
Q Predictions Min            505.19574
V Predictions Mean           2814.8862
V Predictions Std            179.86324
V Predictions Max            2938.4644
V Predictions Min            682.25336
Log Pis Mean                 -5.647521
Log Pis Std                  4.2576904
Log Pis Max                  17.812523
Log Pis Min                  -14.001993
Policy mu Mean               0.07531573
Policy mu Std                0.6927194
Policy mu Max                3.1886742
Policy mu Min                -4.0598483
Policy log std Mean          -0.26430377
Policy log std Std           0.106247835
Policy log std Max           0.1253758
Policy log std Min           -1.3872449
Z mean eval                  0.27411348
Z variance eval              0.040290885
total_rewards                [5498.12500714 5461.51668763 5446.54429781 5484.35915436 5529.01962198
  948.51992646 5432.50824604 5527.52499671 2185.57586742 5534.22148552]
total_rewards_mean           4704.791529105399
total_rewards_std            1593.415379257356
total_rewards_max            5534.221485517664
total_rewards_min            948.5199264625035
Number of train steps total  1404000
Number of env steps total    1822670
Number of rollouts total     0
Train Time (s)               87.22222182102269
(Previous) Eval Time (s)     22.650430829031393
Sample Time (s)              6.71669681603089
Epoch Time (s)               116.58934946608497
Total Train Time (s)         52749.375687913795
Epoch                        350
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 10:57:43.211267 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #350 | Epoch Duration: 109.74767994880676
2020-01-06 10:57:43.211383 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #350 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.30291647
Z variance train             0.043972027
KL Divergence                5.7065496
KL Loss                      0.570655
QF Loss                      1629.0055
VF Loss                      278.11456
Policy Loss                  -2763.9158
Q Predictions Mean           2760.4038
Q Predictions Std            375.07166
Q Predictions Max            2908.7107
Q Predictions Min            270.34338
V Predictions Mean           2768.4412
V Predictions Std            374.6821
V Predictions Max            2922.6658
V Predictions Min            267.39044
Log Pis Mean                 -5.631952
Log Pis Std                  4.7877154
Log Pis Max                  19.526615
Log Pis Min                  -15.870913
Policy mu Mean               0.077917114
Policy mu Std                0.6919092
Policy mu Max                2.8670876
Policy mu Min                -3.0386884
Policy log std Mean          -0.2634611
Policy log std Std           0.10953892
Policy log std Max           0.08769517
Policy log std Min           -1.1066198
Z mean eval                  0.3129491
Z variance eval              0.03597597
total_rewards                [5420.97125099 5377.59392426 5405.21523006 5456.13269483 5400.56294785
 5576.59462346 2021.12376449 5319.56298392 5374.75403007 5381.05886834]
total_rewards_mean           5073.357031826331
total_rewards_std            1019.4420262536656
total_rewards_max            5576.594623459164
total_rewards_min            2021.123764492669
Number of train steps total  1408000
Number of env steps total    1827670
Number of rollouts total     0
Train Time (s)               86.07503561902558
(Previous) Eval Time (s)     15.808537425007671
Sample Time (s)              5.920792043907568
Epoch Time (s)               107.80436508794082
Total Train Time (s)         52858.98728667182
Epoch                        351
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 10:59:32.825490 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #351 | Epoch Duration: 109.61402130126953
2020-01-06 10:59:32.825593 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #351 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.3035195
Z variance train             0.03434577
KL Divergence                6.3267455
KL Loss                      0.6326746
QF Loss                      663.59515
VF Loss                      191.95236
Policy Loss                  -2802.9133
Q Predictions Mean           2797.9683
Q Predictions Std            227.09834
Q Predictions Max            2926.5781
Q Predictions Min            345.45215
V Predictions Mean           2806.4316
V Predictions Std            229.30592
V Predictions Max            2934.587
V Predictions Min            354.07184
Log Pis Mean                 -5.2135267
Log Pis Std                  3.9755995
Log Pis Max                  8.684526
Log Pis Min                  -15.355799
Policy mu Mean               0.06857347
Policy mu Std                0.7198539
Policy mu Max                2.4668286
Policy mu Min                -2.9573839
Policy log std Mean          -0.27613997
Policy log std Std           0.107950956
Policy log std Max           -0.000221923
Policy log std Min           -0.8521471
Z mean eval                  0.23276946
Z variance eval              0.024407238
total_rewards                [5537.50700518 5559.32987499 5565.12147414 5487.79672883 5484.117364
 2174.85295205 5672.30818569 5488.5683549  5629.80179198 5598.60185987]
total_rewards_mean           5219.80055916163
total_rewards_std            1016.732316944901
total_rewards_max            5672.308185689756
total_rewards_min            2174.85295205213
Number of train steps total  1412000
Number of env steps total    1832866
Number of rollouts total     0
Train Time (s)               86.3751385800424
(Previous) Eval Time (s)     17.617982597032096
Sample Time (s)              6.232258646865375
Epoch Time (s)               110.22537982393987
Total Train Time (s)         52969.10880512459
Epoch                        352
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 11:01:22.949677 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #352 | Epoch Duration: 110.12399673461914
2020-01-06 11:01:22.949793 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #352 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.30173165
Z variance train             0.037274636
KL Divergence                6.1200066
KL Loss                      0.61200064
QF Loss                      782.9563
VF Loss                      305.6075
Policy Loss                  -2827.7275
Q Predictions Mean           2826.1147
Q Predictions Std            94.974106
Q Predictions Max            2915.6802
Q Predictions Min            1843.3934
V Predictions Mean           2832.21
V Predictions Std            98.34569
V Predictions Max            2926.8452
V Predictions Min            1791.0797
Log Pis Mean                 -5.3475847
Log Pis Std                  4.2132134
Log Pis Max                  25.210901
Log Pis Min                  -17.418139
Policy mu Mean               0.0683949
Policy mu Std                0.699797
Policy mu Max                2.7433863
Policy mu Min                -3.0171478
Policy log std Mean          -0.27731055
Policy log std Std           0.106299855
Policy log std Max           -0.08073477
Policy log std Min           -1.064059
Z mean eval                  0.3518297
Z variance eval              0.05007995
total_rewards                [3284.78093564 2118.76139063 5405.24159995 3596.53249144 5372.24996432
 5358.56011772 5408.65094551 5396.13043652 5364.51065643 4160.78315625]
total_rewards_mean           4546.620169440595
total_rewards_std            1129.1645007989487
total_rewards_max            5408.650945512551
total_rewards_min            2118.7613906305805
Number of train steps total  1416000
Number of env steps total    1837963
Number of rollouts total     0
Train Time (s)               87.83901942102239
(Previous) Eval Time (s)     17.516374361002818
Sample Time (s)              6.109953492996283
Epoch Time (s)               111.46534727502149
Total Train Time (s)         53079.41159874271
Epoch                        353
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 11:03:13.255077 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #353 | Epoch Duration: 110.3051962852478
2020-01-06 11:03:13.255180 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #353 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.33543083
Z variance train             0.04875049
KL Divergence                5.543785
KL Loss                      0.5543785
QF Loss                      703.87537
VF Loss                      228.02014
Policy Loss                  -2831.4243
Q Predictions Mean           2835.3496
Q Predictions Std            62.44345
Q Predictions Max            2932.1218
Q Predictions Min            2447.3635
V Predictions Mean           2831.4043
V Predictions Std            70.02866
V Predictions Max            2932.8733
V Predictions Min            2281.4978
Log Pis Mean                 -5.6330986
Log Pis Std                  4.2930436
Log Pis Max                  21.647331
Log Pis Min                  -14.308573
Policy mu Mean               0.04030816
Policy mu Std                0.6874825
Policy mu Max                2.161168
Policy mu Min                -2.7383764
Policy log std Mean          -0.27393875
Policy log std Std           0.102429725
Policy log std Max           0.049300164
Policy log std Min           -1.2970107
Z mean eval                  0.2975884
Z variance eval              0.035775173
total_rewards                [ 612.59526038 5308.71620182 5374.67962336 1393.97129532 5275.93069918
 4683.36571858 4295.71027649 5409.92959922 3218.35255399 5273.905818  ]
total_rewards_mean           4084.715704634598
total_rewards_std            1679.3080062064528
total_rewards_max            5409.929599219083
total_rewards_min            612.5952603849834
Number of train steps total  1420000
Number of env steps total    1843146
Number of rollouts total     0
Train Time (s)               87.02507864899235
(Previous) Eval Time (s)     16.356005996989552
Sample Time (s)              6.235862949921284
Epoch Time (s)               109.61694759590318
Total Train Time (s)         53187.79897845158
Epoch                        354
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 11:05:01.645144 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #354 | Epoch Duration: 108.38988089561462
2020-01-06 11:05:01.645248 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #354 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.2760452
Z variance train             0.031177323
KL Divergence                6.5108547
KL Loss                      0.6510855
QF Loss                      660.49963
VF Loss                      368.38147
Policy Loss                  -2824.276
Q Predictions Mean           2812.975
Q Predictions Std            141.03714
Q Predictions Max            2916.9604
Q Predictions Min            964.694
V Predictions Mean           2826.397
V Predictions Std            143.20839
V Predictions Max            2935.6943
V Predictions Min            949.03796
Log Pis Mean                 -5.9384813
Log Pis Std                  4.8662724
Log Pis Max                  30.836096
Log Pis Min                  -15.297373
Policy mu Mean               0.037760697
Policy mu Std                0.6899366
Policy mu Max                2.7080026
Policy mu Min                -2.3586807
Policy log std Mean          -0.2681331
Policy log std Std           0.11409639
Policy log std Max           -0.029940411
Policy log std Min           -1.0247833
Z mean eval                  0.33825842
Z variance eval              0.045922328
total_rewards                [2157.93519586 5402.52948771 5432.56038649 5405.97866174 5413.20227172
 1640.85277802 3703.63563258 4993.18377769 3879.82386354 1313.71559453]
total_rewards_mean           3934.3417649874004
total_rewards_std            1587.8827182040957
total_rewards_max            5432.560386486786
total_rewards_min            1313.7155945252698
Number of train steps total  1424000
Number of env steps total    1848146
Number of rollouts total     0
Train Time (s)               86.54878740699496
(Previous) Eval Time (s)     15.128725119982846
Sample Time (s)              5.890375199960545
Epoch Time (s)               107.56788772693835
Total Train Time (s)         53294.027447709406
Epoch                        355
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 11:06:47.876314 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #355 | Epoch Duration: 106.23097252845764
2020-01-06 11:06:47.876424 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #355 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.2546826
Z variance train             0.031090152
KL Divergence                6.483078
KL Loss                      0.6483078
QF Loss                      671.3235
VF Loss                      883.4467
Policy Loss                  -2803.8457
Q Predictions Mean           2800.27
Q Predictions Std            242.86523
Q Predictions Max            2941.2546
Q Predictions Min            201.18184
V Predictions Mean           2799.2637
V Predictions Std            238.96881
V Predictions Max            2932.452
V Predictions Min            154.34932
Log Pis Mean                 -6.016577
Log Pis Std                  4.6649976
Log Pis Max                  36.577187
Log Pis Min                  -15.687796
Policy mu Mean               0.059626438
Policy mu Std                0.6915817
Policy mu Max                2.6974227
Policy mu Min                -2.8008285
Policy log std Mean          -0.26276135
Policy log std Std           0.10570677
Policy log std Max           -0.012900606
Policy log std Min           -0.9824201
Z mean eval                  0.29265514
Z variance eval              0.04896707
total_rewards                [5391.25346789  929.90200337 5272.43696255 4312.51290801 5460.45011871
 1410.29148511 1145.18606369 2458.73060465 5488.26823466 5419.40752582]
total_rewards_mean           3728.843937445282
total_rewards_std            1895.711758772366
total_rewards_max            5488.26823465785
total_rewards_min            929.9020033739159
Number of train steps total  1428000
Number of env steps total    1853146
Number of rollouts total     0
Train Time (s)               103.26300174195785
(Previous) Eval Time (s)     13.791586982028093
Sample Time (s)              6.429523407074157
Epoch Time (s)               123.4841121310601
Total Train Time (s)         53417.36124741251
Epoch                        356
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 11:08:51.212784 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #356 | Epoch Duration: 123.33627486228943
2020-01-06 11:08:51.212892 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #356 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.28337157
Z variance train             0.036866557
KL Divergence                6.1179285
KL Loss                      0.61179286
QF Loss                      1319.0397
VF Loss                      769.01044
Policy Loss                  -2806.591
Q Predictions Mean           2801.5156
Q Predictions Std            277.9728
Q Predictions Max            2929.4236
Q Predictions Min            309.56775
V Predictions Mean           2813.4062
V Predictions Std            277.22055
V Predictions Max            2945.1072
V Predictions Min            426.15866
Log Pis Mean                 -5.3064537
Log Pis Std                  5.0265527
Log Pis Max                  31.581945
Log Pis Min                  -13.507734
Policy mu Mean               0.086528815
Policy mu Std                0.7207291
Policy mu Max                2.6298542
Policy mu Min                -2.6247272
Policy log std Mean          -0.27390793
Policy log std Std           0.1150874
Policy log std Max           -0.021423206
Policy log std Min           -1.3797705
Z mean eval                  0.29522365
Z variance eval              0.040838618
total_rewards                [5288.22274769 5265.91293221 5410.80898948 5346.99194305 5365.36016417
 5422.65392494 5425.87194171 5226.52974145 5340.64589069 5273.2053534 ]
total_rewards_mean           5336.620362880585
total_rewards_std            67.30869143793744
total_rewards_max            5425.871941711562
total_rewards_min            5226.529741453799
Number of train steps total  1432000
Number of env steps total    1858598
Number of rollouts total     0
Train Time (s)               86.26131849002559
(Previous) Eval Time (s)     13.643510476977099
Sample Time (s)              6.701417773088906
Epoch Time (s)               106.60624674009159
Total Train Time (s)         53529.97825540556
Epoch                        357
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 11:10:43.832543 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #357 | Epoch Duration: 112.61956214904785
2020-01-06 11:10:43.832654 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #357 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.2819418
Z variance train             0.0448182
KL Divergence                5.642048
KL Loss                      0.5642048
QF Loss                      1173.0522
VF Loss                      515.99774
Policy Loss                  -2810.7888
Q Predictions Mean           2803.272
Q Predictions Std            240.78111
Q Predictions Max            2930.117
Q Predictions Min            171.87024
V Predictions Mean           2804.5205
V Predictions Std            241.70172
V Predictions Max            2945.381
V Predictions Min            164.72008
Log Pis Mean                 -4.723094
Log Pis Std                  4.843403
Log Pis Max                  33.799236
Log Pis Min                  -14.227629
Policy mu Mean               0.09401372
Policy mu Std                0.7541446
Policy mu Max                3.3990521
Policy mu Min                -2.773001
Policy log std Mean          -0.2885708
Policy log std Std           0.1138313
Policy log std Max           -0.0078029037
Policy log std Min           -0.9736707
Z mean eval                  0.355804
Z variance eval              0.054105323
total_rewards                [5441.79629532 5397.89592113 5459.21594855 5293.25813644 5439.88716542
 5331.32063756 5389.3390115  5390.5246501  5280.9441383  5390.82258905]
total_rewards_mean           5381.500449338087
total_rewards_std            58.308816229861485
total_rewards_max            5459.215948547596
total_rewards_min            5280.944138299884
Number of train steps total  1436000
Number of env steps total    1863598
Number of rollouts total     0
Train Time (s)               91.19926885899622
(Previous) Eval Time (s)     19.65658616402652
Sample Time (s)              6.270104818046093
Epoch Time (s)               117.12595984106883
Total Train Time (s)         53647.59105533664
Epoch                        358
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 11:12:41.577263 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #358 | Epoch Duration: 117.74448227882385
2020-01-06 11:12:41.577587 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #358 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.27403122
Z variance train             0.03801178
KL Divergence                6.032627
KL Loss                      0.6032627
QF Loss                      1090.6099
VF Loss                      242.09961
Policy Loss                  -2818.7112
Q Predictions Mean           2818.9338
Q Predictions Std            204.05128
Q Predictions Max            2925.3696
Q Predictions Min            101.544266
V Predictions Mean           2822.5513
V Predictions Std            209.10522
V Predictions Max            2935.791
V Predictions Min            52.953796
Log Pis Mean                 -5.20074
Log Pis Std                  4.1134105
Log Pis Max                  16.596909
Log Pis Min                  -14.261321
Policy mu Mean               0.059515085
Policy mu Std                0.7076202
Policy mu Max                2.3005452
Policy mu Min                -2.6141837
Policy log std Mean          -0.27902865
Policy log std Std           0.11031121
Policy log std Max           -0.08504453
Policy log std Min           -0.8275074
Z mean eval                  0.22656146
Z variance eval              0.027165258
total_rewards                [5462.48005277 5428.88645244 5505.58837933 5547.81318574 5436.69191288
 5473.07604958 5477.40529475 5495.4526113  5444.94335247 5348.7101636 ]
total_rewards_mean           5462.104745486699
total_rewards_std            50.601948715266786
total_rewards_max            5547.813185737194
total_rewards_min            5348.710163603328
Number of train steps total  1440000
Number of env steps total    1868760
Number of rollouts total     0
Train Time (s)               87.18644702900201
(Previous) Eval Time (s)     20.274839557998348
Sample Time (s)              6.235691585112363
Epoch Time (s)               113.69697817211272
Total Train Time (s)         53759.734294775815
Epoch                        359
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 11:14:33.594589 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #359 | Epoch Duration: 112.01676678657532
2020-01-06 11:14:33.594710 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #359 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.25111055
Z variance train             0.037014086
KL Divergence                6.059227
KL Loss                      0.6059227
QF Loss                      1005.3777
VF Loss                      348.6604
Policy Loss                  -2839.1604
Q Predictions Mean           2827.923
Q Predictions Std            76.837746
Q Predictions Max            2929.9382
Q Predictions Min            2312.442
V Predictions Mean           2829.6587
V Predictions Std            77.239944
V Predictions Max            2942.1853
V Predictions Min            2445.9895
Log Pis Mean                 -5.0149317
Log Pis Std                  3.9981148
Log Pis Max                  20.075184
Log Pis Min                  -13.916458
Policy mu Mean               0.10623134
Policy mu Std                0.7116004
Policy mu Max                2.275916
Policy mu Min                -1.9916732
Policy log std Mean          -0.2852713
Policy log std Std           0.10637365
Policy log std Max           -0.07515189
Policy log std Min           -0.81647897
Z mean eval                  0.3335333
Z variance eval              0.052217446
total_rewards                [3165.76214536 5399.90701861 5329.12279928 5322.12713731 5318.2166021
 5350.35680431 5339.77137087 5409.47702894 5318.11623698 5319.79154901]
total_rewards_mean           5127.264869276349
total_rewards_std            654.6045114366005
total_rewards_max            5409.477028938271
total_rewards_min            3165.7621453575634
Number of train steps total  1444000
Number of env steps total    1873760
Number of rollouts total     0
Train Time (s)               87.3228803910315
(Previous) Eval Time (s)     18.594432685989887
Sample Time (s)              5.98259931494249
Epoch Time (s)               111.89991239196388
Total Train Time (s)         53872.47018258774
Epoch                        360
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 11:16:26.796446 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #360 | Epoch Duration: 113.20160484313965
2020-01-06 11:16:26.796860 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #360 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.25977418
Z variance train             0.034917057
KL Divergence                6.215701
KL Loss                      0.6215701
QF Loss                      887.99084
VF Loss                      190.23148
Policy Loss                  -2845.38
Q Predictions Mean           2842.7102
Q Predictions Std            79.891754
Q Predictions Max            2947.8691
Q Predictions Min            2164.4644
V Predictions Mean           2840.883
V Predictions Std            85.70006
V Predictions Max            2943.3599
V Predictions Min            2138.5022
Log Pis Mean                 -5.5287876
Log Pis Std                  4.169443
Log Pis Max                  21.705357
Log Pis Min                  -13.073803
Policy mu Mean               0.06258401
Policy mu Std                0.6995885
Policy mu Max                2.3986163
Policy mu Min                -3.138481
Policy log std Mean          -0.2779213
Policy log std Std           0.11094973
Policy log std Max           -0.0634778
Policy log std Min           -1.0196512
Z mean eval                  0.21990702
Z variance eval              0.033358656
total_rewards                [1222.65133914 5354.35417969 5495.22412146 5351.40308746 5560.41408054
 5537.08510296 5552.69155127 5548.43883067 5544.46851584 5520.74817737]
total_rewards_mean           5068.747898640409
total_rewards_std            1284.204041238881
total_rewards_max            5560.414080538837
total_rewards_min            1222.6513391400586
Number of train steps total  1448000
Number of env steps total    1878760
Number of rollouts total     0
Train Time (s)               86.24249262898229
(Previous) Eval Time (s)     19.895869939005934
Sample Time (s)              6.538124045939185
Epoch Time (s)               112.67648661392741
Total Train Time (s)         53983.531902890536
Epoch                        361
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 11:18:17.399595 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #361 | Epoch Duration: 110.60244536399841
2020-01-06 11:18:17.399699 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #361 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.2349546
Z variance train             0.034409158
KL Divergence                6.2086916
KL Loss                      0.62086916
QF Loss                      1907.2029
VF Loss                      459.92227
Policy Loss                  -2771.3184
Q Predictions Mean           2769.8228
Q Predictions Std            391.42465
Q Predictions Max            2941.6672
Q Predictions Min            62.754105
V Predictions Mean           2772.225
V Predictions Std            386.66592
V Predictions Max            2940.8577
V Predictions Min            67.23452
Log Pis Mean                 -5.3230977
Log Pis Std                  4.1717706
Log Pis Max                  15.658447
Log Pis Min                  -17.273628
Policy mu Mean               0.05547628
Policy mu Std                0.7122263
Policy mu Max                2.5303462
Policy mu Min                -2.3174763
Policy log std Mean          -0.27276397
Policy log std Std           0.10648502
Policy log std Max           0.027262762
Policy log std Min           -1.0177431
Z mean eval                  0.27481782
Z variance eval              0.05609393
total_rewards                [4250.0272693  4431.28002175 5304.66038561 5309.62573689 5412.08181281
 5348.23268724 5446.89149177 5399.4833149  3285.65486031 4333.54626446]
total_rewards_mean           4852.148384503086
total_rewards_std            699.2497940434537
total_rewards_max            5446.891491766452
total_rewards_min            3285.6548603096917
Number of train steps total  1452000
Number of env steps total    1883938
Number of rollouts total     0
Train Time (s)               87.40564098500181
(Previous) Eval Time (s)     17.82163051702082
Sample Time (s)              6.1115518140723
Epoch Time (s)               111.33882331609493
Total Train Time (s)         54095.29745528969
Epoch                        362
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 11:20:09.185132 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #362 | Epoch Duration: 111.7853331565857
2020-01-06 11:20:09.185327 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #362 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.30764598
Z variance train             0.057891525
KL Divergence                5.1008606
KL Loss                      0.51008606
QF Loss                      874.2014
VF Loss                      480.17642
Policy Loss                  -2824.0066
Q Predictions Mean           2825.9995
Q Predictions Std            169.77235
Q Predictions Max            2950.2253
Q Predictions Min            1068.1215
V Predictions Mean           2831.581
V Predictions Std            175.9555
V Predictions Max            2956.7444
V Predictions Min            1075.2113
Log Pis Mean                 -5.163848
Log Pis Std                  5.043034
Log Pis Max                  27.098862
Log Pis Min                  -13.707567
Policy mu Mean               0.058933694
Policy mu Std                0.73460525
Policy mu Max                3.892787
Policy mu Min                -3.0575442
Policy log std Mean          -0.2910453
Policy log std Std           0.11733894
Policy log std Max           -0.043398365
Policy log std Min           -1.4384183
Z mean eval                  0.28882647
Z variance eval              0.05624036
total_rewards                [5367.53878638 5342.54912514 5305.67815059 5275.23034239 5438.84631207
 5298.80114806 5178.73930319 5270.7981995  5337.01997803 5374.15639976]
total_rewards_mean           5318.935774510368
total_rewards_std            67.18507665114093
total_rewards_max            5438.846312066894
total_rewards_min            5178.739303194038
Number of train steps total  1456000
Number of env steps total    1888938
Number of rollouts total     0
Train Time (s)               92.06779463699786
(Previous) Eval Time (s)     18.267910659022164
Sample Time (s)              6.484323888958897
Epoch Time (s)               116.82002918497892
Total Train Time (s)         54218.46316615364
Epoch                        363
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 11:22:12.543697 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #363 | Epoch Duration: 123.35822057723999
2020-01-06 11:22:12.543895 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #363 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.2744651
Z variance train             0.051212072
KL Divergence                5.331287
KL Loss                      0.5331287
QF Loss                      984.24335
VF Loss                      312.7585
Policy Loss                  -2823.5193
Q Predictions Mean           2818.2551
Q Predictions Std            190.38672
Q Predictions Max            2944.8235
Q Predictions Min            146.68968
V Predictions Mean           2827.5059
V Predictions Std            194.1115
V Predictions Max            2957.7842
V Predictions Min            88.98879
Log Pis Mean                 -4.9657393
Log Pis Std                  4.128421
Log Pis Max                  9.272634
Log Pis Min                  -17.17447
Policy mu Mean               0.048863083
Policy mu Std                0.73559123
Policy mu Max                2.2200294
Policy mu Min                -3.0019453
Policy log std Mean          -0.29179534
Policy log std Std           0.11473213
Policy log std Max           0.007998452
Policy log std Min           -0.9686129
Z mean eval                  0.24484298
Z variance eval              0.060441006
total_rewards                [5465.96536933 5395.68753939 5370.8883886  5315.69491758 5373.15682218
 5465.49192461 5358.44404419 5315.05327567 5274.16830337 5358.86666211]
total_rewards_mean           5369.341724702232
total_rewards_std            58.65468510762662
total_rewards_max            5465.965369328356
total_rewards_min            5274.168303365791
Number of train steps total  1460000
Number of env steps total    1893938
Number of rollouts total     0
Train Time (s)               111.49799012503354
(Previous) Eval Time (s)     24.805842771020252
Sample Time (s)              7.453238803951535
Epoch Time (s)               143.75707170000533
Total Train Time (s)         54360.90851650457
Epoch                        364
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 11:24:35.003380 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #364 | Epoch Duration: 142.45933175086975
2020-01-06 11:24:35.003673 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #364 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.24283028
Z variance train             0.048373744
KL Divergence                5.4108505
KL Loss                      0.54108506
QF Loss                      1081.758
VF Loss                      604.9397
Policy Loss                  -2810.4326
Q Predictions Mean           2804.8228
Q Predictions Std            228.55206
Q Predictions Max            2939.4314
Q Predictions Min            442.04132
V Predictions Mean           2818.4106
V Predictions Std            226.82706
V Predictions Max            2945.6262
V Predictions Min            406.0579
Log Pis Mean                 -5.049599
Log Pis Std                  4.731215
Log Pis Max                  17.293285
Log Pis Min                  -13.134451
Policy mu Mean               0.07074261
Policy mu Std                0.72883093
Policy mu Max                2.5540178
Policy mu Min                -2.4401472
Policy log std Mean          -0.28474408
Policy log std Std           0.10846215
Policy log std Max           -0.041704968
Policy log std Min           -1.0295656
Z mean eval                  0.26027298
Z variance eval              0.05751556
total_rewards                [5365.62814622 5517.4097233  5333.23380544 5491.12383924 5465.35510931
 5491.28121715 5501.60321929 2826.79562701 5481.6722356  5472.72578234]
total_rewards_mean           5194.682870491513
total_rewards_std            791.3560142756611
total_rewards_max            5517.409723303521
total_rewards_min            2826.7956270141804
Number of train steps total  1464000
Number of env steps total    1899065
Number of rollouts total     0
Train Time (s)               97.22841010097181
(Previous) Eval Time (s)     23.507835762982722
Sample Time (s)              7.5744268879061565
Epoch Time (s)               128.3106727518607
Total Train Time (s)         54488.5196891994
Epoch                        365
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 11:26:42.402775 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #365 | Epoch Duration: 127.3988893032074
2020-01-06 11:26:42.402891 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #365 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.23562653
Z variance train             0.048444293
KL Divergence                5.398852
KL Loss                      0.5398852
QF Loss                      1146.3921
VF Loss                      325.7099
Policy Loss                  -2799.0364
Q Predictions Mean           2798.3452
Q Predictions Std            287.7082
Q Predictions Max            2932.7493
Q Predictions Min            195.6639
V Predictions Mean           2795.1416
V Predictions Std            282.97052
V Predictions Max            2926.3816
V Predictions Min            162.43419
Log Pis Mean                 -5.1267614
Log Pis Std                  4.910658
Log Pis Max                  19.134432
Log Pis Min                  -17.346298
Policy mu Mean               0.06787202
Policy mu Std                0.7254397
Policy mu Max                2.6056914
Policy mu Min                -2.8383927
Policy log std Mean          -0.2865961
Policy log std Std           0.11072477
Policy log std Max           0.27262518
Policy log std Min           -1.1656748
Z mean eval                  0.31158066
Z variance eval              0.06384587
total_rewards                [5464.86562083 5447.63974158 4900.73701788 3288.42349389 5431.35610651
 5473.04384004 5370.31107072 5494.14239462 4891.00092328 5454.64613739]
total_rewards_mean           5121.616634674652
total_rewards_std            649.4345287036637
total_rewards_max            5494.142394620713
total_rewards_min            3288.4234938872937
Number of train steps total  1468000
Number of env steps total    1904065
Number of rollouts total     0
Train Time (s)               123.74331293604337
(Previous) Eval Time (s)     22.59582413797034
Sample Time (s)              7.562547177949455
Epoch Time (s)               153.90168425196316
Total Train Time (s)         54643.710756164335
Epoch                        366
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 11:29:17.731290 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #366 | Epoch Duration: 155.32826614379883
2020-01-06 11:29:17.731530 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #366 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.2324932
Z variance train             0.035801135
KL Divergence                6.1132946
KL Loss                      0.6113295
QF Loss                      1323.4847
VF Loss                      287.4848
Policy Loss                  -2823.8428
Q Predictions Mean           2820.8662
Q Predictions Std            222.14659
Q Predictions Max            2948.914
Q Predictions Min            579.98706
V Predictions Mean           2820.108
V Predictions Std            212.9604
V Predictions Max            2948.8655
V Predictions Min            657.01935
Log Pis Mean                 -5.4103327
Log Pis Std                  4.478177
Log Pis Max                  16.108225
Log Pis Min                  -15.125279
Policy mu Mean               0.08144206
Policy mu Std                0.72288907
Policy mu Max                2.6856115
Policy mu Min                -3.052938
Policy log std Mean          -0.28790042
Policy log std Std           0.1146961
Policy log std Max           -0.07668767
Policy log std Min           -0.93779194
Z mean eval                  0.24045002
Z variance eval              0.043725364
total_rewards                [5439.37221687 5284.55081138 5335.57860688 5420.83494764 5361.59444588
 5425.2107139  5316.56238392 5379.72495339 5439.82419378 5353.88028417]
total_rewards_mean           5375.713355779801
total_rewards_std            51.73099771630011
total_rewards_max            5439.824193778302
total_rewards_min            5284.550811379391
Number of train steps total  1472000
Number of env steps total    1909065
Number of rollouts total     0
Train Time (s)               110.75600026600296
(Previous) Eval Time (s)     24.022130678989924
Sample Time (s)              7.497395623999182
Epoch Time (s)               142.27552656899206
Total Train Time (s)         54788.0615618513
Epoch                        367
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 11:31:42.168466 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #367 | Epoch Duration: 144.43679213523865
2020-01-06 11:31:42.168687 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #367 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.21879998
Z variance train             0.045854524
KL Divergence                5.508317
KL Loss                      0.55083174
QF Loss                      1320.7051
VF Loss                      693.6294
Policy Loss                  -2811.2708
Q Predictions Mean           2804.6687
Q Predictions Std            239.4174
Q Predictions Max            2950.6692
Q Predictions Min            617.7739
V Predictions Mean           2808.957
V Predictions Std            236.4105
V Predictions Max            2947.2512
V Predictions Min            708.5658
Log Pis Mean                 -5.4702516
Log Pis Std                  4.63892
Log Pis Max                  20.054207
Log Pis Min                  -15.530479
Policy mu Mean               0.036291208
Policy mu Std                0.7227012
Policy mu Max                2.710423
Policy mu Min                -3.1957088
Policy log std Mean          -0.2762472
Policy log std Std           0.116984665
Policy log std Max           0.02753444
Policy log std Min           -1.0477471
Z mean eval                  0.21111634
Z variance eval              0.04061296
total_rewards                [5338.81149878 5273.20711945 5332.59929667 5284.8807141  5383.89363284
 5425.78881172 5236.53210453 5433.21133383 5354.0514602  5286.58637755]
total_rewards_mean           5334.956234967712
total_rewards_std            62.475595094511924
total_rewards_max            5433.211333834101
total_rewards_min            5236.53210453198
Number of train steps total  1476000
Number of env steps total    1914065
Number of rollouts total     0
Train Time (s)               129.44351272203494
(Previous) Eval Time (s)     26.183117922977544
Sample Time (s)              8.294936308055185
Epoch Time (s)               163.92156695306767
Total Train Time (s)         54952.334850791376
Epoch                        368
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 11:34:26.303078 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #368 | Epoch Duration: 164.13424682617188
2020-01-06 11:34:26.303280 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #368 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.2076222
Z variance train             0.04597026
KL Divergence                5.488013
KL Loss                      0.5488013
QF Loss                      1017.3981
VF Loss                      159.02567
Policy Loss                  -2815.496
Q Predictions Mean           2815.2964
Q Predictions Std            263.72717
Q Predictions Max            2962.7783
Q Predictions Min            116.873604
V Predictions Mean           2814.9688
V Predictions Std            270.14673
V Predictions Max            2952.8452
V Predictions Min            82.35418
Log Pis Mean                 -5.1625543
Log Pis Std                  4.8251057
Log Pis Max                  23.468689
Log Pis Min                  -13.115835
Policy mu Mean               0.069393784
Policy mu Std                0.7115455
Policy mu Max                2.924347
Policy mu Min                -2.6988292
Policy log std Mean          -0.2770541
Policy log std Std           0.10836519
Policy log std Max           -0.0012836754
Policy log std Min           -1.1509734
Z mean eval                  0.22526833
Z variance eval              0.04379845
total_rewards                [5327.35063391 5261.47658873 5415.20484657 5218.53995128 5316.35800185
 5394.04790068 5393.49142888 5337.11526003 5461.20973587 5435.02613401]
total_rewards_mean           5355.982048180724
total_rewards_std            73.65563581196612
total_rewards_max            5461.209735866525
total_rewards_min            5218.539951277821
Number of train steps total  1480000
Number of env steps total    1919065
Number of rollouts total     0
Train Time (s)               130.31652550096624
(Previous) Eval Time (s)     26.395517489989288
Sample Time (s)              8.096962844021618
Epoch Time (s)               164.80900583497714
Total Train Time (s)         55118.66028675734
Epoch                        369
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 11:37:12.571457 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #369 | Epoch Duration: 166.26803350448608
2020-01-06 11:37:12.571622 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #369 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.22932056
Z variance train             0.06423163
KL Divergence                4.7429953
KL Loss                      0.47429952
QF Loss                      2067.9805
VF Loss                      314.03613
Policy Loss                  -2814.8438
Q Predictions Mean           2805.905
Q Predictions Std            232.67206
Q Predictions Max            2951.857
Q Predictions Min            713.72986
V Predictions Mean           2807.9526
V Predictions Std            224.2419
V Predictions Max            2953.9568
V Predictions Min            742.4064
Log Pis Mean                 -4.685217
Log Pis Std                  5.559764
Log Pis Max                  40.11857
Log Pis Min                  -13.389229
Policy mu Mean               0.07829221
Policy mu Std                0.7378614
Policy mu Max                2.7458806
Policy mu Min                -4.5824275
Policy log std Mean          -0.2807209
Policy log std Std           0.11577219
Policy log std Max           0.030844882
Policy log std Min           -1.5504481
Z mean eval                  0.2510952
Z variance eval              0.056435622
total_rewards                [5315.48252565 5357.0729887  5229.31003556 5305.91265123 5168.2593384
 5178.69732618 5276.58034416 5308.04139665 5178.13315473 5318.94651727]
total_rewards_mean           5263.643627851807
total_rewards_std            65.73035115365624
total_rewards_max            5357.072988701953
total_rewards_min            5168.25933839667
Number of train steps total  1484000
Number of env steps total    1924160
Number of rollouts total     0
Train Time (s)               122.41015995503403
(Previous) Eval Time (s)     27.854282865009736
Sample Time (s)              8.290897923056036
Epoch Time (s)               158.5553407430998
Total Train Time (s)         55273.89630810439
Epoch                        370
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 11:39:47.906798 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #370 | Epoch Duration: 155.33502507209778
2020-01-06 11:39:47.907004 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #370 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.3330235
Z variance train             0.060111336
KL Divergence                5.083129
KL Loss                      0.5083129
QF Loss                      1558.7202
VF Loss                      461.76245
Policy Loss                  -2817.3389
Q Predictions Mean           2815.716
Q Predictions Std            270.17786
Q Predictions Max            2942.9932
Q Predictions Min            214.77263
V Predictions Mean           2815.3345
V Predictions Std            268.44843
V Predictions Max            2955.1787
V Predictions Min            206.88332
Log Pis Mean                 -5.712138
Log Pis Std                  4.156922
Log Pis Max                  9.459444
Log Pis Min                  -15.991861
Policy mu Mean               0.052951794
Policy mu Std                0.69293547
Policy mu Max                3.8784418
Policy mu Min                -2.0919418
Policy log std Mean          -0.27364802
Policy log std Std           0.10777917
Policy log std Max           -0.038394406
Policy log std Min           -1.0245867
Z mean eval                  0.23355731
Z variance eval              0.04383863
total_rewards                [5359.17986225 5304.67889633 5306.02540264 5227.97768503 5171.33956074
 5485.03566572 5267.94612103 5310.59292459 5446.43289376 5410.01665415]
total_rewards_mean           5328.922566624917
total_rewards_std            92.6607483724635
total_rewards_max            5485.035665722768
total_rewards_min            5171.339560743646
Number of train steps total  1488000
Number of env steps total    1929160
Number of rollouts total     0
Train Time (s)               89.0014228450018
(Previous) Eval Time (s)     24.633301523979753
Sample Time (s)              7.321240456949454
Epoch Time (s)               120.955964825931
Total Train Time (s)         55391.56856609724
Epoch                        371
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 11:41:45.472558 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #371 | Epoch Duration: 117.5654456615448
2020-01-06 11:41:45.472658 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #371 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.20407856
Z variance train             0.03536766
KL Divergence                6.11013
KL Loss                      0.611013
QF Loss                      840.32605
VF Loss                      229.63797
Policy Loss                  -2833.4258
Q Predictions Mean           2826.5874
Q Predictions Std            222.94263
Q Predictions Max            2949.2986
Q Predictions Min            442.52795
V Predictions Mean           2832.0156
V Predictions Std            226.54846
V Predictions Max            2963.98
V Predictions Min            420.20465
Log Pis Mean                 -5.3264327
Log Pis Std                  4.648526
Log Pis Max                  27.311317
Log Pis Min                  -15.851488
Policy mu Mean               0.050846606
Policy mu Std                0.70847034
Policy mu Max                3.098754
Policy mu Min                -2.7291193
Policy log std Mean          -0.28063434
Policy log std Std           0.106071085
Policy log std Max           0.10309145
Policy log std Min           -0.91928667
Z mean eval                  0.272565
Z variance eval              0.04388056
total_rewards                [2849.43630157 5438.48342408 5512.45777888 3642.06399836 5422.49105592
 5382.67295005 5479.65622362 5454.7142808  3477.59990917 5356.84942949]
total_rewards_mean           4801.6425351936805
total_rewards_std            986.7701990023423
total_rewards_max            5512.457778883783
total_rewards_min            2849.436301566865
Number of train steps total  1492000
Number of env steps total    1934339
Number of rollouts total     0
Train Time (s)               87.07136055501178
(Previous) Eval Time (s)     21.242554055992514
Sample Time (s)              7.144799900997896
Epoch Time (s)               115.45871451200219
Total Train Time (s)         55502.73143447528
Epoch                        372
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 11:43:36.638208 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #372 | Epoch Duration: 111.16546893119812
2020-01-06 11:43:36.638312 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #372 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.24080908
Z variance train             0.03789013
KL Divergence                5.9949284
KL Loss                      0.59949285
QF Loss                      802.2158
VF Loss                      195.64188
Policy Loss                  -2818.9202
Q Predictions Mean           2813.7314
Q Predictions Std            271.40466
Q Predictions Max            2948.8584
Q Predictions Min            45.765984
V Predictions Mean           2823.3896
V Predictions Std            275.69217
V Predictions Max            2961.535
V Predictions Min            -9.431905
Log Pis Mean                 -5.2240295
Log Pis Std                  4.541716
Log Pis Max                  21.621292
Log Pis Min                  -14.675179
Policy mu Mean               0.07913211
Policy mu Std                0.7159405
Policy mu Max                2.6851218
Policy mu Min                -2.2640855
Policy log std Mean          -0.2814298
Policy log std Std           0.11649761
Policy log std Max           0.04873523
Policy log std Min           -1.037073
Z mean eval                  0.22150798
Z variance eval              0.039162714
total_rewards                [5428.74268413 5377.07143789 5381.64684918 5389.25170758 5330.60209824
 5392.61945392 5481.45119133 5271.03038841 5320.6777484  5339.46745045]
total_rewards_mean           5371.256100952257
total_rewards_std            56.246168870920826
total_rewards_max            5481.451191327487
total_rewards_min            5271.030388412787
Number of train steps total  1496000
Number of env steps total    1939509
Number of rollouts total     0
Train Time (s)               75.83911385497777
(Previous) Eval Time (s)     16.949090975977015
Sample Time (s)              5.943647921958473
Epoch Time (s)               98.73185275291326
Total Train Time (s)         55602.647856561234
Epoch                        373
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 11:45:16.557326 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #373 | Epoch Duration: 99.91893172264099
2020-01-06 11:45:16.557426 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #373 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.24714649
Z variance train             0.046172775
KL Divergence                5.534349
KL Loss                      0.5534349
QF Loss                      633.8367
VF Loss                      172.4548
Policy Loss                  -2847.3228
Q Predictions Mean           2842.9106
Q Predictions Std            150.2378
Q Predictions Max            2952.7632
Q Predictions Min            715.1788
V Predictions Mean           2841.8882
V Predictions Std            154.1149
V Predictions Max            2968.9053
V Predictions Min            697.29913
Log Pis Mean                 -5.64417
Log Pis Std                  3.9840958
Log Pis Max                  11.910497
Log Pis Min                  -13.934689
Policy mu Mean               0.032101896
Policy mu Std                0.6999449
Policy mu Max                2.1178927
Policy mu Min                -2.600731
Policy log std Mean          -0.26962635
Policy log std Std           0.10069682
Policy log std Max           0.61008656
Policy log std Min           -0.8276583
Z mean eval                  0.21637838
Z variance eval              0.033828083
total_rewards                [5283.48568023 5520.16150929 5269.80053958 5437.0863088  5438.76403662
 5446.87523801 5555.74753911 1026.36462511 4402.64591458 5419.07170325]
total_rewards_mean           4880.000309458029
total_rewards_std            1322.6514059138642
total_rewards_max            5555.747539106264
total_rewards_min            1026.3646251086154
Number of train steps total  1500000
Number of env steps total    1944509
Number of rollouts total     0
Train Time (s)               77.1627307550516
(Previous) Eval Time (s)     18.13597550103441
Sample Time (s)              5.77853769302601
Epoch Time (s)               101.07724394911202
Total Train Time (s)         55702.28472795844
Epoch                        374
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 11:46:56.197031 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #374 | Epoch Duration: 99.63951921463013
2020-01-06 11:46:56.197154 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #374 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.21014921
Z variance train             0.04425124
KL Divergence                5.5828857
KL Loss                      0.5582886
QF Loss                      948.11816
VF Loss                      171.19131
Policy Loss                  -2843.3594
Q Predictions Mean           2837.8174
Q Predictions Std            137.66708
Q Predictions Max            2946.6138
Q Predictions Min            1126.374
V Predictions Mean           2842.359
V Predictions Std            133.42427
V Predictions Max            2957.222
V Predictions Min            1258.1217
Log Pis Mean                 -5.4789886
Log Pis Std                  4.2155213
Log Pis Max                  15.47776
Log Pis Min                  -17.233263
Policy mu Mean               -0.011827228
Policy mu Std                0.7063306
Policy mu Max                2.6375737
Policy mu Min                -2.3473234
Policy log std Mean          -0.27223876
Policy log std Std           0.106057845
Policy log std Max           0.0538432
Policy log std Min           -0.8307471
Z mean eval                  0.18817785
Z variance eval              0.048980482
total_rewards                [5521.87875614 5422.50868952 5493.61649308 4842.03890475 5535.96307158
 5501.25011448 5477.51845366 5406.30547079 5396.63900909 5432.80015462]
total_rewards_mean           5403.0519117697995
total_rewards_std            192.67229193041462
total_rewards_max            5535.963071576165
total_rewards_min            4842.038904747316
Number of train steps total  1504000
Number of env steps total    1949509
Number of rollouts total     0
Train Time (s)               74.40759801800596
(Previous) Eval Time (s)     16.69805357698351
Sample Time (s)              5.822337571065873
Epoch Time (s)               96.92798916605534
Total Train Time (s)         55800.51149346557
Epoch                        375
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 11:48:34.426412 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #375 | Epoch Duration: 98.22917342185974
2020-01-06 11:48:34.426509 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #375 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.20072219
Z variance train             0.03628568
KL Divergence                6.043723
KL Loss                      0.6043723
QF Loss                      1815.084
VF Loss                      471.09183
Policy Loss                  -2826.9355
Q Predictions Mean           2823.0417
Q Predictions Std            213.81615
Q Predictions Max            2945.7874
Q Predictions Min            776.6485
V Predictions Mean           2822.96
V Predictions Std            214.45119
V Predictions Max            2945.1255
V Predictions Min            739.8155
Log Pis Mean                 -5.056043
Log Pis Std                  5.373539
Log Pis Max                  28.723078
Log Pis Min                  -18.383286
Policy mu Mean               0.062804714
Policy mu Std                0.73522425
Policy mu Max                3.2706258
Policy mu Min                -2.9668312
Policy log std Mean          -0.2841793
Policy log std Std           0.11123949
Policy log std Max           -0.0790436
Policy log std Min           -1.0809429
Z mean eval                  0.37487525
Z variance eval              0.0873253
total_rewards                [5461.36643824 5302.23612718 5499.29927557 5423.67791006 5535.00602251
 5503.30836326 5373.23480002 5500.40754785 5485.95901483 5513.42518104]
total_rewards_mean           5459.792068055724
total_rewards_std            69.24247948697486
total_rewards_max            5535.006022510244
total_rewards_min            5302.236127177391
Number of train steps total  1508000
Number of env steps total    1954509
Number of rollouts total     0
Train Time (s)               75.36596830695635
(Previous) Eval Time (s)     17.99903341103345
Sample Time (s)              5.843006851966493
Epoch Time (s)               99.20800856995629
Total Train Time (s)         55901.13294918049
Epoch                        376
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 11:50:15.050706 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #376 | Epoch Duration: 100.62411403656006
2020-01-06 11:50:15.050819 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #376 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.4133575
Z variance train             0.08586434
KL Divergence                4.489582
KL Loss                      0.44895822
QF Loss                      1085.4906
VF Loss                      283.17618
Policy Loss                  -2831.933
Q Predictions Mean           2824.819
Q Predictions Std            191.49788
Q Predictions Max            2946.5447
Q Predictions Min            856.745
V Predictions Mean           2825.028
V Predictions Std            190.7825
V Predictions Max            2951.0403
V Predictions Min            956.6796
Log Pis Mean                 -4.916277
Log Pis Std                  4.8564835
Log Pis Max                  38.51611
Log Pis Min                  -13.75914
Policy mu Mean               0.05823907
Policy mu Std                0.7387571
Policy mu Max                2.8743205
Policy mu Min                -3.0057387
Policy log std Mean          -0.28600097
Policy log std Std           0.12911306
Policy log std Max           -0.034113705
Policy log std Min           -1.3598745
Z mean eval                  0.39304346
Z variance eval              0.075441755
total_rewards                [5515.15166985 5375.72961244 5473.6328946  5378.11982674 3444.08128027
 5484.11916315 5363.64991321 5544.26701904 4277.96813256 5363.32681472]
total_rewards_mean           5122.0046326586225
total_rewards_std            660.4592393755154
total_rewards_max            5544.26701904122
total_rewards_min            3444.0812802677347
Number of train steps total  1512000
Number of env steps total    1959509
Number of rollouts total     0
Train Time (s)               79.68989231000887
(Previous) Eval Time (s)     19.41493177699158
Sample Time (s)              6.117806332069449
Epoch Time (s)               105.2226304190699
Total Train Time (s)         56006.244636305666
Epoch                        377
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 11:52:00.165213 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #377 | Epoch Duration: 105.11430859565735
2020-01-06 11:52:00.165314 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #377 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6121735
Z variance train             0.106148556
KL Divergence                4.7132273
KL Loss                      0.47132275
QF Loss                      1171.6497
VF Loss                      693.3859
Policy Loss                  -2830.806
Q Predictions Mean           2824.0952
Q Predictions Std            174.71762
Q Predictions Max            2952.5854
Q Predictions Min            1161.8339
V Predictions Mean           2840.2163
V Predictions Std            179.94243
V Predictions Max            2983.3303
V Predictions Min            1157.0732
Log Pis Mean                 -4.9813976
Log Pis Std                  5.048127
Log Pis Max                  20.260555
Log Pis Min                  -17.355587
Policy mu Mean               0.06910224
Policy mu Std                0.7431964
Policy mu Max                4.15226
Policy mu Min                -2.5437477
Policy log std Mean          -0.28658468
Policy log std Std           0.11145161
Policy log std Max           0.023581266
Policy log std Min           -1.0214183
Z mean eval                  0.38957423
Z variance eval              0.1053756
total_rewards                [5176.23152237 5454.88052473 5396.64806659 5383.64945848 5472.75635859
 5378.37270646 5362.67517625 5392.42190029 5378.9581581  5326.19563563]
total_rewards_mean           5372.278950748264
total_rewards_std            76.66802099834848
total_rewards_max            5472.756358585335
total_rewards_min            5176.231522374369
Number of train steps total  1516000
Number of env steps total    1964509
Number of rollouts total     0
Train Time (s)               81.56688591197599
(Previous) Eval Time (s)     19.306395177030936
Sample Time (s)              6.437536115117837
Epoch Time (s)               107.31081720412476
Total Train Time (s)         56114.989868487755
Epoch                        378
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 11:53:48.913692 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #378 | Epoch Duration: 108.74829363822937
2020-01-06 11:53:48.913805 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #378 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9684558
Z variance train             0.2115376
KL Divergence                5.244458
KL Loss                      0.52444583
QF Loss                      1229.6909
VF Loss                      446.28
Policy Loss                  -2854.2588
Q Predictions Mean           2853.9055
Q Predictions Std            101.50623
Q Predictions Max            2968.2693
Q Predictions Min            1933.3207
V Predictions Mean           2856.1865
V Predictions Std            110.35124
V Predictions Max            2977.0437
V Predictions Min            1900.1451
Log Pis Mean                 -4.856479
Log Pis Std                  4.5601573
Log Pis Max                  16.267776
Log Pis Min                  -14.862116
Policy mu Mean               0.044595227
Policy mu Std                0.7307083
Policy mu Max                2.5521088
Policy mu Min                -2.3843687
Policy log std Mean          -0.29170543
Policy log std Std           0.116277166
Policy log std Max           -0.054928705
Policy log std Min           -0.9655873
Z mean eval                  0.23164324
Z variance eval              0.11895548
total_rewards                [5464.88358331 5464.73173298 5356.75415769 5403.1674865  5486.49090288
 5317.64818035 5356.67262912 5355.16453725 5358.34626718 5394.92354372]
total_rewards_mean           5395.878302098477
total_rewards_std            54.7916149443137
total_rewards_max            5486.490902875503
total_rewards_min            5317.648180354744
Number of train steps total  1520000
Number of env steps total    1969661
Number of rollouts total     0
Train Time (s)               81.60197861900087
(Previous) Eval Time (s)     20.743647597031668
Sample Time (s)              6.778375078109093
Epoch Time (s)               109.12400129414164
Total Train Time (s)         56223.63119989174
Epoch                        379
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 11:55:37.557629 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #379 | Epoch Duration: 108.64374041557312
2020-01-06 11:55:37.557727 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #379 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.23022251
Z variance train             0.106559694
KL Divergence                3.6173158
KL Loss                      0.3617316
QF Loss                      1206.7441
VF Loss                      261.1427
Policy Loss                  -2822.6973
Q Predictions Mean           2820.034
Q Predictions Std            261.8938
Q Predictions Max            2959.0054
Q Predictions Min            -162.6346
V Predictions Mean           2821.8335
V Predictions Std            255.42044
V Predictions Max            2960.7456
V Predictions Min            -11.289048
Log Pis Mean                 -5.1751933
Log Pis Std                  4.4780087
Log Pis Max                  21.313759
Log Pis Min                  -15.442031
Policy mu Mean               0.044108048
Policy mu Std                0.7320436
Policy mu Max                4.294628
Policy mu Min                -2.8779821
Policy log std Mean          -0.28160465
Policy log std Std           0.10299589
Policy log std Max           -0.044196673
Policy log std Min           -0.8138767
Z mean eval                  0.35383302
Z variance eval              0.13673139
total_rewards                [5387.33963682 5340.09936154 5516.39768461 5436.2325925  5480.31668983
 5402.17327332 5455.68304321 5399.65022521 5363.08661434 5389.92819244]
total_rewards_mean           5417.0907313821635
total_rewards_std            51.680672216803295
total_rewards_max            5516.397684614426
total_rewards_min            5340.099361543156
Number of train steps total  1524000
Number of env steps total    1974661
Number of rollouts total     0
Train Time (s)               79.092454840953
(Previous) Eval Time (s)     20.26317706296686
Sample Time (s)              5.850041972997133
Epoch Time (s)               105.20567387691699
Total Train Time (s)         56328.17049901775
Epoch                        380
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 11:57:22.099958 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #380 | Epoch Duration: 104.54215264320374
2020-01-06 11:57:22.100059 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #380 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.5993112
Z variance train             0.2790853
KL Divergence                2.958825
KL Loss                      0.29588252
QF Loss                      984.0373
VF Loss                      632.73584
Policy Loss                  -2833.3145
Q Predictions Mean           2827.2693
Q Predictions Std            191.73396
Q Predictions Max            2945.1477
Q Predictions Min            1151.8253
V Predictions Mean           2833.6274
V Predictions Std            167.19383
V Predictions Max            2968.8608
V Predictions Min            1358.4061
Log Pis Mean                 -5.4818068
Log Pis Std                  4.602767
Log Pis Max                  21.657217
Log Pis Min                  -16.105328
Policy mu Mean               0.049733408
Policy mu Std                0.714148
Policy mu Max                2.771921
Policy mu Min                -2.9258683
Policy log std Mean          -0.27623934
Policy log std Std           0.11651236
Policy log std Max           -0.061504833
Policy log std Min           -1.0957036
Z mean eval                  0.30401114
Z variance eval              0.12955095
total_rewards                [5273.15475232 5537.35042707 5472.85209262 5375.38894412 5403.42242047
 5359.71919423 5476.41256652 5357.96637679 5441.84044606 5541.75497784]
total_rewards_mean           5423.986219803124
total_rewards_std            81.36317317318418
total_rewards_max            5541.754977838446
total_rewards_min            5273.154752316371
Number of train steps total  1528000
Number of env steps total    1979809
Number of rollouts total     0
Train Time (s)               78.236033019959
(Previous) Eval Time (s)     19.59944559901487
Sample Time (s)              6.309841626905836
Epoch Time (s)               104.1453202458797
Total Train Time (s)         56432.66679950454
Epoch                        381
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 11:59:06.599097 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #381 | Epoch Duration: 104.49895286560059
2020-01-06 11:59:06.599212 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #381 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.20281145
Z variance train             0.0876583
KL Divergence                3.9977498
KL Loss                      0.399775
QF Loss                      871.8146
VF Loss                      361.41824
Policy Loss                  -2820.562
Q Predictions Mean           2821.0212
Q Predictions Std            200.2555
Q Predictions Max            2962.5603
Q Predictions Min            102.58543
V Predictions Mean           2826.2725
V Predictions Std            202.5274
V Predictions Max            2958.3054
V Predictions Min            74.333275
Log Pis Mean                 -6.0107703
Log Pis Std                  4.3183312
Log Pis Max                  15.149285
Log Pis Min                  -15.980288
Policy mu Mean               0.031486582
Policy mu Std                0.6927213
Policy mu Max                2.694051
Policy mu Min                -2.5661368
Policy log std Mean          -0.2771729
Policy log std Std           0.11012852
Policy log std Max           0.011584267
Policy log std Min           -0.9607998
Z mean eval                  0.273696
Z variance eval              0.11802715
total_rewards                [5443.43494479 5489.02137887 5445.40723279 5398.59012747 5434.97883196
 5473.04951959 5430.51414314 5452.48385316 5356.34224649 5416.37775521]
total_rewards_mean           5434.0200033464735
total_rewards_std            35.66685808428343
total_rewards_max            5489.021378870968
total_rewards_min            5356.342246494742
Number of train steps total  1532000
Number of env steps total    1984809
Number of rollouts total     0
Train Time (s)               74.42837814596714
(Previous) Eval Time (s)     19.952867515967228
Sample Time (s)              6.1212565780151635
Epoch Time (s)               100.50250223994954
Total Train Time (s)         56532.8332924585
Epoch                        382
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:00:46.768741 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #382 | Epoch Duration: 100.16944408416748
2020-01-06 12:00:46.768855 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #382 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.23387332
Z variance train             0.05602979
KL Divergence                5.045079
KL Loss                      0.50450796
QF Loss                      1091.883
VF Loss                      412.54477
Policy Loss                  -2783.6506
Q Predictions Mean           2783.8362
Q Predictions Std            377.2439
Q Predictions Max            2954.8088
Q Predictions Min            60.99532
V Predictions Mean           2782.5837
V Predictions Std            384.9765
V Predictions Max            2966.5896
V Predictions Min            29.546522
Log Pis Mean                 -5.1152687
Log Pis Std                  5.0060763
Log Pis Max                  21.342712
Log Pis Min                  -12.628087
Policy mu Mean               0.06788343
Policy mu Std                0.72894067
Policy mu Max                2.8739257
Policy mu Min                -2.41375
Policy log std Mean          -0.2792153
Policy log std Std           0.10454697
Policy log std Max           0.22383867
Policy log std Min           -0.9021037
Z mean eval                  0.21909156
Z variance eval              0.18488804
total_rewards                [5511.97048582 2698.26492339 5399.21769596 5451.42042646 5490.15471895
 5469.1909438  5470.53217441 5364.76308731 3774.12924696 5574.5001712 ]
total_rewards_mean           5020.414387426377
total_rewards_std            925.5668434238553
total_rewards_max            5574.500171204108
total_rewards_min            2698.2649233902607
Number of train steps total  1536000
Number of env steps total    1989809
Number of rollouts total     0
Train Time (s)               77.57291679602349
(Previous) Eval Time (s)     19.619584495027084
Sample Time (s)              6.145801343081985
Epoch Time (s)               103.33830263413256
Total Train Time (s)         56635.548956491635
Epoch                        383
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:02:29.487144 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #383 | Epoch Duration: 102.71820592880249
2020-01-06 12:02:29.487251 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #383 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.13443825
Z variance train             0.11657798
KL Divergence                3.2791436
KL Loss                      0.32791436
QF Loss                      909.8427
VF Loss                      437.55478
Policy Loss                  -2830.4404
Q Predictions Mean           2832.538
Q Predictions Std            162.02397
Q Predictions Max            2955.5188
Q Predictions Min            804.3222
V Predictions Mean           2833.1094
V Predictions Std            177.73766
V Predictions Max            2968.6067
V Predictions Min            634.78864
Log Pis Mean                 -5.4617605
Log Pis Std                  4.2840953
Log Pis Max                  19.91132
Log Pis Min                  -13.418048
Policy mu Mean               0.046843596
Policy mu Std                0.69504035
Policy mu Max                2.51705
Policy mu Min                -2.8437932
Policy log std Mean          -0.2698197
Policy log std Std           0.11150199
Policy log std Max           -0.08477068
Policy log std Min           -1.0923971
Z mean eval                  0.17176898
Z variance eval              0.10383968
total_rewards                [5416.22653562 5422.50726379 5348.97156313 5369.86244769 5332.90023053
 5390.95690251 5192.79256974 5353.22785925 5499.03212428 5387.2525684 ]
total_rewards_mean           5371.373006492654
total_rewards_std            74.67500978884532
total_rewards_max            5499.032124276534
total_rewards_min            5192.7925697383
Number of train steps total  1540000
Number of env steps total    1994809
Number of rollouts total     0
Train Time (s)               79.24361760099418
(Previous) Eval Time (s)     18.99927250004839
Sample Time (s)              6.367044175043702
Epoch Time (s)               104.60993427608628
Total Train Time (s)         56741.2498675987
Epoch                        384
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:04:15.191085 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #384 | Epoch Duration: 105.70374846458435
2020-01-06 12:04:15.191199 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #384 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.13516128
Z variance train             0.07873275
KL Divergence                4.147773
KL Loss                      0.41477728
QF Loss                      822.0614
VF Loss                      518.6343
Policy Loss                  -2841.0498
Q Predictions Mean           2837.1968
Q Predictions Std            148.64835
Q Predictions Max            2953.8782
Q Predictions Min            984.11304
V Predictions Mean           2838.8086
V Predictions Std            146.69084
V Predictions Max            2954.8364
V Predictions Min            975.84894
Log Pis Mean                 -5.4146814
Log Pis Std                  3.8376276
Log Pis Max                  10.23848
Log Pis Min                  -13.536283
Policy mu Mean               0.0130116
Policy mu Std                0.7092473
Policy mu Max                2.2468255
Policy mu Min                -2.6236
Policy log std Mean          -0.2764009
Policy log std Std           0.109756514
Policy log std Max           -0.052485075
Policy log std Min           -0.88406587
Z mean eval                  0.21717079
Z variance eval              0.18474871
total_rewards                [5403.81429397 5359.81084735 5465.1794402  5476.75818042 5452.65550845
 3712.45649996 2301.87723209 5414.58823018 5501.75071695 5560.89570524]
total_rewards_mean           4964.978665480954
total_rewards_std            1029.7926045879228
total_rewards_max            5560.895705244354
total_rewards_min            2301.877232085204
Number of train steps total  1544000
Number of env steps total    1999809
Number of rollouts total     0
Train Time (s)               78.94669520197203
(Previous) Eval Time (s)     20.092864357982762
Sample Time (s)              6.334369289979804
Epoch Time (s)               105.3739288499346
Total Train Time (s)         56845.430391981616
Epoch                        385
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:05:59.375761 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #385 | Epoch Duration: 104.1844699382782
2020-01-06 12:05:59.375924 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #385 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.27065918
Z variance train             0.18199566
KL Divergence                2.5208101
KL Loss                      0.252081
QF Loss                      759.0488
VF Loss                      279.19052
Policy Loss                  -2813.082
Q Predictions Mean           2809.2727
Q Predictions Std            363.4416
Q Predictions Max            2962.861
Q Predictions Min            78.819016
V Predictions Mean           2812.2495
V Predictions Std            355.82193
V Predictions Max            2966.8794
V Predictions Min            118.4142
Log Pis Mean                 -5.852285
Log Pis Std                  4.857384
Log Pis Max                  23.60648
Log Pis Min                  -17.79034
Policy mu Mean               0.073596984
Policy mu Std                0.6937465
Policy mu Max                3.462883
Policy mu Min                -3.1962965
Policy log std Mean          -0.2742457
Policy log std Std           0.11099039
Policy log std Max           0.09169349
Policy log std Min           -0.98832107
Z mean eval                  0.22864518
Z variance eval              0.18523028
total_rewards                [5322.37502454 5310.06233595 5252.47893385 5390.04261828 5260.32095526
 5271.15905768 5316.66393541 5229.10183099 5462.1035631  5263.94822147]
total_rewards_mean           5307.825647651636
total_rewards_std            67.5597284731989
total_rewards_max            5462.1035631012155
total_rewards_min            5229.10183099141
Number of train steps total  1548000
Number of env steps total    2004914
Number of rollouts total     0
Train Time (s)               86.50235090003116
(Previous) Eval Time (s)     18.90318122599274
Sample Time (s)              7.47637023194693
Epoch Time (s)               112.88190235797083
Total Train Time (s)         56959.74808673147
Epoch                        386
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:07:53.695686 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #386 | Epoch Duration: 114.31964063644409
2020-01-06 12:07:53.695789 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #386 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.24041224
Z variance train             0.11704572
KL Divergence                3.3485513
KL Loss                      0.33485514
QF Loss                      824.54126
VF Loss                      207.72229
Policy Loss                  -2825.1924
Q Predictions Mean           2822.8608
Q Predictions Std            299.61307
Q Predictions Max            2964.9236
Q Predictions Min            51.13262
V Predictions Mean           2824.8843
V Predictions Std            303.62775
V Predictions Max            2961.2031
V Predictions Min            -10.469328
Log Pis Mean                 -5.46883
Log Pis Std                  4.5150533
Log Pis Max                  17.569328
Log Pis Min                  -14.405317
Policy mu Mean               0.038367074
Policy mu Std                0.6984936
Policy mu Max                2.829402
Policy mu Min                -2.457016
Policy log std Mean          -0.26980746
Policy log std Std           0.10900837
Policy log std Max           0.031335324
Policy log std Min           -0.8748873
Z mean eval                  0.15276632
Z variance eval              0.07842477
total_rewards                [5427.28292414 5358.15466666 5482.23123879 5429.87935398 5412.12748445
 5397.73293572 5378.6154752  5426.47504546 5420.24785834 5363.33820792]
total_rewards_mean           5409.6085190667245
total_rewards_std            35.059107335126846
total_rewards_max            5482.23123879413
total_rewards_min            5358.15466666497
Number of train steps total  1552000
Number of env steps total    2009914
Number of rollouts total     0
Train Time (s)               78.4381589149707
(Previous) Eval Time (s)     20.34067873604363
Sample Time (s)              6.078382938052528
Epoch Time (s)               104.85722058906686
Total Train Time (s)         57064.53423512762
Epoch                        387
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:09:38.485224 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #387 | Epoch Duration: 104.78934812545776
2020-01-06 12:09:38.485380 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #387 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.20314912
Z variance train             0.13979946
KL Divergence                2.9239912
KL Loss                      0.29239914
QF Loss                      908.8717
VF Loss                      734.6903
Policy Loss                  -2817.496
Q Predictions Mean           2819.3823
Q Predictions Std            279.2814
Q Predictions Max            2957.9363
Q Predictions Min            51.389442
V Predictions Mean           2836.524
V Predictions Std            272.7583
V Predictions Max            2982.0598
V Predictions Min            42.999245
Log Pis Mean                 -5.576896
Log Pis Std                  4.879671
Log Pis Max                  27.547134
Log Pis Min                  -14.419743
Policy mu Mean               0.06703813
Policy mu Std                0.71186364
Policy mu Max                3.2773652
Policy mu Min                -3.2451036
Policy log std Mean          -0.27637655
Policy log std Std           0.11340555
Policy log std Max           0.38409597
Policy log std Min           -0.9735397
Z mean eval                  0.2376467
Z variance eval              0.12962875
total_rewards                [5442.92479556 5325.72585412 5526.7335509  5543.24750373 5467.35241773
 5492.61833805 5441.53724066 5513.95321352 4893.59636123 5445.23920722]
total_rewards_mean           5409.292848272115
total_rewards_std            181.4919474692045
total_rewards_max            5543.247503734183
total_rewards_min            4893.596361229133
Number of train steps total  1556000
Number of env steps total    2014914
Number of rollouts total     0
Train Time (s)               78.59921701496933
(Previous) Eval Time (s)     20.272577543044463
Sample Time (s)              6.459653124038596
Epoch Time (s)               105.33144768205239
Total Train Time (s)         57168.8502189077
Epoch                        388
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:11:22.804017 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #388 | Epoch Duration: 104.3185133934021
2020-01-06 12:11:22.804121 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #388 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.20861697
Z variance train             0.1128749
KL Divergence                3.4083831
KL Loss                      0.3408383
QF Loss                      564.74304
VF Loss                      217.4485
Policy Loss                  -2850.2544
Q Predictions Mean           2847.3684
Q Predictions Std            198.43617
Q Predictions Max            2960.4995
Q Predictions Min            242.22136
V Predictions Mean           2849.1714
V Predictions Std            199.72348
V Predictions Max            2971.041
V Predictions Min            252.99445
Log Pis Mean                 -5.7421255
Log Pis Std                  3.7600687
Log Pis Max                  7.649907
Log Pis Min                  -15.092451
Policy mu Mean               0.06617602
Policy mu Std                0.692022
Policy mu Max                2.612959
Policy mu Min                -2.1668286
Policy log std Mean          -0.26462275
Policy log std Std           0.10409923
Policy log std Max           -0.029007345
Policy log std Min           -1.2692332
Z mean eval                  0.23374148
Z variance eval              0.053024698
total_rewards                [5639.47118497 5460.63873797 5469.46053046 4781.55547676 5457.09727491
 4025.97104152 5353.93217204 5509.10541754 4562.68355704 2228.78835104]
total_rewards_mean           4848.870374425574
total_rewards_std            1003.6835815810723
total_rewards_max            5639.471184974485
total_rewards_min            2228.7883510370184
Number of train steps total  1560000
Number of env steps total    2020000
Number of rollouts total     0
Train Time (s)               77.06436873000348
(Previous) Eval Time (s)     19.259408471989445
Sample Time (s)              6.165880209009629
Epoch Time (s)               102.48965741100255
Total Train Time (s)         57269.095136811724
Epoch                        389
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:13:03.051714 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #389 | Epoch Duration: 100.24750924110413
2020-01-06 12:13:03.051816 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #389 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.23240837
Z variance train             0.073832914
KL Divergence                4.3891954
KL Loss                      0.43891954
QF Loss                      1174.2023
VF Loss                      229.5059
Policy Loss                  -2851.2883
Q Predictions Mean           2847.4443
Q Predictions Std            178.01964
Q Predictions Max            2961.083
Q Predictions Min            1118.0713
V Predictions Mean           2848.8384
V Predictions Std            175.8674
V Predictions Max            2956.9973
V Predictions Min            1013.19586
Log Pis Mean                 -5.2997417
Log Pis Std                  4.6569366
Log Pis Max                  21.959862
Log Pis Min                  -15.010191
Policy mu Mean               0.080539465
Policy mu Std                0.71683776
Policy mu Max                2.9077766
Policy mu Min                -2.9147944
Policy log std Mean          -0.28313708
Policy log std Std           0.118490435
Policy log std Max           -0.013602309
Policy log std Min           -1.0943506
Z mean eval                  0.088404834
Z variance eval              0.22027858
total_rewards                [5571.24282388 5452.65820431 5523.63714764 5435.28950111 5516.73425975
 5561.32211283 5476.1310657  5409.73621713 2538.57266621 5410.99069482]
total_rewards_mean           5189.631469338277
total_rewards_std            885.4100137218165
total_rewards_max            5571.242823880386
total_rewards_min            2538.572666205029
Number of train steps total  1564000
Number of env steps total    2025000
Number of rollouts total     0
Train Time (s)               79.40572436299408
(Previous) Eval Time (s)     17.017057641001884
Sample Time (s)              6.038500083901454
Epoch Time (s)               102.46128208789742
Total Train Time (s)         57371.83627351257
Epoch                        390
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:14:45.795861 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #390 | Epoch Duration: 102.74396228790283
2020-01-06 12:14:45.795982 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #390 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11902114
Z variance train             0.049915586
KL Divergence                5.193634
KL Loss                      0.5193634
QF Loss                      992.2846
VF Loss                      192.06422
Policy Loss                  -2864.979
Q Predictions Mean           2861.4766
Q Predictions Std            93.20451
Q Predictions Max            2968.9614
Q Predictions Min            2100.4941
V Predictions Mean           2861.165
V Predictions Std            95.933235
V Predictions Max            2979.1829
V Predictions Min            2096.867
Log Pis Mean                 -5.9953394
Log Pis Std                  3.6196356
Log Pis Max                  9.937366
Log Pis Min                  -16.453308
Policy mu Mean               0.09934757
Policy mu Std                0.6708979
Policy mu Max                2.468846
Policy mu Min                -2.5197988
Policy log std Mean          -0.2757914
Policy log std Std           0.10058128
Policy log std Max           -0.07134567
Policy log std Min           -0.73489743
Z mean eval                  0.21469696
Z variance eval              0.07956946
total_rewards                [5528.24890026 5526.48910203 1517.95497055 5543.27839501 5443.96171214
 5437.43011244 5498.87681001 5519.11614416 5467.57548967 5518.61199869]
total_rewards_mean           5100.154363494467
total_rewards_std            1194.5756444453957
total_rewards_max            5543.278395010671
total_rewards_min            1517.9549705516229
Number of train steps total  1568000
Number of env steps total    2030000
Number of rollouts total     0
Train Time (s)               76.09774687996833
(Previous) Eval Time (s)     17.299534483987372
Sample Time (s)              5.791990854020696
Epoch Time (s)               99.1892722179764
Total Train Time (s)         57471.22067769652
Epoch                        391
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:16:25.183092 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #391 | Epoch Duration: 99.3870267868042
2020-01-06 12:16:25.183197 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #391 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.15722105
Z variance train             0.06386535
KL Divergence                4.643811
KL Loss                      0.46438113
QF Loss                      1657.2557
VF Loss                      501.75027
Policy Loss                  -2840.7114
Q Predictions Mean           2835.3857
Q Predictions Std            240.43846
Q Predictions Max            2961.0818
Q Predictions Min            294.6236
V Predictions Mean           2836.1812
V Predictions Std            239.53387
V Predictions Max            2961.2192
V Predictions Min            309.10275
Log Pis Mean                 -5.110996
Log Pis Std                  4.7815223
Log Pis Max                  21.634735
Log Pis Min                  -14.476406
Policy mu Mean               0.06867953
Policy mu Std                0.7133997
Policy mu Max                2.8124595
Policy mu Min                -2.5228522
Policy log std Mean          -0.27973494
Policy log std Std           0.11259096
Policy log std Max           0.09060021
Policy log std Min           -0.95624197
Z mean eval                  0.06929066
Z variance eval              0.1544941
total_rewards                [5498.66386262 5522.03434792 5532.55092413 5585.42201374 5458.05053475
 1543.1648759  5530.14217711 5523.99007603 5523.12192952 2797.03020328]
total_rewards_mean           4851.417094498733
total_rewards_std            1369.9859234651544
total_rewards_max            5585.422013737016
total_rewards_min            1543.1648758975753
Number of train steps total  1572000
Number of env steps total    2035000
Number of rollouts total     0
Train Time (s)               76.35734692000551
(Previous) Eval Time (s)     17.497088845993858
Sample Time (s)              5.938755963055883
Epoch Time (s)               99.79319172905525
Total Train Time (s)         57570.05185871461
Epoch                        392
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:18:04.017151 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #392 | Epoch Duration: 98.83386182785034
2020-01-06 12:18:04.017252 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #392 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05447663
Z variance train             0.09574913
KL Divergence                3.6460495
KL Loss                      0.36460495
QF Loss                      1306.4921
VF Loss                      968.5233
Policy Loss                  -2812.1511
Q Predictions Mean           2810.0352
Q Predictions Std            262.8866
Q Predictions Max            2959.2668
Q Predictions Min            589.2805
V Predictions Mean           2824.9392
V Predictions Std            262.76443
V Predictions Max            2980.0515
V Predictions Min            576.73224
Log Pis Mean                 -4.952668
Log Pis Std                  5.4044166
Log Pis Max                  25.752724
Log Pis Min                  -16.514286
Policy mu Mean               0.08224286
Policy mu Std                0.7403204
Policy mu Max                2.831987
Policy mu Min                -3.0133886
Policy log std Mean          -0.28140703
Policy log std Std           0.12201938
Policy log std Max           -0.01504837
Policy log std Min           -1.0987382
Z mean eval                  0.08988718
Z variance eval              0.0683329
total_rewards                [5492.40298448 5427.41961126 4362.11268019 5453.74008725 5491.16040268
 5274.79921493 5467.08929233 5617.11110889 5510.20027281 5524.99851819]
total_rewards_mean           5362.1034173002945
total_rewards_std            343.2810968337946
total_rewards_max            5617.111108894783
total_rewards_min            4362.112680194467
Number of train steps total  1576000
Number of env steps total    2040000
Number of rollouts total     0
Train Time (s)               75.69393227196997
(Previous) Eval Time (s)     16.537554444978014
Sample Time (s)              6.040519091067836
Epoch Time (s)               98.27200580801582
Total Train Time (s)         57670.507559533755
Epoch                        393
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:19:44.475753 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #393 | Epoch Duration: 100.45841813087463
2020-01-06 12:19:44.475863 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #393 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07416275
Z variance train             0.10905056
KL Divergence                3.370382
KL Loss                      0.33703822
QF Loss                      679.49634
VF Loss                      596.2296
Policy Loss                  -2833.942
Q Predictions Mean           2828.0496
Q Predictions Std            294.79242
Q Predictions Max            2972.8782
Q Predictions Min            422.39804
V Predictions Mean           2823.0322
V Predictions Std            294.56845
V Predictions Max            2977.261
V Predictions Min            443.52176
Log Pis Mean                 -5.6819596
Log Pis Std                  4.479971
Log Pis Max                  25.656586
Log Pis Min                  -14.993004
Policy mu Mean               0.031408723
Policy mu Std                0.7056948
Policy mu Max                2.5373638
Policy mu Min                -2.7508032
Policy log std Mean          -0.27887172
Policy log std Std           0.105693646
Policy log std Max           0.02166684
Policy log std Min           -0.9528602
Z mean eval                  0.06883459
Z variance eval              0.078581855
total_rewards                [5653.01484113 5561.66429733 5602.95673055 5529.50226015 5530.66596965
 5587.98171528 5543.06190556 5563.27864994 5595.40169629 5556.67275711]
total_rewards_mean           5572.420082298658
total_rewards_std            36.18397422651795
total_rewards_max            5653.014841128968
total_rewards_min            5529.502260154891
Number of train steps total  1580000
Number of env steps total    2045000
Number of rollouts total     0
Train Time (s)               75.6169482920086
(Previous) Eval Time (s)     18.723764333000872
Sample Time (s)              5.947757743066177
Epoch Time (s)               100.28847036807565
Total Train Time (s)         57771.96915135888
Epoch                        394
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:21:25.940823 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #394 | Epoch Duration: 101.46486258506775
2020-01-06 12:21:25.940971 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #394 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.18690757
Z variance train             0.1839366
KL Divergence                2.3249357
KL Loss                      0.23249356
QF Loss                      925.29944
VF Loss                      253.63422
Policy Loss                  -2831.772
Q Predictions Mean           2821.9094
Q Predictions Std            233.46535
Q Predictions Max            2963.6423
Q Predictions Min            279.8512
V Predictions Mean           2828.482
V Predictions Std            237.94542
V Predictions Max            2955.651
V Predictions Min            221.62486
Log Pis Mean                 -5.271383
Log Pis Std                  5.2914166
Log Pis Max                  35.590626
Log Pis Min                  -16.886429
Policy mu Mean               0.050841484
Policy mu Std                0.72743785
Policy mu Max                3.7113667
Policy mu Min                -3.3219733
Policy log std Mean          -0.2851682
Policy log std Std           0.115637735
Policy log std Max           -0.0029801428
Policy log std Min           -1.2338254
Z mean eval                  0.14836717
Z variance eval              0.055645704
total_rewards                [5608.54815766 5515.97090224 1125.60300605 4375.29927685 5502.74769536
 5567.90834944 5479.21730161 5448.02835899 5519.09710125 5598.40900699]
total_rewards_mean           4974.082915645953
total_rewards_std            1329.069292818032
total_rewards_max            5608.548157662751
total_rewards_min            1125.603006051964
Number of train steps total  1584000
Number of env steps total    2050000
Number of rollouts total     0
Train Time (s)               77.6800338900066
(Previous) Eval Time (s)     19.899945138953626
Sample Time (s)              6.185677929024678
Epoch Time (s)               103.7656569579849
Total Train Time (s)         57873.402460230805
Epoch                        395
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:23:07.376958 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #395 | Epoch Duration: 101.43587946891785
2020-01-06 12:23:07.377062 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #395 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1412957
Z variance train             0.09375469
KL Divergence                3.747776
KL Loss                      0.37477762
QF Loss                      887.3391
VF Loss                      345.80554
Policy Loss                  -2852.8464
Q Predictions Mean           2846.1707
Q Predictions Std            171.61797
Q Predictions Max            2962.2498
Q Predictions Min            1240.8876
V Predictions Mean           2847.5774
V Predictions Std            162.26668
V Predictions Max            2970.956
V Predictions Min            1440.4714
Log Pis Mean                 -4.932101
Log Pis Std                  5.4216933
Log Pis Max                  28.331444
Log Pis Min                  -15.245663
Policy mu Mean               0.050409347
Policy mu Std                0.73253715
Policy mu Max                2.9070814
Policy mu Min                -3.3939798
Policy log std Mean          -0.2809642
Policy log std Std           0.11224476
Policy log std Max           -0.068500414
Policy log std Min           -1.0411214
Z mean eval                  0.1198071
Z variance eval              0.079221405
total_rewards                [5407.83727815 5591.35222343 5511.18326171 5541.26420229 5592.45745226
 5575.96752965 5484.91076882 5525.61554136 5473.38710319 5463.83885822]
total_rewards_mean           5516.781421909339
total_rewards_std            57.50651779728753
total_rewards_max            5592.457452262366
total_rewards_min            5407.837278153228
Number of train steps total  1588000
Number of env steps total    2055000
Number of rollouts total     0
Train Time (s)               81.67658578202827
(Previous) Eval Time (s)     17.569938783999532
Sample Time (s)              6.290491675958037
Epoch Time (s)               105.53701624198584
Total Train Time (s)         57981.08857118781
Epoch                        396
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:24:55.065945 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #396 | Epoch Duration: 107.68880128860474
2020-01-06 12:24:55.066047 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #396 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09613971
Z variance train             0.07789177
KL Divergence                4.136007
KL Loss                      0.41360068
QF Loss                      817.45215
VF Loss                      464.9002
Policy Loss                  -2827.6528
Q Predictions Mean           2826.6025
Q Predictions Std            268.40952
Q Predictions Max            2962.6096
Q Predictions Min            123.93688
V Predictions Mean           2825.5044
V Predictions Std            256.29153
V Predictions Max            2968.3757
V Predictions Min            213.61514
Log Pis Mean                 -5.738329
Log Pis Std                  5.2342257
Log Pis Max                  38.372433
Log Pis Min                  -15.186499
Policy mu Mean               0.045889355
Policy mu Std                0.6968059
Policy mu Max                3.126934
Policy mu Min                -3.0319655
Policy log std Mean          -0.27217427
Policy log std Std           0.11867017
Policy log std Max           0.31203157
Policy log std Min           -1.2955952
Z mean eval                  0.1572698
Z variance eval              0.06629113
total_rewards                [5547.51365198 1010.77331469 4381.64529261 5550.99622677 5549.15065287
 5567.00749451 5659.25421726 5529.02507957 5482.73392362 5565.22775851]
total_rewards_mean           4984.332761240095
total_rewards_std            1370.666537288373
total_rewards_max            5659.254217262806
total_rewards_min            1010.7733146918357
Number of train steps total  1592000
Number of env steps total    2060000
Number of rollouts total     0
Train Time (s)               77.15951082803076
(Previous) Eval Time (s)     19.721502713975497
Sample Time (s)              6.113183339009993
Epoch Time (s)               102.99419688101625
Total Train Time (s)         58082.59757858084
Epoch                        397
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:26:36.577855 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #397 | Epoch Duration: 101.51172423362732
2020-01-06 12:26:36.577959 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #397 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.15334082
Z variance train             0.052505422
KL Divergence                5.093159
KL Loss                      0.5093159
QF Loss                      974.64246
VF Loss                      375.05777
Policy Loss                  -2853.8315
Q Predictions Mean           2851.2227
Q Predictions Std            117.27003
Q Predictions Max            2965.3362
Q Predictions Min            1656.133
V Predictions Mean           2851.4312
V Predictions Std            134.1039
V Predictions Max            2966.7258
V Predictions Min            1486.3081
Log Pis Mean                 -5.526304
Log Pis Std                  4.469473
Log Pis Max                  19.56512
Log Pis Min                  -15.563251
Policy mu Mean               0.049641214
Policy mu Std                0.7130344
Policy mu Max                2.8342445
Policy mu Min                -2.3654852
Policy log std Mean          -0.27282152
Policy log std Std           0.110858515
Policy log std Max           -0.04290866
Policy log std Min           -1.1371108
Z mean eval                  0.1391411
Z variance eval              0.04345047
total_rewards                [5370.16219442 5368.05725955 5405.5302768  2596.78174803 5355.49449458
 5476.31392951 5352.94830065 5410.62753031 5413.3610411  5419.97384172]
total_rewards_mean           5116.925061666769
total_rewards_std            840.7953623063838
total_rewards_max            5476.313929506372
total_rewards_min            2596.781748030058
Number of train steps total  1596000
Number of env steps total    2065188
Number of rollouts total     0
Train Time (s)               77.344595313014
(Previous) Eval Time (s)     18.238818423997145
Sample Time (s)              6.511887855944224
Epoch Time (s)               102.09530159295537
Total Train Time (s)         58184.89194366173
Epoch                        398
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:28:18.875122 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #398 | Epoch Duration: 102.29707956314087
2020-01-06 12:28:18.875226 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #398 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.15914579
Z variance train             0.0818944
KL Divergence                4.0599656
KL Loss                      0.40599656
QF Loss                      1379.1019
VF Loss                      417.54654
Policy Loss                  -2855.6738
Q Predictions Mean           2856.8757
Q Predictions Std            108.691055
Q Predictions Max            2985.3638
Q Predictions Min            2306.2798
V Predictions Mean           2864.1934
V Predictions Std            104.75171
V Predictions Max            2984.003
V Predictions Min            2319.499
Log Pis Mean                 -5.253212
Log Pis Std                  4.379146
Log Pis Max                  12.547261
Log Pis Min                  -14.229887
Policy mu Mean               0.060725242
Policy mu Std                0.7135401
Policy mu Max                2.461171
Policy mu Min                -2.7147949
Policy log std Mean          -0.28797537
Policy log std Std           0.11111065
Policy log std Max           0.07473736
Policy log std Min           -0.9431789
Z mean eval                  0.13586658
Z variance eval              0.0762619
total_rewards                [5469.25884061 5413.96691138 5392.53263773 5425.61083348 5412.99800997
 5529.68603633 5448.57374546 5468.09442854 1843.99468985 5363.00730992]
total_rewards_mean           5076.772344327014
total_rewards_std            1078.4928495432653
total_rewards_max            5529.6860363259475
total_rewards_min            1843.9946898486155
Number of train steps total  1600000
Number of env steps total    2070188
Number of rollouts total     0
Train Time (s)               77.64561585197225
(Previous) Eval Time (s)     18.44037515996024
Sample Time (s)              6.257303465041332
Epoch Time (s)               102.34329447697382
Total Train Time (s)         58287.046107912785
Epoch                        399
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:30:01.032201 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #399 | Epoch Duration: 102.15689039230347
2020-01-06 12:30:01.032305 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #399 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1443212
Z variance train             0.056413632
KL Divergence                4.923711
KL Loss                      0.49237108
QF Loss                      2116.8086
VF Loss                      796.59784
Policy Loss                  -2816.7852
Q Predictions Mean           2815.918
Q Predictions Std            334.5617
Q Predictions Max            2973.473
Q Predictions Min            205.26924
V Predictions Mean           2816.426
V Predictions Std            338.89624
V Predictions Max            2977.4146
V Predictions Min            211.22131
Log Pis Mean                 -5.008272
Log Pis Std                  4.6388383
Log Pis Max                  25.19899
Log Pis Min                  -14.830393
Policy mu Mean               0.068534814
Policy mu Std                0.7218274
Policy mu Max                2.4747946
Policy mu Min                -2.9678228
Policy log std Mean          -0.2751457
Policy log std Std           0.116936184
Policy log std Max           0.023714453
Policy log std Min           -1.0821673
Z mean eval                  0.120768264
Z variance eval              0.08748889
total_rewards                [5467.3180787  5458.23767057 5410.49301565 5374.24682818 5458.87313139
 5448.73626333 5438.01264457 5495.26443675 5396.29469173 5518.64424652]
total_rewards_mean           5446.612100738706
total_rewards_std            41.739105690197725
total_rewards_max            5518.644246522894
total_rewards_min            5374.246828181084
Number of train steps total  1604000
Number of env steps total    2075188
Number of rollouts total     0
Train Time (s)               77.42619683902012
(Previous) Eval Time (s)     18.253764013003092
Sample Time (s)              6.223306177940685
Epoch Time (s)               101.9032670299639
Total Train Time (s)         58389.86643836583
Epoch                        400
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:31:43.855452 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #400 | Epoch Duration: 102.82306432723999
2020-01-06 12:31:43.855557 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #400 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.18414912
Z variance train             0.056681704
KL Divergence                4.9556007
KL Loss                      0.49556008
QF Loss                      674.02405
VF Loss                      808.0879
Policy Loss                  -2848.7249
Q Predictions Mean           2839.9644
Q Predictions Std            227.52153
Q Predictions Max            2963.263
Q Predictions Min            454.67957
V Predictions Mean           2830.5781
V Predictions Std            231.08708
V Predictions Max            2971.7292
V Predictions Min            531.3232
Log Pis Mean                 -6.108441
Log Pis Std                  4.3979597
Log Pis Max                  14.880337
Log Pis Min                  -16.872498
Policy mu Mean               0.06807298
Policy mu Std                0.665612
Policy mu Max                2.3855276
Policy mu Min                -2.4492292
Policy log std Mean          -0.26438728
Policy log std Std           0.1051451
Policy log std Max           -0.018790096
Policy log std Min           -1.3664076
Z mean eval                  0.11233522
Z variance eval              0.06945018
total_rewards                [5420.17016656 5447.50507287 5437.5992949  5489.76196404 3587.10309524
 5429.22800025 5474.40732966 5325.60158695 4209.71501288 5303.69846614]
total_rewards_mean           5112.478998948435
total_rewards_std            625.3018949371881
total_rewards_max            5489.761964035481
total_rewards_min            3587.1030952429996
Number of train steps total  1608000
Number of env steps total    2080188
Number of rollouts total     0
Train Time (s)               74.46781773498515
(Previous) Eval Time (s)     19.173352462996263
Sample Time (s)              6.040356675919611
Epoch Time (s)               99.68152687390102
Total Train Time (s)         58488.39081341773
Epoch                        401
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:33:22.382749 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #401 | Epoch Duration: 98.52711200714111
2020-01-06 12:33:22.382850 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #401 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14175873
Z variance train             0.06402506
KL Divergence                4.6429367
KL Loss                      0.4642937
QF Loss                      856.1587
VF Loss                      482.13217
Policy Loss                  -2848.9836
Q Predictions Mean           2845.4116
Q Predictions Std            190.87294
Q Predictions Max            2959.8845
Q Predictions Min            526.2194
V Predictions Mean           2851.8242
V Predictions Std            203.0512
V Predictions Max            2983.6501
V Predictions Min            467.2062
Log Pis Mean                 -6.0017853
Log Pis Std                  4.336321
Log Pis Max                  18.794134
Log Pis Min                  -14.891099
Policy mu Mean               0.055930525
Policy mu Std                0.6776598
Policy mu Max                2.9662137
Policy mu Min                -2.6689258
Policy log std Mean          -0.25955552
Policy log std Std           0.103651464
Policy log std Max           -0.053770564
Policy log std Min           -0.9764496
Z mean eval                  0.2199882
Z variance eval              0.10641525
total_rewards                [5451.90793965 5355.6146156  5266.0809195  5389.2897976  5434.35806117
 5479.159327   5310.03540226 5531.57339767 5488.2302264  1224.35556633]
total_rewards_mean           4993.060525317769
total_rewards_std            1258.7040572384956
total_rewards_max            5531.573397671721
total_rewards_min            1224.3555663303591
Number of train steps total  1612000
Number of env steps total    2085188
Number of rollouts total     0
Train Time (s)               74.06638871500036
(Previous) Eval Time (s)     18.018730579991825
Sample Time (s)              6.0744072468951344
Epoch Time (s)               98.15952654188732
Total Train Time (s)         58586.564551713585
Epoch                        402
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:35:00.559594 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #402 | Epoch Duration: 98.17658257484436
2020-01-06 12:35:00.559694 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #402 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.18553197
Z variance train             0.064152375
KL Divergence                4.702278
KL Loss                      0.4702278
QF Loss                      879.49243
VF Loss                      284.63098
Policy Loss                  -2865.484
Q Predictions Mean           2864.2144
Q Predictions Std            180.6552
Q Predictions Max            2973.973
Q Predictions Min            345.7074
V Predictions Mean           2853.8857
V Predictions Std            178.90292
V Predictions Max            2963.4624
V Predictions Min            373.4729
Log Pis Mean                 -5.30134
Log Pis Std                  4.4397445
Log Pis Max                  16.104172
Log Pis Min                  -16.411015
Policy mu Mean               0.028006623
Policy mu Std                0.7280859
Policy mu Max                2.8719592
Policy mu Min                -2.4788306
Policy log std Mean          -0.2834482
Policy log std Std           0.111967795
Policy log std Max           -0.028653577
Policy log std Min           -1.0710459
Z mean eval                  0.1603495
Z variance eval              0.04606243
total_rewards                [1109.84044266 3464.74505547 5509.86942903 5587.25493278 5508.23032354
 5635.23253383 5593.13103024 4521.50249191 5480.09923866 5551.22567037]
total_rewards_mean           4796.113114849267
total_rewards_std            1394.8624819082054
total_rewards_max            5635.232533833173
total_rewards_min            1109.8404426620498
Number of train steps total  1616000
Number of env steps total    2090370
Number of rollouts total     0
Train Time (s)               74.2978469079826
(Previous) Eval Time (s)     18.03564399399329
Sample Time (s)              6.282597954093944
Epoch Time (s)               98.61608885606984
Total Train Time (s)         58684.29233440262
Epoch                        403
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:36:38.290523 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #403 | Epoch Duration: 97.73074221611023
2020-01-06 12:36:38.290666 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #403 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.13316059
Z variance train             0.05376477
KL Divergence                5.037103
KL Loss                      0.5037103
QF Loss                      740.90015
VF Loss                      233.5439
Policy Loss                  -2847.0806
Q Predictions Mean           2846.0815
Q Predictions Std            246.02164
Q Predictions Max            2971.402
Q Predictions Min            216.64499
V Predictions Mean           2845.9707
V Predictions Std            249.36324
V Predictions Max            2976.8037
V Predictions Min            237.94977
Log Pis Mean                 -5.8930235
Log Pis Std                  4.2024193
Log Pis Max                  25.02264
Log Pis Min                  -18.000853
Policy mu Mean               0.073215075
Policy mu Std                0.68630993
Policy mu Max                2.9169564
Policy mu Min                -3.206466
Policy log std Mean          -0.2720962
Policy log std Std           0.11433321
Policy log std Max           -0.048583366
Policy log std Min           -1.3852935
Z mean eval                  0.124331735
Z variance eval              0.063658945
total_rewards                [5356.24956234 5306.05917835 5345.61659358 5373.69297854 5355.02579945
 5284.45636067 5317.35626247 5276.06450411 5273.81242351 5393.42478878]
total_rewards_mean           5328.17584517967
total_rewards_std            40.41168710237119
total_rewards_max            5393.424788778033
total_rewards_min            5273.812423510093
Number of train steps total  1620000
Number of env steps total    2095370
Number of rollouts total     0
Train Time (s)               74.50762856495567
(Previous) Eval Time (s)     17.15007621998666
Sample Time (s)              6.120032322010957
Epoch Time (s)               97.77773710695328
Total Train Time (s)         58783.88672020048
Epoch                        404
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:38:17.887722 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #404 | Epoch Duration: 99.5969352722168
2020-01-06 12:38:17.887829 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #404 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.13318112
Z variance train             0.047823995
KL Divergence                5.316412
KL Loss                      0.5316412
QF Loss                      792.72876
VF Loss                      457.9468
Policy Loss                  -2850.3152
Q Predictions Mean           2848.2031
Q Predictions Std            198.55426
Q Predictions Max            2970.1292
Q Predictions Min            310.8795
V Predictions Mean           2851.1562
V Predictions Std            201.92126
V Predictions Max            2988.1477
V Predictions Min            290.77405
Log Pis Mean                 -5.3486176
Log Pis Std                  4.2234135
Log Pis Max                  12.003453
Log Pis Min                  -17.325712
Policy mu Mean               0.069762655
Policy mu Std                0.71638733
Policy mu Max                2.3088572
Policy mu Min                -3.6973732
Policy log std Mean          -0.27856007
Policy log std Std           0.10713748
Policy log std Max           -0.04258056
Policy log std Min           -0.89281493
Z mean eval                  0.15655072
Z variance eval              0.073191985
total_rewards                [5408.98054289 5428.46639996 5443.86329264 5432.59964878 3834.72067125
 5465.03152137 1626.3903051  5538.60295717 5575.69224439 1395.61473166]
total_rewards_mean           4514.9962315204775
total_rewards_std            1579.5948700985089
total_rewards_max            5575.692244393227
total_rewards_min            1395.614731662543
Number of train steps total  1624000
Number of env steps total    2100370
Number of rollouts total     0
Train Time (s)               74.62652046204312
(Previous) Eval Time (s)     18.969072577019688
Sample Time (s)              6.028232779877726
Epoch Time (s)               99.62382581894053
Total Train Time (s)         58879.567206584325
Epoch                        405
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:39:53.571132 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #405 | Epoch Duration: 95.68322229385376
2020-01-06 12:39:53.571233 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #405 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.13310888
Z variance train             0.059827566
KL Divergence                4.7895875
KL Loss                      0.47895876
QF Loss                      974.4734
VF Loss                      570.11145
Policy Loss                  -2863.5928
Q Predictions Mean           2854.713
Q Predictions Std            157.41498
Q Predictions Max            2975.056
Q Predictions Min            1409.4373
V Predictions Mean           2865.7488
V Predictions Std            159.64053
V Predictions Max            2982.7153
V Predictions Min            1538.3754
Log Pis Mean                 -5.630545
Log Pis Std                  5.0596237
Log Pis Max                  23.392986
Log Pis Min                  -14.896586
Policy mu Mean               0.08421661
Policy mu Std                0.7080715
Policy mu Max                3.5078592
Policy mu Min                -2.8288941
Policy log std Mean          -0.27750143
Policy log std Std           0.11285653
Policy log std Max           0.007841244
Policy log std Min           -1.1352259
Z mean eval                  0.112415984
Z variance eval              0.051840067
total_rewards                [5521.74864496 5484.87946428 5385.11006893 5498.31580605 5392.28545232
 5478.35037169 5547.78538271 5520.81282661 5282.15026021 5490.4656387 ]
total_rewards_mean           5460.1903916460205
total_rewards_std            77.71311193327003
total_rewards_max            5547.785382705012
total_rewards_min            5282.150260214683
Number of train steps total  1628000
Number of env steps total    2105370
Number of rollouts total     0
Train Time (s)               74.29127858200809
(Previous) Eval Time (s)     15.028262677020393
Sample Time (s)              5.891336265951395
Epoch Time (s)               95.21087752497988
Total Train Time (s)         58978.90594233945
Epoch                        406
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:41:32.913186 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #406 | Epoch Duration: 99.3418653011322
2020-01-06 12:41:32.913312 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #406 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.12565288
Z variance train             0.059564345
KL Divergence                4.7994766
KL Loss                      0.47994766
QF Loss                      903.37494
VF Loss                      416.57217
Policy Loss                  -2858.019
Q Predictions Mean           2853.1147
Q Predictions Std            221.9247
Q Predictions Max            2973.549
Q Predictions Min            267.94107
V Predictions Mean           2862.4685
V Predictions Std            221.86325
V Predictions Max            2994.2043
V Predictions Min            326.12604
Log Pis Mean                 -5.4978576
Log Pis Std                  4.913406
Log Pis Max                  40.73287
Log Pis Min                  -13.684729
Policy mu Mean               0.034415502
Policy mu Std                0.7161482
Policy mu Max                2.36954
Policy mu Min                -4.4660425
Policy log std Mean          -0.2791011
Policy log std Std           0.1171684
Policy log std Max           0.13010705
Policy log std Min           -1.4740453
Z mean eval                  0.113874815
Z variance eval              0.042989187
total_rewards                [5666.92887533 5698.8490005  5677.67607685 3576.08495825 5594.31474532
 4503.13399041 5546.40310866 5569.76199348 5499.43631077 5583.13335139]
total_rewards_mean           5291.57224109613
total_rewards_std            662.0099177591026
total_rewards_max            5698.849000502885
total_rewards_min            3576.0849582492283
Number of train steps total  1632000
Number of env steps total    2110370
Number of rollouts total     0
Train Time (s)               74.80186263797805
(Previous) Eval Time (s)     19.15904313203646
Sample Time (s)              5.93228340591304
Epoch Time (s)               99.89318917592755
Total Train Time (s)         59077.308380894305
Epoch                        407
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:43:11.318422 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #407 | Epoch Duration: 98.40502691268921
2020-01-06 12:43:11.318524 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #407 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.118895814
Z variance train             0.039351944
KL Divergence                5.7720127
KL Loss                      0.5772013
QF Loss                      631.0877
VF Loss                      212.18042
Policy Loss                  -2886.9883
Q Predictions Mean           2881.3213
Q Predictions Std            69.52329
Q Predictions Max            2977.1685
Q Predictions Min            2468.7651
V Predictions Mean           2882.7627
V Predictions Std            67.115005
V Predictions Max            2970.6204
V Predictions Min            2489.2656
Log Pis Mean                 -6.1706285
Log Pis Std                  3.4570696
Log Pis Max                  4.944337
Log Pis Min                  -13.698134
Policy mu Mean               0.06794617
Policy mu Std                0.6868775
Policy mu Max                2.2283568
Policy mu Min                -1.8110766
Policy log std Mean          -0.27146783
Policy log std Std           0.10556501
Policy log std Max           -0.043214224
Policy log std Min           -0.68710274
Z mean eval                  0.111775674
Z variance eval              0.04485753
total_rewards                [5417.76180414 5385.30740707 5472.58688966 1850.8997321  5412.64941269
 2710.11083704 5455.823501   5542.29040874 5496.00608734 5590.56343011]
total_rewards_mean           4833.399950989033
total_rewards_std            1292.1344704303306
total_rewards_max            5590.56343011337
total_rewards_min            1850.8997321046793
Number of train steps total  1636000
Number of env steps total    2115370
Number of rollouts total     0
Train Time (s)               75.47111855796538
(Previous) Eval Time (s)     17.67067565396428
Sample Time (s)              5.910783944069408
Epoch Time (s)               99.05257815599907
Total Train Time (s)         59175.39538511535
Epoch                        408
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:44:49.408493 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #408 | Epoch Duration: 98.08988618850708
2020-01-06 12:44:49.408597 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #408 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10119351
Z variance train             0.05644278
KL Divergence                4.8962674
KL Loss                      0.48962674
QF Loss                      1159.49
VF Loss                      603.0242
Policy Loss                  -2839.8682
Q Predictions Mean           2842.7456
Q Predictions Std            243.04912
Q Predictions Max            2969.7625
Q Predictions Min            408.8011
V Predictions Mean           2846.1104
V Predictions Std            254.68698
V Predictions Max            2979.7817
V Predictions Min            419.62506
Log Pis Mean                 -5.5005617
Log Pis Std                  4.4761314
Log Pis Max                  27.640032
Log Pis Min                  -14.229151
Policy mu Mean               0.06893881
Policy mu Std                0.7173035
Policy mu Max                3.0245564
Policy mu Min                -3.0808756
Policy log std Mean          -0.27025765
Policy log std Std           0.11942017
Policy log std Max           0.010066211
Policy log std Min           -1.1009734
Z mean eval                  0.10397297
Z variance eval              0.06175868
total_rewards                [5540.68902074 3087.45059077 2576.42175213 5466.76195668 2560.9687394
 5529.67621626 5550.03786643 5602.19514225 1737.04920499 4334.01681405]
total_rewards_mean           4198.526730368976
total_rewards_std            1469.8022523817112
total_rewards_max            5602.1951422460825
total_rewards_min            1737.049204987737
Number of train steps total  1640000
Number of env steps total    2120683
Number of rollouts total     0
Train Time (s)               74.85269693599548
(Previous) Eval Time (s)     16.70778907998465
Sample Time (s)              6.305942050006706
Epoch Time (s)               97.86642806598684
Total Train Time (s)         59270.944771892275
Epoch                        409
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:46:24.960867 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #409 | Epoch Duration: 95.55218601226807
2020-01-06 12:46:24.960973 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #409 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10967593
Z variance train             0.051551737
KL Divergence                5.1218367
KL Loss                      0.51218367
QF Loss                      1052.1581
VF Loss                      268.10257
Policy Loss                  -2861.6309
Q Predictions Mean           2863.6343
Q Predictions Std            168.3698
Q Predictions Max            2979.8877
Q Predictions Min            1155.9543
V Predictions Mean           2859.645
V Predictions Std            165.56331
V Predictions Max            2977.0107
V Predictions Min            1266.5072
Log Pis Mean                 -5.670083
Log Pis Std                  4.363839
Log Pis Max                  21.53025
Log Pis Min                  -14.715239
Policy mu Mean               0.06619818
Policy mu Std                0.7029076
Policy mu Max                3.0685616
Policy mu Min                -2.3988528
Policy log std Mean          -0.2777893
Policy log std Std           0.115780845
Policy log std Max           0.18425818
Policy log std Min           -1.1540102
Z mean eval                  0.10945921
Z variance eval              0.05020722
total_rewards                [5421.1060671  5605.36480713 3759.80538695 5447.02717623 5482.12017329
 5514.26818986 5449.0224264  5452.23641425 5467.90769554 5475.39613726]
total_rewards_mean           5307.425447402378
total_rewards_std            518.1311062016451
total_rewards_max            5605.364807131172
total_rewards_min            3759.8053869506143
Number of train steps total  1644000
Number of env steps total    2125855
Number of rollouts total     0
Train Time (s)               75.10307187598664
(Previous) Eval Time (s)     14.393341107002925
Sample Time (s)              6.166340737894643
Epoch Time (s)               95.66275372088421
Total Train Time (s)         59370.4139843061
Epoch                        410
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:48:04.433042 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #410 | Epoch Duration: 99.47198867797852
2020-01-06 12:48:04.433139 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #410 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10682039
Z variance train             0.06593986
KL Divergence                4.5390606
KL Loss                      0.45390606
QF Loss                      781.2877
VF Loss                      419.62668
Policy Loss                  -2862.1304
Q Predictions Mean           2850.4434
Q Predictions Std            227.85567
Q Predictions Max            2964.2651
Q Predictions Min            343.75156
V Predictions Mean           2859.057
V Predictions Std            231.95337
V Predictions Max            2983.4148
V Predictions Min            276.31387
Log Pis Mean                 -5.5776005
Log Pis Std                  4.483369
Log Pis Max                  20.89397
Log Pis Min                  -16.965633
Policy mu Mean               0.07796084
Policy mu Std                0.68850714
Policy mu Max                2.542016
Policy mu Min                -3.06923
Policy log std Mean          -0.27274242
Policy log std Std           0.11235564
Policy log std Max           -0.062094875
Policy log std Min           -1.2512217
Z mean eval                  0.114813946
Z variance eval              0.05888337
total_rewards                [2668.5359577  5336.9090565  1014.65817814 5501.30056115 5581.18375632
 5573.89900952 5516.02196044 5460.6237639  3739.6764476  5459.45814624]
total_rewards_mean           4585.2266837515
total_rewards_std            1513.5461583976921
total_rewards_max            5581.183756321238
total_rewards_min            1014.6581781378112
Number of train steps total  1648000
Number of env steps total    2130855
Number of rollouts total     0
Train Time (s)               75.04338396899402
(Previous) Eval Time (s)     18.202372261031996
Sample Time (s)              5.992955644032918
Epoch Time (s)               99.23871187405894
Total Train Time (s)         59467.20887432207
Epoch                        411
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:49:41.230931 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #411 | Epoch Duration: 96.79771137237549
2020-01-06 12:49:41.231030 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #411 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09254842
Z variance train             0.06937715
KL Divergence                4.418399
KL Loss                      0.4418399
QF Loss                      1071.302
VF Loss                      526.3392
Policy Loss                  -2870.1333
Q Predictions Mean           2876.028
Q Predictions Std            110.527084
Q Predictions Max            2978.31
Q Predictions Min            1866.201
V Predictions Mean           2883.384
V Predictions Std            109.066986
V Predictions Max            2991.4438
V Predictions Min            1885.1344
Log Pis Mean                 -5.985696
Log Pis Std                  4.350508
Log Pis Max                  20.151104
Log Pis Min                  -17.282381
Policy mu Mean               0.073567025
Policy mu Std                0.6790809
Policy mu Max                2.8937109
Policy mu Min                -2.5624413
Policy log std Mean          -0.26496455
Policy log std Std           0.10253132
Policy log std Max           -0.029166996
Policy log std Min           -0.9462705
Z mean eval                  0.13939409
Z variance eval              0.06327195
total_rewards                [5417.17204009 5383.87511083 5281.74750734 5378.73996296 5362.81039118
 5234.00180985 5461.80609281 5325.74746034 1820.03385932 5380.73458985]
total_rewards_mean           5004.666882456179
total_rewards_std            1063.339476240011
total_rewards_max            5461.806092811344
total_rewards_min            1820.0338593157396
Number of train steps total  1652000
Number of env steps total    2135855
Number of rollouts total     0
Train Time (s)               75.14055091497721
(Previous) Eval Time (s)     15.761157751025166
Sample Time (s)              6.000314486795105
Epoch Time (s)               96.90202315279748
Total Train Time (s)         59566.16306272504
Epoch                        412
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:51:20.188074 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #412 | Epoch Duration: 98.9569628238678
2020-01-06 12:51:20.188184 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #412 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.16498008
Z variance train             0.11124392
KL Divergence                3.385544
KL Loss                      0.3385544
QF Loss                      1050.8711
VF Loss                      266.70117
Policy Loss                  -2858.7898
Q Predictions Mean           2853.1125
Q Predictions Std            244.70908
Q Predictions Max            2982.576
Q Predictions Min            62.550926
V Predictions Mean           2860.8472
V Predictions Std            250.90465
V Predictions Max            2998.344
V Predictions Min            57.418476
Log Pis Mean                 -5.889968
Log Pis Std                  4.186497
Log Pis Max                  24.230934
Log Pis Min                  -12.741507
Policy mu Mean               0.059599582
Policy mu Std                0.69209486
Policy mu Max                3.2318823
Policy mu Min                -2.2810416
Policy log std Mean          -0.27944145
Policy log std Std           0.11650624
Policy log std Max           -0.064850524
Policy log std Min           -1.1020572
Z mean eval                  0.15307668
Z variance eval              0.08480144
total_rewards                [5453.10530281 5455.79485728 5452.01916328 5529.55867755 5372.43099827
 5525.29707958 5533.88822354 5554.58087574 5551.97050157 5413.94834167]
total_rewards_mean           5484.259402129547
total_rewards_std            59.998763511952646
total_rewards_max            5554.5808757429395
total_rewards_min            5372.430998267995
Number of train steps total  1656000
Number of env steps total    2140927
Number of rollouts total     0
Train Time (s)               75.50432626099791
(Previous) Eval Time (s)     17.81589236302534
Sample Time (s)              6.18830770108616
Epoch Time (s)               99.50852632510941
Total Train Time (s)         59666.56939569104
Epoch                        413
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:53:00.597424 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #413 | Epoch Duration: 100.40915560722351
2020-01-06 12:53:00.597524 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #413 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.112640835
Z variance train             0.06338258
KL Divergence                4.6415186
KL Loss                      0.46415186
QF Loss                      1156.2637
VF Loss                      935.0148
Policy Loss                  -2873.5154
Q Predictions Mean           2872.7712
Q Predictions Std            202.43207
Q Predictions Max            3002.0417
Q Predictions Min            243.30154
V Predictions Mean           2872.295
V Predictions Std            198.61241
V Predictions Max            2997.3394
V Predictions Min            266.1254
Log Pis Mean                 -5.8825264
Log Pis Std                  3.9681215
Log Pis Max                  20.34558
Log Pis Min                  -15.628744
Policy mu Mean               0.087341964
Policy mu Std                0.69107056
Policy mu Max                3.4403355
Policy mu Min                -2.329708
Policy log std Mean          -0.26881337
Policy log std Std           0.11233115
Policy log std Max           -0.01391384
Policy log std Min           -1.0456574
Z mean eval                  0.10489589
Z variance eval              0.0686904
total_rewards                [5309.88257992 5434.07975904 5223.63571901 5330.34856758 5342.92885385
 5382.70603255 5396.63976455 5305.06155217 5265.36899414 5391.38133726]
total_rewards_mean           5338.203316006999
total_rewards_std            61.50654085453149
total_rewards_max            5434.079759044685
total_rewards_min            5223.635719010076
Number of train steps total  1660000
Number of env steps total    2145927
Number of rollouts total     0
Train Time (s)               74.86452234699391
(Previous) Eval Time (s)     18.716315958998166
Sample Time (s)              5.834647923940793
Epoch Time (s)               99.41548622993287
Total Train Time (s)         59766.08087589394
Epoch                        414
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:54:40.111878 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #414 | Epoch Duration: 99.51425576210022
2020-01-06 12:54:40.111997 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #414 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.13474412
Z variance train             0.06555057
KL Divergence                4.576298
KL Loss                      0.45762983
QF Loss                      713.3338
VF Loss                      238.80318
Policy Loss                  -2862.0605
Q Predictions Mean           2855.013
Q Predictions Std            241.24013
Q Predictions Max            2967.0918
Q Predictions Min            167.02428
V Predictions Mean           2862.85
V Predictions Std            235.71715
V Predictions Max            2984.5503
V Predictions Min            214.18076
Log Pis Mean                 -5.421608
Log Pis Std                  4.1582513
Log Pis Max                  16.752014
Log Pis Min                  -16.335258
Policy mu Mean               0.077154174
Policy mu Std                0.7018612
Policy mu Max                2.5467489
Policy mu Min                -2.360878
Policy log std Mean          -0.27450815
Policy log std Std           0.108009994
Policy log std Max           -0.02435515
Policy log std Min           -0.90929663
Z mean eval                  0.1479215
Z variance eval              0.04148231
total_rewards                [5585.98129935 5518.25483047 5538.01331802 2646.4939626  5600.31061055
 5511.43618387 2860.99301344 5447.57088876 5627.79716263 5581.75915277]
total_rewards_mean           4991.861042246566
total_rewards_std            1121.1570854330707
total_rewards_max            5627.797162627507
total_rewards_min            2646.4939626009113
Number of train steps total  1664000
Number of env steps total    2150927
Number of rollouts total     0
Train Time (s)               74.95489414304029
(Previous) Eval Time (s)     18.81488535698736
Sample Time (s)              6.001867154031061
Epoch Time (s)               99.77164665405871
Total Train Time (s)         59863.92683183105
Epoch                        415
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:56:17.960820 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #415 | Epoch Duration: 97.84874033927917
2020-01-06 12:56:17.960928 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #415 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.12534443
Z variance train             0.07876581
KL Divergence                4.14608
KL Loss                      0.414608
QF Loss                      842.3651
VF Loss                      237.31512
Policy Loss                  -2874.7334
Q Predictions Mean           2866.2234
Q Predictions Std            178.65102
Q Predictions Max            2987.8462
Q Predictions Min            806.5861
V Predictions Mean           2873.749
V Predictions Std            173.59396
V Predictions Max            2993.0964
V Predictions Min            892.40753
Log Pis Mean                 -5.8406544
Log Pis Std                  4.6594787
Log Pis Max                  26.048733
Log Pis Min                  -14.780214
Policy mu Mean               0.07199402
Policy mu Std                0.7079616
Policy mu Max                3.9850125
Policy mu Min                -3.7972488
Policy log std Mean          -0.2750724
Policy log std Std           0.11062568
Policy log std Max           -0.01825121
Policy log std Min           -0.98640835
Z mean eval                  0.13610616
Z variance eval              0.061196268
total_rewards                [5375.61143293 5405.9780793  5305.89284155 5432.13827276 5410.50680557
 5411.71217477 5443.99068883 5386.28895908 5382.37706685 5443.28155229]
total_rewards_mean           5399.777787392901
total_rewards_std            38.82482915589006
total_rewards_max            5443.9906888324695
total_rewards_min            5305.892841546816
Number of train steps total  1668000
Number of env steps total    2155927
Number of rollouts total     0
Train Time (s)               74.8412710300181
(Previous) Eval Time (s)     16.891777358017862
Sample Time (s)              5.976677317055874
Epoch Time (s)               97.70972570509184
Total Train Time (s)         59963.5778963202
Epoch                        416
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:57:57.615165 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #416 | Epoch Duration: 99.65415358543396
2020-01-06 12:57:57.615281 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #416 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.17038295
Z variance train             0.085154556
KL Divergence                4.002269
KL Loss                      0.4002269
QF Loss                      662.3678
VF Loss                      270.95508
Policy Loss                  -2870.811
Q Predictions Mean           2868.0374
Q Predictions Std            204.41013
Q Predictions Max            2992.9614
Q Predictions Min            474.32098
V Predictions Mean           2865.7944
V Predictions Std            191.42406
V Predictions Max            2991.054
V Predictions Min            481.27692
Log Pis Mean                 -5.7415123
Log Pis Std                  4.1196485
Log Pis Max                  18.114285
Log Pis Min                  -13.336039
Policy mu Mean               0.048919305
Policy mu Std                0.6946709
Policy mu Max                2.48163
Policy mu Min                -1.9811924
Policy log std Mean          -0.27600378
Policy log std Std           0.11687366
Policy log std Max           -0.015028089
Policy log std Min           -0.9563329
Z mean eval                  0.11430375
Z variance eval              0.094120115
total_rewards                [5412.16561516 5457.9690749  5457.08164436 5343.45017111 5484.41292778
 5475.84087198 5440.06118254 5346.10535275 5433.2984612  4722.55356309]
total_rewards_mean           5357.29388648615
total_rewards_std            216.60006135385947
total_rewards_max            5484.4129277779175
total_rewards_min            4722.553563086123
Number of train steps total  1672000
Number of env steps total    2160927
Number of rollouts total     0
Train Time (s)               75.16071127197938
(Previous) Eval Time (s)     18.8360013650381
Sample Time (s)              6.122587239020504
Epoch Time (s)               100.11929987603799
Total Train Time (s)         60063.48566119716
Epoch                        417
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 12:59:37.525881 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #417 | Epoch Duration: 99.91051030158997
2020-01-06 12:59:37.525983 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #417 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.13046145
Z variance train             0.054690074
KL Divergence                5.0022993
KL Loss                      0.50022995
QF Loss                      686.9022
VF Loss                      358.81277
Policy Loss                  -2873.442
Q Predictions Mean           2871.2817
Q Predictions Std            200.3117
Q Predictions Max            2989.836
Q Predictions Min            374.0942
V Predictions Mean           2868.8135
V Predictions Std            205.99416
V Predictions Max            2994.066
V Predictions Min            379.31757
Log Pis Mean                 -5.8370094
Log Pis Std                  4.8411818
Log Pis Max                  37.197037
Log Pis Min                  -14.503284
Policy mu Mean               0.062444028
Policy mu Std                0.6991354
Policy mu Max                3.6309156
Policy mu Min                -3.330192
Policy log std Mean          -0.27695483
Policy log std Std           0.11537958
Policy log std Max           0.6097396
Policy log std Min           -1.3744837
Z mean eval                  0.10876773
Z variance eval              0.05820024
total_rewards                [5422.6199072  5413.39877232 5428.4682575  5327.87628066 5273.45362635
 5279.5751984  5326.7533542  5420.37938021 5421.67030143 1727.44540315]
total_rewards_mean           5004.16404814244
total_rewards_std            1093.812864645158
total_rewards_max            5428.468257498912
total_rewards_min            1727.4454031509908
Number of train steps total  1676000
Number of env steps total    2165927
Number of rollouts total     0
Train Time (s)               75.18442182504805
(Previous) Eval Time (s)     18.626995742029976
Sample Time (s)              5.915744582074694
Epoch Time (s)               99.72716214915272
Total Train Time (s)         60161.92026392225
Epoch                        418
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:01:15.963712 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #418 | Epoch Duration: 98.43764877319336
2020-01-06 13:01:15.963820 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #418 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09871986
Z variance train             0.0937214
KL Divergence                3.7291706
KL Loss                      0.37291706
QF Loss                      816.69275
VF Loss                      189.01114
Policy Loss                  -2877.9583
Q Predictions Mean           2876.671
Q Predictions Std            165.37125
Q Predictions Max            2992.4165
Q Predictions Min            903.388
V Predictions Mean           2879.1746
V Predictions Std            164.0099
V Predictions Max            2993.0437
V Predictions Min            918.83826
Log Pis Mean                 -6.277931
Log Pis Std                  4.5190697
Log Pis Max                  23.235569
Log Pis Min                  -17.715343
Policy mu Mean               0.04358164
Policy mu Std                0.66257226
Policy mu Max                2.8886907
Policy mu Min                -2.7350147
Policy log std Mean          -0.26032758
Policy log std Std           0.10394688
Policy log std Max           0.05443707
Policy log std Min           -0.9683522
Z mean eval                  0.10401591
Z variance eval              0.0694309
total_rewards                [5464.54366229 5495.97843936 5541.2555047  5555.64998067 5440.7657634
 5349.68390509 5536.63436063 5413.38464594 5461.34339483 3954.94967732]
total_rewards_mean           5321.41893342234
total_rewards_std            459.43258921289487
total_rewards_max            5555.649980672149
total_rewards_min            3954.949677317223
Number of train steps total  1680000
Number of env steps total    2170927
Number of rollouts total     0
Train Time (s)               75.28735296597006
(Previous) Eval Time (s)     17.3372701589833
Sample Time (s)              5.818478355067782
Epoch Time (s)               98.44310148002114
Total Train Time (s)         60261.41596319026
Epoch                        419
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:02:55.462379 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #419 | Epoch Duration: 99.49846959114075
2020-01-06 13:02:55.462479 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #419 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07362108
Z variance train             0.08010653
KL Divergence                4.070077
KL Loss                      0.4070077
QF Loss                      943.02563
VF Loss                      397.42096
Policy Loss                  -2856.4163
Q Predictions Mean           2852.8652
Q Predictions Std            278.02408
Q Predictions Max            3000.9734
Q Predictions Min            530.9524
V Predictions Mean           2847.9856
V Predictions Std            276.96695
V Predictions Max            3006.3904
V Predictions Min            540.8858
Log Pis Mean                 -5.4889727
Log Pis Std                  4.4065995
Log Pis Max                  26.574253
Log Pis Min                  -15.880514
Policy mu Mean               0.086708486
Policy mu Std                0.69570017
Policy mu Max                3.3685107
Policy mu Min                -2.7928164
Policy log std Mean          -0.27259034
Policy log std Std           0.11232673
Policy log std Max           0.036787093
Policy log std Min           -1.2961785
Z mean eval                  0.10660434
Z variance eval              0.06925338
total_rewards                [5331.41862865 5443.637787   5433.31220932 5382.48871072 2627.73482804
 2236.87777504 5543.60535333 5406.50647619 5546.43955934 5500.02166087]
total_rewards_mean           4845.204298850896
total_rewards_std            1211.3195867309496
total_rewards_max            5546.4395593396075
total_rewards_min            2236.8777750351383
Number of train steps total  1684000
Number of env steps total    2175927
Number of rollouts total     0
Train Time (s)               74.69049190398073
(Previous) Eval Time (s)     18.39243341801921
Sample Time (s)              6.003526809101459
Epoch Time (s)               99.0864521311014
Total Train Time (s)         60358.5034917593
Epoch                        420
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:04:32.552891 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #420 | Epoch Duration: 97.09032845497131
2020-01-06 13:04:32.552992 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #420 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.12901457
Z variance train             0.040208567
KL Divergence                5.725168
KL Loss                      0.57251686
QF Loss                      1058.4869
VF Loss                      1098.4144
Policy Loss                  -2877.7397
Q Predictions Mean           2876.321
Q Predictions Std            197.9474
Q Predictions Max            2989.6965
Q Predictions Min            356.0404
V Predictions Mean           2888.288
V Predictions Std            192.47496
V Predictions Max            3002.8074
V Predictions Min            387.83203
Log Pis Mean                 -6.2307367
Log Pis Std                  3.8708544
Log Pis Max                  12.205854
Log Pis Min                  -16.507381
Policy mu Mean               0.053166423
Policy mu Std                0.6586581
Policy mu Max                2.1665199
Policy mu Min                -2.5937314
Policy log std Mean          -0.26246148
Policy log std Std           0.1020279
Policy log std Max           0.036317244
Policy log std Min           -0.85299647
Z mean eval                  0.079446636
Z variance eval              0.086992934
total_rewards                [2742.45897673 5603.13046143 5561.502567   1774.14715138 2165.35022348
 5603.84211932 5451.46517034 5511.88041734 5608.8796193  5578.45888444]
total_rewards_mean           4560.111559074783
total_rewards_std            1543.298650566237
total_rewards_max            5608.879619295634
total_rewards_min            1774.1471513782237
Number of train steps total  1688000
Number of env steps total    2180927
Number of rollouts total     0
Train Time (s)               74.380083800992
(Previous) Eval Time (s)     16.39610543102026
Sample Time (s)              6.139738101977855
Epoch Time (s)               96.91592733399011
Total Train Time (s)         60454.66261545033
Epoch                        421
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:06:08.714988 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #421 | Epoch Duration: 96.16191363334656
2020-01-06 13:06:08.715092 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #421 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08553026
Z variance train             0.07418996
KL Divergence                4.2569547
KL Loss                      0.42569548
QF Loss                      550.8667
VF Loss                      374.74207
Policy Loss                  -2878.1528
Q Predictions Mean           2868.93
Q Predictions Std            235.13757
Q Predictions Max            3013.9163
Q Predictions Min            593.57904
V Predictions Mean           2871.1758
V Predictions Std            230.3595
V Predictions Max            3009.978
V Predictions Min            586.4929
Log Pis Mean                 -5.605395
Log Pis Std                  4.3935795
Log Pis Max                  33.97895
Log Pis Min                  -12.8039875
Policy mu Mean               0.07293163
Policy mu Std                0.69744664
Policy mu Max                4.3051214
Policy mu Min                -2.7781372
Policy log std Mean          -0.2742025
Policy log std Std           0.111828364
Policy log std Max           -0.032595925
Policy log std Min           -0.99446404
Z mean eval                  0.106484935
Z variance eval              0.052811176
total_rewards                [5501.75652886 1212.16835583 5493.71904204 5557.5539851  5486.67628349
 1849.06618478 5497.60734301 1821.14864653 5499.31047479 5653.81719027]
total_rewards_mean           4357.28240346938
total_rewards_std            1794.935336030634
total_rewards_max            5653.817190271882
total_rewards_min            1212.1683558316588
Number of train steps total  1692000
Number of env steps total    2185927
Number of rollouts total     0
Train Time (s)               75.57050934899598
(Previous) Eval Time (s)     15.641884727985598
Sample Time (s)              6.047723791038152
Epoch Time (s)               97.26011786801973
Total Train Time (s)         60551.52887756331
Epoch                        422
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:07:45.585807 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #422 | Epoch Duration: 96.87062525749207
2020-01-06 13:07:45.585944 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #422 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10147792
Z variance train             0.053040303
KL Divergence                5.0511503
KL Loss                      0.50511503
QF Loss                      1176.7069
VF Loss                      362.24722
Policy Loss                  -2893.6594
Q Predictions Mean           2882.498
Q Predictions Std            150.09265
Q Predictions Max            2993.8032
Q Predictions Min            1144.2472
V Predictions Mean           2887.8042
V Predictions Std            151.24104
V Predictions Max            2989.2656
V Predictions Min            1225.1328
Log Pis Mean                 -5.8373256
Log Pis Std                  4.582309
Log Pis Max                  24.201363
Log Pis Min                  -14.112421
Policy mu Mean               0.057169423
Policy mu Std                0.6881667
Policy mu Max                2.6718254
Policy mu Min                -2.6078403
Policy log std Mean          -0.2732109
Policy log std Std           0.10198455
Policy log std Max           -0.07370035
Policy log std Min           -0.9340485
Z mean eval                  0.12672845
Z variance eval              0.06263641
total_rewards                [5557.89619275 5432.25067053 5453.69940635 5420.67159192 5512.81635625
 5573.35624577 5438.9254544  5500.27805384 5427.90689276 5491.10899931]
total_rewards_mean           5480.890986388208
total_rewards_std            52.22947375582763
total_rewards_max            5573.356245770787
total_rewards_min            5420.671591915292
Number of train steps total  1696000
Number of env steps total    2190927
Number of rollouts total     0
Train Time (s)               75.33893613098189
(Previous) Eval Time (s)     15.25218833598774
Sample Time (s)              6.123183704854455
Epoch Time (s)               96.71430817182409
Total Train Time (s)         60652.08810655214
Epoch                        423
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:09:26.147590 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #423 | Epoch Duration: 100.56154537200928
2020-01-06 13:09:26.147688 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #423 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09894139
Z variance train             0.061670065
KL Divergence                4.6948986
KL Loss                      0.46948987
QF Loss                      1048.2949
VF Loss                      297.40173
Policy Loss                  -2877.4473
Q Predictions Mean           2870.6226
Q Predictions Std            238.84818
Q Predictions Max            3002.2852
Q Predictions Min            632.3752
V Predictions Mean           2879.5322
V Predictions Std            242.72557
V Predictions Max            3011.6152
V Predictions Min            578.6198
Log Pis Mean                 -5.7508507
Log Pis Std                  4.4801683
Log Pis Max                  28.69101
Log Pis Min                  -15.7259655
Policy mu Mean               0.036716603
Policy mu Std                0.7011941
Policy mu Max                3.0614183
Policy mu Min                -2.9064636
Policy log std Mean          -0.27843627
Policy log std Std           0.11403877
Policy log std Max           0.27192202
Policy log std Min           -1.0654798
Z mean eval                  0.09232392
Z variance eval              0.07658048
total_rewards                [5482.32437237 4336.3101457  5555.12477495 5501.23450816 3659.55013512
 1370.20803    5425.66152028 5458.1187429  5493.37444243 5410.74207287]
total_rewards_mean           4769.264874477905
total_rewards_std            1283.5699076550763
total_rewards_max            5555.1247749537715
total_rewards_min            1370.2080299985907
Number of train steps total  1700000
Number of env steps total    2196104
Number of rollouts total     0
Train Time (s)               76.17327814101009
(Previous) Eval Time (s)     19.09922746598022
Sample Time (s)              6.150562467053533
Epoch Time (s)               101.42306807404384
Total Train Time (s)         60751.003596056195
Epoch                        424
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:11:05.066526 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #424 | Epoch Duration: 98.91875648498535
2020-01-06 13:11:05.066631 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #424 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.16027357
Z variance train             0.0505557
KL Divergence                5.2097893
KL Loss                      0.5209789
QF Loss                      616.2925
VF Loss                      149.64445
Policy Loss                  -2892.6687
Q Predictions Mean           2898.7388
Q Predictions Std            173.63962
Q Predictions Max            3007.373
Q Predictions Min            1037.4209
V Predictions Mean           2896.3037
V Predictions Std            175.80986
V Predictions Max            2999.5774
V Predictions Min            977.79395
Log Pis Mean                 -6.244478
Log Pis Std                  4.5597525
Log Pis Max                  19.994043
Log Pis Min                  -15.891813
Policy mu Mean               0.06913961
Policy mu Std                0.69391876
Policy mu Max                2.6603665
Policy mu Min                -3.333604
Policy log std Mean          -0.2643383
Policy log std Std           0.10581113
Policy log std Max           -0.056765273
Policy log std Min           -1.0278112
Z mean eval                  0.13640521
Z variance eval              0.059648693
total_rewards                [5373.85891324 5280.97325158 2954.54779786 5356.15561171 5239.12586152
 5351.96819497 5343.16833244 5363.74627023 2585.92063612 5306.4214875 ]
total_rewards_mean           4815.58863571668
total_rewards_std            1026.7509151626948
total_rewards_max            5373.858913244988
total_rewards_min            2585.920636119392
Number of train steps total  1704000
Number of env steps total    2201288
Number of rollouts total     0
Train Time (s)               78.5194713230012
(Previous) Eval Time (s)     16.59471258998383
Sample Time (s)              6.174350697081536
Epoch Time (s)               101.28853461006656
Total Train Time (s)         60853.09802023228
Epoch                        425
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:12:47.163926 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #425 | Epoch Duration: 102.09720635414124
2020-01-06 13:12:47.164029 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #425 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11316179
Z variance train             0.059628528
KL Divergence                4.782855
KL Loss                      0.47828552
QF Loss                      978.2936
VF Loss                      378.35962
Policy Loss                  -2882.336
Q Predictions Mean           2882.8079
Q Predictions Std            201.73138
Q Predictions Max            2997.3223
Q Predictions Min            420.28314
V Predictions Mean           2893.6084
V Predictions Std            202.55382
V Predictions Max            3013.3992
V Predictions Min            372.12936
Log Pis Mean                 -6.147984
Log Pis Std                  4.7811775
Log Pis Max                  29.85496
Log Pis Min                  -15.57001
Policy mu Mean               0.07058802
Policy mu Std                0.67988455
Policy mu Max                3.0930202
Policy mu Min                -2.4791806
Policy log std Mean          -0.2643432
Policy log std Std           0.107770495
Policy log std Max           -0.03906429
Policy log std Min           -1.115887
Z mean eval                  0.116737664
Z variance eval              0.053717088
total_rewards                [5424.11171292 5282.09054961 5366.42552299 5376.80407481 5299.31738683
 5285.85184594 5467.48457699 5384.75197697 5294.90877921 5164.44904049]
total_rewards_mean           5334.619546676532
total_rewards_std            82.39244631455624
total_rewards_max            5467.484576994055
total_rewards_min            5164.449040491708
Number of train steps total  1708000
Number of env steps total    2206288
Number of rollouts total     0
Train Time (s)               89.10953447397333
(Previous) Eval Time (s)     17.403184268041514
Sample Time (s)              6.086080648005009
Epoch Time (s)               112.59879939001985
Total Train Time (s)         60967.457379817264
Epoch                        426
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:14:41.526300 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #426 | Epoch Duration: 114.36218929290771
2020-01-06 13:14:41.526400 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #426 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11764743
Z variance train             0.05347812
KL Divergence                5.043088
KL Loss                      0.5043088
QF Loss                      2506.4814
VF Loss                      1366.3179
Policy Loss                  -2882.1455
Q Predictions Mean           2877.7683
Q Predictions Std            186.27208
Q Predictions Max            2989.6567
Q Predictions Min            390.33768
V Predictions Mean           2885.9033
V Predictions Std            186.3616
V Predictions Max            3007.1887
V Predictions Min            364.52057
Log Pis Mean                 -5.592806
Log Pis Std                  4.185069
Log Pis Max                  15.82045
Log Pis Min                  -14.976143
Policy mu Mean               0.07166293
Policy mu Std                0.6957576
Policy mu Max                2.3386378
Policy mu Min                -2.6561482
Policy log std Mean          -0.27573496
Policy log std Std           0.11209829
Policy log std Max           -0.051954873
Policy log std Min           -1.034301
Z mean eval                  0.2359703
Z variance eval              0.12861502
total_rewards                [5361.9264688  5424.18038607 5500.11184479 5517.12607646 5512.23150435
 5349.78816256 5416.44829159 5599.73383582 5431.74108801 5495.87921219]
total_rewards_mean           5460.9166870658255
total_rewards_std            73.58557408168068
total_rewards_max            5599.733835824636
total_rewards_min            5349.788162561834
Number of train steps total  1712000
Number of env steps total    2211288
Number of rollouts total     0
Train Time (s)               77.07297343097162
(Previous) Eval Time (s)     19.166371366998646
Sample Time (s)              6.021320200117771
Epoch Time (s)               102.26066499808803
Total Train Time (s)         61069.390774971456
Epoch                        427
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:16:23.462772 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #427 | Epoch Duration: 101.93629217147827
2020-01-06 13:16:23.462871 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #427 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.15552334
Z variance train             0.05622827
KL Divergence                4.9495134
KL Loss                      0.49495134
QF Loss                      746.58044
VF Loss                      410.54068
Policy Loss                  -2880.287
Q Predictions Mean           2874.592
Q Predictions Std            254.40637
Q Predictions Max            2994.2312
Q Predictions Min            60.5659
V Predictions Mean           2875.9556
V Predictions Std            250.96317
V Predictions Max            3001.5706
V Predictions Min            112.27471
Log Pis Mean                 -5.454098
Log Pis Std                  4.727518
Log Pis Max                  17.828272
Log Pis Min                  -16.319769
Policy mu Mean               0.07130295
Policy mu Std                0.7015607
Policy mu Max                2.8543756
Policy mu Min                -2.4050121
Policy log std Mean          -0.28137252
Policy log std Std           0.11503471
Policy log std Max           -0.05497849
Policy log std Min           -0.98751175
Z mean eval                  0.12436658
Z variance eval              0.07601321
total_rewards                [5624.06874711 5513.20508132 5589.58680706 4451.73651373 5564.32913169
 5540.46005252 5503.39317538 5557.32813903 5498.83109077 5619.72902898]
total_rewards_mean           5446.266776758775
total_rewards_std            334.2135031627763
total_rewards_max            5624.068747110433
total_rewards_min            4451.736513727079
Number of train steps total  1716000
Number of env steps total    2216288
Number of rollouts total     0
Train Time (s)               76.83269017096609
(Previous) Eval Time (s)     18.841795210028067
Sample Time (s)              5.896150417916942
Epoch Time (s)               101.5706357989111
Total Train Time (s)         61170.71259461745
Epoch                        428
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:18:04.787713 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #428 | Epoch Duration: 101.32474875450134
2020-01-06 13:18:04.787812 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #428 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1380138
Z variance train             0.04412403
KL Divergence                5.507925
KL Loss                      0.5507925
QF Loss                      472.71454
VF Loss                      180.25606
Policy Loss                  -2908.0605
Q Predictions Mean           2906.8647
Q Predictions Std            83.36661
Q Predictions Max            3002.0603
Q Predictions Min            2224.4172
V Predictions Mean           2910.7886
V Predictions Std            83.513916
V Predictions Max            3016.739
V Predictions Min            2274.277
Log Pis Mean                 -6.5682926
Log Pis Std                  3.4287932
Log Pis Max                  13.120897
Log Pis Min                  -17.380524
Policy mu Mean               0.06395835
Policy mu Std                0.65638417
Policy mu Max                2.0994983
Policy mu Min                -2.790048
Policy log std Mean          -0.2519027
Policy log std Std           0.09785587
Policy log std Max           -0.056570724
Policy log std Min           -0.7381384
Z mean eval                  0.1321641
Z variance eval              0.067432
total_rewards                [5535.47039226 4263.87274021 5538.89442826 5658.7911187  5533.95108656
 5496.47604355 3259.5412651  2814.34854644 5440.72086009 5569.8522643 ]
total_rewards_mean           4911.191874547824
total_rewards_std            1016.4144619020298
total_rewards_max            5658.7911186982055
total_rewards_min            2814.348546443666
Number of train steps total  1720000
Number of env steps total    2221288
Number of rollouts total     0
Train Time (s)               77.54235431103734
(Previous) Eval Time (s)     18.595704315055627
Sample Time (s)              5.865220334031619
Epoch Time (s)               102.00327896012459
Total Train Time (s)         61270.73218836443
Epoch                        429
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:19:44.810394 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #429 | Epoch Duration: 100.02250289916992
2020-01-06 13:19:44.810525 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #429 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11657157
Z variance train             0.05916518
KL Divergence                4.7989397
KL Loss                      0.47989398
QF Loss                      981.4661
VF Loss                      428.2807
Policy Loss                  -2883.1157
Q Predictions Mean           2878.2297
Q Predictions Std            145.58324
Q Predictions Max            3010.4788
Q Predictions Min            1326.8093
V Predictions Mean           2885.0242
V Predictions Std            133.54266
V Predictions Max            3015.4956
V Predictions Min            1478.317
Log Pis Mean                 -5.6395802
Log Pis Std                  4.494489
Log Pis Max                  23.432495
Log Pis Min                  -14.673366
Policy mu Mean               0.08473635
Policy mu Std                0.70332116
Policy mu Max                2.484323
Policy mu Min                -3.0334823
Policy log std Mean          -0.2786953
Policy log std Std           0.11227547
Policy log std Max           -0.08987729
Policy log std Min           -1.3268611
Z mean eval                  0.14965627
Z variance eval              0.06032164
total_rewards                [3532.58461323 5618.22547647 5545.92329106 5590.49626058 5577.9444166
 3979.86107662 5461.06255095 5517.4019626  5533.18593438 2417.69644668]
total_rewards_mean           4877.438202917694
total_rewards_std            1088.0983553917258
total_rewards_max            5618.225476465263
total_rewards_min            2417.6964466823083
Number of train steps total  1724000
Number of env steps total    2226288
Number of rollouts total     0
Train Time (s)               75.15577598597156
(Previous) Eval Time (s)     16.614724491955712
Sample Time (s)              5.869516302016564
Epoch Time (s)               97.64001677994383
Total Train Time (s)         61368.565993751574
Epoch                        430
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:21:22.648848 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #430 | Epoch Duration: 97.83820700645447
2020-01-06 13:21:22.648988 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #430 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10652797
Z variance train             0.07704324
KL Divergence                4.1719437
KL Loss                      0.41719437
QF Loss                      881.2615
VF Loss                      319.7705
Policy Loss                  -2904.9827
Q Predictions Mean           2903.3853
Q Predictions Std            136.63239
Q Predictions Max            3027.74
Q Predictions Min            1575.0264
V Predictions Mean           2901.4138
V Predictions Std            137.2183
V Predictions Max            3026.9019
V Predictions Min            1496.7495
Log Pis Mean                 -5.7072744
Log Pis Std                  4.3619266
Log Pis Max                  27.378456
Log Pis Min                  -13.76905
Policy mu Mean               0.043100573
Policy mu Std                0.687975
Policy mu Max                3.8507636
Policy mu Min                -3.25621
Policy log std Mean          -0.27273363
Policy log std Std           0.11059353
Policy log std Max           -0.08388497
Policy log std Min           -1.1015129
Z mean eval                  0.090790614
Z variance eval              0.09075663
total_rewards                [5523.20530144 5523.96729504 1362.4386119   447.18063476 1785.55469207
 5464.32649152 5495.02544318 5660.72229235 5499.96887222 5588.03424153]
total_rewards_mean           4235.042387600547
total_rewards_std            2012.0217707219488
total_rewards_max            5660.7222923538
total_rewards_min            447.18063475573507
Number of train steps total  1728000
Number of env steps total    2231288
Number of rollouts total     0
Train Time (s)               75.55352544499328
(Previous) Eval Time (s)     16.81271186802769
Sample Time (s)              5.856893862073775
Epoch Time (s)               98.22313117509475
Total Train Time (s)         61464.3179398026
Epoch                        431
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:22:58.404449 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #431 | Epoch Duration: 95.75533723831177
2020-01-06 13:22:58.404590 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #431 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.13405617
Z variance train             0.16242175
KL Divergence                2.557332
KL Loss                      0.25573322
QF Loss                      1173.4915
VF Loss                      274.23996
Policy Loss                  -2887.7964
Q Predictions Mean           2880.0627
Q Predictions Std            234.29497
Q Predictions Max            3017.183
Q Predictions Min            223.52959
V Predictions Mean           2880.0771
V Predictions Std            233.3523
V Predictions Max            3007.8997
V Predictions Min            222.5549
Log Pis Mean                 -5.9282603
Log Pis Std                  4.056953
Log Pis Max                  14.161617
Log Pis Min                  -17.30479
Policy mu Mean               0.06490806
Policy mu Std                0.6868987
Policy mu Max                2.151044
Policy mu Min                -3.018647
Policy log std Mean          -0.28455812
Policy log std Std           0.110678166
Policy log std Max           0.0023101792
Policy log std Min           -0.8968849
Z mean eval                  0.04578032
Z variance eval              0.09112437
total_rewards                [5476.9644386  5354.05351497 5424.91490908 5357.98594703 3458.64357343
 5435.82665829 5347.838784   5484.92934304 5404.21389905 5395.26136576]
total_rewards_mean           5214.0632433260935
total_rewards_std            586.9257265265605
total_rewards_max            5484.929343036382
total_rewards_min            3458.643573434513
Number of train steps total  1732000
Number of env steps total    2236288
Number of rollouts total     0
Train Time (s)               75.59351528499974
(Previous) Eval Time (s)     14.344709416967817
Sample Time (s)              6.056478410901036
Epoch Time (s)               95.99470311286859
Total Train Time (s)         61564.2930830025
Epoch                        432
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:24:38.382591 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #432 | Epoch Duration: 99.97788834571838
2020-01-06 13:24:38.382701 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #432 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04480601
Z variance train             0.1473
KL Divergence                2.702757
KL Loss                      0.27027568
QF Loss                      1124.5775
VF Loss                      716.1302
Policy Loss                  -2883.05
Q Predictions Mean           2879.5293
Q Predictions Std            207.58208
Q Predictions Max            3023.8154
Q Predictions Min            688.0713
V Predictions Mean           2874.7021
V Predictions Std            211.09935
V Predictions Max            3015.9844
V Predictions Min            663.09314
Log Pis Mean                 -5.9690623
Log Pis Std                  4.061984
Log Pis Max                  15.008484
Log Pis Min                  -18.977598
Policy mu Mean               0.07004091
Policy mu Std                0.6872799
Policy mu Max                2.5258076
Policy mu Min                -3.1489325
Policy log std Mean          -0.26110476
Policy log std Std           0.11136935
Policy log std Max           0.009227581
Policy log std Min           -1.0626754
Z mean eval                  0.07445232
Z variance eval              0.07696881
total_rewards                [5590.10355316 5446.33535803 5542.023192   5493.78242177 5559.20064434
 5613.14686106 5565.63494215 5576.58949987 5476.71917308 5554.56490445]
total_rewards_mean           5541.810054991532
total_rewards_std            50.32146195338313
total_rewards_max            5613.146861062172
total_rewards_min            5446.335358025705
Number of train steps total  1736000
Number of env steps total    2241288
Number of rollouts total     0
Train Time (s)               75.6108909950126
(Previous) Eval Time (s)     18.327685400028713
Sample Time (s)              6.025471548025962
Epoch Time (s)               99.96404794306727
Total Train Time (s)         61663.87925820658
Epoch                        433
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:26:17.971852 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #433 | Epoch Duration: 99.5890634059906
2020-01-06 13:26:17.971961 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #433 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.117997505
Z variance train             0.084083304
KL Divergence                3.9798322
KL Loss                      0.39798322
QF Loss                      1099.1558
VF Loss                      562.90454
Policy Loss                  -2914.4744
Q Predictions Mean           2913.3635
Q Predictions Std            113.91001
Q Predictions Max            3011.0427
Q Predictions Min            2002.2382
V Predictions Mean           2909.7764
V Predictions Std            122.45174
V Predictions Max            3014.3774
V Predictions Min            1839.2834
Log Pis Mean                 -5.602681
Log Pis Std                  4.430312
Log Pis Max                  15.303563
Log Pis Min                  -14.853878
Policy mu Mean               0.090484016
Policy mu Std                0.6891268
Policy mu Max                2.4561033
Policy mu Min                -2.600994
Policy log std Mean          -0.27533403
Policy log std Std           0.11216414
Policy log std Max           -0.071730584
Policy log std Min           -1.0295594
Z mean eval                  0.11597009
Z variance eval              0.10861675
total_rewards                [5454.77117116 5516.01738195 1363.94951769 5569.86495056 5518.79285665
 5314.74837617 5471.51320847 5473.54838439 5445.90497395 5500.95622874]
total_rewards_mean           5063.006704972062
total_rewards_std            1234.648744181922
total_rewards_max            5569.8649505645135
total_rewards_min            1363.9495176890832
Number of train steps total  1740000
Number of env steps total    2246288
Number of rollouts total     0
Train Time (s)               77.17313889501384
(Previous) Eval Time (s)     17.95249923900701
Sample Time (s)              5.821935925050639
Epoch Time (s)               100.94757405907148
Total Train Time (s)         61763.17325477052
Epoch                        434
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:27:57.268952 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #434 | Epoch Duration: 99.29690933227539
2020-01-06 13:27:57.269054 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #434 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07587009
Z variance train             0.21131042
KL Divergence                1.9752785
KL Loss                      0.19752786
QF Loss                      901.88666
VF Loss                      373.76117
Policy Loss                  -2888.29
Q Predictions Mean           2882.7896
Q Predictions Std            206.15831
Q Predictions Max            2998.1558
Q Predictions Min            442.29303
V Predictions Mean           2900.8328
V Predictions Std            215.94882
V Predictions Max            3027.3901
V Predictions Min            438.05228
Log Pis Mean                 -5.722137
Log Pis Std                  4.0814605
Log Pis Max                  15.106079
Log Pis Min                  -14.485324
Policy mu Mean               0.063874274
Policy mu Std                0.6841363
Policy mu Max                3.287045
Policy mu Min                -2.1315675
Policy log std Mean          -0.27687332
Policy log std Std           0.10481922
Policy log std Max           -0.0042511523
Policy log std Min           -0.91493374
Z mean eval                  0.2375956
Z variance eval              0.12147313
total_rewards                [5398.63632405 5414.68874181 5429.20359958 5418.03031157 5457.81669331
 5551.65120899 5379.87940152 5423.01717282 5571.29684371 5203.99043159]
total_rewards_mean           5424.821072894856
total_rewards_std            95.01186874810672
total_rewards_max            5571.296843711527
total_rewards_min            5203.990431589928
Number of train steps total  1744000
Number of env steps total    2251409
Number of rollouts total     0
Train Time (s)               77.74257320101606
(Previous) Eval Time (s)     16.301629658963066
Sample Time (s)              5.830938643950503
Epoch Time (s)               99.87514150392963
Total Train Time (s)         61865.792704917374
Epoch                        435
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:29:39.891494 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #435 | Epoch Duration: 102.6223554611206
2020-01-06 13:29:39.891599 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #435 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.19329752
Z variance train             0.10827428
KL Divergence                3.488078
KL Loss                      0.3488078
QF Loss                      584.12036
VF Loss                      226.38667
Policy Loss                  -2887.2222
Q Predictions Mean           2884.8733
Q Predictions Std            285.4132
Q Predictions Max            3020.1519
Q Predictions Min            301.13705
V Predictions Mean           2891.4126
V Predictions Std            286.16556
V Predictions Max            3031.4302
V Predictions Min            316.41055
Log Pis Mean                 -6.244788
Log Pis Std                  4.0485106
Log Pis Max                  19.501974
Log Pis Min                  -15.955578
Policy mu Mean               0.0781984
Policy mu Std                0.6647409
Policy mu Max                2.4153278
Policy mu Min                -3.0324712
Policy log std Mean          -0.2653513
Policy log std Std           0.10113435
Policy log std Max           0.32771462
Policy log std Min           -0.8335474
Z mean eval                  0.1702538
Z variance eval              0.08380647
total_rewards                [5448.84175362 5458.67610172 5520.58770173 5532.51486285 5456.51404864
 5483.75092493 5337.26598332 5505.76373963 5438.00692767 5469.5149805 ]
total_rewards_mean           5465.143702461578
total_rewards_std            52.05708832206066
total_rewards_max            5532.514862851909
total_rewards_min            5337.265983320006
Number of train steps total  1748000
Number of env steps total    2256409
Number of rollouts total     0
Train Time (s)               74.53258972900221
(Previous) Eval Time (s)     19.04863713600207
Sample Time (s)              6.200334255059715
Epoch Time (s)               99.781561120064
Total Train Time (s)         61965.51908648247
Epoch                        436
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:31:19.621368 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #436 | Epoch Duration: 99.7296884059906
2020-01-06 13:31:19.621469 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #436 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.15758851
Z variance train             0.12087786
KL Divergence                3.1916113
KL Loss                      0.31916115
QF Loss                      605.8798
VF Loss                      143.5805
Policy Loss                  -2902.798
Q Predictions Mean           2903.632
Q Predictions Std            184.05737
Q Predictions Max            3026.9631
Q Predictions Min            837.6846
V Predictions Mean           2903.6714
V Predictions Std            186.17802
V Predictions Max            3025.1326
V Predictions Min            755.6512
Log Pis Mean                 -6.168516
Log Pis Std                  3.4603665
Log Pis Max                  5.4546576
Log Pis Min                  -15.990182
Policy mu Mean               0.04849671
Policy mu Std                0.66014034
Policy mu Max                2.611059
Policy mu Min                -2.2029104
Policy log std Mean          -0.26635534
Policy log std Std           0.10196551
Policy log std Max           -0.0700025
Policy log std Min           -0.8490144
Z mean eval                  0.22237964
Z variance eval              0.5044172
total_rewards                [5364.09001741 5278.67568828 5392.82672933 5399.51512146 5322.60050708
 5322.20413073 5327.4280847  5263.3586815  5286.10692173 2774.60574784]
total_rewards_mean           5073.14116300492
total_rewards_std            767.4204087273635
total_rewards_max            5399.51512145613
total_rewards_min            2774.6057478395933
Number of train steps total  1752000
Number of env steps total    2261553
Number of rollouts total     0
Train Time (s)               76.92940820701187
(Previous) Eval Time (s)     18.996556471975055
Sample Time (s)              6.174294494034257
Epoch Time (s)               102.10025917302119
Total Train Time (s)         62067.255693003535
Epoch                        437
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:33:01.362853 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #437 | Epoch Duration: 101.74129295349121
2020-01-06 13:33:01.363010 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #437 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08294606
Z variance train             0.16438118
KL Divergence                2.4942508
KL Loss                      0.24942508
QF Loss                      1210.9698
VF Loss                      384.5621
Policy Loss                  -2884.6445
Q Predictions Mean           2879.1367
Q Predictions Std            243.65816
Q Predictions Max            3006.0398
Q Predictions Min            430.68698
V Predictions Mean           2886.69
V Predictions Std            235.9789
V Predictions Max            3016.4275
V Predictions Min            415.20236
Log Pis Mean                 -5.7347918
Log Pis Std                  5.2613277
Log Pis Max                  30.01031
Log Pis Min                  -17.028122
Policy mu Mean               0.08828627
Policy mu Std                0.68579733
Policy mu Max                2.9341173
Policy mu Min                -4.341784
Policy log std Mean          -0.2625728
Policy log std Std           0.117191754
Policy log std Max           0.121724844
Policy log std Min           -1.4106672
Z mean eval                  0.19478814
Z variance eval              0.49682468
total_rewards                [5541.6606634  5460.17446099 5498.14981832 5358.82309404 5570.1818321
 5474.8320072  5428.55793661 5376.14622107 5384.60379292 5534.69196897]
total_rewards_mean           5462.782179561423
total_rewards_std            70.65891770663855
total_rewards_max            5570.18183210062
total_rewards_min            5358.82309403853
Number of train steps total  1756000
Number of env steps total    2266553
Number of rollouts total     0
Train Time (s)               78.86365829198621
(Previous) Eval Time (s)     18.637381186999846
Sample Time (s)              6.089551020064391
Epoch Time (s)               103.59059049905045
Total Train Time (s)         62171.63069687958
Epoch                        438
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:34:45.740911 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #438 | Epoch Duration: 104.37778615951538
2020-01-06 13:34:45.741020 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #438 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.30317864
Z variance train             0.34210122
KL Divergence                1.3681165
KL Loss                      0.13681166
QF Loss                      1053.0852
VF Loss                      509.78806
Policy Loss                  -2888.0771
Q Predictions Mean           2886.287
Q Predictions Std            218.20686
Q Predictions Max            3023.35
Q Predictions Min            481.5445
V Predictions Mean           2888.2354
V Predictions Std            224.02153
V Predictions Max            3029.7437
V Predictions Min            464.23187
Log Pis Mean                 -5.0830445
Log Pis Std                  4.7017865
Log Pis Max                  22.43586
Log Pis Min                  -15.03504
Policy mu Mean               0.042783782
Policy mu Std                0.7244746
Policy mu Max                2.8011973
Policy mu Min                -3.2287931
Policy log std Mean          -0.2829896
Policy log std Std           0.11775885
Policy log std Max           -0.034978844
Policy log std Min           -0.9229845
Z mean eval                  0.23411472
Z variance eval              0.2136763
total_rewards                [5528.60635193 5516.09447879 5423.93969391 5456.59960729 5442.80975422
 5472.89116599 5490.72374289 5508.91020397 5569.32799227 5426.91791752]
total_rewards_mean           5483.682090877936
total_rewards_std            45.16834439325513
total_rewards_max            5569.327992265251
total_rewards_min            5423.939693912505
Number of train steps total  1760000
Number of env steps total    2271553
Number of rollouts total     0
Train Time (s)               74.07645848899847
(Previous) Eval Time (s)     19.42436711397022
Sample Time (s)              6.044752340123523
Epoch Time (s)               99.54557794309221
Total Train Time (s)         62270.36242578371
Epoch                        439
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:36:24.475751 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #439 | Epoch Duration: 98.7346453666687
2020-01-06 13:36:24.475857 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #439 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.34587955
Z variance train             0.33783078
KL Divergence                1.453088
KL Loss                      0.14530881
QF Loss                      953.3648
VF Loss                      183.55255
Policy Loss                  -2929.055
Q Predictions Mean           2934.8206
Q Predictions Std            73.387276
Q Predictions Max            3035.1733
Q Predictions Min            2415.2925
V Predictions Mean           2927.9565
V Predictions Std            72.42051
V Predictions Max            3029.9932
V Predictions Min            2489.976
Log Pis Mean                 -5.9511385
Log Pis Std                  3.8306363
Log Pis Max                  12.054602
Log Pis Min                  -15.400757
Policy mu Mean               0.07832203
Policy mu Std                0.66860473
Policy mu Max                2.298132
Policy mu Min                -2.7262974
Policy log std Mean          -0.26912114
Policy log std Std           0.103227906
Policy log std Max           -0.06980242
Policy log std Min           -0.82281023
Z mean eval                  0.10455488
Z variance eval              0.26054496
total_rewards                [5488.19983506 5475.71437039 5501.76483467 5457.77081067 5549.44660596
 5551.37482377 5541.31917347 5495.25549059 5534.48195606 5410.26019457]
total_rewards_mean           5500.558809521835
total_rewards_std            43.0914073643286
total_rewards_max            5551.374823768296
total_rewards_min            5410.260194569497
Number of train steps total  1764000
Number of env steps total    2276553
Number of rollouts total     0
Train Time (s)               74.68420935899485
(Previous) Eval Time (s)     18.613222878950182
Sample Time (s)              5.8297073830035515
Epoch Time (s)               99.12713962094858
Total Train Time (s)         62369.88066046068
Epoch                        440
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:38:03.997077 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #440 | Epoch Duration: 99.5211296081543
2020-01-06 13:38:03.997175 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #440 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1597636
Z variance train             3.6630414
KL Divergence                7.8254046
KL Loss                      0.7825405
QF Loss                      1071.1742
VF Loss                      505.6325
Policy Loss                  -2921.731
Q Predictions Mean           2925.4417
Q Predictions Std            137.2764
Q Predictions Max            3032.9739
Q Predictions Min            1741.3855
V Predictions Mean           2920.0803
V Predictions Std            149.81593
V Predictions Max            3032.5828
V Predictions Min            1655.525
Log Pis Mean                 -5.7004185
Log Pis Std                  4.098829
Log Pis Max                  15.993856
Log Pis Min                  -13.813641
Policy mu Mean               0.04630327
Policy mu Std                0.6812013
Policy mu Max                2.6454513
Policy mu Min                -2.575674
Policy log std Mean          -0.27276936
Policy log std Std           0.11439683
Policy log std Max           -0.06255582
Policy log std Min           -1.1656933
Z mean eval                  0.10735717
Z variance eval              0.31247824
total_rewards                [5408.3751961  5335.1708553  5421.66660368 5346.8912834  5333.43375759
 5311.29939591 5253.45364405 5385.09585787 5353.18959649 5362.12067083]
total_rewards_mean           5351.069686122598
total_rewards_std            46.09129027217018
total_rewards_max            5421.666603684626
total_rewards_min            5253.45364404773
Number of train steps total  1768000
Number of env steps total    2281553
Number of rollouts total     0
Train Time (s)               76.4389766509994
(Previous) Eval Time (s)     19.007005601015408
Sample Time (s)              6.058076059038285
Epoch Time (s)               101.50405831105309
Total Train Time (s)         62471.34098748572
Epoch                        441
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:39:45.460523 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #441 | Epoch Duration: 101.4632658958435
2020-01-06 13:39:45.460622 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #441 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.17320271
Z variance train             0.8697979
KL Divergence                0.17293124
KL Loss                      0.017293124
QF Loss                      1164.3712
VF Loss                      250.9831
Policy Loss                  -2886.6711
Q Predictions Mean           2886.834
Q Predictions Std            209.96736
Q Predictions Max            3017.6238
Q Predictions Min            408.3771
V Predictions Mean           2886.478
V Predictions Std            213.1692
V Predictions Max            3017.576
V Predictions Min            417.73972
Log Pis Mean                 -5.6613693
Log Pis Std                  4.0108275
Log Pis Max                  17.217913
Log Pis Min                  -14.283666
Policy mu Mean               0.053340994
Policy mu Std                0.68531626
Policy mu Max                2.7913244
Policy mu Min                -2.860457
Policy log std Mean          -0.27421227
Policy log std Std           0.11807252
Policy log std Max           -0.012279823
Policy log std Min           -1.3456626
Z mean eval                  0.09881638
Z variance eval              0.256807
total_rewards                [2743.43240659 5544.62248631 5543.58050932 5509.55182485 5532.62655324
 5524.52988436 5482.67652437 5544.10994507 3431.82593134 5523.30914948]
total_rewards_mean           5038.026521492983
total_rewards_std            987.4335878923468
total_rewards_max            5544.622486308068
total_rewards_min            2743.432406594846
Number of train steps total  1772000
Number of env steps total    2286553
Number of rollouts total     0
Train Time (s)               76.62457495502895
(Previous) Eval Time (s)     18.966000885993708
Sample Time (s)              6.030328554974403
Epoch Time (s)               101.62090439599706
Total Train Time (s)         62571.85749780777
Epoch                        442
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:41:25.980198 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #442 | Epoch Duration: 100.51949715614319
2020-01-06 13:41:25.980310 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #442 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06911683
Z variance train             0.46489042
KL Divergence                0.64478475
KL Loss                      0.06447848
QF Loss                      680.45435
VF Loss                      189.18248
Policy Loss                  -2896.2236
Q Predictions Mean           2892.6633
Q Predictions Std            247.74464
Q Predictions Max            3010.1265
Q Predictions Min            118.536514
V Predictions Mean           2902.1338
V Predictions Std            245.54497
V Predictions Max            3024.1523
V Predictions Min            166.88683
Log Pis Mean                 -5.8414774
Log Pis Std                  4.9662514
Log Pis Max                  20.146246
Log Pis Min                  -16.06585
Policy mu Mean               0.08747126
Policy mu Std                0.69676816
Policy mu Max                2.6404731
Policy mu Min                -3.0143921
Policy log std Mean          -0.27272898
Policy log std Std           0.10580079
Policy log std Max           -0.066999674
Policy log std Min           -1.064641
Z mean eval                  0.3567576
Z variance eval              0.45736185
total_rewards                [5398.48924563 5466.11608628 5507.70134651 5446.1417363  5390.029378
 5352.51216218 2415.72749404 5419.23237974 2165.78136052 5264.72193965]
total_rewards_mean           4782.645312885251
total_rewards_std            1248.7558330575644
total_rewards_max            5507.701346507575
total_rewards_min            2165.78136051772
Number of train steps total  1776000
Number of env steps total    2291553
Number of rollouts total     0
Train Time (s)               73.68492238898762
(Previous) Eval Time (s)     17.864378849975765
Sample Time (s)              5.950098043016624
Epoch Time (s)               97.49939928198
Total Train Time (s)         62668.4402905968
Epoch                        443
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:43:02.566111 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #443 | Epoch Duration: 96.5857195854187
2020-01-06 13:43:02.566223 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #443 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11933956
Z variance train             0.15200791
KL Divergence                2.6772108
KL Loss                      0.2677211
QF Loss                      712.4519
VF Loss                      542.8753
Policy Loss                  -2891.4622
Q Predictions Mean           2894.0625
Q Predictions Std            225.21542
Q Predictions Max            3024.8171
Q Predictions Min            678.1377
V Predictions Mean           2901.0952
V Predictions Std            224.59889
V Predictions Max            3024.9736
V Predictions Min            686.61505
Log Pis Mean                 -5.737525
Log Pis Std                  4.4981537
Log Pis Max                  38.967815
Log Pis Min                  -14.382907
Policy mu Mean               0.058948763
Policy mu Std                0.6876551
Policy mu Max                3.2052023
Policy mu Min                -2.8876402
Policy log std Mean          -0.26901627
Policy log std Std           0.10241063
Policy log std Max           -0.052468047
Policy log std Min           -1.0041701
Z mean eval                  0.13054872
Z variance eval              0.14716987
total_rewards                [5561.90337632 4212.90235123 5649.22374339 5606.54629802 5550.3248925
 5486.01717338 5552.90393513 1401.40185791 5601.31699067 5665.16454053]
total_rewards_mean           5028.770515908814
total_rewards_std            1277.3049004411082
total_rewards_max            5665.164540528424
total_rewards_min            1401.4018579078681
Number of train steps total  1780000
Number of env steps total    2296743
Number of rollouts total     0
Train Time (s)               73.88339130603708
(Previous) Eval Time (s)     16.95048214698909
Sample Time (s)              6.149580386118032
Epoch Time (s)               96.9834538391442
Total Train Time (s)         62765.69927580893
Epoch                        444
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:44:39.828216 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #444 | Epoch Duration: 97.26190638542175
2020-01-06 13:44:39.828315 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #444 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.17631033
Z variance train             0.06691189
KL Divergence                4.55558
KL Loss                      0.45555803
QF Loss                      706.4346
VF Loss                      254.43631
Policy Loss                  -2923.897
Q Predictions Mean           2921.0225
Q Predictions Std            124.28021
Q Predictions Max            3026.3018
Q Predictions Min            1541.0654
V Predictions Mean           2931.377
V Predictions Std            118.26688
V Predictions Max            3039.411
V Predictions Min            1780.6354
Log Pis Mean                 -6.423759
Log Pis Std                  4.213891
Log Pis Max                  16.782711
Log Pis Min                  -14.504589
Policy mu Mean               0.06386746
Policy mu Std                0.65634006
Policy mu Max                2.5087507
Policy mu Min                -3.288499
Policy log std Mean          -0.26274243
Policy log std Std           0.10561991
Policy log std Max           -0.056778945
Policy log std Min           -0.88882005
Z mean eval                  0.1732004
Z variance eval              0.071758404
total_rewards                [5465.20932574 2714.58586701 5468.08642014 3857.89467068 5509.21048388
 5488.41588731 5512.70746056 1443.44199576 5476.07430186 5517.1484405 ]
total_rewards_mean           4645.277485343123
total_rewards_std            1400.309778437212
total_rewards_max            5517.148440498335
total_rewards_min            1443.4419957618372
Number of train steps total  1784000
Number of env steps total    2301858
Number of rollouts total     0
Train Time (s)               75.22695071296766
(Previous) Eval Time (s)     17.22872513497714
Sample Time (s)              6.044224202109035
Epoch Time (s)               98.49990005005384
Total Train Time (s)         62863.30134233809
Epoch                        445
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:46:17.433444 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #445 | Epoch Duration: 97.60504937171936
2020-01-06 13:46:17.433541 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #445 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.17642327
Z variance train             0.08289627
KL Divergence                4.0549936
KL Loss                      0.40549937
QF Loss                      870.4336
VF Loss                      321.6927
Policy Loss                  -2917.8867
Q Predictions Mean           2915.815
Q Predictions Std            111.45212
Q Predictions Max            3018.4119
Q Predictions Min            1967.1881
V Predictions Mean           2911.9058
V Predictions Std            113.762665
V Predictions Max            3025.1238
V Predictions Min            1897.8827
Log Pis Mean                 -5.931826
Log Pis Std                  4.6293535
Log Pis Max                  24.702473
Log Pis Min                  -15.978834
Policy mu Mean               0.08016165
Policy mu Std                0.6693638
Policy mu Max                3.184372
Policy mu Min                -2.2005844
Policy log std Mean          -0.26289672
Policy log std Std           0.106483504
Policy log std Max           0.0101266205
Policy log std Min           -1.0564843
Z mean eval                  0.14127533
Z variance eval              0.07311039
total_rewards                [5402.92487766 5317.03013789 5491.44816844 5393.03015499 5430.41213229
 5377.21738022 5423.25464078 5500.77290732 5349.6340935  5322.47048493]
total_rewards_mean           5400.819497801536
total_rewards_std            59.9871956170528
total_rewards_max            5500.772907324892
total_rewards_min            5317.030137886401
Number of train steps total  1788000
Number of env steps total    2306992
Number of rollouts total     0
Train Time (s)               73.93930009298492
(Previous) Eval Time (s)     16.33366691903211
Sample Time (s)              5.95374464901397
Epoch Time (s)               96.226711661031
Total Train Time (s)         62962.35172075004
Epoch                        446
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:47:56.487046 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #446 | Epoch Duration: 99.05341792106628
2020-01-06 13:47:56.487150 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #446 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1963449
Z variance train             0.0907644
KL Divergence                3.8717642
KL Loss                      0.38717642
QF Loss                      966.6488
VF Loss                      289.79013
Policy Loss                  -2900.7
Q Predictions Mean           2900.0432
Q Predictions Std            260.02597
Q Predictions Max            3039.4165
Q Predictions Min            380.29968
V Predictions Mean           2913.4092
V Predictions Std            261.64853
V Predictions Max            3050.0605
V Predictions Min            403.22388
Log Pis Mean                 -6.607275
Log Pis Std                  4.286314
Log Pis Max                  20.671917
Log Pis Min                  -19.028496
Policy mu Mean               0.04796907
Policy mu Std                0.6622715
Policy mu Max                2.5455413
Policy mu Min                -2.3174918
Policy log std Mean          -0.2594457
Policy log std Std           0.10459663
Policy log std Max           -0.023131192
Policy log std Min           -1.0161853
Z mean eval                  0.25293672
Z variance eval              0.072967574
total_rewards                [5686.94460406  715.93424824 5410.41347264 3073.65712319 2394.57994244
 5610.91503601 5611.48635443 5612.9523681  4298.75600235 5650.89410255]
total_rewards_mean           4406.653325400771
total_rewards_std            1673.625074235812
total_rewards_max            5686.944604055122
total_rewards_min            715.9342482423116
Number of train steps total  1792000
Number of env steps total    2311992
Number of rollouts total     0
Train Time (s)               73.35466444503982
(Previous) Eval Time (s)     19.16015067504486
Sample Time (s)              5.98403132695239
Epoch Time (s)               98.49884644703707
Total Train Time (s)         63057.47482788912
Epoch                        447
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:49:31.613314 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #447 | Epoch Duration: 95.12607932090759
2020-01-06 13:49:31.613417 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #447 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.27283847
Z variance train             0.07708542
KL Divergence                4.3417406
KL Loss                      0.43417406
QF Loss                      871.1408
VF Loss                      366.38657
Policy Loss                  -2884.026
Q Predictions Mean           2885.5537
Q Predictions Std            279.5811
Q Predictions Max            3025.809
Q Predictions Min            262.78317
V Predictions Mean           2889.6675
V Predictions Std            280.39658
V Predictions Max            3043.1553
V Predictions Min            278.39502
Log Pis Mean                 -6.003644
Log Pis Std                  4.0721016
Log Pis Max                  15.773401
Log Pis Min                  -14.584299
Policy mu Mean               0.07180855
Policy mu Std                0.6797117
Policy mu Max                2.2479331
Policy mu Min                -3.5376022
Policy log std Mean          -0.27153468
Policy log std Std           0.10557222
Policy log std Max           -0.041507483
Policy log std Min           -1.0320857
Z mean eval                  0.84959143
Z variance eval              0.7085437
total_rewards                [4798.77367417 5257.01601697 5570.58007328 5647.60211299 5646.07911071
 5541.33971256 1944.65814451 5532.48162586 5690.91805919 2405.27294301]
total_rewards_mean           4803.472147325738
total_rewards_std            1341.803305908251
total_rewards_max            5690.918059194188
total_rewards_min            1944.6581445116806
Number of train steps total  1796000
Number of env steps total    2317163
Number of rollouts total     0
Train Time (s)               73.46950761199696
(Previous) Eval Time (s)     15.787185054039583
Sample Time (s)              6.219577546056826
Epoch Time (s)               95.47627021209337
Total Train Time (s)         63153.26393698115
Epoch                        448
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:51:07.405544 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #448 | Epoch Duration: 95.79203009605408
2020-01-06 13:51:07.405646 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #448 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.37995386
Z variance train             0.28604692
KL Divergence                1.8224173
KL Loss                      0.18224172
QF Loss                      741.61426
VF Loss                      254.67717
Policy Loss                  -2925.234
Q Predictions Mean           2919.1592
Q Predictions Std            191.62631
Q Predictions Max            3030.3345
Q Predictions Min            443.51447
V Predictions Mean           2922.032
V Predictions Std            193.91559
V Predictions Max            3039.2393
V Predictions Min            386.82632
Log Pis Mean                 -5.7900414
Log Pis Std                  4.9077616
Log Pis Max                  38.327034
Log Pis Min                  -13.239693
Policy mu Mean               0.08042614
Policy mu Std                0.69615144
Policy mu Max                4.3915944
Policy mu Min                -2.8397787
Policy log std Mean          -0.27622712
Policy log std Std           0.10676462
Policy log std Max           0.09728971
Policy log std Min           -1.0305132
Z mean eval                  0.11589243
Z variance eval              0.07772719
total_rewards                [5516.88570583 5547.58850277 5438.4082958  1635.75423948 2363.75747816
 5506.59764207 5536.37968349 5526.66319904 5590.64947678 5507.48899931]
total_rewards_mean           4817.017322272253
total_rewards_std            1418.465852695146
total_rewards_max            5590.649476784089
total_rewards_min            1635.7542394767074
Number of train steps total  1800000
Number of env steps total    2322659
Number of rollouts total     0
Train Time (s)               74.29305186402053
(Previous) Eval Time (s)     16.102740057976916
Sample Time (s)              6.7245945549802855
Epoch Time (s)               97.12038647697773
Total Train Time (s)         63251.061944592104
Epoch                        449
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:52:45.208914 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #449 | Epoch Duration: 97.80317187309265
2020-01-06 13:52:45.209077 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #449 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09418388
Z variance train             0.09618091
KL Divergence                3.674718
KL Loss                      0.36747178
QF Loss                      1471.4479
VF Loss                      225.2883
Policy Loss                  -2929.5024
Q Predictions Mean           2924.9438
Q Predictions Std            73.044846
Q Predictions Max            3024.2737
Q Predictions Min            2527.86
V Predictions Mean           2935.6467
V Predictions Std            74.44571
V Predictions Max            3040.2578
V Predictions Min            2579.9377
Log Pis Mean                 -5.864536
Log Pis Std                  4.3237357
Log Pis Max                  19.68586
Log Pis Min                  -14.642878
Policy mu Mean               0.09728554
Policy mu Std                0.6994808
Policy mu Max                2.4873981
Policy mu Min                -2.0341692
Policy log std Mean          -0.26451477
Policy log std Std           0.11368093
Policy log std Max           0.045403257
Policy log std Min           -0.8368544
Z mean eval                  0.1339347
Z variance eval              0.11821814
total_rewards                [5430.59085137 2934.0137505  5444.55047307 5463.80024141 3665.79112139
 5441.94385444 5475.31387697 5507.9954312  5459.22379097 5467.12631846]
total_rewards_mean           5029.034970977482
total_rewards_std            880.14299892771
total_rewards_max            5507.99543119685
total_rewards_min            2934.0137505027988
Number of train steps total  1804000
Number of env steps total    2327659
Number of rollouts total     0
Train Time (s)               75.2888836049824
(Previous) Eval Time (s)     16.78531543101417
Sample Time (s)              6.35023090505274
Epoch Time (s)               98.42442994104931
Total Train Time (s)         63350.21682300605
Epoch                        450
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:54:24.366803 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #450 | Epoch Duration: 99.15760064125061
2020-01-06 13:54:24.366905 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #450 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.13525133
Z variance train             0.08770194
KL Divergence                3.903916
KL Loss                      0.3903916
QF Loss                      1509.3147
VF Loss                      846.0769
Policy Loss                  -2905.242
Q Predictions Mean           2910.6013
Q Predictions Std            168.10973
Q Predictions Max            3035.6033
Q Predictions Min            1588.9397
V Predictions Mean           2909.666
V Predictions Std            174.24203
V Predictions Max            3045.0544
V Predictions Min            1201.1046
Log Pis Mean                 -5.765734
Log Pis Std                  5.119133
Log Pis Max                  30.7617
Log Pis Min                  -15.387742
Policy mu Mean               0.04984873
Policy mu Std                0.6793461
Policy mu Max                3.3325977
Policy mu Min                -4.0978203
Policy log std Mean          -0.26709244
Policy log std Std           0.11230596
Policy log std Max           -0.05593857
Policy log std Min           -1.1249088
Z mean eval                  0.10180664
Z variance eval              0.0725824
total_rewards                [5302.95593896 5351.86497613 5369.91849939 5417.63449603 5385.23305728
 5330.69697234 5370.87482393 5393.90836221 5267.88895068 5426.048778  ]
total_rewards_mean           5361.702485495992
total_rewards_std            47.24577295635824
total_rewards_max            5426.048777998974
total_rewards_min            5267.888950681751
Number of train steps total  1808000
Number of env steps total    2332659
Number of rollouts total     0
Train Time (s)               73.61316365702078
(Previous) Eval Time (s)     17.518246816005558
Sample Time (s)              5.8756632569711655
Epoch Time (s)               97.0070737299975
Total Train Time (s)         63448.87718678615
Epoch                        451
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:56:03.030345 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #451 | Epoch Duration: 98.66335821151733
2020-01-06 13:56:03.030444 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #451 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.055393506
Z variance train             0.1525581
KL Divergence                2.6370323
KL Loss                      0.26370323
QF Loss                      1413.6284
VF Loss                      409.69186
Policy Loss                  -2909.9722
Q Predictions Mean           2902.3281
Q Predictions Std            265.83392
Q Predictions Max            3043.866
Q Predictions Min            233.17514
V Predictions Mean           2902.0
V Predictions Std            272.7677
V Predictions Max            3050.8735
V Predictions Min            242.1997
Log Pis Mean                 -5.7719965
Log Pis Std                  4.8082047
Log Pis Max                  23.281553
Log Pis Min                  -15.550463
Policy mu Mean               0.050904784
Policy mu Std                0.68768585
Policy mu Max                2.9880304
Policy mu Min                -3.1614966
Policy log std Mean          -0.26587033
Policy log std Std           0.1033184
Policy log std Max           -0.03881547
Policy log std Min           -1.0069112
Z mean eval                  0.04767868
Z variance eval              0.07811208
total_rewards                [5566.8094403  5380.96287987 5322.87886813 5341.70830416 5411.84666279
 5420.06670616 5363.45173182 5473.73724864 5465.2773296  5538.45277916]
total_rewards_mean           5428.519195063362
total_rewards_std            77.55399596791389
total_rewards_max            5566.809440297823
total_rewards_min            5322.878868134147
Number of train steps total  1812000
Number of env steps total    2337659
Number of rollouts total     0
Train Time (s)               73.16765655996278
(Previous) Eval Time (s)     19.17432477802504
Sample Time (s)              6.060156010906212
Epoch Time (s)               98.40213734889403
Total Train Time (s)         63547.521839930094
Epoch                        452
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:57:41.678157 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #452 | Epoch Duration: 98.64763116836548
2020-01-06 13:57:41.678262 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #452 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03373509
Z variance train             0.1656803
KL Divergence                2.4594293
KL Loss                      0.24594294
QF Loss                      883.9541
VF Loss                      345.62247
Policy Loss                  -2891.2537
Q Predictions Mean           2880.4814
Q Predictions Std            316.73117
Q Predictions Max            3043.1343
Q Predictions Min            261.27652
V Predictions Mean           2881.7158
V Predictions Std            307.2732
V Predictions Max            3028.6199
V Predictions Min            315.62854
Log Pis Mean                 -5.175539
Log Pis Std                  5.4044795
Log Pis Max                  33.831516
Log Pis Min                  -16.165627
Policy mu Mean               0.051716868
Policy mu Std                0.7231951
Policy mu Max                2.9428487
Policy mu Min                -3.3664854
Policy log std Mean          -0.29115713
Policy log std Std           0.1237058
Policy log std Max           0.06509136
Policy log std Min           -1.5526184
Z mean eval                  0.16210586
Z variance eval              0.10987885
total_rewards                [5431.22153199 5477.72202007 5408.73261807 5459.36934538 1468.19840012
 5400.1763528  5408.08784148 5474.48196811 5513.91308007 5421.12669653]
total_rewards_mean           5046.302985461823
total_rewards_std            1193.2183391607243
total_rewards_max            5513.913080072134
total_rewards_min            1468.198400121962
Number of train steps total  1816000
Number of env steps total    2342659
Number of rollouts total     0
Train Time (s)               75.91790825000498
(Previous) Eval Time (s)     19.419609093980398
Sample Time (s)              6.147597430914175
Epoch Time (s)               101.48511477489956
Total Train Time (s)         63647.119840662985
Epoch                        453
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 13:59:21.279642 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #453 | Epoch Duration: 99.60129976272583
2020-01-06 13:59:21.279740 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #453 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05733911
Z variance train             0.13578206
KL Divergence                2.8866954
KL Loss                      0.28866956
QF Loss                      567.7868
VF Loss                      156.38507
Policy Loss                  -2943.2695
Q Predictions Mean           2932.1873
Q Predictions Std            63.754322
Q Predictions Max            3035.7524
Q Predictions Min            2621.0056
V Predictions Mean           2947.7104
V Predictions Std            63.933918
V Predictions Max            3052.584
V Predictions Min            2625.782
Log Pis Mean                 -6.1987033
Log Pis Std                  3.585845
Log Pis Max                  9.907396
Log Pis Min                  -15.760983
Policy mu Mean               0.06616534
Policy mu Std                0.65828556
Policy mu Max                1.8488847
Policy mu Min                -3.1827288
Policy log std Mean          -0.26783466
Policy log std Std           0.10395519
Policy log std Max           -0.049972504
Policy log std Min           -0.8763385
Z mean eval                  0.13031548
Z variance eval              0.11017512
total_rewards                [5426.48367617 5388.96653703 1413.87513083 5478.6601417  3610.83007301
 5477.22188992 5458.01140173 5495.85229904 5388.14482592 5398.82774242]
total_rewards_mean           4853.687371776534
total_rewards_std            1270.0950471735223
total_rewards_max            5495.852299042775
total_rewards_min            1413.8751308321903
Number of train steps total  1820000
Number of env steps total    2347659
Number of rollouts total     0
Train Time (s)               73.4549856520025
(Previous) Eval Time (s)     17.535587719990872
Sample Time (s)              5.873640073055867
Epoch Time (s)               96.86421344504924
Total Train Time (s)         63743.11777348013
Epoch                        454
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 14:00:57.280826 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #454 | Epoch Duration: 96.00100541114807
2020-01-06 14:00:57.280927 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #454 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.106278695
Z variance train             0.059615504
KL Divergence                4.7719593
KL Loss                      0.47719595
QF Loss                      834.2432
VF Loss                      326.46295
Policy Loss                  -2911.5767
Q Predictions Mean           2906.254
Q Predictions Std            190.69691
Q Predictions Max            3040.4521
Q Predictions Min            703.6052
V Predictions Mean           2922.031
V Predictions Std            193.66942
V Predictions Max            3041.0598
V Predictions Min            593.27466
Log Pis Mean                 -6.334215
Log Pis Std                  3.718937
Log Pis Max                  10.710092
Log Pis Min                  -15.135449
Policy mu Mean               0.060511462
Policy mu Std                0.6597578
Policy mu Max                2.4324162
Policy mu Min                -2.5633776
Policy log std Mean          -0.26262853
Policy log std Std           0.10408053
Policy log std Max           -0.05478452
Policy log std Min           -1.191874
Z mean eval                  0.106636025
Z variance eval              0.097904526
total_rewards                [5455.97941677 5476.61686804 5663.27474032 5451.59710849 3336.94875894
 5526.66822426 5499.36314033 1541.43568196 5466.62432869 5286.5548111 ]
total_rewards_mean           4870.506307890197
total_rewards_std            1283.170662643187
total_rewards_max            5663.274740324674
total_rewards_min            1541.4356819579632
Number of train steps total  1824000
Number of env steps total    2352659
Number of rollouts total     0
Train Time (s)               73.8140789649915
(Previous) Eval Time (s)     16.672164761985186
Sample Time (s)              5.939866669010371
Epoch Time (s)               96.42611039598705
Total Train Time (s)         63839.9032679192
Epoch                        455
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 14:02:34.069499 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #455 | Epoch Duration: 96.78849148750305
2020-01-06 14:02:34.069599 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #455 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14098266
Z variance train             0.0884565
KL Divergence                3.886435
KL Loss                      0.3886435
QF Loss                      901.29175
VF Loss                      602.8106
Policy Loss                  -2930.1824
Q Predictions Mean           2925.8054
Q Predictions Std            165.65147
Q Predictions Max            3037.4883
Q Predictions Min            826.41925
V Predictions Mean           2921.7524
V Predictions Std            154.6778
V Predictions Max            3030.4648
V Predictions Min            1020.2009
Log Pis Mean                 -5.865848
Log Pis Std                  3.9170737
Log Pis Max                  14.042339
Log Pis Min                  -18.49511
Policy mu Mean               0.050637547
Policy mu Std                0.6653686
Policy mu Max                3.0526571
Policy mu Min                -2.4051282
Policy log std Mean          -0.25430122
Policy log std Std           0.101597816
Policy log std Max           -0.0894791
Policy log std Min           -1.3018588
Z mean eval                  0.11851366
Z variance eval              0.10837489
total_rewards                [5487.21775826 5531.47268278 5456.89463527 5429.65985217 5410.81241431
 5611.4615676  5461.48557331 5431.16212001 5439.98881072 5583.1439013 ]
total_rewards_mean           5484.329931571658
total_rewards_std            65.28291225675129
total_rewards_max            5611.46156760415
total_rewards_min            5410.812414306533
Number of train steps total  1828000
Number of env steps total    2357659
Number of rollouts total     0
Train Time (s)               74.18695930199465
(Previous) Eval Time (s)     17.034334798983764
Sample Time (s)              6.005112201091833
Epoch Time (s)               97.22640630207025
Total Train Time (s)         63939.40440318524
Epoch                        456
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 14:04:13.573941 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #456 | Epoch Duration: 99.50425887107849
2020-01-06 14:04:13.574051 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #456 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14736162
Z variance train             0.1277254
KL Divergence                3.0670834
KL Loss                      0.30670834
QF Loss                      628.80273
VF Loss                      247.8066
Policy Loss                  -2936.6626
Q Predictions Mean           2934.6616
Q Predictions Std            89.09561
Q Predictions Max            3046.5315
Q Predictions Min            2471.9312
V Predictions Mean           2935.584
V Predictions Std            92.074684
V Predictions Max            3070.221
V Predictions Min            2451.5098
Log Pis Mean                 -6.5072527
Log Pis Std                  3.8006318
Log Pis Max                  10.0999
Log Pis Min                  -15.301238
Policy mu Mean               0.01771787
Policy mu Std                0.6535646
Policy mu Max                1.9849063
Policy mu Min                -2.1373823
Policy log std Mean          -0.26032284
Policy log std Std           0.10209839
Policy log std Max           -0.033710457
Policy log std Min           -0.9659186
Z mean eval                  0.11109173
Z variance eval              0.10945115
total_rewards                [5341.68134381 5446.84124109 5502.50197175 5492.26532451 5497.09116112
 5420.1825541  5355.97915641 5528.29944535 5513.56942878 5497.05493228]
total_rewards_mean           5459.546655919531
total_rewards_std            63.01345568255415
total_rewards_max            5528.299445349852
total_rewards_min            5341.681343811332
Number of train steps total  1832000
Number of env steps total    2362748
Number of rollouts total     0
Train Time (s)               77.08050034195185
(Previous) Eval Time (s)     19.31197495094966
Sample Time (s)              6.1535634628962725
Epoch Time (s)               102.54603875579778
Total Train Time (s)         64040.687272358045
Epoch                        457
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 14:05:54.860095 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #457 | Epoch Duration: 101.28595972061157
2020-01-06 14:05:54.860200 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #457 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0481319
Z variance train             0.15497963
KL Divergence                2.6031795
KL Loss                      0.26031795
QF Loss                      767.40204
VF Loss                      635.0241
Policy Loss                  -2894.3135
Q Predictions Mean           2889.2795
Q Predictions Std            317.4748
Q Predictions Max            3044.1313
Q Predictions Min            145.84442
V Predictions Mean           2892.5342
V Predictions Std            319.9698
V Predictions Max            3048.8987
V Predictions Min            98.81787
Log Pis Mean                 -5.2344036
Log Pis Std                  4.9232683
Log Pis Max                  23.095726
Log Pis Min                  -12.861543
Policy mu Mean               0.07555802
Policy mu Std                0.7120159
Policy mu Max                3.413483
Policy mu Min                -3.7908895
Policy log std Mean          -0.27992657
Policy log std Std           0.11233079
Policy log std Max           0.21584265
Policy log std Min           -1.0484478
Z mean eval                  0.20004077
Z variance eval              0.88531244
total_rewards                [5322.75228414 5440.87738727 5424.45159586 5447.00423325 5356.83250059
 5442.11234204 5298.87281144 5377.16213828 5381.27454959 5352.48983116]
total_rewards_mean           5384.38296736283
total_rewards_std            49.99954898121592
total_rewards_max            5447.004233253402
total_rewards_min            5298.872811443364
Number of train steps total  1836000
Number of env steps total    2367748
Number of rollouts total     0
Train Time (s)               79.68173440301325
(Previous) Eval Time (s)     18.051680098986253
Sample Time (s)              5.644500967056956
Epoch Time (s)               103.37791546905646
Total Train Time (s)         64143.833788250224
Epoch                        458
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 14:07:38.009761 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #458 | Epoch Duration: 103.1494824886322
2020-01-06 14:07:38.009861 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #458 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.21724312
Z variance train             0.30996585
KL Divergence                1.4022393
KL Loss                      0.14022394
QF Loss                      1135.8745
VF Loss                      773.3777
Policy Loss                  -2928.8909
Q Predictions Mean           2928.9314
Q Predictions Std            205.48451
Q Predictions Max            3046.799
Q Predictions Min            95.27847
V Predictions Mean           2916.477
V Predictions Std            214.41962
V Predictions Max            3027.0684
V Predictions Min            31.59533
Log Pis Mean                 -6.0455403
Log Pis Std                  3.9518752
Log Pis Max                  14.831697
Log Pis Min                  -15.291822
Policy mu Mean               0.06606026
Policy mu Std                0.6674814
Policy mu Max                2.5101428
Policy mu Min                -2.7431116
Policy log std Mean          -0.26828137
Policy log std Std           0.100288235
Policy log std Max           -0.054316416
Policy log std Min           -0.95752877
Z mean eval                  0.19499785
Z variance eval              0.14961442
total_rewards                [5455.43988911 5449.97959536 5590.19097496 5486.70611249 5407.03656247
 4976.60057195 5542.31921349 5450.4528933  5409.76654936 5352.5838808 ]
total_rewards_mean           5412.107624328943
total_rewards_std            158.82590096824646
total_rewards_max            5590.190974957672
total_rewards_min            4976.600571954786
Number of train steps total  1840000
Number of env steps total    2372748
Number of rollouts total     0
Train Time (s)               79.07592899503652
(Previous) Eval Time (s)     17.82305557100335
Sample Time (s)              5.554559748037718
Epoch Time (s)               102.45354431407759
Total Train Time (s)         64246.04914977634
Epoch                        459
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 14:09:20.228327 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #459 | Epoch Duration: 102.21838569641113
2020-01-06 14:09:20.228427 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #459 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.073381774
Z variance train             0.18045738
KL Divergence                2.2988005
KL Loss                      0.22988005
QF Loss                      692.08636
VF Loss                      199.426
Policy Loss                  -2922.1401
Q Predictions Mean           2919.3945
Q Predictions Std            235.4865
Q Predictions Max            3041.319
Q Predictions Min            387.7458
V Predictions Mean           2927.1606
V Predictions Std            235.10828
V Predictions Max            3050.1704
V Predictions Min            445.71426
Log Pis Mean                 -6.3408155
Log Pis Std                  3.7064872
Log Pis Max                  9.526405
Log Pis Min                  -14.14901
Policy mu Mean               0.06231106
Policy mu Std                0.6494243
Policy mu Max                1.9573016
Policy mu Min                -2.3338592
Policy log std Mean          -0.26166633
Policy log std Std           0.09942972
Policy log std Max           0.03644915
Policy log std Min           -0.81372476
Z mean eval                  0.1279165
Z variance eval              0.14959748
total_rewards                [4099.91837926 5427.64707536 5417.95365998 5460.52079464 5389.81885184
 5457.25402553 5392.01933112 5412.57463917 5428.05943888 5402.38664201]
total_rewards_mean           5288.81528377902
total_rewards_std            396.95563866325335
total_rewards_max            5460.520794642443
total_rewards_min            4099.918379255743
Number of train steps total  1844000
Number of env steps total    2377748
Number of rollouts total     0
Train Time (s)               80.10029415501049
(Previous) Eval Time (s)     17.587708897015546
Sample Time (s)              5.601055741950404
Epoch Time (s)               103.28905879397644
Total Train Time (s)         64349.358242801274
Epoch                        460
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 14:11:03.540579 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #460 | Epoch Duration: 103.31207275390625
2020-01-06 14:11:03.540682 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #460 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.082408324
Z variance train             0.17735809
KL Divergence                2.3396835
KL Loss                      0.23396836
QF Loss                      1658.7644
VF Loss                      215.8233
Policy Loss                  -2922.1174
Q Predictions Mean           2915.79
Q Predictions Std            241.70924
Q Predictions Max            3039.1938
Q Predictions Min            237.77504
V Predictions Mean           2923.5742
V Predictions Std            245.65733
V Predictions Max            3058.5032
V Predictions Min            188.19147
Log Pis Mean                 -6.146365
Log Pis Std                  3.8678617
Log Pis Max                  16.918362
Log Pis Min                  -14.502238
Policy mu Mean               0.063708276
Policy mu Std                0.6693122
Policy mu Max                2.9102447
Policy mu Min                -2.666546
Policy log std Mean          -0.2670945
Policy log std Std           0.10675954
Policy log std Max           -0.02325657
Policy log std Min           -0.9735571
Z mean eval                  0.14048937
Z variance eval              0.10052105
total_rewards                [5560.08142185 4917.71485885 1687.94814853 5576.80793239 5603.24788133
 5187.85004301 1890.04043139 5503.07225845 5629.82711595 5640.75480376]
total_rewards_mean           4719.734489551819
total_rewards_std            1482.185687182814
total_rewards_max            5640.754803763489
total_rewards_min            1687.9481485326708
Number of train steps total  1848000
Number of env steps total    2382939
Number of rollouts total     0
Train Time (s)               79.67643998900894
(Previous) Eval Time (s)     17.610534779028967
Sample Time (s)              5.8522300809272565
Epoch Time (s)               103.13920484896516
Total Train Time (s)         64450.47453814623
Epoch                        461
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 14:12:44.660309 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #461 | Epoch Duration: 101.11953783035278
2020-01-06 14:12:44.660413 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #461 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.15627682
Z variance train             0.06856495
KL Divergence                4.4786644
KL Loss                      0.44786644
QF Loss                      1399.7148
VF Loss                      318.95264
Policy Loss                  -2914.7827
Q Predictions Mean           2907.6118
Q Predictions Std            252.23756
Q Predictions Max            3034.0425
Q Predictions Min            210.95418
V Predictions Mean           2911.086
V Predictions Std            257.77438
V Predictions Max            3042.3325
V Predictions Min            174.44868
Log Pis Mean                 -6.4955044
Log Pis Std                  4.0451145
Log Pis Max                  17.230257
Log Pis Min                  -17.622995
Policy mu Mean               0.048558243
Policy mu Std                0.6457855
Policy mu Max                2.381722
Policy mu Min                -2.4478962
Policy log std Mean          -0.25033098
Policy log std Std           0.10141694
Policy log std Max           0.06907067
Policy log std Min           -0.9261899
Z mean eval                  0.14302161
Z variance eval              0.12066285
total_rewards                [4313.04354529 5644.03199664  751.8102788  5690.01610354 5653.56204532
 5634.35208819 5543.46742681 5687.34371941 5508.33666535 5601.82951449]
total_rewards_mean           5002.779338383523
total_rewards_std            1470.639192593103
total_rewards_max            5690.016103535176
total_rewards_min            751.8102788035865
Number of train steps total  1852000
Number of env steps total    2387939
Number of rollouts total     0
Train Time (s)               73.037222525978
(Previous) Eval Time (s)     15.590680880006403
Sample Time (s)              5.896881916909479
Epoch Time (s)               94.52478532289388
Total Train Time (s)         64545.353290708095
Epoch                        462
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 14:14:19.542196 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #462 | Epoch Duration: 94.88169884681702
2020-01-06 14:14:19.542294 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #462 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.20474756
Z variance train             0.13135889
KL Divergence                3.0758884
KL Loss                      0.30758885
QF Loss                      678.85815
VF Loss                      408.62253
Policy Loss                  -2932.0615
Q Predictions Mean           2930.982
Q Predictions Std            204.69798
Q Predictions Max            3041.7935
Q Predictions Min            126.16948
V Predictions Mean           2942.583
V Predictions Std            207.84279
V Predictions Max            3064.6792
V Predictions Min            183.51921
Log Pis Mean                 -6.6511526
Log Pis Std                  3.767643
Log Pis Max                  15.818019
Log Pis Min                  -14.179434
Policy mu Mean               0.06231146
Policy mu Std                0.6388522
Policy mu Max                2.7567801
Policy mu Min                -2.3758976
Policy log std Mean          -0.26675195
Policy log std Std           0.11205455
Policy log std Max           0.07639669
Policy log std Min           -1.2918152
Z mean eval                  0.106839076
Z variance eval              0.109472975
total_rewards                [5437.64928691 3798.41193108 5574.5705367  5357.42181827 5414.11208586
 5574.03110783 4027.51792175 5424.98434613 1644.12890505 5401.88540227]
total_rewards_mean           4765.471334184873
total_rewards_std            1208.052639355087
total_rewards_max            5574.5705367005585
total_rewards_min            1644.1289050469672
Number of train steps total  1856000
Number of env steps total    2392939
Number of rollouts total     0
Train Time (s)               93.4073255599942
(Previous) Eval Time (s)     15.947391610010527
Sample Time (s)              5.5912001629476435
Epoch Time (s)               114.94591733295238
Total Train Time (s)         64661.18908491306
Epoch                        463
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 14:16:15.381737 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #463 | Epoch Duration: 115.83935713768005
2020-01-06 14:16:15.381857 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #463 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10161195
Z variance train             0.15449736
KL Divergence                2.6358619
KL Loss                      0.2635862
QF Loss                      1061.1428
VF Loss                      333.3069
Policy Loss                  -2883.462
Q Predictions Mean           2879.4563
Q Predictions Std            363.7468
Q Predictions Max            3041.8665
Q Predictions Min            122.01914
V Predictions Mean           2886.4727
V Predictions Std            368.64044
V Predictions Max            3056.2932
V Predictions Min            138.18709
Log Pis Mean                 -5.7572737
Log Pis Std                  4.6079235
Log Pis Max                  25.132294
Log Pis Min                  -16.419537
Policy mu Mean               0.06506387
Policy mu Std                0.68281007
Policy mu Max                2.6352456
Policy mu Min                -3.1270292
Policy log std Mean          -0.27019486
Policy log std Std           0.10533482
Policy log std Max           0.077011555
Policy log std Min           -1.0437192
Z mean eval                  0.18290548
Z variance eval              0.21296862
total_rewards                [5508.2457944  5521.78510236 5546.03126304 5544.90169735 5568.04171672
 5525.39661701 5534.98185422 5472.17592624 1117.56318415 5579.35546223]
total_rewards_mean           5091.847861772085
total_rewards_std            1325.0704981587965
total_rewards_max            5579.3554622327065
total_rewards_min            1117.5631841480472
Number of train steps total  1860000
Number of env steps total    2397939
Number of rollouts total     0
Train Time (s)               93.95178156800102
(Previous) Eval Time (s)     16.840638171997853
Sample Time (s)              6.123924607003573
Epoch Time (s)               116.91634434700245
Total Train Time (s)         64779.11142420501
Epoch                        464
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 14:18:13.307455 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #464 | Epoch Duration: 117.92550611495972
2020-01-06 14:18:13.307569 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #464 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1932031
Z variance train             0.068996765
KL Divergence                4.499234
KL Loss                      0.44992343
QF Loss                      577.6862
VF Loss                      319.83093
Policy Loss                  -2914.1692
Q Predictions Mean           2910.3608
Q Predictions Std            281.55655
Q Predictions Max            3043.6572
Q Predictions Min            19.427618
V Predictions Mean           2917.8667
V Predictions Std            286.55746
V Predictions Max            3053.5222
V Predictions Min            21.605015
Log Pis Mean                 -5.997766
Log Pis Std                  3.8803613
Log Pis Max                  15.729724
Log Pis Min                  -13.558338
Policy mu Mean               0.046943493
Policy mu Std                0.6817719
Policy mu Max                2.5897665
Policy mu Min                -3.9737775
Policy log std Mean          -0.2666755
Policy log std Std           0.10615855
Policy log std Max           0.031042695
Policy log std Min           -1.0371689
Z mean eval                  0.16847932
Z variance eval              0.07314412
total_rewards                [5442.32070953 2365.36524005 5494.5560512  5638.06943925 2189.73212301
 4689.31056948 4807.66210222 5589.81497295 5608.54807876 5526.99218173]
total_rewards_mean           4735.237146818405
total_rewards_std            1269.4381866380866
total_rewards_max            5638.069439252003
total_rewards_min            2189.732123006259
Number of train steps total  1864000
Number of env steps total    2402939
Number of rollouts total     0
Train Time (s)               97.87928445998114
(Previous) Eval Time (s)     17.849596462969203
Sample Time (s)              6.238641784992069
Epoch Time (s)               121.96752270794241
Total Train Time (s)         64900.150153938914
Epoch                        465
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 14:20:14.349397 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #465 | Epoch Duration: 121.041743516922
2020-01-06 14:20:14.349497 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #465 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.15674241
Z variance train             0.06092618
KL Divergence                4.754369
KL Loss                      0.4754369
QF Loss                      898.99207
VF Loss                      278.25345
Policy Loss                  -2944.0942
Q Predictions Mean           2935.5195
Q Predictions Std            213.41281
Q Predictions Max            3051.3909
Q Predictions Min            121.292366
V Predictions Mean           2936.936
V Predictions Std            206.87648
V Predictions Max            3050.1348
V Predictions Min            96.20861
Log Pis Mean                 -7.1728916
Log Pis Std                  3.3809211
Log Pis Max                  13.13776
Log Pis Min                  -15.402704
Policy mu Mean               0.043228436
Policy mu Std                0.61214817
Policy mu Max                2.4348145
Policy mu Min                -2.017121
Policy log std Mean          -0.24056342
Policy log std Std           0.08722074
Policy log std Max           -0.0070563853
Policy log std Min           -0.6720059
Z mean eval                  0.1664983
Z variance eval              0.06842159
total_rewards                [5616.2861849  5560.31440408 5717.3879442  5229.40435607 5552.11760714
 5520.34540482 1763.37232241 5556.84741618 1453.19341527 2020.31731873]
total_rewards_mean           4398.95863738066
total_rewards_std            1745.5171815129188
total_rewards_max            5717.387944199816
total_rewards_min            1453.1934152726035
Number of train steps total  1868000
Number of env steps total    2408094
Number of rollouts total     0
Train Time (s)               104.33420576900244
(Previous) Eval Time (s)     16.923611903039273
Sample Time (s)              6.318094460002612
Epoch Time (s)               127.57591213204432
Total Train Time (s)         65026.81773187191
Epoch                        466
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 14:22:21.020529 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #466 | Epoch Duration: 126.67094802856445
2020-01-06 14:22:21.020634 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #466 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.12938963
Z variance train             0.07808332
KL Divergence                4.156428
KL Loss                      0.4156428
QF Loss                      687.68054
VF Loss                      206.10852
Policy Loss                  -2936.1135
Q Predictions Mean           2931.0027
Q Predictions Std            208.53564
Q Predictions Max            3049.3535
Q Predictions Min            -8.382856
V Predictions Mean           2940.3843
V Predictions Std            209.55011
V Predictions Max            3051.2512
V Predictions Min            -11.09713
Log Pis Mean                 -6.304891
Log Pis Std                  4.034265
Log Pis Max                  32.272575
Log Pis Min                  -16.713766
Policy mu Mean               0.06464853
Policy mu Std                0.65418977
Policy mu Max                3.2984087
Policy mu Min                -2.484393
Policy log std Mean          -0.25310466
Policy log std Std           0.100875124
Policy log std Max           -0.0379937
Policy log std Min           -1.1580617
Z mean eval                  0.19064409
Z variance eval              0.055343043
total_rewards                [5579.26918286 5648.19866391  916.24263214 5555.33219681 5516.74963071
 1930.43662665 5604.76886026 5533.96702892 5302.95420667 5585.60890526]
total_rewards_mean           4717.352793417922
total_rewards_std            1664.8460179865654
total_rewards_max            5648.1986639059505
total_rewards_min            916.2426321357336
Number of train steps total  1872000
Number of env steps total    2413245
Number of rollouts total     0
Train Time (s)               114.0371481210459
(Previous) Eval Time (s)     16.018432796001434
Sample Time (s)              6.807190246065147
Epoch Time (s)               136.86277116311248
Total Train Time (s)         65165.145977187145
Epoch                        467
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 14:24:39.352688 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #467 | Epoch Duration: 138.33197116851807
2020-01-06 14:24:39.352797 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #467 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.15513965
Z variance train             0.09085438
KL Divergence                3.830259
KL Loss                      0.3830259
QF Loss                      1145.1936
VF Loss                      375.2983
Policy Loss                  -2946.333
Q Predictions Mean           2942.7622
Q Predictions Std            191.21313
Q Predictions Max            3053.5657
Q Predictions Min            275.71524
V Predictions Mean           2937.1636
V Predictions Std            195.57356
V Predictions Max            3050.5144
V Predictions Min            248.92537
Log Pis Mean                 -6.4694805
Log Pis Std                  3.8967156
Log Pis Max                  15.474881
Log Pis Min                  -14.475592
Policy mu Mean               0.037984986
Policy mu Std                0.65626913
Policy mu Max                2.8813043
Policy mu Min                -2.8418307
Policy log std Mean          -0.2552443
Policy log std Std           0.105367295
Policy log std Max           -0.042246602
Policy log std Min           -1.028024
Z mean eval                  0.1859159
Z variance eval              0.09043739
total_rewards                [5548.36251824 5447.56872311 5552.28663162 5471.99697269 5522.75787933
 3449.62926992 5400.56473606 5507.73055155 5385.32325198 2653.20198667]
total_rewards_mean           4993.942252116039
total_rewards_std            988.9163999865642
total_rewards_max            5552.286631621568
total_rewards_min            2653.201986673831
Number of train steps total  1876000
Number of env steps total    2418245
Number of rollouts total     0
Train Time (s)               108.86182762798853
(Previous) Eval Time (s)     17.487406862026546
Sample Time (s)              6.249692919023801
Epoch Time (s)               132.59892740903888
Total Train Time (s)         65298.04221908521
Epoch                        468
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 14:26:52.252165 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #468 | Epoch Duration: 132.89928650856018
2020-01-06 14:26:52.252266 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #468 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.18545792
Z variance train             0.055543732
KL Divergence                4.9934826
KL Loss                      0.49934825
QF Loss                      603.7328
VF Loss                      317.7567
Policy Loss                  -2945.7373
Q Predictions Mean           2936.5132
Q Predictions Std            176.207
Q Predictions Max            3038.061
Q Predictions Min            718.03125
V Predictions Mean           2934.981
V Predictions Std            177.4297
V Predictions Max            3038.4097
V Predictions Min            738.733
Log Pis Mean                 -6.286355
Log Pis Std                  4.0903454
Log Pis Max                  13.505281
Log Pis Min                  -15.892328
Policy mu Mean               0.051618792
Policy mu Std                0.6605935
Policy mu Max                2.4148269
Policy mu Min                -2.5617437
Policy log std Mean          -0.25162417
Policy log std Std           0.10384772
Policy log std Max           0.15891358
Policy log std Min           -0.8945654
Z mean eval                  0.14355694
Z variance eval              0.09970553
total_rewards                [5485.8186938  5470.47240627 5347.66855206 5472.36122604 5436.32679146
 5532.1304878  5493.95527591 5438.40416357 5394.21957706 3358.05667097]
total_rewards_mean           5242.941384495273
total_rewards_std            630.260136465148
total_rewards_max            5532.13048780494
total_rewards_min            3358.0566709727145
Number of train steps total  1880000
Number of env steps total    2423245
Number of rollouts total     0
Train Time (s)               105.6981036599609
(Previous) Eval Time (s)     17.78754764900077
Sample Time (s)              6.450296602968592
Epoch Time (s)               129.93594791193027
Total Train Time (s)         65429.78355709324
Epoch                        469
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 14:29:03.997252 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #469 | Epoch Duration: 131.7449016571045
2020-01-06 14:29:03.997391 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #469 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.20370288
Z variance train             0.078018926
KL Divergence                4.22198
KL Loss                      0.42219803
QF Loss                      926.0298
VF Loss                      220.86604
Policy Loss                  -2927.1572
Q Predictions Mean           2925.7456
Q Predictions Std            273.16364
Q Predictions Max            3051.6655
Q Predictions Min            110.77699
V Predictions Mean           2927.916
V Predictions Std            266.4742
V Predictions Max            3056.2834
V Predictions Min            132.32602
Log Pis Mean                 -5.7612734
Log Pis Std                  4.6417084
Log Pis Max                  30.603815
Log Pis Min                  -18.426395
Policy mu Mean               0.032319862
Policy mu Std                0.6816968
Policy mu Max                2.4907918
Policy mu Min                -3.0885377
Policy log std Mean          -0.27096814
Policy log std Std           0.10520169
Policy log std Max           -0.05164346
Policy log std Min           -1.4697542
Z mean eval                  0.19825241
Z variance eval              0.10995966
total_rewards                [5379.64367164 5352.13537098 5283.17995762 5407.88456389 5461.79896814
 5418.75660403 5530.25497243 5476.00336487 5372.45625004 5442.71152068]
total_rewards_mean           5412.482524431834
total_rewards_std            66.59810916082976
total_rewards_max            5530.254972434053
total_rewards_min            5283.179957617998
Number of train steps total  1884000
Number of env steps total    2428245
Number of rollouts total     0
Train Time (s)               112.82367644901387
(Previous) Eval Time (s)     19.596285124018323
Sample Time (s)              6.340215759992134
Epoch Time (s)               138.76017733302433
Total Train Time (s)         65569.77486418933
Epoch                        470
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 14:31:23.993857 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #470 | Epoch Duration: 139.99634838104248
2020-01-06 14:31:23.994020 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #470 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1902149
Z variance train             0.085163616
KL Divergence                4.0162516
KL Loss                      0.40162516
QF Loss                      524.8217
VF Loss                      186.7536
Policy Loss                  -2950.0007
Q Predictions Mean           2944.7397
Q Predictions Std            79.11734
Q Predictions Max            3051.387
Q Predictions Min            2414.4924
V Predictions Mean           2945.1387
V Predictions Std            79.9061
V Predictions Max            3049.7075
V Predictions Min            2412.5723
Log Pis Mean                 -5.9071636
Log Pis Std                  4.040849
Log Pis Max                  8.972466
Log Pis Min                  -15.100486
Policy mu Mean               0.046455152
Policy mu Std                0.6788019
Policy mu Max                1.9027841
Policy mu Min                -2.2839203
Policy log std Mean          -0.273846
Policy log std Std           0.10629966
Policy log std Max           -0.042043276
Policy log std Min           -0.8590771
Z mean eval                  0.17172077
Z variance eval              0.11081083
total_rewards                [5418.37061934 5339.29643885 5375.71377616 5470.29244135 2228.89370907
 5436.63716939 5411.42300145 5447.23583122 5505.61902351 5426.32054785]
total_rewards_mean           5105.980255817529
total_rewards_std            960.0283536910001
total_rewards_max            5505.619023506311
total_rewards_min            2228.893709071177
Number of train steps total  1888000
Number of env steps total    2433245
Number of rollouts total     0
Train Time (s)               107.08641812897986
(Previous) Eval Time (s)     20.832231584005058
Sample Time (s)              7.05355618102476
Epoch Time (s)               134.97220589400968
Total Train Time (s)         65702.24573314324
Epoch                        471
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 14:33:36.469853 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #471 | Epoch Duration: 132.47571110725403
2020-01-06 14:33:36.470002 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #471 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1724765
Z variance train             0.08190908
KL Divergence                4.093198
KL Loss                      0.4093198
QF Loss                      1018.89923
VF Loss                      278.25113
Policy Loss                  -2947.8135
Q Predictions Mean           2937.566
Q Predictions Std            107.80972
Q Predictions Max            3040.9575
Q Predictions Min            2022.2421
V Predictions Mean           2947.877
V Predictions Std            103.11302
V Predictions Max            3054.7307
V Predictions Min            2075.696
Log Pis Mean                 -5.75213
Log Pis Std                  3.9327593
Log Pis Max                  15.131805
Log Pis Min                  -12.748869
Policy mu Mean               0.053303648
Policy mu Std                0.67505485
Policy mu Max                2.6229367
Policy mu Min                -2.1772137
Policy log std Mean          -0.2686201
Policy log std Std           0.10471024
Policy log std Max           0.02452878
Policy log std Min           -1.0487983
Z mean eval                  0.15486948
Z variance eval              0.045292635
total_rewards                [5584.91835806 5435.69970834 5519.57239165 5416.05436946 5568.72801799
 5578.73188221 5606.55048619 5499.25027608 5615.8806801  5574.20884074]
total_rewards_mean           5539.959501081629
total_rewards_std            66.34688174175722
total_rewards_max            5615.880680096023
total_rewards_min            5416.0543694584085
Number of train steps total  1892000
Number of env steps total    2438245
Number of rollouts total     0
Train Time (s)               77.66470075998222
(Previous) Eval Time (s)     18.335489095014054
Sample Time (s)              6.279741415928584
Epoch Time (s)               102.27993127092486
Total Train Time (s)         65805.55188057915
Epoch                        472
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 14:35:19.779318 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #472 | Epoch Duration: 103.30920505523682
2020-01-06 14:35:19.779422 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #472 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.15073273
Z variance train             0.06331458
KL Divergence                4.6728134
KL Loss                      0.46728134
QF Loss                      645.3898
VF Loss                      331.16815
Policy Loss                  -2961.4739
Q Predictions Mean           2955.8303
Q Predictions Std            84.55126
Q Predictions Max            3057.1729
Q Predictions Min            2431.933
V Predictions Mean           2952.146
V Predictions Std            79.91457
V Predictions Max            3049.9324
V Predictions Min            2582.5354
Log Pis Mean                 -6.6327744
Log Pis Std                  3.6991425
Log Pis Max                  17.105259
Log Pis Min                  -15.8164015
Policy mu Mean               0.06786205
Policy mu Std                0.6456201
Policy mu Max                2.3375897
Policy mu Min                -2.5574815
Policy log std Mean          -0.2511701
Policy log std Std           0.10100807
Policy log std Max           -0.022603855
Policy log std Min           -0.93562925
Z mean eval                  0.15208563
Z variance eval              0.101206556
total_rewards                [5439.02464214 5505.54724591 4120.34385444 1212.41886623 5535.0307387
 5545.98832309 5487.84592158 5423.72525879 5611.1560064  5465.02206669]
total_rewards_mean           4934.610292396103
total_rewards_std            1308.3112534902173
total_rewards_max            5611.156006397812
total_rewards_min            1212.4188662265894
Number of train steps total  1896000
Number of env steps total    2443245
Number of rollouts total     0
Train Time (s)               77.15207243704936
(Previous) Eval Time (s)     19.364541750052013
Sample Time (s)              6.100837327016052
Epoch Time (s)               102.61745151411742
Total Train Time (s)         65905.31638747227
Epoch                        473
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 14:36:59.547101 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #473 | Epoch Duration: 99.76758575439453
2020-01-06 14:36:59.547206 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #473 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.17393602
Z variance train             0.080023274
KL Divergence                4.1665707
KL Loss                      0.41665706
QF Loss                      754.24713
VF Loss                      361.24927
Policy Loss                  -2929.6404
Q Predictions Mean           2924.0112
Q Predictions Std            297.97397
Q Predictions Max            3054.2817
Q Predictions Min            136.70634
V Predictions Mean           2920.9468
V Predictions Std            302.1249
V Predictions Max            3060.1672
V Predictions Min            165.22673
Log Pis Mean                 -6.4195795
Log Pis Std                  4.3585844
Log Pis Max                  21.13551
Log Pis Min                  -15.271946
Policy mu Mean               0.07817878
Policy mu Std                0.66562873
Policy mu Max                2.632314
Policy mu Min                -2.4320858
Policy log std Mean          -0.2527241
Policy log std Std           0.10748013
Policy log std Max           0.07559687
Policy log std Min           -0.96191734
Z mean eval                  0.13620704
Z variance eval              0.070945635
total_rewards                [5598.32716828 3626.1184564  5546.43250598 5436.79917895 4589.78344923
 5538.46860691 5497.21991182 5566.37329475 5588.21880422 5504.28314813]
total_rewards_mean           5249.202452466877
total_rewards_std            611.5917382780242
total_rewards_max            5598.327168279847
total_rewards_min            3626.1184564038394
Number of train steps total  1900000
Number of env steps total    2448245
Number of rollouts total     0
Train Time (s)               80.44196273002308
(Previous) Eval Time (s)     16.51445633795811
Sample Time (s)              5.826823943119962
Epoch Time (s)               102.78324301110115
Total Train Time (s)         66009.01308295649
Epoch                        474
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 14:38:43.247055 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #474 | Epoch Duration: 103.69976711273193
2020-01-06 14:38:43.247151 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #474 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.19664893
Z variance train             0.10124806
KL Divergence                3.6767123
KL Loss                      0.36767122
QF Loss                      552.82385
VF Loss                      183.22104
Policy Loss                  -2958.3596
Q Predictions Mean           2955.3154
Q Predictions Std            165.38963
Q Predictions Max            3061.0261
Q Predictions Min            504.3809
V Predictions Mean           2958.5415
V Predictions Std            168.63454
V Predictions Max            3060.7102
V Predictions Min            476.28366
Log Pis Mean                 -6.311111
Log Pis Std                  3.8481169
Log Pis Max                  18.15265
Log Pis Min                  -14.830991
Policy mu Mean               0.06819853
Policy mu Std                0.6608819
Policy mu Max                2.3207684
Policy mu Min                -2.492045
Policy log std Mean          -0.2614784
Policy log std Std           0.10123327
Policy log std Max           -0.0799772
Policy log std Min           -0.88425434
Z mean eval                  0.13621351
Z variance eval              0.052113157
total_rewards                [5511.49074572 5441.00172959 5386.18346216 5390.86812775 5385.79532189
 5473.87694166  677.72983746 5314.37085643 2038.85476595 5506.61647925]
total_rewards_mean           4612.678826785557
total_rewards_std            1656.415741587414
total_rewards_max            5511.490745724605
total_rewards_min            677.7298374579409
Number of train steps total  1904000
Number of env steps total    2453245
Number of rollouts total     0
Train Time (s)               78.5917203790159
(Previous) Eval Time (s)     17.430753452994395
Sample Time (s)              5.71652878500754
Epoch Time (s)               101.73900261701783
Total Train Time (s)         66109.96342162747
Epoch                        475
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 14:40:24.200792 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #475 | Epoch Duration: 100.9535584449768
2020-01-06 14:40:24.200914 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #475 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14636852
Z variance train             0.080886714
KL Divergence                4.1235886
KL Loss                      0.41235885
QF Loss                      873.361
VF Loss                      156.4041
Policy Loss                  -2958.0225
Q Predictions Mean           2954.8828
Q Predictions Std            72.421684
Q Predictions Max            3046.4082
Q Predictions Min            2501.1084
V Predictions Mean           2960.308
V Predictions Std            76.26322
V Predictions Max            3058.7773
V Predictions Min            2421.6472
Log Pis Mean                 -6.2617025
Log Pis Std                  4.2916017
Log Pis Max                  21.824205
Log Pis Min                  -14.420456
Policy mu Mean               0.05003833
Policy mu Std                0.657449
Policy mu Max                2.320433
Policy mu Min                -2.1063528
Policy log std Mean          -0.27012524
Policy log std Std           0.10593266
Policy log std Max           -0.029784396
Policy log std Min           -0.9622136
Z mean eval                  0.1760247
Z variance eval              0.08792654
total_rewards                [5206.22288922 5332.45547202 5323.75730223 5238.01203538 4995.6638191
 5300.03857932 5408.42063644 5397.1244387  5367.58690185 5377.41853496]
total_rewards_mean           5294.670060920753
total_rewards_std            117.61830690038583
total_rewards_max            5408.420636437362
total_rewards_min            4995.663819096256
Number of train steps total  1908000
Number of env steps total    2458245
Number of rollouts total     0
Train Time (s)               76.20167129102629
(Previous) Eval Time (s)     16.645084791001864
Sample Time (s)              6.094634616107214
Epoch Time (s)               98.94139069813536
Total Train Time (s)         66211.82844267151
Epoch                        476
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 14:42:06.069246 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #476 | Epoch Duration: 101.86824679374695
2020-01-06 14:42:06.069349 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #476 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1418763
Z variance train             0.09963571
KL Divergence                3.6708593
KL Loss                      0.36708593
QF Loss                      766.8584
VF Loss                      319.71097
Policy Loss                  -2969.5317
Q Predictions Mean           2960.748
Q Predictions Std            90.68263
Q Predictions Max            3069.5662
Q Predictions Min            2240.8457
V Predictions Mean           2964.764
V Predictions Std            83.95093
V Predictions Max            3058.844
V Predictions Min            2377.2627
Log Pis Mean                 -6.254746
Log Pis Std                  3.9909625
Log Pis Max                  14.533808
Log Pis Min                  -19.801157
Policy mu Mean               0.043763287
Policy mu Std                0.6766821
Policy mu Max                2.6375606
Policy mu Min                -2.2186418
Policy log std Mean          -0.26596862
Policy log std Std           0.106542274
Policy log std Max           -0.0530286
Policy log std Min           -0.9159115
Z mean eval                  0.13279457
Z variance eval              0.06818171
total_rewards                [5351.99033736 5561.48568058 5490.11299755 5405.91888881 5320.09939147
 5461.632556   5471.5626908  5517.58165244 5443.1479844  5336.48007865]
total_rewards_mean           5436.001225805625
total_rewards_std            76.55254900271244
total_rewards_max            5561.485680576304
total_rewards_min            5320.099391470754
Number of train steps total  1912000
Number of env steps total    2463245
Number of rollouts total     0
Train Time (s)               74.08585009898525
(Previous) Eval Time (s)     19.571726627997123
Sample Time (s)              6.076890228956472
Epoch Time (s)               99.73446695593884
Total Train Time (s)         66311.36533276155
Epoch                        477
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 14:43:45.609427 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #477 | Epoch Duration: 99.5399739742279
2020-01-06 14:43:45.609532 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #477 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.16112724
Z variance train             0.095056444
KL Divergence                3.7775002
KL Loss                      0.37775
QF Loss                      791.54846
VF Loss                      181.75421
Policy Loss                  -2960.3418
Q Predictions Mean           2955.567
Q Predictions Std            101.05565
Q Predictions Max            3059.7625
Q Predictions Min            2038.2003
V Predictions Mean           2963.4417
V Predictions Std            101.68284
V Predictions Max            3069.1887
V Predictions Min            2104.1958
Log Pis Mean                 -6.553998
Log Pis Std                  4.1433244
Log Pis Max                  15.312499
Log Pis Min                  -13.652637
Policy mu Mean               0.03730699
Policy mu Std                0.65195316
Policy mu Max                2.3405178
Policy mu Min                -2.302855
Policy log std Mean          -0.26155943
Policy log std Std           0.101207964
Policy log std Max           -0.036305986
Policy log std Min           -0.8273164
Z mean eval                  0.13246079
Z variance eval              0.07719799
total_rewards                [5409.43324954  334.77152941 3928.4333956  5375.29170718 5635.16163901
 5583.73753378 5606.21865587 5520.23346066 5622.70927985 5494.37552287]
total_rewards_mean           4851.036597377528
total_rewards_std            1581.5716203101763
total_rewards_max            5635.161639013384
total_rewards_min            334.7715294125174
Number of train steps total  1916000
Number of env steps total    2468245
Number of rollouts total     0
Train Time (s)               75.66688790498301
(Previous) Eval Time (s)     19.37702170899138
Sample Time (s)              6.229756978107616
Epoch Time (s)               101.27366659208201
Total Train Time (s)         66410.8502280197
Epoch                        478
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 14:45:25.097603 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #478 | Epoch Duration: 99.48798370361328
2020-01-06 14:45:25.097704 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #478 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11731235
Z variance train             0.08688538
KL Divergence                3.9366593
KL Loss                      0.39366594
QF Loss                      680.1687
VF Loss                      197.63683
Policy Loss                  -2960.2192
Q Predictions Mean           2954.5808
Q Predictions Std            171.87129
Q Predictions Max            3060.0664
Q Predictions Min            627.4903
V Predictions Mean           2960.9402
V Predictions Std            175.01495
V Predictions Max            3076.6423
V Predictions Min            592.9461
Log Pis Mean                 -6.6104593
Log Pis Std                  4.411921
Log Pis Max                  26.183594
Log Pis Min                  -13.653385
Policy mu Mean               0.03855586
Policy mu Std                0.63016474
Policy mu Max                2.8057675
Policy mu Min                -2.5598803
Policy log std Mean          -0.24762052
Policy log std Std           0.099364206
Policy log std Max           -0.06816816
Policy log std Min           -1.0864246
Z mean eval                  0.1733588
Z variance eval              0.12909468
total_rewards                [2236.07669099 5517.48245181 5414.84601568 5344.62814968 1445.11696817
 5402.74472444 5436.04179537 5434.03843003 5318.82832063 5414.47518363]
total_rewards_mean           4696.427873043171
total_rewards_std            1439.7126528115837
total_rewards_max            5517.482451809534
total_rewards_min            1445.116968168323
Number of train steps total  1920000
Number of env steps total    2473339
Number of rollouts total     0
Train Time (s)               74.38948071497725
(Previous) Eval Time (s)     17.5911258070264
Sample Time (s)              6.130282149941195
Epoch Time (s)               98.11088867194485
Total Train Time (s)         66508.61004939175
Epoch                        479
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 14:47:02.860746 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #479 | Epoch Duration: 97.76295948028564
2020-01-06 14:47:02.860845 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #479 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.120754346
Z variance train             0.08977517
KL Divergence                3.8530319
KL Loss                      0.3853032
QF Loss                      592.4331
VF Loss                      364.69058
Policy Loss                  -2946.4438
Q Predictions Mean           2942.6104
Q Predictions Std            224.42595
Q Predictions Max            3064.492
Q Predictions Min            613.38153
V Predictions Mean           2949.431
V Predictions Std            224.78995
V Predictions Max            3071.3745
V Predictions Min            630.31116
Log Pis Mean                 -5.989235
Log Pis Std                  4.3780003
Log Pis Max                  18.787989
Log Pis Min                  -17.680965
Policy mu Mean               0.051642735
Policy mu Std                0.678887
Policy mu Max                2.3860047
Policy mu Min                -3.748076
Policy log std Mean          -0.26675197
Policy log std Std           0.10524064
Policy log std Max           -0.048108235
Policy log std Min           -1.0372027
Z mean eval                  0.11866926
Z variance eval              0.06205379
total_rewards                [5633.2804624  5557.85391083 5437.25493812 2869.5435091  5575.46840754
 5456.27260408 5599.3661805  5596.61935179 2873.33046488 5605.16625924]
total_rewards_mean           5020.415608847364
total_rewards_std            1076.1787239621779
total_rewards_max            5633.280462401236
total_rewards_min            2869.543509099128
Number of train steps total  1924000
Number of env steps total    2478339
Number of rollouts total     0
Train Time (s)               73.43264948902652
(Previous) Eval Time (s)     17.24298922799062
Sample Time (s)              5.863198157923762
Epoch Time (s)               96.5388368749409
Total Train Time (s)         66604.86415868369
Epoch                        480
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 14:48:39.118162 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #480 | Epoch Duration: 96.25723767280579
2020-01-06 14:48:39.118262 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #480 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09072101
Z variance train             0.07812296
KL Divergence                4.1557894
KL Loss                      0.41557893
QF Loss                      900.4819
VF Loss                      311.01306
Policy Loss                  -2967.0854
Q Predictions Mean           2971.6533
Q Predictions Std            94.21533
Q Predictions Max            3091.1047
Q Predictions Min            2091.1628
V Predictions Mean           2971.3557
V Predictions Std            91.00357
V Predictions Max            3101.0488
V Predictions Min            2102.4927
Log Pis Mean                 -5.9911203
Log Pis Std                  4.32273
Log Pis Max                  13.308799
Log Pis Min                  -14.167631
Policy mu Mean               0.038107544
Policy mu Std                0.6811321
Policy mu Max                2.581419
Policy mu Min                -2.6361136
Policy log std Mean          -0.26068404
Policy log std Std           0.11106515
Policy log std Max           0.009050757
Policy log std Min           -0.9665908
Z mean eval                  0.13349235
Z variance eval              0.090228125
total_rewards                [4388.9342658  5567.00168099 5546.27099446 5590.50710487 5655.75831347
 3471.02769839 5685.96743672 5556.68011892 5488.40452647 5434.53908282]
total_rewards_mean           5238.509122292346
total_rewards_std            689.1095271195402
total_rewards_max            5685.967436716471
total_rewards_min            3471.0276983923272
Number of train steps total  1928000
Number of env steps total    2483339
Number of rollouts total     0
Train Time (s)               73.91030612302711
(Previous) Eval Time (s)     16.96117703197524
Sample Time (s)              5.873885361012071
Epoch Time (s)               96.74536851601442
Total Train Time (s)         66702.72739982366
Epoch                        481
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 14:50:16.984862 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #481 | Epoch Duration: 97.86651468276978
2020-01-06 14:50:16.984965 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #481 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14111657
Z variance train             0.10573082
KL Divergence                3.5078254
KL Loss                      0.35078254
QF Loss                      884.4209
VF Loss                      654.0283
Policy Loss                  -2967.0945
Q Predictions Mean           2958.3843
Q Predictions Std            161.10829
Q Predictions Max            3070.668
Q Predictions Min            802.97986
V Predictions Mean           2948.0881
V Predictions Std            160.88953
V Predictions Max            3054.3474
V Predictions Min            857.2395
Log Pis Mean                 -6.504849
Log Pis Std                  4.1522913
Log Pis Max                  22.807707
Log Pis Min                  -14.696934
Policy mu Mean               0.04951792
Policy mu Std                0.65284574
Policy mu Max                3.4366324
Policy mu Min                -2.5253716
Policy log std Mean          -0.2564195
Policy log std Std           0.10353947
Policy log std Max           -0.07149407
Policy log std Min           -1.1576403
Z mean eval                  0.12275648
Z variance eval              0.054057248
total_rewards                [5563.39958966 3931.08658309 5577.23968992 5610.43928438 5713.95040048
 5555.55230139 5691.38404922 5674.39542814 5625.54459503 5591.76213361]
total_rewards_mean           5453.475405491365
total_rewards_std            510.10885409242536
total_rewards_max            5713.950400475433
total_rewards_min            3931.0865830891285
Number of train steps total  1932000
Number of env steps total    2488339
Number of rollouts total     0
Train Time (s)               74.40917098597856
(Previous) Eval Time (s)     18.082110717019532
Sample Time (s)              6.138474132982083
Epoch Time (s)               98.62975583598018
Total Train Time (s)         66801.9150173667
Epoch                        482
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 14:51:56.175860 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #482 | Epoch Duration: 99.19081139564514
2020-01-06 14:51:56.175975 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #482 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.107105866
Z variance train             0.058555316
KL Divergence                4.8311605
KL Loss                      0.48311606
QF Loss                      618.037
VF Loss                      404.62592
Policy Loss                  -2967.4573
Q Predictions Mean           2966.3896
Q Predictions Std            131.3477
Q Predictions Max            3080.1875
Q Predictions Min            1400.8774
V Predictions Mean           2969.8394
V Predictions Std            130.72293
V Predictions Max            3077.799
V Predictions Min            1363.7883
Log Pis Mean                 -6.193053
Log Pis Std                  4.595434
Log Pis Max                  36.402527
Log Pis Min                  -15.52508
Policy mu Mean               0.0438641
Policy mu Std                0.657346
Policy mu Max                3.2857955
Policy mu Min                -3.5733187
Policy log std Mean          -0.26260394
Policy log std Std           0.10677313
Policy log std Max           -0.08820068
Policy log std Min           -1.4455286
Z mean eval                  0.103695765
Z variance eval              0.08457033
total_rewards                [3111.32752798 5495.90084061 5697.49120365 5575.78805527 5599.53368208
 5607.53582888 5594.64711524 5663.05520875 5546.85787673 5657.98051978]
total_rewards_mean           5355.011785897315
total_rewards_std            749.9648828695074
total_rewards_max            5697.491203647731
total_rewards_min            3111.3275279798636
Number of train steps total  1936000
Number of env steps total    2493339
Number of rollouts total     0
Train Time (s)               74.03467289003311
(Previous) Eval Time (s)     18.6429613790242
Sample Time (s)              6.041136128129438
Epoch Time (s)               98.71877039718674
Total Train Time (s)         66900.8773983469
Epoch                        483
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 14:53:35.141575 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #483 | Epoch Duration: 98.96551704406738
2020-01-06 14:53:35.141691 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #483 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10546446
Z variance train             0.09814067
KL Divergence                3.648194
KL Loss                      0.3648194
QF Loss                      1146.8945
VF Loss                      983.6382
Policy Loss                  -2940.8977
Q Predictions Mean           2938.842
Q Predictions Std            283.47766
Q Predictions Max            3084.4326
Q Predictions Min            273.85367
V Predictions Mean           2938.5388
V Predictions Std            277.41824
V Predictions Max            3078.4045
V Predictions Min            242.14285
Log Pis Mean                 -5.7048044
Log Pis Std                  4.987143
Log Pis Max                  25.194584
Log Pis Min                  -16.135975
Policy mu Mean               0.045416147
Policy mu Std                0.7057014
Policy mu Max                3.0786166
Policy mu Min                -2.764093
Policy log std Mean          -0.2706468
Policy log std Std           0.11617016
Policy log std Max           0.034477286
Policy log std Min           -1.209522
Z mean eval                  0.13852802
Z variance eval              0.119318046
total_rewards                [5448.26917469 4613.93938196 5342.74391986 5405.1794636  5504.02565141
 5386.01144139 5384.70731911 5446.51748215 5379.69069826 5588.3399702 ]
total_rewards_mean           5349.942450261179
total_rewards_std            254.51284475058193
total_rewards_max            5588.339970197216
total_rewards_min            4613.9393819554525
Number of train steps total  1940000
Number of env steps total    2498339
Number of rollouts total     0
Train Time (s)               78.27537876699353
(Previous) Eval Time (s)     18.889506302017253
Sample Time (s)              6.008677859965246
Epoch Time (s)               103.17356292897603
Total Train Time (s)         67004.96898517787
Epoch                        484
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 14:55:19.238701 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #484 | Epoch Duration: 104.09691643714905
2020-01-06 14:55:19.238873 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #484 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.16598128
Z variance train             0.14900115
KL Divergence                2.7728152
KL Loss                      0.27728152
QF Loss                      1789.0391
VF Loss                      326.99817
Policy Loss                  -2964.9377
Q Predictions Mean           2966.9204
Q Predictions Std            160.00917
Q Predictions Max            3088.0105
Q Predictions Min            780.63324
V Predictions Mean           2969.965
V Predictions Std            168.58873
V Predictions Max            3088.5012
V Predictions Min            697.21533
Log Pis Mean                 -6.3912907
Log Pis Std                  3.8377256
Log Pis Max                  14.362285
Log Pis Min                  -14.941169
Policy mu Mean               0.027194615
Policy mu Std                0.65642434
Policy mu Max                2.236554
Policy mu Min                -2.4153342
Policy log std Mean          -0.25722072
Policy log std Std           0.10054178
Policy log std Max           -0.030877054
Policy log std Min           -0.9713688
Z mean eval                  0.13811277
Z variance eval              0.092224725
total_rewards                [5455.14963335 5428.45972418 5456.51132981 5589.61436018 3590.07965796
 5574.37663219 5457.55913761 5350.81000498 5431.93290338 5378.36986039]
total_rewards_mean           5271.28632440262
total_rewards_std            564.8686226587996
total_rewards_max            5589.614360181376
total_rewards_min            3590.0796579642324
Number of train steps total  1944000
Number of env steps total    2503339
Number of rollouts total     0
Train Time (s)               77.42752897698665
(Previous) Eval Time (s)     19.812638303032145
Sample Time (s)              6.349791890010238
Epoch Time (s)               103.58995917002903
Total Train Time (s)         67107.38261259586
Epoch                        485
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 14:57:01.656384 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #485 | Epoch Duration: 102.41739416122437
2020-01-06 14:57:01.656491 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #485 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.119190015
Z variance train             0.07046299
KL Divergence                4.405114
KL Loss                      0.44051144
QF Loss                      682.71216
VF Loss                      428.4899
Policy Loss                  -2974.5479
Q Predictions Mean           2972.1191
Q Predictions Std            79.74428
Q Predictions Max            3060.894
Q Predictions Min            2383.4492
V Predictions Mean           2988.566
V Predictions Std            80.92478
V Predictions Max            3076.7786
V Predictions Min            2526.8982
Log Pis Mean                 -6.6687884
Log Pis Std                  3.8210013
Log Pis Max                  15.743189
Log Pis Min                  -14.359458
Policy mu Mean               0.061002668
Policy mu Std                0.6436201
Policy mu Max                2.4861076
Policy mu Min                -2.242561
Policy log std Mean          -0.26054668
Policy log std Std           0.10819916
Policy log std Max           -0.05788114
Policy log std Min           -0.92309844
Z mean eval                  0.11425157
Z variance eval              0.06054954
total_rewards                [5452.23821687 1300.75712851 5571.03063039 5519.69011157 5534.52287346
 5422.96204314 5489.08641304 5469.99989565 4783.56812146 5610.6354649 ]
total_rewards_mean           5015.449089897931
total_rewards_std            1258.0588109751088
total_rewards_max            5610.635464895024
total_rewards_min            1300.7571285128315
Number of train steps total  1948000
Number of env steps total    2508339
Number of rollouts total     0
Train Time (s)               75.58918130001985
(Previous) Eval Time (s)     18.639866781013552
Sample Time (s)              6.110679448989686
Epoch Time (s)               100.33972753002308
Total Train Time (s)         67207.32670718193
Epoch                        486
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 14:58:41.604033 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #486 | Epoch Duration: 99.94746017456055
2020-01-06 14:58:41.604135 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #486 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.14022237
Z variance train             0.09155716
KL Divergence                3.836081
KL Loss                      0.3836081
QF Loss                      487.68146
VF Loss                      667.75195
Policy Loss                  -2972.5225
Q Predictions Mean           2964.8218
Q Predictions Std            169.7727
Q Predictions Max            3078.92
Q Predictions Min            801.40216
V Predictions Mean           2963.041
V Predictions Std            165.78537
V Predictions Max            3072.2368
V Predictions Min            805.08374
Log Pis Mean                 -6.135211
Log Pis Std                  4.5622025
Log Pis Max                  24.009598
Log Pis Min                  -14.737668
Policy mu Mean               0.08839459
Policy mu Std                0.67358106
Policy mu Max                2.4707608
Policy mu Min                -2.9458265
Policy log std Mean          -0.26530525
Policy log std Std           0.105091974
Policy log std Max           -0.036855835
Policy log std Min           -1.2496636
Z mean eval                  0.11638997
Z variance eval              0.108751036
total_rewards                [4802.16823356 1943.82029557 5506.9378609  5468.82914216 5293.34998171
 5490.25710498 4682.14787294 5288.81614694 5508.65410047 5427.69248915]
total_rewards_mean           4941.267322837276
total_rewards_std            1037.9867109276656
total_rewards_max            5508.654100465373
total_rewards_min            1943.8202955710972
Number of train steps total  1952000
Number of env steps total    2513339
Number of rollouts total     0
Train Time (s)               75.94609747402137
(Previous) Eval Time (s)     18.247387773008086
Sample Time (s)              5.705177829950117
Epoch Time (s)               99.89866307697957
Total Train Time (s)         67306.63903698395
Epoch                        487
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 15:00:20.919723 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #487 | Epoch Duration: 99.31550693511963
2020-01-06 15:00:20.919821 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #487 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11165075
Z variance train             0.10026373
KL Divergence                3.6046433
KL Loss                      0.36046433
QF Loss                      449.40268
VF Loss                      153.09958
Policy Loss                  -2972.001
Q Predictions Mean           2967.2314
Q Predictions Std            258.38055
Q Predictions Max            3079.8223
Q Predictions Min            189.14017
V Predictions Mean           2970.58
V Predictions Std            261.4852
V Predictions Max            3088.2144
V Predictions Min            177.8249
Log Pis Mean                 -6.780867
Log Pis Std                  3.886541
Log Pis Max                  23.539146
Log Pis Min                  -14.834085
Policy mu Mean               0.06009836
Policy mu Std                0.6251509
Policy mu Max                2.7809856
Policy mu Min                -2.6440878
Policy log std Mean          -0.24822465
Policy log std Std           0.10199545
Policy log std Max           0.12218392
Policy log std Min           -0.9884639
Z mean eval                  0.10230692
Z variance eval              0.06410174
total_rewards                [5170.53185117 5480.46236139 3915.68595226 3230.27215328 4449.39734015
 4248.73362236 5593.59963637 1665.33247446 3745.8078878  2282.06472279]
total_rewards_mean           3978.1888002040696
total_rewards_std            1242.043478991685
total_rewards_max            5593.599636368666
total_rewards_min            1665.3324744647211
Number of train steps total  1956000
Number of env steps total    2518471
Number of rollouts total     0
Train Time (s)               73.22202668403042
(Previous) Eval Time (s)     17.664029148989357
Sample Time (s)              5.955948179936968
Epoch Time (s)               96.84200401295675
Total Train Time (s)         67399.48403853289
Epoch                        488
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 15:01:53.768402 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #488 | Epoch Duration: 92.84849119186401
2020-01-06 15:01:53.768549 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #488 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.12339208
Z variance train             0.10009758
KL Divergence                3.6307
KL Loss                      0.36307
QF Loss                      632.7009
VF Loss                      190.02174
Policy Loss                  -2982.306
Q Predictions Mean           2978.48
Q Predictions Std            179.26779
Q Predictions Max            3075.6577
Q Predictions Min            368.21582
V Predictions Mean           2982.1277
V Predictions Std            182.72168
V Predictions Max            3090.192
V Predictions Min            313.7225
Log Pis Mean                 -6.3779316
Log Pis Std                  3.6196847
Log Pis Max                  7.20765
Log Pis Min                  -14.610658
Policy mu Mean               0.059512105
Policy mu Std                0.6619329
Policy mu Max                3.3406904
Policy mu Min                -2.084437
Policy log std Mean          -0.25624287
Policy log std Std           0.09937355
Policy log std Max           0.29144365
Policy log std Min           -0.9610074
Z mean eval                  0.12318458
Z variance eval              0.10035735
total_rewards                [5570.61345877 5315.16201063 5470.01100158 5570.91354108 5630.0369853
 5477.18668333 5515.30799328 5455.13885428 5432.52563834 5496.393779  ]
total_rewards_mean           5493.328994558979
total_rewards_std            82.99223240810397
total_rewards_max            5630.036985299686
total_rewards_min            5315.162010630352
Number of train steps total  1960000
Number of env steps total    2523471
Number of rollouts total     0
Train Time (s)               79.35384868702386
(Previous) Eval Time (s)     13.670302712998819
Sample Time (s)              6.367704409058206
Epoch Time (s)               99.39185580908088
Total Train Time (s)         67505.11653947097
Epoch                        489
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 15:03:39.405418 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #489 | Epoch Duration: 105.6367609500885
2020-01-06 15:03:39.405520 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #489 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.19202748
Z variance train             0.16767867
KL Divergence                2.5546134
KL Loss                      0.25546134
QF Loss                      556.5004
VF Loss                      318.2054
Policy Loss                  -2975.6113
Q Predictions Mean           2974.8213
Q Predictions Std            229.53859
Q Predictions Max            3081.028
Q Predictions Min            80.69565
V Predictions Mean           2980.9858
V Predictions Std            223.54167
V Predictions Max            3090.9465
V Predictions Min            96.283585
Log Pis Mean                 -6.5664945
Log Pis Std                  3.6912413
Log Pis Max                  16.543577
Log Pis Min                  -15.582815
Policy mu Mean               0.07656252
Policy mu Std                0.6278795
Policy mu Max                2.3536453
Policy mu Min                -2.2245502
Policy log std Mean          -0.24619398
Policy log std Std           0.088437654
Policy log std Max           -0.07442218
Policy log std Min           -0.9841691
Z mean eval                  0.1438504
Z variance eval              0.08669355
total_rewards                [5691.10500234 1748.81284994 5601.09178715 5549.92730449 3860.25792426
 1789.29013753 5539.30039836 5470.34901349 5195.94007787 5520.59753854]
total_rewards_mean           4596.667203397138
total_rewards_std            1500.4652339587876
total_rewards_max            5691.105002336981
total_rewards_min            1748.8128499417746
Number of train steps total  1964000
Number of env steps total    2528471
Number of rollouts total     0
Train Time (s)               79.16135307098739
(Previous) Eval Time (s)     19.91499480395578
Sample Time (s)              6.239653160970192
Epoch Time (s)               105.31600103591336
Total Train Time (s)         67607.21964003186
Epoch                        490
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 15:05:21.512524 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #490 | Epoch Duration: 102.1069188117981
2020-01-06 15:05:21.512650 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #490 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.17385189
Z variance train             0.10819473
KL Divergence                3.4731748
KL Loss                      0.3473175
QF Loss                      444.4315
VF Loss                      262.62213
Policy Loss                  -2983.7344
Q Predictions Mean           2982.651
Q Predictions Std            168.62352
Q Predictions Max            3086.5142
Q Predictions Min            517.106
V Predictions Mean           2983.2163
V Predictions Std            173.04405
V Predictions Max            3097.568
V Predictions Min            478.03662
Log Pis Mean                 -6.795107
Log Pis Std                  3.2158604
Log Pis Max                  8.480712
Log Pis Min                  -14.590032
Policy mu Mean               0.08679585
Policy mu Std                0.6466297
Policy mu Max                1.8814874
Policy mu Min                -2.0335076
Policy log std Mean          -0.25618213
Policy log std Std           0.098463625
Policy log std Max           -0.028423369
Policy log std Min           -1.0313623
Z mean eval                  0.17121238
Z variance eval              0.1096621
total_rewards                [5433.66124113  825.72459267 5490.89720222 5561.68417504 5440.18975022
 5455.89530701 5422.06859251 5461.62361546 5561.32679135 5426.57063482]
total_rewards_mean           5007.96419024216
total_rewards_std            1394.9325510623362
total_rewards_max            5561.684175035055
total_rewards_min            825.7245926695256
Number of train steps total  1968000
Number of env steps total    2533792
Number of rollouts total     0
Train Time (s)               79.85336013801862
(Previous) Eval Time (s)     16.7056886649807
Sample Time (s)              6.584340910019819
Epoch Time (s)               103.14338971301913
Total Train Time (s)         67712.42351491592
Epoch                        491
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 15:07:06.720041 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #491 | Epoch Duration: 105.20728874206543
2020-01-06 15:07:06.720191 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #491 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.17520204
Z variance train             0.13040873
KL Divergence                3.0721288
KL Loss                      0.3072129
QF Loss                      782.2139
VF Loss                      348.46448
Policy Loss                  -2966.7224
Q Predictions Mean           2966.5908
Q Predictions Std            219.00186
Q Predictions Max            3084.5583
Q Predictions Min            344.08005
V Predictions Mean           2974.5017
V Predictions Std            220.87169
V Predictions Max            3096.8618
V Predictions Min            306.7229
Log Pis Mean                 -5.772773
Log Pis Std                  5.08412
Log Pis Max                  25.924812
Log Pis Min                  -15.831239
Policy mu Mean               0.037164737
Policy mu Std                0.6915255
Policy mu Max                2.5974216
Policy mu Min                -2.45241
Policy log std Mean          -0.27656257
Policy log std Std           0.116673246
Policy log std Max           0.049569577
Policy log std Min           -1.3205159
Z mean eval                  0.24176192
Z variance eval              0.17102726
total_rewards                [5578.15890602 5456.35939999 1134.0842725  5474.64709644 2215.83235421
 5530.69065522 5622.75527807 5640.60074982 5606.10557933 5502.72022565]
total_rewards_mean           4776.195451724466
total_rewards_std            1570.4696192410063
total_rewards_max            5640.600749818556
total_rewards_min            1134.0842725002137
Number of train steps total  1972000
Number of env steps total    2538896
Number of rollouts total     0
Train Time (s)               79.86854797898559
(Previous) Eval Time (s)     18.769362266990356
Sample Time (s)              6.468521620030515
Epoch Time (s)               105.10643186600646
Total Train Time (s)         67815.70953706198
Epoch                        492
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 15:08:50.009455 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #492 | Epoch Duration: 103.2891457080841
2020-01-06 15:08:50.009597 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #492 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.18726693
Z variance train             0.13428599
KL Divergence                3.027121
KL Loss                      0.3027121
QF Loss                      533.15625
VF Loss                      238.79108
Policy Loss                  -2968.006
Q Predictions Mean           2959.7017
Q Predictions Std            253.03265
Q Predictions Max            3083.1697
Q Predictions Min            264.4398
V Predictions Mean           2974.3193
V Predictions Std            255.72694
V Predictions Max            3103.2656
V Predictions Min            257.33795
Log Pis Mean                 -6.1461473
Log Pis Std                  4.2296357
Log Pis Max                  17.40538
Log Pis Min                  -15.408621
Policy mu Mean               0.07017029
Policy mu Std                0.66409236
Policy mu Max                2.5829327
Policy mu Min                -2.81217
Policy log std Mean          -0.26491725
Policy log std Std           0.0985142
Policy log std Max           0.0037719011
Policy log std Min           -0.8256267
Z mean eval                  0.13218406
Z variance eval              0.13378343
total_rewards                [5641.27720502  866.93199543 5495.00640381 5637.30493972 5519.25896225
 5547.89983702 5534.63832833 5527.60466497 5522.65473831 2613.36389828]
total_rewards_mean           4790.594097315559
total_rewards_std            1575.0999007282267
total_rewards_max            5641.277205024333
total_rewards_min            866.9319954309778
Number of train steps total  1976000
Number of env steps total    2543896
Number of rollouts total     0
Train Time (s)               80.04212072701193
(Previous) Eval Time (s)     16.951852902013343
Sample Time (s)              6.377463121083565
Epoch Time (s)               103.37143675010884
Total Train Time (s)         67919.78905019804
Epoch                        493
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 15:10:34.092304 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #493 | Epoch Duration: 104.08261251449585
2020-01-06 15:10:34.092410 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #493 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.12522252
Z variance train             0.121299125
KL Divergence                3.177014
KL Loss                      0.31770143
QF Loss                      753.6378
VF Loss                      175.23535
Policy Loss                  -2986.7778
Q Predictions Mean           2977.5137
Q Predictions Std            157.42566
Q Predictions Max            3097.916
Q Predictions Min            785.70807
V Predictions Mean           2989.4585
V Predictions Std            154.34479
V Predictions Max            3102.572
V Predictions Min            858.70325
Log Pis Mean                 -6.2363973
Log Pis Std                  3.8145912
Log Pis Max                  13.913164
Log Pis Min                  -14.824442
Policy mu Mean               0.063456856
Policy mu Std                0.65630996
Policy mu Max                2.2939568
Policy mu Min                -1.9535997
Policy log std Mean          -0.26233897
Policy log std Std           0.098932885
Policy log std Max           0.009498134
Policy log std Min           -0.9157166
Z mean eval                  0.115427494
Z variance eval              0.12051662
total_rewards                [4783.91801318 4652.09069602 5439.20874144 5438.62276805 5578.33425265
 5551.1250719  4227.76528724 4289.69847003 5522.97272238 5455.58678068]
total_rewards_mean           5093.932280355975
total_rewards_std            518.1638426111725
total_rewards_max            5578.334252647429
total_rewards_min            4227.765287242237
Number of train steps total  1980000
Number of env steps total    2548896
Number of rollouts total     0
Train Time (s)               77.02644417597912
(Previous) Eval Time (s)     17.66280360199744
Sample Time (s)              6.385627962008584
Epoch Time (s)               101.07487573998515
Total Train Time (s)         68020.69497145916
Epoch                        494
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 15:12:15.001601 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #494 | Epoch Duration: 100.90909171104431
2020-01-06 15:12:15.001706 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #494 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1735045
Z variance train             0.19692932
KL Divergence                2.2306905
KL Loss                      0.22306906
QF Loss                      956.32837
VF Loss                      326.56317
Policy Loss                  -2996.707
Q Predictions Mean           2994.1907
Q Predictions Std            91.25909
Q Predictions Max            3095.718
Q Predictions Min            2290.0652
V Predictions Mean           3004.8516
V Predictions Std            87.5266
V Predictions Max            3112.1892
V Predictions Min            2357.7546
Log Pis Mean                 -6.7961783
Log Pis Std                  3.6977444
Log Pis Max                  8.839536
Log Pis Min                  -15.217215
Policy mu Mean               0.06767541
Policy mu Std                0.62686485
Policy mu Max                2.6009488
Policy mu Min                -2.5613685
Policy log std Mean          -0.25362372
Policy log std Std           0.09679156
Policy log std Max           -0.05311893
Policy log std Min           -0.9146509
Z mean eval                  0.13922039
Z variance eval              0.10957225
total_rewards                [5480.924057   3802.68520265 5530.02192466 1008.87197753 5655.72904948
 5457.94434165 5534.35436457 5594.11324121 5555.38324165 5425.79520573]
total_rewards_mean           4904.582260612457
total_rewards_std            1398.2768750873129
total_rewards_max            5655.72904948459
total_rewards_min            1008.8719775294057
Number of train steps total  1984000
Number of env steps total    2553896
Number of rollouts total     0
Train Time (s)               74.04128145001596
(Previous) Eval Time (s)     17.496806879993528
Sample Time (s)              6.064341168035753
Epoch Time (s)               97.60242949804524
Total Train Time (s)         68117.60789329908
Epoch                        495
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 15:13:51.918473 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #495 | Epoch Duration: 96.91668367385864
2020-01-06 15:13:51.918610 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #495 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.17514527
Z variance train             0.17232867
KL Divergence                2.4954033
KL Loss                      0.24954033
QF Loss                      770.3657
VF Loss                      244.00461
Policy Loss                  -2993.0063
Q Predictions Mean           2981.9326
Q Predictions Std            193.21613
Q Predictions Max            3076.4353
Q Predictions Min            401.03763
V Predictions Mean           2987.6968
V Predictions Std            191.91353
V Predictions Max            3082.8303
V Predictions Min            403.79904
Log Pis Mean                 -6.834325
Log Pis Std                  3.731672
Log Pis Max                  15.840758
Log Pis Min                  -13.903635
Policy mu Mean               0.05625308
Policy mu Std                0.6279093
Policy mu Max                2.51005
Policy mu Min                -2.0189614
Policy log std Mean          -0.24359855
Policy log std Std           0.09580406
Policy log std Max           -0.03036207
Policy log std Min           -0.85503006
Z mean eval                  0.09859598
Z variance eval              0.081887186
total_rewards                [5387.23362324 5348.66776942 5444.20735761 5382.30223788 5236.74077641
 5391.96035148 5463.79508267 5484.33252026 5327.978909   5428.64932963]
total_rewards_mean           5389.586795760386
total_rewards_std            69.20184211267895
total_rewards_max            5484.332520260765
total_rewards_min            5236.740776406993
Number of train steps total  1988000
Number of env steps total    2558896
Number of rollouts total     0
Train Time (s)               74.67143790004775
(Previous) Eval Time (s)     16.810850885987747
Sample Time (s)              5.917768977989908
Epoch Time (s)               97.4000577640254
Total Train Time (s)         68217.53669876524
Epoch                        496
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 15:15:31.852447 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #496 | Epoch Duration: 99.93375039100647
2020-01-06 15:15:31.852550 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #496 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.113476396
Z variance train             0.10404245
KL Divergence                3.508669
KL Loss                      0.35086688
QF Loss                      1405.9797
VF Loss                      468.46667
Policy Loss                  -2973.0977
Q Predictions Mean           2969.0974
Q Predictions Std            205.21233
Q Predictions Max            3080.9023
Q Predictions Min            112.141655
V Predictions Mean           2972.0654
V Predictions Std            216.34215
V Predictions Max            3087.5833
V Predictions Min            13.569183
Log Pis Mean                 -5.8639917
Log Pis Std                  5.105473
Log Pis Max                  28.611254
Log Pis Min                  -16.898722
Policy mu Mean               0.06753762
Policy mu Std                0.67740154
Policy mu Max                3.836709
Policy mu Min                -2.819747
Policy log std Mean          -0.27216676
Policy log std Std           0.10991082
Policy log std Max           -0.06504951
Policy log std Min           -1.0416174
Z mean eval                  0.10379684
Z variance eval              0.08737459
total_rewards                [1972.28036167 2052.42830036 2122.28749344 5522.73662865 4131.02078889
 5101.15816356  817.89302546 3704.01427764 2930.10279258 5299.64733596]
total_rewards_mean           3365.3569168189947
total_rewards_std            1549.1412605076937
total_rewards_max            5522.736628654744
total_rewards_min            817.8930254555029
Number of train steps total  1992000
Number of env steps total    2563896
Number of rollouts total     0
Train Time (s)               74.45513386197854
(Previous) Eval Time (s)     19.344332527020015
Sample Time (s)              6.093723294034135
Epoch Time (s)               99.89318968303269
Total Train Time (s)         68309.96698813117
Epoch                        497
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 15:17:04.286478 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #497 | Epoch Duration: 92.43384170532227
2020-01-06 15:17:04.286580 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #497 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1072103
Z variance train             0.08200961
KL Divergence                4.034021
KL Loss                      0.4034021
QF Loss                      1488.3506
VF Loss                      261.49426
Policy Loss                  -2989.4387
Q Predictions Mean           2990.358
Q Predictions Std            134.64665
Q Predictions Max            3086.7703
Q Predictions Min            1174.0886
V Predictions Mean           2985.5498
V Predictions Std            138.62648
V Predictions Max            3083.8186
V Predictions Min            1111.1586
Log Pis Mean                 -6.6505623
Log Pis Std                  3.7269163
Log Pis Max                  15.800099
Log Pis Min                  -14.722979
Policy mu Mean               0.07455064
Policy mu Std                0.6357523
Policy mu Max                2.8159113
Policy mu Min                -2.501818
Policy log std Mean          -0.25237447
Policy log std Std           0.098970555
Policy log std Max           -0.06988563
Policy log std Min           -0.91391677
Z mean eval                  0.12515554
Z variance eval              0.06130166
total_rewards                [5609.957944   5628.27498184 2347.57333425 5583.1922489  5693.8563952
 5630.41018554 3320.0535861  5645.20376751  898.32388769 5577.41607586]
total_rewards_mean           4593.426240689642
total_rewards_std            1666.2459048502578
total_rewards_max            5693.856395201899
total_rewards_min            898.3238876915813
Number of train steps total  1996000
Number of env steps total    2569033
Number of rollouts total     0
Train Time (s)               74.19928979198448
(Previous) Eval Time (s)     11.884765337978024
Sample Time (s)              6.188819144852459
Epoch Time (s)               92.27287427481497
Total Train Time (s)         68405.77613883815
Epoch                        498
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 15:18:40.099558 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #498 | Epoch Duration: 95.81288599967957
2020-01-06 15:18:40.099713 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #498 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.11251514
Z variance train             0.08724258
KL Divergence                3.8936417
KL Loss                      0.38936418
QF Loss                      567.17053
VF Loss                      436.1702
Policy Loss                  -3003.1082
Q Predictions Mean           2996.6108
Q Predictions Std            66.17452
Q Predictions Max            3094.4595
Q Predictions Min            2586.0154
V Predictions Mean           2998.348
V Predictions Std            69.34273
V Predictions Max            3104.4377
V Predictions Min            2627.7449
Log Pis Mean                 -6.7455654
Log Pis Std                  3.5811417
Log Pis Max                  10.002797
Log Pis Min                  -14.347071
Policy mu Mean               0.06335824
Policy mu Std                0.64015394
Policy mu Max                2.0845864
Policy mu Min                -2.0472326
Policy log std Mean          -0.25044116
Policy log std Std           0.0964432
Policy log std Max           -0.07163562
Policy log std Min           -0.9103992
Z mean eval                  0.10570358
Z variance eval              0.0817953
total_rewards                [5384.99683334 5384.12157583 5373.56591156 5532.56476492 5416.89830983
 5426.81875261 5372.01511285 5370.28406054 5525.83535544 5384.31690985]
total_rewards_mean           5417.141758676465
total_rewards_std            58.789866233738245
total_rewards_max            5532.564764919056
total_rewards_min            5370.284060537905
Number of train steps total  2000000
Number of env steps total    2574033
Number of rollouts total     0
Train Time (s)               74.24611307599116
(Previous) Eval Time (s)     15.424565016000997
Sample Time (s)              6.094864145037718
Epoch Time (s)               95.76554223702988
Total Train Time (s)         68505.15840499703
Epoch                        499
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 15:20:19.485205 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #499 | Epoch Duration: 99.38538885116577
2020-01-06 15:20:19.485308 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Iteration #499 | Started Training: True
2020-01-06 15:20:19.866972 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] Variant:
2020-01-06 15:20:19.867249 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] {
  "env_name": "Striker-v2",
  "n_train_tasks": 1,
  "n_eval_tasks": 1,
  "latent_size": 5,
  "net_size": 300,
  "path_to_weights": null,
  "env_params": {
    "n_tasks": 2,
    "randomize_tasks": true
  },
  "algo_params": {
    "meta_batch": 1,
    "num_iterations": 500,
    "num_initial_steps": 2000,
    "num_tasks_sample": 5,
    "num_steps_prior": 400,
    "num_steps_posterior": 0,
    "num_extra_rl_steps_posterior": 600,
    "num_train_steps_per_itr": 4000,
    "num_evals": 2,
    "num_steps_per_eval": 600,
    "batch_size": 256,
    "embedding_batch_size": 100,
    "embedding_mini_batch_size": 100,
    "max_path_length": 200,
    "discount": 0.99,
    "soft_target_tau": 0.005,
    "policy_lr": 0.0003,
    "qf_lr": 0.0003,
    "vf_lr": 0.0003,
    "context_lr": 0.0003,
    "reward_scale": 5.0,
    "sparse_rewards": false,
    "kl_lambda": 0.1,
    "use_information_bottleneck": true,
    "use_next_obs_in_context": false,
    "update_post_train": 1,
    "num_exp_traj_eval": 2,
    "recurrent": false,
    "dump_eval_paths": false
  },
  "util_params": {
    "base_log_dir": "./output_no-use-next-obs",
    "use_gpu": true,
    "gpu_id": 0,
    "debug": false,
    "docker": false,
    "num_iterations": 1000
  }
}
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0015519924
Z variance train             0.0069410778
KL Divergence                9.943127
KL Loss                      0.9943127
QF Loss                      388.5434
VF Loss                      22.16988
Policy Loss                  -4.674006
Q Predictions Mean           0.0028797346
Q Predictions Std            0.00088349724
Q Predictions Max            0.005851442
Q Predictions Min            0.00038586464
V Predictions Mean           0.0002351761
V Predictions Std            0.0008746101
V Predictions Max            0.0029615937
V Predictions Min            -0.002179524
Log Pis Mean                 -4.6894407
Log Pis Std                  0.57067317
Log Pis Max                  -2.6322641
Log Pis Min                  -6.1376953
Policy mu Mean               0.00041830988
Policy mu Std                0.001693545
Policy mu Max                0.0036945872
Policy mu Min                -0.002896359
Policy log std Mean          -0.00034540007
Policy log std Std           0.0013093707
Policy log std Max           0.0014011343
Policy log std Min           -0.0036460357
Z mean eval                  0.0036433502
Z variance eval              0.007072744
total_rewards                [-366.93787102 -274.96457034 -313.84415962 -201.40914384 -342.1288536
 -226.18204072 -409.7297155  -397.07356808 -343.53952518 -332.04121252]
total_rewards_mean           -320.78506604082065
total_rewards_std            65.04554430484256
total_rewards_max            -201.40914384032416
total_rewards_min            -409.72971550408334
Number of train steps total  4000
Number of env steps total    7000
Number of rollouts total     0
Train Time (s)               100.20369661797304
(Previous) Eval Time (s)     0
Sample Time (s)              4.692353603022639
Epoch Time (s)               104.89605022099568
Total Train Time (s)         106.31932448386215
Epoch                        0
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 15:22:06.196284 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] [2020_01_06_15_20_19] Iteration #0 | Epoch Duration: 106.32189154624939
2020-01-06 15:22:06.196393 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] [2020_01_06_15_20_19] Iteration #0 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0036431155
Z variance train             0.007074141
KL Divergence                9.896407
KL Loss                      0.9896407
QF Loss                      326.84833
VF Loss                      74.07493
Policy Loss                  108.35199
Q Predictions Mean           -110.33328
Q Predictions Std            56.426613
Q Predictions Max            -0.008061516
Q Predictions Min            -231.93602
V Predictions Mean           -104.552734
V Predictions Std            56.033913
V Predictions Max            -0.034122992
V Predictions Min            -224.08159
Log Pis Mean                 -0.8124323
Log Pis Std                  2.8395436
Log Pis Max                  12.802778
Log Pis Min                  -6.8108
Policy mu Mean               0.02827101
Policy mu Std                0.7100607
Policy mu Max                2.1444197
Policy mu Min                -2.6336968
Policy log std Mean          -0.71323067
Policy log std Std           0.17802633
Policy log std Max           -0.25279248
Policy log std Min           -1.37577
Z mean eval                  0.008291325
Z variance eval              0.0066031376
total_rewards                [-248.9138631  -284.84543206 -311.87872262 -205.48616938 -340.2516847
 -222.10661961 -408.17260773 -385.83581299 -348.92934994 -323.12925342]
total_rewards_mean           -307.95495155534877
total_rewards_std            64.00494538063991
total_rewards_max            -205.48616938421108
total_rewards_min            -408.1726077309376
Number of train steps total  8000
Number of env steps total    12000
Number of rollouts total     0
Train Time (s)               106.10902893199818
(Previous) Eval Time (s)     1.4256142919766717
Sample Time (s)              3.4500117389834486
Epoch Time (s)               110.9846549629583
Total Train Time (s)         217.2652973808581
Epoch                        1
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 15:23:57.142728 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] [2020_01_06_15_20_19] Iteration #1 | Epoch Duration: 110.94623494148254
2020-01-06 15:23:57.142830 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] [2020_01_06_15_20_19] Iteration #1 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008292021
Z variance train             0.006603266
KL Divergence                10.067834
KL Loss                      1.0067834
QF Loss                      285.86304
VF Loss                      42.207897
Policy Loss                  144.60992
Q Predictions Mean           -149.49455
Q Predictions Std            86.208374
Q Predictions Max            -5.1211457
Q Predictions Min            -344.8157
V Predictions Mean           -144.06624
V Predictions Std            85.229675
V Predictions Max            -0.5551392
V Predictions Min            -320.49576
Log Pis Mean                 -0.1961859
Log Pis Std                  2.5291324
Log Pis Max                  7.245655
Log Pis Min                  -6.8930235
Policy mu Mean               0.037254255
Policy mu Std                0.7861529
Policy mu Max                2.1250143
Policy mu Min                -1.9883287
Policy log std Mean          -0.7071029
Policy log std Std           0.18286973
Policy log std Max           -0.15594761
Policy log std Min           -1.55083
Z mean eval                  0.007230232
Z variance eval              0.0062441635
total_rewards                [-254.03857905 -278.18470277 -328.54924772 -204.6761284  -364.23175534
 -226.91023505 -428.77896718 -401.76998843 -358.60784231 -330.06870901]
total_rewards_mean           -317.5816155251781
total_rewards_std            70.81448927565292
total_rewards_max            -204.67612840343176
total_rewards_min            -428.7789671758374
Number of train steps total  12000
Number of env steps total    17000
Number of rollouts total     0
Train Time (s)               101.46104909101268
(Previous) Eval Time (s)     1.387001764960587
Sample Time (s)              3.44949119706871
Epoch Time (s)               106.29754205304198
Total Train Time (s)         323.5920981009258
Epoch                        2
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 15:25:43.470123 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] [2020_01_06_15_20_19] Iteration #2 | Epoch Duration: 106.32720947265625
2020-01-06 15:25:43.470226 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] [2020_01_06_15_20_19] Iteration #2 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0072318865
Z variance train             0.006243895
KL Divergence                10.20739
KL Loss                      1.020739
QF Loss                      335.42056
VF Loss                      71.321686
Policy Loss                  184.5738
Q Predictions Mean           -190.58842
Q Predictions Std            103.70386
Q Predictions Max            -26.168568
Q Predictions Min            -442.76062
V Predictions Mean           -181.68723
V Predictions Std            100.14914
V Predictions Max            -15.101841
V Predictions Min            -428.7142
Log Pis Mean                 -0.83747846
Log Pis Std                  2.5739777
Log Pis Max                  6.382303
Log Pis Min                  -7.073447
Policy mu Mean               -0.19072458
Policy mu Std                0.68648624
Policy mu Max                2.0910754
Policy mu Min                -2.4145977
Policy log std Mean          -0.72602063
Policy log std Std           0.20358741
Policy log std Max           -0.13502574
Policy log std Min           -1.5800977
Z mean eval                  0.0076201544
Z variance eval              0.00592049
total_rewards                [-243.88590738 -276.59460824 -304.11011173 -201.37007148 -338.37534952
 -231.16424036 -407.79302343 -389.82265592 -339.20939971 -320.59727218]
total_rewards_mean           -305.29226399636855
total_rewards_std            64.04793385552203
total_rewards_max            -201.37007148195735
total_rewards_min            -407.7930234328823
Number of train steps total  16000
Number of env steps total    22000
Number of rollouts total     0
Train Time (s)               101.19751403102418
(Previous) Eval Time (s)     1.4164677719818428
Sample Time (s)              3.545560498139821
Epoch Time (s)               106.15954230114585
Total Train Time (s)         429.6898001629743
Epoch                        3
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 15:27:29.568545 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] [2020_01_06_15_20_19] Iteration #3 | Epoch Duration: 106.0982346534729
2020-01-06 15:27:29.568648 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] [2020_01_06_15_20_19] Iteration #3 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.00763717
Z variance train             0.0059204795
KL Divergence                10.339943
KL Loss                      1.0339943
QF Loss                      335.93307
VF Loss                      67.654495
Policy Loss                  174.94951
Q Predictions Mean           -181.44014
Q Predictions Std            90.581825
Q Predictions Max            -46.31985
Q Predictions Min            -406.14288
V Predictions Mean           -175.56586
V Predictions Std            89.858154
V Predictions Max            -43.380493
V Predictions Min            -399.21893
Log Pis Mean                 -0.8282541
Log Pis Std                  2.738236
Log Pis Max                  9.197859
Log Pis Min                  -8.258131
Policy mu Mean               0.049639046
Policy mu Std                0.69994015
Policy mu Max                2.1915755
Policy mu Min                -2.0622897
Policy log std Mean          -0.69951725
Policy log std Std           0.21206753
Policy log std Max           -0.14055073
Policy log std Min           -1.502487
Z mean eval                  0.0071160956
Z variance eval              0.005728171
total_rewards                [-232.47431737 -252.99365021 -282.83945752 -183.24169001 -307.61175882
 -206.72210731 -391.17190949 -373.51885888 -321.07082534 -304.73544197]
total_rewards_mean           -285.6380016922834
total_rewards_std            64.47951602696351
total_rewards_max            -183.24169001163614
total_rewards_min            -391.17190948846724
Number of train steps total  20000
Number of env steps total    27000
Number of rollouts total     0
Train Time (s)               110.90788581303786
(Previous) Eval Time (s)     1.3549594630021602
Sample Time (s)              3.2554567570332438
Epoch Time (s)               115.51830203307327
Total Train Time (s)         545.2560786580434
Epoch                        4
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 15:29:25.135531 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] [2020_01_06_15_20_19] Iteration #4 | Epoch Duration: 115.56679487228394
2020-01-06 15:29:25.135646 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] [2020_01_06_15_20_19] Iteration #4 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.007082262
Z variance train             0.005727841
KL Divergence                10.422945
KL Loss                      1.0422945
QF Loss                      327.52783
VF Loss                      93.64825
Policy Loss                  201.89244
Q Predictions Mean           -209.28358
Q Predictions Std            94.87046
Q Predictions Max            -20.115683
Q Predictions Min            -469.4346
V Predictions Mean           -195.31659
V Predictions Std            90.81071
V Predictions Max            -22.050955
V Predictions Min            -435.4924
Log Pis Mean                 0.20047775
Log Pis Std                  2.5275722
Log Pis Max                  6.955045
Log Pis Min                  -7.244998
Policy mu Mean               0.044538498
Policy mu Std                0.7975186
Policy mu Max                2.3244648
Policy mu Min                -2.1345956
Policy log std Mean          -0.74201065
Policy log std Std           0.27401936
Policy log std Max           -0.16671437
Policy log std Min           -1.7583127
Z mean eval                  0.008495143
Z variance eval              0.0055751754
total_rewards                [-245.33387676 -273.83791071 -305.05064217 -197.09647539 -338.6859653
 -225.89432189 -400.75706802 -383.60256361 -339.27905923 -325.8633306 ]
total_rewards_mean           -303.54012136711776
total_rewards_std            63.64239696882716
total_rewards_max            -197.09647538950458
total_rewards_min            -400.7570680179926
Number of train steps total  24000
Number of env steps total    32000
Number of rollouts total     0
Train Time (s)               107.00756169098895
(Previous) Eval Time (s)     1.4032609050045721
Sample Time (s)              3.3694096410181373
Epoch Time (s)               111.78023223701166
Total Train Time (s)         657.0161288520903
Epoch                        5
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 15:31:16.896233 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] [2020_01_06_15_20_19] Iteration #5 | Epoch Duration: 111.76050019264221
2020-01-06 15:31:16.896340 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] [2020_01_06_15_20_19] Iteration #5 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008489371
Z variance train             0.005575093
KL Divergence                10.490798
KL Loss                      1.0490798
QF Loss                      356.0137
VF Loss                      147.45453
Policy Loss                  190.42657
Q Predictions Mean           -196.26843
Q Predictions Std            84.621185
Q Predictions Max            -18.422758
Q Predictions Min            -473.91733
V Predictions Mean           -185.41913
V Predictions Std            84.39896
V Predictions Max            -31.925566
V Predictions Min            -470.7244
Log Pis Mean                 -0.29161757
Log Pis Std                  2.7182047
Log Pis Max                  7.5942373
Log Pis Min                  -8.450349
Policy mu Mean               -0.087725386
Policy mu Std                0.7739525
Policy mu Max                2.242085
Policy mu Min                -2.2903264
Policy log std Mean          -0.7014156
Policy log std Std           0.2965331
Policy log std Max           -0.117999785
Policy log std Min           -2.100237
Z mean eval                  0.008382494
Z variance eval              0.0053961803
total_rewards                [-253.09384473 -266.35069831 -300.91357743 -199.39140768 -331.05841968
 -237.22852879 -392.70507944 -377.82276132 -328.3755303  -319.890258  ]
total_rewards_mean           -300.6830105672025
total_rewards_std            58.48676037508946
total_rewards_max            -199.3914076771871
total_rewards_min            -392.70507943659953
Number of train steps total  28000
Number of env steps total    37000
Number of rollouts total     0
Train Time (s)               99.23756783700082
(Previous) Eval Time (s)     1.383317707979586
Sample Time (s)              3.4759268240304664
Epoch Time (s)               104.09681236901088
Total Train Time (s)         761.1791544801672
Epoch                        6
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 15:33:01.060430 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] [2020_01_06_15_20_19] Iteration #6 | Epoch Duration: 104.1640043258667
2020-01-06 15:33:01.060531 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] [2020_01_06_15_20_19] Iteration #6 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008360406
Z variance train             0.0053961044
KL Divergence                10.573133
KL Loss                      1.0573133
QF Loss                      177.24481
VF Loss                      57.322205
Policy Loss                  204.25397
Q Predictions Mean           -211.14178
Q Predictions Std            87.95633
Q Predictions Max            -33.683575
Q Predictions Min            -439.51328
V Predictions Mean           -201.0282
V Predictions Std            86.61452
V Predictions Max            -33.872814
V Predictions Min            -429.03763
Log Pis Mean                 -0.5313762
Log Pis Std                  2.514
Log Pis Max                  7.4237747
Log Pis Min                  -6.7109976
Policy mu Mean               -0.13515554
Policy mu Std                0.73914886
Policy mu Max                2.1542828
Policy mu Min                -2.2171032
Policy log std Mean          -0.6748405
Policy log std Std           0.23908514
Policy log std Max           -0.042696685
Policy log std Min           -2.004881
Z mean eval                  0.007090139
Z variance eval              0.005205519
total_rewards                [-241.34065839 -267.98046958 -312.79335836 -188.21890866 -336.50047921
 -216.3125167  -389.58222    -362.68300859 -323.75794474 -320.6302862 ]
total_rewards_mean           -295.9799850426225
total_rewards_std            61.84117405131787
total_rewards_max            -188.2189086629974
total_rewards_min            -389.58222000442214
Number of train steps total  32000
Number of env steps total    42000
Number of rollouts total     0
Train Time (s)               101.15800189197762
(Previous) Eval Time (s)     1.4502902120002545
Sample Time (s)              3.403365747013595
Epoch Time (s)               106.01165785099147
Total Train Time (s)         867.1541906641796
Epoch                        7
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-06 15:34:47.035922 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] [2020_01_06_15_20_19] Iteration #7 | Epoch Duration: 105.97529649734497
2020-01-06 15:34:47.036034 CST | [2020_01_04_10_10_07] [2020_01_05_03_28_02] [2020_01_05_20_18_33] [2020_01_06_15_20_19] Iteration #7 | Started Training: True
